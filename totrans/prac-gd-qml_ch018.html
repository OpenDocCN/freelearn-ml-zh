<html xml:lang="en-US" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<meta charset="utf-8"/>
<meta content="pandoc" name="generator"/>
<title>ch018.xhtml</title>
<link href="../styles/stylesheet1.css" rel="stylesheet" type="text/css"/>
<!-- kobo-style -->
<style id="koboSpanStyle" type="text/css" xmlns="http://www.w3.org/1999/xhtml">.koboSpan { -webkit-text-combine: inherit; }</style>
</head>
<body epub:type="bodymatter">
<section class="level1 chapterHead" data-number="17" id="chapter-9-quantum-support-vector-machines">
<h1 class="H1---Chapter chapterHead" data-number="17"><span class="titlemark"><span class="koboSpan" id="kobo.1.1" xmlns="http://www.w3.org/1999/xhtml">Chapter 9</span></span><br/>
<span id="x1-1600009"><span class="koboSpan" id="kobo.2.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Support Vector Machines</span></span></h1>
<div class="flushright">
<p><em><span class="koboSpan" id="kobo.3.1" xmlns="http://www.w3.org/1999/xhtml">Artificial Intelligence is the new electricity</span></em><br/><span class="koboSpan" id="kobo.4.1" xmlns="http://www.w3.org/1999/xhtml">
— Andrew Ng</span></p>
</div>
<p><span class="koboSpan" id="kobo.5.1" xmlns="http://www.w3.org/1999/xhtml">In the previous chapter, we learned the basics of machine learning and we got a sneak peek into quantum machine learning. </span><span class="koboSpan" id="kobo.5.2" xmlns="http://www.w3.org/1999/xhtml">It is now time for us to work with our first family of quantum machine learning models: that of </span><strong><span class="koboSpan" id="kobo.6.1" xmlns="http://www.w3.org/1999/xhtml">Quantum</span></strong> <strong><span class="koboSpan" id="kobo.7.1" xmlns="http://www.w3.org/1999/xhtml">Support Vector Machines</span></strong><span class="koboSpan" id="kobo.8.1" xmlns="http://www.w3.org/1999/xhtml"> (often abbreviated as </span><strong><span class="koboSpan" id="kobo.9.1" xmlns="http://www.w3.org/1999/xhtml">QSVM</span></strong><span class="koboSpan" id="kobo.10.1" xmlns="http://www.w3.org/1999/xhtml">s). </span><span class="koboSpan" id="kobo.10.2" xmlns="http://www.w3.org/1999/xhtml">These are very </span><span id="dx1-160001"/><span class="koboSpan" id="kobo.11.1" xmlns="http://www.w3.org/1999/xhtml">popular models, and they are most naturally used in binary classification problems.</span></p>
<p><span class="koboSpan" id="kobo.12.1" xmlns="http://www.w3.org/1999/xhtml">In this chapter, we shall learn what (classical) support vector machines are and how they are used, and we will use this knowledge as a foundation to understand quantum support vector machines. </span><span class="koboSpan" id="kobo.12.2" xmlns="http://www.w3.org/1999/xhtml">In addition, we will explore how to implement and train quantum support vector machines with Qiskit and PennyLane.</span></p>
<p><span class="koboSpan" id="kobo.13.1" xmlns="http://www.w3.org/1999/xhtml">The contents of this chapter are the following:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.14.1" xmlns="http://www.w3.org/1999/xhtml">Support vector machines</span></p></li>
<li><p><span class="koboSpan" id="kobo.15.1" xmlns="http://www.w3.org/1999/xhtml">Going quantum</span></p></li>
<li><p><span class="koboSpan" id="kobo.16.1" xmlns="http://www.w3.org/1999/xhtml">Quantum support vector machines in PennyLane</span></p></li>
<li><p><span class="koboSpan" id="kobo.17.1" xmlns="http://www.w3.org/1999/xhtml">Quantum support vector machines in Qiskit</span></p></li>
</ul>
<section class="level2 sectionHead" data-number="17.1" id="support-vector-machines">
<h1 class="sectionHead" data-number="17.1"><span class="titlemark"><span class="koboSpan" id="kobo.18.1" xmlns="http://www.w3.org/1999/xhtml">9.1 </span></span> <span id="x1-1610009.1"><span class="koboSpan" id="kobo.19.1" xmlns="http://www.w3.org/1999/xhtml">Support vector machines</span></span></h1>
<p><span class="koboSpan" id="kobo.20.1" xmlns="http://www.w3.org/1999/xhtml">QSVMs are actually particular </span><span id="dx1-161001"/><span class="koboSpan" id="kobo.21.1" xmlns="http://www.w3.org/1999/xhtml">cases of </span><strong><span class="koboSpan" id="kobo.22.1" xmlns="http://www.w3.org/1999/xhtml">Support Vector Machines</span></strong><span class="koboSpan" id="kobo.23.1" xmlns="http://www.w3.org/1999/xhtml"> (abbreviated as </span><strong><span class="koboSpan" id="kobo.24.1" xmlns="http://www.w3.org/1999/xhtml">SVM</span></strong><span class="koboSpan" id="kobo.25.1" xmlns="http://www.w3.org/1999/xhtml">s). </span><span class="koboSpan" id="kobo.25.2" xmlns="http://www.w3.org/1999/xhtml">In this section, we will explore how these SVMs work and how they’re used in machine learning. </span><span class="koboSpan" id="kobo.25.3" xmlns="http://www.w3.org/1999/xhtml">We will do so by first motivating the SVM formalism with some simple examples, and then building up from there: all the way up into how SVMs can be used to tackle complex classification problems with the kernel trick.</span></p>
<section class="level3 subsectionHead" data-number="17.1.1" id="the-simplest-classifier-you-could-think-of">
<h2 class="subsectionHead" data-number="17.1.1"><span class="titlemark"><span class="koboSpan" id="kobo.26.1" xmlns="http://www.w3.org/1999/xhtml">9.1.1 </span></span> <span id="x1-1620009.1.1"><span class="koboSpan" id="kobo.27.1" xmlns="http://www.w3.org/1999/xhtml">The simplest classifier you could think of</span></span></h2>
<p><span class="koboSpan" id="kobo.28.1" xmlns="http://www.w3.org/1999/xhtml">Let us forget about data for a moment and begin by considering a very naive problem. </span><span class="koboSpan" id="kobo.28.2" xmlns="http://www.w3.org/1999/xhtml">Let’s say that we want to build a very simple </span><span id="dx1-162001"/><span class="koboSpan" id="kobo.29.1" xmlns="http://www.w3.org/1999/xhtml">classifier on the real line. </span><span class="koboSpan" id="kobo.29.2" xmlns="http://www.w3.org/1999/xhtml">In order to do this, all we have to do is split the real number line into two disjoint categories in such a way that any number belong to exactly one of these two categories. </span><span class="koboSpan" id="kobo.29.3" xmlns="http://www.w3.org/1999/xhtml">Thus, if we are given any input (a real number), our classifier will return the category to which it belongs.</span></p>
<p><span class="koboSpan" id="kobo.30.1" xmlns="http://www.w3.org/1999/xhtml">What would be the easiest way in which you could do this? </span><span class="koboSpan" id="kobo.30.2" xmlns="http://www.w3.org/1999/xhtml">Odds are you would first pick a point </span><span class="koboSpan" id="kobo.31.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="a" class="math inline" src="../media/file16.png" style="vertical-align:middle" title="a"/></span><span class="koboSpan" id="kobo.32.1" xmlns="http://www.w3.org/1999/xhtml"> and divide the real number line into the set (category) of numbers smaller than </span><span class="koboSpan" id="kobo.33.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="a" class="math inline" src="../media/file16.png" style="vertical-align:middle" title="a"/></span><span class="koboSpan" id="kobo.34.1" xmlns="http://www.w3.org/1999/xhtml"> and the set of numbers larger than </span><span class="koboSpan" id="kobo.35.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="a" class="math inline" src="../media/file16.png" style="vertical-align:middle" title="a"/></span><span class="koboSpan" id="kobo.36.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.36.2" xmlns="http://www.w3.org/1999/xhtml">Then, of course, you would have to assign </span><span class="koboSpan" id="kobo.37.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="a" class="math inline" src="../media/file16.png" style="vertical-align:middle" title="a"/></span><span class="koboSpan" id="kobo.38.1" xmlns="http://www.w3.org/1999/xhtml"> to one of the two categories, so your categories would be either of the following:</span></p>
<ul>
<li><p><span class="koboSpan" id="kobo.39.1" xmlns="http://www.w3.org/1999/xhtml">The set of real numbers </span><span class="koboSpan" id="kobo.40.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.41.1" xmlns="http://www.w3.org/1999/xhtml"> such that </span><span class="koboSpan" id="kobo.42.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x \leq a" class="math inline" src="../media/file1190.png" style="vertical-align:middle" title="x \leq a"/></span><span class="koboSpan" id="kobo.43.1" xmlns="http://www.w3.org/1999/xhtml"> and the set of numbers </span><span class="koboSpan" id="kobo.44.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.45.1" xmlns="http://www.w3.org/1999/xhtml"> such that </span><span class="koboSpan" id="kobo.46.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x &gt; a" class="math inline" src="../media/file1191.png" style="vertical-align:middle" title="x &gt; a"/></span></p></li>
<li><p><span class="koboSpan" id="kobo.47.1" xmlns="http://www.w3.org/1999/xhtml">The set of numbers </span><span class="koboSpan" id="kobo.48.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.49.1" xmlns="http://www.w3.org/1999/xhtml"> such that </span><span class="koboSpan" id="kobo.50.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x &lt; a" class="math inline" src="../media/file1192.png" style="vertical-align:middle" title="x &lt; a"/></span><span class="koboSpan" id="kobo.51.1" xmlns="http://www.w3.org/1999/xhtml"> and the set of numbers </span><span class="koboSpan" id="kobo.52.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.53.1" xmlns="http://www.w3.org/1999/xhtml"> such that </span><span class="koboSpan" id="kobo.54.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x \geq a" class="math inline" src="../media/file1193.png" style="vertical-align:middle" title="x \geq a"/></span></p></li>
</ul>
<p><span class="koboSpan" id="kobo.55.1" xmlns="http://www.w3.org/1999/xhtml">Either choice would be reasonable.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-166">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.56.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.57.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.58.1" xmlns="http://www.w3.org/1999/xhtml">Actually, the choice as to in which category to include </span><span class="koboSpan" id="kobo.59.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="a" class="math inline" src="../media/file16.png" style="vertical-align:middle" title="a"/></span><span class="koboSpan" id="kobo.60.1" xmlns="http://www.w3.org/1999/xhtml"> is, to some extent, meaningless. </span><span class="koboSpan" id="kobo.60.2" xmlns="http://www.w3.org/1999/xhtml">At the end of the day, if you choose a real number at random, the probability that it be exactly </span><span class="koboSpan" id="kobo.61.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="a" class="math inline" src="../media/file16.png" style="vertical-align:middle" title="a"/></span><span class="koboSpan" id="kobo.62.1" xmlns="http://www.w3.org/1999/xhtml"> is zero. </span><span class="koboSpan" id="kobo.62.2" xmlns="http://www.w3.org/1999/xhtml">This fun fact is sponsored by probability and measure theory!</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.63.1" xmlns="http://www.w3.org/1999/xhtml">That was easy. </span><span class="koboSpan" id="kobo.63.2" xmlns="http://www.w3.org/1999/xhtml">Let’s now say that we want to do the </span><span id="dx1-162002"/><span class="koboSpan" id="kobo.64.1" xmlns="http://www.w3.org/1999/xhtml">same with the real plane (the usual </span><span class="koboSpan" id="kobo.65.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{2}" class="math inline" src="../media/file1194.png" style="vertical-align:middle" title="R^{2}"/></span><span class="koboSpan" id="kobo.66.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.66.2" xmlns="http://www.w3.org/1999/xhtml">In this case, a single point will not suffice to split it, but we could instead consider a good old line! </span><span class="koboSpan" id="kobo.66.3" xmlns="http://www.w3.org/1999/xhtml">This is exemplified in </span><em><span class="koboSpan" id="kobo.67.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.1"><em><span class="koboSpan" id="kobo.68.1" xmlns="http://www.w3.org/1999/xhtml">9.1</span></em></a><span class="koboSpan" id="kobo.69.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.69.2" xmlns="http://www.w3.org/1999/xhtml">Any line can be used to perfectly split the real plane into two categories.</span></p>
<figure>
<span class="koboSpan" id="kobo.70.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 9.1: The line \left. (5\slash 4, - 1) \cdot \overset{\rightarrow}{x} + 0 = 0 \right., which can be equivalently written as \left. y = (5\slash 4)x \right., can be used to divide the real plane into two disjoint categories, which are colored differently. The picture does not specify to which category the line belongs " src="../media/file1197.png"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure9.1"><strong><span class="koboSpan" id="kobo.71.1" xmlns="http://www.w3.org/1999/xhtml">Figure 9.1</span></strong><span class="koboSpan" id="kobo.72.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.73.1" xmlns="http://www.w3.org/1999/xhtml">The line </span><span class="koboSpan" id="kobo.74.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. (5\slash 4, - 1) \cdot \overset{\rightarrow}{x} + 0 = 0 \right." class="math inline" src="../media/file1195.png" style="vertical-align:middle" title="\left. (5\slash 4, - 1) \cdot \overset{\rightarrow}{x} + 0 = 0 \right."/></span><span class="koboSpan" id="kobo.75.1" xmlns="http://www.w3.org/1999/xhtml">, which can be equivalently written as </span><span class="koboSpan" id="kobo.76.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. y = (5\slash 4)x \right." class="math inline" src="../media/file1196.png" style="vertical-align:middle" title="\left. y = (5\slash 4)x \right."/></span><span class="koboSpan" id="kobo.77.1" xmlns="http://www.w3.org/1999/xhtml">, can be used to divide the real plane into two disjoint categories, which are colored differently. </span><span class="koboSpan" id="kobo.77.2" xmlns="http://www.w3.org/1999/xhtml">The picture does not specify to which category the line belongs </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.78.1" xmlns="http://www.w3.org/1999/xhtml">If you go back to your linear algebra notes, you may recall that any line in the plane can be characterized in terms of a vector </span><span class="koboSpan" id="kobo.79.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \in R^{2}" class="math inline" src="../media/file1198.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \in R^{2}"/></span><span class="koboSpan" id="kobo.80.1" xmlns="http://www.w3.org/1999/xhtml"> and a scalar </span><span class="koboSpan" id="kobo.81.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="b \in R" class="math inline" src="../media/file1199.png" style="vertical-align:middle" title="b \in R"/></span><span class="koboSpan" id="kobo.82.1" xmlns="http://www.w3.org/1999/xhtml"> as the set of points </span><span class="koboSpan" id="kobo.83.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x} = (x,y)" class="math inline" src="../media/file1200.png" style="vertical-align:middle" title="\overset{\rightarrow}{x} = (x,y)"/></span><span class="koboSpan" id="kobo.84.1" xmlns="http://www.w3.org/1999/xhtml"> such that </span><span class="koboSpan" id="kobo.85.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0" class="math inline" src="../media/file1201.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0"/></span><span class="koboSpan" id="kobo.86.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.86.2" xmlns="http://www.w3.org/1999/xhtml">Of course, we are using </span><span class="koboSpan" id="kobo.87.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\cdot" class="math inline" src="../media/file1202.png" style="vertical-align:middle" title="\cdot"/></span><span class="koboSpan" id="kobo.88.1" xmlns="http://www.w3.org/1999/xhtml"> to denote the scalar product (that is, </span><span class="koboSpan" id="kobo.89.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} = w_{1}x + w_{2}y" class="math inline" src="../media/file1203.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} = w_{1}x + w_{2}y"/></span><span class="koboSpan" id="kobo.90.1" xmlns="http://www.w3.org/1999/xhtml">, provided that </span><span class="koboSpan" id="kobo.91.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} = (w_{1},w_{2})" class="math inline" src="../media/file1204.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} = (w_{1},w_{2})"/></span><span class="koboSpan" id="kobo.92.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.92.2" xmlns="http://www.w3.org/1999/xhtml">The vector </span><span class="koboSpan" id="kobo.93.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w}" class="math inline" src="../media/file1205.png" style="vertical-align:middle" title="\overset{\rightarrow}{w}"/></span><span class="koboSpan" id="kobo.94.1" xmlns="http://www.w3.org/1999/xhtml"> defines the </span><strong><span class="koboSpan" id="kobo.95.1" xmlns="http://www.w3.org/1999/xhtml">normal</span></strong><span class="koboSpan" id="kobo.96.1" xmlns="http://www.w3.org/1999/xhtml">, or perpendicular, direction to the line, and the constant </span><span class="koboSpan" id="kobo.97.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="b" class="math inline" src="../media/file17.png" style="vertical-align:middle" title="b"/></span><span class="koboSpan" id="kobo.98.1" xmlns="http://www.w3.org/1999/xhtml"> determines the intersection of the line with the </span><span class="koboSpan" id="kobo.99.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="X" class="math inline" src="../media/file9.png" style="vertical-align:middle" title="X"/></span><span class="koboSpan" id="kobo.100.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.101.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Y" class="math inline" src="../media/file11.png" style="vertical-align:middle" title="Y"/></span><span class="koboSpan" id="kobo.102.1" xmlns="http://www.w3.org/1999/xhtml"> axes.</span></p>
<p><span class="koboSpan" id="kobo.103.1" xmlns="http://www.w3.org/1999/xhtml">When we worked on the one-dimensional case and used a point to split the real line, it was trivial to decide which </span><span id="dx1-162005"/><span class="koboSpan" id="kobo.104.1" xmlns="http://www.w3.org/1999/xhtml">category any input belonged to. </span><span class="koboSpan" id="kobo.104.2" xmlns="http://www.w3.org/1999/xhtml">In this case, it is slightly more complicated, but not too much. </span><span class="koboSpan" id="kobo.104.3" xmlns="http://www.w3.org/1999/xhtml">With some elementary geometry, you can check that any number </span><span class="koboSpan" id="kobo.105.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.106.1" xmlns="http://www.w3.org/1999/xhtml"> will be on one side or the other of the line defined by </span><span class="koboSpan" id="kobo.107.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0" class="math inline" src="../media/file1201.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0"/></span><span class="koboSpan" id="kobo.108.1" xmlns="http://www.w3.org/1999/xhtml"> depending on the sign of the quantity </span><span class="koboSpan" id="kobo.109.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b" class="math inline" src="../media/file1207.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b"/></span><span class="koboSpan" id="kobo.110.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.110.2" xmlns="http://www.w3.org/1999/xhtml">That is, if </span><span class="koboSpan" id="kobo.111.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{1} + b" class="math inline" src="../media/file1208.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{1} + b"/></span><span class="koboSpan" id="kobo.112.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.113.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{2} + b" class="math inline" src="../media/file1209.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{2} + b"/></span><span class="koboSpan" id="kobo.114.1" xmlns="http://www.w3.org/1999/xhtml"> have the same sign (both smaller than zero or both greater than zero), we will know that </span><span class="koboSpan" id="kobo.115.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\rightarrow}{x}}_{1}" class="math inline" src="../media/file1210.png" style="vertical-align:middle" title="{\overset{\rightarrow}{x}}_{1}"/></span><span class="koboSpan" id="kobo.116.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.117.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\rightarrow}{x}}_{2}" class="math inline" src="../media/file1211.png" style="vertical-align:middle" title="{\overset{\rightarrow}{x}}_{2}"/></span><span class="koboSpan" id="kobo.118.1" xmlns="http://www.w3.org/1999/xhtml"> will belong to the same category. </span><span class="koboSpan" id="kobo.118.2" xmlns="http://www.w3.org/1999/xhtml">Otherwise, we know they will not.</span></p>
<p><span class="koboSpan" id="kobo.119.1" xmlns="http://www.w3.org/1999/xhtml">There is no reason for us to stop at two dimensions, so let’s kick this up a notch and consider an </span><span class="koboSpan" id="kobo.120.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.121.1" xmlns="http://www.w3.org/1999/xhtml">-dimensional Euclidean space </span><span class="koboSpan" id="kobo.122.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{n}" class="math inline" src="../media/file1212.png" style="vertical-align:middle" title="R^{n}"/></span><span class="koboSpan" id="kobo.123.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.123.2" xmlns="http://www.w3.org/1999/xhtml">Just as we split </span><span class="koboSpan" id="kobo.124.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{2}" class="math inline" src="../media/file1194.png" style="vertical-align:middle" title="R^{2}"/></span><span class="koboSpan" id="kobo.125.1" xmlns="http://www.w3.org/1999/xhtml"> using a line, we could split </span><span class="koboSpan" id="kobo.126.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{n}" class="math inline" src="../media/file1212.png" style="vertical-align:middle" title="R^{n}"/></span><span class="koboSpan" id="kobo.127.1" xmlns="http://www.w3.org/1999/xhtml"> using…an (</span><span class="koboSpan" id="kobo.128.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n - 1" class="math inline" src="../media/file1213.png" style="vertical-align:middle" title="n - 1"/></span><span class="koboSpan" id="kobo.129.1" xmlns="http://www.w3.org/1999/xhtml">)-dimensional hyperplane! </span><span class="koboSpan" id="kobo.129.2" xmlns="http://www.w3.org/1999/xhtml">For instance, we could split </span><span class="koboSpan" id="kobo.130.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{3}" class="math inline" src="../media/file1214.png" style="vertical-align:middle" title="R^{3}"/></span><span class="koboSpan" id="kobo.131.1" xmlns="http://www.w3.org/1999/xhtml"> using an ordinary plane.</span></p>
<p><span class="koboSpan" id="kobo.132.1" xmlns="http://www.w3.org/1999/xhtml">These hyperplanes in </span><span class="koboSpan" id="kobo.133.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{n}" class="math inline" src="../media/file1212.png" style="vertical-align:middle" title="R^{n}"/></span><span class="koboSpan" id="kobo.134.1" xmlns="http://www.w3.org/1999/xhtml"> are defined by their normal vectors </span><span class="koboSpan" id="kobo.135.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \in R^{n}" class="math inline" src="../media/file1215.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \in R^{n}"/></span><span class="koboSpan" id="kobo.136.1" xmlns="http://www.w3.org/1999/xhtml"> and some constants </span><span class="koboSpan" id="kobo.137.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="b \in R" class="math inline" src="../media/file1199.png" style="vertical-align:middle" title="b \in R"/></span><span class="koboSpan" id="kobo.138.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.138.2" xmlns="http://www.w3.org/1999/xhtml">In analogy to what we saw in </span><span class="koboSpan" id="kobo.139.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{2}" class="math inline" src="../media/file1194.png" style="vertical-align:middle" title="R^{2}"/></span><span class="koboSpan" id="kobo.140.1" xmlns="http://www.w3.org/1999/xhtml">, their points are the </span><span class="koboSpan" id="kobo.141.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x} \in R^{n}" class="math inline" src="../media/file1216.png" style="vertical-align:middle" title="\overset{\rightarrow}{x} \in R^{n}"/></span><span class="koboSpan" id="kobo.142.1" xmlns="http://www.w3.org/1999/xhtml"> that satisfy the equations of the form</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.143.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0." class="math display" src="../media/file1217.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.144.1" xmlns="http://www.w3.org/1999/xhtml">Moreover, we can determine to which side of the hyperplane a certain </span><span class="koboSpan" id="kobo.145.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x} \in R^{n}" class="math inline" src="../media/file1216.png" style="vertical-align:middle" title="\overset{\rightarrow}{x} \in R^{n}"/></span><span class="koboSpan" id="kobo.146.1" xmlns="http://www.w3.org/1999/xhtml"> is in terms of the sign of </span><span class="koboSpan" id="kobo.147.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b" class="math inline" src="../media/file1207.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b"/></span><span class="koboSpan" id="kobo.148.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-167">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.149.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.150.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.151.1" xmlns="http://www.w3.org/1999/xhtml">In case you are confused with all these equations and you are curious as to where they come from, let us quickly explain them. </span><span class="koboSpan" id="kobo.151.2" xmlns="http://www.w3.org/1999/xhtml">An (affine) hyperplane can be defined by a normal vector </span><span class="koboSpan" id="kobo.152.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w}" class="math inline" src="../media/file1205.png" style="vertical-align:middle" title="\overset{\rightarrow}{w}"/></span><span class="koboSpan" id="kobo.153.1" xmlns="http://www.w3.org/1999/xhtml"> and by a point </span><span class="koboSpan" id="kobo.154.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{p}" class="math inline" src="../media/file1218.png" style="vertical-align:middle" title="\overset{\rightarrow}{p}"/></span><span class="koboSpan" id="kobo.155.1" xmlns="http://www.w3.org/1999/xhtml"> in the plane. </span><span class="koboSpan" id="kobo.155.2" xmlns="http://www.w3.org/1999/xhtml">Thus, a point </span><span class="koboSpan" id="kobo.156.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.157.1" xmlns="http://www.w3.org/1999/xhtml"> will belong to the hyperplane if and only if </span><span class="koboSpan" id="kobo.158.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x} = \overset{\rightarrow}{p} + \overset{\rightarrow}{v}" class="math inline" src="../media/file1219.png" style="vertical-align:middle" title="\overset{\rightarrow}{x} = \overset{\rightarrow}{p} + \overset{\rightarrow}{v}"/></span><span class="koboSpan" id="kobo.159.1" xmlns="http://www.w3.org/1999/xhtml"> for some vector </span><span class="koboSpan" id="kobo.160.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{v}" class="math inline" src="../media/file1220.png" style="vertical-align:middle" title="\overset{\rightarrow}{v}"/></span><span class="koboSpan" id="kobo.161.1" xmlns="http://www.w3.org/1999/xhtml"> that is orthogonal to </span><span class="koboSpan" id="kobo.162.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w}" class="math inline" src="../media/file1205.png" style="vertical-align:middle" title="\overset{\rightarrow}{w}"/></span><span class="koboSpan" id="kobo.163.1" xmlns="http://www.w3.org/1999/xhtml">, that is, such that </span><span class="koboSpan" id="kobo.164.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{v} = 0" class="math inline" src="../media/file1221.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{v} = 0"/></span><span class="koboSpan" id="kobo.165.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.165.2" xmlns="http://www.w3.org/1999/xhtml">By combining these two expressions, we know that </span><span class="koboSpan" id="kobo.166.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.167.1" xmlns="http://www.w3.org/1999/xhtml"> will belong to the hyperplane if and only if </span><span class="koboSpan" id="kobo.168.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot (\overset{\rightarrow}{x} - \overset{\rightarrow}{p}) = 0" class="math inline" src="../media/file1222.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot (\overset{\rightarrow}{x} - \overset{\rightarrow}{p}) = 0"/></span><span class="koboSpan" id="kobo.169.1" xmlns="http://www.w3.org/1999/xhtml">, which can be rewritten as</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.170.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + ( - \overset{\rightarrow}{w} \cdot \overset{\rightarrow}{p}) = \overset{\rightarrow}{x} \cdot \overset{\rightarrow}{w} + b = 0," class="math display" src="../media/file1223.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + ( - \overset{\rightarrow}{w} \cdot \overset{\rightarrow}{p}) = \overset{\rightarrow}{x} \cdot \overset{\rightarrow}{w} + b = 0,"/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.171.1" xmlns="http://www.w3.org/1999/xhtml">where we have implicitly defined </span><span class="koboSpan" id="kobo.172.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="b = - \overset{\rightarrow}{w} \cdot \overset{\rightarrow}{p}" class="math inline" src="../media/file1224.png" style="vertical-align:middle" title="b = - \overset{\rightarrow}{w} \cdot \overset{\rightarrow}{p}"/></span><span class="koboSpan" id="kobo.173.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.174.1" xmlns="http://www.w3.org/1999/xhtml">Moreover, we have just seen how </span><span class="koboSpan" id="kobo.175.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b" class="math inline" src="../media/file1207.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b"/></span><span class="koboSpan" id="kobo.176.1" xmlns="http://www.w3.org/1999/xhtml"> is the scalar product of </span><span class="koboSpan" id="kobo.177.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x} - \overset{\rightarrow}{p}" class="math inline" src="../media/file1225.png" style="vertical-align:middle" title="\overset{\rightarrow}{x} - \overset{\rightarrow}{p}"/></span><span class="koboSpan" id="kobo.178.1" xmlns="http://www.w3.org/1999/xhtml"> with </span><span class="koboSpan" id="kobo.179.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w}" class="math inline" src="../media/file1205.png" style="vertical-align:middle" title="\overset{\rightarrow}{w}"/></span><span class="koboSpan" id="kobo.180.1" xmlns="http://www.w3.org/1999/xhtml">, a fixed normal vector to the plane. </span><span class="koboSpan" id="kobo.180.2" xmlns="http://www.w3.org/1999/xhtml">This justifies why its sign determines on which side of the hyperplane </span><span class="koboSpan" id="kobo.181.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.182.1" xmlns="http://www.w3.org/1999/xhtml"> lies. </span><span class="koboSpan" id="kobo.182.2" xmlns="http://www.w3.org/1999/xhtml">Remember that, geometrically, the dot product of two vectors </span><span class="koboSpan" id="kobo.183.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{u_{1}} \cdot {\overset{\rightarrow}{u}}_{2}" class="math inline" src="../media/file1226.png" style="vertical-align:middle" title="\overset{\rightarrow}{u_{1}} \cdot {\overset{\rightarrow}{u}}_{2}"/></span><span class="koboSpan" id="kobo.184.1" xmlns="http://www.w3.org/1999/xhtml"> is equal to </span><span class="koboSpan" id="kobo.185.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left\| u \right\|_{1} \cdot \left\| u \right\|_{2} \cdot \cos\theta" class="math inline" src="../media/file1227.png" style="vertical-align:middle" title="\left\| u \right\|_{1} \cdot \left\| u \right\|_{2} \cdot \cos\theta"/></span><span class="koboSpan" id="kobo.186.1" xmlns="http://www.w3.org/1999/xhtml">, where </span><span class="koboSpan" id="kobo.187.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\theta" class="math inline" src="../media/file89.png" style="vertical-align:middle" title="\theta"/></span><span class="koboSpan" id="kobo.188.1" xmlns="http://www.w3.org/1999/xhtml"> denotes the smallest angle between them.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.189.1" xmlns="http://www.w3.org/1999/xhtml">With what we have done so far, we have the tools required to construct (admittedly simple) binary </span><span id="dx1-162006"/><span class="koboSpan" id="kobo.190.1" xmlns="http://www.w3.org/1999/xhtml">classifiers on any Euclidean space. </span><span class="koboSpan" id="kobo.190.2" xmlns="http://www.w3.org/1999/xhtml">All it takes for us to do so is fixing a hyperplane!</span></p>
<p><span class="koboSpan" id="kobo.191.1" xmlns="http://www.w3.org/1999/xhtml">Why is this important to us? </span><span class="koboSpan" id="kobo.191.2" xmlns="http://www.w3.org/1999/xhtml">It turns out that support vector machines do exactly what we have discussed so far.</span></p>
<div class="tcolorbox important" id="tcolobox-168">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.192.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.193.1" xmlns="http://www.w3.org/1999/xhtml">A support vector machine takes inputs in an </span><span class="koboSpan" id="kobo.194.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.195.1" xmlns="http://www.w3.org/1999/xhtml">-dimensional Euclidean space (</span><span class="koboSpan" id="kobo.196.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{n}" class="math inline" src="../media/file1212.png" style="vertical-align:middle" title="R^{n}"/></span><span class="koboSpan" id="kobo.197.1" xmlns="http://www.w3.org/1999/xhtml">) and classifies them according to which side of a hyperplane they are on. </span><span class="koboSpan" id="kobo.197.2" xmlns="http://www.w3.org/1999/xhtml">This hyperplane fully defines the behavior of the SVM. </span><span class="koboSpan" id="kobo.197.3" xmlns="http://www.w3.org/1999/xhtml">Of course, the adjustable parameters of an SVM are the ones that define the hyperplane: following our notation, the components of the normal vector </span><span class="koboSpan" id="kobo.198.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w}" class="math inline" src="../media/file1205.png" style="vertical-align:middle" title="\overset{\rightarrow}{w}"/></span><span class="koboSpan" id="kobo.199.1" xmlns="http://www.w3.org/1999/xhtml"> and the constant </span><span class="koboSpan" id="kobo.200.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="b" class="math inline" src="../media/file17.png" style="vertical-align:middle" title="b"/></span><span class="koboSpan" id="kobo.201.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.202.1" xmlns="http://www.w3.org/1999/xhtml">In order to get the label of any point </span><span class="koboSpan" id="kobo.203.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.204.1" xmlns="http://www.w3.org/1999/xhtml">, all we have to do is look at the sign of </span><span class="koboSpan" id="kobo.205.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b" class="math inline" src="../media/file1207.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b"/></span><span class="koboSpan" id="kobo.206.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.207.1" xmlns="http://www.w3.org/1999/xhtml">As you may have suspected, vanilla SVMs, just on their own, are not the most powerful of binary classification models: they are intrinsically linear and they are not fit to capture sophisticated patterns. </span><span class="koboSpan" id="kobo.207.2" xmlns="http://www.w3.org/1999/xhtml">We will take care of this later in the chapter when we unleash the full potential of SVMs with ”the kernel trick” (stay tuned!). </span><span class="koboSpan" id="kobo.207.3" xmlns="http://www.w3.org/1999/xhtml">In any case, for now, let us rejoice in the simplicity of our model and let’s learn how to train it.</span></p>
</section>
<section class="level3 subsectionHead" data-number="17.1.2" id="how-to-train-support-vector-machines-the-hard-margin-case">
<h2 class="subsectionHead" data-number="17.1.2"><span class="titlemark"><span class="koboSpan" id="kobo.208.1" xmlns="http://www.w3.org/1999/xhtml">9.1.2 </span></span> <span id="x1-1630009.1.2"><span class="koboSpan" id="kobo.209.1" xmlns="http://www.w3.org/1999/xhtml">How to train support vector machines: the hard-margin case</span></span></h2>
<p><span class="koboSpan" id="kobo.210.1" xmlns="http://www.w3.org/1999/xhtml">Let’s say that we have a binary </span><span id="dx1-163001"/><span class="koboSpan" id="kobo.211.1" xmlns="http://www.w3.org/1999/xhtml">classification problem, and we are given some training data consisting of datapoints in </span><span class="koboSpan" id="kobo.212.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{n}" class="math inline" src="../media/file1212.png" style="vertical-align:middle" title="R^{n}"/></span><span class="koboSpan" id="kobo.213.1" xmlns="http://www.w3.org/1999/xhtml"> together with their corresponding labels. </span><span class="koboSpan" id="kobo.213.2" xmlns="http://www.w3.org/1999/xhtml">Naturally, when we train an SVM for this problem, we want to look for the hyperplane that best separates the two categories in the </span><span id="dx1-163002"/><span class="koboSpan" id="kobo.214.1" xmlns="http://www.w3.org/1999/xhtml">training dataset. </span><span class="koboSpan" id="kobo.214.2" xmlns="http://www.w3.org/1999/xhtml">Now we have to make this intuitive idea precise.</span></p>
<p><span class="koboSpan" id="kobo.215.1" xmlns="http://www.w3.org/1999/xhtml">Let the datapoints in our training dataset be </span><span class="koboSpan" id="kobo.216.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\rightarrow}{x}}_{j} \in R^{n}" class="math inline" src="../media/file1228.png" style="vertical-align:middle" title="{\overset{\rightarrow}{x}}_{j} \in R^{n}"/></span><span class="koboSpan" id="kobo.217.1" xmlns="http://www.w3.org/1999/xhtml"> and their expected labels be </span><span class="koboSpan" id="kobo.218.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y_{j} = 1, - 1" class="math inline" src="../media/file1229.png" style="vertical-align:middle" title="y_{j} = 1, - 1"/></span><span class="koboSpan" id="kobo.219.1" xmlns="http://www.w3.org/1999/xhtml"> (read as positive and negative, respectively). </span><span class="koboSpan" id="kobo.219.2" xmlns="http://www.w3.org/1999/xhtml">For now, we will assume that our data can be perfectly separated by a hyperplane. </span><span class="koboSpan" id="kobo.219.3" xmlns="http://www.w3.org/1999/xhtml">Later in the section, we will see what to do when this is not the case.</span></p>
<p><span class="koboSpan" id="kobo.220.1" xmlns="http://www.w3.org/1999/xhtml">Notice that, under the assumption that there is at least one hyperplane separating our data, there will necessarily be an infinite number of such separating hyperplanes (see </span><em><span class="koboSpan" id="kobo.221.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.2"><em><span class="koboSpan" id="kobo.222.1" xmlns="http://www.w3.org/1999/xhtml">9.2</span></em></a><span class="koboSpan" id="kobo.223.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.223.2" xmlns="http://www.w3.org/1999/xhtml">Will any of them be suitable for our goal of building a classifier? </span><span class="koboSpan" id="kobo.223.3" xmlns="http://www.w3.org/1999/xhtml">If we only cared about the training data, then yes, any of them would do the trick. </span><span class="koboSpan" id="kobo.223.4" xmlns="http://www.w3.org/1999/xhtml">In fact, this is exactly what the perceptron model that we discussed in </span><em><span class="koboSpan" id="kobo.224.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <em/> <a href="ch017.xhtml#x1-1390008"><em><span class="koboSpan" id="kobo.225.1" xmlns="http://www.w3.org/1999/xhtml">8</span></em></a><span class="koboSpan" id="kobo.226.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.227.1" xmlns="http://www.w3.org/1999/xhtml">What is Quantum Machine</span></em> <em><span class="koboSpan" id="kobo.228.1" xmlns="http://www.w3.org/1999/xhtml">Learning?</span></em><span class="koboSpan" id="kobo.229.1" xmlns="http://www.w3.org/1999/xhtml">, does: it just looks for a hyperplane separating the training data.</span></p>
<p><span class="koboSpan" id="kobo.230.1" xmlns="http://www.w3.org/1999/xhtml">However, as you surely remember, when we train a classifier, we are interested in getting a low generalization error. </span><span class="koboSpan" id="kobo.230.2" xmlns="http://www.w3.org/1999/xhtml">In our case, one way of trying to achieve this is by looking for a separating hyperplane that can maximize the distance from itself to the training datapoints. </span><span class="koboSpan" id="kobo.230.3" xmlns="http://www.w3.org/1999/xhtml">And that is the way in which SVMs are actually trained. </span><span class="koboSpan" id="kobo.230.4" xmlns="http://www.w3.org/1999/xhtml">The rationale behind this is clear: we expect the new, unseen datapoints to follow a similar distribution to the one that we have seen in the training data. </span><span class="koboSpan" id="kobo.230.5" xmlns="http://www.w3.org/1999/xhtml">So it is very likely that new examples of one class will be closer to training examples of that same class. </span><span class="koboSpan" id="kobo.230.6" xmlns="http://www.w3.org/1999/xhtml">Therefore, if our separating hyperplane is too close to one of the training datapoints, we risk another datapoint of the same class crossing to the other side of the hyperplane and being misclassified. </span><span class="koboSpan" id="kobo.230.7" xmlns="http://www.w3.org/1999/xhtml">For instance, in </span><em><span class="koboSpan" id="kobo.231.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.2"><em><span class="koboSpan" id="kobo.232.1" xmlns="http://www.w3.org/1999/xhtml">9.2</span></em></a><span class="koboSpan" id="kobo.233.1" xmlns="http://www.w3.org/1999/xhtml">, the dashed line does separate the training datapoints, but it is certainly a much more risky choice than, for example, the continuous line.</span></p>
<figure>
<span class="koboSpan" id="kobo.234.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 9.2: Both lines (hyperplanes) separate the two categories, but the continuous line is closer to the datapoints than the dashed line " src="../media/file1230.jpg"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure9.2"><strong><span class="koboSpan" id="kobo.235.1" xmlns="http://www.w3.org/1999/xhtml">Figure 9.2</span></strong><span class="koboSpan" id="kobo.236.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.237.1" xmlns="http://www.w3.org/1999/xhtml">Both lines (hyperplanes) separate the two categories, but the continuous line is closer to the datapoints than the dashed line </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.238.1" xmlns="http://www.w3.org/1999/xhtml">The idea behind the </span><span id="dx1-163005"/><span class="koboSpan" id="kobo.239.1" xmlns="http://www.w3.org/1999/xhtml">training of an SVM is then clear: we seek to find not just any separating hyperplane, but one that is as far away from the </span><span id="dx1-163006"/><span class="koboSpan" id="kobo.240.1" xmlns="http://www.w3.org/1999/xhtml">training points as possible. </span><span class="koboSpan" id="kobo.240.2" xmlns="http://www.w3.org/1999/xhtml">This may seem difficult to achieve, but it can be posed as a rather straightforward optimization problem. </span><span class="koboSpan" id="kobo.240.3" xmlns="http://www.w3.org/1999/xhtml">Let’s explain how to do it in a little bit more detail.</span></p>
<p><span class="koboSpan" id="kobo.241.1" xmlns="http://www.w3.org/1999/xhtml">In a first approach, we could just consider the distance from a separating hyperplane </span><span class="koboSpan" id="kobo.242.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.243.1" xmlns="http://www.w3.org/1999/xhtml"> to all the points in the training dataset, and then try to find a way to tweak </span><span class="koboSpan" id="kobo.244.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.245.1" xmlns="http://www.w3.org/1999/xhtml"> in order to maximize that distance while making sure that </span><span class="koboSpan" id="kobo.246.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.247.1" xmlns="http://www.w3.org/1999/xhtml"> still separates the data properly. </span><span class="koboSpan" id="kobo.247.2" xmlns="http://www.w3.org/1999/xhtml">This is, however, not the best way to present the problem. </span><span class="koboSpan" id="kobo.247.3" xmlns="http://www.w3.org/1999/xhtml">Instead, we may notice how we can associate to each data point a unique hyperplane that is parallel to </span><span class="koboSpan" id="kobo.248.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.249.1" xmlns="http://www.w3.org/1999/xhtml"> and contains that datapoint. </span><span class="koboSpan" id="kobo.249.2" xmlns="http://www.w3.org/1999/xhtml">And, what is more, the parallel hyperplane that goes through the point that is closest to </span><span class="koboSpan" id="kobo.250.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.251.1" xmlns="http://www.w3.org/1999/xhtml"> will itself be a separating hyperplane — and so will be its reflection over </span><span class="koboSpan" id="kobo.252.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.253.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.253.2" xmlns="http://www.w3.org/1999/xhtml">This is illustrated in </span><em><span class="koboSpan" id="kobo.254.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.3"><em><span class="koboSpan" id="kobo.255.1" xmlns="http://www.w3.org/1999/xhtml">9.3</span></em></a><span class="koboSpan" id="kobo.256.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.257.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 9.3: The continuous black line represents a separating hyperplane H. One of the dashed lines is the parallel hyperplane that goes through the closest point to H, and its reflection over H is the other dashed line " src="../media/file1231.jpg"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure9.3"><strong><span class="koboSpan" id="kobo.258.1" xmlns="http://www.w3.org/1999/xhtml">Figure 9.3</span></strong><span class="koboSpan" id="kobo.259.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.260.1" xmlns="http://www.w3.org/1999/xhtml">The continuous black line represents a separating hyperplane </span><span class="koboSpan" id="kobo.261.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.262.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.262.2" xmlns="http://www.w3.org/1999/xhtml">One of the dashed lines is the parallel hyperplane that goes through the closest point to </span><span class="koboSpan" id="kobo.263.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.264.1" xmlns="http://www.w3.org/1999/xhtml">, and its reflection over </span><span class="koboSpan" id="kobo.265.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.266.1" xmlns="http://www.w3.org/1999/xhtml"> is the other dashed line </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.267.1" xmlns="http://www.w3.org/1999/xhtml">This pair of hyperplanes — the parallel plane that goes through the closest point and its reflection — will be the two </span><span id="dx1-163009"/><span class="koboSpan" id="kobo.268.1" xmlns="http://www.w3.org/1999/xhtml">equidistant parallel hyperplanes, which are the furthest apart from each other while still </span><span id="dx1-163010"/><span class="koboSpan" id="kobo.269.1" xmlns="http://www.w3.org/1999/xhtml">separating the data. </span><span class="koboSpan" id="kobo.269.2" xmlns="http://www.w3.org/1999/xhtml">They are unique to </span><span class="koboSpan" id="kobo.270.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.271.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.271.2" xmlns="http://www.w3.org/1999/xhtml">The distance between them is </span><span id="dx1-163011"/><span class="koboSpan" id="kobo.272.1" xmlns="http://www.w3.org/1999/xhtml">known as the </span><strong><span class="koboSpan" id="kobo.273.1" xmlns="http://www.w3.org/1999/xhtml">margin</span></strong><span class="koboSpan" id="kobo.274.1" xmlns="http://www.w3.org/1999/xhtml"> and it is what we aim to maximize. </span><span class="koboSpan" id="kobo.274.2" xmlns="http://www.w3.org/1999/xhtml">This is illustrated in </span><em><span class="koboSpan" id="kobo.275.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.4"><em><span class="koboSpan" id="kobo.276.1" xmlns="http://www.w3.org/1999/xhtml">9.4</span></em></a><span class="koboSpan" id="kobo.277.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.278.1" xmlns="http://www.w3.org/1999/xhtml">We already know that any separating hyperplane </span><span class="koboSpan" id="kobo.279.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.280.1" xmlns="http://www.w3.org/1999/xhtml"> can be characterized by an equation of the form </span><span class="koboSpan" id="kobo.281.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0" class="math inline" src="../media/file1201.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0"/></span><span class="koboSpan" id="kobo.282.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.282.2" xmlns="http://www.w3.org/1999/xhtml">Moreover, any hyperplane that is parallel to </span><span class="koboSpan" id="kobo.283.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.284.1" xmlns="http://www.w3.org/1999/xhtml"> — in particular those that define the margin! </span><span class="koboSpan" id="kobo.284.2" xmlns="http://www.w3.org/1999/xhtml">— can be characterized as </span><span class="koboSpan" id="kobo.285.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = C" class="math inline" src="../media/file1232.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = C"/></span><span class="koboSpan" id="kobo.286.1" xmlns="http://www.w3.org/1999/xhtml"> for some constant </span><span class="koboSpan" id="kobo.287.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="C" class="math inline" src="../media/file234.png" style="vertical-align:middle" title="C"/></span><span class="koboSpan" id="kobo.288.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.288.2" xmlns="http://www.w3.org/1999/xhtml">And not</span><span id="dx1-163012"/><span class="koboSpan" id="kobo.289.1" xmlns="http://www.w3.org/1999/xhtml"> only that, but their reflection over </span><span class="koboSpan" id="kobo.290.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.291.1" xmlns="http://www.w3.org/1999/xhtml"> will be itself characterized by the equation </span><span class="koboSpan" id="kobo.292.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = - C" class="math inline" src="../media/file1233.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = - C"/></span><span class="koboSpan" id="kobo.293.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.293.2" xmlns="http://www.w3.org/1999/xhtml">Hence, we know that, for some constant </span><span class="koboSpan" id="kobo.294.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="C" class="math inline" src="../media/file234.png" style="vertical-align:middle" title="C"/></span><span class="koboSpan" id="kobo.295.1" xmlns="http://www.w3.org/1999/xhtml">, the hyperplanes that define the margin of </span><span class="koboSpan" id="kobo.296.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.297.1" xmlns="http://www.w3.org/1999/xhtml"> can be represented by the equations </span><span class="koboSpan" id="kobo.298.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \pm C" class="math inline" src="../media/file1234.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \pm C"/></span><span class="koboSpan" id="kobo.299.1" xmlns="http://www.w3.org/1999/xhtml">.</span><span id="dx1-163013"/></p>
<p><span class="koboSpan" id="kobo.300.1" xmlns="http://www.w3.org/1999/xhtml">Nevertheless, there is nothing preventing us here from dividing the whole expression by </span><span class="koboSpan" id="kobo.301.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="C" class="math inline" src="../media/file234.png" style="vertical-align:middle" title="C"/></span><span class="koboSpan" id="kobo.302.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.302.2" xmlns="http://www.w3.org/1999/xhtml">So, if we let </span><span class="koboSpan" id="kobo.303.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. \overset{\sim}{w} = \overset{\rightarrow}{w}\slash C \right." class="math inline" src="../media/file1235.png" style="vertical-align:middle" title="\left. \overset{\sim}{w} = \overset{\rightarrow}{w}\slash C \right."/></span><span class="koboSpan" id="kobo.304.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.305.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. \overset{\sim}{b} = b\slash C \right." class="math inline" src="../media/file1236.png" style="vertical-align:middle" title="\left. \overset{\sim}{b} = b\slash C \right."/></span><span class="koboSpan" id="kobo.306.1" xmlns="http://www.w3.org/1999/xhtml">, we know that the hyperplane </span><span class="koboSpan" id="kobo.307.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.308.1" xmlns="http://www.w3.org/1999/xhtml"> will still be represented by </span><span class="koboSpan" id="kobo.309.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\sim}{w} \cdot \overset{\rightarrow}{x} + \overset{\sim}{b} = 0" class="math inline" src="../media/file1237.png" style="vertical-align:middle" title="\overset{\sim}{w} \cdot \overset{\rightarrow}{x} + \overset{\sim}{b} = 0"/></span><span class="koboSpan" id="kobo.310.1" xmlns="http://www.w3.org/1999/xhtml">, but the hyperplanes that define the margin will be characterized by</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.311.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\sim}{w} \cdot \overset{\rightarrow}{x} + \overset{\sim}{b} = \pm 1," class="math display" src="../media/file1238.png" style="vertical-align:middle" title="\overset{\sim}{w} \cdot \overset{\rightarrow}{x} + \overset{\sim}{b} = \pm 1,"/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.312.1" xmlns="http://www.w3.org/1999/xhtml">which looks much more neat!</span></p>
<p><span class="koboSpan" id="kobo.313.1" xmlns="http://www.w3.org/1999/xhtml">Let’s summarize what we have. </span><span class="koboSpan" id="kobo.313.2" xmlns="http://www.w3.org/1999/xhtml">We want to find a hyperplane that, while separating the data properly, maximizes the </span><span id="dx1-163014"/><span class="koboSpan" id="kobo.314.1" xmlns="http://www.w3.org/1999/xhtml">distance to the points in the training dataset. </span><span class="koboSpan" id="kobo.314.2" xmlns="http://www.w3.org/1999/xhtml">We have seen how we can see this as the problem of finding a hyperplane that maximizes the margin: the distance between the two </span><span id="dx1-163015"/><span class="koboSpan" id="kobo.315.1" xmlns="http://www.w3.org/1999/xhtml">equidistant parallel hyperplanes that are the furthest away from each other while still separating the data. </span><span class="koboSpan" id="kobo.315.2" xmlns="http://www.w3.org/1999/xhtml">And we have just proven that, for any separating hyperplane, we can always find some values of </span><span class="koboSpan" id="kobo.316.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w}" class="math inline" src="../media/file1205.png" style="vertical-align:middle" title="\overset{\rightarrow}{w}"/></span><span class="koboSpan" id="kobo.317.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.318.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="b" class="math inline" src="../media/file17.png" style="vertical-align:middle" title="b"/></span><span class="koboSpan" id="kobo.319.1" xmlns="http://www.w3.org/1999/xhtml"> such that those hyperplanes that define the margin can be represented as</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.320.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \pm 1." class="math display" src="../media/file1239.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \pm 1."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.321.1" xmlns="http://www.w3.org/1999/xhtml">It can be shown that the distance between these two hyperplanes is </span><span class="koboSpan" id="kobo.322.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. 2\slash\left\| w \right\| \right." class="math inline" src="../media/file1240.png" style="vertical-align:middle" title="\left. 2\slash\left\| w \right\| \right."/></span><span class="koboSpan" id="kobo.323.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.323.2" xmlns="http://www.w3.org/1999/xhtml">Hence the problem of maximizing the margin can be equivalently stated as the problem of maximizing </span><span class="koboSpan" id="kobo.324.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. 2\slash\left\| w \right\| \right." class="math inline" src="../media/file1240.png" style="vertical-align:middle" title="\left. 2\slash\left\| w \right\| \right."/></span><span class="koboSpan" id="kobo.325.1" xmlns="http://www.w3.org/1999/xhtml"> subject to the constraint that the planes </span><span class="koboSpan" id="kobo.326.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \pm 1" class="math inline" src="../media/file1241.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \pm 1"/></span><span class="koboSpan" id="kobo.327.1" xmlns="http://www.w3.org/1999/xhtml"> properly separate the data.</span></p>
<div class="tcolorbox questionx" id="tcolobox-169">
<span id="x1-163017x9.1.2"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.328.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 9.1</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.329.1" xmlns="http://www.w3.org/1999/xhtml">Show that, as we claimed, the distance between the hyperplanes </span><span class="koboSpan" id="kobo.330.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \pm 1" class="math inline" src="../media/file1241.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \pm 1"/></span><span class="koboSpan" id="kobo.331.1" xmlns="http://www.w3.org/1999/xhtml"> is </span><span class="koboSpan" id="kobo.332.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. 2\slash\left\| w \right\| \right." class="math inline" src="../media/file1240.png" style="vertical-align:middle" title="\left. 2\slash\left\| w \right\| \right."/></span><span class="koboSpan" id="kobo.333.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.334.1" xmlns="http://www.w3.org/1999/xhtml">Let’s now consider an arbitrary element </span><span class="koboSpan" id="kobo.335.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{p} \in R^{N}" class="math inline" src="../media/file1242.png" style="vertical-align:middle" title="\overset{\rightarrow}{p} \in R^{N}"/></span><span class="koboSpan" id="kobo.336.1" xmlns="http://www.w3.org/1999/xhtml"> and a hyperplane </span><span class="koboSpan" id="kobo.337.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.338.1" xmlns="http://www.w3.org/1999/xhtml"> characterized by </span><span class="koboSpan" id="kobo.339.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0" class="math inline" src="../media/file1201.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0"/></span><span class="koboSpan" id="kobo.340.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.340.2" xmlns="http://www.w3.org/1999/xhtml">When the value of </span><span class="koboSpan" id="kobo.341.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{p} + b" class="math inline" src="../media/file1243.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{p} + b"/></span><span class="koboSpan" id="kobo.342.1" xmlns="http://www.w3.org/1999/xhtml"> is zero, we know that </span><span class="koboSpan" id="kobo.343.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{p}" class="math inline" src="../media/file1218.png" style="vertical-align:middle" title="\overset{\rightarrow}{p}"/></span><span class="koboSpan" id="kobo.344.1" xmlns="http://www.w3.org/1999/xhtml"> is in the hyperplane and, as this value drifts away from zero, the point gets further and further away from the hyperplane. </span><span class="koboSpan" id="kobo.344.2" xmlns="http://www.w3.org/1999/xhtml">If it increases and it is between </span><span class="koboSpan" id="kobo.345.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.346.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.347.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.348.1" xmlns="http://www.w3.org/1999/xhtml">, the point </span><span class="koboSpan" id="kobo.349.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{p}" class="math inline" src="../media/file1218.png" style="vertical-align:middle" title="\overset{\rightarrow}{p}"/></span><span class="koboSpan" id="kobo.350.1" xmlns="http://www.w3.org/1999/xhtml"> is between the hyperplane </span><span class="koboSpan" id="kobo.351.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.352.1" xmlns="http://www.w3.org/1999/xhtml"> and the hyperplane </span><span class="koboSpan" id="kobo.353.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 1" class="math inline" src="../media/file1244.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 1"/></span><span class="koboSpan" id="kobo.354.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.354.2" xmlns="http://www.w3.org/1999/xhtml">When this value reaches </span><span class="koboSpan" id="kobo.355.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.356.1" xmlns="http://www.w3.org/1999/xhtml">, the point is in this latter hyperplane. </span><span class="koboSpan" id="kobo.356.2" xmlns="http://www.w3.org/1999/xhtml">And when the value becomes greater than </span><span class="koboSpan" id="kobo.357.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.358.1" xmlns="http://www.w3.org/1999/xhtml">, it moves beyond both hyperplanes. </span><span class="koboSpan" id="kobo.358.2" xmlns="http://www.w3.org/1999/xhtml">Analogously, if this value decreases and it is between </span><span class="koboSpan" id="kobo.359.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.360.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.361.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="- 1" class="math inline" src="../media/file312.png" style="vertical-align:middle" title="- 1"/></span><span class="koboSpan" id="kobo.362.1" xmlns="http://www.w3.org/1999/xhtml">, the point </span><span class="koboSpan" id="kobo.363.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{p}" class="math inline" src="../media/file1218.png" style="vertical-align:middle" title="\overset{\rightarrow}{p}"/></span><span class="koboSpan" id="kobo.364.1" xmlns="http://www.w3.org/1999/xhtml"> is between the hyperplane </span><span class="koboSpan" id="kobo.365.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.366.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.367.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = - 1" class="math inline" src="../media/file1245.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = - 1"/></span><span class="koboSpan" id="kobo.368.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.368.2" xmlns="http://www.w3.org/1999/xhtml">When the value reaches </span><span class="koboSpan" id="kobo.369.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="- 1" class="math inline" src="../media/file312.png" style="vertical-align:middle" title="- 1"/></span><span class="koboSpan" id="kobo.370.1" xmlns="http://www.w3.org/1999/xhtml">, the point is in this last hyperplane. </span><span class="koboSpan" id="kobo.370.2" xmlns="http://www.w3.org/1999/xhtml">And when it is smaller than </span><span class="koboSpan" id="kobo.371.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="- 1" class="math inline" src="../media/file312.png" style="vertical-align:middle" title="- 1"/></span><span class="koboSpan" id="kobo.372.1" xmlns="http://www.w3.org/1999/xhtml">, it has moved beyond both </span><span class="koboSpan" id="kobo.373.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="H" class="math inline" src="../media/file10.png" style="vertical-align:middle" title="H"/></span><span class="koboSpan" id="kobo.374.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.375.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = - 1" class="math inline" src="../media/file1245.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = - 1"/></span><span class="koboSpan" id="kobo.376.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.377.1" xmlns="http://www.w3.org/1999/xhtml">Since we are working under the </span><span id="dx1-163018"/><span class="koboSpan" id="kobo.378.1" xmlns="http://www.w3.org/1999/xhtml">assumption that there are no points inside the margin, the hyperplane </span><span class="koboSpan" id="kobo.379.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0" class="math inline" src="../media/file1201.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = 0"/></span><span class="koboSpan" id="kobo.380.1" xmlns="http://www.w3.org/1999/xhtml"> will properly </span><span id="dx1-163019"/><span class="koboSpan" id="kobo.381.1" xmlns="http://www.w3.org/1999/xhtml">separate the data if, for all the positive entries, </span><span class="koboSpan" id="kobo.382.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b \geq 1" class="math inline" src="../media/file1246.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b \geq 1"/></span><span class="koboSpan" id="kobo.383.1" xmlns="http://www.w3.org/1999/xhtml">, while all the negative ones will satisfy </span><span class="koboSpan" id="kobo.384.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b \leq - 1" class="math inline" src="../media/file1247.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b \leq - 1"/></span><span class="koboSpan" id="kobo.385.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.385.2" xmlns="http://www.w3.org/1999/xhtml">We can write this condition as</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.386.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y_{j}\left( {\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j}} \right) \geq 1," class="math display" src="../media/file1248.png" style="vertical-align:middle" title="y_{j}\left( {\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j}} \right) \geq 1,"/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.387.1" xmlns="http://www.w3.org/1999/xhtml">because we are considering </span><span class="koboSpan" id="kobo.388.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y_{j} = 1" class="math inline" src="../media/file1249.png" style="vertical-align:middle" title="y_{j} = 1"/></span><span class="koboSpan" id="kobo.389.1" xmlns="http://www.w3.org/1999/xhtml"> when the </span><span class="koboSpan" id="kobo.390.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.391.1" xmlns="http://www.w3.org/1999/xhtml">-th example belongs to the positive class and </span><span class="koboSpan" id="kobo.392.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y_{j} = - 1" class="math inline" src="../media/file1250.png" style="vertical-align:middle" title="y_{j} = - 1"/></span><span class="koboSpan" id="kobo.393.1" xmlns="http://www.w3.org/1999/xhtml"> when it belongs to the negative one.</span></p>
<figure>
<span class="koboSpan" id="kobo.394.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 9.4: The hyperplane that could have been returned by an SVM is represented by a black continuous line, and the lines in dashed lines are the equidistant parallel hyperplanes that are the furthest apart from each other while still separating the data. The margin is thus half of the thickness of the colored region " src="../media/file1251.jpg"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure9.4"><strong><span class="koboSpan" id="kobo.395.1" xmlns="http://www.w3.org/1999/xhtml">Figure 9.4</span></strong><span class="koboSpan" id="kobo.396.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="content"><span class="koboSpan" id="kobo.397.1" xmlns="http://www.w3.org/1999/xhtml">The hyperplane that could have been returned by an SVM is represented by a black continuous line, and the lines in dashed lines are the equidistant parallel hyperplanes that are the furthest apart from each other while still separating the data. </span><span class="koboSpan" id="kobo.397.2" xmlns="http://www.w3.org/1999/xhtml">The margin is thus half of the thickness of the colored region </span></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.398.1" xmlns="http://www.w3.org/1999/xhtml">For all this, the problem of finding the hyperplane that best separates the data can be posed as the following optimization problem:</span></p>
<p><span class="koboSpan" id="kobo.399.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\begin{array}{rlrl} {\text{Minimize}\quad} &amp; {\left\| w \right\|\qquad} &amp; &amp; \qquad \\ {\text{subject~to}\quad} &amp; {y_{j}(\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j}, + b) \geq 1,\qquad} &amp; &amp; \qquad \\ \end{array}" class="math display" src="../media/file1252.png" style="vertical-align:middle" title="\begin{array}{rlrl} {\text{Minimize}\quad} &amp; {\left\| w \right\|\qquad} &amp; &amp; \qquad \\ {\text{subject~to}\quad} &amp; {y_{j}(\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j}, + b) \geq 1,\qquad} &amp; &amp; \qquad \\ \end{array}"/></span></p>
<p><span class="koboSpan" id="kobo.400.1" xmlns="http://www.w3.org/1999/xhtml">where, of course, each </span><span class="koboSpan" id="kobo.401.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.402.1" xmlns="http://www.w3.org/1999/xhtml"> defines an individual constraint. </span><span class="koboSpan" id="kobo.402.2" xmlns="http://www.w3.org/1999/xhtml">This formulation suffers from a small problem. </span><span class="koboSpan" id="kobo.402.3" xmlns="http://www.w3.org/1999/xhtml">The Euclidean norm is nice, visual, and geometric, but it has a square root. </span><span class="koboSpan" id="kobo.402.4" xmlns="http://www.w3.org/1999/xhtml">We personally have nothing against square roots — some of our best friends </span><em><span class="koboSpan" id="kobo.403.1" xmlns="http://www.w3.org/1999/xhtml">are</span></em><span class="koboSpan" id="kobo.404.1" xmlns="http://www.w3.org/1999/xhtml"> square roots — but most optimization </span><span id="dx1-163022"/><span class="koboSpan" id="kobo.405.1" xmlns="http://www.w3.org/1999/xhtml">algorithms have some hard </span><span id="dx1-163023"/><span class="koboSpan" id="kobo.406.1" xmlns="http://www.w3.org/1999/xhtml">feelings against them. </span><span class="koboSpan" id="kobo.406.2" xmlns="http://www.w3.org/1999/xhtml">So just to make life easier for us, we may instead consider the following (equivalent) problem.</span></p>
<div class="tcolorbox important" id="tcolobox-170">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.407.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.408.1" xmlns="http://www.w3.org/1999/xhtml">If the data in the training dataset can be separated by a hyperplane, the problem of training an SVM can be posed as the following optimization problem:</span></p>
<span class="koboSpan" id="kobo.409.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\begin{array}{rlrl} {\text{Minimize}\quad} &amp; {\frac{1}{2}\left\| w \right\|^{2}\qquad} &amp; &amp; \qquad \\ {\text{subject~to}\quad} &amp; {y_{j}(\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j} + b) \geq 1.\qquad} &amp; &amp; \qquad \\ \end{array}" class="math display" src="../media/file1253.png" style="vertical-align:middle" title="\begin{array}{rlrl} {\text{Minimize}\quad} &amp; {\frac{1}{2}\left\| w \right\|^{2}\qquad} &amp; &amp; \qquad \\ {\text{subject~to}\quad} &amp; {y_{j}(\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j} + b) \geq 1.\qquad} &amp; &amp; \qquad \\ \end{array}"/></span>
<p><span class="koboSpan" id="kobo.410.1" xmlns="http://www.w3.org/1999/xhtml">This is known as </span><strong><span class="koboSpan" id="kobo.411.1" xmlns="http://www.w3.org/1999/xhtml">hard-margin</span></strong><span class="koboSpan" id="kobo.412.1" xmlns="http://www.w3.org/1999/xhtml"> training, because we are allowing no elements in the training dataset to be misclassified or even to be inside the margin.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.413.1" xmlns="http://www.w3.org/1999/xhtml">That nice and innocent square will save us from so many troubles. </span><span class="koboSpan" id="kobo.413.2" xmlns="http://www.w3.org/1999/xhtml">Notice, by the way, that we’ve introduced a </span><span class="koboSpan" id="kobo.414.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. 1\slash 2 \right." class="math inline" src="../media/file136.png" style="vertical-align:middle" title="\left. 1\slash 2 \right."/></span><span class="koboSpan" id="kobo.415.1" xmlns="http://www.w3.org/1999/xhtml"> factor next to </span><span class="koboSpan" id="kobo.416.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left\| w \right\|^{2}" class="math inline" src="../media/file1254.png" style="vertical-align:middle" title="\left\| w \right\|^{2}"/></span><span class="koboSpan" id="kobo.417.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.417.2" xmlns="http://www.w3.org/1999/xhtml">That’s for reasons of technical convenience, but it isn’t really important.</span></p>
<p><span class="koboSpan" id="kobo.418.1" xmlns="http://www.w3.org/1999/xhtml">With hard-margin training, we need our training data to be perfectly separable by a hyperplane because, otherwise, we will not find any feasible solutions to the optimization problem that we have just defined. </span><span class="koboSpan" id="kobo.418.2" xmlns="http://www.w3.org/1999/xhtml">This scenario is, in most situations, too restrictive. </span><span class="koboSpan" id="kobo.418.3" xmlns="http://www.w3.org/1999/xhtml">Thankfully, we can take an alternative </span><span id="dx1-163024"/><span class="koboSpan" id="kobo.419.1" xmlns="http://www.w3.org/1999/xhtml">approach known as </span><strong><span class="koboSpan" id="kobo.420.1" xmlns="http://www.w3.org/1999/xhtml">soft-margin training</span></strong><span class="koboSpan" id="kobo.421.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</section>
<section class="level3 subsectionHead" data-number="17.1.3" id="soft-margin-training">
<h2 class="subsectionHead" data-number="17.1.3"><span class="titlemark"><span class="koboSpan" id="kobo.422.1" xmlns="http://www.w3.org/1999/xhtml">9.1.3 </span></span> <span id="x1-1640009.1.3"><span class="koboSpan" id="kobo.423.1" xmlns="http://www.w3.org/1999/xhtml">Soft-margin training</span></span></h2>
<p><span class="koboSpan" id="kobo.424.1" xmlns="http://www.w3.org/1999/xhtml">Soft-margin </span><span id="dx1-164001"/><span class="koboSpan" id="kobo.425.1" xmlns="http://www.w3.org/1999/xhtml">training is </span><span id="dx1-164002"/><span class="koboSpan" id="kobo.426.1" xmlns="http://www.w3.org/1999/xhtml">similar to hard-margin training. </span><span class="koboSpan" id="kobo.426.2" xmlns="http://www.w3.org/1999/xhtml">The only difference is that it also incorporates some adjustable </span><strong><span class="koboSpan" id="kobo.427.1" xmlns="http://www.w3.org/1999/xhtml">slack</span></strong><span class="koboSpan" id="kobo.428.1" xmlns="http://www.w3.org/1999/xhtml">, or ”tolerance,” parameters </span><span class="koboSpan" id="kobo.429.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\xi_{j} \geq 0" class="math inline" src="../media/file1255.png" style="vertical-align:middle" title="\xi_{j} \geq 0"/></span><span class="koboSpan" id="kobo.430.1" xmlns="http://www.w3.org/1999/xhtml"> that will add flexibility to the constraints. </span><span class="koboSpan" id="kobo.430.2" xmlns="http://www.w3.org/1999/xhtml">In this way, instead of considering the constraint </span><span class="koboSpan" id="kobo.431.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y_{j}(\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j} + b) \geq 1" class="math inline" src="../media/file1256.png" style="vertical-align:middle" title="y_{j}(\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j} + b) \geq 1"/></span><span class="koboSpan" id="kobo.432.1" xmlns="http://www.w3.org/1999/xhtml">, we will use</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.433.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="y_{j}(w \cdot x_{j} + b) \geq 1 - \xi_{j}." class="math display" src="../media/file1257.png" style="vertical-align:middle" title="y_{j}(w \cdot x_{j} + b) \geq 1 - \xi_{j}."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.434.1" xmlns="http://www.w3.org/1999/xhtml">Thus, when </span><span class="koboSpan" id="kobo.435.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\xi_{j} &gt; 0" class="math inline" src="../media/file1258.png" style="vertical-align:middle" title="\xi_{j} &gt; 0"/></span><span class="koboSpan" id="kobo.436.1" xmlns="http://www.w3.org/1999/xhtml">, we will allow </span><span class="koboSpan" id="kobo.437.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\rightarrow}{x}}_{j}" class="math inline" src="../media/file1259.png" style="vertical-align:middle" title="{\overset{\rightarrow}{x}}_{j}"/></span><span class="koboSpan" id="kobo.438.1" xmlns="http://www.w3.org/1999/xhtml"> to be close to the hyperplane or even on the wrong side of the space (as separated by the hyperplane). </span><span class="koboSpan" id="kobo.438.2" xmlns="http://www.w3.org/1999/xhtml">What is more, the bigger the value of </span><span class="koboSpan" id="kobo.439.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\xi_{j}" class="math inline" src="../media/file1260.png" style="vertical-align:middle" title="\xi_{j}"/></span><span class="koboSpan" id="kobo.440.1" xmlns="http://www.w3.org/1999/xhtml">, the further into the wrong side </span><span class="koboSpan" id="kobo.441.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\rightarrow}{x}}_{j}" class="math inline" src="../media/file1259.png" style="vertical-align:middle" title="{\overset{\rightarrow}{x}}_{j}"/></span><span class="koboSpan" id="kobo.442.1" xmlns="http://www.w3.org/1999/xhtml"> will be.</span></p>
<p><span class="koboSpan" id="kobo.443.1" xmlns="http://www.w3.org/1999/xhtml">Naturally, we would like these </span><span class="koboSpan" id="kobo.444.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\xi_{j}" class="math inline" src="../media/file1260.png" style="vertical-align:middle" title="\xi_{j}"/></span><span class="koboSpan" id="kobo.445.1" xmlns="http://www.w3.org/1999/xhtml"> to be as small as possible, so we need to include them in the cost function that we want to minimize. </span><span class="koboSpan" id="kobo.445.2" xmlns="http://www.w3.org/1999/xhtml">Taking all of this into account, the optimization problem that we shall consider in soft-margin training will be the following.</span></p>
<div class="tcolorbox important" id="tcolobox-171">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.446.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.447.1" xmlns="http://www.w3.org/1999/xhtml">A support vector machine that may not be </span><em><span class="koboSpan" id="kobo.448.1" xmlns="http://www.w3.org/1999/xhtml">necessarily</span></em><span class="koboSpan" id="kobo.449.1" xmlns="http://www.w3.org/1999/xhtml"> able to properly separate the training data with a hyperplane can be trained by solving the following optimization problem:</span></p>
<span class="koboSpan" id="kobo.450.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\begin{array}{rlrl} {\text{Minimize}\quad} &amp; {\frac{1}{2}\left\| w \right\|^{2} + C\sum\limits_{j}\xi_{j}\qquad} &amp; &amp; \qquad \\ {\text{subject~to}\quad} &amp; {y_{j}(\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j} + b) \geq 1 - \xi_{j},\qquad} &amp; &amp; \qquad \\ &amp; {\xi_{j} \geq 0.\qquad} &amp; &amp; \qquad \\ \end{array}" class="math display" src="../media/file1261.png" style="vertical-align:middle" title="\begin{array}{rlrl} {\text{Minimize}\quad} &amp; {\frac{1}{2}\left\| w \right\|^{2} + C\sum\limits_{j}\xi_{j}\qquad} &amp; &amp; \qquad \\ {\text{subject~to}\quad} &amp; {y_{j}(\overset{\rightarrow}{w} \cdot {\overset{\rightarrow}{x}}_{j} + b) \geq 1 - \xi_{j},\qquad} &amp; &amp; \qquad \\  &amp; {\xi_{j} \geq 0.\qquad} &amp; &amp; \qquad \\ \end{array}"/></span>
<p><span class="koboSpan" id="kobo.451.1" xmlns="http://www.w3.org/1999/xhtml">The value </span><span class="koboSpan" id="kobo.452.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="C &gt; 0" class="math inline" src="../media/file1262.png" style="vertical-align:middle" title="C &gt; 0"/></span><span class="koboSpan" id="kobo.453.1" xmlns="http://www.w3.org/1999/xhtml"> is a hyperparameter that can be chosen at will. </span><span class="koboSpan" id="kobo.453.2" xmlns="http://www.w3.org/1999/xhtml">The bigger </span><span class="koboSpan" id="kobo.454.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="C" class="math inline" src="../media/file234.png" style="vertical-align:middle" title="C"/></span><span class="koboSpan" id="kobo.455.1" xmlns="http://www.w3.org/1999/xhtml"> is, the less tolerant we will be to training examples falling inside the margin or on the wrong side of the hyperplane.</span></p>
<p><span class="koboSpan" id="kobo.456.1" xmlns="http://www.w3.org/1999/xhtml">This formulation is </span><span id="dx1-164003"/><span class="koboSpan" id="kobo.457.1" xmlns="http://www.w3.org/1999/xhtml">known as </span><strong><span class="koboSpan" id="kobo.458.1" xmlns="http://www.w3.org/1999/xhtml">soft-margin training</span></strong><span class="koboSpan" id="kobo.459.1" xmlns="http://www.w3.org/1999/xhtml"> of an SVM.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.460.1" xmlns="http://www.w3.org/1999/xhtml">Let us now try to digest this formulation. </span><span class="koboSpan" id="kobo.460.2" xmlns="http://www.w3.org/1999/xhtml">As expected, we also made the </span><span class="koboSpan" id="kobo.461.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\xi_{j}" class="math inline" src="../media/file1260.png" style="vertical-align:middle" title="\xi_{j}"/></span><span class="koboSpan" id="kobo.462.1" xmlns="http://www.w3.org/1999/xhtml"> contribute to our cost function, in such a way that their taking large values will be penalized. </span><span class="koboSpan" id="kobo.462.2" xmlns="http://www.w3.org/1999/xhtml">In addition, we’ve incorporated this </span><span class="koboSpan" id="kobo.463.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="C" class="math inline" src="../media/file234.png" style="vertical-align:middle" title="C"/></span><span class="koboSpan" id="kobo.464.1" xmlns="http://www.w3.org/1999/xhtml"> constant and said that it can be tweaked at will. </span><span class="koboSpan" id="kobo.464.2" xmlns="http://www.w3.org/1999/xhtml">As we mentioned before, in broad terms, the bigger it is, the more unwilling we will be to accept misclassified elements in the </span><span id="dx1-164004"/><span class="koboSpan" id="kobo.465.1" xmlns="http://www.w3.org/1999/xhtml">training dataset. </span><span class="koboSpan" id="kobo.465.2" xmlns="http://www.w3.org/1999/xhtml">Actually, if there is a hyperplane that can perfectly separate the data, setting </span><span class="koboSpan" id="kobo.466.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="C" class="math inline" src="../media/file234.png" style="vertical-align:middle" title="C"/></span><span class="koboSpan" id="kobo.467.1" xmlns="http://www.w3.org/1999/xhtml"> to a huge value would be equivalent to doing hard-margin training. </span><span class="koboSpan" id="kobo.467.2" xmlns="http://www.w3.org/1999/xhtml">At first, it might seem tempting to make </span><span class="koboSpan" id="kobo.468.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="C" class="math inline" src="../media/file234.png" style="vertical-align:middle" title="C"/></span><span class="koboSpan" id="kobo.469.1" xmlns="http://www.w3.org/1999/xhtml"> huge, but this would make our model more prone to overfitting. </span><span class="koboSpan" id="kobo.469.2" xmlns="http://www.w3.org/1999/xhtml">Perfect fits are not that good! </span><span class="koboSpan" id="kobo.469.3" xmlns="http://www.w3.org/1999/xhtml">Balancing the value of </span><span class="koboSpan" id="kobo.470.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="C" class="math inline" src="../media/file234.png" style="vertical-align:middle" title="C"/></span><span class="koboSpan" id="kobo.471.1" xmlns="http://www.w3.org/1999/xhtml"> is one of the many keys behind successful SVM training.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-172">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.472.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.473.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.474.1" xmlns="http://www.w3.org/1999/xhtml">When we train an SVM, the actual loss function that we would like to minimize is</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.475.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="L(\overset{\rightarrow}{w},b;\overset{\rightarrow}{x},y) = \max\{ 0,1 - y(\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b)\}," class="math display" src="../media/file1263.png" style="vertical-align:middle" title="L(\overset{\rightarrow}{w},b;\overset{\rightarrow}{x},y) = \max\{ 0,1 - y(\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b)\},"/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.476.1" xmlns="http://www.w3.org/1999/xhtml">which is </span><span id="dx1-164005"/><span class="koboSpan" id="kobo.477.1" xmlns="http://www.w3.org/1999/xhtml">called the </span><strong><span class="koboSpan" id="kobo.478.1" xmlns="http://www.w3.org/1999/xhtml">hinge loss</span></strong><span class="koboSpan" id="kobo.479.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.479.2" xmlns="http://www.w3.org/1999/xhtml">In fact, our </span><span class="koboSpan" id="kobo.480.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\xi_{j}" class="math inline" src="../media/file1260.png" style="vertical-align:middle" title="\xi_{j}"/></span><span class="koboSpan" id="kobo.481.1" xmlns="http://www.w3.org/1999/xhtml"> variables are direct representatives of that loss. </span><span class="koboSpan" id="kobo.481.2" xmlns="http://www.w3.org/1999/xhtml">Minimizing the expected value of this loss function would be connected to minimizing the proportion of misclassified elements — which is what we want at the end of the day.</span></p>
<p><span class="koboSpan" id="kobo.482.1" xmlns="http://www.w3.org/1999/xhtml">If, in our formulation, we didn’t have the </span><span class="koboSpan" id="kobo.483.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. \left\| w \right\|^{2}\slash 2 \right." class="math inline" src="../media/file1264.png" style="vertical-align:middle" title="\left. \left\| w \right\|^{2}\slash 2 \right."/></span><span class="koboSpan" id="kobo.484.1" xmlns="http://www.w3.org/1999/xhtml"> factor, that would be the training loss that we would be minimizing. </span><span class="koboSpan" id="kobo.484.2" xmlns="http://www.w3.org/1999/xhtml">We included this factor, however, because a small </span><span class="koboSpan" id="kobo.485.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left\| w \right\|^{2}" class="math inline" src="../media/file1254.png" style="vertical-align:middle" title="\left\| w \right\|^{2}"/></span><span class="koboSpan" id="kobo.486.1" xmlns="http://www.w3.org/1999/xhtml"> (that is, a large margin) makes SVM models more robust against overfitting.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.487.1" xmlns="http://www.w3.org/1999/xhtml">We will conclude this analysis of soft-margin training by presenting an equivalent formulation of its optimization problem. </span><span class="koboSpan" id="kobo.487.2" xmlns="http://www.w3.org/1999/xhtml">This </span><span id="dx1-164006"/><span class="koboSpan" id="kobo.488.1" xmlns="http://www.w3.org/1999/xhtml">formulation is known as the </span><strong><span class="koboSpan" id="kobo.489.1" xmlns="http://www.w3.org/1999/xhtml">Lagrangian dual</span></strong><span class="koboSpan" id="kobo.490.1" xmlns="http://www.w3.org/1999/xhtml"> of the optimization problem that we presented previously. </span><span class="koboSpan" id="kobo.490.2" xmlns="http://www.w3.org/1999/xhtml">We will not discuss why these two formulations are equivalent, but you can take our word for it — or you can check the wonderful explanation by Abu-Mostafa, Magdon-Ismail, and Lin </span><span class="cite"><span class="koboSpan" id="kobo.491.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xabu2012blearning"><span class="koboSpan" id="kobo.492.1" xmlns="http://www.w3.org/1999/xhtml">2</span></a><span class="koboSpan" id="kobo.493.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.494.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<div class="tcolorbox important" id="tcolobox-173">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.495.1" xmlns="http://www.w3.org/1999/xhtml">Important note</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.496.1" xmlns="http://www.w3.org/1999/xhtml">The soft-margin training problem can be equivalently written in terms of some optimizable parameters </span><span class="koboSpan" id="kobo.497.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\alpha_{j}" class="math inline" src="../media/file1265.png" style="vertical-align:middle" title="\alpha_{j}"/></span><span class="koboSpan" id="kobo.498.1" xmlns="http://www.w3.org/1999/xhtml"> as follows:</span></p>
<span class="koboSpan" id="kobo.499.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\begin{array}{rlrl} {\text{Maximize}\quad} &amp; {\sum\limits_{j}\alpha_{j} - \frac{1}{2}\sum\limits_{j,k}y_{j}y_{k}\alpha_{j}\alpha_{k}\left( {{\overset{\rightarrow}{x}}_{j} \cdot {\overset{\rightarrow}{x}}_{k}} \right),\qquad} &amp; &amp; \qquad \\ {\text{subject~to}\quad} &amp; {0 \leq \alpha_{j} \leq C,\qquad} &amp; &amp; \qquad \\ &amp; {\sum\limits_{j}\alpha_{j}y_{j} = 0.\qquad} &amp; &amp; \qquad \\ \end{array}" class="math display" src="../media/file1266.png" style="vertical-align:middle" title="\begin{array}{rlrl} {\text{Maximize}\quad} &amp; {\sum\limits_{j}\alpha_{j} - \frac{1}{2}\sum\limits_{j,k}y_{j}y_{k}\alpha_{j}\alpha_{k}\left( {{\overset{\rightarrow}{x}}_{j} \cdot {\overset{\rightarrow}{x}}_{k}} \right),\qquad} &amp; &amp; \qquad \\ {\text{subject~to}\quad} &amp; {0 \leq \alpha_{j} \leq C,\qquad} &amp; &amp; \qquad \\  &amp; {\sum\limits_{j}\alpha_{j}y_{j} = 0.\qquad} &amp; &amp; \qquad \\ \end{array}"/></span>
</div>
</div>
<p><span class="koboSpan" id="kobo.500.1" xmlns="http://www.w3.org/1999/xhtml">This formulation of the SVM soft-margin </span><span id="dx1-164007"/><span class="koboSpan" id="kobo.501.1" xmlns="http://www.w3.org/1999/xhtml">training problem is, most of the time, easier to solve in practice, and it is the one that we will be working with. </span><span class="koboSpan" id="kobo.501.2" xmlns="http://www.w3.org/1999/xhtml">Once we obtain the </span><span class="koboSpan" id="kobo.502.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\alpha_{j}" class="math inline" src="../media/file1265.png" style="vertical-align:middle" title="\alpha_{j}"/></span><span class="koboSpan" id="kobo.503.1" xmlns="http://www.w3.org/1999/xhtml"> values, it is also possible to go back to the original formulation. </span><span class="koboSpan" id="kobo.503.2" xmlns="http://www.w3.org/1999/xhtml">In fact, from the </span><span class="koboSpan" id="kobo.504.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\alpha_{j}" class="math inline" src="../media/file1265.png" style="vertical-align:middle" title="\alpha_{j}"/></span><span class="koboSpan" id="kobo.505.1" xmlns="http://www.w3.org/1999/xhtml"> values, we can recover </span><span class="koboSpan" id="kobo.506.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="b" class="math inline" src="../media/file17.png" style="vertical-align:middle" title="b"/></span><span class="koboSpan" id="kobo.507.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.508.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="w" class="math inline" src="../media/file1267.png" style="vertical-align:middle" title="w"/></span><span class="koboSpan" id="kobo.509.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.509.2" xmlns="http://www.w3.org/1999/xhtml">For instance, it holds that</span></p>
<p><span class="koboSpan" id="kobo.510.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} = \sum\limits_{j}\alpha_{j}y_{j}\overset{\rightarrow}{x_{j}}." class="math display" src="../media/file1268.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} = \sum\limits_{j}\alpha_{j}y_{j}\overset{\rightarrow}{x_{j}}."/></span></p>
<p><span class="koboSpan" id="kobo.511.1" xmlns="http://www.w3.org/1999/xhtml">Notice that </span><span class="koboSpan" id="kobo.512.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w}" class="math inline" src="../media/file1205.png" style="vertical-align:middle" title="\overset{\rightarrow}{w}"/></span><span class="koboSpan" id="kobo.513.1" xmlns="http://www.w3.org/1999/xhtml"> only depends on the training points </span><span class="koboSpan" id="kobo.514.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x_{j}}" class="math inline" src="../media/file1269.png" style="vertical-align:middle" title="\overset{\rightarrow}{x_{j}}"/></span><span class="koboSpan" id="kobo.515.1" xmlns="http://www.w3.org/1999/xhtml">, for which </span><span class="koboSpan" id="kobo.516.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\alpha_{j} \neq 0" class="math inline" src="../media/file1270.png" style="vertical-align:middle" title="\alpha_{j} \neq 0"/></span><span class="koboSpan" id="kobo.517.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.517.2" xmlns="http://www.w3.org/1999/xhtml">These </span><span id="dx1-164008"/><span class="koboSpan" id="kobo.518.1" xmlns="http://www.w3.org/1999/xhtml">vectors are called </span><strong><span class="koboSpan" id="kobo.519.1" xmlns="http://www.w3.org/1999/xhtml">support vectors</span></strong><span class="koboSpan" id="kobo.520.1" xmlns="http://www.w3.org/1999/xhtml"> and, as you can imagine, are the reason behind the name of the SVM model.</span></p>
<p><span class="koboSpan" id="kobo.521.1" xmlns="http://www.w3.org/1999/xhtml">Furthermore, we can also recover </span><span class="koboSpan" id="kobo.522.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="b" class="math inline" src="../media/file17.png" style="vertical-align:middle" title="b"/></span><span class="koboSpan" id="kobo.523.1" xmlns="http://www.w3.org/1999/xhtml"> by finding some </span><span class="koboSpan" id="kobo.524.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x_{j}}" class="math inline" src="../media/file1269.png" style="vertical-align:middle" title="\overset{\rightarrow}{x_{j}}"/></span><span class="koboSpan" id="kobo.525.1" xmlns="http://www.w3.org/1999/xhtml"> that lies at the boundary of the margin and solving a simple equation — see </span><span class="cite"><span class="koboSpan" id="kobo.526.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xabu2012blearning"><span class="koboSpan" id="kobo.527.1" xmlns="http://www.w3.org/1999/xhtml">2</span></a><span class="koboSpan" id="kobo.528.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.529.1" xmlns="http://www.w3.org/1999/xhtml"> for all the details. </span><span class="koboSpan" id="kobo.529.2" xmlns="http://www.w3.org/1999/xhtml">Then, in order to classify a point </span><span class="koboSpan" id="kobo.530.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.531.1" xmlns="http://www.w3.org/1999/xhtml">, we can just compute</span></p>
<p><span class="koboSpan" id="kobo.532.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \sum\limits_{j}\alpha_{j}y_{j}\left( {\overset{\rightarrow}{x_{j}} \cdot \overset{\rightarrow}{x}} \right) + b," class="math display" src="../media/file1271.png" style="vertical-align:middle" title="\overset{\rightarrow}{w} \cdot \overset{\rightarrow}{x} + b = \sum\limits_{j}\alpha_{j}y_{j}\left( {\overset{\rightarrow}{x_{j}} \cdot \overset{\rightarrow}{x}} \right) + b,"/></span></p>
<p><span class="koboSpan" id="kobo.533.1" xmlns="http://www.w3.org/1999/xhtml">and decide whether </span><span class="koboSpan" id="kobo.534.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.535.1" xmlns="http://www.w3.org/1999/xhtml"> goes into the positive or negative class depending on whether the result is bigger than 0 or not.</span></p>
<p><span class="koboSpan" id="kobo.536.1" xmlns="http://www.w3.org/1999/xhtml">We’ve now covered all we need to know about how to train a support vector machine. </span><span class="koboSpan" id="kobo.536.2" xmlns="http://www.w3.org/1999/xhtml">But, with our tools, we can only train these models to obtain linear separations between data, which is, well, not the most exciting of prospects. </span><span class="koboSpan" id="kobo.536.3" xmlns="http://www.w3.org/1999/xhtml">In the next section, we will overcome this limitation with a simple yet powerful trick.</span></p>
</section>
<section class="level3 subsectionHead" data-number="17.1.4" id="the-kernel-trick">
<h2 class="subsectionHead" data-number="17.1.4"><span class="titlemark"><span class="koboSpan" id="kobo.537.1" xmlns="http://www.w3.org/1999/xhtml">9.1.4 </span></span> <span id="x1-1650009.1.4"><span class="koboSpan" id="kobo.538.1" xmlns="http://www.w3.org/1999/xhtml">The kernel trick</span></span></h2>
<p><span class="koboSpan" id="kobo.539.1" xmlns="http://www.w3.org/1999/xhtml">Vanilla SVMs can only be </span><span id="dx1-165001"/><span class="koboSpan" id="kobo.540.1" xmlns="http://www.w3.org/1999/xhtml">trained to find </span><span id="dx1-165002"/><span class="koboSpan" id="kobo.541.1" xmlns="http://www.w3.org/1999/xhtml">linear separations between data elements. </span><span class="koboSpan" id="kobo.541.2" xmlns="http://www.w3.org/1999/xhtml">For example, the data shown in </span><em><span class="koboSpan" id="kobo.542.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.5a"><em><span class="koboSpan" id="kobo.543.1" xmlns="http://www.w3.org/1999/xhtml">9.5a</span></em></a><span class="koboSpan" id="kobo.544.1" xmlns="http://www.w3.org/1999/xhtml"> cannot be separated effectively by any SVM, because there is no way to separate it linearly.</span></p>
<p><span class="koboSpan" id="kobo.545.1" xmlns="http://www.w3.org/1999/xhtml">How do we overcome this? </span><span class="koboSpan" id="kobo.545.2" xmlns="http://www.w3.org/1999/xhtml">Using </span><strong><span class="koboSpan" id="kobo.546.1" xmlns="http://www.w3.org/1999/xhtml">the kernel trick</span></strong><span class="koboSpan" id="kobo.547.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.547.2" xmlns="http://www.w3.org/1999/xhtml">This technique consists in mapping the data from its original space </span><span class="koboSpan" id="kobo.548.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{n}" class="math inline" src="../media/file1212.png" style="vertical-align:middle" title="R^{n}"/></span><span class="koboSpan" id="kobo.549.1" xmlns="http://www.w3.org/1999/xhtml"> to a higher dimensional space </span><span class="koboSpan" id="kobo.550.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{N}" class="math inline" src="../media/file1272.png" style="vertical-align:middle" title="R^{N}"/></span><span class="koboSpan" id="kobo.551.1" xmlns="http://www.w3.org/1999/xhtml">, all in the hope that, in that space, there may be a way to separate the data with a hyperplane. </span><span class="koboSpan" id="kobo.551.2" xmlns="http://www.w3.org/1999/xhtml">This higher dimensional space is </span><span id="dx1-165003"/><span class="koboSpan" id="kobo.552.1" xmlns="http://www.w3.org/1999/xhtml">known as a </span><strong><span class="koboSpan" id="kobo.553.1" xmlns="http://www.w3.org/1999/xhtml">feature space</span></strong><span class="koboSpan" id="kobo.554.1" xmlns="http://www.w3.org/1999/xhtml">, and we will refer to the function </span><span class="koboSpan" id="kobo.555.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left. \varphi:R^{n}\rightarrow R^{N} \right." class="math inline" src="../media/file1273.png" style="vertical-align:middle" title="\left. \varphi:R^{n}\rightarrow R^{N} \right."/></span><span class="koboSpan" id="kobo.556.1" xmlns="http://www.w3.org/1999/xhtml"> — which takes the original data inputs into the </span><span id="dx1-165004"/><span class="koboSpan" id="kobo.557.1" xmlns="http://www.w3.org/1999/xhtml">feature space — as a </span><strong><span class="koboSpan" id="kobo.558.1" xmlns="http://www.w3.org/1999/xhtml">feature</span></strong> <strong><span class="koboSpan" id="kobo.559.1" xmlns="http://www.w3.org/1999/xhtml">map</span></strong><span class="koboSpan" id="kobo.560.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.561.1" xmlns="http://www.w3.org/1999/xhtml">For instance, the data in </span><em><span class="koboSpan" id="kobo.562.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.5a"><em><span class="koboSpan" id="kobo.563.1" xmlns="http://www.w3.org/1999/xhtml">9.5a</span></em></a><span class="koboSpan" id="kobo.564.1" xmlns="http://www.w3.org/1999/xhtml"> is in the </span><span class="koboSpan" id="kobo.565.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.566.1" xmlns="http://www.w3.org/1999/xhtml">-dimensional real line, but we can map it to the </span><span class="koboSpan" id="kobo.567.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2" class="math inline" src="../media/file302.png" style="vertical-align:middle" title="2"/></span><span class="koboSpan" id="kobo.568.1" xmlns="http://www.w3.org/1999/xhtml">-dimensional plane with the function</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.569.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="f(x) = (x,x^{2})." class="math display" src="../media/file1274.png" style="vertical-align:middle" title="f(x) = (x,x^{2})."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.570.1" xmlns="http://www.w3.org/1999/xhtml">As we can see in </span><em><span class="koboSpan" id="kobo.571.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.5b"><em><span class="koboSpan" id="kobo.572.1" xmlns="http://www.w3.org/1999/xhtml">9.5b</span></em></a><span class="koboSpan" id="kobo.573.1" xmlns="http://www.w3.org/1999/xhtml">, upon doing this, there is a hyperplane that perfectly separates the two categories in our dataset.</span></p>
<figure>
<span class="koboSpan" id="kobo.574.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(a) Original data in the real line" src="../media/file1275.png"/></span>
<figcaption aria-hidden="true"><span id="Figure9.5a"><strong><span class="koboSpan" id="kobo.575.1" xmlns="http://www.w3.org/1999/xhtml">(a)</span></strong></span><span class="koboSpan" id="kobo.576.1" xmlns="http://www.w3.org/1999/xhtml"> Original data in the real line</span></figcaption>
</figure>
<figure>
<span class="koboSpan" id="kobo.577.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(b) Data in the feature space" src="../media/file1276.png"/></span>
<figcaption aria-hidden="true"><span id="Figure9.5b"><strong><span class="koboSpan" id="kobo.578.1" xmlns="http://www.w3.org/1999/xhtml">(b)</span></strong></span><span class="koboSpan" id="kobo.579.1" xmlns="http://www.w3.org/1999/xhtml"> Data in the feature space</span></figcaption>
</figure>
<p><span id="Figure9.5"><strong><span class="koboSpan" id="kobo.580.1" xmlns="http://www.w3.org/1999/xhtml">Figure 9.5</span></strong></span><span class="koboSpan" id="kobo.581.1" xmlns="http://www.w3.org/1999/xhtml">: The original data cannot be separated by a hyperplane, but — upon taking it to a higher-dimensional space with a feature map — it can. </span><span class="koboSpan" id="kobo.581.2" xmlns="http://www.w3.org/1999/xhtml">The separating hyperplane is represented by a dashed line</span></p>
<p><span class="koboSpan" id="kobo.582.1" xmlns="http://www.w3.org/1999/xhtml">Looking at the dual form of the soft-margin SVM optimization problem, we can see how, in order to train an SVM — and to later classify new data — on a certain feature space with a feature map </span><span class="koboSpan" id="kobo.583.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\varphi" class="math inline" src="../media/file1277.png" style="vertical-align:middle" title="\varphi"/></span><span class="koboSpan" id="kobo.584.1" xmlns="http://www.w3.org/1999/xhtml">, all we need to ”know” about the feature space is how to compute scalar products in it of elements </span><span id="dx1-165009"/><span class="koboSpan" id="kobo.585.1" xmlns="http://www.w3.org/1999/xhtml">returned by the feature map. </span><span class="koboSpan" id="kobo.585.2" xmlns="http://www.w3.org/1999/xhtml">This is because, during the whole training process, the only operation that depends on the </span><span class="koboSpan" id="kobo.586.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x_{j}}" class="math inline" src="../media/file1269.png" style="vertical-align:middle" title="\overset{\rightarrow}{x_{j}}"/></span><span class="koboSpan" id="kobo.587.1" xmlns="http://www.w3.org/1999/xhtml"> points is the inner product </span><span class="koboSpan" id="kobo.588.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\rightarrow}{x}}_{j} \cdot {\overset{\rightarrow}{x}}_{k}" class="math inline" src="../media/file1278.png" style="vertical-align:middle" title="{\overset{\rightarrow}{x}}_{j} \cdot {\overset{\rightarrow}{x}}_{k}"/></span><span class="koboSpan" id="kobo.589.1" xmlns="http://www.w3.org/1999/xhtml"> — or the inner product </span><span class="koboSpan" id="kobo.590.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x_{j}} \cdot \overset{\rightarrow}{x}" class="math inline" src="../media/file1279.png" style="vertical-align:middle" title="\overset{\rightarrow}{x_{j}} \cdot \overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.591.1" xmlns="http://www.w3.org/1999/xhtml"> when classifying a new point </span><span class="koboSpan" id="kobo.592.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.593.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.593.2" xmlns="http://www.w3.org/1999/xhtml">If instead of </span><span class="koboSpan" id="kobo.594.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x_{j}}" class="math inline" src="../media/file1269.png" style="vertical-align:middle" title="\overset{\rightarrow}{x_{j}}"/></span><span class="koboSpan" id="kobo.595.1" xmlns="http://www.w3.org/1999/xhtml"> we had </span><span class="koboSpan" id="kobo.596.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\varphi(\overset{\rightarrow}{x_{j}})" class="math inline" src="../media/file1280.png" style="vertical-align:middle" title="\varphi(\overset{\rightarrow}{x_{j}})"/></span><span class="koboSpan" id="kobo.597.1" xmlns="http://www.w3.org/1999/xhtml">, we would just need to know how to compute </span><span class="koboSpan" id="kobo.598.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\varphi({\overset{\rightarrow}{x}}_{j}) \cdot \varphi({\overset{\rightarrow}{x}}_{k})" class="math inline" src="../media/file1281.png" style="vertical-align:middle" title="\varphi({\overset{\rightarrow}{x}}_{j}) \cdot \varphi({\overset{\rightarrow}{x}}_{k})"/></span><span class="koboSpan" id="kobo.599.1" xmlns="http://www.w3.org/1999/xhtml"> — or </span><span class="koboSpan" id="kobo.600.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\varphi({\overset{\rightarrow}{x}}_{j}) \cdot \varphi(\overset{\rightarrow}{x})" class="math inline" src="../media/file1282.png" style="vertical-align:middle" title="\varphi({\overset{\rightarrow}{x}}_{j}) \cdot \varphi(\overset{\rightarrow}{x})"/></span><span class="koboSpan" id="kobo.601.1" xmlns="http://www.w3.org/1999/xhtml"> to classify new data </span><span class="koboSpan" id="kobo.602.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.603.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.604.1" xmlns="http://www.w3.org/1999/xhtml">That is, it suffices to be able to compute the function</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.605.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k(x,y) = \varphi(\overset{\rightarrow}{x}) \cdot \varphi(\overset{\rightarrow}{y})," class="math display" src="../media/file1283.png" style="vertical-align:middle" title="k(x,y) = \varphi(\overset{\rightarrow}{x}) \cdot \varphi(\overset{\rightarrow}{y}),"/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.606.1" xmlns="http://www.w3.org/1999/xhtml">and that is the single and only computation that we need to perform in the feature space. </span><span class="koboSpan" id="kobo.606.2" xmlns="http://www.w3.org/1999/xhtml">This is a crucial fact. </span><span class="koboSpan" id="kobo.606.3" xmlns="http://www.w3.org/1999/xhtml">This function is a particular case of what are </span><span id="dx1-165010"/><span class="koboSpan" id="kobo.607.1" xmlns="http://www.w3.org/1999/xhtml">known as </span><strong><span class="koboSpan" id="kobo.608.1" xmlns="http://www.w3.org/1999/xhtml">kernel functions</span></strong><span class="koboSpan" id="kobo.609.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.609.2" xmlns="http://www.w3.org/1999/xhtml">Broadly speaking, kernel functions are functions that </span><em><span class="koboSpan" id="kobo.610.1" xmlns="http://www.w3.org/1999/xhtml">can be</span></em><span class="koboSpan" id="kobo.611.1" xmlns="http://www.w3.org/1999/xhtml"> represented as inner products in some space. </span><span class="koboSpan" id="kobo.611.2" xmlns="http://www.w3.org/1999/xhtml">Mercer’s theorem (see </span><span class="cite"><span class="koboSpan" id="kobo.612.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xabu2012blearning"><span class="koboSpan" id="kobo.613.1" xmlns="http://www.w3.org/1999/xhtml">2</span></a><span class="koboSpan" id="kobo.614.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.615.1" xmlns="http://www.w3.org/1999/xhtml">) gives a nice characterization of them in terms of certain properties such as being symmetric and some other conditions. </span><span class="koboSpan" id="kobo.615.2" xmlns="http://www.w3.org/1999/xhtml">In the cases that we will consider, these conditions are always going to be met, so we don’t need to worry too much about them.</span></p>
<p><span class="koboSpan" id="kobo.616.1" xmlns="http://www.w3.org/1999/xhtml">With this, we have a general understanding of how support vector machines are used in general, and in classical setups in particular. </span><span class="koboSpan" id="kobo.616.2" xmlns="http://www.w3.org/1999/xhtml">We now have all the necessary background to take the step to quantum. </span><span class="koboSpan" id="kobo.616.3" xmlns="http://www.w3.org/1999/xhtml">Get ready to explore quantum support vector machines.</span></p>
</section>
</section>
<section class="level2 sectionHead" data-number="17.2" id="going-quantum">
<h1 class="sectionHead" data-number="17.2"><span class="titlemark"><span class="koboSpan" id="kobo.617.1" xmlns="http://www.w3.org/1999/xhtml">9.2</span></span> <span id="x1-1660009.2"><span class="koboSpan" id="kobo.618.1" xmlns="http://www.w3.org/1999/xhtml">Going quantum</span></span></h1>
<p><span class="koboSpan" id="kobo.619.1" xmlns="http://www.w3.org/1999/xhtml">As we have already mentioned, quantum support vector machines are particular cases of SVMs. </span><span class="koboSpan" id="kobo.619.2" xmlns="http://www.w3.org/1999/xhtml">To be more precise, they are particular cases of SVMs that rely on the kernel trick.</span></p>
<p><span class="koboSpan" id="kobo.620.1" xmlns="http://www.w3.org/1999/xhtml">We have seen in the previous section how, with the kernel trick, we take our data to a feature space: a higher dimensional space in which, we hope, our data will be separable by a hyperplane with the right choice of feature map. </span><span class="koboSpan" id="kobo.620.2" xmlns="http://www.w3.org/1999/xhtml">This feature space is usually just the ordinary Euclidean space but, well, with a higher dimension. </span><span class="koboSpan" id="kobo.620.3" xmlns="http://www.w3.org/1999/xhtml">But we can consider other choices. </span><span class="koboSpan" id="kobo.620.4" xmlns="http://www.w3.org/1999/xhtml">How about…the space of quantum states?</span></p>
<section class="level3 subsectionHead" data-number="17.2.1" id="the-general-idea-behind-quantum-support-vector-machines">
<h2 class="subsectionHead" data-number="17.2.1"><span class="titlemark"><span class="koboSpan" id="kobo.621.1" xmlns="http://www.w3.org/1999/xhtml">9.2.1 </span></span> <span id="x1-1670009.2.1"><span class="koboSpan" id="kobo.622.1" xmlns="http://www.w3.org/1999/xhtml">The general idea behind quantum support vector machines</span></span></h2>
<p><span class="koboSpan" id="kobo.623.1" xmlns="http://www.w3.org/1999/xhtml">A QSVM </span><span id="dx1-167001"/><span class="koboSpan" id="kobo.624.1" xmlns="http://www.w3.org/1999/xhtml">works just like an ordinary SVM that relies on the kernel trick — with the only difference that it uses as feature space a certain space of quantum states.</span></p>
<p><span class="koboSpan" id="kobo.625.1" xmlns="http://www.w3.org/1999/xhtml">As we discussed before, whenever we use the kernel trick, all we need from the feature space is a kernel function. </span><span class="koboSpan" id="kobo.625.2" xmlns="http://www.w3.org/1999/xhtml">That’s the only ingredient involving the feature space that is necessary in order to be able to train a kernel-based SVM and make predictions with it. </span><span class="koboSpan" id="kobo.625.3" xmlns="http://www.w3.org/1999/xhtml">This idea inspired some works, such as the famous paper by Havlíček et al. </span><span class="cite"><span class="koboSpan" id="kobo.626.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xhavlivcek2019supervised"><span class="koboSpan" id="kobo.627.1" xmlns="http://www.w3.org/1999/xhtml">52</span></a><span class="koboSpan" id="kobo.628.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.629.1" xmlns="http://www.w3.org/1999/xhtml">, to try to use quantum circuits to compute kernels and, hopefully, obtain some advantage over classical computers by working in a sophisticated feature space.</span></p>
<p><span class="koboSpan" id="kobo.630.1" xmlns="http://www.w3.org/1999/xhtml">Taking this into account, in order to train and then use a quantum support vector machine for classification, we will be able to do business as usual — doing everything fully classically — except for the computation of the kernel function. </span><span class="koboSpan" id="kobo.630.2" xmlns="http://www.w3.org/1999/xhtml">This function will have to rely on a quantum computer in order to do the following:</span></p>
<ol>
<li><div id="x1-167003x1">
<p><span class="koboSpan" id="kobo.631.1" xmlns="http://www.w3.org/1999/xhtml">Take as input two vectors in the original space of data.</span></p>
</div></li>
<li><div id="x1-167005x2">
<p><span class="koboSpan" id="kobo.632.1" xmlns="http://www.w3.org/1999/xhtml">Map each of them to a quantum state through a </span><strong><span class="koboSpan" id="kobo.633.1" xmlns="http://www.w3.org/1999/xhtml">feature map</span></strong><span class="koboSpan" id="kobo.634.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div></li>
<li><div id="x1-167007x3">
<p><span class="koboSpan" id="kobo.635.1" xmlns="http://www.w3.org/1999/xhtml">Compute the inner product of the quantum states and return it.</span></p>
</div></li>
</ol>
<p><span class="koboSpan" id="kobo.636.1" xmlns="http://www.w3.org/1999/xhtml">We will discuss how to implement these (quantum) </span><span id="dx1-167008"/><span class="koboSpan" id="kobo.637.1" xmlns="http://www.w3.org/1999/xhtml">feature maps in the next subsection, but, in essence, they are just circuits that are parametrized exclusively by the original (classical) data and thus prepare a quantum state that depends only on that data. </span><span class="koboSpan" id="kobo.637.2" xmlns="http://www.w3.org/1999/xhtml">For now, we will just take these feature maps as a given.</span></p>
<p><span class="koboSpan" id="kobo.638.1" xmlns="http://www.w3.org/1999/xhtml">So, let’s say that we have a feature map </span><span class="koboSpan" id="kobo.639.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\varphi" class="math inline" src="../media/file1277.png" style="vertical-align:middle" title="\varphi"/></span><span class="koboSpan" id="kobo.640.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.640.2" xmlns="http://www.w3.org/1999/xhtml">This will be implemented by a circuit </span><span class="koboSpan" id="kobo.641.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\Phi" class="math inline" src="../media/file1284.png" style="vertical-align:middle" title="\Phi"/></span><span class="koboSpan" id="kobo.642.1" xmlns="http://www.w3.org/1999/xhtml"> that will depend on some classical data in the original space: for each input </span><span class="koboSpan" id="kobo.643.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.644.1" xmlns="http://www.w3.org/1999/xhtml">, we will have a circuit </span><span class="koboSpan" id="kobo.645.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\Phi(\overset{\rightarrow}{x})" class="math inline" src="../media/file1285.png" style="vertical-align:middle" title="\Phi(\overset{\rightarrow}{x})"/></span><span class="koboSpan" id="kobo.646.1" xmlns="http://www.w3.org/1999/xhtml"> such that the output of the feature map will be the quantum state </span><span class="koboSpan" id="kobo.647.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\varphi(\overset{\rightarrow}{x}) = \Phi(\overset{\rightarrow}{x})\left| 0 \right\rangle" class="math inline" src="../media/file1286.png" style="vertical-align:middle" title="\varphi(\overset{\rightarrow}{x}) = \Phi(\overset{\rightarrow}{x})\left| 0 \right\rangle"/></span><span class="koboSpan" id="kobo.648.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.648.2" xmlns="http://www.w3.org/1999/xhtml">With a feature map ready, we can then take our kernel function to be</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.649.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k(\overset{\rightarrow}{a},\overset{\rightarrow}{b}) = \left| \left\langle \varphi(a) \middle| \varphi(b) \right\rangle \right|^{2} = \left| {\left\langle 0 \right|\Phi^{\dagger}(a)\Phi(b)\left| 0 \right\rangle} \right|^{2}." class="math display" src="../media/file1287.png" style="vertical-align:middle" title="k(\overset{\rightarrow}{a},\overset{\rightarrow}{b}) = \left| \left\langle \varphi(a) \middle| \varphi(b) \right\rangle \right|^{2} = \left| {\left\langle 0 \right|\Phi^{\dagger}(a)\Phi(b)\left| 0 \right\rangle} \right|^{2}."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.650.1" xmlns="http://www.w3.org/1999/xhtml">And that is something that we can trivially get from a quantum computer! </span><span class="koboSpan" id="kobo.650.2" xmlns="http://www.w3.org/1999/xhtml">As you can easily check yourself, it is nothing more than the probability of measuring all zeros after preparing the state </span><span class="koboSpan" id="kobo.651.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\Phi^{\dagger}(\overset{\rightarrow}{a})\Phi(\overset{\rightarrow}{b})\left| 0 \right\rangle" class="math inline" src="../media/file1288.png" style="vertical-align:middle" title="\Phi^{\dagger}(\overset{\rightarrow}{a})\Phi(\overset{\rightarrow}{b})\left| 0 \right\rangle"/></span><span class="koboSpan" id="kobo.652.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.652.2" xmlns="http://www.w3.org/1999/xhtml">This follows from the fact that the computational basis is orthonormal.</span></p>
<p><span class="koboSpan" id="kobo.653.1" xmlns="http://www.w3.org/1999/xhtml">In case you were wondering how to compute the circuit for </span><span class="koboSpan" id="kobo.654.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\Phi^{\dagger}" class="math inline" src="../media/file1289.png" style="vertical-align:middle" title="\Phi^{\dagger}"/></span><span class="koboSpan" id="kobo.655.1" xmlns="http://www.w3.org/1999/xhtml">, notice that this is just the inverse of </span><span class="koboSpan" id="kobo.656.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\Phi" class="math inline" src="../media/file1284.png" style="vertical-align:middle" title="\Phi"/></span><span class="koboSpan" id="kobo.657.1" xmlns="http://www.w3.org/1999/xhtml">, because quantum circuits are always represented by unitary operations. </span><span class="koboSpan" id="kobo.657.2" xmlns="http://www.w3.org/1999/xhtml">But </span><span class="koboSpan" id="kobo.658.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\Phi" class="math inline" src="../media/file1284.png" style="vertical-align:middle" title="\Phi"/></span><span class="koboSpan" id="kobo.659.1" xmlns="http://www.w3.org/1999/xhtml"> will be given by a series of quantum gates. </span><span class="koboSpan" id="kobo.659.2" xmlns="http://www.w3.org/1999/xhtml">So all you need to do is apply the gates in the circuit from right to left and invert each of them.</span></p>
<p><span class="koboSpan" id="kobo.660.1" xmlns="http://www.w3.org/1999/xhtml">And that is how you implement a quantum kernel function. </span><span class="koboSpan" id="kobo.660.2" xmlns="http://www.w3.org/1999/xhtml">You take a feature map that will return a circuit </span><span class="koboSpan" id="kobo.661.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\Phi(\overset{\rightarrow}{x})" class="math inline" src="../media/file1285.png" style="vertical-align:middle" title="\Phi(\overset{\rightarrow}{x})"/></span><span class="koboSpan" id="kobo.662.1" xmlns="http://www.w3.org/1999/xhtml"> for any input </span><span class="koboSpan" id="kobo.663.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\overset{\rightarrow}{x}" class="math inline" src="../media/file1206.png" style="vertical-align:middle" title="\overset{\rightarrow}{x}"/></span><span class="koboSpan" id="kobo.664.1" xmlns="http://www.w3.org/1999/xhtml">, you prepare the state </span><span class="koboSpan" id="kobo.665.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\Phi^{\dagger}(\overset{\rightarrow}{a})\Phi(\overset{\rightarrow}{b})\left| 0 \right\rangle" class="math inline" src="../media/file1288.png" style="vertical-align:middle" title="\Phi^{\dagger}(\overset{\rightarrow}{a})\Phi(\overset{\rightarrow}{b})\left| 0 \right\rangle"/></span><span class="koboSpan" id="kobo.666.1" xmlns="http://www.w3.org/1999/xhtml"> for the pair of vectors on which you want to compute the kernel, and you return the probability of measuring zero on all the qubits.</span></p>
<p><span class="koboSpan" id="kobo.667.1" xmlns="http://www.w3.org/1999/xhtml">In case you were concerned, by the way, all quantum kernels, as we have defined them, satisfy the conditions needed to qualify as kernel functions </span><span class="cite"><span class="koboSpan" id="kobo.668.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xschuld2021supervised"><span class="koboSpan" id="kobo.669.1" xmlns="http://www.w3.org/1999/xhtml">85</span></a><span class="koboSpan" id="kobo.670.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.671.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.671.2" xmlns="http://www.w3.org/1999/xhtml">In fact, we’ll now ask you to check one of those conditions!</span></p>
<div class="tcolorbox questionx" id="tcolobox-174">
<span id="x1-167010x9.2.1"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.672.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 9.2</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.673.1" xmlns="http://www.w3.org/1999/xhtml">One of the conditions for a function </span><span class="koboSpan" id="kobo.674.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.675.1" xmlns="http://www.w3.org/1999/xhtml"> to be a kernel is that it be symmetric. </span><span class="koboSpan" id="kobo.675.2" xmlns="http://www.w3.org/1999/xhtml">Prove that, indeed, any quantum kernel is symmetric. </span><span class="koboSpan" id="kobo.675.3" xmlns="http://www.w3.org/1999/xhtml">(</span><span class="koboSpan" id="kobo.676.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k(\overset{\rightarrow}{a},\overset{\rightarrow}{b}) = k(\overset{\rightarrow}{b},\overset{\rightarrow}{a})" class="math inline" src="../media/file1290.png" style="vertical-align:middle" title="k(\overset{\rightarrow}{a},\overset{\rightarrow}{b}) = k(\overset{\rightarrow}{b},\overset{\rightarrow}{a})"/></span><span class="koboSpan" id="kobo.677.1" xmlns="http://www.w3.org/1999/xhtml"> for any inputs.)</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.678.1" xmlns="http://www.w3.org/1999/xhtml">Let’s now study how to actually construct those feature maps.</span></p>
</section>
<section class="level3 subsectionHead" data-number="17.2.2" id="feature-maps">
<h2 class="subsectionHead" data-number="17.2.2"><span class="titlemark"><span class="koboSpan" id="kobo.679.1" xmlns="http://www.w3.org/1999/xhtml">9.2.2 </span></span> <span id="x1-1680009.2.2"><span class="koboSpan" id="kobo.680.1" xmlns="http://www.w3.org/1999/xhtml">Feature maps</span></span></h2>
<p><span class="koboSpan" id="kobo.681.1" xmlns="http://www.w3.org/1999/xhtml">A </span><span id="dx1-168001"/><span class="koboSpan" id="kobo.682.1" xmlns="http://www.w3.org/1999/xhtml">feature map, as we have said, is often defined by a parametrized circuit </span><span class="koboSpan" id="kobo.683.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\Phi(\overset{\rightarrow}{x})" class="math inline" src="../media/file1285.png" style="vertical-align:middle" title="\Phi(\overset{\rightarrow}{x})"/></span><span class="koboSpan" id="kobo.684.1" xmlns="http://www.w3.org/1999/xhtml"> that depends on the original data and thus can be used to prepare a state that depends on it. </span><span class="koboSpan" id="kobo.684.2" xmlns="http://www.w3.org/1999/xhtml">In this section, we will study a few interesting feature maps that we will use throughout the rest of the book. </span><span class="koboSpan" id="kobo.684.3" xmlns="http://www.w3.org/1999/xhtml">They will also serve as examples that will allow us to better illustrate what feature maps actually are.</span></p>
<p><span class="paragraphHead"><span id="x1-1690009.2.2"/><strong><span class="koboSpan" id="kobo.685.1" xmlns="http://www.w3.org/1999/xhtml">Angle encoding</span></strong></span><span class="koboSpan" id="kobo.686.1" xmlns="http://www.w3.org/1999/xhtml"> We shall begin with a </span><span id="dx1-169001"/><span class="koboSpan" id="kobo.687.1" xmlns="http://www.w3.org/1999/xhtml">simple yet </span><span id="dx1-169002"/><span class="koboSpan" id="kobo.688.1" xmlns="http://www.w3.org/1999/xhtml">powerful feature map known as </span><strong><span class="koboSpan" id="kobo.689.1" xmlns="http://www.w3.org/1999/xhtml">angle encoding</span></strong><span class="koboSpan" id="kobo.690.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.690.2" xmlns="http://www.w3.org/1999/xhtml">When used on an </span><span class="koboSpan" id="kobo.691.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.692.1" xmlns="http://www.w3.org/1999/xhtml">-qubit circuit, this feature map can take up to </span><span class="koboSpan" id="kobo.693.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.694.1" xmlns="http://www.w3.org/1999/xhtml"> numerical inputs </span><span class="koboSpan" id="kobo.695.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x_{1},\ldots,x_{n}" class="math inline" src="../media/file1291.png" style="vertical-align:middle" title="x_{1},\ldots,x_{n}"/></span><span class="koboSpan" id="kobo.696.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.696.2" xmlns="http://www.w3.org/1999/xhtml">The action of its circuit consists in the application of a rotation gate on each qubit </span><span class="koboSpan" id="kobo.697.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.698.1" xmlns="http://www.w3.org/1999/xhtml"> parametrized by the value </span><span class="koboSpan" id="kobo.699.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x_{j}" class="math inline" src="../media/file407.png" style="vertical-align:middle" title="x_{j}"/></span><span class="koboSpan" id="kobo.700.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.700.2" xmlns="http://www.w3.org/1999/xhtml">In this feature map, we are using the </span><span class="koboSpan" id="kobo.701.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x_{j}" class="math inline" src="../media/file407.png" style="vertical-align:middle" title="x_{j}"/></span><span class="koboSpan" id="kobo.702.1" xmlns="http://www.w3.org/1999/xhtml"> values as angles in the rotations, hence the name of the encoding.</span></p>
<p><span class="koboSpan" id="kobo.703.1" xmlns="http://www.w3.org/1999/xhtml">In angle encoding, we are free to use any rotation gate of our choice. </span><span class="koboSpan" id="kobo.703.2" xmlns="http://www.w3.org/1999/xhtml">However, if we use </span><span class="koboSpan" id="kobo.704.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Z}" class="math inline" src="../media/file120.png" style="vertical-align:middle" title="R_{Z}"/></span><span class="koboSpan" id="kobo.705.1" xmlns="http://www.w3.org/1999/xhtml"> gates and take </span><span class="koboSpan" id="kobo.706.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| 0 \right\rangle" class="math inline" src="../media/file6.png" style="vertical-align:middle" title="\left| 0 \right\rangle"/></span><span class="koboSpan" id="kobo.707.1" xmlns="http://www.w3.org/1999/xhtml"> to be our initial state…the action of our feature map will have no effects whatsoever, as you can easily check from the definition of </span><span class="koboSpan" id="kobo.708.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Z}" class="math inline" src="../media/file120.png" style="vertical-align:middle" title="R_{Z}"/></span><span class="koboSpan" id="kobo.709.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.709.2" xmlns="http://www.w3.org/1999/xhtml">That is why, when </span><span class="koboSpan" id="kobo.710.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Z}" class="math inline" src="../media/file120.png" style="vertical-align:middle" title="R_{Z}"/></span><span class="koboSpan" id="kobo.711.1" xmlns="http://www.w3.org/1999/xhtml"> gates are used, it is customary to precede them by Hadamard gates acting on each qubit. </span><span class="koboSpan" id="kobo.711.2" xmlns="http://www.w3.org/1999/xhtml">All this is shown in </span><em><span class="koboSpan" id="kobo.712.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.6"><em><span class="koboSpan" id="kobo.713.1" xmlns="http://www.w3.org/1999/xhtml">9.6</span></em></a><span class="koboSpan" id="kobo.714.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<figure>
<span class="koboSpan" id="kobo.715.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 9.6: Angle encoding for an input (x_{1},\ldots,x_{n}) using different rotation gates" src="../media/file1293.jpg"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure9.6"><strong><span class="koboSpan" id="kobo.716.1" xmlns="http://www.w3.org/1999/xhtml">Figure 9.6</span></strong><span class="koboSpan" id="kobo.717.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.718.1" xmlns="http://www.w3.org/1999/xhtml">Angle encoding for an input </span><span class="koboSpan" id="kobo.719.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(x_{1},\ldots,x_{n})" class="math inline" src="../media/file1292.png" style="vertical-align:middle" title="(x_{1},\ldots,x_{n})"/></span><span class="koboSpan" id="kobo.720.1" xmlns="http://www.w3.org/1999/xhtml"> using different rotation gates</span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.721.1" xmlns="http://www.w3.org/1999/xhtml">The </span><span id="dx1-169005"/><span class="koboSpan" id="kobo.722.1" xmlns="http://www.w3.org/1999/xhtml">variables that are fed to the </span><span id="dx1-169006"/><span class="koboSpan" id="kobo.723.1" xmlns="http://www.w3.org/1999/xhtml">angle encoding feature map should be normalized within a certain interval. </span><span class="koboSpan" id="kobo.723.2" xmlns="http://www.w3.org/1999/xhtml">If they are normalized between </span><span class="koboSpan" id="kobo.724.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.725.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.726.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4\pi" class="math inline" src="../media/file1294.png" style="vertical-align:middle" title="4\pi"/></span><span class="koboSpan" id="kobo.727.1" xmlns="http://www.w3.org/1999/xhtml">, then the data will be mapped to a wider region of the feature space than if they were normalized between </span><span class="koboSpan" id="kobo.728.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.729.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.730.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.731.1" xmlns="http://www.w3.org/1999/xhtml">, for example. </span><span class="koboSpan" id="kobo.731.2" xmlns="http://www.w3.org/1999/xhtml">However, this would come at the cost of having the two extrema of the dataset identified under the action of the feature map. </span><span class="koboSpan" id="kobo.731.3" xmlns="http://www.w3.org/1999/xhtml">That’s because 0 and </span><span class="koboSpan" id="kobo.732.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2\pi" class="math inline" src="../media/file1295.png" style="vertical-align:middle" title="2\pi"/></span><span class="koboSpan" id="kobo.733.1" xmlns="http://www.w3.org/1999/xhtml"> are exactly the same angle and, in our definition of rotation gates, we divided the input angle by </span><span class="koboSpan" id="kobo.734.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2" class="math inline" src="../media/file302.png" style="vertical-align:middle" title="2"/></span><span class="koboSpan" id="kobo.735.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.736.1" xmlns="http://www.w3.org/1999/xhtml">The choice of normalization will thus be a trade-off between separating the extrema in the feature space and using the widest possible region in it.</span></p>
<p><span class="paragraphHead"><span id="x1-1700009.2.2"/><strong><span class="koboSpan" id="kobo.737.1" xmlns="http://www.w3.org/1999/xhtml">Amplitude encoding</span></strong></span><span class="koboSpan" id="kobo.738.1" xmlns="http://www.w3.org/1999/xhtml"> Angle </span><span id="dx1-170001"/><span class="koboSpan" id="kobo.739.1" xmlns="http://www.w3.org/1999/xhtml">encoding can take </span><span class="koboSpan" id="kobo.740.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.741.1" xmlns="http://www.w3.org/1999/xhtml"> inputs on </span><span class="koboSpan" id="kobo.742.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.743.1" xmlns="http://www.w3.org/1999/xhtml"> qubits. </span><span class="koboSpan" id="kobo.743.2" xmlns="http://www.w3.org/1999/xhtml">Does that </span><span id="dx1-170002"/><span class="koboSpan" id="kobo.744.1" xmlns="http://www.w3.org/1999/xhtml">seem good enough? </span><span class="koboSpan" id="kobo.744.2" xmlns="http://www.w3.org/1999/xhtml">Well, get ready for a big jump. </span><span class="koboSpan" id="kobo.744.3" xmlns="http://www.w3.org/1999/xhtml">The </span><strong><span class="koboSpan" id="kobo.745.1" xmlns="http://www.w3.org/1999/xhtml">amplitude encoding</span></strong><span class="koboSpan" id="kobo.746.1" xmlns="http://www.w3.org/1999/xhtml"> feature map can take </span><span class="koboSpan" id="kobo.747.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2^{n}" class="math inline" src="../media/file256.png" style="vertical-align:middle" title="2^{n}"/></span><span class="koboSpan" id="kobo.748.1" xmlns="http://www.w3.org/1999/xhtml"> inputs when implemented on an </span><span class="koboSpan" id="kobo.749.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.750.1" xmlns="http://www.w3.org/1999/xhtml">-qubit circuit. </span><span class="koboSpan" id="kobo.750.2" xmlns="http://www.w3.org/1999/xhtml">That is a lot, and it will enable us to effectively train QSVMs on datasets with a large number of variables. </span><span class="koboSpan" id="kobo.750.3" xmlns="http://www.w3.org/1999/xhtml">So, how does it work then?</span></p>
<p><span class="koboSpan" id="kobo.751.1" xmlns="http://www.w3.org/1999/xhtml">If the amplitude encoding feature map is given an input </span><span class="koboSpan" id="kobo.752.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x_{0},\ldots,x_{2^{n} - 1}" class="math inline" src="../media/file1296.png" style="vertical-align:middle" title="x_{0},\ldots,x_{2^{n} - 1}"/></span><span class="koboSpan" id="kobo.753.1" xmlns="http://www.w3.org/1999/xhtml">, it simply prepares the state</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.754.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\left| {\varphi(\overset{\rightarrow}{a})} \right\rangle = \frac{1}{\sqrt{\sum\limits_{k}x_{k}^{2}}}\sum\limits_{k = 0}^{2^{n} - 1}x_{k}\left| k \right\rangle." class="math display" src="../media/file1297.png" style="vertical-align:middle" title="\left| {\varphi(\overset{\rightarrow}{a})} \right\rangle = \frac{1}{\sqrt{\sum\limits_{k}x_{k}^{2}}}\sum\limits_{k = 0}^{2^{n} - 1}x_{k}\left| k \right\rangle."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.755.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we’ve had to include a normalization factor to make sure that the output was, indeed, a quantum state. </span><span class="koboSpan" id="kobo.755.2" xmlns="http://www.w3.org/1999/xhtml">Remember from </span><em><span class="koboSpan" id="kobo.756.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch008.xhtml#x1-180001"><em><span class="koboSpan" id="kobo.757.1" xmlns="http://www.w3.org/1999/xhtml">1</span></em></a><span class="koboSpan" id="kobo.758.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.759.1" xmlns="http://www.w3.org/1999/xhtml">Foundations of</span></em> <em><span class="koboSpan" id="kobo.760.1" xmlns="http://www.w3.org/1999/xhtml">Quantum Computing</span></em><span class="koboSpan" id="kobo.761.1" xmlns="http://www.w3.org/1999/xhtml">, that all quantum states need to be normalized vectors! </span><span class="koboSpan" id="kobo.761.2" xmlns="http://www.w3.org/1999/xhtml">It’s easy to see from the definition that amplitude encoding can work for any input except for the zero vector — for the zero vector, amplitude encoding is undefined. </span><span class="koboSpan" id="kobo.761.3" xmlns="http://www.w3.org/1999/xhtml">We can’t divide by zero!</span></p>
<p><span class="koboSpan" id="kobo.762.1" xmlns="http://www.w3.org/1999/xhtml">Implementing this </span><span id="dx1-170003"/><span class="koboSpan" id="kobo.763.1" xmlns="http://www.w3.org/1999/xhtml">feature map in terms of elementary quantum gates is by no means simple. </span><span class="koboSpan" id="kobo.763.2" xmlns="http://www.w3.org/1999/xhtml">If you want all the gory details, you can check the book by Schuld and Petruccione </span><span class="cite"><span class="koboSpan" id="kobo.764.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xschuld"><span class="koboSpan" id="kobo.765.1" xmlns="http://www.w3.org/1999/xhtml">106</span></a><span class="koboSpan" id="kobo.766.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.767.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.767.2" xmlns="http://www.w3.org/1999/xhtml">Luckily, it is built into most quantum computing frameworks.</span></p>
<p><span class="koboSpan" id="kobo.768.1" xmlns="http://www.w3.org/1999/xhtml">By the way, when using </span><span id="dx1-170004"/><span class="koboSpan" id="kobo.769.1" xmlns="http://www.w3.org/1999/xhtml">amplitude encoding, there is an unavoidable loss of information if you decide to ”push the feature map to its limit.” </span><span class="koboSpan" id="kobo.769.2" xmlns="http://www.w3.org/1999/xhtml">In general, you won’t be using all the </span><span class="koboSpan" id="kobo.770.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2^{n}" class="math inline" src="../media/file256.png" style="vertical-align:middle" title="2^{n}"/></span><span class="koboSpan" id="kobo.771.1" xmlns="http://www.w3.org/1999/xhtml"> parameters that it offers — you will only use some of them and fill the rest with zeros or any other value of your choice. </span><span class="koboSpan" id="kobo.771.2" xmlns="http://www.w3.org/1999/xhtml">But, if you use all the </span><span class="koboSpan" id="kobo.772.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2^{n}" class="math inline" src="../media/file256.png" style="vertical-align:middle" title="2^{n}"/></span><span class="koboSpan" id="kobo.773.1" xmlns="http://www.w3.org/1999/xhtml"> inputs to encode variables, there’s a small issue: that the number of degrees of freedom of an </span><span class="koboSpan" id="kobo.774.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.775.1" xmlns="http://www.w3.org/1999/xhtml">-qubit state is actually </span><span class="koboSpan" id="kobo.776.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2^{n} - 1" class="math inline" src="../media/file1298.png" style="vertical-align:middle" title="2^{n} - 1"/></span><span class="koboSpan" id="kobo.777.1" xmlns="http://www.w3.org/1999/xhtml">, not </span><span class="koboSpan" id="kobo.778.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="2^{n}" class="math inline" src="../media/file256.png" style="vertical-align:middle" title="2^{n}"/></span><span class="koboSpan" id="kobo.779.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.779.2" xmlns="http://www.w3.org/1999/xhtml">This is, in any case, not a big deal. </span><span class="koboSpan" id="kobo.779.3" xmlns="http://www.w3.org/1999/xhtml">This loss of information can be ignored for sufficiently big values of </span><span class="koboSpan" id="kobo.780.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.781.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="paragraphHead"><span id="x1-1710009.2.2"/><strong><span class="koboSpan" id="kobo.782.1" xmlns="http://www.w3.org/1999/xhtml">ZZ feature map</span></strong></span><span class="koboSpan" id="kobo.783.1" xmlns="http://www.w3.org/1999/xhtml"> Lastly, we will </span><span id="dx1-171001"/><span class="koboSpan" id="kobo.784.1" xmlns="http://www.w3.org/1999/xhtml">present a known </span><span id="dx1-171002"/><span class="koboSpan" id="kobo.785.1" xmlns="http://www.w3.org/1999/xhtml">feature map that may bring you memories from </span><em><span class="koboSpan" id="kobo.786.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch013.xhtml#x1-940005"><em><span class="koboSpan" id="kobo.787.1" xmlns="http://www.w3.org/1999/xhtml">5</span></em></a><span class="koboSpan" id="kobo.788.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.789.1" xmlns="http://www.w3.org/1999/xhtml">QAOA: Quantum Approximate Optimization</span></em> <em><span class="koboSpan" id="kobo.790.1" xmlns="http://www.w3.org/1999/xhtml">Algorithm</span></em><span class="koboSpan" id="kobo.791.1" xmlns="http://www.w3.org/1999/xhtml">, where we implemented circuits for Hamiltonians with </span><span class="koboSpan" id="kobo.792.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Z_{j}Z_{k}" class="math inline" src="../media/file363.png" style="vertical-align:middle" title="Z_{j}Z_{k}"/></span><span class="koboSpan" id="kobo.793.1" xmlns="http://www.w3.org/1999/xhtml"> terms. </span><span class="koboSpan" id="kobo.793.2" xmlns="http://www.w3.org/1999/xhtml">It’s called the </span><strong><span class="koboSpan" id="kobo.794.1" xmlns="http://www.w3.org/1999/xhtml">ZZ feature map</span></strong><span class="koboSpan" id="kobo.795.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.795.2" xmlns="http://www.w3.org/1999/xhtml">It is implemented by Qiskit and it can take </span><span class="koboSpan" id="kobo.796.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.797.1" xmlns="http://www.w3.org/1999/xhtml"> inputs </span><span class="koboSpan" id="kobo.798.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="a_{1},\ldots,a_{n}" class="math inline" src="../media/file1299.png" style="vertical-align:middle" title="a_{1},\ldots,a_{n}"/></span><span class="koboSpan" id="kobo.799.1" xmlns="http://www.w3.org/1999/xhtml"> on </span><span class="koboSpan" id="kobo.800.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.801.1" xmlns="http://www.w3.org/1999/xhtml"> qubits, just like angle embedding. </span><span class="koboSpan" id="kobo.801.2" xmlns="http://www.w3.org/1999/xhtml">Its parametrized circuit is constructed following these steps:</span></p>
<ol>
<li><div id="x1-171004x1">
<p><span class="koboSpan" id="kobo.802.1" xmlns="http://www.w3.org/1999/xhtml">Apply a Hadamard gate on each qubit.</span></p>
</div></li>
<li><div id="x1-171006x2">
<p><span class="koboSpan" id="kobo.803.1" xmlns="http://www.w3.org/1999/xhtml">Apply, on each qubit </span><span class="koboSpan" id="kobo.804.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.805.1" xmlns="http://www.w3.org/1999/xhtml">, a rotation </span><span class="koboSpan" id="kobo.806.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Z}(2x_{j})" class="math inline" src="../media/file1300.png" style="vertical-align:middle" title="R_{Z}(2x_{j})"/></span><span class="koboSpan" id="kobo.807.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div></li>
<li><div id="x1-171008x3">
<p><span class="koboSpan" id="kobo.808.1" xmlns="http://www.w3.org/1999/xhtml">For each pair of elements </span><span class="koboSpan" id="kobo.809.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\{ j,k\} \subseteq \{ 1,\ldots,n\}" class="math inline" src="../media/file1301.png" style="vertical-align:middle" title="\{ j,k\} \subseteq \{ 1,\ldots,n\}"/></span><span class="koboSpan" id="kobo.810.1" xmlns="http://www.w3.org/1999/xhtml"> with </span><span class="koboSpan" id="kobo.811.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j &lt; k" class="math inline" src="../media/file1302.png" style="vertical-align:middle" title="j &lt; k"/></span><span class="koboSpan" id="kobo.812.1" xmlns="http://www.w3.org/1999/xhtml">, do the following:</span></p>
<ol>
<li><div id="x1-171010x1">
<p><span class="koboSpan" id="kobo.813.1" xmlns="http://www.w3.org/1999/xhtml">Apply a CNOT gate targeting qubit </span><span class="koboSpan" id="kobo.814.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.815.1" xmlns="http://www.w3.org/1999/xhtml"> and controlled by qubit </span><span class="koboSpan" id="kobo.816.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.817.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div></li>
<li><div id="x1-171012x2">
<p><span class="koboSpan" id="kobo.818.1" xmlns="http://www.w3.org/1999/xhtml">Apply, on qubit </span><span class="koboSpan" id="kobo.819.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.820.1" xmlns="http://www.w3.org/1999/xhtml">, a rotation </span><span class="koboSpan" id="kobo.821.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{Z}\left( {2(\pi - x_{j})(\pi - x_{k})} \right)" class="math inline" src="../media/file1303.png" style="vertical-align:middle" title="R_{Z}\left( {2(\pi - x_{j})(\pi - x_{k})} \right)"/></span><span class="koboSpan" id="kobo.822.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div></li>
<li><div id="x1-171014x3">
<p><span class="koboSpan" id="kobo.823.1" xmlns="http://www.w3.org/1999/xhtml">Repeat step </span><a href="#x1-171010x1"><span class="koboSpan" id="kobo.824.1" xmlns="http://www.w3.org/1999/xhtml">3a</span></a><span class="koboSpan" id="kobo.825.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div></li>
</ol>
</div></li>
</ol>
<p><span class="koboSpan" id="kobo.826.1" xmlns="http://www.w3.org/1999/xhtml">In </span><em><span class="koboSpan" id="kobo.827.1" xmlns="http://www.w3.org/1999/xhtml">Figure</span></em> <a href="#Figure9.7"><em><span class="koboSpan" id="kobo.828.1" xmlns="http://www.w3.org/1999/xhtml">9.7</span></em></a><span class="koboSpan" id="kobo.829.1" xmlns="http://www.w3.org/1999/xhtml"> you can find a representation of the ZZ feature map on three qubits.</span></p>
<p><span class="koboSpan" id="kobo.830.1" xmlns="http://www.w3.org/1999/xhtml">As with angle encoding, normalization plays a big role in the ZZ feature map. </span><span class="koboSpan" id="kobo.830.2" xmlns="http://www.w3.org/1999/xhtml">In order to guarantee a healthy balance between separating the extrema of the dataset and using as big a region a possible in the feature space, the variables could be normalized to </span><span class="koboSpan" id="kobo.831.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\lbrack 0,1\rbrack" class="math inline" src="../media/file1145.png" style="vertical-align:middle" title="\lbrack 0,1\rbrack"/></span><span class="koboSpan" id="kobo.832.1" xmlns="http://www.w3.org/1999/xhtml"> or </span><span class="koboSpan" id="kobo.833.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\lbrack 0,3\rbrack" class="math inline" src="../media/file1304.png" style="vertical-align:middle" title="\lbrack 0,3\rbrack"/></span><span class="koboSpan" id="kobo.834.1" xmlns="http://www.w3.org/1999/xhtml">, for example.</span></p>
<figure>
<span class="koboSpan" id="kobo.835.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="Figure 9.7: ZZ feature map on three qubits with inputs x_{1},x_{2},x_{3}" src="../media/file1306.jpg"/></span>
<figcaption aria-hidden="true"><span class="id" id="Figure9.7"><strong><span class="koboSpan" id="kobo.836.1" xmlns="http://www.w3.org/1999/xhtml">Figure 9.7</span></strong><span class="koboSpan" id="kobo.837.1" xmlns="http://www.w3.org/1999/xhtml">: </span></span><span class="koboSpan" id="kobo.838.1" xmlns="http://www.w3.org/1999/xhtml">ZZ feature map on three qubits with inputs </span><span class="koboSpan" id="kobo.839.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x_{1},x_{2},x_{3}" class="math inline" src="../media/file1305.png" style="vertical-align:middle" title="x_{1},x_{2},x_{3}"/></span></figcaption>
</figure>
<p><span class="koboSpan" id="kobo.840.1" xmlns="http://www.w3.org/1999/xhtml">Of course, when designing a </span><span id="dx1-171017"/><span class="koboSpan" id="kobo.841.1" xmlns="http://www.w3.org/1999/xhtml">quantum feature map, your </span><span id="dx1-171018"/><span class="koboSpan" id="kobo.842.1" xmlns="http://www.w3.org/1999/xhtml">imagination is the only limit. </span><span class="koboSpan" id="kobo.842.2" xmlns="http://www.w3.org/1999/xhtml">The ones that we have presented here are some of the most popular ones — and the ones that you will find in frameworks such as PennyLane and Qiskit — but research on quantum feature maps and their properties is an active area. </span><span class="koboSpan" id="kobo.842.3" xmlns="http://www.w3.org/1999/xhtml">If you want to take a look at other possibilities, we can recommend the paper by Sim, Johnson, and Aspuru-Guzik </span><span class="cite"><span class="koboSpan" id="kobo.843.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#Xsim2019expressibility"><span class="koboSpan" id="kobo.844.1" xmlns="http://www.w3.org/1999/xhtml">88</span></a><span class="koboSpan" id="kobo.845.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.846.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.847.1" xmlns="http://www.w3.org/1999/xhtml">But enough theory for now! </span><span class="koboSpan" id="kobo.847.2" xmlns="http://www.w3.org/1999/xhtml">Let’s put into practice all that we have learned by implementing some QSVMs with both PennyLane and Qiskit.</span></p>
</section>
</section>
<section class="level2 sectionHead" data-number="17.3" id="quantum-support-vector-machines-in-pennylane">
<h1 class="sectionHead" data-number="17.3"><span class="titlemark"><span class="koboSpan" id="kobo.848.1" xmlns="http://www.w3.org/1999/xhtml">9.3 </span></span> <span id="x1-1720009.3"><span class="koboSpan" id="kobo.849.1" xmlns="http://www.w3.org/1999/xhtml">Quantum support vector machines in PennyLane</span></span></h1>
<p><span class="koboSpan" id="kobo.850.1" xmlns="http://www.w3.org/1999/xhtml">It has been a long journey but, finally, we are ready to see </span><span id="dx1-172001"/><span class="koboSpan" id="kobo.851.1" xmlns="http://www.w3.org/1999/xhtml">QSVMs in action. </span><span class="koboSpan" id="kobo.851.2" xmlns="http://www.w3.org/1999/xhtml">In this section, we are going to train and run a bunch of QSVM models using PennyLane. </span><span class="koboSpan" id="kobo.851.3" xmlns="http://www.w3.org/1999/xhtml">Just to get started, let’s import NumPy and set a seed so that our results are reproducible:</span></p>
<p><span id="x1-172002"/></p>
<pre class="lstlisting" id="listing-207"><span class="koboSpan" id="kobo.852.1" xmlns="http://www.w3.org/1999/xhtml">

import numpy as np 
 
 
 
seed = 1234 
 
np.random.seed(seed)
</span></pre>
<section class="level3 subsectionHead" data-number="17.3.1" id="setting-the-scene-for-training-a-qsvm">
<h2 class="subsectionHead" data-number="17.3.1"><span class="titlemark"><span class="koboSpan" id="kobo.853.1" xmlns="http://www.w3.org/1999/xhtml">9.3.1 </span></span> <span id="x1-1730009.3.1"><span class="koboSpan" id="kobo.854.1" xmlns="http://www.w3.org/1999/xhtml">Setting the scene for training a QSVM</span></span></h2>
<p><span class="koboSpan" id="kobo.855.1" xmlns="http://www.w3.org/1999/xhtml">Now, if we want to </span><span id="dx1-173001"/><span class="koboSpan" id="kobo.856.1" xmlns="http://www.w3.org/1999/xhtml">train QSVMs, we need some data to work with. </span><span class="koboSpan" id="kobo.856.2" xmlns="http://www.w3.org/1999/xhtml">In today’s ever-changing job market, you should always keep your options open and, as promising as quantum machine learning may be, you may want to have a backup career plan. </span><span class="koboSpan" id="kobo.856.3" xmlns="http://www.w3.org/1999/xhtml">Well, we’ve got you covered. </span><span class="koboSpan" id="kobo.856.4" xmlns="http://www.w3.org/1999/xhtml">Have you ever dreamed of becoming a world-class sommelier? </span><span class="koboSpan" id="kobo.856.5" xmlns="http://www.w3.org/1999/xhtml">Today is your lucky day! </span><span class="koboSpan" id="kobo.856.6" xmlns="http://www.w3.org/1999/xhtml">(We are just kidding, of course, but we will use this wine theme to give some flavor to our example!)</span></p>
<p><span class="koboSpan" id="kobo.857.1" xmlns="http://www.w3.org/1999/xhtml">We’ve already seen how the scikit-learn package offers lots of tools and resources for machine learning. </span><span class="koboSpan" id="kobo.857.2" xmlns="http://www.w3.org/1999/xhtml">It turns out that among them are a collection of pre-defined datasets on which to train ML models, and one of those datasets is a ”wine recognition dataset” </span><span class="cite"><span class="koboSpan" id="kobo.858.1" xmlns="http://www.w3.org/1999/xhtml">[</span><a href="ch030.xhtml#XDua:2019"><span class="koboSpan" id="kobo.859.1" xmlns="http://www.w3.org/1999/xhtml">32</span></a><span class="koboSpan" id="kobo.860.1" xmlns="http://www.w3.org/1999/xhtml">]</span></span><span class="koboSpan" id="kobo.861.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.861.2" xmlns="http://www.w3.org/1999/xhtml">This is a labeled dataset with information about wines. </span><span class="koboSpan" id="kobo.861.3" xmlns="http://www.w3.org/1999/xhtml">In total, it has </span><span class="koboSpan" id="kobo.862.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="13" class="math inline" src="../media/file1307.png" style="vertical-align:middle" title="13"/></span><span class="koboSpan" id="kobo.863.1" xmlns="http://www.w3.org/1999/xhtml"> numeric variables that describe the color intensity, alcohol concentration, and other fancy things whose meaning and significance we have no clue about. </span><span class="koboSpan" id="kobo.863.2" xmlns="http://www.w3.org/1999/xhtml">The labels correspond to the kind of wine. </span><span class="koboSpan" id="kobo.863.3" xmlns="http://www.w3.org/1999/xhtml">There are three possible labels, so, if we just ignore one, we are left with a beautiful dataset for a binary classification problem.</span></p>
<p><span class="koboSpan" id="kobo.864.1" xmlns="http://www.w3.org/1999/xhtml">We can load the set with the </span><code><span class="koboSpan" id="kobo.865.1" xmlns="http://www.w3.org/1999/xhtml">load_wine</span></code><span class="koboSpan" id="kobo.866.1" xmlns="http://www.w3.org/1999/xhtml"> function in </span><code><span class="koboSpan" id="kobo.867.1" xmlns="http://www.w3.org/1999/xhtml">sklearn</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.868.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.869.1" xmlns="http://www.w3.org/1999/xhtml">datasets</span></code><span class="koboSpan" id="kobo.870.1" xmlns="http://www.w3.org/1999/xhtml"> as follows:</span></p>
<pre class="lstlisting" id="listing-208"><span class="koboSpan" id="kobo.871.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.datasets import load_wine 
 
x,y = load_wine(return_X_y = True)
</span></pre>
<p><span class="koboSpan" id="kobo.872.1" xmlns="http://www.w3.org/1999/xhtml">We have set </span><code><span class="koboSpan" id="kobo.873.1" xmlns="http://www.w3.org/1999/xhtml">return_X_y</span></code><span class="koboSpan" id="kobo.874.1" xmlns="http://www.w3.org/1999/xhtml"> to true so that we also get the labels.</span></p>
<p><span class="koboSpan" id="kobo.875.1" xmlns="http://www.w3.org/1999/xhtml">You can find all the details about this dataset in its online documentation (</span><a class="url" href="https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset"><span class="koboSpan" id="kobo.876.1" xmlns="http://www.w3.org/1999/xhtml">https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset</span></a><span class="koboSpan" id="kobo.877.1" xmlns="http://www.w3.org/1999/xhtml"> or </span><a class="url" href="https://archive.ics.uci.edu/ml/datasets/Wine"><span class="koboSpan" id="kobo.878.1" xmlns="http://www.w3.org/1999/xhtml">https://archive.ics.uci.edu/ml/datasets/Wine</span></a><span class="koboSpan" id="kobo.879.1" xmlns="http://www.w3.org/1999/xhtml">, if you want to check the original source of the data). </span><span class="koboSpan" id="kobo.879.2" xmlns="http://www.w3.org/1999/xhtml">According to it, the </span><span class="koboSpan" id="kobo.880.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="59" class="math inline" src="../media/file1308.png" style="vertical-align:middle" title="59"/></span><span class="koboSpan" id="kobo.881.1" xmlns="http://www.w3.org/1999/xhtml"> first elements in the dataset must belong to the first category (label </span><span class="koboSpan" id="kobo.882.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.883.1" xmlns="http://www.w3.org/1999/xhtml">) while the </span><span class="koboSpan" id="kobo.884.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="71" class="math inline" src="../media/file1309.png" style="vertical-align:middle" title="71"/></span><span class="koboSpan" id="kobo.885.1" xmlns="http://www.w3.org/1999/xhtml"> subsequent ones have to belong to the second one (label </span><span class="koboSpan" id="kobo.886.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.887.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.887.2" xmlns="http://www.w3.org/1999/xhtml">Thus, if we want to ignore the third category, we can just run the following piece of code:</span></p>
<pre class="lstlisting" id="listing-209"><span class="koboSpan" id="kobo.888.1" xmlns="http://www.w3.org/1999/xhtml">

x = x[:59+71] 
 
y = y[:59+71]
</span></pre>
<p><span class="koboSpan" id="kobo.889.1" xmlns="http://www.w3.org/1999/xhtml">And thus we have a labeled dataset with two categories. </span><span class="koboSpan" id="kobo.889.2" xmlns="http://www.w3.org/1999/xhtml">A perfect binary classification problem.</span></p>
<p><span class="koboSpan" id="kobo.890.1" xmlns="http://www.w3.org/1999/xhtml">Before we proceed, however, a few disclaimers are in order. </span><span class="koboSpan" id="kobo.890.2" xmlns="http://www.w3.org/1999/xhtml">This wine recognition problem that we are </span><span id="dx1-173006"/><span class="koboSpan" id="kobo.891.1" xmlns="http://www.w3.org/1999/xhtml">going to work with is — from a machine learning point of view — very simple. </span><span class="koboSpan" id="kobo.891.2" xmlns="http://www.w3.org/1999/xhtml">You don’t need very sophisticated models or a lot of computing power to tackle it. </span><span class="koboSpan" id="kobo.891.3" xmlns="http://www.w3.org/1999/xhtml">Thus, using a QSVM for this problem is overkill. </span><span class="koboSpan" id="kobo.891.4" xmlns="http://www.w3.org/1999/xhtml">It will work, yes, but that doesn’t diminish the fact that we will be overdoing it. </span><span class="koboSpan" id="kobo.891.5" xmlns="http://www.w3.org/1999/xhtml">Quantum support vector machines can tackle complex problems, but we thought it would be better to keep things simple. </span><span class="koboSpan" id="kobo.891.6" xmlns="http://www.w3.org/1999/xhtml">You may call us overprotective, but we thought that using examples that could take two hours to run — or even two days! </span><span class="koboSpan" id="kobo.891.7" xmlns="http://www.w3.org/1999/xhtml">— might not be exactly ideal from a pedagogical perspective. </span><span class="koboSpan" id="kobo.891.8" xmlns="http://www.w3.org/1999/xhtml">We will also see how some examples yield better results than others. </span><span class="koboSpan" id="kobo.891.9" xmlns="http://www.w3.org/1999/xhtml">Unless we state otherwise, that won’t be indicative of any general pattern. </span><span class="koboSpan" id="kobo.891.10" xmlns="http://www.w3.org/1999/xhtml">It will just mean that it so happens, some things work better than others for this particular problem. </span><span class="koboSpan" id="kobo.891.11" xmlns="http://www.w3.org/1999/xhtml">After all, from the few experiments that we will run, it wouldn’t be sensible to draw hard conclusions!</span></p>
<p><span class="koboSpan" id="kobo.892.1" xmlns="http://www.w3.org/1999/xhtml">With those remarks out of the way, let’s attack our problem. </span><span class="koboSpan" id="kobo.892.2" xmlns="http://www.w3.org/1999/xhtml">We shall begin by splitting our dataset into a training dataset and a test dataset:</span></p>
<pre class="lstlisting" id="listing-210"><span class="koboSpan" id="kobo.893.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.model_selection import train_test_split 
 
x_tr, x_test, y_tr, y_test = train_test_split(x, y, train_size = 0.9)
</span></pre>
<p><span class="koboSpan" id="kobo.894.1" xmlns="http://www.w3.org/1999/xhtml">We won’t be making direct model comparisons, nor will we be using validation losses, so we will not use a validation dataset.</span></p>
<p><span class="koboSpan" id="kobo.895.1" xmlns="http://www.w3.org/1999/xhtml">As we discussed previously, most feature maps expect our data to be normalized, and, regardless of that, normalizing your data is in general a good practice in machine learning. </span><span class="koboSpan" id="kobo.895.2" xmlns="http://www.w3.org/1999/xhtml">So that’s what we shall do now! </span><span class="koboSpan" id="kobo.895.3" xmlns="http://www.w3.org/1999/xhtml">We will actually use the most simple of normalization techniques: scaling each of the variables linearly in such a way that the maximum absolute value taken by each variable be </span><span class="koboSpan" id="kobo.896.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.897.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.897.2" xmlns="http://www.w3.org/1999/xhtml">This can be achieved with a </span><code><span class="koboSpan" id="kobo.898.1" xmlns="http://www.w3.org/1999/xhtml">MaxAbsScaler</span></code><span class="koboSpan" id="kobo.899.1" xmlns="http://www.w3.org/1999/xhtml"> object from </span><code><span class="koboSpan" id="kobo.900.1" xmlns="http://www.w3.org/1999/xhtml">sklearn</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.901.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.902.1" xmlns="http://www.w3.org/1999/xhtml">preprocessing</span></code><span class="koboSpan" id="kobo.903.1" xmlns="http://www.w3.org/1999/xhtml"> as follows:</span></p>
<pre class="lstlisting" id="listing-211"><span class="koboSpan" id="kobo.904.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.preprocessing import MaxAbsScaler 
 
 
 
scaler = MaxAbsScaler() 
 
x_tr = scaler.fit_transform(x_tr)
</span></pre>
<p><span class="koboSpan" id="kobo.905.1" xmlns="http://www.w3.org/1999/xhtml">And, with that, we know that — since all our variables were positive — all the values in our training </span><span id="dx1-173013"/><span class="koboSpan" id="kobo.906.1" xmlns="http://www.w3.org/1999/xhtml">dataset will be between </span><span class="koboSpan" id="kobo.907.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.908.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.909.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.910.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.910.2" xmlns="http://www.w3.org/1999/xhtml">If there were negative values, our scaled variables would take values in </span><span class="koboSpan" id="kobo.911.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\lbrack - 1,1\rbrack" class="math inline" src="../media/file1310.png" style="vertical-align:middle" title="\lbrack - 1,1\rbrack"/></span><span class="koboSpan" id="kobo.912.1" xmlns="http://www.w3.org/1999/xhtml"> instead. </span><span class="koboSpan" id="kobo.912.2" xmlns="http://www.w3.org/1999/xhtml">Notice that we have only normalized our training dataset. </span><span class="koboSpan" id="kobo.912.3" xmlns="http://www.w3.org/1999/xhtml">Normalizing the whole dataset </span><em><span class="koboSpan" id="kobo.913.1" xmlns="http://www.w3.org/1999/xhtml">simultaneously</span></em><span class="koboSpan" id="kobo.914.1" xmlns="http://www.w3.org/1999/xhtml"> would be, in a way, cheating, because we could be polluting the training dataset with information from the test dataset. </span><span class="koboSpan" id="kobo.914.2" xmlns="http://www.w3.org/1999/xhtml">For instance, if we had an outlier in the test dataset with a very high value in some variable — a value never reached in the training dataset — this would be reflected in the normalization, and, thus, the independence of our test dataset could be compromised.</span></p>
<p><span class="koboSpan" id="kobo.915.1" xmlns="http://www.w3.org/1999/xhtml">Now that the training dataset is normalized, we need to normalize the test dataset using the same proportions as the training dataset. </span><span class="koboSpan" id="kobo.915.2" xmlns="http://www.w3.org/1999/xhtml">In this way, the training dataset receives no information about the test dataset. </span><span class="koboSpan" id="kobo.915.3" xmlns="http://www.w3.org/1999/xhtml">This can be achieved with the following piece of code:</span></p>
<pre class="lstlisting" id="listing-212"><span class="koboSpan" id="kobo.916.1" xmlns="http://www.w3.org/1999/xhtml">

x_test = scaler.transform(x_test) 
 
x_test = np.clip(x_test,0,1)
</span></pre>
<p><span class="koboSpan" id="kobo.917.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we have used the same </span><code><span class="koboSpan" id="kobo.918.1" xmlns="http://www.w3.org/1999/xhtml">scaler</span></code><span class="koboSpan" id="kobo.919.1" xmlns="http://www.w3.org/1999/xhtml"> object as before, but we have called the </span><code><span class="koboSpan" id="kobo.920.1" xmlns="http://www.w3.org/1999/xhtml">transform</span></code><span class="koboSpan" id="kobo.921.1" xmlns="http://www.w3.org/1999/xhtml"> method instead of </span><code><span class="koboSpan" id="kobo.922.1" xmlns="http://www.w3.org/1999/xhtml">fit_transform</span></code><span class="koboSpan" id="kobo.923.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.923.2" xmlns="http://www.w3.org/1999/xhtml">In that way, the scaler uses the proportions that it saved before. </span><span class="koboSpan" id="kobo.923.3" xmlns="http://www.w3.org/1999/xhtml">In addition, we’ve run an instruction to ”cut” the values in the test dataset at </span><span class="koboSpan" id="kobo.924.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0" class="math inline" src="../media/file12.png" style="vertical-align:middle" title="0"/></span><span class="koboSpan" id="kobo.925.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><span class="koboSpan" id="kobo.926.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.927.1" xmlns="http://www.w3.org/1999/xhtml"> — just in case there were some outliers and in order to comply with the normalization requirements of some of the feature maps that we will use.</span></p>
</section>
<section class="level3 subsectionHead" data-number="17.3.2" id="pennylane-and-scikit-learn-go-on-their-first-date">
<h2 class="subsectionHead" data-number="17.3.2"><span class="titlemark"><span class="koboSpan" id="kobo.928.1" xmlns="http://www.w3.org/1999/xhtml">9.3.2 </span></span> <span id="x1-1740009.3.2"><span class="koboSpan" id="kobo.929.1" xmlns="http://www.w3.org/1999/xhtml">PennyLane and scikit-learn go on their first date</span></span></h2>
<p><span class="koboSpan" id="kobo.930.1" xmlns="http://www.w3.org/1999/xhtml">We’ve said it </span><span id="dx1-174001"/><span class="koboSpan" id="kobo.931.1" xmlns="http://www.w3.org/1999/xhtml">countless times: QSVMs are like normal SVMs, but with a quantum kernel. </span><span class="koboSpan" id="kobo.931.2" xmlns="http://www.w3.org/1999/xhtml">So let’s implement that kernel with PennyLane.</span></p>
<p><span class="koboSpan" id="kobo.932.1" xmlns="http://www.w3.org/1999/xhtml">Our dataset has </span><span class="koboSpan" id="kobo.933.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="13" class="math inline" src="../media/file1307.png" style="vertical-align:middle" title="13"/></span><span class="koboSpan" id="kobo.934.1" xmlns="http://www.w3.org/1999/xhtml"> variables. </span><span class="koboSpan" id="kobo.934.2" xmlns="http://www.w3.org/1999/xhtml">Using angle encoding or the ZZ feature map on the </span><span class="koboSpan" id="kobo.935.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="13" class="math inline" src="../media/file1307.png" style="vertical-align:middle" title="13"/></span><span class="koboSpan" id="kobo.936.1" xmlns="http://www.w3.org/1999/xhtml"> variables would require us to use </span><span class="koboSpan" id="kobo.937.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="13" class="math inline" src="../media/file1307.png" style="vertical-align:middle" title="13"/></span><span class="koboSpan" id="kobo.938.1" xmlns="http://www.w3.org/1999/xhtml"> qubits, which might not be feasible if we want our kernel to be simulated on some not especially powerful computers. </span><span class="koboSpan" id="kobo.938.2" xmlns="http://www.w3.org/1999/xhtml">Thus, we can resort to amplitude encoding using </span><span class="koboSpan" id="kobo.939.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4" class="math inline" src="../media/file143.png" style="vertical-align:middle" title="4"/></span><span class="koboSpan" id="kobo.940.1" xmlns="http://www.w3.org/1999/xhtml"> qubits. </span><span class="koboSpan" id="kobo.940.2" xmlns="http://www.w3.org/1999/xhtml">As we mentioned before, this feature map can accept up to </span><span class="koboSpan" id="kobo.941.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.942.1" xmlns="http://www.w3.org/1999/xhtml"> inputs; we will fill the remaining ones with zeros — PennyLane will make that easy.</span></p>
<p><span class="koboSpan" id="kobo.943.1" xmlns="http://www.w3.org/1999/xhtml">This is how we can implement our quantum kernel:</span></p>
<pre class="lstlisting" id="listing-213"><span class="koboSpan" id="kobo.944.1" xmlns="http://www.w3.org/1999/xhtml">

import pennylane as qml 
 
 
 
nqubits = 4 
 
dev = qml.device("lightning.qubit", wires = nqubits) 
 
 
 
@qml.qnode(dev) 
 
def kernel_circ(a, b): 
 
    qml.AmplitudeEmbedding( 
 
        a, wires=range(nqubits), pad_with=0, normalize=True) 
 
    qml.adjoint(qml.AmplitudeEmbedding( 
 
        b, wires=range(nqubits), pad_with=0, normalize=True)) 
 
    return qml.probs(wires = range(nqubits))
</span></pre>
<p><span class="koboSpan" id="kobo.945.1" xmlns="http://www.w3.org/1999/xhtml">Now, there are a few things to digest here. </span><span class="koboSpan" id="kobo.945.2" xmlns="http://www.w3.org/1999/xhtml">We are first importing PennyLane, setting the number of qubits in a variable, and defining a device; nothing new there. </span><span class="koboSpan" id="kobo.945.3" xmlns="http://www.w3.org/1999/xhtml">And then comes the definition of the circuit of our kernel. </span><span class="koboSpan" id="kobo.945.4" xmlns="http://www.w3.org/1999/xhtml">In this definition, we are using </span><code><span class="koboSpan" id="kobo.946.1" xmlns="http://www.w3.org/1999/xhtml">AmplitudeEmbedding</span></code><span class="koboSpan" id="kobo.947.1" xmlns="http://www.w3.org/1999/xhtml">, which returns an operation equivalent to the amplitude encoding of its first argument. </span><span class="koboSpan" id="kobo.947.2" xmlns="http://www.w3.org/1999/xhtml">In our case, we use the arrays </span><code><span class="koboSpan" id="kobo.948.1" xmlns="http://www.w3.org/1999/xhtml">a</span></code><span class="koboSpan" id="kobo.949.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.950.1" xmlns="http://www.w3.org/1999/xhtml">b</span></code><span class="koboSpan" id="kobo.951.1" xmlns="http://www.w3.org/1999/xhtml"> for this first argument. </span><span class="koboSpan" id="kobo.951.2" xmlns="http://www.w3.org/1999/xhtml">They are the classical data that our kernel function takes as input. </span><span class="koboSpan" id="kobo.951.3" xmlns="http://www.w3.org/1999/xhtml">In addition to this, we also ask </span><code><span class="koboSpan" id="kobo.952.1" xmlns="http://www.w3.org/1999/xhtml">AmplitudeEmbedding</span></code><span class="koboSpan" id="kobo.953.1" xmlns="http://www.w3.org/1999/xhtml"> to normalize each input vector for us, just as amplitude encoding needs us to do, and, since our arrays have </span><span class="koboSpan" id="kobo.954.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="13" class="math inline" src="../media/file1307.png" style="vertical-align:middle" title="13"/></span><span class="koboSpan" id="kobo.955.1" xmlns="http://www.w3.org/1999/xhtml"> elements instead of the required </span><span class="koboSpan" id="kobo.956.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="16" class="math inline" src="../media/file619.png" style="vertical-align:middle" title="16"/></span><span class="koboSpan" id="kobo.957.1" xmlns="http://www.w3.org/1999/xhtml">, we set </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.958.1" xmlns="http://www.w3.org/1999/xhtml">pad_with</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.959.1" xmlns="http://www.w3.org/1999/xhtml">=</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.960.1" xmlns="http://www.w3.org/1999/xhtml">0</span></code></span></span><span class="koboSpan" id="kobo.961.1" xmlns="http://www.w3.org/1999/xhtml"> to fill the remaining values with zeros. </span><span class="koboSpan" id="kobo.961.2" xmlns="http://www.w3.org/1999/xhtml">Also notice that we are using </span><code><span class="koboSpan" id="kobo.962.1" xmlns="http://www.w3.org/1999/xhtml">qml</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.963.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.964.1" xmlns="http://www.w3.org/1999/xhtml">adjoint</span></code><span class="koboSpan" id="kobo.965.1" xmlns="http://www.w3.org/1999/xhtml"> to compute the adjoint (or inverse) of the amplitude encoding of </span><code><span class="koboSpan" id="kobo.966.1" xmlns="http://www.w3.org/1999/xhtml">b</span></code><span class="koboSpan" id="kobo.967.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.968.1" xmlns="http://www.w3.org/1999/xhtml">Lastly, we retrieve an array with the </span><span id="dx1-174014"/><span class="koboSpan" id="kobo.969.1" xmlns="http://www.w3.org/1999/xhtml">probabilities of measuring each possible state in the computational basis. </span><span class="koboSpan" id="kobo.969.2" xmlns="http://www.w3.org/1999/xhtml">The first element of this array (that is, the probability of getting a zero value in all the qubits) will be the output of our kernel.</span></p>
<p><span class="koboSpan" id="kobo.970.1" xmlns="http://www.w3.org/1999/xhtml">Now we have our quantum kernel almost ready. </span><span class="koboSpan" id="kobo.970.2" xmlns="http://www.w3.org/1999/xhtml">If you’d like to check that the circuit works as expected, you can try it out on some elements from the training dataset. </span><span class="koboSpan" id="kobo.970.3" xmlns="http://www.w3.org/1999/xhtml">For instance, you could run </span><span class="lstinline"><span style="color:#000000"><code><span class="koboSpan" id="kobo.971.1" xmlns="http://www.w3.org/1999/xhtml">kernel_circ</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.972.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.973.1" xmlns="http://www.w3.org/1999/xhtml">x_tr</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.974.1" xmlns="http://www.w3.org/1999/xhtml">[0],</span></code></span><span style="color:#000000"> </span><span style="color:#000000"><code><span class="koboSpan" id="kobo.975.1" xmlns="http://www.w3.org/1999/xhtml">x_tr</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.976.1" xmlns="http://www.w3.org/1999/xhtml">[1])</span></code></span></span><span class="koboSpan" id="kobo.977.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.977.2" xmlns="http://www.w3.org/1999/xhtml">If the two arguments are the same, keep in mind that you should always get </span><span class="koboSpan" id="kobo.978.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.979.1" xmlns="http://www.w3.org/1999/xhtml"> in the first entry of the returned array (which corresponds, as we have mentioned, to the output of the kernel).</span></p>
<div class="tcolorbox questionx" id="tcolobox-175">
<span id="x1-174016x9.3.2"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.980.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 9.3</span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.981.1" xmlns="http://www.w3.org/1999/xhtml">Prove that, indeed, any quantum kernel evaluated on two identical entries always needs to return the output </span><span class="koboSpan" id="kobo.982.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.983.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.984.1" xmlns="http://www.w3.org/1999/xhtml">Our next step will be using this quantum kernel in an SVM. </span><span class="koboSpan" id="kobo.984.2" xmlns="http://www.w3.org/1999/xhtml">Our good old scikit-learn has its own implementation, </span><code><span class="koboSpan" id="kobo.985.1" xmlns="http://www.w3.org/1999/xhtml">SVC</span></code><span class="koboSpan" id="kobo.986.1" xmlns="http://www.w3.org/1999/xhtml">, of support vector machines, and it works with custom kernels, so there we have it! </span><span class="koboSpan" id="kobo.986.2" xmlns="http://www.w3.org/1999/xhtml">In order to use a custom kernel, you are required to provide a </span><code><span class="koboSpan" id="kobo.987.1" xmlns="http://www.w3.org/1999/xhtml">kernel</span></code><span class="koboSpan" id="kobo.988.1" xmlns="http://www.w3.org/1999/xhtml"> function accepting two arrays, </span><code><span class="koboSpan" id="kobo.989.1" xmlns="http://www.w3.org/1999/xhtml">A</span></code><span class="koboSpan" id="kobo.990.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.991.1" xmlns="http://www.w3.org/1999/xhtml">B</span></code><span class="koboSpan" id="kobo.992.1" xmlns="http://www.w3.org/1999/xhtml">, and returning a matrix with entries </span><span class="koboSpan" id="kobo.993.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="(j,k)" class="math inline" src="../media/file356.png" style="vertical-align:middle" title="(j,k)"/></span><span class="koboSpan" id="kobo.994.1" xmlns="http://www.w3.org/1999/xhtml"> containing the kernel applied to </span><code><span class="koboSpan" id="kobo.995.1" xmlns="http://www.w3.org/1999/xhtml">A</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.996.1" xmlns="http://www.w3.org/1999/xhtml">[</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.997.1" xmlns="http://www.w3.org/1999/xhtml">j</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.998.1" xmlns="http://www.w3.org/1999/xhtml">]</span></code><span class="koboSpan" id="kobo.999.1" xmlns="http://www.w3.org/1999/xhtml"> and </span><code><span class="koboSpan" id="kobo.1000.1" xmlns="http://www.w3.org/1999/xhtml">B</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1001.1" xmlns="http://www.w3.org/1999/xhtml">[</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1002.1" xmlns="http://www.w3.org/1999/xhtml">k</span></code></span><code><span class="koboSpan" id="kobo.1003.1" xmlns="http://www.w3.org/1999/xhtml">]</span></code><span class="koboSpan" id="kobo.1004.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1004.2" xmlns="http://www.w3.org/1999/xhtml">Once the kernel is prepared, the SVM can be trained with the </span><code><span class="koboSpan" id="kobo.1005.1" xmlns="http://www.w3.org/1999/xhtml">fit</span></code><span class="koboSpan" id="kobo.1006.1" xmlns="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.1006.2" xmlns="http://www.w3.org/1999/xhtml">All of this is done in the following piece of code:</span></p>
<pre class="lstlisting" id="listing-214"><span class="koboSpan" id="kobo.1007.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.svm import SVC 
 
def qkernel(A, B): 
 
    return np.array([[kernel_circ(a, b)[0] for b in B] for a in A]) 
 
 
 
svm = SVC(kernel = qkernel).fit(x_tr, y_tr)
</span></pre>
<p><span class="koboSpan" id="kobo.1008.1" xmlns="http://www.w3.org/1999/xhtml">The training can take up to a few minutes depending on the performance of your computer. </span><span class="koboSpan" id="kobo.1008.2" xmlns="http://www.w3.org/1999/xhtml">Once it is over, you can check the accuracy of your trained model with the following instructions:</span></p>
<pre class="lstlisting" id="listing-215"><span class="koboSpan" id="kobo.1009.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.metrics import accuracy_score 
 
 
 
print(accuracy_score(svm.predict(x_test), y_test))
</span></pre>
<p><span class="koboSpan" id="kobo.1010.1" xmlns="http://www.w3.org/1999/xhtml">In our case, this gives an accuracy of </span><span class="koboSpan" id="kobo.1011.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.92" class="math inline" src="../media/file1311.png" style="vertical-align:middle" title="0.92"/></span><span class="koboSpan" id="kobo.1012.1" xmlns="http://www.w3.org/1999/xhtml">, meaning that the SVM is capable of classifying most of the elements in the test dataset correctly.</span></p>
<p><span class="koboSpan" id="kobo.1013.1" xmlns="http://www.w3.org/1999/xhtml">This shows us how to train and run a quantum support vector in a fairly simple manner. </span><span class="koboSpan" id="kobo.1013.2" xmlns="http://www.w3.org/1999/xhtml">But we can consider more sophisticated scenarios. </span><span class="koboSpan" id="kobo.1013.3" xmlns="http://www.w3.org/1999/xhtml">Are you ready for that?</span></p>
</section>
<section class="level3 subsectionHead" data-number="17.3.3" id="reducing-the-dimensionality-of-a-dataset">
<h2 class="subsectionHead" data-number="17.3.3"><span class="titlemark"><span class="koboSpan" id="kobo.1014.1" xmlns="http://www.w3.org/1999/xhtml">9.3.3 </span></span> <span id="x1-1750009.3.3"><span class="koboSpan" id="kobo.1015.1" xmlns="http://www.w3.org/1999/xhtml">Reducing the dimensionality of a dataset</span></span></h2>
<p><span class="koboSpan" id="kobo.1016.1" xmlns="http://www.w3.org/1999/xhtml">We have just seen how to use </span><span id="dx1-175001"/><span class="koboSpan" id="kobo.1017.1" xmlns="http://www.w3.org/1999/xhtml">amplitude encoding to take full advantage of the </span><span class="koboSpan" id="kobo.1018.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="13" class="math inline" src="../media/file1307.png" style="vertical-align:middle" title="13"/></span><span class="koboSpan" id="kobo.1019.1" xmlns="http://www.w3.org/1999/xhtml"> variables of our dataset while only using </span><span class="koboSpan" id="kobo.1020.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="4" class="math inline" src="../media/file143.png" style="vertical-align:middle" title="4"/></span><span class="koboSpan" id="kobo.1021.1" xmlns="http://www.w3.org/1999/xhtml"> qubits. </span><span class="koboSpan" id="kobo.1021.2" xmlns="http://www.w3.org/1999/xhtml">In most cases, that is a good approach. </span><span class="koboSpan" id="kobo.1021.3" xmlns="http://www.w3.org/1999/xhtml">But there are also some problems in which it may prove better to reduce the number of variables in the dataset — while trying to minimize the loss of information, of course — and thus be able to use other feature maps that could perhaps yield better results.</span></p>
<p><span class="koboSpan" id="kobo.1022.1" xmlns="http://www.w3.org/1999/xhtml">In this subsection, we are going to illustrate this approach. </span><span class="koboSpan" id="kobo.1022.2" xmlns="http://www.w3.org/1999/xhtml">We shall try to reduce the number of variables in our dataset to </span><span class="koboSpan" id="kobo.1023.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.1024.1" xmlns="http://www.w3.org/1999/xhtml"> and, then, we will train a QSVM on the new, reduced variables using angle encoding.</span></p>
<p><span class="koboSpan" id="kobo.1025.1" xmlns="http://www.w3.org/1999/xhtml">If you want to reduce the dimensionality of a dataset while minimizing information loss, as we aim to do now, there are many options at your disposal. </span><span class="koboSpan" id="kobo.1025.2" xmlns="http://www.w3.org/1999/xhtml">You may want to have a look at autoencoders, for instance. </span><span class="koboSpan" id="kobo.1025.3" xmlns="http://www.w3.org/1999/xhtml">In any case, for the purposes of this section, we will consider a </span><span id="dx1-175002"/><span class="koboSpan" id="kobo.1026.1" xmlns="http://www.w3.org/1999/xhtml">technique known as </span><strong><span class="koboSpan" id="kobo.1027.1" xmlns="http://www.w3.org/1999/xhtml">principal</span></strong> <strong><span class="koboSpan" id="kobo.1028.1" xmlns="http://www.w3.org/1999/xhtml">component analysis</span></strong><span class="koboSpan" id="kobo.1029.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<div class="tcolorbox learnmore" id="tcolobox-176">
<div class="tcolorbox-title">
<p><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.1030.1" xmlns="http://www.w3.org/1999/xhtml">To learn more</span></span><span class="cmss-10x-x-109"><span class="koboSpan" id="kobo.1031.1" xmlns="http://www.w3.org/1999/xhtml">…</span></span></p>
</div>
<div class="tcolorbox-content">
<p><span class="koboSpan" id="kobo.1032.1" xmlns="http://www.w3.org/1999/xhtml">Before actually using principal component analysis, you may reasonably be curious about how this fancy-sounding technique works.</span></p>
<p><span class="koboSpan" id="kobo.1033.1" xmlns="http://www.w3.org/1999/xhtml">When you have a dataset with </span><span class="koboSpan" id="kobo.1034.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="n" class="math inline" src="../media/file244.png" style="vertical-align:middle" title="n"/></span><span class="koboSpan" id="kobo.1035.1" xmlns="http://www.w3.org/1999/xhtml"> variables, you essentially have a set of points in </span><span class="koboSpan" id="kobo.1036.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{n}" class="math inline" src="../media/file1212.png" style="vertical-align:middle" title="R^{n}"/></span><span class="koboSpan" id="kobo.1037.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1037.2" xmlns="http://www.w3.org/1999/xhtml">With this set, you may consider what are </span><span id="dx1-175003"/><span class="koboSpan" id="kobo.1038.1" xmlns="http://www.w3.org/1999/xhtml">known as the </span><strong><span class="koboSpan" id="kobo.1039.1" xmlns="http://www.w3.org/1999/xhtml">principal</span></strong> <strong><span class="koboSpan" id="kobo.1040.1" xmlns="http://www.w3.org/1999/xhtml">directions</span></strong><span class="koboSpan" id="kobo.1041.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1041.2" xmlns="http://www.w3.org/1999/xhtml">The first principal direction is the direction of the line that best fits the data as measured by the mean squared error. </span><span class="koboSpan" id="kobo.1041.3" xmlns="http://www.w3.org/1999/xhtml">The second principal direction is the direction of the line that best fits the data while being orthogonal to the first principal direction. </span><span class="koboSpan" id="kobo.1041.4" xmlns="http://www.w3.org/1999/xhtml">This goes on in such a way that the </span><span class="koboSpan" id="kobo.1042.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k" class="math inline" src="../media/file317.png" style="vertical-align:middle" title="k"/></span><span class="koboSpan" id="kobo.1043.1" xmlns="http://www.w3.org/1999/xhtml">-th principal direction is that of the line that best fits the data while being orthogonal to the first, second, and all the way up to the (</span><span class="koboSpan" id="kobo.1044.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="k - 1" class="math inline" src="../media/file1312.png" style="vertical-align:middle" title="k - 1"/></span><span class="koboSpan" id="kobo.1045.1" xmlns="http://www.w3.org/1999/xhtml">)-th principal direction.</span></p>
<p><span class="koboSpan" id="kobo.1046.1" xmlns="http://www.w3.org/1999/xhtml">We thus may consider an orthonormal basis </span><span class="koboSpan" id="kobo.1047.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="\{ v_{1},\ldots,v_{n}\}" class="math inline" src="../media/file1313.png" style="vertical-align:middle" title="\{ v_{1},\ldots,v_{n}\}"/></span><span class="koboSpan" id="kobo.1048.1" xmlns="http://www.w3.org/1999/xhtml"> of </span><span class="koboSpan" id="kobo.1049.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R^{n}" class="math inline" src="../media/file1212.png" style="vertical-align:middle" title="R^{n}"/></span><span class="koboSpan" id="kobo.1050.1" xmlns="http://www.w3.org/1999/xhtml"> in which </span><span class="koboSpan" id="kobo.1051.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="v_{j}" class="math inline" src="../media/file1314.png" style="vertical-align:middle" title="v_{j}"/></span><span class="koboSpan" id="kobo.1052.1" xmlns="http://www.w3.org/1999/xhtml"> points in the direction of the </span><span class="koboSpan" id="kobo.1053.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="j" class="math inline" src="../media/file258.png" style="vertical-align:middle" title="j"/></span><span class="koboSpan" id="kobo.1054.1" xmlns="http://www.w3.org/1999/xhtml">-th principal component. </span><span class="koboSpan" id="kobo.1054.2" xmlns="http://www.w3.org/1999/xhtml">The vectors in this orthonormal basis will be of the form </span><span class="koboSpan" id="kobo.1055.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="v_{j} = (v_{j}^{1},\ldots,v_{j}^{n}) \in R^{n}" class="math inline" src="../media/file1315.png" style="vertical-align:middle" title="v_{j} = (v_{j}^{1},\ldots,v_{j}^{n}) \in R^{n}"/></span><span class="koboSpan" id="kobo.1056.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1056.2" xmlns="http://www.w3.org/1999/xhtml">Of course, the superscripts are not exponents! </span><span class="koboSpan" id="kobo.1056.3" xmlns="http://www.w3.org/1999/xhtml">They are just superscripts.</span></p>
<p><span class="koboSpan" id="kobo.1057.1" xmlns="http://www.w3.org/1999/xhtml">When using principal component analysis, we simply compute the vectors of the aforementioned basis. </span><span class="koboSpan" id="kobo.1057.2" xmlns="http://www.w3.org/1999/xhtml">And, then, we define the variables</span></p>
<table class="equation-star">
<tbody>
<tr class="odd odd">
<td><span class="koboSpan" id="kobo.1058.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\sim}{x}}_{j} = v_{j}^{1}x_{1} + \cdots + v_{j}^{n}x_{n}." class="math display" src="../media/file1316.png" style="vertical-align:middle" title="{\overset{\sim}{x}}_{j} = v_{j}^{1}x_{1} + \cdots + v_{j}^{n}x_{n}."/></span></td>
</tr>
</tbody>
</table>
<p><span class="koboSpan" id="kobo.1059.1" xmlns="http://www.w3.org/1999/xhtml">And, lastly, in order to reduce the dimensionality of our dataset to </span><span class="koboSpan" id="kobo.1060.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="m" class="math inline" src="../media/file259.png" style="vertical-align:middle" title="m"/></span><span class="koboSpan" id="kobo.1061.1" xmlns="http://www.w3.org/1999/xhtml"> variables, we just keep the variables </span><span class="koboSpan" id="kobo.1062.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\sim}{x}}_{1},\ldots,{\overset{\sim}{x}}_{m}" class="math inline" src="../media/file1317.png" style="vertical-align:middle" title="{\overset{\sim}{x}}_{1},\ldots,{\overset{\sim}{x}}_{m}"/></span><span class="koboSpan" id="kobo.1063.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1063.2" xmlns="http://www.w3.org/1999/xhtml">This is all done under the assumption that the variables </span><span class="koboSpan" id="kobo.1064.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="{\overset{\sim}{x}}_{j}" class="math inline" src="../media/file1318.png" style="vertical-align:middle" title="{\overset{\sim}{x}}_{j}"/></span><span class="koboSpan" id="kobo.1065.1" xmlns="http://www.w3.org/1999/xhtml"> are, as we have defined them, sorted in decreasing order of relevance towards our problem.</span></p>
</div>
</div>
<p><span class="koboSpan" id="kobo.1066.1" xmlns="http://www.w3.org/1999/xhtml">So how do we use principal </span><span id="dx1-175004"/><span class="koboSpan" id="kobo.1067.1" xmlns="http://www.w3.org/1999/xhtml">component analysis to reduce the number of variables in our dataset? </span><span class="koboSpan" id="kobo.1067.2" xmlns="http://www.w3.org/1999/xhtml">Well, scikit-learn is here to save the day. </span><span class="koboSpan" id="kobo.1067.3" xmlns="http://www.w3.org/1999/xhtml">It implements a </span><code><span class="koboSpan" id="kobo.1068.1" xmlns="http://www.w3.org/1999/xhtml">PCA</span></code><span class="koboSpan" id="kobo.1069.1" xmlns="http://www.w3.org/1999/xhtml"> class that works in an analogous way to that of the </span><code><span class="koboSpan" id="kobo.1070.1" xmlns="http://www.w3.org/1999/xhtml">MaxAbsScaler</span></code><span class="koboSpan" id="kobo.1071.1" xmlns="http://www.w3.org/1999/xhtml"> class that we used before.</span></p>
<p><span class="koboSpan" id="kobo.1072.1" xmlns="http://www.w3.org/1999/xhtml">This </span><code><span class="koboSpan" id="kobo.1073.1" xmlns="http://www.w3.org/1999/xhtml">PCA</span></code><span class="koboSpan" id="kobo.1074.1" xmlns="http://www.w3.org/1999/xhtml"> class comes with a </span><code><span class="koboSpan" id="kobo.1075.1" xmlns="http://www.w3.org/1999/xhtml">fit</span></code><span class="koboSpan" id="kobo.1076.1" xmlns="http://www.w3.org/1999/xhtml"> method that analyzes the data and figures out the best way to reduce its dimensionality using principal component analysis. </span><span class="koboSpan" id="kobo.1076.2" xmlns="http://www.w3.org/1999/xhtml">Then, in addition, it comes with a </span><code><span class="koboSpan" id="kobo.1077.1" xmlns="http://www.w3.org/1999/xhtml">transform</span></code><span class="koboSpan" id="kobo.1078.1" xmlns="http://www.w3.org/1999/xhtml"> method that can then transform any data in the way it learned to do when </span><code><span class="koboSpan" id="kobo.1079.1" xmlns="http://www.w3.org/1999/xhtml">fit</span></code><span class="koboSpan" id="kobo.1080.1" xmlns="http://www.w3.org/1999/xhtml"> was invoked. </span><span class="koboSpan" id="kobo.1080.2" xmlns="http://www.w3.org/1999/xhtml">Also, just like </span><code><span class="koboSpan" id="kobo.1081.1" xmlns="http://www.w3.org/1999/xhtml">MaxAbsScaler</span></code><span class="koboSpan" id="kobo.1082.1" xmlns="http://www.w3.org/1999/xhtml">, the </span><code><span class="koboSpan" id="kobo.1083.1" xmlns="http://www.w3.org/1999/xhtml">PCA</span></code><span class="koboSpan" id="kobo.1084.1" xmlns="http://www.w3.org/1999/xhtml"> class has a </span><code><span class="koboSpan" id="kobo.1085.1" xmlns="http://www.w3.org/1999/xhtml">fit_transform</span></code><span class="koboSpan" id="kobo.1086.1" xmlns="http://www.w3.org/1999/xhtml"> method that fits the data and transforms it simultaneously:</span></p>
<pre class="lstlisting" id="listing-216"><span class="koboSpan" id="kobo.1087.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.decomposition import PCA 
 
 
 
pca = PCA(n_components = 8) 
 
 
 
xs_tr = pca.fit_transform(x_tr) 
 
xs_test = pca.transform(x_test)
</span></pre>
<p><span class="koboSpan" id="kobo.1088.1" xmlns="http://www.w3.org/1999/xhtml">And, with this, we have </span><span id="dx1-175011"/><span class="koboSpan" id="kobo.1089.1" xmlns="http://www.w3.org/1999/xhtml">effectively reduced the number of variables in our dataset to </span><span class="koboSpan" id="kobo.1090.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="8" class="math inline" src="../media/file506.png" style="vertical-align:middle" title="8"/></span><span class="koboSpan" id="kobo.1091.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1091.2" xmlns="http://www.w3.org/1999/xhtml">Notice, by the way, how we have used the </span><code><span class="koboSpan" id="kobo.1092.1" xmlns="http://www.w3.org/1999/xhtml">fit_transform</span></code><span class="koboSpan" id="kobo.1093.1" xmlns="http://www.w3.org/1999/xhtml"> method on the training data and the </span><code><span class="koboSpan" id="kobo.1094.1" xmlns="http://www.w3.org/1999/xhtml">transform</span></code><span class="koboSpan" id="kobo.1095.1" xmlns="http://www.w3.org/1999/xhtml"> method on the test data, all in order to preserve the independence of the test dataset.</span></p>
<p><span class="koboSpan" id="kobo.1096.1" xmlns="http://www.w3.org/1999/xhtml">We are now ready to implement and train a QSVM using angle encoding. </span><span class="koboSpan" id="kobo.1096.2" xmlns="http://www.w3.org/1999/xhtml">For this, we may use the </span><code><span class="koboSpan" id="kobo.1097.1" xmlns="http://www.w3.org/1999/xhtml">AngleEmbedding</span></code><span class="koboSpan" id="kobo.1098.1" xmlns="http://www.w3.org/1999/xhtml"> operator provided by PennyLane. </span><span class="koboSpan" id="kobo.1098.2" xmlns="http://www.w3.org/1999/xhtml">The following piece of code defines the training; it is very similar to our previous kernel definition and, thus, pretty self-explanatory:</span></p>
<pre class="lstlisting" id="listing-217"><span class="koboSpan" id="kobo.1099.1" xmlns="http://www.w3.org/1999/xhtml">

nqubits = 8 
 
dev = qml.device("lightning.qubit", wires=nqubits) 
 
 
 
@qml.qnode(dev) 
 
def kernel_circ(a, b): 
 
    qml.AngleEmbedding(a, wires=range(nqubits)) 
 
    qml.adjoint(qml.AngleEmbedding(b, wires=range(nqubits))) 
 
    return qml.probs(wires = range(nqubits))
</span></pre>
<p><span class="koboSpan" id="kobo.1100.1" xmlns="http://www.w3.org/1999/xhtml">Once we have a kernel, we can train a QSVM as we did before, this time reusing the </span><code><span class="koboSpan" id="kobo.1101.1" xmlns="http://www.w3.org/1999/xhtml">qkernel</span></code><span class="koboSpan" id="kobo.1102.1" xmlns="http://www.w3.org/1999/xhtml"> function, which will be using the new </span><code><span class="koboSpan" id="kobo.1103.1" xmlns="http://www.w3.org/1999/xhtml">kernel_circ</span></code><span class="koboSpan" id="kobo.1104.1" xmlns="http://www.w3.org/1999/xhtml"> definition:</span></p>
<pre class="lstlisting" id="listing-218"><span class="koboSpan" id="kobo.1105.1" xmlns="http://www.w3.org/1999/xhtml">

svm = SVC(kernel = qkernel).fit(xs_tr, y_tr) 
 
 
 
print(accuracy_score(svm.predict(xs_test), y_test))
</span></pre>
<p><span class="koboSpan" id="kobo.1106.1" xmlns="http://www.w3.org/1999/xhtml">The returned accuracy on the test dataset is </span><span class="koboSpan" id="kobo.1107.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1108.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1108.2" xmlns="http://www.w3.org/1999/xhtml">Just a perfect classification in this case.</span></p>
</section>
<section class="level3 subsectionHead" data-number="17.3.4" id="implementing-and-using-custom-feature-maps">
<h2 class="subsectionHead" data-number="17.3.4"><span class="titlemark"><span class="koboSpan" id="kobo.1109.1" xmlns="http://www.w3.org/1999/xhtml">9.3.4 </span></span> <span id="x1-1760009.3.4"><span class="koboSpan" id="kobo.1110.1" xmlns="http://www.w3.org/1999/xhtml">Implementing and using custom feature maps</span></span></h2>
<p><span class="koboSpan" id="kobo.1111.1" xmlns="http://www.w3.org/1999/xhtml">PennyLane comes with a wide </span><span id="dx1-176001"/><span class="koboSpan" id="kobo.1112.1" xmlns="http://www.w3.org/1999/xhtml">selection of built-in feature maps; you can find them all in the online documentation (</span><a class="url" href="https://pennylane.readthedocs.io/en/stable/introduction/templates.html"><span class="koboSpan" id="kobo.1113.1" xmlns="http://www.w3.org/1999/xhtml">https://pennylane.readthedocs.io/en/stable/introduction/templates.html</span></a><span class="koboSpan" id="kobo.1114.1" xmlns="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.1114.2" xmlns="http://www.w3.org/1999/xhtml">Nevertheless, you may want to define your own. </span><span class="koboSpan" id="kobo.1114.3" xmlns="http://www.w3.org/1999/xhtml">In this subsection, we will train a QSVM on the reduced dataset using our own implementation of the ZZ feature map. </span><span class="koboSpan" id="kobo.1114.4" xmlns="http://www.w3.org/1999/xhtml">Let’s take feature maps into our own hands!</span></p>
<p><span class="koboSpan" id="kobo.1115.1" xmlns="http://www.w3.org/1999/xhtml">We can begin by implementing the feature map as a function with the following piece of code:</span></p>
<pre class="lstlisting" id="listing-219"><span class="koboSpan" id="kobo.1116.1" xmlns="http://www.w3.org/1999/xhtml">

from itertools import combinations 
 
 
 
def ZZFeatureMap(nqubits, data): 
 
 
 
    # Number of variables that we will load: 
 
    # could be smaller than the number of qubits. 
 
    </span><span class="koboSpan" id="kobo.1116.2" xmlns="http://www.w3.org/1999/xhtml">nload = min(len(data), nqubits) 
 
 
 
    for i in range(nload): 
 
        qml.Hadamard(i) 
 
        qml.RZ(2.0 * data[i], wires = i) 
 
 
 
    for pair in list(combinations(range(nload), 2)): 
 
        q0 = pair[0] 
 
        q1 = pair[1] 
 
 
 
        qml.CZ(wires = [q0, q1]) 
 
        qml.RZ(2.0 * (np.pi - data[q0]) * 
 
            (np.pi - data[q1]), wires = q1) 
 
        qml.CZ(wires = [q0, q1])
</span></pre>
<p><span class="koboSpan" id="kobo.1117.1" xmlns="http://www.w3.org/1999/xhtml">In this implementation, we have used the </span><code><span class="koboSpan" id="kobo.1118.1" xmlns="http://www.w3.org/1999/xhtml">combinations</span></code><span class="koboSpan" id="kobo.1119.1" xmlns="http://www.w3.org/1999/xhtml"> function from the </span><code><span class="koboSpan" id="kobo.1120.1" xmlns="http://www.w3.org/1999/xhtml">itertools</span></code><span class="koboSpan" id="kobo.1121.1" xmlns="http://www.w3.org/1999/xhtml"> module. </span><span class="koboSpan" id="kobo.1121.2" xmlns="http://www.w3.org/1999/xhtml">It takes two arguments: an array </span><code><span class="koboSpan" id="kobo.1122.1" xmlns="http://www.w3.org/1999/xhtml">arr</span></code><span class="koboSpan" id="kobo.1123.1" xmlns="http://www.w3.org/1999/xhtml"> and an integer </span><code><span class="koboSpan" id="kobo.1124.1" xmlns="http://www.w3.org/1999/xhtml">l</span></code><span class="koboSpan" id="kobo.1125.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1125.2" xmlns="http://www.w3.org/1999/xhtml">And it returns an array with all the sorted tuples of length </span><code><span class="koboSpan" id="kobo.1126.1" xmlns="http://www.w3.org/1999/xhtml">l</span></code><span class="koboSpan" id="kobo.1127.1" xmlns="http://www.w3.org/1999/xhtml"> with </span><span id="dx1-176022"/><span class="koboSpan" id="kobo.1128.1" xmlns="http://www.w3.org/1999/xhtml">elements from the array </span><code><span class="koboSpan" id="kobo.1129.1" xmlns="http://www.w3.org/1999/xhtml">arr</span></code><span class="koboSpan" id="kobo.1130.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.1131.1" xmlns="http://www.w3.org/1999/xhtml">Notice how we have written the </span><code><span class="koboSpan" id="kobo.1132.1" xmlns="http://www.w3.org/1999/xhtml">ZZFeatureMap</span></code><span class="koboSpan" id="kobo.1133.1" xmlns="http://www.w3.org/1999/xhtml"> function as we would write any circuit, taking advantage of all the flexibility that PennyLane gives us. </span><span class="koboSpan" id="kobo.1133.2" xmlns="http://www.w3.org/1999/xhtml">Having defined this function for the ZZ feature map, we may use it on a kernel function and then train a QSVM just as we have done before:</span></p>
<pre class="lstlisting" id="listing-220"><span class="koboSpan" id="kobo.1134.1" xmlns="http://www.w3.org/1999/xhtml">

nqubits = 4 
 
dev = qml.device("lightning.qubit", wires = nqubits) 
 
 
 
@qml.qnode(dev) 
 
def kernel_circ(a, b): 
 
    ZZFeatureMap(nqubits, a) 
 
    qml.adjoint(ZZFeatureMap)(nqubits, b) 
 
    return qml.probs(wires = range(nqubits)) 
 
 
 
svm = SVC(kernel=qkernel).fit(xs_tr, y_tr) 
 
print(accuracy_score(svm.predict(xs_test), y_test))
</span></pre>
<p><span class="koboSpan" id="kobo.1135.1" xmlns="http://www.w3.org/1999/xhtml">In this case, the test accuracy is </span><span class="koboSpan" id="kobo.1136.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="0.77" class="math inline" src="../media/file1319.png" style="vertical-align:middle" title="0.77"/></span><span class="koboSpan" id="kobo.1137.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.1138.1" xmlns="http://www.w3.org/1999/xhtml">There’s one detail to which you should pay attention here, and it is the fact that </span><code><span class="koboSpan" id="kobo.1139.1" xmlns="http://www.w3.org/1999/xhtml">qml</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1140.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.1141.1" xmlns="http://www.w3.org/1999/xhtml">adjoint</span></code><span class="koboSpan" id="kobo.1142.1" xmlns="http://www.w3.org/1999/xhtml"> is acting on the </span><code><span class="koboSpan" id="kobo.1143.1" xmlns="http://www.w3.org/1999/xhtml">ZZFeatureMap</span></code><span class="koboSpan" id="kobo.1144.1" xmlns="http://www.w3.org/1999/xhtml"> function itself, not on its output! </span><span class="koboSpan" id="kobo.1144.2" xmlns="http://www.w3.org/1999/xhtml">Remember that taking the adjoint of a circuit is the same as considering the inverse of that circuit.</span></p>
<p><span class="koboSpan" id="kobo.1145.1" xmlns="http://www.w3.org/1999/xhtml">That’s all we had in store about QSVMs on PennyLane. </span><span class="koboSpan" id="kobo.1145.2" xmlns="http://www.w3.org/1999/xhtml">Now it’s time for us to see how things are done in Qiskit Land.</span></p>
</section>
</section>
<section class="level2 sectionHead" data-number="17.4" id="quantum-support-vector-machines-in-qiskit">
<h1 class="sectionHead" data-number="17.4"><span class="titlemark"><span class="koboSpan" id="kobo.1146.1" xmlns="http://www.w3.org/1999/xhtml">9.4 </span></span> <span id="x1-1770009.4"><span class="koboSpan" id="kobo.1147.1" xmlns="http://www.w3.org/1999/xhtml">Quantum support vector machines in Qiskit</span></span></h1>
<p><span class="koboSpan" id="kobo.1148.1" xmlns="http://www.w3.org/1999/xhtml">In the previous section, we </span><span id="dx1-177001"/><span class="koboSpan" id="kobo.1149.1" xmlns="http://www.w3.org/1999/xhtml">mastered the use of QSVMs in PennyLane. </span><span class="koboSpan" id="kobo.1149.2" xmlns="http://www.w3.org/1999/xhtml">You may want to review </span><em><span class="koboSpan" id="kobo.1150.1" xmlns="http://www.w3.org/1999/xhtml">subsection</span></em> <a href="#x1-1730009.3.1"><em><span class="koboSpan" id="kobo.1151.1" xmlns="http://www.w3.org/1999/xhtml">9.3.1</span></em></a><span class="koboSpan" id="kobo.1152.1" xmlns="http://www.w3.org/1999/xhtml"> and the beginning of </span><em><span class="koboSpan" id="kobo.1153.1" xmlns="http://www.w3.org/1999/xhtml">subsection</span></em> <a href="#x1-1750009.3.3"><em><span class="koboSpan" id="kobo.1154.1" xmlns="http://www.w3.org/1999/xhtml">9.3.3</span></em></a><span class="koboSpan" id="kobo.1155.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1155.2" xmlns="http://www.w3.org/1999/xhtml">That is where we prepare the dataset that we will be using here too. </span><span class="koboSpan" id="kobo.1155.3" xmlns="http://www.w3.org/1999/xhtml">In addition to running the code in those subsections, you will have to do the following import:</span></p>
<pre class="lstlisting" id="listing-221"><span class="koboSpan" id="kobo.1156.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.metrics import accuracy_score
</span></pre>
<p><span class="koboSpan" id="kobo.1157.1" xmlns="http://www.w3.org/1999/xhtml">Now it’s time for us to switch to Qiskit. </span><span class="koboSpan" id="kobo.1157.2" xmlns="http://www.w3.org/1999/xhtml">In some ways, Qiskit can be easier to use than PennyLane — although this is probably a matter of taste. </span><span class="koboSpan" id="kobo.1157.3" xmlns="http://www.w3.org/1999/xhtml">In addition, Qiskit will enable us to directly train and run our QSVM models using the real quantum computers available at IBM Quantum. </span><span class="koboSpan" id="kobo.1157.4" xmlns="http://www.w3.org/1999/xhtml">Nevertheless, for now, let us begin with QSVMs on our beloved Qiskit Aer simulator.</span></p>
<section class="level3 subsectionHead" data-number="17.4.1" id="qsvms-on-qiskit-aer">
<h2 class="subsectionHead" data-number="17.4.1"><span class="titlemark"><span class="koboSpan" id="kobo.1158.1" xmlns="http://www.w3.org/1999/xhtml">9.4.1 </span></span> <span id="x1-1780009.4.1"><span class="koboSpan" id="kobo.1159.1" xmlns="http://www.w3.org/1999/xhtml">QSVMs on Qiskit Aer</span></span></h2>
<p><span class="koboSpan" id="kobo.1160.1" xmlns="http://www.w3.org/1999/xhtml">To get started, let us just import Qiskit:</span></p>
<pre class="lstlisting" id="listing-222"><span class="koboSpan" id="kobo.1161.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit import *
</span></pre>
<p><span class="koboSpan" id="kobo.1162.1" xmlns="http://www.w3.org/1999/xhtml">When we defined a </span><span id="dx1-178002"/><span class="koboSpan" id="kobo.1163.1" xmlns="http://www.w3.org/1999/xhtml">QSVM in PennyLane, we had to ”manually” implement a kernel function in order to pass it to scikit-learn. </span><span class="koboSpan" id="kobo.1163.2" xmlns="http://www.w3.org/1999/xhtml">This process is simplified in Qiskit, for all it takes to define a quantum kernel is to instantiate a </span><code><span class="koboSpan" id="kobo.1164.1" xmlns="http://www.w3.org/1999/xhtml">QuantumKernel</span></code><span class="koboSpan" id="kobo.1165.1" xmlns="http://www.w3.org/1999/xhtml"> object. </span><span class="koboSpan" id="kobo.1165.2" xmlns="http://www.w3.org/1999/xhtml">In the initializer, we are asked to provide a </span><code><span class="koboSpan" id="kobo.1166.1" xmlns="http://www.w3.org/1999/xhtml">backend</span></code><span class="koboSpan" id="kobo.1167.1" xmlns="http://www.w3.org/1999/xhtml"> argument, which will be, of course, the backend object on which the quantum kernel will run. </span><span class="koboSpan" id="kobo.1167.2" xmlns="http://www.w3.org/1999/xhtml">By default, the feature map that the quantum kernel will use is the ZZ feature map with two qubits, but we can use a different feature map by passing a value to the </span><code><span class="koboSpan" id="kobo.1168.1" xmlns="http://www.w3.org/1999/xhtml">feature_map</span></code><span class="koboSpan" id="kobo.1169.1" xmlns="http://www.w3.org/1999/xhtml"> object. </span><span class="koboSpan" id="kobo.1169.2" xmlns="http://www.w3.org/1999/xhtml">This value should be a parametrized circuit representing the feature map.</span></p>
<p><span class="koboSpan" id="kobo.1170.1" xmlns="http://www.w3.org/1999/xhtml">Defining parametrized circuits in Qiskit is actually fairly easy. </span><span class="koboSpan" id="kobo.1170.2" xmlns="http://www.w3.org/1999/xhtml">If you want to use an individual parameter in a circuit, you can just import </span><code><span class="koboSpan" id="kobo.1171.1" xmlns="http://www.w3.org/1999/xhtml">Parameter</span></code><span class="koboSpan" id="kobo.1172.1" xmlns="http://www.w3.org/1999/xhtml"> from </span><code><span class="koboSpan" id="kobo.1173.1" xmlns="http://www.w3.org/1999/xhtml">qiskit</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1174.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1175.1" xmlns="http://www.w3.org/1999/xhtml">circuit</span></code><span class="koboSpan" id="kobo.1176.1" xmlns="http://www.w3.org/1999/xhtml"> and define a parameter object as </span><code><span class="koboSpan" id="kobo.1177.1" xmlns="http://www.w3.org/1999/xhtml">Parameter</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1178.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1179.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1180.1" xmlns="http://www.w3.org/1999/xhtml">label</span></code></span><span style="color:#0086E5"><code><span class="koboSpan" id="kobo.1181.1" xmlns="http://www.w3.org/1999/xhtml">"</span></code></span><code><span class="koboSpan" id="kobo.1182.1" xmlns="http://www.w3.org/1999/xhtml">)</span></code><span class="koboSpan" id="kobo.1183.1" xmlns="http://www.w3.org/1999/xhtml"> with any label of your choice. </span><span class="koboSpan" id="kobo.1183.2" xmlns="http://www.w3.org/1999/xhtml">This object can then be used in quantum circuits. </span><span class="koboSpan" id="kobo.1183.3" xmlns="http://www.w3.org/1999/xhtml">For example, we may define a circuit with an </span><span class="koboSpan" id="kobo.1184.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.1185.1" xmlns="http://www.w3.org/1999/xhtml">-rotation parametrized by a value </span><span class="koboSpan" id="kobo.1186.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="x" class="math inline" src="../media/file269.png" style="vertical-align:middle" title="x"/></span><span class="koboSpan" id="kobo.1187.1" xmlns="http://www.w3.org/1999/xhtml"> as follows:</span></p>
<pre class="lstlisting" id="listing-223"><span class="koboSpan" id="kobo.1188.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit.circuit import Parameter 
 
parameter = Parameter("x") 
 
qc = QuantumCircuit(1) 
 
qc.rx(parameter, 0)
</span></pre>
<p><span class="koboSpan" id="kobo.1189.1" xmlns="http://www.w3.org/1999/xhtml">If you want to use an array of </span><span id="dx1-178007"/><span class="koboSpan" id="kobo.1190.1" xmlns="http://www.w3.org/1999/xhtml">parameters in a circuit, you may define a </span><code><span class="koboSpan" id="kobo.1191.1" xmlns="http://www.w3.org/1999/xhtml">ParameterVector</span></code><span class="koboSpan" id="kobo.1192.1" xmlns="http://www.w3.org/1999/xhtml"> object instead. </span><span class="koboSpan" id="kobo.1192.2" xmlns="http://www.w3.org/1999/xhtml">It can also be imported from </span><code><span class="koboSpan" id="kobo.1193.1" xmlns="http://www.w3.org/1999/xhtml">qiskit</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1194.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.1195.1" xmlns="http://www.w3.org/1999/xhtml">circuit</span></code><span class="koboSpan" id="kobo.1196.1" xmlns="http://www.w3.org/1999/xhtml"> and, in addition to the mandatory label, it accepts an optional </span><code><span class="koboSpan" id="kobo.1197.1" xmlns="http://www.w3.org/1999/xhtml">length</span></code><span class="koboSpan" id="kobo.1198.1" xmlns="http://www.w3.org/1999/xhtml"> argument setting the length of the array. </span><span class="koboSpan" id="kobo.1198.2" xmlns="http://www.w3.org/1999/xhtml">By default, this length is set to zero. </span><span class="koboSpan" id="kobo.1198.3" xmlns="http://www.w3.org/1999/xhtml">We may use these parameter vector objects as in the following example:</span></p>
<pre class="lstlisting" id="listing-224"><span class="koboSpan" id="kobo.1199.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit.circuit import ParameterVector 
 
parameter = ParameterVector("x", length = 2) 
 
qc = QuantumCircuit(2) 
 
qc.rx(parameter[0], 0) 
 
qc.rx(parameter[1], 1)
</span></pre>
<div class="tcolorbox questionx" id="tcolobox-177">
<span id="x1-178014x9.4.1"/>
<div class="tcolorbox-title">
<p><span class="koboSpan" id="kobo.1200.1" xmlns="http://www.w3.org/1999/xhtml">Exercise 9.4</span></p>
</div>
<div class="tcolorbox-content"><span class="koboSpan" id="kobo.1201.1" xmlns="http://www.w3.org/1999/xhtml">
Define an </span><code><span class="koboSpan" id="kobo.1202.1" xmlns="http://www.w3.org/1999/xhtml">AngleEncodingX</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1203.1" xmlns="http://www.w3.org/1999/xhtml">(</span></code></span><span style="color:#000000"><code><span class="koboSpan" id="kobo.1204.1" xmlns="http://www.w3.org/1999/xhtml">n</span></code></span>
<code><span class="koboSpan" id="kobo.1205.1" xmlns="http://www.w3.org/1999/xhtml">)</span></code><span class="koboSpan" id="kobo.1206.1" xmlns="http://www.w3.org/1999/xhtml"> function that return the feature map for angle encoding using </span><span class="koboSpan" id="kobo.1207.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="R_{X}" class="math inline" src="../media/file118.png" style="vertical-align:middle" title="R_{X}"/></span><span class="koboSpan" id="kobo.1208.1" xmlns="http://www.w3.org/1999/xhtml"> rotations on </span><code><span class="koboSpan" id="kobo.1209.1" xmlns="http://www.w3.org/1999/xhtml">n</span></code><span class="koboSpan" id="kobo.1210.1" xmlns="http://www.w3.org/1999/xhtml"> qubits.
</span></div>
</div>
<p><span class="koboSpan" id="kobo.1211.1" xmlns="http://www.w3.org/1999/xhtml">Using parametrized circuits, we may define any feature map of our choice for its use in a quantum kernel; for instance, we could just send any of the </span><code><span class="koboSpan" id="kobo.1212.1" xmlns="http://www.w3.org/1999/xhtml">qc</span></code><span class="koboSpan" id="kobo.1213.1" xmlns="http://www.w3.org/1999/xhtml"> objects that we have created in the previous pieces of code as the </span><code><span class="koboSpan" id="kobo.1214.1" xmlns="http://www.w3.org/1999/xhtml">feature_map</span></code><span class="koboSpan" id="kobo.1215.1" xmlns="http://www.w3.org/1999/xhtml"> parameter in the </span><code><span class="koboSpan" id="kobo.1216.1" xmlns="http://www.w3.org/1999/xhtml">QuantumKernel</span></code><span class="koboSpan" id="kobo.1217.1" xmlns="http://www.w3.org/1999/xhtml"> constructor. </span><span class="koboSpan" id="kobo.1217.2" xmlns="http://www.w3.org/1999/xhtml">Nevertheless, Qiskit already comes with some pre-defined feature maps out of the box. </span><span class="koboSpan" id="kobo.1217.3" xmlns="http://www.w3.org/1999/xhtml">For our case, we may generate a circuit for the ZZ feature map on eight qubits using the following piece of code:</span></p>
<pre class="lstlisting" id="listing-225"><span class="koboSpan" id="kobo.1218.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit.circuit.library import ZZFeatureMap 
 
zzfm = ZZFeatureMap(8)
</span></pre>
<p><span class="koboSpan" id="kobo.1219.1" xmlns="http://www.w3.org/1999/xhtml">As a matter of fact, this feature map can be further customized by providing additional arguments. </span><span class="koboSpan" id="kobo.1219.2" xmlns="http://www.w3.org/1999/xhtml">We shall use them in the following chapter.</span></p>
<p><span class="koboSpan" id="kobo.1220.1" xmlns="http://www.w3.org/1999/xhtml">Once we have our </span><span id="dx1-178017"/><span class="koboSpan" id="kobo.1221.1" xmlns="http://www.w3.org/1999/xhtml">feature map, we can trivially set up a quantum kernel reliant on the Aer simulator as follows:</span></p>
<pre class="lstlisting" id="listing-226"><span class="koboSpan" id="kobo.1222.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit_machine_learning.kernels import QuantumKernel 
 
from qiskit.providers.aer import AerSimulator 
 
qkernel = QuantumKernel(feature_map = zzfm, 
 
            quantum_instance = AerSimulator())
</span></pre>
<p><span class="koboSpan" id="kobo.1223.1" xmlns="http://www.w3.org/1999/xhtml">And that’s all it takes! </span><span class="koboSpan" id="kobo.1223.2" xmlns="http://www.w3.org/1999/xhtml">By the way, here we are using the Qiskit Machine Learning package. </span><span class="koboSpan" id="kobo.1223.3" xmlns="http://www.w3.org/1999/xhtml">Please, refer to </span><em><span class="koboSpan" id="kobo.1224.1" xmlns="http://www.w3.org/1999/xhtml">Appendix</span></em> <a href="ch027.xhtml#x1-240000D"><em><span class="koboSpan" id="kobo.1225.1" xmlns="http://www.w3.org/1999/xhtml">D</span></em></a><em><span class="koboSpan" id="kobo.1226.1" xmlns="http://www.w3.org/1999/xhtml">, Installing the Tools</span></em><span class="koboSpan" id="kobo.1227.1" xmlns="http://www.w3.org/1999/xhtml">, for installation instructions.</span></p>
<p><span class="koboSpan" id="kobo.1228.1" xmlns="http://www.w3.org/1999/xhtml">If we’d like to train a QSVM model using our freshly-created kernel, we can use Qiskit’s own extension of the SVC class provided by scikit-learn. </span><span class="koboSpan" id="kobo.1228.2" xmlns="http://www.w3.org/1999/xhtml">It’s called </span><code><span class="koboSpan" id="kobo.1229.1" xmlns="http://www.w3.org/1999/xhtml">QSVC</span></code><span class="koboSpan" id="kobo.1230.1" xmlns="http://www.w3.org/1999/xhtml"> and it can be imported from </span><code><span class="koboSpan" id="kobo.1231.1" xmlns="http://www.w3.org/1999/xhtml">quantum_machine_learning</span></code><span style="color:#000000"><code><span class="koboSpan" id="kobo.1232.1" xmlns="http://www.w3.org/1999/xhtml">.</span></code></span><code><span class="koboSpan" id="kobo.1233.1" xmlns="http://www.w3.org/1999/xhtml">algorithms</span></code><span class="koboSpan" id="kobo.1234.1" xmlns="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1234.2" xmlns="http://www.w3.org/1999/xhtml">It works just like the original </span><code><span class="koboSpan" id="kobo.1235.1" xmlns="http://www.w3.org/1999/xhtml">SVC</span></code><span class="koboSpan" id="kobo.1236.1" xmlns="http://www.w3.org/1999/xhtml"> class, but it accepts a </span><code><span class="koboSpan" id="kobo.1237.1" xmlns="http://www.w3.org/1999/xhtml">quantum_kernel</span></code><span class="koboSpan" id="kobo.1238.1" xmlns="http://www.w3.org/1999/xhtml"> argument to which we can pass </span><code><span class="koboSpan" id="kobo.1239.1" xmlns="http://www.w3.org/1999/xhtml">QuantumKernel</span></code><span class="koboSpan" id="kobo.1240.1" xmlns="http://www.w3.org/1999/xhtml"> objects.</span></p>
<p><span class="koboSpan" id="kobo.1241.1" xmlns="http://www.w3.org/1999/xhtml">Thus, these are the instructions that we have to run in order to train a QSVM with our kernel:</span></p>
<pre class="lstlisting" id="listing-227"><span class="koboSpan" id="kobo.1242.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit_machine_learning.algorithms import QSVC 
 
 
 
qsvm = QSVC(quantum_kernel = qkernel) 
 
qsvm.fit(xs_tr, y_tr)
</span></pre>
<p><span class="koboSpan" id="kobo.1243.1" xmlns="http://www.w3.org/1999/xhtml">As with PennyLane, this will take a few minutes to run. </span><span class="koboSpan" id="kobo.1243.2" xmlns="http://www.w3.org/1999/xhtml">Notice, by the way, that we have used the reduced dataset (</span><code><span class="koboSpan" id="kobo.1244.1" xmlns="http://www.w3.org/1999/xhtml">xs_tr</span></code><span class="koboSpan" id="kobo.1245.1" xmlns="http://www.w3.org/1999/xhtml">), because we are using the ZZ feature map on 8 qubits.</span></p>
<p><span class="koboSpan" id="kobo.1246.1" xmlns="http://www.w3.org/1999/xhtml">Once the training is complete, we can get the accuracy on the test dataset as we have always done:</span></p>
<pre class="lstlisting" id="listing-228"><span class="koboSpan" id="kobo.1247.1" xmlns="http://www.w3.org/1999/xhtml">

print(accuracy_score(qsvm.predict(xs_test), y_test))
</span></pre>
<p><span class="koboSpan" id="kobo.1248.1" xmlns="http://www.w3.org/1999/xhtml">In this case, the </span><span id="dx1-178027"/><span class="koboSpan" id="kobo.1249.1" xmlns="http://www.w3.org/1999/xhtml">returned accuracy was </span><span class="koboSpan" id="kobo.1250.1" xmlns="http://www.w3.org/1999/xhtml"><img alt="1" class="math inline" src="../media/file13.png" style="vertical-align:middle" title="1"/></span><span class="koboSpan" id="kobo.1251.1" xmlns="http://www.w3.org/1999/xhtml">.</span></p>
<p><span class="koboSpan" id="kobo.1252.1" xmlns="http://www.w3.org/1999/xhtml">That is all you need to know about how to run QSVMs on the Aer simulator. </span><span class="koboSpan" id="kobo.1252.2" xmlns="http://www.w3.org/1999/xhtml">Now, let’s get real.</span></p>
</section>
<section class="level3 subsectionHead" data-number="17.4.2" id="qsvms-on-ibm-quantum-computers">
<h2 class="subsectionHead" data-number="17.4.2"><span class="titlemark"><span class="koboSpan" id="kobo.1253.1" xmlns="http://www.w3.org/1999/xhtml">9.4.2 </span></span> <span id="x1-1790009.4.2"><span class="koboSpan" id="kobo.1254.1" xmlns="http://www.w3.org/1999/xhtml">QSVMs on IBM quantum computers</span></span></h2>
<p><span class="koboSpan" id="kobo.1255.1" xmlns="http://www.w3.org/1999/xhtml">Training and using </span><span id="dx1-179001"/><span class="koboSpan" id="kobo.1256.1" xmlns="http://www.w3.org/1999/xhtml">QSVMs on real hardware with Qiskit couldn’t be easier. </span><span class="koboSpan" id="kobo.1256.2" xmlns="http://www.w3.org/1999/xhtml">We will show how it can be done in this subsection.</span></p>
<p><span class="koboSpan" id="kobo.1257.1" xmlns="http://www.w3.org/1999/xhtml">Firstly, as we did back in </span><em><span class="koboSpan" id="kobo.1258.1" xmlns="http://www.w3.org/1999/xhtml">Chapter</span></em> <a href="ch009.xhtml#x1-400002"><em><span class="koboSpan" id="kobo.1259.1" xmlns="http://www.w3.org/1999/xhtml">2</span></em></a><span class="koboSpan" id="kobo.1260.1" xmlns="http://www.w3.org/1999/xhtml">, </span><em><span class="koboSpan" id="kobo.1261.1" xmlns="http://www.w3.org/1999/xhtml">The Tools of the Trade in Quantum</span></em> <em><span class="koboSpan" id="kobo.1262.1" xmlns="http://www.w3.org/1999/xhtml">Computing</span></em><span class="koboSpan" id="kobo.1263.1" xmlns="http://www.w3.org/1999/xhtml">, we will load our IBM Quantum account:</span></p>
<pre class="lstlisting" id="listing-229"><span class="koboSpan" id="kobo.1264.1" xmlns="http://www.w3.org/1999/xhtml">

provider = IBMQ.load_account()
</span></pre>
<p><span class="koboSpan" id="kobo.1265.1" xmlns="http://www.w3.org/1999/xhtml">Naturally, for this to work, you should have saved your access token beforehand. </span><span class="koboSpan" id="kobo.1265.2" xmlns="http://www.w3.org/1999/xhtml">At the time of writing, free accounts don’t have access to any real quantum devices with eight qubits, but there are some with seven qubits. </span><span class="koboSpan" id="kobo.1265.3" xmlns="http://www.w3.org/1999/xhtml">We can select the one that is the least busy with the following piece of code:</span></p>
<pre class="lstlisting" id="listing-230"><span class="koboSpan" id="kobo.1266.1" xmlns="http://www.w3.org/1999/xhtml">

from qiskit.providers.ibmq import * 
 
 
 
dev_list = provider.backends( 
 
    filters = lambda x: x.configuration().n_qubits &gt;= 7, 
 
    simulator = False) 
 
dev = least_busy(dev_list)
</span></pre>
<p><span class="koboSpan" id="kobo.1267.1" xmlns="http://www.w3.org/1999/xhtml">Of course, we will have to further reduce our data to seven variables, but we can do that very easily:</span></p>
<pre class="lstlisting" id="listing-231"><span class="koboSpan" id="kobo.1268.1" xmlns="http://www.w3.org/1999/xhtml">

from sklearn.decomposition import PCA 
 
 
 
pca = PCA(n_components = 7) 
 
 
 
xss_tr = pca.fit_transform(x_tr) 
 
 
 
xss_test = pca.transform(x_test)
</span></pre>
<p><span class="koboSpan" id="kobo.1269.1" xmlns="http://www.w3.org/1999/xhtml">And, with this, we have all the </span><span id="dx1-179016"/><span class="koboSpan" id="kobo.1270.1" xmlns="http://www.w3.org/1999/xhtml">ingredients ready to train a QSVM on real hardware! </span><span class="koboSpan" id="kobo.1270.2" xmlns="http://www.w3.org/1999/xhtml">We will have to follow the same steps as before — only this time using our real device as </span><code><span class="koboSpan" id="kobo.1271.1" xmlns="http://www.w3.org/1999/xhtml">quantum_instance</span></code><span class="koboSpan" id="kobo.1272.1" xmlns="http://www.w3.org/1999/xhtml"> in the instantiation of our quantum kernel!</span></p>
<pre class="lstlisting" id="listing-232"><span class="koboSpan" id="kobo.1273.1" xmlns="http://www.w3.org/1999/xhtml">

zzfm = ZZFeatureMap(7) 
 
qkernel = QuantumKernel(feature_map = zzfm, quantum_instance = dev) 
 
qsvm = QSVC(quantum_kernel = qkernel) 
 
qsvm.fit(xss_tr, y_tr)
</span></pre>
<p><span class="koboSpan" id="kobo.1274.1" xmlns="http://www.w3.org/1999/xhtml">When you execute this code, all the circuit parameters are known in advance. </span><span class="koboSpan" id="kobo.1274.2" xmlns="http://www.w3.org/1999/xhtml">For this reason, Qiskit will try to send as many circuits as possible at the same time. </span><span class="koboSpan" id="kobo.1274.3" xmlns="http://www.w3.org/1999/xhtml">However, these jobs still have to wait in the queue. </span><span class="koboSpan" id="kobo.1274.4" xmlns="http://www.w3.org/1999/xhtml">Depending on the number of points in your dataset and on your access privileges, this may take quite a long time to complete!</span></p>
<p><span class="koboSpan" id="kobo.1275.1" xmlns="http://www.w3.org/1999/xhtml">With this, we can bring our study of QSVMs in Qiskit to an end.</span></p>
</section>
</section>
<section class="level2 likesectionHead" data-number="17.5" id="summary-8">
<h1 class="likesectionHead" data-number="17.5"><span id="x1-1800009.4.2"><span class="koboSpan" id="kobo.1276.1" xmlns="http://www.w3.org/1999/xhtml">Summary</span></span></h1>
<p><span id="Q1-1-248"/></p>
<p><span class="koboSpan" id="kobo.1277.1" xmlns="http://www.w3.org/1999/xhtml">In this chapter, we first learned what support vector machines are, and how they can be trained to solve binary classification problems. </span><span class="koboSpan" id="kobo.1277.2" xmlns="http://www.w3.org/1999/xhtml">We began by considering vanilla vector machines, and then we introduced the kernel trick — which opened up a world of possibilities! </span><span class="koboSpan" id="kobo.1277.3" xmlns="http://www.w3.org/1999/xhtml">In particular, we saw how QSVMs are nothing more than a support vector machine with a quantum kernel.</span></p>
<p><span class="koboSpan" id="kobo.1278.1" xmlns="http://www.w3.org/1999/xhtml">From there on, we learned how quantum kernels actually work and how to implement them. </span><span class="koboSpan" id="kobo.1278.2" xmlns="http://www.w3.org/1999/xhtml">We explored the essential role of feature maps, and discussed a few of the most well-known ones.</span></p>
<p><span class="koboSpan" id="kobo.1279.1" xmlns="http://www.w3.org/1999/xhtml">Finally, we learned how to implement, train, and use quantum support vector machines with PennyLane and Qiskit. </span><span class="koboSpan" id="kobo.1279.2" xmlns="http://www.w3.org/1999/xhtml">In addition, we were able to very easily run QSVMs on real hardware thanks to Qiskit’s interface to IBM Quantum.</span></p>
<p><span class="koboSpan" id="kobo.1280.1" xmlns="http://www.w3.org/1999/xhtml">And that pretty much covers how QSVMs can help you can identify wines — or solve any other classification task — like an expert, all while happily ignoring what the ”alkalinity of ash” of a wine is. </span><span class="koboSpan" id="kobo.1280.2" xmlns="http://www.w3.org/1999/xhtml">Who knows? </span><span class="koboSpan" id="kobo.1280.3" xmlns="http://www.w3.org/1999/xhtml">Maybe these SVM models could open the door for you to enjoy a bohemian life of wine-tasting! </span><span class="koboSpan" id="kobo.1280.4" xmlns="http://www.w3.org/1999/xhtml">No need to thank us.</span></p>
<p><span class="koboSpan" id="kobo.1281.1" xmlns="http://www.w3.org/1999/xhtml">In the next chapter, we will consider another family of quantum machine learning models: that of quantum neural networks. </span><span class="koboSpan" id="kobo.1281.2" xmlns="http://www.w3.org/1999/xhtml">Things are about to get deep!</span></p>
</section>
</section>
</body>
</html>
