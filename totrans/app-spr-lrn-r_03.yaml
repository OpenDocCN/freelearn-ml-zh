- en: '*Chapter 3:*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第三章：*'
- en: Introduction to Supervised Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习简介
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Explain supervised learning and machine learning workflow
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释监督学习和机器学习工作流程
- en: Use and explore the Beijing PM2.5 dataset
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用和探索北京PM2.5数据集
- en: Explain the difference between continuous and categorical dependent variables
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释连续和分类因变量的区别
- en: Implement the basic regression and classification algorithms in R
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在R中实现基本的回归和分类算法
- en: Identify the key differences between supervised learning and other types of
    machine learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分监督学习与其他类型机器学习的关键差异
- en: Work with the evaluation metrics of supervised learning algorithms
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与监督学习算法的评估指标一起工作
- en: Perform model diagnostics for avoiding biased coefficient estimates and large
    standard errors
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行模型诊断，以避免系数估计偏差和大的标准误差
- en: In this chapter, we will introduce supervised learning and demonstrate the workflow
    of building machine learning models with real-world examples.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍监督学习，并通过实际案例展示构建机器学习模型的流程。
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: In the previous chapters, we explored some of packages of R, such as the `dplyr`,
    `plyr`, `lubridate`, and `ggplot2`, where we discussed the basics of storing and
    processing data in R. Later, the same ideas were used in Exploratory Data Analysis
    (EDA) to understand the ways to break data into smaller parts, extract insights
    from data, and explore other ways to understand the data better, before venturing
    into advanced modeling techniques.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们探讨了R的一些包，如`dplyr`、`plyr`、`lubridate`和`ggplot2`，其中我们讨论了在R中存储和处理数据的基本方法。后来，这些思想被用于探索性数据分析（EDA），以了解如何将数据分解成更小的部分，从数据中提取洞察力，并探索其他更好地理解数据的方法，在尝试高级建模技术之前。
- en: In this chapter, we will take one step further toward introducing machine learning
    ideas. While broadly laying the foundation for thinking about various algorithms
    in machine learning, we will discuss supervised learning at length.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将进一步介绍机器学习思想。在广泛地为思考机器学习中的各种算法打下基础的同时，我们将详细讨论监督学习。
- en: Supervised learning is based on data that is well labeled by domain experts.
    For classifying cats and dogs from images, an algorithm first needs to see the
    images labeled as cats and dogs and then learn the features based on the label.
    Most enterprises with a good volume of historical data are the biggest beneficiaries
    of the wealth of knowledge they can extract from such data. If the data is clean
    and annotated well, supervised learning can result in a high accuracy of prediction,
    unlike other machine learning algorithms, which generally produce large errors
    in the beginning. In the absence of the right labels, it becomes difficult to
    derive any meaning out of data, other than just being able to do exploratory analysis
    and clustering.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '监督学习基于由领域专家良好标记的数据。对于从图像中分类猫和狗，算法首先需要看到标记为猫和狗的图像，然后根据标签学习特征。大多数拥有大量历史数据的企业的最大受益者是从这些数据中提取的丰富知识。如果数据干净且标注良好，监督学习可以实现高预测精度，这与其他机器学习算法不同，其他机器学习算法通常在开始时会产生较大的误差。在没有正确标签的情况下，从数据中提取任何意义变得困难，除了能够进行探索性分析和聚类之外。 '
- en: The standard component in solving real-world problems like predicting loan default
    (yes/no), failure of manufacturing machines in factories (yes/no), object detection
    in driverless cars (road, car, signal), predicting stock market prices (numeric)
    is a set of inputs (features) and a given output (label), which is usually obtained
    from historical data. When we predict the quantitative output, we call it **regression**,
    and when we predict the qualitative output, we call it **classification**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决现实世界问题（如预测贷款违约（是/否）、工厂制造机器故障（是/否）、自动驾驶汽车中的目标检测（道路、汽车、信号）、预测股票市场价格（数值））时，标准组件是一组输入（特征）和一个给定的输出（标签），这通常是从历史数据中获得的。当我们预测定量输出时，我们称之为**回归**，当我们预测定性输出时，我们称之为**分类**。
- en: Summary of the Beijing PM2.5 Dataset
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 北京PM2.5数据集概述
- en: In the urban and rural parts of many nations, the primary pollutant, fine particulate
    matter, is the cause of many health risks in humans and also affects climate change.
    In particular, PM2.5, defined as an airborne particle with an aerodynamic diameter
    of less than 2.5 µm, is the major category of atmospheric particulate matter.
    Various studies have linked PM2.5 with serious health problems such as heart attack
    and lung morbidity. The table in this section shows the types of atmospheric particulate
    matter and their size distribution in micrometers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多国家的城市和农村地区，主要污染物，细颗粒物，是导致人类许多健康风险的原因，同时也影响气候变化。特别是，PM2.5，定义为直径小于2.5 µm的气溶胶颗粒，是大气颗粒物的主要类别。各种研究将PM2.5与严重的健康问题联系起来，如心脏病和中风。本节中的表格显示了大气颗粒物的类型及其微米级的尺寸分布。
- en: 'In this and the remaining chapters, we will use the dataset published by the
    authors of the research paper, *Assessing Beijing''s PM2.5 pollution: severity,
    weather impact, APEC and winter heating*, where they use hourly PM2.5 readings
    taken at the US Embassy in Beijing located at 116.47 E, 39.95 N in conjunction
    with hourly meteorological measurements at **Beijing Capital International Airport**
    (**BCIA**), obtained from weather.nocrew.org. Their study claims to be the first
    to combine PM2.5 and meteorological data for an extended period in China''s PM2.5
    pollution. The following table describes the attributes in the dataset:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章和后续章节中，我们将使用研究论文《评估北京的PM2.5污染：严重程度、天气影响、APEC和冬季供暖》的作者发布的数据集，其中他们使用位于北京116.47
    E，39.95 N的美国大使馆的每小时PM2.5读数，以及从weather.nocrew.org获得的每小时气象测量数据，这些数据是在**北京首都国际机场**（**BCIA**）获得的。他们的研究声称是首次在中国PM2.5污染中结合了PM2.5和气象数据。以下表格描述了数据集中的属性：
- en: '![Figure 3.1: Attributes in Beijing''s PM2.5 dataset.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.1：北京PM2.5数据集的属性。'
- en: '](img/C12624_03_01.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/C12624_03_01.jpg)'
- en: 'Figure 3.1: Attributes in Beijing''s PM2.5 dataset.'
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.1：北京PM2.5数据集的属性。
- en: 'Exercise 40: Exploring the Data'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习40：探索数据
- en: In this exercise, we will learn the structure of the data with sample values
    for each attribute and use the `summary` function. We will see the five number
    summary statistics for numeric variables.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将通过每个属性的样本值学习数据的结构，并使用`summary`函数。我们将看到数值变量的五个数字摘要统计量。
- en: 'Perform the following steps to complete this exercise:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成此练习：
- en: 'First, use the following command to read the Beijing PM2.5 dataset into the
    PM25 DataFrame object:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用以下命令将北京PM2.5数据集读入PM25数据框对象：
- en: '[PRE0]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, print the structure of data with sample values using the `str` command:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用`str`命令打印具有样本值的数据结构：
- en: '[PRE1]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output of the previous command is as follows:'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上一条命令的输出如下：
- en: '[PRE2]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Observe that the dataset contains `43824` observations and 13 attributes. Observe
    that the dataset contains data from 2010 to 2014\. The values of pm2.5, temperature,
    pressure, combined wind direction, cumulated wind speed, cumulated hours of snow,
    and cumulated hours of rain are aggregated at every hour of the day.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 观察到数据集包含`43824`个观测值和13个属性。观察到数据集包含2010年至2014年的数据。pm2.5、温度、气压、综合风向、累积风速、累积降雪小时数和累积降雨小时数的值每天每小时都会汇总。
- en: 'Now, let''s show the summary statistics of the dataset:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们展示数据集的摘要统计量：
- en: '[PRE3]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is as follows:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE4]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following image is a graphical representation of the size distribution
    (in micrometers) of atmospheric particulate matter:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像是大气颗粒物尺寸分布（微米）的图形表示：
- en: '![Figure 3.2: Types and size distribution (in micrometers) of atmospheric particulate
    matter.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.2：大气颗粒物的类型和尺寸分布（微米）。'
- en: '](img/C12624_03_02.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/C12624_03_02.jpg)'
- en: 'Figure 3.2: Types and size distribution (in micrometers) of atmospheric particulate
    matter.'
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.2：大气颗粒物的类型和尺寸分布（微米）。
- en: 'Source: https://en.wikipedia.org/wiki/File:Airborne-particulate-size-chart.svg'
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 来源：https://en.wikipedia.org/wiki/File:Airborne-particulate-size-chart.svg
- en: Note
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The authors of the article "The impact of PM2.5 on the human respiratory system"
    published in the **Journal of Thoracic Disease** (**JTD**) discuss the association
    of air pollution with respiratory system diseases. They offer a comprehensive
    data-driven approach for explaining the factors causing such respiratory diseases.
    Special attention is given to Beijing, where the adverse effect of rising PM2.5
    has been studied extensively by researchers and has become a mainstream discussion
    point in the various climate change forums around the world. One can find more
    detail in the article at https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4740125/.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 发表在《胸科疾病杂志》（**JTD**）上的文章《PM2.5 对人类呼吸系统的影响》的作者讨论了空气污染与呼吸系统疾病之间的关联。他们提供了一种全面的数据驱动方法来解释导致此类呼吸疾病的原因。特别关注北京，研究人员已经广泛研究了
    PM2.5 上升的负面影响，并已成为全球各种气候变化论坛的主流讨论点。更多细节可以在文章中找到，链接为 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4740125/。
- en: Regression and Classification Problems
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归问题和分类问题
- en: We see classification and regression problems all around us in our daily life.
    The chances of rain from https://weather.com, our emails getting filtered into
    the spam mailbox and inbox, our personal and home loans getting accepted or rejected,
    deciding to pick our next holiday destination, exploring the options for buying
    a new house, investment decisions to gain short- and long-term benefits, purchasing
    the next book from Amazon; the list goes on and on. The world around us today
    is increasingly being run by algorithms that help us with our choices (which is
    not always a good thing).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的日常生活中，我们随处可见分类和回归问题。例如，从 https://weather.com 获取降雨概率，我们的电子邮件被过滤到垃圾邮件箱和收件箱，我们的个人和家庭贷款被批准或拒绝，决定选择下一个假日目的地，探索购买新房的选项，投资决策以获得短期和长期收益，从亚马逊购买下一本书；这个列表可以一直继续下去。我们周围的世界今天正越来越多地由帮助我们做出选择的算法（这并不总是好事）来运行。
- en: 'As discussed in *Chapter 2*, *Exploratory Analysis of Data*, we will use the
    **Minto Pyramid** principle called **Situation–Complication–Question** (**SCQ**)
    to define our problem statement. The following table shows the SCQ approach for
    Beijing''s PM2.5 problem:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如第 2 章*数据探索分析*中所述，我们将使用被称为**情境-复杂性-问题**（**SCQ**）的**Minto 金字塔**原则来定义我们的问题陈述。以下表格展示了针对北京的
    PM2.5 问题的 SCQ 方法：
- en: '![Figure 3.3: Applying SCQ on Beijing''s PM2.5 problem.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.3：应用 SCQ 解决北京的 PM2.5 问题。'
- en: '](img/C12624_03_03.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/C12624_03_03.jpg)'
- en: 'Figure 3.3: Applying SCQ on Beijing''s PM2.5 problem.'
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '![图 3.3：应用 SCQ 解决北京的 PM2.5 问题。'
- en: Now, in the SCQ construct described in the previous table, we can do a simple
    correlation analysis to establish the factors affecting the PM2.5 levels or create
    a predictive problem (prediction means finding an approximate function that maps
    from input variables to an output) that estimates the PM2.5 levels using all the
    factors. For the clarity of terminology, we will refer to factors as input variables.
    Then, PM2.5 becomes the dependent variable (often referred to as output variable).
    The dependent variable could be either categorical or continuous.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在前面表格中描述的 SCQ 构造中，我们可以进行简单的相关性分析，以确定影响 PM2.5 水平的因素，或者创建一个预测问题（预测意味着找到一个近似函数，将输入变量映射到输出），使用所有因素估计
    PM2.5 水平。为了术语的清晰，我们将把因素称为输入变量。然后，PM2.5 成为因变量（通常被称为输出变量）。因变量可以是分类的或连续的。
- en: 'For example, in the email classification into **SPAM**/**NOT SPAM** problem,
    the dependent variable is categorical. The following table highlights some critical
    differences between regression and classification problems:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在电子邮件分类到 **SPAM**/**非 SPAM** 的问题中，因变量是分类的。以下表格突出了回归问题和分类问题之间的一些关键区别：
- en: '![Figure 3.4: Difference between regression and classification problems.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.4：回归问题和分类问题之间的区别。'
- en: '](img/C12624_03_04.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/C12624_03_04.jpg)'
- en: 'Figure 3.4: Difference between regression and classification problems.'
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.4：回归问题和分类问题之间的区别。
- en: Machine Learning Workflow
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习工作流程
- en: In order to demonstrate the end-to-end process of building a predictive model
    (machine learning or supervised learning), we have created an easy-to-comprehend
    workflow. The first step is to design the problem, then source and prepare the
    data, which leads to coding the model for training and evaluation, and, finally,
    deploying the model. In the scope of this chapter, we will keep the model explanation
    to a bare minimum, as it will be covered again in detail in chapters 4 and 5.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示构建预测模型（机器学习或监督学习）的端到端过程，我们创建了一个易于理解的流程。第一步是设计问题，然后是获取和准备数据，这导致为训练和评估编码模型，最后部署模型。在本章的范围内，我们将保持模型解释的简洁，因为它将在第
    4 章和第 5 章中详细讨论。
- en: 'The following figure describes the workflow required to build a predictive
    model starting from preparing the data to deploying the model:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 下图描述了从准备数据到部署模型所需的整个工作流程：
- en: '![Figure 3.5: Machine learning workflow.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.5：机器学习工作流程。'
- en: '](img/C12624_03_05.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 C12624_03_05.jpg](img/C12624_03_05.jpg)'
- en: 'Figure 3.5: Machine learning workflow.'
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3.5：机器学习工作流程。
- en: Design the Problem
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设计问题
- en: Once we identify the domain of work, brainstorming on the designing of the problem
    is carried out. The idea is to first define the problem as a regression or classification
    problem. Once that is done, we choose the right target variable, along with identifying
    the features. The target variable is important because it decides how the training
    will take place. A supervised learning algorithm keeps the target variable at
    the center, while it tries to find a pattern from the given set of features.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了工作领域，就会进行问题设计的头脑风暴。首先，将问题定义为回归问题或分类问题。一旦完成，我们选择正确的目标变量，并识别特征。目标变量很重要，因为它决定了训练的方式。监督学习算法将目标变量放在中心，同时试图从给定的特征集中找到模式。
- en: Source and Prepare Data
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据来源和准备
- en: Data gathering and preparation is a painstaking job, mainly when the data sources
    are diverse and many. With each data source, the challenges are different and
    hence the time taken to process it varies. Data sources with tabular data are
    the easiest to process provided they do not contain a lot of garbage information,
    whereas textual data is the hardest to clean because of its free-flowing nature.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集和准备是一项费力的工作，尤其是在数据来源多样且众多的情况下。对于每个数据源，挑战都是不同的，因此处理所需的时间也会有所不同。如果表格数据不包含大量垃圾信息，那么具有表格数据的数据源是最容易处理的，而文本数据由于其自由流动的特性，清理起来最为困难。
- en: Code the Model
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码模型
- en: Once the data is prepared and ready, we take up the task of choosing the right
    model. Most often, the experts first go with one baseline model to gauge the predictability
    power of the algorithm using input features and the target variable. Then, one
    can either directly try the state-of-the-art algorithms or decide to go with a
    trial-and-error method (of trying to use all the possible models). One must understand
    that there is no right or wrong model, and everything depends on the data. In
    coding, the data is randomly divided into training and testing. The code is written
    to train the model on the training dataset, and evaluation happens on the testing
    data. This ensures that the model does not underperform when it is deployed in
    the real world.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据准备就绪，我们就开始选择合适的模型。通常，专家们首先选择一个基线模型，以评估算法使用输入特征和目标变量的可预测性。然后，可以直接尝试最先进的算法，或者决定采用试错法（尝试使用所有可能的模型）。必须理解的是，没有绝对正确或错误的模型，一切取决于数据。在编码过程中，数据被随机分为训练集和测试集。代码被编写来在训练数据集上训练模型，评估则在测试数据上进行，这确保了模型在实际部署时不会表现不佳。
- en: Train and Evaluate
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练和评估
- en: Model evaluation is the important part of the model, where its usability in
    practice is decided. Based on a given set of model evaluation metrics, we need
    to decide, after all the trial and error, the best model. In each iteration, metrics
    such as the R-squared value, accuracy, precision, and F-score are computed. Usually,
    the entire data is divided into training and testing data (with a third split
    for validation set also often included). The model is trained on the training
    data and tested on the testing data. This separation ensures that the model is
    not doing any rote learning. In more technical terms, the model is not overfitting
    (more on this in the *Evaluation Metrics* section in this chapter). Usually, at
    this stage of the workflow, one could decide to go back and include more variables,
    train the model, and redeploy. The process is repeated until the accuracy (or
    the other metrics of importance) of the model reaches a plateau.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估是模型的重要组成部分，其中决定了其在实际中的可用性。基于给定的一组模型评估指标，我们需要在经过多次尝试和错误后，决定最佳模型。在每次迭代中，计算如R平方值、准确率、精确率和F分数等指标。通常，整个数据被分为训练数据和测试数据（通常还包括一个用于验证的第三部分）。模型在训练数据上训练，在测试数据上测试。这种分离确保模型不会进行任何机械学习。在更技术性的术语中，模型不会过拟合（关于这一点，请参阅本章的*评估指标*部分）。通常，在这个工作流程的阶段，一个人可以决定返回并包括更多变量，训练模型，然后重新部署。这个过程会重复进行，直到模型的准确率（或其他重要指标）达到平台期。
- en: We use a random number generator function like `sample()` in R for splitting
    the data randomly into different parts as done in the next exercise 2, step 2.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用随机数生成函数，如R中的`sample()`函数，将数据随机分割成不同的部分，就像在下一个练习2的第2步中所做的那样。
- en: 'Exercise 41: Creating a Train-and-Test Dataset Randomly Generated by the Beijing
    PM2.5 Dataset'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习41：从北京PM2.5数据集中随机生成训练和测试数据集
- en: In this exercise, we will create a randomly generated train-and-test dataset
    from the Beijing PM2.5 dataset. We will reuse the `PM25` object created in the
    earlier exercise.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从北京PM2.5数据集中创建一个随机生成的训练和测试数据集。我们将重用之前练习中创建的`PM25`对象。
- en: 'Perform the following steps:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤：
- en: 'Create a `num_index` variable and set it to a value equal to the number of
    observations in the Beijing''s PM2.5 dataset:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`num_index`变量，并将其设置为北京PM2.5数据集中观测值的数量：
- en: '[PRE5]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Using the `sample()` function, randomly select 70% of the `num_index` values,
    and store them in `train_index`:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`sample()`函数，随机选择`num_index`值的70%，并将它们存储在`train_index`中：
- en: '[PRE6]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Use `train_index` to select a random subset of rows from the Beijing PM2.5
    dataset and store them in a DataFrame named `PM25_Train`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_index`从北京PM2.5数据集中选择一个随机子集的行，并将它们存储到一个名为`PM25_Train`的DataFrame中：
- en: '[PRE7]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Store the remaining observation into a DataFrame named `PM25_Test`:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将剩余的观测值存储到一个名为`PM25_Test`的DataFrame中：
- en: '[PRE8]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The exercise shows a simple example for creating the train-and-test set. A randomly
    selected set for training and testing ensures that the model has no bias and learns
    well from all the possible examples before being used in the real world on unseen
    data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 练习展示了创建训练和测试集的简单示例。随机选择的训练和测试集确保模型没有偏见，并在用于现实世界中的未见数据之前，从所有可能的示例中学习得很好。
- en: Deploy the Model
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署模型
- en: Once the best model is selected, the next step is to enable the model output
    to be used by a business application. The model is hosted as a **REpresentational
    State Transfer** (**REST**) API. These APIs are a way to host a web application
    as an endpoint that listens to any request for a model call and usually returns
    a JSON object as a response.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦选定了最佳模型，下一步就是使模型输出能够被业务应用使用。该模型以**表示状态转移**（**REST**）API的形式托管。这些API是以端点托管Web应用的方式，它监听对模型调用的任何请求，通常返回一个JSON对象作为响应。
- en: Deployment of the model is becoming an essential part of all machine learning
    projects in the industry. A model that is not deployable is no good for a company,
    and perhaps, merely serves the purpose of R&D. An increasing number of professionals
    are specializing in model deployment, which is sometimes a tedious and complicated
    process. In order to give the model deployment its due importance, we have given
    it a dedicated chapter, that is *Chapter 8*, *Model Deployment*.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的部署正成为工业界所有机器学习项目的必要部分。一个不可部署的模型对公司来说毫无价值，也许仅仅是为了研发目的。越来越多的专业人士正在专注于模型部署，这有时是一个繁琐且复杂的过程。为了给模型部署应有的重视，我们为其专门设立了一章，即*第8章，模型部署*。
- en: Regression
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归
- en: 'Now that we have seen the machine learning workflow, we will take two widely
    used types of machine learning algorithms: regression and classification; both
    employ supervised learning to train the models. The entire theme of this book
    revolves around these two types of algorithms. The Beijing PM2.5 dataset will
    be used extensively in demonstrating both these types. The dataset will help in
    understanding how one can convert a regression problem into a classification problem
    and vice versa.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了机器学习的工作流程，我们将探讨两种广泛使用的机器学习算法：回归和分类；两者都采用监督学习来训练模型。本书的整个主题围绕这两种类型的算法展开。北京PM2.5数据集将在演示这两种类型时被广泛使用。该数据集有助于理解如何将回归问题转换为分类问题，反之亦然。
- en: Simple and Multiple Linear Regression
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单和多重线性回归
- en: Regression is one of the most useful and essential tools in analytics and econometrics
    (the branch of economics concerned with the use of mathematical methods, especially
    statistics, in describing economic systems). In many ways, modern machine learning
    has its roots in statistics, and one can attribute that mostly to Sir Francis
    Galton's work. Galton was an English Victorian-era statistician and polymath with
    deep interest and expertise in fields such as genetics, psychology, and anthropology.
    He was the first to apply statistical methods to study human behavior and intelligence.
    Notably, his publication, *Regression Towards Mediocrity in Hereditary Stature*,
    had many insightful findings based on regression.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是分析学和计量经济学（关注于使用数学方法，尤其是统计学，来描述经济系统的经济学分支）中最有用和最基本的工具之一。在许多方面，现代机器学习的根源在于统计学，这主要归功于弗朗西斯·高尔顿爵士的工作。高尔顿是一位对遗传学、心理学和人类学等领域有深厚兴趣和专长的英国维多利亚时代统计学家和博学家。他是第一个将统计方法应用于研究人类行为和智力的人。值得注意的是，他的出版物《遗传身高回归到中等》基于回归有许多有洞察力的发现。
- en: In this section, we will briefly analyze the various factors that affect the
    PM2.5 levels using the Beijing dataset. In particular, the effect of variables
    such as dew point, temperature, wind speed, and pressure on PM2.5 will be explored.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要分析影响PM2.5水平的各种因素，使用北京数据集。特别是，我们将探讨露点、温度、风速和压力等变量对PM2.5的影响。
- en: Assumptions in Linear Regression Models
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线性回归模型中的假设
- en: As regression borrows many of its concepts from applied statistics to model
    the data, it comes with many assumptions. One should not apply regression algorithms
    to any dataset or problem. Let's examine the assumptions for linear regression
    before we build any model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 由于回归从应用统计学中借鉴了许多概念来建模数据，因此它伴随着许多假设。我们不应将回归算法应用于任何数据集或问题。在我们构建任何模型之前，让我们先检查线性回归的假设。
- en: The following table shows the assumptions and how we can statistically test
    whether the linear regression model follows the assumption or not. The table also
    shows some corrective actions if the assumption is violated. We will take up an
    elaborate discussion on these assumptions and perform diagnostic analysis to identify
    the violation in much detail in *Chapter 4*, *Regression.*
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了假设以及我们如何从统计上测试线性回归模型是否遵循该假设。该表还显示了一些如果假设被违反的纠正措施。我们将在第4章“回归”中详细讨论这些假设，并执行诊断分析以识别违规情况。
- en: '![Figure 3.6: Various assumptions in a linear regression model (Part 1).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.6：线性回归模型中的各种假设（第一部分）。'
- en: '](img/C12624_03_06.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12624_03_06.jpg)'
- en: 'Figure 3.6: Various assumptions in a linear regression model (Part 1).'
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.6：线性回归模型中的各种假设（第一部分）。
- en: '![Figure 3.7: Various assumptions in a linear regression model (Part 2).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.7：线性回归模型中的各种假设（第二部分）。'
- en: '](img/C12624_03_07.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C12624_03_07.jpg)'
- en: 'Figure 3.7: Various assumptions in a linear regression model (Part 2).'
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.7：线性回归模型中的各种假设（第二部分）。
- en: Exploratory Data Analysis (EDA)
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索性数据分析（EDA）
- en: Building regression models requires an in-depth analysis of the patterns and
    relationship between target and input variables. The Beijing dataset provides
    a magnitude of different environmental factors that may affect the PM2.5 levels
    in the atmosphere.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 构建回归模型需要对目标变量和输入变量之间的模式和关系进行深入分析。北京数据集提供了大量可能影响大气中PM2.5水平的环境因素。
- en: 'Exercise 42: Exploring the Time Series Views of PM2.5, DEWP, TEMP, and PRES
    variables of the Beijing PM2.5 Dataset'
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习42：探索北京PM2.5数据集中PM2.5、DEWP、TEMP和PRES变量的时间序列视图
- en: In this exercise, we will visualize the `pm2.5`, `DEWP`, `TEMP`, and `PRES`
    variables in a time series plot and observe any patterns that may emerge over
    the years in these variables.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'Import all the required libraries in the system:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, transform year, month, and hour into datetime using the `lubridate` package
    function named `ymd_h`:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Plot the PM2.5, TEMP, DEWP, and PRES for all the years using the following
    command:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, use the following command to plot the graphs:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The plot is as follows:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.8: Scatterplot showing the trend and seasonality of environmental
    factors like temperature, dew point, and pressure, along with PM2.5 levels in
    Beijing from 2010 to 2014 end.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_03_08.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.8: Scatterplot showing the trend and seasonality of environmental
    factors like temperature, dew point, and pressure, along with PM2.5 levels in
    Beijing from 2010 to 2014 end.'
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this exercise, we first show a time series view of the `PM2.5`, `DEWP`, `TEMP`,
    and `PRES` variables from the dataset and observe the pattern. As shown in *Figure
    3.8*, a distinct seasonality is observed `DEWP`, `TEMP`, and `PRES` show seasonality
    (the same pattern repeating every 12 months), PM2.5 seems to have a random pattern.
    This is an early indication that it's highly unlikely that we will see any effect
    of the three variables on PM2.5\. However, let's probe further to ascertain this
    hypothesis using a correlation plot and observe if there exits any relationship
    between the variables.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 43: Undertaking Correlation Analysis'
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will undertake a correlation analysis to study the strength
    of the relationship between the various factors.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `corrplot` package into the system using the following command:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now, create a new object and store the required values from `PM25` into it:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Use the `corrplot` package to display the graphical representation of a correlation
    matrix:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The plot is as follows:'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.9: Correlation between all the pairs of variables in the Beijing
    dataset.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_03_09.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.9: Correlation between all the pairs of variables in the Beijing dataset.'
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: First, we compute the correlation between all the variables. The resulting correlation
    plot shows that there appear to be no strong correlations between PM2.5 and the
    other variables. However, `PM2.5` and `DEWP`, `TEMP`, and `Iws` show some mild
    correlation, which indicates some relationship. This should not come as a surprise,
    because we saw in *Figure 3.8*, that while three variables follow a seasonality
    trend, PM2.5 seems more random. Note here that we have not done any processing
    or transformation to the dataset; these findings come directly from our first
    level of analysis. We will go into much detail later, in *Chapter 4*, *Regression*.
    Now, let's also visualize the relationship between the variables using a scatterplot.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 44: Drawing a Scatterplot to Explore the Relationship between PM2.5
    Levels and Other Factors'
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习44：绘制散点图以探索 PM2.5 水平与其他因素之间的关系
- en: In this exercise, we will use a scatterplot to explore the relationship between
    `pm2.5` levels and other factors. We will like to see whether there emerge any
    interesting patterns or relationships. A scatterplot is a simple and effective
    visualization for exploratory analysis on the relationships between variables.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用散点图来探索 `pm2.5` 水平与其他因素之间的关系。我们希望看到是否会出现任何有趣的模式或关系。散点图是探索变量之间关系的简单而有效的可视化工具。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来完成练习：
- en: 'Import the `ggplot2` package into your system:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `ggplot2` 包导入到您的系统中：
- en: '[PRE16]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Plot the scatterplot between `DEWP` and `PM2.5`, with the `month` variable
    used for color:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以 `month` 变量作为颜色绘制 `DEWP` 和 `PM2.5` 之间的散点图：
- en: '[PRE17]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The scatterplot is as follows:'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 散点图如下：
- en: '![Figure 3.10: Scatterplot showing the relationship between DEWP and PM2.5
    levels.'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.10：显示 DEWP 和 PM2.5 水平之间关系的散点图。'
- en: '](img/C12624_03_10.jpg)'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/C12624_03_10.jpg](img/C12624_03_10.jpg)'
- en: 'Figure 3.10: Scatterplot showing the relationship between DEWP and PM2.5 levels.'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.10：显示 DEWP 和 PM2.5 水平之间关系的散点图。
- en: 'Plot the scatterplot between `TEMP` and `PM2.5`, with the `month` variable
    used for color:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以 `month` 变量作为颜色绘制 `TEMP` 和 `PM2.5` 之间的散点图：
- en: '[PRE18]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The scatterplot is as follows:'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 散点图如下：
- en: '![Figure 3.11: Scatterplot showing the relationship between TEMP and PM2.5
    levels.'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.11：显示 TEMP 和 PM2.5 水平之间关系的散点图。'
- en: '](img/C12624_03_11.jpg)'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/C12624_03_11.jpg](img/C12624_03_11.jpg)'
- en: 'Figure 3.11: Scatterplot showing the relationship between TEMP and PM2.5 levels.'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.11：显示 TEMP 和 PM2.5 水平之间关系的散点图。
- en: 'Create a scatterplot between `DEWP` and `PM2.5`, with an hour of the day used
    for color and separate views for months of the year:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个以一天中的小时为颜色，按月份分别显示的 `DEWP` 和 `PM2.5` 之间的散点图：
- en: '[PRE19]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The scatterplot is as follows:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 散点图如下：
- en: '![Figure 3.12: Scatterplot showing the relationship between DEWP and PM2.5
    split by month of the year.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.12：按年份月份拆分的 DEWP 和 PM2.5 关系的散点图。'
- en: '](img/C12624_03_12.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/C12624_03_12.jpg](img/C12624_03_12.jpg)'
- en: 'Figure 3.12: Scatterplot showing the relationship between DEWP and PM2.5 split
    by month of the year.'
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.12：按年份月份拆分的 DEWP 和 PM2.5 关系的散点图。
- en: In order to gauge some relationship between variables, we used a scatterplot
    between `PM2.5` and `DEWP` with a line of fit. Observe that in the code, we have
    passed an argument to `geom_smooth()`, that is, `method = "auto"`, which automatically
    decides, based on the data, which model to use to fit a line. As shown in *Figure
    3.10*, the line is not linear. The `geom_smooth` method chooses `TEMP` and `PM2.5`
    plot, as shown in *Figure 3.11*. However, we could go one step further and split
    the scatterplot month-wise, as shown in *Figure 3.12*. This shows that a linear
    relationship exists, but it is highly season-dependent. For example, in April
    (represented by the integer `4`), the `DEWP` and `PM2.5` have a near-to-perfect
    straight line fit. We will extend this discussion into further details in *Chapter
    4*, *Regression*.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估变量之间的一些关系，我们使用 `PM2.5` 和 `DEWP` 之间的散点图并添加了拟合线。观察代码中，我们向 `geom_smooth()`
    传递了一个参数，即 `method = "auto"`，它会根据数据自动决定使用哪种模型来拟合直线。如图 *图3.10* 所示，直线不是线性的。`geom_smooth`
    方法选择了 `TEMP` 和 `PM2.5` 的绘图，如图 *图3.11* 所示。然而，我们可以更进一步，按月份拆分散点图，如图 *图3.12* 所示。这表明存在线性关系，但它高度依赖于季节。例如，在四月（用整数
    `4` 表示），`DEWP` 和 `PM2.5` 有一个近乎完美的直线拟合。我们将在 *第4章*，*回归* 中进一步讨论这个话题。
- en: So, we have seen some violation of assumption and the lack of a strong correlation
    between the environmental factors and PM2.5\. However, there seems to be some
    scope for further scrutiny. In this introductory chapter on supervised learning,
    we will only focus on the approach based on our machine learning workflow.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经看到了一些假设的违反和环境污染因素与 PM2.5 之间缺乏强相关性的情况。然而，似乎还有进一步审查的空间。在本章关于监督学习的介绍中，我们只关注基于我们的机器学习工作流程的方法。
- en: Note
  id: totrans-157
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 备注
- en: 'To know more about GAM, review this document: https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch13.pdf.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 GAM 的信息，请参阅此文档：https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch13.pdf。
- en: 'Activity 5: Draw a Scatterplot between PRES and PM2.5 Split by Months'
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动5：按月份绘制 PRES 和 PM2.5 的散点图
- en: In this activity, we will create a scatterplot between `DWEP` and `PM2.5`. Through
    this activity, we will learn to use the `facet_wrap()` function to create a layer
    on top of `ggplot()` for splitting the visualization of scatterplot into each
    month, thus helping to observe any seasonality pattern.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将创建`DWEP`和`PM2.5`之间的散点图。通过这个活动，我们将学习使用`facet_wrap()`函数在`ggplot()`之上创建一个层，将散点图的可视化分割到每个月，从而帮助观察任何季节性模式。
- en: 'Perform the following steps to complete the activity:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来完成活动：
- en: In `ggplot`, assign the component of the `a()` method with the `PRES` variable.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`ggplot`中，使用`PRES`变量分配`a()`方法的组件。
- en: In the next layer of the `geom_smooth()` method, set `colour = "blue"` to differentiate.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`geom_smooth()`方法的下一层，将`colour = "blue"`设置为区分。
- en: Finally, in the `facet_wrap()` layer, use the `month` variable to draw a separate
    segregation for each month.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在`facet_wrap()`层中，使用`month`变量为每个月绘制单独的隔离图。
- en: 'The plot is as follows:'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图表如下：
- en: '![Figure 3.13: Scatterplot showing the relationship between PRES and PM2.5.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.13：显示PRES和PM2.5之间关系的散点图。'
- en: '](img/C12624_03_13.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/C12624_03_13.jpg)'
- en: 'Figure 3.13: Scatterplot showing the relationship between PRES and PM2.5.'
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3.13：显示PRES和PM2.5之间关系的散点图。
- en: Note
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 445.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第445页找到。
- en: Model Building
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型构建
- en: We have briefly explored the relationship between `PM2.5` and a few factors
    such as `TEMP` and `DEWP`. The same analysis could be followed for other variables
    such as `PRES`, `Iwd`, and more. In this section, let's create a linear model.
    (We never hesitate to run a model even if we know the choice of model isn't the
    best. A trial-and-error approach in machine learning is always the best way to
    establish facts.)
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简要探讨了`PM2.5`与一些因素（如`TEMP`和`DEWP`）之间的关系。同样的分析可以应用于其他变量，如`PRES`、`Iwd`等。在本节中，让我们创建一个线性模型。（即使我们知道模型的选择不是最好的，我们也不会犹豫去运行模型。机器学习中的试错法总是建立事实的最佳方式。）
- en: 'In general, a linear regression models the linear relationship between an input
    variable (independent variable) and a target variable (dependent variable or explanatory
    variable). If we have one explanatory variable, it is called **simple linear regression**,
    and where there is more than one explanatory variable, it''s called **multiple
    linear regression**. The following equation is the mathematical representation
    of linear regression or a linear predictor function with *p* explanatory variables
    and *n* observations:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，线性回归模型输入变量（自变量）和目标变量（因变量或解释变量）之间的线性关系。如果我们有一个解释变量，它被称为**简单线性回归**；如果有多个解释变量，则称为**多元线性回归**。以下方程是线性回归或线性预测函数的数学表示，其中包含*p*个解释变量和*n*个观测值：
- en: '![](img/C12624_03_20.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/C12624_03_20.jpg)'
- en: Here, each ![A picture containing furniture, table, seat, stool
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，每个![包含家具、桌子、座椅、凳子
- en: Description automatically generated](img/C12624_03_21.png) is a vector of column
    values (explanatory variable) for ![](img/C12624_03_22.png), and ![A picture containing
    furniture
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/C12624_03_21.png)是一个列值的向量（解释变量）对于![包含家具的图片
- en: Description automatically generated](img/C12624_03_23.png) is the unknown parameter
    or coefficient. ![A picture containing furniture, seat
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/C12624_03_23.png)是未知的参数或系数。![包含家具、座椅
- en: Description automatically generated](img/C12624_03_24.png) makes this equation
    suitable for simple linear regression. There are many algorithms to fit this function
    onto the data. The most popular one is **ordinary least square** (**OLS**). We
    will discuss OLS in detail in our next chapter on regression.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/C12624_03_24.png)，这使得这个方程适合简单的线性回归。有许多算法可以将这个函数拟合到数据上。最流行的一个是**普通最小二乘法**（**OLS**）。我们将在下一章关于回归的章节中详细讨论OLS。
- en: Another way to think of ![A picture containing furniture
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种思考方式是![包含家具的图片
- en: Description automatically generated](img/C12624_03_25.png) is that it's a linear
    predictor function that fits the observations in the ![](img/C12624_03_26.png)—dimension
    space as closely as possible, minimizing the residual sum of squares (the difference
    in the actual value of the target value from the predicted value).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](img/C12624_03_25.png)是它是一个线性预测函数，尽可能地将观测值拟合到![图片](img/C12624_03_26.png)维度的空间中，最小化残差平方和（目标值的实际值与预测值之间的差异）。
- en: In the following exercise, we will skip the split of the dataset into train
    and test, as we are still in the exploration stage and have not decided to formally
    approach the modeling exercise. (We will touch on that in the next chapter.) We
    will use the `lm()` method in R for building a linear model. Again, more details
    on that in the next chapter. At this point, it is suffice to note that `lm()`
    fits a target variable to a straight line using either one or more input variables.
    In a simple linear regression, we use only one variable to fit the line, and in
    multiple linear regression, we can use more than one variable.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，我们将跳过将数据集分为训练集和测试集的步骤，因为我们仍然处于探索阶段，尚未决定正式进行建模练习。（我们将在下一章中涉及这一点。）我们将使用
    R 中的 `lm()` 方法构建线性模型。同样，关于这一点将在下一章中详细介绍。目前，只需注意 `lm()` 方法使用一个或多个输入变量将目标变量拟合到一条直线。在简单线性回归中，我们只使用一个变量来拟合直线，而在多重线性回归中，我们可以使用多个变量。
- en: 'Exercise 45: Exploring Simple and Multiple Regression Models'
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 45：探索简单和多重回归模型
- en: In this exercise, we will explore simple and multiple regression models.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将探索简单和多重回归模型。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: Import the required libraries and packages into R-Studio.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所需的库和包导入 R-Studio。
- en: 'Next, create a DataFrame object named `simple_PM25_linear_model` and use the
    `lm()` method to build a linear model:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一个名为 `simple_PM25_linear_model` 的 DataFrame 对象，并使用 `lm()` 方法构建线性模型：
- en: '[PRE20]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Print the summary of the object using the summary method, as illustrated here:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用如下所示的方法，使用 summary 方法打印对象的摘要：
- en: '[PRE21]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE22]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, create another DataFrame object and use the `lm()` method to build a
    linear model:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建另一个 DataFrame 对象，并使用 `lm()` 方法构建线性模型：
- en: '[PRE23]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Print the summary of the model object using the `summary` function:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `summary` 函数打印模型对象的摘要：
- en: '[PRE24]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE25]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Model Interpretation
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型解释
- en: Now, based on the previous output of both the simple and multiple linear regression
    models, let's try to understand what each part of the output means. At this juncture
    of the book, it's sufficient to know what each part means; we will discuss the
    results in *Chapter 4*, *Regression*.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，基于简单和多重线性回归模型的先前输出，让我们尝试理解输出中的每一部分代表什么。在本书的这个阶段，了解每一部分的意义就足够了；我们将在 *第 4 章*，*回归*
    中讨论结果。
- en: Part `lm()` method with the dependent and independent variables, represented
    like a formula using the `~` symbol. This resembles our linear predictor function.
    In a simple regression model, there is only one variable—`DEWP`—and in a multiple
    model, there are `DEWP`, `TEMP`, and `Iws`. You also see the five summary statistics
    of residuals (min, first quartile, median, third quartile, and max). This indicates
    how far the predicted values are from the actual value.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `lm()` 方法与因变量和自变量，用 `~` 符号表示的公式形式表示。这类似于我们的线性预测函数。在简单的回归模型中，只有一个变量——`DEWP`——而在多重模型中，有
    `DEWP`、`TEMP` 和 `Iws`。您还可以看到残差的五个汇总统计量（最小值、第一四分位数、中位数、第三四分位数和最大值）。这表明预测值与实际值之间的差距。
- en: Part `X_j` into our prediction equation, we will get the predictions. The column
    named `Std`. Error is the standard error of the estimate. t-value is obtained
    by taking the ratio of `Estimate` and `Std`. Error, and p-value highlights the
    statistical significance of the estimate. The visual clues, that is, the `*` and
    . symbols are based on the p-value. A value less than 0.001 gets a three star
    versus a value between 0.1 and 0.05, which gets a `.` (dot). Three stars means
    the best case and that the estimates corresponding to the independent variable
    are significant and useful in predicting (or explaining) the dependent variable.
    In other words, p-value helps in determining the significance of a regression
    model over a null model (just the mean of the dependent variable).
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 `X_j` 部分纳入我们的预测方程中，我们将得到预测值。名为 `Std. Error` 的列是估计的标准误差。t 值是通过将 `Estimate`
    和 `Std. Error` 的比率得到的，而 p 值突出了估计的统计显著性。视觉线索，即 `*` 和 . 符号是基于 p 值的。小于 0.001 的值得到三个星号，而介于
    0.1 和 0.05 之间的值得到一个 `.`（点）。三个星号意味着最佳情况，即对应于自变量的估计是显著的并且对预测（或解释）因变量是有用的。换句话说，p
    值有助于确定回归模型相对于零模型（仅因变量的均值）的显著性。
- en: 'Part **C**:'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部分 **C**：
- en: This part is the one that shows the efficacy of the model. The most important
    values to observe are the R-squared and adjusted R-squared values, which are statistical
    measures that signify the percentage of variation for a dependent variable that's
    explained by independent variable(s) in a regression model.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Go through the section on evaluation metrics in this chapter to see the interpretation
    on how well the model has done on R-squared and adjusted R-squared metrics.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to the regression algorithm, classification also learns from the dependent
    or target variables and uses all the predictor or independent variables to find
    the right pattern. The major difference comes from the idea that in classification,
    the target variable is categorical, whereas in regression, it is numeric. In this
    section, we will introduce logistic regression to demonstrate the concept using
    the Beijing PM2.5 dataset.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Logistic regression** is the most favorable white-box model used for binary
    classification. White-box models are defined as models providing visibility into
    the entire reasoning done for the prediction. For each prediction made, we can
    leverage the model''s mathematical equation and decode the reasons for the prediction
    made. There are also a set of classification models that are entirely black-box,
    that is, by no means can we understand the reasoning for the prediction leveraged
    by the model. In situations where we want to focus only on the end outcome, we
    should prefer black-box models as they are more powerful.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: A Brief Introduction
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Though the name ends with **regression**, logistic regression is a technique
    used to predict binary categorical outcomes and is hence a good choice for classification
    problems. As discussed in the previous section, we need a different approach to
    model for a categorical outcome. This can be done by transforming the outcome
    into the log of the odds ratio or the probability of the event to happen.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s distill this approach into simpler constructs. Assume that the probability
    of success for an event is 0.7\. Then, the probability of failure for the same
    event would be defined as *1 – 0.7 = 0.3*. The odds of success are defined as
    the ratio of the probability of success to the probability of failure. The odds
    of success would then be *0.7/0.3 = 2.33*, that is, the odds of success are 2
    to 1\. If the probability of success is 0.5, that is, a 50-50 chance, the odds
    of success are 1 to 1\. The logistic regression model can be mathematically represented
    as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_27.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
- en: Here, ![A drawing of a person
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'Description automatically generated](img/C12624_03_28.png) is the log of the
    odds ratio, which is also called the **logit** function. Solving the math further,
    we can deduce the probability of the outcome as shown:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_29.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
- en: Discussing the mathematical background and derivation of the equations is beyond
    the scope of this chapter. However, to summarize, the logit function, which is
    the link function (or logic function), helps logistic regression reframe the problem
    (predicted outcome) intuitively as the log of the odds ratio. This, when solved,
    helps us to predict the probability of a binary dependent variable.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Mechanics of Logistic Regression
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Just like linear regression, where the beta coefficients for the variables are
    estimated using the OLS method, the logistic regression model leverages the **maximum
    likelihood estimation** (**MLE**) method. The MLE function estimates the best
    set of values of the model parameters or beta coefficients such that it maximizes
    the likelihood function, that is, the probability estimates. It can also be defined
    as the *agreement* of the selected model with the observed data). When the best
    set of parameter values is estimated, plugging these values/beta coefficients
    into the model equation, as defined earlier, helps in estimating the probability
    of the outcome for a given sample. Akin to OLS, MLE is an iterative process.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Model Building
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like linear regression for building a logistic regression model in R, we have
    the `glm()` generalized linear model method to fit the data and logit function
    to score the observation.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'The syntax of using the glm() function is as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Here, Y is our dependent variable and X1, X2 and X3 are the independent variables.
    The argument data will take the training dataset. The family argument is set to
    binomial(link='logit'), which fits a logistic regression model.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 46: Storing the Rolling 3-Hour Average in the Beijing PM2.5 Dataset'
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will create a new variable that stores the rolling 3-hour
    average of the PM2.5 variable in the Beijing PM2.5 dataset. The rolling average
    will smoothen any noise from a reading of PM2.5.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use the `rollapply` method from the `zoo` package to complete the exercise:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Combine the `year`, `month`, `day`, and `hour` into a new variable called `datetime`:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Remove the NAs and look at the top 6 values of the `pm2.5` variable in the
    PM2.5 dataset:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output is as follows:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Store the `PM25_subset` into a `zoo` object of ordered observation with datetime
    as its index, and print the top 6 values:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output is as follows:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Use the `rollapply` function to create a 3-hour rolling average of the `pm2.5`
    variable, and print the top 6 values:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output is as follows:'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Observe that the `145.33` value is the average of three hours of the `pm2.5`
    variable, as shown in step 3 (`129`, `148`, and `159`).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 6: Transforming Variables and Deriving New Variables to Build a Model'
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this activity, we will perform a series of transformations and derive new
    variables before building the model. We need to convert the `pm2.5` variable into
    a categorical variable to apply a logistic regression model.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps need to be performed before we can build a logistic regression
    classification model:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Combine the year, month, day, and hour into a new variable called `datetime`.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the datetime variable, calculate the average of the `pm2.5` values with
    a 3-hour window. Name this new variable `PM25_three_hour_pm25_avg`.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a binary variable called `pollution_level`. It gets a value `1` if `PM25_three_hour_pm25_avg`
    is greater than `35`, else `0`.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using `pollution_level` as the dependent variable, build a logistic regression
    model.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the summary of the model.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The final output is as follows:'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 446.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Interpreting a Model
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A large part of the `glm()` output looks similar to the `lm()` method but with
    a few new values, such as the following:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '**Null deviance**'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Residual deviance**'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Akaike Information Criterion** (**AIC**)'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fisher scoring**'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to avoid scoring, all the above measures will be described in detail
    in *Chapter 5*, *Classification*.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Refer to0 the next section on *Evaluation Metrics* (the *Confusion Matrix Based
    Metrics* section) in this chapter to find an interpretation of how well the model
    has done on R-squared and adjusted R-squared metrics.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation Metrics
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will go through all the evaluation measures for assessing
    the quality of the machine learning model predictions. Based on the dependent
    variable, we have several choices for the evaluation measures. In the train and
    evaluate step of our Machine Learning Workflow, we mentioned that until we get
    the desired results, we keep iterating the training model by adding new variables
    or changing the parameters. In each iteration, we try to optimize for any one
    or two evaluation metrics. The following table summarizes the various types of
    metrics used for regression, classification, and recommender systems. Given the
    scope of this book, we will delve into more details on regression and classification
    algorithms:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.14: Metrics for various types of machine learning algorithms.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_03_14.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.14: Metrics for various types of machine learning algorithms.'
  id: totrans-266
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Mean Absolute Error (MAE)
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Absolute error is direction-agnostic, which means that it is does not matter
    whether the predicted value of the dependent variable by the model on the test
    dataset is less than or greater than the actual value. So, in our example of the
    Beijing PM2.5 dataset, MAE will give us the average absolute error (difference
    in the predicted and actual values of the dependent variable) in PM2.5 prediction
    indifferent to the direction of error (positive or negative):'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_30.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/C12624_03_31.png) is the value of the ith observation of the dependent
    variable, and ![](img/C12624_03_32.png) is the predicted or expected value.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Root Mean Squared Error (RMSE)
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Similar to MAE, root mean square error also computes the average prediction
    error. However, it is based on a quadratic scoring, where the square root of the
    average squared error is computed. Moreover, unlike MAE, which takes the absolute
    difference between the predicted and actual values, RMSE takes the square, which
    adds more weight to the high error values before taking the square root:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_33.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/C12624_03_34.png) represents the difference between the actual
    and estimated values of the dependent variable for the ith observation.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: R-squared
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: R-squared measures the percentage (value between 0 and 1 or from 0% to 100%)
    of the variance in the response variable explained by the linear model. In other
    words, it measures the variance explained by the input features. 0% R-squared
    means the model's input feature explains nothing about the response variable.
    Closer to 100% means that the model is a good predictor of the response variable.
    For example, if we want to predict the price of a house in a locality, features
    such as the number of bedrooms, area in sq. ft, and proximity to a school and
    market decides the value of a property. However, R-squared alone cannot be used
    for assessing the goodness of the model. Various diagnostic checks on residual,
    normality, and heteroscedasticity are also required. We will discuss this in detail
    in *Chapter 4*, *Regression*.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_35.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/C12624_03_36.png) is the sum of the square difference between
    the actual and estimated values of the dependent variable, while ![](img/C12624_03_37.png)
    represents the sum of the square difference between the actual and mean of the
    dependent variable.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_38.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
- en: Adjusted R-square
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we add new variables in the regression model, the R-squared value of the
    model improves as the contribution of the newer variables in explaining the variation
    of the dependent variable increases. (A counter-argument arises if the newer variables
    are poorly designed and are not relevant for explaining the dependent variable.)
    So, for the evaluation metric to be agnostic to the number of variables, we penalize
    the R-squared value by incorporating *n* and *q* (number of observations and number
    of variables, respectively) in the calculation. This is called adjusted R-squared,
    adjusted for both the number of observations and variables. It is a good practice
    to look at the adjusted R-squared when dealing with multiple linear regression.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '**MSE** (**mean squared error**):'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_39.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
- en: Here, *n* is the number of observations, and *q* is the number of coefficients
    in the model.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '**MST** (**mean squared total**):'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_40.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
- en: Mean Reciprocal Rank (MRR)
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MRR is popularly used to evaluate algorithms in search engines, recommender
    algorithms, and many other information retrieval algorithms in the digital space.
    MRR is easy to interpret. In general, it could be used to evaluate algorithms
    that produce a list of responses for an input. Examples are the search results
    you see in Google for your query and the product recommendations you see on Amazon.
    The following table shows an example of computing the reciprocal rank. MRR ranges
    from 0 to 1; a value closer to 1 indicates that the algorithm is giving relevant
    results at the top of the list.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_41.jpg)![Figure 3.15: Example of computing reciprocal rank.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_03_15.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.15: Example of computing reciprocal rank.'
  id: totrans-291
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 47: Finding Evaluation Metrics'
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will find the MAE, RMSE, R-squared, Adjusted R-squared,
    and MRR.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Import the required libraries and packages.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a variable named `y_predicted` and assign the value from the `multiple_PM25_linear_model`:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Use the following command to assign values from the `PM25` dataset:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Find the MAE using the mean function:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output is as follows:'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Next, calculate the RMSE:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is as follows:'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, calculate the R-squared value using the following command:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The output is as follows:'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Next, find the adjusted R-squared using the following command:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The output is as follows:'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Finally, use the following command to find the MRR:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output is as follows:'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Observe that MAE gives a value of `59.82` and RMSE is `82.09,` which shows a
    high variance in the errors. In other words, the observations have a high error
    (which increases the variance of the frequency distribution of error magnitudes)
    in prediction; MAE fails to identify the error, whereas RMSE amplifies it well.
    If the MAE and RMSE are almost equal, we could infer that the variance in the
    frequency distribution of error magnitudes is low and that the model is doing
    well with all the observations.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: Confusion Matrix-Based Metrics
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Confusion matrix-based metrics are used in classification algorithms. There
    are a series of metrics one could derive from the confusion matrix (also called
    the `A` and `B`. Otherwise, there is nothing negative or positive about the target
    variable. The contingency table could also be NxN, where *N* is the number of
    classes or categories in the response variable. For example, if we want to classify
    the 26 handwritten characters of the English alphabet in a given image, we need
    a 26x26 matrix:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.16: Elements of the confusion matrix.'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_03_16.jpg)'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.16: Elements of the confusion matrix.'
  id: totrans-325
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If we arrange the **TP**, **TN**, **FP**, and **FN** in a 2x2 contingency matrix,
    we obtain the confusion matrix, as shown in the following table:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.17: Confusion matrix.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_03_17.jpg)'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.17: Confusion matrix.'
  id: totrans-329
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Accuracy
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Accuracy measures the correct overall classifications by the model for both
    positive and negative examples. The sum of the diagonal elements in the matrix
    (TP and TN) divided by the total number of positive and negative observations
    gives the accuracy. Accuracy is not always a reliable metric in real-world scenarios.
    Consider that we would like to distinguish cancer CT scans from benign CT scans.
    Clearly, we may have many negative scans and few positive scans. This leads to
    what we call the **unbalanced dataset**. If the model mostly predicts benign scans
    accurately but produces a significant error in predicting cancer CT scans, the
    accuracy may still be high, but the model is not so useful.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_42.jpg)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
- en: Sensitivity
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to tackle the issue we discussed with *accuracy*, we could use a combination
    of sensitivity, also known as recall, hit rate, or **true positive rate** (**TPR**),
    and specificity (discussed in the next section). Sensitivity gives the predictive
    power of the model with respect to the positive cases (detecting cancer in a CT
    scan). We obtain sensitivity from the ratio of all **true positive** (**TP**)
    cases to the number of **positive** (**P**) cases.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_43.jpg)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
- en: Specificity
  id: totrans-336
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Specificity provides the quantitative assessment of correct predictions of negative
    examples (for example, detecting benign CT scans). We obtain sensitivity from
    the ratio of a number of true negative cases to the number of negative cases.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_44.jpg)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
- en: High sensitivity and specificity values signify a superior model. In most cases,
    we try to balance the two metrics to get the best model.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: F1 Score
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: F1 score combines precision and sensitivity by taking the harmonic mean (appropriate
    for taking averages of two or more rates) of both, as described by the following
    formulas. **Positive predictive value** (**PPV** or precision) measures the number
    of true predictions over the sum of a number of true and false positives, that
    is, how many of all the predictions of positive cases were correct.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C12624_03_45.jpg)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
- en: F1 score is more robust than accuracy but still suffers in the case of unbalanced
    classes.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: There is no good or bad metric for evaluating the goodness of a classification
    model. Machine learning practitioners usually look at a combination of many metrics
    to conclude the goodness of a model. That is why it becomes important to know
    how to interpret each of the above discussed metrics.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 48: Working with Model Evaluation on Training Data'
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will work with model evaluation on training data using
    the `confusionMatrix` function from the `caret` package. The function prints metrics
    such as accuracy, sensitivity, specificity, and many more.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: Import the required libraries and packages into the system.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a variable name `predicated` and assign the value, as illustrated here:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Next, create another variable named `actual`, as illustrated here:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Import the caret library:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Finally, use the `confusionMatrix` method to describe the performance of the
    classification model:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output is as follows:'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Many of the metrics shown in the results of the `confusionMatric()` output are
    described in this section. However, here's a quick summary before you read the
    details. The accuracy of this logistic regression model is 80%, which is good
    as per the standard. This indicates that we can predict the normal and above normal
    PM2.5 values using other environmental factors with 80% accuracy. However, note
    that the accuracy is on the entire training dataset. We have not split the data
    into two parts for checking the overfitting scenarios, a condition in which the
    model performs really good when tested on training data but shows inferior results
    on testing (or unseen) data.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: Sensitivity and specificity are 46% and 93%, respectively. This means the model
    is doing good for negative cases (1-Above normal PM2.5). Generally, there must
    be a tradeoff between these two metrics. However, in this case, the priority for
    the model is to be able to predict as many **Above Normal** states as possible.
    Hence, high specificity is desirable once we have the confusion matrix; it's possible
    to calculate all the metrics from it.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: Receiver Operating Characteristic (ROC) Curve
  id: totrans-361
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the context of classification models, the output of a prediction is obtained
    as a quantitative estimate, usually a probability measure. In a binary logistic
    regression, the usual choice of the threshold to classify one observation from
    the other (for example, spam versus non-spam) is 0.5\. This means that if the
    probability is greater than 0.5, classify it as spam and if not, non-spam. Now,
    depending on the threshold, you will get different values of TP, TN, FP, and FN
    in the confusion matrix we discussed earlier. While it is a standard practice
    to look at the confusion matrix at a given threshold (usually 0.5), it might not
    give us the complete view of whether the model will perform well in the real world,
    which is why the choice of threshold is essential.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: The ROC curve is an elegant visualization showing the variation between the
    true positive rate (often referenced by sensitivity) and the true negative rate
    (often referenced by specificity) at every possible threshold. It helps us identify
    the right threshold for classification. Also, the area under the ROC curve (referred
    to as AUC), which varies between 0 and 1, tells us how good the model is. Closer
    to 1 means that the model is successfully able to classify between positive and
    negative classes for most of the observation.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: Using the ROCR package in R, we will obtain the ROC curve for the PM2.5 prediction
    using logistic regression. Also, we will observe the AUC in the next exercise.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 49: Creating an ROC Curve'
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will use the ROCR package to obtain the ROC curve.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the ROCR package into the system using the following command:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Next, define the pred1 and pref1 objects:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Next, find the AUC using the following command:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output is as follows:'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Plot the graph using the plot command:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '![Figure 3.18: ROC curve between true positive rate (sensitivity) and false
    positive rate (specificity).'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/C12624_03_18.jpg)'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 3.18: ROC curve between true positive rate (sensitivity) and false positive
    rate (specificity).'
  id: totrans-380
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Summary
  id: totrans-381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we started out with laying the process for building a machine
    learning workflow, starting from designing the problem and moving to deploying
    the model. We briefly discussed simple and multiple and logistic regressions along
    with all the evaluation metrics needed to interpret and judge the performance
    of the model. These two algorithms demonstrate the supervised learning for regression
    and classification problems, respectively.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the chapter, we used the Beijing PM2.5 dataset to build the models.
    In the process, we also converted a regression problem to a classification problem
    by simply re-engineering the dependent variable. Such re-engineering is often
    taken up on real-world problems to suit a particular use case.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will delve into the details of regression algorithms
    and will elaborate the various types of regression algorithms beyond linear regression
    and discuss when to use which one.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
