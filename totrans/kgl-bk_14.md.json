["```py\n!pip install kaggle-environments --upgrade \n```", "```py\nfrom kaggle_environments import evaluate, make\nenv = make(\"connectx\", debug=True)\nenv.render() \n```", "```py\ndef my_agent(observation, configuration):\n    from random import choice\n    # me:me_or_enemy=1, enemy:me_or_enemy=2\n    def check_vertical_chance(me_or_enemy):\n        for i in range(0, 7):\n            if observation.board[i+7*5] == me_or_enemy \\\n            and observation.board[i+7*4] == me_or_enemy \\\n            and observation.board[i+7*3] == me_or_enemy \\\n            and observation.board[i+7*2] == 0:\n                return i\n            elif observation.board[i+7*4] == me_or_enemy \\\n            and observation.board[i+7*3] == me_or_enemy \\\n            and observation.board[i+7*2] == me_or_enemy \\\n            and observation.board[i+7*1] == 0:\n                return i\n            elif observation.board[i+7*3] == me_or_enemy \\\n            and observation.board[i+7*2] == me_or_enemy \\\n            and observation.board[i+7*1] == me_or_enemy \\\n            and observation.board[i+7*0] == 0:\n                return i\n        # no chance\n        return -99 \n```", "```py\n def check_horizontal_chance(me_or_enemy):\n        chance_cell_num = -99\n        for i in [0,7,14,21,28,35]:\n            for j in range(0, 4):\n                val_1 = i+j+0\n                val_2 = i+j+1\n                val_3 = i+j+2\n                val_4 = i+j+3\n                if sum([observation.board[val_1] == me_or_enemy, \\\n                        observation.board[val_2] == me_or_enemy, \\\n                        observation.board[val_3] == me_or_enemy, \\\n                        observation.board[val_4] == me_or_enemy]) == 3:\n                    for k in [val_1,val_2,val_3,val_4]:\n                        if observation.board[k] == 0:\n                            chance_cell_num = k\n                            # bottom line\n                            for l in range(35, 42):\n                                if chance_cell_num == l:\n                                    return l - 35\n                            # others\n                            if observation.board[chance_cell_num+7] != 0:\n                                return chance_cell_num % 7\n        # no chance\n        return -99 \n```", "```py\n# me:me_or_enemy=1, enemy:me_or_enemy=2\ndef check_slanting_chance(me_or_enemy, lag, cell_list):\n        chance_cell_num = -99\n        for i in cell_list:\n            val_1 = i+lag*0\n            val_2 = i+lag*1\n            val_3 = i+lag*2\n            val_4 = i+lag*3\n            if sum([observation.board[val_1] == me_or_enemy, \\\n                    observation.board[val_2] == me_or_enemy, \\\n                    observation.board[val_3] == me_or_enemy, \\\n                    observation.board[val_4] == me_or_enemy]) == 3:\n                for j in [val_1,val_2,val_3,val_4]:\n                    if observation.board[j] == 0:\n                        chance_cell_num = j\n                        # bottom line\n                        for k in range(35, 42):\n                            if chance_cell_num == k:\n                                return k - 35\n                        # others\n                        if chance_cell_num != -99 \\\n                        and observation.board[chance_cell_num+7] != 0:\n                            return chance_cell_num % 7\n        # no chance\n        return -99 \n```", "```py\n def check_my_chances():\n        # check my vertical chance\n        result = check_vertical_chance(my_num)\n        if result != -99:\n            return result\n        # check my horizontal chance\n        result = check_horizontal_chance(my_num)\n        if result != -99:\n            return result\n        # check my slanting chance 1 (up-right to down-left)\n        result = check_slanting_chance(my_num, 6, [3,4,5,6,10,11,12,13,17,18,19,20])\n        if result != -99:\n            return result\n        # check my slanting chance 2 (up-left to down-right)\n        result = check_slanting_chance(my_num, 8, [0,1,2,3,7,8,9,10,14,15,16,17])\n        if result != -99:\n            return result\n        # no chance\n        return -99 \n```", "```py\nenv.reset()\nenv.run([my_agent, \"random\"])\nenv.render(mode=\"ipython\", width=500, height=450) \n```", "```py\n%%writefile submission.py\nimport random\ndef nash_equilibrium_agent(observation, configuration):\n    return random.randint(0, 2) \n```", "```py\n!pip install -q -U kaggle_environments\nfrom kaggle_environments import make \n```", "```py\nenv = make(\n    \"rps\", \n    configuration={\"episodeSteps\": 1000}\n) \n```", "```py\n%%writefile submission_copy_opponent.py\ndef copy_opponent_agent(observation, configuration):\n    if observation.step > 0:\n        return observation.lastOpponentAction\n    else:\n        return 0\n# nash_equilibrium_agent vs copy_opponent_agent\nenv.run(\n    [\"submission.py\", \"submission_copy_opponent.py\"]\n)\nenv.render(mode=\"ipython\", width=500, height=400) \n```", "```py\n%%writefile submission.py\nimport json\nimport numpy as np\nimport pandas as pd\nbandit_state = None\ntotal_reward = 0\nlast_step = None \n```", "```py\ndef multi_armed_bandit_agent (observation, configuration):\n    global history, history_bandit\n    step = 1.0         # balance exploration / exploitation\n    decay_rate = 0.97  # how much do we decay the win count after each call\n\n    global bandit_state,total_reward,last_step\n\n    if observation.step == 0:\n        # initial bandit state\n        bandit_state = [[1,1] for i in range(configuration[\"banditCount\"])]\n    else:       \n        # updating bandit_state using the result of the previous step\n        last_reward = observation[\"reward\"] - total_reward\n        total_reward = observation[\"reward\"]\n\n        # we need to understand who we are Player 1 or 2\n        player = int(last_step == observation.lastActions[1])\n\n        if last_reward > 0:\n            bandit_state[observation.lastActions[player]][0] += last_reward * step\n        else:\n            bandit_state[observation.lastActions[player]][1] += step\n\n        bandit_state[observation.lastActions[0]][0] = (bandit_state[observation.lastActions[0]][0] - 1) * decay_rate + 1\n        bandit_state[observation.lastActions[1]][0] = (bandit_state[observation.lastActions[1]][0] - 1) * decay_rate + 1\n    # generate random number from Beta distribution for each agent and select the most lucky one\n    best_proba = -1\n    best_agent = None\n    for k in range(configuration[\"banditCount\"]):\n        proba = np.random.beta(bandit_state[k][0],bandit_state[k][1])\n        if proba > best_proba:\n            best_proba = proba\n            best_agent = k\n\n    last_step = best_agent\n    return best_agent \n```", "```py\n%%writefile random_agent.py\nimport random\ndef random_agent(observation, configuration):\n    return random.randrange(configuration.banditCount)\nfrom kaggle_environments import make\nenv = make(\"mab\", debug=True)\nenv.reset()\nenv.run([\"random_agent.py\", \"submission.py\"])\nenv.render(mode=\"ipython\", width=800, height=700) \n```"]