- en: Chapter 10. Object Recognition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章. 对象识别
- en: In this chapter, we are going to learn about object recognition and how we can
    use it to build a visual search engine. We will discuss feature detection, building
    feature vectors, and using machine learning to build a classifier. We will learn
    how to use these different blocks to build an object recognition system.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习对象识别以及如何使用它来构建视觉搜索引擎。我们将讨论特征检测、构建特征向量以及使用机器学习来构建分类器。我们将学习如何使用这些不同的模块来构建一个对象识别系统。
- en: 'By the end of this chapter, you will know:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将知道：
- en: What is the difference between object detection and object recognition
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象检测与对象识别的区别是什么
- en: What is a dense feature detector
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是密集特征检测器
- en: What is a visual dictionary
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是视觉词典
- en: How to build a feature vector
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建特征向量
- en: What is supervised and unsupervised learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是监督学习和无监督学习
- en: What are Support Vector Machines and how to use them to build a classifier
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是支持向量机以及如何使用它们来构建分类器
- en: How to recognize an object in an unknown image
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在未知图像中识别一个对象
- en: Object detection versus object recognition
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对象检测与对象识别的比较
- en: Before we proceed, we need to understand what we are going to discuss in this
    chapter. You must have frequently heard the terms "object detection" and "object
    recognition", and they are often mistaken to be the same thing. There is a very
    distinct difference between the two.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，我们需要了解本章将要讨论的内容。你一定经常听到“对象检测”和“对象识别”这两个术语，并且它们经常被误认为是同一件事。两者之间有一个非常明显的区别。
- en: Object detection refers to detecting the presence of a particular object in
    a given scene. We don't know what the object might be. For instance, we discussed
    face detection in [Chapter 4](ch04.html "Chapter 4. Detecting and Tracking Different
    Body Parts"), *Detecting and Tracking Different Body Parts*. During the discussion,
    we only detected whether or not a face is present in the given image. We didn't
    recognize the person! The reason we didn't recognize the person is because we
    didn't care about that in our discussion. Our goal was to find the location of
    the face in the given image. Commercial face recognition systems employ both face
    detection and face recognition to identify a person. First, we need to locate
    the face, and then, run the face recognizer on the cropped face.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对象检测是指检测给定场景中特定对象的存在。我们不知道这个对象可能是什么。例如，我们在[第4章](ch04.html "第4章. 检测和跟踪不同的身体部位")中讨论了人脸检测，*检测和跟踪不同的身体部位*。在讨论中，我们只检测了给定图像中是否存在人脸。我们没有识别出这个人！我们没有识别出这个人的原因是我们在讨论中并不关心这一点。我们的目标是找到给定图像中人脸的位置。商业人脸识别系统同时使用人脸检测和人脸识别来识别一个人。首先，我们需要定位人脸，然后，在裁剪的人脸上进行人脸识别。
- en: Object recognition is the process of identifying an object in a given image.
    For instance, an object recognition system can tell you if a given image contains
    a dress or a pair of shoes. In fact, we can train an object recognition system
    to identify many different objects. The problem is that object recognition is
    a really difficult problem to solve. It has eluded computer vision researchers
    for decades now, and has become the holy grail of computer vision. Humans can
    identify a wide variety of objects very easily. We do it everyday and we do it
    effortlessly, but computers are unable to do it with that kind of accuracy.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对象识别是在给定图像中识别对象的过程。例如，一个对象识别系统可以告诉你一个给定的图像是否包含连衣裙或一双鞋。实际上，我们可以训练一个对象识别系统来识别许多不同的对象。问题是对象识别是一个真正难以解决的问题。它已经让计算机视觉研究人员困惑了几十年，并已成为计算机视觉的圣杯。人类可以很容易地识别各种各样的对象。我们每天都在做，而且毫不费力，但计算机无法以那种精度做到这一点。
- en: 'Let''s consider the following image of a latte cup:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下咖啡杯的图像：
- en: '![Object detection versus object recognition](img/B04554_10_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![对象检测与对象识别](img/B04554_10_01.jpg)'
- en: 'An object detector will give you the following information:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对象检测器会给你以下信息：
- en: '![Object detection versus object recognition](img/B04554_10_02.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![对象检测与对象识别](img/B04554_10_02.jpg)'
- en: 'Now, consider the following image of a teacup:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑以下茶杯的图像：
- en: '![Object detection versus object recognition](img/B04554_10_03.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![对象检测与对象识别](img/B04554_10_03.jpg)'
- en: 'If you run it through an object detector, you will see the following result:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行它通过对象检测器，你会看到以下结果：
- en: '![Object detection versus object recognition](img/B04554_10_04.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![对象检测与对象识别](img/B04554_10_04.jpg)'
- en: 'As you can see, the object detector detects the presence of the teacup, but
    nothing more than that. If you train an object recognizer, it will give you the
    following information, as shown in the image below:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，对象检测器检测到了茶杯的存在，但仅此而已。如果您训练一个对象识别器，它将提供以下信息，如下面的图像所示：
- en: '![Object detection versus object recognition](img/B04554_10_05.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![对象检测与对象识别](img/B04554_10_05.jpg)'
- en: 'If you consider the second image, it will give you the following information:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您考虑第二张图像，它将为您提供以下信息：
- en: '![Object detection versus object recognition](img/B04554_10_06.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![对象检测与对象识别](img/B04554_10_06.jpg)'
- en: As you can see, a perfect object recognizer would give you all the information
    associated with that object. An object recognizer functions more accurately if
    it knows where the object is located. If you have a big image and the cup is a
    small part of it, then the object recognizer might not be able to recognize it.
    Hence, the first step is to detect the object and get the bounding box. Once we
    have that, we can run an object recognizer to extract more information.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，一个完美的对象识别器会为您提供与该对象相关的所有信息。如果对象识别器知道对象的位置，它将运行得更准确。如果您有一个大图像，而杯子只是其中的一小部分，那么对象识别器可能无法识别它。因此，第一步是检测对象并获取边界框。一旦我们有了这个，我们就可以运行对象识别器来提取更多信息。
- en: What is a dense feature detector?
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是密集特征检测器？
- en: 'In order to extract a meaningful amount of information from the images, we
    need to make sure our feature extractor extracts features from all the parts of
    a given image. Consider the following image:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从图像中提取有意义的信息，我们需要确保我们的特征提取器能够从给定图像的所有部分提取特征。考虑以下图像：
- en: '![What is a dense feature detector?](img/B04554_10_07.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![什么是密集特征检测器？](img/B04554_10_07.jpg)'
- en: 'If you extract features using a feature extractor, it will look like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用特征提取器提取特征，它将看起来像这样：
- en: '![What is a dense feature detector?](img/B04554_10_08.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![什么是密集特征检测器？](img/B04554_10_08.jpg)'
- en: 'If you use `Dense` detector, it will look like this:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用`Dense`检测器，它将看起来像这样：
- en: '![What is a dense feature detector?](img/B04554_10_09.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![什么是密集特征检测器？](img/B04554_10_09.jpg)'
- en: 'We can control the density as well. Let''s make it sparse:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以控制密度。让我们将其变为稀疏的：
- en: '![What is a dense feature detector?](img/B04554_10_10.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![什么是密集特征检测器？](img/B04554_10_10.jpg)'
- en: 'By doing this, we can make sure that every single part in the image is processed.
    Here is the code to do it:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，我们可以确保图像的每个部分都被处理。以下是实现此功能的代码：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This gives us close control over the amount of information that gets extracted.
    When we use a SIFT detector, some parts of the image are neglected. This works
    well when we are dealing with the detection of prominent features, but when we
    are building an object recognizer, we need to evaluate all parts of the image.
    Hence, we use a dense detector and then extract features from those keypoints.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够对提取的信息量进行更精确的控制。当我们使用SIFT检测器时，图像的一些部分会被忽略。当我们处理显著特征的检测时，这效果很好，但当我们构建对象识别器时，我们需要评估图像的所有部分。因此，我们使用密集检测器，然后从这些关键点中提取特征。
- en: What is a visual dictionary?
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是视觉词典？
- en: 'We will be using the **Bag of Words** model to build our object recognizer.
    Each image is represented as a histogram of visual words. These visual words are
    basically the **N** centroids built using all the keypoints extracted from training
    images. The pipeline is as shown in the image that follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**词袋模型**来构建我们的对象识别器。每个图像都表示为视觉词的直方图。这些视觉词基本上是使用从训练图像中提取的所有关键点构建的**N**个质心。流程如图所示：
- en: '![What is a visual dictionary?](img/B04554_10_11.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![什么是视觉词典？](img/B04554_10_11.jpg)'
- en: From each training image, we detect a set of keypoints and extract features
    for each of those keypoints. Every image will give rise to a different number
    of keypoints. In order to train a classifier, each image must be represented using
    a fixed length feature vector. This feature vector is nothing but a histogram,
    where each bin corresponds to a visual word.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从每个训练图像中，我们检测一组关键点并为每个关键点提取特征。每个图像都会产生不同数量的关键点。为了训练一个分类器，每个图像必须使用固定长度的特征向量来表示。这个特征向量实际上就是一个直方图，其中每个bin对应一个视觉词。
- en: When we extract all the features from all the keypoints in the training images,
    we perform K-Means clustering and extract N centroids. This N is the length of
    the feature vector of a given image. Each image will now be represented as a histogram,
    where each bin corresponds to one of the 'N' centroids. For simplicity, let's
    say that N is set to 4\. Now, in a given image, we extract **K** keypoints. Out
    of these K keypoints, some of them will be closest to the first centroid, some
    of them will be closest to the second centroid, and so on. So, we build a histogram
    based on the closest centroid to each keypoint. This histogram becomes our feature
    vector. This process is called **vector quantization**.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们从训练图像中的所有关键点中提取所有特征后，我们执行K-Means聚类并提取N个质心。这个N是给定图像特征向量的长度。现在，每张图像都将表示为一个直方图，其中每个bin对应于这“N”个质心中的一个。为了简单起见，让我们假设N设置为4。现在，在给定的图像中，我们提取**K**个关键点。在这些K个关键点中，一些将最接近第一个质心，一些将最接近第二个质心，依此类推。因此，我们根据每个关键点最近质心构建直方图。这个直方图成为我们的特征向量。这个过程被称为**向量量化**。
- en: 'To understand vector quantization, let''s consider an example. Assume we have
    an image and we''ve extracted a certain number of feature points from it. Now
    our goal is to represent this image in the form of a feature vector. Consider
    the following image:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解向量量化，让我们考虑一个例子。假设我们有一个图像，并且我们已经从中提取了一定数量的特征点。现在我们的目标是将以特征向量的形式表示这张图像。考虑以下图像：
- en: '![What is a visual dictionary?](img/B04554_10_12.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![什么是视觉词典？](img/B04554_10_12.jpg)'
- en: 'As you can see, we have 4 centroids. Bear in mind that the points shown in
    the figures represent the feature space and not the actual geometric locations
    of those feature points in the image. It is shown this way in the preceding figure
    so that it''s easy to visualize. Points from many different geometric locations
    in an image can be close to each other in the feature space. Our goal is to represent
    this image as a histogram, where each bin corresponds to one of these centroids.
    This way, no matter how many feature points we extract from an image, it will
    always be converted to a fixed length feature vector. So, we "round off" each
    feature point to its nearest centroid, as shown in the next image:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们有4个质心。请记住，图中的点代表特征空间，而不是这些特征点在图像中的实际几何位置。前一个图中的展示方式是为了便于可视化。来自图像中许多不同几何位置的点可以在特征空间中彼此靠近。我们的目标是表示这张图像为直方图，其中每个bin对应于这些质心中的一个。这样，无论我们从图像中提取多少特征点，它都将始终转换为固定长度的特征向量。因此，我们将每个特征点“四舍五入”到其最近的质心，如图中所示：
- en: '![What is a visual dictionary?](img/B04554_10_13.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![什么是视觉词典？](img/B04554_10_13.jpg)'
- en: 'If you build a histogram for this image, it will look like this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你为这张图像构建直方图，它将看起来像这样：
- en: '![What is a visual dictionary?](img/B04554_10_14.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![什么是视觉词典？](img/B04554_10_14.jpg)'
- en: 'Now, if you consider a different image with a different distribution of feature
    points, it will look like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你考虑一个具有不同特征点分布的不同图像，它将看起来像这样：
- en: '![What is a visual dictionary?](img/B04554_10_15.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![什么是视觉词典？](img/B04554_10_15.jpg)'
- en: 'The clusters would look like the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这些簇看起来如下：
- en: '![What is a visual dictionary?](img/B04554_10_16.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![什么是视觉词典？](img/B04554_10_16.jpg)'
- en: 'The histogram would look like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图将看起来像这样：
- en: '![What is a visual dictionary?](img/B04554_10_17.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![什么是视觉词典？](img/B04554_10_17.jpg)'
- en: As you can see, the histograms are very different for the two images even though
    the points seem to be randomly distributed. This is a very powerful technique
    and it's widely used in computer vision and signal processing. There are many
    different ways to do this and the accuracy depends on how fine-grained you want
    it to be. If you increase the number of centroids, you will be able to represent
    the image better, thereby increasing the uniqueness of your feature vector. Having
    said that, it's important to mention that you cannot just keep increasing the
    number of centroids indefinitely. If you do that, it will become too noisy and
    lose its power.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，尽管点似乎随机分布，但这两个图像的直方图非常不同。这是一个非常强大的技术，并且在计算机视觉和信号处理中得到广泛应用。有许多不同的方法来做这件事，准确性取决于你希望它有多精细。如果你增加质心的数量，你将能够更好地表示图像，从而增加特征向量的唯一性。话虽如此，重要的是要提到，你不能无限制地增加质心的数量。如果你这样做，它将变得过于嘈杂并失去其力量。
- en: What is supervised and unsupervised learning?
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是监督学习和无监督学习？
- en: If you are familiar with the basics of machine learning, you will certainly
    know what supervised and unsupervised learning is all about. To give a quick refresher,
    supervised learning refers to building a function based on labeled samples. For
    example, if we are building a system to separate dress images from footwear images,
    we first need to build a database and label it. We need to tell our algorithm
    what images correspond to dresses and what images correspond to footwear. Based
    on this data, the algorithm will learn how to identify dresses and footwear so
    that when an unknown image comes in, it can recognize what's inside that image.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您熟悉机器学习的基础知识，您当然会知道监督学习和无监督学习是什么。为了快速回顾，监督学习是指基于标记样本构建一个函数。例如，如果我们正在构建一个系统来区分服装图像和鞋类图像，我们首先需要建立一个数据库并对它进行标记。我们需要告诉我们的算法哪些图像对应于服装，哪些图像对应于鞋类。基于这些数据，算法将学习如何识别服装和鞋类，以便当未知图像进入时，它可以识别图像中的内容。
- en: Unsupervised learning is the opposite of what we just discussed. There is no
    labeled data available here. Let's say we have a bunch of images, and we just
    want to separate them into three groups. We don't know what the criteria will
    be. So, an unsupervised learning algorithm will try to separate the given set
    of data into 3 groups in the best possible way. The reason we are discussing this
    is because we will be using a combination of supervised and unsupervised learning
    to build our object recognition system.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习是我们刚才讨论内容的反面。这里没有可用的标记数据。假设我们有一堆图像，我们只想将它们分成三个组。我们不知道标准是什么。因此，无监督学习算法将尝试以最佳方式将给定数据集分成3组。我们讨论这个问题的原因是因为我们将使用监督学习和无监督学习的组合来构建我们的目标识别系统。
- en: What are Support Vector Machines?
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是支持向量机？
- en: '**Support Vector Machines** (**SVM**) are supervised learning models that are
    very popular in the realm of machine learning. SVMs are really good at analyzing
    labeled data and detecting patterns. Given a bunch of data points and the associated
    labels, SVMs will build the separating hyperplanes in the best possible way.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**（**SVM**）是机器学习领域中非常流行的监督学习模型。SVM在分析标记数据和检测模式方面非常出色。给定一些数据点和相关的标签，SVM将以最佳方式构建分隔超平面。'
- en: 'Wait a minute, what are "hyperplanes"? To understand that, let''s consider
    the following figure:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 等一下，什么是“超平面”？为了理解这一点，让我们考虑以下图示：
- en: '![What are Support Vector Machines?](img/B04554_10_18.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![什么是支持向量机？](img/B04554_10_18.jpg)'
- en: As you can see, the points are being separated by line boundaries that are equidistant
    from the points. This is easy to visualize in 2 dimensions. If it were in 3 dimensions,
    the separators would be planes. When we build features for images, the length
    of the feature vectors is usually in the six-digit range. So, when we go to such
    a high dimensional space, the equivalent of "lines" would be hyperplanes. Once
    the hyperplanes are formulated, we use this mathematical model to classify unknown
    data, based on where it falls on this map.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，点被等距离于点的线边界分开。在二维空间中这很容易可视化。如果是在三维空间中，分隔器将是平面。当我们为图像构建特征时，特征向量的长度通常在六位数范围内。因此，当我们进入这样一个高维空间时，“线”的等价物将是超平面。一旦超平面被确定，我们就使用这个数学模型来根据数据在这个地图上的位置对未知数据进行分类。
- en: What if we cannot separate the data with simple straight lines?
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果我们无法用简单的直线分离数据怎么办？
- en: 'There is something called the **kernel trick** that we use in SVMs. Consider
    the following image:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在支持向量机（SVM）中，有一种称为**核技巧**的东西。考虑以下图像：
- en: '![What if we cannot separate the data with simple straight lines?](img/B04554_10_19.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![如果我们不能用简单的直线分离数据怎么办？](img/B04554_10_19.jpg)'
- en: 'As we can see, we cannot draw a simple straight line to separate the red points
    from the blue points. Coming up with a nice curvy boundary that will satisfy all
    the points is prohibitively expensive. SVMs are really good at drawing "straight
    lines". So, what''s our answer here? The good thing about SVMs is that they can
    draw these "straight lines" in any number of dimensions. So technically, if you
    project these points into a high dimensional space, where they can separated by
    a simple hyperplane, SVMs will come up with an exact boundary. Once we have that
    boundary, we can project it back to the original space. The projection of this
    hyperplane on our original lower dimensional space looks curvy, as we can see
    in the next figure:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们不能简单地画一条直线来将红色点与蓝色点分开。提出一个能满足所有点的优美曲线边界是过于昂贵的。SVMs（支持向量机）在画“直线”方面真的很擅长。那么，我们的答案是什么？SVMs（支持向量机）的好处是它们可以在任意数量的维度上画这些“直线”。所以从技术上讲，如果你将这些点投影到一个高维空间中，在那里它们可以通过一个简单的超平面分开，SVMs（支持向量机）将提出一个精确的边界。一旦我们有了这个边界，我们就可以将其投影回原始空间。这个超平面在我们原始的低维空间上的投影看起来是弯曲的，正如我们在下一张图中可以看到的：
- en: '![What if we cannot separate the data with simple straight lines?](img/B04554_10_20.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![如果我们不能用简单的直线分离数据怎么办？](img/B04554_10_20.jpg)'
- en: The topic of SVMs is really deep and we will not be able to discuss it in detail
    here. If you are really interested, there is a ton of material available online.
    You can go through a simple tutorial to understand it better.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: SVMs（支持向量机）的主题真的很深奥，我们在这里无法详细讨论。如果你真的感兴趣，网上有大量的资料可供参考。你可以通过一个简单的教程来更好地理解它。
- en: How do we actually implement this?
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们实际上是如何实现这个的？
- en: We have now arrived at the core. The discussion up until now was necessary because
    it gives you the background required to build an object recognition system. Now,
    let's build an object recognizer that can recognize whether the given image contains
    a dress, a pair of shoes, or a bag. We can easily extend this system to detect
    any number of items. We are starting with three distinct items so that you can
    start experimenting with it later.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经到达了核心。到目前为止的讨论是必要的，因为它为你提供了构建物体识别系统所需的背景知识。现在，让我们构建一个可以识别给定图像是否包含连衣裙、一双鞋或一个包的物体识别器。我们可以轻松地将这个系统扩展到检测任意数量的物品。我们从一个不同的三个物品开始，这样你以后可以开始实验。
- en: Before we start, we need to make sure that we have a set of training images.
    There are many databases available online where the images are already arranged
    into groups. Caltech256 is perhaps one of the most popular databases for object
    recognition. You can download it from [http://www.vision.caltech.edu/Image_Datasets/Caltech256](http://www.vision.caltech.edu/Image_Datasets/Caltech256).
    Create a folder called `images` and create three subfolders inside it, that is,
    `dress`, `footwear`, and `bag`. Inside each of those subfolders, add 20 images
    corresponding to that item. You can just download these images from the internet,
    but make sure those images have a clean background.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们需要确保我们有一组训练图像。网上有许多数据库可供下载，其中图像已经被分组成组。Caltech256可能是物体识别中最受欢迎的数据库之一。你可以从[http://www.vision.caltech.edu/Image_Datasets/Caltech256](http://www.vision.caltech.edu/Image_Datasets/Caltech256)下载它。创建一个名为`images`的文件夹，并在其中创建三个子文件夹，即`dress`、`footwear`和`bag`。在每个这些子文件夹中，添加对应物品的20张图像。你可以直接从互联网上下载这些图像，但请确保这些图像有干净的背景。
- en: 'For example, a dress image would like this:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一件连衣裙的图片可能如下所示：
- en: '![How do we actually implement this?](img/B04554_10_21.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![我们实际上是如何实现这个的？](img/B04554_10_21.jpg)'
- en: 'A footwear image would look like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一双鞋的图片可能如下所示：
- en: '![How do we actually implement this?](img/B04554_10_22.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![我们实际上是如何实现这个的？](img/B04554_10_22.jpg)'
- en: 'A bag image would look like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包的图片可能如下所示：
- en: '![How do we actually implement this?](img/B04554_10_23.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![我们实际上是如何实现这个的？](img/B04554_10_23.jpg)'
- en: Now that we have 60 training images, we are ready to start. As a side note,
    object recognition systems actually need tens of thousands of training images
    in order to perform well in the real world. Since we are building an object recognizer
    to detect 3 types of objects, we will take only 20 training images per object.
    Adding more training images will increase the accuracy and robustness of our system.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了60张训练图像，我们准备开始。作为旁注，物体识别系统实际上需要成千上万张训练图像才能在现实世界中表现良好。由于我们正在构建一个用于检测3种物体的物体识别器，我们将为每种物体只取20张训练图像。增加更多的训练图像将提高我们系统的准确性和鲁棒性。
- en: 'The first step here is to extract feature vectors from all the training images
    and build the visual dictionary (also known as codebook). Here is the code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的第一步是从所有训练图像中提取特征向量并构建视觉字典（也称为代码簿）。以下是代码：
- en: '[PRE1]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: What happened inside the code?
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码内部发生了什么？
- en: The first thing we need to do is extract the centroids. This is how we are going
    to build our visual dictionary. The `get_centroids` method in the `FeatureExtractor`
    class is designed to do this. We keep collecting the image features extracted
    from keypoints until we have a sufficient number of them. Since we are using a
    dense detector, 10 images should be sufficient. The reason we are just taking
    10 images is because they will give rise to a large number of features. The centroids
    will not change much even if you add more feature points.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要做的是提取质心。这是我们构建视觉字典的方法。`FeatureExtractor`类中的`get_centroids`方法被设计用来做这件事。我们持续收集从关键点提取的图像特征，直到我们拥有足够多的特征。由于我们使用的是密集检测器，10张图像应该足够了。我们只取10张图像的原因是，它们会产生大量的特征。即使你添加更多的特征点，质心也不会有太大的变化。
- en: Once we've extracted the centroids, we are ready to move on to the next step
    of feature extraction. The set of centroids is our visual dictionary. The function,
    `extract_feature_map`, will extract a feature vector from each image and associate
    it with the corresponding label. The reason we do this is because we need this
    mapping to train our classifier. We need a set of datapoints, and each datapoint
    should be associated with a label. So, we start from an image, extract the feature
    vector, and then associate it with the corresponding label (like bag, dress, or
    footwear).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们提取了质心，我们就准备好进行下一步的特征提取。质心集合是我们的视觉字典。`extract_feature_map`函数将从每个图像中提取特征向量，并将其与相应的标签关联起来。我们这样做的原因是我们需要这种映射来训练我们的分类器。我们需要一组数据点，并且每个数据点都应该与一个标签相关联。因此，我们从图像开始，提取特征向量，然后将其与相应的标签（如包、连衣裙或鞋类）关联起来。
- en: The `Quantizer` class is designed to achieve vector quantization and build the
    feature vector. For each keypoint extracted from the image, the `get_feature_vector`
    method finds the closest visual word in our dictionary. By doing this, we end
    up building a histogram based on our visual dictionary. Each image is now represented
    as a combination from a set of visual words. Hence the name, **Bag of Words**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`Quantizer`类被设计用来实现向量量化并构建特征向量。对于从图像中提取的每个关键点，`get_feature_vector`方法会找到我们字典中最接近的视觉词。通过这样做，我们最终基于我们的视觉字典构建了一个直方图。现在每个图像都表示为视觉词集合的组合。因此得名，**词袋模型**。'
- en: 'The next step is to train the classifier using these features. Here is the
    code:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用这些特征来训练分类器。以下是代码：
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: How did we build the trainer?
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们是如何构建训练器的？
- en: 'We use the `scikit-learn` package to build the SVM model. You can install it,
    as shown next:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`scikit-learn`包来构建SVM模型。你可以按照下面的步骤进行安装：
- en: '[PRE3]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We start with labeled data and feed it to the `OneVsOneClassifier` method. We
    have a `classify` method that classifies an input image and associates a label
    with it.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从标记数据开始，并将其馈送到`OneVsOneClassifier`方法。我们有一个`classify`方法，它可以对输入图像进行分类并将其与标签关联起来。
- en: 'Let''s give this a trial run, shall we? Make sure you have a folder called
    `images`, where you have the training images for the three classes. Create a folder
    called `models`, where the learning models will be stored. Run the following commands
    on your terminal to create the features and train the classifier:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试运行一下，怎么样？确保你有一个名为`images`的文件夹，其中包含三个类别的训练图像。创建一个名为`models`的文件夹，用于存储学习模型。在你的终端上运行以下命令以创建特征并训练分类器：
- en: '[PRE4]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now that the classifier has been trained, we just need a module to classify
    the input image and detect the object inside. Here is the code to do it:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在分类器已经训练好了，我们只需要一个模块来对输入图像进行分类并检测其中的物体。以下是实现这一功能的代码：
- en: '[PRE5]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We are all set! We just extract the `feature` vector from the input image and
    use it as the input argument to the classifier. Let''s go ahead and see if this
    works. Download a random footwear image from the internet and make sure it has
    a clean background. Run the following command by replacing `new_image.jpg` with
    the right filename:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备就绪！我们只需从输入图像中提取`特征`向量，并将其作为分类器的输入参数。让我们继续看看这行不行。从互联网上下载一张随机的鞋类图像，并确保它有一个干净的背景。用以下命令替换`new_image.jpg`为正确的文件名：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can use the same technique to build a visual search engine. A visual search
    engine looks at the input image and shows a bunch of images that are similar to
    it. We can reuse the object recognition framework to build this. Extract the feature
    vector from the input image, and compare it with all the feature vectors in the
    training dataset. Pick out the top matches and display the results. This is a
    simple way of doing things!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用相同的技巧来构建一个视觉搜索引擎。视觉搜索引擎会查看输入图像，并显示一系列与它相似的图像。我们可以重用物体识别框架来构建这个系统。从输入图像中提取特征向量，并将其与训练数据集中的所有特征向量进行比较。挑选出最匹配的，并显示结果。这是一种简单的方法！
- en: In the real world, we have to deal with billions of images. So, you cannot afford
    to search through every single image before you display the output. There are
    a lot of algorithms that are used to make sure that this is efficient and fast
    in the real world. Deep Learning is being used extensively in this field and it
    has shown a lot of promise in recent years. It is a branch of machine learning
    that focuses on learning optimal representation of data, so that it becomes easier
    for the machines to *learn* new tasks. You can learn more about it at [http://deeplearning.net](http://deeplearning.net).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，我们必须处理数十亿张图片。因此，在你展示输出之前，不可能逐张搜索每一张图片。有许多算法被用来确保在现实世界中这个过程既高效又快速。深度学习在这个领域被广泛使用，并且在近年来展现出了巨大的潜力。它是机器学习的一个分支，专注于学习数据的最佳表示，使得机器更容易*学习*新的任务。你可以在[http://deeplearning.net](http://deeplearning.net)了解更多相关信息。
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to build an object recognition system. The differences
    between object detection and object recognition were discussed in detail. We learned
    about the dense feature detector, visual dictionary, vector quantization, and
    how to use these concepts to build a feature vector. The concepts of supervised
    and unsupervised learning were discussed. We talked about Support Vector Machines
    and how we can use them to build a classifier. We learned how to recognize an
    object in an unknown image, and how we can extend that concept to build a visual
    search engine.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何构建一个物体识别系统。物体检测和物体识别之间的区别被详细讨论。我们学习了密集特征检测器、视觉词典、矢量量化，以及如何使用这些概念来构建特征向量。我们还讨论了监督学习和无监督学习。我们讨论了支持向量机，以及我们如何使用它们来构建分类器。我们学习了如何在未知图像中识别物体，以及如何将这一概念扩展以构建视觉搜索引擎。
- en: In the next chapter, we are going to discuss stereo imaging and 3D reconstruction.
    We will talk about how we can build a depth map and extract the 3D information
    from a given scene.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论立体成像和3D重建。我们将讨论如何构建深度图并从给定的场景中提取3D信息。
