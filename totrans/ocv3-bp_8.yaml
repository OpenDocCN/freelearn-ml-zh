- en: Chapter 7. Gyroscopic Video Stabilization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 陀螺仪视频稳定化
- en: Video stabilization is a classic problem in computer vision. The idea is simple
    – you have a video stream that's shaky, and you're trying to identify the best
    way to negate the motion of the camera to produce a smooth motion across images.
    The resulting video is easier to view and has a cinematic look.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 视频稳定化是计算机视觉中的一个经典问题。其理念很简单——你有一个摇曳的视频流，你试图找到最佳方法来消除相机的运动，以在图像之间产生平滑的运动。结果视频更容易观看，并且具有电影般的视觉效果。
- en: Over the years, there have been a number of approaches being tried to solve
    this. Videos have traditionally been stabilized by using data available only from
    images, or using specialized hardware to negate physical motion in the camera.
    Gyroscopes in mobile devices are the middle ground between these two approaches.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几年里，已经尝试了多种方法来解决这一问题。传统上，视频是通过使用仅从图像中可用的数据或使用专用硬件来消除相机中的物理运动来进行稳定的。移动设备中的陀螺仪介于这两种方法之间。
- en: 'In this chapter, we''ll cover the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: An Android camera application to record media and gyroscope traces
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Android相机应用程序来记录媒体和陀螺仪轨迹
- en: Using the video and gyroscope trace to find mathematical unknowns
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用视频和陀螺仪轨迹来寻找数学未知数
- en: Using the physical camera unknowns to compensate for camera motion
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用物理相机未知数来补偿相机运动
- en: Identifying rolling shutter in the camera
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别相机中的滚动快门
- en: Note
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Rolling shutter on a camera sensor produces unwanted effects. We'll cover this
    in detail in a later section. Also, refer to [Chapter 1](part0015_split_000.html#E9OE2-940925703e144daa867f510896bffb69
    "Chapter 1. Getting the Most out of Your Camera System"), *Getting the Most out
    of Your Camera System*, for a detailed discussion.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 相机传感器上的滚动快门会产生不希望的效果。我们将在后面的部分详细讨论这个问题。同时，请参阅[第1章](part0015_split_000.html#E9OE2-940925703e144daa867f510896bffb69
    "第1章. 最大限度地发挥您的相机系统的作用")，*最大限度地发挥您的相机系统的作用*，以获取详细讨论。
- en: Before we get started, let's take a look at some techniques that were used in
    the past to solve this problem.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们看看过去用来解决这个问题的一些技术。
- en: Stabilization with images
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用图像进行稳定化
- en: Video stabilization with images alone seems like the first logical step. Indeed,
    initial research on stabilizing video captured by cameras was based on using information
    readily available from the camera sensors to understand how they move image by
    image.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 仅使用图像进行视频稳定化似乎是第一个合乎逻辑的步骤。确实，最初关于稳定由相机捕获的视频的研究是基于使用来自相机传感器的可用信息来理解它们是如何逐帧移动的。
- en: 'The idea is to find keypoints in an image sequence to understand how they move
    image by image. Keypoints are pixel locations on an image that match these criteria:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 理念是在图像序列中找到关键点，以了解它们是如何逐帧移动的。关键点是图像上满足以下标准的像素位置：
- en: Keypoints should be easily recognizable and distinguishable from each other.
    Corners of objects are good keypoints while a point on a blank wall is not.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键点应该容易识别，并且彼此之间可以区分开来。物体的角点是好的关键点，而空白墙上的一个点则不是。
- en: It should be possible to track keypoints across multiple images to calculate
    motion. You should be able to tell exactly where the keypoint has moved from one
    frame to another.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该能够跟踪多个图像中的关键点以计算运动。你应该能够确切地知道关键点从一个帧移动到另一个帧的确切位置。
- en: For performance, identifying these keypoints should be fast and memory-efficient.
    This is usually a bottleneck on low memory and low power devices.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了性能，识别这些关键点应该是快速且内存高效的。这通常是低内存和低功耗设备上的瓶颈。
- en: Research with these criteria led to several unique approaches like including
    some famous algorithms such as SIFT, SURF, ORB, FREAK, and so on. These techniques
    often work well.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以这些标准进行的研究导致了几个独特的方法，包括一些著名的算法，如SIFT、SURF、ORB、FREAK等。这些技术通常效果很好。
- en: 'OpenCV comes with several common keypoint detectors. These include ORB, FAST,
    BRISK, SURF, and so on. Check the 2D Features Framework documentation page for
    more information on how to use these at: [http://docs.opencv.org/3.0-beta/modules/features2d/doc/feature_detection_and_description.html](http://docs.opencv.org/3.0-beta/modules/features2d/doc/feature_detection_and_description.html).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV附带了一些常见的特征点检测器。这些包括ORB、FAST、BRISK、SURF等。有关如何使用这些检测器的更多信息，请参阅2D特征框架文档页面：[http://docs.opencv.org/3.0-beta/modules/features2d/doc/feature_detection_and_description.html](http://docs.opencv.org/3.0-beta/modules/features2d/doc/feature_detection_and_description.html)。
- en: The keypoint detectors, however, have their own set of drawbacks. Firstly, the
    results of stabilization are highly dependent on the quality of the images. For
    example, a low resolution image might not produce the best set of features. Out
    of focus and blurry images are another concern. This puts a constraint on the
    types of sequences that can be stabilized. A scene with a clear blue sky and yellow
    sand might not contain enough features.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，关键点检测器也有其自身的缺点。首先，稳定化的结果高度依赖于图像的质量。例如，低分辨率图像可能不会产生最佳的特征集。对焦不清晰和模糊的图像也是另一个问题。这限制了可以稳定化序列的类型。一个清晰的蓝天和黄色沙子的场景可能不包含足够多的特征。
- en: A surface with a repetitive pattern will confuse the algorithm because the same
    features keep showing up in different positions.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 重复图案的表面会混淆算法，因为相同的特征在不同的位置反复出现。
- en: '![Stabilization with images](img/00116.jpeg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![使用图像进行稳定化](img/00116.jpeg)'
- en: Note
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The image above is taken from: [https://d2v9y0dukr6mq2.cloudfront.net/video/thumbnail/kG-5Wkc/crowd-of-people-walking-crossing-street-at-night-in-times-square-slow-motion-30p_ekqzvese__S0000.jpg](https://d2v9y0dukr6mq2.cloudfront.net/video/thumbnail/kG-5Wkc/crowd-of-people-walking-crossing-street-at-night-in-times-square-slow-motion-30p_ekqzvese__S0000.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图像来自：[https://d2v9y0dukr6mq2.cloudfront.net/video/thumbnail/kG-5Wkc/crowd-of-people-walking-crossing-street-at-night-in-times-square-slow-motion-30p_ekqzvese__S0000.jpg](https://d2v9y0dukr6mq2.cloudfront.net/video/thumbnail/kG-5Wkc/crowd-of-people-walking-crossing-street-at-night-in-times-square-slow-motion-30p_ekqzvese__S0000.jpg)
- en: Secondly, if there is a large amount of motion in the image (such as people
    walking in the background or a truck moving across the road), the stabilization
    will be skewed because of it. The keypoint is tracking the moving object and not
    the motion of the camera itself. This limits the types of videos that can be successfully
    stabilized with such an approach. There are ways of getting around such constraints
    – however, it makes the algorithm more complex.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，如果图像中有大量的运动（如背景中行走的人群或路上行驶的卡车），由于这种运动，稳定化将会偏斜。关键点是跟踪移动的物体，而不是相机的运动本身。这限制了可以使用这种方法成功稳定化的视频类型。有绕过这种限制的方法——然而，这使算法变得更加复杂。
- en: Stabilization with hardware
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用硬件进行稳定化
- en: Certain industries, such as the movie industry and the military, expect high
    quality video stabilization. Using just images in those varied environments would
    not work. This led industries to create hardware-based image stabilization rigs.
    For example, a quadcopter with a camera needs to have a high quality video output
    despite (potentially) bad lighting conditions, wind, and so on.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 某些行业，如电影行业和军事行业，期望高质量的图像稳定。在这些复杂的环境中仅使用图像是无法工作的。这导致行业创建了基于硬件的图像稳定装置。例如，带有相机的四旋翼无人机即使在（可能）恶劣的照明条件下、风中等情况下，也需要有高质量的视频输出。
- en: '![Stabilization with hardware](img/00117.jpeg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![使用硬件进行稳定化](img/00117.jpeg)'
- en: Note
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The image above is taken from [http://g01.a.alicdn.com/kf/HTB1.ogPIpXXXXaXXVXXq6xXFXXXw/GH4-A7S-SUMMER-DYS-3-axis-3-Axis-Gimbal-dslr-camera-Stabilizer-gyro-brushless-gimbal-steadicam.jpg](http://g01.a.alicdn.com/kf/HTB1.ogPIpXXXXaXXVXXq6xXFXXXw/GH4-A7S-SUMMER-DYS-3-axis-3-Axis-Gimbal-dslr-camera-Stabilizer-gyro-brushless-gimbal-steadicam.jpg)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图像来自 [http://g01.a.alicdn.com/kf/HTB1.ogPIpXXXXaXXVXXq6xXFXXXw/GH4-A7S-SUMMER-DYS-3-axis-3-Axis-Gimbal-dslr-camera-Stabilizer-gyro-brushless-gimbal-steadicam.jpg](http://g01.a.alicdn.com/kf/HTB1.ogPIpXXXXaXXVXXq6xXFXXXw/GH4-A7S-SUMMER-DYS-3-axis-3-Axis-Gimbal-dslr-camera-Stabilizer-gyro-brushless-gimbal-steadicam.jpg)
- en: These devices use a gyroscope to physically move and rotate the camera so that
    the image sequence stays stable. The results look excellent since you're actually
    compensating for the motion of the camera.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设备使用陀螺仪来物理移动和旋转相机，从而使图像序列保持稳定。由于实际上是在补偿相机的运动，所以结果看起来非常出色。
- en: These devices tend to be on the more expensive side and thus unaffordable for
    the common consumer. They also tend to be quite bulky. The average person would
    not want to carry a two kilogram rig on his vacation.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设备往往价格较高，因此对于普通消费者来说可能负担不起。它们也往往相当庞大。普通人不会想在度假时携带两公斤重的装置。
- en: A hybrid of hardware and software
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 硬件与软件的混合体
- en: This chapter covers a hybrid solution between the original software-only approach
    and hardware devices. This became possible only recently, with the advent of the
    smartphone. People now had a high quality camera and a gyroscope in a small form.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了原始纯软件方法和硬件设备之间的混合解决方案。这种解决方案只有在智能手机出现之后才成为可能。人们现在可以在一个小型设备上获得高质量的相机和陀螺仪。
- en: The idea behind this approach is to use the gyroscope to capture motion and
    the camera sensor to capture light. These two streams are then fused so that the
    image is always stable.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法背后的思想是使用陀螺仪来捕捉运动，使用相机传感器来捕捉光线。然后，将这两个流融合在一起，以便图像始终稳定。
- en: As the sensors' density increases and we head to 4K cameras, selecting a (stable)
    subregion of the image becomes an increasingly viable option as we can discard
    more of the image without compromising on the quality.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 随着传感器密度的增加，我们朝着 4K 相机发展，选择图像的（稳定）子区域变得越来越可行，因为我们可以在不牺牲质量的情况下丢弃更多的图像。
- en: The math
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数学
- en: Before we jump into the code, let's take an overview of the algorithm. There
    are four key components.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入代码之前，让我们概述一下算法。有四个关键组件。
- en: The first is the pinhole camera model. We try and approximate real world positions
    to pixels using this matrix.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一是针孔相机模型。我们试图使用这个矩阵将现实世界的位置近似到像素。
- en: The second is the camera motion estimate. We need to use data from the gyroscope
    to figure out the orientation of the phone at any given moment.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二是相机运动估计。我们需要使用陀螺仪的数据来确定手机在任何给定时刻的朝向。
- en: The third is the rolling shutter computation. We need to specify the direction
    of the rolling shutter and estimate the duration of the rolling shutter.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三是滚动快门计算。我们需要指定滚动快门的方向并估计滚动快门的持续时间。
- en: The fourth is the image warping expression. Using all the information from the
    previous calculations, we need to generate a new image so that it becomes stable.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四是图像扭曲表达式。使用之前计算的所有信息，我们需要生成一个新的图像，使其变得稳定。
- en: The camera model
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相机模型
- en: We use the standard pinhole camera model. This model is used in several algorithms
    and is a good approximation of an actual camera.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用标准的针孔相机模型。这个模型在几个算法中使用，并且是实际相机的良好近似。
- en: '![The camera model](img/00118.jpeg)![The camera model](img/00119.jpeg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![相机模型](img/00118.jpeg)![相机模型](img/00119.jpeg)'
- en: There are three unknowns. The *o* variables indicate the origin of the camera
    axis in the image plane (these can be assumed to be 0). The two 1s in the matrix
    indicate the aspect ratio of the pixels (we're assuming square pixels). The *f*
    indicates the focal length of the lens. We're assuming the focal length is the
    same in both horizontal and vertical directions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个未知数。*o* 变量表示图像平面上相机轴的原点（这些可以假设为 0）。矩阵中的两个 1 表示像素的宽高比（我们假设像素是正方形的）。*f* 表示镜头的焦距。我们假设水平和垂直方向上的焦距相同。
- en: 'Using this model, we can see that:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个模型，我们可以看到：
- en: '![The camera model](img/00120.jpeg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![相机模型](img/00120.jpeg)'
- en: Here, X is the point in the real world. There is also an unknown scaling factor,
    *q*, present.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，X 是现实世界中的点。还有一个未知的比例因子，*q* 存在。
- en: Note
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Estimating this unknown is not possible for monocular vision unless the physical
    dimensions of an object are known.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不知道物体的物理尺寸，对于单目视觉来说，估计这个未知数是不可能的。
- en: '*K* is the intrinsic matrix and *x* is the point on the image.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*K* 是内在矩阵，*x* 是图像上的点。'
- en: The Camera motion
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相机运动
- en: 'We can assume that the world origin is the same as the camera origin. Then,
    the motion of the camera can be described in terms of the orientation of the camera.
    Thus, at any given time *t*:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以假设世界原点与相机原点相同。然后，相机的运动可以用相机的朝向来描述。因此，在任意给定的时间 *t*：
- en: '![The Camera motion](img/00121.jpeg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![相机运动](img/00121.jpeg)'
- en: The rotation matrix *R* can be calculated by integrating the angular velocity
    of the camera (obtained from the gyroscope).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过积分相机的角速度（从陀螺仪获得）来计算旋转矩阵 *R*。
- en: '![The Camera motion](img/00122.jpeg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![相机运动](img/00122.jpeg)'
- en: Here, *ω[d]* is the gyroscope drift and *t[d]* is the delay between the gyroscope
    and frame timestamps. These are unknowns as well; we need a mechanism to calculate
    them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*ω[d]* 是陀螺仪漂移，*t[d]* 是陀螺仪和帧时间戳之间的延迟。这些也是未知数；我们需要一种机制来计算它们。
- en: Rolling shutter compensation
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 滚动快门补偿
- en: When you click a picture, the common assumption is that the entire image is
    captured in one go. This is indeed the case for images captured with CCD sensors
    (which were prevalent a while back). With the commercialization of CMOS image
    sensors, this is no longer the case. Some CMOS sensors support a global shutter
    too but, in this chapter, we'll assume the sensor has a rolling shutter.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当你点击一张照片时，常见的假设是整个图像一次性被捕获。对于使用 CCD 传感器捕获的图像来说，这确实是正确的（这些传感器曾经很普遍）。随着 CMOS 图像传感器的商业化，这种情况已经不再适用。一些
    CMOS 传感器也支持全局快门，但在这个章节中，我们将假设传感器具有滚动快门。
- en: Images are captured one row at a time—usually the first row is captured first,
    then the second row, and so on. There's a very slight delay between the consecutive
    rows of an image.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图像是一行一行地捕获的——通常首先捕获第一行，然后是第二行，依此类推。图像的连续行之间存在非常小的延迟。
- en: This leads to strange effects. This is very visible when we're correcting camera
    shake (for example if there's a lot of motion in the camera).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致奇怪的效果。当我们纠正相机抖动时（例如，如果相机有大量运动），这种现象非常明显。
- en: '![Rolling shutter compensation](img/00123.jpeg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![滚动快门补偿](img/00123.jpeg)'
- en: The fan blades are the same size; however due to the fast motion, the rolling
    shutter causes artifacts in the image recorded by the sensor.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 扇叶大小相同；然而，由于快速运动，滚动快门导致传感器记录的图像中出现了伪影。
- en: 'To model the rolling shutter, we need to identify at what time a specific row
    was captured. This can be done as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要模拟滚动快门，我们需要确定特定行是在何时被捕获的。这可以通过以下方式完成：
- en: '![Rolling shutter compensation](img/00124.jpeg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![滚动快门补偿](img/00124.jpeg)'
- en: Here, *t[i]* is the time when the i^(th) frame was captured, *h* is the height
    of the image frame, and *t[s]* is the duration of the rolling shutter, that is,
    the time it takes to scan from top to bottom. Assuming each row takes the same
    time, the y^(th) row would take *t[s] * y / h* additional time to get scanned.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*t[i]* 是第 i 个帧被捕获的时间，*h* 是图像帧的高度，而 *t[s]* 是滚动快门的持续时间，即从顶部到底部扫描所需的时间。假设每一行花费相同的时间，第
    y 行需要额外的 *t[s] * y / h* 时间来扫描。
- en: Note
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This assumes the rolling shutter happens from top to bottom. A rolling shutter
    from bottom to top can be modeled with a negative value for t[s]. Also, a rolling
    shutter from left to right can be modeled by replacing *y / h* with *x / w* where
    *w* is the width of the frame.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这假设滚动快门是从顶部到底部发生的。从底部到顶部的滚动快门可以通过将 t[s] 的值设置为负数来建模。同样，从左到右的滚动快门可以通过将 *y / h*
    替换为 *x / w* 来建模，其中 *w* 是帧的宽度。
- en: Image warping
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像扭曲
- en: 'So far, we have the estimated camera motion and a model for correcting the
    rolling shutter. We''ll combine both and identify a relationship across multiple
    frames:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经有了估计的相机运动和纠正滚动快门的模型。我们将两者结合起来，并在多个帧之间识别关系：
- en: '![Image warping](img/00125.jpeg) (for frame i with rotation configuration 1)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图像扭曲](img/00125.jpeg)（对于旋转配置为 1 的帧 i）'
- en: '![Image warping](img/00126.jpeg) (for frame j with rotation configuration 2)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图像扭曲](img/00126.jpeg)（对于旋转配置为 2 的帧 j）'
- en: 'We can combine these two equations:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这两个方程组合起来：
- en: '![Image warping](img/00127.jpeg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图像扭曲](img/00127.jpeg)'
- en: 'From here, we can calculate a warping matrix:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以计算一个扭曲矩阵：
- en: '![Image warping](img/00128.jpeg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图像扭曲](img/00128.jpeg)'
- en: 'Now, the relationship between points x[i] and x[j] can be more succinctly described
    as:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，点 x[i] 和 x[j] 之间的关系可以更简洁地描述为：
- en: '![Image warping](img/00129.jpeg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图像扭曲](img/00129.jpeg)'
- en: This warp matrix simultaneously corrects both the video shake and the rolling
    shutter.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这个扭曲矩阵同时纠正了视频抖动和滚动快门。
- en: Now we can map the original video to an artificial camera that has smooth motion
    and a global shutter (no rolling shutter artifacts).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将原始视频映射到一个具有平滑运动和全局快门（无滚动快门伪影）的人工相机。
- en: This artificial camera can be simulated by low-pass filtering the input camera's
    motion and setting the rolling shutter duration to zero. A low pass filter removes
    high frequency noise from the camera orientation. Thus, the artificial camera's
    motion will appear much smoother.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这个人工相机可以通过对输入相机的运动进行低通滤波并将滚动快门持续时间设置为零来模拟。低通滤波器从相机方向中移除高频噪声。因此，人工相机的运动将看起来更加平滑。
- en: Ideally, this matrix can be calculated for each row in the image. However, in
    practice, subdividing the image into five subsections produces good results as
    well (with better performance).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，这个矩阵可以针对图像中的每一行进行计算。然而，在实践中，将图像分成五个子部分也能产生良好的结果（性能更佳）。
- en: Project overview
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目概述
- en: Let's take a moment to understand how the code in this chapter is organized.
    We have two moving pieces. One is the mobile application and the second is the
    video stabilizer.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花点时间来理解本章中的代码是如何组织的。我们有两个移动部分。一个是移动应用程序，另一个是视频稳定器。
- en: 'The mobile app only records video and stores the gyroscope signals during the
    video. It dumps this data into two files: a `.mp4` and a `.csv` file. These two
    files are the input for the next step. There is no computation on the mobile device.
    In this chapter, we''ll use Android as our platform. Moving to any other platform
    should be fairly easy—we are doing only basic tasks that any platform should support.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 移动应用程序只记录视频并在视频期间存储陀螺仪信号。它将这些数据放入两个文件中：一个`.mp4`文件和一个`.csv`文件。这两个文件是下一步的输入。在移动设备上没有进行计算。在本章中，我们将使用Android作为我们的平台。迁移到任何其他平台应该相对容易——我们只进行任何平台都应该支持的基本任务。
- en: The video stabilizer runs on a desktop. This is to help you figure out what's
    happening in the stabilization algorithm much more easily. Debugging, stepping
    through code and viewing images on a mobile device is relatively slower than iterating
    on a desktop. We have some really good scientific modules available for free (from
    the Python community. In this project, we will use Scipy, Numpy, and Matplotlib).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 视频稳定器在桌面运行。这是为了帮助你更容易地了解稳定化算法中发生的情况。在移动设备上调试、逐步执行代码和查看图像相对较慢，比在桌面迭代要慢。我们有一些非常好的免费科学模块可用（来自Python社区。在这个项目中，我们将使用Scipy、Numpy和Matplotlib）。
- en: Capturing data
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 捕获数据
- en: First, we need to create an app for a mobile device that can capture both images
    and gyroscope signals simultaneously. Interestingly, these aren't readily available
    (at least on Android).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个移动设备应用程序，它可以同时捕获图像和陀螺仪信号。有趣的是，这些并不容易获得（至少在Android上）。
- en: Once we have a video and gyro stream, we'll look at how to use that data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了视频和陀螺仪流，我们将探讨如何使用这些数据。
- en: Create a standard Android application (I use Android Studio). We'll start by
    creating a blank application. The goal is to create a simple app that starts recording
    video and gyro signals on touching the screen. On touching again, the recording
    stops and a video file and a text file are saved on the phone. These two files
    can then be used by OpenCV to compute the best stabilization.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个标准的Android应用程序（我使用Android Studio）。我们首先创建一个空白应用程序。目标是创建一个简单的应用程序，在触摸屏幕时开始录制视频和陀螺仪信号。再次触摸时，录制停止，并在手机上保存一个视频文件和一个文本文件。这两个文件然后可以被OpenCV用来计算最佳稳定化。
- en: Note
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Code in this section is available in the GitHub repository for this book: [https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_7](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_7)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的代码可在本书的GitHub仓库中找到：[https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_7](https://github.com/OpenCVBlueprints/OpenCVBlueprints/tree/master/chapter_7)
- en: Recording video
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 录制视频
- en: 'We''ll start by implementing a simple video recording utility. Create a new
    blank project in Android Studio (I named it GyroRecorder and named the activity
    Recorder). First, we start by adding permissions to our app. Open `AndroidManifest.xml`
    in your project and add these permissions:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先实现一个简单的视频录制工具。在Android Studio中创建一个新的空白项目（我命名为GyroRecorder，并将活动命名为Recorder）。首先，我们开始添加权限到我们的应用程序。在你的项目中打开`AndroidManifest.xml`并添加以下权限：
- en: '[PRE0]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This simply lets our app access the camera and write to storage (the gyro file
    and the video). Next, open the main activity visual editor and add a TextureView
    and a Button element inside a vertical LinearLayout.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是让我们的应用程序访问相机并写入存储（陀螺仪文件和视频）。接下来，打开主活动视觉编辑器，在垂直LinearLayout中添加一个TextureView和一个Button元素。
- en: Change the names of these elements to `texturePreview` and `btnRecord` respectively.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些元素的名称分别更改为`texturePreview`和`btnRecord`。
- en: '![Recording video](img/00130.jpeg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![录制视频](img/00130.jpeg)'
- en: 'Now we start with some code. In the main activity class, add these lines:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们开始编写一些代码。在主活动类中，添加以下这些行：
- en: '[PRE1]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: These objects will be used to communicate with Android to indicate when to start
    recording.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这些对象将被用来与Android通信，指示何时开始录制。
- en: Note
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Android Studio automatically adds imports to your code as you type. For example,
    the above piece results in the addition of:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Android Studio在你键入时自动将导入添加到你的代码中。例如，上面的代码片段会导致以下导入的添加：
- en: '[PRE2]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next, we need to initialize these objects. We do that in the `onCreate` event.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要初始化这些对象。我们在`onCreate`事件中这样做。
- en: '[PRE3]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `onCreate` method already contains some methods (`super.onCreate`, `setContentView`,
    and so on; we will add a few lines after that). Now, we need to define what `onCaptureClick`
    does.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`onCreate`方法已经包含了一些方法（如`super.onCreate`、`setContentView`等；我们将在之后添加几行）。现在，我们需要定义`onCaptureClick`的作用。'
- en: '[PRE4]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you want to explore `strings.xml`, refer to [Chapter 2](part0023_split_000.html#LTSU2-940925703e144daa867f510896bffb69
    "Chapter 2. Photographing Nature and Wildlife with an Automated Camera"), *Working
    with Camera Frames*, of the PacktPub book *Android Application Programming with
    OpenCV*.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想探索`strings.xml`，请参考PacktPub书籍《使用OpenCV的Android应用程序编程》的第二章，*与相机帧一起工作*，部分0023_split_000.html#LTSU2-940925703e144daa867f510896bffb69。
- en: Here, we use the internal `isRecording` variable to notify the media recorder
    and camera to start saving the stream. We need to create a new thread because
    initializing the media recorder and camera usually takes a few milliseconds. This
    lag would be noticeable on the UI if we did it in the main thread.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用内部的`isRecording`变量来通知媒体录制器和相机开始保存流。我们需要创建一个新的线程，因为初始化媒体录制器和相机通常需要几毫秒。如果在主线程中这样做，这种延迟会在UI上变得明显。
- en: 'Once we''re done recording (the user taps the Stop button and we need to release
    the media recorder. This happens in the `releaseMediaRecorder` method:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们完成录制（用户点击停止按钮，我们需要释放媒体录制器。这发生在`releaseMediaRecorder`方法中）：
- en: '[PRE5]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now, we look at creating a new thread. Create this class in your main activity
    class.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来看创建一个新的线程。在你的主活动类中创建这个类。
- en: '[PRE6]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This creates an object of the type `AsyncTask`. Creating a new object of this
    class automatically creates a new thread and runs `doInBackground` in that thread.
    We want to prepare the media recorder in this thread. Preparing the media recorder
    involves identifying supported image sizes from the camera, finding the suitable
    height, setting the bitrate of the video and specifying the destination video
    file.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了一个`AsyncTask`类型的对象。创建这个类的新对象会自动创建一个新的线程，并在该线程中运行`doInBackground`。我们想在同一个线程中准备媒体录制器。准备媒体录制器涉及到从相机识别支持的视频尺寸，找到合适的高度，设置视频的比特率以及指定目标视频文件。
- en: 'In your main activity class, create a new method called `prepareVideoRecorder`:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的主活动类中，创建一个名为`prepareVideoRecorder`的新方法：
- en: '[PRE7]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now that we have supported video sizes, we need to find the optimal image size
    for the camera. This is done here:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了支持的视频尺寸，我们需要找到相机的最佳图像尺寸。这是在这里完成的：
- en: '[PRE8]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'With the optimal size in hand, we can now set up the camera recorder settings:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有最佳尺寸后，我们现在可以设置相机录制器设置：
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, we try to contact the camera hardware and set up these parameters:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们尝试接触相机硬件并设置这些参数：
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, along with setting the camera parameters, we also specify a preview surface.
    The preview surface is used to display what the camera sees live.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，除了设置相机参数外，我们还指定了一个预览表面。预览表面用于显示相机实时看到的画面。
- en: 'With the camera setup done, we can now set up the media recorder:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 相机设置完成后，我们现在可以设置媒体录制器：
- en: '[PRE11]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This just sets whatever we already know about the video stream—we're simply
    passing information from what we've gathered into the media recorder.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是设置我们已知的视频流信息——我们只是将收集到的信息传递给媒体录制器。
- en: Note
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This configuration does not record audio. In this project, we're not concerned
    with the audio signals. However, it should be straightforward to configure the
    media recorder to store audio as well.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置不记录音频。在这个项目中，我们并不关心音频信号。然而，将媒体录制器配置为存储音频应该是相当直接的。
- en: 'With everything in place, we try to start the media recorder:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一切准备就绪后，我们尝试启动媒体录制器：
- en: '[PRE12]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: And that's the end of the `prepareVideoRecorder` method. We've referenced a
    bunch of variables and functions that do not exist yet, so we'll define some of
    them now.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是`prepareVideoRecorder`方法的结束。我们引用了一些还不存在的变量和函数，所以现在我们将定义其中的一些。
- en: 'The first is `getOptimalPreviewSize`. Define this method in your activity''s
    class:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个是`getOptimalPreviewSize`。在活动类中定义这个方法：
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This function simply tries to match all possible image sizes against an expected
    aspect ratio. If it cannot find a close match, it returns the closest match (based
    on the expected height).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数只是尝试将所有可能的图像尺寸与预期的宽高比进行匹配。如果找不到接近的匹配项，它将返回最接近的匹配项（基于预期的宽度）。
- en: 'The second is `getOutputMediaFile`. This function uses the Android API to find
    an acceptable location to store our videos. Define this method in the main activity
    class as well:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是`getOutputMediaFile`。这个函数使用Android API来找到一个可接受的位置来存储我们的视频。在主活动类中定义此方法：
- en: '[PRE14]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: It finds the media storage location for pictures and appends a timestamp to
    the filename.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 它会找到图片和应用程序的媒体存储位置，并将时间戳附加到文件名上。
- en: Now we have almost everything to start recording videos. Two more method definitions
    and we'll have a working video recorder.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们几乎拥有了开始录制视频所需的一切。再定义两个方法，我们就会有一个工作的视频录制器。
- en: '[PRE15]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The `onPause` method is called whenever the user switches to another app. It's
    being a good citizen to release hardware dependencies when you're not using them.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户切换到另一个应用程序时，会调用`onPause`方法。当你不使用它们时释放硬件依赖是一个好公民的行为。
- en: Recording gyro signals
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 录制陀螺仪信号
- en: 'In the previous section, we only looked at recording video. For this project,
    we also need to record gyroscope signals. With Android, this is accomplished by
    using a sensor event listener. We''ll modify the main activity class for this.
    Add this `implements` clause:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们只看了录制视频。对于这个项目，我们还需要录制陀螺仪信号。在Android中，这是通过使用传感器事件监听器来完成的。我们将为此修改主活动类。添加此`implements`子句：
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we need to add a few new objects to our class:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要向我们的类中添加几个新对象：
- en: '[PRE17]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The `SensorManager` object manages all sensors on the hardware. We''re only
    interested in the gyroscope, so we have a `Sensor` object for it. `PrintStream`
    writes a text file with the gyroscope signals. We now need to initialize these
    objects. We do that in the `onCreate` method. Modify the method so that it looks
    like this:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`SensorManager`对象管理硬件上的所有传感器。我们只对陀螺仪感兴趣，所以我们有一个`Sensor`对象用于它。`PrintStream`将陀螺仪信号写入文本文件。我们现在需要初始化这些对象。我们在`onCreate`方法中这样做。修改该方法，使其看起来像这样：'
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Here, we're fetching the gyroscope sensor and registering that this class should
    receive events (`registerListener`). We're also mentioning the frequency we want
    data to flow in.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在获取陀螺仪传感器并注册这个类应该接收事件（`registerListener`）。我们还在说明我们想要数据流动的频率。
- en: 'Next, we initialize the `PrintStream` in the `prepareVideoRecorder` method:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在`prepareVideoRecorder`方法中初始化`PrintStream`：
- en: '[PRE19]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This tries to open a new stream to a text file. We fetch the text file name
    using:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这尝试打开一个新流到文本文件。我们使用以下方式获取文本文件名：
- en: '[PRE20]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This is almost the same code as `getOutputMediaFile`, except that it returns
    a `.csv` file (instead of an `.mp4`) in the same directory.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这几乎与`getOutputMediaFile`相同，只是它返回的是同一目录下的`.csv`文件（而不是`.mp4`）。
- en: 'One last thing and we''ll be recording gyroscope signals as well. Add this
    method to the main activity class:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一件事情，我们还将录制陀螺仪信号。将此方法添加到主活动类中：
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The idea is to store values returned by the sensor into the file as soon as
    possible.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 理念是将传感器返回的值尽可能快地存储到文件中。
- en: Android specifics
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Android特有内容
- en: 'In this section, we''ll look at some Android-specific tasks: one is rendering
    an overlay on top of the camera view and the second is reading media files on
    Android.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将查看一些Android特有的任务：一是将叠加层渲染到相机视图之上，二是读取Android上的媒体文件。
- en: The overlay is helpful for general information and debugging, and looks nice
    too! Think of it like the heads up display on a consumer camera.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 该叠加层对一般信息和调试很有帮助，而且看起来也很漂亮！想象一下，它就像消费级相机上的抬头显示一样。
- en: The reading media files section is something we don't use in this chapter (we
    read media files using Python). However, if you decide to write an Android app
    that processes videos on the device itself, this section should get you started.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 读取媒体文件的部分在本章中我们没有使用（我们使用Python读取媒体文件）。然而，如果你决定编写一个在设备本身上处理视频的Android应用程序，这一部分应该能帮助你入门。
- en: Threaded overlay
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程化叠加层
- en: Now that we have the camera preview working, we want to render some additional
    information on top of it. We'll be drawing three things; first, a red circle to
    indicate whether recording is active, second, the current gyroscope values (angular
    velocity and estimated theta) just for information, and third, a safety rectangle.
    When stabilizing, we'll probably be cropping the image a bit. The rectangle will
    guide your video recording to stay within a relatively safe zone.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使相机预览工作正常，我们想在它上面渲染一些额外的信息。我们将绘制三样东西；首先，一个红色圆圈来指示是否正在录制，其次，当前陀螺仪值（角速度和估计的theta）仅作为信息，第三，一个安全矩形。在稳定时，我们可能会稍微裁剪一下图像。这个矩形将指导你的视频录制保持在相对安全区域内。
- en: Along with this, we'll also be setting it up so that you can create buttons
    on this overlay. Simple touch events can be used to execute specific functions.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，我们还将设置它，以便您可以在覆盖层上创建按钮。简单的触摸事件可以用来执行特定功能。
- en: You don't need this section for the application to work, but it's a good idea
    to know how to render on top of an OpenCV camera view while recording.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 您不需要这个部分来使应用程序工作，但了解如何在录制时在OpenCV相机视图中渲染是很重要的。
- en: 'Before we start working on the overlay widget, let''s define a supporting class,
    `Point3`. Create a new class called `Point3` with three double attributes:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始处理覆盖层小部件之前，让我们定义一个支持类，`Point3`。创建一个名为`Point3`的新类，具有三个double属性：
- en: '[PRE22]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We start by defining a new class, `CameraOverlayWidget`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义了一个新的类，`CameraOverlayWidget`。
- en: '[PRE23]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We've subclassed this from `SurfaceView` to be able to render things on it.
    It also implements the gesture detector class so that we'll be able to monitor
    touch events on this widget.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`SurfaceView`派生了这个子类，以便能够在它上面渲染事物。它还实现了手势检测类，这样我们就能监控此小部件的触摸事件。
- en: '[PRE24]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We define a bunch of variables to be used by the class. Some of them are `Paint`
    objects – which are used by the `SurfaceView` to render things. We've created
    different paints for the safety rectangle, the red recording circle, and the text.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一组变量，供类使用。其中一些是`Paint`对象——这些对象由`SurfaceView`用于渲染事物。我们为安全矩形、红色记录圆圈和文本创建了不同的油漆。
- en: Next, there are variables that describe the current state of the recorder. These
    variables answer questions like, is it currently recording? What's the size of
    the video? What is the latest gyro reading? We'll use these state variables to
    render the appropriate overlay.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，有一些变量描述了记录器的当前状态。这些变量回答了诸如，它目前正在录制吗？视频的大小是多少？最新的陀螺仪读数是什么？我们将使用这些状态变量来渲染适当的覆盖层。
- en: We also define some safety fractions – the safety rectangle will have a margin
    of 0.15 on each edge.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了一些安全系数——安全矩形将在每一边都有0.15的边距。
- en: '[PRE25]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: And finally, we add a few event listeners – we'll use these to detect touches
    in specific areas of the overlay (we won't be using these though).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们添加了一些事件监听器——我们将使用这些监听器来检测覆盖层特定区域中的触摸（我们实际上不会使用这些）。
- en: 'Let''s look at the constructor for this class:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个类的构造函数：
- en: '[PRE26]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Here, we set up some basics when the object is initialized. We create the paint
    objects in `initializePaints`, create a new thread for rendering the overlay and
    also create a gesture detector.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在对象初始化时设置了一些基本设置。我们在`initializePaints`中创建油漆对象，为渲染覆盖层创建一个新的线程，并创建一个手势检测器。
- en: '[PRE27]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: As you can see, paints describe the physical attributes of the things to draw.
    For example, `paintRecordCircle` is red and fills whatever shape we draw. Similarly,
    the record text shows up white with a text size of 20.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，油漆描述了要绘制的事物的物理属性。例如，`paintRecordCircle`是红色，并填充我们绘制的任何形状。同样，记录文本以白色显示，文本大小为20。
- en: Now let's look at the `RenderThread` class—the thing that does the actual drawing
    of the overlay. We start by defining the class itself and defining the `run` method.
    The `run` method is executed when the thread is spawned. On returning from this
    method, the thread stops.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看`RenderThread`类——实际绘制覆盖层的那个东西。我们首先定义类本身，并定义`run`方法。当线程启动时执行`run`方法。从这个方法返回后，线程停止。
- en: '[PRE28]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Now let's add the `renderOverlay` method to `RenderThread`. We start by getting
    a lock on the canvas and drawing a transparent color background. This clears anything
    that already exists on the overlay.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将`renderOverlay`方法添加到`RenderThread`中。我们首先锁定画布并绘制一个透明的颜色背景。这将清除覆盖层上已经存在的内容。
- en: '[PRE29]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Now, we draw the safety bounds of the camera view. While stabilizing the video,
    we'll inevitably have to crop certain parts of the image. The safe lines mark
    this boundary. In our case, we take a certain percentage of the view as safe.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们绘制相机视图的安全边界。在稳定视频时，我们不可避免地必须裁剪图像的某些部分。安全线标记了这个边界。在我们的情况下，我们取视图的一定百分比作为安全区域。
- en: '[PRE30]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: If we're recording, we want to blink the red recording circle and the recording
    text. We do this by taking the current time and the start time.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在录制，我们想要闪烁红色记录圆圈和记录文本。我们通过获取当前时间和开始时间来实现这一点。
- en: '[PRE31]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Now we draw a button that says "Record" on it.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们绘制一个按钮，上面写着“Record”。
- en: '[PRE32]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: While recording the video, we will also display some useful information—the
    current angular velocity and estimated angle. You can verify if the algorithm
    is working as expected or not.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在录制视频时，我们还将显示一些有用的信息——当前的角速度和估计的角度。你可以验证算法是否按预期工作。
- en: '[PRE33]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: And, with this, the render overlay method is complete!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 并且，有了这个，渲染覆盖方法就完成了！
- en: '[PRE34]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This class can be used to spawn a new thread and this thread simply keeps the
    overlay updated. We've added a special logic for the recording circle so that
    it makes the red circle blink.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类可以用来启动一个新线程，这个线程简单地保持覆盖更新。我们为录制圆圈添加了特殊的逻辑，使其使红色圆圈闪烁。
- en: Next, let's look at some of the supporting functions in `CameraOverlayWidget`.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看`CameraOverlayWidget`中的某些支持函数。
- en: '[PRE35]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Two simple set and unset methods enable or disable the red circle.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 两个简单的设置和取消设置方法可以启用或禁用红色圆圈。
- en: '[PRE36]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: If the size of the widget changes (we'll be setting it fullscreen on the preview
    pane), we should know about it and capture the size in these variables. This will
    affect the positioning of the various elements and the safety rectangle.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果小部件的大小发生变化（我们将在预览窗格中将其设置为全屏），我们应该知道这一点并捕获这些变量中的大小。这将影响各种元素和安全性矩形的定位。
- en: '[PRE37]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We also have a few set methods that let you change the values to be displayed
    on the overlay.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有一些设置方法，允许你更改要在覆盖上显示的值。
- en: '[PRE38]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: There are other functions that can be used to modify the overlay being displayed.
    These functions set the gyroscope values.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 有其他函数可以用来修改正在显示的覆盖。这些函数设置陀螺仪值。
- en: Now, let's look at some Android-specific lifecycle events such as pause, resume,
    and so on.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看一些Android特有的生命周期事件，例如暂停、恢复等。
- en: '[PRE39]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: These two methods ensure we're not using processor cycles when the app isn't
    in the foreground. We simply stop the rendering thread if the app goes to a paused
    state and resume painting when it's back.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个方法确保当应用不在前台时，我们不会使用处理器周期。如果应用进入暂停状态，我们简单地停止渲染线程，当它返回时继续绘制。
- en: '[PRE40]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: When the surface is created, we set up the pixel format (we want it to be transparent,
    we make the surface of the type RGBA). Also, we should spawn a new thread to get
    the overlay rendering going.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建表面时，我们设置像素格式（我们希望它是透明的，所以我们创建一个RGBA类型的表面）。此外，我们应该启动一个新线程以开始覆盖渲染。
- en: 'With that, we''re almost ready with our overlay display. One last thing remains—responding
    to touch events. Let''s do that now:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们的覆盖显示就快完成了。最后一件事是响应触摸事件。让我们现在就做这件事：
- en: '[PRE41]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'These functions do nothing but pass on events to the event listener, if there
    is any. We''re responding to the following events: `onTouchEvent`, `onDown`, `onShowPress`,
    `onFlight`, `onLongPress`, `onScroll`, `onSingleTapUp`.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数只是将事件传递给事件监听器，如果有任何事件监听器的话。我们正在响应以下事件：`onTouchEvent`、`onDown`、`onShowPress`、`onFlight`、`onLongPress`、`onScroll`、`onSingleTapUp`。
- en: 'One final piece of code remains for the overlay class. We''ve used something
    called `OverlayEventListener` at certain places in the class but have not yet
    defined it. Here''s what it looks like:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 对于覆盖类，我们还有一些代码需要完成。我们在类的某些地方使用了`OverlayEventListener`，但尚未定义它。下面是这个类的样子：
- en: '[PRE42]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: With this defined, we will now be able to create event handlers for specific
    buttons being touched on the overlay (the calibrate and record buttons).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了这一点后，我们现在将能够为覆盖上被触摸的特定按钮创建事件处理器（校准和记录按钮）。
- en: Reading media files
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 读取媒体文件
- en: Once you've written the media file, you need a mechanism to read individual
    frames from the movie. We can use Android's Media Decoder to extract frames and
    convert them into OpenCV's native Mat data structure. We'll start by creating
    a new class called `SequentialFrameExtractor`.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你写好了媒体文件，你需要一个机制来从电影中读取单个帧。我们可以使用Android的媒体解码器来提取帧并将它们转换为OpenCV的本地Mat数据结构。我们将首先创建一个名为`SequentialFrameExtractor`的新类。
- en: Most of this section is based on Andy McFadden's tutorial on using the MediaCodec
    at bigflake.com.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分的大部分内容基于Andy McFadden在bigflake.com上关于使用MediaCodec的教程。
- en: Note
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: As mentioned earlier, you don't need this class to get through this chapter's
    project. If you decide to write an Android app that reads media files, this class
    should get you started. Feel free to skip this if you like!
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，你不需要这个类来完成本章的项目。如果你决定编写一个读取媒体文件的Android应用，这个类应该能帮助你入门。如果你喜欢，可以随意跳过这一部分！
- en: We will be using the Android app only to record the video and gyro signals.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将仅使用Android应用来记录视频和陀螺仪信号。
- en: '[PRE43]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '`mFilename` is the name of the file that''s being read, it should only be set
    when an object of `SequentialFrameExtractor` is created. `CodecOutputSurface`
    is a construct borrowed from [http://bigflake.com](http://bigflake.com) that encapsulates
    logic to render a frame using OpenGL and fetches raw bytes for us to use. It is
    available on the website and also in the accompanying code. The next is `MediaCodec`—Android''s
    way of letting you access the decoding pipeline.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`mFilename`是正在读取的文件名，它应该在创建`SequentialFrameExtractor`对象时设置。`CodecOutputSurface`是从[http://bigflake.com](http://bigflake.com)借用的结构，用于封装使用OpenGL渲染帧的逻辑，并为我们获取原始字节。它可以在网站上找到，也可以在配套代码中找到。接下来是`MediaCodec`——Android让你访问解码管道的方式。'
- en: '`FrameAvailableListener` is an interface we''ll create in just a moment. It
    allows us to respond whenever a frame becomes available.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '`FrameAvailableListener`是我们即将创建的接口。它允许我们在帧可用时做出响应。'
- en: What is `TIMEOUT_USEC` and `decodeCount`?
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`TIMEOUT_USEC`和`decodeCount`是什么？'
- en: '[PRE44]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We've created a constructor and a new `start` method. The `start` method is
    when the decoding begins and it will start firing the `onFrameAvailable` method
    as new frames become available.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个构造函数和一个新的`start`方法。`start`方法是解码开始的地方，它将在新帧可用时开始触发`onFrameAvailable`方法。
- en: '[PRE45]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Here, we loop over all the tracks available in the given file (audio, video,
    and so on) and identify a video track to work with. We're assuming this is a mono-video
    file, so we should be good to select the first video track that shows up.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们遍历给定文件中所有可用的轨迹（音频、视频等）并识别一个要处理的视频轨迹。我们假设这是一个单声道视频文件，因此我们应该能够选择第一个出现的视频轨迹。
- en: With the track selected, we can now start the actual decoding process. Before
    that, we must set up a decoding surface and some buffers. The way MediaCodec works
    is that it keeps accumulating data into a buffer. Once it accumulates an entire
    frame, the data is passed onto a surface to be rendered.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择了轨迹之后，我们现在可以开始实际的解码过程。在此之前，我们必须设置解码表面和一些缓冲区。MediaCodec的工作方式是它将数据持续积累到缓冲区中。一旦它积累了一个完整的帧，数据就会被传递到表面进行渲染。
- en: '[PRE46]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'With the initial setup done, we now get into the decoding loop:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成初始设置后，我们现在进入解码循环：
- en: '[PRE47]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'This is the input half of the media extraction. This loop reads the file and
    queues chunks for the decoder. As things get decoded, we need to route it to the
    places we need:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这是媒体提取的输入部分。这个循环读取文件并将块排队以供解码器使用。随着解码的进行，我们需要将其路由到所需的位置：
- en: '[PRE48]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: This completes the output half of the decode loop. Whenever a frame is complete,
    it converts the raw data into a Mat structure and creates a new `Frame` object.
    This is then passed to the `onFrameAvailable` method.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了解码循环的输出部分。每当一个帧完成时，它将原始数据转换为Mat结构并创建一个新的`Frame`对象。然后，它被传递到`onFrameAvailable`方法。
- en: Once the decoding is complete, the media extractor is released and we're done!
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦解码完成，媒体提取器就会被释放，我们就完成了！
- en: 'The only thing left is to define what `FrameAvailableListener` is. We shall
    do that now:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的唯一事情就是定义`FrameAvailableListener`是什么。我们现在就来定义它：
- en: '[PRE49]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: This is a common pattern in Java when defining such listeners. The listeners
    contain methods that are fired on specific events (in our case, when a frame is
    available, or when the processing of a frame is complete).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在Java中定义此类监听器时的常见模式。监听器包含在特定事件上触发的方法（在我们的案例中，当帧可用或帧处理完成时）。
- en: Calibration
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 校准
- en: In the section that discusses the mathematical basis, we found several unknown
    camera parameters. These parameters need to be figured out so we can process each
    image and stabilize it. As with any calibration process, we need to use a predefined
    scene. Using this scene and a relative handshake, we will try to estimate the
    unknown parameters.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论数学基础的章节中，我们发现了几个未知的相机参数。这些参数需要确定，以便我们可以处理每一张图像并使其稳定。与任何校准过程一样，我们需要使用预定义的场景。使用这个场景和相对握手，我们将尝试估计未知参数。
- en: 'The unknown parameters are:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 未知参数包括：
- en: Focal length of the lens
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镜头的焦距
- en: Delay between gyroscope and frame timestamps
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陀螺仪和帧时间戳之间的延迟
- en: Bias in the gyroscope
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陀螺仪的偏差
- en: Duration of the rolling shutter
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滚动快门的持续时间
- en: It is often possible to detect the focal length of a phone camera (in terms
    of millimeters) using the platform API (`getFocalLength()` for Android). However,
    we're interested in the camera space focal length. This number is a product of
    the physical focal length and a conversion ratio that depends on the image resolution
    and the physical size of the camera sensor, which might differ across cameras.
    It is also possible to find the conversion ratio by trigonometry if the field
    of view (`getVerticalViewAngle()` and `getHorizontalViewAngle()` for Android)
    is known for a sensor and lens setup. However, we'll just leave it as an unknown
    and let the calibration find it for us.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 通常可以使用平台API（Android的`getFocalLength()`）检测手机摄像头的焦距（以毫米为单位）。然而，我们感兴趣的是相机空间的焦距。这个数字是物理焦距和转换率的乘积，转换率取决于图像分辨率和相机传感器的物理尺寸，这些可能因相机而异。如果已知传感器和镜头设置的视野（Android的`getVerticalViewAngle()`和`getHorizontalViewAngle()`），也可以通过三角学找到转换率。但是，我们将它留作未知，让校准为我们找到它。
- en: Note
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you're interested in more information on this, refer to [Chapter 5](part0043_split_000.html#190862-940925703e144daa867f510896bffb69
    "Chapter 5. Generic Object Detection for Industrial Applications"), *Combining
    Image Tracking with 3D Rendering*, of PacktPub's *Android Application Programming
    with OpenCV*.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对这方面的更多信息感兴趣，请参阅PacktPub的《Android应用编程与OpenCV》的第五章，*结合图像跟踪与3D渲染*，[第5章](part0043_split_000.html#190862-940925703e144daa867f510896bffb69
    "第5章。工业应用中的通用目标检测")。
- en: We need to estimate the delay between gyro and frame timestamps to improve the
    quality of the output on sharp turns. This also offsets any lag introduced by
    the phone when recording the video.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高在急转弯时输出的质量，我们需要估计陀螺仪和帧时间戳之间的延迟。这也抵消了手机在录制视频时引入的任何延迟。
- en: Rolling shutter effects are visible at high speed and the estimated parameter
    tries to correct these.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动快门效应在高速时可见，估计参数试图纠正这些。
- en: It is possible to calculate these parameters with a short clip that's shaky.
    We use a feature detector from OpenCV to do this.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一段摇晃的短剪辑可以计算这些参数。我们使用OpenCV的特征检测器来完成这个任务。
- en: Note
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: During this phase, we'll be using Python. The SciPy library provides us with
    mathematical functions that we can use out of the box. It is possible to implement
    these on your own, but that would require a more in-depth explanation of how mathematical
    optimization works. Along with this, we'll use Matplotlib to generate graphs.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们将使用Python。SciPy库为我们提供了可以直接使用的数学函数。虽然可以自己实现这些函数，但这将需要更深入地解释数学优化的工作原理。此外，我们还将使用Matplotlib来生成图表。
- en: Data structures
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据结构
- en: 'We''ll set up three key data structures: first, the unknown parameters, second,
    something to read the gyro data file generated by the Android app, and third,
    a representation of the video being processed.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将设置三个关键的数据结构：首先，未知参数，其次，用于读取由Android应用生成的陀螺仪数据文件的东西，第三，正在处理的视频的表示。
- en: 'The first structure is to store the estimates from the calibration. It contains
    four values:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个结构是用来存储校准的估计值。它包含四个值：
- en: An estimate of the focal length of the camera (in camera units, not physical
    units)
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摄像头焦距的估计（以相机单位表示，而不是物理单位）
- en: The delay between the gyroscope timestamps and the frame timestamps
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陀螺仪时间戳和帧时间戳之间的延迟
- en: The gyroscope bias
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陀螺仪偏差
- en: The rolling shutter estimated
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滚动快门估计
- en: Let's start by creating a new file called `calibration.py`.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先创建一个名为`calibration.py`的新文件。
- en: '[PRE50]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Reading the gyroscope trace
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 读取陀螺仪轨迹
- en: Next, we'll define a class to read in the `.csv` file generated by the Android
    app.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个类来读取由Android应用生成的`.csv`文件。
- en: '[PRE51]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We initialize the class with two main variables: the file path to read, and
    a dictionary of angular velocities. This dictionary will store mappings between
    the timestamp and the angular velocity at that instant. We''ll eventually need
    to calculate actual angles from the angular velocity, but that will happen outside
    this class.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用两个主要变量初始化这个类：读取的文件路径和角速度的字典。这个字典将存储时间戳和该时刻角速度之间的映射。我们最终需要从角速度计算实际角度，但这将在类外发生。
- en: Now we add the `parse` method. This method will actually read the file and populate
    the Omega dictionary.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们添加了`parse`方法。这个方法实际上会读取文件并填充Omega字典。
- en: '[PRE52]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: We validate that the first line of the csv file matches our expectation. If
    not, the csv file was probably not compatible and will error out over the next
    few lines.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们验证 csv 文件的第一行是否符合我们的预期。如果不一致，则 csv 文件可能不兼容，并在接下来的几行中出错。
- en: '[PRE53]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Here, we initiate a loop over the entire file. The `strip` function removed
    any additional whitespace (tabs, spaces, newline characters, among others) that
    might be stored in the file.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们开始在整个文件上循环。`strip` 函数移除了文件中可能存储的任何额外空白（制表符、空格、换行符等）。
- en: After removing the whitespace, we split the string with commas (this is a comma-separated
    file!).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在删除空白后，我们用逗号分隔字符串（这是一个逗号分隔的文件！）。
- en: '[PRE54]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Information read from the file is plain strings so we convert that into the
    appropriate numeric type and store it in `self.omega`. We're now ready to parse
    the csv files and get started with numeric calculations.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 从文件中读取的信息是纯字符串，因此我们将其转换为适当的数值类型并存储在 `self.omega` 中。我们现在可以解析 csv 文件并开始进行数值计算。
- en: Before we do that, we'll define a few more useful functions.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，我们将定义一些更多有用的函数。
- en: '[PRE55]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: The `get_timestamps` method on this class will return a sorted list of timestamps.
    Building on this, we also define a function called `get_signal`. The angular velocity
    is composed of three signals. These signals are packed together in `self.omega`.
    The `get_signal` function lets us extract a specific component of the signal.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类上的 `get_timestamps` 方法将返回一个按顺序排列的时间戳列表。在此基础上，我们还定义了一个名为 `get_signal` 的函数。角速度由三个信号组成。这些信号一起打包在
    `self.omega` 中。`get_signal` 函数使我们能够提取信号的特定组件。
- en: For example, `get_signal(0)` returns the X component of angular velocity.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`get_signal(0)` 返回角速度的 X 分量。
- en: '[PRE56]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: These utility functions return only the specific signal we're looking at. We'll
    be using these signals to smooth out individual signals, calculate the angle,
    and so on.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这些实用函数仅返回我们正在查看的特定信号。我们将使用这些信号来平滑单个信号、计算角度等。
- en: Another issue we need to address is that the timestamps are discrete. For example,
    we might have angular velocities at timestamp N and the next reading might exist
    at N+500000 (remember, the timestamps are in nanoseconds). However, the video
    file might have a frame at N+250000\. We need a way to interpolate between two
    angular velocity readings.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个我们需要解决的问题是时间戳是离散的。例如，我们可能在时间戳 N 处有角速度，下一次读取可能存在于 N+500000（记住，时间戳是以纳秒为单位的）。然而，视频文件可能在
    N+250000 处有一个帧。我们需要在两个角速度读取之间进行插值。
- en: We'll use simple linear interpolation to estimate the angular velocity at any
    given moment.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用简单的线性插值来估计任意时刻的角速度。
- en: '[PRE57]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: This method takes in a timestamp and returns the estimated angular velocity.
    If the exact timestamp already exists, there is no estimation to do.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法接受一个时间戳并返回估计的角速度。如果确切的时戳已经存在，则无需进行估计。
- en: '[PRE58]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Here we're walking over the timestamps and finding the timestamp that is closest
    to the one requested.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们遍历时间戳，找到最接近请求的时间戳。
- en: '[PRE59]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Once we have the two closest timestamps (`i` and `i+1` in the list `sorted_timestamps`),
    we're ready to start linear interpolation. We calculate the estimated X, Y, and
    Z angular velocities and return these values.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了两个最接近的时间戳（列表 `sorted_timestamps` 中的 `i` 和 `i+1`），我们就准备好开始线性插值。我们计算估计的
    X、Y 和 Z 角速度，并返回这些值。
- en: This finishes our work on reading the gyroscope file!
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了我们对陀螺仪文件的读取工作！
- en: The training video
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练视频
- en: We'll also create a new class that lets us treat the entire video sequence as
    a single entity. We'll extract useful information from the video in a single pass
    and store it for future reference, making our code both faster and more memory
    efficient.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将创建一个新的类，使我们能够将整个视频序列视为一个单一实体。我们将单次遍历视频以提取有用的信息，并将其存储以供将来参考，使我们的代码更快、更节省内存。
- en: '[PRE60]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: We initialize the class with some variables we'll be using throughout. Most
    of the variables are self-explanatory. `frameInfo` stores details about every
    frame—like the timestamp of a given frame and keypoints (useful for calibration).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用将在整个过程中使用的变量初始化该类。大多数变量都是不言自明的。`frameInfo` 存储有关每个帧的详细信息——如给定帧的时间戳和关键点（用于校准）。
- en: '[PRE61]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: We define a new method that will do all the heavy lifting for us. We start by
    creating the OpenCV video reading object (`VideoCapture`) and try to read a single
    frame.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个新的方法，将为我们完成所有繁重的工作。我们首先创建 OpenCV 视频读取对象（`VideoCapture`）并尝试读取一个帧。
- en: '[PRE62]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The `get` method on a `VideoCapture` object returns information about the video
    sequence. Zero (0) happens to be the constant for fetching the timestamp in milliseconds.
    We convert this into nanoseconds and print out a helpful message!
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在`VideoCapture`对象上的`get`方法返回有关视频序列的信息。零（0）恰好是获取毫秒级时间戳的常量。我们将此转换为纳秒并打印出有用的信息！
- en: '[PRE63]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: If this is the first frame being read, we won't have a previous frame. We're
    also not interested in storing keypoints for the first frame. So we just move
    on to the next frame.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是第一个被读取的帧，我们将没有前一个帧。我们也不感兴趣存储第一个帧的关键点。所以我们直接跳到下一个帧。
- en: '[PRE64]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: If you set the `skip_keypoints` parameter to `true`, it'll just store the timestamps
    of each frame. You might then use this parameter to read a video after you've
    already calibrated your device and already have the values of the various unknowns.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将`skip_keypoints`参数设置为`true`，它将只存储每个帧的时间戳。你可能会在已经校准了你的设备并且已经得到了各种未知数的值之后使用此参数来读取视频。
- en: '[PRE65]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: We convert the previous and the current frame into grayscale and extract some
    good features to track. We'll use these features and track them in the new frame.
    This gives us a visual estimate of how the orientation of the camera changed.
    We already have the gyroscope data for this; we just need to calibrate some unknowns.
    We achieve this by using the visual estimate.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将前一个和当前帧转换为灰度图并提取一些良好的特征以进行跟踪。我们将使用这些特征并在新帧中跟踪它们。这给我们提供了一个视觉估计，即相机的方向如何改变。我们已经有这个陀螺仪数据；我们只需要校准一些未知数。我们通过使用视觉估计来实现这一点。
- en: '[PRE66]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: If no corners were found in the old frame, that's not a good sign. Was it a
    very blurry frame? Were there no good features to track? So we simply skip processing
    it.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在旧帧中没有找到任何角，这不是一个好兆头。这是不是一个非常模糊的帧？是否有良好的特征进行跟踪？所以我们简单地跳过处理它。
- en: 'If we did find keypoints to track, we use optical flow to identify where they
    are in the new frame:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们确实找到了用于跟踪的关键点，我们使用光流来确定它们在新帧中的位置：
- en: '[PRE67]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: This gives us the position of the corners in the new frame. We can then estimate
    the motion that happened between the previous frame and the current, and correlate
    it with the gyroscope data.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们提供了新帧中角的位置。然后我们可以估计前一个帧和当前帧之间的运动，并将其与陀螺仪数据相关联。
- en: A common issue with `goodFeaturesToTrack` is that the features aren't robust.
    They often move around, losing the position they were tracking. To get around
    this, we add another test just to ensure such random outliers don't make it to
    the calibration phase. This is done with the help of RANSAC.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`goodFeaturesToTrack`的一个常见问题是特征不够稳健。它们经常移动，失去了它们跟踪的位置。为了解决这个问题，我们添加另一个测试，以确保这样的随机异常值不会进入校准阶段。这是通过RANSAC来完成的。'
- en: Note
  id: totrans-314
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**RANSAC** stands for **Ran**dom **Sa**mple **C**onsensus. The key idea of
    RANSAC is that the given dataset contains a set of inliers that fit perfectly
    to a given model. It gives you the set of points that most closely satisfy a given
    constraint. In our case, these inliers would account for the points moving from
    one set of positions to another. It does not matter how numerous the outliers
    of the data set are.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '**RANSAC**代表**Ran**dom **Sa**mple **C**onsensus（随机样本一致性）。RANSAC的关键思想是给定的数据集包含一组内点，这些内点完美地适合给定的模型。它给你一组最接近满足给定约束的点。在我们的情况下，这些内点将解释为点从一个位置移动到另一个位置。数据集的异常值数量多少并不重要。'
- en: OpenCV comes with a utility function to calculate the perspective transform
    between two frames. While the transform is being estimated, the function also
    tries to figure out which points are outliers. We'll hook into this functionality
    for our purposes too!
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV附带一个计算两个帧之间透视变换的实用函数。当正在估计变换时，该函数还试图找出哪些点是异常值。我们也将利用这个功能来实现我们的目的！
- en: '[PRE68]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: We need at least four keypoints to calculate the perspective transform between
    two frames. If there aren't enough points, we just store whatever we have. We
    get a better result if there are more points and some are eliminated.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 我们至少需要四个关键点来计算两个帧之间的透视变换。如果没有足够的点，我们只需存储我们拥有的任何东西。如果有更多的点并且一些被消除，我们得到的结果会更好。
- en: '[PRE69]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Once we have everything figured out, we just store it in the frame information
    list. And this marks the end of our method!
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们弄清楚了一切，我们只需将其存储在帧信息列表中。这也标志着我们方法的结束！
- en: Handling rotations
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理旋转
- en: Let's take a look at how we rotate frames to stabilize them.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何旋转帧以稳定它们。
- en: Rotating an image
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 旋转图像
- en: 'Before we get into how images can be rotated for our project, let''s look at
    rotating images in general. The goal is to produce images like the one below:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨如何在我们的项目中旋转图像之前，让我们先看看一般如何旋转图像。目标是产生如下所示的图像：
- en: '![Rotating an image](img/00131.jpeg)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![旋转图像](img/00131.jpeg)'
- en: Rotating an image in 2D is simple, there's only one axis. A 2D rotation can
    be achieved by using an affine transform.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在2D中旋转图像很简单，只有一个轴。2D旋转可以通过使用仿射变换来实现。
- en: '![Rotating an image](img/00132.jpeg)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![旋转图像](img/00132.jpeg)'
- en: In our project, we need to rotate images around all three axes. An affine transform
    is not sufficient to produce these, so we need to go towards a perspective transform.
    Also, rotations are linear transformations; this means we can split an arbitrary
    rotation into its component X, Y, and Z rotations and use that to compose the
    rotation.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的项目中，我们需要围绕所有三个轴旋转图像。一个仿射变换不足以产生这些变换，因此我们需要转向透视变换。此外，旋转是线性变换；这意味着我们可以将任意旋转分解为其X、Y和Z分量旋转，并使用这些分量来组合旋转。
- en: To achieve this, we'll use the OpenCV Rodrigues function call to generate these
    transformation matrices. Let's start by writing a function that arbitrarily rotates
    an image.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们将使用OpenCV的Rodrigues函数调用生成这些变换矩阵。让我们先写一个函数，它可以任意旋转一个图像。
- en: '[PRE70]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: This method accepts a source image that needs to be rotated, the three rotation
    angles, an optional translation, the focal length in pixels, and whether the angles
    are in radians or not. If the angles are in degrees, we need to convert them to
    radians. We also force convert these into `float`.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法接受一个需要旋转的源图像，三个旋转角度，一个可选的平移，像素焦距，以及角度是否以弧度表示。如果角度是以度表示的，我们需要将它们转换为弧度。我们还强制将它们转换为`float`。
- en: Next, we'll calculate the width and the height of the source image. These, along
    with the focal length, are used to transform the rotation matrix (which is in
    real world space) into image space.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将计算源图像的宽度和高度。这些，连同焦距，用于将旋转矩阵（在现实世界空间中）转换为图像空间。
- en: '[PRE71]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Now, we use the Rodrigues function to generate the rotation matrix:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用Rodrigues函数生成旋转矩阵：
- en: '[PRE72]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: The Rodrigues function takes a vector (a list) that contains the three rotation
    angles and returns the rotation matrix. The matrix returned is a 3x3 matrix. We'll
    convert that into a 4x4 homogeneous matrix so that we can apply transformations
    to it.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: Rodrigues函数接受一个包含三个旋转角度的向量（列表），并返回一个旋转矩阵。返回的矩阵是一个3x3矩阵。我们将将其转换为4x4齐次矩阵，这样我们就可以对其应用变换。
- en: Note
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It's usually a good idea to keep dz equal to the focal length. This implies
    that the image was captured at just the right focal length and needs to be rotated
    about that point. You are free to change dz to other values, but usually setting
    it equal to F gives good results.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，保持dz等于焦距是一个好主意。这意味着图像是在正确的焦距下捕获的，并且需要围绕这个点旋转。你可以自由地将dz更改为其他值，但通常将dz设置为F可以得到很好的结果。
- en: 'We now apply a simple translation to the matrix. The translation matrix is
    easily evaluated as follows:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将一个简单的平移应用到矩阵上。平移矩阵可以很容易地评估如下：
- en: '[PRE73]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Until now, all transformations have happened in world space. We need to change
    these into image space. This is accomplished by the simple pinhole model of a
    camera.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，所有的变换都是在世界空间中发生的。我们需要将这些变换转换为图像空间。这是通过相机的简单针孔模型实现的。
- en: '[PRE74]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Combining these transforms is straightforward:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 结合这些变换是直接的：
- en: '[PRE75]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: This matrix can now be used in OpenCV's `warpPerspective` method to rotate the
    source image.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵现在可以用于OpenCV的`warpPerspective`方法来旋转源图像。
- en: '[PRE76]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: The output of this isn't exactly what you want though, the images are rotated
    about (0, 0) in the image. We need to rotate the image about the center. To achieve
    this, we need to insert an additional translation matrix right *before* the rotations
    happen.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这个输出的结果并不是你想要的，图像是围绕图像中的(0, 0)旋转的。我们需要围绕图像中心旋转。为了实现这一点，我们需要在旋转发生之前插入一个额外的平移矩阵。
- en: '[PRE77]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Now, we insert the matrix A1 at the very beginning:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们在非常开始处插入矩阵A1：
- en: '[PRE78]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Now images should rotate around the center; this is exactly what we want and
    is a self-contained method that we can use to rotate images arbitrarily in 3D
    space using OpenCV.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 现在图像应该围绕中心旋转；这正是我们想要的，并且是一个自包含的方法，我们可以使用它来使用OpenCV在3D空间中任意旋转图像。
- en: Accumulated rotations
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 累积旋转
- en: Rotating an image with a single rotation vector is quite straightforward. In
    this section, we'll extend that method so it is better suited for our project.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单个旋转向量旋转图像相当直接。在本节中，我们将扩展该方法，使其更适合我们的项目。
- en: 'We have two data sources active when recording a video: the image capture and
    the gyroscope trace. These are captured at different rates—images every few milliseconds
    and gyroscope signals every few microseconds. To calculate the exact rotation
    required to stabilize an image, we need to accumulate the rotation of dozens of
    gyroscope signals. This means that the rotation matrix needs to have information
    on several different gyroscope data samples.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在录制视频时，我们有两个数据源处于活动状态：图像捕获和陀螺仪轨迹。这些是在不同的速率下捕获的——每几毫秒捕获一次图像，每几微秒捕获一次陀螺仪信号。为了计算稳定图像所需的精确旋转，我们需要累积数十个陀螺仪信号。这意味着旋转矩阵需要有关多个不同陀螺仪数据样本的信息。
- en: Also, the gyroscope and image sensors are not in sync; we will need to use linear
    interpolation on the gyroscope signals to bring them in sync.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，陀螺仪和图像传感器不同步；我们需要在陀螺仪信号上使用线性插值来使它们同步。
- en: Let's write a function that returns the transformation matrix.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个返回变换矩阵的函数。
- en: '[PRE79]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'This function takes a lot of parameters. Let''s go over each of them:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数接受很多参数。让我们逐一介绍它们：
- en: '`w`, `h`: We need to know the size of the image to convert it from world space
    to image space.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`w`、`h`：我们需要知道图像的大小，以便将其从世界空间转换为图像空间。'
- en: 'theta_*: Currently, we have access to angular velocity. From there, we can
    evaluate actual angles and that is what this function accepts as parameters.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: theta_*：目前，我们可以访问角速度。从那里，我们可以评估实际角度，这正是这个函数作为参数接受的。
- en: 'Timestamps: The time each sample was taken.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间戳：每个样本被采集的时间。
- en: '`prev`, `current`: Accumulate rotations between these timestamps. This will
    usually provide the timestamp of the previous frame and the current frame.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prev`、`current`：在这些时间戳之间累积旋转。这通常将提供前一帧和当前帧的时间戳。'
- en: '`f`, `gyro_delay`, `gyro_drift`, and `shutter_duration` are used to improve
    the estimate of the rotation matrix. The last three of these are optional (and
    they get set to zero if you don''t pass them).'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`f`、`gyro_delay`、`gyro_drift`和`shutter_duration`被用来提高旋转矩阵估计的准确性。其中最后三个是可选的（如果你没有传递它们，它们将被设置为0）。'
- en: From the previous section, we know that we need to start by translating (or
    we'll get rotations about (0, 0)).
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一节中，我们知道我们需要先进行平移（否则我们将得到关于(0, 0)的旋转）。
- en: '[PRE80]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: We'll use the "transform" matrix to accumulate rotations across multiple gyroscope
    samples.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用“变换”矩阵来累积多个陀螺仪样本之间的旋转。
- en: Next, we offset the timestamps by using `gyro_delay`. This is just adding (or
    subtracting, based on the sign of its value) to the timestamp.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`gyro_delay`偏移时间戳。这只是在时间戳上添加（或根据其值的符号减去）。
- en: '[PRE81]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: If the updated `prev` and `current` values exist in the timestamps (meaning
    we have values captured from the sensor at that time instant) – great! No need
    to interpolate. Otherwise, we use the function `fetch_closest_trio` to interpolate
    the signals to the given timestamp.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 如果更新的`prev`和`current`值存在于时间戳中（这意味着我们在那个时间瞬间从传感器捕获了值）——太好了！不需要插值。否则，我们使用`fetch_closest_trio`函数来将信号插值到给定的时间戳。
- en: 'This helper function returns three things:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 这个辅助函数返回三件事：
- en: The interpolated rotation for the requested timestamp
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求时间戳的插值旋转
- en: The closest timestamp in the sensor data
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传感器数据中最接近的时间戳
- en: The timestamp right after it
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它之后的那个时间戳
- en: We use `start_timestamp` and `end_timestamp` for iterating now.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用`start_timestamp`和`end_timestamp`进行迭代。
- en: '[PRE82]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: We iterate over each timestamp in the physical data. We add the gyroscope delay
    and use that to fetch the closest (interpolated) signals. Once that's done, we
    add the gyroscope drift per component. This is just a constant that should be
    added to compensate for errors in the gyroscope.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历物理数据中的每个时间戳。我们添加陀螺仪延迟并使用它来获取最接近的（插值）信号。一旦完成，我们为每个组件添加陀螺仪漂移。这只是一个常数，应该添加以补偿陀螺仪的错误。
- en: Using these rotation angles, we now calculate the rotation matrix, as in the
    previous section.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些旋转角度，我们现在计算旋转矩阵，就像上一节中那样。
- en: '[PRE83]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: This piece of code is almost the same as that in the previous section. There
    are a few key differences though. Firstly, we're providing negative values to
    Rodrigues. This is to negate the effect of motion. Secondly, the X and Y values
    are swapped. (`gyro_drifted[1]` comes first, followed by `gyro_drifted[0]`). This
    is required because the axes of the gyroscope and the ones used by these matrices
    are different.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码几乎与上一节中的相同。尽管如此，也有一些关键的区别。首先，我们向Rodrigues提供负值。这是为了抵消运动的影响。其次，X和Y的值被交换了。（`gyro_drifted[1]`排在前面，然后是`gyro_drifted[0]`）。这是必需的，因为陀螺仪的轴和这些矩阵使用的轴是不同的。
- en: 'This completes the iteration over the gyroscope samples between the specified
    timestamps. To complete this, we need to translate in the Z direction just like
    in the previous section. Since this can be hardcoded, let''s do that:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了在指定时间戳之间对陀螺仪样本的迭代。为了完成这个任务，我们需要在Z方向上平移，就像在上一节中做的那样。由于这可以硬编码，让我们这样做：
- en: '[PRE84]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: We also need to use the camera matrix to convert from world space to image space.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要使用相机矩阵将世界空间转换为图像空间。
- en: '[PRE85]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: We first translate in the Z direction and then convert to image space. This
    section essentially lets you rotate frames of your video with the gyroscope parameters.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在Z方向上平移，然后转换为图像空间。这一节实际上允许你使用陀螺仪参数旋转视频帧。
- en: The calibration class
  id: totrans-385
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准类
- en: With our data structures ready, we're in a good place to start the key piece
    of this project. The calibration builds on all the previously mentioned classes.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 数据结构准备就绪后，我们就处于开始这个项目关键部分的良好位置。校准建立在之前提到的所有类的基础上。
- en: As always, we'll create a new class which encapsulates all the calibration-related
    tasks.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们将创建一个新的类，它封装了所有与校准相关的任务。
- en: '[PRE86]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The object requires two things: the video file and the gyroscope data file.
    These get stored in the object.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 该对象需要两个东西：视频文件和陀螺仪数据文件。这些将被存储在对象中。
- en: Before jumping directly into the calibration method, let's create some utility
    functions that will be helpful when calibrating.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在直接跳入校准方法之前，让我们创建一些在校准时会有帮助的实用函数。
- en: '[PRE87]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: This method generates a Gaussian kernel of a given size. We'll use this to smooth
    out the angular velocity signals in a bit.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法生成一个给定大小的高斯核。我们将使用它来平滑角速度信号。
- en: '[PRE88]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: This function does the actual smoothing of a signal. Given an input signal,
    it generates the Gaussian kernel and convolves it with the input signal.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数执行信号的真正平滑。给定一个输入信号，它生成高斯核并与输入信号卷积。
- en: Note
  id: totrans-395
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Convolutions are a mathematical tool to produce new functions. You can think
    of the gyroscope signal as a function; you give it a timestamp and it returns
    a value. To smooth it out, we need to combine it with another function. This function,
    called the Gaussian function, is a smooth bell curve. Both these functions have
    different time ranges on which they operate (the gyroscope function might return
    values between a time of 0 seconds and 50 seconds while the Gaussian function
    might just work for a time of 0 seconds to 5 seconds). Convolving these two functions
    produces a third function that behaves a bit like both, thereby effectively smoothing
    out the minor variations in the gyroscope signal.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积是产生新函数的数学工具。你可以把陀螺仪信号看作一个函数；你给它一个时间戳，它就返回一个值。为了使其平滑，我们需要将其与另一个函数结合。这个函数称为高斯函数，是一个平滑的钟形曲线。这两个函数在不同的时间范围内操作（陀螺仪函数可能在0秒到50秒之间返回值，而高斯函数可能只适用于0秒到5秒的时间）。卷积这两个函数产生第三个函数，它在某种程度上类似于两者，从而有效地平滑了陀螺仪信号中的微小变化。
- en: Next, we write a function that calculates an error score giving two sets of
    points. This will be a building block in estimating how good the calibration has
    been.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们编写一个函数，它计算两个点集的错误分数。这将是估计校准效果好坏的一个构建块。
- en: '[PRE89]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'This error score is straightforward: you have two lists of points and you calculate
    the distance between the corresponding points on the two lists and sum it up.
    A higher error score means the points on the two lists don''t correspond perfectly.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 这个错误分数是直接的：你有两个点列表，你计算两个列表上对应点的距离并将它们相加。更高的错误分数意味着两个列表上的点不完全对应。
- en: This method, however, only gives us the error on a single frame. We're concerned
    about errors across the whole video. We therefore write another method.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法只给出了单个帧上的错误。我们关心的是整个视频中的错误。因此，我们编写了另一个方法。
- en: '[PRE90]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: We pass in the video object and all the details we have estimated (the theta,
    timestamps, focal length, gyroscope delay, and so on). With these details, we
    try to do the video stabilization and see what differences exists between the
    visually tracked keypoints and the gyroscope-based transformations.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传递视频对象和所有已估计的细节（theta、时间戳、焦距、陀螺仪延迟等）。有了这些细节，我们尝试进行视频稳定并查看视觉跟踪的关键点与基于陀螺仪的转换之间的差异。
- en: 'Since we''re calculating the error across the whole video, we need to iterate
    over each frame. If the frame''s information does not have any keypoints in it,
    we simply ignore the frame. If the frame does have keypoints, here''s what we
    do:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在计算整个视频的误差，我们需要遍历每一帧。如果帧的信息中没有关键点，我们就简单地忽略该帧。如果帧中有关键点，这里是我们所做的工作：
- en: '[PRE91]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: The `getAccumulatedRotation` function is something we'll write soon. The key
    idea of the function is to return a transformation matrix for the given theta
    (the angles we need to rotate to stabilize the video). We can apply this transform
    to `old_corners` and compare it to `new_corners`.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '`getAccumulatedRotation` 函数是我们很快将要编写的。该函数的关键思想是返回给定 theta（我们需要旋转以稳定视频的角度）的转换矩阵。我们可以将此转换应用于
    `old_corners` 并将其与 `new_corners` 进行比较。'
- en: 'Since `new_corners` was obtained visually, it is the ground truth. We want
    `getAccumulatedRotation` to return a transformation that matches the visual ground
    truth perfectly. This means the error between `new_corners` and the transformed
    `old_corners` should be minimal. This is where `calcErrorScore` helps us:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `new_corners` 是通过视觉获得的，因此它是真实值。我们希望 `getAccumulatedRotation` 返回一个与视觉真实值完美匹配的转换。这意味着
    `new_corners` 和转换后的 `old_corners` 之间的误差应该是最小的。这就是 `calcErrorScore` 帮助我们的地方：
- en: '[PRE92]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'We''re ready to calculate the error across the whole video! Now let''s move
    to the calibration function:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好在整个视频中计算误差！现在让我们转到校准函数：
- en: '[PRE93]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The first step is to smooth out the noise in the angular velocity signals. This
    is the desired signal with smooth motion.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是平滑角速度信号中的噪声。这是具有平滑运动的期望信号。
- en: '[PRE94]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: We'll be writing the `gaussian_filter` method soon; for now, let's just keep
    in mind that it returns a smoothed out signal.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快将编写 `gaussian_filter` 方法；现在，让我们记住它返回一个平滑的信号。
- en: '![The calibration class](img/00133.jpeg)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
  zh: '![校准类](img/00133.jpeg)'
- en: Next, we calculate the difference between the physical signal and the desired
    signal. We need to do this separately for each component.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算物理信号和期望信号之间的差异。我们需要为每个组件分别进行此操作。
- en: '[PRE95]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: We also need to calculate the delta between the timestamps. We'll be using this
    for integration.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要计算时间戳之间的差值。我们将使用这个差值来进行积分。
- en: '[PRE96]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Next, we integrate the angular velocities to get actual angles. Integration
    introduces errors into our equations but that's okay. It is good enough for our
    purposes.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将角速度积分以获得实际角度。积分会引入我们的方程中的误差，但这没关系。对于我们的目的来说，这已经足够好了。
- en: '[PRE97]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: And that's it. We have calculated the amount of theta that will stabilize the
    image! However, this is purely from the gyroscope's view. We still need to calculate
    the unknowns so that we can use these thetas to stabilize the image.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。我们已经计算了将稳定图像的 theta 数量！然而，这纯粹是从陀螺仪的角度来看。我们仍然需要计算未知数，以便我们可以使用这些 theta 来稳定图像。
- en: To do this, we initialize some of the unknowns as variables with an arbitrary
    initial value (0 in most cases). Also, we load the video and process the keypoint
    information.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们将一些未知数初始化为具有任意初始值的变量（大多数情况下为0）。同时，我们加载视频并处理关键点信息。
- en: '[PRE98]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: Now, we use SciPy's optimize method to minimize the error. To do this, we must
    first convert these unknowns into a Numpy array.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用 SciPy 的优化方法来最小化误差。为此，我们必须首先将这些未知数转换为 Numpy 数组。
- en: '[PRE99]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Since we''ve not yet incorporated fixing the rolling shutter, we ignore that
    in the parameters list. Next, we call the actual optimization function:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们尚未将固定滚动快门纳入其中，因此在参数列表中忽略它。接下来，我们调用实际的优化函数：
- en: '[PRE100]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Executing this function takes a few seconds, but it produces the values of
    the unknowns for us. We can then extract these from the result as follows:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此函数需要几秒钟，但它会为我们提供未知数的值。然后我们可以按照以下方式从结果中提取这些值：
- en: '[PRE101]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: With this, we're done with calibration! All we need to do is return all the
    relevant calculations we've done just now.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就完成了校准！我们只需要返回刚才所做的所有相关计算。
- en: '[PRE102]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: And that's a wrap!
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，大功告成！
- en: Undistorting images
  id: totrans-432
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矫正图像
- en: In the previous section, we calculated all the unknowns in our equations. Now,
    we can go ahead with fixing the shaky video.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们计算了方程中的所有未知数。现在，我们可以继续修复摇摇晃晃的视频。
- en: We'll start off by creating a new method called `stabilize_video`. This method
    will take a video file and a corresponding csv file.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建一个新的方法，称为`stabilize_video`。这个方法将接受一个视频文件和一个相应的csv文件。
- en: '[PRE103]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: We create an object of the calibration class we just defined and pass it the
    required information. Now, we just need to call the calibrate function.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个我们刚刚定义的校准类对象，并传递了所需的信息。现在，我们只需要调用校准函数。
- en: '[PRE104]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: This method call may take a while to execute, but we need to run this only once
    for every device. Once calculated, we can store these values in a text file and
    read them from there.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法调用可能需要一段时间才能执行，但我们只需要为每个设备运行一次。一旦计算出来，我们可以将这些值存储在文本文件中，并从中读取。
- en: Once we have estimated all the unknowns, we start by reading the video file
    for each frame.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们估计了所有未知数，我们就开始读取每个帧的视频文件。
- en: '[PRE105]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: Now we start iterating over each frame and correcting the rotations.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们开始遍历每一帧并纠正旋转。
- en: '[PRE106]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: Next, we fetch the timestamp from the video stream and use that to fetch the
    closest rotation sample.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们从视频流中获取时间戳，并使用它来获取最近的旋转样本。
- en: '[PRE107]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: The `VideoCapture` class returns timestamps in milliseconds. We convert that
    into nanoseconds to keep consistent units.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '`VideoCapture`类返回毫秒级的时间戳。我们将它转换为纳秒以保持一致的单位。'
- en: '[PRE108]'
  id: totrans-446
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: With these pieces, we now fetch the accumulated rotation.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了这些部分，我们现在获取累积的旋转。
- en: '[PRE109]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'Next, we write the transformed frame into a file and move on to the next frame:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将变换后的帧写入文件，并继续处理下一帧：
- en: '[PRE110]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: And this finishes our simple function to negate the shakiness of the device.
    Once we have all the images, we can combine them into a single video with `ffmpeg`.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就完成了消除设备抖动的简单函数。一旦我们有了所有图像，我们就可以使用`ffmpeg`将它们合并成一个单独的视频。
- en: '[PRE111]'
  id: totrans-452
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: Testing calibration results
  id: totrans-453
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试校准结果
- en: The effectiveness of the calibration depends on how accurately it can replicate
    motion on the video. For any frame, we have matching keypoints in the previous
    and current frames. This gives a sense of the general motion of the scene.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 校准的有效性取决于它能够多准确地复制视频上的运动。对于任何一帧，我们都有前一帧和当前帧中匹配的关键点。这给出了场景一般运动的感觉。
- en: Using the estimated parameters, if we are able to use previous frames' keypoints
    to generate the current frames' keypoints, we can assume the calibration has been
    successful.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 使用估计的参数，如果我们能够使用前一帧的关键点来生成当前帧的关键点，我们可以假设校准已经成功。
- en: Rolling shutter compensation
  id: totrans-456
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 滚动快门补偿
- en: At this point, our video is stable, however, when objects in the scene are moving
    quickly, the rolling shutter effects become more pronounced.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的视频已经稳定，然而，当场景中的物体快速移动时，滚动快门效应变得更加明显。
- en: To fix this, we'll need to do a few things. First, incorporate the rolling shutter
    speed into our calibration code. Second, when warping images, we need to unwarp
    the rolling shutter as well.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们需要做几件事情。首先，将滚动快门速度纳入我们的校准代码。其次，在扭曲图像时，我们还需要对滚动快门进行反扭曲。
- en: Calibrating the rolling shutter
  id: totrans-459
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准滚动快门
- en: 'To start calibrating the rolling shutter duration, we need to tweak the error
    function to incorporate another term. Let''s start by looking at the `calcErrorAcrossVideo`
    method. The part we''re interested in is:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始校准滚动快门持续时间，我们需要调整误差函数以包含另一个项。让我们先看看`calcErrorAcrossVideo`方法。我们感兴趣的部分是：
- en: '[PRE112]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: Also, we'll need to add logic to transform a corner based on its location—a
    corner in the upper part of the image is transformed differently from a corner
    in the lower half.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还需要添加逻辑来根据角落的位置变换一个角落——图像上半部分的角落与下半部分的角落变换方式不同。
- en: So far, we have had a single transformation matrix and that was usually sufficient.
    However, now, we need to have multiple transformation matrices, one for each row.
    We could choose to do this for every row of pixels, however that is a bit excessive.
    We only need transforms for rows that contain a corner we're tracking.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只有一个变换矩阵，这通常足够了。然而，现在，我们需要有多个变换矩阵，每个行都有一个。我们可以选择为每个像素行都这样做，但这有点过度。我们只需要包含我们正在跟踪的角落的行的变换。
- en: 'We''ll start by replacing the two lines mentioned above. We need to loop over
    each corner individually and warp it. Let''s do this with a simple `for` loop:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先替换上面提到的两行。我们需要逐个遍历每个角落并对其进行扭曲。让我们用一个简单的`for`循环来做这件事：
- en: '[PRE113]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: Here, we extract the x and y coordinates of the old corner and try to estimate
    the timestamp when this particular pixel was captured. Here, I'm assuming the
    rolling shutter is in the vertical direction, from the top of the frame to the
    bottom.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们提取旧角点的 x 和 y 坐标，并尝试估计这个特定像素被捕获的时间戳。这里，我假设滚动快门是垂直方向的，从画面顶部到底部。
- en: We use the current estimate of the rolling shutter duration and estimate subtract
    and add time based on the row the corner belongs to. It should be simple to adapt
    this for a horizontal rolling shutter as well. Instead of using `y` and `frameHeight`,
    you would have to use `x` and `frameWidth`—the calculation would stay the same.
    For now, we'll just assume this is going to be a vertical rolling shutter.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用当前估计的滚动快门持续时间，并根据角点所在的行估计减去和添加的时间。对于水平滚动快门，这也应该很容易适应。你将不得不使用 `x` 和 `frameWidth`
    而不是 `y` 和 `frameHeight`——计算将保持不变。目前，我们假设这将是一个垂直滚动快门。
- en: Now that we have the estimated timestamp of capture, we can get the rotation
    matrix for that instant (remember, the gyroscope produces a higher resolution
    data than the camera sensor).
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了捕获的估计时间戳，我们可以得到那个瞬间的旋转矩阵（记住，陀螺仪产生的数据分辨率高于相机传感器）。
- en: '[PRE114]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: This line is almost the same as the original we had; the only difference is
    that we've replaced `current_timestamp` with `pt_timestamp`.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 这行几乎与原始的相同；唯一的区别是我们将 `current_timestamp` 替换为 `pt_timestamp`。
- en: Next, we need to transform this point based on the rolling shutter duration.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要根据滚动快门持续时间转换这个点。
- en: '[PRE115]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: After transforming, we simply append it to the `transformed_corners` list (just
    like we did earlier).
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 变换后，我们只需将其追加到 `transformed_corners` 列表（就像我们之前做的那样）。
- en: With this, we're done with the calibration part. Now, we move onto warping images.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个，我们就完成了校准部分。现在，我们转向图像扭曲。
- en: Warping with grid points
  id: totrans-475
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用网格点进行扭曲
- en: 'Let''s start by writing a function that will do the warping for us. This function
    takes in these inputs:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先编写一个函数，这个函数将为我们执行扭曲。这个函数接受以下输入：
- en: The original image
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始图像
- en: A bunch of points that should ideally line up in a perfect grid
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列理想上应该整齐排列在完美网格中的点
- en: The size of the point list gives us the number of rows and columns to expect
    and the function returns a perfectly aligned image.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 点列表的大小给我们提供了预期的行数和列数，并且该函数返回一个完美对齐的图像。
- en: '![Warping with grid points](img/00134.jpeg)'
  id: totrans-480
  prefs: []
  type: TYPE_IMG
  zh: '![使用网格点进行扭曲](img/00134.jpeg)'
- en: 'Let''s define the function:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个函数：
- en: '[PRE116]'
  id: totrans-482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: As mentioned earlier, this takes in an image and the list of control points.
    We store the size of the image for future reference.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这需要一个图像和控制点的列表。我们存储图像的大小以供将来参考。
- en: '[PRE117]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: The size we stored earlier will most likely have three channels in it. So we
    create a new variable called `mapsize`; this stores the size of the image but
    only one channel. We'll use this later for creating matrices for use by the remap
    function in OpenCV.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前存储的大小很可能有三个通道。因此，我们创建了一个名为 `mapsize` 的新变量；它存储了图像的大小，但只有一个通道。我们将在以后使用它来创建
    OpenCV 中 remap 函数使用的矩阵。
- en: We also create a blank image of the same size as the original. Next, we look
    at calculating the number of rows and columns in the grid.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还创建了一个与原始图像大小相同的空白图像。接下来，我们查看计算网格中的行数和列数。
- en: '[PRE118]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: We'll use the variables in some loops soon.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快将在一些循环中使用这些变量。
- en: '[PRE119]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: These lists store all the source (distorted) points and the destination (perfectly
    aligned) points. We'll have to use `distorted_grid` to populate `pt_src_all`.
    We'll procedurally generate the destination based on the number of rows and columns
    in the input data.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 这些列表存储了所有源（扭曲）点和目标（完美对齐）点。我们将使用 `distorted_grid` 来填充 `pt_src_all`。我们将根据输入数据中的行数和列数程序性地生成目标。
- en: '[PRE120]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: The distorted grid should be a list of lists. Each row is a list that contains
    its points.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 变形网格应该是一个列表的列表。每一行是一个包含其点的列表。
- en: Now, we generate the procedural destination points using the `quads_per_*` variables
    we calculated earlier.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用之前计算的 `quads_per_*` 变量生成程序性目标点。
- en: '[PRE121]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: This generates the ideal grid based on the number of points we passed to the
    method.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 这根据我们传递给方法的点数生成理想的网格。
- en: We then have all the required information to calculate the interpolation between
    the source and destination grids. We'll be using `scipy` to calculate the interpolation
    for us. We then pass this to OpenCV's remap method and that applies it to an image.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了计算源网格和目标网格之间插值所需的所有信息。我们将使用`scipy`为我们计算插值。然后我们将其传递给OpenCV的remap方法，并将其应用于图像。
- en: 'To begin with, `scipy` needs a representation of the expected output grid so
    we need to specify a dense grid that contains all the pixels of the image. This
    is done with:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`scipy`需要一个表示预期输出网格的表示，因此我们需要指定一个包含图像所有像素的密集网格。这是通过以下方式完成的：
- en: '[PRE122]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: Once we have the base grid defined, we can use Scipy's `interpolate` module
    to calculate the mapping for us.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了基本网格，我们就可以使用Scipy的`interpolate`模块来为我们计算映射。
- en: '[PRE123]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '`g_out` contains both the `x` and `y` coordinates of the remapping; we need
    to split this into individual components for OpenCV''s `remap` method to work.'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '`g_out`包含重新映射的`x`和`y`坐标；我们需要将其拆分为单独的组件，以便OpenCV的`remap`方法能够工作。'
- en: '[PRE124]'
  id: totrans-502
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: These matrices are exactly what remap expects and we can now simply run it with
    the appropriate parameters.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 这些矩阵正是remap所期望的，我们可以现在简单地用适当的参数运行它。
- en: '[PRE125]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: And that completes our method. We can use this in our stabilization code and
    fix the rolling shutter as well.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就完成了我们的方法。我们可以在我们的稳定化代码中使用它，并修复滚动快门。
- en: Unwarping with calibration
  id: totrans-506
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用校准去畸变
- en: Here, we discuss how to warp images given a mesh for stabilizing the video.
    We split each frame into a 10x10 mesh. We warp the mesh and that results in warping
    the image (like control points). Using this approach, we should get good results
    and decent performance as well.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们讨论了如何根据网格对视频进行稳定化扭曲图像。我们将每一帧分割成10x10的网格。我们扭曲网格，这会导致图像扭曲（就像控制点）。使用这种方法，我们应该得到良好的结果和不错的性能。
- en: 'The actual unwarp happens in the `accumulateRotation` method:'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的去畸变发生在`accumulateRotation`方法中：
- en: '[PRE126]'
  id: totrans-509
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: 'Here, there''s a single perspective transform happening. Now, instead, we have
    to do a different transform for each of the 10x10 control points and use the `meshwarp`
    method to fix the rolling shutter. So replace the `transform =` line with the
    contents below:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，有一个单一的透视变换正在进行。现在，相反，我们必须对每个10x10的控制点进行不同的变换，并使用`meshwarp`方法来修复滚动快门。所以用下面的内容替换`transform
    =`行：
- en: '[PRE127]'
  id: totrans-511
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'We have now generated the original grid in the `pts` list. Now, we need to
    generate the transformed coordinates:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经在`pts`列表中生成了原始网格。现在，我们需要生成变换坐标：
- en: '[PRE128]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: 'If a shutter duration is passed, we generate the timestamp at which this specific
    pixel was recorded. Now we can transform (`pixel_x`, `pixel_y`) based on the shutter
    rotation and append that to `current_row_transformed`:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 如果传递了快门持续时间，我们生成记录这个特定像素的时间戳。现在我们可以根据快门旋转变换（`pixel_x`，`pixel_y`），并将其附加到`current_row_transformed`：
- en: '[PRE129]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'This completes the grid for `meshwarp`. Now all we need to do is generate the
    warped image. This is simple since we already have the required method:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了`meshwarp`的网格。现在我们只需要生成扭曲后的图像。这很简单，因为我们已经有了所需的方法：
- en: '[PRE130]'
  id: totrans-517
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: And this completes our transformation. We now have rolling shutter incorporated
    into our undistortion as well.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就完成了我们的变换。现在，滚动快门也被纳入了我们的去畸变中。
- en: What's next?
  id: totrans-519
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接下来是什么？
- en: What we have right now is a very barebones implementation of video stabilization.
    There are a few more things you can add to it to make it more robust, more automated
    and the output more pleasing to the eye. Here are a few things to get you started.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个非常基础的视频稳定化实现。你可以添加一些东西来使其更健壮、更自动化，并且输出更令人满意。以下是一些开始的方法。
- en: Identifying gyroscope axes
  id: totrans-521
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别陀螺仪轴
- en: In this chapter, we've hard-coded the axes of the gyroscope. This might not
    be the case for all mobile phone manufacturers. Using a similar calibration technique,
    you should be able to find an axes configuration that minimizes errors across
    the video.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们硬编码了陀螺仪的轴。这可能并不适用于所有手机制造商。使用类似的校准技术，你应该能够找到一个最小化视频误差的轴配置。
- en: Estimating the rolling shutter direction
  id: totrans-523
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 估计滚动快门方向
- en: We've hard-coded the direction of the rolling shutter. Using specific techniques
    (like blinking an LED really fast at the camera), it is possible to estimate the
    direction of the rolling shutter and incorporate that into the calibration code.
    Certain camera sensors don't have the rolling shutter artifacts at all. This test
    can also identify if such a sensor is being used.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经硬编码了滚动快门的方向。使用特定的技术（比如在相机上快速闪烁LED），可以估计滚动快门的方向并将其纳入校准代码。某些相机传感器根本不具有滚动快门的伪影。这个测试还可以确定是否使用了这样的传感器。
- en: Smoother timelapses
  id: totrans-525
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更平滑的时间流逝
- en: Now that we've stabilized the video, we can speed up (or slow down) the video
    much better. There are commercial packages that do similar tasks – now your OpenCV
    code can do it too!
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经稳定了视频，我们可以更好地加快（或减慢）视频的速度。有一些商业软件包执行类似任务——现在你的OpenCV代码也可以做到这一点！
- en: Repository of calibration parameters
  id: totrans-527
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准参数仓库
- en: You will have to calibrate every new device type you come across. If you move
    from one device type (say, a Samsung S5 to an iPhone 6), you'll have to run a
    calibration for this combination of lens and sensor. However, moving between different
    devices of the same kind does not require a re-calibration (such as moving from
    one iPhone 6 to another). If you're able to collect enough calibration results,
    your code can run perfectly on pretty much any device.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 你将不得不校准你遇到的每一种新设备类型。如果你从一个设备类型（比如，从三星S5切换到iPhone 6），你将不得不为此组合的镜头和传感器运行校准。然而，在不同类型的同一设备之间移动不需要重新校准（比如，从一个iPhone
    6移动到另一个）。如果你能收集足够的校准结果，你的代码几乎可以在任何设备上完美运行。
- en: Note
  id: totrans-529
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You could also figure out a fallback mechanism if the repository does not have
    the required parameters.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仓库中没有所需的参数，你也可以想出一个后备机制。
- en: Incorporating translations
  id: totrans-531
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 翻译的整合
- en: Currently, we're only using rotations. This means that if you shake the camera
    in a single plane, the algorithm won't do much. By using inputs from the accelerometer
    and using the translation of keypoints, it should be possible to compensate for
    translation as well. This should produce higher quality video.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们只使用旋转。这意味着如果你在单一平面上摇动相机，算法不会做太多。通过使用加速度计的输入和使用关键点的平移，应该可以补偿平移。这将产生更高品质的视频。
- en: Additional tips
  id: totrans-533
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外的提示
- en: Here are some additional things to keep in mind while working with Python and
    computer vision in general. They should help speed up your work and keep you safe
    from unexpected crashes!
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Python和计算机视觉时，以下是一些需要记住的额外事项。它们应该有助于加快你的工作并让你免受意外崩溃的影响！
- en: Use the Python pickle module
  id: totrans-535
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Python的pickle模块
- en: Python gives us a neat way to store Python objects as files on disk. In our
    project, we have the gyroscope calibration class. This class stores information
    like the video dimensions and keypoints across different frames. Calculating this
    information from scratch everytime you want to test your code is cumbersome. You
    can easily pickle this object into a file and read back the data when required.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: Python为我们提供了一种巧妙的方法，可以将Python对象作为文件存储在磁盘上。在我们的项目中，我们有陀螺仪校准类。这个类存储了视频尺寸和关键点等信息，这些信息跨越不同的帧。每次你想测试你的代码时，从头开始计算这些信息是繁琐的。你可以轻松地将这个对象序列化到文件中，并在需要时读取回数据。
- en: 'Here is some sample code for pickling the video object in our code:'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们代码中序列化视频对象的示例代码：
- en: '[PRE131]'
  id: totrans-538
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'To read the object back into the script:'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将对象读回脚本中：
- en: '[PRE132]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: This saves time when iterating on code and verifying if something works as expected.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 这在迭代代码和验证是否按预期工作方面节省了时间。
- en: Write out single images
  id: totrans-542
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输出单个图像
- en: When working with videos, you most often end up using something like the VideoWriter
    class from OpenCV. You feed it frames and it writes out a video file. While this
    is a perfectly valid way to get things done, you have more control if you write
    out individual frames to disk and then use a video encoder to combine the images
    into a video stream.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理视频时，你通常最终会使用类似OpenCV中的VideoWriter类。你给它提供帧，然后它输出一个视频文件。虽然这是一种完全有效的方法来完成工作，但如果你将单个帧写入磁盘，然后使用视频编码器将图像组合成视频流，你会拥有更多的控制权。
- en: A simple way to combine multiple images is to use `ffmpeg`.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `ffmpeg` 是合并多个图像的一个简单方法。
- en: '[PRE133]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: Testing without the delta
  id: totrans-546
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不使用差值进行测试
- en: In the project, we're trying to stabilize video – thus we're calculating the
    delta between the actual gyroscope signal and a smoothed out version of the signal.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目中，我们试图稳定视频——因此我们计算实际陀螺仪信号与信号平滑版本之间的差值。
- en: You might want to try it out with just the actual gyroscope signal; this will
    totally keep the video still. This might be useful for situations where you want
    the camera to appear completely still.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想只用实际的陀螺仪信号来尝试；这将完全保持视频静止。这可能适用于你希望相机看起来完全静止的情况。
- en: Summary
  id: totrans-549
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we''ve covered quite a bit: talking to your gyroscope, using
    that to find unknowns, negating the effects of camera shake and rolling shutter.'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们涵盖了相当多的内容：与陀螺仪通信、使用它来找到未知数、抵消相机抖动和滚动快门的影响。
- en: We started out by creating an Android app that uses background tasks to initiate
    recording media into a video file. While doing this, we figured out how to extend
    OpenCV's camera view class to incorporate custom UI and responsiveness. With this,
    you can now create very sophisticated UIs with an OpenCV backend. Along with this,
    we also captured the gyroscope trace and stored it in a single file. The sampling
    rate of the gyroscope and the media were different – however, we did not care
    about it at this stage. We'll let the app store a higher density of gyroscope
    traces (every few hundred microseconds versus every few dozen milliseconds for
    the media).
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建了一个Android应用，该应用使用后台任务将媒体记录到视频文件中。在这个过程中，我们发现了如何扩展OpenCV的相机视图类以包含自定义UI和响应性。有了这个，你现在可以使用OpenCV后端创建非常复杂的UI。此外，我们还捕获了陀螺仪轨迹并将其存储在一个单独的文件中。陀螺仪和媒体的采样率不同——然而，在这个阶段我们并不关心它。我们将让应用存储更高密度的陀螺仪轨迹（每几百微秒与每几十毫秒的媒体相比）。
- en: 'Once we had the media/csv pair, we used Python and the numpy/scipy libraries
    to calibrate the system. We had three unknowns initially: the pixel focal length
    of the camera, the gyroscope delay (the offset between the gyroscope recordings
    and the media timestamps) and the gyroscope drift.'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了媒体/CSV对，我们就使用Python和numpy/scipy库来校准系统。最初我们有三个未知数：相机的像素焦距、陀螺仪延迟（陀螺仪记录和媒体时间戳之间的偏移）以及陀螺仪漂移。
- en: We devised an error function that takes the expected keypoints and the transformed
    keypoints and returns the amount of errors. We then used this to calculate errors
    across the whole video. Using this, and Scipy's optimize method, we were able
    to find the values for these unknowns. This calibration needs to happen only once
    for each device type.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了一个错误函数，该函数接受预期的关键点和变换后的关键点，并返回错误量。然后我们使用这个函数来计算整个视频的错误。利用这个函数和Scipy的优化方法，我们能够找到这些未知数的值。这种校准对于每种设备类型只需要进行一次。
- en: Then we added another parameter to our calibration—the rolling shutter. Estimating
    the value of this unknown was similar to the previous three, however, incorporating
    the undistortion was a bit tricky. We had to create a new method called `meshwarp`
    that takes a distorted grid. This method rectifies the grid and removes artifacts
    due to the rolling shutter. We worked on a vertical rolling shutter, however it
    should be easy to convert it to a horizontal rolling shutter.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们为校准添加了另一个参数——滚动快门。估计这个未知数的值与前面的三个类似，然而，引入去畸变有点棘手。我们不得不创建一个新的方法`meshwarp`，它接受一个畸变的网格。这个方法校正网格并消除由于滚动快门产生的伪影。我们针对垂直滚动快门进行了工作，然而将其转换为水平滚动快门应该很容易。
- en: 'We touched upon a lot of different areas: sensors, calibration, and geometric
    distortions. I hope this chapter gives you an insight into designing your own
    pipelines for working with images.'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 我们触及了许多不同的领域：传感器、校准和几何畸变。我希望这一章能让你对设计自己的图像处理管道有所启发。
