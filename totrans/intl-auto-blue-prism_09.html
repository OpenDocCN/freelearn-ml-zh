<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><div id="_idContainer265">
			<h1 id="_idParaDest-142" class="chapter-number"><a id="_idTextAnchor146"/>9</h1>
			<h1 id="_idParaDest-143"><a id="_idTextAnchor147"/>ML Deployments and Database Operations</h1>
			<p>The biggest sources of ongoing maintenance for <em class="italic">RPA</em> are due to handling changes to the business logic (Processes) and applications (Objects). With IA, another source of ongoing changes is added into the mix—updating BP to use new ML models as they’re changed. Imagine that models are only updated once per year and that we have five models. That’s still five times per year that we’ll need to modify how our IA solutions are configured due to ML <span class="No-Break">model updates.</span></p>
			<p>Even if the updated ML model keeps the exact same API endpoint definition as before, we still need to understand what ML deployment strategy is being used, as this affects how we plan<a id="_idIndexMarker705"/> for <strong class="bold">rollbacks</strong> in case the model is not performing <span class="No-Break">as expected.</span></p>
			<p>We discussed the <strong class="bold">ML Deployer</strong> User Role in <a href="B18416_08.xhtml#_idTextAnchor133"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>. This User Role is responsible for regularly updating the <a id="_idIndexMarker706"/>ML models that are in production. In this chapter, we’ll discuss the most common ML deployment strategies, how they affect what needs to happen in BP to update the model, and the plan <span class="No-Break">for rollbacks.</span></p>
			<p>Another way that IA changes our operations lies in database maintenance and ML data extraction. <a href="B18416_08.xhtml#_idTextAnchor133"><span class="No-Break"><em class="italic">Chapter 8</em></span></a> also discussed the <strong class="bold">ML Auditor</strong> User Role, which can export Session Log data after logging into the BP software. If we don’t want to dedicate a Role within BP for this, we can instead regularly extract this data directly from <span class="No-Break">the database.</span></p>
			<p>In this chapter, we’re going to cover the following topics related to operations that emerge specifically due <span class="No-Break">to IA:</span></p>
			<ul>
				<li>ML deployments <span class="No-Break">and rollbacks</span></li>
				<li>Database maintenance and <span class="No-Break">data exporting</span></li>
			</ul>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor148"/>ML deployments and rollbacks</h1>
			<p>ML is often<a id="_idIndexMarker707"/> developed and deployed by a team that’s outside of the IA organization. Once a new model is available, the IA team needs to update the connection points between BP and the ML model so that the automation can make use of it. The steps needed to safely update these connection points from BP differ based on which ML deployment strategy is being used. In this section, we’ll describe the most common ML deployment strategies. We’ll also discuss how the IA solution configuration should be changed to make use of a new ML model, given a <span class="No-Break">particular strategy.</span></p>
			<p>The ML deployment strategy also impacts how we can roll back from a new model to a previous one. Problems with ML models often don’t result in Session-halting failures that are easily detected. Models continue to produce predictions even if they’re flawed. If an issue is discovered with a model, we need to be ready to roll back to a previous one so that automation cases can continue to run. Of course, rolling back might not be an option if we’re using <span class="No-Break">third-party-developed models.</span></p>
			<p>Recall the different ways that an ML algorithm can be triggered from BP, which were discussed in <em class="italic">Chapters 1</em>, <em class="italic">2</em>, and <em class="italic">3</em>: <em class="italic">Web</em> <em class="italic">APIs,</em> <em class="italic">CLI scripts</em>, and <em class="italic">Code Stages</em>. In the sections that follow, we’ll see how the deployment strategies for each of these differ and how our IA solution should be configured to maintain auditability. We’ll also discuss the steps needed to safely roll back an ML model to its <span class="No-Break">previous version.</span></p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor149"/>Web API deployment strategies</h2>
			<p>Common<a id="_idIndexMarker708"/> ways of deploying ML Web APIs include <em class="italic">replacement</em>, <em class="italic">rolling</em>, <em class="italic">blue-green</em>, <em class="italic">canary</em>, and <em class="italic">shadow</em> deployments. I’ll explain the underlying concepts behind each of these methods and what the IA team should do to use the new model in production. For many of these strategies, we also need to consider whether the ML team <em class="italic">overwrites</em> the previous model by reusing the <em class="italic">same API endpoint</em> or offers a <em class="italic">new endpoint</em> in addition to previous endpoints. A new endpoint allows us to quickly switch back to an <span class="No-Break">older model.</span></p>
			<h3>Replacement deployments</h3>
			<p>This is the simplest <a id="_idIndexMarker709"/>Web API deployment strategy <a id="_idIndexMarker710"/>where <em class="italic">planned downtime</em> is required. The old ML model is taken completely offline and the new model is put into place. Coordination with the ML team is needed to ensure that no Sessions are running during <a id="_idIndexMarker711"/>the<a id="_idIndexMarker712"/> <span class="No-Break">switch-over period.</span></p>
			<h4>API endpoint is overwritten</h4>
			<p>If the<a id="_idIndexMarker713"/> API endpoint is reused after the new model is deployed, it means that the URL is kept exactly the same. We need to use the <strong class="source-inline">Model Version</strong> Environment Variable (present in all of the Process templates from <a href="B18416_07.xhtml#_idTextAnchor114"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>) to keep track of when the model was <span class="No-Break">actually updated:</span></p>
			<div>
				<div id="_idContainer235" class="IMG---Figure">
					<img src="image/image_00_001.jpg" alt="Figure 9.1 – The Model Version Environment Variable should be changed when the model is updated" width="1420" height="640"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – The Model Version Environment Variable should be changed when the model is updated</p>
			<p>The sequence of steps needed to update the BP solution is shown in the following figure. Prior to deploying the new ML model, we have to ensure that Sessions that use the model have stopped running since downtime is required. After the new model is brought online, we change <strong class="source-inline">Model Version</strong> and start the <span class="No-Break">Sessions again:</span></p>
			<div>
				<div id="_idContainer236" class="IMG---Figure">
					<img src="image/image_00_002.jpg" alt="Figure 9.2 – Replacement deployments when the existing endpoint is overwritten" width="1650" height="273"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Replacement deployments when the existing endpoint is overwritten</p>
			<p>Downtime <a id="_idIndexMarker714"/>will be required for the ML team to undo their deployment in case of a rollback. A sample rollback procedure is shown in the following image. Instead of waiting for in-flight Sessions to end, you might want to request for an <strong class="bold">Immediate</strong> <strong class="bold">Stop</strong> or use the <strong class="bold">Kill Switch</strong> if the model is severely flawed. Once the previous model is brought back, we revert to the previous value of <span class="No-Break"><strong class="source-inline">Model Version</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer237" class="IMG---Figure">
					<img src="image/image_00_003.jpg" alt="Figure 9.3 – Rolling back a replacement deployment when the endpoint is overwritten" width="1650" height="273"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Rolling back a replacement deployment when the endpoint is overwritten</p>
			<p>Since this replacement deployment strategy requires downtime, it’s better suited to IA Processes where the Work Queue volumes are low and the ML model changes <span class="No-Break">are infrequent.</span></p>
			<h4>New API endpoint is created</h4>
			<p>If there’s a<a id="_idIndexMarker715"/> new API endpoint, updating the IA solution to use the new endpoint is almost the same as the steps in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.2</em>. The only difference lies in updating the Web API Service configuration to use the new API URL, in addition to the <strong class="source-inline">Model Version</strong> Environment Variable. Recall that the details of changing a URL in a Web API Service don’t actually get saved into the Audit Logs, such that you can retrieve the URL’s value. If we’re using an Object and not a Web API Service, we need to change the Environment Variable that stores the endpoint <span class="No-Break">URL instead:</span></p>
			<div>
				<div id="_idContainer238" class="IMG---Figure">
					<img src="image/image_00_004.jpg" alt="Figure 9.4 – Replacement deployments when a new endpoint is created" width="1650" height="265"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Replacement deployments when a new endpoint is created</p>
			<p>Rolling back in this case is easy, as the previous API should still be available. All we need to do is to change the Web API Service URL (or the Object Environment Variable URL), and the <strong class="source-inline">Model Version</strong> back to what they were before. If you want to be even safer, you can retire the Schedules and wait for all Sessions to be completed before making <span class="No-Break">these changes:</span></p>
			<div>
				<div id="_idContainer239" class="IMG---Figure">
					<img src="image/image_00_005.jpg" alt="Figure 9.5 – Rolling back a replacement deployment when a new endpoint is created" width="717" height="237"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – Rolling back a replacement deployment when a new endpoint is created</p>
			<p>The <em class="italic">replacement</em> strategy is<a id="_idIndexMarker716"/> probably the simplest type of deployment that exists. The remaining strategies discussed in this chapter are more sophisticated and don’t require downtime. Since there’s no downtime, there won’t be a requirement to retire/unretire schedules or ensure that Sessions that use the ML model aren’t running. Of course, it’s still safer to perform solution deployments and changes during periods of downtime. The <em class="italic">rolling updates</em> strategy is <span class="No-Break">discussed next.</span></p>
			<h3>Rolling updates</h3>
			<p>Rolling deployments can <a id="_idIndexMarker717"/>be performed when there are multiple servers hosting the API behind a load balancer. An image of a simple rolling <a id="_idIndexMarker718"/>deployment can be seen in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.6</em>. We start with all API servers connected to the load balancer, running <em class="italic">version 1</em> of the API (A). <em class="italic">Server 1</em> is removed from the load balancer (<em class="italic">B</em>), and updated to serve <em class="italic">V2</em> of the API (<em class="italic">C</em>). After updating, <em class="italic">Server 1</em> is reconnected to the load balancer (<em class="italic">D</em>), meaning that both model versions (<em class="italic">V1</em> on <em class="italic">Server 1</em> and <em class="italic">V2</em> on <em class="italic">Server 2</em>) are being served simultaneously. Next, we remove <em class="italic">Server 2</em> from the load balancer (<em class="italic">E</em>), update it to <em class="italic">V2</em> (<em class="italic">F</em>), and connect it back to the load balancer (<em class="italic">G</em>). We repeat these steps until all servers <span class="No-Break">are updated.</span></p>
			<p>Note that there’s <em class="italic">no downtime</em> for the ML API service, but there are also periods of time (<em class="italic">D</em>) where predictions can be made against both the old and new model, which complicates auditing. There’s a chance that we won’t know which model was used to make a prediction during the timeframe when both the old and new models are potentially <span class="No-Break">being served.</span></p>
			<div>
				<div id="_idContainer240" class="IMG---Figure">
					<img src="image/image_00_006.jpg" alt="Figure 9.6 – An example rolling update deployment" width="842" height="1022"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – An example rolling update deployment</p>
			<p>Again, we <a id="_idIndexMarker719"/>have to consider two cases for this type <a id="_idIndexMarker720"/>of deployment. The first is when the existing API endpoint is overwritten and the second is when a new API endpoint <span class="No-Break">is created.</span></p>
			<h4>API endpoint is overwritten</h4>
			<p>If the API endpoint<a id="_idIndexMarker721"/> is reused, we might not know which version of the API is being served while the servers behind the load balancer are being updated. The only way we would know is if the model version is returned as part of the API response, but that isn’t guaranteed. For auditing reasons, it’s safest if we suspend calling the ML endpoint just prior to when the rolling update begins and resume once we know that all servers have been updated. However, we probably won’t know when the ML team will start a rolling update, especially if they’re <span class="No-Break">third-party developers.</span></p>
			<p>In this case, it’s simplest to just update the <strong class="source-inline">Model Version</strong> Environment Variable once we receive notice that the deployment is 100% complete. If you need to know exactly which ML model has been used during the deployment timeframe, you’ll need to ask the model developers to check their <span class="No-Break">server logs:</span></p>
			<div>
				<div id="_idContainer241" class="IMG---Figure">
					<img src="image/image_00_007.jpg" alt="Figure 9.7 – Rolling deployments when the existing endpoint is overwritten" width="1209" height="330"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – Rolling deployments when the existing endpoint is overwritten</p>
			<p>Rolling back is largely the same procedure as deploying a new model. A rollback is initiated and we wait to be notified that it’s complete. Once complete, we can update the <strong class="source-inline">Model Version</strong> <span class="No-Break">Environment Variable.</span></p>
			<div>
				<div id="_idContainer242" class="IMG---Figure">
					<img src="image/image_00_008.jpg" alt="Figure 9.8 – Rolling back a rolling deployment when the endpoint is overwritten" width="1004" height="274"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – Rolling back a rolling deployment when the endpoint is overwritten</p>
			<h4>New API endpoint is created</h4>
			<p>If a new API <a id="_idIndexMarker722"/>endpoint is introduced, we need to update two things. The first is the <strong class="source-inline">Model Version</strong> Environment Variable.. The second depends on whether we’re using a <em class="italic">Web</em> API <em class="italic">Service</em> or an <em class="italic">Object</em> to call the API. Depending on which one we’re using, we either change the Web API Service configuration to use the new API URL or the Object Environment Variable/Data Item that stores the <span class="No-Break">API URL:</span></p>
			<div>
				<div id="_idContainer243" class="IMG---Figure">
					<img src="image/image_00_009.jpg" alt="Figure 9.9 – Rolling deployments when a new endpoint is created" width="1650" height="344"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.9 – Rolling deployments when a new endpoint is created</p>
			<p>Rolling back the API to a previous version is simple since the previous API endpoint still exists. We reverse the changes to the <strong class="source-inline">Model Version</strong> Environment Variable, and the Web API Service configuration URL (or Object Environment <span class="No-Break">Variable/Data Item).</span></p>
			<div>
				<div id="_idContainer244" class="IMG---Figure">
					<img src="image/image_00_010.jpg" alt="Figure 9.10 – Rolling back a rolling deployment when a new endpoint is created" width="807" height="267"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.10 – Rolling back a rolling deployment when a new endpoint is created</p>
			<p>A major disadvantage of rolling deployments is not knowing exactly which ML model was used for predictions made during the deployment phase. The next strategy that we’ll discuss, called blue-green deployments, doesn’t have this ambiguity and also has <span class="No-Break">no downtime.</span></p>
			<h3>Blue-green deployments</h3>
			<p>In a blue-green<a id="_idIndexMarker723"/> deployment, there’s<a id="_idIndexMarker724"/> duplicate infrastructure positioned behind a load balancer, but only one set of infrastructures is actively serving requests at any time. A sample blue-green deployment can be seen in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.11</em>. Suppose that we’re currently running <em class="italic">version 1</em> of the model on the set of <em class="italic">green</em> servers (<em class="italic">A</em>). When the model needs updating to <em class="italic">version 2</em>, it’s deployed onto a separate set of blue servers, which are normally not serving requests (<em class="italic">B</em>). Once model version 2 is ready to be used, the load balancer is changed to serve requests only to the blue servers (<em class="italic">C</em>). The green server with the previous model <span class="No-Break">sits idle:</span></p>
			<div>
				<div id="_idContainer245" class="IMG---Figure">
					<img src="image/image_00_011.jpg" alt="Figure 9.11 – An example blue-green deployment" width="820" height="291"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.11 – An example blue-green deployment</p>
			<p>Similar to rolling updates, blue-green<a id="_idIndexMarker725"/> deployments shouldn’t have service downtime. The main difference with blue-green and rolling updates is that there’s always a copy of the previous model on standby that can be switched back to by reconfiguring the load balancer. There also isn’t an ambiguous period where multiple models can be serving predictions at once. Both of these points make blue-green deployments better suited for IA auditing <a id="_idIndexMarker726"/>when compared to <span class="No-Break">rolling updates.</span></p>
			<h4>API endpoint is overwritten</h4>
			<p>If the URL <a id="_idIndexMarker727"/>endpoint is reused, we need to wait for a notification stating that the deployment is complete and change the <strong class="source-inline">Model Version</strong> <span class="No-Break">Environment Variable.</span></p>
			<div>
				<div id="_idContainer246" class="IMG---Figure">
					<img src="image/image_00_012.jpg" alt="Figure 9.12 – Blue-green deployments when the existing endpoint is overwritten" width="1252" height="308"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.12 – Blue-green deployments when the existing endpoint is overwritten</p>
			<p>Rolling back <a id="_idIndexMarker728"/>requires the ML/infrastructure team to change the configuration of their load balancer. Once that’s done, the IA team can change the <strong class="source-inline">Model Version</strong> Environment Variable back to its previous value. The speed of rolling back a blue-green deployment when the endpoint is overwritten should be much faster than rolling back a rolling <span class="No-Break">update one:</span></p>
			<div>
				<div id="_idContainer247" class="IMG---Figure">
					<img src="image/image_00_013.jpg" alt="Figure 9.13 – Rolling back a blue-green deployment when the endpoint is overwritten" width="1252" height="312"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.13 – Rolling back a blue-green deployment when the endpoint is overwritten</p>
			<h4>New API endpoint is created</h4>
			<p>When we<a id="_idIndexMarker729"/> have a new API endpoint, we need to update the <strong class="source-inline">Model Version</strong> Environment Variable, followed by the Object Environment Variable/Data Item API URL or Web API Service <span class="No-Break">configuration URL:</span></p>
			<div>
				<div id="_idContainer248" class="IMG---Figure">
					<img src="image/image_00_014.jpg" alt="Figure 9.14 – Blue-green deployments when a new endpoint is created" width="1650" height="344"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.14 – Blue-green deployments when a new endpoint is created</p>
			<p>Since the current set of servers, whether that be blue or green, contain both the latest and previous versions of the ML model, rolling back doesn’t actually require reconfiguring the load balancer. We simply revert the Environment Variables/Data Items or Web API Service URL back to what they <span class="No-Break">were before:</span></p>
			<div>
				<div id="_idContainer249" class="IMG---Figure">
					<img src="image/image_00_005.jpg" alt="Figure 9.15 – Rolling back a blue-green deployment when a new endpoint is created" width="717" height="237"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.15 – Rolling back a blue-green deployment when a new endpoint is created</p>
			<p>For the three <a id="_idIndexMarker730"/>deployment strategies that we’ve discussed so far (replacement, rolling, blue-green), the new ML model’s API URL can either be reused (stay the same) or changed. If the new model has a different URL, we need to actively change the IA solution configuration before the new ML model will be called. This is in contrast with the next two deployment methods that we’ll see, where the URL of the new model will always stay the same. If previous versions of the model are kept active, those will be given <span class="No-Break">new URLs.</span></p>
			<h3>Canary deployments</h3>
			<p>Under canary deployments, both <a id="_idIndexMarker731"/>the new and old model are served in parallel during a period of ML hypercare (<span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.16</em>, <em class="italic">B</em>). Initially, only<a id="_idIndexMarker732"/> a small percentage of requests are routed to the new model; for example, 95% of requests will go to the old model, with 5% of the traffic going to the new one (<em class="italic">C</em>). The percentage of requests reaching the new ML model is increased, as confidence in the new model’s performance grows (<em class="italic">D</em>). This eventually reaches 100% (<em class="italic">E</em>) and the servers hosting the old model are shut <span class="No-Break">down (</span><span class="No-Break"><em class="italic">F</em></span><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer250" class="IMG---Figure">
					<img src="image/image_00_016.jpg" alt="Figure 9.16 – An example canary deployment" width="842" height="612"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.16 – An example canary deployment</p>
			<p>The IA team will likely have no visibility nor control over which requests get chosen to run against the new model. This means that we genuinely can’t tell which Sessions will be running on the old and new ML models during the switchover period unless that information is provided in the API response. If we need to know for certain which ML API version is being used for audit reasons, we’ll need to access the logs of the ML service directly and cross-reference them with the timestamps of the Session Logs, which might not be possible if the model is <span class="No-Break">third-party developed.</span></p>
			<p>Canary <a id="_idIndexMarker733"/>deployments imply that there’s a single URL endpoint that <a id="_idIndexMarker734"/>remains unchanged as the model gets updated. So, the only thing that needs to be done in BP is updating the <strong class="source-inline">Model Version</strong> Environment Variable once we receive a notification stating that all traffic is being directed to the new model. Similar to rolling updates, we won’t know for sure which model was being used to make predictions during the <span class="No-Break">deployment period.</span></p>
			<div>
				<div id="_idContainer251" class="IMG---Figure">
					<img src="image/image_00_017.jpg" alt="Figure 9.17 – Canary deployments" width="1341" height="334"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.17 – Canary deployments</p>
			<p>Full<a id="_idIndexMarker735"/> rollbacks in canary deployments are rare, as their purpose is <a id="_idIndexMarker736"/>to catch issues during the deployment period. What normally happens is that during deployment, success criteria for the traffic directed at the new model aren’t met and everything is rolled back immediately. This kind of rollback doesn’t require any changes to BP because it occurs <em class="italic">before</em> we’ve made any configuration changes to the <span class="No-Break">IA solution.</span></p>
			<p>However, if a rollback is needed after the full deployment has happened, we should only need to change back to the previous value of <strong class="source-inline">Model Version</strong>, as the API URL <span class="No-Break">remains unchanged.</span></p>
			<div>
				<div id="_idContainer252" class="IMG---Figure">
					<img src="image/image_00_018.jpg" alt="Figure 9.18 – Rolling back a canary deployment" width="1272" height="348"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.18 – Rolling back a canary deployment</p>
			<p>Canary <a id="_idIndexMarker737"/>deployments (similar to rolling updates) result in <em class="italic">ambiguity</em> with respect to which model was actually used in production during the deployment period. Because of this, it’s best to avoid them (if possible) or to always return the <a id="_idIndexMarker738"/>model version in the API response. Instead, we can consider using shadow deployments (discussed next), which also run two models in parallel. Shadow deployments differ from canary deployments, as there’s a clear switchover point between the old and <span class="No-Break">new models.</span></p>
			<h3>Shadow deployments</h3>
			<p>With shadow <a id="_idIndexMarker739"/>deployments, both the <a id="_idIndexMarker740"/>old and new predictions are called simultaneously against live data. However, the newer model is called behind the scenes and its API response isn’t sent back to the caller (<span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.19</em>, <em class="italic">A</em>). The shadow prediction results are retrieved directly from the server logs, which are analyzed by the ML team. Once the ML team is satisfied with the new model, it’s fully switched over (<em class="italic">B</em>) and the previous model is <span class="No-Break">removed (</span><span class="No-Break"><em class="italic">C</em></span><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer253" class="IMG---Figure">
					<img src="image/image_00_019.jpg" alt="Figure 9.19 – An example shadow deployment" width="799" height="301"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.19 – An example shadow deployment</p>
			<p>Shadow deployments are usually achieved by mirroring traffic from the load balancer to the server hosting the new ML model. Note that this is similar in concept to that in the <em class="italic">Process template for evaluating a new model</em> section presented in <a href="B18416_06.xhtml#_idTextAnchor093"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>. The difference between shadow deployments and the template version is that the template version explicitly calls both predictions in sequence. The load balancer implementation only needs one API request and the call is made <span class="No-Break">in parallel.</span></p>
			<p>Shadow deployments are preferred over canary deployments for IA since there’s a clean cutover point to using the new model <span class="No-Break">in production.</span></p>
			<p>Due to the live proving nature of shadow deployments, it’s implied that the endpoint URL stays the same. As such, all we need to do in terms of BP is to change <strong class="source-inline">Model Version</strong> once the deployment <span class="No-Break">is complete:</span></p>
			<div>
				<div id="_idContainer254" class="IMG---Figure">
					<img src="image/image_00_020.jpg" alt="Figure 9.20 – Shadow deployments" width="1165" height="293"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.20 – Shadow deployments</p>
			<p>Rolling back a<a id="_idIndexMarker741"/> shadow deployment requires<a id="_idIndexMarker742"/> reversing the change to <span class="No-Break"><strong class="source-inline">Model Version</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer255" class="IMG---Figure">
					<img src="image/image_00_021.jpg" alt="Figure 9.21 – Rolling back a shadow deployment" width="1138" height="311"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.21 – Rolling back a shadow deployment</p>
			<p>This concludes the discussion of Web API-based deployments. Let’s summarize the five strategies that <span class="No-Break">we’ve seen.</span></p>
			<h3>Web API deployment summary</h3>
			<p>If we can influence how <a id="_idIndexMarker743"/>the ML models are deployed, the preferred methods are <em class="italic">blue-green</em> and <em class="italic">shadow</em>. This is because there’s a clean cutoff from the previous ML model to the new one, which makes it clear which model was used during a Session. Between these two, <em class="italic">blue-green</em> would likely have faster rollbacks, since the previous ML model version is waiting on standby. You could always pair the blue-green deployment with the <em class="italic">Process</em> template for evaluating a new model for a shadow deployment-like effect. Using the template will call the proposed ML model right after the actual model, generating logs for the ML <span class="No-Break">team’s analysis.</span></p>
			<p>The deployment period for <em class="italic">canary</em> and <em class="italic">rolling updates</em> will have ambiguity with regard to which model was actually called. To find out which ML model was actually served during the deployment period, we need to request logs from the servers that are hosting the models or have the API response indicate which version of an ML model was <span class="No-Break">being used.</span></p>
			<p>The four deployment methods mentioned don’t require downtime. If we’re allowed downtime, it’s reasonable to go with a <em class="italic">replacement</em> deployment strategy, as retiring Schedules and ensuring that no Sessions are active is the safest way to perform changes to any BP solution. We can of course decide to pair downtime with any of the other deployment strategies <span class="No-Break">as well.</span></p>
			<p>If the ML model is third-party developed or a hosted service, it’s highly unlikely that we’ll be able to influence the deployment strategy. It’s also unlikely that we’ll know when a deployment occurs. We basically need to keep an eye on the API documentation to find out when something has changed or hope that the API call returns the <span class="No-Break">model version.</span></p>
			<p>Moving on from<a id="_idIndexMarker744"/> API deployments, let’s look at script-based deployments, which are comprised of batch files, PowerShell scripts, and Python scripts that are directly executed on the Digital Worker through the <span class="No-Break">command line.</span></p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor150"/>Script deployment strategies</h2>
			<p>There are two main strategies for <a id="_idIndexMarker745"/>script-based ML deployments. The first is to install the script and its dependencies <em class="italic">directly</em> onto each Digital Worker’s Windows system. The second is to <em class="italic">virtualize</em> the scripts and its dependencies. Regardless of which strategy is chosen, it’s important to version control the scripts, which helps to document the dependencies and <span class="No-Break">simplify rollbacks.</span></p>
			<h3>Direct deployment</h3>
			<p>For a<a id="_idIndexMarker746"/> direct deployment, we need to consider the <em class="italic">location</em> of the scripts and install the <em class="italic">dependencies</em> that are needed to run them. The scripts can be located in an executable network location or saved locally onto each<a id="_idIndexMarker747"/> Digital <span class="No-Break">Worker itself.</span></p>
			<p>The difficulty of deployment lies in properly configuring the Windows system to ensure that the dependencies required by the updated model are properly set up. This likely requires IT to manually install packages through the command line. This can be time-consuming if it needs to be repeated across many <span class="No-Break">Digital Workers.</span></p>
			<p>From a purely BP perspective, an update to the ML scripts shouldn’t result in many changes beyond modifying the path to the script executable, its arguments, and the <strong class="source-inline">Model Version</strong> Environment Variable. Unfortunately, these changes require <em class="italic">downtime</em>, as updates to Processes, Objects and Environment Variables are stored in the BP database. Modifications to these can only happen once after deployments to all VMs <span class="No-Break">have finished.</span></p>
			<div>
				<div id="_idContainer256" class="IMG---Figure">
					<img src="image/image_00_022.jpg" alt="Figure 9.22 – Direct deployments" width="1650" height="263"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.22 – Direct deployments</p>
			<p>The easiest<a id="_idIndexMarker748"/> way to prepare for rollbacks in a direct deployment is to take an image of the Digital Worker VM before deploying the new ML model. If we find an issue with the ML model after it’s deployed, we can roll back by reverting back to the previous image. Note that reverting the Digital Worker VM back to its previous state still requires undoing changes to the BP solution, such as changing the <strong class="source-inline">Model Version</strong> Environment Variable, the path to the script executable, its arguments, etc. Those changes are saved inside the BP database, and not the <span class="No-Break">individual VMs.</span></p>
			<div>
				<div id="_idContainer257" class="IMG---Figure">
					<img src="image/image_00_023.jpg" alt="Figure 9.23 – Rolling back a direct deployment through image backups" width="1650" height="272"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.23 – Rolling back a direct deployment through image backups</p>
			<p>If creating an <a id="_idIndexMarker749"/>image backup isn’t possible, you’ll <a id="_idIndexMarker750"/>need to roll it back manually. A manual rollback is error-prone because downgrading dependencies is rarely possible. It will likely require uninstalling and reinstalling packages from scratch. Doing this across many Digital Workers will be <span class="No-Break">very tedious.</span></p>
			<h3>Virtualized deployment</h3>
			<p>Another deployment option that <a id="_idIndexMarker751"/>makes <a id="_idIndexMarker752"/>rolling back simple is to use <em class="italic">virtualization</em> inside of the Digital Worker itself. You can deploy scripts inside of local containers (such as Docker), VM images, Windows Subsystem for Linux, etc. A virtualized deployment will come bundled with all of the necessary dependencies for a particular version of the <span class="No-Break">ML model.</span></p>
			<p>Again, changes to BP Processes, Objects, and Environment Variables are applied to all Sessions, so it isn’t possible to partially deploy an ML solution on just a few Digital Workers (outside of cloning the entire BP Release and renaming everything). Therefore, deploying a virtualized ML solution requires downtime, and the help of IT to ensure that the correct image is <span class="No-Break">started automatically:</span></p>
			<div>
				<div id="_idContainer258" class="IMG---Figure">
					<img src="image/image_00_024.jpg" alt="Figure 9.24 – Virtualized deployments" width="1650" height="263"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.24 – Virtualized deployments</p>
			<p>To roll back a virtualized script deployment, revert to the previous version of the image. Again, we still need to undo changes that were made to the IA solution, as those are saved in the <span class="No-Break">BP database:</span></p>
			<div>
				<div id="_idContainer259" class="IMG---Figure">
					<img src="image/image_00_025.jpg" alt="Figure 9.25 – Rolling back a virtualized deployment" width="1650" height="272"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.25 – Rolling back a virtualized deployment</p>
			<p>Virtualized deployments will have heavier resource requirements (CPU and RAM) on the Digital Worker when compared with direct deployments. However, rolling back a locally running VM can likely be executed faster, as fewer teams need to get involved. Both methods have pros <span class="No-Break">and cons.</span></p>
			<p>We’ve completed the discussion on how to deploy and roll back script-based ML models. Next, let’s discuss Code <span class="No-Break">Stage deployments.</span></p>
			<h2 id="_idParaDest-147"><a id="_idTextAnchor151"/>Code Stage deployment strategies</h2>
			<p>Code Stage ML deployments will be <a id="_idIndexMarker753"/>familiar to RPA teams, as they can be done as standard Object XML or <strong class="source-inline">.bprelease</strong> imports. Some might also require copying <strong class="source-inline">.dll</strong> files to the location specified in the Object, to a folder on the System Path, or to the BP installation folder. The only additional step compared to importing any other non-ML Code Stage is to change the <strong class="source-inline">Model Version</strong> Environment Variable. Downtime will be required if we need to copy new <strong class="source-inline">.dll</strong> files, because they require a Runtime Resource restart to <span class="No-Break">be recognized:</span></p>
			<div>
				<div id="_idContainer260" class="IMG---Figure">
					<img src="image/image_00_026.jpg" alt="Figure 9.26 – Code Stage deployments" width="1650" height="264"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.26 – Code Stage deployments</p>
			<p>Rolling back a Code Stage deployment is simple. Re-import a previous version of the Object or Release, copy back the correct <strong class="source-inline">.dll</strong> files, delete any newly added <strong class="source-inline">.dll</strong> files, and revert to a previous <strong class="source-inline">Model Version</strong> Environment Variable value. It’s important that you keep a copy of the <strong class="source-inline">.dll</strong> files needed for previous models for <span class="No-Break">rollback purposes.</span></p>
			<div>
				<div id="_idContainer261" class="IMG---Figure">
					<img src="image/image_00_027.jpg" alt="Figure 9.27 – Rolling back a Code Stage deployment" width="1650" height="261"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.27 – Rolling back a Code Stage deployment</p>
			<p>This concludes the section on the deployment strategies for Web APIs, CLI scripts, and Code Stages. It’s important to understand the specific strategy being used to deploy the new ML model, as this affects how we implement changes in our IA solution, and how we can roll back to previous versions of the model. Next, let’s explore how IA changes the database management requirements of BP, and how we can use SQL to extract ML logs, instead of doing so through the BP software through the ML <span class="No-Break">Auditor Role.</span></p>
			<h1 id="_idParaDest-148"><a id="_idTextAnchor152"/>Database operations</h1>
			<p>BP’s database <a id="_idIndexMarker754"/>is primarily used for operations and isn’t intended to be a permanent datastore for record keeping. As the database table sizes grow, the database starts to perform more slowly, which reduces the Digital Worker execution speed. Adding IA steps into a Process leads to additional logging, which increases the growth rate of certain tables. Ongoing database maintenance has always been a key factor in ensuring the smooth performance of BP RPA, and the need for database maintenance is only amplified once we start <span class="No-Break">doing IA.</span></p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor153"/>Table growth maintenance</h2>
			<p>The tables that are most<a id="_idIndexMarker755"/> affected by IA are <strong class="source-inline">BPAWorkQueueItem</strong> and <strong class="source-inline">BPASessionLog_*</strong>. <strong class="source-inline">BPAWorkQueueItem</strong> stores<a id="_idIndexMarker756"/> the Item data of Work <span class="No-Break">Queue Items.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout"><strong class="source-inline">BPASessionLog_*</strong>, means the various Session Logging tables, including <strong class="source-inline">BPASessionLog_NonUnicode</strong>, <strong class="source-inline">BPASessionLog_NonUnicode_pre65</strong>, <strong class="source-inline">BPASessionLog_Unicode</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">BPASessionLog_Unicode_pre65</strong></span><span class="No-Break">.</span></p>
			<h3>BPAWorkQueueItem</h3>
			<p>We’re likely storing the entirety<a id="_idIndexMarker757"/> of the input data needed for the ML algorithm in the <a id="_idIndexMarker758"/>Work Queue Item data. If the ML algorithm has many columns of input data, <strong class="source-inline">BPAWorkQueueItem</strong> will grow very quickly in size. There are four primary ways to manage the growth rate of this table. The first is to delete Work Queue Items directly from the BP user interface. This isn’t recommended as the UI has limits on how many Work Queue Items can be selected and deleted <span class="No-Break">at once.</span></p>
			<p>The second way is to use a database script that’s provided by BP’s Customer Support. This SQL script will delete rows from the Work Queue related tables if they’re older than a certain date. For instance, you can configure the script to keep 30 days’ worth of Work Queue Items, and have the script run daily through the SQL Server Agent. This ensures that your Work Queue Item tables won’t have more than 30 days’ worth <span class="No-Break">of data.</span></p>
			<p>The third way is to use <a id="_idIndexMarker759"/>the <strong class="bold">Blue Prism Archiver XBP</strong> asset, which is available on the DX at <a href="https://digitalexchange.blueprism.com/dx/entry/3439/solution/blue-prism-archiver-xbp">https://digitalexchange.blueprism.com/dx/entry/3439/solution/blue-prism-archiver-xbp</a>. This asset allows you to move Work Queue Items out of the main BP database, into a different database. More details can be found on the DX <span class="No-Break">page’s documentation.</span></p>
			<p>Finally, there’s another DX asset called <a id="_idIndexMarker760"/>the <strong class="bold">DB Servicer XBP</strong>, found at <a href="https://digitalexchange.blueprism.com/dx/entry/3439/solution/db-servicer">https://digitalexchange.blueprism.com/dx/entry/3439/solution/db-servicer</a>. This asset can perform maintenance on numerous BP tables, including <strong class="source-inline">BPAWorkQueueItem</strong> and the various <strong class="source-inline">BPASessionLog_*</strong> tables, which are <span class="No-Break">discussed next.</span></p>
			<h3>BPASessionLog*</h3>
			<p>IA increases the growth <a id="_idIndexMarker761"/>rate of the various Session Log tables simply because there are more Process and Object Stages to execute, and log into the database. As mentioned <a id="_idIndexMarker762"/>in the previous paragraph, one way to manage the growth of this table is to use the <strong class="bold">DB Servicer XBP</strong> from<a id="_idIndexMarker763"/> <span class="No-Break">the DX.</span></p>
			<p>The <strong class="source-inline">BPASessionLog_*</strong> tables can also be managed through an SQL script that’s provided by Customer Support. The script lets us specify how many days of Session Logs we want to keep. Anything older than the number of days will be deleted from the database. Once set up, the SQL script needs to be run on a <span class="No-Break">scheduled basis.</span></p>
			<p>A third option to keep the Session Logging table sizes in check is to use the in-product archiving function. This can be found under <strong class="bold">System</strong> | <strong class="bold">System</strong> | <strong class="bold">Archiving</strong>. This function can be configured to either delete or export Session Logs into a compressed <strong class="source-inline">.gz</strong> format. We must specify which Runtime Resource we want to perform the archiving (during its idle time), where on the Runtime Resource we want the archive files saved, and how many days’ worth of logs we want to keep in the <span class="No-Break">BP database.</span></p>
			<div>
				<div id="_idContainer262" class="IMG---Figure">
					<img src="image/image_00_028.jpg" alt="Figure 9.28 – The in-product archiver, which can slow down the Session Log growth rate" width="1043" height="412"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.28 – The in-product archiver, which can slow down the Session Log growth rate</p>
			<p>The final option is to delete Sessions by hand through the BP user interface. This is unrealistic for most companies as there are potentially thousands of Sessions (if not more) being <span class="No-Break">run regularly.</span></p>
			<p>IA requires <a id="_idIndexMarker764"/>us to refine our BP database maintenance practices. IA also leads to new requirements in terms of data exporting. For example, ML Auditors want to know what inputs have led to what predictions and how those predictions have been used. Data scientists want to know the manual verification results so that they can update the algorithm. If our ML model is third-party developed or hosted, the only way of getting these logs is through the BP database, as we won’t <a id="_idIndexMarker765"/>have access to the underlying ML <span class="No-Break">server logs.</span></p>
			<p>While exporting this data can be done through the BP user interface, it may be preferable to automate and export this data directly from <span class="No-Break">the database.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Data exporting should be done during off hours, preferably on read-only versions of the database, to minimize the impact on BP <span class="No-Break">production operations.</span></p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor154"/>Extracting ML prediction data from the database</h2>
			<p>Based on the<a id="_idIndexMarker766"/> templates presented in <a href="B18416_07.xhtml#_idTextAnchor114"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, our ML prediction data can potentially be extracted from two database locations. The first is from the Work Queue tables, which works if we’re using the template that separates the ML predictions into its own Work Queue. If we’re not using the template with dedicated Work Queues, we can query the Session Log tables to find <span class="No-Break">this data.</span></p>
			<h3>Querying Work Queue data</h3>
			<p>If you’re <a id="_idIndexMarker767"/>using a template that has a dedicated Work Queue for ML, it’s straightforward to query for Work Queue data through SQL. The SQL following script allows you to provide data scientists with the input data to the algorithm, the predicted result, and the confidence score. The only thing that needs changing is the name of the Work Queue, and you could potentially add dates to limit the range of results that <span class="No-Break">are returned:</span></p>
			<pre class="console">
SELECT data FROM BPAWorkQueueItem wqi, BPAWorkQueue wq
WHERE wq.name = '<strong class="bold">ML Queue Name (To Change)</strong>'
AND wqi.queueid = wq.id;</pre>			<p>The <strong class="source-inline">data</strong> column that’s selected is an XML string. This XML format can be directly opened by Excel or parsed by data scientists using their programming language <span class="No-Break">of choice.</span></p>
			<h3>Querying Session Log data</h3>
			<p>In all of the <a id="_idIndexMarker768"/>IA templates, we’ve deliberately enabled logging in some Stages to make extracting the prediction data easier in both the Session Log Viewer and through the database. The two Stages where logging is enabled are shown in the following figure and are named identically across the three IA templates. This common naming scheme is required for our SQL <span class="No-Break">to work:</span></p>
			<div>
				<div id="_idContainer263" class="IMG---Figure">
					<img src="image/image_00_029.jpg" alt="Figure 9.29 – Common Stages to log ML prediction results" width="768" height="569"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.29 – Common Stages to log ML prediction results</p>
			<p>We can <a id="_idIndexMarker769"/>query the Session Logs to specifically find these two Stages, by passing in the name of the Process. Depending on how BP is configured, you might also need to change the database table name from <strong class="source-inline">BPASessionLog_NonUnicode</strong> <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">BPASessionLog_Unicode</strong></span><span class="No-Break">.</span></p>
			<pre class="console">
SELECT * FROM
(SELECT logid, stagename, LAG(result, <strong class="bold">1</strong>, 0) OVER(ORDER BY logid) as modelversion, attributexml, startdatetime from <strong class="bold">BPASessionLog_NonUnicode</strong> WHERE stagename in ('Log [Model Version]', 'Set [Prediction] and [Confidence Score]') AND processname = '<strong class="bold">To Change</strong>') as tbl
WHERE stagename = 'Set [Prediction] and [Confidence Score]';</pre>			<p>The <strong class="source-inline">modelversion</strong> column is populated with the model version from <strong class="source-inline">Log [Model Version]</strong> Calculation Stage. The <strong class="source-inline">attributexml</strong> column contains the logged values from the <strong class="source-inline">Set [Prediction] and [Confidence Score]</strong> Multi <span class="No-Break">Calc Stage.</span></p>
			<p>The <strong class="source-inline">LAG(result, 1, 0) OVER(ORDER BY logid)</strong> SQL syntax allows us to select the value from <strong class="source-inline">Log [Model Version]</strong> and <strong class="source-inline">Set [Prediction] and [Confidence Score]</strong> on a single row, even though they belong to different Session Log entries. This relies on there being only <strong class="source-inline">1</strong> Stage of difference between the two. If there are more Session Log records between the two Stages, you’ll need to change the <strong class="source-inline">1</strong> value <span class="No-Break">to match.</span></p>
			<p>If you’re using the <strong class="bold">Example 4 – New Model Evaluation Process Template</strong> from <a href="B18416_06.xhtml#_idTextAnchor093"><span class="No-Break"><em class="italic">Chapter 6</em></span></a> to <a id="_idIndexMarker770"/>evaluate a second ML model in production, the following SQL can <span class="No-Break">be used:</span></p>
			<pre class="console">
SELECT logid, stagename, result, attributexml, startdatetime from <strong class="bold">BPASessionLog_NonUnicode</strong>
WHERE stagename = 'Log New Model Evaluation Results'
AND processname = '<strong class="bold">To Change</strong>';</pre>			<h2 id="_idParaDest-151"><a id="_idTextAnchor155"/>Exporting reviewed prediction data from the database</h2>
			<p>The<a id="_idIndexMarker771"/> reviewed prediction results might also be found in two locations depending on which template is used. If the two-Work Queue or three-Work Queue templates are used, we can find them from the <strong class="source-inline">BPAWorkQueueItem</strong> table. If not, we can look into the <span class="No-Break"><strong class="source-inline">BPASessionLog_*</strong></span><span class="No-Break"> table.</span></p>
			<h3>Querying Work Queue data</h3>
			<p>For the HITL<a id="_idIndexMarker772"/> Review Work Queue, we only retrieve results where we know for certain that the review has occurred. We do this by checking for the presence of a Collection Field <span class="No-Break">named </span><span class="No-Break"><strong class="source-inline">Confidence</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
SELECT data FROM BPAWorkQueueItem wqi, BPAWorkQueue wq
WHERE wq.name = '<strong class="bold">ML Queue Name (To Change)</strong>'
AND data like '%"Confidence"%'
AND wqi.queueid = wq.id;</pre>			<h3>Querying Session Log data</h3>
			<p>In all three<a id="_idIndexMarker773"/> templates, there’s a commonly named Stage that has logging deliberately enabled, to capture the corrected prediction result and the justification reason. This Stage is shown in the <span class="No-Break">following figure:</span></p>
			<div>
				<div id="_idContainer264" class="IMG---Figure">
					<img src="image/image_00_030.jpg" alt="Figure 9.30 – A common Stage to log the review result and justification" width="819" height="415"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.30 – A common Stage to log the review result and justification</p>
			<p>The SQL to find this Stage in the Session Log tables is <span class="No-Break">as follows:</span></p>
			<pre class="console">
SELECT logid, attributexml, startdatetime from <strong class="bold">BPASessionLog_NonUnicode</strong>
WHERE stagename = 'Set [Reviewed Prediction] and [Review Justification]'
AND processname = '<strong class="bold">To Change</strong>';</pre>			<p>The <strong class="source-inline">attributexml</strong> column <a id="_idIndexMarker774"/>will need to be parsed by the data scientists manually or opened <span class="No-Break">in Excel.</span></p>
			<h1 id="_idParaDest-152"><a id="_idTextAnchor156"/>Summary</h1>
			<p>In this chapter, we discussed two topics which are new, ongoing activities that are required by IA: ML deployments and <span class="No-Break">database operations.</span></p>
			<p>For deployments of model updates, we discussed the different strategies that are available for Web API, CLI script, and Code Stage-based ML models. Regardless of how the ML model is deployed, we need to think clearly about which steps are needed to update the IA solution, and how to roll it back. This includes whether downtime is needed, what needs to be changed (Objects, Processes, Web API Service Configurations, Environment Variables, copying files, etc.), who performs these changes, and in what order they should be <span class="No-Break">performed in.</span></p>
			<p>IA affects BP database operations in two main ways. IA leads to faster database table growth, especially for the Work Queue and Session Log tables. The database team that supports IA must really perfect their database maintenance as database growth can negatively affect the performance of BP. Next, IA requires more reports and audits to be generated. It may be desirable to do this from the database. Some sample SQL queries have been provided to extract ML-related logs that work with the Process templates of <a href="B18416_06.xhtml#_idTextAnchor093"><span class="No-Break"><em class="italic">Chapter 6</em></span></a> and <a href="B18416_07.xhtml#_idTextAnchor114"><span class="No-Break"><em class="italic">Chapter 7</em></span></a><span class="No-Break">.</span></p>
			<p>The ongoing IA operations discussed in this chapter, together with the LAM, User Roles and MTE of <a href="B18416_08.xhtml#_idTextAnchor133"><span class="No-Break"><em class="italic">Chapter 8</em></span></a> are part of a larger topic, called the BP <strong class="bold">Robotic Operating Model</strong> (<strong class="bold">ROM</strong>). The ROM is a methodology designed to help firms achieve their automation outcomes. In the next chapter, we’ll be discussing what potential changes IA will have on <span class="No-Break">the ROM.</span></p>
		</div>
	</div>
</div>
</body></html>