- en: Chapter 3. Processing Color Images with Classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the Strategy pattern in an algorithm design
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a Controller design pattern to communicate with processing modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting color representations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Representing colors with hue, saturation, and brightness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Good computer vision programs begin with good programming practices. Building
    a bug-free application is just the beginning. What you really want is an application
    that you and the programmers working with you will be able to easily adapt and
    evolve as new requirements come in. This chapter will show you how to make the
    best use of some of the object-oriented programming principles in order to build
    good quality software programs. In particular, we will introduce a few important
    design patterns that will help you build applications with components that are
    easy to test, maintain, and reuse.
  prefs: []
  type: TYPE_NORMAL
- en: Design patterns are a well-known concept in software engineering. Basically,
    a design pattern is a sound, reusable solution to a generic problem that occurs
    frequently in software designing. Many software patterns have been introduced
    and well documented. Good programmers should build a working knowledge of these
    existing patterns.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also has a secondary objective. It will teach you how to play with
    image colors. The example used throughout this chapter will show you how to detect
    the pixels of a given color, and the last two recipes will explain how to work
    with different color spaces.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Strategy pattern in an algorithm design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The objective of the Strategy design pattern is to encapsulate an algorithm
    in a class. This way, it becomes easier to replace a given algorithm by another
    one or to chain several algorithms together in order to build a more complex process.
    In addition, this pattern facilitates the deployment of an algorithm by hiding
    as much of its complexity as possible behind an intuitive programming interface.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's say we want to build a simple algorithm that will identify all of the
    pixels in an image that have a given color. For this, the algorithm has to accept
    an image and a color as input and will return a binary image showing the pixels
    that have the specified color. The tolerance with which we want to accept a color
    will be another parameter to be specified before running the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once an algorithm has been encapsulated in a class using the Strategy design
    pattern, it can be deployed by creating an instance of this class. Typically,
    the instance will be created when the program is initialized. At the time of construction,
    the class instance will initialize the different parameters of the algorithm with
    their default values such that it will immediately be ready to be used. The algorithm's
    parameter values can also be read and set using appropriate methods. In the case
    of an application with a GUI, these parameters can be displayed and modified using
    different widgets (text fields, sliders, and so on) so that a user can easily
    play with them.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will show you the structure of a Strategy class in the next section; let''s
    start with an example on how it can be deployed and used. Let''s write a simple
    main function that will run our proposed color detection algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this program to detect a blue sky in the colored version of the *Castle*
    image presented in the previous chapter produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/00019.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Here, a white pixel indicates a positive detection of the sought color, and
    black indicates negative.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, the algorithm we encapsulated in this class is relatively simple
    (as we will see next, it is composed of just one scanning loop and one tolerance
    parameter). The Strategy design pattern becomes really powerful when the algorithm
    to be implemented is more complex, has many steps, and includes several parameters.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The core process of this algorithm is easy to build. It is a simple scanning
    loop that goes over each pixel, comparing its color with the target color. Using
    what we learned in the *Scanning an image with iterators* recipe of the previous
    chapter, this loop can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cv::Mat` variable''s `image` refers to the input image, while `result`
    refers to the binary output image. Therefore, the first step consists of setting
    up the required iterators. The scanning loop then becomes easy to implement. The
    distance between the current pixel color and the target color is evaluated on
    each iteration in order to check whether it is within the tolerance parameter
    defined by `maxDist`. If that is the case, the value `255` (white) is then assigned
    to the output image; if not, `0` (black) is assigned. To compute the distance
    to the target color, the `getDistanceToTargetColor` method is used. There are
    different ways to compute this distance. One could, for example, calculate the
    Euclidean distance between the three vectors that contain the RGB color values.
    To keep this computation simple, we simply sum the absolute differences of the
    RGB values (this is also known as the city-block distance) in our case. Note that
    in modern architecture, a floating-point Euclidean distance can be faster to compute
    than a simple city-block distance; this is also something to take into consideration
    in your design. Also, for more flexibility, we write the `getDistanceToTargetColor`
    method in terms of a `getColorDistance` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how we used `cv::Vec3d` to hold the three unsigned char that represent
    the RGB values of a color. The `target` variable obviously refers to the specified
    target color, and as we will see, it is defined as a member variable in the class
    algorithm that we will define. Now, let''s complete the definition of the processing
    method. Users will provide an input image, and the result will be returned once
    the image scanning is completed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Each time this method is called, it is important to check if the output image
    that contains the resulting binary map needs to be reallocated to fit the size
    of the input image. This is why we use the `create` method of `cv::Mat`. Remember
    that this method will only proceed to reallocation if the specified size or depth
    do not correspond to the current image structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have the core processing method defined, let''s see what additional
    methods should be added in order to deploy this algorithm. We have previously
    determined what input and output data our algorithm requires. Therefore, we will
    first define the class attributes that will hold this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to create an instance of the class that encapsulates our algorithm
    (which we have named `ColorDetector`), we need to define a constructor. Remember
    that one of the objectives of the Strategy design pattern is to make algorithm
    deployment as easy as possible. The simplest constructor that can be defined is
    an empty one. It will create an instance of the class algorithm in a valid state.
    We then want the constructor to initialize all the input parameters to their default
    values (or the values that are known to generally give a good result). In our
    case, we decided that a distance of `100` is generally an acceptable tolerance
    parameter. We also set the default target color. We chose black for no particular
    reason. The idea is to make sure we always start with predictable and valid input
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, a user who creates an instance of our class algorithm can immediately
    call the process method with a valid image and obtain a valid output. This is
    another objective of the Strategy pattern, that is, to make sure that the algorithm
    always runs with valid parameters. Obviously, the users of this class will want
    to use their own settings. This is done by providing the user with the appropriate
    getters and setters. Let''s start with the `color` tolerance parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how we first check the validity of the input. Again, this is to make sure
    that our algorithm will never be run in an invalid state. The target color can
    be set in a similar manner as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This time it is interesting to note that we have provided the user with two
    definitions of the `setTargetColor` method. In the first version of the definition,
    the three color components are specified as three arguments, while in the second
    version, `cv::Vec3b` is used to hold the color values. Again, the objective is
    to facilitate the use of our class algorithm. The user can simply select the setter
    that best fits their needs.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe introduced you to the idea of encapsulating an algorithm in a class
    using the Strategy design pattern. The example algorithm used in this recipe consisted
    of identifying the pixels of an image that has a color sufficiently close to a
    specified target color. This computation could have been done otherwise. Also,
    the implementation of a Strategy design pattern could be complemented using function
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: Computing the distance between two color vectors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To compute the distance between two color vectors, we used the following simple
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'However, OpenCV includes a function to compute the Euclidean norm of a vector.
    Consequently, we could have computed our distance as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: A very similar result would then be obtained using this definition of the `getDistance`
    method. Here, we use `cv::Vec3i` (a 3-vector array of integers) because the result
    of the subtraction is an integer value.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also interesting to recall from [Chapter 2](part0019_split_000.html#page
    "Chapter 2. Manipulating Pixels"), *Manipulating Pixels*, that the OpenCV matrix
    and vector data structures include a definition of the basic arithmetic operators.
    Consequently, one could have proposed the following definition for the distance
    computation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This definition may look right at the first glance; however, it is wrong. This
    is because all these operators always include a call to `saturate_cast` (see the
    *Scanning an image with neighbor access* recipe in the previous chapter) in order
    to ensure that the results stay within the domain of the input type (here, it
    is `uchar`). Therefore, in the cases where the target value is greater than the
    corresponding color value, the value `0` will be assigned instead of the negative
    value that one would have expected. A correct formulation would then be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: However, using two function calls to compute the distance between two 3-vector
    arrays is inefficient.
  prefs: []
  type: TYPE_NORMAL
- en: Using OpenCV functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this recipe, we used a loop with iterators in order to perform our computation.
    Alternatively, we could have achieved the same result by calling a sequence of
    OpenCV functions. The color detection method will then be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This method uses the `absdiff` function that computes the absolute difference
    between the pixels of an image and, in this case, a scalar value. Instead of a
    scalar value, another image can be provided as the second argument to this function.
    In the latter case, a pixel-by-pixel difference will be applied; consequently,
    the two images must be of the same size. The individual channels of the difference
    image are then extracted using the `split` function (discussed in the *There's
    more…* section of the *Performing simple image arithmetic* recipe of [Chapter
    2](part0019_split_000.html#page "Chapter 2. Manipulating Pixels"), *Manipulating
    Pixels*) in order to be able to add them together. It is important to note that
    the result of this sum may sometimes be greater than `255`, but because saturation
    is always applied, the result will be stopped at `255`. The consequence is that
    with this version, the `maxDist` parameter must also be less than `256`; this
    should be corrected if you consider this behavior unacceptable. The last step
    is to create a binary image by using the threshold function. This function is
    commonly used to compare all the pixels with a threshold value (the third parameter),
    and in the regular thresholding mode (`cv::THRESH_BINARY`), it assigns the defined
    maximum value (the fourth parameter) to all the pixels greater than threshold
    and `0`. Here, we used the inverse mode (`cv::THRESH_BINARY_INV`) in which the
    defined maximum value is assigned to the pixels that have a value lower than or
    equal to the threshold. Of interest are also the `cv::THRESH_TOZERO_INV` and `cv::THRESH_TOZERO_INV`
    modes, which leave the pixels greater than or lower than the threshold unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: Using the OpenCV functions is always a good idea. You can then quickly build
    complex applications and potentially reduce the number of bugs. The result is
    often more efficient (thanks to the optimization efforts invested by the OpenCV
    contributors). However, when many intermediate steps are performed, you may find
    that the resulting method consumes more memory.
  prefs: []
  type: TYPE_NORMAL
- en: The functor or function object
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using the C++ operator overloading, it is possible to create a class for which
    its instances behave as functions. The idea is to overload the `operator()` method
    such that a call to the processing method of a class behaves exactly like a simple
    function call. The resulting class instance is called a function object or a **functor**.
    Often, a functor includes a full constructor such that it can be used immediately
    after being created. For example, you can add the following constructor to your
    `ColorDetector` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Obviously, you can still use the setters and getters that have been defined
    previously. The functor method can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'To detect a given color with this functor method, simply write the following
    code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the call to the color detection method now looks like a function
    call. As a matter of fact, the `colordetector` variable can be used as if it were
    the name of a function.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The policy-based class design, introduced by A. Alexandrescu, is an interesting
    variant of the Strategy design pattern in which algorithms are selected at compile
    time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The *Design Patterns: Elements of Reusable Object-Oriented Software*, *Erich
    Gamma et al, Addison-Wesley, 1994*, is one of the classic books on the subject'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a Controller design pattern to communicate with processing modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you build more complex applications, you will need to create multiple algorithms
    that can be combined together in order to accomplish some advanced tasks. Consequently,
    to properly set up the application and have all the classes communicate together
    will become more and more complex. It then becomes advantageous to centralize
    the control of the application in a single class. This is the idea behind the
    Controller design pattern. A Controller is a particular object that plays a central
    role in an application, and we will explore this in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using your favorite IDE, create a simple dialog-based application with two
    buttons; one button to select an image, and another button to start the processing,
    shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/00020.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Here, we use the `ColorDetector` class of the previous recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The role of the `Controller` class is to first create the classes required
    to execute the application. Here, there is only one class, but in a more complex
    application, several classes would be created. In addition, we need two member
    variables in order to hold a reference to the input and output results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we chose to use a dynamic allocation for our class; you can also simply
    declare a class variable. You then need to define all of the setters and getters
    that a user would need to control the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You also need a method, which will be invoked, to start the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, you will need a method to obtain the result of the processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, it is important to clean up everything when the application terminates
    (and the `Controller` class is released):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the previously mentioned `Controller` class, a programmer can easily build
    an interface for an application that will execute your algorithm. There is no
    need for the programmer to understand how all the classes are connected together
    or to find out which methods in which class must be called to have everything
    running properly. All this is done by the `Controller` class. The only requirement
    is to create an instance of the `Controller` class.
  prefs: []
  type: TYPE_NORMAL
- en: The setters and getters that are defined in the `Controller` class are the ones
    that are required to deploy your algorithm. Most often, these methods simply call
    the corresponding ones in the appropriate class. The simple example used here
    includes only one class algorithm, but in general, several class instances will
    be involved. Therefore, the role of `Controller` is to redirect the request to
    the appropriate class (in object-oriented programming, this mechanism is called
    delegation). Another objective of the Controller pattern is to simplify the interface
    for the application classes. As an example of such simplification, consider the
    `setTargetColor` and `getTargetColor` methods. Both use `uchar` to set and get
    the color of interest. This eliminates the necessity for the application programmer
    to know anything about the `cv::Vec3b` class.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, the Controller also prepares the data provided by the application
    programmer. This is what we did in the case of the `setInputImage` method, in
    which the image that corresponds to the given filename is loaded in the memory.
    The method returns `true` or `false` depending on whether the loading operation
    was successful (an exception could also have been thrown to handle this situation).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `process` method is the one that runs the algorithm. This method
    does not return a result, and another method must be called in order to get the
    result of the latest processing performed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to create a very basic dialog-based application using this controller,
    just add a `ColorDetectController` member variable to the dialog class (called
    `colordetect` here). As an example, using the MS Visual Studio framework, the
    `Open button` callback method of an MFC dialog would look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The second button executes the `Process` method and displays the result as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Obviously, a more complete application would include additional widgets in order
    to allow the user to set the algorithm parameters.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you build an application, always take the time to structure it such that
    it will be easy to maintain and evolve. There exist a number of architectural
    patterns that can help you meet this objective.
  prefs: []
  type: TYPE_NORMAL
- en: The Model-View-Controller architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Model-View-Controller** (**MVC**) architecture has the objective to produce
    an application that clearly separates the application logic from the user interface.
    As the name suggests, the MVC pattern involves three main components.
  prefs: []
  type: TYPE_NORMAL
- en: The **Model** contains information concerning the application. It holds all
    the data that is processed by the application. When new data is produced, it will
    inform the Controller (often asynchronously), which in turn will ask the view
    to display the new results. Often, the Model will group together several algorithms,
    possibly implemented following the Strategy pattern. All these algorithms are
    a part of the Model.
  prefs: []
  type: TYPE_NORMAL
- en: The **View** corresponds to the user interface. It is composed of the different
    widgets that present the data to the user and allow the user to interact with
    the application. One of its roles is to send the commands issued by the user to
    the Controller. When new data is available, it refreshes itself in order to display
    the new information.
  prefs: []
  type: TYPE_NORMAL
- en: The **Controller** is the module that bridges the View and the Model together.
    It receives requests from the View and relays them to the appropriate methods
    in the model. It is also informed when the Model changes its state; consequently,
    the Controller asks the View to refresh in order to display this new information.
  prefs: []
  type: TYPE_NORMAL
- en: Under the MVC architecture, the user interface calls the Controller methods.
    It does not contain any application data and does not implement any application
    logic. Consequently, it is easy to substitute an interface with another one. The
    designer of the GUI does not need to understand the functioning of the application.
    Reciprocally, the application logic can be modified without the GUI being affected.
  prefs: []
  type: TYPE_NORMAL
- en: Converting color representations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The earlier recipes taught you how to encapsulate an algorithm into a class.
    This way, the algorithm becomes easier to use through a simplified interface.
    Encapsulation also permits you to modify an algorithm's implementation without
    impacting the classes that use it. This principle is illustrated in the next recipe,
    where we will modify the `ColorDetector` class algorithm in order to use another
    color space. Therefore, this recipe will also be an opportunity to introduce color
    conversions with OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The RGB color space is based on the use of the red, green, and blue additive
    primary colors. These have been selected because when they are combined together,
    they can produce a wide gamut of different colors. In fact, the human visual system
    is also based on the trichromatic perception of colors, with cone cell sensitivity
    located around the red, green, and blue spectrum. It is often the default color
    space in digital imagery because that is the way they are acquired. Captured light
    goes through the red, green, and blue filters. Additionally, in digital images,
    the red, green, and blue channels are adjusted such that when combined in equal
    amounts, a gray-level intensity is obtained, that is, from black `(0,0,0)` to
    white `(255,255,255)`.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, computing the distance between the colors using the RGB color
    space is not the best way to measure the similarity between two given colors.
    Indeed, RGB is not a perceptually uniform color space. This means that two colors
    at a given distance might look very similar, while two other colors separated
    by the same distance might look very different.
  prefs: []
  type: TYPE_NORMAL
- en: To solve this problem, other color representations that have the property of
    being perceptually uniform have been introduced. In particular, the CIE L*a*b*
    is one such color model. By converting our images to this representation, the
    Euclidean distance between an image pixel and the target color will then be a
    meaningful measure of the visual similarity between the two colors. In this recipe,
    we will show you how to modify the previous application in order to work with
    CIE L*a*b*.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Conversion of images between different color spaces is easily done through
    the use of the `cv::cvtColor` OpenCV function. Let''s convert the input image
    to the CIE L*a*b* color space at the beginning of the process method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The converted variable contains the image after color conversion. In the `ColorDetector`
    class, it is defined as a class attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'You also need to convert the input target color. You can do this by creating
    a temporary image that contains only one pixel. Note that you need to keep the
    same signature as in the earlier recipes, that is, the user continues to supply
    the target color in RGB:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: If the application of the preceding recipe is compiled with this modified class,
    it will now detect the pixels of the target color using the CIE L*a*b* color model.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When an image is converted from one color space to another, a linear or nonlinear
    transformation is applied on each input pixel to produce the output pixels. The
    pixel type of the output image will match the one of the input image. Even if
    you work with 8-bit pixels most of the time, you can also use a color conversion
    with floating-point images (in which case, the pixel values are generally assumed
    to vary between `0` and `1.0`) or with integer images (with pixels generally varying
    between `0` and `65535`). However, the exact domain of the pixel values depends
    on the specific color space and destination image type. For example, with the
    CIE L*a*b* color space, the `L` channel, which represents the brightness of each
    pixel, varies between `0` and `100`, and it is rescaled between `0` and `255`
    in the case of the 8-bit images. The `a` and `b` channels correspond to the chromaticity
    components. These channels contain information about the color of a pixel, independent
    of its brightness. Their values vary between `-127` and `127`; for 8-bit images,
    `128` is added to each value in order to make it fit within the `0` to `255` interval.
    However, note that the 8-bit color conversion will introduce rounding errors that
    will make the transformation imperfectly reversible.
  prefs: []
  type: TYPE_NORMAL
- en: Most commonly used color spaces are available. It is just a question of providing
    the right color space conversion code to the OpenCV function (for CIE L*a*b*,
    this code is `CV_BGR2Lab`). Among these is YCrCb, which is the color space used
    in a JPEG compression. To convert a color space from BGR to YCrCb, the code will
    be `CV_BGR2YCrCb`. Note that all the conversions that involve the three regular
    primary colors, red, green, and blue, are available in the RGB and BGR order.
  prefs: []
  type: TYPE_NORMAL
- en: The CIE L*u*v* color space is another perceptually uniform color space. You
    can convert from BGR to CIE L*u*v by using the `CV_BGR2Luv` code. Both L*a*b*
    and L*u*v* use the same conversion formula for the brightness channel but use
    a different representation for the chromaticity channels. Also, note that since
    these two color spaces distort the RGB color domain in order to make it perceptually
    uniform, these transformations are nonlinear (therefore, they are costly to compute).
  prefs: []
  type: TYPE_NORMAL
- en: There is also the CIE XYZ color space (with the `CV_BGR2XYZ` code). It is a
    standard color space used to represent any perceptible color in a device-independent
    way. In the computation of the L*u*v and L*a*b color spaces, the XYZ color space
    is used as an intermediate representation. The transformation between RGB and
    XYZ is linear. It is also interesting to note that the `Y` channel corresponds
    to a gray-level version of the image.
  prefs: []
  type: TYPE_NORMAL
- en: HSV and HLS are interesting color spaces because they decompose the colors into
    their hue and saturation components plus the value or luminance component, which
    is a more natural way for humans to describe colors.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also convert color images to a gray-level intensity. The output will
    be a one-channel image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: It is also possible to do the conversion in another direction, but the three
    channels of the resulting color image will then be identically filled with the
    corresponding values in the gray-level image.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Using the mean shift algorithm to find an object* recipe in [Chapter 4](part0032_split_000.html#page
    "Chapter 4. Counting the Pixels with Histograms"), *Counting the Pixels with Histograms*,
    uses the HSV color space in order to find an object in an image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Many good references are available on the color space theory. Among them, the
    following is a complete reference: *The Structure and Properties of Color Spaces
    and the Representation of Color Images*, *E. Dubois*, *Morgan and Claypool Publishers*,
    *2009*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Representing colors with hue, saturation, and brightness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we played with image colors. We used different color spaces
    and tried to identify image areas that have a specific color. The RGB color space,
    for instance, was considered, and although it is an effective representation for
    the capture and display of colors in electronic imaging systems, this representation
    is not very intuitive. This is not the way humans think about colors. We talk
    about colors in terms of their tint, brightness, or colorfulness (that is, whether
    it is a vivid or pastel color). The **phenomenal color spaces** based on the concept
    of hue, saturation, and brightness were introduced to help users to specify the
    colors using properties that are more intuitive to them. In this recipe, we will
    explore the concepts of hue, saturation, and brightness as a means to describe
    colors.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The conversion of a BGR image into a phenomenal color space is done using the
    `cv::cvtColor` function that was explored in the previous recipe. Here, we will
    use the `CV_BGR2HSV` conversion code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We can go back to the BGR space using the `CV_HSV2BGR` code. We can visualize
    each of the HSV components by splitting the converted image channels into three
    independent images, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we are working on 8-bit images, OpenCV rescales the channel values to
    cover the `0` to `255` range (except for the hue, which is rescaled between `0`
    and `180` as it will be explained in the next section). This is very convenient
    as we are able to display these channels as gray-level images. The value channel
    of the castle image will then look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/00021.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The same image in the saturation channel will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/00022.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, the image with the hue channel is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/00023.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: These images are interpreted in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The phenomenal color spaces have been introduced because they correspond to
    the way humans tend to naturally organize colors. Indeed, humans prefer to describe
    colors with intuitive attributes such as tint, colorfulness, and brightness. These
    three attributes are the basis of most phenomenal color spaces. **Hue** designates
    the dominant color; the names that we give to colors (such as green, yellow, blue,
    and red) correspond to the different hue values. **Saturation** tells us how vivid
    the color is; pastel colors have low saturation, while the colors of the rainbow
    are highly saturated. Finally, **brightness** is a subjective attribute that refers
    to the luminosity of a color. Other phenomenal color spaces use the concept of
    color **value** or color **lightness** as a way to characterize the relative color
    intensity.
  prefs: []
  type: TYPE_NORMAL
- en: 'These color components try to mimic the intuitive human perception of colors.
    In consequence, there is no standard definition for them. In the literature, you
    will find several different definitions and formulae of the hue, saturation, and
    brightness. OpenCV proposes two implementations of phenomenal color spaces: the
    HSV and the HLS color spaces. The conversion formulas are slightly different,
    but they give very similar results.'
  prefs: []
  type: TYPE_NORMAL
- en: The value component is probably the easiest to interpret. In the OpenCV implementation
    of the HSV space, it is defined as the maximum value of the three BGR components.
    It is a very simplistic implementation of the brightness concept. For a definition
    that matches the human visual system better, you should use the `L` channel of
    the L*a*b* or L*u*v* color spaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute the saturation, OpenCV uses a formula based on the minimum and maximum
    values of the BGR components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/00024.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The idea is that a grayscale color in which the three R, G, and B components
    are all equal will correspond to a perfectly desaturated color; therefore, it
    will have a saturation value of `0`. Saturation is then a value between `0` and
    `1.0`. For 8-bit images, saturation is rescaled to a value between `0` and `255`,
    and when displayed as a gray-level image, brighter areas correspond to the colors
    that have a higher saturation color. For example, from the saturation image in
    the previous section, it can be seen that the blue of the water is more saturated
    than the light blue pastel color of the sky, as expected. The different shades
    of gray have, by definition, a saturation value equal to zero (because, in this
    case, all the three BGR components are equal). This can be observed on the different
    roofs of the castle, which are made of a dark gray stone. Finally, in the saturation
    image, you may have noticed some white spots located at areas that correspond
    to very dark regions of the original image. These are a consequence of the used
    definition for saturation. Indeed, because saturation measures only the relative
    difference between the maximum and minimum BGR values, a triplet such as (1,0,0)
    gives a perfect saturation of `1.0`, even if this color would be seen as black.
    Consequently, the saturation values measured at dark regions are unreliable and
    should not be considered.
  prefs: []
  type: TYPE_NORMAL
- en: The hue of a color is generally represented by an angle value between `0` and
    `360`, with the red color at `0` degree. In the case of an 8-bit image, OpenCV
    divides this angle by two to fit within the single byte range. Therefore, each
    hue value corresponds to a given color tint independent of its brightness and
    saturation. For example, both the sky and the water have the same hue value, approximately
    `200` degrees (intensity, `100`), which corresponds to the blue shade; the green
    color of the trees in the background has a hue of around `90` degrees. It is important
    to note that hue is less reliable when evaluated for colors that have a very low
    saturation.
  prefs: []
  type: TYPE_NORMAL
- en: The HSB color space is often represented by a cone, where each point inside
    corresponds to a particular color. The angular position corresponds to the hue
    of the color, the saturation is the distance from the central axis, and the brightness
    is given by the height. The tip of the cone corresponds to the black color for
    which the hue and saturation are undefined.
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/00025.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Interesting effects can be created by playing with the HSV values. Several
    color effects that can be created using photo editing software are accomplished
    by this color space. For example, you may decide to modify an image by assigning
    a constant brightness to all the pixels of an image without changing the hue and
    saturation. This can be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives the following screenshot, which now looks like a drawing (see the
    book''s graphic bundle to view this image in color):'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/00026.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The HSV color space can also be very convenient to use when you want to look
    for objects of specific colors.
  prefs: []
  type: TYPE_NORMAL
- en: Using colors for detection – skin tone detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Color information can be very useful for the initial detection of specific objects.
    For example, the detection of road signs in a driver-assistance application could
    rely on the colors of standard signs in order to quickly extract potential road
    sign candidates. The detection of skin color is another example in which the detected
    skin regions could be used as an indicator of the presence of a human in an image;
    this approach is very often used in gesture recognition where skin tone detection
    is used to detect hand positions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, to detect an object using color, you first need to collect a large
    database of image samples that contain the object captured from different viewing
    conditions. These will be used to define the parameters of your classifier. You
    also need to select the color representation that you will use for classification.
    For skin tone detection, many studies have shown that skin color from the diverse
    ethnical groups clusters well in the hue-saturation space. For this reason, we
    will simply use the hue and saturation values to identify the skin tones in the
    following image (see the book''s graphic bundle to view this image in color):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using colors for detection – skin tone detection](img/00027.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, we have defined a function that classifies the pixels of an image
    as skin or non-skin simply based on an interval of values (the minimum and maximum
    hue, and the minimum and maximum saturation):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Having a large set of skin (and non-skin) samples at our disposal, we could
    have used a probabilistic approach in which the likelihood of observing a given
    color in the skin class versus that of observing the same color in the non-skin
    class. Here, we empirically defined an acceptable hue-saturation interval for
    our test image (remember that the 8-bit version of the hue goes from 0 to 180
    and saturation goes from 0 to 255):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The following detection image is obtained as the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using colors for detection – skin tone detection](img/00028.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note that, for simplicity, we have not considered color saturation in the detection.
    In practice, excluding the colors with a high saturation would have reduced the
    possibility of the wrong detection of bright reddish colors as skin. Obviously,
    a reliable and accurate detection of skin color would require a much more elaborate
    analysis that would have to be based on a large number of skin samples. It is
    also very difficult to guarantee good detection across different images because
    many factors influence the color rendering in photography, such as white balancing
    and lighting conditions. Nevertheless, as shown in this chapter, only using hue
    information as an initial detector gives us acceptable results.
  prefs: []
  type: TYPE_NORMAL
