<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Step 3 &#x2013; Validating the Results"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Step 3 – Validating the Results</h1></div></div></div><p>In the previous chapter, we estimated the language of new countries starting from their flag. For this purpose, we used KNN algorithm that is a supervised learning algorithm. We built KNN and measured its accuracy cross validating the estimated language. In this chapter, we will see how to measure the accuracy in a more reliable way and we will tune the KNN parameters to improve its performance. To be able to do the tasks in this chapter, it's not necessary for you to have read the previous chapter, although it is recommended so that you can order to understand how the KNN algorithm works.</p><p>In this chapter, you will learn how to:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Validate the accuracy of an algorithm</li><li class="listitem" style="list-style-type: disc">Tune the algorithm parameters</li><li class="listitem" style="list-style-type: disc">Select the most relevant data features</li><li class="listitem" style="list-style-type: disc">Optimize the parameters and the features together</li></ul></div><div class="section" title="Validating a machine learning model"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec32"/>Validating a machine learning model</h1></div></div></div><p>Starting from a <a id="id317" class="indexterm"/>table describing the countries, flags and their language, the KNN estimates a new country language starting from its flag attributes. In this chapter, we will evaluate the performance of KNN.</p><div class="section" title="Measuring the accuracy of an algorithm"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec36"/>Measuring the accuracy of an algorithm</h2></div></div></div><p>We have <a id="id318" class="indexterm"/>already evaluated the <a id="id319" class="indexterm"/>algorithm accuracy by cross validating the estimated language. First, we split the data in two parts that are the training set and the test set. Then, we built the KNN algorithm using the training set in order to estimate the test set countries' language. Counting how many times the estimated language was correct, we defined an accuracy index as the percentage of correct guesses. The accuracy depends on which data we put into the test set. Since we randomly defined the training set countries, the accuracy changes every time we repeat the cross validation. Then, the result of this approach is not reliable.</p><p>The target of this chapter is to evaluate KNN using a reliable technique in the sense that the accuracy doesn't change validating the same model twice. Repeating the train/set split and the validation many times, almost every country will be in both the training and the test set at least once. We can compute the average accuracy and it will take account of all the countries in both the training and the test sets. After a few iterations, the average accuracy will be reliable since it won't significantly change increasing the number of iterations.</p><p>Before <a id="id320" class="indexterm"/>evaluating KNN, we need to load the <code class="literal">kknn</code> and <code class="literal">data.table</code> packages:</p><div class="informalexample"><pre class="programlisting"># load the packages
library('kknn')
library('data.table')</pre></div><p>We can define a function building and cross validating KNN using a defined set of parameters and data so that we can quickly evaluate the algorithm with any configuration. Since the R commands are similar to the previous chapter, we will go quickly through them. The input of the functions is:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A table containing the data</li><li class="listitem" style="list-style-type: disc">A vector containing the name of the features that we use</li><li class="listitem" style="list-style-type: disc">KNN parameters</li></ul></div><p>The steps are <a id="id321" class="indexterm"/>as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Define which rows belong to the training and test sets. We build <code class="literal">indexTrain</code>, which is a vector specifying which rows will be in the training set. We set a probability of 10 percent for a flag to be in the test set. In <a class="link" href="ch05.html" title="Chapter 5. Step 2 – Applying Machine Learning Techniques">Chapter 5</a>, <span class="emphasis"><em>Step 2 – Applying Machine Learning Techniques</em></span>, we set a probability of 20 percent, but in this chapter we will repeat the validation many times, so 10 percent is enough.</li><li class="listitem">Starting from <code class="literal">indexTrain</code>, extract the rows going into <code class="literal">dtTrain</code> and into <code class="literal">dtTest</code>.</li><li class="listitem">Define the formula defining the features and the attribute to predict.</li><li class="listitem">Build KNN using the input parameters.</li><li class="listitem">Define the <code class="literal">languageFitted</code> vector containing the estimated language of the test set.</li><li class="listitem">Count how many times <code class="literal">languageFitted</code> is the same as the real language.</li><li class="listitem">Compute the accuracy index as the number of times the predicted language and the real language match, divided by the number of countries in the test set.</li></ol></div><p>This is the <a id="id322" class="indexterm"/>R code to build the <a id="id323" class="indexterm"/>function. The comments reflect the numbered bullet points, as shown:</p><div class="informalexample"><pre class="programlisting">validateKnn &lt;- function(
  dtFeatures, # data table with the features
  arrayFeatures, # feature names array
  k = 10, # knn parameter
  kernel = 'rectangular', # knn parameter
  distance = 1 # knn parameter
){
  
  # 1 define the training/test set rows
  indexTrain &lt;- sample(
    x=c(TRUE, FALSE),
    size=nrow(dtFeatures),
    replace=TRUE,
    prob=c(0.9, 0.1)
  )
  
  # 2 define the training/test set
  dtTrain &lt;- dtFeatures[indexTrain]
  dtTest &lt;- dtFeatures[!indexTrain]
  
  # 3 define the formula
  formulaOutput &lt;- 'language ~'
  formulaFeatures &lt;- paste(arrayFeatures, collapse = ' + ')
  formulaKnn &lt;- paste(formulaOutput, formulaFeatures)
  formulaKnn &lt;- formula(formulaKnn)
  
  # 4 build the KNN model
  modelKnn &lt;- kknn(
    formula = formulaKnn,
    train = dtTrain,
    test = dtTest,
    k = k,
    kernel = kernel,
    distance = distance
  )
  
  # 5 defining the predicted language
  languageFitted &lt;- modelKnn$fitted.values
  
  # 6 count the corrected predictions and the total
  languageReal &lt;- dtTest[, language]
  nRows &lt;- length(languageReal)
  
  # 7 define the accuracy index
  percCorrect &lt;- sum(languageFitted == languageReal) / nRows
  
  return(percCorrect)
}</pre></div><p>Here, <code class="literal">validateKnn</code> <a id="id324" class="indexterm"/>is the <a id="id325" class="indexterm"/>starting point to validate the KNN algorithm.</p></div><div class="section" title="Defining the average accuracy"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec37"/>Defining the average accuracy</h2></div></div></div><p>In <a id="id326" class="indexterm"/>order to use <code class="literal">validateKnn</code>, we need to define the input, as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The data table with the features, as shown:<div class="informalexample"><pre class="programlisting">setwd('&lt;INSER/YOUR/DIRECTORY/PATH&gt;")
dfFeatures &lt;- read.table(file = 'dtFeatures.txt')</pre></div></li><li class="listitem" style="list-style-type: disc">The vector containing all the possible features to include in KNN:<div class="informalexample"><pre class="programlisting">arrayFeatures &lt;- names(dfFeatures)
arrayFeatures &lt;- arrayFeatures[arrayFeatures != 'language']</pre></div></li><li class="listitem" style="list-style-type: disc">The KNN parameters that can either be set or left as their defaults.</li></ul></div><p>Now, we have all the <a id="id327" class="indexterm"/>elements to be able to use <code class="literal">validateKnn</code>. We can use a random subset of them, for instance, the first 10 features. With regard to the parameters, we can leave all of them to their default, except <code class="literal">k</code> that is equal to <code class="literal">8</code>, as shown:</p><div class="informalexample"><pre class="programlisting"># evaluate a model accuracy
validateKnn(
  dtFeatures = dtFeatures,
  arrayFeatures = arrayFeatures[1:10],
  k = 8
)
<span class="strong"><strong>[1] 0.3571429</strong></span>
</pre></div><p>Running <code class="literal">validateKnn</code> more than once, we can notice that the result changes every time, as expected. However, now we can define another function running <code class="literal">validateKnn</code> multiple times. Then, we compute the accuracy average and use it as a reliable performance index. Our new function is called <code class="literal">cvKnn</code> because it cross validates KNN a defined number of times.</p><p>The <code class="literal">cvKnn</code> arguments are the data table, the number of iterations, the feature names, and the KNN <a id="id328" class="indexterm"/>parameters. Let's start defining the data table and the number of iterations. All the other input is the same as <code class="literal">validateKnn</code>. In order to have clear and compact code, we can use the ellipsis (...) specifying that we can add other arguments. Then, we can pass these arguments to any function using the ellipsis again. This means that when we will call <code class="literal">validateKnn</code>, we can use <code class="literal">validateKnn(...)</code> to specify that any extra argument of <code class="literal">cvKnn</code> will be an input for <code class="literal">validateKnn</code>.</p><p>The <a id="id329" class="indexterm"/>function steps are:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Defining an <a id="id330" class="indexterm"/>empty vector <code class="literal">arrayPercCorrect</code> that will contain the accuracies.</li><li class="listitem">Running <code class="literal">validateKnn</code> and defining <code class="literal">arrayPercCorrect</code>, which contains the accuracy.</li><li class="listitem">Adding the accuracy <code class="literal">arrayPercCorrect</code> to <code class="literal">arrayPercCorrect</code>.</li></ol></div><p>This is the code that builds the function:</p><div class="informalexample"><pre class="programlisting">cvKnn &lt;- function(
  dtFeatures, # data table with the features
  nIterations=10, # number of iterations
  ... # feature names array and knn parameters
){
  
  # 1 initialize the accuracy array
  arrayPercCorrect &lt;- c()
  
  for(iIteration in 1:nIterations){
    
    # 2 build and validate the knn
    percCorrect &lt;- validateKnn(dtFeatures, ...)
    
    # 3 add the accuracy to the array
    arrayPercCorrect &lt;- c(arrayPercCorrect, percCorrect)
  }
 
  return(arrayPercCorrect)
}</pre></div><p>Now, we can use <code class="literal">cvKnn</code> to build and validate KNN 500 times. Then, we compute the average accuracy as a KNN performance index:</p><div class="informalexample"><pre class="programlisting"># determine the accuracies
arrayPercCorrect = cvKnn(
  dtFeatures, nIterations=500,
  arrayFeatures=arrayFeatures
)
# compute the average accuracy
percCorrectMean &lt;- mean(arrayPercCorrect)
percCorrectMean
<span class="strong"><strong>[1] 0.2941644</strong></span>
</pre></div><p>We <a id="id331" class="indexterm"/>define <code class="literal">percCorrectMean</code>, which can be used as an accuracy index.</p></div><div class="section" title="Visualizing the average accuracy computation"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec38"/>Visualizing the average accuracy computation</h2></div></div></div><p>In <a id="id332" class="indexterm"/>order to see how much the <a id="id333" class="indexterm"/>result changed at any iteration, we can compare each step's accuracy with their average. First, we build a chart with the accuracies using <code class="literal">plot</code> and the parameters are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">x</code>: This is the vector that we want to plot (<code class="literal">arrayPercCorrect</code>).</li><li class="listitem" style="list-style-type: disc"><code class="literal">ylim</code>: This is the accuracy that is a number between 0 and 1. With <code class="literal">ylim = c(0, 1)</code>, we specify that the region that we visualize is between 0 and 1.</li><li class="listitem" style="list-style-type: disc"><code class="literal">xlab</code> and <code class="literal">ylab</code>: These are the axis labels.</li><li class="listitem" style="list-style-type: disc"><code class="literal">main</code>: This is the title.</li></ul></div><p>The code is as follows:</p><div class="informalexample"><pre class="programlisting"># plot the accuracy at each iteration
plot(
  x = arrayPercCorrect,
  ylim = c(0, 1),
  xlab = 'Iteration', ylab = 'Accuracy',
  main = 'Accuracy at each iteration'
)</pre></div><p>In order to compare the accuracies with their average, we can display the average by drawing a red dashed horizontal line with <code class="literal">abline</code>, as shown:</p><div class="informalexample"><pre class="programlisting">help(abline)
abline(h=percCorrectMean, col='red', lty='dashed')</pre></div><p>We can visualize the values' range by drawing a horizontal line for both the minimum and the maximum range, as shown:</p><div class="informalexample"><pre class="programlisting">abline(h=min(arrayPercCorrect), col='blue', lty='dashed')
abline(h=max(arrayPercCorrect), col='blue', lty='dashed')</pre></div><p>The plot obtained is as follows:</p><div class="mediaobject"><img src="graphics/7740OS_06_01.jpg" alt="Visualizing the average accuracy computation"/></div><p>The accuracy varies a lot from one iteration to another and the range is between 0 percent and 70 percent. As expected, a single accuracy is completely unreliable. What about the average among 500 iterations? How many iterations do we need to have a stable result?</p><p>We can visualize the accuracy index at the first iteration, then the average among the first two iterations, then the average among the first three, and so on. If at any point the average stops <a id="id334" class="indexterm"/>changing, we don't need to go any further. By building a chart we can observe how many iterations it takes to reach a stable average.</p><p>First, let's <a id="id335" class="indexterm"/>define <code class="literal">arrayCumulate</code> containing the cumulated average that is the partial average until each iteration, as shown:</p><div class="informalexample"><pre class="programlisting"># plot the average accuracy until each iteration
arrayCumulate &lt;- c()
for(nIter in 1:length(arrayPercCorrect)){
  cumulateAccuracy &lt;- mean(arrayPercCorrect[1:nIter])
  arrayCumulate &lt;- c(arrayCumulate, cumulateAccuracy)
}</pre></div><p>Using the same commands as before, we build a new chart. The only new argument is <code class="literal">type='l'</code> and it specifies that we display a line instead of points. In order to zoom into the area with the averages, we remove the <code class="literal">ylim</code> argument, as shown:</p><div class="informalexample"><pre class="programlisting">plot(
  x = arrayCumulate,
  type = 'l',
  xlab = 'Iteration', ylab = 'Cumulate accuracy',
  main = 'Average accuracy until each iteration'
)
abline(h = percCorrectMean, col = 'red', lty = 'dashed')</pre></div><p>The plot <a id="id336" class="indexterm"/>obtained is <a id="id337" class="indexterm"/>as follows:</p><div class="mediaobject"><img src="graphics/7740OS_06_02.jpg" alt="Visualizing the average accuracy computation"/></div><p>We can notice that the accuracy is nearly stable after the 100 iterations. Assuming that it won't change too much with different parameter configuration, we can use 100 iterations to validate the KNN algorithm.</p><p>In this section, we have seen how to automatically evaluate a model performance using a specific set of features and some defined parameters. In the following sections, we will use this function <a id="id338" class="indexterm"/>to <a id="id339" class="indexterm"/>optimize the model's performance.</p></div></div></div>
<div class="section" title="Tuning the parameters"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec33"/>Tuning the parameters</h1></div></div></div><p>This section <a id="id340" class="indexterm"/>shows you how to improve the performance of KNN by tuning its parameters. We are dealing with the <span class="emphasis"><em>k</em></span> parameter that defines the number of neighbors. Use these steps to identify the <span class="emphasis"><em>k</em></span> parameter performing best:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Define which values of <span class="emphasis"><em>k</em></span> we will test. The KNN works locally, in the sense that given a new country flag it identifies just a few similar flags. How many of them should we use at most? Since there are less than 200 flags in total, we don't want to use more than 50 flags. Then, we should test each <span class="emphasis"><em>k</em></span> between 1 and 50 and we can define <code class="literal">arrayK</code> containing the options:<div class="informalexample"><pre class="programlisting"># define the k to test
arrayK &lt;- 1:50</pre></div></li><li class="listitem">Define the number of iterations. For each <span class="emphasis"><em>k</em></span> in <code class="literal">arrayK</code>, we need to build and validate the KNN a sufficiently high amount of times defined by <code class="literal">nIterations</code>. In the previous chapter, we learned that we need at least 100 iterations to have a meaningful KNN accuracy:<div class="informalexample"><pre class="programlisting">nIterations &lt;- 100</pre></div></li><li class="listitem">Evaluate the accuracy for each <span class="emphasis"><em>k</em></span>.</li><li class="listitem">Choose the <span class="emphasis"><em>k</em></span> that maximizes the accuracy.</li></ol></div><p>The last two steps are more detailed and we will explore them in depth.</p><p>In order to measure the accuracy for each <span class="emphasis"><em>k</em></span>, we define <code class="literal">dtAccuracyK</code> as an empty data table that will contain the accuracies. Then, we use a <code class="literal">for</code> loop to run KNN with each <span class="emphasis"><em>k</em></span> in <span class="emphasis"><em>arrayK</em></span> and add the new results. The steps are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Run and validate KNN using <code class="literal">cvKnn</code>.</li><li class="listitem">Define the rows that we will add to <code class="literal">dtAccuracyK</code> containing the accuracy and the <span class="emphasis"><em>k</em></span>.</li><li class="listitem">Add the new rows to <code class="literal">dtAccuracyK</code> using <code class="literal">rbind</code>:<div class="informalexample"><pre class="programlisting"># validate the knn with different k
dtAccuracyK &lt;- data.table()
for(k in arrayK)
{

  # run the KNN and compute the accuracies
  arrayAccuracy &lt;- cvKnn(
    dtFeatures,
    nIterations=nIterations,
    arrayFeatures = arrayFeatures,
    k = k
  )
  # define the new data table rows
  rowsAccuracyK &lt;- data.table(
    accuracy = arrayAccuracy,
    k = k
  )
  # add the new rows to the accuracy table
  dtAccuracyK &lt;- rbind(
    dtAccuracyK,
    rowsAccuracyK
    )
}</pre></div></li></ol></div><p>Now, let's <a id="id341" class="indexterm"/>take a look at <code class="literal">result.head(dtAccuracyK)</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>    accuracy k</strong></span>
<span class="strong"><strong>1: 0.3636364 1</strong></span>
<span class="strong"><strong>2: 0.4545455 1</strong></span>
<span class="strong"><strong>3: 0.4000000 1</strong></span>
<span class="strong"><strong>4: 0.2727273 1</strong></span>
<span class="strong"><strong>5: 0.3000000 1</strong></span>
<span class="strong"><strong>6: 0.2500000 1</strong></span>
</pre></div><p>Each row of <code class="literal">dtAccuracyK</code> contains an iteration of KNN. The first column displays the accuracy and the second column displays the <span class="emphasis"><em>k</em></span> used in the iteration.</p><p>In order to visualize the results, we can use <code class="literal">plot</code>. The two dimensions that we want to visualize are the <span class="emphasis"><em>k</em></span> and the accuracy. The input is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">x</code>, <code class="literal">y</code>: These are the plot dimensions that are the <code class="literal">k</code> and <code class="literal">accuracy</code> columns</li><li class="listitem" style="list-style-type: disc"><code class="literal">xlab</code>, <code class="literal">ylab</code>: These are the axis labels that are <code class="literal">k</code> and <code class="literal">accuracy</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">main</code>: This is the chart title</li><li class="listitem" style="list-style-type: disc"><code class="literal">ylim</code>: These are the <span class="emphasis"><em>y</em></span> region limits that are <code class="literal">0</code> and <code class="literal">1</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">col</code>: This is the color of the points that is gray, in order to put emphasis on the black points that we will add later</li></ul></div><p>The code is as follows:</p><div class="informalexample"><pre class="programlisting"># plot all the accuracies
plot(
  x = dtAccuracyK[, k],
  y = dtAccuracyK[, accuracy],
  xlab = 'K', ylab = 'Accuracy',
  main = 'KNN accuracy using different k',
  ylim = c(0, 1),
  col = 'grey'
)</pre></div><p>The plot obtained is as follows:</p><div class="mediaobject"><img src="graphics/7740OS_06_03.jpg" alt="Tuning the parameters"/></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip04"/>Tip</h3><p>You can also use <code class="literal">type = 'str(dtCvK)'</code> instead of <code class="literal">type = 'o'</code>.</p></div></div><p>We cannot notice any relevant difference depending on <span class="emphasis"><em>k</em></span>. The reason is that the accuracy varies a lot from one iteration to another. In order to identify <span class="emphasis"><em>k</em></span> performing better, we can compute the average performance for each <span class="emphasis"><em>k</em></span>. We call the new data table <code class="literal">dtCvK</code> because we're cross <a id="id342" class="indexterm"/>validating the model, as shown:</p><div class="informalexample"><pre class="programlisting"># compute the average accuracy
dtCvK &lt;- dtAccuracyK[
  , list(accuracy = mean(accuracy)),
  by='k'
  ]
View(dtCvK)</pre></div><p>Here, <code class="literal">dtCvK</code> contains the average accuracy of each <span class="emphasis"><em>k</em></span>. We can add it to the chart using points that is a function adding the new points to the current chart. In order to make the points more visible, we display full points using <code class="literal">pch = 16</code>, as shown:</p><div class="informalexample"><pre class="programlisting"># add the average accuracy to the chart
help(points)
points(
  x = dtCvK[, k],
  y = dtCvK[, accuracy],
  pch = 16
)</pre></div><p>The plot is as follows:</p><div class="mediaobject"><img src="graphics/7740OS_06_04.jpg" alt="Tuning the parameters"/></div><p>The average <a id="id343" class="indexterm"/>accuracies vary across the <span class="emphasis"><em>k</em></span>, but it is hard to notice the difference because it is always around 0.3 to 0.4. In order to see the difference more clearly, we can plot just the average without visualizing the <span class="emphasis"><em>y</em></span> limits, as shown:</p><div class="informalexample"><pre class="programlisting"># plot the average accuracy
plot(
  x = dtCvK[, k],
  y = dtCvK[, accuracy],
  xlab = 'k', ylab = 'accuracy',
  main = 'average knn accuracy using different k',
  type = 'o'
)</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip13"/>Tip</h3>
You can also use <code class="literal">type = 'str(dtCvK)'</code> instead of type = <code class="literal">'o'</code>.
</div></div><p>We can identify the <span class="emphasis"><em>k</em></span> performing best and add it to the chart using <code class="literal">abline</code>:</p><div class="informalexample"><pre class="programlisting"># identify the k performing best
kOpt &lt;- dtCvK[accuracy == max(accuracy), k]
abline(v = kOpt, col = 'red')</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip05"/>Tip</h3><p>You can also use <code class="literal">kOpt &lt;- 27</code> instead of <code class="literal">kOpt &lt;- dtCvK[accuracy == max(accuracy), k]</code>.</p></div></div><p>The plot obtained is as follows:</p><div class="mediaobject"><img src="graphics/7740OS_06_05.jpg" alt="Tuning the parameters"/></div><p>The optimal <span class="emphasis"><em>k</em></span> is 27 and the KNN performs very well if the <span class="emphasis"><em>k</em></span> is in the 22 to 30 range.</p><p>In this chapter, we <a id="id344" class="indexterm"/>identified <span class="emphasis"><em>k</em></span> performing at its best. However, there are still other parameters that we haven't optimized, such as the distance method. In addition, we can improve the algorithm selecting the features to include and we will explore it in the next section.</p></div>
<div class="section" title="Selecting the data features to include in the model"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec34"/>Selecting the data features to include in the model</h1></div></div></div><p>In the <a id="id345" class="indexterm"/>previous section, we set a KNN parameter <a id="id346" class="indexterm"/>maximizing the performance. Another tuning option is to define which data we use to build the model. Our table describes the flags using 37 features and we included all of them in the model. However, KNN might perform better including only a subset of them.</p><p>The easiest way to select the features is to use a filter (as anticipated in the <span class="emphasis"><em>Ranking the features using a filter or a dimensionality reduction</em></span> section in <a class="link" href="ch04.html" title="Chapter 4. Step 1 – Data Exploration and Feature Engineering">Chapter 4</a>, <span class="emphasis"><em>Step 1 – Data Exploration and Feature Engineering</em></span>) that estimates the impact of each feature and includes only the most relevant features. After ranking all the features on the basis of their relevance, we can define the <code class="literal">n</code> parameters specifying how many of them we include in the model. Then, we can maximize the accuracy depending on <code class="literal">n</code>, using an approach similar to the previous section.</p><p>The first step is defining how to rank the features. We can use the information gain ratio filter that estimated the impact of each feature ignoring the others. We have already talked about <a id="id347" class="indexterm"/>the information gain ratio and its <a id="id348" class="indexterm"/>limitations (refer to the <span class="emphasis"><em>Ranking the features using a filter or a dimensionality reduction</em></span> section in <a class="link" href="ch04.html" title="Chapter 4. Step 1 – Data Exploration and Feature Engineering">Chapter 4</a>, <span class="emphasis"><em>Step 1 – Data Exploration and Feature Engineering</em></span>) and we will use the same R commands, as shown:</p><div class="informalexample"><pre class="programlisting"># rank the features
library('FSelector')
dfGains &lt;- information.gain(
  language~., dtFeatures
  )
dfGains$feature &lt;- row.names(dfGains)
dtGains &lt;- data.table(dfGains)
dtGains &lt;- dtGains[order(attr_importance, decreasing = T)]
arrayFeatures &lt;- dtGains[, feature]</pre></div><p>Here, <code class="literal">arrayFeatures</code> contains the features sorted by relevance. Now, we can build the model choosing the top <span class="emphasis"><em>n</em></span> features. The options for <span class="emphasis"><em>n</em></span> are the numbers between <code class="literal">1</code> and the total number of features, and we define <code class="literal">arrayN</code> containing them, as shown:</p><div class="informalexample"><pre class="programlisting"># define the number of features to test
arrayN &lt;- 1:length(arrayFeatures)</pre></div><p>In order to store the accuracy of each iteration, we define <code class="literal">dtAccuracyN</code> as an empty data table and we iteratively add the rows using a <code class="literal">for</code> loop. The steps are as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Validate KNN using <code class="literal">cvKnn</code> and store the accuracies in <code class="literal">arrayAccuracy</code>. We set the <span class="emphasis"><em>k</em></span> parameter equal to <code class="literal">kOpt (27)</code>, that is, the optimal <span class="emphasis"><em>k</em></span> defined in the previous section.</li><li class="listitem">Define the <code class="literal">rowsAccuracyN</code> data table with the rows to add.</li><li class="listitem">Add the new rows to <code class="literal">dtAccuracyN</code> using <code class="literal">rbind</code>.</li></ol></div><p>This is the code generating the <code class="literal">for</code> loop:</p><div class="informalexample"><pre class="programlisting">for(n in arrayN)
{
  # 1 run the KNN and compute the accuracies
  arrayAccuracy &lt;- cvKnn(
    dtFeatures,
    nIterations = nIterations,
    arrayFeatures = arrayFeatures[1:n],
    k = kOpt
  )
  
  # 2 define the new data table rows
  rowsAccuracyN &lt;- data.table(
    accuracy = arrayAccuracy,
    n = n
  )
  
  # 3 add the new rows to the accuracy table
  dtAccuracyN &lt;- rbind(
    dtAccuracyN,
    rowsAccuracyN
  )
}</pre></div><p>Here, <code class="literal">dtAccuracyN</code> contains each iteration accuracy, depending on <span class="emphasis"><em>n</em></span>. We can build a chart containing <a id="id349" class="indexterm"/>all the accuracies and their average <a id="id350" class="indexterm"/>across different values of <span class="emphasis"><em>n</em></span>, by using the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Build a chart displaying the accuracy at each iteration:<div class="informalexample"><pre class="programlisting">plot(
  x = dtAccuracyN[, n],
  y = dtAccuracyN[, accuracy],
  xlab = 'N', ylab = 'Accuracy',
  main = 'KNN accuracy using different features',
  ylim = c(0, 1),
  col = 'grey'
)</pre></div></li><li class="listitem">Starting from <code class="literal">dtAccuracyN</code>, compute the average accuracy for each iteration:<div class="informalexample"><pre class="programlisting">dtCvN &lt;- dtAccuracyN[
  , list(accuracy = mean(accuracy)),
  by='n'
  ]</pre></div></li><li class="listitem">Add the points with the average accuracy to the chart:<div class="informalexample"><pre class="programlisting">Points(
  x = dtCvN[, n],
  y = dtCvN[, accuracy],
  xlab = 'n', ylab = 'accuracy',
  pch = 16
)</pre></div></li></ol></div><p>The plot obtained is as follows:</p><div class="mediaobject"><img src="graphics/7740OS_06_06.jpg" alt="Selecting the data features to include in the model"/></div><p>The chart shows <a id="id351" class="indexterm"/>that we achieved the best accuracies using <a id="id352" class="indexterm"/>high values of <span class="emphasis"><em>n</em></span>. In order to identify the best <span class="emphasis"><em>n</em></span>, we can plot just their averages. Then, we define <code class="literal">nOpt</code> that is the <span class="emphasis"><em>n</em></span> performing best and we add a red vertical line corresponding to it, as shown:</p><div class="informalexample"><pre class="programlisting"># plot the average accuracy
plot(
  x = dtCvN[, n],
  y = dtCvN[, accuracy],
  xlab = 'N', ylab = 'Accuracy',
  main = 'Average knn accuracy using different features',
  type = 'o'
)

# identify the n performing best
nOpt &lt;- dtCvN[accuracy == max(accuracy), n]
abline(v = nOpt, col = 'red')</pre></div><p>The plot obtained is as follows:</p><div class="mediaobject"><img src="graphics/7740OS_06_07.jpg" alt="Selecting the data features to include in the model"/></div><p>The number of features performing best is <span class="strong"><strong>15</strong></span> and the performance decreases slowly after this point.</p><p>In the chart, we can notice that there are some points in which the accuracy decreases a lot adding a new feature (for example, <span class="strong"><strong>3</strong></span>, <span class="strong"><strong>11</strong></span>, <span class="strong"><strong>13</strong></span>). In these points, we are adding a feature that decreases the performance. What if we just decide not to include it? We can start building the model <a id="id353" class="indexterm"/>using the most relevant feature only, and <a id="id354" class="indexterm"/>then add the second most relevant feature. If the performance improves, we keep the second feature; otherwise, we discard it. After that, we do the same with the third feature and we repeat this until we have added or discarded each feature. This approach is called wrapper and it allows us to define a better feature set than the filter.</p><p>In this section, we identified the best <span class="emphasis"><em>n</em></span> and the best <span class="emphasis"><em>k</em></span>, so we use them to build KNN with a good performance.</p></div>
<div class="section" title="Tuning features and parameters together"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec35"/>Tuning features and parameters together</h1></div></div></div><p>In the <a id="id355" class="indexterm"/>previous two sections, we identified the best <span class="emphasis"><em>k</em></span> using all the features (<code class="literal">n=37</code>). Then, using the optimal <span class="emphasis"><em>k</em></span>, we identified the best <span class="emphasis"><em>n</em></span>. What if the algorithm performs better with <code class="literal">k=30</code> and <code class="literal">n=25</code>? We haven't explored that combination as well as many other options, so there might be a combination performing better than <code class="literal">k=27</code> and <code class="literal">n=15</code>.</p><p>In order to <a id="id356" class="indexterm"/>identify the best option, the most simple approach is to test all the alternatives. However, if there are too many possible combinations between the variables, we don't have enough computational power to test all of them. In that case, we can identify the optimal parameters using optimization algorithms such as the gradient descend.</p><p>Fortunately, in our case, we are tuning only two parameters and we can test just a part of their possible values. For instance, if we choose 20 values of <span class="emphasis"><em>n</em></span> and 20 values of <span class="emphasis"><em>k</em></span>, we have 400 combinations. In order to do that, we carry out the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Define the options for <span class="emphasis"><em>k</em></span>. Include all features, the KNN had the best performance with <code class="literal">k=26</code> and it performed badly after <code class="literal">40</code>. However, setting a lower <span class="emphasis"><em>n</em></span>, things may change, so we need to test all the possible <span class="emphasis"><em>k</em></span>. In order to limit the number of options, we can limit our testing to the odd numbers. Let's generate all the odd numbers between 1 and 49 using <code class="literal">seq</code>. The <code class="literal">from</code> and <code class="literal">to</code> arguments define the start and end of the sequence. The <code class="literal">by</code> argument defines the increment that is 2 to generate the odd numbers. Using <code class="literal">seq</code>, we build <code class="literal">arrayK</code> containing all the options for <span class="emphasis"><em>k</em></span>, as shown:<div class="informalexample"><pre class="programlisting">arrayK &lt;- seq(from = 1, to =  49, by = 2)</pre></div></li><li class="listitem">Define the options for <span class="emphasis"><em>n</em></span>. We have already seen that the algorithm performs very badly using just a small feature set, so we can test <span class="emphasis"><em>n</em></span> between 10 and the total number of features, that is, 37. Similar to <span class="emphasis"><em>k</em></span>, we include only the odd numbers:<div class="informalexample"><pre class="programlisting">arrayN &lt;- seq(from = 11, to = 37, by = 2)</pre></div></li><li class="listitem">Generate all the possible combinations between <span class="emphasis"><em>k</em></span> and <span class="emphasis"><em>n</em></span>. For this purpose, we can use <code class="literal">expand.grid</code>. Given two or more vectors, <code class="literal">expand.grid</code> generates a data frame with all their possible combinations. In our case, we generate a <code class="literal">k</code> column starting from <code class="literal">arrayK</code> and a <code class="literal">n</code> column starting from <code class="literal">arrayN</code>, as shown:<div class="informalexample"><pre class="programlisting">dfParameters &lt;- expand.grid(k=arrayK, n=arrayN)</pre></div></li><li class="listitem">Convert <code class="literal">dfParameters</code> into a data table:<div class="informalexample"><pre class="programlisting">dtParameters &lt;- data.table(dfParameters)</pre></div></li></ol></div><p>Now, we can take a look at <code class="literal">dtParameters</code> using <code class="literal">head</code>:</p><div class="informalexample"><pre class="programlisting">head(dtParameters)
<span class="strong"><strong>    k  n</strong></span>
<span class="strong"><strong>1:  1 11</strong></span>
<span class="strong"><strong>2:  3 11</strong></span>
<span class="strong"><strong>3:  5 11</strong></span>
<span class="strong"><strong>4:  7 11</strong></span>
<span class="strong"><strong>5:  9 11</strong></span>
<span class="strong"><strong>6: 11 11</strong></span>
</pre></div><p>Here, <code class="literal">dtParameters</code> contains a row for each of the 350 combinations. We need to determine the accuracies and store them in a new column called <code class="literal">accuracy</code>. In order to do that, we use a <code class="literal">for</code> loop running over the rows. The <code class="literal">iConfig</code> variable is the row index defined as a number between 1 and the number of rows <code class="literal">nrow(dtParameters)</code>. There are different combinations, so it might take a while to run this part of the code. After each iteration we build the model using the parameters contained in the row that are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>k</strong></span>: This has the <code class="literal">dtParameters[iConfig, k]</code> parameter</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>n</strong></span>: This has the <code class="literal">dtParameters[iConfig, n]</code> parameter</li></ul></div><p>Consider the <a id="id357" class="indexterm"/>following code:</p><div class="informalexample"><pre class="programlisting"># validate the knn with different k and nFeatures
for(iConfig in 1:nrow(dtParameters)){  
  
  arrayAccuracy &lt;- cvKnn(
    dtFeatures, nIterations = nIterations,
    arrayFeatures = arrayFeatures[1:dtParameters[iConfig, n]],
    k = dtParameters[iConfig, k]
  )</pre></div><p>Now, we can compute the <code class="literal">arrayAccuracy</code> average and add it to <code class="literal">dtParameters</code>:</p><div class="informalexample"><pre class="programlisting">  # add the average accuracy to dtParameters
  dtParameters[iConfig, accuracy := mean(arrayAccuracy)]
}</pre></div><p>Each row of <code class="literal">dtParameters</code> contains a parameter set and its related accuracy. In order to view the accuracies <a id="id358" class="indexterm"/>in a more convenient way, we can build a matrix whose rows correspond to <code class="literal">n</code> and whose columns correspond to <code class="literal">k</code>. Each element of the matrix displays the accuracy. In order to build the matrix, we can use <code class="literal">reshape</code>, as shown:</p><div class="informalexample"><pre class="programlisting"># reshape dtParameters into a matrix
help(reshape)</pre></div><p>The <code class="literal">reshape</code> syntax is quite complex. In our case, that matrix that we want to build is in a <code class="literal">wide</code> format, so we need to specify <code class="literal">direction = "wide"</code>. The other arguments define the columns that we use and they are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">v.names</code>: This column defines the matrix values (the accuracies)</li><li class="listitem" style="list-style-type: disc"><code class="literal">idvar</code>: This column defines the matrix rows (the values of <code class="literal">n</code>)</li><li class="listitem" style="list-style-type: disc"><code class="literal">timevar</code>: This column defines the matrix columns (the values of <code class="literal">k</code>)</li></ul></div><p>Using <code class="literal">reshape</code>, we can build the <code class="literal">dfAccuracy</code> data frame, as shown:</p><div class="informalexample"><pre class="programlisting">dfAccuracy &lt;- reshape(
  data = dtParameters,
  direction = "wide",
  v.names = "accuracy",
  idvar = "n",
  timevar = "k"
)
View(dfAccuracy)</pre></div><p>The <code class="literal">n</code> column contains the <span class="emphasis"><em>n</em></span> parameter and we remove it in order to have a data frame with the accuracy only. Then, we convert the data frame into a matrix, as shown:</p><div class="informalexample"><pre class="programlisting">dfAccuracy$n &lt;- NULL
matrixAccuracy &lt;- as.matrix(dfAccuracy)</pre></div><p>Now, we <a id="id359" class="indexterm"/>can specify <code class="literal">n</code> and <code class="literal">k</code> as the row names and column <a id="id360" class="indexterm"/>names respectively, as shown:</p><div class="informalexample"><pre class="programlisting">rownames(matrixAccuracy) &lt;- arrayN
colnames(matrixAccuracy) &lt;- arrayK
View(matrixAccuracy)</pre></div><p>In order to visualize the accuracy depending on the parameters, we can build a heat map that is a chart representing the matrix. The two chart dimensions are <code class="literal">k</code> and <code class="literal">n</code> and the color represents the value. We can build this chart using <code class="literal">image</code>:</p><div class="informalexample"><pre class="programlisting"># plot the performance depending on k and n
help(image)</pre></div><p>The arguments that we use are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">z</code>: This is the matrix</li><li class="listitem" style="list-style-type: disc"><code class="literal">x</code> and <code class="literal">y</code>: These are the dimension names, contained in <code class="literal">arrayN</code> and <code class="literal">arrayK</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">xLab</code> and <code class="literal">yLab</code>: These are the axis labels</li><li class="listitem" style="list-style-type: disc"><code class="literal">col</code>: This is the vector of colors that we display (we can use the <code class="literal">heat.colors</code> function)</li></ul></div><p>Consider the following code:</p><div class="informalexample"><pre class="programlisting">image(
  x = arrayN, y = arrayK, z = matrixAccuracy,
  xlab = 'n', ylab = 'k',
  col = heat.colors(100)
)</pre></div><p>The plot obtained is as follows:</p><div class="mediaobject"><img src="graphics/7740OS_06_08.jpg" alt="Tuning features and parameters together"/></div><p>A high accuracy is represented by the pale yellow color and a low accuracy is represented by the red color. We can notice that we achieved the best accuracy with <span class="emphasis"><em>k</em></span> in the 9 to 19 range and <span class="emphasis"><em>n</em></span> in the 29 to 33 range. The worst performance is when <span class="emphasis"><em>n</em></span> is low and <span class="emphasis"><em>k</em></span> is high.</p><p>Let's see what the best performing combination is. Consider <a id="id361" class="indexterm"/>the following code:</p><div class="informalexample"><pre class="programlisting"># identify the best k-n combination
kOpt &lt;- dtParameters[accuracy == max(accuracy), k]
nOpt &lt;- dtParameters[accuracy == max(accuracy), n]</pre></div><p>The best combination is <code class="literal">k=11</code> and <code class="literal">n=33</code> and we were not able to identify it maximizing the parameters separately. The reason is that the KNN performs well with <code class="literal">k=11</code> only if we don't include all the features.</p><p>In this section, we saw a simple way to optimize two parameters. In other contexts, we need more advanced techniques.</p><p>A limit of this approach is that we tuned only two parameters. We can achieve better performances <a id="id362" class="indexterm"/>tuning other KNN parameters <a id="id363" class="indexterm"/>such as the distance method.</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec36"/>Summary</h1></div></div></div><p>In this chapter, we learned how to evaluate the performance of a model as the average accuracy of the prediction. We understood how to determine an accurate cross-validation index expressing the accuracy. Starting from the cross-validation index, we tuned the parameters. In addition, we learned how to select the features using a filter or a frapper and how to tune features and parameters at the same time. This chapter described the last part of building a machine learning solution and the next chapter shows an overview of some of the most important machine learning techniques.</p></div></body></html>