# 前言

这本书的标题暗示了其核心主题：**解释**、**机器学习**和**Python**，其中第一个主题是最关键的。

那么，为什么解释如此重要呢？

**可解释机器学习**，通常被称为**可解释人工智能**（**XAI**），包含了一系列不断增长的技术，帮助我们从模型中获取洞察力，旨在确保模型是安全、公平和可靠的——我相信这是我们所有人都对模型共同追求的目标。

随着人工智能超越传统软件甚至人类任务，机器学习模型被视为一种更高级的软件形式。虽然它们在二进制数据上运行，但它们并不典型；它们的逻辑不是由开发者明确编写的，而是从数据模式中产生的。这就是解释介入的地方，帮助我们理解这些模型，定位它们的错误，并在任何潜在的事故发生之前纠正它们。因此，解释对于在这些模型中培养信任和道德考量至关重要。值得注意的是，在不远的将来，模型训练可能会从编码转向更直观的拖放界面。在这种情况下，理解机器学习模型成为一项宝贵的技能。

目前，在数据预处理、探索、模型训练和部署过程中，仍然涉及大量的编码工作。尽管这本书中充满了Python示例，但它并不仅仅是一本与实际应用或更广泛图景脱节的编码指南。这本书的精髓在于，在**可解释机器学习**方面，优先考虑**为什么**（why）而不是**如何**（how），因为解释围绕着**为什么**这个问题。

因此，本书的大部分章节都是通过概述一个使命（即**为什么**）然后深入探讨方法论（即**如何**）来开始的。目标是使用章节中讨论的技术来实现这个使命，并强调理解结果。章节结束时，会思考从练习中获得的实际见解。

这本书的结构是渐进式的，从基础知识开始，逐步过渡到更复杂的话题。本书中使用的工具都是开源的，并且是微软、谷歌和IBM等领先研究机构的产品。尽管可解释性是一个庞大的研究领域，其中许多方面仍处于发展阶段，但这本书并不旨在涵盖所有内容。其主要目标是深入探讨一系列可解释性工具，对那些在机器学习领域工作的人来说大有裨益。

书籍的前几部分介绍了可解释性，强调了其在商业环境中的重要性，并讨论了其核心组件和挑战。接下来的部分提供了各种解释技术及其应用的详细概述，无论是用于分类、回归、表格数据、时间序列、图像还是文本。在最后一部分，读者将参与针对可解释性的模型调整和数据训练的实践练习，重点关注简化模型、解决偏差、设置约束和确保可靠性。

到本书结束时，读者将熟练使用可解释性技术来深入了解机器学习模型。

# 本书面向的对象

本书面向多样化的读者群体，包括：

+   面临解释他们创建和管理的人工智能系统功能日益增长挑战的数据专业人士，并寻求提高它们的方法。

+   致力于通过学习模型解释技术和策略来克服从公平性到鲁棒性的模型挑战的数据科学家和机器学习专业人士。

+   对机器学习有基本了解并精通Python的潜在数据科学家。

+   致力于深化他们对角色实际方面的知识，以更有效地指导他们倡议的AI伦理官员。

+   渴望将可解释的机器学习整合到他们的运营中，与公平、责任和透明度价值观保持一致的AI项目监督者和商业领袖。

# 本书涵盖的内容

*第一章*，*解释、可解释性和可解释性；以及为什么这一切都如此重要？*介绍了机器学习解释和相关概念，如可解释性、可解释性、黑盒模型和透明度，为这些术语提供定义以避免歧义。然后，我们强调了机器学习可解释性对企业的价值。

*第二章*，*可解释性的关键概念*，通过心血管疾病预测示例介绍了两个基本概念（特征重要性和决策区域）以及用于分类解释方法的最重要的分类法。我们还详细说明了哪些元素阻碍了机器学习可解释性，作为对未来的初步介绍。

*第三章*，*解释挑战*，讨论了用于机器学习解释的传统方法，这些方法用于回归和分类，并以航班延误预测问题为例。然后，我们将检查这些传统方法的局限性，并解释“白盒”模型为什么本质上可解释，以及为什么我们并不总是可以使用白盒模型。为了回答这个问题，我们考虑了预测性能和模型可解释性之间的权衡。最后，我们将发现一些新的“玻璃盒”模型，这些模型试图不在这个权衡中妥协。

*第四章*，*全局模型无关解释方法*，探讨了**部分依赖图**（**PDP**）和基于博弈论的**SHapley Additive exPlanations**（**SHAP**），使用二手车定价回归模型，然后可视化条件边际分布**累积局部效应**（**ALE**）图。

*第五章*，*局部模型无关解释方法*，涵盖了局部解释方法，解释单个或一组预测。为此，本章介绍了如何利用SHAP和**局部可解释模型无关解释**（**LIME**）通过巧克力评分示例进行局部解释，包括表格和文本数据。

*第六章*，*锚点和反事实解释*，继续讨论局部模型解释，但仅限于分类问题。我们使用再犯风险预测示例来了解我们如何以人类可解释的方式解释不公平的预测。本章涵盖了锚点、反事实和**假设-if-工具**（**WIT**）。

*第七章*，*可视化卷积神经网络*，探讨了与**卷积神经网络**（**CNN**）模型一起工作的解释方法，以垃圾分类器模型为例。一旦我们掌握了CNN如何通过激活来学习，我们将研究几种基于梯度的归因方法，如显著性图、Grad-CAM和集成梯度，以调试类别归因。最后，我们将通过基于扰动的归因方法，如特征消除、遮挡敏感性、Shapley值采样和KernelSHAP，扩展我们的归因调试知识。

*第八章*，*解释NLP Transformer*，讨论了如何在餐厅评论情感分类Transformer模型中可视化注意力机制，随后解释了集成梯度归因，并探索了**学习可解释性工具**（**LIT**）。

*第九章*，*多元预测和敏感性分析的解释方法*，使用交通预测问题和**长短期记忆**（**LSTM**）模型来展示如何使用集成梯度和SHAP来处理此类用例。最后，本章探讨了预测和不确定性是如何内在联系的，以及敏感性分析——一种旨在衡量模型输出相对于其输入的不确定性的方法。我们研究了两种方法：Morris用于因素优先级排序和Sobol用于因素固定。

*第10章*，*可解释性特征选择和工程*，通过一个具有挑战性的非营利性直接邮寄优化问题来回顾基于过滤器的特征选择方法，例如斯皮尔曼相关系数，并了解嵌入方法，例如Lasso。然后，你将发现包装方法，如顺序特征选择和混合方法，如递归特征消除，以及更高级的方法，如遗传算法。最后，尽管特征工程通常在选择之前进行，但在尘埃落定之后探索特征工程仍有其价值。

*第11章*，*偏差缓解和因果推断方法*，通过信用卡违约问题来展示利用公平性指标和可视化来检测不希望的偏差。然后，本章探讨如何通过预处理方法，如重新加权和不偏见的移除器，以及后处理的均衡机会来减少它。然后，我们测试降低信用卡违约的处理方法，并利用因果模型来确定它们的**平均处理效应**（**ATE**）和**条件平均处理效应**（**CATE**）。最后，我们测试因果假设和估计的稳健性。

*第12章*，*单调约束和模型调优以实现可解释性*，继续从*第7章*中的再犯风险预测问题。我们将学习如何在数据侧通过特征工程设置护栏，以及在模型上的单调性和交互约束，以确保公平性，同时学习在存在多个目标时如何调整模型。

*第13章*，*对抗鲁棒性*，使用面部口罩检测问题来涵盖端到端对抗解决方案。对手可以通过多种方式故意破坏模型，我们专注于规避攻击，如Carlini和Wagner无穷范数和对抗补丁，并简要解释其他形式的攻击。我们解释了两种防御方法：空间平滑预处理和对抗训练。最后，我们演示了一种鲁棒性评估方法。

*第14章*，*机器学习可解释性的未来是什么？*，总结了在机器学习可解释性方法生态系统中的所学内容。然后，对接下来可能发生的事情进行推测！

# 为了充分利用这本书

+   你需要一个带有Python 3.9+的Jupyter环境。你可以做以下任何一项：

    +   通过**Anaconda Navigator**或使用`pip`从头开始在你的机器上安装。

    +   使用基于云的，例如**Google Colaboratory**、**Kaggle Notebooks**、**Azure Notebooks**或**Amazon Sagemaker**。

+   如何开始操作的说明将相应地有所不同，所以我们强烈建议你在网上搜索设置它们的最新说明。

+   关于安装书中使用的许多包的说明，请访问GitHub仓库，其中`README.MD`文件将包含更新的说明。鉴于包经常更改，我们预计这些说明会随着时间的推移而变化。我们还使用`README.MD`中详细说明的特定版本测试了代码，因此如果后续版本有任何问题，请安装特定版本。

+   各个章节都有关于如何检查是否正确安装了正确包的说明。

+   但根据**Jupyter**的设置方式，安装包可能最好通过命令行或使用`conda`来完成，所以我们建议你根据需要调整这些安装说明。

+   如果你使用的是这本书的数字版，请自己输入代码或通过GitHub仓库（下一节中提供链接）获取代码。这样做可以帮助你避免与代码复制粘贴相关的任何潜在错误。

+   如果你不是机器学习从业者或是一个初学者，最好按顺序阅读这本书，因为许多概念仅在早期章节中进行了详细解释。对于在机器学习方面有经验但不太熟悉可解释性的从业者，可以快速浏览前三章以获取必要的伦理背景和概念定义，以便理解其余内容，但其余章节应按顺序阅读。对于有可解释性基础的资深从业者，按任何顺序阅读本书都应没问题。

+   关于代码，你可以边读边运行代码，也可以只为了理论而阅读书籍。但如果你打算运行代码，最好是以书籍为指导，帮助解释结果并加强你对理论的理解。

+   在阅读本书时，思考你可以如何使用学到的工具，希望到书的结尾，你将受到启发，将新获得的知识付诸实践！

## 下载示例代码文件

本书代码包托管在GitHub上，网址为[https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/)。如果代码有更新，它将在现有的GitHub仓库中更新。你还可以在`README.MD`文件中找到硬件和软件的要求列表。

我们还有其他来自我们丰富图书和视频目录的代码包，可在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)找到。查看它们吧！

## 下载彩色图像

我们还提供了一份包含本书中使用的截图/图表的彩色图像的PDF文件。你可以从这里下载：[https://packt.link/gbp/9781803235424](https://packt.link/gbp/9781803235424)。

## 使用的约定

本书使用了几个文本约定。

`CodeInText`：表示文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter/X用户名。例如：“接下来，让我们定义一个`device`变量，因为如果您有一个支持CUDA的GPU型号，推理将执行得更快。”

代码块设置如下：

[PRE0]

当我们希望您注意代码块中的特定部分时，相关的行或项目将以粗体显示：

[PRE1]

任何命令行输入或输出都应如下编写：

[PRE2]

**粗体**：表示新术语、重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词在文本中显示如下。例如：“已选择**预测**选项卡，此选项卡左侧有一个**数据表**，您可以在其中选择和固定单个数据点，以及一个左侧带有**分类结果**的面板。”

警告或重要提示看起来是这样的。

小贴士和技巧看起来是这样的。

# 联系我们

我们欢迎读者的反馈。

**一般反馈**：请将邮件发送至`feedback@packtpub.com`，并在邮件主题中提及书籍标题。如果您对本书的任何方面有疑问，请通过`questions@packtpub.com`与我们联系。

**勘误**：尽管我们已经尽一切努力确保内容的准确性，但错误仍然可能发生。如果您在此书中发现错误，我们将不胜感激，如果您能向我们报告此错误。请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，点击**提交勘误**，并填写表格。

**盗版**：如果您在互联网上发现我们作品的任何非法副本，如果您能提供位置地址或网站名称，我们将不胜感激。请通过`copyright@packtpub.com`与我们联系，并提供材料的链接。

**如果您有兴趣成为作者**：如果您在某个主题上具有专业知识，并且您有兴趣撰写或为书籍做出贡献，请访问[http://authors.packtpub.com](http://authors.packtpub.com)。

# 分享您的想法

一旦您阅读了《使用Python 2e进行可解释机器学习》，我们很乐意听到您的想法！请[点击此处直接访问此书的亚马逊评论页面](https://www.packtpub.com/)并分享您的反馈。

您的评论对我们和科技社区都很重要，并将帮助我们确保我们提供高质量的内容。

# 下载此书的免费PDF副本

感谢您购买此书！

您喜欢在路上阅读，但无法携带您的印刷书籍到处走？

您购买的电子书是否与您选择的设备不兼容？

不要担心，现在，每购买一本Packt书籍，您都可以免费获得该书的DRM免费PDF版本。

在任何地方、任何设备上阅读。直接从您最喜欢的技术书籍中搜索、复制和粘贴代码到您的应用程序中。

优惠不会就此结束，您还可以获得独家折扣、时事通讯和每日免费内容的每日邮箱访问权限

按照以下简单步骤获取优惠：

1.  扫描下面的二维码或访问以下链接

![](img/B18406_Free_PDF.png)

[https://packt.link/free-ebook/9781803235424](https://packt.link/free-ebook/9781803235424)

1.  提交您的购买证明

1.  就这样！我们将直接将您的免费PDF和其他优惠发送到您的邮箱
