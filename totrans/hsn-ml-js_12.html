<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Choosing the Best Algorithm for Your Application</h1>
                </header>
            
            <article>
                
<p>There are three distinct phases in the software-engineering process: conception, implementation, and deployment. This book has primarily focused on the implementation phase of the process, which is when a software engineer develops the core functionality (that is, a <strong>machine learning</strong> (<strong>ML</strong>) algorithm) and features of the project. In the last chapter, we discussed matters concerning the deployment phase. Our learning is nearly complete.</p>
<p>In this final chapter, we'll turn to the conception phase in order to round out our understanding of the full ML development process. Specifically, we'll discuss how to choose the best algorithm for a given problem. The ML ecosystem is evolving, intimidating, and full of jargon unfamiliar even to experienced software developers.<span> I often see students of ML get stuck at the beginning of the process, not knowing where to start in a vast and unfamiliar landscape. What they don't know </span><span>yet</span><span> </span><span>is that once you get past the initial hurdle of choosing an algorithm and decrypting the jargon, the rest of the journey is much easier. </span></p>
<p>The goal of this chapter is to provide a compass, a simple guide one can use to find a way around the landscape. It's not always easy to select the right algorithm, but sometimes it is. The first sections of this chapter will teach you four simple decision points—essentially four multiple-choice questions<span>—that you can use to focus in on the most suitable algorithms for your project. Most of the time, you'll end up with only one or two algorithms to choose from after going through this process.</span></p>
<p>We'll then continue our education by discussing other topics related to planning an ML system. We'll discuss the telltale signs that you've chosen the wrong algorithm so that you can identify mistakes early on. You'll also learn how to tell the difference between using the wrong algorithm versus a bad implementation of one. </p>
<p>I'll also show you an example of combining two different ML models, so that you can compose larger systems out of individual models that are best suited to their own tasks. This approach can yield great results if designed carefully. </p>
<p>I called this chapter a compass—<span>not a map—for a reason. It is not a comprehensive guide that covers every ML algorithm known to computer scientists. As with a compass, you must also use your guile and skills to find your way. Use this chapter to find your own project's starting point, and then follow up with your own research. While the 20 or so algorithms and techniques we've discussed in this book give you a pretty wide view of the landscape, they're only a fraction of the ecosystem.</span></p>
<p>As we come to the beginning of the end of this book, I'd like to give you one final piece of advice. To become an expert at something requires a consistent dedication to <em>both </em>practice and play. If you want to become a world-class pianist, you must spend countless hours doing meticulous rote practice with a metronome, practicing fingering exercises and learning challenging <em>études</em>.</p>
<p>But you also have to <em>play</em>, which is where exploration happens and creativity is developed. After thirty minutes of running drills, a pianist might spend thirty minutes improvising jazz and experimenting with melody and counterpoint, learning the <em>je ne sais quoi</em> or the emotive essence of the scales and patterns in the music. That playful exploration, the experimentation involved in creativity, develops the intuitive sense of music in a way that rote practice does not. Rote practice—meticulous work and study<span>—</span>in turn develops the mechanical sense and skill that play cannot. Practice and play elevate each other in a virtuous cycle. The skilled are able to explore farther and deeper than the unskilled, and the excitement of what lies even deeper still is what motivates the practice that develops the skill. Time and patience, practice and play, motivation and discipline are the only things you need to go from being a novice to an expert. </p>
<p>ML is the opposite of jazz piano, but the path to expertise is the same. The rote practice of ML<span>—the equivalent of practicing scales—is building and implementing algorithms. I particularly recommend writing algorithms from scratch as practice; that's the only true way to understand what's really going on inside. Don't just write an algorithm from scratch once to prove to yourself that you can. Write the algorithm several times, in different environments, different programming languages, different architectures, with different datasets, and keep doing that until you can write nearly the whole thing off the top of your head. I'm fairly certain I can write a Naive Bayes classifier blindfolded in any of three programming languages, just as you would be able to after you've written dozens of them. </span></p>
<p>The play of ML lies in experimentation. This chapter is about choosing the best algorithm for your application, but it isn't rule of law. If you never experiment you'll never develop a rich intuition for the algorithms or data. Experiment with other approaches, parameters, or variations on algorithms and learn from the experimentation. You'll be surprised at how often an experiment can end up successful, but more importantly than that, experimentation should be part of your practice and education.</p>
<p>Let's kick the chapter off by discussing the four major decision points you can use to hone your skills on an algorithm:</p>
<ul>
<li>Mode of learning</li>
<li>The task at hand</li>
<li>The format or form of the data</li>
<li>Available resources</li>
</ul>
<p>Also we'll discuss what to do when it all goes wrong, and finally we'll discuss combining multiple models together.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Mode of learning</h1>
                </header>
            
            <article>
                
<p>The first decision point to visit when choosing an ML algorithm is the mode of the learning process: supervised, unsupervised, or reinforcement learning. These modes have very little overlap; in general an algorithm is either supervised or unsupervised but not both. This narrows your choices down by roughly half, and fortunately it is very easy to tell which mode of learning applies to your problem.</p>
<p>The difference between supervised and unsupervised learning is marked by whether or not you need labeled training examples to teach the algorithm. If all you have is data points, and not labels or categories to associate them with, then you are only able to perform unsupervised learning. You must therefore choose one of the unsupervised learning algorithms, such as k-means clustering, regressions, <strong>Principal Component Analysis</strong> (<strong>PCA</strong>), or singular value decomposition. </p>
<p>Another telltale difference between supervised and unsupervised learning is whether or not there is a way to judge semantic accuracy. If the concept of judging accuracy doesn't make sense in your application (because you don't have labeled training or reference data), then you are facing an unsupervised learning problem. </p>
<p>In some cases, however, you will not have training data but the problem is best solved by a supervised learning problem. It's important to recognize the difference between having training data and <em>needing </em>training data. When you need training data, you are likely looking at a supervised learning problem. If you need training data but don't have it, you'll have to figure out some way to get the training data. </p>
<p>The simplest way to generate training data for a problem is to generate it yourself. In an image classification task you can simply label a few hundred images by hand to generate your training data. This is time consuming but will work for small training sets.</p>
<p>A more scalable approach is to use a service like Amazon Mechanical Turk, through which you pay human workers $0.05-$0.10 to label each image. The Mechanical Turk approach has become very popular with ML researchers and data scientists, as it is a fast and scalable way to generate a large volume of training data at a reasonable cost. Generating labels for 5,000 images might cost $250 and take a day or two on Mechanical Turk. If you think $250 is expensive, consider the cost of the time it would take for you to label those 5,000 images personally.</p>
<p>There are more clever ways to generate training data, such as shifting the responsibility to your application's users. Years ago, when Facebook first introduced the ability to tag people in photos, they required the photo's uploader to draw a box around each subject's face and tag them. After billions of photo uploads, Facebook has a huge training set that not just identifies facial forms but also specific people in photos. Nowadays, there is no need to draw boxes around peoples' faces when tagging photos, and typically Facebook is able to figure out who each subject in the photo is automatically. We, the users, provided them with this massive training set. </p>
<p>Supervised learning is made apparent by the act of training an algorithm on prelabeled data, with the goal of algorithm learning from the labels, and by being able to extend that knowledge and apply it to new, unseen examples. If you find yourself in a situation where you have a lot of data points and some, but not all, have the correct answers or labels available, you likely want a supervised learning algorithm. If you have a million emails, 5,000 of which were manually filtered as spam or not spam, and if the goal is to extend that knowledge to the other 995,000 messages, you're looking for a supervised learning algorithm. </p>
<p>If you have a situation where you need to judge the semantic accuracy of the algorithm, you must also use a supervised learning algorithm. An unsupervised algorithm has no source of truth; those algorithms will cluster or smooth or extrapolate data, but without a canonical reference, there is no way to judge the algorithm's accuracy. A supervised learning algorithm, on the other hand, can be judged in terms of semantic accuracy as the prelabeled training data serves as the source of truth. </p>
<p>While we haven't covered reinforcement learning algorithms in this book, they are marked by situations where the algorithm must affect its environment in an attempt to optimize behavior. There is a degree of separation between the algorithm's output and the results of the action, since the environment itself is a factor. An example of reinforcement learning is teaching an AI to play a video game by scanning the screen and using mouse and keyboard controls. An AI playing <em>Super Mario Bros.</em> can only interact with the environment by hitting combinations of up, down, left, right, A, and B on the control pad. The algorithm's output takes an action in the environment, and the environment will either reward or punish those actions. The algorithm therefore tries to maximize its reward, for instance by collecting coins, making progress through the level, defeating enemies, and not falling into bottomless pits. </p>
<p>Reinforcement learning algorithms are a major topic in applied robotics, control system design, simulation-based optimization, hardware-in-the-loop simulation, and many other fields that blend the physical world with the algorithmic world. Reinforcement learning is most effective when the system you're studying<span>—the environment—is a sophisticated black box that cannot be directly modeled. Reinforcement learning is used, for instance, to optimize control strategies for systems that will be used in arbitrary environments, such as a robot that must autonomously navigate unknown terrain. </span></p>
<p>Finally, there are tasks that require only the optimization of a system whose model is either known or directly observable. These are only tangentially considered ML problems, and are more appropriately called <strong>optimization problems</strong>. If you must choose the best driving route from Point A to Point B based on current traffic conditions, you can use a genetic algorithm, for instance. If you must optimize a small number of parameters that configure a different model, you might try a grid search. If you must determine the boundary conditions of a complex system, Monte Carlo methods might be able to help. If you must find the global optimum of a continuous system, then stochastic gradient descent might serve your purpose.</p>
<p>Optimization algorithms are often used to solve problems with ML algorithms. Indeed, the backpropagation algorithm used to train ANNs uses gradient descent as its optimizer. The parameters given to k-means or other unsupervised algorithms can be tuned automatically through grid search in order to minimize variance. We have not discussed optimization algorithms in-depth in this book, but you should be aware of them and their use cases.</p>
<p>When choosing an algorithm for your application, start with the simplest question: Do I need supervised or unsupervised learning? Determine whether you have or can generate training data; if you cannot, you are forced to use unsupervised algorithms. Ask yourself whether you need to judge the accuracy of the algorithm's output (supervised learning), or whether you are simply exploring data (unsupervised). </p>
<p>After you've identified the mode of learning, which will cut your available choices roughly in half, you can further hone in on the algorithm you need by thinking about the specific task at hand, or the goal of your research.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The task at hand</h1>
                </header>
            
            <article>
                
<p>The most effective way to partition the world of ML algorithms is to consider the task at hand, or the desired results and purpose of the algorithm. If you can identify the goal of your problem—that is, whether you need to predict continuous values based on inputs, categorize data, classify text, reduce dimensionality, and so on<span>—</span>you'll be able to reduce your choices to only a handful of algorithms. </p>
<p>For example, in cases where you need to predict a continuous output value—such as a prediction for server load at a future date<span>—</span>you will likely need a regression algorithm. There are only a handful of regression algorithms to choose from, and the other decision points in this guide will help to reduce those options further. </p>
<p>In cases where you need to inspect data and identify data points that look similar to one another, a clustering algorithm would be the most appropriate. The specific clustering algorithm you choose will depend on the other decision points, <span>such as </span>the format or form of the data, the linearity or nonlinearity of the relationships, and the resources<span> </span><span>available to you</span><span> (time, processing power, memory, and so on).</span></p>
<p>If the purpose of your algorithm is to categorize a data point with one of a dozen possible labels, you must choose from one of a handful of classification algorithms. Again, selecting the correct algorithm from the family of classification algorithms available to you will depend on the form of the data, your requirements for accuracy and any resource limitations imposed upon you. </p>
<p>One common issue novice researchers face at this stage is a lack of clarity of the actual goal of the project versus the capabilities of individual algorithms. Sometimes, the business goal of a problem is abstract and only partially defined. It is often the case in those situations that the business goal is only achievable through the use of several individual algorithms. A student of ML may have difficulty identifying the concrete technical steps that must be composed in order to achieve the goal.</p>
<p>An illustrative example is the business goal of writing an application that analyzes an image and returns a natural language description of the image's contents. For instance, when uploading a picture of a path through a park, the goal might be to return the text <em>a park bench and trash pail on a path with trees in the background</em>. It would be easy to fixate on the singular business goal of the project and assume that a single business goal maps to a single algorithm.</p>
<p>However, this example requires at least two or three ML algorithms. First, a <strong>Convolutional Neural Network</strong> (<strong>CNN</strong>) must be able to identify objects in an image. Another algorithm must then be able to determine the spatial relationships between the objects. Finally, an NLP or ML algorithm must be able to take the output of the first two algorithms and compose a natural language representation from that information.</p>
<p>The ability to understand a business goal and translate it into concrete technical steps takes time and experience to develop. You must be able to parse the business goal and work backwards in order to decompose it into individual subtasks. Once you've identified the subtasks, determining which algorithm best fits each subtask becomes a straightforward exercise in this decision-making process. We'll discuss the topic of composing algorithms shortly, but for now the important take-away is that some business goals will require multiple ML algorithms. </p>
<p>In some cases, the task at hand will narrow your choices down to just a single algorithm. Object detection in images, for instance, is best achieved by a CNN. There are, of course, many different specialized subtypes of CNNs that can perform object detection (RCNN, Fast RCNN, Mask RCNN, and so on), but in this case we are able to narrow the playing field down to just CNNs.</p>
<p>In other cases, the task at hand can be achieved with several or many algorithms, in which case you must use additional decision points in order to choose the best one for your application. Sentiment analysis, for instance, can be achieved with many algorithms. Naive Bayes classifiers, maximum entropy models, random forests, and ANNs (particularly RNNs) can all solve the sentiment analysis problem. </p>
<p>You may also be required to compose multiple algorithms in order to achieve the best accuracy for your sentiment analyzer. Therefore, the decision of which approach to use will depend not only on the task at hand, but also the form and format of the data used by the other algorithms in your composition. Not every algorithm is compatible for use in composition with all other algorithms, so the form and format decision point is effectively recursive, and you will need to apply it to each of the subtasks that you have identified in pursuit of your business goal. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Format, form, input, and output</h1>
                </header>
            
            <article>
                
<p>What I've been describing as the format and form of data encapsulates several concepts. Most superficially, the <em>format</em> of the data relates to the specific data types (for example, integers, continuous numbers/floats, text, and discrete categories) of both the input and output of the application. The <em>form</em> of the data encapsulates the relationships between the data structures and the overall shape of the problem or solution space. These factors can help you select the appropriate algorithm even when the task at hand has given you several choices for an algorithm. </p>
<p>When dealing with text (the format), for instance, you must consider how the text is treated in terms of its relationship to the problem space and the task at hand; I call this the form of the data. When filtering spam it is generally not necessary to map the relationships between individual words. When analyzing text for sentiment it may indeed be necessary to map some relationships between words (for example, to deal with negations or other language modifiers), and this will require an additional level of dimensionality. When parsing text in order to build a knowledge graph you will need to map the relationships between not only the individual words but their conceptual meanings <span>meticulously</span>, requiring an even higher level of dimensionality.</p>
<p>In these examples, the format of the data is the same—all three examples deal with text—but the form is different. The shape of the problem space is different. The spam filter has a simpler problem space with lower dimensionality and linearly separable relationships; each word is treated independently. The sentiment analyzer has a different form, requiring some additional dimensionality in the problem space in order to encode the relationships between some words, but not necessarily all relationships between all words. The knowledge graph problem requires a highly dimensional space into which the complex semantic and spacial relationships between words must be mapped. </p>
<p>In these text analysis cases, you can often ask yourself a series of simple questions that helps you narrow in on the correct algorithm: can each word be treated independently? Do we need to consider words being modified by other words (<em>like</em> versus <em>not like</em>, or <em>good</em> versus <em>very good</em>)? Do we need to maintain relationships between words separated by large distances (for example, a Wikipedia article that introduces a subject in the first paragraph but continues to refer to the subject many paragraphs later)?</p>
<p>Each relationship you keep track of adds a level of dimensionality to the problem space, so you must choose an algorithm that can work effectively in the dimensionality of the problem. Using a low-dimensionality algorithm <span>such as </span>naive Bayes on a high-dimensional problem <span>such as </span>a knowledge graph problem would not yield good results; this is akin to a person who lives their whole life in three dimensions trying to visualize the ten-dimensional space of superstring theory in physics. </p>
<p>Conversely, a highly dimensional algorithm such as a <span><strong>Long Short-Term Memory</strong> (</span><strong>LSTM</strong>) RNN can solve low-dimensional problems <span>such as </span>spam filtering, but it comes with a cost: the time and resources required to train a highly dimensional algorithm. They are incongruous with the difficulty of the problem. A Bayesian classifier can be trained on millions of documents in dozens of seconds, but an LSTM RNN might require hours of training for the same task and be slower to evaluate a data point by an order of magnitude. Even then, there is no guarantee that the LSTM RNN will outperform the Bayesian classifier in terms of accuracy. </p>
<p>You must also consider the form and dimensionality when working with numerical data. Compared to statistical analysis, time-series analysis requires an additional dimension in order to capture the ordinality of the data in addition to the value of the data. This is analogous to the difference between a bag-of-words text algorithm <span>such as N</span>aive Bayes versus one that preserves sequential ordering of text <span>such as </span>an LSTM RNN. </p>
<p>Finally, the structural format of the data might be a consideration, though formats can often be successfully converted into more amenable formats. In <a href="0f60907a-63b3-43ce-b4dd-13d9755b09d5.xhtml" target="_blank">Chapter 10</a>, <em>Natural Language Processing in Practice</em>, we discussed the Word2vec word-embedding algorithm which converts text into numerical vectors so that they can be used as the inputs to a neural network (which requires numerical inputs). Format conversion actually makes our decision-making process more difficult, as it allows us to choose from a wider array of algorithms. Using Word2vec means that we can use text as an input to algorithms that don't normally accept text, therefore giving us many more options to choose from. </p>
<p>Another common format conversion is the quantization or bucketing of continuous numerical values. For instance, a continuous numerical value ranging from 0–10 could be quantized into three buckets: small, medium, and large. This conversion allows us to use our continuous-value data in algorithms that only deal with discrete values or categories.</p>
<p>You should also consider the form and format of the output that you require from an algorithm. In a classification task the nominal output of the classifier will be a discrete label that describes the input. But not all classifiers are created equally. A decision tree classifier will yield one label as its output, whereas a Bayesian classifier will yield the probabilities of all possible labels as its output. In both cases the nominal output is a probable label, but the Bayesian classifier also returns the confidence of its guess along with a probability distribution over all possible guesses. In some tasks, the only thing you need from the algorithm is a single label; in other cases, the probability distribution is useful or even required. </p>
<p>The form of the output of an algorithm is closely related to the mathematical mechanism of the model. This means that, even without a deep understanding of the algorithm itself, you can evaluate the mathematical properties of a model by looking at the form of its output. If a classifier returns probabilities as part of its output, it is likely a probabilistic classifier that can be used for tasks where you suspect a nondeterministic approach would be more effective than a deterministic one. </p>
<p>Similarly, if an algorithm returns semantically ordered output (as opposed to unordered output), that's a clue that the algorithm itself models and remembers some form of ordering. Even if your application doesn't directly require ordered output, you might still choose this algorithm because you recognize that the form of your data contains information embedded in the ordinality of the data. If you know, on the other hand, that the ordinality of your data contains no relevant information, then an algorithm which returns ordered output (and therefore models ordinality as a dimension) may be overkill. </p>
<p>If you still have a few algorithms to choose from at this point, the last step to honing in on the best algorithm will be to consider the resources available to you and balance them against your requirements for accuracy and speed. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Available resources</h1>
                </header>
            
            <article>
                
<p>It is often the case that there is no clear winner discernible from an array of algorithm options. In a sentiment analysis problem, for instance, there are several possible approaches and it is not often clear which to take. You can choose from a Naive Bayes classifier with embedded negations, a Naive Bayes classifier using bigrams, an LSTM RNN, a maximum entropy model, and several other techniques. </p>
<p>If the format and form decision point doesn't help you here—for instance, if you have no requirement for a probabilistic classifier<span>—you can make your decision based on your available resources and performance targets. A Bayesian classifier is lightweight with quick training times, very fast evaluation times, a small memory footprint and comparatively small storage and CPU requirements.</span></p>
<p>An LSTM RNN, on the other hand, is a sophisticated model that takes a long time to train, a moderate amount of evaluation time, significant CPU/GPU requirements, especially during training, and steeper memory and storage requirements than the Bayesian classifier. </p>
<p>If no other factor gives you clear guidance on how to choose an algorithm, you can make your decision based on the resources available (CPU, GPU, memory, storage, or time) to you or your application's user. In this case, there is almost always a trade-off; more sophisticated models are typically more accurate than simple ones. This is not always true, of course, as naive Bayes classifiers consistently outperform other approaches to spam filtering; but this is because of the form and dimensionality of the spam detection problem space. </p>
<p>In some cases, the limiting factor for your application will be training or evaluation time. An application that requires evaluations in 1 ms or less may not be an appropriate use case for an ANN, whereas an application that tolerates 50 ms evaluations is much more flexible.</p>
<p>In other cases, the limiting factor or the resource available is the required accuracy of the algorithm. If you consider incorrect predictions to be a form of resource consumption, you may be able to determine a lower bound on the required accuracy of an algorithm. The world of ML is not too different from the world of high-performance sports, in that the difference between the gold medal and the bronze may only be a matter of a fraction of a second.</p>
<p>The same applies to ML algorithms: a state-of-the-art algorithm for a particular problem might have an accuracy of 94%, while a more commonplace algorithm might yield 90% accuracy. <span>If the cost of an incorrect prediction is sufficiently high, that difference of four percentage points might be the deciding factor in which algorithm you choose and how much time and energy you invest in the problem. If, on the other hand, the cost of an incorrect prediction is low, the more common algorithm might be your best choice based on the resources, time, and effort required to implement it.</span></p>
<p>If you carefully consider these four decision points—the mode of learning, the task at hand, the format and form of the data, and the resources available to you—you will often find that the best algorithm to choose stands out clearly. This will not always be the case; sometimes you will be forced to make a judgment call based on the algorithms and processes you're most comfortable with.</p>
<p>Sometimes, after choosing an algorithm, you will find that your results are unacceptable. It can be tempting to throw out your algorithm <span>immediately</span> and choose a new one, but use caution here as it's often difficult to tell the difference between a bad choice of algorithm and a bad configuration of an algorithm. You must therefore be prepared to debug your system when it all goes wrong.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">When it goes wrong</h1>
                </header>
            
            <article>
                
<p>There is a wide range of possible undesirable outcomes in ML. These can range from models that simply don't work to models that do work but use an unnecessary amount of resources in the process. Negative outcomes can be caused by many factors, such as the selection of an inappropriate algorithm, poor feature engineering, improper training techniques, insufficient preprocessing, or misinterpretation of results. </p>
<p>In the best-case scenario—that is, the best-case scenario of a negative outcome<span>—the problem will make itself apparent in the early stages of your implementation. You may find during the training and validation stage that your ANN never achieves an accuracy greater than 50%. In some cases, an ANN will quickly stabilize at a value like 25% accuracy after only a few training epochs and never improve. </span></p>
<p>Problems that make themselves obvious during training in this manner are the easiest to debug. In general, these are indications that you've selected the wrong algorithm for your problem. In the case of ANNs, which are rarely the <em>wrong </em>choice because they are so flexible, this type of plateau can indicate that you've designed the wrong network topology (too few layers or too few hidden neurons) or selected the wrong activation functions for your layers (for example, using tanh when sigmoid is more appropriate). In this case, you have made a reasonable decision to use an ANN, but have configured it incorrectly.</p>
<p>Sometimes the problem is more difficult to debug, particularly when you have not written the algorithm from first principles. In <a href="8ba34275-43c8-4d0c-a8d3-8e0dd89dd2f9.xhtml" target="_blank">Chapter 5</a>, <em>Classification Algorithms</em>, I introduced you to the random forest classifier and we found that its accuracy was unacceptably low for our example problem. Was the decision to use a random forest simply a poor decision? Or was it a reasonable decision that was hindered by the incorrect selection of parameters? In that case, the answer was <strong>neither</strong>. I was confident of my choice of using a random forest as well as my parameter selection, so I ran the same data and parameters through a random forest library in a different programming language and got results more in line with my expectations. This pointed to a third likely possibility: there must be something wrong with the specific implementation of the random forest algorithm in the library that I chose to demonstrate.</p>
<p>Unfortunately, without the confidence that experience brings, it would be easy to assume that random forest was simply a poor choice of algorithm for that problem. This is why I encourage both practice and play, theory and experimentation. Without a thorough understanding of the concepts that underlie random forests I may have been tricked into believing that the algorithm itself was to blame, and without a tendency to experiment I may never have confirmed that the algorithm and parameters were indeed appropriate.</p>
<p>When things go wrong, my advice is to return to first principles. Go back to the very beginning of your engineering design process, and consider each step in turn. Is the selection of the algorithm appropriate? Is the form and format of the data appropriate? Is the algorithm able to resolve the dimensionality of the problem space <span>sufficiently</span>? Have I trained the algorithm appropriately? Ask yourself these questions until you've identified the one that you have the least confidence in, and then start exploring and experimenting.</p>
<p>From my perspective, the worst-case scenario for ML is an algorithm that <em>fails silently</em>. These are cases where an algorithm achieves its training and validation successfully, is deployed into a real application, but generates poor results from real-world data. The algorithm has not been able to generalize its knowledge and has only memorized the training data well enough to pass validation. The silent failure occurs because the algorithm lulls you into a false sense of security by showing good accuracy during validation. You then deploy the algorithm into production, trusting its results, only to find a month or a year later that the algorithm has been grossly underperforming and making poor decisions affecting real people or processes that now need to be corrected.</p>
<p>For that reason, you must always monitor the performance of your algorithms under real-world workloads. You should periodically spot-check the algorithm's work to make sure that its real-world accuracy is comparable to what you've observed during training. If an algorithm shows 85% accuracy during training, and a production spot-check of 20 data points yields 15 correct answers (75%), that algorithm is probably working as expected. However, if you find that only 50% of real-world evaluations are correct, you should expand your audit of the algorithm and potentially retrain it based on an updated training set drawn from your more realistic data points. </p>
<p>These silent failures are often caused by over-training or poor training. Even if you have followed best practices for training and split your prelabeled data set into separate training and validation sets, it is still possible to overtrain and undergeneralize. In some cases the source data itself can be blamed. If your entire training and validation set was generated from survey results of college students, for instance, the model may not be able to accurately evaluate survey results from senior citizens. In this case, even though you have validated your model on an independent data set, the training and validation data itself is not an appropriate random sampling of real-world conditions. In real-world usage you will see a lower accuracy than the validation results, as the source data you used to train the model has been compromised by selection bias.</p>
<p>A similar thing can happen with other types of classification tasks. A sentiment analysis algorithm trained on movie reviews may not be able to generalize to restaurant reviews; the jargon and tone—the form<em> </em>of the data—may be different between those two data sources.</p>
<p>If your model is underperforming and you are truly lost as to what to do next, turn to experimentation and exploration. Test out a different algorithm with the same training set and compare results. Try generating a new training set, either one more broad or more narrow. Experiment with different tokenization techniques, different preprocessing techniques, and potentially even different implementations of the same algorithm. Search the web to see how other researchers approach similar problems, and most importantly, never give up. Frustration is part of the learning process.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Combining models</h1>
                </header>
            
            <article>
                
<p>Sometimes, in order to achieve a singular business goal, you'll need to combine multiple algorithms and models and use them in concert to solve a single problem. There are two broad approaches to achieving this: combining models in series and combining them in parallel. </p>
<p>In a series combination of models, the outputs of the first model become the inputs of the second. A very simple example of this is the Word2vec word-embedding algorithm used before a classifier ANN. The Word2vec algorithm is itself an ANN whose outputs are used as the inputs to another ANN. In this case, Word2vec and the classifier are trained separately but evaluated together, in series.</p>
<p>You can also consider a CNN to be a serial combination of models; the operation of each of the layers (convolution, max pooling, and fully connected) each has a different purpose and is essentially a separate model whose output provides the input to the next layer. In this case, however, the entire network is both evaluated and trained as a single unit. </p>
<p>Models run in parallel are often called <strong>ensembles</strong>, with the random forest being a straightforward example. In a random forest many individual decision trees are run in parallel and their outputs combined. More generally, however, there is no requirement for models run in parallel to be of the same type of algorithm. When analyzing sentiment, for instance, you can run both a bigram Naive Bayes classifier and an LSTM RNN in parallel, and use a weighted average of their outputs in order to produce more accurate results than either would return individually.</p>
<p>In some cases, you can combine models in order to better handle heterogeneous data. Let's imagine a business goal where a user should be classified into one of ten psychometric categories based on both their written content and also a number of other features derived from their profile. Perhaps the goal is to analyze a user on Twitter in order to determine which marketing vertical to place them in: <span><em>fashionista</em>, <em>weekend warrior</em>, <em>sports junkie</em>, and so on</span>. The data available to you is the text content of their tweet history, their list of friends and content interactions, and a number of derived metrics <span>such as </span>average post frequency, average Flesch-Kincaid reading ease, friends-to-followers ratio, and so on.</p>
<p>This problem is a classification task, but it is a business goal that requires multiple technical steps to achieve. Because the input data is not homogeneous, we must split the problem up into parts and solve each separately. We then combine the parts to compose an accurate and performant ML system.</p>
<p>First, we can take text content of the user's tweets and pass that through a naive Bayes classifier in order to determine which of the 10 categories the content best fits. The classifier will return a probability distribution like <em>5% fashionista, 60% sports junkie, and 25% weekend warrior</em>. This classifier alone is probably not sufficient to solve the problem; weekend warriors and sports junkies tend to write about similar topics, and the Bayesian classifier cannot tell the difference between the two because there's so much overlap.</p>
<p>Fortunately, we can combine the text classification with other signals, <span>such as </span>how often the user posts images to Twitter, how often they tweet on weekends versus weekdays, and so on. An algorithm like random forest, which can deal with heterogeneous input data, would be useful here.</p>
<p>The approach we can take is to use the 10 probabilities generated by the Bayesian classifier, combine them with another 10 features derived directly from the user's profile data, and feed the combined list of 20 features to the random forest classifier. The random forest will learn when to trust the Bayesian classifier's output and when to lean more heavily on other signals. In cases where the Bayesian classifier has difficulty discerning between sports junkies and weekend warriors, for instance, the random forest may be able to draw distinctions between the two based on the additional context. </p>
<p>Furthermore, the random forest will be able to learn when to trust the Bayesian probabilities and when not to. A random forest might learn that the Bayesian classifier is often correct when it judges <em>fashionista</em> with a 90% probability. It might similarly learn that the Bayesian classifier is unreliable when judging <em>weekend warrior</em> even at high probabilities, and that for a significant proportion of the time a weekend warrior might be mistaken for a sports junkie. </p>
<p>From an intuitive perspective, the random forest is a good algorithm to choose for this use case. Because it is based on decision trees, it is able to create decision points based on the values of specific attributes. A random forest might generate a logical structure like this: </p>
<ul>
<li>If <em>bayes_fashionista_probability</em> &gt; 85%, return <em>fashionista</em></li>
<li>If <em>bayes_weekend_warrior_probability</em> &gt; 99%, return <em>weekend warrior</em></li>
<li>If <em>bayes_weekend_warrior_probability</em> &lt; 99%, continue to:
<ul>
<li>If <em>twitter_weekend_post_frequency</em> &gt; 70%, return <em>weekend warrior</em></li>
<li>Else, if <em>bayes_sports_junkie_probability</em> &gt; 60%, return <em>sports junkie</em></li>
</ul>
</li>
</ul>
<p>In this simplified example, the random forest has learned to trust the Bayesian classifier's judgment for the <em>fashionista</em> category. However, the forest will only trust the Bayesian classifier's judgement of weekend warriors if the probability is very high. If the Bayesian classifier is less than certain about the weekend warrior classification, <span>then</span><span> </span><span>the random forest can turn to the user's frequency of tweets on the weekend as a separate signal used to discriminate between weekend warriors and sports junkies.</span></p>
<p>When designed thoughtfully, composed models like this one can be very powerful tools capable of handling many situations. This technique allows you to decompose a business goal into multiple technical goals, choose the best algorithm for each type of data or classification, and combine the results into one coherent and confident response. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Most of this book has focused on the implementation of ML algorithms used to solve specific problems. However, the implementation of an algorithm is only one part of the software-engineering design process. An engineer must also be skilled in choosing the right algorithm or system for her problem and be able to debug issues as they arise. </p>
<p>In this chapter, you learned a simple four-point decision-making process that can help you choose the best algorithm or algorithms for a specific use case. Using the process of elimination, you can progressively reduce your options by disqualifying algorithms based on each of those decision points. Most obviously, you should not use an unsupervised algorithm when you're facing a supervised learning problem. You can further eliminate options by considering the specific task at hand or business goal, considering the format and form of the input and output data or the problem space, and doing a cost-benefit analysis with regards to the resources available to you. </p>
<p>We also discussed some problems that can arise when using ML models in the real world, <span>such as </span>the insidious issue of silent failures caused by poor training practices, or the more obvious failures caused by inappropriate algorithm selection or network topology.</p>
<p>Finally, we discussed the idea of composing models <span>in</span><span> </span><span>either series or parallel, in order to leverage the particular strengths of algorithms, especially when presented with heterogeneous data. I showed an example of a random forest classifier that uses both direct signals and the outputs of a separate Bayesian classifier as its inputs; this approach helps to disambiguate confusing signals coming from the Bayesian classifier, which on its own may not be able to resolve overlapping categories accurately.</span></p>
<p>There is much more I wish I could teach you. This book has simply been an overview, a whirlwind introduction to the central concepts and algorithms of ML. Each one of the algorithms I've shown you is its own field of research that goes much deeper than what can be taught in just 10 or 20 pages. </p>
<p>I do not expect this book to solve all your ML problems, and neither should you. I hope, however, that this book has given you a solid foundation of understanding on top of which you can build your future education. In a field like ML, both esoteric and full of jargon, the biggest challenge is often knowing where to start. Hopefully the information in these pages has given you enough understanding and clarity to be able to navigate the wider world of ML on your own.</p>
<p>As you finish reading these final pages, I do not expect you to be fluent in the language of ML<span> </span><span>yet</span><span>, but hopefully you are now conversational. While you may not yet be able to design exotic ANN topologies on your own, you should at least be comfortable with the core concepts, be able to communicate with other researchers, and find your own way to resources for continued in-depth learning. You can also solve many types of problems that you may not have been able to previously, and if that is the case then I have achieved my goal.</span></p>
<p>I have one final request of you: if you do continue your ML education, particularly in the JavaScript ecosystem, please contribute back to the community. As you have seen, there are many high-quality JavaScript ML libraries and tools available today, but there are also major gaps in the ecosystem. Some algorithms and techniques simply do not <span>exist in the JavaScript world </span>yet, and I would encourage you to seek out opportunities to fill in these gaps as best as you can, whether by contributing to open source software or writing educational materials for others to use.</p>
<p>Thank you for taking the time to read this humble introduction to machine learning in JavaScript—I hope it has served you well.</p>
<p> </p>


            </article>

            
        </section>
    </body></html>