<html><head></head><body>
		<div id="_idContainer136">
			<h1 id="_idParaDest-180"><em class="italic"><a id="_idTextAnchor184"/>Chapter 12</em>: Realizing Business Value with AutoML</h1>
			<p>You have acquired a wide variety of technical skills throughout this book. You're now able to train regression, classification, and forecasting models with AutoML. You can code AutoML solutions in Python using Jupyter notebooks, you know how to navigate <strong class="bold">Azure Machine Learning</strong> <strong class="bold">Studio</strong>, and you can even integrate machine learning pipelines in <strong class="bold">Azure Data Factory</strong> (<strong class="bold">ADF</strong>). Yet, technical skills alone will not guarantee the success of your projects. In order to realize business value, you have to gain the trust and acceptance of your end users. </p>
			<p>In this chapter, you will begin by learning how to present end-to-end architectures in a way that makes it easy for end users to understand. Then, you will learn which visualizations and metrics to use to show off your model's performance, after which you will learn how to visualize and interpret AutoML's built-in explainability function. </p>
			<p>You will also explore options to run AutoML outside of <strong class="bold">Azure Machine Learning Service (AMLS)</strong> and end the chapter with a section on gaining end user trust by aligning your message with the type of solution you are providing.</p>
			<p>By the end of this chapter, you will be primed for success. You will have gained some of the soft skills necessary to communicate your solution to end users, increasing the likelihood that your end-to-end solution is adopted and used by your organization. Failing to gain end user trust is a major reason why data science projects fail, and by following the guidelines in this chapter, you will be much more successful at creating excitement for your solution. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Architecting AutoML solutions</li>
				<li>Visualizing AutoML modeling results</li>
				<li>Explaining AutoML results to your business</li>
				<li>Using AutoML in other Microsoft products</li>
				<li>Realizing business value</li>
			</ul>
			<h1 id="_idParaDest-181"><a id="_idTextAnchor185"/>Technical requirements</h1>
			<p>In this chapter, you will use models that you created in previous chapters to retrieve graphs, charts, and metrics. As such, you will need a working internet connection, an Azure account, and an AMLS workspace. You will also need to complete the exercises in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>, and <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a><em class="italic">, Building an AutoML Classification Solution</em>.</p>
			<p>The following are the prerequisites for the chapter:</p>
			<ul>
				<li>Access to the internet.</li>
				<li>A web browser, preferably Google Chrome or Microsoft Edge Chromium.</li>
				<li>A Microsoft Azure account.</li>
				<li>An AMLS workspace.</li>
				<li>You need to have trained and registered the <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong> machine learning model in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>.</li>
				<li>You need to have trained and registered the <strong class="source-inline">Iris-Multi-Classification</strong> machine learning model in <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a><em class="italic">, Building an AutoML Classification Solution</em>.</li>
			</ul>
			<p>There is no new code for this chapter.</p>
			<h1 id="_idParaDest-182"><a id="_idTextAnchor186"/>Architecting AutoML solutions</h1>
			<p><strong class="bold">Architecting AutoML</strong> solutions <a id="_idIndexMarker789"/>refers to drawing end-to-end diagrams. These act as blueprints for how you should build out<a id="_idIndexMarker790"/> your solution, and also can be used to explain to your end users how everything works. While many IT solutions are complex and can take many forms, AutoML-based solutions follow standard patterns that require you to make a few important decisions.</p>
			<p>In this section, you'll first learn what decisions to make before architecting a decision. Then, you will learn how to architect an end-to-end batch scoring solution and an end-to-end real-time <a id="_idIndexMarker791"/>scoring solution that's easy to explain to end users. Although the architecture may be simplified, the more standard it is, the easier it is to implement, explain, and understand.</p>
			<h2 id="_idParaDest-183"><a id="_idTextAnchor187"/>Making key architectural decisions for AutoML solutions</h2>
			<p>When drawing an<a id="_idIndexMarker792"/> architectural diagram, there are several key considerations you need to make, the most important being whether you need to make a batch or real-time solution. Batch solutions have very different requirements than real-time solutions and mostly follow a template involving AMLS and ADF. Real-time solutions, on the other hand, are more customizable.  </p>
			<p>First, we'll examine key questions to ask for batch solutions as they're easier to understand. You only need to worry about where your data comes from, how often your solution should score new data, when should you retrain models, and how your end users will receive results. That's it. </p>
			<p>There is also the question of how you<a id="_idIndexMarker793"/> should orchestrate your various <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) pipelines as you schedule them in either AMLS or ADF. ADF is generally the best choice since you can use it to move data in and out of Azure easily. The following table provides a summary of key questions and answers for architecting a batch solution:  </p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="image/Table_12.1_B16595.jpg" alt="Figure 12.1 – Key considerations for batch solutions  "/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.1 – Key considerations for batch solutions </p>
			<p>Real-time <a id="_idIndexMarker794"/>solutions, on the other hand, are much more complicated. You still have to ask where your input data is coming from and how often you should retrain your AutoML model. Additionally, you should figure out where your endpoint will score data. This can be exceptionally complicated, as you use your endpoint nearly anywhere. Most commonly, this will be some sort of web application or serverless piece of code. </p>
			<p>Lastly, you need to figure out how many requests will your endpoint have to serve at once, how fast of a response your end users require, and what size your <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>) cluster <a id="_idIndexMarker795"/>should be to accommodate demand for your solution. The following table provides a summary of key questions and answers for architecting a real-time solution:</p>
			<div>
				<div id="_idContainer126" class="IMG---Figure">
					<img src="image/Table_12.2_B16595.jpg" alt="Figure 12.2 – Key considerations for real-time solutions  "/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.2 – Key considerations for real-time solutions </p>
			<p>Once you've asked and answered these questions, you're ready to start building out an architectural diagram. First, you'll learn a common pattern for batch solutions. </p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor188"/>Architecting a batch solution</h2>
			<p>AutoML <a id="_idIndexMarker796"/>batch solutions are fairly easy to build once you have answered where your input data is coming from and where you will land your results. They always follow roughly the same pattern. First, you will ingest data from both on-premises and cloud sources through ADF and land the <a id="_idIndexMarker797"/>data in an <strong class="bold">Azure Data Lake Storage Gen 2 (ADLS Gen 2)</strong> storage account. This makes your data accessible to AMLS.</p>
			<p>Once it's in the data lake, you use AutoML in AMLS to train and register an ML model. Your next step is to take that model and use it to create both a scoring pipeline and a training pipeline. You then orchestrate both ML pipelines through ADF, deciding on one schedule for your scoring pipeline and another schedule for your training pipeline.</p>
			<p>Training pipelines automatically register a new version of your model in AMLS, but you need to decide where to land the final output of your scoring pipeline. Natively, scoring pipelines are designed to land data in ADLS Gen 2. Once it's there, you should set up an ADF copy activity to move data from the data lake to its final destination. The full end-to-end architecture is presented in the following diagram:</p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="image/Figure_12.1_B16595.jpg" alt="Figure 12.3– Common batch architecture "/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.3– Common batch architecture</p>
			<p>Make similar diagrams for every batch AutoML solution you make, and reuse them as often as needed. Following a <a id="_idIndexMarker798"/>template architecture will make you and your team more productive over time. </p>
			<p>Next, you'll learn a common architecture for real-time solutions. Take careful note of the similarities and differences. While the beginning is identical to batch architecture, the end is quite different.</p>
			<h2 id="_idParaDest-185"><a id="_idTextAnchor189"/>Architecting a real-time solution</h2>
			<p>Real-time solution architectures <a id="_idIndexMarker799"/>require more careful consideration. How will your end users interact with your endpoint, if at all? Are you designing a web app where users score data whenever they want? Do you have a streaming system sending thousands of signals into your endpoint at once? Once you have these questions answered, you can fully flesh out the architecture.</p>
			<p>As for batch solutions, the first step involves ingesting data with ADF into ADLS Gen 2 and training and registering AutoML models using AMLS. That part is identical. Once your model is trained, you need to create a real-time scoring endpoint and an ML training pipeline. You'll schedule the retraining in ADF as usual to update your model on some sort of cadence.</p>
			<p>You also need to decide where your endpoint will live. In this architecture, it sits on a user-facing web application. Users can pass data into the web app at any time during the day, at which point the results will be displayed on the screen and also immediately sent to ADLS Gen 2. The following diagram displays the full end-to-end architecture:</p>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/Figure_12.2_B16595.jpg" alt="Figure 12.4 – Common real-time architecture "/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.4 – Common real-time architecture</p>
			<p>Presenting architectures to<a id="_idIndexMarker800"/> your end users is a key part of gaining acceptance for your solution. End users need to understand, in a general way, how everything connects and works. After presenting your architecture, you should then focus on presenting the results of your AutoML model. Teaching users how all the pieces fit together is just an introduction. Displaying your model's results in a way that end users can understand will go a long way in getting them to champion your solution. </p>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor190"/>Visualizing AutoML modeling results</h1>
			<p>Presenting the results of your <a id="_idIndexMarker801"/>AutoML model to your business is integral to the adoption of your solution. After all, your end users are unlikely to adopt your solution unless they can be sure that it meets certain standards of performance. There are many ways of presenting the results of ML models; the most effective way of presenting your results is through visualizations. </p>
			<p>Thankfully, AutoML runs provide automatic visualizations for results of regression, classification, and forecasting. Regression and forecasting share identical visualizations, while classification is quite different. In each case, you only want to share a single visualization with your end user; multiple views of the same results are likely to only cause confusion. </p>
			<p>In this section, you'll first uncover what to show your end user for classification before moving onto regression and forecasting.</p>
			<h2 id="_idParaDest-187"><a id="_idTextAnchor191"/>Visualizing the results of classification</h2>
			<p>Confusion matrices, as <a id="_idIndexMarker802"/>shown in <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a><em class="italic">, Building an AutoML Classification Solution</em>, are the key to presenting results from AutoML classification training runs. Ultimately, what end users usually care about is how accurate your model is, and whether there is a tendency toward false positives or false negatives. In order to get this information, follow these steps:</p>
			<ol>
				<li>Navigate to AML studio at <a href="https://ml.azure.com">https://ml.azure.com</a>. </li>
				<li>Click <strong class="bold">Experiments</strong> under <strong class="bold">Assets</strong> on the left-hand panel. </li>
				<li>Click the blue link to <strong class="source-inline">Iris-Multi-Classification</strong>. This is the experiment you used to train a classification model in <a href="B16595_05_ePub.xhtml#_idTextAnchor068"><em class="italic">Chapter 5</em></a><em class="italic">, Building an AutoML Classification Solution</em>.</li>
				<li>Click the blue link to your latest run. This link is found under <strong class="bold">Run ID</strong> and begins with <strong class="source-inline">AutoML_</strong> followed by a unique identifier string. If there are multiple runs, use your latest.</li>
				<li>Click <strong class="bold">Models</strong> near<a id="_idIndexMarker803"/> the top of your screen.</li>
				<li>Click the blue link to the name of your highest-performing model under <strong class="bold">Algorithm name</strong>. It is likely either <strong class="bold">StackEnsemble</strong> or <strong class="bold">VotingEnsemble</strong>. You will know it's your highest-performing model because it will be the only one with the <strong class="bold">View explanation</strong> link. </li>
				<li>Click <strong class="bold">Metrics</strong> near the top of your screen.</li>
				<li>Check the boxes for <strong class="bold">accuracy</strong> and <strong class="bold">confusion_matrix</strong>.</li>
				<li>On the confusion matrix, click the drop-down box and select <strong class="bold">Normalized</strong>. You should see a chart similar to the one in the following figure: </li>
			</ol>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="image/Figure_12.3_B16595.jpg" alt="Figure 12.5 – Classification results for your business users "/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.5 – Classification results for your business users</p>
			<p>This chart contains all of <a id="_idIndexMarker804"/>the information your end users are looking for. First, the model is 98.7% accurate. Next, it always identifies <em class="italic">Iris-setosa</em> and <em class="italic">Iris-virginica</em> correctly. Lastly, there's a 4% chance that your model will incorrectly identify an <em class="italic">Iris-versicolor</em> as an <em class="italic">Iris-virginica</em>. </p>
			<p>Keep it at that level of detail when explaining your results to your business users. Explain that this was based on training data, and you expect that the results may be a little worse when applied to data that the model has never seen before.</p>
			<p class="callout-heading">Important tip</p>
			<p class="callout">The larger the sample size and the more representative your sample data is of the real world, the more applicable your training results will be to scoring new data points. This is one reason why it's always important to collect as much good data as you can and to make sure that your data is free from sampling bias. </p>
			<p>Most commonly, this chart <a id="_idIndexMarker805"/>will satisfy most of your end users' questions about your model's performance. Since the AutoML-generated graph can be difficult to read, one thing you can do to improve it is recreate this graph in another tool such as PowerPoint. Regression and forecasting also have one chart that is quite powerful for presenting results. </p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor192"/>Visualizing the results of forecasting and regression</h2>
			<p>The predicted versus<a id="_idIndexMarker806"/> true graph, first introduced in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>, is key to presenting the results of both problem types. This graph shows the performance of your model over a range of scores. It's a little bit more difficult to explain than the confusion matrix, however, and requires you to carefully explain it to your end users. To access it, follow these steps:</p>
			<ol>
				<li value="1"> Navigate to AML studio at <a href="https://ml.azure.com">https://ml.azure.com</a>. </li>
				<li>Click <strong class="bold">Experiments</strong> under <strong class="bold">Assets</strong> on the left-hand panel. </li>
				<li>Click the blue link to open <strong class="source-inline">Diabetes-Sample Regression</strong>. This is the experiment you used to train a regression model in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>.</li>
				<li>Click the blue link to open your latest run. This link is found under <strong class="bold">Run ID</strong> and begins with <strong class="source-inline">AutoML_</strong> followed by a unique identifier string. If there are multiple runs, use your latest run.</li>
				<li>Click <strong class="bold">Models</strong> near the top of your screen.</li>
				<li>Click the blue link to open the name of your highest-performing model under <strong class="bold">Algorithm name</strong>. It is likely either <strong class="bold">StackEnsemble</strong> or <strong class="bold">VotingEnsemble</strong>. You will know it's your highest-performing model because it will be the only one with the <strong class="bold">View explanation</strong> link. </li>
				<li>Click <strong class="bold">Metrics</strong> near the top of your screen.</li>
				<li>Check the<a id="_idIndexMarker807"/> boxes for <strong class="bold">mean_absolute_percentage error</strong> and <strong class="bold">predicted_true</strong>. You should see a chart similar to the one in the following figure:</li>
			</ol>
			<div>
				<div id="_idContainer130" class="IMG---Figure">
					<img src="image/Figure_12.4_B16595.jpg" alt="Figure 12.6 – Regression/forecasting results for your business end users "/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.6 – Regression/forecasting results for your business end users</p>
			<p><strong class="bold">Mean absolute percentage error</strong> (<strong class="bold">MAPE</strong>) is usually<a id="_idIndexMarker808"/> the best regression metric to use with business errors. In this case, it shows that your AutoML model is usually 39.4% off, not especially impressive compared to your near-perfect Iris model. Business people tend to find MAPE to be the easiest metric to understand, as it doesn't require a background in statistics or a deep understanding of standard deviation or variance.</p>
			<p>The predicted versus true graph shows how well your model performs at predicting scores across a range of values. Ideally, you want your blue line (<strong class="bold">Average Predicted Value</strong>) to match your green line (<strong class="bold">Ideal</strong>). At the very least, you want most of your green line (<strong class="bold">Ideal</strong>) to fall within the shaded boundaries around the blue line (<strong class="bold">Average Predicted Value</strong>). </p>
			<p>You want to<a id="_idIndexMarker809"/> explain that for scores of 74.4 to around 250, your model does a pretty good job of predicting the true score. Outside of that range, your model performs worse, tending to overpredict true scores beneath 74.4 and underpredict scores above 250. Use the following histogram to point out how the training data was distributed. Perhaps collecting more sample data points at the higher end and lower end of the spectrum will improve your model.</p>
			<p>Occasionally, someone with a background in statistics may be among your end users. If this is the case, you also want to show them the residuals graph that you can obtain by checking the <strong class="bold">Residuals</strong> box. They will want to know if your model shows evidence of bias, and by showing a bell-shaped residuals histogram as shown in the following figure, you can put their minds at ease:</p>
			<div>
				<div id="_idContainer131" class="IMG---Figure">
					<img src="image/Figure_12.5_B16595.jpg" alt="Figure 12.7 – Residuals histogram for regression and forecasting "/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.7 – Residuals histogram for regression and forecasting</p>
			<p>Forecasting is <a id="_idIndexMarker810"/>identical to regression in terms of presenting results; they use identical graphs. By showing the right visualization to your end users, you can assuage them of any concerns they have about performance. However, they usually ask a follow-up question. <em class="italic">How does your model actually work?</em> To answer that question, you need to use AutoML's built-in explainability features.</p>
			<h1 id="_idParaDest-189"><a id="_idTextAnchor193"/>Explaining AutoML results to your business</h1>
			<p>To realize <a id="_idIndexMarker811"/>business value, your AutoML models must be implemented and used by the business. A common obstacle to implementation is a lack of trust stemming from a lack of understanding of how ML works. At the same time, explaining the ins and outs of how individual ML algorithms work is a poor way to gain trust. Throwing math symbols and complicated statistics at end users will not work unless they already have a deep background in mathematics. </p>
			<p>Instead, use AutoML's inbuilt explainability. As long as you enable explainability when training models, you can say exactly which features AutoML is using to generate predictions. In general, it's a good practice to do the following four things:</p>
			<ul>
				<li>Always<a id="_idIndexMarker812"/> enable explainability when training any AutoML model.</li>
				<li>When presenting results to the business, first show performance, then show explainability.</li>
				<li>Rank the features in order of most to least important.</li>
				<li>Drop any unimportant features from future training runs.</li>
			</ul>
			<p>Simpler models are easier to understand and lead to faster acceptance among end users. For this reason, you should always emphasize which features the model is using to train. </p>
			<p>In order to access explainability, use the following steps:</p>
			<ol>
				<li value="1">Navigate to AML studio at <a href="https://ml.azure.com">https://ml.azure.com</a>. </li>
				<li>Click <strong class="bold">Experiments</strong> under <strong class="bold">Assets</strong> on the left-hand panel. </li>
				<li>Click the blue link to open <strong class="source-inline">Diabetes-Sample Regression</strong>. This is the experiment you used to train a regression model in <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a><em class="italic">, Building an AutoML Regression Solution</em>.</li>
				<li>Click the blue link to open your latest run. This link is found under <strong class="bold">Run ID</strong> and begins with <strong class="source-inline">AutoML_</strong> followed by a unique identifier string. If there are multiple runs, use your latest.</li>
				<li>Click <strong class="bold">Models</strong> near the top of your screen.</li>
				<li>Click <strong class="bold">View explanation</strong>.</li>
				<li>Click the first ID number under <strong class="bold">Explanation ID</strong>. These are explanations for your raw features that AutoML used to train your model.</li>
				<li>Click <strong class="bold">Aggregate feature importance</strong> to see which raw features were most important in training your AutoML model.</li>
				<li>Use the scroller<a id="_idIndexMarker813"/> to see the top 10 features used to train your model as in the following figure:</li>
			</ol>
			<div>
				<div id="_idContainer132" class="IMG---Figure">
					<img src="image/Figure_12.6_B16595.jpg" alt="Figure 12.8 – Explainability visualization "/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.8 – Explainability visualization</p>
			<p>This visualization shows that the two most important features used to train the <strong class="source-inline">Diabetes-AllData-Regression-AutoML</strong> model were <strong class="source-inline">S5</strong> and <strong class="source-inline">BMI</strong>. Blood pressure (<strong class="source-inline">BP</strong>), <strong class="source-inline">S3</strong>, and <strong class="source-inline">SEX</strong> were also important, but not nearly as much as <strong class="source-inline">S5</strong> and <strong class="source-inline">BMI</strong>. To train the model, <strong class="source-inline">S5</strong> and <strong class="source-inline">BMI</strong> were both nearly 5 times as important as <strong class="source-inline">SEX</strong>. The remaining five features, <strong class="source-inline">S2</strong>, <strong class="source-inline">S6</strong>, <strong class="source-inline">S1</strong>, <strong class="source-inline">AGE</strong>, and <strong class="source-inline">S4</strong>, were only minor contributors to your ML model; the model didn't find them important.</p>
			<p class="callout-heading">Important tip</p>
			<p class="callout">It's very likely that your business partners will try to infer causation from this graph. It's important to keep in mind that, without controlled scientific experimentation, explainability within any ML models can only show correlation, not causation.</p>
			<p>Present <a id="_idIndexMarker814"/>this chart to your end users to gain their trust; it's easy to understand and shows them exactly which features are being used by AutoML to make predictions. Not only can you show them which features are being used, but you can also show them the relative importance of each of the columns of your dataset. Use this chart to tell a story that's engaging and makes sense; you can even begin by showing this chart to your business audience and asking them for their interpretations. Let them tell the story and make the solution on their own. </p>
			<p>It's best to show explainability slides after you have explained architecture and performance. Architecture explains how the solution works in an end-to-end format without diving too deep into technical details. Performance gives your users confidence in how accurate they can expect the model to be at any given time. Logically, your users will then inquire as to how your AutoML model is making predictions. This is where you show the explainability chart instead of making the mistake of diving deep into statistics and algorithms.  </p>
			<p>Having covered architecture, performance visualizations, and explainability, you now have all of the tools you need to gain the trust and acceptance of your end users. The next section is going to expand upon the various places you can use AutoML to expand the breadth of solutions that you can develop. Even when using AutoML outside of AMLS, keep in mind to always use explainability.</p>
			<h1 id="_idParaDest-190"><a id="_idTextAnchor194"/>Using AutoML in other Microsoft products</h1>
			<p>In this book, you've<a id="_idIndexMarker815"/> learned how to use AutoML on Azure, but you<a id="_idIndexMarker816"/> can also use AutoML in a wider suite of Microsoft products. While you can easily create and productionalize just about any AutoML solution following the architectural patterns in the <em class="italic">Architecting AutoML solutions</em> section of this chapter, there are certain scenarios in which you may want to use AutoML on other Microsoft platforms. You can find AutoML in the following places:</p>
			<ul>
				<li>PowerBI</li>
				<li>Azure Synapse Analytics</li>
				<li>ML.NET</li>
				<li>HDInsight</li>
				<li>SQL Server</li>
				<li>Azure Databricks</li>
			</ul>
			<p>Even though <a id="_idIndexMarker817"/>AutoML is available for these services, there are <a id="_idIndexMarker818"/>many differences of which you should be aware. Some services are code-free while others are code-only. Some services preclude you from training forecasting algorithms and others are based on entirely different ML frameworks. In this section, you will be guided through the general capabilities service by service. </p>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor195"/>Using AutoML within PowerBI</h2>
			<p><strong class="bold">PowerBI</strong> is Microsoft's<a id="_idIndexMarker819"/> business analytics solution that lets users<a id="_idIndexMarker820"/> visualize data to gain rapid insights. It's one of the most popular and powerful dashboarding tools on the market, and both the <em class="italic">Power BI Premium</em> and <em class="italic">Power BI Embedded</em> licenses of the software allow you to use AutoML directly with the tool. This is a no-code version of AutoML that works similarly to the AutoML GUI you can find in AML studio, as seen in <em class="italic">Figure 12.7</em>:</p>
			<div>
				<div id="_idContainer133" class="IMG---Figure">
					<img src="image/Figure_12.7_B16595.jpg" alt="Figure 12.9 – AutoML in PowerBI"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.9 – AutoML in PowerBI  </p>
			<p>In this case, AutoML is<a id="_idIndexMarker821"/> integrated with <strong class="bold">PowerBI dataflows</strong>, a <a id="_idIndexMarker822"/>self-service data<a id="_idIndexMarker823"/> preparation tool. As with AutoML on Azure, you can use it to train models, save (register) models, and use models to make predictions that can be saved as new columns in your data. Unlike AutoML on Azure, it only supports regression and classification problems, not forecasting. Another feature that both services have in common is model explainability.</p>
			<p>If you're a data analyst who regularly builds data visualization dashboards, AutoML on PowerBI is a great tool to add to your repertoire. You can easily add predictions into your data directly and visualize them with little effort. AutoML on PowerBI is also great for one-off ML jobs. Azure Synapse Analytics is another common service where data analysts use AutoML.</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor196"/>Using AutoML within Azure Synapse Analytics</h2>
			<p><strong class="bold">Azure Synapse Analytics</strong> (<strong class="bold">ASA</strong>) is Azure's premier data analytics service. It features an SQL data warehouse for big data, Spark-based analytics, and ADF-style ETL pipelines, all in one place. If you have an AMLS workspace and link<a id="_idIndexMarker824"/> it to ASA using a linked service similar to ADF, you can also use Azure AutoML directly within Synapse. </p>
			<p>In order to use AutoML, you will need to have a Spark cluster and create Spark tables from your data. <strong class="bold">Spark</strong> is an <a id="_idIndexMarker825"/>open source analytics engine used to quickly process big data through distributing workloads across a cluster of virtual machines. With ASA, you can code Spark solutions with either PySpark (a version of Python), C#, Spark SQL, or Scala. Spark tables are simply data tables made within this framework.</p>
			<p>Once you have a Spark table, all you need to do is right-click it, click <strong class="bold">Machine Learning</strong>, and then click <strong class="bold">Enrich with new model</strong>. You'll then be greeted by a very familiar interface: the AutoML GUI you first used in <a href="B16595_03_ePub.xhtml#_idTextAnchor044"><em class="italic">Chapter 3</em></a><em class="italic">, Training Your First AutoML Model</em>. Since ASA directly uses your AMLS workspace to train models using AutoML, the capabilities and user experience are identical. You can also code an AutoML solution using PySpark within ASA. </p>
			<p>It's best to think of Synapse's AutoML capability as a shortcut rather than a separate experience from AMLS. Use it whenever you're already working within ASA and would like to quickly train an ML model using data inside an ASA data warehouse.</p>
			<h2 id="_idParaDest-193"><a id="_idTextAnchor197"/>Using AutoML with ML.NET</h2>
			<p><strong class="bold">.NET Framework</strong> is <a id="_idIndexMarker826"/>a software development framework that lets you build applications in C#, F#, and<a id="_idIndexMarker827"/> Visual Basic. <strong class="bold">ML.NET</strong> lets you add ML capabilities to .NET <a id="_idIndexMarker828"/>Framework and AutoML is one of its many capabilities. You can code ML.NET solutions into your application or use the <strong class="bold">ML.NET Model Builder</strong> to<a id="_idIndexMarker829"/> create AutoML solutions through a guided user interface.</p>
			<p>One interesting aspect of the ML.NET Model Builder is that you can use AutoML for a variety of predefined scenarios, including regression, classification, image classification, text classification, and object detection. You are thus not limited to only tabular data but can use automated ML with images too.</p>
			<p>Try using AutoML within ML.NET if you are building a .NET application and would like to easily add ML to it. This is the most appropriate use case, and it assumes that you have a great deal of experience developing within  .NET Framework. If you are not a .NET developer, you're better off developing your AutoML solutions within AMLS workspaces.</p>
			<h2 id="_idParaDest-194"><a id="_idTextAnchor198"/>Using AutoML on SQL Server, HDInsight, and Azure Databricks</h2>
			<p>AutoML<a id="_idIndexMarker830"/> is also <a id="_idIndexMarker831"/>available on<a id="_idIndexMarker832"/> a variety of <a id="_idIndexMarker833"/>other services, including <strong class="bold">SQL Server</strong>, <strong class="bold">HDInsight</strong>, and <strong class="bold">Azure Databricks</strong>. SQL Server is Microsoft's<a id="_idIndexMarker834"/> well-known <strong class="bold">relational database management system</strong> (<strong class="bold">RDBMS</strong>), whereas<a id="_idIndexMarker835"/> HDInsight is Azure's version of Hadoop for processing <a id="_idIndexMarker836"/>big data. Azure Databricks is the premier cloud-based Spark tool on Azure for big data processing and analytics. All three of the services can make use of Azure AutoML through Python.</p>
			<p>When working with these tools, you will first need to create an AMLS workspace, install the AzureML-SDK, and connect your AMLS workspace to the other service. Then, you will need to code a solution. With HDInsight and Databricks, you will use Spark, whereas in SQL Server you will need to use a <strong class="source-inline">sp_execute_external_script</strong> stored procedure to run Python code. <strong class="bold">Stored procedures</strong> are<a id="_idIndexMarker837"/> reusable bits of SQL code that you can save and repeatedly use.</p>
			<p>An important difference between these three services and ASA, PowerBI, and ML.NET is that there is no guided user interface option for AutoML. You must create solutions with code. If you are already building an application or data pipeline in SQL Server, HDInsight, or Azure Databricks and would like to include AutoML as part of that solution, feel free to do model training within those services. </p>
			<p>Another use case for Azure Databricks specifically is when you would like to train an AutoML model with very large data (100 GB dataframes); it's then appropriate to run AutoML using the Spark distributed framework.  </p>
			<p>Now that you're familiar with the many different tools in which AutoML is available, you will have a lot more flexibility in building AutoML solutions. Just because you've built a solution, however, doesn't mean that people will use it. To conclude this chapter and the book, the last section will focus on strategies and techniques to gain end user acceptance, the key to realizing business value.  </p>
			<h1 id="_idParaDest-195"><a id="_idTextAnchor199"/>Realizing business value</h1>
			<p>Realizing business value<a id="_idIndexMarker838"/> ultimately comes down to whether your business partners choose to act on the predictions of your ML models. Without action, the work of data scientists amounts to little more than a science experiment. Your business partners must be motivated and willing to make your predictions a part of their decision-making process. Gaining their trust is paramount. </p>
			<p>In order to gain the trust of your company's decision-making leadership, you first have to ascertain what kind of solution you are building with AutoML. Some solutions are rather easily and rapidly adopted, while others are likely to encounter hard resistance. </p>
			<p>There are key two factors that determine how readily your AutoML solution is accepted: whether your tool is replacing an existing solution and whether your tool is directly involved in an automated decision process or is assisting human decision makers. <em class="italic">Figure 12.8</em> shows how difficult it is to gain acceptance based on these factors:</p>
			<div>
				<div id="_idContainer134" class="IMG---Figure">
					<img src="image/Figure_12.8_B16595.jpg" alt="Figure 12.10– Difficulty of gaining traction with business users based on key factors"/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.10– Difficulty of gaining traction with business users based on key factors</p>
			<p>The more <a id="_idIndexMarker839"/>automated your solution is, the easier it is to gain acceptance. Processes that run under the hood, after all, are not subject to human supervision. There is no human manually deciding whether each credit card transaction is fraudulent; this task can only be accomplished by automated processes. </p>
			<p>Since there's no human in the loop in the first place, you're not going to encounter resistance when trying to improve automated processes with ML models. In contrast, when you try to augment a human decision maker with AI-generated predictions, you are likely to encounter skepticism and resistance.</p>
			<p>Likewise, entirely new solutions are much more easily accepted than tools that replace old solutions. While this is also true for replacing existing automated systems with AI solutions, this is even truer when you are trying to replace existing systems that executives and managers use to make decisions. Many people are slow to embrace change, especially change that they don't fully understand. </p>
			<p>In this section, we'll introduce strategies to gain trust and get business users to adopt your AutoML-based solution based on the key factors.</p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor200"/>Getting the business to adopt a new, automated solution </h2>
			<p>This is easy. Imagine<a id="_idIndexMarker840"/> your company is building a new sales portal and they want to create a system that automatically generates product recommendations for online shoppers as they browse items on your website. You propose to build a recommendation system training an ML model using AutoML and scoring the model using a real-time scoring endpoint hosted on AKS. </p>
			<p>Very likely, the response to your proposal will be overwhelmingly positive. Your executive leadership will be impressed by your adoption of cutting-edge AI technology. Business management in charge of the project will be happy just to have a high-performing solution. Your IT department will be interested in learning the new technology and will be more than happy to help you implement a new, high-profile project.</p>
			<p>If there's any resistance at all, it will be from people who will want to get a better understanding of how your AI solution works. For this reason, it's recommended that you provide model explanations along with a general overview of how ML works and how AutoML works. People are more likely to support your project if they can explain how it works to other people, so work at developing that understanding. </p>
			<h2 id="_idParaDest-197"><a id="_idTextAnchor201"/>Getting the business to replace an older, automated process</h2>
			<p>Replacing an older automated solution with one driven by ML is a bit more difficult than creating an entirely new process. This is usually because business users already understand how the old process works. If you are trying to replace a rules-based system, based on a series of if-then statements, this is even more difficult because the old process was easier for a human being to understand.</p>
			<p>In this case, your best strategy is to compare the results of your new AutoML-based solution with the results of the old solution side by side for weeks or months. Do not immediately shut down the old process; you should run both processes simultaneously until your end users are convinced and have faith in the output of your ML model. Only then should you turn off and permanently shut down the old solution.</p>
			<p>You may think that <a id="_idIndexMarker841"/>explaining how ML and AutoML works would be your best strategy here, but end users used to one system mistakenly assume that AI works similarly to the old solution. Dispelling this notion can be difficult and the extreme difference in approach may make some users lose trust. For this reason, it's best to orient your end users to results first before providing them with deep, detailed explanations. Once they trust your results, they will naturally open up to the process.</p>
			<h2 id="_idParaDest-198"><a id="_idTextAnchor202"/>Getting the business to adopt a new, decision-assistance tool</h2>
			<p>One key thing to realize when providing AI-generated recommendations or predictions to a group of decision makers is that, for the problem at hand, they've been making decisions for years. They may not yet have a tool, but they do have their gut intuition and years of experience. Thus, they're often skeptical of any new tool or technology that proclaims it will help them in their job. Remember that no one ever rose to the top of a company by making bad decisions.</p>
			<p>In this case, it's best to try to assuage their fears by assuring them that this is just a tool to provide them with predictions or recommendations. It's advice. It may be AI-generated, but at the end of the day, advice is advice, and the decision ultimately still rests in their hands. </p>
			<p>One analogy that's useful is that, in the world of chess, AI may beat grandmasters, but grandmasters assisted by AI can beat AI. Humans ultimately remain in control.</p>
			<p>You should also stress the statistical nature of ML-generated predictions. They are not perfect, nor are they infallible. If you forecast market share to fall to 11.3% next month with a 95% confidence interval of plus/minus 0.2% and it actually falls to 11.1%, your model was correct and within the expected range. </p>
			<p>If your model tells you a certain basketball player has a 70% chance of doing well on your team and that player fails, then your model was still right, but the 30% chance happened.   </p>
			<p class="callout-heading">Important tip</p>
			<p class="callout">When making an AI for decision assistance, such as most forecasting models, it's important that your model is as accurate as possible and doesn't show wide swings in accuracy. Nothing loses trust as fast as a widely fluctuating model.</p>
			<p>By stressing that you <a id="_idIndexMarker842"/>are only providing advice and that the advice is statistical in nature, your model has a higher chance of being used by the business over a long period of time. They won't feel threatened if it's just advice and they won't stop using your model when the statistically less likely thing happens because they understand that it will happen once in a while.</p>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor203"/>Getting the business to replace an old decision assistance tool</h2>
			<p>Perhaps the most difficult type of project regarding gaining acceptance from a business audience is when you replace an old, trusted tool with one driven by ML. In this case, the tool you are replacing may have existed for many years. </p>
			<p>Many experienced users are likely to object to a new process or solution, irrespective of how much it improves the current state. This is due<a id="_idIndexMarker843"/> to <strong class="bold">familiarity bias</strong>, the preference of human beings of the familiar to the unfamiliar.</p>
			<p>Overcoming familiarity bias and getting business users to adopt your solution is quite a challenge and needs to be approached systematically. First, like replacing an older, automated process, you should not shut down the old solution; you need to keep it running so you can compare results side by side. If you do not do this, it is likely that experienced users will negatively and unfairly compare your tool to the old solution; they need to see that it is an improvement upon the old solution.</p>
			<p>Comparing results side by side is necessary but not sufficient to gaining end user acceptance. Additionally, you need the users to understand your AutoML-generated solution. </p>
			<p>One common criticism of AI solutions is that it is difficult to understand how they work. In contrast, the system you are replacing will have had years to teach its users its ins and outs. Thus, you should present explainability slides at the forefront of your solution; you should also explain the architecture and explain exactly how AutoML works, when you plan on retraining models, and how you plan on continually evaluating and monitoring the solution.</p>
			<p>A person-by-person approach to gaining trust will also go a long way to your solution's success. Only present your solution to the entire group after you've had a series of one-on-one meetings with all end users individually. </p>
			<p>If there are too many end users, identify and meet the most influential people within the group. By addressing their concerns, training them on their solutions, and encouraging them to talk to other end users, you will be able to build a group of people who will champion your solution, increasing its chances of long-term success.</p>
			<p>In order of difficulty, from <a id="_idIndexMarker844"/>easiest to hardest, to gain end-user trust and guarantee adoption over time, here's the list of solution types: an AutoML solution for a new automated process, an AutoML solution replacing an automated process, an AutoML solution to help human beings make decisions, an AutoML solution to replace an existing decision-assistance tool. The following table provides a summary:</p>
			<div>
				<div id="_idContainer135" class="IMG---Figure">
					<img src="image/Table_12.3_B16595.jpg" alt="Figure 12.11 – How to gain trust based on the type of AutoML solution "/>
				</div>
			</div>
			<p class="figure-caption">Figure 12.11 – How to gain trust based on the type of AutoML solution</p>
			<p>As you can see, just<a id="_idIndexMarker845"/> because you build a highly performing AutoML solution does not mean it will be adopted by the business. You also need to work just as hard at gaining your end users' trust. By identifying the type of AutoML solution you are building and following the appropriate guidelines, you will be able to gain trust one end user at a time. Once enough people champion your solution, it will be well on its way to becoming a trusted tool set up for long-term success and adoption. </p>
			<h1 id="_idParaDest-200"><a id="_idTextAnchor204"/>Summary</h1>
			<p>Gaining end user acceptance can be difficult, but having the right approach can make it a lot easier. Walking your end users through an architectural diagram, carefully explaining the model's performance to them using the right metrics, and spending time explaining which features the model is using to make predictions are all key to selling your solution to end users. Furthermore, you can tailor your message based on what type of solution you are building to gain end user trust. </p>
			<p>You are now at the end of the book and I'd like you to reflect on the journey. You've acquired many technical skills, including the ability to train AutoML models, deploy AutoML models for scoring in batch and real-time scoring, and design, create, and implement full end-to-end AutoML solutions. You also have an approach to sell those solutions to your business partners, gain their trust, and, ultimately, realize value. By crafting powerful solutions with AutoML on Azure, you'll be able to make a lasting impact and advance your career. </p>
		</div>
</body></html>