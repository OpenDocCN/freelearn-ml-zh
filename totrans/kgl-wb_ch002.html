<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-US">
<head>
<meta charset="utf-8"/>
<meta name="generator" content="packt"/>
<title>01 The most renowned tabular competition: Porto Seguro’s Safe Driver Prediction</title>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet2.css"/>

</head>
<body>
<section id="the-most-renowned-tabular-competition-porto-seguros-safe-driver-prediction" class="level1 pkt" data-number="2">
<h1 data-number="2">01 The most renowned tabular competition: Porto Seguro’s Safe Driver Prediction</h1>
<section id="join-our-book-community-on-discord" class="level2" data-number="2.1">
<h2 data-number="2.1">Join our book community on Discord</h2>
<p><a href="https://packt.link/EarlyAccessCommunity">https://packt.link/EarlyAccessCommunity</a></p>
<figure>
<img src="../media/file0.png" style="width:10em" />
</figure>
<p>Learning how to perform top on the leaderboard on any Kaggle competition requires patience, diligence and many attempts in order to learn the best way to compete and achieve top results. For this reason, we have thought of a workbook that can help you build faster those skills by leading you to try some Kaggle competitions of the past and to learn how to make top competitions for them by reading discussions, reusing notebooks, engineering features and training various models.</p>
<p>We start in the book from one of the most renowned tabular competitions, Porto Seguro’s Safe Driver Prediction. In this competition, you are asked to solve a common problem in insurance, to figure out who is going to have an auto insurance claim in the next year. Such information is useful in order to increase the insurance fee to drivers more likely to have a claim and to lower it to those less likely to.</p>
<p>In illustrating the key insight and technicalities necessary for cracking this competition we will show you the necessary code and ask you to study and answer about topics to be found on the Kaggle book itself. Therefore, without much more ado, let’s start immediately this new learning path of yours.</p>
<p>In this chapter, you will learn:</p>
<ul>
<li>How to tune and train a LightGBM model.</li>
<li>How to build a denoising auto-encoder and how to use it to feed a neural network.</li>
<li>How to effectively blend models that are quite different from each other.</li>
</ul>
</section>
<section id="understanding-the-competition-and-the-data" class="level2" data-number="2.2">
<h2 data-number="2.2">Understanding the competition and the data</h2>
<p>Porto Seguro is the third largest insurance company in Brazil (it operates in Brazil and Uruguay), offering car insurance coverage as well as many other insurance products. Having used analytical methods and machine learning for the past 20 years in order to tailor their prices and make auto insurance coverage more accessible to more drivers. In order to explore new ways to achieve their task, they sponsored a competition (<a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction</a>), expecting Kagglers to come up with new and better methods of solving some of their core analytical problems.</p>
<p>The competition aims at having Kagglers build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year, which is a quite common kind of task (the sponsor mentions it as a “classical challenge for insurance”). For doing so, the sponsor provided a train and test sets and the competition appears ideal for anyone since the dataset is not very large and it seems very well prepared.</p>
<p>As stated in the page of the competition devoted to presenting the data (<a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/data">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/data</a>):</p>
<blockquote>
<em>“features that belong to similar groupings are tagged as such in the feature names (e.g., ind, reg, car, calc). In addition, feature names include the postfix bin to indicate binary features and cat to indicate categorical features. Features without these designations are either continuous or ordinal. Values of -1 indicate that the feature was missing from the observation. The target column signifies whether or not a claim was filed for that policy holder”.</em>
</blockquote>
<p>The data preparation for the competition had been quite carefully not to leak any information and, though, maintaining secrecy about the meaning of the features, it is quite clear to refer the different used tags to specific kind of features commonly used insurance modeling:</p>
<ul>
<li>ind refers to “individual characteristics”</li>
<li>car refer to “cars characteristics”</li>
<li>calc to “calculated features”</li>
<li>reg to “regional/geographic features”</li>
</ul>
<p>As for the individual features, there has been much speculation during the competition. See for instance <a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41489">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41489</a> or <a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41488">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41488</a> both by Raddar or again the attempts to attribute the feature to Porto Seguro’s online quote form <a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41057">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41057</a>. In spite of all such efforts, in the end the meaning of the features has remained a mystery up until now.</p>
<p>The interesting fact about this competition is that:</p>
<ol>
<li>the data is real world, though the features are anonymous</li>
<li>the data is really very well prepared, without leakages of any sort (no magic features here)</li>
<li>the test set not only holds the same categorical levels of the train test, and it also seems to be from the same distribution, though Yuya Yamamoto argues that pre-processing the data with t-SNE leads to a failing adversarial validation test (<a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44784">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44784</a>) .</li>
</ol>
<blockquote>
<p>As a first exercise, referring to the contents and the code on the Kaggle Book related to adversarial validation (starting from page 179), prove that train and test data most probably originated from the same data distribution.</p>
</blockquote>
<p>An interesting post by Tilii (Mensur Dlakic, associate Professor at Montana State University: <a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/42197">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/42197</a>) demonstrates using tSNE that “there are many people who are very similar in terms of their insurance parameters, yet some of them will file a claim and others will not”. What Tilii mentions is quite typical of what happens in insurance where to certain priors (insurance parameters) there is sticked the same probability of something happening but that event will happen or not based on how long we observe the situation.</p>
<p>Take for instance IoT and telematic data in insurance. It is quite common to analyze a driver's behavior in order to predict if she or he will file a claim in the future. If your observation period is too short (for instance one year as in the case of this competition), it may happen that even very bad drivers won’t have a claim because it is a matter of not too high probability of the outcome that can become a reality only after a certain amount of time. Similar ideas are discussed by Andy Harless (<a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/42735">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/42735</a>) which argues instead that the real task of the competition is to guess <em>“the value of a latent continuous variable that determines which drivers are more likely to have accidents”</em> because actually <em>“making a claim is not a characteristic of a driver; it's a result of chance”</em>.</p>
</section>
<section id="understanding-the-evaluation-metric" class="level2" data-number="2.3">
<h2 data-number="2.3">Understanding the Evaluation Metric</h2>
<p>The metric used in the competition is the "normalized Gini coefficient" (named for the similar Gini coefficient/index used in Economics), which has been previously used in another competition, the Allstate Claim Prediction Challenge (<a href="https://www.kaggle.com/competitions/ClaimPredictionChallenge">https://www.kaggle.com/competitions/ClaimPredictionChallenge</a>). From that competition, we can get a very clear explanation about what this metric is about:</p>
<p><em>When you submit an entry, the observations are sorted from "largest prediction" to "smallest prediction". This is the only step where your predictions come into play, so only the order determined by your predictions matters. Visualize the observations arranged from left to right, with the largest predictions on the left. We then move from left to right, asking "In the leftmost x% of the data, how much of the actual observed loss have you accumulated?" With no model, you can expect to accumulate 10% of the loss in 10% of the predictions, so no model (or a "null" model) achieves a straight line. We call the area between your curve and this straight line the Gini coefficient.</em></p>
<p><em>There is a maximum achievable area for a "perfect" model. We will use the normalized Gini coefficient by dividing the Gini coefficient of your model by the Gini coefficient of the perfect model.</em></p>
<p>Another good explanation is provided in the competition by the notebook by Kilian Batzner: <a href="https://www.kaggle.com/code/batzner/gini-coefficient-an-intuitive-explanation">https://www.kaggle.com/code/batzner/gini-coefficient-an-intuitive-explanation</a> that, though means of plots and toy examples tries to give a sense to a not so common metric but in the actuarial departments of insurance companies.</p>
<blockquote>
<p>In chapter 5 of the Kaggle Book (pages 95 onward), we explained how to deal with competition metrics, especially if they are new and generally unknown. As an exercise, can you find out how many competitions on Kaggle have used the normalized Gini coefficient as an evaluation metric?</p>
</blockquote>
<p>The metric can be approximated by the Mann–Whitney U non-parametric statistical test and by the ROC-AUC score because it approximately corresponds to 2 * ROC-AUC - 1. Hence, maximizing the ROC-AUC is the same as maximizing the Normalized Gini coefficient (for a reference see the “Relation to other statistical measures” in the Wikipedia entry: <a href="https://en.wikipedia.org/wiki/Gini_coefficient">https://en.wikipedia.org/wiki/Gini_coefficient</a>).</p>
<p>The metric can also be approximately expressed as the covariance of scaled prediction rank and scaled target value, resulting in a more understandable rank association measure (see Dmitriy Guller: <a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/40576">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/40576</a>)</p>
<p>From the point of view of the objective function, you can optimize for the binary logloss (as you would do in a classification problem). Nor ROC-AUC nor the normalized Gini coefficient are differentiable and they may be used only for metric evaluation on the validation set (for instance for early stopping or for reducing the learning rate in a neural network). However, optimizing for the logloss doesn’t always improve the ROC-AUC and the normalized Gini coefficients. There is actually a differentiable ROC-AUC approximation (Calders, Toon, and Szymon Jaroszewicz. "Efficient AUC optimization for classification." European conference on principles of data mining and knowledge discovery. Springer, Berlin, Heidelberg, 2007 <a href="https://link.springer.com/content/pdf/10.1007/978-3-540-74976-9_8.pdf">https://link.springer.com/content/pdf/10.1007/978-3-540-74976-9_8.pdf</a>). However, it seems that it is not necessary to use anything different from logloss as objective function and ROC-AUC or normalized Gini coefficient as evaluation metric in the competition.</p>
<p>There are actually a few Python implementations among the notebooks. We have used here and we suggest the work by CPMP (<a href="https://www.kaggle.com/code/cpmpml/extremely-fast-gini-computation/notebook">https://www.kaggle.com/code/cpmpml/extremely-fast-gini-computation/notebook</a>) that uses Numba for speeding up computations: it is both exact and fast.</p>
</section>
<section id="examining-the-top-solutions-ideas-from-michael-jahrer" class="level2" data-number="2.4">
<h2 data-number="2.4">Examining the top solution’s ideas from Michael Jahrer</h2>
<p>Michael Jahrer (<a href="https://www.kaggle.com/mjahrer">https://www.kaggle.com/mjahrer</a>, competitions grandmaster and one of the winners of the Netflix Prize in the team "BellKor's Pragmatic Chaos"), has led for long time and by a fair margin the public leaderboard during the competition and, when finally the private one has been disclosed, has been declared the winner.</p>
<p>Shortly after, in the discussion forum, he published a short summary of his solution that has become a reference for many Kagglers because of his smart usage of denoising autoencoders and neural networks (<a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44629">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44629</a>). Although Michael hasn’t accompanied his post by any Python code regarding his solution (he quoted it as an “old school” and “low level” one, being directly written in C++/CUDA with no Python), his writing is quite rich in references to what models he has used as well to theirs hyper-parameters and architectures.</p>
<p>First, Michael explains that his solution is composed of a blend of six models (one LightGBM model and five neural networks). Moreover, since no advantage could be gained by weighting the contributions of each model to the blend (as well as doing linear and non-linear stacking) likely because of overfitting, he states that he resorted to just a plain blend of models (an arithmetic mean) that have been built from different seeds.</p>
<p>Such insight makes the task much easier for us in order to replicate his approach, also because he also mentions that just having blend together the LightGBM’s results with one from the neural networks he built would have been enough to guarantee the first place in the competition. That will limit our exercise work to two good single models instead of a host of them. In addition, he mentioned having done little data processing, but dropping some columns and one-hot encoding categorical features.</p>
</section>
<section id="building-a-lightgbm-submission" class="level2" data-number="2.5">
<h2 data-number="2.5">Building a LightGBM submission</h2>
<p>Our exercise starts by working out a solution based on LightGBM. You can find the code already set for execution at the Kaggle Notebook at this address: <a href="https://www.kaggle.com/code/lucamassaron/workbook-lgb">https://www.kaggle.com/code/lucamassaron/workbook-lgb</a>. Although we made the code readily available, we instead suggest you to type or copy the code directly from the book and execute it cell by cell, understanding what each line of code does and you could furthermore personalise the solution and have it perform even better.</p>
<p>We start by importing key packages (Numpy, Pandas, Optuna for hyper-parameter optimization, LightGBM and some utility functions). We also define a configuration class and instantiate it. We will discuss the parameters defined into the configuration class during the exploration of the code as we progress. What is important to remark here is that by using a class containing all your parameters it will be easier for you to modify them in a consistent way along the code. In the heat of a competition, it is easy to forget to update a parameter that it is referred to in multiple places in the code and it is always difficult to set the parameters when they are dispersed among cells and functions. A configuration class can save you a lot of effort and spare you mistakes along the way.</p>
<div class="C0-SHCodePACKT">
<pre><code>import numpy as np
import pandas as pd
import optuna
import lightgbm as lgb
from path import Path
from sklearn.model_selection import StratifiedKFold
class Config:
    input_path = Path(&#39;../input/porto-seguro-safe-driver-prediction&#39;)
    optuna_lgb = False
    n_estimators = 1500
    early_stopping_round = 150
    cv_folds = 5
    random_state = 0
    params = {&#39;objective&#39;: &#39;binary&#39;,
              &#39;boosting_type&#39;: &#39;gbdt&#39;,
              &#39;learning_rate&#39;: 0.01,
              &#39;max_bin&#39;: 25,
              &#39;num_leaves&#39;: 31,
              &#39;min_child_samples&#39;: 1500,
              &#39;colsample_bytree&#39;: 0.7,
              &#39;subsample_freq&#39;: 1,
              &#39;subsample&#39;: 0.7,
              &#39;reg_alpha&#39;: 1.0,
              &#39;reg_lambda&#39;: 1.0,
              &#39;verbosity&#39;: 0,
              &#39;random_state&#39;: 0}
    
config = Config()</code></pre>
</div>
<p>The next step requires importing train, test and the sample submission datasets. By doing so by pandas csv reading function, we also set the index of the uploaded dataframes to the identifier (the ‘id’ column) of each data example.</p>
<p>Since features that belong to similar groupings are tagged (using ind, reg, car, calc tags in their labels) and also binary and categorical features are easy to locate (they use the bin and cat, respectively, tags in their labels), we can enumerate them and record them into lists.</p>
<div class="C0-SHCodePACKT">
<pre><code>train = pd.read_csv(config.input_path / &#39;train.csv&#39;, index_col=&#39;id&#39;)
test = pd.read_csv(config.input_path / &#39;test.csv&#39;, index_col=&#39;id&#39;)
submission = pd.read_csv(config.input_path / &#39;sample_submission.csv&#39;, index_col=&#39;id&#39;)
calc_features = [feat for feat in train.columns if &quot;_calc&quot; in feat]
cat_features = [feat for feat in train.columns if &quot;_cat&quot; in feat]</code></pre>
</div>
<p>Then, we just extract the target (a binary target of 0s and 1s) and remove it from the train dataset.</p>
<div class="C0-SHCodePACKT">
<pre><code>target = train[&quot;target&quot;]
train = train.drop(&quot;target&quot;, axis=&quot;columns&quot;)</code></pre>
</div>
<p>At this point, as pointed out by Michael Jahrer, we can drop the calc features. This idea has recurred a lot during the competition (<a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41970">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41970</a>), especially in notebooks, both because it could be empirically verified that dropping them improved the public leaderboard score, both because they performed poorly in gradient boosting models (their importance is always below the average). We can argue that, since they are engineered features, they do not contain new information in respect of their origin features but they just add noise to any model trained comprising them.</p>
<div class="C0-SHCodePACKT">
<pre><code>train = train.drop(calc_features, axis=&quot;columns&quot;)
test = test.drop(calc_features, axis=&quot;columns&quot;)</code></pre>
</div>
<blockquote>
<p>During the competition, Tilii has tested feature elimination using Boruta (<a href="https://github.com/scikit-learn-contrib/boruta_py">https://github.com/scikit-learn-contrib/boruta_py</a>). You can find his kernel here: <a href="https://www.kaggle.com/code/tilii7/boruta-feature-elimination/notebook">https://www.kaggle.com/code/tilii7/boruta-feature-elimination/notebook</a>. As you can check, there is no calc_feature considered as a confirmed feature by Boruta.</p>
<blockquote>
<p>Exercise: based on the suggestions provided in the Kaggle Book at page 220 (“Using feature importance to evaluate your work”), as an exercise, code your own feature selection notebook for this competition and check what features should be kept and what should be discarded.</p>
</blockquote>
</blockquote>
<p>Categorical features are instead one-hot encoded. Since we want to retrain their labels, and since the same levels are present both in train and test (the result of a careful train/test split between the two arranged by the Porto Seguro team), instead of the usual Scikit-Learn OneHotEncoder (<a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html</a>) we use the pandas get_dummies function (<a href="https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html">https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html</a>). Since the pandas function may produce different encodings if the features and their levels differ from train to test set, we assert a check on the one hot encoding resulting in the same for both.</p>
<div class="C0-SHCodePACKT">
<pre><code>train = pd.get_dummies(train, columns=cat_features)
test = pd.get_dummies(test, columns=cat_features)
assert((train.columns==test.columns).all())</code></pre>
</div>
<p>After one hot encoding the categorical features we have completed doing all the data processing. We proceed to define our evaluation metric, the Normalized Gini Coefficient, as previously discussed. Since we are going to use a LightGBM model, we have to add a suitable wrapper (<code>gini_lgb</code>) in order to return to the GBM algorithm the evaluation of the training and the validation sets in a form that could works with it (see: <a href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Booster.html?highlight=higher_better#lightgbm.Booster.eval">https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Booster.html?highlight=higher_better#lightgbm.Booster.eval</a> - “Each evaluation function should accept two parameters: preds, eval_data, and return <code>(eval_name</code>, <code>eval_result</code>, <code>is_higher_better</code>) or list of such tuples”).</p>
<div class="C0-SHCodePACKT">
<pre><code>from numba import jit
@jit
def eval_gini(y_true, y_pred):
    y_true = np.asarray(y_true)
    y_true = y_true[np.argsort(y_pred)]
    ntrue = 0
    gini = 0
    delta = 0
    n = len(y_true)
    for i in range(n-1, -1, -1):
        y_i = y_true[i]
        ntrue += y_i
        gini += y_i * delta
        delta += 1 - y_i
    gini = 1 - 2 * gini / (ntrue * (n - ntrue))
    return gini
def gini_lgb(y_true, y_pred):
    eval_name = &#39;normalized_gini_coef&#39;
    eval_result = eval_gini(y_true, y_pred)
    is_higher_better = True
    return eval_name, eval_result, is_higher_better</code></pre>
</div>
<p>As for the training parameters, we found that the parameters suggested by Michael Jahrer in his post (<a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44629">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44629</a>) work perfectly. You may also try to come up with the same parameters or with similarly performing ones by performing a search by optuna (<a href="https://optuna.org/">https://optuna.org/</a>) if you set the <code>optuna_lgb</code> flag to True in the config class. Here the optimization tries to find the best values for key parameters such as the learning rate and the regularization parameters, based on a 5-fold cross-validation test on training data. In order to speed up things, early stopping on the validation itself is taken into account (which, we are aware, could actually advantage some values that can overfit better the validation fold - a good alternative could be to remove the early stopping callback and keep a fixed number of rounds for the training).</p>
<div class="C0-SHCodePACKT">
<pre><code>if config.optuna_lgb:
        
    def objective(trial):
        params = {
    &#39;learning_rate&#39;: trial.suggest_float(&quot;learning_rate&quot;, 0.01, 1.0),
    &#39;num_leaves&#39;: trial.suggest_int(&quot;num_leaves&quot;, 3, 255),
    &#39;min_child_samples&#39;: trial.suggest_int(&quot;min_child_samples&quot;, 
                                           3, 3000),
    &#39;colsample_bytree&#39;: trial.suggest_float(&quot;colsample_bytree&quot;, 
                                            0.1, 1.0),
    &#39;subsample_freq&#39;: trial.suggest_int(&quot;subsample_freq&quot;, 0, 10),
    &#39;subsample&#39;: trial.suggest_float(&quot;subsample&quot;, 0.1, 1.0),
    &#39;reg_alpha&#39;: trial.suggest_loguniform(&quot;reg_alpha&quot;, 1e-9, 10.0),
    &#39;reg_lambda&#39;: trial.suggest_loguniform(&quot;reg_lambda&quot;, 1e-9, 10.0),
        }
        
        score = list()
        skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, 
                              random_state=config.random_state)
        for train_idx, valid_idx in skf.split(train, target):
            X_train = train.iloc[train_idx]
            y_train = target.iloc[train_idx]
            X_valid = train.iloc[valid_idx] 
            y_valid = target.iloc[valid_idx]
            model = lgb.LGBMClassifier(**params,
                                    n_estimators=1500,
                                    early_stopping_round=150,
                                    force_row_wise=True)
            callbacks=[lgb.early_stopping(stopping_rounds=150, 
                                          verbose=False)]
            model.fit(X_train, y_train, 
                      eval_set=[(X_valid, y_valid)],  
                      eval_metric=gini_lgb, callbacks=callbacks)
              
            score.append(
                model.best_score_[&#39;valid_0&#39;][&#39;normalized_gini_coef&#39;])
        return np.mean(score)
    study = optuna.create_study(direction=&quot;maximize&quot;)
    study.optimize(objective, n_trials=300)
    print(&quot;Best Gini Normalized Score&quot;, study.best_value)
    print(&quot;Best parameters&quot;, study.best_params)
    
    params = {&#39;objective&#39;: &#39;binary&#39;,
              &#39;boosting_type&#39;: &#39;gbdt&#39;,
              &#39;verbosity&#39;: 0,
              &#39;random_state&#39;: 0}
    
    params.update(study.best_params)
    
else:
    params = config.params</code></pre>
</div>
<p>During the competition, Tilii has tested feature elimination using Boruta (<a href="https://github.com/scikit-learn-contrib/boruta_py">https://github.com/scikit-learn-contrib/boruta_py</a>). You can find his kernel here: <a href="https://www.kaggle.com/code/tilii7/boruta-feature-elimination/notebook">https://www.kaggle.com/code/tilii7/boruta-feature-elimination/notebook</a>. As you can check, there is no calc_feature considered as a confirmed feature by Boruta.</p>
<blockquote>
<p>In the Kaggle Book, we explain about both hyper-parameter optimization (pages 241 onward) and provide some key hyper-parameters for the LightGBM model. As an exercise, try to improve the hyper-parameter search by reducing or increasing the explored parameters and by trying alternative methods such as the random search or the halving search from Scikit-Learn (pages 245-246).</p>
</blockquote>
<p>Once we have our best parameters (or we simply try Jahrer’s ones), we are ready to train and predict. Our strategy, as suggested by the best solution, is to train a model on each cross-validation folds and use that fold to contribute to an average of test predictions. The snippet of code will produce both the test predictions and the out of fold predictions on the train set, later useful for figuring out how to ensemble the results.</p>
<div class="C0-SHCodePACKT">
<pre><code>preds = np.zeros(len(test))
oof = np.zeros(len(train))
metric_evaluations = list()
skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, random_state=config.random_state)
for idx, (train_idx, valid_idx) in enumerate(skf.split(train, 
                                                       target)):
    print(f&quot;CV fold {idx}&quot;)
    X_train, y_train = train.iloc[train_idx], target.iloc[train_idx]
    X_valid, y_valid = train.iloc[valid_idx], target.iloc[valid_idx]
    
    model = lgb.LGBMClassifier(**params,
                               n_estimators=config.n_estimators,
                    early_stopping_round=config.early_stopping_round,
                               force_row_wise=True)
    
    callbacks=[lgb.early_stopping(stopping_rounds=150), 
               lgb.log_evaluation(period=100, show_stdv=False)]
    
    model.fit(X_train, y_train, 
              eval_set=[(X_valid, y_valid)], 
              eval_metric=gini_lgb, callbacks=callbacks)
    metric_evaluations.append(
                model.best_score_[&#39;valid_0&#39;][&#39;normalized_gini_coef&#39;])
    preds += (model.predict_proba(test,  
              num_iteration=model.best_iteration_)[:,1] 
              / skf.n_splits)
    oof[valid_idx] = model.predict_proba(X_valid,  
                    num_iteration=model.best_iteration_)[:,1]</code></pre>
</div>
<p>The model training shouldn’t take too long. In the end you can get reported the Normalized Gini Coefficient obtained during the cross-validation procedure.</p>
<div class="C0-SHCodePACKT">
<pre><code>print(f&quot;LightGBM CV normalized Gini coefficient:  
        {np.mean(metric_evaluations):0.3f}  
        ({np.std(metric_evaluations):0.3f})&quot;)</code></pre>
</div>
<p>The results are quite encouraging because the average score is 0.289 and the standard deviation of the values is quite small.</p>
<div class="C0-SHConPACKT">
<pre><code>LightGBM CV Gini Normalized Score: 0.289 (0.015)</code></pre>
</div>
<p>All that is left is to save the out-of-fold and the test predictions as a submission and to verify the results on the public and private leaderboards.</p>
<div class="C0-SHCodePACKT">
<pre><code>submission[&#39;target&#39;] = preds
submission.to_csv(&#39;lgb_submission.csv&#39;)
oofs = pd.DataFrame({&#39;id&#39;:train_index, &#39;target&#39;:oof})
oofs.to_csv(&#39;dnn_oof.csv&#39;, index=False)</code></pre>
</div>
<p>The obtained public score should be around 0.28442. The associated private score is about 0.29121, placing you in the 30<sup>th</sup> position in the final leaderboard. A quite good result, but we still have to blend it with a different model, a neural network.</p>
<p>Bagging the training set (i.e. taking multiple bootstraps of the training data and training multiple models based on the bootstraps) should increase the performance, though, as Michael Jahrer himself noted in his post, not all that much.</p>
</section>
<section id="setting-up-a-denoising-auto-encoder-and-a-dnn" class="level2" data-number="2.6">
<h2 data-number="2.6">Setting up a Denoising Auto-encoder and a DNN</h2>
<p>The next step is not to set up a denoising auto-encoder (DAE) and a neural network that can learn and predict from it. You can find the running code at this notebook: <a href="https://www.kaggle.com/code/lucamassaron/workbook-dae">https://www.kaggle.com/code/lucamassaron/workbook-dae</a> . The notebook can be run in GPU mode (speedier), but it can also run in CPU one with some slight modifications.</p>
<blockquote>
<p>You can read more about denoising auto-encoders as being used in Kaggle competitions in the Kaggle Book, at pages 226 and following.</p>
</blockquote>
<p>Actually there are no examples around reproducing Michael Jahrer’s approach in the competition using DAEs, but we tooked example from a working TensorFlow implementation in another competition by OsciiArt (<a href="https://www.kaggle.com/code/osciiart/denoising-autoencoder">https://www.kaggle.com/code/osciiart/denoising-autoencoder</a>).</p>
<p>Here we start by importing all the necessary packages, especially TensorFlow and Keras. Since we are going to create multiple neural networks, we point out to TensorFlow not to use all the GPU memory available by using the experimental <code>set_memory_growth</code> command. Such will avoid having memory overflow problems along the way. We also record the Leaky Relu activation as a custom one, so we can just mention it as an activation by a string in Keras layers.</p>
<div class="C0-SHCodePACKT">
<pre><code>import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from path import Path
import gc
import optuna
from sklearn.model_selection import StratifiedKFold
from scipy.special import erfinv
import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices(&#39;GPU&#39;)
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)
from tensorflow import keras
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2
from tensorflow.keras.metrics import AUC
from tensorflow.keras.utils import get_custom_objects
from tensorflow.keras.layers import Activation, LeakyReLU
get_custom_objects().update({&#39;leaky-relu&#39;: Activation(LeakyReLU(alpha=0.2))})</code></pre>
</div>
<p>Related to our intention of creating multiple neural networks without running out of memory, we also define a simple function for cleaning the memory in GPU and removing models that are no longer needed.</p>
<div class="C0-SHCodePACKT">
<pre><code>def gpu_cleanup(objects):
    if objects:
        del(objects)
    K.clear_session()
    gc.collect()</code></pre>
</div>
<p>We also reconfigure the Config class in order to take into account multiple parameters related to the denoising auto-encoder and the neural network. As previously stated about the LightGBM, having all the parameters in a single place renders simpler modifying them in a consistent way.</p>
<div class="C0-SHCodePACKT">
<pre><code>class Config:
    input_path = Path(&#39;../input/porto-seguro-safe-driver-prediction&#39;)
    dae_batch_size = 128
    dae_num_epoch = 50
    dae_architecture = [1500, 1500, 1500]
    reuse_autoencoder = False
    batch_size = 128
    num_epoch = 150
    units = [64, 32]
    input_dropout=0.06
    dropout=0.08
    regL2=0.09
    activation=&#39;selu&#39;
    
    cv_folds = 5
    nas = False
    random_state = 0
    
config = Config()</code></pre>
</div>
<p>As previously, we load the datasets and proceed processing the features by removing the calc features and one hot encoding the categorical ones. We leave missing cases valued at -1, as Michael Jahrer pointed out in his solution.</p>
<div class="C0-SHCodePACKT">
<pre><code>train = pd.read_csv(config.input_path / &#39;train.csv&#39;, index_col=&#39;id&#39;)
test = pd.read_csv(config.input_path / &#39;test.csv&#39;, index_col=&#39;id&#39;)
submission = pd.read_csv(config.input_path / &#39;sample_submission.csv&#39;, index_col=&#39;id&#39;)
calc_features = [feat for feat in train.columns if &quot;_calc&quot; in feat]
cat_features = [feat for feat in train.columns if &quot;_cat&quot; in feat]
target = train[&quot;target&quot;]
train = train.drop(&quot;target&quot;, axis=&quot;columns&quot;)
train = train.drop(calc_features, axis=&quot;columns&quot;)
test = test.drop(calc_features, axis=&quot;columns&quot;)
train = pd.get_dummies(train, columns=cat_features)
test = pd.get_dummies(test, columns=cat_features)
assert((train.columns==test.columns).all())</code></pre>
</div>
<p>However, differently from our previous approach, we have to rescale all the features that are not binary or one hot-encoded categorical. Rescaling will allow the optimization algorithm of both the auto-encoder and the neural network to converge to a good solution faster because it will have to work with values set into a comparable and predefined range. Instead of using statistical normalisation, GaussRank is a procedure that also allows the modification of the distribution of transformed variables into a Gaussian one.</p>
<p>As also stated in some papers, such as in the Batch Normalization paper: <a href="https://arxiv.org/pdf/1502.03167.pdf">https://arxiv.org/pdf/1502.03167.pdf</a>, neural networks perform even better if you provide them a Gaussian input. Accordingly to this NVidia blog post, <a href="https://developer.nvidia.com/blog/gauss-rank-transformation-is-100x-faster-with-rapids-and-cupy/">https://developer.nvidia.com/blog/gauss-rank-transformation-is-100x-faster-with-rapids-and-cupy/</a>, GaussRank works most of the times but when features are already normally distributed or are extremely asymmetrical (in such cases applying the transformation may lead to worsened performances).</p>
<div class="C0-SHCodePACKT">
<pre><code>print(&quot;Applying GaussRank to columns: &quot;, end=&#39;&#39;)
to_normalize = list()
for k, col in enumerate(train.columns):
    if &#39;_bin&#39; not in col and &#39;_cat&#39; not in col and &#39;_missing&#39; not in col:
        to_normalize.append(col)
print(to_normalize)
def to_gauss(x): return np.sqrt(2) * erfinv(x) 
def normalize(data, norm_cols):
    n = data.shape[0]
    for col in norm_cols:
        sorted_idx = data[col].sort_values().index.tolist()
        uniform = np.linspace(start=-0.99, stop=0.99, num=n)
        normal = to_gauss(uniform)
        normalized_col = pd.Series(index=sorted_idx, data=normal)
        data[col] = normalized_col
    return data
train = normalize(train, to_normalize)
test = normalize(test, to_normalize)</code></pre>
</div>
<p>We can apply the GaussRank transformation separately on the train and test features on all the numeric features of our dataset:</p>
<div class="C0-SHConPACKT">
<pre><code>Applying GaussRank to columns: [&#39;ps_ind_01&#39;, &#39;ps_ind_03&#39;, &#39;ps_ind_14&#39;, &#39;ps_ind_15&#39;, &#39;ps_reg_01&#39;, &#39;ps_reg_02&#39;, &#39;ps_reg_03&#39;, &#39;ps_car_11&#39;, &#39;ps_car_12&#39;, &#39;ps_car_13&#39;, &#39;ps_car_14&#39;, &#39;ps_car_15&#39;]</code></pre>
</div>
<p>When normalising the features, we simply turn our data into a NumPy array of float32 values, the ideal input for a GPU.</p>
<div class="C0-SHCodePACKT">
<pre><code>features = train.columns
train_index = train.index
test_index = test.index
train = train.values.astype(np.float32)
test = test.values.astype(np.float32)</code></pre>
</div>
<p>Next, we just prepare some useful functions such as the evaluation function, the normalized Gini coefficient and a plotting function helpful representing a Keras model history of fitting on both training and validation sets.</p>
<div class="C0-SHCodePACKT">
<pre><code>def plot_keras_history(history, measures):
    rows = len(measures) // 2 + len(measures) % 2
    fig, panels = plt.subplots(rows, 2, figsize=(15, 5))
    plt.subplots_adjust(top = 0.99, bottom=0.01, 
                        hspace=0.4, wspace=0.2)
    try:
        panels = [item for sublist in panels for item in sublist]
    except:
        pass
    for k, measure in enumerate(measures):
        panel = panels[k]
        panel.set_title(measure + &#39; history&#39;)
        panel.plot(history.epoch, history.history[measure],  
                   label=&quot;Train &quot;+measure)
        try:
            panel.plot(history.epoch,  
                       history.history[&quot;val_&quot;+measure], 
                       label=&quot;Validation &quot;+measure)
        except:
            pass
        panel.set(xlabel=&#39;epochs&#39;, ylabel=measure)
        panel.legend()
        
    plt.show(fig)
from numba import jit
@jit
def eval_gini(y_true, y_pred):
    y_true = np.asarray(y_true)
    y_true = y_true[np.argsort(y_pred)]
    ntrue = 0
    gini = 0
    delta = 0
    n = len(y_true)
    for i in range(n-1, -1, -1):
        y_i = y_true[i]
        ntrue += y_i
        gini += y_i * delta
        delta += 1 - y_i
    gini = 1 - 2 * gini / (ntrue * (n - ntrue))
    return gini</code></pre>
</div>
<p>The next functions are actually a bit more complex and more related to the functioning of both the denoising auto-encoder and the supervised neural network. The <code>batch_generator</code> is a function that will create a generator providing shuffled chunks of the data based on a batch size. It isn’t actually used as a stand-alone generator but as part of a more complex batch generator that we are soon going to describe, the <code>mixup_generator</code>.</p>
<div class="C0-SHCodePACKT">
<pre><code>def batch_generator(x, batch_size, shuffle=True, random_state=None):
    batch_index = 0
    n = x.shape[0]
    while True:
        if batch_index == 0:
            index_array = np.arange(n)
            if shuffle:
                np.random.seed(seed=random_state)
                index_array = np.random.permutation(n)
        current_index = (batch_index * batch_size) % n
        if n &gt;= current_index + batch_size:
            current_batch_size = batch_size
            batch_index += 1
        else:
            current_batch_size = n - current_index
            batch_index = 0
        batch = x[index_array[current_index: current_index + current_batch_size]]
        yield batch</code></pre>
</div>
<p>The <code>mixup_generator</code>, another generator, returns batches of data whose values have been partially swapped in order to create some noise and augment the data in order for the denoising auto-encoder (DAE) not to overfit the train set. It works based on a swap rate, fixed at 15% of features as suggested by Michael Jahrer.</p>
<p>The function generates two distinct batches of data, one to be released to the model and another to be used as a source for the value to be swapped in the batch to be released. Based on a random choice, whose base probability is the swap rate, at each batch a certain number of features is decided to be swapped between the two batches.</p>
<p>Such assures that the DAE cannot always rely on the same features (since they can be randomly swapped from time to time) but it has to concentrate on the whole of the features (something similar to dropout in a certain sense). in order to find relations between them and reconstruct correctly the data at the end of the process.</p>
<div class="C0-SHCodePACKT">
<pre><code>def mixup_generator(X, batch_size, swaprate=0.15, shuffle=True, random_state=None):
    if random_state is None:
        random_state = np.randint(0, 999)
    num_features = X.shape[1]
    num_swaps = int(num_features * swaprate)    
    generator_a = batch_generator(X, batch_size, shuffle, 
                                  random_state)
    generator_b = batch_generator(X, batch_size, shuffle, 
                                  random_state + 1)
    while True:
        batch = next(generator_a)
        mixed_batch = batch.copy()
        effective_batch_size = batch.shape[0]
        alternative_batch = next(generator_b)
        assert((batch != alternative_batch).any())
        for i in range(effective_batch_size):
            swap_idx = np.random.choice(num_features, num_swaps, 
                                        replace=False)
            mixed_batch[i, swap_idx] = alternative_batch[i, swap_idx]
        yield (mixed_batch, batch)</code></pre>
</div>
<p>The <code>get_DAE</code> is the function that builds the denoising auto-encoder. It accepts a parameter for defining the architecture which in our case has been set to three layers of 1500 nodes each (as suggested from Michael Jahrer’s solution). The first layer should act as an encoder, the second is a bottleneck layer ideally containing the latent features capable of expressing the information in the data, the last layer is a decoding layer, capable of reconstructing the initial input data. The three layers have a relu activation function, no bias and each one is followed by a batch normalization layer. The final output with the reconstructed input data has a linear activation. The training is provided using an adam optimizer with standard settings (the optimised cost function is the mean squared error - mse).</p>
<div class="C0-SHCodePACKT">
<pre><code>def get_DAE(X, architecture=[1500, 1500, 1500]):
    features = X.shape[1]
    inputs = Input((features,))
    for i, nodes in enumerate(architecture):
        layer = Dense(nodes, activation=&#39;relu&#39;, 
                      use_bias=False, name=f&quot;code_{i+1}&quot;)
        if i==0:
            x = layer(inputs)
        else:
            x = layer(x)
        x = BatchNormalization()(x)
    outputs = Dense(features, activation=&#39;linear&#39;)(x)
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;, 
                  metrics=[&#39;mse&#39;, &#39;mae&#39;])
    return model</code></pre>
</div>
<p>The <code>extract_dae_features</code> function is reported here only for educational purposes. The function helps in the extraction of the values of specific layers of the trained denoising auto-encoder. The extraction works by building a new model combining the DAE input layer and the desired output one. A simple predict will then extract the values we need (the predict also allows fixing the preferred batch size in order to fit any memory requirement).</p>
<p>In the case of the competition, given the number of observations and the number of the features to be taken out from the auto-encoder, if we were to use this function, the resulting dense matrix would be too large to be handled by the memory of a Kaggle notebook. For this reason our strategy won’t be to transform the original data into the auto-encoder node values of the bottleneck layer but to fuse the auto-encoder with its frozen layers up to the bottleneck with the supervised neural network, as we will be discussing soon.</p>
<div class="C0-SHCodePACKT">
<pre><code>def extract_dae_features(autoencoder, X, layers=[3]):
    data = []
    for layer in layers:
        if layer==0:
            data.append(X)
        else:
            get_layer_output = Model([autoencoder.layers[0].input], 
                                  [autoencoder.layers[layer].output])
            layer_output = get_layer_output.predict(X, 
                                                    batch_size=128)
            data.append(layer_output)
    data = np.hstack(data)
    return data</code></pre>
</div>
<p>To complete the work with the DAE, we have a final function wrapping all the previous ones into an unsupervised training procedure (at least partially unsupervised since there is an early stop monitor set on a validation set). The function sets up the mix-up generator, creates the denoising auto-encoder architecture and then trains it, monitoring its fit on a validation set for an early stop if there are signs of overfitting. Finally, before returning the trained DAE, it plots a graph of the training and validation fit and it stores the model on disk.</p>
<p>Even if we try to fix a seed on this model, contrary to the LightGBM model, the results are extremely variable and they may influence the final ensemble results. Though the result will be a high scoring one, it may land higher or lower on the private leaderboard, though the results obtained on the public one are very correlated to the public leaderboard and it will be easy for you to always pick up the best final submission based on its public results.</p>
<div class="C0-SHCodePACKT">
<pre><code>def autoencoder_fitting(X_train, X_valid, filename=&#39;dae&#39;,  
                        random_state=None, suppress_output=False):
    if suppress_output:
        verbose = 0
    else:
        verbose = 2
        print(&quot;Fitting a denoising autoencoder&quot;)
    tf.random.set_seed(seed=random_state)
    generator = mixup_generator(X_train, 
                                batch_size=config.dae_batch_size, 
                                swaprate=0.15, 
                                random_state=config.random_state)
                                
    dae = get_DAE(X_train, architecture=config.dae_architecture)
    steps_per_epoch = np.ceil(X_train.shape[0] / 
                              config.dae_batch_size)
    early_stopping = EarlyStopping(monitor=&#39;val_mse&#39;, 
                                mode=&#39;min&#39;, 
                                patience=5, 
                                restore_best_weights=True,
                                verbose=0)
    history = dae.fit(generator,
                    steps_per_epoch=steps_per_epoch,
                    epochs=config.dae_num_epoch,
                    validation_data=(X_valid, X_valid),
                    callbacks=[early_stopping],
                    verbose=verbose)
    if not suppress_output: plot_keras_history(history, 
                                           measures=[&#39;mse&#39;, &#39;mae&#39;])
    dae.save(filename)
    return dae</code></pre>
</div>
<p>Having dealt with the DAE, we take the chance also to define the supervised neural model down the line that should predict our claim expectations. As a first step, we define a function to define a single layer of the work:</p>
<ul>
<li>Random normal initialization, since empirically it has been found to converge to better results in this problem</li>
<li>A dense layer with L2 regularization and parametrable activation function</li>
<li>An excludable and tunable dropout</li>
</ul>
<p>Here is the code for creating the dense blocks:</p>
<div class="C0-SHCodePACKT">
<pre><code>def dense_blocks(x, units, activation, regL2, dropout):
    kernel_initializer = keras.initializers.RandomNormal(mean=0.0, 
                                stddev=0.1, seed=config.random_state)
    for k, layer_units in enumerate(units):
        if regL2 &gt; 0:
            x = Dense(layer_units, activation=activation, 
                      kernel_initializer=kernel_initializer, 
                      kernel_regularizer=l2(regL2))(x)
        else:
            x = Dense(layer_units, 
                      kernel_initializer=kernel_initializer, 
                      activation=activation)(x)
        if dropout &gt; 0:
            x = Dropout(dropout)(x)
    return x</code></pre>
</div>
<p>As you may have already noticed, the function defining the single layer is quite customizable. The same goes for the wrapper architecture function, taking inputs for the number of layers and units in them, dropout probabilities, regularization and activation type. The idea is to be able to run a Neural Architecture Search (NAS) and figure out what configuration should perform better in our problem.</p>
<p>As a final note on the function, among the inputs it is required to provide the trained DAE because its inputs are used as the neural network model inputs while its first layers are connected to the DAE’s outputs. In such a way we are de facto concatenating the two models into one (the DAE weights are frozen anyway and not trainable, though). This solution has been devised in order to avoid having to transform all your training data but only the single batches that the neural network is processing, thus saving memory in the system.</p>
<div class="C0-SHCodePACKT">
<pre><code>def dnn_model(dae, units=[4500, 1000, 1000], 
            input_dropout=0.1, dropout=0.5,
            regL2=0.05,
            activation=&#39;relu&#39;):
    
    inputs = dae.get_layer(&quot;code_2&quot;).output
    if input_dropout &gt; 0:
        x = Dropout(input_dropout)(inputs)
    else:
        x = tf.keras.layers.Layer()(inputs)
    x = dense_blocks(x, units, activation, regL2, dropout)
    outputs = Dense(1, activation=&#39;sigmoid&#39;)(x)
    model = Model(inputs=dae.input, outputs=outputs)
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
                loss=keras.losses.binary_crossentropy,
                metrics=[AUC(name=&#39;auc&#39;)])
    return model</code></pre>
</div>
<p>We conclude with a wrapper for the training process, including all the steps in order to train the entire pipeline on a cross-validation fold.</p>
<div class="C0-SHCodePACKT">
<pre><code>def model_fitting(X_train, y_train, X_valid, y_valid, autoencoder, 
                 filename, random_state=None, suppress_output=False):
        if suppress_output:
            verbose = 0
        else:
            verbose = 2
            print(&quot;Fitting model&quot;)
        early_stopping = EarlyStopping(monitor=&#39;val_auc&#39;, 
                                    mode=&#39;max&#39;, 
                                    patience=10, 
                                    restore_best_weights=True,
                                    verbose=0)
        rlrop = ReduceLROnPlateau(monitor=&#39;val_auc&#39;, 
                                mode=&#39;max&#39;,
                                patience=2,
                                factor=0.75,
                                verbose=0)
        
        tf.random.set_seed(seed=random_state)
        model = dnn_model(autoencoder,
                    units=config.units,
                    input_dropout=config.input_dropout,
                    dropout=config.dropout,
                    regL2=config.regL2,
                    activation=config.activation)
        
        history = model.fit(X_train, y_train, 
                            epochs=config.num_epoch, 
                            batch_size=config.batch_size, 
                            validation_data=(X_valid, y_valid),
                            callbacks=[early_stopping, rlrop],
                            shuffle=True,
                            verbose=verbose)
        model.save(filename)
        
        if not suppress_output:  
            plot_keras_history(history, measures=[&#39;loss&#39;, &#39;auc&#39;])
        return model, history</code></pre>
</div>
<p>Since our DAE implementation is surely different from Jahrer’s, although the idea behind is the same, we cannot rely completely on his indications on the architecture of the supervised neural network and we have to look for the ideal ones as we have been looking for the best hyper-parameters in the LightGBM model. Using Optuna and leveraging the multiple parameters that we set open for configuring the network’s architecture, we can run this code snippet for some hours and get an idea about what could work better.</p>
<p>In our experiments we that:</p>
<ul>
<li>we should use a two layer network with few nodes, 64 and 32 respectively.</li>
<li>input dropout, dropout between layers and some L2 regularization do help.</li>
<li>It is better to use the SELU activation function.</li>
</ul>
<p>Here is the code snippet for running the entire optimization experiments:</p>
<div class="C0-SHCodePACKT">
<pre><code>if config.nas is True:
    def evaluate():
        metric_evaluations = list()
        skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, random_state=config.random_state)
        for k, (train_idx, valid_idx) in enumerate(skf.split(train, target)):
            
            X_train, y_train = train[train_idx, :], target[train_idx]
            X_valid, y_valid = train[valid_idx, :], target[valid_idx]
            if config.reuse_autoencoder:
                autoencoder = load_model(f&quot;./dae_fold_{k}&quot;)
            else:
                autoencoder = autoencoder_fitting(X_train, X_valid,
                                                filename=f&#39;./dae_fold_{k}&#39;, 
                                                random_state=config.random_state,
                                                suppress_output=True)
            
            model, _ = model_fitting(X_train, y_train, X_valid, y_valid,
                                        autoencoder=autoencoder,
                                        filename=f&quot;dnn_model_fold_{k}&quot;, 
                                        random_state=config.random_state,
                                        suppress_output=True)
            
            val_preds = model.predict(X_valid, batch_size=128, verbose=0)
            best_score = eval_gini(y_true=y_valid, y_pred=np.ravel(val_preds))
            metric_evaluations.append(best_score)
            
            gpu_cleanup([autoencoder, model])
        
        return np.mean(metric_evaluations)
    def objective(trial):
        params = {
                &#39;first_layer&#39;: trial.suggest_categorical(&quot;first_layer&quot;, [8, 16, 32, 64, 128, 256, 512]),
                &#39;second_layer&#39;: trial.suggest_categorical(&quot;second_layer&quot;, [0, 8, 16, 32, 64, 128, 256]),
                &#39;third_layer&#39;: trial.suggest_categorical(&quot;third_layer&quot;, [0, 8, 16, 32, 64, 128, 256]),
                &#39;input_dropout&#39;: trial.suggest_float(&quot;input_dropout&quot;, 0.0, 0.5),
                &#39;dropout&#39;: trial.suggest_float(&quot;dropout&quot;, 0.0, 0.5),
                &#39;regL2&#39;: trial.suggest_uniform(&quot;regL2&quot;, 0.0, 0.1),
                &#39;activation&#39;: trial.suggest_categorical(&quot;activation&quot;, [&#39;relu&#39;, &#39;leaky-relu&#39;, &#39;selu&#39;])
        }
        config.units = [nodes for nodes in [params[&#39;first_layer&#39;], params[&#39;second_layer&#39;], params[&#39;third_layer&#39;]] if nodes &gt; 0]
        config.input_dropout = params[&#39;input_dropout&#39;]
        config.dropout = params[&#39;dropout&#39;]
        config.regL2 = params[&#39;regL2&#39;]
        config.activation = params[&#39;activation&#39;]
        
        return evaluate()
    study = optuna.create_study(direction=&quot;maximize&quot;)
    study.optimize(objective, n_trials=60)
    print(&quot;Best Gini Normalized Score&quot;, study.best_value)
    print(&quot;Best parameters&quot;, study.best_params)
    config.units = [nodes for nodes in [study.best_params[&#39;first_layer&#39;], study.best_params[&#39;second_layer&#39;], study.best_params[&#39;third_layer&#39;]] if nodes &gt; 0]
    config.input_dropout = study.best_params[&#39;input_dropout&#39;]
    config.dropout = study.best_params[&#39;dropout&#39;]
    config.regL2 = study.best_params[&#39;regL2&#39;]
    config.activation = study.best_params[&#39;activation&#39;]</code></pre>
</div>
<blockquote>
<p>If you are looking for more information about more on Neural Architecture Search (NAS), you can have a look at the Kaggle Book, at pages 276 onward. In the case of the DAE and the supervised neural network, it is critical to look for the best architecture since we are implementing something surely different from Michael Jahrer solution.</p>
<blockquote>
<p>As an exercise, try to improve the hyper-parameter search by using KerasTuner (to be found on pages 285 onward in the Kaggle Book), a fast solution for optimizing neural networks that has seen the important contribution of François Chollet, the creator of Keras.</p>
</blockquote>
</blockquote>
<p>Having finally set everything ready, we are set to start the training. In about one hour, on a Kaggle notebook with GPU, you can obtain complete test and out-of-fold predictions.</p>
<div class="C0-SHCodePACKT">
<pre><code>preds = np.zeros(len(test))
oof = np.zeros(len(train))
metric_evaluations = list()
skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, random_state=config.random_state)
for k, (train_idx, valid_idx) in enumerate(skf.split(train, target)):
    print(f&quot;CV fold {k}&quot;)
    
    X_train, y_train = train[train_idx, :], target[train_idx]
    X_valid, y_valid = train[valid_idx, :], target[valid_idx]
    if config.reuse_autoencoder:
        print(&quot;restoring previously trained dae&quot;)
        autoencoder = load_model(f&quot;./dae_fold_{k}&quot;)
    else:
        autoencoder = autoencoder_fitting(X_train, X_valid,
                                        filename=f&#39;./dae_fold_{k}&#39;, 
                                        random_state=config.random_state)
    
    model, history = model_fitting(X_train, y_train, X_valid, y_valid,
                                autoencoder=autoencoder,
                                filename=f&quot;dnn_model_fold_{k}&quot;, 
                                random_state=config.random_state)
    
    val_preds = model.predict(X_valid, batch_size=128)
    best_score = eval_gini(y_true=y_valid, 
                           y_pred=np.ravel(val_preds))
    best_epoch = np.argmax(history.history[&#39;val_auc&#39;]) + 1
    print(f&quot;[best epoch is {best_epoch}]\tvalidation_0-gini_dnn: {best_score:0.5f}\n&quot;)
    
    metric_evaluations.append(best_score)
    preds += (model.predict(test, batch_size=128).ravel() / 
              skf.n_splits)
    oof[valid_idx] = model.predict(X_valid, batch_size=128).ravel()
    gpu_cleanup([autoencoder, model])</code></pre>
</div>
<p>As done with the LighGBM model, we can get an idea of the results by looking at the average fold normalized Gini coefficient.</p>
<div class="C0-SHCodePACKT">
<pre><code>print(f&quot;DNN CV normalized Gini coefficient: {np.mean(metric_evaluations):0.3f} ({np.std(metric_evaluations):0.3f})&quot;)</code></pre>
</div>
<p>The results won’t be quite in line with what previously obtained using the LightGBM.</p>
<div class="C0-SHConPACKT">
<pre><code>DNN CV Gini Normalized Score: 0.276 (0.015)</code></pre>
</div>
<p>Producing the submission and submitting it will result in a public score of about 0.27737 and a private score of about 0.28471 (results may vary wildly as we previously mentioned), not quite a high score.</p>
<div class="C0-SHCodePACKT">
<pre><code>submission[&#39;target&#39;] = preds
submission.to_csv(&#39;dnn_submission.csv&#39;)
oofs = pd.DataFrame({&#39;id&#39;:train_index, &#39;target&#39;:oof})
oofs.to_csv(&#39;dnn_oof.csv&#39;, index=False)</code></pre>
</div>
<p>The scarce results from the neural network seem to go by the adage that neural networks underperform in tabular problems. As Kagglers, anyway, we know that all models are useful for a successful placing on the leaderboard, we just need to figure out how to best use them. Surely, a neural network feed with an auto-encoder has worked out a solution less affected by noise in data and elaborated the information in a different way than a GBM.</p>
</section>
<section id="ensembling-the-results" class="level2" data-number="2.7">
<h2 data-number="2.7">Ensembling the results</h2>
<p>Now, having two models, what’s left is to mix them together and see if we can improve the results. As suggested by Jahrer we go straight for a blend of them, but we do not limit ourselves to producing just an average of the two (since our approach in the end has slightly differed from Jahrer’s one) but we will also try to get optimal weights for the blend. We start importing the out-of-fold predictions and having our evaluation function ready.</p>
<div class="C0-SHCodePACKT">
<pre><code>import pandas as pd
import numpy as np
from numba import jit
@jit
def eval_gini(y_true, y_pred):
    y_true = np.asarray(y_true)
    y_true = y_true[np.argsort(y_pred)]
    ntrue = 0
    gini = 0
    delta = 0
    n = len(y_true)
    for i in range(n-1, -1, -1):
        y_i = y_true[i]
        ntrue += y_i
        gini += y_i * delta
        delta += 1 - y_i
    gini = 1 - 2 * gini / (ntrue * (n - ntrue))
    return gini
lgb_oof = pd.read_csv(&quot;../input/workbook-lgb/lgb_oof.csv&quot;)
dnn_oof = pd.read_csv(&quot;../input/workbook-dae/dnn_oof.csv&quot;)
target = pd.read_csv(&quot;../input/porto-seguro-safe-driver-prediction/train.csv&quot;, usecols=[&#39;id&#39;,&#39;target&#39;]) </code></pre>
</div>
<p>Once done, we turn the out-of-fold predictions of the LightGBM and the neural network into ranks since the normalized Gini coefficient is sensible to rankings (as would be a ROC-AUC evaluation).</p>
<div class="C0-SHCodePACKT">
<pre><code>lgb_oof_ranks = (lgb_oof.target.rank() / len(lgb_oof))
dnn_oof_ranks = (dnn_oof.target.rank() / len(dnn_oof))</code></pre>
</div>
<p>Now we just test if, by combining the two models using different weights we can get a better evaluation on the out-of-fold data.</p>
<div class="C0-SHCodePACKT">
<pre><code>baseline = eval_gini(y_true=target.target, y_pred=lgb_oof_ranks)
print(f&quot;starting from a oof lgb baseline {baseline:0.5f}\n&quot;)
best_alpha = 1.0
for alpha in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:
    ensemble = alpha * lgb_oof_ranks + (1.0 - alpha) * dnn_oof_ranks
    score = eval_gini(y_true=target.target, y_pred=ensemble)
    print(f&quot;lgd={alpha:0.1f} dnn={(1.0 - alpha):0.1f} -&gt; {score:0.5f}&quot;)
    
    if score &gt; baseline:
        baseline = score
        best_alpha = alpha
        
print(f&quot;\nBest alpha is {best_alpha:0.1f}&quot;)</code></pre>
</div>
<p>When ready, by running the snippet we can get interesting results:</p>
<div class="C0-SHConPACKT">
<pre><code>starting from a oof lgb baseline 0.28850
lgd=0.1 dnn=0.9 -&gt; 0.27352
lgd=0.2 dnn=0.8 -&gt; 0.27744
lgd=0.3 dnn=0.7 -&gt; 0.28084
lgd=0.4 dnn=0.6 -&gt; 0.28368
lgd=0.5 dnn=0.5 -&gt; 0.28595
lgd=0.6 dnn=0.4 -&gt; 0.28763
lgd=0.7 dnn=0.3 -&gt; 0.28873
lgd=0.8 dnn=0.2 -&gt; 0.28923
lgd=0.9 dnn=0.1 -&gt; 0.28916
Best alpha is 0.8</code></pre>
</div>
<p>It seems that blending using a strong weight (0.8) on the LightGBM model and a weaker one (0.2) on the neural network may lead to an over performing model. We immediately try this hypothesis by setting a blend with the same weights for the models and the ideal weights that we have found out.</p>
<div class="C0-SHCodePACKT">
<pre><code>lgb_submission = pd.read_csv(&quot;../input/workbook-lgb/lgb_submission.csv&quot;)
dnn_submission = pd.read_csv(&quot;../input/workbook-dae/dnn_submission.csv&quot;)
submission = pd.read_csv(
&quot;../input/porto-seguro-safe-driver-prediction/sample_submission.csv&quot;)</code></pre>
</div>
<p>First we try the equal weights solution:</p>
<div class="C0-SHCodePACKT">
<pre><code>lgb_ranks = (lgb_submission.target.rank() / len(lgb_submission))
dnn_ranks = (dnn_submission.target.rank() / len(dnn_submission))
submission.target = lgb_ranks * 0.5 + dnn_ranks * 0.5
submission.to_csv(&quot;equal_blend_rank.csv&quot;, index=False)</code></pre>
</div>
<p>It leads to a public score of 0.28393 and a private score of 0.29093, which is around 50<sup>th</sup> position in the final leaderboard, a bit far from our expectations. Now let’s try using the weights the out-of-fold predictions helped us to find:</p>
<div class="C0-SHCodePACKT">
<pre><code>lgb_ranks = (lgb_submission.target.rank() / len(lgb_submission))
dnn_ranks = (dnn_submission.target.rank() / len(dnn_submission))
submission.target = lgb_ranks * best_alpha +  dnn_ranks * (1.0 - best_alpha)
submission.to_csv(&quot;blend_rank.csv&quot;, index=False)</code></pre>
</div>
<p>Here the results lead to a public score of 0.28502 and a private score of 0.29192 that turns out to be around the seventh position in the final leaderboard. A much better result indeed, because the LightGBM is a good one but it is probably missing some nuances in the data that can be provided as a favorable correction by adding some information from the neural network trained on the denoised data.</p>
<blockquote>
<p>As pointed out by CPMP in his solution (<a href="https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44614">https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44614</a>), depending on how to build your cross-validation, you can experience a “huge variation of Gini scores among folds”. For this reason, CPMP suggests to decrease the variance of the estimates by using many different seeds for multiple cross-validations and averaging the results.</p>
<blockquote>
<p>Exercise: as an exercise, try to modify the code we used in order to create more stable predictions, especially for the denoising auto-encoder.</p>
</blockquote>
</blockquote>
</section>
<section id="summary" class="level2" data-number="2.8">
<h2 data-number="2.8">Summary</h2>
<p>In this first chapter, you have dealt with a classical tabular competition. By reading the notebooks and discussions of the competition, we have come up with a simple solution involving just two models to be easily blended. In particular, we have offered an example on how to use a denoising auto-encoder in order to produce an alternative data processing particularly useful when operating with neural networks for tabular data. By understanding and replicating solutions on past competitions, you can quickly build up your core competencies on Kaggle competitions and be quickly able to perform consistently and highly in more recent competitions and challenges.</p>
<p>In the next chapter, we will explore another tabular competition from Kaggle, this time revolving about a complex prediction problem with time series.</p>
</section>
</section>
</body>
</html>
