- en: Chapter 7. Traffic Stops and Crash Locations – When Two Datasets Are Better
    Than One
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you remember from [Chapter 4](part0032_split_000.html#UGI01-a18db0be6c20485ba81f22e43ca13055
    "Chapter 4. Traffic Stops – Barking Up the Wrong Tree?"), *Traffic Stops – Barking
    Up the Wrong Tree?*, we used a decision tree to help us determine if a person
    received a ticket or a warning based on several seasonality factors like time
    of day, day of the week, and the like. Ultimately, we could not find a relationship.
    Your first inclination might be to throw out the dataset, which I think is a mistake
    because there might be data gold in them thar hills, but we are just using the
    wrong model. Also, if a single dataset is not profitable, I typically start augmenting
    that set with others to see if the combination of features will provide a more
    satisfactory answer. In this chapter, let's go back to our Code-4-Good group and
    see if we can both augment the traffic stop dataset and apply some different models
    that will help us formulate interesting questions and answers. Perhaps even if
    we are not asking the right questions, the computer can help us ask the right
    questions too.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To this point in the book, we have used several different models to answer
    our questions: linear regression, logistic regression, and kNN to name a few.
    Although different in their methodology, they share a common thread; we told the
    computer the answer (called the dependent or *y* variable) and then provided a
    series of features (called independent or *x* variables) that can be associated
    with that answer. Consider the following diagram for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Unsupervised learning](img/00085.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We then presented the computer with some combination of independent variables
    that it had not seen before and asked it to guess the answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Unsupervised learning](img/00086.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We then compared to the known answers via the test and, if it did a good job
    guessing, we would use the model in production:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Unsupervised learning](img/00087.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This methodology of telling the computer the answer ahead of time is called
    *supervised learning*. The term *supervised* is used because we provide the computer
    an answer explicitly and then tell it which model to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is another class of models that do not provide the answer to the computer.
    This class is called *unsupervised learning*. If your mental model of *unsupervised
    learning* is the chaos that engulfs a sixth grade class when a substitute teacher
    shows up the day before summer vacation, you are not far off. Okay, maybe not
    *that* bad. With unsupervised learning, we hand the computer a data frame of only
    attributes and ask it to tell us about the data. With that information, we can
    then narrow down the data that might help us make insightful business decisions.
    For example, let''s say you send this data frame to the computer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Unsupervised learning](img/00088.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'It might tell you that the data seems to cluster in two areas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Unsupervised learning](img/00089.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Although you might have eye-balled this relationship on this simple 2D data
    frame, the task becomes much harder, if not impossible, when adding more rows
    and features. In this chapter, we are going to use the k-means model to do this
    kind of clustering.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, we can use the computer to tell us what features are useful in a data
    frame and what features are just noise. For example, consider this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Hours Of Studying | Number Of Beers | StudyLocation |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 4 | Dorm |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 5 | Dorm |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 0 | Dorm |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 1 | Dorm |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 8 | Dorm |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 4 | Dorm |'
  prefs: []
  type: TYPE_TB
- en: Will the inclusion of **StudyLocation** in our data frame lead to any insights?
    The answer is no, because the values are all the same. In this chapter, we are
    going to use **Principle Component Analysis** (**PCA**) to this kind of feature
    filtering; it will tell us what features are important and what can be safely
    removed.
  prefs: []
  type: TYPE_NORMAL
- en: k-means
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned in the prior section, k-means is an unsupervised technique: observations
    are grouped based on mean of each cluster. Let''s take a look at k-means in action.
    Open up Visual Studio and create a new Visual F# Windows Library Project. Rename
    the `Script.fsx` file to `kmeans.fsx`. Open up the **NuGet Package Manager** console
    and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, go to the script and replace all of the contents with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let''s create an array of different beverages that are served at our
    local restaurant:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI, you will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Go back to the script and enter in some records of some patrons of the restaurant.
    We are using a float value because that is what Accord expects as an input.:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending that to the REPL gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You will notice that there are nine different patrons and each had three drinks.
    Patron number 1 had a Boone''s Farm, a Mad Dog, and a Night Train. With this data
    ready, let''s run a k-means against it. Enter this into the script file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send this to the FSI, you will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This output takes each patron and assigns them to one of the three clusters.
    For example, Patrons number 1 and 2 are in cluster number 0\. If we wanted more
    observations in each cluster, we could change the `numberOfClusters` like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'And sending that to the FSI would give the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that the computer does not try to label or otherwise assign any value
    to each of the clusters. The data scientist would then need to assign a meaningful
    value, if one is possible. Go back to the script and change the `numberOfClusters`
    back to three and resend to the FSI. Looking at the input array, we can say that
    the cluster assigned `0` is for fortified wine drinkers, cluster `1` is for hard
    liquor drinkers, and cluster `2` is for beer drinkers. However, sometimes you
    may not be able to tell what each cluster means by eye-balling the input array.
    In that case, you can ask Accord for some (limited) help. Enter this into the
    script file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI will give the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Notice the mean is mid-threes, which is a low number as we are counting from
    0 to 13\. We could say that category 0's label should be *Buckfast*-like drinkers,
    which is generally correct.
  prefs: []
  type: TYPE_NORMAL
- en: Principle Component Analysis (PCA)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another common task we can do with unsupervised learning is to help us throw
    out features that are not relevant. If you remember from the last chapter, we
    used a stepwise regression to determine the best features when building our model
    and then used Occum's Razor to toss insignificant features. One of the more common
    things you can do with PCA is use this unsupervised model as a way of picking
    the best features—the **principle components** of the frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add another script file to your project and name it `pca.fsx`. Add in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI gives the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the `sourceMatix` is a list of students that studied for a certain
    number of hours for an exam and the number of beers that they consumed before
    the exam. For example, the first student studied 2.5 hours and drank 2.4 beers.
    Unlike similar examples you have seen in the book so far, you will notice that
    there is not a dependent variable (Y) in this frame. We don't know if these students
    passed or not. But with just these features, we can determine which ones would
    be the most useful for an analysis. You might be saying to yourself, "How is that
    possible?" Without going too much into the math, the PCA will look at the variance
    of each of the variables under a series of scenarios. If the variable can explain
    differences, it is given a higher score. If it cannot, it is given a lower one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what PCA tells us about this dataset. Enter this code into the script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the REPL, we will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: You will notice that the output of the `ComponentMatrix` property is a 2 x 2
    array with the complementary value as a cross. In formal terms, this jagged array
    is called an eigenvector and the contents of the array are called eigenvalues.
    If you start working deeply with PCA, you will need to come up to speed with what
    those words mean and the implications of the values. For our purposes here, we
    can safely ignore these values (unless you want to toss around the word, eigenvalue,
    at your next family gathering).
  prefs: []
  type: TYPE_NORMAL
- en: 'The important property that we do need to pay attention to with PCA is the
    component proportions. Go back to the script file and enter this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the REPL gives the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: These values are important for our analysis. Notice how adding these two values
    together amounts to 100 percent? These percentages tell you the amount of variance
    (and therefore the amount of usefulness) in the data frame. In this case, the
    hours of studying is 96 percent of the variance with the amount of beer being
    only 4 percent, so if we wanted to use this data in some kind of analysis, we
    would certainly pick the hours of studying and safely discard the beer drinking.
    Note that if we increased the range of beers being drunk, the percentages would
    shift and perhaps we would want to use both variables. This is a fairly simple
    example with two features. PCA really shines when you have lots and lots of features
    and you need to determine their usefulness.
  prefs: []
  type: TYPE_NORMAL
- en: Traffic stop and crash exploration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the k-means and PCA theory under our belts, let''s see what we can do
    with open data. If you remember, we had a dataset for traffic stops. Let''s bring
    in two more datasets: the number of car crashes over the same time period, and
    also the amount of precipitation on the day of the crash/ticket.'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the script and the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Visual Studio, create a new Visual F# Library Project called `Hack4Good.Traffic`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Preparing the script and the data](img/00090.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the project is created, rename the `Script.fsx` file to `Clustering.fsx`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Preparing the script and the data](img/00091.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, open the NuGet Package Manager console and enter this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Inside `Clustering.fsx`, enter in the following code into the script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send this to the FSI, you will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'With this prep code out of the way, let''s bring down the stop data from the
    database. Put the following code into the script file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send it to the REPL, you will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'All of this data should be familiar to you from [Chapter 4](part0032_split_000.html#UGI01-a18db0be6c20485ba81f22e43ca13055
    "Chapter 4. Traffic Stops – Barking Up the Wrong Tree?"), *Traffic Stops – Barking
    Up the Wrong Tree?*. The only real difference is that there is now a geolocation
    type that holds both latitude and longitude. Notice that we assign whatever values
    are in the database first in this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, you will notice that we are making the values to three decimal point
    precision with the `Math.Round`. With this data local, let''s bring in the crash
    data. Enter the following code into the script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We have one more dataset we want to use: the traffic conditions for each day.
    Enter the following into the script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: With these three datasets available, let's combine the traffic stop and traffic
    crash datasets together into a single data frame to see if there is anything going
    on with geolocation.
  prefs: []
  type: TYPE_NORMAL
- en: Geolocation analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Go to the script file and add the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the REPL gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This code should look familiar to you by now; we are counting up the number
    of traffic stops by geolocation. For the first record, geopoint 35.789/-78.829
    had 178 traffic stops.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, go back to the script and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the REPL gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This code is identical to the stop data; we are counting up the number of traffic
    crashes by geolocation. For the first record, geopoint 35.790/-78.781 had 51 traffic
    crashes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our next step is to combine these two datasets into a single data frame that
    we can send to Accord. As for most things in F#, let''s use types and functions
    to achieve this. Go back to the script file and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send this to the FSI, you will see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'There is some new code here that can seem intimidating at first (at least,
    it was to me). We are using the LINQ class Enumerable''s *Join* method to join
    the `crashData` and `stopData` together. The *Join* method takes in several parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: The first dataset (in this case `crashData`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second dataset (in this case `stopData`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lambda that extracts the value from the first dataset, which we will use to
    join. In this case, the first item of the tuple, which is the geolocation value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lambda that extracts the value from the second dataset, which we will use
    to join. In this case, the first item of the tuple, which is the geolocation value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lambda that specifies what the output of the join operation will look like.
    In this case, it is the record type called `GeoTraffic` that we defined on the
    first line of this code block.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The key thing to realize about using the Join method is that it only keeps records
    that are in both datasets (an inner join to you SQL fans). This means if there
    is a geolocation that has one traffic ticket and no traffic stops, it is dropped
    from our analysis. If you want to do an outer join, there is the *GroupJoin* method
    that does this. Since we are only really interested in high-activity areas, an
    inner join seems more appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: 'With our data frame created, we are now ready to send the data to Accord''s
    k-means. If you remember, Accord''s k-means wants the input to be a jagged array
    of floats. Therefore, we have one last transformation. Go to the script file and
    enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending to the FSI, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Go back to the script file and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending to the REPL, we will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Woot! We have a k-means working on our traffic data. If you inspect each of
    the clusters, you will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We have three clusters. I pulled the means and the proportions from each of
    the clusters and put them into a spreadsheet like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Crashes | Stops | % of records |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 67.5 | 6.48 | 20.2% |'
  prefs: []
  type: TYPE_TB
- en: '| 11.69 | 2.62 | 76.3% |'
  prefs: []
  type: TYPE_TB
- en: '| 188.87 | 13.35 | 4.5% |'
  prefs: []
  type: TYPE_TB
- en: 'Looking at all the three clusters, it is notable that there are a lot more
    traffic crashes than stops. Also of interest is that the first and second cluster
    have about a 10:1 ratio of crashes to stops but the really high crash areas have
    a higher proportion of crashes to stops—about 14:1\. It seems reasonable to conclude
    that there are a few high-crash areas in town and the police are very active there,
    but they could be even more active. I would name each cluster after their activity
    level: (low, medium, and high). If the geolocation was not in our data frame (a
    majority of the points in town), we could call that *no activity*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, enter this into the script file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: We have seen `.zip` before. We are merging our data frame that contains the
    geolocation, number of stops, and number of crashes with the labels frame that
    came out k-means. Then we can look up a given geolocation and see its cluster
    assignment. For example, geolocation 35.790/-78.781 is in Cluster 1—or medium
    activity.
  prefs: []
  type: TYPE_NORMAL
- en: PCA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a pretty good sense of the data via k-means, let's see if we
    can use PCA to uncover even more insights in our traffic data. Instead of location,
    let's look at date. As we found in [Chapter 4](part0032_split_000.html#UGI01-a18db0be6c20485ba81f22e43ca13055
    "Chapter 4. Traffic Stops – Barking Up the Wrong Tree?"), *Traffic Stops – Barking
    Up the Wrong Tree?*, using our decision tree, there was nothing we could conclude
    with different bins of date/time and our traffic tickets. Perhaps augmenting the
    stop data with crash and weather will lead to something.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go back into the `Clustering.fsx` script file and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI gives the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This code is very much like the code we already wrote when creating the `crashData`
    for k-means. In this case, we are counting up traffic crashes by `DayOfYear`.
    `DayOfYear` assigns each day of the year an index value. For example, January
    1 gets a 1, January 2 gets a 2 and December 31 gets a 365 or 366, depending on
    if it is a leap year or not. Notice that it is one-based because `DateTime.DayOfYear`
    is one-based.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go back into the script file and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the FSI gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can probably guess, this sums up the number of traffic stops by the
    day of the year. Pressing onward, go to the script file and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending this to the REPL gives us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Just like crash and stop data, this creates a dataset with the amount of precipitation
    by day of year. You will notice that the data was already at the date level (sometimes
    called the level of atomicity), so an `Array.map` was used to transform the date;
    we don't need to use `countBy`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the initial datasets created, we now need a way to join all three together.
    The `Enumerable.Join` method that we used in the k-means example will not do here,
    so we will have to build our own joiner function. Go into the script file and
    enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send this to the FSI, you will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a pretty complicated function signature. It might help if I added parameter
    hints to the method as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send this to the FSI, you will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This should be slightly more accessible but less generic, which is fine because
    all of our datasets (crash, stops, and weather) are arrays of `int*int`. Reading
    the output, we see that `getItem` is a function that takes in one parameter named
    dataset that is an array of `int` tuples `(int * int)[]` and another parameter
    named item that is an int. The function then attempts to find the tuple in the
    array whose `fst` has the same value as the item. If it is found, it returns the
    second value of the tuple. If it does not find the item in the array, it returns
    `0`.
  prefs: []
  type: TYPE_NORMAL
- en: This function will work well for all three of our datasets (crash, stops, and
    weather) because all three only hold records for days they have observations.
    For traffic stops, this is not a problem because there was at least one traffic
    stop on each day of the year. However, there were 16 days where there were no
    traffic crashes recorded, so `stopData` has 350 records and there were over 250
    days where there was not any precipitation, so `weatherData` only has 114 records.
  prefs: []
  type: TYPE_NORMAL
- en: Since the first way of creating `getItem` is more generic and idiomatic to F#,
    I will use it for the remaining part of the chapter. Both the examples are in
    the example script file that you can download.
  prefs: []
  type: TYPE_NORMAL
- en: 'Going back to the script, enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send this to the REPL, you will see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The first line creates a record type that contains the number of crashes, stops,
    and precipitation for the day. I used rain as the field name because we rarely
    get snow in North Carolina and I want to rub it in to any reader who lives up
    north. Of course, when we do get snow, it is borderline Armageddon.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next block of code is where we create our final data frame. First, an integer
    array is created with every day of the year. A mapper function is then applied
    that calls `getItem` three times for each item of the array: the first time for
    `crashData`, the second for stop data, and finally for weather data. The results
    are put into the `TrafficDay` record.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With the data frame setup, we are now ready for Accord. Go to the script file
    and enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send it to the REPL, you will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a jagged array that Accord wants. Go back to the script and enter the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'When you send this to the REPL, you will get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: This shows that 94 percent of the variance in our data frame is from crashes,
    not stops or the weather. This is interesting because common wisdom is that, once
    it rains (or <gasp> snows <gasp>) in North Carolina, traffic accidents spike.
    Although that might make a good press story, this one-year sample does not bear
    it out.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We now have a couple of models that point to some interesting ideas:'
  prefs: []
  type: TYPE_NORMAL
- en: There are a few locations that account for most of the traffic crashes and tickets
    in town
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weather is not as important as you might think
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this knowledge, we are ready to put machine learning to work for us.
  prefs: []
  type: TYPE_NORMAL
- en: The Code-4-Good application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's create a Windows application that helps people drive more safely. In addition,
    let's make the application "smart" so that it will progressively get more accurate.
    Let's start in Visual Studio with the project you have already created.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning assembly
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Go into the **Solution** **Explorer** and rename `Library1.fs` to `TrafficML.fs`.
    Add a reference to `System.Data`, `System.Data.Entity`, `System.Data.Linq`, and
    `FSharp.Data.TypeProviders`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Machine learning assembly](img/00092.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Adding references
  prefs: []
  type: TYPE_NORMAL
- en: 'Go into the `TrafficML.fs` file and enter the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: I know it feels weird not to send code you just wrote to FSI, but there is no
    way of getting immediate feedback of the code you wrote in a compliable file.
    We will be addressing this in the next chapter when we talk TDD. Until then, just
    compile the project to make sure you are on the right track.
  prefs: []
  type: TYPE_NORMAL
- en: 'Back to the `TrafficML.fs` file, enter the following wall of code or copy it
    from the book''s download:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: This code is very similar to the k-means code we wrote in the `Clustering.fsx`
    script file. Notice that all the work of getting the data, shaping it, and running
    a k-means on it happens in the constructor of the `TrafficML` type. This means
    every time you create a new instance of the class from another location, you are
    making database calls and running the model. Also, notice that the connection
    string is hardcoded into the `SqlEntity` type provider for the type but then passed
    in via the constructor parameter when `GetDataContext()` is actually called. This
    allows you to move to code around environments (dev/test/prod). The downside is
    that you need to have your DEV environment exposed always so that the type is
    generated. One way to avoid this is to hardcode your Entity Framework `.edmx`/schema
    into the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go back to the `TrafficML.fs` file and enter in the following function to the
    `TrafficML` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: This does a search of the geolocations. If there is a match, the cluster is
    returned. If there is no match, *a-1* is returned, signifying that there was not
    a match. We now have enough to make a first pass at creating a real time "smart"
    traffic application.
  prefs: []
  type: TYPE_NORMAL
- en: The UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the **Solution Explorer**, add a new Visual C# WPF Application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00093.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'After the project is created, add a reference from the C# UI project to the
    F# one, `System.Configuration` and `System.Device`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00094.jpeg)![The UI](img/00095.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As a quick preparatory note, you are supposed to follow MVVM and command relay
    patterns when writing WFP applications which we will not cover in this book. This
    is a book about machine learning, not coddling humans via a delightful UI, so
    I code up enough of the UI just to get it to work. If you are interested in doing
    WPF following best practices, consider *Windows Presentation Foundation 4.5 Cookbook*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the UI project, open up the `MainWindow.xaml` file, locate the `Grid`
    element, and enter in this XAML inside the grid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, open up `MainWindow.xaml.cs` and enter the following `using` statements
    to the block of `using` at the top of the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Your file should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00096.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Inside the `MainWindow` class, enter three class-level variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Your file should look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00097.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, in the `MainWindow()` constructor, add in the following code below `InitializeComponent()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Your file should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00098.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, create the `Watcher_PositionChanged` method for the event handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create a loop to refresh the `MachineLearning` model every minute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, add an event handler placeholder for the button clicks on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'If you collapse the code to definitions (*CTRL* + *M*, *L*), your code should
    look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00099.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, go into **Solution Explorer**, right-click to add a new **Application
    Configuration** file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00100.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Adding new Application Configuration file
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside that `app.config` file, replace the contents with this XML (replace
    the connection string with your connection string if you are using a local instance
    of the database):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Go to **Solution** **Explorer** and make the UI project the startup project:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00101.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Compile your project. If all is well, try to run it. You should get a warning
    dialog like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00102.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'And then you will get a screen like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The UI](img/00103.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Once you completely take in the awesomeness of the user experience, stop running
    the application. So far, this is pretty good. If we put this application on a
    location-aware device (like a GPS) in the car and drive around, the status bar
    will warn us if we are within a quarter mile of a geolocation that might have
    a crash or stop risk. However, if we want to give ourselves more of a heads up,
    we need to add a bit more of code.
  prefs: []
  type: TYPE_NORMAL
- en: Adding distance calculations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Go back to the F# project and open up the `TrafficML.fs` file. Locate the last
    line of the constructor. It looks like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Below this line, enter the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: These two functions allow us to calculate the distance between geolocations.
    Since the earth is curved, we can't simply subtract the latitudes and longitudes
    between the two geolocations. The Haversine formula is the most common way to
    do this calculation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the end of the file and add the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: What we are doing is overloading the `GetCluster` function with an additional
    parameter called distance. Using this input distance, we can calculate how far
    it is between the geolocation parameter and every geolocation in our `trafficGeo`
    array. If there are any matches, we sort by the highest number of cluster (`sortByDescending`)
    and return it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go back to our UI project and open the `MainWindow.xaml.cs` file and locate
    the `Watcher_PositionChanged` method. Find the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Replace it with the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: We now have a two mile heads-up to any problem area on the roads.
  prefs: []
  type: TYPE_NORMAL
- en: Augmenting with human observations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is one more thing we want to do to our UI. If you look at some of the
    *crowd source* road applications like Waze, they provide real-time notifications.
    Our app bases its classification based on historical data. However, if we were
    driving down the street in an area that was classified as *low risk*, and we saw
    a traffic crash, we would want to elevate the location to a *high risk*. Ideally,
    all the users of our application would get this update and override the model's
    classification of the geolocation (at least for the time being) and then we would
    update our database so that, as we retrain our model, the information gets more
    accurate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the `notifyButton_Click` event holder and replace `//TODO` with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The compiler will complain to you because we have not implemented the `AddGeolocationToClusterOverride`
    yet. Go back over to the F# project and open the `TrafficML.fs` file. At the very
    bottom, add the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have a way of updating the database for any override. Note that you
    will not be able to write to the shared database on Azure that was created for
    this book, but you will be able to write to your local copy. As a final step,
    go up to where we created the `trafficGeo` on the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'Replace that line with the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: This block goes to the database and pulls down all overrides that occurred within
    the last 5 minutes and places them in the overrides array. It then creates a function
    called `checkForOverride` that takes in the `geoTraffic` value. If the latitude
    and longitude match the override table, the `geoTraffic` value is replaced with
    a new value that has the override value assigned by the database and not from
    the k-means model. If no match is found, the original value is returned. Finally,
    we pipe this function to the creation of `trafficGeo`. Note that if you try and
    execute this on our shared server, it will throw an exception because you don't
    have rights to write to the database. Hopefully, though, the intention is clear
    with this example. With that, we have a real-time system where we combine machine
    learning and human observations to give our end user the best possible predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We covered a lot of ground in this chapter. We looked at k-means and PCA to
    help us find hidden relationships in our traffic datasets. We then built an application
    that took advantage of the insights we gleaned to make drivers more aware and,
    hopefully, safer. This application is unique because it blended both real-time
    machine learning modeling and human observations to provide the best possible
    outcome for the driver.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to look at some of the limitations of our
    coding so far in this book and see if we can improve on both model and feature
    selection.
  prefs: []
  type: TYPE_NORMAL
