- en: Introducing CUDA and Getting Started with CUDA
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 CUDA 并开始使用 CUDA
- en: This chapter gives you a brief introduction to CUDA architecture and how it
    has redefined the parallel processing capabilities of GPUs. The application of
    CUDA architecture in real-life scenarios will be demonstrated. This chapter will
    serve as a starting guide for software developers who want to accelerate their
    applications by using general-purpose GPUs and CUDA. The chapter describes development
    environments used for CUDA application development and how the CUDA toolkit can
    be installed on all operating systems. It covers how basic code can be developed
    using CUDA C and executed on Windows and Ubuntu operating systems.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章为您简要介绍了 CUDA 架构及其如何重新定义了 GPU 的并行处理能力。本章将演示 CUDA 架构在实际场景中的应用。对于想要通过使用通用 GPU
    和 CUDA 来加速其应用程序的软件开发人员，本章将作为入门指南。本章描述了用于 CUDA 应用程序开发的开发环境，以及如何在所有操作系统上安装 CUDA
    工具包。它涵盖了如何使用 CUDA C 开发基本代码，并在 Windows 和 Ubuntu 操作系统上执行。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introducing CUDA
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 CUDA
- en: Applications of CUDA
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA 的应用
- en: CUDA development environments
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA 开发环境
- en: Installing CUDA toolkit on Windows, Linux, and macOS
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Windows、Linux 和 macOS 上安装 CUDA 工具包
- en: Developing simple code, using CUDA C
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发简单代码，使用 CUDA C
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires familiarity with the basic C or C++ programming language.
    All the code used in this chapter can be downloaded from the following GitHub
    link: [https://github.com/bhaumik2450/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA
    /Chapter1](https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA/).
    The code can be executed on any operating system, though it is only tested on
    Windows 10 and Ubuntu 16.04.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章要求您熟悉基本的 C 或 C++ 编程语言。本章中使用的所有代码都可以从以下 GitHub 链接下载：[https://github.com/bhaumik2450/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA/Chapter1](https://github.com/PacktPublishing/Hands-On-GPU-Accelerated-Computer-Vision-with-OpenCV-and-CUDA/).
    代码可以在任何操作系统上执行，尽管它仅在 Windows 10 和 Ubuntu 16.04 上进行了测试。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，了解代码的实际应用：
- en: '[http://bit.ly/2PTQMUk](http://bit.ly/2PTQMUk) [](http://bit.ly/2PTQMUk)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2PTQMUk](http://bit.ly/2PTQMUk) [](http://bit.ly/2PTQMUk)'
- en: Introducing CUDA
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 CUDA
- en: '**Compute Unified Devi****ce Architecture** (**CUDA**) is a very popular parallel
    computing platform and programming model developed by NVIDIA. It is only supported
    on NVIDIA GPUs. OpenCL is used to write parallel code for other types of GPUs
    such as AMD and Intel, but it is more complex than CUDA. CUDA allows creating
    massively parallel applications running on **graphics processing units** (**GPU**s)
    with simple programming APIs. Software developers using C and C++ can accelerate
    their software application and leverage the power of GPUs by using CUDA C or C++.
    Programs written in CUDA are similar to programs written in simple C or C++ with
    the addition of keywords needed to exploit parallelism of GPUs. CUDA allows a
    programmer to specify which part of CUDA code will execute on the CPU and which
    part will execute on the GPU.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**统一计算设备架构**（**CUDA**）是由 NVIDIA 开发的一个非常流行的并行计算平台和编程模型。它仅支持 NVIDIA GPU。OpenCL
    用于为其他类型的 GPU（如 AMD 和 Intel）编写并行代码，但它比 CUDA 复杂。CUDA 允许通过简单的编程 API 在 **图形处理单元**（**GPU**s）上创建大规模并行应用程序。使用
    C 和 C++ 的软件开发人员可以通过使用 CUDA C 或 C++ 来加速他们的软件应用程序，并利用 GPU 的强大功能。用 CUDA 编写的程序与简单的
    C 或 C++ 程序类似，只是增加了用于利用 GPU 并行性的关键字。CUDA 允许程序员指定 CUDA 代码的哪一部分将在 CPU 上执行，哪一部分将在
    GPU 上执行。'
- en: The next section describes the need for parallel computing and how CUDA architecture
    can leverage the power of the GPU, in detail.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将详细描述并行计算的需求以及 CUDA 架构如何利用 GPU 的强大功能。
- en: Parallel processing
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行处理
- en: In recent years, consumers have been demanding more and more functionalities
    on a single hand held device. So, there is a need for packaging more and more
    transistors on a small area that can work quickly and consume minimal power. We
    need a fast processor that can carry out multiple tasks with a high clock speed,
    a small area, and minimum power consumption. Over many decades, transistor sizing
    has seen a gradual decrease resulting in the possibility of more and more transistors
    being packed on a single chip. This has resulted in a constant rise of the clock
    speed. However, this situation has changed in the last few years with the clock
    speed being more or less constant. So, what is the reason for this? Have transistors
    stopped getting smaller? The answer is no. The main reason behind clock speed
    being constant is high power dissipation with high clock rate. Small transistors
    packed in a small area and working at high speed will dissipate large power, and
    hence it is very difficult to keep the processor cool. As clock speed is getting
    saturated in terms of development, we need a new computing paradigm to increase
    the performance of the processors. Let's understand this concept by taking a small
    real-life example.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，消费者对单一手持设备的功能需求越来越多。因此，需要在小面积上封装越来越多的晶体管，以便快速工作并消耗最小的功率。我们需要一个高速处理器，它可以在高时钟速度、小面积和最小功耗的情况下执行多个任务。在几十年的时间里，晶体管尺寸逐渐减小，使得在单个芯片上可以封装越来越多的晶体管成为可能。这导致了时钟速度的持续提升。然而，在过去的几年里，这种情况发生了变化，时钟速度大致保持不变。那么，这是为什么？晶体管停止变得更小了吗？答案是否定的。时钟速度保持不变的主要原因是在高时钟速率下的高功耗。在小型区域内紧密排列并高速工作的小型晶体管会消耗大量功率，因此很难保持处理器的冷却。随着时钟速度在开发方面趋于饱和，我们需要一种新的计算范式来提高处理器的性能。让我们通过一个小型的现实生活例子来理解这个概念。
- en: 'Suppose you are told to dig a very big hole in a small amount of time. You
    will have the following three options to complete this work in time:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你被告知在很短的时间内挖一个非常大的洞。你有以下三种选择来按时完成这项工作：
- en: You can dig faster.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以挖得更快。
- en: You can buy a better shovel.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以购买一把更好的铲子。
- en: You can hire more diggers, who can help you complete the work.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以雇佣更多的挖掘工，他们可以帮助你完成工作。
- en: If we can draw a parallel between this example and a computing paradigm, then
    the first option is similar to having a faster clock. The second option is similar
    to having more transistors that can do more work per clock cycle. But, as we have
    discussed in the previous paragraph, power constraints have put limitations on
    these two steps. The third option is similar to having many smaller and simpler
    processors that can carry out tasks in parallel. A GPUfollows this computing paradigm.
    Instead of having one big powerful processor that can perform complex tasks, it
    has many small and simple processors that can get work done in parallel. The details
    of GPU architecture are explained in the next section.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能在本例与计算范式之间建立类比，那么第一种选择类似于拥有更快的时钟。第二种选择类似于拥有更多晶体管，每个时钟周期可以完成更多的工作。但是，正如我们在上一段中讨论的，功率限制对这些两个步骤都施加了限制。第三种选择类似于拥有许多小型且简单的处理器，它们可以并行执行任务。GPU遵循这种计算范式。它不是拥有一个能够执行复杂任务的大而强大的处理器，而是拥有许多小型且简单的处理器，它们可以并行完成工作。GPU架构的细节将在下一节中解释。
- en: Introducing GPU architecture and CUDA
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍GPU架构和CUDA
- en: GeForce 256 was the first GPU developed by NVIDIA in 1999\. Initially, GPUs
    were only used for rendering high-end graphics on monitors. They were only used
    for pixel computations. Later on, people realized that if GPUs can do pixel computations,
    then they would also be able to do other mathematical calculations. Nowadays,
    GPUs are used in many applications other than rendering graphics. These kinds
    of GPUs are called **General-Purpose GPUs** (**GPGPUs**).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: GeForce 256是NVIDIA在1999年开发的第一个GPU。最初，GPU仅用于在显示器上渲染高端图形。它们仅用于像素计算。后来，人们意识到如果GPU能够进行像素计算，那么它们也能够进行其他数学计算。如今，GPU被用于许多除了渲染图形之外的应用。这类GPU被称为**通用型GPU**（**GPGPU**）。
- en: The next question that may have come to your mind is the difference between
    the hardware architecture of a CPU and a GPU that allows it to carry out parallel
    computation. A CPU has a complex control hardware and less data computation hardware.
    Complex control hardware gives a CPU flexibility in performance and a simple programming
    interface, but it is expensive in terms of power. On the other hand, a GPU has
    simple control hardware and more hardware for data computation that gives it the
    ability for parallel computation. This structure makes it more power-efficient.
    The disadvantage is that it has a more restrictive programming model. In the early
    days of GPU computing, graphics APIs such as OpenGL and DirectX were the only
    way to interact with GPUs. This was a complex task for normal programmers, who
    were not familiar with OpenGL or DirectX. This led to the development of CUDA
    programming architecture, which provided an easy and efficient way of interacting
    with the GPUs. More details about CUDA architecture are given in the next section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 可能接下来出现在你脑海中的问题是，CPU 和 GPU 的硬件架构差异，这使它们能够执行并行计算。CPU 拥有复杂的控制硬件和较少的数据计算硬件。复杂的控制硬件使
    CPU 在性能上具有灵活性，并提供了简单的编程接口，但从功耗角度来看是昂贵的。另一方面，GPU 拥有简单的控制硬件和更多用于数据计算硬件，这使得它能够进行并行计算。这种结构使其更加节能。缺点是它有一个更加限制性的编程模型。在
    GPU 计算的早期阶段，图形 API，如 OpenGL 和 DirectX，是唯一与 GPU 交互的方式。这对不熟悉 OpenGL 或 DirectX 的普通程序员来说是一个复杂的任务。这导致了
    CUDA 编程架构的发展，它提供了一种简单高效的方式与 GPU 交互。关于 CUDA 架构的更多细节将在下一节中给出。
- en: Normally, the performance of any hardware architecture is measured in terms
    of latency and throughput. *Latency* is the time taken to complete a given task,
    while *throughput* is the amount of the task completed in a given time. These
    are not contradictory concepts. More often than not, improving one improves the
    other. In a way, most hardware architectures are designed to improve either latency
    or throughput. For example, suppose you are standing in a queue at the post office.
    Your goal is to complete your work in a small amount of time, so you want to improve
    latency, while an employee sitting at a post office window wants to see more and
    more customers in a day. So, the employee's goal is to increase the throughput.
    Improving one will lead to an improvement in the other, in this case, but the
    way both sides look at this improvement is different.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，任何硬件架构的性能都是通过延迟和吞吐量来衡量的。*延迟* 是完成给定任务所需的时间，而 *吞吐量* 是在给定时间内完成的任务量。这些概念并不矛盾。大多数情况下，提高一个会提高另一个。从某种意义上说，大多数硬件架构都是为了提高延迟或吞吐量而设计的。例如，假设你正在邮局排队。你的目标是尽可能快地完成工作，所以你想要提高延迟，而坐在邮局窗口的员工则希望每天看到越来越多的客户。因此，员工的目标是增加吞吐量。提高一个将导致另一个的提高，在这种情况下，但双方看待这种提高的方式是不同的。
- en: In the same way, normal sequential CPUs are designed to optimize latency, while
    GPUs are designed to optimize throughput. CPUs are designed to execute all instructions
    in the minimum time, while GPUs are designed to execute more instructions in a
    given time. This design concept of GPUs makes them very useful in image processing
    and computer vision applications, which we are targeting in this book, because
    we don't mind a delay in the processing of a single pixel. What we want is that
    more pixels should be processed in a given time, which can be done on a GPU.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，普通的顺序 CPU 是为了优化延迟而设计的，而 GPU 是为了优化吞吐量而设计的。CPU 是为了以最短的时间执行所有指令，而 GPU 是为了在给定时间内执行更多的指令。这种
    GPU 的设计概念使它们在图像处理和计算机视觉应用中非常有用，这是我们在这本书中要针对的应用，因为我们不介意单个像素的处理延迟。我们想要的更多是，在给定时间内处理更多的像素，这可以在
    GPU 上完成。
- en: So, to summarize, parallel computing is what we need if we want to increase
    computational performance at the same clock speed and power requirement. GPUs
    provide this capability by having lots of simple computational units working in
    parallel. Now, to interact with the GPU and to take advantage of its parallel
    computing capabilities, we need a simple parallel programming architecture, which
    is provided by CUDA.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总结来说，如果我们想在相同的时钟速度和功耗下提高计算性能，就需要并行计算。GPU 通过拥有大量并行工作的简单计算单元来提供这种能力。现在，为了与
    GPU 交互并利用其并行计算能力，我们需要一个简单的并行编程架构，这正是 CUDA 提供的。
- en: CUDA architecture
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA 架构
- en: This section covers basic hardware modifications done in GPU architecture and
    the general structure of software programs developed using CUDA. We will not discuss
    the syntax of the CUDA program just yet, but we will cover the steps to develop
    the code. The section will also cover some basic terminology that will be followed
    throughout this book.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了在 GPU 架构中进行的硬件修改以及使用 CUDA 开发的软件程序的一般结构。我们目前不会讨论 CUDA 程序的语法，但我们将介绍编写代码的步骤。本节还将涵盖一些将在整本书中使用的术语。
- en: CUDA architecture includes several new components specifically designed for
    general-purpose computations in GPUs, which were not present in earlier architectures.
    It includes the unified shedder pipeline which allows all **arithmetic** **logical
    units** (**ALU**s) present on a GPU chip to be marshaled by a single CUDA program.
    The ALUs are also designed to comply with IEEE floating-point single and double-precision
    standards so that it can be used in general-purpose applications. The instruction
    set is also tailored to general purpose computation and not specific to pixel
    computations. It also allows arbitrary read and write access to memory. These
    features make CUDA GPU architecture very useful in general purpose applications.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA 架构包括专为在 GPU 上进行通用计算而设计的几个新组件，这些组件在早期架构中并不存在。它包括统一的舍入流水线，该流水线允许 GPU 芯片上所有的
    **算术** **逻辑单元**（**ALU**s）由单个 CUDA 程序进行调度。这些 ALU 也被设计为符合 IEEE 浮点单精度和双精度标准，以便在通用应用程序中使用。指令集也针对通用计算进行了定制，而不是针对像素计算。它还允许对内存进行任意的读写访问。这些特性使得
    CUDA GPU 架构在通用应用程序中非常有用。
- en: All GPUs have many parallel processing units called *cores*. On the hardware
    side, these cores are divided into streaming processors and **streaming multiprocessors**
    (**SM**s). The GPU has a grid of these streaming multiprocessors. On the software
    side, a CUDA program is executed as a series of multiple threads running in parallel.
    Each thread is executed on a different core. The GPU can be viewed as a combination
    of many blocks, and each block can execute many threads. Each block is bound to
    a different SM on the GPU. How mapping is done between a block and SM is not known
    to a CUDA programmer, but it is known and done by a scheduler. The threads from
    same block can communicate with one another. The GPU has a hierarchical memory
    structure that deals with communication between threads inside one block and multiple
    blocks. This will be dealt with in detail in the upcoming chapters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 GPU 都有许多称为 *核心* 的并行处理单元。在硬件方面，这些核心被分为流处理器和 **流多处理器**（**SM**s）。GPU 有一个由这些流多处理器组成的网格。在软件方面，CUDA
    程序作为一系列并行运行的多个线程执行。每个线程在不同的核心上执行。GPU 可以看作是许多块的组合，每个块可以执行许多线程。每个块绑定到 GPU 上的不同 SM。块与
    SM 之间的映射方式对 CUDA 程序员来说是未知的，但这是由调度器知道并完成的。来自同一块的所有线程可以相互通信。GPU 有一个处理线程之间通信的分层内存结构，包括一个块内和多个块之间的通信。这将在接下来的章节中详细介绍。
- en: As a programmer, you will be curious to know what will be the programming model
    in CUDA and how the code will understand whether it should be executed on the
    CPU or the GPU. For this book, we will assume that we have a computing platform
    comprising a CPU and a GPU. We will call a CPU and its memory the *host* and a
    GPU and its memory a *device*. A CUDA code contains the code for both the host
    and the device. The host code is compiled on CPU by a normal C or C++ compiler,
    and the device code is compiled on the GPU by a GPU compiler. The host code calls
    the device code by something called a *kernel* call. It will launch many threads
    in parallel on a device. The count of how many threads to be launched on a device
    will be provided by the programmer.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名程序员，你可能想知道 CUDA 中的编程模型是什么，代码将如何理解它应该在 CPU 还是 GPU 上执行。对于这本书，我们将假设我们有一个由 CPU
    和 GPU 组成的计算平台。我们将把 CPU 及其内存称为 *主机*，把 GPU 及其内存称为 *设备*。CUDA 代码包含主机和设备的代码。主机代码由常规的
    C 或 C++ 编译器在 CPU 上编译，设备代码由 GPU 编译器在 GPU 上编译。主机代码通过所谓的 *内核调用* 来调用设备代码。它将在设备上并行启动许多线程。要启动的线程数量将由程序员提供。
- en: 'Now, you might ask how this device code is different from a normal C code.
    The answer is that it is similar to a normal sequential C code. It is just that
    this code is executed on a greater number of cores in parallel. However, for this
    code to work, it needs data on the device''s memory. So, before launching threads,
    the host copies data from the host memory to the device memory. The thread works
    on data from the device''s memory and stores the result on the device''s memory.
    Finally, this data is copied back to the host memory for further processing. To
    summarize, the steps to develop a CUDA C program are as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可能会问这种设备代码与普通C代码有何不同。答案是，它与普通的顺序C代码相似。只是这种代码是在更多的核心上并行执行的。然而，为了使此代码工作，它需要在设备内存上的数据。因此，在启动线程之前，主机将数据从主机内存复制到设备内存。线程在设备内存上的数据上工作，并将结果存储在设备内存中。最后，这些数据被复制回主机内存以进行进一步处理。总之，开发CUDA
    C程序的基本步骤如下：
- en: Allocate memory for data in the host and device memory.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主机和设备内存中为数据分配内存。
- en: Copy data from the host memory to the device memory.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据从主机内存复制到设备内存。
- en: Launch a kernel by specifying the degree of parallelism.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过指定并行度来启动内核。
- en: After all the threads are finished, copy the data back from the device memory
    to the host memory.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在所有线程完成后，将数据从设备内存复制回主机内存。
- en: Free up all memory used on the host and the device.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 释放主机和设备上使用的所有内存。
- en: CUDA applications
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA应用
- en: 'CUDA has seen an unprecedented growth in the last decade. It is being used
    in a wide variety of applications in various domains. It has transformed research
    in multiple fields. In this section, we will look at some of these domains and
    how CUDA is accelerating growth in each domain:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，CUDA经历了前所未有的增长。它被用于各种领域的大量应用中。它已经改变了多个领域的研究。在本节中，我们将探讨一些这些领域以及CUDA如何加速每个领域的增长：
- en: '**Computer vision applications**: Computer vision and image processing algorithms
    are computationally intensive. With more and more cameras capturing images at
    high definition, there is a need to process these large images in real time. With
    the CUDA acceleration of these algorithms, applications such as image segmentation,
    object detection, and classification can achieve a real-time frame rate performance
    of more than 30 frames per second. CUDA and the GPU allow the faster training
    of deep neural networks and other deep-learning algorithms; this has transformed
    research in computer vision. NVIDIA is developing several hardware platforms such
    as Jetson TX1, Jetson TX2, and Jetson TK1, which can accelerate computer vision
    applications. NVIDIA drive platform is also one of the platforms that is made
    for autonomous drive applications.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算机视觉应用**: 计算机视觉和图像处理算法计算密集。随着越来越多的摄像头以高清格式捕捉图像，需要实时处理这些大图像。通过这些算法的CUDA加速，图像分割、目标检测和分类等应用可以实现每秒超过30帧的实时帧率性能。CUDA和GPU允许更快地训练深度神经网络和其他深度学习算法；这已经改变了计算机视觉的研究。NVIDIA正在开发多个硬件平台，如Jetson
    TX1、Jetson TX2和Jetson TK1，这些平台可以加速计算机视觉应用。NVIDIA驱动平台也是为自动驾驶应用而设计的平台之一。'
- en: '**Medical imaging**: The medical imaging field is seeing widespread use of
    GPUs and CUDA in reconstruction and the processing of MRI images and **Computed
    tomography** (**CT**) images. It has drastically reduced the processing time for
    these images. Nowadays, there are several devices that are shipped with GPUs,
    and several libraries are available to process these images with CUDA acceleration.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医学成像**: 医学成像领域正在广泛使用GPU和CUDA进行MRI图像和**计算机断层扫描**（**CT**）图像的重建和处理。这极大地缩短了这些图像的处理时间。如今，有几种设备配备了GPU，并且有几个库可用于使用CUDA加速处理这些图像。'
- en: '**Financial computing**: There is a need for better data analytics at a lower
    cost in all financial firms, and this will help in informed decision-making. It
    includes complex risk calculation and initial and lifetime margin calculation,
    which have to be done in real time. GPUs help financial firms to do these kinds
    of analytics in real time without adding too much overhead cost.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**金融计算**: 所有金融公司都需要在较低的成本下进行更好的数据分析，这将有助于做出明智的决策。它包括复杂的风险评估和初始及终身保证金计算，这些必须在实时完成。GPU帮助金融公司实时进行这些类型的分析，而不会增加太多的开销成本。'
- en: '**Life science, bioinformatics, and computational chemistry**: Simulating DNA
    genes, sequencing, and protein docking are computationally intensive tasks that
    need high computation resources. GPUs help in this kind of analysis and simulation.
    GPUs can run common molecular dynamics, quantum chemistry, and protein docking
    applications more than five times faster than normal CPUs.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生命科学、生物信息学和计算化学**：模拟DNA基因、测序和蛋白质对接是计算密集型任务，需要高计算资源。GPU有助于这种分析和模拟。GPU可以比普通CPU快五倍以上运行常见的分子动力学、量子化学和蛋白质对接应用程序。'
- en: '**Weather research and forecasting**: Several weather prediction applications,
    ocean modeling techniques, and tsunami prediction techniques utilize GPU and CUDA
    for faster computation and simulations, compared to CPUs.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**气象研究和预报**：与CPU相比，几个天气预报应用程序、海洋模拟技术和海啸预测技术利用GPU和CUDA进行更快的计算和模拟。'
- en: '**Electronics Design Automation (EDA)**: Due to the increasing complexity in
    VLSI technology and the semiconductor fabrication process, the performance of
    EDA tools is lagging behind in this technological progress. It leads to incomplete
    simulations and missed functional bugs. Therefore, the EDA industry has been seeking
    faster simulation solutions. GPU and CUDA acceleration are helping this industry
    to speed up computationally intensive EDA simulations, including functional simulation,
    placement and routing, Signal integrity and electromagnetics, SPICE circuit simulation,
    and so on.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子设计自动化（EDA）**：由于VLSI技术和半导体制造工艺的日益复杂，EDA工具的性能落后于这种技术进步。这导致模拟不完整和遗漏功能错误。因此，EDA行业一直在寻求更快的模拟解决方案。GPU和CUDA加速正在帮助这个行业加快计算密集型EDA模拟，包括功能模拟、布局和布线、信号完整性与电磁学、SPICE电路模拟等。'
- en: '**Government and defense**: GPU and CUDA acceleration is also widely used by
    governments and militaries. Aerospace, defense, and intelligence industries are
    taking advantage of CUDA acceleration in converting large amounts of data into
    actionable information.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**政府和军事**：GPU和CUDA加速也广泛应用于政府和军队。航空航天、国防和情报行业正在利用CUDA加速将大量数据转换为可操作信息。'
- en: CUDA development environment
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA开发环境
- en: 'To start developing an application using CUDA, you will need to set up the
    development environment for it. There are some prerequisites for setting up a
    development environment for CUDA. These include the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用CUDA开发应用程序，您需要为其设置开发环境。设置CUDA开发环境有一些先决条件。这些包括以下内容：
- en: A CUDA-supported GPU
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持CUDA的GPU
- en: An NVIDIA graphics card driver
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA显卡驱动程序
- en: A standard C compiler
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准C编译器
- en: A CUDA development kit
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA开发套件
- en: How to check for these prerequisites and install them is discussed in the following
    sub section.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如何检查这些先决条件并安装它们将在以下子节中讨论。
- en: CUDA-supported GPU
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持CUDA的GPU
- en: 'As discussed earlier, CUDA architecture is only supported on NVIDIA GPUs. It
    is not supported on other GPUs such as AMD and Intel. Almost all GPUs developed
    by NVIDIA in the last decade support CUDA architecture and can be used to develop
    and execute CUDA applications. A detailed list of CUDA-supported GPUs can be found
    on the NVIDIA website: [https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus).
    If you can find your GPU in this list, you will be able to run CUDA applications
    on your PC.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，CUDA架构仅支持NVIDIA GPU。它不支持AMD和Intel等其他GPU。过去十年中几乎所有的NVIDIA GPU都支持CUDA架构，可以用于开发和执行CUDA应用程序。CUDA支持的GPU详细列表可以在NVIDIA网站上找到：[https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus)。如果您能在列表中找到您的GPU，您将能够在您的PC上运行CUDA应用程序。
- en: 'If you don''t know which GPU is on your PC, then you can find it by following
    these steps:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不知道您的PC上安装了哪种GPU，可以通过以下步骤找到它：
- en: '**On windows:**'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在Windows上**：'
- en: In the Start menu, type *device manager* and press *Enter*.
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始菜单中，键入*设备管理器*并按*Enter*。
- en: In the device manager, expand the display adaptors. There, you will find the
    name of your NVIDIA GPU.
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在设备管理器中展开显示适配器。在那里，您将找到您的NVIDIA GPU的名称。
- en: '**On Linux:**'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在Linux上**：'
- en: Open Terminal.
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端。
- en: Run `sudo lshw -C video`.
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`sudo lshw -C video`。
- en: This will list information regarding your graphics card, usually including its
    make and model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这将列出有关您的显卡的信息，通常包括其制造商和型号。
- en: '**On macOS:**'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在macOS上**：'
- en: Go to the Apple Menu | About this Mac | More info.
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往苹果菜单 | 关于本机 | 更多信息。
- en: Select Graphics/Displays under Contents list. There, you will find the name
    of your NVIDIA GPU.
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在内容列表下选择“图形/显示”。在那里，你可以找到你的 NVIDIA GPU 名称。
- en: If you have a CUDA-enabled GPU, then you are good to proceed to the next step.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个启用了 CUDA 的 GPU，那么你可以继续下一步。
- en: NVIDIA graphics card driver
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NVIDIA 显卡驱动程序
- en: 'If you want to communicate with NVIDIA GPU hardware, then you will need a system
    software for it. NVIDIA provides a device driver to communicate with the GPU hardware.
    If the NVIDIA graphics card is properly installed, then these drivers are installed
    automatically with it on your PC. Still, it is good practice to check for driver
    updates periodically from the NVIDIA website: [http://www.nvidia.in/Download/index.aspx?lang=en-in](http://www.nvidia.in/Download/index.aspx?lang=en-in).
    You can select your graphics card and operating system for driver download from
    this link.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要与 NVIDIA GPU 硬件进行通信，那么你需要为其安装系统软件。NVIDIA 提供了一个用于与 GPU 硬件通信的设备驱动程序。如果 NVIDIA
    显卡安装正确，那么这些驱动程序会自动与你的 PC 一起安装。然而，定期从 NVIDIA 网站检查驱动程序更新是一个好习惯：[http://www.nvidia.in/Download/index.aspx?lang=en-in](http://www.nvidia.in/Download/index.aspx?lang=en-in)。你可以通过此链接选择你的显卡和操作系统来下载驱动程序。
- en: Standard C compiler
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准C编译器
- en: 'Whenever you are running a CUDA application, it will need two compilers: one
    for GPU code and one for CPU code. The compiler for the GPU code will come with
    an installation of CUDA toolkit, which will be discussed in the next section.
    You also need to install a standard C compiler for executing CPU code. There are
    different C compilers based on the operating systems:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 每当你运行 CUDA 应用程序时，它将需要两个编译器：一个用于 GPU 代码，另一个用于 CPU 代码。GPU 代码的编译器将随 CUDA 工具包的安装一起提供，这将在下一节中讨论。你还需要安装一个标准的
    C 编译器来执行 CPU 代码。根据操作系统，有不同的 C 编译器：
- en: '**On Windows**: For all Microsoft Windows editions, it is recommended to use
    Microsoft Visual Studio C compiler. It comes with Microsoft Visual Studio and
    can be downloaded from its official website: [https://www.visualstudio.com/downloads/](https://www.visualstudio.com/downloads/).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在 Windows 上**：对于所有 Microsoft Windows 版本，建议使用 Microsoft Visual Studio C 编译器。它包含在
    Microsoft Visual Studio 中，并且可以从其官方网站下载：[https://www.visualstudio.com/downloads/](https://www.visualstudio.com/downloads/)。'
- en: The express edition for commercial applications needs to be purchased, but you
    can use community editions for free in non-commercial applications. For running
    the CUDA application, install Microsoft Visual Studio with a Microsoft Visual
    Studio C compiler selected. Different CUDA versions support different Visual Studio
    editions, so you can refer to the NVIDIA CUDA website for Visual Studio version
    support.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 商业应用的精简版需要购买，但在非商业应用中你可以免费使用社区版。为了运行 CUDA 应用程序，请安装带有 Microsoft Visual Studio
    C 编译器的 Microsoft Visual Studio。不同的 CUDA 版本支持不同的 Visual Studio 版本，因此你可以参考 NVIDIA
    CUDA 网站以了解 Visual Studio 版本支持情况。
- en: '**On Linux**: Mostly, all Linux distributions come with a standard **GNU C
    Complier** (**GCC**), and hence it can be used to compile CPU code for CUDA applications.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在 Linux 上**：大多数 Linux 发行版都自带标准的 **GNU C 编译器**（**GCC**），因此它可以用来编译 CUDA 应用程序的
    CPU 代码。'
- en: '**On Mac**: On the Mac operating system, you can install a GCC compiler by
    downloading and installing Xcode for macOS. It is freely available and can be
    downloaded from Apple''s website:'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在 Mac 上**：在 Mac 操作系统上，你可以通过下载和安装 macOS 的 Xcode 来安装 GCC 编译器。它是免费提供的，可以从苹果的网站下载：'
- en: '[https://developer.apple.com/xcode/](https://developer.apple.com/xcode/)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://developer.apple.com/xcode/](https://developer.apple.com/xcode/)'
- en: CUDA development kit
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA 开发套件
- en: CUDA needs a GPU compiler for compiling GPU code. This compiler comes with a
    CUDA development toolkit. If you have an NVIDIA GPU with the latest driver update
    and have installed a standard C compiler for your operating system, you are good
    to proceed to the final step of installing the CUDA development toolkit. A step-by-step
    guide for installing the CUDA toolkit is discussed in the next section.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA 需要一个 GPU 编译器来编译 GPU 代码。这个编译器包含在 CUDA 开发工具包中。如果你有一个带有最新驱动程序更新的 NVIDIA GPU，并且已经为你的操作系统安装了标准的
    C 编译器，那么你可以继续到最后一步，安装 CUDA 开发工具包。下一节将讨论安装 CUDA 工具包的逐步指南。
- en: Installing the CUDA toolkit on all operating systems
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在所有操作系统上安装 CUDA 工具包
- en: 'This section covers instructions on how to install CUDA on all supported platforms.
    It also describes steps to verify installation. While installing CUDA, you can
    choose between a network installer and an offline local installer. A network installer
    has a lower initial download size, but it needs an internet connection while installing.
    A local offline installer has a higher initial download size. The steps discussed
    in this book are for local installation. A CUDA toolkit can be downloaded for
    Windows, Linux, and macOS for both 32-bit and 64-bit architecture from the following
    link: [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads).'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了如何在所有支持的平台上安装 CUDA 的说明。它还描述了验证安装的步骤。在安装 CUDA 时，您可以选择网络安装程序或离线本地安装程序。网络安装程序具有较小的初始下载大小，但在安装过程中需要互联网连接。本地离线安装程序具有较大的初始下载大小。本书中讨论的步骤适用于本地安装。可以从以下链接下载适用于
    Windows、Linux 和 macOS 的 CUDA 工具包，包括 32 位和 64 位架构：[https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)。
- en: After downloading the installer, refer to the following steps for your particular
    operating system. CUDAx.x is used as notation in the steps, where x.x indicates
    the version of CUDA that you have downloaded.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 下载安装程序后，根据您的特定操作系统参考以下步骤。步骤中使用 CUDAx.x 作为表示法，其中 x.x 表示您已下载的 CUDA 版本。
- en: Windows
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Windows
- en: 'This section covers the steps to install CUDA on Windows, which are as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了在 Windows 上安装 CUDA 的步骤，如下所示：
- en: Double-click on the installer. It will ask you to select the folder where temporary
    installation files will be extracted. Select the folder of your choice. It is
    recommended to keep this as the default.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 双击安装程序。它将要求您选择临时安装文件将被提取的文件夹。选择您选择的文件夹。建议保持默认设置。
- en: Then, the installer will check for system compatibility. If your system is compatible,
    you can follow the on screen prompt to install CUDA. You can choose between an
    express installation (default) and a custom installation. A custom installation
    allows you to choose which features of CUDA to install. It is recommended to select
    the express default installation.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，安装程序将检查系统兼容性。如果您的系统兼容，您可以按照屏幕提示安装 CUDA。您可以选择快速安装（默认）或自定义安装。自定义安装允许您选择要安装的
    CUDA 功能。建议选择快速默认安装。
- en: The installer will also install CUDA sample programs and the CUDA Visual Studio
    integration.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装程序还将安装 CUDA 示例程序和 CUDA Visual Studio 集成。
- en: Please make sure you have Visual Studio installed before running this installer.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行此安装程序之前，请确保您已安装 Visual Studio。
- en: 'To confirm that the installation is successful, the following aspects should
    be ensured:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认安装成功，以下方面应得到保证：
- en: All the CUDA samples will be located at `C:\ProgramData\NVIDIA Corporation\CUDA
    Samples\vx.x` if you have chosen the default path for installation.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您选择了默认安装路径，所有 CUDA 示例都将位于 `C:\ProgramData\NVIDIA Corporation\CUDA Samples\vx.x`。
- en: To check installation, you can run any project.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要检查安装，您可以运行任何项目。
- en: We are using the device query project located at `C:\ProgramData\NVIDIA Corporation\CUDA
    Samples\vx.x\1_Utilities\deviceQuery`.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用位于 `C:\ProgramData\NVIDIA Corporation\CUDA Samples\vx.x\1_Utilities\deviceQuery`
    的设备查询项目。
- en: Double-click on the `*.sln` file of your Visual Studio edition. It will open
    this project in Visual Studio.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 双击您 Visual Studio 版本的 `*.sln` 文件。它将在 Visual Studio 中打开此项目。
- en: 'Then you can click on the local Windows debugger in Visual Studio. If the build
    is successful and the following output is displayed, then the installation is
    complete:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以在 Visual Studio 中点击本地 Windows 调试器。如果构建成功并显示以下输出，则表示安装完成：
- en: '![](img/a44f83ca-c438-4b21-8901-493ff5c0a47a.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a44f83ca-c438-4b21-8901-493ff5c0a47a.png)'
- en: Linux
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Linux
- en: This section covers the steps to install CUDA on Linux distributions. In this
    section, the installation of CUDA in Ubuntu, which is a popular Linux distribution,
    is discussed using distribution-specific packages or using the `apt-get` command
    (which is specific to Ubuntu).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了在 Linux 发行版上安装 CUDA 的步骤。在本节中，使用特定于发行版的软件包或使用 `apt-get` 命令（仅适用于 Ubuntu）讨论了在流行的
    Linux 发行版 Ubuntu 中的 CUDA 安装。
- en: 'The steps to install CUDA using the `*.deb` installer downloaded from the CUDA
    website are as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用从 CUDA 网站下载的 `*.deb` 安装程序安装 CUDA 的步骤如下：
- en: 'Open Terminal and run the `dpkg` command, which is used to install packages
    in Debian-based systems:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端并运行 `dpkg` 命令，该命令用于在基于 Debian 的系统中安装软件包：
- en: '[PRE0]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Install the CUDA public GPG key using the following command:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装 CUDA 公共 GPG 密钥：
- en: '[PRE1]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, update the `apt` repository cache using the following command:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用以下命令更新 `apt` 仓库缓存：
- en: '[PRE2]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then you can install CUDA using the following command:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以使用以下命令安装 CUDA：
- en: '[PRE3]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Include the CUDA installation path in the PATH environment variable using the
    following command:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 PATH 环境变量中包含 CUDA 安装路径：
- en: If you have not installed CUDA at default locations, you need to change the
    path to point at your installation location.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有在默认位置安装 CUDA，您需要更改路径以指向您的安装位置。
- en: '[PRE4]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Set the `LD_LIBRARY_PATH` environment variable:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 `LD_LIBRARY_PATH` 环境变量：
- en: '[PRE5]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can also install the CUDA toolkit by using the `apt-get` package manager,
    available with Ubuntu OS. You can run the following command in Terminal:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过使用 Ubuntu OS 中的 `apt-get` 软件包管理器来安装 CUDA 工具包。您可以在终端中运行以下命令：
- en: '[PRE6]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: To check whether the CUDA GPU compiler has been installed, you can run the `nvcc
    -V` command from Terminal. It calls the GCC compiler for C code and the NVIDIA
    PTX compiler for the CUDA code.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查 CUDA GPU 编译器是否已安装，您可以从终端运行 `nvcc -V` 命令。它调用 GCC 编译器来编译 C 代码，以及 NVIDIA PTX
    编译器来编译 CUDA 代码。
- en: 'You can install the NVIDIA Nsight Eclipse plugin, which will give the GUI Integrated
    Development Environment for executing CUDA programs, using the following command:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令安装 NVIDIA Nsight Eclipse 插件，它将为执行 CUDA 程序提供 GUI 集成开发环境：
- en: '[PRE7]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After installation, you can run the `deviceQuery` project located at `~/NVIDIA_CUDA-x.x_Samples`.
    If the CUDA toolkit is installed and configured correctly, the output for `deviceQuery`
    should look similar to the following:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，您可以在 `~/NVIDIA_CUDA-x.x_Samples` 位置运行 `deviceQuery` 项目。如果 CUDA 工具包已正确安装和配置，`deviceQuery`
    的输出应类似于以下内容：
- en: '![](img/08ce73ed-45be-4f7a-bf0c-1da1060bb208.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/08ce73ed-45be-4f7a-bf0c-1da1060bb208.png)'
- en: Mac
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mac
- en: 'This section covers steps to install CUDA on macOS. It needs the `*.dmg` installer
    downloaded from the CUDA website. The steps to install after downloading the installer
    are as follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了在 macOS 上安装 CUDA 的步骤。需要从 CUDA 网站下载的 `*.dmg` 安装程序。下载安装程序后的安装步骤如下：
- en: Launch the installer and follow the onscreen prompt to complete the installation.
    It will install all prerequisites, CUDA, toolkit, and CUDA samples.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动安装程序，按照屏幕上的提示完成安装。它将安装所有先决条件、CUDA、工具包和 CUDA 示例。
- en: 'Then, you need to set environment variables to point at CUDA installation using
    the following commands:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您需要使用以下命令设置环境变量，以指向 CUDA 安装位置：
- en: If you have not installed CUDA at the default locations, you need to change
    the path to point at your installation location.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有在默认位置安装 CUDA，您需要更改路径以指向您的安装位置。
- en: '[PRE8]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Run the script: `cuda-install-samples-x.x.sh`. It will install CUDA samples
    with write permissions.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行脚本：`cuda-install-samples-x.x.sh`。它将以写权限安装 CUDA 示例。
- en: After it has completed, you can go to `bin/x86_64/darwin/release` and run the
    `deviceQuery` project. If the CUDA toolkit is installed and configured correctly,
    it will display your GPU's device properties.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，您可以去 `bin/x86_64/darwin/release` 并运行 `deviceQuery` 项目。如果 CUDA 工具包已正确安装和配置，它将显示您的
    GPU 的设备属性。
- en: A basic program in CUDA C
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA C 中的基本程序
- en: In this section, we will start learning CUDA programming by writing a very basic
    program using CUDA C. We will start by writing a `Hello, CUDA!` program in CUDA
    C and execute it. Before going into the details of code, one thing that you should
    recall is that host code is compiled by the standard C compiler and that the device
    code is executed by an NVIDIA GPU compiler. A NVIDIA tool feeds the host code
    to a standard C compiler such as Visual Studio for Windows and a GCC compiler
    for Ubuntu, and it uses macOS for execution. It is also important to note that
    the GPU compiler can run CUDA code without any device code. All CUDA code must
    be saved with a `*.cu` extension.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过编写一个非常基础的 CUDA C 程序来开始学习 CUDA 编程。我们将从编写一个 `Hello, CUDA!` 程序开始，并执行它。在深入代码细节之前，您应该记住的是，主机代码由标准
    C 编译器编译，而设备代码由 NVIDIA GPU 编译器执行。一个 NVIDIA 工具将主机代码传递给标准 C 编译器，例如 Windows 的 Visual
    Studio 和 Ubuntu 的 GCC 编译器，并使用 macOS 来执行。还重要的是要注意，GPU 编译器可以在没有任何设备代码的情况下运行 CUDA
    代码。所有 CUDA 代码都必须以 `*.cu` 扩展名保存。
- en: 'The following is the code for `Hello, CUDA!`:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为 `Hello, CUDA!` 的代码：
- en: '[PRE9]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If you look closely at the code, it will look very similar to that of the simple
    `Hello, CUDA!` program written in C for the CPU execution. The function of this
    code is also similar. It just prints `Hello, CUDA!` on Terminal or the command
    line. So, two questions that should come to your mind is: how is this code different,
    and where is the role of CUDA C in this code? The answer to these questions can
    be given by closely looking at the code. It has two main differences, compared
    to code written in simple C:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细查看代码，它看起来会非常类似于为 CPU 执行编写的简单 `Hello, CUDA!` C 程序。这段代码的功能也是相似的。它只是在终端或命令行上打印
    `Hello, CUDA!`。所以，应该出现在你脑海中的两个问题是：这段代码有什么不同，CUDA C 在这段代码中扮演什么角色？这些问题的答案可以通过仔细查看代码来给出。与简单
    C 编写的代码相比，它有两个主要的不同点：
- en: An empty function called `myfirstkernel` with `__global__` prefix
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有 `__global__` 前缀的空函数 `myfirstkernel`
- en: Call the `myfirstkernel` function with `<< <1,1> >>`
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `<< <1,1> >>` 调用 `myfirstkernel` 函数
- en: '`__global__` is a qualifier added by CUDA C to standard C. It tells the compiler
    that the function definition that follows this qualifier should be complied to
    run on a device, rather than a host. So, in the previous code, `myfirstkernel`
    will run on a device instead of a host, though, in this code, it is empty.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`__global__` 是 CUDA C 添加到标准 C 中的一个限定符。它告诉编译器，此限定符之后的功能定义应该被编译在设备上运行，而不是在主机上。因此，在前面的代码中，`myfirstkernel`
    将在设备上运行而不是在主机上，尽管在这个代码中它是空的。'
- en: Now where will the main function run? The NVCC compiler will feed this function
    to host the C compiler, as it is not decorated by the `global` keyword, and hence
    the `main` function will run on the host.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，主函数将在哪里运行？NVCC 编译器会将此函数传递给宿主 C 编译器，因为它没有被 `global` 关键字装饰，因此 `main` 函数将在宿主上运行。
- en: The second difference in the code is the call to the empty `myfirstkernel` function
    with some angular brackets and numeric values. This is a CUDA C trick to call
    device code from host code. It is called a *kernel* call. The details of a kernel
    call will be explained in later chapters. The values inside the angular brackets
    indicate arguments we want to pass from the host to the device at runtime. Basically,
    it indicates the number of blocks and the number of threads that will run in parallel
    on the device. So, in this code, `<< <1,1> >>` indicates that `myfirstkernel`
    will run on one block and one thread or block on the device. Though this is not
    an optimal use of device resources, it is a good starting point to understand
    the difference between code executed on the host and code executed on a device.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 代码中的第二个不同点是调用空的 `myfirstkernel` 函数，并带有一些尖括号和数字值。这是从宿主代码调用设备代码的 CUDA C 技巧。这被称为
    *kernel* 调用。kernel 调用的细节将在后面的章节中解释。尖括号内的值表示我们希望在运行时从宿主传递到设备的参数。基本上，它表示将在设备上并行运行的块和线程的数量。因此，在这个代码中，`<<
    <1,1> >>` 表示 `myfirstkernel` 将在设备上的一个块和一个线程或块上运行。尽管这不是设备资源的最佳使用，但它是一个理解在宿主上执行和在设备上执行的代码之间差异的好起点。
- en: Again, to revisit and revise the `Hello, CUDA!` code, the `myfirstkernel` function
    will run on a device with one block and one thread or block. It will be launched
    from the host code inside the main function by a method called **kernel launch**.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '再次，为了回顾和修改 `Hello, CUDA!` 代码，`myfirstkernel` 函数将在一个块和一个线程或块上运行在设备上。它将通过在主函数内部的宿主代码中调用一种称为
    **kernel launch** 的方法来启动。 '
- en: After writing code, how will you execute this code and see the output? The next
    section describes the steps to write and execute the `Hello, CUDA!` code on Windows
    and Ubuntu.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 编写代码后，你将如何执行此代码并查看输出？下一节将描述在 Windows 和 Ubuntu 上编写和执行 `Hello, CUDA!` 代码的步骤。
- en: Steps for creating a CUDA C program on Windows
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Windows 上创建 CUDA C 程序的步骤
- en: 'This section describes the steps to create and execute a basic CUDA C program
    on Windows using Visual Studio. The steps are as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了在 Windows 上使用 Visual Studio 创建和执行基本 CUDA C 程序的步骤。步骤如下：
- en: Open Microsoft Visual Studio.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Microsoft Visual Studio。
- en: Go to File | New | Project.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往文件 | 新建 | 工程。
- en: Select NVIDIA | CUDA 9.0 | CUDA 9.0 Runtime.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 NVIDIA | CUDA 9.0 | CUDA 9.0 Runtime。
- en: Give your desired name to the project and click on OK.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给项目命名你想要的名称，然后点击确定。
- en: It will create a project with a sample `kernel.cu` file. Now open this file
    by double-clicking on it.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将创建一个包含示例 `kernel.cu` 文件的工程。现在通过双击它来打开此文件。
- en: Delete existing code from the file and write the given code earlier.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文件中删除现有的代码，并写入之前给出的代码。
- en: 'Build the project from the Build tab and press *Ctrl* + *F5* to debug the code.
    If everything works correctly, you will see `Hello, CUDA!` displayed on the command
    line, as shown here:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从“构建”选项卡构建项目，并按 *Ctrl* + *F5* 调试代码。如果一切正常，你将在命令行看到 `Hello, CUDA!` 如此显示：
- en: '![](img/08c42110-ea31-453a-8396-80935ab8d035.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/08c42110-ea31-453a-8396-80935ab8d035.png)'
- en: Steps for creating a CUDA C program on Ubuntu
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Ubuntu 上创建 CUDA C 程序的步骤
- en: 'This section describes the steps to create and execute a basic CUDA C program
    on Ubuntu using the Nsight Eclipse plugin. The steps are as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了在 Ubuntu 上使用 Nsight Eclipse 插件创建和执行基本 CUDA C 程序的步骤。步骤如下：
- en: Open Nsight by opening Terminal and typing nsight into it.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在终端中打开终端并输入 nsight 来打开 Nsight。
- en: Go to File | New |CUDA C/C++ Projects.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往文件 | 新建 | CUDA C/C++ 项目。
- en: Give your desired name to the project and click on OK.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给项目起一个你喜欢的名字，然后点击确定。
- en: It will create a project with a sample file. Now open this file by double-clicking
    on it.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将创建一个带有示例文件的项目。现在通过双击它来打开此文件。
- en: Delete the existing code from the file and write the given code earlier.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文件中删除现有的代码，并写入之前给出的代码。
- en: 'Run the code by pressing the play button. If everything works correctly, you
    will see `Hello, CUDA!` displayed on Terminal as shown here:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过按播放按钮运行代码。如果一切正常，你将在终端看到 `Hello, CUDA!` 如此显示：
- en: '![](img/3ae3b999-ffe4-4963-9239-b44031d6e601.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3ae3b999-ffe4-4963-9239-b44031d6e601.png)'
- en: Summary
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: To summarize, in this chapter, you were introduced to CUDA and briefed upon
    the importance of parallel computing. Applications of CUDA and GPUs in various
    domains were discussed at length. The chapter described the hardware and software
    setup required to execute CUDA applications on your PCs. It gave a step-by-step
    procedure to install CUDA on local PCs.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在本章中，你被介绍了 CUDA 并简要介绍了并行计算的重要性。详细讨论了 CUDA 和 GPU 在各个领域的应用。本章描述了在个人电脑上执行
    CUDA 应用所需的硬件和软件设置。它提供了一个逐步的过程，用于在本地电脑上安装 CUDA。
- en: The last section gave a starting guide for application development in CUDA C
    by developing a simple program and executing it on Windows and Ubuntu.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一节通过开发一个简单的程序并在 Windows 和 Ubuntu 上执行它，为 CUDA C 应用程序开发提供了一个入门指南。
- en: In the next chapter, we will build on this knowledge of programming in CUDA
    C. You will be introduced to parallel computing using CUDA C by way of several
    practical examples to show how it is faster compared to normal programming. You
    will also be introduced to the concepts of threads and blocks and how synchronization
    is performed between multiple threads and blocks.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将基于 CUDA C 编程的知识来构建。你将通过几个实际示例了解如何使用 CUDA C 进行并行计算，以展示它相对于常规编程的快速性。你还将了解线程和块的概念以及如何在多个线程和块之间进行同步。
- en: Questions
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Explain three methods to increase the performance of your computing hardware.
    Which method is used to develop GPUs?
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释三种提高计算硬件性能的方法。哪种方法用于开发 GPU？
- en: 'True or false: Improving latency will improve throughput.'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正误判断：提高延迟将提高吞吐量。
- en: 'Fill in the blanks: CPUs are designed to improve ___ and GPUs are designed
    to improve __ .'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填空：CPU 设计用于提高___，而 GPU 设计用于提高___。
- en: Take an example of traveling from one place to another that is 240 km away.
    You can take a car that can accommodate five people, with a speed of 60 kmph or
    a bus that can accommodate 40 people, with a speed of 40 kmph. Which option will
    provide better latency, and which option will provide better throughput?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以从一个地方到另一个地方旅行为例，距离为 240 公里。你可以选择一辆可以容纳五人的汽车，速度为 60 公里/小时，或者一辆可以容纳 40 人的公共汽车，速度为
    40 公里/小时。哪种选项将提供更好的延迟，哪种选项将提供更好的吞吐量？
- en: Explain the reasons that make GPU and CUDA particularly useful in computer vision
    applications.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释使 GPU 和 CUDA 在计算机视觉应用中特别有用的原因。
- en: 'True or False: A CUDA compiler cannot compile code with no device code.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正误判断：CUDA 编译器不能编译没有设备代码的代码。
- en: In the `Hello, CUDA!` example discussed in this chapter, will the `printf` statement
    be executed by the host or the device?
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章讨论的 `Hello, CUDA!` 示例中，`printf` 语句将由主机还是设备执行？
