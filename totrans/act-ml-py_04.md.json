["```py\npip install datasets transformers huggingface_hub && apt-get install git-lfs\n```", "```py\nfrom transformers import pipeline\nimport torch\nfrom datasets import load_dataset\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\n```", "```py\nsentiment_pipeline = pipeline(\"sentiment-analysis\")\ndata = [\"I love you\", \"I hate you\"]\nsentiment_pipeline(data)\n```", "```py\n[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n{'label': 'NEGATIVE', 'score': 0.9991129040718079}]\n```", "```py\nimdb = load_dataset(\"imdb\")\n```", "```py\nsmall_dataset = imdb[\"train\"].shuffle(seed=120).\n    select([i for i in list(range(5))])\nprint(small_dataset)\n```", "```py\nDataset({\n    features: ['text', 'label'],\n    num_rows: 5\n})\n```", "```py\nsmall_dataset[-1]\n```", "```py\n{'text': \"Shot into car from through the windscreen, someone is playing someone else their latest song, someone else didn't react, according to the voice-over. I just wonder how that came to be made. There were too many scenes in this movie that I wondered about how come a camera was there. If the scenes shot where the Warhols descended on a BJM post-party are true then that was inexcusable exploitation to the max, if not, then it was a total fabrication, either way it made me uncomfortable, if that was the purpose? All the way thru this movie I kept wondering how the footage came about. Taken at face value, a nice portrait of the (tortured) genius we all believe ourselves to be.\",\n'label': 1}\n```", "```py\nclasses = ['NEGATIVE', 'POSITIVE']\nresults = []\nfor review in small_dataset['text']:\nresults.append(classes.index(sentiment_pipeline(review)[0]['label']))\nprint(results)\n```", "```py\n[1, 0, 0, 1, 0]\n```", "```py\ny_true = np.array(small_dataset['label'])\nx_true = np.array(small_dataset['text'])\n```", "```py\n# Compare to true labels\nmismatches = np.where(results != y_true)[0]\n# Return mismatched samples\nX_mismatched = x_true[mismatches]\ny_mismatched = y_true[mismatches]\nprint(f\"There are {len(X_mismatched)} mismatches: {X_mismatched}\")\n```", "```py\nThere are 2 mismatches: ['\"Meatball Machine\" has got to be one of the most complex ridiculous, awful and over-exaggerated sci-fi horror films that I have ever came across. It is about good against evil and a coming-of-age tale, with the aim of to entertain with bloody, sleazy and humorous context. Because of that the violence isn\\'t particularly gruesome and it doesn\\'t make you squirm, but the gratuitous bloodletting and nudity does run freely. The performances by Issei Takahashi and Toru Tezuka is the worst i have seen, if that was not enough it is also directed by an unheard of director called Yudai Yamaguchi. This movie just have it all, it is bad to the bone!, A must see for every b-movie freak!!!... Simply: an enjoying and rare gem.'\n\"Shot into car from through the windscreen, someone is playing someone else their latest song, someone else didn't react, according to the voice-over. I just wonder how that came to be made. There were too many scenes in this movie that I wondered about how come a camera was there. If the scenes shot where the Warhols descended on a BJM post-party are true then that was inexcusable exploitation to the max, if not, then it was a total fabrication, either way it made me uncomfortable, if that was the purpose? All the way thru this movie I kept wondering how the footage came about. Taken at face value, a nice portrait of the (tortured) genius we all believe ourselves to be.\"]\n```", "```py\ndummy_annotator_labels = ['positive', 'negative', 'positive', \n    'positive', 'positive']\ndummy_known_labels = ['negative', 'negative', 'positive', 'positive', \n    'negative']\n```", "```py\naccuracy = accuracy_score(dummy_annotator_labels, dummy_known_labels)\nprint(f\"Annotator accuracy: {accuracy*100:.2f}%\")\nkappa = cohen_kappa_score(dummy_annotator_labels, dummy_known_labels)\nprint(f\"Cohen's Kappa: {kappa:.3f}\")\n```", "```py\nAnnotator accuracy: 60.00%\nCohen's Kappa: 0.286\n```", "```py\ndummy_annotator_labels_1 = ['positive', 'negative', 'positive', \n    'positive', 'positive']\ndummy_annotator_labels_2 = ['positive', 'negative', 'positive', \n    'negative', 'positive']\ndummy_annotator_labels_3 = ['negative', 'negative', 'positive', \n    'positive', 'negative']\n```", "```py\ndf = pd.DataFrame({\n    \"Annotator1\": dummy_annotator_labels_1,\n    \"Annotator2\": dummy_annotator_labels_2,\n    \"Annotator3\": dummy_annotator_labels_3\n})\n```", "```py\ndf[\"MajorityVote\"] = df.mode(axis=1)[0]\nprint(df[\"MajorityVote\"])\n```", "```py\n0    positive\n1    negative\n2    positive\n3    positive\n4    positive\n```", "```py\n    dataset = load_dataset('imdb')\n    ```", "```py\n    dummy_unlabeled_dataset_with_predictions_from_a_model \\\n        dataset['train']\n    df = pd.DataFrame(\n        dummy_unlabeled_dataset_with_predictions_from_a_model)\n    ```", "```py\n    n_label_0 = df[df['label'] == 0].shape[0]\n    n_label_1 = df[df['label'] == 1].shape[0]\n    ```", "```py\n    nb_samples = 1000\n    n_sample_0 = int(0.8 * nb_samples)\n    n_sample_1 = int(0.2 * nb_samples)\n    sample_0 = df[df['label'] == 0].sample(n_sample_0, \n        replace=False)\n    sample_1 = df[df['label'] == 1].sample(n_sample_1, \n        replace=False)\n    # Concatenate the two samples into a single dataframe\n    sample_df = pd.concat([sample_0, sample_1], ignore_index=True)\n    # Print the sample dataframe\n    print(f\"We have {len(sample_df['label'][sample_df['label']==0])} class 0 samples and {len(sample_df['label'][sample_df['label']==1])} class 1 samples\")\n    We have 800 class 0 samples and 200 class 1 samples\n    ```"]