["```py\nfrom deap import base, creator\n```", "```py\ncreator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n```", "```py\ncreator.create(\"Individual\", list, fitness=creator.FitnessMax)\n```", "```py\nimport random\n```", "```py\nfrom deap import tools\n```", "```py\ntoolbox = base.Toolbox()\n```", "```py\ntoolbox.register(\"individual\",tools.initRepeat,creator.Individual,\n```", "```py\n                 random.random, n=10)\n```", "```py\n[0.30752039354315985,0.2491982746819209,0.8423374678316783,0.3401579175109981,0.7699302429041264,0.046433183902334974,0.5287019598616896,0.28081693679292696,0.9562244184741888,0.0008450701833065954]\n```", "```py\n    from scipy.stats import randint,truncnorm,uniform\n    toolbox.register(“param_1”, randint.rvs, 5, 200)\n    toolbox.register(“param_2”, truncnorm.rvs, 0, 0.5, 0.005, 0.01)\n    toolbox.register(“param_3”, uniform.rvs, 0, 1)\n    ```", "```py\n    toolbox.register(“individual”,tools.initCycle,creator.Individual,\n        (\n            toolbox.param_1,\n            toolbox.param_2,\n            toolbox.param_3\n        ),\n        n=1,\n    )\n    ```", "```py\n[172, 0.005840196235159121, 0.37250162585120816]\n```", "```py\n    toolbox.register(“population”, tools.initRepeat, list, toolbox.individual, n=5)\n    ```", "```py\n[[168, 0.009384417146554462, 0.4732188841620628],\n[7, 0.009356636359759574, 0.6722125618177741],\n[126, 0.00927973696427319, 0.7417964302134438],\n[88, 0.008112369078803545, 0.4917555243983919],\n[34, 0.008615337472475908, 0.9164442190622125]]\n```", "```py\n# selection strategy\n```", "```py\ntoolbox.register(\"select\", tools.selTournament, tournsize=3)\n```", "```py\n# crossover strategy\n```", "```py\ntoolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n```", "```py\n# mutation strategy\n```", "```py\ntoolbox.register(\"mutate\", tools.mutPolynomialBounded, eta = 0.1, low=-2, up=2, indpb=0.15)\n```", "```py\ntoolbox.register(\"evaluate\", obj_func)\n```", "```py\nimport multiprocessing\n```", "```py\npool = multiprocessing.Pool()\n```", "```py\ntoolbox.register(\"map\", pool.map)\n```", "```py\nfitnesses = toolbox.map(toolbox.evaluate, individual)\n```", "```py\n    # GA Parameters\n    NPOP = 50 #population size\n    NGEN = 15 #number of trials\n    CXPB = 0.5 #cross-over probability\n    MUTPB = 0.2 #mutation probability\n    ```", "```py\nimport random\nrandom.seed(1)\n```", "```py\nfrom deap import creator, base\ncreator.create(“FitnessMax”, base.Fitness, weights=(1.0,))\n```", "```py\ncreator.create(“Individual”, list, fitness=creator.FitnessMax)\n```", "```py\ntoolbox = base.Toolbox()\n```", "```py\nPARAM_NAMES = [“model__n_estimators”,”model__criterion”,\n             “model__class_weight”,”model__min_samples_split”\n```", "```py\nfrom scipy.stats import randint,truncnorm\ntoolbox.register(“model__n_estimators”, randint.rvs, 5, 200)\ntoolbox.register(“model__criterion”, random.choice, [“gini”, “entropy”])\ntoolbox.register(“model__class_weight”, random.choice, [“balanced”,”balanced_subsample”])\ntoolbox.register(“model__min_samples_split”, truncnorm.rvs, 0, 0.5, 0.005, 0.01)\n```", "```py\nfrom deap import tools\ntoolbox.register(\n    “individual”,\n    tools.initCycle,\n    creator.Individual,\n    (\n        toolbox.model__n_estimators,\n        toolbox.model__criterion,\n        toolbox.model__class_weight,\n        toolbox.model__min_samples_split,\n    ),\n)\n```", "```py\ntoolbox.register(“population”, tools.initRepeat, list, toolbox.individual)\n```", "```py\ntoolbox.register(“select”, tools.selTournament, tournsize=3)\n```", "```py\ntoolbox.register(“mate”, tools.cxUniform, indpb=CXPB)\n```", "```py\ndef mutPolynomialBoundedMix(individual, eta, low, up, is_int, indpb, discrete_params):\n    for i in range(len(individual)):\n        if discrete_params[i]:\n            if random.random() < indpb:\n                individual[i] = random.choice(discrete_params[i])\n        else:\n            individual[i] = tools.mutPolynomialBounded([individual[i]], \n                                                          eta[i], low[i], up[i], indpb)[0][0]\n\n        if is_int[i]:\n            individual[i] = int(individual[i])\n\n    return individual,\n```", "```py\ntoolbox.register(“mutate”, mutPolynomialBoundedMix, \n                 eta = [0.1,None,None,0.1], \n                 low = [5,None,None,0], \n                 up = [200,None,None,1],\n                 is_int = [True,False,False,False],\n                 indpb=MUTPB,\n                 discrete_params=[[],[“gini”, “entropy”],[“balanced”,”balanced_subsample”],[]]\n                )\n```", "```py\n    def evaluate(individual):\n        # convert list of parameter values into dictionary of kwargs\n        strategy_params = {k: v for k, v in zip(PARAM_NAMES, individual)}\n\n        if strategy_params['model__min_samples_split'] > 1 or strategy_params['model__min_samples_split'] <= 0:\n            return [-np.inf]\n\n        tuned_pipe = clone(pipe).set_params(**strategy_params)\n        return [np.mean(cross_val_score(tuned_pipe,X_train_full, y_train, cv=5, scoring='f1',))]\n    ```", "```py\ntoolbox.register(“evaluate”, evaluate)\n```", "```py\n    import multiprocessing\n    import numpy as np\n    ```", "```py\npool = multiprocessing.Pool(16)\ntoolbox.register(“map”, pool.map)\n```", "```py\nmean = np.ndarray(NGEN)\nbest = np.ndarray(NGEN)\n```", "```py\nhall_of_fame = tools.HallOfFame(maxsize=3)\n```", "```py\npop = toolbox.population(n=NPOP)\n```", "```py\nfor g in range(NGEN):\n```", "```py\n    offspring = toolbox.select(pop, len(pop))\n```", "```py\n    offspring = list(map(toolbox.clone, offspring))\n```", "```py\n    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n        if random.random() < CXPB:\n            toolbox.mate(child1, child2)\n            del child1.fitness.values\n            del child2.fitness.values\n```", "```py\n    for mutant in offspring:\n        if random.random() < MUTPB:\n            toolbox.mutate(mutant)\n            del mutant.fitness.values\n```", "```py\n    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n    for ind, fit in zip(invalid_ind, fitnesses):\n        ind.fitness.values = fit\n```", "```py\n    pop[:] = offspring\n    hall_of_fame.update(pop)\n    fitnesses = [\n        ind.fitness.values[0] for ind in pop if not np.isinf(ind.fitness.values[0])\n    ]\n    mean[g] = np.mean(fitnesses)\n    best[g] = np.max(fitnesses)\n```", "```py\n    params = {}\n    for idx_hof, param_name in enumerate(PARAM_NAMES):\n        params[param_name] = hall_of_fame[0][idx_hof]\n    print(params)\n    ```", "```py\n{'model__n_estimators': 101,\n'model__criterion': 'entropy',\n'model__class_weight': 'balanced',\n'model__min_samples_split': 0.0007106340458649385}\n```", "```py\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfig, ax = plt.subplots(sharex=True, figsize=(8, 6))\nsns.lineplot(x=range(NGEN), y=mean, ax=ax, label=”Average Fitness Score”)\nsns.lineplot(x=range(NGEN), y=best, ax=ax, label=”Best Fitness Score”)\nax.set_title(“Fitness Score”,size=20)\nax.set_xticks(range(NGEN))\nax.set_xlabel(“Iteration”)\nplt.tight_layout()\nplt.show()\n```", "```py\n    from sklearn.base import clone\n    tuned_pipe = clone(pipe).set_params(**params)\n    tuned_pipe.fit(X_train_full,y_train)\n    ```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    N = 50 #swarm size\n    w = 0.5 #inertia weight coefficient\n    c1 = 0.3 #cognitive coefficient\n    c2 = 0.5 #social coefficient\n    num_trials = 15 #number of trials\n    ```", "```py\nimport random\nrandom.seed(1)\n```", "```py\nfrom deap import creator, base\ncreator.create(“FitnessMax”, base.Fitness, weights=(1.0,))\n```", "```py\ncreator.create(“Particle”, list, fitness=creator.FitnessMax,\n               speed=list, smin=list, smax=list, best=None)\n```", "```py\ntoolbox = base.Toolbox()\n```", "```py\nPARAM_NAMES = [“model__n_estimators”,”model__criterion”,\n             “model__class_weight”,”model__min_samples_split”\n```", "```py\nfrom scipy.stats import randint,truncnorm\ntoolbox.register(“model__n_estimators”, randint.rvs, 5, 200)\ntoolbox.register(“model__criterion”, random.choice, [0,1])\ntoolbox.register(“model__class_weight”, random.choice, [0,1])\ntoolbox.register(“model__min_samples_split”, truncnorm.rvs, 0, 0.5, 0.005, 0.01)\n```", "```py\nfrom deap import tools\ndef generate(speed_bound):\n    part = tools.initCycle(creator.Particle,\n                           [toolbox.model__n_estimators,\n                            toolbox.model__criterion,\n                            toolbox.model__class_weight,\n                            toolbox.model__min_samples_split,\n                           ]\n                          )\n    part.speed = [random.uniform(speed_bound[i]['smin'], speed_bound[i]['smax']) for i in range(len(part))]\n    part.smin = [speed_bound[i]['smin'] for i in range(len(part))]\n    part.smax = [speed_bound[i]['smax'] for i in range(len(part))]\n    return part\n```", "```py\ntoolbox.register(“particle”, generate, \n                 speed_bound=[{'smin': -2.5,'smax': 2.5},\n                              {'smin': -1,'smax': 1},\n                              {'smin': -1,'smax': 1},\n                              {'smin': -0.001,'smax': 0.001}])\n```", "```py\ntoolbox.register(“population”, tools.initRepeat, list, toolbox.particle)\n```", "```py\n    import operator\n    import math\n    def updateParticle(part, best, c1, c2, w, is_int):\n        w = [w for _ in range(len(part))]\n        u1 = (random.uniform(0, 1)*c1 for _ in range(len(part)))\n        u2 = (random.uniform(0, 1)*c2 for _ in range(len(part)))\n        v_u1 = map(operator.mul, u1, map(operator.sub, part.best, part))\n        v_u2 = map(operator.mul, u2, map(operator.sub, best, part))\n        part.speed = list(map(operator.add, map(operator.mul, w, part.speed), map(operator.add, v_u1, v_u2)))\n        for i, speed in enumerate(part.speed):\n            if abs(speed) < part.smin[i]:\n                part.speed[i] = math.copysign(part.smin[i], speed)\n            elif abs(speed) > part.smax[i]:\n                part.speed[i] = math.copysign(part.smax[i], speed)\n        part[:] = list(map(operator.add, part, part.speed))\n\n        for i, pos in enumerate(part):\n            if is_int[i]:\n                part[i] = int(pos)\n    ```", "```py\ntoolbox.register(“update”, updateParticle, c1=c1, c2=c2, w=w,\n                is_int=[True,True,True,False]\n                )\n```", "```py\n    def evaluate(particle):\n        # convert list of parameter values into dictionary of kwargs\n        strategy_params = {k: v for k, v in zip(PARAM_NAMES, particle)}\n        strategy_params[“model__criterion”] = “gini” if strategy_params[“model__criterion”]==0 else “entropy”\n        strategy_params[“model__class_weight”] = “balanced” if strategy_params[“model__class_weight”]==0 else “balanced_subsample”\n\n        if strategy_params['model__min_samples_split'] > 1 or strategy_params['model__min_samples_split'] <= 0:\n            return [-np.inf]\n\n        tuned_pipe = clone(pipe).set_params(**strategy_params)\n\n        return [np.mean(cross_val_score(tuned_pipe,X_train_full, y_train, cv=5, scoring='f1',))]\n    ```", "```py\ntoolbox.register(“evaluate”, evaluate)\n```", "```py\n    import multiprocessing\n    import numpy as np\n    ```", "```py\npool = multiprocessing.Pool(16)\ntoolbox.register(“map”, pool.map)\n```", "```py\nmean_arr = np.ndarray(num_trials)\nbest_arr = np.ndarray(num_trials)\n```", "```py\nhall_of_fame = tools.HallOfFame(maxsize=3)\n```", "```py\npop = toolbox.population(n=NPOP)\n```", "```py\nbest = None\nfor g in range(num_trials):\n    fitnesses = toolbox.map(toolbox.evaluate, pop)\n    for part, fit in zip(pop, fitnesses):\n        part.fitness.values = fit\n\n        if not part.best or part.fitness.values > part.best.fitness.values:\n            part.best = creator.Particle(part)\n            part.best.fitness.values = part.fitness.values\n        if not best or part.fitness.values > best.fitness.values:\n            best = creator.Particle(part)\n            best.fitness.values = part.fitness.values\n    for part in pop:\n        toolbox.update(part, best)\n\n    hall_of_fame.update(pop)    \n    fitnesses = [\n        ind.fitness.values[0] for ind in pop if not np.isinf(ind.fitness.values[0])\n    ]\n    mean_arr[g] = np.mean(fitnesses)\n    best_arr[g] = np.max(fitnesses)\n```", "```py\n    params = {}\n    for idx_hof, param_name in enumerate(PARAM_NAMES):\n        if param_name == “model__criterion”:\n            params[param_name] = “gini” if hall_of_fame[0][idx_hof]==0 else “entropy”\n        elif param_name == “model__class_weight”:\n            params[param_name] = “balanced” if hall_of_fame[0][idx_hof]==0 else “balanced_subsample”\n        else:\n            params[param_name] = hall_of_fame[0][idx_hof]   \n    print(params)\n    ```", "```py\n{'model__n_estimators': 75,\n'model__criterion': 'entropy',\n'model__class_weight': 'balanced',\n'model__min_samples_split': 0.0037241038302412493}\n```", "```py\n    from sklearn.base import clone \n    tuned_pipe = clone(pipe).set_params(**params) \n    tuned_pipe.fit(X_train_full,y_train)\n    ```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    hyperparameter_space = {\n        ' n_estimators ': {'_type': 'randint', '_value': [5, 200]},\n        ' criterion ': {'_type': 'choice', '_value': ['gini', 'entropy']},\n        ' min_samples_split ': {'_type': 'uniform', '_value': [0, 0.1]},\n    } \n    ```", "```py\nfrom nni.experiment import Experiment\nexperiment = Experiment('local')\n```", "```py\nexperiment.config.trial_command = 'python model.py'\nexperiment.config.trial_code_directory = '.'\n```", "```py\nexperiment.config.search_space = hyperparameter_space\n```", "```py\nexperiment.config.tuner.name = 'TPE'\nexperiment.config.tuner.class_args['optimize_mode'] = 'maximize'\n```", "```py\nexperiment.config.max_trial_number = 50\nexperiment.config.trial_concurrency = 5\n```", "```py\nexperiment.config.max_experiment_duration = '1h'\n```", "```py\n    experiment.run(8080) \n    ```", "```py\n    searchSpaceFile: hyperparameter_space.json\n    trial_command: python model.py\n    trial_code_directory: .\n\n    trial_concurrency: 5\n    max_trial_number: 50\n\n    tuner:\n      name: TPE\n      class_args:\n        optimize_mode: maximize\n\n    training_service:\n      platform: local\n    ```", "```py\n    nnictl create --config config.yaml --port 8080\n    ```", "```py\nexperiment.config.assessor.name = 'Medianstop'\n```", "```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\ndef load_data():\n    df = pd.read_csv(f”{Path(__file__).parent.parent}/train.csv”,sep=”;”)\n\n    #Convert the target variable to integer\n    df['y'] = df['y'].map({'yes':1,'no':0})\n\n    #Split full data into train and test data\n    df_train, df_test = train_test_split(df, test_size=0.1, random_state=0) \n\n    #Get list of categorical and numerical features\n    numerical_feats = list(df_train.drop(columns='y').select_dtypes(include=np.number).columns)\n    categorical_feats = list(df_train.drop(columns='y').select_dtypes(exclude=np.number).columns)\n\n    X_train = df_train.drop(columns=['y'])\n    y_train = df_train['y']\n    X_test = df_test.drop(columns=['y'])\n    y_test = df_test['y']\n\n    return X_train, X_test, y_train, y_test, numerical_feats, categorical_feats\n```", "```py\ndef get_default_parameters():\n    params = {\n        'model__n_estimators': 5,\n        'model__criterion': 'gini',\n        'model__class_weight': 'balanced',\n        'model__min_samples_split': 0.01,\n    }\n\n    return params\n```", "```py\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\ndef get_model(PARAMS, numerical_feats, categorical_feats): \n```", "```py\n    numeric_preprocessor = StandardScaler()\n```", "```py\n    categorical_preprocessor = OneHotEncoder(handle_unknown=”ignore”)\n```", "```py\n    preprocessor = ColumnTransformer(\n        transformers=[\n            (“num”, numeric_preprocessor, numerical_feats),\n            (“cat”, categorical_preprocessor, categorical_feats),\n        ]\n    )\n```", "```py\n    pipe = Pipeline(\n        steps=[(“preprocessor”, preprocessor), \n               (“model”, RandomForestClassifier(random_state=0))]\n    )\n```", "```py\n    pipe = pipe.set_params(**PARAMS)\n\n    return pipe\n```", "```py\nimport nni\nimport logging\nfrom sklearn.model_selection import cross_val_score\nLOG = logging.getLogger('nni_sklearn')\ndef run(X_train, y_train, model):\n    model.fit(X_train, y_train)\n    score = np.mean(cross_val_score(model,X_train, y_train, \n                    cv=5, scoring='f1')\n            )\n    LOG.debug('score: %s', score)\n    nni.report_final_result(score)\n```", "```py\nif __name__ == '__main__':\n    X_train, _, y_train, _, numerical_feats, categorical_feats = load_data()\n    try:\n        # get parameters from tuner\n        RECEIVED_PARAMS = nni.get_next_parameter()\n        LOG.debug(RECEIVED_PARAMS)\n        PARAMS = get_default_parameters()\n        PARAMS.update(RECEIVED_PARAMS)\n        LOG.debug(PARAMS)\n        model = get_model(PARAMS, numerical_feats, categorical_feats)\n        run(X_train, y_train, model)\n    except Exception as exception:\n        LOG.exception(exception)\n        raise\n```", "```py\n    {“model__n_estimators”: {“_type”: “randint”, “_value”: [5, 200]}, “model__criterion”: {“_type”: “choice”, “_value”: [“gini”, “entropy”]}, “model__class_weight”: {“_type”: “choice”, “_value”: [“balanced”,”balanced_subsample”]}, “model__min_samples_split”: {“_type”: “uniform”, “_value”: [0, 0.1]}}\n    ```", "```py\n    searchSpaceFile: hyperparameter_space.json\n    experimentName: nni_sklearn\n    trial_command: python '/mnt/c/Users/Louis\\ Owen/Desktop/Packt/Hyperparameter-Tuning-with-Python/nni/model.py'\n    trial_code_directory: .\n    trial_concurrency: 10\n    max_trial_number: 100 \n    maxExperimentDuration: 1h\n    tuner: \n      name: GridSearch\n    training_service:\n      platform: local\n    ```", "```py\n    nnictl create --config config.yaml --port 8080\n    ```", "```py\nbest_parameters = {\n    “model__n_estimators”: 27,\n    “model__criterion”: “entropy”,\n    “model__class_weight”: “balanced_subsample”,\n    “model__min_samples_split”: 0.05\n}\n```", "```py\nfrom sklearn.base import clone\ntuned_pipe = clone(pipe).set_params(**best_parameters)\n# Fit the pipeline on train data \ntuned_pipe.fit(X_train_full,y_train)\n```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    hyperparameter_space = { \n        'model__n_estimators': {'_type': 'randint', '_value': [5, 200]}, \n        'model__criterion': {'_type': 'choice', '_value': ['gini', 'entropy']}, \n        'model__class_weight': {'_type': 'choice', '_value': [“balanced”,”balanced_subsample”]}, \n        'model__min_samples_split': {'_type': 'uniform', '_value': [0, 0.1]}, \n    }  \n    ```", "```py\n    experiment = Experiment('local')\n\n    experiment.config.experiment_name = 'nni_sklearn_random_search'\n    experiment.config.tuner.name = 'Random'\n    experiment.config.tuner.class_args['seed'] = 0\n\n    # Boilerplate code\n    experiment.config.trial_command = “python '/mnt/c/Users/Louis\\ Owen/Desktop/Packt/Hyperparameter-Tuning-with-Python/nni/model.py'”\n    experiment.config.trial_code_directory = '.'\n    experiment.config.search_space = hyperparameter_space\n    experiment.config.max_trial_number = 100\n    experiment.config.trial_concurrency = 10\n    experiment.config.max_experiment_duration = '1h'\n    ```", "```py\n    experiment.run(8080, wait_completion = True, debug = False)\n    ```", "```py\nbest_trial = sorted(experiment.export_data(),key = lambda x: x.value, reverse = True)[0]\nprint(best_trial.parameter)\n```", "```py\n    {'model__n_estimators': 194, 'model__criterion': 'entropy', 'model__class_weight': 'balanced_subsample', 'model__min_samples_split': 0.0014706304965369289}\n    ```", "```py\nfrom sklearn.base import clone\ntuned_pipe = clone(pipe).set_params(**best_trial.parameter)\n# Fit the pipeline on train data \ntuned_pipe.fit(X_train_full,y_train)\n```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    experiment = Experiment('local')\n    experiment.config.experiment_name = 'nni_sklearn_tpe'\n    experiment.config.tuner.name = 'TPE'\n    experiment.config.tuner.class_args = {'optimize_mode': 'maximize', 'seed': 0}\n\n    # Boilerplate code\n    # same with previous section\n    ```", "```py\n    experiment.run(8080, wait_completion = True, debug = False)\n    ```", "```py\nbest_trial = sorted(experiment.export_data(),key = lambda x: x.value, reverse = True)[0]\nprint(best_trial.parameter)\n```", "```py\n{'model__n_estimators': 195, 'model__criterion': 'entropy', 'model__class_weight': 'balanced_subsample', 'model__min_samples_split': 0.0006636374717157983}\n```", "```py\nfrom sklearn.base import clone\ntuned_pipe = clone(pipe).set_params(**best_trial.parameter)\n```", "```py\ntuned_pipe.fit(X_train_full,y_train)\n```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    experiment = Experiment('local')\n\n    experiment.config.experiment_name = 'nni_sklearn_smac'\n    experiment.config.tuner.name = 'SMAC'\n    experiment.config.tuner.class_args['optimize_mode'] = 'maximize'\n    # Boilerplate code\n    # same with previous section\n    ```", "```py\n    experiment.run(8080, wait_completion = True, debug = False)\n    ```", "```py\nbest_trial = sorted(experiment.export_data(),key = lambda x: x.value, reverse = True)[0]\nprint(best_trial.parameter)\n```", "```py\n{'model__class_weight': 'balanced', 'model__criterion': 'entropy', 'model__min_samples_split': 0.0005502416428725066, 'model__n_estimators': 199}\n```", "```py\nfrom sklearn.base import clone\ntuned_pipe = clone(pipe).set_params(**best_trial.parameter)\n# Fit the pipeline on train data \ntuned_pipe.fit(X_train_full,y_train)\n```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    non_numeric_mapping = params = {\n       'model__criterion': ['gini','entropy'],\n       'model__class_weight': ['balanced','balanced_subsample'],\n        }\n    ```", "```py\n    hyperparameter_space_numeric = { \n        'model__n_estimators': {'_type': 'randint', '_value': [5, 200]}, \n        'model__criterion': {'_type': 'choice', '_value': [0, 1]}, \n        'model__class_weight': {'_type': 'choice', '_value': [0, 1]}, \n        'model__min_samples_split': {'_type': 'uniform', '_value': [0, 0.1]}, \n    }  \n    ```", "```py\n    experiment = Experiment('local')\n\n    experiment.config.experiment_name = 'nni_sklearn_bogp'\n    experiment.config.tuner.name = 'GPTuner'\n    experiment.config.tuner.class_args = {\n    'optimize_mode': 'maximize', 'utility': 'ei','xi': 0.01}\n    # Boilerplate code\n    experiment.config.trial_command = “python '/mnt/c/Users/Louis\\ Owen/Desktop/Packt/Hyperparameter-Tuning-with-Python/nni/model_numeric.py'”\n    experiment.config.trial_code_directory = '.'\n    experiment.config.search_space = hyperparameter_space_numeric\n    experiment.config.max_trial_number = 100\n    experiment.config.trial_concurrency = 10\n    experiment.config.max_experiment_duration = '1h'\n    ```", "```py\n    experiment.run(8080, wait_completion = True, debug = False)\n    ```", "```py\nnon_numeric_mapping = params = {\n'model__criterion': ['gini','entropy'],\n'model__class_weight': ['balanced','balanced_subsample'],\n    }\nbest_trial = sorted(experiment.export_data(),key = lambda x: x.value, reverse = True)[0]\nfor key in non_numeric_mapping:\n    best_trial.parameter[key] = non_numeric_mapping[key][best_trial.parameter[key]]\nprint(best_trial.parameter)\n```", "```py\n{'model__class_weight': 'balanced_subsample', 'model__criterion': 'entropy', 'model__min_samples_split': 0.00055461211818435, 'model__n_estimators': 159}\n```", "```py\nfrom sklearn.base import clone\ntuned_pipe = clone(pipe).set_params(**best_trial.parameter)\n```", "```py\ntuned_pipe.fit(X_train_full,y_train)\n```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    experiment = Experiment('local')\n\n    experiment.config.experiment_name = 'nni_sklearn_metis'\n    experiment.config.tuner.name = 'MetisTuner'\n    experiment.config.tuner.class_args['optimize_mode'] = 'maximize'\n    # Boilerplate code \n    # same as previous section\n    ```", "```py\n    experiment.run(8080, wait_completion = True, debug = False)\n    ```", "```py\nnon_numeric_mapping = params = {\n'model__criterion': ['gini','entropy'],\n'model__class_weight': ['balanced','balanced_subsample'],\n    }\nbest_trial = sorted(experiment.export_data(),key = lambda x: x.value, reverse = True)[0]\nfor key in non_numeric_mapping:\n    best_trial.parameter[key] = non_numeric_mapping[key][best_trial.parameter[key]]\nprint(best_trial.parameter)\n```", "```py\n{'model__n_estimators': 122, 'model__criterion': 'gini', 'model__class_weight': 'balanced', 'model__min_samples_split': 0.00173059072806428}\n```", "```py\nfrom sklearn.base import clone\ntuned_pipe = clone(pipe).set_params(**best_trial.parameter)\n# Fit the pipeline on train data \ntuned_pipe.fit(X_train_full,y_train)\n```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    experiment = Experiment('local')\n\n    experiment.config.experiment_name = 'nni_sklearn_anneal'\n    experiment.config.tuner.name = 'Anneal'\n    experiment.config.tuner.class_args['optimize_mode'] = 'maximize'\n    # Boilerplate code\n    experiment.config.trial_command = “python '/mnt/c/Users/Louis\\ Owen/Desktop/Packt/Hyperparameter-Tuning-with-Python/nni/model.py'”\n    experiment.config.trial_code_directory = '.'\n    experiment.config.search_space = hyperparameter_space\n    experiment.config.max_trial_number = 100\n    experiment.config.trial_concurrency = 10\n    experiment.config.max_experiment_duration = '1h'\n    ```", "```py\n    experiment.run(8080, wait_completion = True, debug = False)\n    ```", "```py\nbest_trial = sorted(experiment.export_data(),key = lambda x: x.value, reverse = True)[0]\nprint(best_trial.parameter)\n```", "```py\n{'model__n_estimators': 103, 'model__criterion': 'gini', 'model__class_weight': 'balanced_subsample', 'model__min_samples_split': 0.0010101249953063539}\n```", "```py\nfrom sklearn.base import clone\ntuned_pipe = clone(pipe).set_params(**best_trial.parameter)\n# Fit the pipeline on train data \ntuned_pipe.fit(X_train_full,y_train)\n```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    hyperparameter_space_advisor = { \n        'model__criterion': {'_type': 'choice', '_value': ['gini', 'entropy']}, \n        'model__class_weight': {'_type': 'choice', '_value': [“balanced”,”balanced_subsample”]}, \n        'model__min_samples_split': {'_type': 'uniform', '_value': [0, 0.1]}, \n    }  \n    ```", "```py\n    experiment = Experiment('local')\n\n    experiment.config.experiment_name = 'nni_sklearn_hyper_band'\n    experiment.config.advisor.name = 'Hyperband'\n    experiment.config.advisor.class_args['optimize_mode'] = 'maximize'\n    experiment.config.advisor.class_args['R'] = 200\n    experiment.config.advisor.class_args['eta'] = 3\n    experiment.config.advisor.class_args['exec_mode'] = 'parallelism'\n\n    # Boilerplate code\n    experiment.config.trial_command = “python '/mnt/c/Users/Louis\\ Owen/Desktop/Packt/Hyperparameter-Tuning-with-Python/nni/model_advisor.py'”\n    experiment.config.trial_code_directory = '.'\n    experiment.config.search_space = hyperparameter_space_advisor\n    experiment.config.max_trial_number = 100\n    experiment.config.trial_concurrency = 10\n    experiment.config.max_experiment_duration = '1h'\n    ```", "```py\n    experiment.run(8080, wait_completion = True, debug = False)\n    ```", "```py\nbest_trial = sorted(experiment.export_data(),key = lambda x: x.value, reverse = True)[0]\nbest_trial.parameter['model__n_estimators'] = best_trial.parameter['TRIAL_BUDGET'] * 50\ndel best_trial.parameter['TRIAL_BUDGET']\nprint(best_trial.parameter)\n```", "```py\n{'model__criterion': 'gini', 'model__class_weight': 'balanced_subsample', 'model__min_samples_split': 0.001676130360763284, 'model__n_estimators': 100}\n```", "```py\nfrom sklearn.base import clone\ntuned_pipe = clone(pipe).set_params(**best_trial.parameter)\n```", "```py\ntuned_pipe.fit(X_train_full,y_train)\n```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\npip install \"nni[BOHB]\"\n```", "```py\n    experiment = Experiment('local')\n\n    experiment.config.experiment_name = 'nni_sklearn_bohb'\n    experiment.config.advisor.name = 'BOHB'\n    experiment.config.advisor.class_args['optimize_mode'] = 'maximize'\n    experiment.config.advisor.class_args['max_budget'] = 200\n    experiment.config.advisor.class_args['min_budget'] = 5\n    experiment.config.advisor.class_args['eta'] = 3\n    # Boilerplate code  \n    # same as previous section\n    ```", "```py\n    experiment.run(8080, wait_completion = True, debug = False)\n    ```", "```py\nbest_trial = sorted(experiment.export_data(),key = lambda x: x.value, reverse = True)[0]\nbest_trial.parameter['model__n_estimators'] = best_trial.parameter['TRIAL_BUDGET'] * 50\ndel best_trial.parameter['TRIAL_BUDGET']\nprint(best_trial.parameter)\n```", "```py\n{'model__class_weight': 'balanced', 'model__criterion': 'gini', 'model__min_samples_split': 0.000396569883631686, 'model__n_estimators': 1100}\n```", "```py\nfrom sklearn.base import clone\ntuned_pipe = clone(pipe).set_params(**best_trial.parameter)\n# Fit the pipeline on train data \ntuned_pipe.fit(X_train_full,y_train)\n```", "```py\n    y_pred = tuned_pipe.predict(X_test_full)\n    print(f1_score(y_test, y_pred))\n    ```", "```py\n    searchSpaceFile: hyperparameter_space_pbt.json\n    trialCommand: python '/mnt/c/Users/Louis\\ Owen/Desktop/Packt/Hyperparameter-Tuning-with-Python/nni/model_pbt.py'\n    trialGpuNumber: 1\n    trialConcurrency: 10\n    maxTrialNumber: 100\n    maxExperimentDuration: 1h\n    tuner:\n      name: PBTTuner\n      classArgs:\n        optimize_mode: maximize\n    trainingService:\n      platform: local\n      useActiveGpu: false\n    ```", "```py\n    nnictl create --config config_pbt.yaml --port 8080\n    ```"]