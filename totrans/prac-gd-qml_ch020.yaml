- en: Chapter 11
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章
- en: 'The Best of Both Worlds: Hybrid Architectures'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 两种世界的最佳结合：混合架构
- en: '*Unity makes strength.*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*团结就是力量。*'
- en: — English aphorism
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: — 英文谚语
- en: 'By now, we have a solid understanding of both classical and quantum neural
    networks. In this chapter, we will leverage this knowledge to explore an interesting
    kind of model: hybrid architectures of quantum neural networks.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们对经典和量子神经网络都有了坚实的理解。在本章中，我们将利用这些知识来探索一种有趣类型的模型：量子神经网络的混合架构。
- en: In this chapter, we will discuss what these models are and how they can be useful,
    and we will also learn how to implement and train them with PennyLane and Qiskit.
    The whole chapter is going to be very hands-on, and we will also take the time
    to fill in some gaps regarding the actual practice of training models in real-world
    scenarios. In addition to this — and just to spice things up a bit — we will go
    beyond our usual binary classifiers and also consider other kinds of problems.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论这些模型是什么以及它们如何有用，我们还将学习如何使用PennyLane和Qiskit来实现和训练它们。整章将非常实用，我们还将花时间填补一些关于在现实场景中训练模型的实际实践方面的空白。除此之外——为了增加一些趣味性——我们还将超越我们通常的二分类器，并考虑其他类型的问题。
- en: 'We’ll cover the following topics in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: The what and why of hybrid architectures
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合架构的“什么”和“为什么”
- en: Hybrid architectures in PennyLane (with a brief overview of best practices for
    training models in real-world scenarios and an introduction to multi-class classification
    problems)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PennyLane中的混合架构（包括在现实场景中训练模型的最佳实践概述以及多类分类问题的介绍）
- en: Hybrid architectures in Qiskit (with an introduction to PyTorch)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiskit中的混合架构（包括PyTorch的介绍）
- en: This is going to be a very exciting chapter. Let’s begin by giving meaning to
    these hybrid architectures.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是一个非常激动人心的章节。让我们首先为这些混合架构赋予意义。
- en: 11.1 The what and why of hybrid architectures
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11.1 混合架构的“什么”和“为什么”
- en: 'Up until now, we’ve used the adjective ”hybrid” to describe algorithms that
    rely on both classical and quantum processing; algorithms such as QAOA or VQE
    fit in this category, as well as the training of QSVMs and QNNs. When we talk
    about **hybrid architectures** or **hybrid models**, however, we refer to something
    more specific: we speak about models that combine classical models with other
    quantum-based models by joining them together and training them as a single unit.
    Of course, the training of hybrid models will itself be a hybrid algorithm. We
    know that the terminology might be confusing, but what can we do? Hybrid is too
    versatile a word to give it up.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用形容词“混合”来描述依赖于经典和量子处理的算法；例如QAOA或VQE以及QSVMs和QNNs的训练都属于这一类别。然而，当我们谈论**混合架构**或**混合模型**时，我们指的是更具体的东西：我们谈论的是通过将它们组合在一起并作为一个单一单元进行训练，将经典模型与其他基于量子模型的模型结合在一起的模型。当然，混合模型的训练本身也将是一个混合算法。我们知道术语可能有些令人困惑，但我们能怎么办呢？混合这个词太灵活了，不能放弃。
- en: In particular, we will combine quantum neural networks with classical neural
    networks, for they are the two models that fit more naturally together. The way
    we will go about doing this will be by taking a usual classical neural network
    and plugging in a quantum neural network as one of its layers. In this way, the
    ”quantum layer” will take as input the outputs of the previous layer (or the inputs
    to the model, if there’s no layer before it) and will feed its output to the next
    layer (should there be any). The output of the quantum neural network will be
    a numerical array of length ![k](img/file317.png "k"); thus, in the eyes of the
    next layer, the quantum layer will behave as if it were a classical layer with
    ![k](img/file317.png "k") neurons.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其地，我们将结合量子神经网络和经典神经网络，因为它们是两种更自然地结合在一起的模式。我们将通过将一个普通的经典神经网络作为其一层插入量子神经网络来实现这一点。这样，“量子层”将接受前一层的输出（或如果没有前一层，则为模型的输入）并将其输出传递给下一层（如果有）。量子神经网络的输出将是一个长度为![k](img/file317.png
    "k")的数值数组；因此，在下一层看来，量子层将表现得像一个具有![k](img/file317.png "k")个神经元的经典层。
- en: These hybrid architectures combining classical and quantum neural networks are
    said to be, to the surprise of no one, **hybrid quantum neural** **networks**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结合经典和量子神经网络的混合架构据说对任何人来说都不会感到惊讶，**混合量子神经网络**。
- en: Important note
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In summary, a hybrid QNN is a classical neural network in which one or more
    of its layers have been replaced by quantum layers. These are quantum neural networks
    that get inputs from the outputs of the previous layer and feed their outputs
    to the next one. Of course, if there’s no next layer, the output of the quantum
    layer will be the output of the network. Analogously, if there’s no previous layer,
    the input to the quantum network will be the model’s input.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，混合QNN是一个经典神经网络，其中一层或多层已被量子层所取代。这些是量子神经网络，它们从前一层的输出获取输入，并将它们的输出馈送到下一层。当然，如果没有下一层，量子层的输出将是网络的输出。类似地，如果没有前一层，量子网络的输入将是模型的输入。
- en: 'As we’ve already hinted, a hybrid neural network is trained as a single unit:
    the training process involves the optimization of both the parameters of the classical
    layers and those of the quantum neural networks inside the quantum layers.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经暗示的，混合神经网络作为一个单一单元进行训练：训练过程涉及经典层的参数和量子层内量子神经网络的参数的优化。
- en: 'To make the whole definition of hybrid QNNs more clear, let us consider a simple
    example of how one such network may be constructed:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使混合QNNs的定义更加清晰，让我们考虑一个简单的例子，说明这样一个网络可能如何构建：
- en: The hybrid QNN must begin taking some classical inputs. Let’s say it takes ![16](img/file619.png
    "16").
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 混合QNN必须开始接收一些经典输入。比如说它接收![16](img/file619.png "16")。
- en: We may then feed the input into a usual classical layer with ![8](img/file506.png
    "8") neurons and use the sigmoid activation function.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将输入数据馈送到一个通常的经典层，该层包含![8](img/file506.png "8")个神经元，并使用sigmoid激活函数。
- en: Then, we will add a quantum layer. This quantum layer will have to accept ![8](img/file506.png
    "8") inputs from the previous layer. For example, we could use a QNN with three
    qubits using amplitude encoding. The output of this quantum layer could be, for
    instance, the expectation values of the first and second qubits, both measured
    on the computational basis. In this case, this quantum layer that we have added
    will return two numeric values.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将添加一个量子层。这个量子层必须从前一层接受![8](img/file506.png "8")个输入。例如，我们可以使用一个具有三个量子比特并使用振幅编码的QNN。这个量子层的输出可以是，例如，第一个和第二个量子比特在计算基上的期望值。在这种情况下，我们添加的这个量子层将返回两个数值。
- en: Finally, we may add a classical layer with a single neuron that uses the sigmoid
    activation function. This layer will take inputs from the quantum layer, so it
    will accept two inputs. It will essentially treat the quantum layer as if it were
    a classical layer with two neurons.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可能添加一个包含单个神经元并使用sigmoid激活函数的经典层。这个层将从量子层接收输入，因此它将接受两个输入。它基本上将量子层视为一个具有两个神经元的经典层。
- en: And that’s how you can build yourself a simple hybrid QNN — at least in theory!
    But the question is... why would we want to do such a thing? What are these hybrid
    models good for? Let’s illustrate it with a typical example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你可以构建一个简单的混合QNN的方法——至少在理论上是这样！但问题是...我们为什么要这样做？这些混合模型有什么好处？让我们用一个典型的例子来说明。
- en: 'In the previous chapter, we learned how to use a QNN to tackle a (binary) classification
    task. But, due to the limitations of current quantum hardware and simulators,
    we were forced to apply some dimensionality reduction techniques on our data before
    we could use it. That’s a situation where hybrid QNNs may prove useful: why not
    combine, in a single model, classical dimensionality reduction carried out by
    a classical neural network with classification performed by a quantum neural network?'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用QNN来解决一个（二进制）分类任务。但是，由于当前量子硬件和模拟器的限制，我们被迫在可以使用之前对我们的数据进行一些降维处理。这就是混合QNNs可能有用的情况：为什么不将经典神经网络执行的经典降维与量子神经网络执行的分类结合在一个模型中呢？
- en: In this way, instead of first reducing the dimensionality of our data and then
    classifying it with a quantum neural network, we could consider a hybrid QNN with
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式，我们不必首先降低数据的维度，然后用量子神经网络对其进行分类，我们可以考虑一个具有以下特征的混合QNN：
- en: a bunch of classical layers that would reduce the dimensionality of our data,
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列经典层，这些层将降低我们数据的维度，
- en: joined to a quantum layer that would be in charge of making the classification.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与一个负责分类的量子层相连。
- en: Of course, since the whole network would be trained as a single unit, there
    would be no way to truly tell whether the classical part of the network is only
    doing dimensionality reduction and the quantum part is only doing classification.
    Most likely, both parts will work on both tasks to some degree.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，由于整个网络将作为一个单一单元进行训练，我们无法真正判断网络的经典部分是否只进行降维，而量子部分只进行分类。很可能是两个部分都会在一定程度上同时处理这两个任务。
- en: 'Before proceeding any further, a few disclaimers are in order. First and foremost:
    quantum layers are not any sort of magical tool that will surely lead to great
    improvements in the performance of a classical neural network. Actually, if used
    unwisely, quantum layers could very easily have a negative impact on your model!
    The key takeaway is that you shouldn’t blindly use a quantum layer solely as a
    replacement for a classical layer in a network. Be intentional. If you are going
    to include a quantum layer in your model, think about the role it’s going to play
    in it.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续前进之前，有一些免责声明是必要的。首先也是最重要的：量子层并不是一种神奇的工具，它一定会导致经典神经网络的性能得到显著提升。实际上，如果使用不当，量子层可能会对你的模型产生负面影响！关键是要记住，你不应该盲目地将量子层仅作为网络中经典层的替代品。要有目的性。如果你打算在你的模型中包含量子层，考虑它在模型中将扮演什么角色。
- en: In addition, when working with hybrid QNNs, you should watch out for how you
    are joining classical and quantum layers together. For instance, if you have a
    quantum layer using a feature map that requires its inputs to be normalized, maybe
    using an ELU activation function in the previous layer isn’t the best of ideas,
    because it is in no way bounded. On the other hand, in that case, a sigmoid activation
    function could be a great fit for the previous layer.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当与混合量子神经网络一起工作时，你应该注意如何将经典层和量子层结合起来。例如，如果你有一个使用需要其输入归一化的特征图的量子层，那么在前一层使用ELU激活函数可能不是最好的主意，因为它没有任何界限。另一方面，在这种情况下，sigmoid激活函数可能非常适合前一层。
- en: In the use case that we discussed a few paragraphs ago (combining classical
    data reduction with quantum classification), we can witness the ”intentionality”
    that we’ve just talked about. We do know that, in principle, a neural network
    can do a good job at reducing data dimensionality; in case you didn’t know, it’s
    a known fact that, using something called **autoencoders** [[104](ch030.xhtml#Xhandsonml),
    Chapter 17], one can train an **encoder** network that can reduce the dimensionality
    of a dataset. And we know that a quantum neural network can do a good job at classifying
    data coming from a dimensionality reduction technique (just have a look at the
    previous chapter!). So there must be some choice of parameters such that the combined
    hybrid model will successfully accomplish both tasks. Hence, with the right training,
    our hybrid model should be able to perform at least as well as it would if a classical
    encoder and a quantum classifier were trained separately. And the important bit
    is the ”at least,” because when training the classical encoder and the quantum
    classifier together we can join their powers!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前讨论的用例中（结合经典数据降维与量子分类），我们可以见证我们刚刚提到的“目的性”。我们知道，从原则上讲，神经网络可以很好地处理数据降维；如果你不知道，这是一个已知的事实：使用一种称为**自动编码器**（[104](ch030.xhtml#Xhandsonml)，第17章）的技术，可以训练一个**编码器**网络来降低数据集的维度。我们还知道，量子神经网络可以很好地对来自降维技术的数据进行分类（只需看看上一章的内容！）因此，必须有一些参数的选择，使得结合的混合模型能够成功完成这两个任务。因此，通过适当的训练，我们的混合模型应该能够至少与分别训练的经典编码器和量子分类器一样好。重要的是“至少”，因为当一起训练经典编码器和量子分类器时，我们可以结合它们的力量！
- en: And that’s the heuristic justification behind this interesting application of
    hybrid neural networks. Actually, this is the use case that we will devote this
    chapter to. However, this is by no means the only application of hybrid models!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是混合神经网络这一有趣应用的启发式理由。实际上，这是我们将在本章中探讨的用例。然而，这绝对不是混合模型唯一的用途！
- en: To learn more…
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多...
- en: Hybrid architectures can also be used in regression problems, as we will later
    see in an exercise. In fact, this is a very interesting application, for Skolit
    et al. [[91](ch030.xhtml#Xskolik2022quantum)] have shown that adding a final layer
    with trainable parameters that transform the output of a quantum neural network
    can be very beneficial in certain reinforcement learning problems.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 混合架构也可以用于回归问题，正如我们将在练习中看到的。事实上，这是一个非常有趣的应用，Skolit等人[[91](ch030.xhtml#Xskolik2022quantum)]已经表明，在量子神经网络输出上添加一个具有可训练参数的最终层可以在某些强化学习问题中非常有益。
- en: Now we promised that this chapter would be very hands-on, and we are going to
    honor that. That should have been enough of a theoretical introduction, so let’s
    gear up! Get ready to train a bunch of hybrid QNNs to classify some data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们承诺这一章将非常实用，我们将履行这一承诺。理论介绍应该已经足够了，所以让我们准备起来！准备好训练一系列混合量子神经网络（QNNs）来对数据进行分类。
- en: 11.2 Hybrid architectures in PennyLane
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11.2 PennyLane中的混合架构
- en: In this section, we are going to use PennyLane to implement and train a couple
    of hybrid QNNs in order to solve some classification problems. Firstly, we will
    tackle a binary classification problem, just to better understand how hybrid QNNs
    work in a familiar setting. Then, we will take one step further and do the same
    for a multi-class classification problem.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用PennyLane实现和训练几个混合QNNs来解决一些分类问题。首先，我们将解决一个二元分类问题，以便更好地理解混合QNNs在熟悉环境中的工作方式。然后，我们将更进一步，对多类分类问题做同样的处理。
- en: Before we get to the problems, though, let us set things up.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始解决问题之前，让我们先做好准备工作。
- en: 11.2.1 Setting things up
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2.1 准备工作
- en: 'As on previous occasions, we shall begin by importing NumPy and TensorFlow
    and setting a seed for both packages — all to ensure the reproducibility of our
    results:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如同之前的场合，我们将首先导入NumPy和TensorFlow，并为这两个包设置一个种子——所有这些都是为了确保我们结果的复现性：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now we can also import some useful functions from scikit-learn. We’ve already
    used them extensively — they need no introduction!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以从scikit-learn导入一些有用的函数了。我们已经广泛地使用了它们——无需介绍！
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this chapter, we will generate our own datasets to have more flexibility.
    In order to create them, we will rely on the `make_classification` function in
    the scikit-learn package. Remember that we introduced it in *Chapter* [*8*](ch017.xhtml#x1-1390008),
    *What Is* *Quantum Machine Learning?*:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将生成自己的数据集以获得更多的灵活性。为了创建它们，我们将依赖于scikit-learn包中的`make_classification`函数。记住，我们在*第*[*8*](ch017.xhtml#x1-1390008)，*什么是*
    *量子机器学习？* 中介绍了它：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Also, in this section, we will use the Lightning simulator with adjoint differentiation
    in order to get a good performance. Thus, we need to change the default datatype
    used by Keras models:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在本节中，我们将使用具有伴随微分的Lightning模拟器来获得良好的性能。因此，我们需要更改Keras模型默认使用的数据类型：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We can now import PennyLane and define the hermitian matrix ![M](img/file704.png
    "M") that we used in the previous chapter. Recall that it corresponds to the observable
    that assigns the eigenvalue ![1](img/file13.png "1") to ![\left| 0 \right\rangle](img/file6.png
    "\left| 0 \right\rangle") and the eigenvalue ![0](img/file12.png "0") to ![\left|
    1 \right\rangle](img/file14.png "\left| 1 \right\rangle"); that is, ![M = \left|
    0 \right\rangle\left\langle 0 \right|](img/file1388.png "M = \left| 0 \right\rangle\left\langle
    0 \right|").
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以导入PennyLane并定义我们在上一章中使用过的厄米矩阵 ![M](img/file704.png "M")。回想一下，它对应于将特征值
    ![1](img/file13.png "1") 分配给 ![\left| 0 \right\rangle](img/file6.png "\left| 0
    \right\rangle") 和特征值 ![0](img/file12.png "0") 分配给 ![\left| 1 \right\rangle](img/file14.png
    "\left| 1 \right\rangle") 的可观测量；也就是说，![M = \left| 0 \right\rangle\left\langle
    0 \right|](img/file1388.png "M = \left| 0 \right\rangle\left\langle 0 \right|")。
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Lastly, we may import Matplotlib and reuse the function that we defined in
    the previous chapter for plotting training and validation losses:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以导入Matplotlib并重用我们在上一章中定义的用于绘制训练和验证损失的函数：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: And that’s all we need to get started. Let’s go for our first problem.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 那就是我们开始所需的所有内容。让我们开始我们的第一个问题。
- en: 11.2.2 A binary classification problem
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2.2 二元分类问题
- en: 'We are now ready to build our first hybrid QNN and train it to solve a binary
    classification task. Of course, the first thing we need is data and, as we discussed
    in the previous section, we shall generate it using the `make_classification`
    function. Using a hybrid QNN that will ”combine classical encoding with quantum
    classification” can make sense if, for instance, we have a large number of variables
    (features) in our dataset, so we will generate a dataset with ![20](img/file588.png
    "20") variables — that might already be quite large for current quantum hardware!
    Just to make sure that we have enough data, we will generate ![1000](img/file790.png
    "1000") samples. This is how we can do it:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好构建我们的第一个混合QNN，并训练它来解决一个二元分类任务。当然，我们首先需要数据，正如我们在上一节中讨论的，我们将使用`make_classification`函数来生成它。使用将“结合经典编码与量子分类”的混合QNN是有意义的，如果我们数据集中有大量的变量（特征），因此我们将生成一个包含![20](img/file588.png
    "20")个变量的数据集——这已经对于当前的量子硬件来说可能相当大了！为了确保我们有足够的数据，我们将生成![1000](img/file790.png "1000")个样本。这就是我们如何做到这一点的：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: By default, the `make_classification` functions generate datasets with two possible
    classes. Just what we wanted!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`make_classification`函数生成具有两个可能类别的数据集。这正是我们想要的！
- en: 'As usual, we will have to split this dataset into some training, validation,
    and test datasets:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，我们必须将这个数据集分成一些训练集、验证集和测试集：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With our data ready, we need to think about the model that we will use. Let’s
    begin by constructing the quantum layer (the QNN) that we will include at the
    end of the network.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据已经准备好了，我们需要考虑我们将要使用的模型。让我们先构建网络末尾将包含的量子层（QNN）。
- en: 'For this problem, we will use the two-local variational form that we introduced
    in the previous chapter (see *Figure* [*10.2*](ch019.xhtml#Figure10.2)). As you
    surely remember, we can implement it in PennyLane as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题，我们将使用我们在上一章中介绍的两个局部变分形式（参见*图* [*10.2*](ch019.xhtml#Figure10.2)）。正如你肯定记得的，我们可以在PennyLane中如下实现它：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will take the quantum layer to be a simple QNN on four qubits using angle
    embedding as a feature map followed by the two-local variational form that we
    have just implemented. The measurement operation in the QNN will be the computation
    of the expectation value of ![M](img/file704.png "M") on the first qubit; that’s
    a sensible choice for binary classifiers in general, because it returns a value
    between ![0](img/file12.png "0") and ![1](img/file13.png "1"). The QNN can be
    defined as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将量子层视为一个简单的四比特QNN，使用角度嵌入作为特征图，随后是刚刚实现的两个局部变分形式。QNN中的测量操作将是计算第一个量子比特上![M](img/file704.png
    "M")的期望值；这对于二元分类器来说是一个合理的选择，因为它返回一个介于![0](img/file12.png "0")和![1](img/file13.png
    "1")之间的值。QNN可以定义为如下：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Notice how we have already declared the weights dictionary that we will have
    to send to the TensorFlow interface in order to create the quantum layer. In it,
    we’ve specified that our variational form uses ![4 \cdot (2 + 1) = 12](img/file1398.png
    "4 \cdot (2 + 1) = 12") weights.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们已经声明了权重字典，我们必须将其发送到TensorFlow接口以创建量子层。在其中，我们指定我们的变分形式使用![4 \cdot (2 + 1)
    = 12](img/file1398.png "4 \cdot (2 + 1) = 12")个权重。
- en: 'We will define our hybrid QNN to have an input layer with ![20](img/file588.png
    "20") inputs in order to match the dimension of our data. This will be followed
    by a classical layer, which will be immediately followed by the quantum neural
    network (the quantum layer). Since our QNN accepts ![4](img/file143.png "4") inputs,
    the classical layer will have ![4](img/file143.png "4") neurons itself. Moreover,
    for the QNN to work optimally, we need the data to be normalized, so the classical
    layer will use a sigmoid activation function. We can define this model in Keras
    as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义我们的混合QNN，使其具有![20](img/file588.png "20")个输入，以匹配我们数据的维度。这将随后是一个经典层，紧接着是量子神经网络（量子层）。由于我们的QNN接受![4](img/file143.png
    "4")个输入，因此经典层本身也将有![4](img/file143.png "4")个神经元。此外，为了使QNN能够最优地工作，我们需要数据被归一化，因此经典层将使用sigmoid激活函数。我们可以在Keras中如下定义此模型：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To learn more…
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多…
- en: 'When defining the Keras model, you may be tempted to store the quantum layer
    in a variable and then use it in the model definition, as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义Keras模型时，你可能倾向于将量子层存储在一个变量中，然后在模型定义中使用它，如下所示：
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This code will work and, a priori, there’s nothing wrong with it. However, if
    you decide to reset or modify your model, you will also have to rerun the first
    line, with the definition of `qlayer`, if you want to re-initialize the optimizable
    parameters (weights) in the quantum neural network!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将有效运行，并且从先验知识来看，它没有任何问题。然而，如果你决定重置或修改你的模型，你也将不得不重新运行第一行，即`qlayer`的定义，如果你想要重新初始化量子神经网络中的可优化参数（权重）！
- en: 'Having the model ready, we can also define our usual early stopping callback:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模型准备就绪后，我们还可以定义我们常用的早期停止回调：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We’ve set the patience to ![2](img/file302.png "2") epochs in order to speed
    up the training; having a higher patience may easily lead to better results!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将耐心设置为![2](img/file302.png "2")个epoch，以加快训练速度；有更高的耐心可能会轻易地带来更好的结果！
- en: 'And now, all it takes for us to train our model is to — just as we’ve always
    done on TensorFlow — pick an optimizer, compile our model with the binary cross
    entropy loss function, and call the `fit` method with the appropriate arguments:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们训练模型所需做的只是——就像我们一直在TensorFlow上所做的那样——选择一个优化器，使用二元交叉熵损失函数编译我们的模型，并使用适当的参数调用`fit`方法：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Et voilà! In just a matter of minutes, your flashy hybrid model will have finished
    training. Take a moment to reflect on how easy this was. You have been able to
    train a hybrid QNN with full ease, just as if it were a simple QNN. With PennyLane,
    quantum machine learning is a piece of cake.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Et voilà！只需几分钟，你那炫目的混合模型就会完成训练。花点时间反思一下这有多简单。你能够轻松地训练一个混合QNN，就像它是一个简单的QNN一样。有了PennyLane，量子机器学习变得易如反掌。
- en: 'To check how well the training went, we can plot the training and validation
    losses with our custom function:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查训练情况，我们可以使用我们的自定义函数绘制训练和验证损失：
- en: '[PRE14]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The generated plot can be found in *Figure* [*11.1*](#Figure11.1).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表可以在*图* [*11.1*](#Figure11.1) 中找到。
- en: '![Figure 11.1: Evolution of the training and validation loss functions in the
    training of a hybrid QNN binary classifier ](img/file1399.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图11.1：混合QNN二分类器训练中训练和验证损失函数的演变](img/file1399.png)'
- en: '**Figure 11.1**: Evolution of the training and validation loss functions in
    the training of a hybrid QNN binary classifier'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**图11.1**：混合QNN二分类器训练中训练和验证损失函数的演变'
- en: 'Those losses look really good; there don’t seem to be signs of overfitting
    and the model appears to be learning. In any case, let’s compute the test accuracy.
    We may also compute the training and validation accuracies, just for reference:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些损失看起来非常好；似乎没有过拟合的迹象，模型看起来正在学习。无论如何，让我们计算测试准确率。我们也可以计算训练和验证准确率，仅供参考：
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When running the preceding code, we can see how our model has a training accuracy
    of ![95\%](img/file1400.png "95\%"), a validation accuracy of ![90\%](img/file1401.png
    "90\%"), and a test accuracy of ![96\%](img/file1402.png "96\%").
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行前面的代码时，我们可以看到我们的模型有![95\%](img/file1400.png "95\%")的训练准确率，![90\%](img/file1401.png
    "90\%")的验证准确率，以及![96\%](img/file1402.png "96\%")的测试准确率。
- en: That’s a very satisfactory result. We have just trained our first hybrid QNN
    binary classifier, and we’ve seen how it can be effectively used to solve classification
    tasks.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常令人满意的结果。我们刚刚训练了我们的第一个混合QNN二分类器，并看到了它如何有效地解决分类任务。
- en: Exercise 11.1
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.1
- en: Try to solve this problem using two additional (dense) classical layers, with
    ![16](img/file619.png "16") and ![8](img/file506.png "8") neurons each. Compare
    the results.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用两个额外的（密集的）经典层解决这个问题，每个层有![16](img/file619.png "16")和![8](img/file506.png
    "8")个神经元。比较结果。
- en: Now, we said that this chapter was going to be hands-on and we truly meant it.
    So far, we have just trained models and gotten them right in one shot, but that’s
    something that rarely happens in practice. That’s why we’ve put together a small
    subsection on how to optimize models in real-world conditions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们说这一章将是一个动手实践，我们确实是这么想的。到目前为止，我们只是训练模型并在一次尝试中就得到了正确的结果，但在实践中这种情况很少发生。这就是为什么我们专门编写了一个小节，介绍如何在现实世界条件下优化模型。
- en: 11.2.3 Training models in the real world
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2.3 在现实世界中训练模型
- en: Whether you believe it or not, we care for you, our dear reader. All this time,
    behind each and every model that we’ve trained, we’ve invested hours of meticulous
    parameter selection and model preparation — all to make sure that the results
    we give you are good enough, if not optimal.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是否相信，我们都关心你，亲爱的读者。在这段时间里，在每一个我们训练的模型背后，我们都投入了数小时细致的参数选择和模型准备——都是为了确保我们给出的结果足够好，如果不是最优的。
- en: When you set out to train models on your own, you will soon find out that things
    don’t always work as well as you expected. For each well-performing model, there
    will be tens or even hundreds of discarded ones. And that’s something you need
    to prepare yourself for.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当您开始自己训练模型时，您很快就会发现自己期望的事情并不总是那么顺利。对于每个表现良好的模型，都会有成十甚至上百个被丢弃的模型。这是您需要做好准备的事情。
- en: 'At the early stages of a machine learning project in general — and a quantum
    machine learning project in particular — you should address two main following
    questions:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在一般机器学习项目的早期阶段——尤其是量子机器学习项目——您应该解决以下两个主要问题：
- en: '**How will you log all your results?** When you train lots of models, you need
    to find a way to log their performances together with their architectures and
    the parameters used in their training. That way, you can easily identify what
    works and what doesn’t, and you can avoid repeating the same mistakes.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您将如何记录所有结果？** 当您训练大量模型时，您需要找到一种方法来记录它们的性能以及它们的架构和训练中使用的参数。这样，您可以轻松地识别出哪些有效，哪些无效，并避免重复犯同样的错误。'
- en: '**How will you explore variations of your models?** Keeping a separate script
    for every model can be manageable when you are not training many models, but this
    isn’t a solution for large-scale projects. Oftentimes, you want to try a wide
    range of configurations and see which one works best. And automation can truly
    make your life easier in this regard.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您将如何探索您模型的变体？** 当您不训练很多模型时，为每个模型保留一个单独的脚本可能是可管理的，但这并不是大规模项目的解决方案。通常，您想尝试广泛的配置，看看哪一个效果最好。而自动化在这方面确实可以让您的生活更轻松。'
- en: We leave the first question to you. In truth, there’s no universal way to address
    it — it all depends on the problem at hand and on the training strategy that you
    take. However, in regard to the second question, we do have something to offer.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将第一个问题留给您。实际上，没有通用的方法来解决这个问题——它完全取决于手头的问题和您采取的训练策略。然而，关于第二个问题，我们确实有一些东西可以提供。
- en: When training a model, choosing good hyperparameters — such as a good batch
    size or learning rate — is not an easy task, but it is a crucial one. Should you
    use a smaller or a larger learning rate? How many layers should you use? Of what
    type? Decisions, decisions, decisions! The number of possibilities grows exponentially,
    so it is impossible to explore every one of them. But, in machine learning, finding
    a good configuration can be the difference between success and failure. How can
    we do this systematically and (kind of) effortlessly?
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型时，选择良好的超参数——例如良好的批量大小或学习率——并不是一件容易的事情，但这是一件至关重要的任务。您应该使用较小的还是较大的学习率？您应该使用多少层？它们是什么类型的？决定，决定，决定！可能性的数量呈指数增长，因此不可能探索每一个。但在机器学习中，找到一个好的配置可能是成功与失败之间的区别。我们如何系统地（某种程度上）轻松地做到这一点呢？
- en: There are quite a few packages and utilities out there that can help you automate
    the search for optimal training parameters. One of the most popular ones is the
    Optuna package, which we are about to demonstrate. Please refer to *Appendix*
    [*D*](ch027.xhtml#x1-240000D), *Installing the Tools*, for installation instructions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在市面上有很多软件包和实用工具可以帮助您自动化搜索最佳训练参数。其中最受欢迎的一个是Optuna软件包，我们即将演示它。请参阅*附录* [*D*](ch027.xhtml#x1-240000D)，*安装工具*，获取安装说明。
- en: To learn more…
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多...
- en: The process of automatically searching for optimal training parameters in a
    machine learning problem fits into what is known as **automated machine learning**,
    usually abbreviated as **AutoML**. This refers to the use of automation in order
    to solve machine learning problems. Having machines in charge of training other
    machines!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习问题中自动搜索最佳训练参数的过程符合所谓的**自动化机器学习**，通常缩写为**AutoML**。这指的是使用自动化来解决机器学习问题。让机器负责训练其他机器！
- en: 'Once you’ve installed Optuna, you can import it as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您安装了Optuna，您可以按照以下方式导入它：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We are going to use Optuna to find the best possible learning rate between the
    values ![0.001](img/file1165.png "0.001") and ![0.1](img/file1163.png "0.1").
    In order to do this, we need to define a function (which we shall call `objective`)
    with a single argument (`trial`). The objective function should use the training
    parameters that we want to optimize — in a manner that we will soon make precise
    — and it should return whichever metric we want to optimize. For instance, in
    our case, we would like to maximize the validation accuracy, so the objective
    function should train a model and return the validation accuracy.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Optuna 在值 ![0.001](img/file1165.png "0.001") 和 ![0.1](img/file1163.png
    "0.1") 之间找到最佳的学习率。为了做到这一点，我们需要定义一个函数（我们将称之为 `objective`），它只有一个参数（`trial`）。目标函数应该使用我们想要优化的训练参数——我们将很快明确这一点——并且应该返回我们想要优化的任何指标。例如，在我们的情况下，我们希望最大化验证准确率，因此目标函数应该训练一个模型并返回验证准确率。
- en: 'The `trial` argument of the `objective` function is meant to represent an object
    of the `Trial` class that can be found in the `optuna``.``trial` module. We will
    use this object to define, within the objective function itself, the training
    parameters that we want to optimize, while also specifying their constraints:
    whether we want them to be integers or floats, the ranges within which we want
    our values to be, and so on.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`objective` 函数的 `trial` 参数旨在表示 `optuna.trial` 模块中可以找到的 `Trial` 类的对象。我们将使用此对象在目标函数本身中定义我们想要优化的训练参数，同时指定它们的约束：我们是否希望它们是整数或浮点数，我们希望我们的值在哪个范围内，等等。'
- en: 'For our case, this is the objective function that we would have to define:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的情况，这是我们必须要定义的目标函数：
- en: '[PRE17]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Notice how we have defined the learning rate as an optimizable parameter by
    calling the `trial``.``suggest_float``(``"``learning_rate``"``,` `0.001,` `0.1)`
    method. In general, if you want to optimize a parameter named `"``parameter``"`,
    the following applies:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们是如何通过调用 `trial.suggest_float`(`"learning_rate"`，`0.001`，`0.1`) 方法将学习率定义为可优化参数的。一般来说，如果你想优化名为
    `"parameter"` 的参数，以下适用：
- en: If the data type of the parameter is a float and the parameter is bounded between
    `m` and `M`, you should call the `suggest_float``(``"``parameter``"``,` `m``,`
    `M``)` method. If you only want your parameter to take discrete values between
    `m` and `M` separated by a step `s`, you can send the optional argument `step`
    `=` `s`, which defaults to `None` (by default, the parameter will take continuous
    values).
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果参数的数据类型是浮点数，并且参数被限制在 `m` 和 `M` 之间，你应该调用 `suggest_float`(`"parameter"`，`m`，`M`)
    方法。如果你只想让你的参数在 `m` 和 `M` 之间以步长 `s` 分隔的离散值中取值，你可以发送可选参数 `step` `=` `s`，默认值为 `None`（默认情况下，参数将取连续值）。
- en: If the data type of the parameter is an integer bounded between `m` and `M`,
    you should call `suggest_int``(``"``parameter``"``,` `m``,` `M``)`. Also, if the
    values of the parameter should be separated by a step `s` from `m` to `M`, you
    can send in `step` `=` `s`.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果参数的数据类型是介于 `m` 和 `M` 之间的整数，你应该调用 `suggest_int`(`"parameter"`，`m`，`M`)。此外，如果参数的值应该从
    `m` 到 `M` 以步长 `s` 分隔，你可以发送 `step` `=` `s`。
- en: 'If your parameter takes values out of a list `values` of possible values, you
    should call `suggest_categorical``(``"``parameter``"``,` `values``)`. For instance,
    if we wanted to try out different activation functions on a layer of a neural
    network, we could use something like the following:'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的参数的值在可能的值列表 `values` 中，你应该调用 `suggest_categorical`(`"parameter"`，`values`)。例如，如果我们想在神经网络的层上尝试不同的激活函数，我们可以使用以下类似的方法：
- en: '[PRE18]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Of course, a single objective function can have as many optimizable parameters
    as desired. They would just be defined with separate invocations of the methods
    that we’ve just outlined.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一个单一的目标函数可以有任意多的可优化参数。它们只是通过我们刚刚概述的方法的单独调用来定义的。
- en: 'So that’s how you can create an objective function and specify the parameters
    that you want to optimize within it. Now, how do we optimize them? The first step
    is to create a `Study` object with the `create_study` function, just as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这就是你可以创建一个目标函数并指定在其中要优化的参数的方法。现在，我们如何优化它们呢？第一步是使用 `create_study` 函数创建一个 `Study`
    对象，就像下面这样：
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here we have specified that we want to create a study in order to maximize
    some objective function and using `TPESampler` with a seed. By default, Optuna
    will try to minimize objective functions — that’s why we had to send in that argument.
    The sampler that we’ve passed is just the object that, during the optimization
    process, is going to look for values to try. The one we’ve selected is the default
    one, but we have passed it manually so that we could give it a seed and get reproducible
    results. There are many other samplers. Most notably, `GridSampler` allows you
    to try all the combinations of parameters out of a pre-defined ”search space.”
    For instance, we could use the following sampler:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们指定了我们要创建一个研究来最大化某个目标函数，并使用带有种子的`TPESampler`。默认情况下，Optuna会尝试最小化目标函数——这就是为什么我们必须传递那个参数。我们传递的采样器只是一个在优化过程中将寻找尝试值的对象。我们选择的是默认的采样器，但我们手动传递它，以便给它一个种子并得到可重复的结果。还有很多其他的采样器。最值得注意的是，`GridSampler`允许你尝试预定义的“搜索空间”中所有参数的组合。例如，我们可以使用以下采样器：
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This would make Optuna try out the values ![0.001](img/file1165.png "0.001"),
    ![0.003](img/file1403.png "0.003"), ![0.005](img/file1389.png "0.005"), ![0.008](img/file1404.png
    "0.008"), and ![0.01](img/file1093.png "0.01") — and no others.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使Optuna尝试![0.001](img/file1165.png "0.001")、![0.003](img/file1403.png "0.003")、![0.005](img/file1389.png
    "0.005")、![0.008](img/file1404.png "0.008")和![0.01](img/file1093.png "0.01")——以及其他值。
- en: If you want to learn more about how these samplers work, you may have a look
    at their online documentation ([https://optuna.readthedocs.io/en/stable/reference/samplers/index.html](https://optuna.readthedocs.io/en/stable/reference/samplers/index.html)).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于这些采样器如何工作的信息，你可以查看它们的在线文档([https://optuna.readthedocs.io/en/stable/reference/samplers/index.html](https://optuna.readthedocs.io/en/stable/reference/samplers/index.html))。
- en: 'With the `Study` object ready, all we have to do is call the `optimize` method
    specifying the objective function and the number of trials that we will let Optuna
    run:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备好`Study`对象后，我们只需要调用`optimize`方法，指定目标函数和我们将让Optuna运行的试验次数：
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Upon running this (it can take a while), you will get an output similar to
    the following:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个（可能需要一段时间），你将得到类似以下输出的结果：
- en: '[PRE22]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: With the parameter variations that we have considered, we haven’t seen any significant
    differences in performance. But, still, at least we’ve learned how to use Optuna!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们考虑的参数变化中，我们没有看到性能上的任何显著差异。但是，至少我们学会了如何使用Optuna！
- en: Exercise 11.2
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.2
- en: Use Optuna to simultaneously optimize the learning rate and the batch size of
    the model.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Optuna同时优化模型的学习率和批量大小。
- en: As a final remark, notice how, in the objective function, we have used the validation
    accuracy and not the test accuracy. The test dataset, remember, should only be
    used once we’ve already picked our best model. Otherwise, its independence is
    compromised. For instance, if we had saved the models following each Optuna trial,
    now it would make sense for us to compute the test accuracy on the trial 4 model
    in order to make sure that we have a low generalization error.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点，请注意，在目标函数中，我们使用了验证准确率而不是测试准确率。记住，测试数据集应该在已经选择了最佳模型之后才能使用。否则，其独立性会受到损害。例如，如果我们每次Optuna试验后都保存了模型，那么现在对我们来说，在试验4的模型上计算测试准确率是有意义的，以确保我们有一个低泛化误差。
- en: Exercise 11.3
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.3
- en: Optuna can be used on any framework, not just TensorFlow — it can be used to
    optimize any parameters that you want for any purpose! All you have to do is build
    a suitable objective function. To further illustrate this, use Optuna to find
    the minimum of the function ![f(x) = {(x - 3)}^{2}](img/file1405.png "f(x) = {(x
    - 3)}^{2}").
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna可以在任何框架中使用，而不仅仅是TensorFlow——它可以用来优化任何目的的任何参数！你只需要构建一个合适的目标函数。为了进一步说明这一点，使用Optuna找到函数![f(x)
    = {(x - 3)}^{2}](img/file1405.png "f(x) = {(x - 3)}^{2}")的最小值。
- en: To learn more…
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多...
- en: In these few pages, we haven’t been able to cover all there is to know about
    Optuna. If you would like to learn more, you should have a look at its online
    documentation. You can find it at [https://optuna.readthedocs.io/en/stable/index.html](https://optuna.readthedocs.io/en/stable/index.html).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这几页中，我们还没有能够涵盖关于Optuna的所有知识。如果你想了解更多，你应该查看其在线文档。你可以在[https://optuna.readthedocs.io/en/stable/index.html](https://optuna.readthedocs.io/en/stable/index.html)找到它。
- en: 'That was a short overview of how to train (quantum) machine learning models
    in real-world scenarios. In the following subsection, we will leave our comfort
    zone and use PennyLane to solve a new problem for us: a multi-class classification
    task.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对如何在现实场景中训练（量子）机器学习模型的一个简要概述。在接下来的小节中，我们将走出我们的舒适区，使用PennyLane为我们解决一个新的问题：一个多分类任务。
- en: 11.2.4 A multi-class classification problem
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2.4 多分类问题
- en: 'This is going to be an exciting subsection, for we are about to consider a
    new kind of problem on which to apply our QML knowledge. Nonetheless, every long
    journey begins with a first step, and ours shall be to reset the seeds of NumPy
    and TensorFlow, just to make reproducibility easier:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是一个令人兴奋的小节，因为我们即将考虑一个可以应用我们的量子机器学习知识的新问题。然而，任何漫长的旅程都是从第一步开始的，我们的第一步将是重置NumPy和TensorFlow的种子，以便更容易实现可重复性：
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We are about to consider a multi-class classification problem and, of course,
    the first thing we need is data. Our good old `make_classification` function can
    help us here, for we can give it the optional argument `n_classes` `=` `3` in
    order for it to generate a dataset with ![3](img/file472.png "3") distinct classes,
    which will be labeled as ![0](img/file12.png "0"), ![1](img/file13.png "1"), and
    ![2](img/file302.png "2"). However, there’s a catch. Increasing the number of
    classes means that, as per the function’s requirements, we will also have to tweak
    some of the default parameters; a valid configuration can be reached by setting
    the argument `n_clusters_per_class` to ![1](img/file13.png "1"). Thus, we can
    generate our dataset for ternary classification as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将考虑一个多分类问题，当然，我们首先需要的是数据。我们熟悉的`make_classification`函数在这里可以帮助我们，我们可以给它一个可选参数`n_classes`
    `=` `3`，以便它生成一个包含![3](img/file472.png "3")个不同类别的数据集，这些类别将被标记为![0](img/file12.png
    "0")、![1](img/file13.png "1")和![2](img/file302.png "2")。然而，有一个问题。增加类别的数量意味着，根据函数的要求，我们还需要调整一些默认参数；通过将参数`n_clusters_per_class`设置为![1](img/file13.png
    "1")，我们可以达到一个有效的配置。因此，我们可以这样生成我们的三分类数据集：
- en: '[PRE24]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Now that we have data, it’s time for us to think about the model. We are approaching
    a new kind of problem, so we need to go back to the basics. For now, let’s forget
    about the hybrid component of the network, and let’s try to think about how we
    could design a QNN capable of solving a ternary classification problem.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了数据，是我们思考模型的时候了。我们正接近一种新的问题类型，因此我们需要回归基础。目前，让我们先忘记网络的混合组件，试着思考如何设计一个能够解决三分类问题的QNN（量子神经网络）。
- en: A general perspective on multi-class classification tasks
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多分类任务的一般视角
- en: In this regard, it is useful to look at how this kind of problem is handled
    with classical neural networks. We know that, when solving binary classification
    problems, we consider neural networks having a single neuron in the final layer
    with a bounded activation function; in this way, we assign a label depending on
    whether the output is closer to ![0](img/file12.png "0") or ![1](img/file13.png
    "1"). Such an approach might not be as effective, in general, when having multiple
    classes.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，看看这种问题是如何用经典神经网络处理的是有用的。我们知道，在解决二元分类问题时，我们考虑的是在最终层只有一个神经元且具有有界激活函数的神经网络；这样，我们根据输出是更接近![0](img/file12.png
    "0")还是![1](img/file13.png "1")来分配标签。这种做法在处理多个类别时，通常可能不太有效。
- en: When working with ![k](img/file317.png "k")-class classification problems, neural
    networks are usually designed to have ![k](img/file317.png "k") neurons in their
    final layer — again, with bounded activation functions that make the values lie
    between ![0](img/file12.png "0") and ![1](img/file13.png "1"). And how is a label
    assigned from the output of these neurons? Easy. Each neuron is associated to
    a label, so we just assign the label of the neuron that has the highest output.
    Heuristically, you may think of each of these ![k](img/file317.png "k") neurons
    in the final layer as light bulbs — whose brightness is determined by their output
    — indicating how likely it is that the input will belong to a certain category.
    All we do in the end is assigning the category of the light bulb that shines the
    most!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理![k](img/file317.png "k")类分类问题时，神经网络通常设计为在它们的最终层有![k](img/file317.png "k")个神经元——再次强调，使用有界激活函数，使得值介于![0](img/file12.png
    "0")和![1](img/file13.png "1")之间。那么，如何从这些神经元的输出中分配标签呢？很简单。每个神经元都与一个标签相关联，所以我们只需分配输出最高的神经元的标签。直观地，你可以将这些![k](img/file317.png
    "k")个最终层的神经元看作是灯泡——其亮度由其输出决定——表示输入属于某个类别的可能性。我们最终所做的只是分配最亮的灯泡对应的类别！
- en: Porting this idea to quantum neural networks is easy. Instead of taking the
    expectation value of the observable ![M](img/file704.png "M") on the first qubit,
    we return an array of values with the expectation values of the ![M](img/file704.png
    "M") observable on the first ![k](img/file317.png "k") qubits — assigning to each
    qubit a label. It couldn’t be easier.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个想法应用到量子神经网络中很容易。我们不是在第一个量子比特上取可观测量![M](img/file704.png "M")的期望值，而是返回一个包含期望值数组的值，这些期望值是在第一个![k](img/file317.png
    "k")个量子比特上的![M](img/file704.png "M")可观测量——为每个量子比特分配一个标签。这真是太简单了。
- en: To learn more…
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多...
- en: There are other ways to build classifiers in problems with multiple classes.
    For instance, two popular approaches are the **one-versus-all** and **one-versus-one**
    methods. They involve training multiple binary classifiers and combining their
    results. We invite you to have a look at chapter 3 of Geron’s book if you are
    curious [[104](ch030.xhtml#Xhandsonml)].
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理多类问题中构建分类器有其他方法。例如，两种流行的方法是**一对多**和**一对一**方法。它们涉及训练多个二元分类器并合并它们的结果。如果你对此好奇，请查看Geron的书籍的第3章[[104](ch030.xhtml#Xhandsonml)]。
- en: 'That solves the problem of designing a QNN that can handle our task, but we
    still have an issue left: we don’t yet have a suitable loss function for this
    kind of problem. In binary classification, we could rely on the binary cross-entropy
    function, but it doesn’t work for problems with multiple categories. Luckily for
    us, there’s a loss function that generalizes the binary cross entropy. Please,
    let us introduce you to the **categorical cross-entropy** loss.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就解决了设计一个能够处理我们任务的QNN的问题，但我们仍然有一个遗留问题：我们还没有为这类问题找到一个合适的损失函数。在二元分类中，我们可以依赖二元交叉熵函数，但它不适用于多类别问题。幸运的是，有一个泛化二元交叉熵的损失函数。请允许我们向您介绍**分类交叉熵**损失函数。
- en: 'Let us consider an arbitrary neural network ![N](img/file784.png "N") that,
    for any choice of parameters ![\theta](img/file89.png "\theta") and any input
    ![x](img/file269.png "x"), returns an array ![N_{\theta}(x)](img/file1406.png
    "N_{\theta}(x)") with ![k](img/file317.png "k") entries, all of them between ![0](img/file12.png
    "0") and ![1](img/file13.png "1"). The categorical cross-entropy loss function
    depends on the parameters of the neural network ![\theta](img/file89.png "\theta"),
    the inputs ![x](img/file269.png "x"), and the targets ![y](img/file270.png "y"),
    but there is an important subtlety: the loss function expects the targets ![y](img/file270.png
    "y") to be in **one-hot** **form**. This means that ![y](img/file270.png "y")
    shouldn’t be a number representing a label (![0,1,\ldots,k - 1](img/file1407.png
    "0,1,\ldots,k - 1")). Instead, it should be a vector (an array) with ![k](img/file317.png
    "k") entries that are all set to ![0](img/file12.png "0") except for the entry
    in the position of the label, which should be set to ![1](img/file13.png "1").
    Thus, instead of having ![y = 0](img/file1408.png "y = 0"), we would have ![y
    = (1,0,\ldots,0)](img/file1409.png "y = (1,0,\ldots,0)"), or, instead of having
    ![y = k - 1](img/file1410.png "y = k - 1"), we would have ![y = (0,\ldots,0,1)](img/file1411.png
    "y = (0,\ldots,0,1)"). Under these assumptions, the categorical cross-entropy
    is defined as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个任意的神经网络![N](img/file784.png "N")，对于任何参数![\theta](img/file89.png "\theta")的选择和任何输入![x](img/file269.png
    "x")，它返回一个包含![k](img/file317.png "k")个条目的数组![N_{\theta}(x)](img/file1406.png "N_{\theta}(x)")，所有条目都在![0](img/file12.png
    "0")和![1](img/file13.png "1")之间。类别交叉熵损失函数依赖于神经网络的参数![\theta](img/file89.png "\theta")、输入![x](img/file269.png
    "x")和目标![y](img/file270.png "y")，但有一个重要的细微差别：损失函数期望目标![y](img/file270.png "y")以**独热****形式**出现。这意味着![y](img/file270.png
    "y")不应该是一个表示标签的数字 (![0,1,\ldots,k - 1](img/file1407.png "0,1,\ldots,k - 1"))。相反，它应该是一个包含![k](img/file317.png
    "k")个条目的向量（数组），其中所有条目都设置为![0](img/file12.png "0")，除了标签位置的条目，应该设置为![1](img/file13.png
    "1")。因此，我们不会得到![y = 0](img/file1408.png "y = 0")，而是得到![y = (1,0,\ldots,0)](img/file1409.png
    "y = (1,0,\ldots,0)"),或者，我们不会得到![y = k - 1](img/file1410.png "y = k - 1")，而是得到![y
    = (0,\ldots,0,1)](img/file1411.png "y = (0,\ldots,0,1)"),等等。在这些假设下，类别交叉熵被定义为如下：
- en: '![H(\theta;x,y) = - \sum\limits_{j = 1}^{k}y_{j}{\log}(N_{\theta}(x)_{j}).](img/file1412.png
    "H(\theta;x,y) = - \sum\limits_{j = 1}^{k}y_{j}{\log}(N_{\theta}(x)_{j}).")'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![H(\theta;x,y) = - \sum\limits_{j = 1}^{k}y_{j}{\log}(N_{\theta}(x)_{j}).](img/file1412.png
    "H(\theta;x,y) = - \sum\limits_{j = 1}^{k}y_{j}{\log}(N_{\theta}(x)_{j}).")'
- en: Of course, we have used the subindex ![j](img/file258.png "j") in ![y](img/file270.png
    "y") and ![N_{\theta}(x)](img/file1406.png "N_{\theta}(x)") to denote their ![j](img/file258.png
    "j")-th entries. Notice how, in this definition, we have implicitly assumed that
    the first neuron in the final layer is associated to the label ![0](img/file12.png
    "0"), the second neuron is associated to ![1](img/file13.png "1"), and so on.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们在![y](img/file270.png "y")和![N_{\theta}(x)](img/file1406.png "N_{\theta}(x)")中使用了下标![j](img/file258.png
    "j")来表示它们的![j](img/file258.png "j")-th条目。注意，在这个定义中，我们隐含地假设了最终层的第一个神经元与标签![0](img/file12.png
    "0")相关联，第二个神经元与![1](img/file13.png "1")相关联，以此类推。
- en: Exercise 11.4
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.4
- en: Prove that the binary cross-entropy loss is a particular case of the categorical
    cross-entropy loss for ![k = 2](img/file1413.png "k = 2").
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 证明二元交叉熵损失是类别交叉熵损失的一个特殊情况，当![k = 2](img/file1413.png "k = 2")时。
- en: Of course, the categorical cross-entropy function is a reasonable loss function
    for multi-class classification, and it shares some nice properties with the binary
    cross-entropy loss function. For instance, it is zero if a classifier gets an
    output completely right (it assigns ![1](img/file13.png "1") to the correct output
    and ![0](img/file12.png "0") to the rest), but it diverges if a classifier assigns
    ![1](img/file13.png "1") to a wrong output and ![0](img/file12.png "0") to the
    rest.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，类别交叉熵函数是多类分类的一个合理的损失函数，并且它与二元交叉熵损失函数共享一些良好的性质。例如，如果一个分类器完全正确地得到了输出（它将![1](img/file13.png
    "1")分配给正确的输出，将![0](img/file12.png "0")分配给其余部分），那么它的值就是零，但如果分类器将![1](img/file13.png
    "1")分配给错误的输出，将![0](img/file12.png "0")分配给其余部分，那么它就会发散。
- en: So far, we already know how to implement our QNN and we have a loss function,
    so we just have to finalize the details of our architecture. Regarding the quantum
    layer, we already know which observable we are going to use, so that’s not a problem.
    For the feature map, we will rely on angular encoding and, for the variational
    form, we shall use the two-local variational form. To keep things somewhat efficient,
    we will take our QNN to have four qubits, and we will leave the rest of the hybrid
    architecture just as it was in the previous subsection.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经知道如何实现我们的QNN，并且我们有一个损失函数，所以我们只需要最终确定我们架构的细节。关于量子层，我们已经知道我们将使用哪个可观察量，所以这不是问题。对于特征图，我们将依赖角度编码，对于可变形式，我们将使用双局部可变形式。为了保持一定的效率，我们将我们的QNN设置为四个量子位，并将混合架构的其他部分保持与上一小节相同。
- en: That’s enough abstract thinking for now; let’s get to the code. And be prepared,
    because things are about to get hot.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经足够进行抽象思考了；让我们转向代码。并且做好准备，因为接下来事情可能会变得很热。
- en: Implementing a QNN for a ternary classification problem
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 实现一个用于三分类问题的QNN
- en: According to our plan, the first thing that we need to do is encode our array
    of targets `y` in one-hot form.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的计划，我们首先需要做的事情是将我们的目标数组`y`编码为one-hot形式。
- en: Exercise 11.5
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.5
- en: There is a variation of the categorical cross entropy loss that doesn’t require
    the targets to be in one-hot form. It is the **sparse** **categorical cross entropy
    loss**. Try to replicate what follows using this loss function and the unencoded
    targets. You may access it as `tf``.``keras``.``losses``.` `SparseCategoricalCrossentropy`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一种分类交叉熵损失的变体，它不需要目标以one-hot形式存在。这就是**稀疏** **分类交叉熵损失**。尝试使用这个损失函数和未编码的目标来复制以下内容。你可以通过`tf.keras.losses.SparseCategoricalCrossentropy`来访问它。
- en: We could implement our own one-hot encoder, but there’s no need to. The scikit-learn
    package — once again to our rescue! — already implements a `OneHotEncoder` class,
    which you can import from `sklearn``.``preprocessing`. You can work with this
    class just as you would with other familiar scikit-learn classes, such as `MaxAbsScaler`.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以自己实现一个one-hot编码器，但没必要。scikit-learn包——再次拯救我们！——已经实现了一个`OneHotEncoder`类，你可以从`sklearn.preprocessing`导入它。你可以像使用其他熟悉的scikit-learn类一样使用这个类，例如`MaxAbsScaler`。
- en: 'In order to one-hot-encode an array of targets, you would need a `OneHotEncoder`
    object and you would just have to pass the array to the `fit_transform` method.
    But with a catch: the array should be a column vector! Our array of targets `y`
    is one-dimensional, so we will have to reshape it before we can feed it to the
    `fit_transform` method. Thus, this is how we can encode our array of targets in
    one-hot form:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对目标数组进行one-hot编码，你需要一个`OneHotEncoder`对象，你只需要将数组传递给`fit_transform`方法。但是有一个限制：数组应该是一个列向量！我们的目标数组`y`是一维的，所以我们必须在将其传递给`fit_transform`方法之前对其进行重塑。因此，这就是我们如何将目标数组编码为one-hot形式的方法：
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Notice how we have added the argument `sparse` `=` `False`. This Boolean value,
    which defaults to `True`, determines whether or not the encoder should return
    sparse matrices. Sparse matrices are datatypes that can be very memory-efficient
    when storing matrices with lots of zeros, such as one-hot encoded arrays. Essentially,
    instead of logging the value of each entry in a matrix, a sparse matrix only keeps
    track of the non-zero entries in it. When working with very large matrices, it
    can save a ton of memory, but, sadly, using sparse matrices would lead to problems
    in the training, so we need our one-hot encoder to give us an ordinary array.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们添加了`sparse = False`参数。这个默认为`True`的布尔值决定了编码器是否应该返回稀疏矩阵。稀疏矩阵是一种数据类型，当存储具有许多零的矩阵（如one-hot编码数组）时，可以非常节省内存。本质上，稀疏矩阵只跟踪矩阵中的非零条目，而不是记录矩阵中每个条目的值。当处理非常大的矩阵时，它可以节省大量的内存，但遗憾的是，使用稀疏矩阵会导致训练中出现问题，因此我们需要我们的one-hot编码器给我们一个普通数组。
- en: To learn more…
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多...
- en: 'The neat thing about the `OneHotEncoder` class is that, once we have encoded
    an array of targets with representatives from each class using `fit_transform`,
    we can use the `transform` method on any array of targets. In our case, the `hot`
    object will remember that there are ![3](img/file472.png "3") classes in our dataset,
    and hence `hot``.` `transform` will encode any targets correctly: even if it’s
    given an input with nothing other than zeros, it will still encode them as arrays
    of length ![3](img/file472.png "3").'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`OneHotEncoder` 类的巧妙之处在于，一旦我们使用 `fit_transform` 对每个类别的代表进行编码后，我们就可以在任意目标数组上使用
    `transform` 方法。在我们的例子中，`hot` 对象将记住我们的数据集中有 ![3](img/file472.png "3") 个类别，因此 `hot`
    的 `transform` 方法将正确地编码任何目标：即使它接收到的输入除了零以外什么都没有，它仍然会将它们编码为长度为 ![3](img/file472.png
    "3") 的数组。'
- en: 'We have to do nothing more to our data, so we can now split it into some training,
    validation, and test datasets:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对我们的数据不再需要做任何事情，因此现在我们可以将其分成一些训练、验证和测试数据集：
- en: '[PRE26]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'And we can now implement the QNN that will constitute the quantum layer of
    our model. In truth, there’s nothing particularly special about this quantum neural
    network other than the fact that it will return an array of values rather than
    a single one. We can define it, according to our previous specification, as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以实现构成我们模型量子层的 QNN。实际上，这个量子神经网络没有什么特别之处，除了它将返回一个值数组而不是单个值。根据我们之前的规格，我们可以定义它如下：
- en: '[PRE27]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The code is pretty self-explanatory. Notice that, as usual, we have taken the
    chance to define the weights dictionary that we will use in the definition of
    the quantum Keras layer. In this case, we will be using ![12](img/file601.png
    "12") weights, exactly as in the case of our model in *Subsection* * [*11.2.2*](#x1-19900011.2.2),
    because we are using the same variational form and the same number of qubits and
    repetitions.*
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 代码相当直观。请注意，像往常一样，我们有机会定义一个权重字典，这个字典将在量子 Keras 层的定义中使用。在这种情况下，我们将使用 ![12](img/file601.png
    "12") 权重，正如我们在 *子节* * [*11.2.2*](#x1-19900011.2.2) 中的模型一样，因为我们使用的是相同的变分形式和相同数量的量子比特和重复次数。
- en: '*With our QNN ready, we can define the Keras model for our hybrid QNN. This
    is just analogous to what we did in the previous subsection, with a few important
    differences — don’t copy-paste so fast! First of all, in this case, we need to
    set the output dimension of the quantum layer to three, not one. And, much more
    importantly, we need to add an extra activation function on the QNN output.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '*随着我们的 QNN 准备就绪，我们可以定义混合 QNN 的 Keras 模型。这就像我们在前面的子节中做的那样，但有一些重要的区别——不要那么快复制粘贴！首先，在这种情况下，我们需要将量子层的输出维度设置为三个，而不是一个。更重要的是，我们需要在
    QNN 输出上添加一个额外的激活函数。'
- en: 'The categorical cross entropy loss function expects probability distributions.
    In principle, it assumes that the output of the ![j](img/file258.png "j")-th neuron
    is the probability that the input belong to category ![j](img/file258.png "j").
    Thus, the data that the model outputs should be normalized: it should add up to
    ![1](img/file13.png "1"). Nevertheless, a priori, there’s no way for us to guarantee
    that the QNN will return some normalized outputs with our current setup. In order
    to ensure this, we may use the **softmax** activation function, which is defined
    as'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 离散交叉熵损失函数期望概率分布。原则上，它假设第 ![j](img/file258.png "j") 个神经元的输出是输入属于类别 ![j](img/file258.png
    "j") 的概率。因此，模型输出的数据应该是归一化的：它应该加起来等于 ![1](img/file13.png "1")。然而，从先验的角度来看，我们无法保证我们的
    QNN 将返回一些归一化的输出。为了确保这一点，我们可以使用 **softmax** 激活函数，其定义如下
- en: '| ![\sigma(x_{1},\ldots,x_{n}) = \frac{1}{\sum\limits_{j = 1}^{n}e^{x_{j}}}(e^{x_{1}},\ldots,e^{x_{n}}).](img/file1414.png
    "\sigma(x_{1},\ldots,x_{n}) = \frac{1}{\sum\limits_{j = 1}^{n}e^{x_{j}}}(e^{x_{1}},\ldots,e^{x_{n}}).")
    |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| ![\sigma(x_{1},\ldots,x_{n}) = \frac{1}{\sum\limits_{j = 1}^{n}e^{x_{j}}}(e^{x_{1}},\ldots,e^{x_{n}}).](img/file1414.png
    "\sigma(x_{1},\ldots,x_{n}) = \frac{1}{\sum\limits_{j = 1}^{n}e^{x_{j}}}(e^{x_{1}},\ldots,e^{x_{n}}).")
    |'
- en: It’s easy to check that ![\sigma](img/file1415.png "\sigma") is a vector with
    components bounded by ![0](img/file12.png "0") and ![1](img/file13.png "1") which
    add up to ![1](img/file13.png "1") and, hence, is a probability distribution.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易验证 ![\sigma](img/file1415.png "\sigma") 是一个由 ![0](img/file12.png "0") 和 ![1](img/file13.png
    "1") 界定的向量，其分量之和为 ![1](img/file13.png "1")，因此是一个概率分布。
- en: 'In addition to these modifications, we will add an extra classical layer with
    ![8](img/file506.png "8") neurons:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些修改之外，我们还将添加一个额外的经典层，包含 ![8](img/file506.png "8") 个神经元：
- en: '[PRE28]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: And we can now compile our model with the Adam optimizer and the categorical
    cross-entropy loss before training it with the `fit` method; nothing particularly
    exciting here. As a fun fact, if you were forgetful enough to tell TensorFlow
    to use the binary cross-entropy loss instead of the categorical cross-entropy
    one, it would still use the categorical cross-entropy loss (don’t look at us;
    we don’t say it from experience, right?). This is a rather nice and thoughtful
    feature from the guys behind TensorFlow.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用Adam优化器和分类交叉熵损失来编译我们的模型，并在`fit`方法之前对其进行训练；这里没有什么特别激动人心的地方。有趣的事实是，如果你足够健忘，告诉TensorFlow使用二元交叉熵损失而不是分类交叉熵损失，它仍然会使用分类交叉熵损失（不要看我们；我们不是从经验中说的，对吧？）。这是TensorFlow背后的人们的相当好和周到的一个特性。
- en: '[PRE29]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'After a few minutes of training, we may get a plot of the evolution of the
    training and validation losses with the following instruction:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 经过几分钟的训练，我们可能会得到以下指令下训练和验证损失演变的图表：
- en: '[PRE30]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The resulting plot can be found in *Figure* [*11.2*](#Figure11.2), which shows
    the evolution of both losses.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图表可以在*图* [*11.2*](#Figure11.2) 中找到，它显示了损失函数的演变。
- en: '![Figure 11.2: Evolution of the training and validation loss functions in the
    training of a hybrid QNN multi-class classifier ](img/file1416.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图11.2：混合QNN多类分类器训练中训练和验证损失函数的演变](img/file1416.png)'
- en: '**Figure 11.2**: Evolution of the training and validation loss functions in
    the training of a hybrid QNN multi-class classifier'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**图11.2**：混合QNN多类分类器训练中训练和验证损失函数的演变'
- en: 'We may now compute the training, validation, and test accuracies of our freshly-trained
    models, but, in order to do so, the `accuracy_score` function needs the predicted
    and actual labels to be represented by numbers, not encoded in one-hot form as
    arrays. Hence, we need to undo the one-hot encoding. For this purpose, we can
    just use the `argmax` method, which returns the entry of the maximum value in
    an array, and it can be given an optional `axis` argument for it to be applied
    only in one axis. Thus, we may compute the accuracy scores as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以计算我们新训练的模型的训练、验证和测试准确率，但为了做到这一点，`accuracy_score`函数需要预测和实际标签以数字形式表示，而不是以one-hot形式作为数组进行编码。因此，我们需要撤销one-hot编码。为此，我们可以使用`argmax`方法，它返回数组中最大值的条目，并且可以提供一个可选的`axis`参数，以便它只在一个轴上应用。因此，我们可以按以下方式计算准确率得分：
- en: '[PRE31]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This returns a training accuracy of ![67\%](img/file1417.png "67\%"), a validation
    accuracy of ![53\%](img/file1418.png "53\%"), and a test accuracy of ![60\%](img/file1419.png
    "60\%"). Notice that the low accuracy on the validation dataset — compared to
    that of the training dataset — seems to indicate an overfitting problem. This
    might be fixed, for example, by using a larger training dataset; of course, this
    would lead to longer training times.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回以下训练准确率![67%](img/file1417.png "67%")，验证准确率![53%](img/file1418.png "53%")，以及测试准确率![60%](img/file1419.png
    "60%")。请注意，与训练数据集相比，验证数据集上的低准确率似乎表明存在过拟合问题。这可能可以通过使用更大的训练数据集来修复；当然，这会导致更长的训练时间。
- en: Exercise 11.6
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.6
- en: Just to further leave our ”classifier comfort zone,” try to implement a hybrid
    model able to do regression. This model should be trained on some data with inputs
    ![x](img/file269.png "x") and target values ![y](img/file270.png "y") for which
    there is a continuous function ![f(x)](img/file800.png "f(x)") such that ![f(x)
    \simeq y](img/file1420.png "f(x) \simeq y") (you can create such a dataset, for
    instance, with the `make_regression` method from scikit-learn). The model should
    try to learn the function ![f](img/file778.png "f") for all the points in the
    dataset.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步跳出我们的“分类器舒适区”，尝试实现一个能够进行回归的混合模型。这个模型应该在一些具有输入![x](img/file269.png "x")和目标值![y](img/file270.png
    "y")的数据上训练，对于这些数据存在一个连续函数![f(x)](img/file800.png "f(x)")，使得![f(x) ≈ y](img/file1420.png
    "f(x) ≈ y")（例如，您可以使用scikit-learn的`make_regression`方法创建这样的数据集）。该模型应该尝试学习数据集中所有点的函数![f](img/file778.png
    "f")。
- en: You may design this model using some classical layers, followed by a quantum
    layer like the ones that we have considered, and a final classical layer with
    no activation functions and just one neuron. You should train it with the mean
    squared error loss.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用一些经典层设计这个模型，然后是一个我们考虑过的量子层，最后是一个没有激活函数且只有一个神经元的经典层。您应该使用均方误差损失对其进行训练。
- en: That concludes our study of hybrid architectures in PennyLane. It’s time for
    us to get to Qiskit, and that’s going to be a very different adventure!
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们在 PennyLane 中对混合架构的研究。是时候我们转向 Qiskit 了，这将是一次非常不同的冒险！
- en: 11.3 Hybrid architectures in Qiskit
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11.3 Qiskit 中的混合架构
- en: In the previous section, we discussed how hybrid QNNs could be implemented and
    trained using PennyLane in conjunction with TensorFlow, an ML framework that we
    already know how to use. We will devote this section to studying how to work with
    these hybrid architectures in Qiskit, and in this mission we will need to face
    a new challenge.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了如何使用 PennyLane 和我们已知的机器学习框架 TensorFlow 来实现和训练混合量子神经网络。我们将在本节中研究如何在
    Qiskit 中使用这些混合架构，在这个任务中，我们将面临一个新的挑战。
- en: 'For better or for worse, Qiskit doesn’t have a built-in TensorFlow interface
    at the time of writing. It only has native support for a different ML framework:
    PyTorch. So, if we want to get those hybrid NNs working on Qiskit, we better learn
    a thing or two about PyTorch. As daunting as this task may seem, it won’t be such
    a hassle and it will greatly pay off in the future — and, yes, the future is our
    next chapter on QGANs.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 无论好坏，截至撰写本文时，Qiskit 没有内置的 TensorFlow 接口。它只支持一个不同的机器学习框架：PyTorch。因此，如果我们想在 Qiskit
    上运行那些混合神经网络，我们最好学习一些关于 PyTorch 的知识。尽管这项任务可能看起来很艰巨，但它不会那么麻烦，而且将来会带来巨大的回报——是的，未来就是我们的下一章关于
    QGANs。
- en: Important note
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We will be using **version 1.13** of the PyTorch package. If you are using a
    different version, things may be slightly different!
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 **版本 1.13** 的 PyTorch 包。如果您使用的是不同版本，事情可能会有所不同！
- en: What’s so special about PyTorch to be worth our time beyond this short section?
    Come and see.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 有什么特别之处，值得我们花时间在这短短的一节之外去了解？来看看吧。
- en: 11.3.1 Nice to meet you, PyTorch!
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3.1 欢迎来到 PyTorch！
- en: So far, we have worked with TensorFlow. In our experience, this framework provides
    a very easy and streamlined experience for the implementation and training of
    all sorts of network-based models. However, there’s a small catch behind all that
    ease of use. In this book, we haven’t been using ”pure TensorFlow,” but we have
    been relying heavily on Keras. In spite of being fully integrated into TensorFlow,
    Keras is a component that creates some additional layers of abstraction in order
    to simplify the handling of neural-network models in TensorFlow. All this time,
    Keras has been taking care of lots of things for us behind the scenes.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在使用 TensorFlow。根据我们的经验，这个框架为各种基于网络的模型的实现和训练提供了一个非常简单和流畅的体验。然而，在这所有易用性背后，有一个小小的陷阱。在这本书中，我们并没有使用“纯
    TensorFlow”，而是严重依赖 Keras。尽管 Keras 已经完全集成到 TensorFlow 中，但它是一个创建了一些额外的抽象层以简化 TensorFlow
    中神经网络模型处理的组件。在这段时间里，Keras 一直在幕后为我们处理很多事情。
- en: 'At the time of writing, there are two very popular ML frameworks out there:
    TensorFlow and PyTorch. The former we already know, the latter we soon will. PyTorch,
    unlike TensorFlow, doesn’t come with its own Keras (although there are some third-party
    packages that provide similar functionalities). In PyTorch, we will have to take
    care of many details ourselves. And that’s great. Granted, learning how to use
    PyTorch will require a tiny bit more effort on our part, but PyTorch will offer
    us a level of flexibility that TensorFlow’s Keras simply can’t. Let’s get started
    then.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，有两个非常流行的机器学习框架：TensorFlow 和 PyTorch。前者我们已经很熟悉了，后者我们很快就会了解。与 TensorFlow
    不同，PyTorch 并没有自带 Keras（尽管有一些第三方包提供了类似的功能）。在 PyTorch 中，我们将不得不自己处理许多细节。这很好。当然，学习如何使用
    PyTorch 将需要我们付出一点额外的努力，但 PyTorch 将为我们提供 TensorFlow 的 Keras 简单无法达到的灵活性。那么，让我们开始吧。
- en: We will be using version 1.13 of the PyTorch package. Please refer to *Appendix*
    [*D*](ch027.xhtml#x1-240000D), *Installing the Tools*, for instructions on how
    to install it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 PyTorch 包的 1.13 版本。请参阅 *附录* [*D*](ch027.xhtml#x1-240000D)，*安装工具*，了解如何安装它。
- en: 'As usual, we shall begin by importing NumPy and a few utilities from scikit-learn.
    We will also set a seed for NumPy:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，我们将从导入 NumPy 和 scikit-learn 的一些实用工具开始。我们还将为 NumPy 设置一个种子：
- en: '[PRE32]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'With those imports out of the way, we can get to our main dish. This is how
    you can import PyTorch and give it a seed to ensure reproducibility:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成这些导入之后，我们可以进入我们的主要内容。这是如何导入 PyTorch 并为其设置一个种子以确保可重复性的方法：
- en: '[PRE33]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Most functionality related to the implementation of models is in the `torch``.``nn`
    module, and most activation functions can be found in the `torch``.``nn``.``functional`
    module, so let’s import these as well:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 与模型实现相关的多数功能都在 `torch.nn` 模块中，而大多数激活函数可以在 `torch.nn.functional` 模块中找到，所以让我们也导入这些模块：
- en: '[PRE34]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Those are all the imports that we need for now.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这些就是我们现在需要的所有导入。
- en: Setting up a model in PyTorch
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 PyTorch 中设置模型
- en: In order to understand how the PyTorch package works, we will implement and
    train a simple binary classifier as a (classical) neural network. This neural
    network will take ![16](img/file619.png "16") inputs and return a unique output
    between ![0](img/file12.png "0") and ![1](img/file13.png "1"). As usual, the two
    possible labels will be ![0](img/file12.png "0") and ![1](img/file13.png "1")
    and the output label will be decided based on whether the network output is closer
    to ![0](img/file12.png "0") or ![1](img/file13.png "1").
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解 PyTorch 包的工作原理，我们将实现并训练一个简单的二分类器作为（经典的）神经网络。这个神经网络将接受 ![16](img/file619.png
    "16") 个输入，并返回一个介于 ![0](img/file12.png "0") 和 ![1](img/file13.png "1") 之间的唯一输出。像往常一样，两个可能的标签将是
    ![0](img/file12.png "0") 和 ![1](img/file13.png "1")，输出标签将根据网络输出更接近 ![0](img/file12.png
    "0") 还是 ![1](img/file13.png "1") 来决定。
- en: 'Let’s see how we can implement this neural network classifier. In PyTorch,
    model architectures are defined as subclasses of the `nn``.``Module` class, and
    individual models are objects of these subclasses. When defining subclasses of
    `nn``.``Module`, you should implement an initializer that first calls the parent’s
    initializer and then prepares all the variables of the model architecture; for
    instance, all the network layers should be initialized here. In addition, you
    need to provide a `forward` method that defines the behavior of the network: this
    method should take any input to the network as an argument and return its output.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何实现这个神经网络分类器。在 PyTorch 中，模型架构被定义为 `nn.Module` 类的子类，而单个模型是这些子类的对象。在定义
    `nn.Module` 的子类时，你应该实现一个初始化器，该初始化器首先调用父类的初始化器，然后准备模型架构的所有变量；例如，所有的网络层都应该在这里初始化。此外，你需要提供一个
    `forward` 方法来定义网络的行为：这个方法应该接受网络输入的任何参数，并返回其输出。
- en: 'Our desired neural network could be implemented as follows (don’t worry, we
    will discuss this piece of code right away):'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望实现的神经网络可以如下实现（别担心，我们马上就会讨论这段代码）：
- en: '[PRE35]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'There are a few things to digest in this implementation. Let us first look
    at the initializer. As expected, we are defining a subclass of `nn``.``Module`
    and we are first calling the parent’s initializer; so far, so good. Then we are
    defining what seem to be the layers of the neural network, and here is where some
    confusion may arise. Our first issue arises from terminology: ”linear layers”
    are PyTorch’s equivalent of Keras’ ”dense” layers — not a big deal. But then we
    have a deeper issue. Back in our Keras days, we defined the layers of a neural
    network by specifying the number of neurons they had and their activation function.
    But here there’s no trace of activation functions and the layers take what seem
    to be two-dimensional arguments. What’s going on?'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实现中，有几个要点需要消化。让我们首先看看初始化器。正如预期的那样，我们正在定义一个 `nn.Module` 的子类，并且我们首先调用了父类的初始化器；到目前为止，一切顺利。然后我们定义了看起来像是神经网络层的部分，这就是可能出现混淆的地方。我们第一个问题来自于术语：“线性层”是
    PyTorch 对 Keras “密集”层的等效，这不是什么大问题。但接着我们遇到了更深层次的问题。回到我们使用 Keras 的日子，我们通过指定神经网络的神经元数量及其激活函数来定义网络层。但在这里，我们找不到激活函数的痕迹，而且层接受看起来像是二维的参数。这是怎么回事？
- en: In a neural network, you have a bunch of neurons that are arranged into arrays,
    and these arrays are connected by some ”linear wiring” between them. In addition,
    each array of neurons has a (usually non-linear) activation function. In Keras,
    layers were associated to these arrays of neurons themselves (with their activation
    functions) and to the ”linear wiring” before them. In PyTorch, on the other hand,
    when we speak of layers, we only refer to the linear wiring between these arrays
    of neurons. Hence, `nn``.``Linear``(16,` `8)` is nothing more than the linear
    wiring — with its weights and biases — between an array of ![16](img/file619.png
    "16") neurons and an array of ![8](img/file506.png "8") neurons. This will make
    more sense when we look at the `forward` method.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络中，你有一堆排列成数组的神经元，这些数组通过它们之间的某些“线性连接”相互连接。此外，每个神经元数组都有一个（通常是非线性）激活函数。在 Keras
    中，层与这些神经元数组本身（及其激活函数）以及它们之前的“线性连接”相关联。另一方面，在 PyTorch 中，当我们提到层时，我们只指的是这些神经元数组之间的线性连接。因此，`nn``.``Linear``(16,`
    `8)` 仅仅是 ![16](img/file619.png "16") 个神经元数组与 ![8](img/file506.png "8") 个神经元数组之间的线性连接——包括其权重和偏差。当我们查看
    `forward` 方法时，这会更有意义。
- en: The `forward` method defines what happens to any input that gets into the network.
    In its implementation, we can see how any input, which will be a PyTorch tensor
    of length ![16](img/file619.png "16"), goes through the first layer. This first
    layer is the ”linear wiring” between an array of ![16](img/file619.png "16") neurons
    and an array of ![8](img/file506.png "8") neurons; it has its own weights ![w_{jk}](img/file1421.png
    "w_{jk}") and biases ![b_{k}](img/file1422.png "b_{k}") and, for any input ![(x_{1},\ldots,x_{16})](img/file1423.png
    "(x_{1},\ldots,x_{16})"), it returns a vector ![({\hat{x}}_{1},\ldots,{\hat{x}}_{8})](img/file1424.png
    "({\hat{x}}_{1},\ldots,{\hat{x}}_{8})") with
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`forward` 方法定义了任何输入进入网络后会发生什么。在其实现中，我们可以看到任何输入，它将是一个长度为 ![16](img/file619.png
    "16") 的 PyTorch 张量，如何通过第一层。这一层是 ![16](img/file619.png "16") 个神经元数组与 ![8](img/file506.png
    "8") 个神经元数组之间的“线性连接”；它有自己的权重 ![w_{jk}](img/file1421.png "w_{jk}") 和偏差 ![b_{k}](img/file1422.png
    "b_{k}")，并且对于任何输入 ![(x_{1},\ldots,x_{16})](img/file1423.png "(x_{1},\ldots,x_{16})")，它返回一个向量
    ![({\hat{x}}_{1},\ldots,{\hat{x}}_{8})](img/file1424.png "({\hat{x}}_{1},\ldots,{\hat{x}}_{8})")，其'
- en: '| ![{\hat{x}}_{k} = \sum\limits_{j = 1}^{16}w_{jk}x_{j} + b_{k}.](img/file1425.png
    "{\hat{x}}_{k} = \sum\limits_{j = 1}^{16}w_{jk}x_{j} + b_{k}.") |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| ![{\hat{x}}_{k} = \sum\limits_{j = 1}^{16}w_{jk}x_{j} + b_{k}.](img/file1425.png
    "{\hat{x}}_{k} = \sum\limits_{j = 1}^{16}w_{jk}x_{j} + b_{k}.") |'
- en: Then, each entry in the resulting tensor goes through the ELU activation function.
    The rest of the code is self-explanatory and simply defines a neural network that
    matches our specifications.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，结果张量中的每个条目都会通过 ELU 激活函数。其余的代码是自我解释的，它只是简单地定义了一个符合我们规格的神经网络。
- en: To learn more…
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多…
- en: Layers in PyTorch define their own weights and biases. If you wish to remove
    the biases — setting them to zero for all eternity — you may do so by sending
    the optional argument `bias` `=` `False` when initializing a layer.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 中的层定义它们自己的权重和偏差。如果您希望移除偏差——将其设置为永远为零——您可以在初始化层时发送可选参数 `bias` `=` `False`。
- en: 'Now that we have our model architecture defined, we can instantiate it into
    an individual model by initializing an object of the `TorchClassifier` class.
    A nice thing about PyTorch models, by the way, is that they can be printed; their
    output gives you an overview of the different model components. Let’s create our
    model object and see this in action:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了模型架构，我们可以通过初始化 `TorchClassifier` 类的对象来将其实例化为一个单独的模型。顺便说一句，PyTorch 模型的一个优点是它们可以被打印；它们的输出会给你一个不同模型组件的概述。让我们创建我们的模型对象并看看这个动作：
- en: '[PRE36]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Upon running this, we get the following output from the print instruction:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后，我们从打印指令中得到了以下输出：
- en: '[PRE37]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This is somewhat analogous to the model summaries that we could print in Keras.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们在 Keras 中可以打印的模型摘要有些类似。
- en: 'By default, the weights and biases of models are random, so our newly-created
    `model` should already be ready to be used. Let’s try it out! The `torch``.``rand`
    function can create a random tensor of any specified size. We will use it to feed
    our model some random data and see if it works:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型的权重和偏差是随机的，因此我们新创建的 `model` 应该已经准备好使用。让我们试试看！`torch``.``rand` 函数可以创建任何指定大小的随机张量。我们将使用它来向我们的模型提供一些随机数据，看看它是否工作：
- en: '[PRE38]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This is the output that we get:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的输出：
- en: '[PRE39]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'And there we have it! As expected, our model returns a value between ![0](img/file12.png
    "0") and ![1](img/file13.png "1"). By the way, notice one little thing in the
    output: right next to the tensor value, there is a `grad_fn` value that somehow
    remembers that this output was last obtained from the application of a sigmoid
    function. Interesting, isn’t it? Well, you may remember that TensorFlow used its
    own tensor datatype, and PyTorch has its own tensors too. The cool thing about
    them is that every PyTorch tensor keeps track of how it was computed in order
    to enable gradient computation through backpropagation. We will further discuss
    this later on in this subsection.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！正如预期的那样，我们的模型返回的值在![0](img/file12.png "0")和![1](img/file13.png "1")之间。顺便说一下，注意输出中的一个细节：在张量值旁边，有一个`grad_fn`值，它以某种方式记得这个输出是最后通过应用sigmoid函数获得的。有趣，不是吗？好吧，你可能记得TensorFlow使用它自己的张量数据类型，PyTorch也有它自己的张量。它们酷的地方在于，每个PyTorch张量都会跟踪它是如何计算的，以便通过反向传播启用梯度计算。我们将在本小节稍后进一步讨论这一点。
- en: 'In any case, now that our network is all set up, let us generate some data
    and split it into some training, validation, and test datasets:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，现在我们的网络已经全部设置好了，让我们生成一些数据，并将其分成一些训练、验证和测试数据集：
- en: '[PRE40]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Training a model in PyTorch
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在PyTorch中训练模型
- en: In principle, we could work with this raw data just as we did in TensorFlow
    — perhaps converting it to PyTorch tensors, but still. However, we know that PyTorch
    will require us to take care of many things ourselves; one of which will be splitting
    our data into batches should we want to. Doing that ourselves could be tedious
    to say the least. Thankfully, PyTorch comes with some tools that can assist us
    in the process, so we better give them a shot.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在原则上，我们可以像在TensorFlow中那样处理这些原始数据——也许将其转换为PyTorch张量，但仍然如此。然而，我们知道PyTorch将需要我们亲自处理许多事情；其中之一就是，如果我们想的话，将我们的数据分成批次。自己来做这件事至少是繁琐的。幸运的是，PyTorch提供了一些工具，可以帮助我们在过程中，所以我们最好给他们一个机会。
- en: 'The best way to deal with datasets in PyTorch is by storing data in subclasses
    of a `Dataset` class, which can be found in the `torch``.``utils``.``data` module.
    Any subclasses of `Dataset` should implement an initializer, a `__getitem__` method
    (to access data items by indexing), and a `__len__` method (returning the number
    of items in the dataset). For our purposes, we can create a subclass in order
    to create datasets from our NumPy arrays:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch中处理数据集的最佳方式是将数据存储在`Dataset`类的子类中，该类位于`torch.utils.data`模块中。任何`Dataset`的子类都应该实现一个初始化器，一个`__getitem__`方法（通过索引访问数据项），以及一个`__len__`方法（返回数据集中的项目数量）。为了我们的目的，我们可以创建一个子类，以便从我们的NumPy数组中创建数据集：
- en: '[PRE41]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Notice how we have added some size-checking to ensure that the data array and
    the labels vector have matching dimensions, and how we have reshaped the array
    of targets — that’s in order to avoid problems with the loss functions, which
    expect them to be column vectors. With this class set up, we may create dataset
    objects for the training, validation and test datasets as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何添加了一些尺寸检查，以确保数据数组和标签向量具有匹配的维度，以及我们如何重塑目标数组——这是为了避免与损失函数的问题，它们期望它们是列向量。有了这个类，我们可以创建训练、验证和测试数据集的数据集对象，如下所示：
- en: '[PRE42]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Just to check whether our implementation was successful, let us try to access
    the first element in `tr_data` and get the length of the training dataset:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查我们的实现是否成功，让我们尝试访问`tr_data`中的第一个元素，并获取训练数据集的长度：
- en: '[PRE43]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This is the output returned by these instructions:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这些指令返回的输出：
- en: '[PRE44]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We can see how, indeed, it gave us a tuple with a tensor of length ![16](img/file619.png
    "16") and its corresponding label. Also, a call to the `len` function did return
    the correct number of items in our dataset. Now, you may reasonably wonder why
    we should bother with all this mess of creating dataset classes. There are a couple
    of reasons. For one, this allows us to have our data organized and structured
    in a more orderly manner. What is more, using dataset objects, we can create data
    loaders. The `DataLoader` class can be imported from `torch``.``utils``.``data`
    and its objects allow us to easily iterate through batches of data. An example
    may help clarify this.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，它确实给了我们一个长度为![16](img/file619.png "16")的张量及其对应的标签的元组。此外，调用`len`函数确实返回了我们数据集中的正确项目数。现在，你可能会合理地想知道为什么我们要费心创建数据集类。有几个原因。首先，这允许我们以更有序的方式组织和结构化我们的数据。更重要的是，使用数据集对象，我们可以创建数据加载器。`DataLoader`类可以从`torch.utils.data`导入，并且它的对象允许我们轻松地遍历数据批次。一个例子可能有助于澄清这一点。
- en: 'Let’s say that we want to iterate over the training dataset in batches of ![2](img/file302.png
    "2"). All we would have to do is to create a data loader with the `tr_data` dataset
    specifying the batch size and the fact that we would like it to shuffle the data.
    Then, we could create an iterator object out of the data loader with the `iter`
    function and iterate over all the batches. This is shown in the following piece
    of code:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要以![2](img/file302.png "2")个批次迭代训练数据集。我们只需创建一个数据加载器，指定`tr_data`数据集的批次大小以及我们希望它打乱数据的事实。然后，我们可以使用`iter`函数从数据加载器中创建一个迭代器对象，并遍历所有批次。这在上面的代码片段中有所展示：
- en: '[PRE45]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'You may recall from Python 101 that calling `next``(``tr_loader``)` for the
    first time would be equivalent to running a `for` `x` `in` `tr_loader` loop and
    extracting the value of `x` in the first iteration. This is the output that we
    get:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得，从Python 101中，第一次调用`next(``tr_loader``)`将与运行一个`for` `x` `in` `tr_loader`循环并提取第一次迭代的`x`值等价。这是我们得到的结果：
- en: '[PRE46]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: And there you have it! In each iteration of the data loader, we get an array
    with the training data in the batch and its corresponding array of targets. All
    is shuffled and taken care of by PyTorch automatically. Neat, isn’t it? That can
    and will save us a good deal of effort.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 看到这里！在数据加载器的每个迭代中，我们得到一个包含批次中训练数据的数组及其对应的标签数组。所有这些都会由PyTorch自动打乱和处理。这不是很酷吗？这可以并且将会节省我们大量的精力。
- en: We must say that, in truth, you could technically use data loaders without going
    through the whole process of defining datasets — just sending in the numpy arrays.
    But it wouldn’t be the most ”PyTorchy” of practices. Anyhow, this settles our
    preparation of datasets.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须说，实际上，你可以技术上使用数据加载器而无需经过定义数据集的全过程——只需发送numpy数组即可。但这并不是最“PyTorch”的做法。无论如何，这解决了我们准备数据集的工作。
- en: 'In the training process, we will use, as always, the binary cross-entropy loss.
    We can save its function in a variable as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们将像往常一样使用二元交叉熵损失。我们可以将其函数保存在一个变量中，如下所示：
- en: '[PRE47]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Thus, the `get_loss` function will take a tensor of values between ![0](img/file12.png
    "0") and ![1](img/file13.png "1") and a matching tensor of labels, and will use
    them to compute the binary cross entropy loss. To see if it works as expected,
    we may compute a simple loss:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`get_loss`函数将接受一个介于![0](img/file12.png "0")和![1](img/file13.png "1")之间的值张量以及一个匹配的标签张量，并使用它们来计算二元交叉熵损失。为了看看它是否按预期工作，我们可以计算一个简单的损失：
- en: '[PRE48]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Since the only value in the tensor matches the expected value, we should get
    a loss of ![0](img/file12.png "0") and, indeed, this instruction returns `tensor`
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 由于张量中的唯一值与预期值匹配，我们应该得到![0](img/file12.png "0")的损失，并且确实，这条指令返回了`tensor`。
- en: '`(0.)`.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`(0.)`。'
- en: 'We are already preparing ourselves for the training. In our case, since our
    dataset has ![1000](img/file790.png "1000") elements, it could make sense to use
    a batch size of ![100](img/file389.png "100"), so let us prepare the training
    data loader to that effect:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在为训练做准备。在我们的情况下，由于我们的数据集有![1000](img/file790.png "1000")个元素，使用![100](img/file389.png
    "100")个批次大小是有意义的，因此让我们为这个目的准备训练数据加载器：
- en: '[PRE49]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'As usual, we will rely on the Adam optimizer for the training. The optimizer
    is implemented as a class in the `torch``.``optim` module, and, in order to use
    it, we need to specify which parameters it is going to optimize; in our case,
    that will be the parameters in our model, which we can retrieve with the `parameters`
    method. In addition, we can further configure the optimizer by passing optional
    arguments for the learning rate, among other adjustable parameters. We will use
    a learning rate of ![0.005](img/file1389.png "0.005") and trust the default values
    of the remaining parameters. Thus, we can define our optimizer as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，我们将依赖 Adam 优化器进行训练。优化器在 `torch``.``optim` 模块中实现为一个类，为了使用它，我们需要指定它将要优化的参数；在我们的情况下，那将是模型中的参数，我们可以通过
    `parameters` 方法检索它们。此外，我们可以通过传递可选参数（如学习率等可调整参数）来进一步配置优化器。我们将使用学习率 ![0.005](img/file1389.png
    "0.005") 并信任剩余参数的默认值。因此，我们可以定义我们的优化器如下：
- en: '[PRE50]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now we have all the ingredients ready and we can finally get to the training
    itself. In Keras, this would’ve been as easy as calling a method with a bunch
    of parameters, but here we have to work the training out ourselves! We will begin
    by defining a function that will perform one full training epoch. It will be the
    following:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了所有必要的材料，我们可以最终进行训练本身。在 Keras 中，这就像调用一个带有许多参数的方法一样简单，但在这里我们必须自己处理训练！我们将首先定义一个函数，它将执行一个完整的训练周期。它将是以下内容：
- en: '[PRE51]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The code is pretty much self-explanatory, but a few details deserve clarification.
    We have used two new methods: `backward` and `step`. Oversimplifying a bit, the
    `backward` method on `loss` computes the gradient of the loss by tracing back
    how it was computed and saving the partial derivatives in the optimizable parameters
    of the model on which the loss depends. This is the famous backpropagation technique
    that we talked about in *Chapter* *[*8*](ch017.xhtml#x1-1390008), *What Is Quantum*
    *Machine Learning?*. Then, `opt``.``step``()` prompts the optimizer to update
    the optimizable parameters using the derivatives that `loss``.``backward``()`
    computed.*'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 代码基本上是自我解释的，但有一些细节需要澄清。我们使用了两种新的方法：`backward` 和 `step`。简单来说，`backward` 方法在 `loss`
    上通过回溯其计算过程并保存依赖于该损失的模型的可优化参数的偏导数来计算损失的梯度。这就是我们在 *第* *8* *章* *[*8*](ch017.xhtml#x1-1390008)，*什么是量子机器学习？*
    *中讨论的著名反向传播技术。然后，`opt``.``step``()` 提示优化器使用 `loss``.``backward``()` 计算的导数来更新可优化参数。*
- en: '*To learn more…'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '*要了解更多信息...'
- en: 'If you are curious about how differentiation works with the `backward` method
    on PyTorch tensors, we can run a quick example to illustrate. We may define two
    variables, `a` and `b`, taking the values ![2](img/file302.png "2") and ![3](img/file472.png
    "3") respectively as follows:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对 PyTorch 张量上的 `backward` 方法如何进行微分感兴趣，我们可以运行一个快速示例来演示。我们可能定义两个变量，`a` 和 `b`，分别取值
    ![2](img/file302.png "2") 和 ![3](img/file472.png "3")，如下所示：
- en: '[PRE52]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Notice how we set `requires_grad` `=` `True` to tell PyTorch that these are
    variables it should keep track of. We may then define the function ![f(a,b) =
    a^{2} + b](img/file1426.png "f(a,b) = a^{2} + b") and compute its gradient as
    follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何设置 `requires_grad` `=` `True` 来告诉 PyTorch 这些是它应该跟踪的变量。然后我们可以定义函数 ![f(a,b)
    = a^{2} + b](img/file1426.png "f(a,b) = a^{2} + b") 并计算其梯度如下：
- en: '[PRE53]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We know that ![\left. \partial f\slash\partial a = (\partial\slash\partial a)a^{2}
    + b = 2a \right.](img/file1427.png "\left. \partial f\slash\partial a = (\partial\slash\partial
    a)a^{2} + b = 2a \right."), which in our case is equal to ![2a = 2 \cdot 2 = 4](img/file1428.png
    "2a = 2 \cdot 2 = 4"). When we run the `backward` method, PyTorch has already
    computed this partial derivative for us, and we can access it by calling `a``.``grad`,
    which, as expected, returns `tensor``([4.])`. Analogously, ![\left. \partial f\slash\partial
    b = 1 \right.](img/file1429.png "\left. \partial f\slash\partial b = 1 \right."),
    and, as expected, `b``.``grad` returns `tensor` `([1.])`.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道 ![\left. \partial f\slash\partial a = (\partial\slash\partial a)a^{2} +
    b = 2a \right.](img/file1427.png "\left. \partial f\slash\partial a = (\partial\slash\partial
    a)a^{2} + b = 2a \right.")，在我们的情况下等于 ![2a = 2 \cdot 2 = 4](img/file1428.png "2a
    = 2 \cdot 2 = 4")。当我们运行 `backward` 方法时，PyTorch 已经为我们计算了这个偏导数，我们可以通过调用 `a``.``grad`
    来访问它，正如预期的那样，它返回 `tensor``([4.])`。类似地，![\left. \partial f\slash\partial b = 1
    \right.](img/file1429.png "\left. \partial f\slash\partial b = 1 \right.")，并且正如预期的那样，`b``.``grad`
    返回 `tensor` `([1.])`。
- en: In principle, we could train our model by calling `run_epoch` manually as many
    times as we wanted, but why suffer like that when we can leave Python in charge?
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 从原则上讲，我们可以通过手动多次调用 `run_epoch` 来训练我们的模型，但为什么要在那种情况下受苦，当我们可以让 Python 负责的时候呢？
- en: 'Let us define a training loop in which, at each iteration, we will run an epoch
    and log the training and validation loss obtained over the whole dataset. Instead
    of fixing a specific number of epochs, we will keep iterating until the validation
    loss increases — this will be our own version of the early stopping callback that
    we used in TensorFlow. The following piece of code gets the job done:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个训练循环，在每次迭代中，我们将运行一个epoch并记录整个数据集上获得的训练和验证损失。而不是固定一个特定的epoch数，我们将继续迭代，直到验证损失增加——这将是我们在TensorFlow中使用的早期停止回调的版本。以下代码块完成了这项工作：
- en: '[PRE54]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Notice how, when logging the losses in `tr_losses`, we have converted the PyTorch
    tensors to floats. This is the output that we get after executing this loop:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当在`tr_losses`中记录损失时，我们已经将PyTorch张量转换为浮点数。这是执行此循环后得到的输出：
- en: '[PRE55]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'An image is worth a thousand words, so, just to get a visual overview of the
    performance of our training, let us recycle the `plot_losses` function that we
    had for TensorFlow and run it:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 一图胜千言，为了对训练性能有一个直观的了解，让我们重新使用为TensorFlow准备的`plot_losses`函数并运行它：
- en: '[PRE56]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The resulting plot can be found in *Figure* [*11.3*](#Figure11.3). The plot
    does show some signs of overfitting, but likely not something to be concerned
    about; in any case, let’s wait until we get the accuracy over the test dataset.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图可以在*图* [*11.3*](#Figure11.3)中找到。该图确实显示出一些过拟合的迹象，但可能不是需要担心的问题；无论如何，让我们等到我们在测试数据集上获得准确性后再说。
- en: '![Figure 11.3: Evolution of the training and validation losses over the training
    of a classical binary classifier with PyTorch ](img/file1430.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图11.3：使用PyTorch训练经典二分类器的训练和验证损失演变](img/file1430.png)'
- en: '**Figure 11.3**: Evolution of the training and validation losses over the training
    of a classical binary classifier with PyTorch'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '**图11.3**：使用PyTorch训练经典二分类器的训练和验证损失演变'
- en: 'In order to get the accuracy of our classifier on the training, validation,
    and test datasets, we can run the following instructions:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取我们的分类器在训练、验证和测试数据集上的准确性，我们可以运行以下指令：
- en: '[PRE57]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: This returns a training accuracy of ![94\%](img/file1431.png "94\%"), a validation
    accuracy of ![92\%](img/file1432.png "92\%"), and a test accuracy of ![96\%](img/file1402.png
    "96\%").
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回了94%的训练准确性![94\%](img/file1431.png "94\%")，92%的验证准确性和96%的测试准确性![96\%](img/file1402.png
    "96\%")。
- en: We have just concluded our not-that-short introduction to PyTorch. Let’s go
    quantum!
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚结束了关于PyTorch的简短介绍。让我们进入量子领域！
- en: 11.3.2 Building a hybrid binary classifier with Qiskit
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3.2 使用Qiskit构建混合二分类器
- en: 'In this subsection, we will implement our first hybrid QNN with Qiskit. The
    process will be fairly straightforward, and we will be able to rely on a good
    deal of the code that we already have. To get started, let us import the Qiskit
    package and the ZZ feature map and two-local variational form that come bundled
    with it:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们将实现我们的第一个混合QNN，使用Qiskit。这个过程将相当直接，我们将能够依赖我们已有的大量代码。为了开始，让我们导入Qiskit包以及它附带捆绑的ZZ特征图和双局部变分形式：
- en: '[PRE58]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'With a QNN, it will be advisable to use smaller datasets in order for the training
    time to be reasonable on our simulators. We can prepare them, along with the corresponding
    dataset and data loader objects, as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 使用QNN时，为了使训练时间在我们的模拟器上合理，建议使用较小的数据集。我们可以按照以下方式准备它们，以及相应的数据集和数据加载器对象：
- en: '[PRE59]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Our quantum layer will be a simple ![4](img/file143.png "4")-qubit QNN with
    one instance of the ZZ feature map and the two-local variational form. Thus, the
    components that we will use in our QNN circuit will be the following:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们量子层将是一个简单的![4](img/file143.png "4")-比特QNN，包含一个ZZ特征图实例和双局部变分形式。因此，我们将在QNN电路中使用的组件如下：
- en: '[PRE60]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Here, we have instantiated the two-local form as in *Chapter* [*10*](ch019.xhtml#x1-18100010),
    *Quantum* *Neural Networks*.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们实例化了与*第* [*10*](ch019.xhtml#x1-18100010) *章* *量子* *神经网络*中相同的双局部形式。
- en: 'Also, just as we did in the previous chapter, we could use the `TwoLayerQNN`
    class in order to generate our quantum neural network according to our specifications.
    We may import it as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，就像我们在上一章中做的那样，我们可以使用`TwoLayerQNN`类来生成符合我们规格的量子神经网络。我们可以按以下方式导入它：
- en: '[PRE61]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'We are now ready to define our model architecture with PyTorch. Its structure
    will be analogous to that of a classical architecture. The only difference is
    that we will have to define a quantum neural network object in the initializer,
    and we will have to rely on the `TorchConnector` in order to use the QNN in the
    `forward` method. This `TorchConnector` is analogous to the `qml``.``qnn``.``KerasLayer`
    that we used in PennyLane — only that it’s for Qiskit and PyTorch! This is how
    we may then define our hybrid network and instantiate a model:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备好使用PyTorch定义我们的模型架构。其结构将与经典架构类似。唯一的区别是我们必须在初始化器中定义一个量子神经网络对象，并且我们必须依赖`TorchConnector`来在`forward`方法中使用QNN。这个`TorchConnector`类似于我们在PennyLane中使用的`qml``.``qnn``.``KerasLayer`，只是它是为Qiskit和PyTorch设计的！这就是我们定义混合网络并实例化模型的方式：
- en: '[PRE62]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Notice how we’ve passed the optional argument `input_gradients` `=` `True` to
    the `TwoLayer` initializer; that is required for the PyTorch interface to work
    properly. Apart from that, the construction of the quantum neural network was
    fully analogous to what we did in *Chapter* [*10*](ch019.xhtml#x1-18100010), *Quantum
    Neural Networks*. A detail that perhaps deserves an explanation is the reason
    why we have included a final classical layer after the quantum one. This is because
    our QNN will return values between ![- 1](img/file312.png "- 1") and ![1](img/file13.png
    "1"), not between ![0](img/file12.png "0") and ![1](img/file13.png "1"); by including
    this final layer followed by the classical sigmoid activation function, we can
    ensure that the output of our network will be bounded between ![0](img/file12.png
    "0") and ![1](img/file13.png "1"), as we expect.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何将可选参数`input_gradients` `=` `True`传递给`TwoLayer`初始化器；这是PyTorch接口正常工作所必需的。除此之外，量子神经网络的构建与我们在*第10章*，*量子神经网络*中做的是完全类似的。可能需要解释的一个细节是我们为什么在量子层之后包含一个最终的经典层。这是因为我们的QNN将返回介于![-
    1](img/file312.png "- 1")和![1](img/file13.png "1")之间的值，而不是介于![0](img/file12.png
    "0")和![1](img/file13.png "1")之间；通过包含这个最终层并跟随经典sigmoid激活函数，我们可以确保网络的输出将介于![0](img/file12.png
    "0")和![1](img/file13.png "1")之间，正如我们所期望的那样。
- en: 'Now all we have left to do before we can start the training is prepare the
    optimizer, and send the model parameters to it:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始训练之前，我们只剩下准备优化器和将模型参数发送给它的任务：
- en: '[PRE63]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'And we can simply reuse the `run_epoch` function to complete the training,
    just as we did in the previous subsection:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以简单地重用`run_epoch`函数来完成训练，就像我们在前面的子节中做的那样：
- en: '[PRE64]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'This is the output that the execution will yield:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是执行将产生的输出：
- en: '[PRE65]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'As before, we can get a plot of the loss evolution as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，我们可以得到损失演变的图表如下：
- en: '[PRE66]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: This returns the plot shown in *Figure* [*11.4*](#Figure11.4). There does seem
    to be some overfitting, which could likely be fixed by giving more data to the
    classifier.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回了*图*[*11.4*](#Figure11.4)中显示的图表。似乎存在一些过拟合，这很可能是通过向分类器提供更多数据来解决的。
- en: '![Figure 11.4: Evolution of the training and validation losses over the training
    of a hybrid binary classifier with PyTorch ](img/file1433.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![图11.4：使用PyTorch训练混合二分类器的训练和验证损失演变](img/file1433.png)'
- en: '**Figure 11.4**: Evolution of the training and validation losses over the training
    of a hybrid binary classifier with PyTorch'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '**图11.4**：使用PyTorch训练混合二分类器的训练和验证损失演变'
- en: 'In any case, let’s compute the training, validation, and test accuracies to
    get a better insight into the performance of the classifier. We may do that by
    executing the following instructions:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，让我们计算训练、验证和测试准确率，以更好地了解分类器的性能。我们可以通过执行以下指令来完成：
- en: '[PRE67]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Upon running this, we get a training accuracy of ![92\%](img/file1432.png "92\%"),
    a validation accuracy of ![86\%](img/file1434.png "86\%"), and a test accuracy
    of ![74\%](img/file1435.png "74\%"). This confirms our suspicions regarding the
    existence of overfitting. As in other cases, should we want to fix this, we could
    try training the model with additional data, for instance.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后，我们得到训练准确率为![92%](img/file1432.png "92%")，验证准确率为![86%](img/file1434.png
    "86%")，测试准确率为![74%](img/file1435.png "74%")。这证实了我们对过拟合存在的怀疑。与其他情况一样，如果我们想解决这个问题，我们可以尝试用额外的数据训练模型，例如。
- en: Of course, all that we’ve learned about how to train hybrid QNNs with PyTorch
    and Qiskit also works for ordinary QNNs. If you want to train a simple Qiskit
    QNN using PyTorch, you’ve just learned how to do it; all it will take is defining
    a model with no classical layers.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们关于如何使用PyTorch和Qiskit训练混合QNN的所有知识也适用于普通QNN。如果您想使用PyTorch训练一个简单的Qiskit QNN，您已经学会了如何做；只需定义一个没有经典层的模型即可。
- en: This concludes our study of hybrid neural networks in Qiskit. But we still have
    one thing left before bringing this section to an end.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这标志着我们在Qiskit中对混合神经网络的研究结束。但在结束这一节之前，我们还有一件事要做。
- en: One of the advantages of Qiskit is its tight integration with IBM’s quantum
    hardware. Nevertheless, as was the case in our study of quantum optimization,
    queueing times make the training of any QNN model on real hardware unfeasible
    through the usual interfaces to IBM’s hardware — that is, just using a real hardware
    backend, as we discussed in *Chapter* [*2*](ch009.xhtml#x1-400002), *The* *Tools
    of the Trade in Quantum Computing*. Thankfully, there’s a better way.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: Qiskit的一个优点是与IBM量子硬件的紧密集成。然而，正如我们在量子优化研究中所做的那样，排队时间使得通过IBM硬件的常规接口（即仅使用真实硬件后端，正如我们在第[*2*](ch009.xhtml#x1-400002)章“量子计算中的工具”中讨论的那样）在真实硬件上训练任何QNN模型变得不可行。幸运的是，有更好的方法。
- en: 11.3.3 Training Qiskit QNNs with Runtime
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3.3 使用Runtime训练Qiskit QNNs
- en: Using Qiskit’s Runtime service, as we did in *Chapters* [*5*](ch013.xhtml#x1-940005)
    and [*7*](ch015.xhtml#x1-1190007), we can effectively train any QNN model defined
    in PyTorch through a Qiskit Torch connector on any of the devices and simulators
    provided by IBM Quantum. All it takes is waiting on a single queue, and the whole
    training process is executed as a unit — with all the executions on quantum hardware
    included. The folks at IBM refer to this use case of Qiskit Runtime as ”Torch
    Runtime.”
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Qiskit的Runtime服务，就像我们在第[*5*](ch013.xhtml#x1-940005)章和第[*7*](ch015.xhtml#x1-1190007)章中所做的那样，我们可以通过Qiskit
    Torch连接器在IBM Quantum提供的任何设备和模拟器上有效地训练任何在PyTorch中定义的QNN模型。只需等待一个队列，整个训练过程作为一个单元执行——包括所有在量子硬件上的执行。IBM的同事们将Qiskit
    Runtime的这个用例称为“Torch Runtime”。
- en: 'That is very convenient. However, we must warn you that, at the time of writing,
    the queuing times to run these Torch Runtime programs can be somewhat long: around
    the order of a few hours. Also, you should keep in mind that — again, at the time
    of writing — this service enables you to train QNNs defined on PyTorch, but not
    hybrid QNNs! That is, your PyTorch model should not have any classical layers
    whatsoever.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常方便。但是，我们必须警告您，在撰写本文时，运行这些Torch Runtime程序可能需要相当长的排队时间：大约几小时。此外，您应该记住——同样，在撰写本文时——这项服务使您能够训练在PyTorch上定义的QNN，但不能训练混合QNN！也就是说，您的PyTorch模型不应有任何经典层。
- en: 'We will train a simple QNN model on a real device. As usual, we should firstly
    load our IBMQ account and pick a device. We will pick the least busy device among
    all the real devices with at least four qubits:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在一个真实设备上训练一个简单的QNN模型。像往常一样，我们首先应该加载我们的IBMQ账户并选择一个设备。我们将选择所有至少有四个量子比特的真实设备中最不繁忙的设备：
- en: '[PRE68]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'We may define a simple QNN model with the PyTorch connector as follows:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用PyTorch连接器定义一个简单的QNN模型，如下所示：
- en: '[PRE69]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Then, we may generate some data on which to train this model using the `make_classification`
    function:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用`make_classification`函数生成一些数据来训练这个模型：
- en: '[PRE70]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Notice how we have adjusted some of the parameters of the `make_classification`
    function in order to comply with its requirements (check its documentation at
    [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)
    for more details).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们是如何调整`make_classification`函数的一些参数，以符合其要求的（更多详细信息，请查看其文档[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)）。
- en: 'Our model should return values between ![0](img/file12.png "0") and ![1](img/file13.png
    "1"), but the observable that we have chosen for our circuit — the default one,
    the parity observable (check *Chapter* [*10*](ch019.xhtml#x1-18100010), *Quantum
    Neural Networks*, for reference) — returns two possible values: ![1](img/file13.png
    "1") or ![- 1](img/file312.png "- 1"), not ![0](img/file12.png "0") and ![1](img/file13.png
    "1"). Thus we need to update the targets mapping ![\left. 0\mapsto - 1 \right.](img/file1436.png
    "\left. 0\mapsto - 1 \right.") and ![\left. 1\mapsto 1 \right.](img/file1437.png
    "\left. 1\mapsto 1 \right."). This can be done with the following instructions:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模式应该返回![0](img/file12.png "0")和![1](img/file13.png "1")之间的值，但我们为我们的电路选择的可观测量——默认的可观测量，偶校验可观测量（参考*第10章*[*10*](ch019.xhtml#x1-18100010)，*量子神经网络*）——返回两个可能的值：![1](img/file13.png
    "1")或![−1](img/file312.png "−1")，而不是![0](img/file12.png "0")和![1](img/file13.png
    "1")。因此，我们需要更新目标映射![0→−1](img/file1436.png "0→−1")和![1→1](img/file1437.png "1→1")。这可以通过以下指令完成：
- en: '[PRE71]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Let us now set up some data loaders for the training, validation, and test
    data:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在为训练、验证和测试数据设置一些数据加载器：
- en: '[PRE72]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'And the only ingredients that we have left to define are the optimizer and
    the loss function. We can still rely on Adam as an optimizer, but the binary cross
    entropy loss will no longer work since our labels are now ![- 1](img/file312.png
    "- 1") and ![1](img/file13.png "1") instead of ![0](img/file12.png "0") and ![1](img/file13.png
    "1"); thus, we will use the mean squared error loss instead:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们剩下的唯一需要定义的成分是优化器和损失函数。我们仍然可以使用Adam作为优化器，但由于我们的标签现在是![−1](img/file312.png "−1")和![1](img/file13.png
    "1")而不是![0](img/file12.png "0")和![1](img/file13.png "1")，二进制交叉熵损失将不再适用；因此，我们将使用均方误差损失：
- en: '[PRE73]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'In order to be able to use our model with Torch Runtime, we will have to define
    a Torch Runtime Client, `client`, specifying a few self-explanatory parameters.
    This is done as follows:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够使用我们的模型与Torch Runtime一起使用，我们必须定义一个Torch Runtime客户端，`client`，指定一些自解释的参数。这可以通过以下方式完成：
- en: '[PRE74]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We have set the number of epochs to ![5](img/file296.png "5") in order to get
    some quick results, but feel free to increase it.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将epoch的数量设置为![5](img/file296.png "5")以获得一些快速的结果，但请随意增加它。
- en: 'And now this is the instruction that we need to execute if we want to train
    our model:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这是我们要执行的指令，如果我们想要训练我们的模型：
- en: '[PRE75]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: This will likely take a while because of the queue time required to run a Torch
    Runtime program. Sit back and relax. Eventually, your model will be trained. Once
    that happens, you can get information about the training from the `result` object,
    whose type is `TorchRuntimeResult`. In particular, the attributes `train_history`
    and `val_history` will show you the evolution of the training and validation losses
    throughout the training process.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能需要一段时间，因为运行Torch Runtime程序所需的队列时间。请放松并休息。最终，你的模型将被训练。一旦发生这种情况，你可以从`result`对象中获取有关训练的信息，其类型为`TorchRuntimeResult`。特别是，`train_history`和`val_history`属性将显示在整个训练过程中训练和验证损失的演变。
- en: 'If you’d like to get the model’s prediction on some data — for instance, the
    test dataset — all you have to do is send a data loader object with the data to
    the `predict` method. And this is how you can get your predictions:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要获取模型对某些数据的预测——例如，测试数据集——你只需要将数据的数据加载器对象发送到`predict`方法。以下是如何获取你的预测：
- en: '[PRE76]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Don’t expect to get great results! The model that we have defined is not very
    powerful and we only trained for a few epochs. As if that were not enough, when
    you run on real hardware, there’s always the issue of having to deal with noise.
    Of course, you could use error mitigation as we did back in *Chapter* [*7*](ch015.xhtml#x1-1190007),
    *VQE: Variational Quantum Eigensolver*, by setting `measurement_error_mitigation`
    `=` `True` in the `TorchRuntimeClient` instantiation.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '不要期望获得出色的结果！我们定义的模型并不强大，我们只训练了几个epoch。更不用说，当你运行在实际硬件上时，总是存在处理噪声的问题。当然，你可以使用我们之前在*第7章*[*7*](ch015.xhtml#x1-1190007)，*VQE:
    变分量子本征值求解器*中使用的错误缓解方法，通过在`TorchRuntimeClient`实例化时设置`measurement_error_mitigation`
    `=` `True`。'
- en: 11.3.4 A glimpse into the future
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3.4 看向未来的一瞥
- en: The way in which we have worked with Torch Runtime is supported by IBM at the
    time of writing, but change is the only constant in Qiskit land.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 我们与Torch Runtime合作的方式在撰写本文时得到了IBM的支持，但在Qiskit的世界里，变化是唯一的不变。
- en: In the future, Torch Runtime will no longer be supported and, instead, it will
    be necessary to use a different interface in order to train quantum neural networks
    with Qiskit Runtime. This interface — which, at the time of writing, is still
    in active development — will rely on the `Sampler` and `Estimator` objects that
    we mentioned in *Section* [*7.3.7*](ch015.xhtml#x1-1320007.3.7). In this subsection,
    we will present to you a simple example that will showcase how to work with this
    new interface.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，Torch Runtime将不再被支持，并且将需要使用不同的接口来使用Qiskit Runtime训练量子神经网络。这个接口——在撰写本文时，它仍在积极开发中——将依赖于我们在*第7.3.7节*
    *[*7.3.7*](ch015.xhtml#x1-1320007.3.7)中提到的`Sampler`和`Estimator`对象。在本小节中，我们将向您展示一个简单的示例，展示如何使用这个新接口。
- en: 'The following piece of code can be used to train a simple variational quantum
    classifier (a `VQC` object) using the ”new” Qiskit Runtime on the `ibmq_lima`
    device:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段可以用于在`ibmq_lima`设备上使用“新”的Qiskit Runtime训练一个简单的变分量子分类器（一个`VQC`对象）：
- en: '[PRE77]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Please note that you need to install the `qiskit_ibm_runtime` package (refer
    to *Appendix* *[*D*](ch027.xhtml#x1-240000D), *Installing the Tools*, for instructions)
    and replace `"``TOKEN``"` with your actual IBM Quantum token.*
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您需要安装`qiskit_ibm_runtime`包（有关说明，请参阅*附录* *[*D*](ch027.xhtml#x1-240000D)，*安装工具*），并将`"``TOKEN``"`替换为您实际的IBM量子令牌。
- en: '*As a matter of fact, when you send a program through this new Qiskit Runtime
    interface, you will likely see a fairly big collection of jobs on your IBM Quantum
    dashboard. Don’t worry, Runtime is working just fine. All those jobs correspond
    to different calls to the quantum computer, but they are all executed without
    the need to wait in the queue after each and every job execution.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '*实际上，当您通过这个新的Qiskit Runtime接口发送程序时，您很可能会在IBM Quantum仪表板上看到一大堆作业。不用担心，Runtime运行得很好。所有这些作业都对应于对量子计算机的不同调用，但它们都是无需在每个作业执行后等待队列即可执行。'
- en: And that’s all we wanted to share with you about the Torch Runtime utility.
    Let’s wrap up this chapter.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们想与你们分享的有关Torch Runtime实用工具的所有内容。让我们结束这一章。
- en: Summary
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This has been a long and intense chapter. We began by learning what hybrid
    neural networks actually are and in which use cases they can be useful. We then
    explored how to implement and train these hybrid networks in PennyLane and, along
    the way, we discussed a few good practices that apply to any machine learning
    project. In addition, we left our comfort zone and considered a new kind of QML
    problem: the training of multi-class classifiers.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一段漫长而紧张的经历。我们首先学习了混合神经网络实际上是什么，以及它们在哪些用例中可能有用。然后我们探讨了如何在PennyLane中实现和训练这些混合网络，在这个过程中，我们还讨论了一些适用于任何机器学习项目的良好实践。此外，我们跳出舒适区，考虑了一种新的量子机器学习问题：多类分类器的训练。
- en: Once we finished our study of PennyLane, we dived into Qiskit, and a big surprise
    was waiting for us there. Since Qiskit relied on an interface with the PyTorch
    ML package for the implementation of hybrid QNNs, we invested a good deal of effort
    in learning how to use PyTorch. In the process, we saw how PyTorch provided us
    with a level of flexibility that we simply couldn’t get using TensorFlow and Keras.
    At the point where we had a solid understanding of the PyTorch package, we got
    to work with Qiskit and its PyTorch connector and we trained a hybrid QNN with
    them.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成对PennyLane的学习后，我们深入研究了Qiskit，那里有一个惊喜在等着我们。由于Qiskit依赖于与PyTorch ML包的接口来实现混合量子神经网络，我们投入了大量精力学习如何使用PyTorch。在这个过程中，我们看到了PyTorch如何为我们提供一种使用TensorFlow和Keras所无法获得的灵活性。在我们对PyTorch包有了稳固的理解之后，我们开始使用Qiskit及其PyTorch连接器，并用它们训练了一个混合量子神经网络。
- en: Lastly, we concluded the chapter by fulfilling a promise we made in *Chapter*
    [*10*](ch019.xhtml#x1-18100010), *Quantum Neural Networks*, and we discussed how
    to train quantum neural networks on IBM’s quantum hardware using Torch Runtime.***
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过履行在*第10章* *[*10*](ch019.xhtml#x1-18100010)，*量子神经网络*中做出的承诺，结束了这一章，并讨论了如何使用Torch
    Runtime在IBM的量子硬件上训练量子神经网络。
