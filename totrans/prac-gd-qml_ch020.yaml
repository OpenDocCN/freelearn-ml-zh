- en: Chapter 11
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章
- en: 'The Best of Both Worlds: Hybrid Architectures'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 两种世界的最佳结合：混合架构
- en: '*Unity makes strength.*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*团结就是力量。*'
- en: — English aphorism
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: — 英文谚语
- en: 'By now, we have a solid understanding of both classical and quantum neural
    networks. In this chapter, we will leverage this knowledge to explore an interesting
    kind of model: hybrid architectures of quantum neural networks.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们对经典和量子神经网络都有了坚实的理解。在本章中，我们将利用这些知识来探索一种有趣类型的模型：量子神经网络的混合架构。
- en: In this chapter, we will discuss what these models are and how they can be useful,
    and we will also learn how to implement and train them with PennyLane and Qiskit.
    The whole chapter is going to be very hands-on, and we will also take the time
    to fill in some gaps regarding the actual practice of training models in real-world
    scenarios. In addition to this — and just to spice things up a bit — we will go
    beyond our usual binary classifiers and also consider other kinds of problems.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论这些模型是什么以及它们如何有用，我们还将学习如何使用PennyLane和Qiskit来实现和训练它们。整章将非常实用，我们还将花时间填补一些关于在现实场景中训练模型的实际实践方面的空白。除此之外——为了增加一些趣味性——我们还将超越我们通常的二分类器，并考虑其他类型的问题。
- en: 'We’ll cover the following topics in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: The what and why of hybrid architectures
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合架构的“什么”和“为什么”
- en: Hybrid architectures in PennyLane (with a brief overview of best practices for
    training models in real-world scenarios and an introduction to multi-class classification
    problems)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PennyLane中的混合架构（包括在现实场景中训练模型的最佳实践概述以及多类分类问题的介绍）
- en: Hybrid architectures in Qiskit (with an introduction to PyTorch)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiskit中的混合架构（包括PyTorch的介绍）
- en: This is going to be a very exciting chapter. Let’s begin by giving meaning to
    these hybrid architectures.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是一个非常激动人心的章节。让我们首先为这些混合架构赋予意义。
- en: 11.1 The what and why of hybrid architectures
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11.1 混合架构的“什么”和“为什么”
- en: 'Up until now, we’ve used the adjective ”hybrid” to describe algorithms that
    rely on both classical and quantum processing; algorithms such as QAOA or VQE
    fit in this category, as well as the training of QSVMs and QNNs. When we talk
    about **hybrid architectures** or **hybrid models**, however, we refer to something
    more specific: we speak about models that combine classical models with other
    quantum-based models by joining them together and training them as a single unit.
    Of course, the training of hybrid models will itself be a hybrid algorithm. We
    know that the terminology might be confusing, but what can we do? Hybrid is too
    versatile a word to give it up.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用形容词“混合”来描述依赖于经典和量子处理的算法；例如QAOA或VQE以及QSVMs和QNNs的训练都属于这一类别。然而，当我们谈论**混合架构**或**混合模型**时，我们指的是更具体的东西：我们谈论的是通过将它们组合在一起并作为一个单一单元进行训练，将经典模型与其他基于量子模型的模型结合在一起的模型。当然，混合模型的训练本身也将是一个混合算法。我们知道术语可能有些令人困惑，但我们能怎么办呢？混合这个词太灵活了，不能放弃。
- en: In particular, we will combine quantum neural networks with classical neural
    networks, for they are the two models that fit more naturally together. The way
    we will go about doing this will be by taking a usual classical neural network
    and plugging in a quantum neural network as one of its layers. In this way, the
    ”quantum layer” will take as input the outputs of the previous layer (or the inputs
    to the model, if there’s no layer before it) and will feed its output to the next
    layer (should there be any). The output of the quantum neural network will be
    a numerical array of length ![k](img/file317.png "k"); thus, in the eyes of the
    next layer, the quantum layer will behave as if it were a classical layer with
    ![k](img/file317.png "k") neurons.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其地，我们将结合量子神经网络和经典神经网络，因为它们是两种更自然地结合在一起的模式。我们将通过将一个普通的经典神经网络作为其一层插入量子神经网络来实现这一点。这样，“量子层”将接受前一层的输出（或如果没有前一层，则为模型的输入）并将其输出传递给下一层（如果有）。量子神经网络的输出将是一个长度为![k](img/file317.png
    "k")的数值数组；因此，在下一层看来，量子层将表现得像一个具有![k](img/file317.png "k")个神经元的经典层。
- en: These hybrid architectures combining classical and quantum neural networks are
    said to be, to the surprise of no one, **hybrid quantum neural** **networks**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结合经典和量子神经网络的混合架构据说对任何人来说都不会感到惊讶，**混合量子神经网络**。
- en: Important note
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In summary, a hybrid QNN is a classical neural network in which one or more
    of its layers have been replaced by quantum layers. These are quantum neural networks
    that get inputs from the outputs of the previous layer and feed their outputs
    to the next one. Of course, if there’s no next layer, the output of the quantum
    layer will be the output of the network. Analogously, if there’s no previous layer,
    the input to the quantum network will be the model’s input.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，混合QNN是一个经典神经网络，其中一层或多层已被量子层所取代。这些是量子神经网络，它们从前一层的输出获取输入，并将它们的输出馈送到下一层。当然，如果没有下一层，量子层的输出将是网络的输出。类似地，如果没有前一层，量子网络的输入将是模型的输入。
- en: 'As we’ve already hinted, a hybrid neural network is trained as a single unit:
    the training process involves the optimization of both the parameters of the classical
    layers and those of the quantum neural networks inside the quantum layers.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经暗示的，混合神经网络作为一个单一单元进行训练：训练过程涉及经典层的参数和量子层内量子神经网络的参数的优化。
- en: 'To make the whole definition of hybrid QNNs more clear, let us consider a simple
    example of how one such network may be constructed:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使混合QNNs的定义更加清晰，让我们考虑一个简单的例子，说明这样一个网络可能如何构建：
- en: The hybrid QNN must begin taking some classical inputs. Let’s say it takes ![16](img/file619.png
    "16").
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 混合QNN必须开始接收一些经典输入。比如说它接收![16](img/file619.png "16")。
- en: We may then feed the input into a usual classical layer with ![8](img/file506.png
    "8") neurons and use the sigmoid activation function.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以将输入数据馈送到一个通常的经典层，该层包含![8](img/file506.png "8")个神经元，并使用sigmoid激活函数。
- en: Then, we will add a quantum layer. This quantum layer will have to accept ![8](img/file506.png
    "8") inputs from the previous layer. For example, we could use a QNN with three
    qubits using amplitude encoding. The output of this quantum layer could be, for
    instance, the expectation values of the first and second qubits, both measured
    on the computational basis. In this case, this quantum layer that we have added
    will return two numeric values.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将添加一个量子层。这个量子层必须从前一层接受![8](img/file506.png "8")个输入。例如，我们可以使用一个具有三个量子比特并使用振幅编码的QNN。这个量子层的输出可以是，例如，第一个和第二个量子比特在计算基上的期望值。在这种情况下，我们添加的这个量子层将返回两个数值。
- en: Finally, we may add a classical layer with a single neuron that uses the sigmoid
    activation function. This layer will take inputs from the quantum layer, so it
    will accept two inputs. It will essentially treat the quantum layer as if it were
    a classical layer with two neurons.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可能添加一个包含单个神经元并使用sigmoid激活函数的经典层。这个层将从量子层接收输入，因此它将接受两个输入。它基本上将量子层视为一个具有两个神经元的经典层。
- en: And that’s how you can build yourself a simple hybrid QNN — at least in theory!
    But the question is... why would we want to do such a thing? What are these hybrid
    models good for? Let’s illustrate it with a typical example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你可以构建一个简单的混合QNN的方法——至少在理论上是这样！但问题是...我们为什么要这样做？这些混合模型有什么好处？让我们用一个典型的例子来说明。
- en: 'In the previous chapter, we learned how to use a QNN to tackle a (binary) classification
    task. But, due to the limitations of current quantum hardware and simulators,
    we were forced to apply some dimensionality reduction techniques on our data before
    we could use it. That’s a situation where hybrid QNNs may prove useful: why not
    combine, in a single model, classical dimensionality reduction carried out by
    a classical neural network with classification performed by a quantum neural network?'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何使用QNN来解决一个（二进制）分类任务。但是，由于当前量子硬件和模拟器的限制，我们被迫在可以使用之前对我们的数据进行一些降维处理。这就是混合QNNs可能有用的情况：为什么不将经典神经网络执行的经典降维与量子神经网络执行的分类结合在一个模型中呢？
- en: In this way, instead of first reducing the dimensionality of our data and then
    classifying it with a quantum neural network, we could consider a hybrid QNN with
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式，我们不必首先降低数据的维度，然后用量子神经网络对其进行分类，我们可以考虑一个具有以下特征的混合QNN：
- en: a bunch of classical layers that would reduce the dimensionality of our data,
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列经典层，这些层将降低我们数据的维度，
- en: joined to a quantum layer that would be in charge of making the classification.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与一个负责分类的量子层相连。
- en: Of course, since the whole network would be trained as a single unit, there
    would be no way to truly tell whether the classical part of the network is only
    doing dimensionality reduction and the quantum part is only doing classification.
    Most likely, both parts will work on both tasks to some degree.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，由于整个网络将作为一个单一单元进行训练，我们无法真正判断网络的经典部分是否只进行降维，而量子部分只进行分类。很可能是两个部分都会在一定程度上同时处理这两个任务。
- en: 'Before proceeding any further, a few disclaimers are in order. First and foremost:
    quantum layers are not any sort of magical tool that will surely lead to great
    improvements in the performance of a classical neural network. Actually, if used
    unwisely, quantum layers could very easily have a negative impact on your model!
    The key takeaway is that you shouldn’t blindly use a quantum layer solely as a
    replacement for a classical layer in a network. Be intentional. If you are going
    to include a quantum layer in your model, think about the role it’s going to play
    in it.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续前进之前，有一些免责声明是必要的。首先也是最重要的：量子层并不是一种神奇的工具，它一定会导致经典神经网络的性能得到显著提升。实际上，如果使用不当，量子层可能会对你的模型产生负面影响！关键是要记住，你不应该盲目地将量子层仅作为网络中经典层的替代品。要有目的性。如果你打算在你的模型中包含量子层，考虑它在模型中将扮演什么角色。
- en: In addition, when working with hybrid QNNs, you should watch out for how you
    are joining classical and quantum layers together. For instance, if you have a
    quantum layer using a feature map that requires its inputs to be normalized, maybe
    using an ELU activation function in the previous layer isn’t the best of ideas,
    because it is in no way bounded. On the other hand, in that case, a sigmoid activation
    function could be a great fit for the previous layer.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当与混合量子神经网络一起工作时，你应该注意如何将经典层和量子层结合起来。例如，如果你有一个使用需要其输入归一化的特征图的量子层，那么在前一层使用ELU激活函数可能不是最好的主意，因为它没有任何界限。另一方面，在这种情况下，sigmoid激活函数可能非常适合前一层。
- en: In the use case that we discussed a few paragraphs ago (combining classical
    data reduction with quantum classification), we can witness the ”intentionality”
    that we’ve just talked about. We do know that, in principle, a neural network
    can do a good job at reducing data dimensionality; in case you didn’t know, it’s
    a known fact that, using something called **autoencoders** [[104](ch030.xhtml#Xhandsonml),
    Chapter 17], one can train an **encoder** network that can reduce the dimensionality
    of a dataset. And we know that a quantum neural network can do a good job at classifying
    data coming from a dimensionality reduction technique (just have a look at the
    previous chapter!). So there must be some choice of parameters such that the combined
    hybrid model will successfully accomplish both tasks. Hence, with the right training,
    our hybrid model should be able to perform at least as well as it would if a classical
    encoder and a quantum classifier were trained separately. And the important bit
    is the ”at least,” because when training the classical encoder and the quantum
    classifier together we can join their powers!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前讨论的用例中（结合经典数据降维与量子分类），我们可以见证我们刚刚提到的“目的性”。我们知道，从原则上讲，神经网络可以很好地处理数据降维；如果你不知道，这是一个已知的事实：使用一种称为**自动编码器**（[104](ch030.xhtml#Xhandsonml)，第17章）的技术，可以训练一个**编码器**网络来降低数据集的维度。我们还知道，量子神经网络可以很好地对来自降维技术的数据进行分类（只需看看上一章的内容！）因此，必须有一些参数的选择，使得结合的混合模型能够成功完成这两个任务。因此，通过适当的训练，我们的混合模型应该能够至少与分别训练的经典编码器和量子分类器一样好。重要的是“至少”，因为当一起训练经典编码器和量子分类器时，我们可以结合它们的力量！
- en: And that’s the heuristic justification behind this interesting application of
    hybrid neural networks. Actually, this is the use case that we will devote this
    chapter to. However, this is by no means the only application of hybrid models!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是混合神经网络这一有趣应用的启发式理由。实际上，这是我们将在本章中探讨的用例。然而，这绝对不是混合模型唯一的用途！
- en: To learn more…
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多...
- en: Hybrid architectures can also be used in regression problems, as we will later
    see in an exercise. In fact, this is a very interesting application, for Skolit
    et al. [[91](ch030.xhtml#Xskolik2022quantum)] have shown that adding a final layer
    with trainable parameters that transform the output of a quantum neural network
    can be very beneficial in certain reinforcement learning problems.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 混合架构也可以用于回归问题，正如我们将在练习中看到的。事实上，这是一个非常有趣的应用，Skolit等人[[91](ch030.xhtml#Xskolik2022quantum)]已经表明，在量子神经网络输出上添加一个具有可训练参数的最终层可以在某些强化学习问题中非常有益。
- en: Now we promised that this chapter would be very hands-on, and we are going to
    honor that. That should have been enough of a theoretical introduction, so let’s
    gear up! Get ready to train a bunch of hybrid QNNs to classify some data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们承诺这一章将非常实用，我们将履行这一承诺。理论介绍应该已经足够了，所以让我们准备起来！准备好训练一系列混合量子神经网络（QNNs）来对数据进行分类。
- en: 11.2 Hybrid architectures in PennyLane
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11.2 PennyLane中的混合架构
- en: In this section, we are going to use PennyLane to implement and train a couple
    of hybrid QNNs in order to solve some classification problems. Firstly, we will
    tackle a binary classification problem, just to better understand how hybrid QNNs
    work in a familiar setting. Then, we will take one step further and do the same
    for a multi-class classification problem.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用PennyLane实现和训练几个混合QNNs来解决一些分类问题。首先，我们将解决一个二元分类问题，以便更好地理解混合QNNs在熟悉环境中的工作方式。然后，我们将更进一步，对多类分类问题做同样的处理。
- en: Before we get to the problems, though, let us set things up.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始解决问题之前，让我们先做好准备工作。
- en: 11.2.1 Setting things up
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2.1 准备工作
- en: 'As on previous occasions, we shall begin by importing NumPy and TensorFlow
    and setting a seed for both packages — all to ensure the reproducibility of our
    results:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如同之前的场合，我们将首先导入NumPy和TensorFlow，并为这两个包设置一个种子——所有这些都是为了确保我们结果的复现性：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now we can also import some useful functions from scikit-learn. We’ve already
    used them extensively — they need no introduction!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以从scikit-learn导入一些有用的函数了。我们已经广泛地使用了它们——无需介绍！
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this chapter, we will generate our own datasets to have more flexibility.
    In order to create them, we will rely on the `make_classification` function in
    the scikit-learn package. Remember that we introduced it in *Chapter* [*8*](ch017.xhtml#x1-1390008),
    *What Is* *Quantum Machine Learning?*:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将生成自己的数据集以获得更多的灵活性。为了创建它们，我们将依赖于scikit-learn包中的`make_classification`函数。记住，我们在*第*[*8*](ch017.xhtml#x1-1390008)，*什么是*
    *量子机器学习？* 中介绍了它：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Also, in this section, we will use the Lightning simulator with adjoint differentiation
    in order to get a good performance. Thus, we need to change the default datatype
    used by Keras models:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在本节中，我们将使用具有伴随微分的Lightning模拟器来获得良好的性能。因此，我们需要更改Keras模型默认使用的数据类型：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We can now import PennyLane and define the hermitian matrix ![M](img/file704.png
    "M") that we used in the previous chapter. Recall that it corresponds to the observable
    that assigns the eigenvalue ![1](img/file13.png "1") to ![\left| 0 \right\rangle](img/file6.png
    "\left| 0 \right\rangle") and the eigenvalue ![0](img/file12.png "0") to ![\left|
    1 \right\rangle](img/file14.png "\left| 1 \right\rangle"); that is, ![M = \left|
    0 \right\rangle\left\langle 0 \right|](img/file1388.png "M = \left| 0 \right\rangle\left\langle
    0 \right|").
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以导入PennyLane并定义我们在上一章中使用过的厄米矩阵 ![M](img/file704.png "M")。回想一下，它对应于将特征值
    ![1](img/file13.png "1") 分配给 ![\left| 0 \right\rangle](img/file6.png "\left| 0
    \right\rangle") 和特征值 ![0](img/file12.png "0") 分配给 ![\left| 1 \right\rangle](img/file14.png
    "\left| 1 \right\rangle") 的可观测量；也就是说，![M = \left| 0 \right\rangle\left\langle
    0 \right|](img/file1388.png "M = \left| 0 \right\rangle\left\langle 0 \right|")。
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Lastly, we may import Matplotlib and reuse the function that we defined in
    the previous chapter for plotting training and validation losses:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以导入Matplotlib并重用我们在上一章中定义的用于绘制训练和验证损失的函数：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: And that’s all we need to get started. Let’s go for our first problem.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 那就是我们开始所需的所有内容。让我们开始我们的第一个问题。
- en: 11.2.2 A binary classification problem
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2.2 二元分类问题
- en: 'We are now ready to build our first hybrid QNN and train it to solve a binary
    classification task. Of course, the first thing we need is data and, as we discussed
    in the previous section, we shall generate it using the `make_classification`
    function. Using a hybrid QNN that will ”combine classical encoding with quantum
    classification” can make sense if, for instance, we have a large number of variables
    (features) in our dataset, so we will generate a dataset with ![20](img/file588.png
    "20") variables — that might already be quite large for current quantum hardware!
    Just to make sure that we have enough data, we will generate ![1000](img/file790.png
    "1000") samples. This is how we can do it:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好构建我们的第一个混合QNN，并训练它来解决一个二元分类任务。当然，我们首先需要数据，正如我们在上一节中讨论的，我们将使用`make_classification`函数来生成它。使用将“结合经典编码与量子分类”的混合QNN是有意义的，如果我们数据集中有大量的变量（特征），因此我们将生成一个包含![20](img/file588.png
    "20")个变量的数据集——这已经对于当前的量子硬件来说可能相当大了！为了确保我们有足够的数据，我们将生成![1000](img/file790.png "1000")个样本。这就是我们如何做到这一点的：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: By default, the `make_classification` functions generate datasets with two possible
    classes. Just what we wanted!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`make_classification`函数生成具有两个可能类别的数据集。这正是我们想要的！
- en: 'As usual, we will have to split this dataset into some training, validation,
    and test datasets:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，我们必须将这个数据集分成一些训练集、验证集和测试集：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With our data ready, we need to think about the model that we will use. Let’s
    begin by constructing the quantum layer (the QNN) that we will include at the
    end of the network.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据已经准备好了，我们需要考虑我们将要使用的模型。让我们先构建网络末尾将包含的量子层（QNN）。
- en: 'For this problem, we will use the two-local variational form that we introduced
    in the previous chapter (see *Figure* [*10.2*](ch019.xhtml#Figure10.2)). As you
    surely remember, we can implement it in PennyLane as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题，我们将使用我们在上一章中介绍的两个局部变分形式（参见*图* [*10.2*](ch019.xhtml#Figure10.2)）。正如你肯定记得的，我们可以在PennyLane中如下实现它：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will take the quantum layer to be a simple QNN on four qubits using angle
    embedding as a feature map followed by the two-local variational form that we
    have just implemented. The measurement operation in the QNN will be the computation
    of the expectation value of ![M](img/file704.png "M") on the first qubit; that’s
    a sensible choice for binary classifiers in general, because it returns a value
    between ![0](img/file12.png "0") and ![1](img/file13.png "1"). The QNN can be
    defined as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将量子层视为一个简单的四比特QNN，使用角度嵌入作为特征图，随后是刚刚实现的两个局部变分形式。QNN中的测量操作将是计算第一个量子比特上![M](img/file704.png
    "M")的期望值；这对于二元分类器来说是一个合理的选择，因为它返回一个介于![0](img/file12.png "0")和![1](img/file13.png
    "1")之间的值。QNN可以定义为如下：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Notice how we have already declared the weights dictionary that we will have
    to send to the TensorFlow interface in order to create the quantum layer. In it,
    we’ve specified that our variational form uses ![4 \cdot (2 + 1) = 12](img/file1398.png
    "4 \cdot (2 + 1) = 12") weights.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们已经声明了权重字典，我们必须将其发送到TensorFlow接口以创建量子层。在其中，我们指定我们的变分形式使用![4 \cdot (2 + 1)
    = 12](img/file1398.png "4 \cdot (2 + 1) = 12")个权重。
- en: 'We will define our hybrid QNN to have an input layer with ![20](img/file588.png
    "20") inputs in order to match the dimension of our data. This will be followed
    by a classical layer, which will be immediately followed by the quantum neural
    network (the quantum layer). Since our QNN accepts ![4](img/file143.png "4") inputs,
    the classical layer will have ![4](img/file143.png "4") neurons itself. Moreover,
    for the QNN to work optimally, we need the data to be normalized, so the classical
    layer will use a sigmoid activation function. We can define this model in Keras
    as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义我们的混合QNN，使其具有![20](img/file588.png "20")个输入，以匹配我们数据的维度。这将随后是一个经典层，紧接着是量子神经网络（量子层）。由于我们的QNN接受![4](img/file143.png
    "4")个输入，因此经典层本身也将有![4](img/file143.png "4")个神经元。此外，为了使QNN能够最优地工作，我们需要数据被归一化，因此经典层将使用sigmoid激活函数。我们可以在Keras中如下定义此模型：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To learn more…
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多…
- en: 'When defining the Keras model, you may be tempted to store the quantum layer
    in a variable and then use it in the model definition, as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义Keras模型时，你可能倾向于将量子层存储在一个变量中，然后在模型定义中使用它，如下所示：
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This code will work and, a priori, there’s nothing wrong with it. However, if
    you decide to reset or modify your model, you will also have to rerun the first
    line, with the definition of `qlayer`, if you want to re-initialize the optimizable
    parameters (weights) in the quantum neural network!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将有效运行，并且从先验知识来看，它没有任何问题。然而，如果你决定重置或修改你的模型，你也将不得不重新运行第一行，即`qlayer`的定义，如果你想要重新初始化量子神经网络中的可优化参数（权重）！
- en: 'Having the model ready, we can also define our usual early stopping callback:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模型准备就绪后，我们还可以定义我们常用的早期停止回调：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We’ve set the patience to ![2](img/file302.png "2") epochs in order to speed
    up the training; having a higher patience may easily lead to better results!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将耐心设置为![2](img/file302.png "2")个epoch，以加快训练速度；有更高的耐心可能会轻易地带来更好的结果！
- en: 'And now, all it takes for us to train our model is to — just as we’ve always
    done on TensorFlow — pick an optimizer, compile our model with the binary cross
    entropy loss function, and call the `fit` method with the appropriate arguments:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们训练模型所需做的只是——就像我们一直在TensorFlow上所做的那样——选择一个优化器，使用二元交叉熵损失函数编译我们的模型，并使用适当的参数调用`fit`方法：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Et voilà! In just a matter of minutes, your flashy hybrid model will have finished
    training. Take a moment to reflect on how easy this was. You have been able to
    train a hybrid QNN with full ease, just as if it were a simple QNN. With PennyLane,
    quantum machine learning is a piece of cake.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Et voilà！只需几分钟，你那炫目的混合模型就会完成训练。花点时间反思一下这有多简单。你能够轻松地训练一个混合QNN，就像它是一个简单的QNN一样。有了PennyLane，量子机器学习变得易如反掌。
- en: 'To check how well the training went, we can plot the training and validation
    losses with our custom function:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查训练情况，我们可以使用我们的自定义函数绘制训练和验证损失：
- en: '[PRE14]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The generated plot can be found in *Figure* [*11.1*](#Figure11.1).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表可以在*图* [*11.1*](#Figure11.1) 中找到。
- en: '![Figure 11.1: Evolution of the training and validation loss functions in the
    training of a hybrid QNN binary classifier ](img/file1399.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图11.1：混合QNN二分类器训练中训练和验证损失函数的演变](img/file1399.png)'
- en: '**Figure 11.1**: Evolution of the training and validation loss functions in
    the training of a hybrid QNN binary classifier'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**图11.1**：混合QNN二分类器训练中训练和验证损失函数的演变'
- en: 'Those losses look really good; there don’t seem to be signs of overfitting
    and the model appears to be learning. In any case, let’s compute the test accuracy.
    We may also compute the training and validation accuracies, just for reference:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些损失看起来非常好；似乎没有过拟合的迹象，模型看起来正在学习。无论如何，让我们计算测试准确率。我们也可以计算训练和验证准确率，仅供参考：
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When running the preceding code, we can see how our model has a training accuracy
    of ![95\%](img/file1400.png "95\%"), a validation accuracy of ![90\%](img/file1401.png
    "90\%"), and a test accuracy of ![96\%](img/file1402.png "96\%").
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行前面的代码时，我们可以看到我们的模型有![95\%](img/file1400.png "95\%")的训练准确率，![90\%](img/file1401.png
    "90\%")的验证准确率，以及![96\%](img/file1402.png "96\%")的测试准确率。
- en: That’s a very satisfactory result. We have just trained our first hybrid QNN
    binary classifier, and we’ve seen how it can be effectively used to solve classification
    tasks.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常令人满意的结果。我们刚刚训练了我们的第一个混合QNN二分类器，并看到了它如何有效地解决分类任务。
- en: Exercise 11.1
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.1
- en: Try to solve this problem using two additional (dense) classical layers, with
    ![16](img/file619.png "16") and ![8](img/file506.png "8") neurons each. Compare
    the results.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用两个额外的（密集的）经典层解决这个问题，每个层有![16](img/file619.png "16")和![8](img/file506.png
    "8")个神经元。比较结果。
- en: Now, we said that this chapter was going to be hands-on and we truly meant it.
    So far, we have just trained models and gotten them right in one shot, but that’s
    something that rarely happens in practice. That’s why we’ve put together a small
    subsection on how to optimize models in real-world conditions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们说这一章将是一个动手实践，我们确实是这么想的。到目前为止，我们只是训练模型并在一次尝试中就得到了正确的结果，但在实践中这种情况很少发生。这就是为什么我们专门编写了一个小节，介绍如何在现实世界条件下优化模型。
- en: 11.2.3 Training models in the real world
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2.3 在现实世界中训练模型
- en: Whether you believe it or not, we care for you, our dear reader. All this time,
    behind each and every model that we’ve trained, we’ve invested hours of meticulous
    parameter selection and model preparation — all to make sure that the results
    we give you are good enough, if not optimal.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是否相信，我们都关心你，亲爱的读者。在这段时间里，在每一个我们训练的模型背后，我们都投入了数小时细致的参数选择和模型准备——都是为了确保我们给出的结果足够好，如果不是最优的。
- en: When you set out to train models on your own, you will soon find out that things
    don’t always work as well as you expected. For each well-performing model, there
    will be tens or even hundreds of discarded ones. And that’s something you need
    to prepare yourself for.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当您开始自己训练模型时，您很快就会发现自己期望的事情并不总是那么顺利。对于每个表现良好的模型，都会有成十甚至上百个被丢弃的模型。这是您需要做好准备的事情。
- en: 'At the early stages of a machine learning project in general — and a quantum
    machine learning project in particular — you should address two main following
    questions:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在一般机器学习项目的早期阶段——尤其是量子机器学习项目——您应该解决以下两个主要问题：
- en: '**How will you log all your results?** When you train lots of models, you need
    to find a way to log their performances together with their architectures and
    the parameters used in their training. That way, you can easily identify what
    works and what doesn’t, and you can avoid repeating the same mistakes.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您将如何记录所有结果？** 当您训练大量模型时，您需要找到一种方法来记录它们的性能以及它们的架构和训练中使用的参数。这样，您可以轻松地识别出哪些有效，哪些无效，并避免重复犯同样的错误。'
- en: '**How will you explore variations of your models?** Keeping a separate script
    for every model can be manageable when you are not training many models, but this
    isn’t a solution for large-scale projects. Oftentimes, you want to try a wide
    range of configurations and see which one works best. And automation can truly
    make your life easier in this regard.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您将如何探索您模型的变体？** 当您不训练很多模型时，为每个模型保留一个单独的脚本可能是可管理的，但这并不是大规模项目的解决方案。通常，您想尝试广泛的配置，看看哪一个效果最好。而自动化在这方面确实可以让您的生活更轻松。'
- en: We leave the first question to you. In truth, there’s no universal way to address
    it — it all depends on the problem at hand and on the training strategy that you
    take. However, in regard to the second question, we do have something to offer.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将第一个问题留给您。实际上，没有通用的方法来解决这个问题——它完全取决于手头的问题和您采取的训练策略。然而，关于第二个问题，我们确实有一些东西可以提供。
- en: When training a model, choosing good hyperparameters — such as a good batch
    size or learning rate — is not an easy task, but it is a crucial one. Should you
    use a smaller or a larger learning rate? How many layers should you use? Of what
    type? Decisions, decisions, decisions! The number of possibilities grows exponentially,
    so it is impossible to explore every one of them. But, in machine learning, finding
    a good configuration can be the difference between success and failure. How can
    we do this systematically and (kind of) effortlessly?
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型时，选择良好的超参数——例如良好的批量大小或学习率——并不是一件容易的事情，但这是一件至关重要的任务。您应该使用较小的还是较大的学习率？您应该使用多少层？它们是什么类型的？决定，决定，决定！可能性的数量呈指数增长，因此不可能探索每一个。但在机器学习中，找到一个好的配置可能是成功与失败之间的区别。我们如何系统地（某种程度上）轻松地做到这一点呢？
- en: There are quite a few packages and utilities out there that can help you automate
    the search for optimal training parameters. One of the most popular ones is the
    Optuna package, which we are about to demonstrate. Please refer to *Appendix*
    [*D*](ch027.xhtml#x1-240000D), *Installing the Tools*, for installation instructions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在市面上有很多软件包和实用工具可以帮助您自动化搜索最佳训练参数。其中最受欢迎的一个是Optuna软件包，我们即将演示它。请参阅*附录* [*D*](ch027.xhtml#x1-240000D)，*安装工具*，获取安装说明。
- en: To learn more…
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多...
- en: The process of automatically searching for optimal training parameters in a
    machine learning problem fits into what is known as **automated machine learning**,
    usually abbreviated as **AutoML**. This refers to the use of automation in order
    to solve machine learning problems. Having machines in charge of training other
    machines!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习问题中自动搜索最佳训练参数的过程符合所谓的**自动化机器学习**，通常缩写为**AutoML**。这指的是使用自动化来解决机器学习问题。让机器负责训练其他机器！
- en: 'Once you’ve installed Optuna, you can import it as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您安装了Optuna，您可以按照以下方式导入它：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We are going to use Optuna to find the best possible learning rate between the
    values ![0.001](img/file1165.png "0.001") and ![0.1](img/file1163.png "0.1").
    In order to do this, we need to define a function (which we shall call `objective`)
    with a single argument (`trial`). The objective function should use the training
    parameters that we want to optimize — in a manner that we will soon make precise
    — and it should return whichever metric we want to optimize. For instance, in
    our case, we would like to maximize the validation accuracy, so the objective
    function should train a model and return the validation accuracy.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Optuna 在值 ![0.001](img/file1165.png "0.001") 和 ![0.1](img/file1163.png
    "0.1") 之间找到最佳的学习率。为了做到这一点，我们需要定义一个函数（我们将称之为 `objective`），它只有一个参数（`trial`）。目标函数应该使用我们想要优化的训练参数——我们将很快明确这一点——并且应该返回我们想要优化的任何指标。例如，在我们的情况下，我们希望最大化验证准确率，因此目标函数应该训练一个模型并返回验证准确率。
- en: 'The `trial` argument of the `objective` function is meant to represent an object
    of the `Trial` class that can be found in the `optuna``.``trial` module. We will
    use this object to define, within the objective function itself, the training
    parameters that we want to optimize, while also specifying their constraints:
    whether we want them to be integers or floats, the ranges within which we want
    our values to be, and so on.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`objective` 函数的 `trial` 参数旨在表示 `optuna.trial` 模块中可以找到的 `Trial` 类的对象。我们将使用此对象在目标函数本身中定义我们想要优化的训练参数，同时指定它们的约束：我们是否希望它们是整数或浮点数，我们希望我们的值在哪个范围内，等等。'
- en: 'For our case, this is the objective function that we would have to define:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的情况，这是我们必须要定义的目标函数：
- en: '[PRE17]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Notice how we have defined the learning rate as an optimizable parameter by
    calling the `trial``.``suggest_float``(``"``learning_rate``"``,` `0.001,` `0.1)`
    method. In general, if you want to optimize a parameter named `"``parameter``"`,
    the following applies:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们是如何通过调用 `trial.suggest_float`(`"learning_rate"`，`0.001`，`0.1`) 方法将学习率定义为可优化参数的。一般来说，如果你想优化名为
    `"parameter"` 的参数，以下适用：
- en: If the data type of the parameter is a float and the parameter is bounded between
    `m` and `M`, you should call the `suggest_float``(``"``parameter``"``,` `m``,`
    `M``)` method. If you only want your parameter to take discrete values between
    `m` and `M` separated by a step `s`, you can send the optional argument `step`
    `=` `s`, which defaults to `None` (by default, the parameter will take continuous
    values).
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果参数的数据类型是浮点数，并且参数被限制在 `m` 和 `M` 之间，你应该调用 `suggest_float`(`"parameter"`，`m`，`M`)
    方法。如果你只想让你的参数在 `m` 和 `M` 之间以步长 `s` 分隔的离散值中取值，你可以发送可选参数 `step` `=` `s`，默认值为 `None`（默认情况下，参数将取连续值）。
- en: If the data type of the parameter is an integer bounded between `m` and `M`,
    you should call `suggest_int``(``"``parameter``"``,` `m``,` `M``)`. Also, if the
    values of the parameter should be separated by a step `s` from `m` to `M`, you
    can send in `step` `=` `s`.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果参数的数据类型是介于 `m` 和 `M` 之间的整数，你应该调用 `suggest_int`(`"parameter"`，`m`，`M`)。此外，如果参数的值应该从
    `m` 到 `M` 以步长 `s` 分隔，你可以发送 `step` `=` `s`。
- en: 'If your parameter takes values out of a list `values` of possible values, you
    should call `suggest_categorical``(``"``parameter``"``,` `values``)`. For instance,
    if we wanted to try out different activation functions on a layer of a neural
    network, we could use something like the following:'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的参数的值在可能的值列表 `values` 中，你应该调用 `suggest_categorical`(`"parameter"`，`values`)。例如，如果我们想在神经网络的层上尝试不同的激活函数，我们可以使用以下类似的方法：
- en: '[PRE18]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Of course, a single objective function can have as many optimizable parameters
    as desired. They would just be defined with separate invocations of the methods
    that we’ve just outlined.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一个单一的目标函数可以有任意多的可优化参数。它们只是通过我们刚刚概述的方法的单独调用来定义的。
- en: 'So that’s how you can create an objective function and specify the parameters
    that you want to optimize within it. Now, how do we optimize them? The first step
    is to create a `Study` object with the `create_study` function, just as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这就是你可以创建一个目标函数并指定在其中要优化的参数的方法。现在，我们如何优化它们呢？第一步是使用 `create_study` 函数创建一个 `Study`
    对象，就像下面这样：
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here we have specified that we want to create a study in order to maximize
    some objective function and using `TPESampler` with a seed. By default, Optuna
    will try to minimize objective functions — that’s why we had to send in that argument.
    The sampler that we’ve passed is just the object that, during the optimization
    process, is going to look for values to try. The one we’ve selected is the default
    one, but we have passed it manually so that we could give it a seed and get reproducible
    results. There are many other samplers. Most notably, `GridSampler` allows you
    to try all the combinations of parameters out of a pre-defined ”search space.”
    For instance, we could use the following sampler:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This would make Optuna try out the values ![0.001](img/file1165.png "0.001"),
    ![0.003](img/file1403.png "0.003"), ![0.005](img/file1389.png "0.005"), ![0.008](img/file1404.png
    "0.008"), and ![0.01](img/file1093.png "0.01") — and no others.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: If you want to learn more about how these samplers work, you may have a look
    at their online documentation ([https://optuna.readthedocs.io/en/stable/reference/samplers/index.html](https://optuna.readthedocs.io/en/stable/reference/samplers/index.html)).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'With the `Study` object ready, all we have to do is call the `optimize` method
    specifying the objective function and the number of trials that we will let Optuna
    run:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Upon running this (it can take a while), you will get an output similar to
    the following:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: With the parameter variations that we have considered, we haven’t seen any significant
    differences in performance. But, still, at least we’ve learned how to use Optuna!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.2
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Use Optuna to simultaneously optimize the learning rate and the batch size of
    the model.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: As a final remark, notice how, in the objective function, we have used the validation
    accuracy and not the test accuracy. The test dataset, remember, should only be
    used once we’ve already picked our best model. Otherwise, its independence is
    compromised. For instance, if we had saved the models following each Optuna trial,
    now it would make sense for us to compute the test accuracy on the trial 4 model
    in order to make sure that we have a low generalization error.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.3
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Optuna can be used on any framework, not just TensorFlow — it can be used to
    optimize any parameters that you want for any purpose! All you have to do is build
    a suitable objective function. To further illustrate this, use Optuna to find
    the minimum of the function ![f(x) = {(x - 3)}^{2}](img/file1405.png "f(x) = {(x
    - 3)}^{2}").
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: In these few pages, we haven’t been able to cover all there is to know about
    Optuna. If you would like to learn more, you should have a look at its online
    documentation. You can find it at [https://optuna.readthedocs.io/en/stable/index.html](https://optuna.readthedocs.io/en/stable/index.html).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'That was a short overview of how to train (quantum) machine learning models
    in real-world scenarios. In the following subsection, we will leave our comfort
    zone and use PennyLane to solve a new problem for us: a multi-class classification
    task.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 11.2.4 A multi-class classification problem
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is going to be an exciting subsection, for we are about to consider a
    new kind of problem on which to apply our QML knowledge. Nonetheless, every long
    journey begins with a first step, and ours shall be to reset the seeds of NumPy
    and TensorFlow, just to make reproducibility easier:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We are about to consider a multi-class classification problem and, of course,
    the first thing we need is data. Our good old `make_classification` function can
    help us here, for we can give it the optional argument `n_classes` `=` `3` in
    order for it to generate a dataset with ![3](img/file472.png "3") distinct classes,
    which will be labeled as ![0](img/file12.png "0"), ![1](img/file13.png "1"), and
    ![2](img/file302.png "2"). However, there’s a catch. Increasing the number of
    classes means that, as per the function’s requirements, we will also have to tweak
    some of the default parameters; a valid configuration can be reached by setting
    the argument `n_clusters_per_class` to ![1](img/file13.png "1"). Thus, we can
    generate our dataset for ternary classification as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Now that we have data, it’s time for us to think about the model. We are approaching
    a new kind of problem, so we need to go back to the basics. For now, let’s forget
    about the hybrid component of the network, and let’s try to think about how we
    could design a QNN capable of solving a ternary classification problem.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: A general perspective on multi-class classification tasks
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this regard, it is useful to look at how this kind of problem is handled
    with classical neural networks. We know that, when solving binary classification
    problems, we consider neural networks having a single neuron in the final layer
    with a bounded activation function; in this way, we assign a label depending on
    whether the output is closer to ![0](img/file12.png "0") or ![1](img/file13.png
    "1"). Such an approach might not be as effective, in general, when having multiple
    classes.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: When working with ![k](img/file317.png "k")-class classification problems, neural
    networks are usually designed to have ![k](img/file317.png "k") neurons in their
    final layer — again, with bounded activation functions that make the values lie
    between ![0](img/file12.png "0") and ![1](img/file13.png "1"). And how is a label
    assigned from the output of these neurons? Easy. Each neuron is associated to
    a label, so we just assign the label of the neuron that has the highest output.
    Heuristically, you may think of each of these ![k](img/file317.png "k") neurons
    in the final layer as light bulbs — whose brightness is determined by their output
    — indicating how likely it is that the input will belong to a certain category.
    All we do in the end is assigning the category of the light bulb that shines the
    most!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Porting this idea to quantum neural networks is easy. Instead of taking the
    expectation value of the observable ![M](img/file704.png "M") on the first qubit,
    we return an array of values with the expectation values of the ![M](img/file704.png
    "M") observable on the first ![k](img/file317.png "k") qubits — assigning to each
    qubit a label. It couldn’t be easier.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: There are other ways to build classifiers in problems with multiple classes.
    For instance, two popular approaches are the **one-versus-all** and **one-versus-one**
    methods. They involve training multiple binary classifiers and combining their
    results. We invite you to have a look at chapter 3 of Geron’s book if you are
    curious [[104](ch030.xhtml#Xhandsonml)].
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'That solves the problem of designing a QNN that can handle our task, but we
    still have an issue left: we don’t yet have a suitable loss function for this
    kind of problem. In binary classification, we could rely on the binary cross-entropy
    function, but it doesn’t work for problems with multiple categories. Luckily for
    us, there’s a loss function that generalizes the binary cross entropy. Please,
    let us introduce you to the **categorical cross-entropy** loss.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us consider an arbitrary neural network ![N](img/file784.png "N") that,
    for any choice of parameters ![\theta](img/file89.png "\theta") and any input
    ![x](img/file269.png "x"), returns an array ![N_{\theta}(x)](img/file1406.png
    "N_{\theta}(x)") with ![k](img/file317.png "k") entries, all of them between ![0](img/file12.png
    "0") and ![1](img/file13.png "1"). The categorical cross-entropy loss function
    depends on the parameters of the neural network ![\theta](img/file89.png "\theta"),
    the inputs ![x](img/file269.png "x"), and the targets ![y](img/file270.png "y"),
    but there is an important subtlety: the loss function expects the targets ![y](img/file270.png
    "y") to be in **one-hot** **form**. This means that ![y](img/file270.png "y")
    shouldn’t be a number representing a label (![0,1,\ldots,k - 1](img/file1407.png
    "0,1,\ldots,k - 1")). Instead, it should be a vector (an array) with ![k](img/file317.png
    "k") entries that are all set to ![0](img/file12.png "0") except for the entry
    in the position of the label, which should be set to ![1](img/file13.png "1").
    Thus, instead of having ![y = 0](img/file1408.png "y = 0"), we would have ![y
    = (1,0,\ldots,0)](img/file1409.png "y = (1,0,\ldots,0)"), or, instead of having
    ![y = k - 1](img/file1410.png "y = k - 1"), we would have ![y = (0,\ldots,0,1)](img/file1411.png
    "y = (0,\ldots,0,1)"). Under these assumptions, the categorical cross-entropy
    is defined as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '![H(\theta;x,y) = - \sum\limits_{j = 1}^{k}y_{j}{\log}(N_{\theta}(x)_{j}).](img/file1412.png
    "H(\theta;x,y) = - \sum\limits_{j = 1}^{k}y_{j}{\log}(N_{\theta}(x)_{j}).")'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
- en: Of course, we have used the subindex ![j](img/file258.png "j") in ![y](img/file270.png
    "y") and ![N_{\theta}(x)](img/file1406.png "N_{\theta}(x)") to denote their ![j](img/file258.png
    "j")-th entries. Notice how, in this definition, we have implicitly assumed that
    the first neuron in the final layer is associated to the label ![0](img/file12.png
    "0"), the second neuron is associated to ![1](img/file13.png "1"), and so on.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.4
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Prove that the binary cross-entropy loss is a particular case of the categorical
    cross-entropy loss for ![k = 2](img/file1413.png "k = 2").
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the categorical cross-entropy function is a reasonable loss function
    for multi-class classification, and it shares some nice properties with the binary
    cross-entropy loss function. For instance, it is zero if a classifier gets an
    output completely right (it assigns ![1](img/file13.png "1") to the correct output
    and ![0](img/file12.png "0") to the rest), but it diverges if a classifier assigns
    ![1](img/file13.png "1") to a wrong output and ![0](img/file12.png "0") to the
    rest.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: So far, we already know how to implement our QNN and we have a loss function,
    so we just have to finalize the details of our architecture. Regarding the quantum
    layer, we already know which observable we are going to use, so that’s not a problem.
    For the feature map, we will rely on angular encoding and, for the variational
    form, we shall use the two-local variational form. To keep things somewhat efficient,
    we will take our QNN to have four qubits, and we will leave the rest of the hybrid
    architecture just as it was in the previous subsection.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: That’s enough abstract thinking for now; let’s get to the code. And be prepared,
    because things are about to get hot.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a QNN for a ternary classification problem
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: According to our plan, the first thing that we need to do is encode our array
    of targets `y` in one-hot form.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.5
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: There is a variation of the categorical cross entropy loss that doesn’t require
    the targets to be in one-hot form. It is the **sparse** **categorical cross entropy
    loss**. Try to replicate what follows using this loss function and the unencoded
    targets. You may access it as `tf``.``keras``.``losses``.` `SparseCategoricalCrossentropy`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: We could implement our own one-hot encoder, but there’s no need to. The scikit-learn
    package — once again to our rescue! — already implements a `OneHotEncoder` class,
    which you can import from `sklearn``.``preprocessing`. You can work with this
    class just as you would with other familiar scikit-learn classes, such as `MaxAbsScaler`.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to one-hot-encode an array of targets, you would need a `OneHotEncoder`
    object and you would just have to pass the array to the `fit_transform` method.
    But with a catch: the array should be a column vector! Our array of targets `y`
    is one-dimensional, so we will have to reshape it before we can feed it to the
    `fit_transform` method. Thus, this is how we can encode our array of targets in
    one-hot form:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Notice how we have added the argument `sparse` `=` `False`. This Boolean value,
    which defaults to `True`, determines whether or not the encoder should return
    sparse matrices. Sparse matrices are datatypes that can be very memory-efficient
    when storing matrices with lots of zeros, such as one-hot encoded arrays. Essentially,
    instead of logging the value of each entry in a matrix, a sparse matrix only keeps
    track of the non-zero entries in it. When working with very large matrices, it
    can save a ton of memory, but, sadly, using sparse matrices would lead to problems
    in the training, so we need our one-hot encoder to give us an ordinary array.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'The neat thing about the `OneHotEncoder` class is that, once we have encoded
    an array of targets with representatives from each class using `fit_transform`,
    we can use the `transform` method on any array of targets. In our case, the `hot`
    object will remember that there are ![3](img/file472.png "3") classes in our dataset,
    and hence `hot``.` `transform` will encode any targets correctly: even if it’s
    given an input with nothing other than zeros, it will still encode them as arrays
    of length ![3](img/file472.png "3").'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'We have to do nothing more to our data, so we can now split it into some training,
    validation, and test datasets:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'And we can now implement the QNN that will constitute the quantum layer of
    our model. In truth, there’s nothing particularly special about this quantum neural
    network other than the fact that it will return an array of values rather than
    a single one. We can define it, according to our previous specification, as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The code is pretty self-explanatory. Notice that, as usual, we have taken the
    chance to define the weights dictionary that we will use in the definition of
    the quantum Keras layer. In this case, we will be using ![12](img/file601.png
    "12") weights, exactly as in the case of our model in *Subsection* * [*11.2.2*](#x1-19900011.2.2),
    because we are using the same variational form and the same number of qubits and
    repetitions.*
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '*With our QNN ready, we can define the Keras model for our hybrid QNN. This
    is just analogous to what we did in the previous subsection, with a few important
    differences — don’t copy-paste so fast! First of all, in this case, we need to
    set the output dimension of the quantum layer to three, not one. And, much more
    importantly, we need to add an extra activation function on the QNN output.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'The categorical cross entropy loss function expects probability distributions.
    In principle, it assumes that the output of the ![j](img/file258.png "j")-th neuron
    is the probability that the input belong to category ![j](img/file258.png "j").
    Thus, the data that the model outputs should be normalized: it should add up to
    ![1](img/file13.png "1"). Nevertheless, a priori, there’s no way for us to guarantee
    that the QNN will return some normalized outputs with our current setup. In order
    to ensure this, we may use the **softmax** activation function, which is defined
    as'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '| ![\sigma(x_{1},\ldots,x_{n}) = \frac{1}{\sum\limits_{j = 1}^{n}e^{x_{j}}}(e^{x_{1}},\ldots,e^{x_{n}}).](img/file1414.png
    "\sigma(x_{1},\ldots,x_{n}) = \frac{1}{\sum\limits_{j = 1}^{n}e^{x_{j}}}(e^{x_{1}},\ldots,e^{x_{n}}).")
    |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
- en: It’s easy to check that ![\sigma](img/file1415.png "\sigma") is a vector with
    components bounded by ![0](img/file12.png "0") and ![1](img/file13.png "1") which
    add up to ![1](img/file13.png "1") and, hence, is a probability distribution.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to these modifications, we will add an extra classical layer with
    ![8](img/file506.png "8") neurons:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: And we can now compile our model with the Adam optimizer and the categorical
    cross-entropy loss before training it with the `fit` method; nothing particularly
    exciting here. As a fun fact, if you were forgetful enough to tell TensorFlow
    to use the binary cross-entropy loss instead of the categorical cross-entropy
    one, it would still use the categorical cross-entropy loss (don’t look at us;
    we don’t say it from experience, right?). This is a rather nice and thoughtful
    feature from the guys behind TensorFlow.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'After a few minutes of training, we may get a plot of the evolution of the
    training and validation losses with the following instruction:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The resulting plot can be found in *Figure* [*11.2*](#Figure11.2), which shows
    the evolution of both losses.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2: Evolution of the training and validation loss functions in the
    training of a hybrid QNN multi-class classifier ](img/file1416.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
- en: '**Figure 11.2**: Evolution of the training and validation loss functions in
    the training of a hybrid QNN multi-class classifier'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'We may now compute the training, validation, and test accuracies of our freshly-trained
    models, but, in order to do so, the `accuracy_score` function needs the predicted
    and actual labels to be represented by numbers, not encoded in one-hot form as
    arrays. Hence, we need to undo the one-hot encoding. For this purpose, we can
    just use the `argmax` method, which returns the entry of the maximum value in
    an array, and it can be given an optional `axis` argument for it to be applied
    only in one axis. Thus, we may compute the accuracy scores as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This returns a training accuracy of ![67\%](img/file1417.png "67\%"), a validation
    accuracy of ![53\%](img/file1418.png "53\%"), and a test accuracy of ![60\%](img/file1419.png
    "60\%"). Notice that the low accuracy on the validation dataset — compared to
    that of the training dataset — seems to indicate an overfitting problem. This
    might be fixed, for example, by using a larger training dataset; of course, this
    would lead to longer training times.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 11.6
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Just to further leave our ”classifier comfort zone,” try to implement a hybrid
    model able to do regression. This model should be trained on some data with inputs
    ![x](img/file269.png "x") and target values ![y](img/file270.png "y") for which
    there is a continuous function ![f(x)](img/file800.png "f(x)") such that ![f(x)
    \simeq y](img/file1420.png "f(x) \simeq y") (you can create such a dataset, for
    instance, with the `make_regression` method from scikit-learn). The model should
    try to learn the function ![f](img/file778.png "f") for all the points in the
    dataset.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: You may design this model using some classical layers, followed by a quantum
    layer like the ones that we have considered, and a final classical layer with
    no activation functions and just one neuron. You should train it with the mean
    squared error loss.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: That concludes our study of hybrid architectures in PennyLane. It’s time for
    us to get to Qiskit, and that’s going to be a very different adventure!
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: 11.3 Hybrid architectures in Qiskit
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we discussed how hybrid QNNs could be implemented and
    trained using PennyLane in conjunction with TensorFlow, an ML framework that we
    already know how to use. We will devote this section to studying how to work with
    these hybrid architectures in Qiskit, and in this mission we will need to face
    a new challenge.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'For better or for worse, Qiskit doesn’t have a built-in TensorFlow interface
    at the time of writing. It only has native support for a different ML framework:
    PyTorch. So, if we want to get those hybrid NNs working on Qiskit, we better learn
    a thing or two about PyTorch. As daunting as this task may seem, it won’t be such
    a hassle and it will greatly pay off in the future — and, yes, the future is our
    next chapter on QGANs.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: We will be using **version 1.13** of the PyTorch package. If you are using a
    different version, things may be slightly different!
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: What’s so special about PyTorch to be worth our time beyond this short section?
    Come and see.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.1 Nice to meet you, PyTorch!
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have worked with TensorFlow. In our experience, this framework provides
    a very easy and streamlined experience for the implementation and training of
    all sorts of network-based models. However, there’s a small catch behind all that
    ease of use. In this book, we haven’t been using ”pure TensorFlow,” but we have
    been relying heavily on Keras. In spite of being fully integrated into TensorFlow,
    Keras is a component that creates some additional layers of abstraction in order
    to simplify the handling of neural-network models in TensorFlow. All this time,
    Keras has been taking care of lots of things for us behind the scenes.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'At the time of writing, there are two very popular ML frameworks out there:
    TensorFlow and PyTorch. The former we already know, the latter we soon will. PyTorch,
    unlike TensorFlow, doesn’t come with its own Keras (although there are some third-party
    packages that provide similar functionalities). In PyTorch, we will have to take
    care of many details ourselves. And that’s great. Granted, learning how to use
    PyTorch will require a tiny bit more effort on our part, but PyTorch will offer
    us a level of flexibility that TensorFlow’s Keras simply can’t. Let’s get started
    then.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: We will be using version 1.13 of the PyTorch package. Please refer to *Appendix*
    [*D*](ch027.xhtml#x1-240000D), *Installing the Tools*, for instructions on how
    to install it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, we shall begin by importing NumPy and a few utilities from scikit-learn.
    We will also set a seed for NumPy:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'With those imports out of the way, we can get to our main dish. This is how
    you can import PyTorch and give it a seed to ensure reproducibility:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Most functionality related to the implementation of models is in the `torch``.``nn`
    module, and most activation functions can be found in the `torch``.``nn``.``functional`
    module, so let’s import these as well:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Those are all the imports that we need for now.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a model in PyTorch
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to understand how the PyTorch package works, we will implement and
    train a simple binary classifier as a (classical) neural network. This neural
    network will take ![16](img/file619.png "16") inputs and return a unique output
    between ![0](img/file12.png "0") and ![1](img/file13.png "1"). As usual, the two
    possible labels will be ![0](img/file12.png "0") and ![1](img/file13.png "1")
    and the output label will be decided based on whether the network output is closer
    to ![0](img/file12.png "0") or ![1](img/file13.png "1").
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how we can implement this neural network classifier. In PyTorch,
    model architectures are defined as subclasses of the `nn``.``Module` class, and
    individual models are objects of these subclasses. When defining subclasses of
    `nn``.``Module`, you should implement an initializer that first calls the parent’s
    initializer and then prepares all the variables of the model architecture; for
    instance, all the network layers should be initialized here. In addition, you
    need to provide a `forward` method that defines the behavior of the network: this
    method should take any input to the network as an argument and return its output.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: 'Our desired neural network could be implemented as follows (don’t worry, we
    will discuss this piece of code right away):'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'There are a few things to digest in this implementation. Let us first look
    at the initializer. As expected, we are defining a subclass of `nn``.``Module`
    and we are first calling the parent’s initializer; so far, so good. Then we are
    defining what seem to be the layers of the neural network, and here is where some
    confusion may arise. Our first issue arises from terminology: ”linear layers”
    are PyTorch’s equivalent of Keras’ ”dense” layers — not a big deal. But then we
    have a deeper issue. Back in our Keras days, we defined the layers of a neural
    network by specifying the number of neurons they had and their activation function.
    But here there’s no trace of activation functions and the layers take what seem
    to be two-dimensional arguments. What’s going on?'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: In a neural network, you have a bunch of neurons that are arranged into arrays,
    and these arrays are connected by some ”linear wiring” between them. In addition,
    each array of neurons has a (usually non-linear) activation function. In Keras,
    layers were associated to these arrays of neurons themselves (with their activation
    functions) and to the ”linear wiring” before them. In PyTorch, on the other hand,
    when we speak of layers, we only refer to the linear wiring between these arrays
    of neurons. Hence, `nn``.``Linear``(16,` `8)` is nothing more than the linear
    wiring — with its weights and biases — between an array of ![16](img/file619.png
    "16") neurons and an array of ![8](img/file506.png "8") neurons. This will make
    more sense when we look at the `forward` method.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: The `forward` method defines what happens to any input that gets into the network.
    In its implementation, we can see how any input, which will be a PyTorch tensor
    of length ![16](img/file619.png "16"), goes through the first layer. This first
    layer is the ”linear wiring” between an array of ![16](img/file619.png "16") neurons
    and an array of ![8](img/file506.png "8") neurons; it has its own weights ![w_{jk}](img/file1421.png
    "w_{jk}") and biases ![b_{k}](img/file1422.png "b_{k}") and, for any input ![(x_{1},\ldots,x_{16})](img/file1423.png
    "(x_{1},\ldots,x_{16})"), it returns a vector ![({\hat{x}}_{1},\ldots,{\hat{x}}_{8})](img/file1424.png
    "({\hat{x}}_{1},\ldots,{\hat{x}}_{8})") with
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '| ![{\hat{x}}_{k} = \sum\limits_{j = 1}^{16}w_{jk}x_{j} + b_{k}.](img/file1425.png
    "{\hat{x}}_{k} = \sum\limits_{j = 1}^{16}w_{jk}x_{j} + b_{k}.") |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
- en: Then, each entry in the resulting tensor goes through the ELU activation function.
    The rest of the code is self-explanatory and simply defines a neural network that
    matches our specifications.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: To learn more…
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Layers in PyTorch define their own weights and biases. If you wish to remove
    the biases — setting them to zero for all eternity — you may do so by sending
    the optional argument `bias` `=` `False` when initializing a layer.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have our model architecture defined, we can instantiate it into
    an individual model by initializing an object of the `TorchClassifier` class.
    A nice thing about PyTorch models, by the way, is that they can be printed; their
    output gives you an overview of the different model components. Let’s create our
    model object and see this in action:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Upon running this, we get the following output from the print instruction:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This is somewhat analogous to the model summaries that we could print in Keras.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, the weights and biases of models are random, so our newly-created
    `model` should already be ready to be used. Let’s try it out! The `torch``.``rand`
    function can create a random tensor of any specified size. We will use it to feed
    our model some random data and see if it works:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This is the output that we get:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'And there we have it! As expected, our model returns a value between ![0](img/file12.png
    "0") and ![1](img/file13.png "1"). By the way, notice one little thing in the
    output: right next to the tensor value, there is a `grad_fn` value that somehow
    remembers that this output was last obtained from the application of a sigmoid
    function. Interesting, isn’t it? Well, you may remember that TensorFlow used its
    own tensor datatype, and PyTorch has its own tensors too. The cool thing about
    them is that every PyTorch tensor keeps track of how it was computed in order
    to enable gradient computation through backpropagation. We will further discuss
    this later on in this subsection.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'In any case, now that our network is all set up, let us generate some data
    and split it into some training, validation, and test datasets:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Training a model in PyTorch
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In principle, we could work with this raw data just as we did in TensorFlow
    — perhaps converting it to PyTorch tensors, but still. However, we know that PyTorch
    will require us to take care of many things ourselves; one of which will be splitting
    our data into batches should we want to. Doing that ourselves could be tedious
    to say the least. Thankfully, PyTorch comes with some tools that can assist us
    in the process, so we better give them a shot.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'The best way to deal with datasets in PyTorch is by storing data in subclasses
    of a `Dataset` class, which can be found in the `torch``.``utils``.``data` module.
    Any subclasses of `Dataset` should implement an initializer, a `__getitem__` method
    (to access data items by indexing), and a `__len__` method (returning the number
    of items in the dataset). For our purposes, we can create a subclass in order
    to create datasets from our NumPy arrays:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Notice how we have added some size-checking to ensure that the data array and
    the labels vector have matching dimensions, and how we have reshaped the array
    of targets — that’s in order to avoid problems with the loss functions, which
    expect them to be column vectors. With this class set up, we may create dataset
    objects for the training, validation and test datasets as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Just to check whether our implementation was successful, let us try to access
    the first element in `tr_data` and get the length of the training dataset:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This is the output returned by these instructions:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We can see how, indeed, it gave us a tuple with a tensor of length ![16](img/file619.png
    "16") and its corresponding label. Also, a call to the `len` function did return
    the correct number of items in our dataset. Now, you may reasonably wonder why
    we should bother with all this mess of creating dataset classes. There are a couple
    of reasons. For one, this allows us to have our data organized and structured
    in a more orderly manner. What is more, using dataset objects, we can create data
    loaders. The `DataLoader` class can be imported from `torch``.``utils``.``data`
    and its objects allow us to easily iterate through batches of data. An example
    may help clarify this.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say that we want to iterate over the training dataset in batches of ![2](img/file302.png
    "2"). All we would have to do is to create a data loader with the `tr_data` dataset
    specifying the batch size and the fact that we would like it to shuffle the data.
    Then, we could create an iterator object out of the data loader with the `iter`
    function and iterate over all the batches. This is shown in the following piece
    of code:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'You may recall from Python 101 that calling `next``(``tr_loader``)` for the
    first time would be equivalent to running a `for` `x` `in` `tr_loader` loop and
    extracting the value of `x` in the first iteration. This is the output that we
    get:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: And there you have it! In each iteration of the data loader, we get an array
    with the training data in the batch and its corresponding array of targets. All
    is shuffled and taken care of by PyTorch automatically. Neat, isn’t it? That can
    and will save us a good deal of effort.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: We must say that, in truth, you could technically use data loaders without going
    through the whole process of defining datasets — just sending in the numpy arrays.
    But it wouldn’t be the most ”PyTorchy” of practices. Anyhow, this settles our
    preparation of datasets.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: 'In the training process, we will use, as always, the binary cross-entropy loss.
    We can save its function in a variable as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Thus, the `get_loss` function will take a tensor of values between ![0](img/file12.png
    "0") and ![1](img/file13.png "1") and a matching tensor of labels, and will use
    them to compute the binary cross entropy loss. To see if it works as expected,
    we may compute a simple loss:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Since the only value in the tensor matches the expected value, we should get
    a loss of ![0](img/file12.png "0") and, indeed, this instruction returns `tensor`
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '`(0.)`.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'We are already preparing ourselves for the training. In our case, since our
    dataset has ![1000](img/file790.png "1000") elements, it could make sense to use
    a batch size of ![100](img/file389.png "100"), so let us prepare the training
    data loader to that effect:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'As usual, we will rely on the Adam optimizer for the training. The optimizer
    is implemented as a class in the `torch``.``optim` module, and, in order to use
    it, we need to specify which parameters it is going to optimize; in our case,
    that will be the parameters in our model, which we can retrieve with the `parameters`
    method. In addition, we can further configure the optimizer by passing optional
    arguments for the learning rate, among other adjustable parameters. We will use
    a learning rate of ![0.005](img/file1389.png "0.005") and trust the default values
    of the remaining parameters. Thus, we can define our optimizer as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now we have all the ingredients ready and we can finally get to the training
    itself. In Keras, this would’ve been as easy as calling a method with a bunch
    of parameters, but here we have to work the training out ourselves! We will begin
    by defining a function that will perform one full training epoch. It will be the
    following:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The code is pretty much self-explanatory, but a few details deserve clarification.
    We have used two new methods: `backward` and `step`. Oversimplifying a bit, the
    `backward` method on `loss` computes the gradient of the loss by tracing back
    how it was computed and saving the partial derivatives in the optimizable parameters
    of the model on which the loss depends. This is the famous backpropagation technique
    that we talked about in *Chapter* *[*8*](ch017.xhtml#x1-1390008), *What Is Quantum*
    *Machine Learning?*. Then, `opt``.``step``()` prompts the optimizer to update
    the optimizable parameters using the derivatives that `loss``.``backward``()`
    computed.*'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '*To learn more…'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are curious about how differentiation works with the `backward` method
    on PyTorch tensors, we can run a quick example to illustrate. We may define two
    variables, `a` and `b`, taking the values ![2](img/file302.png "2") and ![3](img/file472.png
    "3") respectively as follows:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Notice how we set `requires_grad` `=` `True` to tell PyTorch that these are
    variables it should keep track of. We may then define the function ![f(a,b) =
    a^{2} + b](img/file1426.png "f(a,b) = a^{2} + b") and compute its gradient as
    follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We know that ![\left. \partial f\slash\partial a = (\partial\slash\partial a)a^{2}
    + b = 2a \right.](img/file1427.png "\left. \partial f\slash\partial a = (\partial\slash\partial
    a)a^{2} + b = 2a \right."), which in our case is equal to ![2a = 2 \cdot 2 = 4](img/file1428.png
    "2a = 2 \cdot 2 = 4"). When we run the `backward` method, PyTorch has already
    computed this partial derivative for us, and we can access it by calling `a``.``grad`,
    which, as expected, returns `tensor``([4.])`. Analogously, ![\left. \partial f\slash\partial
    b = 1 \right.](img/file1429.png "\left. \partial f\slash\partial b = 1 \right."),
    and, as expected, `b``.``grad` returns `tensor` `([1.])`.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: In principle, we could train our model by calling `run_epoch` manually as many
    times as we wanted, but why suffer like that when we can leave Python in charge?
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us define a training loop in which, at each iteration, we will run an epoch
    and log the training and validation loss obtained over the whole dataset. Instead
    of fixing a specific number of epochs, we will keep iterating until the validation
    loss increases — this will be our own version of the early stopping callback that
    we used in TensorFlow. The following piece of code gets the job done:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Notice how, when logging the losses in `tr_losses`, we have converted the PyTorch
    tensors to floats. This is the output that we get after executing this loop:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'An image is worth a thousand words, so, just to get a visual overview of the
    performance of our training, let us recycle the `plot_losses` function that we
    had for TensorFlow and run it:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The resulting plot can be found in *Figure* [*11.3*](#Figure11.3). The plot
    does show some signs of overfitting, but likely not something to be concerned
    about; in any case, let’s wait until we get the accuracy over the test dataset.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3: Evolution of the training and validation losses over the training
    of a classical binary classifier with PyTorch ](img/file1430.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
- en: '**Figure 11.3**: Evolution of the training and validation losses over the training
    of a classical binary classifier with PyTorch'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to get the accuracy of our classifier on the training, validation,
    and test datasets, we can run the following instructions:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: This returns a training accuracy of ![94\%](img/file1431.png "94\%"), a validation
    accuracy of ![92\%](img/file1432.png "92\%"), and a test accuracy of ![96\%](img/file1402.png
    "96\%").
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: We have just concluded our not-that-short introduction to PyTorch. Let’s go
    quantum!
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.2 Building a hybrid binary classifier with Qiskit
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this subsection, we will implement our first hybrid QNN with Qiskit. The
    process will be fairly straightforward, and we will be able to rely on a good
    deal of the code that we already have. To get started, let us import the Qiskit
    package and the ZZ feature map and two-local variational form that come bundled
    with it:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'With a QNN, it will be advisable to use smaller datasets in order for the training
    time to be reasonable on our simulators. We can prepare them, along with the corresponding
    dataset and data loader objects, as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Our quantum layer will be a simple ![4](img/file143.png "4")-qubit QNN with
    one instance of the ZZ feature map and the two-local variational form. Thus, the
    components that we will use in our QNN circuit will be the following:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Here, we have instantiated the two-local form as in *Chapter* [*10*](ch019.xhtml#x1-18100010),
    *Quantum* *Neural Networks*.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, just as we did in the previous chapter, we could use the `TwoLayerQNN`
    class in order to generate our quantum neural network according to our specifications.
    We may import it as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'We are now ready to define our model architecture with PyTorch. Its structure
    will be analogous to that of a classical architecture. The only difference is
    that we will have to define a quantum neural network object in the initializer,
    and we will have to rely on the `TorchConnector` in order to use the QNN in the
    `forward` method. This `TorchConnector` is analogous to the `qml``.``qnn``.``KerasLayer`
    that we used in PennyLane — only that it’s for Qiskit and PyTorch! This is how
    we may then define our hybrid network and instantiate a model:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Notice how we’ve passed the optional argument `input_gradients` `=` `True` to
    the `TwoLayer` initializer; that is required for the PyTorch interface to work
    properly. Apart from that, the construction of the quantum neural network was
    fully analogous to what we did in *Chapter* [*10*](ch019.xhtml#x1-18100010), *Quantum
    Neural Networks*. A detail that perhaps deserves an explanation is the reason
    why we have included a final classical layer after the quantum one. This is because
    our QNN will return values between ![- 1](img/file312.png "- 1") and ![1](img/file13.png
    "1"), not between ![0](img/file12.png "0") and ![1](img/file13.png "1"); by including
    this final layer followed by the classical sigmoid activation function, we can
    ensure that the output of our network will be bounded between ![0](img/file12.png
    "0") and ![1](img/file13.png "1"), as we expect.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'Now all we have left to do before we can start the training is prepare the
    optimizer, and send the model parameters to it:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'And we can simply reuse the `run_epoch` function to complete the training,
    just as we did in the previous subsection:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'This is the output that the execution will yield:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'As before, we can get a plot of the loss evolution as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: This returns the plot shown in *Figure* [*11.4*](#Figure11.4). There does seem
    to be some overfitting, which could likely be fixed by giving more data to the
    classifier.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4: Evolution of the training and validation losses over the training
    of a hybrid binary classifier with PyTorch ](img/file1433.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
- en: '**Figure 11.4**: Evolution of the training and validation losses over the training
    of a hybrid binary classifier with PyTorch'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: 'In any case, let’s compute the training, validation, and test accuracies to
    get a better insight into the performance of the classifier. We may do that by
    executing the following instructions:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Upon running this, we get a training accuracy of ![92\%](img/file1432.png "92\%"),
    a validation accuracy of ![86\%](img/file1434.png "86\%"), and a test accuracy
    of ![74\%](img/file1435.png "74\%"). This confirms our suspicions regarding the
    existence of overfitting. As in other cases, should we want to fix this, we could
    try training the model with additional data, for instance.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Of course, all that we’ve learned about how to train hybrid QNNs with PyTorch
    and Qiskit also works for ordinary QNNs. If you want to train a simple Qiskit
    QNN using PyTorch, you’ve just learned how to do it; all it will take is defining
    a model with no classical layers.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our study of hybrid neural networks in Qiskit. But we still have
    one thing left before bringing this section to an end.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: One of the advantages of Qiskit is its tight integration with IBM’s quantum
    hardware. Nevertheless, as was the case in our study of quantum optimization,
    queueing times make the training of any QNN model on real hardware unfeasible
    through the usual interfaces to IBM’s hardware — that is, just using a real hardware
    backend, as we discussed in *Chapter* [*2*](ch009.xhtml#x1-400002), *The* *Tools
    of the Trade in Quantum Computing*. Thankfully, there’s a better way.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.3 Training Qiskit QNNs with Runtime
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using Qiskit’s Runtime service, as we did in *Chapters* [*5*](ch013.xhtml#x1-940005)
    and [*7*](ch015.xhtml#x1-1190007), we can effectively train any QNN model defined
    in PyTorch through a Qiskit Torch connector on any of the devices and simulators
    provided by IBM Quantum. All it takes is waiting on a single queue, and the whole
    training process is executed as a unit — with all the executions on quantum hardware
    included. The folks at IBM refer to this use case of Qiskit Runtime as ”Torch
    Runtime.”
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: 'That is very convenient. However, we must warn you that, at the time of writing,
    the queuing times to run these Torch Runtime programs can be somewhat long: around
    the order of a few hours. Also, you should keep in mind that — again, at the time
    of writing — this service enables you to train QNNs defined on PyTorch, but not
    hybrid QNNs! That is, your PyTorch model should not have any classical layers
    whatsoever.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: 'We will train a simple QNN model on a real device. As usual, we should firstly
    load our IBMQ account and pick a device. We will pick the least busy device among
    all the real devices with at least four qubits:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'We may define a simple QNN model with the PyTorch connector as follows:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Then, we may generate some data on which to train this model using the `make_classification`
    function:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Notice how we have adjusted some of the parameters of the `make_classification`
    function in order to comply with its requirements (check its documentation at
    [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)
    for more details).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 'Our model should return values between ![0](img/file12.png "0") and ![1](img/file13.png
    "1"), but the observable that we have chosen for our circuit — the default one,
    the parity observable (check *Chapter* [*10*](ch019.xhtml#x1-18100010), *Quantum
    Neural Networks*, for reference) — returns two possible values: ![1](img/file13.png
    "1") or ![- 1](img/file312.png "- 1"), not ![0](img/file12.png "0") and ![1](img/file13.png
    "1"). Thus we need to update the targets mapping ![\left. 0\mapsto - 1 \right.](img/file1436.png
    "\left. 0\mapsto - 1 \right.") and ![\left. 1\mapsto 1 \right.](img/file1437.png
    "\left. 1\mapsto 1 \right."). This can be done with the following instructions:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Let us now set up some data loaders for the training, validation, and test
    data:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'And the only ingredients that we have left to define are the optimizer and
    the loss function. We can still rely on Adam as an optimizer, but the binary cross
    entropy loss will no longer work since our labels are now ![- 1](img/file312.png
    "- 1") and ![1](img/file13.png "1") instead of ![0](img/file12.png "0") and ![1](img/file13.png
    "1"); thus, we will use the mean squared error loss instead:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'In order to be able to use our model with Torch Runtime, we will have to define
    a Torch Runtime Client, `client`, specifying a few self-explanatory parameters.
    This is done as follows:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We have set the number of epochs to ![5](img/file296.png "5") in order to get
    some quick results, but feel free to increase it.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: 'And now this is the instruction that we need to execute if we want to train
    our model:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: This will likely take a while because of the queue time required to run a Torch
    Runtime program. Sit back and relax. Eventually, your model will be trained. Once
    that happens, you can get information about the training from the `result` object,
    whose type is `TorchRuntimeResult`. In particular, the attributes `train_history`
    and `val_history` will show you the evolution of the training and validation losses
    throughout the training process.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’d like to get the model’s prediction on some data — for instance, the
    test dataset — all you have to do is send a data loader object with the data to
    the `predict` method. And this is how you can get your predictions:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Don’t expect to get great results! The model that we have defined is not very
    powerful and we only trained for a few epochs. As if that were not enough, when
    you run on real hardware, there’s always the issue of having to deal with noise.
    Of course, you could use error mitigation as we did back in *Chapter* [*7*](ch015.xhtml#x1-1190007),
    *VQE: Variational Quantum Eigensolver*, by setting `measurement_error_mitigation`
    `=` `True` in the `TorchRuntimeClient` instantiation.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.4 A glimpse into the future
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The way in which we have worked with Torch Runtime is supported by IBM at the
    time of writing, but change is the only constant in Qiskit land.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: In the future, Torch Runtime will no longer be supported and, instead, it will
    be necessary to use a different interface in order to train quantum neural networks
    with Qiskit Runtime. This interface — which, at the time of writing, is still
    in active development — will rely on the `Sampler` and `Estimator` objects that
    we mentioned in *Section* [*7.3.7*](ch015.xhtml#x1-1320007.3.7). In this subsection,
    we will present to you a simple example that will showcase how to work with this
    new interface.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: 'The following piece of code can be used to train a simple variational quantum
    classifier (a `VQC` object) using the ”new” Qiskit Runtime on the `ibmq_lima`
    device:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Please note that you need to install the `qiskit_ibm_runtime` package (refer
    to *Appendix* *[*D*](ch027.xhtml#x1-240000D), *Installing the Tools*, for instructions)
    and replace `"``TOKEN``"` with your actual IBM Quantum token.*
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '*As a matter of fact, when you send a program through this new Qiskit Runtime
    interface, you will likely see a fairly big collection of jobs on your IBM Quantum
    dashboard. Don’t worry, Runtime is working just fine. All those jobs correspond
    to different calls to the quantum computer, but they are all executed without
    the need to wait in the queue after each and every job execution.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: And that’s all we wanted to share with you about the Torch Runtime utility.
    Let’s wrap up this chapter.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This has been a long and intense chapter. We began by learning what hybrid
    neural networks actually are and in which use cases they can be useful. We then
    explored how to implement and train these hybrid networks in PennyLane and, along
    the way, we discussed a few good practices that apply to any machine learning
    project. In addition, we left our comfort zone and considered a new kind of QML
    problem: the training of multi-class classifiers.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Once we finished our study of PennyLane, we dived into Qiskit, and a big surprise
    was waiting for us there. Since Qiskit relied on an interface with the PyTorch
    ML package for the implementation of hybrid QNNs, we invested a good deal of effort
    in learning how to use PyTorch. In the process, we saw how PyTorch provided us
    with a level of flexibility that we simply couldn’t get using TensorFlow and Keras.
    At the point where we had a solid understanding of the PyTorch package, we got
    to work with Qiskit and its PyTorch connector and we trained a hybrid QNN with
    them.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we concluded the chapter by fulfilling a promise we made in *Chapter*
    [*10*](ch019.xhtml#x1-18100010), *Quantum Neural Networks*, and we discussed how
    to train quantum neural networks on IBM’s quantum hardware using Torch Runtime.***
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
