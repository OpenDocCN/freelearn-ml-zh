- en: Developing Segmentation Algorithms for Text Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we learned about a wide range of image processing
    techniques such as thresholding, contours descriptors, and mathematical morphology.
    In this chapter, we will discuss common problems that you may face while dealing
    with scanned documents, such as identifying where the text is or adjusting its
    rotation. We will also learn how to combine techniques presented in the previous
    chapters to solve those problems. By the end of this chapter, we will have segmented
    regions of text that can be sent to an **optical character recognition** (**OCR**)
    library.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you should be able to answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What kind of OCR applications exists?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the common problems while writing an OCR application?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I identify regions of documents?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I deal with problems like skewing and other elements in the middle of
    the text?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I use Tesseract OCR to identify my text?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires familiarity with the basic C++ programming language. All
    of the code that's used in this chapter can be downloaded from the following GitHub
    link:[https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_10](https://github.com/PacktPublishing/Learn-OpenCV-4-By-Building-Projects-Second-Edition/tree/master/Chapter_10).
    The code can be executed on any operating system, though it has only been tested
    on Ubuntu.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://bit.ly/2KIoJFX](http://bit.ly/2KIoJFX)'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing optical character recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Identifying text in an image is a very popular application for computer vision.
    This process is commonly called **optical character recognition**, and is divided
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Text preprocessing and segmentation**: During this step, the computer must
    deal with image noise, and rotation (skewing), and identify what areas are candidate
    text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text identification**: This is the process of identifying each letter in
    text. Although this is also a computer vision topic, we will not show how you
    to do this in this book purely using OpenCV. Instead, we will show you how to
    use the Tesseract library to do this step, since it was integrated in OpenCV 3.0\.
    If you are interested in learning how to do what Tesseract does by yourself, take
    a look at Packt''s *Mastering OpenCV* book, which presents a chapter on car plate
    recognition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The preprocessing and segmentation phase can vary greatly depending on the
    source of the text. Let''s take a look at common situations where preprocessing
    is done:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Production OCR applications with a scanner**: This is a very reliable source
    of text. In this scenario, the background of the image is usually white and the
    document is almost aligned with the scanner margins. The content that''s being
    scanned contains basically text, with almost no noise. This kind of application
    relies on simple preprocessing techniques that can adjust text quickly and maintain
    a fast scanning pace. When writing production OCR software, it is common to delegate
    the identification of important text regions to the user, and create a quality
    pipeline for text verification and indexing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scanning text in a casually taken picture or in a video**: This is a much
    more complex scenario, since there''s no indication of where the text can be.
    This scenario is called **scene text recognition**, and OpenCV 4.0 contains a
    contrib library to deal with it. We will cover this in [Chapter 11](e39c0201-3568-4793-911b-9af5d1883d66.xhtml),
    *Text Recognition with Tesseract*. Usually, the preprocessor will use texture
    analysis techniques to identify the text patterns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Creating a production quality OCR for historical texts**: Historical texts
    are also scanned, but they have several additional problems, such as noise that''s
    created by the old paper color and the use of ink. Other common problems are decorated
    letters and specific text fonts, and low contrast content that''s created by ink
    that is erased over time. It''s not uncommon to write specific OCR software for
    the documents at hand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scanning maps**, **diagrams**, **and charts**: Maps, diagrams, and charts
    pose an especially difficult scenario since the text is usually in any orientation
    and in the middle of image content. For example, city names are often clustered,
    and ocean names often follow country shore contour lines. Some charts are heavily
    colored, with text appearing in both clear and dark tones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OCR application strategies also vary according to the objective of the identification.
    Will it be used for a full text search? Or should the text be separated into logical
    fields to index a database with information for a structured search?
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will focus on preprocessing scanned text, or text that''s
    been photographed by a camera. We''ll consider that the text is the main purpose
    of the image, such as in a photographed piece of paper or card, for example, in
    this parking ticket:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/33c9ec1a-b339-43aa-ba68-b3a2425be2a6.png)'
  prefs: []
  type: TYPE_IMG
- en: We'll try to remove common noise, deal with text rotation (if any), and crop
    the possible text regions. While most OCR APIs already do these things automatically
    – and probably with state-of-the-art algorithms—it is still worth knowing how
    things happen under the hood. This will allow you to better understand most OCR
    APIs parameters and will give you better knowledge about the potential OCR problems
    you may face.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software that identifies letters does so by comparing text with previously recorded
    data. Classification results can be improved greatly if the input text is clear,
    if the letters are in a vertical position, and if there's no other elements, such
    as images sent to the classification software. In this section, we'll learn how
    to adjust text by using **preprocessing**.
  prefs: []
  type: TYPE_NORMAL
- en: Thresholding the image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We usually start preprocessing by thresholding the image. This eliminates all
    color information. Most OpenCV functions consider information to be written in
    white, and the background to be black. So, let''s start by creating a threshold
    function to match this criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `binarize` function applies a threshold, similar to what we did in [Chapter
    4](ceaab6b4-2f4a-45e4-9f5d-2544c75bd405.xhtml), *Delving into Histogram and Filters*.
    But here, we will use the Otsu method by passing `THRESH_OTSU` in the fourth parameter
    of the function. The Otsu method maximizes inter-class variance. Since a threshold
    creates only two classes (the black and white pixels), this is the same as minimizing
    the intraclass variance. This method works using the image histogram. Then, it
    iterates through all the possible threshold values and calculates the spread for
    the pixel values for each side of the threshold, that is, the pixels that are
    either in the background or in the foreground of the image. The purpose of this
    process is to find the threshold value where the sum of both spreads are at their
    minimum.
  prefs: []
  type: TYPE_NORMAL
- en: After the thresholding is done, the function counts how many white pixels are
    in the image. The black pixels are simply the total number of pixels in the image,
    given by the image area, minus the white pixel count. Since text is usually written
    over a plain background, we will verify whether there are more white pixels than
    there are black pixels. In this case, we are dealing with black text over a white
    background, so we will invert the image for further processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of the thresholding process with the parking ticket image is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/49e0e74e-2cf2-436f-9f97-bdfabcace97c.png)'
  prefs: []
  type: TYPE_IMG
- en: Text segmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next step is to find where the text is located and extract it. There are
    two common strategies for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using connected component analysis**: Searching groups of connected pixels
    in the image. This will be the technique that will be used in this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use classifiers to search for a previously trained letter texture pattern**:
    with texture features such as **Haralick **features, wavelet transforms are often
    used. Anther option is to identify **maximally stable extremal regions** (**MSER**s)
    in this task. This approach is more robust for text in a complex background and
    will be studied in [Chapter 11](e39c0201-3568-4793-911b-9af5d1883d66.xhtml), *Text
    Recognition with Tesseract*. You can read about Haralick features at his own website,
    which can be found at [http://haralick.org/journals/TexturalFeatures.pdf](http://haralick.org/journals/TexturalFeatures.pdf).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating connected areas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you take a closer look at the image, you'll notice that the letters are always
    together in blocks, formed by text paragraphs. That leaves us with the question,
    how do we detect and remove these blocks?
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to make these blocks even more evident. We can do this by
    using the dilation morphological operator. Recall from [Chapter 8](58a72603-be5a-465f-aa7b-fc8ab1aae596.xhtml),
    *Video Surveillance*, *Background Modeling*, *and Morphological Operations*, that
    dilation makes the image elements thicker. Let''s look at a small code snippet
    that does the trick:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we start by creating a 3 x 3 cross kernel that will be
    used in the morphological operation. Then, we apply dilation five times, centered
    on this kernel. The exact kernel size and number of times vary according to the
    situation. Just make sure that the values glue all of the letters in the same
    line together.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of this operation is presented in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3e7f8e70-3d29-4e4d-9a76-15df7d9db8e7.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice that we now have huge white blocks. They match exactly with each paragraph
    of text, and also match with other non-textual elements, like images or the border
    noise.
  prefs: []
  type: TYPE_NORMAL
- en: The ticket image that comes with the code is a low resolution image. OCR engines
    usually work with high resolution images (200 or 300 DPI), so it may be necessary
    to apply dilation more than five times.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying paragraph blocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next step is to perform connect component analysis to find blocks that
    correspond with paragraphs. OpenCV has a function for this, which we previously
    used in [Chapter 5](b788527c-5892-4547-8add-0864ccbd3f95.xhtml), *Automated Optical
    Inspection*, *Object Segmentation*, *and Detection*. This is the `findContours`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the first parameter, we pass our dilated image. The second parameter is
    the vector of detected contours. Then, we use the option to retrieve only external
    contours and to use simple approximation. The image contours are presented as
    follows. Each tone of gray represents a different contour:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/77e6041a-d703-4078-ab93-1e24f2a6c85e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The last step is to identify the minimum rotated bounding rectangle of each
    contour. OpenCV provides a handy function for this operation called `minAreaRect`.
    This function receives a vector of arbitrary points and returns a `RoundedRect`
    containing the bounding box. This is also a good opportunity to discard unwanted
    rectangles, that is, rectangles that are obviously not text. Since we are making
    software for OCR, we''ll assume that the text contains a group of letters. With
    this assumption, we''ll discard text in the following situations:'
  prefs: []
  type: TYPE_NORMAL
- en: The rectangle width or size is too small, that is, smaller than 20 pixels. This
    will help discard border noises and other small artifacts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rectangle of the image has a width/height proportion smaller than two. That
    is, rectangles that resemble a square, such as the image icons, or are much taller,
    will also be discarded.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's a little caveat in the second condition. Since we are dealing with rotated
    bounding boxes, we must test whether the bounding box angle is smaller than -45
    degrees. If it is, the text is vertically rotated, so the proportion that we must
    take into account is height/width.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check this out by looking at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see which boxes this algorithm selected:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/740e6bb3-bd1c-4304-b490-fb7e2711ce0e.png)'
  prefs: []
  type: TYPE_IMG
- en: That's certainly a good result!
  prefs: []
  type: TYPE_NORMAL
- en: We should notice that the algorithm described in step 2, in the preceding code,
    will also discard single letters. This is not a big issue since we are creating
    an OCR preprocessor, and single symbols are usually meaningless with context information;
    one example of such a case is the page numbers. The page numbers will be discarded
    with this process since they usually appear alone at the bottom of the page, and
    the size and proportion of the text will also be disturbed. But this will not
    be a problem, since after the text passes through the OCR, you will end up with
    a huge amount of text files with no page division at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll place all of this code in a function with the following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Text extraction and skewing adjustment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, all we must do is extract the text and adjust the text skew. This is done
    by the `deskewAndCrop` function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we start by reading the desired region angle and size. As we saw earlier,
    the angle may be less than -45 degrees. This means that the text is vertically
    aligned, so we must add 90 degrees to the rotation angle and switch the width
    and height properties. Next, we need to rotate the text. First, we start by creating
    a 2D affine transformation matrix that describes the rotation. We do so by using
    the `getRotationMatrix2D` OpenCV function. This function takes three parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CENTER**: The central position of the rotation. The rotation will pivot around
    this center. In our case, we use the box center.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ANGLE**: The rotation angle. If the angle is negative, the rotation will
    occur in a clockwise direction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SCALE**: The isotropic scale factor. We will use `1.0` since we want to keep
    the box''s original scale untouched.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The rotation itself is made by using the `warpAffine` function. This function
    takes four mandatory arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '**SRC**: The input `mat` array to be transformed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DST**: The destination `mat` array.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**M**: A transformation matrix. This matrix is a 2 x 3 affine transformation
    matrix. This may be a translation, scale, or rotation matrix. In our case, we
    will just use the matrix we recently created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SIZE**: The size of the output image. We will generate an image that''s the
    same size as our input image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are another three optional arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '**FLAGS**: These indicate how the image should be interpolated. We use `BICUBIC_INTERPOLATION`
    for better quality. The default is `LINEAR_INTERPOLATION`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BORDER**: Border mode. We use the default, `BORDER_CONSTANT`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BORDER VALUE**: The color of the border. We use the default, which is black.
    Then, we use the `getRectSubPix` function. After we rotate our image, we need
    to crop the rectangle area of our bounding box. This function takes four mandatory
    arguments and one optional argument, and returns the cropped image:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IMAGE**: The image to crop.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SIZE**: A `cv::Size` object describing the width and height of the box to
    be cropped.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CENTER**: The central pixel of the area to be cropped. Notice that since
    we rotated around the center, this point is conveniently the same.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PATCH**: The destination image.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PATCH_TYPE**: The depth of the destination image. We use the default value,
    representing the same depth of the source image.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The final step is done by the `copyMakeBorder` function. This function adds
    a border around the image. This is important, since the classification stage usually
    expects a margin around the text. The function parameters are very simple: the
    input and output images, the border thickness at the top, bottom, left, and right,
    the border type, and the color of the new border.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the card image, the following images will be generated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4fb5fee5-8e34-40b6-b20c-2544729a0efc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, it''s time to put every function together. Let''s present the main method
    that does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Loads the ticket image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calls our binarization function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Find all text regions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shows each region in a window
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will present the main method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: For the complete source code, take a look at the `segment.cpp` file that comes
    with this book.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Tesseract OCR on your operating system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Tesseract is an open source OCR engine that was originally developed by Hewlett-Packard
    Laboratories Bristol and Hewlett-Packard Co. All of its code is licensed under
    the Apache License and hosted on GitHub at [https://github.com/tesseract-ocr](https://github.com/tesseract-ocr).
    It is considered one of the most accurate OCR engines available: it can read a
    wide variety of image formats and can convert text written in more than 60 languages.
    In this session, we will teach you how to install Tesseract on Windows or Mac.
    Since there''s lots of Linux distributions, we will not teach you how to install
    it on this operating system. Normally, Tesseract offers installation packages
    in your package repository, so, before compiling Tesseract yourself, just search
    for it there.'
  prefs: []
  type: TYPE_NORMAL
- en: Installing Tesseract on Windows
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tesseract uses the **C++ Archive Network** (**CPPAN**) as its dependency manager.
    To install Tesseract, follow these steps.
  prefs: []
  type: TYPE_NORMAL
- en: Building the latest library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Download the latest CPPAN client from [https://cppan.org/client/](https://cppan.org/client/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the command line, run
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`cppan --build pvt.cppan.demo.google.tesseract.tesseract-master`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Setting up Tesseract in Visual Studio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Set up `vcpkg`,the Visual C++ Package Manager, at [https://github.com/Microsoft/vcpkg](https://github.com/Microsoft/vcpkg).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For a 64-bit compilation, use `vcpkg install tesseract:x64-windows`. You may
    also add `--head` for the master branch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Static linking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s also possible to static link ([https://github.com/tesseract-ocr/tesseract/wiki/Compiling#static-linking](https://github.com/tesseract-ocr/tesseract/wiki/Compiling#static-linking))
    Tesseract in your project. This will avoid `dlls` to be packaged with your executable
    files. To do this, use `vcpkg`, like we did previously, with the following command
    for a 32-bit installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can use the following command for a 64-bit installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Installing Tesseract on Mac
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The easiest way to install Tesseract OCR on Mac is using **Homebrew**. If you
    don't have Homebrew installed, just go to Homebrew's site ([http://brew.sh/](http://brew.sh/)),
    open your console, and run the **Ruby script** that is on the front page. You
    may be required to type in your administrator password.
  prefs: []
  type: TYPE_NORMAL
- en: 'After Homebrew is installed, just type in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The English language is already included in this installation. If you want
    to install other language packs, just run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This will install all of the language packs. Then, just go to the Tesseract
    installation directory and delete any unwanted languages. Homebrew usually installs
    stuff in the `/usr/local/` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Tesseract OCR library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While Tesseract OCR is already integrated with OpenCV 3.0, it's still worth
    studying its API since it allows for finer grained control over Tesseract parameters.
    This integration will be studied in [Chapter 11](e39c0201-3568-4793-911b-9af5d1883d66.xhtml),
    *Text Recognition with Tesseract*.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an OCR function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''ll change the previous example to work with Tesseract. Start by adding
    `tesseract/baseapi.h` and `fstream` to the `include` list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we''ll create a global `TessBaseAPI` object that represents our Tesseract
    OCR engine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `ocr` engine is completely self-contained. If you want to create a multi-threaded
    piece of OCR software, just add a different `TessBaseAPI` object in each thread,
    and the execution will be fairly thread-safe. You just need to guarantee that
    file writing is not done over the same file, otherwise you'll need to guarantee
    safety for this operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will create a function called **identify text **(`identifyText`) that
    will run the `ocr`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s explain this function line-by-line. In the first line, we start by initializing
    `tesseract`. This is done by calling the `Init` function. This function has the
    following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s explain each parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '`datapath`: This is the path to the root directory of `tessdata` files. The
    path must end with a backslash `/` character. The `tessdata` directory contains
    the language files that you installed. Passing `NULL` to this parameter will make
    `tesseract` search its installation directory, which is the location that this
    folder is normally present in. It''s common to change this value to `args[0]`
    when deploying an application, and include the `tessdata` folder in your application
    path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`language`: This is a three letter word for the language code (for example,
    eng for English, por for Portuguese, or hin for Hindi). Tesseract supports loading
    multiple language codes by using the `+` sign. Therefore, passing `eng+por` will
    load both the English and Portuguese languages. Of course, you can only use languages
    you have previously installed, otherwise the loading process will fail. A language
    config file may specify that two or more languages must be loaded together. To
    prevent that, you may use a tilde `~`. For example, you can use `hin+~eng` to
    guarantee that English is not loaded with Hindi, even if it is configured to do
    so.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OcrEngineMode`: These are the OCR algorithms that will be used. It can have
    one of the following values:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OEM_TESSERACT_ONLY`: Uses just `tesseract`. It''s the fastest method, but
    it also has less precision.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OEM_CUBE_ONLY`: Uses the Cube engine. It''s slower, but more precise. This
    will only work if your language was trained to support this engine mode. To check
    if that''s the case, look for `.cube` files for your language in the `tessdata`
    folder. The support for English language is guaranteed.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OEM_TESSERACT_CUBE_COMBINED`: This combines both Tesseract and Cube to achieve
    the best possible OCR classification. This engine has the best accuracy and the
    slowest execution time.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OEM_DEFAULT`: This infers the strategy based on the language config file,
    command-line config file or, in the absence of both, uses `OEM_TESSERACT_ONLY`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It's important to emphasize that the `Init` function can be executed many times.
    If a different language or engine mode is provided, Tesseract will clear the previous
    configuration and start again. If the same parameters are provided, Tesseract
    is smart enough to simply ignore the command. The `init` function returns `0`
    in case of success and `-1` in case of failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our program will then proceed by setting the page segmentation mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'There are several segmentation modes available:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PSM_OSD_ONLY`: Using this mode, Tesseract will just run its preprocessing
    algorithms to detect orientation and script detection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_AUTO_OSD`: This tells Tesseract to do automatic page segmentation with
    orientation and script detection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_AUTO_ONLY`: This does page segmentation, but avoids doing orientation,
    script detection, or OCR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_AUTO`: This does page segmentation and OCR, but avoids doing orientation
    or script detection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_SINGLE_COLUMN`: This assumes that the text of variable sizes is displayed
    in a single column.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_SINGLE_BLOCK_VERT_TEXT`: This treats the image as a single uniform block
    of vertically aligned text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_SINGLE_BLOCK`: This assumes a single block of text, and is the default
    configuration. We will use this flag since our preprocessing phase guarantees
    this condition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_SINGLE_LINE`: Indicates that the image contains only one line of text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_SINGLE_WORD`: Indicates that the image contains just one word.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_SINGLE_WORD_CIRCLE`: Informs us that the image is a just one word disposed
    in a circle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PSM_SINGLE_CHAR`: Indicates that the image contains a single character.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notice that Tesseract already has **deskewing** and text segmentation algorithms
    implemented, just like most OCR libraries do. But it's interesting to know of
    such algorithms since you may provide your own preprocessing phase for specific
    needs. This allows you to improve text detection in many cases. For example, if
    you are creating an OCR application for old documents, the default threshold used
    by Tesseract may create a dark background. Tesseract may also be confused by borders
    or severe text skewing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we call the `SetImage` method with the following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The parameters are almost self-explanatory, and most of them can be read directly
    from our `Mat` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '`data`: A raw byte array containing image data. OpenCV contains a function
    called `data()` in the `Mat` class that provides a direct pointer to the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width`: Image width.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`height`: Image height.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bytes_per_pixel`: Number of bytes per pixel. We are using `1`, since we are
    dealing with a binary image. If you want the code to be more generic, you could
    also use the `Mat::elemSize()` function, which provides the same information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bytes_per_line`: Number of bytes in a single line. We are using the `Mat::step`
    property since some images add trailing bytes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we call `GetUTF8Text` to run the recognition itself. The recognized text
    is returned, encoded with UTF8 and without BOM. Before returning it, we also print
    some debug information.
  prefs: []
  type: TYPE_NORMAL
- en: '`MeanTextConf` returns a confidence index, which may by a number from `0` to
    `100`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Sending the output to a file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s change our main method to send the recognized output to a file. We do
    this by using a standard `ofstream`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The following line opens the file in binary mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This is important since Tesseract returns text encoded in UTF-8, taking into
    account special characters that are available in Unicode. We also write the output
    directly using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In this sample, we called the `identify` function using Portuguese as an input
    language (this is the language the ticket was written in). You may use another
    photo, if you like.
  prefs: []
  type: TYPE_NORMAL
- en: The complete source file is provided in the `segmentOcr.cpp` file, which comes
    with this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`ticket.png` is a low resolution image, since we imagined you would want to
    display a window with the image while studying this code. For this image, the
    Tesseract results are rather poor. If you want to test with a higher resolution
    image, the code for this book provides you with a `ticketHigh.png` image. To test
    with this image, change the dilation repetitions to `12` and the minimum box size
    from `20` to `60`. You''ll get a much higher confidence rate (about 87%), and
    the resulting text will be almost fully readable. The `segmentOcrHigh.cpp` file
    contains these modifications.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we presented a brief introduction to OCR applications. We saw
    that the preprocessing phase of such systems must be adjusted according to the
    type of document we are planning to identify. We have learned about common operations
    while preprocessing text files, such as thresholding, cropping, skewing, and text
    region segmentation. Finally, we learned how to install and use Tesseract OCR
    to convert our image into text.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll use a more sophisticated OCR technique to identify
    text in a casually taken picture or video –a situation known as scene text recognition.
    This is a much more complex scenario, since the text can be anywhere, in any font,
    and with different illuminations and orientations. There can even be no text at
    all! We'll also learn how to use the OpenCV 3.0 text contribution module, which
    is fully integrated with Tesseract.
  prefs: []
  type: TYPE_NORMAL
