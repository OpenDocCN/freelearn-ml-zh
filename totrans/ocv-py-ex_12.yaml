- en: Chapter 12. Augmented Reality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you are going to learn about augmented reality and how you
    can use it to build cool applications. We will discuss pose estimation and plane
    tracking. You will learn how to map the coordinates from 2D to 3D, and how we
    can overlay graphics on top of a live video.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will know:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the premise of augmented reality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is pose estimation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to track a planar object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to map coordinates from 3D to 2D
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to overlay graphics on top of a video in real time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the premise of augmented reality?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we jump into all the fun stuff, let's understand what augmented reality
    means. You would have probably seen the term "augmented reality" being used in
    a variety of contexts. So, we should understand the premise of augmented reality
    before we start discussing the implementation details. Augmented Reality refers
    to the superposition of computer-generated input such as imagery, sounds, graphics,
    and text on top of the real world.
  prefs: []
  type: TYPE_NORMAL
- en: Augmented reality tries to blur the line between what's real and what's computer-generated
    by seamlessly merging the information and enhancing what we see and feel. It is
    actually closely related to a concept called mediated reality where a computer
    modifies our view of the reality. As a result of this, the technology works by
    enhancing our current perception of reality. Now the challenge here is to make
    it look seamless to the user. It's easy to just overlay something on top of the
    input video, but we need to make it look like it is part of the video. The user
    should feel that the computer-generated input is closely following the real world.
    This is what we want to achieve when we build an augmented reality system.
  prefs: []
  type: TYPE_NORMAL
- en: Computer vision research in this context explores how we can apply computer-generated
    imagery to live video streams so that we can enhance the perception of the real
    world. Augmented reality technology has a wide variety of applications including,
    but not limited to, head-mounted displays, automobiles, data visualization, gaming,
    construction, and so on. Now that we have powerful smartphones and smarter machines,
    we can build high-end augmented reality applications with ease.
  prefs: []
  type: TYPE_NORMAL
- en: What does an augmented reality system look like?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s consider the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What does an augmented reality system look like?](img/B04554_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As we can see here, the camera captures the real world video to get the reference
    point. The graphics system generates the virtual objects that need to be overlaid
    on top of the video. Now the video-merging block is where all the magic happens.
    This block should be smart enough to understand how to overlay the virtual objects
    on top of the real world in the best way possible.
  prefs: []
  type: TYPE_NORMAL
- en: Geometric transformations for augmented reality
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The outcome of augmented reality is amazing, but there are a lot of mathematical
    things going on underneath. Augmented reality utilizes a lot of geometric transformations
    and the associated mathematical functions to make sure everything looks seamless.
    When talking about a live video for augmented reality, we need to precisely register
    the virtual objects on top of the real world. To understand it better, let's think
    of it as an alignment of two cameras—the real one through which we see the world,
    and the virtual one that projects the computer generated graphical objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to build an augmented reality system, the following geometric transformations
    need to be established:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Object-to-scene**: This transformation refers to transforming the 3D coordinates
    of a virtual object and expressing them in the coordinate frame of our real-world
    scene. This ensures that we are positioning the virtual object in the right location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scene-to-camera**: This transformation refers to the pose of the camera in
    the real world. By "pose", we mean the orientation and location of the camera.
    We need to estimate the point of view of the camera so that we know how to overlay
    the virtual object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Camera-to-image**: This refers to the calibration parameters of the camera.
    This defines how we can project a 3D object onto a 2D image plane. This is the
    image that we will actually see in the end.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Geometric transformations for augmented reality](img/B04554_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As we can see here, the car is trying to fit into the scene but it looks very
    artificial. If we don''t convert the coordinates in the right way, it looks unnatural.
    This is what we were talking about in the object-to-scene transformation! Once
    we transform the 3D coordinates of the virtual object into the coordinate frame
    of the real world, we need to estimate the pose of the camera:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Geometric transformations for augmented reality](img/B04554_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We need to understand the position and rotation of the camera because that's
    what the user will see. Once we estimate the camera pose, we are ready to put
    this 3D scene on a 2D image.
  prefs: []
  type: TYPE_NORMAL
- en: '![Geometric transformations for augmented reality](img/B04554_12_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Once we have these transformations, we can build the complete system.
  prefs: []
  type: TYPE_NORMAL
- en: What is pose estimation?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we proceed, we need to understand how to estimate the camera pose. This
    is a very critical step in an augmented reality system and we need to get it right
    if we want our experience to be seamless. In the world of augmented reality, we
    overlay graphics on top of an object in real time. In order to do that, we need
    to know the location and orientation of the camera, and we need to do it quickly.
    This is where pose estimation becomes very important. If you don't track the pose
    correctly, the overlaid graphics will not look natural.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What is pose estimation?](img/B04554_12_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The arrow line represents that the surface is normal. Let''s say the object
    changes its orientation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![What is pose estimation?](img/B04554_12_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now even though the location is the same, the orientation has changed. We need
    to have this information so that the overlaid graphics looks natural. We need
    to make sure that it's aligned to this orientation as well as position.
  prefs: []
  type: TYPE_NORMAL
- en: How to track planar objects?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you understand what pose estimation is, let''s see how you can use
    it to track planar objects. Let''s consider the following planar object:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to track planar objects?](img/B04554_12_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now if we extract feature points from this image, we will see something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to track planar objects?](img/B04554_12_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s tilt the cardboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to track planar objects?](img/B04554_12_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As we can see, the cardboard is tilted in this image. Now if we want to make
    sure our virtual object is overlaid on top of this surface, we need to gather
    this planar tilt information. One way to do this is by using the relative positions
    of those feature points. If we extract the feature points from the preceding image,
    it will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to track planar objects?](img/B04554_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the feature points got closer horizontally on the far end of
    the plane as compared to the ones on the near end.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to track planar objects?](img/B04554_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So we can utilize this information to extract the orientation information from
    the image. If you remember, we discussed perspective transformation in detail
    when we were discussing geometric transformations as well as panoramic imaging.
    All we need to do is use those two sets of points and extract the homography matrix.
    This homography matrix will tell us how the cardboard turned.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to track planar objects?](img/B04554_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We start by selecting the region of interest.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to track planar objects?](img/B04554_12_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We then extract feature points from this region of interest. Since we are tracking
    planar objects, the algorithm assumes that this region of interest is a plane.
    That was obvious, but it's better to state it explicitly! So make sure you have
    a cardboard in your hand when you select this region of interest. Also, it'll
    be better if the cardboard has a bunch of patterns and distinctive points so that
    it's easy to detect and track the feature points on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let the tracking begin! We''ll move the cardboard around to see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to track planar objects?](img/B04554_12_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, the feature points are being tracked inside the region of interest.
    Let''s tilt it and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to track planar objects?](img/B04554_12_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Looks like the feature points are being tracked properly. As we can see, the
    overlaid rectangle is changing its orientation according to the surface of the
    cardboard.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code to do it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: What happened inside the code?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To start with, we have a `PoseEstimator` class that does all the heavy lifting
    here. We need something to detect the features in the image and something to match
    the features between successive images. So we use the ORB feature detector and
    the Flann feature matcher. As we can see, we initialize the class with these parameters
    in the constructor.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we select a region of interest, we call the `add_target` method to
    add that to our list of tracking targets. This method just extracts the features
    from that region of interest and stores in one of the class variables. Now that
    we have a target, we are ready to track it!
  prefs: []
  type: TYPE_NORMAL
- en: The `track_target` method handles all the tracking. We take the current frame
    and extract all the keypoints. However, we are not really interested in all the
    keypoints in the current frame of the video. We just want the keypoints that belong
    to our target object. So now, our job is to find the closest keypoints in the
    current frame.
  prefs: []
  type: TYPE_NORMAL
- en: We now have a set of keypoints in the current frame and we have another set
    of keypoints from our target object in the previous frame. The next step is to
    extract the homography matrix from these matching points. This homography matrix
    tells us how to transform the overlaid rectangle so that it's aligned with the
    cardboard surface. We just need to take this homography matrix and apply it to
    the overlaid rectangle to obtain the new positions of all its points.
  prefs: []
  type: TYPE_NORMAL
- en: How to augment our reality?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we know how to track planar objects, let's see how to overlay 3D objects
    on top of the real world. The objects are 3D but the video on our screen is 2D.
    So the first step here is to understand how to map those 3D objects to 2D surfaces
    so that it looks realistic. We just need to project those 3D points onto planar
    surfaces.
  prefs: []
  type: TYPE_NORMAL
- en: Mapping coordinates from 3D to 2D
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once we estimate the pose, we project the points from the 3D to the 2D. Consider
    the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Mapping coordinates from 3D to 2D](img/B04554_12_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As we can see here, the TV remote control is a 3D object but we are seeing
    it on a 2D plane. Now if we move it around, it will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Mapping coordinates from 3D to 2D](img/B04554_12_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This 3D object is still on a 2D plane. The object has moved to a different location
    and the distance from the camera has changed as well. How do we compute these
    coordinates? We need a mechanism to map this 3D object onto the 2D surface. This
    is where the 3D to 2D projection becomes really important.
  prefs: []
  type: TYPE_NORMAL
- en: We just need to estimate the initial camera pose to start with. Now, let's assume
    that the intrinsic parameters of the camera are already known. So we can just
    use the `solvePnP` function in OpenCV to estimate the camera's pose. This function
    is used to estimate the object's pose using a set of points. You can read more
    about it at [http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#bool
    solvePnP(InputArray objectPoints, InputArray imagePoints, InputArray cameraMatrix,
    InputArray distCoeffs, OutputArray rvec, OutputArray tvec, bool useExtrinsicGuess,
    int flags)](http://docs.opencv.org/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#bool%20solvePnP(InputArray%20objectPoints,%20InputArray%20imagePoints,%20InputArray%20cameraMatrix,%20InputArray%20distCoeffs,%20OutputArray%20rvec,%20OutputArray%20tvec,%20bool%20useExtrinsicGuess,%20int%20flags)).
    Once we do this, we need to project these points onto 2D. We use the OpenCV function
    `projectPoints` to do this. This function calculates the projections of those
    3D points onto the 2D plane.
  prefs: []
  type: TYPE_NORMAL
- en: How to overlay 3D objects on a video?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have all the different blocks, we are ready to build the final
    system. Let''s say we want to overlay a pyramid on top of our cardboard as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to overlay 3D objects on a video?](img/B04554_12_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s tilt the cardboard to see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to overlay 3D objects on a video?](img/B04554_12_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Looks like the pyramid is following the surface. Let''s add a second target:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to overlay 3D objects on a video?](img/B04554_12_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can keep adding more targets and all those pyramids will be tracked nicely.
    Let''s see how to do this using OpenCV Python. Make sure to save the previous
    file as `pose_estimation.py` because we will be importing a couple of classes
    from there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Let's look at the code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The class `Tracker` is used to perform all the computations here. We initialize
    the class with the pyramid structure that is defined using edges and vertices.
    The logic that we use to track the surface is the same as we discussed earlier
    because we are using the same class. We just need to use `solvePnP` and `projectPoints`
    to map the 3D pyramid to the 2D surface.
  prefs: []
  type: TYPE_NORMAL
- en: Let's add some movements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we know how to add a virtual pyramid, let''s see if we can add some
    movements. Let''s see how we can dynamically change the height of the pyramid.
    When you start, the pyramid will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Let''s add some movements](img/B04554_12_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you wait for some time, the pyramid gets taller and it will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Let''s add some movements](img/B04554_12_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see how to do it in OpenCV Python. Inside the augmented reality code
    that we just discussed, add the following snippet at the end of the `__init__`
    method in the `Tracker` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the structure, we need to add the code to dynamically change
    the height. Replace the `overlay_graphics()` method with the following method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we know how to change the height, let''s go ahead and make the pyramid
    dance for us. We can make the tip of the pyramid oscillate in a nice periodic
    fashion. So when you start, it will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Let''s add some movements](img/B04554_12_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you wait for some time, it will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Let''s add some movements](img/B04554_12_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You can look at `augmented_reality_motion.py` for the implementation details.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our next experiment, we will make the whole pyramid move around the region
    of interest. We can make it move in any way we want. Let''s start by adding linear
    diagonal movement around our selected region of interest. When you start, it will
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Let''s add some movements](img/B04554_12_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After some time, it will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Let''s add some movements](img/B04554_12_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Refer to `augmented_reality_dancing.py` to see how to change the `overlay_graphics()`
    method to make it dance. Let''s see if we can make the pyramid go around in circles
    around our region of interest. When you start, it will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Let''s add some movements](img/B04554_12_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After some time, it will move to a new position:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Let''s add some movements](img/B04554_12_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You can refer to `augmented_reality_circular_motion.py` to see how to make this
    happen. You can make it do anything you want. You just need to come up with the
    right mathematical formula and the pyramid will literally dance to your tune!
    You can also try out other virtual objects to see what you can with it. There
    are a lot of things you can do with a lot of different objects. These examples
    provide a good reference point, on top of which you can build many interesting
    augmented reality applications.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the premise of augmented reality and understood
    what an augmented reality system looks like. We discussed the geometric transformations
    required for augmented reality. You learned how to use those transformations to
    estimate the camera pose. You learned how to track planar objects. We discussed
    how we can add virtual objects on top of the real world. You learned how to modify
    the virtual objects in different ways to add cool effects. Remember that the world
    of computer vision is filled with endless possibilities! This book is designed
    to teach you the necessary skills to get started on a wide variety of projects.
    Now it's up to you and your imagination to use the skills you have acquired here
    to build something unique and interesting.
  prefs: []
  type: TYPE_NORMAL
