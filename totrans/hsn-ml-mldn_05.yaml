- en: Regression Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With our development environment configured and our first ML.NET application
    completed, it is now time to dive into regression models. In this chapter, we
    will dive into the math behind regression models, as well as the various applications
    of regression models. We will also build two additional ML.NET applications, one
    utilizing a linear regression model and the other a logistic regression model.
    The linear regression application will predict employee attrition based on various
    employee attributes. The logistic regression application will perform basic static
    file analysis on a file to determine whether it is malicious or benign. Finally,
    we will explore how to evaluate a regression model with the properties ML.NET
    exposes in regression models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down various regression models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the linear regression application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the logistic regression application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating a regression model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breaking down regression models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While there are several regression model types available in the machine learning
    eco-system, there are two primary regression models groups: linear and logistic,
    both of which have rich implementations in ML.NET.'
  prefs: []
  type: TYPE_NORMAL
- en: 'ML.NET provides the following linear regression trainers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`FastTreeRegressionTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FastTreeTweedieTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FastForestRegressionTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GamRegressionTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LbfgsPoissonRegressionTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LightGbmRegressionTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OlsTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OnlineGradientDescentTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SdcaRegressionTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The employee attrition application we will be creating later in this chapter
    utilizes the linear regression SDCA trainer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, ML.NET provides the following binary logistic regression trainers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`LbfgsLogisticRegressionBinaryTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SdcaLogisticRegressionBinaryTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SdcaNonCalibratedBinaryTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SymbolicSgdLogisticRegressionBinaryTrainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the file classification application, we will be utilizing the `SDCALogisticRegressionBinaryTrainer`
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the type of regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With all of these options, how do you choose the right type of regression model?
  prefs: []
  type: TYPE_NORMAL
- en: The type of regression model you choose depends on what your expected output
    is. If you are looking for just a Boolean (that is, 0 or 1) value, logistic regression
    models should be used like in the file classification application we will be writing
    later in this chapter. In addition, if you are looking to return a specific pre-defined
    range of values, perhaps a car type such as coupe, convertible, or hatchback,
    a logistic regression model is the correct model to choose from.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, linear regression models return a numeric value, such as the employment
    duration example we will explore later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, to summarize, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: If your output is a Boolean value, use a logistic regression model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your output is comprised of a preset range type of values (akin to an enumeration),
    use a logistic regression model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your output is a numeric unknown value, use a linear regression model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a linear regression trainer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When looking at the list of nine linear regression trainers ML.NET, it can be
    a bit daunting to ask which is the best.
  prefs: []
  type: TYPE_NORMAL
- en: For ML.NET linear regression trainers, by and large, the most popular are FastTree
    and LightGBM. The three FastTree algorithms utilize neighbor-joining and use heuristics
    to quickly identify candidate joins to build out a decision tree. LightGBM is
    a very popular linear regression algorithm that utilizes a **Gradient-based One
    Side Sampling** (**GOSS**) to filter out the data instances for finding a split
    value. Both trainers provide both quick training and predict times while also
    providing very accurate model performance. Also, more documentation, papers, and
    research are available with both of these algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The remaining five trainers are useful and worth a deep dive for experimentation,
    but overall you will likely find equal or greater success with LightGBM and FastTree.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a logistic regression trainer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given the four logistic regression trainers available in ML.NET, which is the
    best for your problem? Whilst all four regression trainers return a binary classification,
    they are optimized for different datasets and workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Are you looking to train and predict in a low memory environment? If so, the
    L-BFGS logistic regression trainer (`LbfgsLogisticRegressionBinaryTrainer`) is
    a logical choice given that it was created to handle memory-restricted environments.
  prefs: []
  type: TYPE_NORMAL
- en: Both of the SDCA-based trainers—`SdcaLogisticRegressionBinaryTrainer` and `SdcaNonCalibratedBinaryTrainer`—have
    been optimized for scalability in training. If your training set is large and
    you are looking for binary classification, either of the SDCA trainers would be
    a good choice.
  prefs: []
  type: TYPE_NORMAL
- en: The `SymbolicSgdLogisticRegressionBinaryTrainer` model is different from the
    other three in that it is based on a stochastic gradient descent algorithm. This
    means rather than looking to maximize the error function, the algorithm looks
    to minimize the error function.
  prefs: []
  type: TYPE_NORMAL
- en: If you are curious to expand your knowledge of SCDAs and in particular how Microsoft
    Research experimented with scaling SCDAs, give this white paper a read: [https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/main-3.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/main-3.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Creating the linear regression application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, the application we will be creating is an employee attrition
    predictor. Given a set of attributes tied to an employee, we can predict how long
    they will remain at their current job. The attributes included in this example
    aren't a definitive list of attributes, nor should be used as-is in a production
    environment; however, we can use this as a starting point for predicting a singular
    numeric output based on several attributes.
  prefs: []
  type: TYPE_NORMAL
- en: As with [Chapter 1](b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml), *Getting Started
    with Machine Learning and ML.NET*, the completed project code, sample dataset,
    and project files can be downloaded here: [https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_linear_regression](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_linear_regression).
  prefs: []
  type: TYPE_NORMAL
- en: Diving into the trainer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As previously mentioned, for this linear regression application, we will be
    using the SDCA trainer. **SDCA** stands for **Stochastic Dual Coordinate Ascent**
    and if you may recall, we used the logistic regression version of this trainer
    in the example in [Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml), *Setting
    Up the ML.NET Environment*.
  prefs: []
  type: TYPE_NORMAL
- en: To the average reader, all four words that comprise SDCA might be unknown, so
    let's break down what each means to give better clarity to what happens when you
    utilize an SDCA trainer. Starting with *Stochastic*, which, in other words, means
    unpredictability. And in the case of machine learning, it means attempting to
    probabilistically predict the error function and feed random samples from your
    training set into the optimizer. The use of *Dual Coordinate* means two variables
    are coupled when training the model. As you have probably guessed, this makes
    the model much more complex but doesn't require any extra work to be utilized.
    Lastly, *Ascent* refers to maximizing the value of the error function.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the project architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building on the project architecture and code we created in [Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml),
    *Setting Up the ML.NET Environment*, the major change architecturally in this
    example is the mechanism for input. [Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml), *Setting
    Up the ML.NET Environment*,used a simple string to provide sentiment analysis
    via a command-line argument. In this application, there are several properties
    to pass into the model; therefore, for this application, we are now using a JSON
    file to contain our input data. With this addition, we are now including the popular
    `Newtonsoft.Json` NuGet package (version 12.0.2 is the latest at the time of this
    writing and what is used in the included sample). If you are building this project
    from scratch and do not remember how to add a NuGet reference, please refer back
    to [Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml), *Setting Up the ML.NET
    Environment*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the Visual Studio Solution Explorer view of
    the project. The new addition to the solution is the `ExtensionMethods` class
    file, which we will review in the next section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9759fb4f-f8f5-4bb0-93db-cd76f0ff7971.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `sampledata.csv` file contains 40 rows of random data; feel free to adjust
    the data to fit your own observations or to adjust the trained model. Here is
    a snippet of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Each of these rows contains the value for the properties in the newly created
    `EmploymentHistory` class that we will review later on in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to use a larger dataset to train and expand this example, the website
    Kaggle offers a dataset created by IBM data scientists. This dataset is available
    here: [https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset).
  prefs: []
  type: TYPE_NORMAL
- en: Diving into the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this application as noted, we are building on top of the work completed
    in [Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml), *Setting Up the ML.NET
    Environment*. For this deep dive, we are going to focus solely on the code that
    was changed for this application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The classes that were changed or added are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ExtensionMethods`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EmploymentHistory`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EmploymentHistoryPrediction`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Predictor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Trainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Program`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ExtensionMethods class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This newly added class provides an easy to use an extension method to return
    all of the properties in a class except the label.If you are unfamiliar with extension
    methods, these methods provide a very simple syntax to potentially provide complex
    actions on a single object, like in this case, where we take an arbitrary type
    and return all of the properties it contains (except for `labelName`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The EmploymentHistory class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `EmploymentHistory` class is the container class that contains the data
    to both predict and train our model. These columns map in order for the sample
    data reviewed previously. If you begin experimenting with new features and add
    to this list, ensure you increment the array index appropriately:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The EmploymentHistoryPrediction class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `EmploymentHistoryPrediction` class contains only the prediction value
    of how many months the employee is projected to be at his or her job in the `DurationInMonths`
    property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The Predictor class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a couple of changes in this class to handle the employment prediction
    scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, validate that the input file exists before making a prediction on it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The other change is in the prediction call itself. As you probably guessed,
    the TSrc and TDst arguments need to be adjusted to utilize both of the new classes
    we created, `EmploymentHistory` and `EmploymentHistoryPrediction`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Given that we are no longer simply passing in the string and building an object
    on the fly, we need to first read in the file as text. We then deserialize the
    JSON into our `EmploymentHistory` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we need to adjust the output of our prediction to match our new `EmploymentHistoryPrediction`
    properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The Trainer class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inside the `Trainer` class, a large portion was rewritten to handle the expanded
    features used and to provide regression algorithm evaluation as opposed to the
    binary classification we looked at in [Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml), *Setting
    Up the ML.NET Environment*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first change is the use of a comma to separate the data as opposed to the
    default tab like we used in [Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml), *Setting
    Up the ML.NET Environment*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The next change is in the pipeline creation itself. In our first application,
    we had a label and fed that straight into the pipeline. With this application,
    we have nine features to predict the duration of a person's employment in the
    `DurationInMonths` property and append each one of them to the pipeline using
    the C# 6.0 feature, `nameof`. You might have noticed the use of magic strings
    to map class properties to features in various code samples on GitHub and MSDN;
    personally, I find this error-prone compared to the strongly typed approach.
  prefs: []
  type: TYPE_NORMAL
- en: For every property, we call the `NormalizeMeanVariance` transform method, which
    as the name implies normalizes the input data both on the mean and the variance.
    ML.NET computes this by subtracting the mean of the input data and dividing that
    value by the variance of the inputted data. The purpose behind this is to nullify
    outliers in the input data so the model isn't skewed to handle an edge case compared
    to the normal range. For example, suppose the sample dataset of employment history
    had 20 rows and all but one of those rows had a person with 50 years experience.
    The one row that didn't fit would be normalized to better fit within the ranges
    of values entered into the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, note the use of the extension method referred to earlier to help
    to simplify the following code, when we concatenate all of the feature columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then create the `Sdca` trainer using the default parameters (`"Label"`
    and `"Features"`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we call the `Regression.Evaluate` method to provide regression specific
    metrics, followed by a `Console.WriteLine` call to provide these metrics to your
    console output. We will go into detail about what each of these means in the last
    section of this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The Program class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The only change in the `Program` class was the help text to indicate usage
    for predict requires a filename, not a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Running the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run the application the process is nearly identical to Chapter 2''s sample
    application. To iterate more quickly, the debug configuration automatically passes
    in the included `sampledata.csv` file as a command-line parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f4d37e52-1dcc-4cca-8fd1-b899579f0d6a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Going forward, due to the increasing complexity of the applications, all sample
    applications will have this preset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the training on the command line as we did in [Chapter 1](b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml),
    *Getting Started with Machine Learning and ML.NET,* simply pass in the following
    command (assuming you are using the included sample dataset):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note the expanded output to include several metric data points—we will go through
    what each one of these means at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'After training the model, build a sample JSON file and save it as `input.json`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the model with this file, simply pass in the filename to the built application
    and the predicted output will show:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Feel free to modify the values and see how the prediction changes based on
    the dataset that the model was trained on.  A few areas of experimentation from
    this point might be to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Add some additional features based on your own experience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modify `sampledata.csv` to include your team's experience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modify the sample application to have a GUI to make running predicts easier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the logistic regression application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, the application we will be creating to demonstrate logistic
    regressions is a file classifier. Given a file (of any type), we extract the strings
    from the file. This is a very common approach to performing file classification
    although, like the previous example, this is often just an element of file classification,
    not the only component. Therefore, don't expect this to find the next zero-day
    piece of malware!
  prefs: []
  type: TYPE_NORMAL
- en: The completed project code, sample dataset, and project files can be downloaded
    here:[ ](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_logistic_regression)[https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_logistic_regression](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_logistic_regression)[.](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_logistic_regression)
  prefs: []
  type: TYPE_NORMAL
- en: The trainer used in this application also uses SDCA but using the logistic regression
    variation that was discussed earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: As in the previous example, we will begin by exploring the project architecture,
    diving into the code, and then show how you can run the example to both train
    and predict.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the project architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building on the project architecture and code we created in the previous example,
    the major change architecturally in this example is feature extraction. With this
    example, we will add in the `FeatureExtractor` class in addition to creating new
    input and prediction classes. The reason for this is going back to the idea of
    keeping things separate and well defined as discussed in [Chapter 2](b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml), *Setting
    Up the ML.NET Environment*. For this example application and future applications
    you may write, they, more than likely, will have input files to convert into rows
    of data. By having a separate class handle this part of the pipeline, you can
    encapsulate this functionality cleanly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the Visual Studio Solution Explorer view of
    the project. The new addition to the solution is the `FeatureExtractor` class
    file that we will review in the next section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c49ce931-dac3-4c89-a977-ada86e7ab1a7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `sampledata.csv` file contains eight rows of random data. Feel free to
    adjust the data to fit your own observations or adjust the trained model. Here
    is the included sample data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Each of these rows contains two columns worth of data. The first is the classification,
    with true being malicious and false being benign. These properties are mapped
    in the newly created `FileInput` class that we will review later on in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Diving into the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this application as noted, we are building on top of the work completed
    earlier within this chapter. Again, for this deep dive, we are going to focus
    solely on the code that was changed for this application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Classes that were changed or added are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`FeatureExtractor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FileInput`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`FilePrediction`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BaseML`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Predictor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Trainer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Program`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The FeatureExtractor class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This newly added class provides our feature extraction for the given folder
    of files**. **Once extraction is complete, the classification and strings data
    is written out to the `sampledata` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The FileInput class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `FileInput` class provides the container for the trained classification
    and the strings data we extract:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The FilePrediction class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `FilePrediction` class provides the container for the classification, probability,
    and score:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The BaseML class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the `BaseML` class, we have made several enhancements, starting with the
    constructor. In the constructor, we initialize the `stringRex` variable to the
    regular expression we will use to extract strings. `Encoding.RegisterProvider`
    is critical to utilize the Windows-1252 encoding. This encoding is the encoding
    Windows Executables utilize:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The next major addition is the `GetStrings` method. This method takes the bytes,
    runs the previously created compiled regular expression, and extracts the string
    matches:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, we define the method definition and initialize the `stringLines`
    variable to hold the strings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will sanity check the input data is not null or empty:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The next block of code we open a `MemoryStream` object and then a `StreamReader`
    object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'We will then loop through the `streamReader` object until an `EndOfStream`
    condition is reached, reading line by line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We then will apply some string clean up of the data and handle whether the
    line is empty or not gracefully:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will append the regular expression matches and append those matches
    to the previously defined `stringLines` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we will return the `stringLines` variable converted into a single string
    using the `string.Join` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The Predictor class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Predictor` class, much like what was changed in the linear regression
    example, is simply modified to support the new model and return the classification:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by passing in the two new classes, `FileInput` and `FilePrediction`,to
    the `CreatePredictionEngine` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create the `FileInput` object, setting the `Strings` property with
    the return value of the `GetStrings` method we wrote earlier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we update the output call to the `Console` object with our file classification
    and probability:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The Trainer class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the `Trainer` class, we will build a new pipeline to train our model. The
    `FeaturizeText` transform builds NGrams from the strings data we previously extracted
    from the files. **NGrams** are a popular method to create vectors from a string
    to, in turn, feed the model. You can think of NGrams as breaking a longer string
    into ranges of characters based on the value of the NGram parameter. A bi-gram,
    for instance, would take the following sentence, *ML.NET is great* and convert
    it into *ML-.N-ET-is-gr-ea-t*. Lastly, we build the `SdcaLogisticRegression` trainer
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'For those looking to deep dive further into the `Transforms` Catalog API, check
    out the documentation from Microsoft here: [https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transformscatalog?view=ml-dotnet](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transformscatalog?view=ml-dotnet).'
  prefs: []
  type: TYPE_NORMAL
- en: The Program class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the `Program` class, we added a third option to extract features and create
    the sample data `.tsv` file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, we modify the help text to indicate the new extract option that takes
    a path to the training folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, we also need to modify the main switch/case to support the `extract`
    argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Running the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the addition of feature extraction in our pipeline, we first need to perform
    feature extraction on the files:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Assuming the folder of files called `temp_data` exists, execute the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The output shows the count of extracted files and the output sample file.
  prefs: []
  type: TYPE_NORMAL
- en: 'To train the model using either the included `sampledata.csv` or one you trained
    yourself, execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The `chapter3.mdl` model file should exist in the folder executed in once complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the newly trained model against an existing file such as the compiled
    `chapter3` executable, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: If you are looking for sample files, the `c:\Windows` and `c:\Windows\System32`
    folders contain numerous Windows Executables and DLLs. In addition, if you are
    looking to create malicious-looking files that are actually clean, you can create
    files on the fly on [http://cwg.io](http://cwg.io) in various file formats. This
    is a helpful tool in the cyber-security space where testing new functionality
    on a development machine is much safer than detonating real zero-day threats on!
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating a regression model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in previous chapters, evaluating a model is a critical part of
    the overall model building process. A poorly trained model will only provide inaccurate
    predictions. Fortunately, ML.NET provides many popular attributes to calculate
    model accuracy based on a test set at the time of training to give you an idea
    of how well your model will perform in a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'In ML.NET, as noted earlier in the linear regression sample application, there
    are five properties that comprise the `RegressionMetrics` class object. These
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Loss function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mean absolute error
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mean squared error
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: R-squared
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Root mean squared error
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next sections, we will break down how these values are calculated and
    ideal values to look for.
  prefs: []
  type: TYPE_NORMAL
- en: Loss function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This property uses the loss function set when the regression trainer was initialized.
    In the case of our linear regression example application, we used the default
    constructor, which for SDCA is defaulted to the `SquaredLoss` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other regression loss functions offered by ML.NET are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`TweedieLoss` (used for Tweedie regression models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PoissonLoss` (used for Poisson regression models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The idea behind this property is to allow some flexibility when it comes to
    evaluating your model compared to the other four properties that use fixed algorithms
    for evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Mean squared error
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Mean Squared Error**, also known as **MSE**, is defined as the measure of
    the average of the squares of the errors. To put it simply, please refer to the
    following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb4d71a8-e7cc-4b33-bb07-776c6e17aa3b.png)'
  prefs: []
  type: TYPE_IMG
- en: The dots correlate to data points for our model, while the blue line is the
    prediction line. The distance between the red dots and the prediction line is
    the error. For MSE, the value is calculated based on these points and their distances
    to the line. From that value, the mean is calculated. For MSE, the smaller the
    value, the better fitting and more accurate predictions you will have with your
    model.
  prefs: []
  type: TYPE_NORMAL
- en: MSE is best used to evaluate models when outliers are critical to the prediction
    output.
  prefs: []
  type: TYPE_NORMAL
- en: Mean absolute error
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Mean Absolute Error**, also known as **MAE**, is similar to MSE, with the
    critical difference that it sums the distances between the points and the prediction
    lines as opposed to computing the mean. It should be noted, MAE does not take
    into account directions in calculating the sum. For instance, if you had two data
    points, equidistant from the line, one being above and the other below, in effect,
    this would be balanced out with a positive and negative value. In machine learning,
    this is referred to as mean bias error, however, ML.NET does not provide this
    as part of the `RegressionMetrics` class at the time of this writing.'
  prefs: []
  type: TYPE_NORMAL
- en: MAE is best used to evaluate models when outliers are considered simply anomalies
    and shouldn't be counted in evaluating a model's performance.
  prefs: []
  type: TYPE_NORMAL
- en: R-squared
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: R-squared, also called the coefficient of determination, is another method of
    representing how accurate the prediction is compared to the test set. R-squared
    is calculated by taking the sum of the distance between every data point and the
    mean squared, subtracting them and then squaring it.
  prefs: []
  type: TYPE_NORMAL
- en: R-squared values generally range between 0 and 1, represented as a floating-point
    value. A negative value can occur when the fitted model is evaluated to be worse
    than an average fit. However, a low number does not always reflect that the model
    is bad. Predictions such as the one we looked at in this chapter that is based
    on predicting human actions are often found to be under 50%.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, higher values aren't necessarily a sure sign of the model's performance,
    as this could be considered an overfitting of the model. This happens in cases
    when there are a lot of features fed to the model, thereby making the model more
    complex than, for instance, the model we built in [Chapter 1](b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml),
    *Getting Started with Machine Learning and ML.NET*, or there is simply not enough
    diversity in the training and test sets. For example, if all of the employees
    were roughly the same values, and the test set holdout was comprised of the same
    ranges of values, this would be considered overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Root mean squared error
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Root mean squared** **error**, also known as **RMSE**, is arguably the easiest
    to understand given the previous methods. Take the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a9168326-ca8b-49d0-b37b-614cfaf918c1.png)'
  prefs: []
  type: TYPE_IMG
- en: In the case of testing the model as we did previously with the holdout set,
    the red dots are the actual values from the test set, while the blue dots are
    the predicted values. The *X*depicted is the distance between the predicted and
    actual values. RMSE simply takes a mean of all of those distances, squares that
    value, and then takes the square root.
  prefs: []
  type: TYPE_NORMAL
- en: A value under 180 is generally considered a good model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this chapter, we looked into the differences between linear and logistic
    regression models. In addition, we reviewed when to choose linear or logistic
    models along with the trainers ML.NET provides. We also created and trained our
    first linear regression application using SDCA and ML.NET to predict employee
    attrition. We also created a logistic regression application using SDCA and ML.NET
    to provide file classification. Lastly, we also dove into how to evaluate a regression
    model and the various properties that ML.NET exposes to achieve a proper evaluation
    of your regression models.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will deep dive into binary classification algorithms.
  prefs: []
  type: TYPE_NORMAL
