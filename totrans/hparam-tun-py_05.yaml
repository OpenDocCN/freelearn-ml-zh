- en: '*Chapter 4*: Exploring Bayesian Optimization'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Bayesian optimization** (**BO**) is the second out of four groups of hyperparameter
    tuning methods. Unlike grid search and random search, which are categorized as
    uninformed search methods, all of the methods that belong to the BO group are
    categorized as **informed search** methods, meaning they are learning from previous
    iterations to (hopefully) provide a better search space in the future.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss several methods that belong to the BO group,
    including **Gaussian process** (**GP**), **sequential model-based algorithm configuration**
    (**SMAC**), **Tree-structured Parzen Estimators** (**TPE**), and Metis. Similar
    to [*Chapter 3*](B18753_03_ePub.xhtml#_idTextAnchor031), *Exploring Exhaustive
    Search*, we will discuss the definition of each method, the differences between
    them, how they work, and the pros and cons of each method.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to explain BO and its variations
    when someone asks you. You will not only be able to explain what they are, but
    also how they work, in a high-level and technical way. You will also be able to
    tell the differences between them, along with the pros and cons of each of the
    methods. Furthermore, you will experience a crucial benefit once you understand
    the ins and outs of each method; that is, you will be able to understand what’s
    happening if there are errors or unexpected results and understand how to set
    up the method configuration to match your specific problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing BO
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding BO GP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding SMAC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding TPE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Metis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing BO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: BO is categorized as an informed search hyperparameter tuning method, meaning
    the search is learning from previous iterations to have a (hopefully) better subspace
    in the next iterations. It is also categorized as the **sequential model-based
    optimization** (**SMBO**) group. All SMBO methods work by sequentially updating
    probability models to estimate the effect of a set of hyperparameters on their
    performance based on historical observed data, as well as suggesting new hyperparameters
    to be tested in the following trials.
  prefs: []
  type: TYPE_NORMAL
- en: BO is a popular hyperparameter tuning method due to its *data-efficient* property,
    meaning it needs a relatively small number of samples to get to the optimal solution.
    You may be wondering, how exactly does BO get this ground-breaking data-efficient
    property? This property exists thanks to BO’s ability to learn from previous iterations.
    BO can learn and predict which subspace is worth visiting in the future by utilizing
    a **probabilistic regression model**, which acts as the *cheap cloned version
    of the expensive objective function*, and an **acquisition function**, which governs
    which *set of hyperparameters should be tested* in the next iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The objective function is just a function that takes hyperparameter values
    as input and returns the cross-validation score (see [*Chapter 1*](B18753_01_ePub.xhtml#_idTextAnchor014),
    *Evaluating Machine Learning Models*). We do not know what the output of the objective
    function for all possible hyperparameter values is. If we did, there would be
    no need to perform hyperparameter tuning. We could just use that function to get
    the hyperparameter values, which results in the highest cross-validation score.
    That’s why we need a probabilistic regression model, to approximate the objective
    function by fitting a set of known hyperparameter and cross-validation score value
    pairs (see *Figure 4.1*). The approximation concept is *similar to the concept
    of ML-based regressor* models, such as random forest, linear regression, and many
    more. First, we fit the regressor to the samples of independent and dependent
    variables; then, the model will try to *learn* from the data, which in the end
    can be used to predict new given data. The probabilistic regression model is also
    often called the **surrogate model**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Illustration of the probabilistic regression model, M'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.1 – Illustration of the probabilistic regression model, M
  prefs: []
  type: TYPE_NORMAL
- en: The acquisition function *governs which subspace we should search in the next
    iteration*. Thanks to this function, BO enables us to learn from past experiences
    and have fewer hyperparameter tuning iterations compared to random search, in
    general.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Remember that, to get the cross-validation score, we need to perform multiple
    training and evaluation processes (see [*Chapter 1*](B18753_01_ePub.xhtml#_idTextAnchor014)*,*
    *Evaluating Machine Learning Models*). This is an *expensive process* when you
    have a big, complex model with a large amount of training data. That’s why the
    acquisition function plays a big role here.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, BO works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Split the original full data into train and test sets. (See [*Chapter 1*](B18753_01_ePub.xhtml#_idTextAnchor014)*,*
    *Evaluating Machine Learning Models*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the hyperparameter space, *H*, with the accompanied distributions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the objective function, *f*, based on the train set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the stopping criterion. Usually, the number of trials is used. However,
    it is also possible to use the time taken or convergence as the stopping criterion.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initializes the empty set, *D*, which will be used to store the initial pairs
    of hyperparameter values and cross-validation scores, as well as the resulting
    pairs suggested by the acquisition function, *A*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize several pairs of hyperparameter values and cross-validation scores
    and store them in *D*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fit the probabilistic regression model/surrogate model, *M*, using the value
    pairs in *D*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sample the next set of hyperparameters by utilizing the acquisition function,
    *A*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform optimization on the acquisition function, *A*, with the help of the
    surrogate model, *M*, to sample which hyperparameters are to be passed to the
    acquisition function.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the expected optimal set of hyperparameters based on the acquisition function,
    *A*.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the cross-validation score using the objective function, *f*, based
    on the output from *Step 8*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the hyperparameters and cross-validation score pair from *Step 8* and *Step
    9* to set *D*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *Steps 7* to *10* until the stopping criterion is met.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Trains on the full training set using the final hyperparameter values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the final trained model on the test set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can initialize the hyperparameter values and cross-validation scores, as
    shown in *Step 6*, using several sampling strategies. The most straightforward
    and go-to way, in practice, is to just perform **random sampling**. However, there
    are also other methods that you may consider during your experiments, such as
    the **quasi-random** or **Latin hypercube** sampling methods.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to random search, we also need to define the distribution of each hyperparameter
    in BO. You may wonder if BO can also work on a non-numerical type of hyperparameter.
    The answer is *based on the probabilistic regression model* you are using. There
    are several surrogate models you can choose from. Those options will be discussed
    in the next three sections of this chapter, and they include **GP**, **Tree-structured
    Parzen Estimator** (**TPE**), random forest, extra trees, or other ML-based regressors.
    In this book, we will discuss the random forest regressor that’s implemented in
    the SMAC model.
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth noting that the optimization process in *Step 8* can be *replaced
    with a random search*. So, instead of performing some kind of second-order optimization
    method, we can randomly sample sets of hyperparameters from the search space and
    pass them onto the acquisition function. Then, we can get the optimal set of hyperparameters
    based on the output from the acquisition function. When using random search in
    this step, we still utilize the acquisition function to govern which subspace
    we should search for in the next iteration, but we add some random behavior to
    it, with the hope that we can escape the local optimum and converge toward the
    global optimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first and the most popular acquisition function is **expected improvement**
    (**EI**), which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_001.png) when ![](img/Formula_B18753_04_002.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B18753_04_003.png) when ![](img/Formula_B18753_04_004.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_005.png), ![](img/Formula_B18753_04_006.png)
    and ![](img/Formula_B18753_04_007.png) are the cumulative distribution and probability
    density functions of the standard normal distribution, respectively. ![](img/Formula_B18753_04_008.png)
    and ![](img/Formula_B18753_04_009.png) represent the expected performance and
    the uncertainty, respectively, that are captured by the surrogate model. Finally,
    ![](img/Formula_B18753_04_010.png) represents the current best value of the objective
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Implicitly, the EI acquisition function enables BO methods to have the *exploration
    versus exploitation trade-off property*. This property can be achieved by two
    terms competing within the formula. When the value of the first term is high,
    meaning the expected performance, ![](img/Formula_B18753_04_011.png), is higher
    than the current best value, ![](img/Formula_B18753_04_012.png), EI will favor
    the exploitation process. On the other hand, when the uncertainty is very high,
    meaning we have a high value of ![](img/Formula_B18753_04_013.png), EI will favor
    the exploration process. By exploitation, this means that the acquisition function
    will recommend the set of hyperparameters that possibly get a higher value of
    the objective function, *f*. In terms of exploration, this means that the acquisition
    function will recommend the set of hyperparameters from the subspace that we haven’t
    explored yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can imagine this exploration and exploitation trade-off as when you are
    craving some food. Let’s say you want to have lunch with your brother today. Imagine
    the following two scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: “Hey bro, let’s have lunch at our favorite restaurant today!”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Hey bro, have you heard of the new restaurant up there? Why don’t we try it
    for lunch?”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first scenario, you choose to eat at your favorite restaurant since you
    are confident that there is nothing wrong with the food and, more importantly,
    you are *confident about the taste of the food and the overall experience* of
    eating at that restaurant. This first scenario best explains what we call the
    exploitation process. In the second scenario, you *don’t have any idea what the
    overall experience* of eating at that new restaurant is. It may be worse than
    your favorite restaurant, but it may also potentially be your new favorite restaurant!
    This is what we call the exploration process.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: In some implementations, such as in the **Scikit-optimize** package, there is
    a hyperparameter that enables us to *control how much we are leaning toward exploitation*
    compared to exploration. In Scikit-optimize, the sign of the EI function is negative.
    This is because the package *treats the optimization problem as the minimization
    problem* by default.
  prefs: []
  type: TYPE_NORMAL
- en: In our previous explanation, we treated the optimization problem as the maximization
    problem since we wanted to get the highest cross-validation score possible. Don’t
    confuse this with the minimization versus maximization problem – just choose what
    best describes the problem you will be facing in practice!
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the EI acquisition function that’s implemented in the Scikit-optimize
    package:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_014.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see in the first term, the value of ![](img/Formula_B18753_04_015.png)
    will control how big our tendency is toward exploitation compared to exploration.
    The smaller the ![](img/Formula_B18753_04_016.png) value is, the more we lean
    toward exploitation. We will learn more about the implementation part of BO using
    Scikit or other packages from [*Chapter 7*](B18753_07_ePub.xhtml#_idTextAnchor062)*,
    Hyperparameter Tuning via Scikit* to [*Chapter 10*](B18753_10_ePub.xhtml#_idTextAnchor092)*,
    Advanced Hyperparameter Tuning with DEAP and Microsoft NNI*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a better understanding of how the exploration and exploitation trade-off
    happens during the hyperparameter tuning phase, let’s look at an example. Let’s
    say, for instance, we are using the GP surrogate model to estimate the following
    objective function. There’s no need to worry about what and how GP works for now;
    we will discuss it in more detail in the next section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_017.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/Formula_B18753_04_018.png) is a noise that follows the standard
    normal distribution. The following is a plot of this function within the range
    of ![](img/Formula_B18753_04_019.png). Note that, in this example, we are assuming
    that we know what the true objective function is. However, in practice, this function
    is unknown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Plot of the objective function, f(x)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.2 – Plot of the objective function, f(x)
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say we are using the EI as the acquisition function, setting the number
    of trials as `15`, setting the initial number of points as `5`, and setting the
    ![](img/Formula_B18753_04_020.png) value to `0.01`. You can see how the fitting
    process works for the first five trials in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – GP and EI illustration, δ = 0.01'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.3 – GP and EI illustration, δ = 0.01
  prefs: []
  type: TYPE_NORMAL
- en: Each row in the preceding figure corresponds to the first until the fifth trial.
    The left column contains information on the objective function (*red dashed line*),
    the GP surrogate model approximation of the objective function (*green dashed
    line*), how sure the approximation is (*green transparent area*), and the observed
    points up to each trial (*red dots*). The right column contains information on
    the EI acquisition function values (*blue line*) and the next point (*blue dot*)
    to be included in the next trials.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s run through each of the rows in *Figure 4.3* so that you understand how
    it works. In the first trial (*see the first row from the top in the left column*),
    we initialize five random sample points – or hyperparameter values, in the context
    of hyperparameter tuning – and fit the GP model based on those five points. Remember
    that the GP model doesn’t know the actual objective function; the only information
    it has is just those five random points. Then (*see the first row from the top
    in the right column*), based on the fitted GP model, we get the value of the EI
    acquisition function across the space. In this case, the space is just a range
    – that is, ![](img/Formula_B18753_04_022.png). We also get the point to be included
    in the next trials, which in this case is around point `0.5`.
  prefs: []
  type: TYPE_NORMAL
- en: In the second trial, we utilize the point suggested by the EI acquisition function
    and fit the GP model again based on the six sample points we have (*see the second
    row from the top in the left column*). If you compare the GP approximation of
    the second trial with the first trial, you will see that it is closer to the true
    objective function. Next (*see the second row from the top in the right column*),
    we repeat the same process, which is to generate the EI function value across
    the space and the point to be included in the next trial. The suggested point
    in this step is around `0.7`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We keep repeating the same process until the stopping criteria are met, which
    in this case is 15 trials. The following plot shows the result after 15 trials.
    It is much better than the approximation in the first trial (*see the green dashed
    line*)! You can also see that there are some ranges of ![](img/Formula_B18753_04_023.png)
    where the confidence of the GP approximation is high, such as around points `–1.5`
    and `1.6`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Result after 15 trials, δ = 0.01'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_004.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.4 – Result after 15 trials, δ = 0.01
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the preceding plot, the final suggested point, or the hyperparameter
    value, is `–1.5218`, which results in the value of the objective function being
    equal to `–1.9765`. Let’s also look at the convergence plot from the first until
    the last trial. From the following convergence plot, we can see how our surrogate
    model and acquisition function help us get the minimum value of the objective
    function based on all the trials:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Convergence plot'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_005.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.5 – Convergence plot
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s try to change the value of ![](img/Formula_B18753_04_025.png) to
    a lower value than what we had previously to see how the EI acquisition function
    will favor exploitation more than exploration. Let’s set the ![](img/Formula_B18753_04_026.png)
    value to be 1,000 times lower than the previous value. Note that we only change
    the ![](img/Formula_B18753_04_027.png)value and leave the other setups as-is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – GP and EI illustration, δ = 0.00001'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.6 – GP and EI illustration, δ = 0.00001
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the EI acquisition function suggested most of the points in
    a range between **0.5** and **1.4**. The acquisition function doesn’t suggest
    exploring the ![](img/Formula_B18753_04_029.png) range, although we can get a
    much lower objective function value in that range. This happens because there
    are no initial random points in that range, and we favor exploitation a lot in
    this example. The following plot shows the final results after 15 trials. In this
    case, we get a worse result when we favor more exploitation over exploration.
    However, this is not always the case. *You have to experiment* since different
    data, different objective functions, a different hyperparameter space, and different
    implementations may result in different conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Result after 15 trials, δ = 0.00001'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_007.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.7 – Result after 15 trials, δ = 0.00001
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s see what the impact is if we set the ![](img/Formula_B18753_04_031.png)
    value to `100`, which in this case means that we favor exploration more than exploitation.
    Similar to the previous trial, after running 15 trials, we got the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 – Result after 15 trials, δ = 100'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.8 – Result after 15 trials, δ = 100
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the points that are suggested by the acquisition function (*the
    red dots*) are all over the place. This is because we set such a high ![](img/Formula_B18753_04_033.png)
    value. This means that the acquisition function’s outputs will suggest points
    in the space that haven’t been observed yet. We will learn how to produce the
    plots shown here in [*Chapter 7*](B18753_07_ePub.xhtml#_idTextAnchor062), *Hyperparameter
    Tuning via Scikit*.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the EI acquisition function, there are also other popular acquisition
    functions that you may consider using, including **Probability of Improvement**
    (**PI**) and **Upper Confidence Bound** (**UCB**).
  prefs: []
  type: TYPE_NORMAL
- en: 'PI is the acquisition function that existed before EI. It is simpler than EI
    – in fact, the formula of ![](img/Formula_B18753_04_034.png) is derived based
    on the following simple definition of *improvement*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_035.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The idea of ![](img/Formula_B18753_04_036.png) is to return the size of improvement,
    if there is improvement between the expected performance and the current best
    performance, or just return zero if there is no improvement. Based on ![](img/Formula_B18753_04_037.png),
    we can define PI as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_038.png) when ![](img/Formula_B18753_04_039.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B18753_04_040.png) when ![](img/Formula_B18753_04_041.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The problem with PI is that it will *give the same reward for all sets of hyperparameters*,
    so long as there’s an improvement compared to the current best value, ![](img/Formula_B18753_04_042.png),
    no matter how big the improvement is. This behavior is not very preferable in
    practice since it can *guide us to the local minima and get us stuck in there*.
    If you are familiar with calculus and statistics, you will realize that EI is
    just the expectation over ![](img/Formula_B18753_04_037.png), as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_044.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_045.png) is the probability density function
    of the standard normal distribution. Unlike PI, the *EI acquisition function will
    take the size of improvement into account*.
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the UCB, it is very straightforward compared to others. We have the
    power to control the trade-off between exploration and exploitation by ourselves
    via the ![](img/Formula_B18753_04_046.png)parameter. This acquisition function
    can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_047.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, UCB *doesn’t take into account the current best value* of the
    objective function. It only considers the expected performance and the uncertainty
    captured by the surrogate model. You can control the exploration and exploitation
    trade-off by changing the ![](img/Formula_B18753_04_048.png)value. If you want
    to lean toward exploring the search space, then you can increase the value of
    ![](img/Formula_B18753_04_049.png). However, if you want to focus more on the
    set of hyperparameters that are expected to perform well, then you can decrease
    the value of ![](img/Formula_B18753_04_050.png).
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the variations of surrogate model and acquisition functions, there
    are also other variations of BO methods based on modifying the algorithm itself,
    including Metis and **Bayesian optimization and HyperBand** (**BOHB**). We will
    discuss Metis in the *Understanding Metis* section and BOHB in [*Chapter 6*](B18753_06_ePub.xhtml#_idTextAnchor054),
    *Exploring* *Multi-Fidelity Optimization*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the pros and cons of BO hyperparameter tuning, in general,
    compared to other hyperparameter tuning methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9 – Pros and cons of BO'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_009.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.9 – Pros and cons of BO
  prefs: []
  type: TYPE_NORMAL
- en: BO can handle expensive objective functions and is more data-efficient and arguably
    better than random search when it has good initial points. You can utilize the
    set of hyperparameters we used for the initial points up to *Step 6* from the
    procedure mentioned at the beginning of this section. However, if you don’t have
    that privileged access, BO still can outperform random search if you give the
    method some more time since it has to build a good surrogate model first from
    scratch, especially if you have a huge hyperparameter space. Once BO has built
    a good surrogate model, it tends to work faster than random search to find the
    optimal set of hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: There is also another way to speed up the relatively slow warm-up process of
    BO. The idea is to adopt a **meta-learning** procedure to initialize the initial
    set of hyperparameters by learning from meta-features in other, similar datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Speeding Up BO’s Warm-Up
  prefs: []
  type: TYPE_NORMAL
- en: 'See the following paper for more information: *Efficient and Robust Automated
    Machine Learning*, by Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost
    Springenberg, Manuel Blum, Frank Hutter ([https://papers.nips.cc/paper/2015/hash/11d0e6287202fced83f79975ec59a3a6-Abstract.html](https://papers.nips.cc/paper/2015/hash/11d0e6287202fced83f79975ec59a3a6-Abstract.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: BO also has a nice feature that random search doesn’t have – the ability to
    control the exploration and exploitation trade-off, as explained previously in
    this section. This feature enables BO to do more than just constantly explore,
    as random search does.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you are aware of what BO is, how it works, what its important components
    are, and the pros and cons of this method, we will dive deeper into the variations
    of BO in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding BO GP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Bayesian optimization Gaussian process** (**BOGP**) is one of the variants
    of the BO hyperparameter tuning method. It is well-known for its good capability
    in describing the objective function. This variant is very popular due to the
    unique *analytically tractable* nature of the surrogate model and its ability
    to produce relatively accurate approximation, even with only a few observed points.'
  prefs: []
  type: TYPE_NORMAL
- en: However, BOGP has limitations. It *only works on continuous hyperparameters*,
    not on the discrete or categorical types of hyperparameters. It is not recommended
    to use BOGP when you need a lot of iterations to get the optimal set of hyperparameters,
    especially when you have a large number of samples. This is BOGP has a ![](img/Formula_B18753_04_051.png)
    runtime, where ![](img/Formula_B18753_04_052.png) is the number of samples. If
    you have *more than 10 hyperparameters* to be optimized, the common belief is
    that BOGP is not the right hyperparameter tuning method for you.
  prefs: []
  type: TYPE_NORMAL
- en: Having GP as the surrogate model means that we utilize GP as the *prior* for
    our objective function. Then, we can utilize the prior along with a *likelihood
    model* to compute the *posterior* that we care about. All of these nerdy terms
    can easily be understood if we are familiar with the famous **Bayes Theorem**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bayes Theorem allows us to calculate the probability of an event, given a specific
    condition, by utilizing our previous knowledge or common belief that we have.
    Formally, Bayes Theorem is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_053.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_054.png)is the event we want to know the probability
    of, and ![](img/Formula_B18753_04_116.png) refers to the specific condition we
    mentioned previously. The left-hand side of the equation, ![](img/Formula_B18753_04_055.png),
    is what we called as the posterior. ![](img/Formula_B18753_04_056.png) is the
    prior and ![](img/Formula_B18753_04_057.png) is what we call the likelihood model.
    Finally, ![](img/Formula_B18753_04_058.png) is just a constant to ensure that
    the resulting value of this formula is bound in the range of ![](img/Formula_B18753_04_059.png).
  prefs: []
  type: TYPE_NORMAL
- en: To understand Bayes Theorem, let’s walk through an example. Let’s say we want
    to know the probability of you eating at your favorite restaurant, given that
    today’s weather is sunny. In this example, you eating at your favorite restaurant
    is the event we are interested in. This is ![](img/Formula_B18753_04_060.png)
    in the equation. The information that today is sunny refers to ![](img/Formula_B18753_04_117.png)
    in the equation.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you are eating at your favorite restaurant for 40 out of 100 days.
    This means that before knowing what today’s weather is, your ![](img/Formula_B18753_04_061.png)
    is equal to ![](img/Formula_B18753_04_062.png). Let’s also assume that out of
    100 days, there are 30 sunny days. Then, the ![](img/Formula_B18753_04_063.png)
    value is equal to ![](img/Formula_B18753_04_064.png). Based on your experience
    of eating at your favorite restaurant, you have realized that you ate in the sunny
    weather condition 20 out of 40 times. Thus, the likelihood, ![](img/Formula_B18753_04_065.png),
    is equal to ![](img/Formula_B18753_04_066.png). Using all of this information,
    we can calculate the probability of you eating at your restaurant, given that
    today’s weather is sunny, as ![](img/Formula_B18753_04_067.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are ready to revisit the GP. BOGP utilizes GP as the surrogate model.
    GP as the surrogate model means that we utilize it as the prior of our objective
    function, which implies that the *posterior distribution is also a GP*. You can
    think of GP as a generalization of a Gaussian distribution that you are familiar
    with. Unlike Gaussian distribution, which describes the distribution of a random
    variable, *GP describes the distribution over functions*. Similar to the Gaussian
    distribution that is accompanied by the mean and variance of the random variable,
    GP is also accompanied by the *mean and covariance* of the function. As for the
    *likelihood*, we assume that the objective function, *f*, follows a normal likelihood
    with noise:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_068.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B18753_04_069.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, we can describe ![](img/Formula_B18753_04_070.png), or the values of
    our objective function for all *n* samples. as a GP with a mean function of ![](img/Formula_B18753_04_071.png)
    and a covariance kernel, ![](img/Formula_B18753_04_072.png), sized *n x n*, which
    is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_073.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The distribution of prediction from GP also follows the Gaussian distribution,
    which can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_074.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the value of ![](img/Formula_B18753_04_075.png)and ![](img/Formula_B18753_04_076.png)
    can be *analytically derived from the kernel*, ![](img/Formula_B18753_04_077.png).
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, *GP approximates the objective function by following a normal
    distribution assumption*. In practice, GP can also be utilized when we don’t have
    zero mean processes, as per our previous assumption. However, we need to do some
    preprocessing on the values of the objective function to center them to zero.
    Choosing the *right covariance kernel*, ![](img/Formula_B18753_04_078.png), is
    also crucial. It highly impacts the performance of our hyperparameter tuning process.
    The most popular kernel that’s used in practice is the *Matern kernel*. However,
    we must choose the right kernel for our case, since each kernel has a characteristic
    that may or may not be suitable for our objective function. We will discuss the
    kernels that are available in the Scikit package in [*Chapter 7*](B18753_07_ePub.xhtml#_idTextAnchor062),
    *Hyperparameter Tuning via Scikit*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the list of pros and cons of BOGP compared to other
    variants of the BO hyperparameter tuning method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10 – Pros and cons of BOGP'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_010.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.10 – Pros and cons of BOGP
  prefs: []
  type: TYPE_NORMAL
- en: In the previous section, we saw how GP works in practice, where we discussed
    the exploration and exploitation trade-off. You can revisit that example to get
    a better understanding of how GP works in practice through the help of visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned about utilizing GP as the surrogate model in BO,
    along with the pros and cons compared to other variants of BO. In the next section,
    we will learn about another variant of BO that utilizes random forest as the surrogate
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding SMAC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**SMAC** is part of the BO hyperparameter tuning method group and utilizes
    random forest as the surrogate model. This method is optimized to handle discrete
    or categorical hyperparameters. If your hyperparameter space is huge and is dominated
    by discrete hyperparameters, then SMAC is a good choice for you.'
  prefs: []
  type: TYPE_NORMAL
- en: Similar to BOGP, SMAC also works by modeling the objective function. Specifically,
    it utilizes random forest as the surrogate model to create an estimation of the
    real objective function, which can then be passed to the acquisition function
    (see the *Introducing BO* section for more details).
  prefs: []
  type: TYPE_NORMAL
- en: Random forest is a **machine learning** (**ML**) algorithm that can be utilized
    in classification or regression tasks. It is built upon a collection of decision
    trees, which is known to perform well with categorical types of features. The
    name random forest comes from the fact that it is built from several decision
    trees. We will discuss random forest, along with its hyperparameters, in more
    detail in [*Chapter 11*](B18753_11_ePub.xhtml#_idTextAnchor110), *Understanding
    Hyperparameters of Popular Algorithms*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main difference between SMAC and BOGP lies in the type of surrogate model
    that’s used in each method. While BOGP utilizes GP as the surrogate model, SMAC
    utilizes random forest as the surrogate model. The acquisition function that was
    used in the original paper on SMAC is the *EI function with some modifications*
    on how the optimization process in *Step 8* in the *Introducing BO* section is
    done, which also can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – Optimization process of the acquisition function'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_011.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.11 – Optimization process of the acquisition function
  prefs: []
  type: TYPE_NORMAL
- en: 'In SMAC, similar to BOGP, we are also assuming that the distribution of our
    surrogate model’s *prediction follows the Gaussian distribution*, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_079.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the ![](img/Formula_B18753_04_080.png)and ![](img/Formula_B18753_04_081.png)
    values are derived from the *random forest prediction’s mean and variance*, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: We can also *utilize random forest to perform hyperparameter tuning on a random
    forest model*! How is this possible? How can a model be used to improve the performance
    of another model of the same type?
  prefs: []
  type: TYPE_NORMAL
- en: It is possible because we are treating one model as the surrogate model while
    the other one is the actual model that is fitted to the independent variables
    to predict the dependent variable. As the surrogate model, random forest will
    act as the regressor, which has the goal of learning the relationship between
    the hyperparameter space and the corresponding objective function. So, when we
    said that we are utilizing random forest to perform hyperparameter tuning on a
    random forest model, there are two random forest models with different goals and
    different input-output pairs!
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following steps to get a better understanding of this concept.
    Note that the following procedure replaces *Steps 7* to *11* in the *Introducing
    BO* section:'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. (The first few steps are the same as we saw earlier).
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Fit the *first random forest model*, which acts as a surrogate model, *M*,
    using the value pairs in *D*. Remember that *D* consists of pairs of hyperparameter
    values and the cross-validation score.
  prefs: []
  type: TYPE_NORMAL
- en: '8\. Sample the next set of hyperparameters by utilizing the acquisition function,
    *A*:'
  prefs: []
  type: TYPE_NORMAL
- en: Perform optimization on the acquisition function with the help of the surrogate
    model, *M*, to sample which hyperparameters are to be passed to the acquisition
    function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the optimal set of hyperparameters based on the acquisition function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 9\. Compute the cross-validation score using the objective function, *f*, based
    on the output from *Step 8*. Note that the cross-validation score is computed
    based on the *second random forest model*, whose goal is to learn the relationship
    between the dependent and independent variables from our original problem.
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Add the hyperparameters and cross-validation score pair from *Step 8* and
    *Step 9* to set *D*.
  prefs: []
  type: TYPE_NORMAL
- en: 11\. Repeat *Steps 7* to *10* until the stopping criteria are met.
  prefs: []
  type: TYPE_NORMAL
- en: 12\. (The last few steps are the same as we saw earlier).
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering, why bother utilizing the same ML algorithm as the surrogate
    model? Why don’t we just perform a grid search or random search instead? Remember
    that the surrogate model is just one piece of the full BO algorithm. There is
    also the acquisition function and other optimization steps that can help us get
    the optimal set of hyperparameters faster. It is worth noting that *we can utilize
    any ML model* other than random forest. When it comes to tree-based ML models,
    XGBoost, CatBoost, and LightGBM are also popular among data scientists since they
    work well in practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *Introducing BO* section, we saw how GP works with the EI acquisition
    function to estimate a dummy objective function. Let’s use the same dummy objective
    function, as defined here, and see the result of utilizing random forest (not
    necessarily the SMAC algorithm) as the surrogate model instead of GP. We will
    still use EI as the acquisition function in this example and the Scikit-optimize
    package as the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_082.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_083.png) is a noise that follows the standard
    normal distribution. Please see *Figure 4.2* for a visualization of this dummy
    objective function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s set the number of trials and the exploitation versus exploration trade-off
    controller, ![](img/Formula_B18753_04_084.png), using the default values given
    by the Scikit-optimize package for the random forest surrogate model, which are
    `100` and `0.01`, respectively. You can see how the random forest surrogate model
    fitting process works for the first five trials in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.12 – Random forest and EI illustration; δ = 0.01; trials 1 – 5'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_012.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.12 – Random forest and EI illustration; δ = 0.01; trials 1 – 5
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, not many things happened in the first five trials. Even the
    approximation of the objective function that’s given by the random forest (*see
    the green-dashed line*) is still very bad since it is just a straight line! Let’s
    see what the condition is during trials 71 until 75:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.13 – Random forest and EI illustration; δ = 0.01; trials 71- 75'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_013.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.13 – Random forest and EI illustration; δ = 0.01; trials 71- 75
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that our random forest surrogate model has improved a lot
    in estimating the true objective function. One interesting point is that the acquisition
    function curve looks very different from the one we saw when utilizing GP as the
    surrogate model. Here, the acquisition function looks edgier, just like the one
    we usually see from visualizing random forest. Finally, let’s see what the final
    form of the approximated function is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.14 – Result after 100 trials; δ = 0.01'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_014.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.14 – Result after 100 trials; δ = 0.01
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that random forest fails to fit the true objective function
    in general, but it succeeds to focus on the local minima of the objective function.
    This happens because *random forest needs a lot of data*, or in this case, the
    observed points (*see red dots*), to have a good approximation of the objective
    function. You can also see the convergence plot of the fitting process, starting
    from the first until the last trial, in the following plot. If we compare *Figure
    4.15* to *Figure 4.5*, we can easily see that, in this example, random forest,
    when supported by the EI acquisition function, learns much slower than GP supported
    by EI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.15 – Convergence plot'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_015.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.15 – Convergence plot
  prefs: []
  type: TYPE_NORMAL
- en: 'From *Figure 4.14*, we can also see that, currently, we are only focusing on
    several ranges and missing the global minima of the dummy objective function,
    which is located around the ![](img/Formula_B18753_04_088.png) range. Let’s see
    if changing the value of ![](img/Formula_B18753_04_089.png) to `100` can solve
    this issue. The expectation is that the EI acquisition function can help the random
    forest surrogate model *explore more* in other ranges of values as well. You can
    see the result of the first five trials in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.16 – Random forest and EI illustration; δ = 100; trials 1 – 5'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_016.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.16 – Random forest and EI illustration; δ = 100; trials 1 – 5
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the first five trials of the default ![](img/Formula_B18753_04_091.png)
    value, we still can’t see much of the learning process. Let’s see what the condition
    is during trials 71 until 75:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.17 – Random forest and EI illustration; δ = 100; trials 71 – 75'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_017.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.17 – Random forest and EI illustration; δ = 100; trials 71 – 75
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see a very big difference between *Figure 4.17* and *Figure 4.13*.
    Finally, let’s see what the final form of the approximated function is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.18 – Result after 100 trials; δ = 100'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_018.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.18 – Result after 100 trials; δ = 100
  prefs: []
  type: TYPE_NORMAL
- en: By changing the value of ![](img/Formula_B18753_04_094.png) to `100`, it seems
    that our expectation has been achieved. The approximation from the random forest
    surrogate model (*see the green-dashed line*) is now focusing on more than specific
    ranges. Moreover, we even get a better result compared to GP (see *Figure 4.4*).
    Again, it is worth noting that this is not always the case – you must experiment
    a lot on your own since different data, different objective functions, a different
    hyperparameter space, and different implementations may result in different conclusions.
    We will learn how to implement random forest as the surrogate model and how to
    produce these figures in [*Chapter 7*](B18753_07_ePub.xhtml#_idTextAnchor062),
    *Hyperparameter Tuning via Scikit*.
  prefs: []
  type: TYPE_NORMAL
- en: There is another method, called **Bayesian optimization inside a Grove** (**BOinG**),
    whose goal is to get the best of both worlds by utilizing random forest and GP
    as surrogate models.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Optimization Inside a Grove
  prefs: []
  type: TYPE_NORMAL
- en: 'See the following paper for more information: *Searching in the Forest for
    Local Bayesian Optimization*, by Difan Deng and Marius Lindauer ([https://arxiv.org/abs/2111.05834](https://arxiv.org/abs/2111.05834)).'
  prefs: []
  type: TYPE_NORMAL
- en: BOinG works by using *two-stage optimization* by using global and local models
    to cut down the computational cost and focus more on the promising subspace, respectively.
    In BOinG, random forest is utilized as the global model and GP as the local model.
    The global model is responsible for searching the promising subspace of the local
    model. Thus, a global model should be flexible enough to handle complex problems
    with different types of hyperparameters. Since the local model only searches in
    a promising subspace, it is possible to utilize a more accurate but expensive
    model, such as GP.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table lists the pros and cons of utilizing random forest as a
    surrogate model compared to other variants of the BO hyperparameter tuning method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.19 – Pros and cons of utilizing random forest as a surrogate model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_019.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.19 – Pros and cons of utilizing random forest as a surrogate model
  prefs: []
  type: TYPE_NORMAL
- en: A conditional hyperparameter is a hyperparameter that will only be utilized
    when a certain condition is met. The tree structure of random forest is very suitable
    for this kind of situation since it can just add another branch of the tree to
    check whether the condition is met or not. The condition is usually just a specific
    value or range of other hyperparameters in the space.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you are aware of SMAC and utilizing random forest as a surrogate model
    in general, in the next section, we will discuss another variant of BO that has
    a different approach in terms of approximating the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding TPE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**TPE** is another variant of BO that performs well in general and can be utilized
    for both categorical and continuous types of hyperparameters. Unlike BOGP, which
    has cubical time complexity, TPE runs in linear time. TPE is suggested if you
    have a huge hyperparameter space and have a very tight budget for evaluating the
    cross-validation score.'
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between TPE and BOGP or SMAC is in the way that it models
    the relationship between hyperparameters and the cross-validation score. Unlike
    BOGP or SMAC, which approximate the value of the objective function, or the posterior
    probability, ![](img/Formula_B18753_04_095.png), *TPE works the other way around*.
    It tries to get the optimal hyperparameters based on the condition of the objective
    function, or the likelihood probability, ![](img/Formula_B18753_04_096.png) (see
    the explanation of Bayes Theorem in the *Understanding BO GP* section).
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, unlike BOGP or SMAC, which construct a predictive distribution
    over the objective function, TPE tries to utilize the information of the objective
    function to *model the hyperparameter distributions*. To be more precise, when
    the optimization problem is in the form of a *minimization problem*, ![](img/Formula_B18753_04_097.png)
    is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_098.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_099.png) and ![](img/Formula_B18753_04_100.png)
    are utilized when the value of the objective function is lower or higher than
    the threshold, ![](img/Formula_B18753_04_101.png), respectively. There is no specific
    rule on how to choose the threshold, ![](img/Formula_B18753_04_102.png). However,
    in the **Hyperopt** and **Microsoft NNI** implementations, this threshold is chosen
    based on the TPE’s hyperparameter, ![](img/Formula_B18753_04_103.png), and the
    number of observed points in *D* up to the current trial. The definition of ![](img/Formula_B18753_04_104.png)
    tells us that TPE has two models that act as the learning algorithm based on the
    value of the objective function, which is ruled by the threshold, ![](img/Formula_B18753_04_105.png).
  prefs: []
  type: TYPE_NORMAL
- en: When the *distribution of hyperparameters is continuous*, TPE will utilize **Gaussian
    mixture models** (**GMMs**), along with the EI acquisition function, to suggest
    the next set of hyperparameters to be tested. If the continuous distribution is
    not a Gaussian distribution, then TPE will convert it to mimic the Gaussian distribution.
    For example, if the specified hyperparameter distribution is the uniform distribution,
    then it will be converted into a truncated Gaussian distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The probabilities of the different possible outcomes for the multinomial distribution
    within the GMM, and the mean and variance values for the normal distribution within
    the GMM, are generated by the **adaptive Parzen estimator**. This estimator is
    responsible for constructing the two probability distributions, ![](img/Formula_B18753_04_106.png)
    and ![](img/Formula_B18753_04_107.png), based on the mean and variance of the
    normal hyperparameter distribution, as well as the hyperparameter value of all
    observed points in *D* up to the current trial.
  prefs: []
  type: TYPE_NORMAL
- en: When the *distribution is categorical or discrete*, TPE will convert the categorical
    distribution into a re-weighted categorical and use *weighted random sampling*,
    along with the EI acquisition function, to suggest the expected best set of hyperparameters.
    The weights in the random sampling procedure are generated based on the historical
    counts of the hyperparameter value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The EI acquisition function definition in TPE is a bit different from the definition
    we learned about in the *Introducing BO* section. In TPE, we are using Bayes Theorem
    when deriving the EI formula. The simple formulation of the EI acquisition function
    in TPE is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_108.png)'
  prefs: []
  type: TYPE_IMG
- en: The proportionality defined here tells us that to get a high value of EI, we
    need to get a high ![](img/Formula_B18753_04_109.png) ratio. In other words, when
    the optimization problem is in the form of a *minimization problem*, the EI acquisition
    function must suggest more hyperparameters from ![](img/Formula_B18753_04_110.png)
    over ![](img/Formula_B18753_04_111.png). It is the other way around when the optimization
    problem is in the form of a *maximization problem*. For example, when we use accuracy
    to measure the performance of our classification model, then we should sample
    more hyperparameters from ![](img/Formula_B18753_04_112.png) over ![](img/Formula_B18753_04_113.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, TPE works as follows. Note that the following procedure describes
    how TPE works for the *minimization problem*. This procedure replaces *Steps 7*
    to *11* in the *Introducing BO* section:'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. (The first few steps are the same as we saw earlier).
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Divide pairs of hyperparameter values and cross-validation scores in *D*
    into two groups based on the threshold, ![](img/Formula_B18753_04_114.png), namely
    *below* and *above* groups (see *Figure 4.19*).
  prefs: []
  type: TYPE_NORMAL
- en: '8\. Sample the next set of hyperparameters by utilizing the EI acquisition
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: For each group, calculate the probabilities, means, and variances for the GMM
    using the adaptive Parzen estimator (if it’s a continuous type) or weights for
    random sampling (if it’s a categorical type).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each group, fit the GMM (if it’s a continuous type), or perform random sampling
    (if it’s a categorical type), to sample which hyperparameters will be passed to
    the EI acquisition function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each group, calculate the probability of those samples being good samples
    (for the below group), or the probability of those samples being bad samples (for
    the above group).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the expected optimal set of hyperparameters based on the EI acquisition
    function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 9\. Compute the cross-validation score using the objective function, *f*, based
    on the output from *Step 8*.
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Add the hyperparameters and cross-validation score pair from *Step 8* and
    *Step 9* to set *D*.
  prefs: []
  type: TYPE_NORMAL
- en: 11\. Repeat *Steps 7* to *10* until the stopping criteria have been met.
  prefs: []
  type: TYPE_NORMAL
- en: '12\. (The last few steps are the same as we saw earlier):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.20 – Illustration of groups division in TPE'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_020.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.20 – Illustration of groups division in TPE
  prefs: []
  type: TYPE_NORMAL
- en: Based on the stated procedure and the preceding plot, we can see that, unlike
    BOGP or SMAC, which constructs a predictive distribution over the objective function,
    TPE tries to utilize the information of the objective function to model the hyperparameter
    distributions. This way, we are not only focusing on the best-observed points
    during the trials – we are focusing on the *distribution of the best-observed
    points* instead.
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering why the *Tree-structured* term is within the TPE method’s
    name. This term refers to the conditional hyperparameters that we discussed in
    the previous section. This means that there are hyperparameters in the space that
    will only be utilized when a certain condition is met. We will see what a tree-structured
    or conditional hyperparameter space looks like in [*Chapter 8*](B18753_08_ePub.xhtml#_idTextAnchor074),
    *Hyperparameter Tuning via Hyperopt*, and [*Chapter 9*](B18753_09_ePub.xhtml#_idTextAnchor082),
    *Hyperparameter Tuning via Optuna*.
  prefs: []
  type: TYPE_NORMAL
- en: One of the drawbacks that TPE has is that it may *overlook the interdependencies
    among hyperparameters* in a certain space since the Parzen estimators work univariately.
    However, this is not the case for BOGP or SMAC, since the surrogate model is constructed
    based on the configurations in the hyperparameter space. Thus, they can take into
    account the interdependencies among hyperparameters. Fortunately, there is an
    implementation of TPE that overcomes this drawback. The **Optuna** package provides
    the **multivariate TPE** implementation, which can take into account the interdependencies
    among hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table lists of pros and cons of utilizing TPE compared to other
    variants of the BO hyperparameter tuning method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.21 – Pros and cons of TPE'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_021.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.21 – Pros and cons of TPE
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Some implementations support parallel tuning, but with a trade-off between the
    suggested hyperparameter quality and the wall time. The Microsoft NNI package
    supports this feature via the `constant_liar_type` argument, which will be discussed
    in more detail in [*Chapter 10*](B18753_10_ePub.xhtml#_idTextAnchor092), *Advanced
    Hyperparameter Tuning with DEAP and Microsoft NNI*.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned about TPE, along with its pros and cons compared
    to other variants of BO. In the next section, we will learn about another variant
    of BO that has a slightly modified algorithm compared to the BO method in general.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Metis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metis is one of the variants of BO that has several algorithm modifications
    compared to the BO method in general. Metis utilizes GP and GMM in its algorithm.
    GP is used as the surrogate model and outliers detector, while GMM is used as
    part of the acquisition function, similar to TPE.
  prefs: []
  type: TYPE_NORMAL
- en: What makes Metis different from other BO methods, in general, is that it can
    *balance exploration and exploitation more data-efficiently* than the EI acquisition
    function. It can also *handle noise in the data that doesn’t follow the Gaussian*
    distribution, and this is the case most of the time. Unlike most of the methods
    that perform random sampling to initialize the set of hyperparameters and cross-validation
    score, *D*, Metis utilizes **Latin Hypercube Sampling** (**LHS**), which is a
    stratified sampling procedure based on the equal interval of each hyperparameter.
    This sampling method is believed to be more data-efficient compared to random
    sampling to achieve the same exploration coverage.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, how can Metis balance exploration and exploitation more efficiently than
    the EI acquisition function, in terms of the needs of the observed points? This
    is achieved through the *custom acquisition function* that Metis has, which consists
    of three sub-acquisition functions, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lowest confidence** (**LC**): This sub-acquisition function’s goal is to
    sample hyperparameters with the highest uncertainty. In other words, the goal
    of this sub-acquisition function is to *maximize exploration*. This function is
    defined as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_115.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Parzen estimator**: This sub-acquisition function is inspired by the TPE
    method, which utilizes GMM to estimate how likely the sampled hyperparameter is
    part of the *below* or *above* group (see the *Understanding TPE* section for
    more details). The goal of this sub-acquisition function is to sample hyperparameters
    with the highest probability to be the optimum hyperparameters. In other words,
    it is *optimized for exploitation*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2.326`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on candidates suggested by these three sub-acquisition functions, Metis
    will then compute their *information gain* to select the final candidate to be
    included in the next trial. This selection process is done by utilizing the lower
    bound of the GP estimation confidence interval. Metis will measure the difference
    between the lower bound of the interval and the expected mean from GP. The candidate
    that has the highest improvement will be selected as the final candidate.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that Metis can handle non-Gaussian noise in the data because
    of the diagnostic model. The detected outliers made it possible for Metis to resample
    the previously tested hyperparameters so that it is robust to non-Gaussian noise
    as well. This way, Metis can *balance exploration, exploitation, and re-sampling*
    during the hyperparameter tuning process.
  prefs: []
  type: TYPE_NORMAL
- en: To have a better understanding of how Metis works, take a look at the following
    procedure. Note that the following procedure replaces *Steps 6* to *11* in the
    *Introducing BO* section.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. (The first few steps are the same as we saw earlier).
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Initialize several pairs of hyperparameter values and cross-validations
    scores using the LHS method, and store them in *D*.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Fit a GP that acts as a surrogate model, *M*, using the value pairs in *D*.
  prefs: []
  type: TYPE_NORMAL
- en: '8\. Sample the next set of hyperparameters by utilizing the *custom acquisition
    function*, which consists of three sub-acquisition functions:'
  prefs: []
  type: TYPE_NORMAL
- en: Get the current best optimum set of hyperparameters
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the suggested hyperparameters for *exploration* via the LC sub-acquisition
    function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the suggested hyperparameters for *exploitation* via the Parzen estimator
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the suggested hyperparameters to be resampled based on the *detected outliers*
    by the diagnostic model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the *information gain* from each suggested candidate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the candidate that has the highest information gain.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If no candidate is suggested, then pick one random candidate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 9\. Compute the cross-validation score using the objective function, *f*, based
    on the output from *Step 8*. Note that the cross-validation score is computed
    based on the *second random forest model*, whose goal is to learn the relationship
    between the dependent and independent variables from our original problem.
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Add the hyperparameters and cross-validation score pair from *Step 8* and
    *Step 9* to set *D*.
  prefs: []
  type: TYPE_NORMAL
- en: 11\. Repeat *Steps 7* to *10* until the stopping criteria are met.
  prefs: []
  type: TYPE_NORMAL
- en: 12\. (*The last few steps are the same as we saw earlier*).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table lists the pros and cons of utilizing Metis compared to
    other variants of the BO hyperparameter tuning method:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.22 – Pros and cons of Metis'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_022.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.22 – Pros and cons of Metis
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth noting that, unlike other BO variants, there is only one package
    that implements Metis for the hyperparameter tuning method, which is **Microsoft
    NNI**. As you may have noticed, all the variants of BO that were discussed in
    this chapter have the drawback of not being able to exploit parallel computing
    resources. So, why didn’t we put that drawback in the first section instead? Because
    there is a variant of BO, namely BOHB, that can exploit the parallel computing
    resources. We will discuss BOHB in more detail in [*Chapter 6*](B18753_06_ePub.xhtml#_idTextAnchor054),
    *Exploring Multi-Fidelity Optimization*.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered Metis in detail, including, what it is, how it works,
    what makes it different from other BO variants, and its pros and cons.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the second out of four groups of hyperparameter
    tuning methods, called the BO group. We not only discussed BO in general but also
    several of its variants, including BOGP, SMAC, TPE, and Metis. We saw what makes
    each of the variants differ from each other, along with the pros and cons of each.
    At this point, you should be able to explain BO with confidence when someone asks
    you and apply hyperparameter tuning methods in this group with ease.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will start discussing heuristic search, the third group
    of hyperparameter tuning methods. The goal of the next chapter is similar to this
    chapter: to provide a better understanding of the methods that belong to the heuristic
    search group.'
  prefs: []
  type: TYPE_NORMAL
