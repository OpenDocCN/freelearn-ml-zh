- en: '*Chapter 4*: Exploring Bayesian Optimization'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Bayesian optimization** (**BO**) is the second out of four groups of hyperparameter
    tuning methods. Unlike grid search and random search, which are categorized as
    uninformed search methods, all of the methods that belong to the BO group are
    categorized as **informed search** methods, meaning they are learning from previous
    iterations to (hopefully) provide a better search space in the future.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will discuss several methods that belong to the BO group,
    including **Gaussian process** (**GP**), **sequential model-based algorithm configuration**
    (**SMAC**), **Tree-structured Parzen Estimators** (**TPE**), and Metis. Similar
    to [*Chapter 3*](B18753_03_ePub.xhtml#_idTextAnchor031), *Exploring Exhaustive
    Search*, we will discuss the definition of each method, the differences between
    them, how they work, and the pros and cons of each method.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to explain BO and its variations
    when someone asks you. You will not only be able to explain what they are, but
    also how they work, in a high-level and technical way. You will also be able to
    tell the differences between them, along with the pros and cons of each of the
    methods. Furthermore, you will experience a crucial benefit once you understand
    the ins and outs of each method; that is, you will be able to understand what’s
    happening if there are errors or unexpected results and understand how to set
    up the method configuration to match your specific problem.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Introducing BO
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding BO GP
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding SMAC
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding TPE
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Metis
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing BO
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: BO is categorized as an informed search hyperparameter tuning method, meaning
    the search is learning from previous iterations to have a (hopefully) better subspace
    in the next iterations. It is also categorized as the **sequential model-based
    optimization** (**SMBO**) group. All SMBO methods work by sequentially updating
    probability models to estimate the effect of a set of hyperparameters on their
    performance based on historical observed data, as well as suggesting new hyperparameters
    to be tested in the following trials.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: BO is a popular hyperparameter tuning method due to its *data-efficient* property,
    meaning it needs a relatively small number of samples to get to the optimal solution.
    You may be wondering, how exactly does BO get this ground-breaking data-efficient
    property? This property exists thanks to BO’s ability to learn from previous iterations.
    BO can learn and predict which subspace is worth visiting in the future by utilizing
    a **probabilistic regression model**, which acts as the *cheap cloned version
    of the expensive objective function*, and an **acquisition function**, which governs
    which *set of hyperparameters should be tested* in the next iteration.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'The objective function is just a function that takes hyperparameter values
    as input and returns the cross-validation score (see [*Chapter 1*](B18753_01_ePub.xhtml#_idTextAnchor014),
    *Evaluating Machine Learning Models*). We do not know what the output of the objective
    function for all possible hyperparameter values is. If we did, there would be
    no need to perform hyperparameter tuning. We could just use that function to get
    the hyperparameter values, which results in the highest cross-validation score.
    That’s why we need a probabilistic regression model, to approximate the objective
    function by fitting a set of known hyperparameter and cross-validation score value
    pairs (see *Figure 4.1*). The approximation concept is *similar to the concept
    of ML-based regressor* models, such as random forest, linear regression, and many
    more. First, we fit the regressor to the samples of independent and dependent
    variables; then, the model will try to *learn* from the data, which in the end
    can be used to predict new given data. The probabilistic regression model is also
    often called the **surrogate model**:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 目标函数只是一个函数，它接受超参数值作为输入并返回交叉验证分数（参见[*第1章*](B18753_01_ePub.xhtml#_idTextAnchor014)，*评估机器学习模型*）。我们不知道目标函数对所有可能超参数值的输出是什么。如果我们知道，就没有必要进行超参数调整。我们可以直接使用该函数来获取超参数值，这将导致获得最高的交叉验证分数。这就是为什么我们需要一个概率回归模型，通过拟合一组已知的超参数和交叉验证分数值对来近似目标函数（参见*图4.1*）。近似的概念与基于机器学习的回归器模型的概念类似，例如随机森林、线性回归等。首先，我们将回归器拟合到独立变量和依赖变量的样本；然后，模型将尝试*学习*数据，最终可以用来预测新的给定数据。概率回归模型也常被称为**代理模型**：
- en: '![Figure 4.1 – Illustration of the probabilistic regression model, M'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 4.1 – Illustration of the probabilistic regression model, M'
- en: '](img/B18753_04_001.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18753_04_001.jpg](img/B18753_04_001.jpg)'
- en: Figure 4.1 – Illustration of the probabilistic regression model, M
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 – 概率回归模型，M的示意图
- en: The acquisition function *governs which subspace we should search in the next
    iteration*. Thanks to this function, BO enables us to learn from past experiences
    and have fewer hyperparameter tuning iterations compared to random search, in
    general.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 获取函数*控制我们在下一次迭代中应该搜索哪个子空间*。多亏了这个函数，贝叶斯优化（BO）使我们能够从过去的经验中学习，并且与随机搜索相比，通常需要更少的超参数调整迭代。
- en: Important Note
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Remember that, to get the cross-validation score, we need to perform multiple
    training and evaluation processes (see [*Chapter 1*](B18753_01_ePub.xhtml#_idTextAnchor014)*,*
    *Evaluating Machine Learning Models*). This is an *expensive process* when you
    have a big, complex model with a large amount of training data. That’s why the
    acquisition function plays a big role here.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，为了获得交叉验证分数，我们需要执行多次训练和评估过程（参见[*第1章*](B18753_01_ePub.xhtml#_idTextAnchor014)*，*评估机器学习模型*）。当你有一个大型的、复杂的模型以及大量的训练数据时，这是一个*昂贵的流程*。这就是为什么获取函数在这里扮演着重要角色。
- en: 'In general, BO works as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，贝叶斯优化（BO）的工作原理如下：
- en: Split the original full data into train and test sets. (See [*Chapter 1*](B18753_01_ePub.xhtml#_idTextAnchor014)*,*
    *Evaluating Machine Learning Models*).
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将原始完整数据集分为训练集和测试集。（参见[*第1章*](B18753_01_ePub.xhtml#_idTextAnchor014)*，*评估机器学习模型*）
- en: Define the hyperparameter space, *H*, with the accompanied distributions.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义超参数空间，*H*及其伴随的分布。
- en: Define the objective function, *f*, based on the train set.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据训练集定义目标函数，*f*。
- en: Define the stopping criterion. Usually, the number of trials is used. However,
    it is also possible to use the time taken or convergence as the stopping criterion.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义停止标准。通常，使用试验次数。然而，也可以使用时间或收敛性作为停止标准。
- en: Initializes the empty set, *D*, which will be used to store the initial pairs
    of hyperparameter values and cross-validation scores, as well as the resulting
    pairs suggested by the acquisition function, *A*.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个空集合，*D*，该集合将用于存储初始的超参数值对和交叉验证分数，以及由获取函数，*A*建议的结果值对。
- en: Initialize several pairs of hyperparameter values and cross-validation scores
    and store them in *D*.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化几个超参数值对和交叉验证分数，并将它们存储在*D*中。
- en: Fit the probabilistic regression model/surrogate model, *M*, using the value
    pairs in *D*.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*D*中的值对拟合概率回归模型/代理模型，*M*。
- en: 'Sample the next set of hyperparameters by utilizing the acquisition function,
    *A*:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过利用获取函数，*A*，采样下一组超参数：
- en: Perform optimization on the acquisition function, *A*, with the help of the
    surrogate model, *M*, to sample which hyperparameters are to be passed to the
    acquisition function.
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the expected optimal set of hyperparameters based on the acquisition function,
    *A*.
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the cross-validation score using the objective function, *f*, based
    on the output from *Step 8*.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the hyperparameters and cross-validation score pair from *Step 8* and *Step
    9* to set *D*.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *Steps 7* to *10* until the stopping criterion is met.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Trains on the full training set using the final hyperparameter values.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the final trained model on the test set.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can initialize the hyperparameter values and cross-validation scores, as
    shown in *Step 6*, using several sampling strategies. The most straightforward
    and go-to way, in practice, is to just perform **random sampling**. However, there
    are also other methods that you may consider during your experiments, such as
    the **quasi-random** or **Latin hypercube** sampling methods.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Similar to random search, we also need to define the distribution of each hyperparameter
    in BO. You may wonder if BO can also work on a non-numerical type of hyperparameter.
    The answer is *based on the probabilistic regression model* you are using. There
    are several surrogate models you can choose from. Those options will be discussed
    in the next three sections of this chapter, and they include **GP**, **Tree-structured
    Parzen Estimator** (**TPE**), random forest, extra trees, or other ML-based regressors.
    In this book, we will discuss the random forest regressor that’s implemented in
    the SMAC model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth noting that the optimization process in *Step 8* can be *replaced
    with a random search*. So, instead of performing some kind of second-order optimization
    method, we can randomly sample sets of hyperparameters from the search space and
    pass them onto the acquisition function. Then, we can get the optimal set of hyperparameters
    based on the output from the acquisition function. When using random search in
    this step, we still utilize the acquisition function to govern which subspace
    we should search for in the next iteration, but we add some random behavior to
    it, with the hope that we can escape the local optimum and converge toward the
    global optimum.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'The first and the most popular acquisition function is **expected improvement**
    (**EI**), which is defined as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_001.png) when ![](img/Formula_B18753_04_002.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B18753_04_003.png) when ![](img/Formula_B18753_04_004.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_005.png), ![](img/Formula_B18753_04_006.png)
    and ![](img/Formula_B18753_04_007.png) are the cumulative distribution and probability
    density functions of the standard normal distribution, respectively. ![](img/Formula_B18753_04_008.png)
    and ![](img/Formula_B18753_04_009.png) represent the expected performance and
    the uncertainty, respectively, that are captured by the surrogate model. Finally,
    ![](img/Formula_B18753_04_010.png) represents the current best value of the objective
    function.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/Formula_B18753_04_005.png)、![](img/Formula_B18753_04_006.png)和![](img/Formula_B18753_04_007.png)分别表示标准正态分布的累积分布函数和概率密度函数。![](img/Formula_B18753_04_008.png)和![](img/Formula_B18753_04_009.png)分别代表由代理模型捕捉到的预期性能和不确定性。最后，![](img/Formula_B18753_04_010.png)代表目标函数的当前最佳值。
- en: Implicitly, the EI acquisition function enables BO methods to have the *exploration
    versus exploitation trade-off property*. This property can be achieved by two
    terms competing within the formula. When the value of the first term is high,
    meaning the expected performance, ![](img/Formula_B18753_04_011.png), is higher
    than the current best value, ![](img/Formula_B18753_04_012.png), EI will favor
    the exploitation process. On the other hand, when the uncertainty is very high,
    meaning we have a high value of ![](img/Formula_B18753_04_013.png), EI will favor
    the exploration process. By exploitation, this means that the acquisition function
    will recommend the set of hyperparameters that possibly get a higher value of
    the objective function, *f*. In terms of exploration, this means that the acquisition
    function will recommend the set of hyperparameters from the subspace that we haven’t
    explored yet.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 暗示地，EI获取函数使得BO方法具有*探索与利用的权衡特性*。这种特性可以通过公式内的两个术语之间的竞争来实现。当第一个术语的值很高时，意味着预期性能![](img/Formula_B18753_04_011.png)高于当前最佳值![](img/Formula_B18753_04_012.png)，EI将倾向于利用过程。另一方面，当不确定性非常高时，意味着我们有一个高值![](img/Formula_B18753_04_013.png)，EI将倾向于探索过程。通过利用，这意味着获取函数将推荐可能获得目标函数*f*更高值的超参数集。至于探索，这意味着获取函数将推荐来自我们尚未探索的子空间的超参数集。
- en: 'You can imagine this exploration and exploitation trade-off as when you are
    craving some food. Let’s say you want to have lunch with your brother today. Imagine
    the following two scenarios:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将这种探索与利用的权衡想象成当你渴望食物的时候。比如说，你今天想和你的兄弟一起吃午饭。想象以下两种情况：
- en: “Hey bro, let’s have lunch at our favorite restaurant today!”
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “嘿，兄弟，我们今天就去我们最喜欢的餐厅吃午饭吧！”
- en: “Hey bro, have you heard of the new restaurant up there? Why don’t we try it
    for lunch?”
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “嘿，兄弟，你听说过那里的新餐厅吗？我们为什么不去那里吃午饭呢？”
- en: In the first scenario, you choose to eat at your favorite restaurant since you
    are confident that there is nothing wrong with the food and, more importantly,
    you are *confident about the taste of the food and the overall experience* of
    eating at that restaurant. This first scenario best explains what we call the
    exploitation process. In the second scenario, you *don’t have any idea what the
    overall experience* of eating at that new restaurant is. It may be worse than
    your favorite restaurant, but it may also potentially be your new favorite restaurant!
    This is what we call the exploration process.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下，你选择在你最喜欢的餐厅用餐，因为你确信食物没有问题，更重要的是，你对这家餐厅的食物和整体用餐体验*非常有信心*。这个第一种情况最好地解释了我们所说的利用过程。在第二种情况下，你对那家新餐厅的整体用餐体验*一无所知*。它可能比你最喜欢的餐厅差，但也可能成为你新的最爱！这就是我们所说的探索过程。
- en: Important Note
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In some implementations, such as in the **Scikit-optimize** package, there is
    a hyperparameter that enables us to *control how much we are leaning toward exploitation*
    compared to exploration. In Scikit-optimize, the sign of the EI function is negative.
    This is because the package *treats the optimization problem as the minimization
    problem* by default.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些实现中，例如在**Scikit-optimize**包中，有一个超参数可以让我们控制相对于探索，我们有多大的倾向于利用。在Scikit-optimize中，EI函数的符号是负的。这是因为该包默认将优化问题视为最小化问题。
- en: In our previous explanation, we treated the optimization problem as the maximization
    problem since we wanted to get the highest cross-validation score possible. Don’t
    confuse this with the minimization versus maximization problem – just choose what
    best describes the problem you will be facing in practice!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the EI acquisition function that’s implemented in the Scikit-optimize
    package:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_014.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: As you can see in the first term, the value of ![](img/Formula_B18753_04_015.png)
    will control how big our tendency is toward exploitation compared to exploration.
    The smaller the ![](img/Formula_B18753_04_016.png) value is, the more we lean
    toward exploitation. We will learn more about the implementation part of BO using
    Scikit or other packages from [*Chapter 7*](B18753_07_ePub.xhtml#_idTextAnchor062)*,
    Hyperparameter Tuning via Scikit* to [*Chapter 10*](B18753_10_ePub.xhtml#_idTextAnchor092)*,
    Advanced Hyperparameter Tuning with DEAP and Microsoft NNI*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'To get a better understanding of how the exploration and exploitation trade-off
    happens during the hyperparameter tuning phase, let’s look at an example. Let’s
    say, for instance, we are using the GP surrogate model to estimate the following
    objective function. There’s no need to worry about what and how GP works for now;
    we will discuss it in more detail in the next section:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_017.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/Formula_B18753_04_018.png) is a noise that follows the standard
    normal distribution. The following is a plot of this function within the range
    of ![](img/Formula_B18753_04_019.png). Note that, in this example, we are assuming
    that we know what the true objective function is. However, in practice, this function
    is unknown:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Plot of the objective function, f(x)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_002.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.2 – Plot of the objective function, f(x)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say we are using the EI as the acquisition function, setting the number
    of trials as `15`, setting the initial number of points as `5`, and setting the
    ![](img/Formula_B18753_04_020.png) value to `0.01`. You can see how the fitting
    process works for the first five trials in the following figure:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – GP and EI illustration, δ = 0.01'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_003.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.3 – GP and EI illustration, δ = 0.01
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Each row in the preceding figure corresponds to the first until the fifth trial.
    The left column contains information on the objective function (*red dashed line*),
    the GP surrogate model approximation of the objective function (*green dashed
    line*), how sure the approximation is (*green transparent area*), and the observed
    points up to each trial (*red dots*). The right column contains information on
    the EI acquisition function values (*blue line*) and the next point (*blue dot*)
    to be included in the next trials.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Let’s run through each of the rows in *Figure 4.3* so that you understand how
    it works. In the first trial (*see the first row from the top in the left column*),
    we initialize five random sample points – or hyperparameter values, in the context
    of hyperparameter tuning – and fit the GP model based on those five points. Remember
    that the GP model doesn’t know the actual objective function; the only information
    it has is just those five random points. Then (*see the first row from the top
    in the right column*), based on the fitted GP model, we get the value of the EI
    acquisition function across the space. In this case, the space is just a range
    – that is, ![](img/Formula_B18753_04_022.png). We also get the point to be included
    in the next trials, which in this case is around point `0.5`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: In the second trial, we utilize the point suggested by the EI acquisition function
    and fit the GP model again based on the six sample points we have (*see the second
    row from the top in the left column*). If you compare the GP approximation of
    the second trial with the first trial, you will see that it is closer to the true
    objective function. Next (*see the second row from the top in the right column*),
    we repeat the same process, which is to generate the EI function value across
    the space and the point to be included in the next trial. The suggested point
    in this step is around `0.7`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'We keep repeating the same process until the stopping criteria are met, which
    in this case is 15 trials. The following plot shows the result after 15 trials.
    It is much better than the approximation in the first trial (*see the green dashed
    line*)! You can also see that there are some ranges of ![](img/Formula_B18753_04_023.png)
    where the confidence of the GP approximation is high, such as around points `–1.5`
    and `1.6`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Result after 15 trials, δ = 0.01'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_004.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.4 – Result after 15 trials, δ = 0.01
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the preceding plot, the final suggested point, or the hyperparameter
    value, is `–1.5218`, which results in the value of the objective function being
    equal to `–1.9765`. Let’s also look at the convergence plot from the first until
    the last trial. From the following convergence plot, we can see how our surrogate
    model and acquisition function help us get the minimum value of the objective
    function based on all the trials:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Convergence plot'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_005.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.5 – Convergence plot
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s try to change the value of ![](img/Formula_B18753_04_025.png) to
    a lower value than what we had previously to see how the EI acquisition function
    will favor exploitation more than exploration. Let’s set the ![](img/Formula_B18753_04_026.png)
    value to be 1,000 times lower than the previous value. Note that we only change
    the ![](img/Formula_B18753_04_027.png)value and leave the other setups as-is:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – GP and EI illustration, δ = 0.00001'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_006.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.6 – GP and EI illustration, δ = 0.00001
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the EI acquisition function suggested most of the points in
    a range between **0.5** and **1.4**. The acquisition function doesn’t suggest
    exploring the ![](img/Formula_B18753_04_029.png) range, although we can get a
    much lower objective function value in that range. This happens because there
    are no initial random points in that range, and we favor exploitation a lot in
    this example. The following plot shows the final results after 15 trials. In this
    case, we get a worse result when we favor more exploitation over exploration.
    However, this is not always the case. *You have to experiment* since different
    data, different objective functions, a different hyperparameter space, and different
    implementations may result in different conclusions:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Result after 15 trials, δ = 0.00001'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_007.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.7 – Result after 15 trials, δ = 0.00001
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s see what the impact is if we set the ![](img/Formula_B18753_04_031.png)
    value to `100`, which in this case means that we favor exploration more than exploitation.
    Similar to the previous trial, after running 15 trials, we got the following results:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 – Result after 15 trials, δ = 100'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_008.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.8 – Result after 15 trials, δ = 100
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the points that are suggested by the acquisition function (*the
    red dots*) are all over the place. This is because we set such a high ![](img/Formula_B18753_04_033.png)
    value. This means that the acquisition function’s outputs will suggest points
    in the space that haven’t been observed yet. We will learn how to produce the
    plots shown here in [*Chapter 7*](B18753_07_ePub.xhtml#_idTextAnchor062), *Hyperparameter
    Tuning via Scikit*.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Besides the EI acquisition function, there are also other popular acquisition
    functions that you may consider using, including **Probability of Improvement**
    (**PI**) and **Upper Confidence Bound** (**UCB**).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'PI is the acquisition function that existed before EI. It is simpler than EI
    – in fact, the formula of ![](img/Formula_B18753_04_034.png) is derived based
    on the following simple definition of *improvement*:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_035.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
- en: 'The idea of ![](img/Formula_B18753_04_036.png) is to return the size of improvement,
    if there is improvement between the expected performance and the current best
    performance, or just return zero if there is no improvement. Based on ![](img/Formula_B18753_04_037.png),
    we can define PI as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_038.png) when ![](img/Formula_B18753_04_039.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B18753_04_040.png) when ![](img/Formula_B18753_04_041.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: 'The problem with PI is that it will *give the same reward for all sets of hyperparameters*,
    so long as there’s an improvement compared to the current best value, ![](img/Formula_B18753_04_042.png),
    no matter how big the improvement is. This behavior is not very preferable in
    practice since it can *guide us to the local minima and get us stuck in there*.
    If you are familiar with calculus and statistics, you will realize that EI is
    just the expectation over ![](img/Formula_B18753_04_037.png), as shown here:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_044.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_045.png) is the probability density function
    of the standard normal distribution. Unlike PI, the *EI acquisition function will
    take the size of improvement into account*.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the UCB, it is very straightforward compared to others. We have the
    power to control the trade-off between exploration and exploitation by ourselves
    via the ![](img/Formula_B18753_04_046.png)parameter. This acquisition function
    can be defined as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_047.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: As you can see, UCB *doesn’t take into account the current best value* of the
    objective function. It only considers the expected performance and the uncertainty
    captured by the surrogate model. You can control the exploration and exploitation
    trade-off by changing the ![](img/Formula_B18753_04_048.png)value. If you want
    to lean toward exploring the search space, then you can increase the value of
    ![](img/Formula_B18753_04_049.png). However, if you want to focus more on the
    set of hyperparameters that are expected to perform well, then you can decrease
    the value of ![](img/Formula_B18753_04_050.png).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the variations of surrogate model and acquisition functions, there
    are also other variations of BO methods based on modifying the algorithm itself,
    including Metis and **Bayesian optimization and HyperBand** (**BOHB**). We will
    discuss Metis in the *Understanding Metis* section and BOHB in [*Chapter 6*](B18753_06_ePub.xhtml#_idTextAnchor054),
    *Exploring* *Multi-Fidelity Optimization*.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the pros and cons of BO hyperparameter tuning, in general,
    compared to other hyperparameter tuning methods:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9 – Pros and cons of BO'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_009.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.9 – Pros and cons of BO
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: BO can handle expensive objective functions and is more data-efficient and arguably
    better than random search when it has good initial points. You can utilize the
    set of hyperparameters we used for the initial points up to *Step 6* from the
    procedure mentioned at the beginning of this section. However, if you don’t have
    that privileged access, BO still can outperform random search if you give the
    method some more time since it has to build a good surrogate model first from
    scratch, especially if you have a huge hyperparameter space. Once BO has built
    a good surrogate model, it tends to work faster than random search to find the
    optimal set of hyperparameters.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: There is also another way to speed up the relatively slow warm-up process of
    BO. The idea is to adopt a **meta-learning** procedure to initialize the initial
    set of hyperparameters by learning from meta-features in other, similar datasets.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Speeding Up BO’s Warm-Up
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'See the following paper for more information: *Efficient and Robust Automated
    Machine Learning*, by Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost
    Springenberg, Manuel Blum, Frank Hutter ([https://papers.nips.cc/paper/2015/hash/11d0e6287202fced83f79975ec59a3a6-Abstract.html](https://papers.nips.cc/paper/2015/hash/11d0e6287202fced83f79975ec59a3a6-Abstract.html)).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: BO also has a nice feature that random search doesn’t have – the ability to
    control the exploration and exploitation trade-off, as explained previously in
    this section. This feature enables BO to do more than just constantly explore,
    as random search does.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Now that you are aware of what BO is, how it works, what its important components
    are, and the pros and cons of this method, we will dive deeper into the variations
    of BO in the following sections.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Understanding BO GP
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Bayesian optimization Gaussian process** (**BOGP**) is one of the variants
    of the BO hyperparameter tuning method. It is well-known for its good capability
    in describing the objective function. This variant is very popular due to the
    unique *analytically tractable* nature of the surrogate model and its ability
    to produce relatively accurate approximation, even with only a few observed points.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: However, BOGP has limitations. It *only works on continuous hyperparameters*,
    not on the discrete or categorical types of hyperparameters. It is not recommended
    to use BOGP when you need a lot of iterations to get the optimal set of hyperparameters,
    especially when you have a large number of samples. This is BOGP has a ![](img/Formula_B18753_04_051.png)
    runtime, where ![](img/Formula_B18753_04_052.png) is the number of samples. If
    you have *more than 10 hyperparameters* to be optimized, the common belief is
    that BOGP is not the right hyperparameter tuning method for you.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Having GP as the surrogate model means that we utilize GP as the *prior* for
    our objective function. Then, we can utilize the prior along with a *likelihood
    model* to compute the *posterior* that we care about. All of these nerdy terms
    can easily be understood if we are familiar with the famous **Bayes Theorem**.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'Bayes Theorem allows us to calculate the probability of an event, given a specific
    condition, by utilizing our previous knowledge or common belief that we have.
    Formally, Bayes Theorem is defined as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_053.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_054.png)is the event we want to know the probability
    of, and ![](img/Formula_B18753_04_116.png) refers to the specific condition we
    mentioned previously. The left-hand side of the equation, ![](img/Formula_B18753_04_055.png),
    is what we called as the posterior. ![](img/Formula_B18753_04_056.png) is the
    prior and ![](img/Formula_B18753_04_057.png) is what we call the likelihood model.
    Finally, ![](img/Formula_B18753_04_058.png) is just a constant to ensure that
    the resulting value of this formula is bound in the range of ![](img/Formula_B18753_04_059.png).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: To understand Bayes Theorem, let’s walk through an example. Let’s say we want
    to know the probability of you eating at your favorite restaurant, given that
    today’s weather is sunny. In this example, you eating at your favorite restaurant
    is the event we are interested in. This is ![](img/Formula_B18753_04_060.png)
    in the equation. The information that today is sunny refers to ![](img/Formula_B18753_04_117.png)
    in the equation.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you are eating at your favorite restaurant for 40 out of 100 days.
    This means that before knowing what today’s weather is, your ![](img/Formula_B18753_04_061.png)
    is equal to ![](img/Formula_B18753_04_062.png). Let’s also assume that out of
    100 days, there are 30 sunny days. Then, the ![](img/Formula_B18753_04_063.png)
    value is equal to ![](img/Formula_B18753_04_064.png). Based on your experience
    of eating at your favorite restaurant, you have realized that you ate in the sunny
    weather condition 20 out of 40 times. Thus, the likelihood, ![](img/Formula_B18753_04_065.png),
    is equal to ![](img/Formula_B18753_04_066.png). Using all of this information,
    we can calculate the probability of you eating at your restaurant, given that
    today’s weather is sunny, as ![](img/Formula_B18753_04_067.png)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are ready to revisit the GP. BOGP utilizes GP as the surrogate model.
    GP as the surrogate model means that we utilize it as the prior of our objective
    function, which implies that the *posterior distribution is also a GP*. You can
    think of GP as a generalization of a Gaussian distribution that you are familiar
    with. Unlike Gaussian distribution, which describes the distribution of a random
    variable, *GP describes the distribution over functions*. Similar to the Gaussian
    distribution that is accompanied by the mean and variance of the random variable,
    GP is also accompanied by the *mean and covariance* of the function. As for the
    *likelihood*, we assume that the objective function, *f*, follows a normal likelihood
    with noise:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_068.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: '![](img/Formula_B18753_04_069.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: 'Then, we can describe ![](img/Formula_B18753_04_070.png), or the values of
    our objective function for all *n* samples. as a GP with a mean function of ![](img/Formula_B18753_04_071.png)
    and a covariance kernel, ![](img/Formula_B18753_04_072.png), sized *n x n*, which
    is defined as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_073.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
- en: 'The distribution of prediction from GP also follows the Gaussian distribution,
    which can be defined as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_074.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
- en: Here, the value of ![](img/Formula_B18753_04_075.png)and ![](img/Formula_B18753_04_076.png)
    can be *analytically derived from the kernel*, ![](img/Formula_B18753_04_077.png).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, *GP approximates the objective function by following a normal
    distribution assumption*. In practice, GP can also be utilized when we don’t have
    zero mean processes, as per our previous assumption. However, we need to do some
    preprocessing on the values of the objective function to center them to zero.
    Choosing the *right covariance kernel*, ![](img/Formula_B18753_04_078.png), is
    also crucial. It highly impacts the performance of our hyperparameter tuning process.
    The most popular kernel that’s used in practice is the *Matern kernel*. However,
    we must choose the right kernel for our case, since each kernel has a characteristic
    that may or may not be suitable for our objective function. We will discuss the
    kernels that are available in the Scikit package in [*Chapter 7*](B18753_07_ePub.xhtml#_idTextAnchor062),
    *Hyperparameter Tuning via Scikit*.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the list of pros and cons of BOGP compared to other
    variants of the BO hyperparameter tuning method:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10 – Pros and cons of BOGP'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_010.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.10 – Pros and cons of BOGP
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: In the previous section, we saw how GP works in practice, where we discussed
    the exploration and exploitation trade-off. You can revisit that example to get
    a better understanding of how GP works in practice through the help of visualizations.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned about utilizing GP as the surrogate model in BO,
    along with the pros and cons compared to other variants of BO. In the next section,
    we will learn about another variant of BO that utilizes random forest as the surrogate
    model.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Understanding SMAC
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**SMAC** is part of the BO hyperparameter tuning method group and utilizes
    random forest as the surrogate model. This method is optimized to handle discrete
    or categorical hyperparameters. If your hyperparameter space is huge and is dominated
    by discrete hyperparameters, then SMAC is a good choice for you.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Similar to BOGP, SMAC also works by modeling the objective function. Specifically,
    it utilizes random forest as the surrogate model to create an estimation of the
    real objective function, which can then be passed to the acquisition function
    (see the *Introducing BO* section for more details).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Random forest is a **machine learning** (**ML**) algorithm that can be utilized
    in classification or regression tasks. It is built upon a collection of decision
    trees, which is known to perform well with categorical types of features. The
    name random forest comes from the fact that it is built from several decision
    trees. We will discuss random forest, along with its hyperparameters, in more
    detail in [*Chapter 11*](B18753_11_ePub.xhtml#_idTextAnchor110), *Understanding
    Hyperparameters of Popular Algorithms*.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'The main difference between SMAC and BOGP lies in the type of surrogate model
    that’s used in each method. While BOGP utilizes GP as the surrogate model, SMAC
    utilizes random forest as the surrogate model. The acquisition function that was
    used in the original paper on SMAC is the *EI function with some modifications*
    on how the optimization process in *Step 8* in the *Introducing BO* section is
    done, which also can be seen in the following screenshot:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – Optimization process of the acquisition function'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_011.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.11 – Optimization process of the acquisition function
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'In SMAC, similar to BOGP, we are also assuming that the distribution of our
    surrogate model’s *prediction follows the Gaussian distribution*, as shown here:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_079.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
- en: Here, the ![](img/Formula_B18753_04_080.png)and ![](img/Formula_B18753_04_081.png)
    values are derived from the *random forest prediction’s mean and variance*, respectively.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: We can also *utilize random forest to perform hyperparameter tuning on a random
    forest model*! How is this possible? How can a model be used to improve the performance
    of another model of the same type?
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: It is possible because we are treating one model as the surrogate model while
    the other one is the actual model that is fitted to the independent variables
    to predict the dependent variable. As the surrogate model, random forest will
    act as the regressor, which has the goal of learning the relationship between
    the hyperparameter space and the corresponding objective function. So, when we
    said that we are utilizing random forest to perform hyperparameter tuning on a
    random forest model, there are two random forest models with different goals and
    different input-output pairs!
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following steps to get a better understanding of this concept.
    Note that the following procedure replaces *Steps 7* to *11* in the *Introducing
    BO* section:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 6\. (The first few steps are the same as we saw earlier).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Fit the *first random forest model*, which acts as a surrogate model, *M*,
    using the value pairs in *D*. Remember that *D* consists of pairs of hyperparameter
    values and the cross-validation score.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '8\. Sample the next set of hyperparameters by utilizing the acquisition function,
    *A*:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Perform optimization on the acquisition function with the help of the surrogate
    model, *M*, to sample which hyperparameters are to be passed to the acquisition
    function.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the optimal set of hyperparameters based on the acquisition function.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 9\. Compute the cross-validation score using the objective function, *f*, based
    on the output from *Step 8*. Note that the cross-validation score is computed
    based on the *second random forest model*, whose goal is to learn the relationship
    between the dependent and independent variables from our original problem.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Add the hyperparameters and cross-validation score pair from *Step 8* and
    *Step 9* to set *D*.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 11\. Repeat *Steps 7* to *10* until the stopping criteria are met.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 12\. (The last few steps are the same as we saw earlier).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering, why bother utilizing the same ML algorithm as the surrogate
    model? Why don’t we just perform a grid search or random search instead? Remember
    that the surrogate model is just one piece of the full BO algorithm. There is
    also the acquisition function and other optimization steps that can help us get
    the optimal set of hyperparameters faster. It is worth noting that *we can utilize
    any ML model* other than random forest. When it comes to tree-based ML models,
    XGBoost, CatBoost, and LightGBM are also popular among data scientists since they
    work well in practice.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *Introducing BO* section, we saw how GP works with the EI acquisition
    function to estimate a dummy objective function. Let’s use the same dummy objective
    function, as defined here, and see the result of utilizing random forest (not
    necessarily the SMAC algorithm) as the surrogate model instead of GP. We will
    still use EI as the acquisition function in this example and the Scikit-optimize
    package as the implementation:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_082.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_083.png) is a noise that follows the standard
    normal distribution. Please see *Figure 4.2* for a visualization of this dummy
    objective function.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s set the number of trials and the exploitation versus exploration trade-off
    controller, ![](img/Formula_B18753_04_084.png), using the default values given
    by the Scikit-optimize package for the random forest surrogate model, which are
    `100` and `0.01`, respectively. You can see how the random forest surrogate model
    fitting process works for the first five trials in the following figure:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.12 – Random forest and EI illustration; δ = 0.01; trials 1 – 5'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_012.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.12 – Random forest and EI illustration; δ = 0.01; trials 1 – 5
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, not many things happened in the first five trials. Even the
    approximation of the objective function that’s given by the random forest (*see
    the green-dashed line*) is still very bad since it is just a straight line! Let’s
    see what the condition is during trials 71 until 75:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.13 – Random forest and EI illustration; δ = 0.01; trials 71- 75'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_013.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.13 – Random forest and EI illustration; δ = 0.01; trials 71- 75
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that our random forest surrogate model has improved a lot
    in estimating the true objective function. One interesting point is that the acquisition
    function curve looks very different from the one we saw when utilizing GP as the
    surrogate model. Here, the acquisition function looks edgier, just like the one
    we usually see from visualizing random forest. Finally, let’s see what the final
    form of the approximated function is:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.14 – Result after 100 trials; δ = 0.01'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_014.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.14 – Result after 100 trials; δ = 0.01
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that random forest fails to fit the true objective function
    in general, but it succeeds to focus on the local minima of the objective function.
    This happens because *random forest needs a lot of data*, or in this case, the
    observed points (*see red dots*), to have a good approximation of the objective
    function. You can also see the convergence plot of the fitting process, starting
    from the first until the last trial, in the following plot. If we compare *Figure
    4.15* to *Figure 4.5*, we can easily see that, in this example, random forest,
    when supported by the EI acquisition function, learns much slower than GP supported
    by EI:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.15 – Convergence plot'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_015.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.15 – Convergence plot
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: 'From *Figure 4.14*, we can also see that, currently, we are only focusing on
    several ranges and missing the global minima of the dummy objective function,
    which is located around the ![](img/Formula_B18753_04_088.png) range. Let’s see
    if changing the value of ![](img/Formula_B18753_04_089.png) to `100` can solve
    this issue. The expectation is that the EI acquisition function can help the random
    forest surrogate model *explore more* in other ranges of values as well. You can
    see the result of the first five trials in the following figure:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.16 – Random forest and EI illustration; δ = 100; trials 1 – 5'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_016.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.16 – Random forest and EI illustration; δ = 100; trials 1 – 5
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the first five trials of the default ![](img/Formula_B18753_04_091.png)
    value, we still can’t see much of the learning process. Let’s see what the condition
    is during trials 71 until 75:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.17 – Random forest and EI illustration; δ = 100; trials 71 – 75'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_017.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.17 – Random forest and EI illustration; δ = 100; trials 71 – 75
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see a very big difference between *Figure 4.17* and *Figure 4.13*.
    Finally, let’s see what the final form of the approximated function is:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.18 – Result after 100 trials; δ = 100'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_018.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.18 – Result after 100 trials; δ = 100
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: By changing the value of ![](img/Formula_B18753_04_094.png) to `100`, it seems
    that our expectation has been achieved. The approximation from the random forest
    surrogate model (*see the green-dashed line*) is now focusing on more than specific
    ranges. Moreover, we even get a better result compared to GP (see *Figure 4.4*).
    Again, it is worth noting that this is not always the case – you must experiment
    a lot on your own since different data, different objective functions, a different
    hyperparameter space, and different implementations may result in different conclusions.
    We will learn how to implement random forest as the surrogate model and how to
    produce these figures in [*Chapter 7*](B18753_07_ePub.xhtml#_idTextAnchor062),
    *Hyperparameter Tuning via Scikit*.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: There is another method, called **Bayesian optimization inside a Grove** (**BOinG**),
    whose goal is to get the best of both worlds by utilizing random forest and GP
    as surrogate models.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Optimization Inside a Grove
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 'See the following paper for more information: *Searching in the Forest for
    Local Bayesian Optimization*, by Difan Deng and Marius Lindauer ([https://arxiv.org/abs/2111.05834](https://arxiv.org/abs/2111.05834)).'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: BOinG works by using *two-stage optimization* by using global and local models
    to cut down the computational cost and focus more on the promising subspace, respectively.
    In BOinG, random forest is utilized as the global model and GP as the local model.
    The global model is responsible for searching the promising subspace of the local
    model. Thus, a global model should be flexible enough to handle complex problems
    with different types of hyperparameters. Since the local model only searches in
    a promising subspace, it is possible to utilize a more accurate but expensive
    model, such as GP.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table lists the pros and cons of utilizing random forest as a
    surrogate model compared to other variants of the BO hyperparameter tuning method:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.19 – Pros and cons of utilizing random forest as a surrogate model'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_019.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.19 – Pros and cons of utilizing random forest as a surrogate model
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: A conditional hyperparameter is a hyperparameter that will only be utilized
    when a certain condition is met. The tree structure of random forest is very suitable
    for this kind of situation since it can just add another branch of the tree to
    check whether the condition is met or not. The condition is usually just a specific
    value or range of other hyperparameters in the space.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Now that you are aware of SMAC and utilizing random forest as a surrogate model
    in general, in the next section, we will discuss another variant of BO that has
    a different approach in terms of approximating the objective function.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Understanding TPE
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**TPE** is another variant of BO that performs well in general and can be utilized
    for both categorical and continuous types of hyperparameters. Unlike BOGP, which
    has cubical time complexity, TPE runs in linear time. TPE is suggested if you
    have a huge hyperparameter space and have a very tight budget for evaluating the
    cross-validation score.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: The main difference between TPE and BOGP or SMAC is in the way that it models
    the relationship between hyperparameters and the cross-validation score. Unlike
    BOGP or SMAC, which approximate the value of the objective function, or the posterior
    probability, ![](img/Formula_B18753_04_095.png), *TPE works the other way around*.
    It tries to get the optimal hyperparameters based on the condition of the objective
    function, or the likelihood probability, ![](img/Formula_B18753_04_096.png) (see
    the explanation of Bayes Theorem in the *Understanding BO GP* section).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, unlike BOGP or SMAC, which construct a predictive distribution
    over the objective function, TPE tries to utilize the information of the objective
    function to *model the hyperparameter distributions*. To be more precise, when
    the optimization problem is in the form of a *minimization problem*, ![](img/Formula_B18753_04_097.png)
    is defined as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_098.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/Formula_B18753_04_099.png) and ![](img/Formula_B18753_04_100.png)
    are utilized when the value of the objective function is lower or higher than
    the threshold, ![](img/Formula_B18753_04_101.png), respectively. There is no specific
    rule on how to choose the threshold, ![](img/Formula_B18753_04_102.png). However,
    in the **Hyperopt** and **Microsoft NNI** implementations, this threshold is chosen
    based on the TPE’s hyperparameter, ![](img/Formula_B18753_04_103.png), and the
    number of observed points in *D* up to the current trial. The definition of ![](img/Formula_B18753_04_104.png)
    tells us that TPE has two models that act as the learning algorithm based on the
    value of the objective function, which is ruled by the threshold, ![](img/Formula_B18753_04_105.png).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: When the *distribution of hyperparameters is continuous*, TPE will utilize **Gaussian
    mixture models** (**GMMs**), along with the EI acquisition function, to suggest
    the next set of hyperparameters to be tested. If the continuous distribution is
    not a Gaussian distribution, then TPE will convert it to mimic the Gaussian distribution.
    For example, if the specified hyperparameter distribution is the uniform distribution,
    then it will be converted into a truncated Gaussian distribution.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: The probabilities of the different possible outcomes for the multinomial distribution
    within the GMM, and the mean and variance values for the normal distribution within
    the GMM, are generated by the **adaptive Parzen estimator**. This estimator is
    responsible for constructing the two probability distributions, ![](img/Formula_B18753_04_106.png)
    and ![](img/Formula_B18753_04_107.png), based on the mean and variance of the
    normal hyperparameter distribution, as well as the hyperparameter value of all
    observed points in *D* up to the current trial.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: When the *distribution is categorical or discrete*, TPE will convert the categorical
    distribution into a re-weighted categorical and use *weighted random sampling*,
    along with the EI acquisition function, to suggest the expected best set of hyperparameters.
    The weights in the random sampling procedure are generated based on the historical
    counts of the hyperparameter value.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'The EI acquisition function definition in TPE is a bit different from the definition
    we learned about in the *Introducing BO* section. In TPE, we are using Bayes Theorem
    when deriving the EI formula. The simple formulation of the EI acquisition function
    in TPE is defined as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_108.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
- en: The proportionality defined here tells us that to get a high value of EI, we
    need to get a high ![](img/Formula_B18753_04_109.png) ratio. In other words, when
    the optimization problem is in the form of a *minimization problem*, the EI acquisition
    function must suggest more hyperparameters from ![](img/Formula_B18753_04_110.png)
    over ![](img/Formula_B18753_04_111.png). It is the other way around when the optimization
    problem is in the form of a *maximization problem*. For example, when we use accuracy
    to measure the performance of our classification model, then we should sample
    more hyperparameters from ![](img/Formula_B18753_04_112.png) over ![](img/Formula_B18753_04_113.png).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, TPE works as follows. Note that the following procedure describes
    how TPE works for the *minimization problem*. This procedure replaces *Steps 7*
    to *11* in the *Introducing BO* section:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 6\. (The first few steps are the same as we saw earlier).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Divide pairs of hyperparameter values and cross-validation scores in *D*
    into two groups based on the threshold, ![](img/Formula_B18753_04_114.png), namely
    *below* and *above* groups (see *Figure 4.19*).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '8\. Sample the next set of hyperparameters by utilizing the EI acquisition
    function:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: For each group, calculate the probabilities, means, and variances for the GMM
    using the adaptive Parzen estimator (if it’s a continuous type) or weights for
    random sampling (if it’s a categorical type).
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each group, fit the GMM (if it’s a continuous type), or perform random sampling
    (if it’s a categorical type), to sample which hyperparameters will be passed to
    the EI acquisition function.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each group, calculate the probability of those samples being good samples
    (for the below group), or the probability of those samples being bad samples (for
    the above group).
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the expected optimal set of hyperparameters based on the EI acquisition
    function.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 9\. Compute the cross-validation score using the objective function, *f*, based
    on the output from *Step 8*.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Add the hyperparameters and cross-validation score pair from *Step 8* and
    *Step 9* to set *D*.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 11\. Repeat *Steps 7* to *10* until the stopping criteria have been met.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '12\. (The last few steps are the same as we saw earlier):'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.20 – Illustration of groups division in TPE'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_020.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.20 – Illustration of groups division in TPE
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Based on the stated procedure and the preceding plot, we can see that, unlike
    BOGP or SMAC, which constructs a predictive distribution over the objective function,
    TPE tries to utilize the information of the objective function to model the hyperparameter
    distributions. This way, we are not only focusing on the best-observed points
    during the trials – we are focusing on the *distribution of the best-observed
    points* instead.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering why the *Tree-structured* term is within the TPE method’s
    name. This term refers to the conditional hyperparameters that we discussed in
    the previous section. This means that there are hyperparameters in the space that
    will only be utilized when a certain condition is met. We will see what a tree-structured
    or conditional hyperparameter space looks like in [*Chapter 8*](B18753_08_ePub.xhtml#_idTextAnchor074),
    *Hyperparameter Tuning via Hyperopt*, and [*Chapter 9*](B18753_09_ePub.xhtml#_idTextAnchor082),
    *Hyperparameter Tuning via Optuna*.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: One of the drawbacks that TPE has is that it may *overlook the interdependencies
    among hyperparameters* in a certain space since the Parzen estimators work univariately.
    However, this is not the case for BOGP or SMAC, since the surrogate model is constructed
    based on the configurations in the hyperparameter space. Thus, they can take into
    account the interdependencies among hyperparameters. Fortunately, there is an
    implementation of TPE that overcomes this drawback. The **Optuna** package provides
    the **multivariate TPE** implementation, which can take into account the interdependencies
    among hyperparameters.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table lists of pros and cons of utilizing TPE compared to other
    variants of the BO hyperparameter tuning method:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.21 – Pros and cons of TPE'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_021.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.21 – Pros and cons of TPE
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Some implementations support parallel tuning, but with a trade-off between the
    suggested hyperparameter quality and the wall time. The Microsoft NNI package
    supports this feature via the `constant_liar_type` argument, which will be discussed
    in more detail in [*Chapter 10*](B18753_10_ePub.xhtml#_idTextAnchor092), *Advanced
    Hyperparameter Tuning with DEAP and Microsoft NNI*.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned about TPE, along with its pros and cons compared
    to other variants of BO. In the next section, we will learn about another variant
    of BO that has a slightly modified algorithm compared to the BO method in general.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Metis
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metis is one of the variants of BO that has several algorithm modifications
    compared to the BO method in general. Metis utilizes GP and GMM in its algorithm.
    GP is used as the surrogate model and outliers detector, while GMM is used as
    part of the acquisition function, similar to TPE.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: What makes Metis different from other BO methods, in general, is that it can
    *balance exploration and exploitation more data-efficiently* than the EI acquisition
    function. It can also *handle noise in the data that doesn’t follow the Gaussian*
    distribution, and this is the case most of the time. Unlike most of the methods
    that perform random sampling to initialize the set of hyperparameters and cross-validation
    score, *D*, Metis utilizes **Latin Hypercube Sampling** (**LHS**), which is a
    stratified sampling procedure based on the equal interval of each hyperparameter.
    This sampling method is believed to be more data-efficient compared to random
    sampling to achieve the same exploration coverage.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'So, how can Metis balance exploration and exploitation more efficiently than
    the EI acquisition function, in terms of the needs of the observed points? This
    is achieved through the *custom acquisition function* that Metis has, which consists
    of three sub-acquisition functions, as shown here:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '**Lowest confidence** (**LC**): This sub-acquisition function’s goal is to
    sample hyperparameters with the highest uncertainty. In other words, the goal
    of this sub-acquisition function is to *maximize exploration*. This function is
    defined as follows:'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/Formula_B18753_04_115.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
- en: '**Parzen estimator**: This sub-acquisition function is inspired by the TPE
    method, which utilizes GMM to estimate how likely the sampled hyperparameter is
    part of the *below* or *above* group (see the *Understanding TPE* section for
    more details). The goal of this sub-acquisition function is to sample hyperparameters
    with the highest probability to be the optimum hyperparameters. In other words,
    it is *optimized for exploitation*.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2.326`.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on candidates suggested by these three sub-acquisition functions, Metis
    will then compute their *information gain* to select the final candidate to be
    included in the next trial. This selection process is done by utilizing the lower
    bound of the GP estimation confidence interval. Metis will measure the difference
    between the lower bound of the interval and the expected mean from GP. The candidate
    that has the highest improvement will be selected as the final candidate.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that Metis can handle non-Gaussian noise in the data because
    of the diagnostic model. The detected outliers made it possible for Metis to resample
    the previously tested hyperparameters so that it is robust to non-Gaussian noise
    as well. This way, Metis can *balance exploration, exploitation, and re-sampling*
    during the hyperparameter tuning process.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: To have a better understanding of how Metis works, take a look at the following
    procedure. Note that the following procedure replaces *Steps 6* to *11* in the
    *Introducing BO* section.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 5\. (The first few steps are the same as we saw earlier).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Initialize several pairs of hyperparameter values and cross-validations
    scores using the LHS method, and store them in *D*.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Fit a GP that acts as a surrogate model, *M*, using the value pairs in *D*.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '8\. Sample the next set of hyperparameters by utilizing the *custom acquisition
    function*, which consists of three sub-acquisition functions:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: Get the current best optimum set of hyperparameters
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the suggested hyperparameters for *exploration* via the LC sub-acquisition
    function
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the suggested hyperparameters for *exploitation* via the Parzen estimator
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the suggested hyperparameters to be resampled based on the *detected outliers*
    by the diagnostic model.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the *information gain* from each suggested candidate.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the candidate that has the highest information gain.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If no candidate is suggested, then pick one random candidate.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 9\. Compute the cross-validation score using the objective function, *f*, based
    on the output from *Step 8*. Note that the cross-validation score is computed
    based on the *second random forest model*, whose goal is to learn the relationship
    between the dependent and independent variables from our original problem.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Add the hyperparameters and cross-validation score pair from *Step 8* and
    *Step 9* to set *D*.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: 11\. Repeat *Steps 7* to *10* until the stopping criteria are met.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 12\. (*The last few steps are the same as we saw earlier*).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table lists the pros and cons of utilizing Metis compared to
    other variants of the BO hyperparameter tuning method:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.22 – Pros and cons of Metis'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18753_04_022.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.22 – Pros and cons of Metis
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth noting that, unlike other BO variants, there is only one package
    that implements Metis for the hyperparameter tuning method, which is **Microsoft
    NNI**. As you may have noticed, all the variants of BO that were discussed in
    this chapter have the drawback of not being able to exploit parallel computing
    resources. So, why didn’t we put that drawback in the first section instead? Because
    there is a variant of BO, namely BOHB, that can exploit the parallel computing
    resources. We will discuss BOHB in more detail in [*Chapter 6*](B18753_06_ePub.xhtml#_idTextAnchor054),
    *Exploring Multi-Fidelity Optimization*.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered Metis in detail, including, what it is, how it works,
    what makes it different from other BO variants, and its pros and cons.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the second out of four groups of hyperparameter
    tuning methods, called the BO group. We not only discussed BO in general but also
    several of its variants, including BOGP, SMAC, TPE, and Metis. We saw what makes
    each of the variants differ from each other, along with the pros and cons of each.
    At this point, you should be able to explain BO with confidence when someone asks
    you and apply hyperparameter tuning methods in this group with ease.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will start discussing heuristic search, the third group
    of hyperparameter tuning methods. The goal of the next chapter is similar to this
    chapter: to provide a better understanding of the methods that belong to the heuristic
    search group.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
