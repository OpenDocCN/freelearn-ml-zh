- en: '*Chapter 6*: Alerting on ML Analysis'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第六章*：基于机器学习分析的警报'
- en: The previous chapter ([*Chapter 5*](B17040_05_Epub_AM.xhtml#_idTextAnchor090)*,
    Interpreting Results*) explained in depth how anomaly detection and forecasting
    results are stored in Elasticsearch indices. This gives us the proper background
    to now create proactive, actionable, and informative alerts on those results.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 前一章（[*第五章*](B17040_05_Epub_AM.xhtml#_idTextAnchor090)*，结果解释*）深入讲解了异常检测和预测结果是如何存储在Elasticsearch索引中的。这为我们现在创建主动的、可操作的、信息丰富的警报提供了适当的背景。
- en: At the time of writing this book, we find ourselves at an inflection point.
    For several years, Elastic ML has relied on the alerting capabilities of Watcher
    (a component of Elasticsearch) as this was the exclusive mechanism to alert on
    data. However, a new platform of alerting has been designed as part of Kibana
    (and was deemed GA in v7.11) and this new approach will be the primary mechanism
    of alerting moving forward.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，我们发现我们正处于一个转折点。多年来，Elastic ML一直依赖于Watcher（Elasticsearch的一个组件）的警报功能，因为这是唯一可以针对数据进行警报的机制。然而，一个新的警报平台已经被设计为Kibana的一部分（并在v7.11中被认为是GA），这种新的方法将成为未来警报的主要机制。
- en: There are still some interesting pieces of functionality that Watcher can provide
    that are not yet available in Kibana alerting. As such, this chapter will showcase
    the usage of alerts using both Kibana alerting and Watcher. Depending on your
    needs, you can decide which approach you would like to use.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Watcher仍然提供一些有趣的功能，这些功能在Kibana警报中尚未提供。因此，本章将展示使用Kibana警报和Watcher创建警报的使用方法。根据您的需求，您可以选择您想使用的方法。
- en: 'Specifically, this chapter will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，本章将涵盖以下主题：
- en: Understanding alerting concepts
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解警报概念
- en: Building alerts from the ML UI
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从机器学习UI构建警报
- en: Creating alerts with a watch
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用watch创建警报
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The information in this chapter will use the Elastic Stack as it exists in v7.12\.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的信息将使用v7.12版本的Elastic Stack。
- en: Understanding alerting concepts
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解警报概念
- en: Hopefully, without running the risk of being overly pedantic, a few declarations
    can be made here about alerting and how certain aspects of alerting (especially
    with respect to anomaly detection) are extremely important to understand before
    we get into the mechanics of configuring those alerts.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 希望不会过于咬文嚼字，这里可以提出一些关于警报和某些警报方面（尤其是关于异常检测）的重要性声明，在我们深入研究配置这些警报的机制之前，这些方面是非常重要的。
- en: Anomalies are not necessarily alerts
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常不一定是警报
- en: This needs to be explicitly said. Often, users who first embrace anomaly detection
    feel compelled to alert on everything once they realize that you can alert on
    anomalies. This is potentially a really challenging situation if anomaly detection
    is deployed across hundreds, thousands, or even tens of thousands of entities.
    Anomaly detection, while certainly liberating users from having to define specific,
    rule-driven exceptions or hardcoded thresholds from alerts, also has the potential
    to be deployed broadly across a lot of data. We need to be cognizant that detailed
    alerting on every little anomaly could be potentially quite noisy if we're not
    careful.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要明确指出。通常，最初接受异常检测的用户一旦意识到可以针对异常发出警报，就会感到有必要对一切发出警报。如果异常检测部署在数百、数千甚至数万个实体上，这可能会是一个极具挑战性的情况。异常检测虽然确实可以释放用户从定义特定的、基于规则的异常或硬编码的阈值警报中解脱出来，但也可能在大规模数据中广泛部署。我们需要意识到，如果我们不小心，对每一个小异常的详细警报可能会非常嘈杂。
- en: 'Fortunately, there are a few mechanisms that we''ve already learned about in
    [*Chapter 5*](B17040_05_Epub_AM.xhtml#_idTextAnchor090)*, Interpreting Results*,
    that help us mitigate such a situation:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们在[*第五章*](B17040_05_Epub_AM.xhtml#_idTextAnchor090)*，结果解释*中已经了解了一些机制，这些机制有助于我们减轻这种情况：
- en: '**Summarization**: We learned that anomalousness is not only reported for individual
    anomalies (at the "record level") but is also summarized at the bucket level and
    influencer level. These summary scores can facilitate alerting at a higher level
    of abstraction if we so desire.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总结**：我们了解到异常性不仅报告了单个异常（在“记录级别”），还在桶级别和影响因素级别进行了总结。如果我们愿意，这些总结分数可以促进更高层次的抽象警报。'
- en: '**Normalized** **scoring**: Because every anomaly detection job has a custom
    normalization scale that is purpose-built for the specific detector configuration
    and dataset being analyzed, it means that we can leverage the normalized scoring
    that comes out of Elastic ML to rate-limit the typical alerting cadence. Perhaps
    for a specific job that you create, alerting at a minimum anomaly score of 10
    will typically give about a dozen alerts per day, a score of 50 will give about
    one per day, and a score of 90 will give about one alert per week. In other words,
    you can effectively tune the alerting to your own tolerance for the number of
    alerts you''d prefer to get per unit of time (of course, except for the case of
    an unexpected system-wide outage, which may create more alerts than usual).'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化** **评分**：由于每个异常检测作业都有一个定制的标准化范围，它是专门为特定的检测配置和正在分析的数据集构建的，这意味着我们可以利用Elastic
    ML输出的标准化评分来限制典型的警报频率。也许对于您创建的特定作业，以至少10分的异常分数进行警报通常每天会收到大约一打警报，50分的分数每天会收到大约一个警报，90分的分数每周会收到大约一个警报。换句话说，您可以有效地调整警报，以适应您对每单位时间内希望接收的警报数量的容忍度（当然，除了意外系统级故障的情况，这可能会产生比平时更多的警报）。'
- en: '**Correlation**/**combination**: Perhaps alerting on a single metric anomaly
    (a host''s CPU being abnormally high) is not as compelling as a group of related
    anomalies (CPU is high, free memory is low, and response time is also high). Alerting
    on compound events or sequences may be more meaningful for some situations.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关性**/**组合**：也许对单个指标异常（例如，主机的CPU异常高）的警报不如对一组相关异常（CPU高、空闲内存低、响应时间也高）的警报有说服力。在某些情况下，对复合事件或序列的警报可能更有意义。'
- en: The bottom line is that even though there isn't a one-size-fits-all philosophy
    about the best way to structure alerting and increase the effectiveness of alerts,
    there are some options available to the user in order to choose what may be right
    for you.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 事实是，尽管没有一种适合所有情况的哲学来结构警报并提高警报的有效性，但用户仍然有一些选项可供选择，以确定最适合您的方法。
- en: In real-time alerting, timing matters
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在实时警报中，时间很重要
- en: Back in [*Chapter 2*](B17040_02_Epub_AM.xhtml#_idTextAnchor033)*, Enabling and
    Operationalization*, we learned that anomaly detection jobs are a relatively complex
    orchestration of querying of raw data, analyzing that data, and reporting of the
    results as an ongoing process that can run in near real time. As such, there were
    a few key aspects of the job's configuration that determined the cadence of that
    process, namely the `bucket_span`, `frequency`, and `query_delay` parameters.
    These parameters define when results are "available" and what timestamp the values
    will have. This is extremely important because alerting on anomaly detection jobs
    will involve a subsequent query to the results indices (`.ml-anomalies-*`), and
    clearly, when that query is run and what time range is used matters whether or
    not you actually find the anomalies you are looking for.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第2章*](B17040_02_Epub_AM.xhtml#_idTextAnchor033)*，启用和实施*中，我们了解到异常检测作业是一个相对复杂的原始数据查询、数据分析以及结果报告的持续过程，这个过程可以在接近实时的情况下运行。因此，作业配置的几个关键方面决定了该过程的节奏，即`bucket_span`、`frequency`和`query_delay`参数。这些参数定义了结果何时“可用”以及值将具有哪个时间戳。这一点非常重要，因为对异常检测作业的警报将涉及对结果索引（`.ml-anomalies-*`）的后续查询，显然，查询何时运行以及使用的时间范围将决定您是否真正找到了所寻找的异常。
- en: 'To illustrate, let''s look at the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，让我们看看以下内容：
- en: '![Figure 6.1 – A representation of the bucket span, query delay, and frequency
    with respect to now'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.1 – 当前时间下桶跨度、查询延迟和频率的表示'
- en: '](img/B17040_06_1.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_06_1.jpg)'
- en: Figure 6.1 – A representation of the bucket span, query delay, and frequency
    with respect to now
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 当前时间下桶跨度、查询延迟和频率的表示
- en: In *Figure 6.1*, we see that a particular bucket of time (represented by the
    width of time equal to *t2-t1*), lags the current system time (`query_delay`.
    Within the bucket, there may be subdivisions of time, as defined by the `frequency`
    parameter. With respect to how the results of this bucket are written to the results
    indices (`.ml-anomalies-*`), we should remember that the timestamp of the documents
    written for this bucket will all have a `timestamp` value equal to the time at
    *t1*, the leading edge of the bucket.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图6.1*中，我们看到一个特定的时间桶（由等于*t2-t1*的时间宽度表示），滞后于当前系统时间（`query_delay`）。在桶内，可能存在由`frequency`参数定义的时间细分。关于这个桶的结果如何写入结果索引（`.ml-anomalies-*`），我们应该记住，为这个桶编写的文档的`timestamp`值都将等于桶的前沿时间*t1*。
- en: 'To make a practical example for discussion, let''s imagine the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了讨论一个实际例子，让我们想象以下情况：
- en: '`bucket_span` = 15 minutes'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bucket_span` = 15分钟'
- en: '`frequency` = 15 minutes'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frequency` = 15分钟'
- en: '`query_delay` = 2 minutes'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query_delay` = 2分钟'
- en: If `query_delay`) and the results document was written into `.ml-anomalies-*`
    soon after (but written with a timestamp equal to 11:45 A.M.). Therefore, if at
    12:05 P.M. we looked into `.ml-anomalies-*` to see whether results were there
    for 11:45 A.M., we would be pretty confident they would exist, and we could inspect
    the content. However, if **now** were only 12:01 P.M., the results documents for
    the bucket corresponding to 11:45 A.M.-12:00 P.M. would not yet exist and wouldn't
    be written for another minute or so. We can see that the timing of things is very
    important.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`query_delay`）并且结果文档在不久之后写入`.ml-anomalies-*`（但带有11:45 A.M.的时间戳）。因此，如果在12:05
    P.M.我们查看`.ml-anomalies-*`以查看11:45 A.M.的结果是否存在，我们相当有信心它们会存在，并且我们可以检查内容。然而，如果**现在**只有12:01
    P.M.，那么对应于11:45 A.M.-12:00 P.M.的桶的结果文档尚不存在，并且将在大约一分钟之后写入。我们可以看到，事情的时间安排非常重要。
- en: If in our example scenario, we instead had reduced the value of `frequency`
    to 7.5 minutes or 5 minutes, then we would indeed have access to the results of
    the bucket "sooner," but the results would be marked as **interim** and are subject
    to change when the bucket is finalized.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在我们的示例场景中，我们将`frequency`的值降低到7.5分钟或5分钟，那么我们确实可以更早地访问桶的结果，但结果会被标记为**临时**，并且当桶最终确定时，结果可能会发生变化。
- en: Note
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Interim results are created within a bucket if the frequency is a sub-multiple
    of the bucket span, but not all detectors make interim results. For example, if
    you have a `max` or `high_count` detector, then an interim result that shows a
    higher-than-expected value over the typical value is possible and sensible – you
    don't need to see the contents of the entire bucket to know that you've already
    exceeded expectations. However, if you have a `mean` detector, you really do need
    to see that entire bucket's worth of observations before determining the average
    value – therefore, interim results are not produced because they are not sensible.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果频率是桶跨度的一个子倍数，则会在桶内创建临时结果，但并非所有检测器都生成临时结果。例如，如果你有一个`max`或`high_count`检测器，那么显示高于典型值的临时结果是有可能且合理的——你不需要看到整个桶的内容就能知道你已经超过了预期。然而，如果你有一个`mean`检测器，你确实需要在确定平均值之前看到整个桶的观测值——因此，不会生成临时结果，因为它们没有意义。
- en: 'So, with that said, if we now take the diagram from *Figure 6.1* and advance
    time a little, but also draw the buckets before and after this one, it will look
    like the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，说到这里，如果我们现在从*图6.1*的图中稍微推进时间，但也画出这个桶之前和之后的桶，它看起来会像以下这样：
- en: '![Figure 6.2 – A representation of consecutive buckets'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.2 – 连续桶的表示'
- en: '](img/B17040_06_2.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17040_06_2.jpg]'
- en: Figure 6.2 – A representation of consecutive buckets
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 连续桶的表示
- en: Here in *Figure 6.2*, we see that the current system time (again, denoted by
    `is_interim:true` flag as first shown in [*Chapter 5*](B17040_05_Epub_AM.xhtml#_idTextAnchor090)*,
    Interpreting Results*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*图6.2*中，我们看到当前系统时间（再次，由`is_interim:true`标志表示，如[*第五章*](B17040_05_Epub_AM.xhtml#_idTextAnchor090)*，解释结果*中首次展示）。
- en: 'If we wanted to invoke an alert search that basically asked the question, "Are
    there any new anomalies created since last time I looked?" and the time that we
    invoked that search was done at the time that is **now** in *Figure 6.2*, then
    we should notice the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要调用一个基本询问“自上次我查看以来是否有任何新的异常产生？”的警报搜索，并且我们调用该搜索的时间是在*图6.2*中所示的时间**现在**，那么我们应该注意以下情况：
- en: The "look back" period of time should be about twice the width of `bucket_span`.
    This is because this guarantees that we will see any interim results that may
    be published for the current bucket (here **bucket t2**) and any finalized results
    for the previous bucket (here **bucket t1**). Results from **bucket t0** will
    not be matched because the timestamp for **bucket t0** is outside of the window
    of time queried – this is okay as long as we get the alert query to repeat on
    a proper schedule (see the following point).
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “回顾”的时间段应该是 `bucket_span` 宽度的两倍左右。这是因为这保证了我们将看到当前时间桶（此处为 **bucket t2**）可能发布的任何中间结果，以及前一个时间桶（此处为
    **bucket t1**）的任何最终结果。来自 **bucket t0** 的结果将不会匹配，因为 **bucket t0** 的时间戳在查询的时间窗口之外——只要我们确保警报查询能够按照适当的计划重复执行（参见以下要点）。
- en: The time chosen to run this query could fall practically anywhere within bucket
    *t2*'s window of time and this will still work as described. This is important
    because the schedule at which the alert query runs will likely be asynchronous
    to the schedule that the anomaly detection job is operating (and writing results).
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行此查询选择的时间可能几乎在任何时间桶 *t2* 的时间窗口内，并且这仍然会按描述的方式工作。这很重要，因为警报查询的运行计划可能与异常检测作业运行的计划（以及写入结果）不同步。
- en: We would likely schedule our alert search to repeat its operation at most at
    an interval equal to `bucket_span`, but it could be executed more frequently if
    we're interested in catching interim anomalies in the current, not-yet-fiinalized
    bucket.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可能会将警报搜索的重复操作间隔安排在等于 `bucket_span` 的最大间隔内，但如果我们对捕捉当前尚未最终确定的时间桶中的中间异常感兴趣，它可能会更频繁地执行。
- en: If we didn't want to consider interim results, we would need to modify the query
    such that `is_interim:false` was part of the query logic to not match them.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们不希望考虑中间结果，我们需要修改查询，使得 `is_interim:false` 成为查询逻辑的一部分，以避免匹配它们。
- en: Given all of these conditions, you might think that there is some type of dark
    magic that is required to get this working correctly and reliably. Fortunately,
    when we build the alerts using Kibana from the Elastic ML UI, these considerations
    are taken care of for you. However, if you feel like you are a wizard and fully
    understand how this all works, then you may not be too intimidated by the prospect
    of building very custom alert conditions using Watcher, where you will have complete
    control.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些条件，你可能会认为需要某种类型的黑暗魔法才能正确且可靠地实现这一点。幸运的是，当我们使用 Elastic ML UI 从 Kibana 构建警报时，这些考虑因素会为你处理。然而，如果你觉得自己是一位巫师并且完全理解这一切是如何工作的，那么你可能不会对使用
    Watcher 构建非常定制的警报条件感到太害怕，在那里你将拥有完全的控制权。
- en: In the following main sections, we'll do some examples using each method so
    that you can compare and contrast how they work.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下主要部分中，我们将使用每种方法进行一些示例，以便您可以比较和对比它们的工作方式。
- en: Building alerts from the ML UI
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 ML UI 构建警报
- en: With the release of v7.12, Elastic ML changed its default alert handler from
    Watcher to Kibana alerting. Prior to v7.12, the user had a choice of accepting
    a default **watch** (an instance of a script for Watcher) if alerting was selected
    from the ML UI, or the user could create a watch from scratch. This section will
    focus on the new workflow using Kibana alerting as of v7.12, which offers a nice
    balance of flexibility and ease of use.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 v7.12 版本的发布，Elastic ML 将其默认警报处理程序从 Watcher 更改为 Kibana 警报。在 v7.12 之前，如果用户从
    ML UI 选择警报，可以选择接受默认的 **watch**（Watcher 脚本的一个实例），或者用户可以从头创建一个 watch。本节将重点介绍自 v7.12
    以来使用 Kibana 警报的新工作流程，它提供了灵活性和易用性之间的良好平衡。
- en: To create a working, illustrative example of real-time alerting, we will contrive
    a scenario using the Kibana sample web logs dataset that we first used in [*Chapter
    3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049)*, Anomaly Detection.*
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '为了创建一个工作且具有说明性的实时警报示例，我们将使用 Kibana 样本网络日志数据集构建一个场景，这是我们首先在 [*第 3 章*](B17040_03_Epub_AM.xhtml#_idTextAnchor049)*，异常检测*
    中使用的。 '
- en: 'The process outlined in this section will be as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本节概述的过程如下：
- en: Define some sample anomaly detection jobs on the sample data.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在样本数据上定义一些样本异常检测作业。
- en: Define two alerts on two of the anomaly detection jobs.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在两个异常检测作业上定义两个警报。
- en: Run a simulation of anomalous behavior, to catch that behavior in an alert.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行异常行为的模拟，以便在警报中捕捉这种行为。
- en: Let's first define the sample anomaly detection jobs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先定义一些样本异常检测作业。
- en: Defining sample anomaly detection jobs
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义样本异常检测作业
- en: Of course, before we can build alerts, we need jobs running in real time. We
    can leverage the sample ML jobs that come with the same Kibana web logs dataset.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在我们能够构建警报之前，我们需要实时运行的工作。我们可以利用与同一Kibana网络日志数据集一起提供的示例ML工作。
- en: Note
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you still have this dataset loaded in your cluster, you should delete it
    and re-add it. This will reset the timestamps on the dataset so that about half
    of the data will be in the past and the rest will be in the future. Having some
    data in the future will allow us to pretend that data is appearing in real time
    and therefore our real-time anomaly detection jobs and our alerts on those jobs
    will act like they are truly real time.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仍然在你的集群中加载了这个数据集，你应该删除它并重新添加。这将重置数据集的时间戳，使得大约一半的数据在过去，另一半在将来。有一些数据在未来将允许我们假装数据是实时出现的，因此我们的实时异常检测工作和针对这些工作的警报将表现得像是真正的实时。
- en: 'To get started, let''s reload the sample data and build some sample jobs:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，让我们重新加载示例数据并构建一些示例工作：
- en: From the Kibana home screen, click on **Try our sample data**:![Figure 6.3 –
    Kibana home screen
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Kibana首页，点击**尝试我们的示例数据**：![图6.3 – Kibana首页
- en: '](img/B17040_06_3.jpg)'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_3.jpg)'
- en: Figure 6.3 – Kibana home screen
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.3 – Kibana首页
- en: Click on **Index Patterns** in the **Sample web logs** section (if already loaded,
    please remove and re-add):![Figure 6.4 – Add sample web logs data
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**示例网络日志**部分点击**索引模式**（如果已经加载，请删除并重新添加）：![图6.4 – 添加示例网络日志数据
- en: '](img/B17040_06_4.jpg)'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_4.jpg)'
- en: Figure 6.4 – Add sample web logs data
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.4 – 添加示例网络日志数据
- en: Under the **View data** menu, select **ML jobs** to create some sample jobs:![Figure
    6.5 – Selecting to create some sample ML jobs
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**查看数据**菜单下，选择**ML工作**来创建一些示例工作：![图6.5 – 选择创建一些示例ML工作
- en: '](img/B17040_06_5.jpg)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_5.jpg)'
- en: Figure 6.5 – Selecting to create some sample ML jobs
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.5 – 选择创建一些示例ML工作
- en: Give the three sample jobs a job ID prefix (here `alert-demo-` was chosen) and
    make sure you de-select Use full `kibana_sample_data_logs` data and pick the end
    time to be the closest 15 minutes to your current system time (in your time zone):![Figure
    6.6 – Naming the sample jobs with a prefix and selecting now as the end time
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给三个示例工作分配一个工作ID前缀（这里选择了`alert-demo-`），并确保你取消选择使用完整的`kibana_sample_data_logs`数据，并选择结束时间为你当前系统时间（在你所在的时区）最近的15分钟：![图6.6
    – 使用前缀命名示例工作并选择当前时间作为结束时间
- en: '](img/B17040_06_6.jpg)'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_6.jpg)'
- en: Figure 6.6 – Naming the sample jobs with a prefix and selecting now as the end
    time
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.6 – 使用前缀命名示例工作并选择当前时间作为结束时间
- en: Notice in *Figure 6.6* that **Apr 8, 2021 @ 11:00:00.00** was chosen as the
    end time and that a date of 11 days earlier (**Mar 28, 2021 @ 00:00:00.00**) was
    chosen as the start time (the sample data goes back about 11 days from when you
    install it). The current local time at the time of this screenshot was 11:10 A.M.
    on April 8th. This is important in the spirit of trying to make this sample data
    seem real time. Click the **Create Jobs** button to set the job creation in motion.
    Once the jobs are created, you will see the following screen:![Figure 6.7 – Sample
    jobs completed initial run
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意在*图6.6*中，**2021年4月8日 11:00:00.00**被选为结束时间，而11天前的日期（**2021年3月28日 00:00:00.00**）被选为开始时间（示例数据从你安装它的时候开始大约11天）。这个截图的时间是4月8日上午11:10。这在尝试使这个示例数据看起来是实时数据的精神上很重要。点击**创建工作**按钮开始工作创建。一旦工作创建完成，你将看到以下屏幕：![图6.7
    – 示例工作完成初始运行
- en: '](img/B17040_06_7.jpg)'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_7.jpg)'
- en: Figure 6.7 – Sample jobs completed initial run
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.7 – 示例工作完成初始运行
- en: We don't need to view the results just yet. Instead, we need to make sure these
    three jobs are running in real time. Let's click **Anomaly Detection** at the
    top to return us to the **Job** **Management** page. There we can see our three
    jobs have analyzed some data but are now in the closed state with the data feeds
    currently stopped:![Figure 6.8 – Sample jobs in the Jobs Management screen
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在还不需要查看结果。相反，我们需要确保这三个工作正在实时运行。让我们点击顶部的**异常检测**返回到**工作** **管理**页面。在那里我们可以看到我们的三个工作已经分析了一些数据，但现在处于关闭状态，数据源目前已停止：![图6.8
    – 工作管理屏幕中的示例工作
- en: '](img/B17040_06_8.jpg)'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_8.jpg)'
- en: Figure 6.8 – Sample jobs in the Jobs Management screen
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.8 – 工作管理屏幕中的示例工作
- en: Now we need to enable these three jobs to run in real time. Click the boxes
    next to each job, and then select the gear icon to bring up the menu to choose
    **Start data feeds** for all three jobs:![Figure 6.9 – Starting the datafeed for
    all three sample jobs
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要启用这三个作业以实时运行。点击每个作业旁边的方框，然后选择齿轮图标以弹出菜单来为所有三个作业选择**启动数据流**：![图 6.9 – 启动所有三个示例作业的数据流
- en: '](img/B17040_06_9.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_9.jpg)'
- en: Figure 6.9 – Starting the datafeed for all three sample jobs
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.9 – 启动所有三个示例作业的数据流
- en: In the pop-up window, choose the top option for both **Search start time** and
    **Search end time**, ensuring that the job will continue to run in real time.
    For now, we will leave **Create alert after datafeed has started** unchecked as
    we will create our own alerts in just a moment:![Figure 6.10 – Starting the data
    feeds of the three sample jobs to run in real time
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在弹出窗口中，选择**搜索开始时间**和**搜索结束时间**的最高选项，确保作业将继续实时运行。现在，我们将保留**数据流启动后创建警报**未勾选，因为我们将在稍后创建自己的警报：![图
    6.10 – 启动三个示例作业的数据流以实时运行
- en: '](img/B17040_06_10.jpg)'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_10.jpg)'
- en: Figure 6.10 – Starting the data feeds of the three sample jobs to run in real
    time
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.10 – 启动三个示例作业的数据流以实时运行
- en: 'After clicking the **Start** button, we will see that our three jobs are now
    in the opened/started state:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**启动**按钮后，我们会看到我们的三个作业现在处于打开/启动状态：
- en: '![Figure 6.11 – Sample jobs now running in real time'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.11 – 示例作业现在实时运行'
- en: '](img/B17040_06_11.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_06_11.jpg)'
- en: Figure 6.11 – Sample jobs now running in real time
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.11 – 示例作业现在实时运行
- en: Now that we have our jobs up and running, let's now define a few alerts against
    them.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经让作业运行起来，接下来定义一些针对它们的警报。
- en: Creating alerts against the sample jobs
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对示例作业创建警报
- en: 'With our jobs running in real time, we can now define some alerts for our jobs:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的作业现在正在实时运行，我们可以为我们的作业定义一些警报：
- en: For the `alert-demo-response_code_rates` job, click the **…** icon and select
    **Create alert**:![Figure 6.12 – Creating an alert for a sample job
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`alert-demo-response_code_rates`作业，点击**…**图标并选择**创建警报**：![图 6.12 – 为示例作业创建警报
- en: '](img/B17040_06_12.jpg)'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_12.jpg)'
- en: Figure 6.12 – Creating an alert for a sample job
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.12 – 为示例作业创建警报
- en: Now the **Create alert** flyout window appears, and we can now begin to fill
    in our desired alert configuration:![Figure 6.13 – Creating an alert configuration
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在出现**创建警报**弹出窗口，我们可以开始填写我们想要的警报配置：![图 6.13 – 创建警报配置
- en: '](img/B17040_06_13.jpg)'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_13.jpg)'
- en: Figure 6.13 – Creating an alert configuration
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.13 – 创建警报配置
- en: In *Figure 6.13*, we will name our alert, but will also define that we wish
    to have this alert check for anomalies every 10 minutes. This job's `bucket_span`
    is set for 1 hour, but the frequency is set to 10 minutes – therefore interim
    results will be available much sooner than the full bucket time. This is also
    why we chose to include interim results in our alert configuration, so that we
    can get notified as soon as possible. We also set **Result type** to be of type
    **Bucket** to give us a summarized treatment of the anomalousness, as previously
    discussed. Finally, we set the severity threshold to **51** to have alerts be
    generated only for anomalies of a score exceeding that value.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*图 6.13*中，我们将命名我们的警报，但也会定义我们希望这个警报每10分钟检查一次异常。这个作业的`bucket_span`设置为1小时，但频率设置为10分钟——因此中间结果将比完整桶时间更早可用。这也是我们选择在警报配置中包含中间结果的原因，这样我们就可以尽快收到通知。我们还设置了**结果类型**为**桶**类型，以便我们得到异常性的总结处理，如前所述。最后，我们将严重程度阈值设置为**51**，以便只有得分超过该值的异常才会生成警报。
- en: Before we continue too far, we can check the alert configuration on past data.
    Putting `30d` into the test box, we can see that there was only one other alert
    in the last 30 days' worth of data that matched this alert condition:![Figure
    6.14 – Testing alert configuration on past data
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们继续之前，我们可以检查历史数据上的警报配置。将`30d`输入测试框中，我们可以看到在过去30天的数据中只有一个其他警报符合这个警报条件：![图 6.14
    – 在历史数据上测试警报配置
- en: '](img/B17040_06_14.jpg)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_06_14.jpg)'
- en: Figure 6.14 – Testing alert configuration on past data
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.14 – 在历史数据上测试警报配置
- en: Lastly, we can configure an action to invoke on an alert being fired. In this
    case, our system was pre-configured to use Slack as an alert action, so we will
    choose that here, but there are many other options available for the user to consider
    (please see [https://www.elastic.co/guide/en/kibana/current/action-types.html](https://www.elastic.co/guide/en/kibana/current/action-types.html)
    to explore all options available and how to customize the alert messaging):![Figure
    6.15 – Configuring alert action
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17040_06_15.jpg)'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.15 – Configuring alert action
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Clicking on the **Save** button will obviously save the alert, which is then
    viewable and modifiable via the **Stack Management | Alerts and Actions** area
    of Kibana:![Figure 6.16 – Alerts management
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17040_06_16.jpg)'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.16 – Alerts management
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We are going to create one more alert, for the `alert-demo-url_scanning` job.
    This time, we''ll create a **Record** alert, but with the other configuration
    parameters similar to the prior example:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.17 – Configuring another alert on the URL scanning job'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_06_17.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.17 – Configuring another alert on the URL scanning job
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our two alerts configured, let's move on to simulating an actually
    anomalous situation in real time to trigger our alerts.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Simulating some real-time anomalous behavior
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Triggering simulated anomalous behavior in the context of these sample web logs
    is a little tricky, but not too hard. It will involve some usage of the Elasticsearch
    APIs, executing a few commands via **the Dev Tools console** in Kibana. Console
    is where you can issue API calls to Elasticsearch and see the output (response)
    of those API calls.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: If you are unfamiliar with Console, please consult [https://www.elastic.co/guide/en/kibana/current/console-kibana.html](https://www.elastic.co/guide/en/kibana/current/console-kibana.html).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: What we will be simulating is twofold – we'll inject several fake documents
    into the index that the anomaly detection job is monitoring, and then wait for
    the alert to fire. These documents will show a spike in requests from a fictitious
    IP address of `0.0.0.0` that will result in a response code of `404` and will
    also be requesting random URL paths.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get started:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to determine the current time for you in UTC. We must know the UTC
    time (as opposed to your local time zone''s time) because the documents stored
    in the Elasticsearch index are stored in UTC. To determine this, you can simply
    use an online tool (such as Googling `current time utc`). At the time of writing,
    the current UTC time is 4:41 P.M. on April 8, 2021\. Converted into the format
    that Elasticsearch expects for the `kibana_sample_data_logs` index, this will
    take the form of this:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s now insert some new bogus documents into the `kibana_sample_data_logs`
    index at the current time (perhaps with a little buffer – rounding up to the next
    half hour, in this case to 17:00). Replace the `timestamp` field value accordingly
    and invoke the following command *at least 20 times* in the Dev Tools console
    to insert:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can then dynamically modify only the documents we just inserted (in particular,
    the `url` field) to simulate that the URLs are all unique by using a little script
    to randomize the field value in an `_update_by_query` API call:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can validate that we have correctly created a bunch of unique, random requests
    from our bogus IP address by looking that the appropriate time in Kibana Discover:![Figure
    6.18 – Our contrived burst of anomalous events shown in Discover
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B17040_06_18.jpg)'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.18 – Our contrived burst of anomalous events shown in Discover
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Notice in *Figure 6.18* that we had to peek into the future a little to see
    the documents we artificially inserted (as the red vertical line in the timeline
    near 12:45 P.M. is the actual current system time in the local time zone). Also
    notice that our inserted documents have a nice-looking random `url` field as well.
    Now that we have "laid the trap" for anomaly detection to find, and we have our
    alerts ready, we must now sit back and patiently wait for the alerts to trigger.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Receiving and reviewing the alerts
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since the anomalous behavior we inserted is now waiting to be found by our anomaly
    detection job and our alerts, we can contemplate when we should expect to see
    that alert. We should recognize that given our jobs have bucket spans of 1 hour,
    frequencies of 10 minutes, and query delays on the order of 1-2 minutes (and that
    our alerts will indeed look for interim results – and that our alerts are running
    with a 10-minute frequency that is asynchronous from the anomaly detection job),
    we should expect to see our alerts between 1:12 P.M. and 1:20 P.M. local time.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'Right on cue, the alert messages for the two jobs surface in Slack at 1:16
    P.M. and 1:18 P.M. local time:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19 – Alerts received in the Slack client'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_06_19.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.19 – Alerts received in the Slack client
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'The top alert in *Figure 6.19*, of course, is for the anomaly detection job
    that was counting the number of events for each `response.keyword` (and thus seeing
    the spike of 404 documents exceeds expectations) and the bottom alert is for the
    other job that notices the high distinct count of unique URLs that were being
    requested. Notice that both jobs correctly identify `clientip = 0.0.0.0` as an
    influencer into the anomalies. Included in the alert text is the ability to follow
    the link to directly view the information in **Anomaly** **Explorer**. In *Figure*
    *6.20*, we can see that by following the link in the second alert, we arrive at
    a familiar place to investigate the anomaly further:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20 – Anomaly Explorer from the alert drill-down link'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_06_20.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.20 – Anomaly Explorer from the alert drill-down link
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.20 – 来自警报钻取链接的异常探索器
- en: Hopefully, through this example you can see not only how to use the alerts using
    the Kibana alerting framework on anomaly detection jobs but can now also appreciate
    the intricacies of the real-time operation of both the job and the alert. The
    settings within the job's datafeed and alert sampling interval truly affect how
    real-time the alerts can be. We could have, for example, reduced both the datafeed
    `frequency` and the alert's **Check every** setting to shave a few minutes off.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 希望通过这个示例，你不仅能看到如何使用Kibana警报框架在异常检测作业上使用警报，现在也能欣赏到作业和警报实时操作的复杂性。作业数据源和警报采样间隔的设置确实会影响警报的实时性。例如，我们可以减少数据源的`频率`和警报的**检查间隔**设置，以节省几分钟。
- en: In the next section, we won't attempt to replicate a real-time alert detection
    with Watcher, but we will work to understand the equivalent settings within a
    watch to accomplish what we need to interface Watcher to an anomaly detection
    job and to also showcase some interesting example watches.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们不会尝试使用Watcher复制实时警报检测，但我们将努力理解监控中的等效设置以完成我们需要的工作，将Watcher与异常检测作业接口，并展示一些有趣的示例监控。
- en: Creating an alert with a watch
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用监控创建警报
- en: Prior to version 7.12, Watcher was used as the mechanism to alert on anomalies
    found by Elastic ML. **Watcher** is a very flexible native plugin for Elasticsearch
    that can handle a number of automation tasks and alerting is certainly one of
    them. In versions 7.11 and earlier, users could either create their own **watch**
    (an instance of an automation task in Watcher) from scratch to alert on anomaly
    detection job results or opt to use a default watch template that was created
    for them by the Elastic ML UI. We will first look at the default watch that was
    provided and then will discuss some ideas around custom watches.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在版本7.12之前，Watcher被用作Elastic ML发现异常的警报机制。**Watcher**是一个非常灵活的Elasticsearch原生插件，可以处理许多自动化任务，警报当然也是其中之一。在版本7.11及更早版本中，用户可以从头创建自己的**监控**（Watcher中的自动化任务实例）以警报异常检测作业结果，或者选择使用Elastic
    ML UI为他们创建的默认监控模板。我们首先将查看提供的默认监控，然后讨论一些关于自定义监控的想法。
- en: Understanding the anatomy of the legacy default ML watch
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解遗留默认机器学习监控的结构
- en: 'Now that alerting on anomaly detection jobs is handled by the new Kibana alerting
    framework, the legacy watch default template (plus a few other examples) are memorialized
    in a GitHub repository here: [https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/ml_examples](https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/ml_examples).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在异常检测作业的警报处理由新的Kibana警报框架处理，因此遗留的监控默认模板（以及一些其他示例）被保存在此GitHub仓库中：[https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/ml_examples](https://github.com/elastic/examples/tree/master/Alerting/Sample%20Watches/ml_examples)。
- en: 'In dissecting the default ML watch (`default_ml_watch.json`) and the companion
    version, which has an email action (`default_ml_watch_email.json`), we see that
    there are four main sections:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析默认机器学习监控（`default_ml_watch.json`）及其伴随版本（具有电子邮件操作`default_ml_watch_email.json`），我们看到有四个主要部分：
- en: '**trigger**: Defines the scheduling of the watch'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**触发器**：定义监控的调度'
- en: '**input**: Specifies the input data to be evaluated'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入**：指定要评估的输入数据'
- en: '`actions` section is executed'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行`操作`部分
- en: '**actions**: Lists the desired actions to take if the watch''s condition is
    met'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作**：列出当监控条件满足时希望执行的操作'
- en: Note
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: For a full explanation of all of the options of Watcher, please consult the
    Elastic documentation at [https://www.elastic.co/guide/en/elasticsearch/reference/current/how-watcher-works.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/how-watcher-works.html).
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有关Watcher所有选项的完整说明，请参阅Elastic文档：[https://www.elastic.co/guide/en/elasticsearch/reference/current/how-watcher-works.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/how-watcher-works.html)。
- en: Let's discuss each section in depth.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入讨论每个部分。
- en: The trigger section
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 触发器部分
- en: 'In the default ML watch, the `trigger` section is defined as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在默认的机器学习监控中，`触发器`部分定义如下：
- en: '[PRE3]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here, we can see that the interval at which the watch will fire in real time
    is every 82 seconds. This usually should be a random value between 60 and 120
    seconds so that if a node restarts, all of the watches will not be synchronized,
    and they will have their execution times more evenly spread out to reduce any
    potential load on the cluster. It is also important that this interval value is
    less than or equal to the bucket span of the job. As explained earlier in this
    chapter, having it larger than the bucket span may cause recently written anomaly
    records to be missed by the watch. With the interval being less (or even much
    less) than the bucket span of the job, you can also take advantage of the advanced
    notification that is available when there are interim results, anomalies that
    can still be determined despite not having seen all of the data within a bucket
    span.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们可以看到实时触发watch的间隔是每82秒。这通常应该是一个介于60到120秒之间的随机值，这样如果节点重启，所有的watch都不会同步，它们将会有更均匀的执行时间，以减少对集群的潜在负载。同样重要的是，这个间隔值应该小于或等于工作的bucket跨度。正如本章前面所解释的，如果这个值大于bucket跨度，可能会导致最近写入的异常记录被watch错过。当间隔小于（甚至远小于）工作的bucket跨度时，你也可以利用当有中间结果时提供的先进通知，即使没有看到bucket跨度内的所有数据，也可以确定异常。
- en: The input section
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入部分
- en: 'The `input` section starts with a `search` section in which the following `query`
    is defined against the `.ml-anomalies-*` index pattern:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`input`部分从`search`部分开始，其中定义了以下`query`针对`.ml-anomalies-*`索引模式：'
- en: '[PRE4]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, we are asking Watcher to query for `bucket`, `record`, and `influencer`
    result documents for a job (you would replace `<job_id>` with the actual `job_id`
    for the anomaly detection job of interest) in the last 30 minutes. As we know
    from earlier in the chapter, this look-back window should be twice the `bucket_span`
    value of the ML job (this template must assume that the job's bucket span is 15
    minutes). While all result types were asked for, we will later see that only the
    bucket-level results are used to evaluate whether or not to create an alert.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们要求Watcher查询过去30分钟内一个工作（你将用感兴趣的异常检测工作的实际`job_id`替换`<job_id>`）的`bucket`、`record`和`influencer`结果文档。正如我们在本章前面的内容中了解到的，这个回溯窗口应该是ML工作`bucket_span`值的两倍（这个模板必须假设工作的bucket跨度是15分钟）。虽然要求了所有结果类型，但稍后我们会看到，只有bucket级别的结果用于评估是否创建警报。
- en: 'Next comes a series of three aggregations. When they''re collapsed, they look
    as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是一系列三个聚合。当它们折叠时，看起来如下：
- en: '![Figure 6.21 – Query aggregations in the watch input'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.21 – watch输入中的查询聚合'
- en: '](img/B17040_06_21.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_06_21.jpg)'
- en: Figure 6.21 – Query aggregations in the watch input
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.21 – watch输入中的查询聚合
- en: 'The `bucket_results` aggregation first filters for buckets where the anomaly
    score is greater than or equal to 75:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`bucket_results`聚合首先筛选出异常分数大于或等于75的bucket：'
- en: '[PRE5]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, a sub-aggregation asks for the top 1 bucket sorted by `anomaly_score`:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，一个子聚合要求按`anomaly_score`排序的前1个bucket：
- en: '[PRE6]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, still within the `top_bucket_hits` sub-aggregation, there are a series
    of defined `script_fields`:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，仍然在`top_bucket_hits`子聚合中，有一系列定义的`script_fields`：
- en: '[PRE7]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: These newly defined variables will be used by the watch to provide more functionality
    and context. Some of the variables are merely reformatting values (`score` is
    just a rounded version of `anomaly_score`), while `start` and `end` will later
    fill a functional role by defining a start and end time that is equal to +/- 10
    bucket spans from the time of the anomalous bucket. This is later used by the
    UI to show an appropriate contextual time range before and after the anomalous
    bucket so that the user can see things more clearly.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这些新定义的变量将被watch用于提供更多功能和上下文。其中一些变量仅仅是重新格式化值（`score`只是`anomaly_score`的一个四舍五入版本），而`start`和`end`将后来通过定义一个等于异常bucket时间+/-
    10个bucket跨度的开始和结束时间来发挥功能作用。这后来被UI用于在异常bucket之前和之后显示适当的时间范围，以便用户可以更清楚地看到事物。
- en: The `influencer_results` and `record_results` aggregations ask for the top three
    influencer scores and record scores, but only the output of the `record_results`
    aggregation is used in subsequent parts of the watch (and only in the `action`
    section of `default_ml_watch_email.json`, which contains some default email text).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`influencer_results`和`record_results`聚合要求前三个影响者分数和记录分数，但只有`record_results`聚合的输出用于watch的后续部分（并且仅在`default_ml_watch_email.json`的`action`部分中，其中包含一些默认电子邮件文本）。'
- en: The condition section
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 条件部分
- en: 'The `condition` section is where `input` is evaluated to see whether or not
    the `action` section is executed. In this case, the `condition` section is as
    follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`condition`部分是评估`input`以确定是否执行`action`部分的地方。在这种情况下，`condition`部分如下：'
- en: '[PRE8]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We are using this to check whether the `bucket_results` aggregation returned
    any documents (where `doc_count` is greater than 0). In other words, if the `bucket_results`
    aggregation did indeed return non-zero results, that indicates that there were
    indeed documents where `anomaly_score` was greater than 75\. If true, then the
    `action` section will be invoked.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个来检查`bucket_results`聚合是否返回了任何文档（其中`doc_count`大于0）。换句话说，如果`bucket_results`聚合确实返回了非零结果，那么这表明确实存在`anomaly_score`大于75的文档。如果是这样，那么将调用`action`部分。
- en: The action section
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`action`部分'
- en: 'The `action` section of our default watches has two parts in our case: one
    `log` action for logging information to a file and a `send_email` action for sending
    an email. The text of the watch won''t be repeated here for brevity (it is a lot
    of text). The `log` action will print a message to an output file, which by default
    is the Elasticsearch log file. Notice that the syntax of the message is using
    the templating language called **Mustache** (named because of its prolific usage
    of curly braces). Simply put, variables contained in Mustache''s double curly
    braces will be substituted with their actual values. As a result, for one of the
    sample jobs we created earlier in the chapter, the logging text written out to
    the file may look as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们默认监视的`action`部分在我们的案例中有两个部分：一个用于将信息记录到文件的`log`动作和一个用于发送电子邮件的`send_email`动作。为了简洁，这里不会重复监视的文本（它有很多文本）。`log`动作将消息打印到输出文件，默认情况下是Elasticsearch日志文件。请注意，消息的语法使用的是名为**Mustache**的模板语言（因其大量使用花括号而得名）。简单来说，Mustache的双花括号中的变量将被它们的实际值替换。因此，对于我们在本章前面创建的一个示例作业，写入文件的日志文本可能如下所示：
- en: '[PRE9]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This alert should look familiar to what we saw in our Slack message earlier
    in the chapter – of course, because it is derived from the same information. The
    email version of the action may look as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这个警报应该看起来很熟悉，就像我们在本章前面的Slack消息中看到的那样——当然，因为它是从相同的信息中派生出来的。动作的电子邮件版本可能如下所示：
- en: '[PRE10]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: It is obvious that the format of the alert HTML is really oriented not around
    getting the user a summary of the information but enticing the user to investigate
    further by clicking on the link within the email.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，警报HTML格式的格式并不是围绕为用户提供信息摘要，而是通过在电子邮件中点击链接来诱使用户进一步调查。
- en: Also, it is notable that the top three records are reported in the text of the
    email response. In our example case, there is only one record (a `count` detector
    with a score of 91). This section of information came from the `record_results`
    aggregation we described previously in the `input` section of the watch.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，值得注意的是，前三条记录在电子邮件响应的文本中报告。在我们的例子中，只有一个记录（一个得分为91的`count`检测器）。这部分信息来自我们在监视的`input`部分之前描述的`record_results`聚合。
- en: 'This default watch is a good, usable alert that provides summarized information
    about the unusualness of the dataset over time, but it is also good to understand
    the implications of using this:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这个默认监视是一个很好的、可用的警报，它提供了关于数据集随时间异常性的总结信息，但了解使用它的含义也很重要：
- en: The main condition for firing the alert is a bucket anomaly score above a certain
    value. Therefore, it would not alert on individual anomalous records within a
    bucket in the case where their score does not lift the overall bucket score above
    the stated threshold.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 触发警报的主要条件是桶异常分数超过某个值。因此，在桶内个别异常记录的分数没有将整体桶分数提升到所声明的阈值的情况下，不会对它们发出警报。
- en: By default, only a maximum of the top three record scores in the bucket are
    reported in the output, and only in the email version.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，输出中只报告桶中前三条记录的最高分数，并且仅在电子邮件版本中。
- en: The only action in these examples is logging and email. Adding other actions
    (Slack message, webhook, and so on) would require manually editing the watch.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些例子中唯一的动作是记录和电子邮件。添加其他动作（Slack消息、webhook等）需要手动编辑监视。
- en: Knowing this information, it may become necessary at some point to create a
    more full- featured, complex watch to fully customize the behavior and output
    of the watch. In the next section, we'll discuss some more examples of creating
    a watch from scratch.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这些信息后，在某个时候可能需要创建一个功能更全面、更复杂的手表，以完全自定义手表的行为和输出。在下一节中，我们将讨论一些从头开始创建手表的更多示例。
- en: Custom watches can offer some unique functionality
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定制手表可以提供一些独特的功能
- en: For those who feel emboldened and want to dig deeper into some advanced aspects
    of Watcher, let's look at some highlights from a few of the other samples in the
    GitHub repository. These include examples of querying the results of multiple
    jobs at once, programmatically combining the anomaly scores, and dynamically gathering
    additional potential root-cause evidence of other anomalies correlated in time.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些感到自信并想深入了解Watcher的一些高级功能的人来说，让我们看看GitHub仓库中其他一些样本的一些亮点。这些包括同时查询多个作业的结果的示例、程序化组合异常分数，以及动态收集与时间相关联的其他异常的潜在根本原因证据。
- en: Chained inputs and scripted conditions
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连接输入和脚本条件
- en: 'A nice example of an interesting watch is `multiple_jobs_watch.json`, which
    shows the ability to do a chained input (doing multiple queries against the results
    of multiple jobs) but also executing a more dynamic condition using a script:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的定制手表示例是`multiple_jobs_watch.json`，它展示了进行连接输入（对多个作业的结果进行多次查询）的能力，但同时也使用脚本执行更动态的条件：
- en: '[PRE11]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This is basically saying that the alert only gets triggered if the combined
    weighted anomaly scores of the three different jobs are greater than a value of
    75\. In other words, not every job is considered equally important, and the weighting
    takes that into account.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上意味着只有当三个不同作业的加权异常分数总和大于75的值时，警报才会被触发。换句话说，并不是每个作业都被视为同等重要，并且权重考虑了这一点。
- en: Passing information between chained inputs
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在连接输入之间传递信息
- en: 'Another unique aspect of chained inputs is that information gleaned from one
    input chain can be passed along to another. As shown in `chained_watch.json`,
    the second and third input chains use the `timestamp` value learned from the first
    query as part of the `range` filter:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 连接输入的另一个独特之处在于，从一条输入链中获得的信息可以被传递到另一条。如`chained_watch.json`所示，第二条和第三条输入链使用从第一次查询中学习的`timestamp`值作为`range`过滤器的一部分：
- en: '[PRE12]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This effectively means that the watch is gathering anomalies as evidence culled
    from a window of time prior to a presumably important anomaly from the first job.
    This kind of alert aligns nicely to the situation we''ll discuss in [*Chapter
    7*](B17040_07_Epub_AM.xhtml#_idTextAnchor131)*, AIOps and Root Cause Analysis*,
    in which a real application problem is solved by looking for correlated anomalies
    in a window of time around the anomaly of a KPI. Therefore, a sample output of
    this watch could look like this:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上意味着该手表正在收集作为证据的异常，这些异常是从第一个作业中一个可能的重要异常之前的时间窗口中提取的。这种警报与我们在[*第7章*](B17040_07_Epub_AM.xhtml#_idTextAnchor131)*，AIOps和根本原因分析*中将要讨论的情况非常吻合，其中通过在KPI异常周围的时间窗口中寻找相关异常来解决一个真实的应用程序问题。因此，这个手表的样本输出可能看起来像这样：
- en: '[PRE13]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, the formatting of the output that collates results from each of the three
    payloads is managed with a hefty **transform** script that leverages the Java-like
    **Painless** scripting language.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，管理来自每个三个有效载荷的结果的输出格式化的是一个强大的**transform**脚本，该脚本利用类似Java的**Painless**脚本语言。
- en: Note
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on the Painless scripting language, please consult the
    Elastic documentation at [https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-painless.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-painless.html).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解更多关于Painless脚本语言的信息，请参阅Elastic文档，网址为[https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-painless.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-painless.html)。
- en: If you're not intimidated by the code-heavy format of Watcher, you can wield
    it as a very powerful tool to implement some very interesting and useful alert
    schemes.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不会被Watcher代码密集的格式吓倒，你可以将其用作一个非常强大的工具来实施一些非常有趣和有用的警报方案。
- en: Summary
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Anomaly detection jobs are certainly useful on their own, but when combined
    with near real-time alerting, users can really harness the power of automated
    analysis – while also being confident about getting only alerts that are meaningful.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测作业本身当然很有用，但与近乎实时的警报结合使用时，用户可以真正利用自动化分析的力量——同时也可以对只收到有意义的警报感到自信。
- en: After a practical study of how to effectively capture the results of anomaly
    detection jobs with real-time alerts, we went through a comprehensive example
    of using the new Kibana alerting framework to easily define some intuitive alerts
    and we tested them with a realistic alerting scenario. We then witnessed how an
    expert user can leverage the full power of Watcher for advanced alerting techniques
    if Kibana alerting cannot satisfy the complex alerting requirements.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在对如何通过实时警报有效捕捉异常检测工作结果进行实际研究之后，我们通过一个全面的示例展示了如何使用新的Kibana警报框架轻松定义一些直观的警报，并在一个现实警报场景中测试了它们。然后，我们见证了如果Kibana警报无法满足复杂的警报需求，专家用户如何利用Watcher的全部功能来实现高级警报技术。
- en: In the next chapter, we'll see how anomaly detection jobs can assist not only
    with alerting on important key performance indicators but also how Elastic ML's
    automated analysis of a broad set of data within a specific application context
    is the means to achieving some "AI" on tracking down an application problem and
    determining its root cause.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到异常检测工作如何不仅能够帮助警报重要的关键性能指标，而且还将展示Elastic ML在特定应用场景中对大量数据的自动分析是如何实现追踪应用问题并确定其根本原因的“AI”手段。
