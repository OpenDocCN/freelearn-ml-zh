- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recommender Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recommender systems are algorithms, programs, and services that are designed
    to use data to predict which objects (goods or services) are of interest to a
    user. There are two main types of recommender systems: *content-based* and *collaborative
    filtering*. **Content-based recommender systems** are based on data that’s been
    collected from specific products. They recommend objects to a user that are similar
    to ones the user has previously acquired or shown interest in. **Collaborative
    filtering recommender systems** filter out objects that a user might like based
    on the reaction history of other, similar users of these systems. They also usually
    consider the user’s previous reactions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll learn how to implement recommender system algorithms
    based on both content and collaborative filtering. We’re going to discuss different
    approaches for implementing collaborative filtering algorithms, implement systems
    using only the linear algebra library, and learn how to use the `mlpack` library
    to solve collaborative filtering problems. We’ll be using the MovieLens dataset
    provided by GroupLens from a research lab in the Department of Computer Science
    and Engineering at the University of Minnesota: [https://grouplens.org/datasets/movielens/](B19849_08.xhtml#_idTextAnchor473).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of recommender system algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the collaborative filtering method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of item-based collaborative filtering with C++
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To complete this chapter, you’ll need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The `Eigen` library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Armadillo` library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `mlpack` library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A modern C++ compiler with C++20 support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CMake build system version >= 3.10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code files for this chapter can be found in this book’s GitHub repository:
    [https://github.com/PacktPublishing/Hands-On-Machine-Learning-with-C-Second-Edition/tree/main/Chapter08](B19849_08.xhtml#_idTextAnchor470).'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of recommender system algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A recommender system’s task is to inform a user about an object that could be
    the most interesting to them at a given time. Often, such an object is a product
    or service, but it may be information—for example, in the form of a recommended
    news article.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we dive into the technicalities of the recommender system, let’s look
    at some real-world scenarios where recommender systems are used to improve user
    experience and increase sales. The following are the most common applications:'
  prefs: []
  type: TYPE_NORMAL
- en: Recommender systems help online retailers suggest products that might interest
    a customer based on their past purchases, browsing history, and other data. This
    helps customers find relevant products more easily and increases the likelihood
    of conversion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Music and video streaming services use recommender systems to suggest music
    or videos based on a user’s listening or viewing history. The goal is to provide
    personalized content recommendations that keep users engaged with the platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social media platforms such as Meta and Instagram use recommender systems to
    show users content from friends and pages they might be interested in. This keeps
    users engaged and spending time on the platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advertisers use recommender systems to target adverts at specific audiences
    based on their interests, demographics, and behavior. This improves the effectiveness
    of advertising campaigns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: News websites, blogs, and search engines use recommender systems to recommend
    articles, stories, or search results based on user preferences and search history.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommender systems can be used to suggest treatments, medications, or medical
    procedures based on patient data and medical research.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Travel websites and hotel booking platforms use recommender systems to suggest
    travel destinations, accommodations, and activities based on a traveler’s preferences,
    budget, and travel history.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Educational platforms and online courses use recommender systems to personalize
    learning experiences by suggesting courses, materials, and learning paths based
    on student performance, interests, and goals.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Video game platforms use recommender systems to suggest games based on player
    preferences, play style, and gaming history.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just a few examples of how recommender systems are applied in real-life
    scenarios. They’ve become an essential tool for businesses looking to improve
    customer engagement, increase sales, and provide personalized experiences.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite the many existing algorithms, we can divide recommender systems into
    several basic approaches. The most common are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary-based**: Non-personal models based on the average product rating'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Content-based**: Models based on the intersection of product descriptions
    and user interests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collaborative filtering**: Models based on interests of similar user groups'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Matrix factorization**: Methods based on the preferences matrix’s decomposition'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The basis of any recommender system is the preferences matrix. It has all users
    of the service laid on one of the axes and recommendation objects on the other.
    The recommendation objects are usually called **items**. At the intersection of
    rows and columns (user, item), this matrix is filled with ratings that indicate
    user interest in a product, expressed on a given scale (for example, from 1 to
    5), as illustrated in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **item1** | **item 2** | **item3** |'
  prefs: []
  type: TYPE_TB
- en: '| user1 | 1 |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| user2 |  | 2 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| user3 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| user4 |  |  | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| user5 | 3 | 1 |  |'
  prefs: []
  type: TYPE_TB
- en: '| user6 |  | 4 |  |'
  prefs: []
  type: TYPE_TB
- en: Table 8.1 – User interest count
  prefs: []
  type: TYPE_NORMAL
- en: Users usually evaluate only a small number of the items in the catalog; the
    task of the recommender system is to summarize this information and predict the
    attitude the user might have toward other items. In other words, you need to fill
    in all the blank cells in the preceding table.
  prefs: []
  type: TYPE_NORMAL
- en: 'People’s consumption patterns are different, and new products don’t have to
    be recommended all the time. You can show repeated items—for example, when a user
    has bought something they’ll need again. According to this principle, there are
    two groups of items:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Repeatable**: For example, shampoos or razors, which are always needed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unrepeatable**: For example, books or films, which are rarely purchased repeatedly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the product can’t be attributed to one of these groups, it makes sense to
    determine the group type of repetitive purchases individually (someone usually
    buys only a specific brand, but someone else might try everything in the catalog).
  prefs: []
  type: TYPE_NORMAL
- en: Determining what product *interests* a user is also subjective. Some users need
    things only from their favorite category (conservative recommendations), while
    others respond more to non-standard goods (risky recommendations). For example,
    a video-hosting service may only recommend new series from their favorite TV series
    (conservative) but may periodically recommend new shows or new genres. Ideally,
    you should choose a strategy for displaying recommendations for each client separately
    by using generalized information about the client’s preferences.
  prefs: []
  type: TYPE_NORMAL
- en: 'The essential part of datasets that are used to build recommendation models
    is user reactions to different objects or items. These reactions are typically
    called user ratings of objects. We can obtain user ratings in the following ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Explicit ratings**: The user gives their rating for the product, leaves a
    review, or *likes* the page.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Implicit ratings**: The user doesn’t express their attitude, but an indirect
    conclusion can be made from their actions. For example, if they bought a product,
    it means they like it; if they read the description for a long time, it means
    they have serious interest.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, explicit preferences are better. However, in practice, not all services
    allow users to express their interests clearly, and not all users have the desire
    to do so. Both types of assessments are often used in tandem and complement each
    other well.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also essential to distinguish between the terms *prediction* (the prediction
    of the degree of interest) and the *recommendation* itself (showing the recommendation).
    How to show something is a separate task from the task of *what to show*. *How
    to show* is a task that uses the estimates obtained in the prediction step, and
    can be implemented in different ways.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discussed the basics of recommender systems. In the following
    sections, we’ll look at the essential building blocks of recommender systems.
    Let’s begin by looking at the main principles of content-based filtering, user
    and item-based collaborative filtering, and collaborative filtering based on matrix
    factorization.
  prefs: []
  type: TYPE_NORMAL
- en: Non-personalized recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For non-personalized recommendations, the potential interest of the user is
    determined by the average rating of the product: *if everyone likes it, you’ll
    like it too*. According to this principle, most services work when the user isn’t
    authorized on the system.'
  prefs: []
  type: TYPE_NORMAL
- en: Content-based recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Personal recommendations use the maximum information available about the user—primarily,
    information about their previous purchases. Content-based filtering was one of
    the first approaches to be developed for personalized recommendations. In this
    approach, the product’s description (content) is compared with the interests of
    the user, which are obtained from their previous assessments. The more the product
    meets these interests, the higher the potential interest of the user. The obvious
    requirement here is that all products in the catalog should have a description.
  prefs: []
  type: TYPE_NORMAL
- en: 'Historically, the subject of content-based recommendations was products with
    unstructured descriptions: films, books, or articles. Their features may be, for
    example, text descriptions, reviews, or casts. However, nothing prevents the use
    of usual numerical or categorical features.'
  prefs: []
  type: TYPE_NORMAL
- en: Unstructured features are described in a text-typical way—vectors in the space
    of words (vector-space model). Each element of a vector is a feature that potentially
    characterizes the interest of the user. Similarly, an item (product) is a vector
    in the same space.
  prefs: []
  type: TYPE_NORMAL
- en: As users interact with the system (say, they buy films), the vector descriptions
    of the goods they’ve purchased merge (sum up and normalize) into a single vector
    and, thus, form the vector of a user’s interests. Using this vector of interests,
    we can find the product and the description of which is closest to it—that is,
    we can solve the problem of finding the nearest neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: When forming the vector space of a product presentation, instead of individual
    words, you can use shingles or n-grams (successive pairs of words, triples of
    words, or other numbers of words). This approach makes the model more detailed,
    but more data is required for training.
  prefs: []
  type: TYPE_NORMAL
- en: In different places of the description of the product, the weight of keywords
    may differ (for example, the description of the film may consist of a title, a
    brief description, and a detailed description). Product descriptions from different
    users can be weighed differently. For example, we can give more weight to active
    users who have many ratings. Similarly, you can weigh them by item. The higher
    the average rating of an object, the greater its weight (similar to PageRank).
    If the product description allows links to external sources, then you can also
    analyze all third-party information related to the product.
  prefs: []
  type: TYPE_NORMAL
- en: The cosine distance is often used to compare product representation vectors.
    This distance measures the value of proximity between two vectors.
  prefs: []
  type: TYPE_NORMAL
- en: When adding a new assessment, the vector of interests is updated incrementally
    (only for those elements that have changed). During the update, it makes sense
    to give a bit more weight to new estimates since the user’s preferences may change.
    You’ll notice that content-based filtering almost wholly repeats the query-document
    matching mechanism used in search engines such as Google. The only difference
    lies in the form of a search query—content filtering systems use a vector that
    describes the interests of the user, whereas search engines use keywords of the
    requested document. When search engines began to add personalization, this distinction
    was erased even more.
  prefs: []
  type: TYPE_NORMAL
- en: User-based collaborative filtering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This class of system began to develop in the 90s. Under this approach, recommendations
    are generated based on the interests of other, similar users. Such recommendations
    are the result of the **collaboration** of many users, hence the name of the method.
  prefs: []
  type: TYPE_NORMAL
- en: The classical implementation of the algorithm is based on the principle of **k-nearest
    neighbors** (**kNN**). For every user, we look for the **k** most similar to them
    (in terms of preferences). Then, we supplement the information about the user
    with known data from their neighbors. So, for example, if it’s known that your
    neighbors are delighted with a movie, and you haven’t watched it for some reason,
    this is a great reason to recommend this movie.
  prefs: []
  type: TYPE_NORMAL
- en: The similarity is, in this case, a synonym for a *correlation* of interests
    and can be considered in many ways—Pearson’s correlation, cosine distance, Jaccard
    distance, Hamming distance, and other types of distances.
  prefs: []
  type: TYPE_NORMAL
- en: The classical implementation of the algorithm has one distinct disadvantage—it’s
    poorly applicable in practice due to the quadratic complexity of the calculations.
    As with any nearest neighbor method, it requires all pairwise distances between
    users to be calculated (and there may be millions of users). It’s easy to calculate
    that the complexity of calculating the distance matrix is ![](img/B19849_08_01.png),
    where ![](img/B19849_Formula_001.png) is the number of users, and ![](img/B19849_08_03.png)
    is the number of items (goods).
  prefs: []
  type: TYPE_NORMAL
- en: 'This problem can be partly mitigated by purchasing high-performance hardware.
    But if you approach it wisely, then it’s better to introduce some corrections
    to the algorithm in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: Update distances not with every purchase but with batches (for example, once
    a day)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t recalculate the distance matrix completely, but update it incrementally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose some iterative and approximate algorithms (for example, **Alternating
    Least** **Squares** (**ALS**))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fulfill the following assumptions to make the algorithm more practical:'
  prefs: []
  type: TYPE_NORMAL
- en: The tastes of people don’t change over time (or they do change, but they’re
    the same for everyone)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If people’s tastes are the same, then they’re the same in everything
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, if two clients prefer the same films, then they also like the same
    book. This assumption is often the case when the recommended products are homogeneous
    (for example, films only). If this isn’t the case, then a couple of clients may
    well have the same eating habits but their political views might be the opposite;
    here, the algorithm is less efficient.
  prefs: []
  type: TYPE_NORMAL
- en: The neighborhood of the user in the space of preferences (the user’s neighbors),
    which we analyze to generate new recommendations, can be chosen in different ways.
    We can work with all users of the system; we can set a certain proximity threshold;
    we can choose several neighbors at random; or we can take the **k** most similar
    neighbors (this is the most popular approach). If we take too many neighbors,
    we get a higher chance of random noise, and vice versa. If we take too little,
    we get more accurate recommendations, but fewer goods can be recommended.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting development in the collaborative approach is trust-based recommendations,
    which take into account not only the proximity of people according to their interests
    but also their *social* proximity and the degree of trust between them. If, for
    example, we see that on Facebook, a girl occasionally visits a page that has her
    friend’s audio recordings, then she trusts her musical taste. Therefore, when
    making recommendations to the girl, you can add new songs from her friend’s playlist.
  prefs: []
  type: TYPE_NORMAL
- en: Item-based collaborative filtering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The item-based approach is a natural alternative to the classic user-based approach
    described previously and almost repeats it, except for one thing—it applies to
    the transposed preference matrix, which looks for similar products instead of
    users.
  prefs: []
  type: TYPE_NORMAL
- en: For each client, a user-based collaborative filtering system searches a group
    of customers who are similar to this user in terms of previous purchases, and
    then the system averages their preferences. These average preferences serve as
    recommendations for the user. In the case of item-based collaborative filtering,
    the nearest neighbors are searched for on a variety of products (items) using
    the columns of a preference matrix, and the averaging occurs precisely according
    to them.
  prefs: []
  type: TYPE_NORMAL
- en: If some products are meaningfully similar to each other, then users’ reactions
    to these products will be the same. Therefore, when we see that some products
    have a strong correlation between their estimates, this may indicate that these
    products are equivalent to each other.
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage of the item-based approach over the user-based approach is
    lower computation complexity. When there are many users (almost always), the task
    of finding the nearest neighbor becomes poorly computable. For example, for 1
    million users, you need to calculate and store ~500 billion distances. If the
    distance is encoded in 8 bytes, this results in 4 **terabytes** (**TB**) for the
    distance matrix alone. If we take an item-based approach, then the computational
    complexity decreases from ![](img/B19849_08_04.png) to ![](img/B19849_08_05.png),
    and the distance matrix has a dimension no longer than 1 million per 1 million
    but 100 by 100, as per the number of items (goods).
  prefs: []
  type: TYPE_NORMAL
- en: Estimating the proximity of products is much more accurate than assessing the
    proximity of users. This assumption is a direct consequence of the fact that there
    are usually many more users than items, and therefore the standard error in calculating
    the correlation of items is significantly less because we have more information
    to work from.
  prefs: []
  type: TYPE_NORMAL
- en: In the user-based version, the description of users usually has a very sparse
    distribution (there are many goods, but only a few evaluations). On the one hand,
    this helps to optimize the calculation—we multiply only those elements where an
    intersection exists. But, on the other hand, the list of items that a system can
    recommend to a user is minimal due to the limited number of user neighbors (users
    who have similar preferences). Also, user preferences may change over time, but
    the descriptions of the goods are much more stable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the algorithm almost wholly repeats the user-based version: it
    uses the same cosine distance as the primary measure of proximity and has the
    same need for data normalization. Since the correlation of items is considered
    on a higher number of observations, it isn’t as critical to recalculate it after
    each new assessment, and this can be done periodically in a batch mode.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at another approach to generalizing user interests based on
    matrix factorization methods.
  prefs: []
  type: TYPE_NORMAL
- en: Factorization algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It would be nice to describe the interests of the user with more extensive features—not
    in the format of *they love movies X, Y, and Z*, but in the format of *they love
    romantic comedies*. Besides the fact that it increases the generalizability of
    the model, it also solves the problem of having a large data dimension—after all,
    the interests are described not by the items vector, but by a significantly smaller
    preference vector.
  prefs: []
  type: TYPE_NORMAL
- en: Such approaches are also called **spectral decomposition** or **high-frequency
    filtering** (since we remove the noise and leave the useful signal). There are
    many different types of matrix decomposition in algebra, and one of the most commonly
    used is called **singular value** **decomposition** (**SVD**).
  prefs: []
  type: TYPE_NORMAL
- en: Initially, the SVD method was used to select pages that are similar in meaning
    but not in content. More recently, it has started being used in recommendations.
    The method is based on decomposing the original *R* rating matrix into a product
    of three matrices, ![](img/B19849_08_06.png), where the sizes of the matrices
    are ![](img/B19849_08_07.png) and *r* is the rank of the decomposition, which
    is the parameter characterizing the degree of detail decomposition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Applying this decomposition to our matrix of preferences, we can get the following
    two matrices of factors (abbreviated descriptions):'
  prefs: []
  type: TYPE_NORMAL
- en: '**U**: A compact description of user preferences'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**S**: A compact description of the characteristics of the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When using this approach, we can’t know which particular characteristics correspond
    to the factors in the reduced descriptions; for us, they’re encoded with some
    numbers. Therefore, SVD is an uninterpreted model. It’s sufficient to multiply
    the matrix of factors to obtain an approximation of the matrix of preferences.
    By doing this, we get a rating for all customer-product pairs.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical family of such algorithms is called **non-negative matrix factorization**
    (**NMF**). As a rule, the calculation of such expansions is very computationally
    expensive. Therefore, in practice, they often resort to their approximate iterative
    variants. ALS is a popular iterative algorithm for decomposing a matrix of preferences
    into a product of two matrices: **user factors** (**U**) and **product factors**
    (**I**). It works on the principle of minimizing the **root mean square error**
    (**RMSE**) on the affixed ratings. Optimization takes place alternately—first
    by user factors, then by product factors. Also, to avoid retraining, the regularization
    coefficients are added to the RMSE.'
  prefs: []
  type: TYPE_NORMAL
- en: If we supplement the matrix of preferences with a new dimension containing information
    about the user or product, then we can work not with the matrix of preferences,
    but with the tensor. Thus, we use more available information and possibly get
    a more accurate model.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we considered different approaches to solving recommender systems’
    tasks. Now, we’re going to discuss methods for estimating the similarity of user
    preferences.
  prefs: []
  type: TYPE_NORMAL
- en: Similarity or preferences correlation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can consider the similarity or correlation of two user preferences in different
    ways, but in general, we need to compare two vectors. Let’s look at some of the
    most popular vector comparison measures.
  prefs: []
  type: TYPE_NORMAL
- en: Pearson’s correlation coefficient
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This measure is a classic coefficient that can be applied when comparing vectors.
    Its primary disadvantage is that when the intersection is estimated as low, then
    the correlation can be high by accident. To combat accidental high correlation,
    you can multiply by a factor of 50/min (50, rating intersection) or any other
    damping factor, the effect of which decreases with an increasing number of estimates.
    An example is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Spearman’s correlation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The main difference compared to Pearson’s correlation is the rank factor—that
    is, it doesn’t work with absolute values of ratings, but with their sequence numbers.
    In general, the result is very close to Pearson’s correlation. An example is shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Cosine distance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Cosine distance is another classic measuring factor. If you look closely, the
    cosine of the angle between the standardized vectors is Pearson’s correlation,
    the same formula. This distance uses cosine properties: if the two vectors are
    co-directed (that is, the angle between them is 0), then the cosine of the angle
    between them is 1\. Conversely, the cosine of the angle between perpendicular
    vectors is 0\. An example is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: With that, we’ve discussed methods we can use to estimate the similarity of
    user preferences. The next important issue we’ll discuss is preparing data so
    that it can be used in recommender system algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Data scaling and standardization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All users evaluate (rate) items differently. If someone puts 5s in a row, instead
    of waiting for 4s from someone else, it’s better to normalize the data before
    calculating it—that is, convert the data into a single scale so that the algorithm
    can compare the results correctly. After, the predicted estimate needs to be converted
    into the original scale via inverse transformation (and, if necessary, rounded
    to the nearest whole number).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several ways to normalize data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Centering (mean-centering)**: From the user’s ratings, subtract their average
    rating. This type of normalization is only relevant for non-binary matrices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standardization (z-score)**: In addition to centering, this divides the user’s
    rating by the standard deviation of the user. But in this case, after the inverse
    transformation, the rating can go beyond the scale (for example, six on a five-point
    scale), but such situations are quite rare and can be solved by rounding to the
    nearest acceptable estimate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Double standardization**: The first time data is normalized by user ratings;
    the second time, by item ratings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The details of these normalization techniques were provided in [*Chapter 2*](B19849_02.xhtml#_idTextAnchor075),
    *Data Processing*. The following section will describe a problem with recommender
    systems known as the **cold start problem**, which appears in the early stages
    of system work when the system doesn’t have enough data to make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Cold start problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A cold start is a typical situation when a sufficient amount of data hasn’t
    been accumulated for the correct operation of the recommender system yet (for
    example, when a product is new or is just rarely bought). If the ratings of only
    three users estimate the average rating, such an assessment isn’t reliable, and
    users understand this. In such situations, ratings are often artificially adjusted.
  prefs: []
  type: TYPE_NORMAL
- en: The first way to do this is to show not the average value, but the smoothed
    average (damped mean). With a small number of ratings, the displayed rating leans
    more toward a specific safe *average* indicator, and as soon as a sufficient number
    of new ratings are typed, the *averaging* adjustment stops operating.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach is to calculate confidence intervals for each rating. Mathematically,
    the more estimates we have, the smaller the variation of the average will be and,
    therefore, the more confidence we have in its accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: For example, we can display the lower limit of the interval (low **confidence
    interval** (**CI**) bound) as a rating. At the same time, it’s clear that such
    a system is quite conservative, with a tendency to underestimate ratings for new
    items.
  prefs: []
  type: TYPE_NORMAL
- en: Since the estimates are limited to a specific scale (for example, from 0 to
    1), the usual methods for calculating the confidence interval are poorly applicable
    here due to the distribution tails that go to infinity, and the symmetry of the
    interval itself. There’s a more accurate way to calculate it—the Wilson CI.
  prefs: []
  type: TYPE_NORMAL
- en: The cold start problem is also relevant for non-personalized recommendations.
    The general approach here is to replace what currently can’t be calculated by
    different heuristics—for example, replace it with an average rating, use a simpler
    algorithm, or not use the product at all until the data has been collected.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue that should be considered when we develop a recommender system
    is the relevance of recommendations, which considers factors other than the user’s
    interests—for example, it can be the freshness of a publication or a user’s rating.
  prefs: []
  type: TYPE_NORMAL
- en: Relevance of recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In some cases, it’s also essential to consider the *freshness* of the recommendation.
    This consideration is especially important for articles or posts on forums. Fresh
    entries should often get to the top. The correction factors (damping factors)
    are usually used to make such updates. The following formulas are used for calculating
    the rating of articles on media sites.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of a rating calculation in the *Hacker* news magazine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *U* denotes upvotes, *D* denotes downvotes, *P* denotes penalty (additional
    adjustment for the implementation of other business rules), and *T* denotes recording
    time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following equation shows a *Reddit* rating calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *U* denotes the number of upvotes, *D* denotes the number of downvotes,
    and *T* denotes the recording time. The first term evaluates the *quality of the
    record*, and the second corrects for the time.
  prefs: []
  type: TYPE_NORMAL
- en: There’s no universal formula, and each service invents the formula that best
    solves its problem; it can only be tested empirically.
  prefs: []
  type: TYPE_NORMAL
- en: The following section will discuss the existing approaches to testing recommender
    systems. This isn’t a straightforward task because it’s usually hard to estimate
    the quality of a recommendation without having exact target values in a training
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing system quality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Testing a recommender system is a complicated process that always poses many
    questions, mainly due to the ambiguity of the concept of *quality*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, in machine learning problems, there are two main approaches to
    testing:'
  prefs: []
  type: TYPE_NORMAL
- en: Offline model testing on historical data using retro tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the model using A/B testing (we run several options and see which one
    gives the best result)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these approaches are actively used in developing recommender systems.
    The main limitation that we have to face is that we can only evaluate the accuracy
    of the forecast on those products that the user has already evaluated or rated.
    The standard approach is to use cross-validation alongside the **leave-one-out**
    and **leave-p-out** methods. Repeating the test and averaging the results provides
    a more stable assessment of quality.
  prefs: []
  type: TYPE_NORMAL
- en: The *leave-one-out* approach uses the model that’s been trained on all items
    except one and is evaluated by the user. This excluded item is used for model
    testing. This procedure is done for all *n* items, and an average is calculated
    among the obtained *n* quality estimates.
  prefs: []
  type: TYPE_NORMAL
- en: The *leave-p-out* approach is the same, but at each step, ![](img/B19849_Formula_119.png)
    points are excluded.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can divide all quality metrics into the following three categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prediction accuracy**: Estimates the accuracy of the predicted rating'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decision support**: Evaluates the relevance of the recommendations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rank accuracy metrics**: Evaluates the quality of the ranking of recommendations
    issued'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unfortunately, there’s no single recommended metric for all occasions, and everyone
    who’s involved in testing a recommender system selects it to fit their goals.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we’ll formalize the collaborative filtering method
    and show the math behind it.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the collaborative filtering method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll formalize the recommender system problem. We have a set
    of users, ![](img/B19849_08_14.png), a set of items, ![](img/B19849_08_15.png)
    (movies, tracks, products, and so on), and a set of estimates, ![](img/B19849_08_16.png).
    Each estimate is given by a user ![](img/B19849_08_17.png), an object ![](img/B19849_Formula_0721.png),
    its result ![](img/B19849_08_19.png), and, possibly, some other characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re required to predict preference as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We’re required to predict personal recommendations as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We’re required to predict similar objects as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Remember that the main idea behind collaborative filtering is that similar
    users usually like similar objects. Let’s start with the simplest method:'
  prefs: []
  type: TYPE_NORMAL
- en: Select some conditional measures of similarity of users according to their history
    of ![](img/B19849_08_23.png) ratings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Unite users into groups (clusters) so that similar users will end up in the
    same cluster: ![](img/B19849_08_24.png).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Predict the item’s user rating as the cluster’s average rating for this object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B19849_08_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This algorithm has several problems:'
  prefs: []
  type: TYPE_NORMAL
- en: There’s nothing to recommend to new or atypical users. For such users, there’s
    no suitable cluster with similar users.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It ignores the specificity of each user. In a sense, we divide all users into
    classes (templates).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no one in the cluster has rated the item, the prediction won’t work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can improve this method and replace hard clustering with the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For an item-based version, the formula will be symmetrical, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'These approaches have the following disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Cold start problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bad predictions for new and atypical users or items
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trivial recommendations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resource intensity calculations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To overcome these problems, you can use SVD. The preference (ratings) matrix
    can be decomposed into the product of three matrices, ![](img/B19849_08_28.png).
    Let’s denote the product of the first two matrices for one matrix, ![](img/B19849_08_29.png),
    where *R* is the matrix of preferences, *U* is the matrix of parameters of users,
    and *V* is the matrix of parameters of items.
  prefs: []
  type: TYPE_NORMAL
- en: 'To predict the user rating, *U*, for an item, ![](img/B19849_08_30.png), we
    take a vector, ![](img/B19849_08_31.png) (parameter set), for a given user and
    a vector for a given item, ![](img/B19849_08_32.png). Their scalar product is
    the prediction we need: ![](img/B19849_08_33.png). Using this approach, we can
    identify the hidden features of items and user interests by user history. For
    example, it may happen that at the first coordinate of the vector, each user has
    a number indicating whether the user is more likely to be a boy or a girl, and
    the second coordinate is a number reflecting the approximate age of the user.
    In the item, the first coordinate shows whether it’s more interesting to boys
    or girls, and the second one shows the age group of users this item appeals to.'
  prefs: []
  type: TYPE_NORMAL
- en: However, there are also several problems. The first one is the preferences matrix,
    *R*, which isn’t entirely known to us, so we can’t merely take its SVD decomposition.
    Secondly, the SVD decomposition isn’t the only one we have, so even if we find
    at least some decomposition, it’s unlikely that it’s optimal for our task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we need machine learning. We can’t find the SVD decomposition of the
    matrix since we don’t know the matrix itself. However, we can take advantage of
    this idea and come up with a prediction model that works like SVD. Our model depends
    on many parameters—vectors of users and items. For the given parameters, to predict
    the estimate, we must take the user vector, the vector of the item, and get their
    scalar product, ![](img/B19849_08_34.png). However, since we don’t know vectors,
    they still need to be obtained. The idea is that we have user ratings with which
    we can find optimal parameters so that our model can predict these estimates as
    accurately as possible using the following equation: ![](img/B19849_08_35.png).
    We want to find such parameters’ *θ* values so that the square error is as small
    as possible. We also want to make fewer mistakes in the future, but we don’t know
    what estimates we need. Accordingly, we can’t optimize parameters’ *θ* values.
    We already know the ratings given by users, so we can try to choose parameters
    based on the estimates we already have to minimize the error. We can also add
    another term, the *regularizer*, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Regularization is needed to combat overfitting. To find the optimal parameters,
    you need to optimize the following function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'There are many parameters: for each user and item, we have the vector that
    we want to optimize. The most well-known method for optimizing functions is **gradient
    descent** (**GD**). Suppose we have a function of many variables, and we want
    to optimize it. We take an initial value, and then we look at where we can move
    to minimize this value. The GD method is an iterative algorithm—it takes the parameters
    of a certain point repeatedly, looks at the gradient, and steps against its direction,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'There are various problems with this method: it works very slowly and it finds
    local, rather than global, minima. The second problem isn’t so bad for us because
    in our case, the value of the function in local minima is close to the global
    optimum.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the GD method isn’t always necessary. For example, if we need to calculate
    the minimum for a parabola, there’s no need to act by this method as we know precisely
    where its minimum is. It turns out that the functionality that we’re trying to
    optimize—the sum of the squares of errors plus the sum of the squares of all the
    parameters—is also a quadratic function, which is very similar to a parabola.
    For each specific parameter, if we fix all the others, it’s just a parabola. For
    those, we can accurately determine at least one coordinate. The ALS method is
    based on this assumption. We alternate between accurately finding minima in one
    coordinate or another, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We fix all the parameters of the items, optimize the parameters of users, fix
    the parameters of users, and then optimize the parameters of items. We act iteratively,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This method works reasonably quickly, and you can parallelize each step. However,
    there’s still a problem with implicit data because we have neither full user data
    nor full item data. So, we can penalize the items that don’t have ratings in the
    update rule. By doing so, we depend only on the items that have ratings from the
    users and don’t make any assumptions about the items that aren’t rated. So, let’s
    define a weight matrix, ![](img/B19849_08_41.png), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The cost functions that we’re trying to minimize look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_43.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that we need regularization terms to avoid overfitting the data. We can
    use the following solutions for factor vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/B19849_08_45.png) and ![](img/B19849_08_46.png)are diagonal matrices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another approach for dealing with implicit data is to introduce confidence
    levels. Let’s define a set of binary observation variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_47.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we can define confidence levels for each ![](img/B19849_08_48.png) value.
    When ![](img/B19849_08_49.png), we have low confidence. This can be because the
    user has never been exposed to that item or it may be unavailable at the time.
    For example, it could be explained by the user buying a gift for someone else.
    Hence, we would have *low confidence*. When ![](img/B19849_08_50.png) is larger,
    we should have much more confidence. For example, we can define confidence as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_51.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/B19849_08_52.png) is a hyperparameter that should be tuned for
    a given dataset. The updated optimization function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_53.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/B19849_08_54.png) is a diagonal matrix with ![](img/B19849_08_55.png)
    values. The following solutions are for user and item ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_56.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'However, it’s an expensive computational problem to calculate the ![](img/B19849_08_57.png)
    expression. However, it can be optimized in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_58.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This means that ![](img/B19849_08_59.png) can be precomputed at each of the
    steps, and ![](img/B19849_08_60.png) only contains the non-zero entries where
    ![](img/B19849_08_61.png) was non-zero. Now that we’ve learned about collaborative
    filtering in detail, let’s understand it further practically by considering a
    few examples of how to implement a collaborative filtering recommender system.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we’ll learn how to use different C++ libraries for
    developing recommender systems.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of item-based collaborative filtering with C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s look at how we can implement a collaborative filtering recommender system.
    We’ll be using the MovieLens dataset provided by GroupLens from the research lab
    in the Department of Computer Science and Engineering at the University of Minnesota:
    [https://grouplens.org/datasets/movielens/](B19849_08.xhtml#_idTextAnchor473).
    They’ve provided a full dataset containing 20 million movie ratings and a smaller
    one for education that contains 100,000 ratings. We recommend starting with the
    smaller one because it allows us to see results earlier and detect implementation
    errors faster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This dataset consists of several files, but we’re only interested in two of
    them: `ratings.csv` and `movies.csv`. The rating file contains lines with the
    following format: the user ID, the movie ID, the rating, and the timestamp. In
    this dataset, users made ratings on a 5-star scale, with half-star increments
    (0.5 stars to 5.0 stars). The movie’s file contains lines with the following format:
    the movie ID, the title, and the genre. The movie ID is the same in both files
    so that we can see which movies users are rating.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the Eigen library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let’s learn how to implement a collaborative filtering recommender system
    based on matrix factorization with ALS and with a pure linear algebra library
    as a backend. In the following sample, we’re using the `Eigen` library. The steps
    to implement a collaborative filtering recommender system are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must make base type definitions, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'These definitions allow us to write less source code for matrices’ types and
    to quickly change floating-point precision. Next, we must define and initialize
    the ratings (preferences) matrix, list of movie titles, and binary rating flags
    matrix, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We have a particular helper function, `LoadMovies`, which loads files into
    the map container, as shown in the following code snippet:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the data has been loaded, we can initialize matrix objects so that they’re
    the right size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: However, because we’ve loaded data into the map, we need to move the required
    rating values to the matrix object.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we must initialize the movie titles list, convert user IDs into our zero-based
    sequential order, and initialize the binary rating matrix (this is used in the
    algorithm to deal with implicit data), as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the rating matrix has been initialized, we must define and initialize
    our training variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we must define and initialize the regularization matrix and identity
    matrices, which are constant during all learning cycles:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Additionally, because we’re implementing an algorithm version that can handle
    implicit data, we need to convert our rating matrix into another format to decrease
    computational complexity. Our version of the algorithm needs user ratings in the
    form of ![](img/B19849_08_62.png) and diagonal matrices for every user and item
    so that we can make two containers with corresponding matrix objects. The code
    for this can be seen in the following block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we’re ready to implement the main learning loop. As discussed previously,
    the ALS algorithm can be easily parallelized, so we use the `OpenMP` compiler
    extension to calculate user and item parameters in parallel.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s define the main learning cycle, which runs for a specified number of
    iterations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following code shows how to update item parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following code shows how to update users’ preferences:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we have two parts of the loop body that are pretty much the same. First,
    we updated item parameters with frizzed user options, and then we updated user
    preferences with frizzed item parameters. Notice that all matrix objects were
    moved outside of the internal loop body to reduce memory allocations and significantly
    improve program performance. Also, notice that we parallelized the user and item
    parameters’ calculations separately because one of them should always be frizzed
    when the other is being calculated. To calculate exact values for user preferences
    and item parameters, we must use the following formula:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B19849_08_63.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*X T X* and *Y T Y* are precomputed at each step. Also, notice that these formulas
    are expressed in the form of the linear equation system, *X = AB*. We use the
    `colPivHouseholderQr` function from the `Eigen` library to solve it and get exact
    values for the user and item parameters. This linear equation system can also
    be solved with other methods. The `colPivHouseholderQr` function was chosen because
    it shows a better ratio between computational speed and accuracy in the `Eigen`
    library implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To estimate the progress of the learning process of our system, we can calculate
    the **mean squared error** (**MSE**) between the original rating matrix and a
    predicted one. To calculate the predicted rating matrix, we must define another
    function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To calculate the MSE, we can use the ![](img/B19849_08_64.png) expression from
    our optimization function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Please note that we have to use weights and binary ratings to get a meaningful
    value for the error because a similar approach was used during the learning process.
    Direct error calculation gives the wrong result because the predicted matrix has
    non-zero predictions, whereas the original rating matrix has zeros. It’s essential
    to understand that this algorithm doesn’t learn the original scale of ratings
    (from 0 to 5); instead, it learns prediction values in a range from 0 to 1\. It
    follows on from the function we optimize, as shown here:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B19849_08_65.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We can use the previously defined movies list to show movie recommendations.
    The following function shows user preferences and system recommendations. To identify
    what a user likes, we’ll show movie titles that the user has rated with a rating
    value of more than 3\. We’ll also show movies that the system rates as equal to
    or higher than a 0.8 rating coefficient to identify which movie the system recommends
    to the user by running the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This function can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Using the mlpack library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `mlpack` library is a general-purpose machine learning library that provides
    a lot of different algorithms and command-line tools to process the data and learn
    these algorithms without explicit programming. As a basis, this library uses the
    `Armadillo` linear algebra library for math calculations. Other libraries we’ve
    used in previous chapters don’t have collaborative filtering algorithm implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To load the `MovieLens` dataset, use the same loading helper function that
    you did in the previous section. Once the data has been loaded, convert it into
    a format suitable for an object of the `mlpack::cf::CFType` type. This type implements
    a collaborative filtering algorithm and can be configured with different types
    of matrix factorization approaches. An object of this type can use dense as well
    as sparse rating matrices. In the case of a dense matrix, it should have three
    rows. The first row corresponds to users, the second row corresponds to items,
    and the third row corresponds to the rating. This structure is called a `arma::SpMat<DataType>`
    type from the `Armadillo` library, as illustrated in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can initialize the `mlpack::cf::CFType` class object. It takes the
    next parameters in the constructor: the rating matrix, the matrix decomposition
    policy, the number of neighbors, the number of target factors, the number of iterations,
    and the minimum value of learning error, after which the algorithm can stop.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this object, only perform the nearest neighbor search on the **H** matrix.
    This means you avoid calculating the full rating matrix, using the observation
    that if the rating matrix is **X = W H**, then the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This expression can be seen as the nearest neighbor search on the **H** matrix
    with the Mahalanobis distance, as illustrated in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that as a decomposition policy, the object of the `mlpack::NMFPolicy`
    type was used. This shows how to implement the non-negative matrix factorization
    algorithm with the ALS approach. There are several decomposition algorithms in
    the `mlpack` library. For example, batch SVD decomposition is implemented in the
    `mlpack::BatchSVDPolicy` type. The constructor of this object also does the complete
    training, so after its call has finished, we can use this object to get recommendations.
    Recommendations can be retrieved with the `GetRecommendations` method. This method
    gets the number of recommendations you want to get, the output matrix for recommendations,
    and the list of user IDs for users you want to get recommendations from, as shown
    in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the `GetRecommendations` method returns the item IDs as its output.
    So, we can see that using this library for implementing a recommender system is
    much easier than writing it from scratch. Also, there are many more configuration
    options in the `mlpack` library for building such systems—for example, we can
    configure the neighbor detection policy and which distance measure to use. These
    configurations can significantly improve the quality of the system you build because
    you can make them according to your particular task.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we discussed what recommender systems are and the types that
    exist today. We studied two main approaches to building recommender systems: content-based
    recommendations and collaborative filtering. We identified two types of collaborative
    filtering: user-based and item-based. Then, we looked at how to implement these
    approaches, as well as their pros and cons. We found out that an important issue
    we must rectify when implementing recommender systems is the amount of data and
    the associated large computational complexity of algorithms. We considered approaches
    to overcome computational complexity problems, such as partial data updates and
    approximate iterative algorithms such as ALS. We found out how matrix factorization
    can help to solve the problem with incomplete data, improve the generalizability
    of the model, and speed up the calculations. We also implemented a system of collaborative
    filtering based on the linear algebra library and used the `mlpack` general-purpose
    machine learning library.'
  prefs: []
  type: TYPE_NORMAL
- en: It makes sense to look at new methods that can be applied to recommender system
    tasks, such as autoencoders, variational autoencoders, or deep collaborative approaches.
    In recent research papers, these approaches show more impressive results than
    classical methods such as ALS. All these new methods are non-linear models, so
    they can potentially beat the limited modeling capacity of linear factor models.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll discuss ensemble learning techniques. The main idea
    of these techniques is to combine either different types of machine learning algorithms
    or use a set of the same kind of algorithms to obtain better predictive performance.
    Combining several algorithms into one ensemble allows us to get the best characteristics
    of each so that we can cover the disadvantages in a single algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Collaborative Filtering for Implicit Feedback* *Datasets*: [http://yifanhu.net/PUB/cf.pdf](B19849_08.xhtml#_idTextAnchor476)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ALS Implicit Collaborative* *Filtering*: [https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe](B19849_08.xhtml#_idTextAnchor482)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Collaborative* *Filtering*: [https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/](B19849_08.xhtml#_idTextAnchor485)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `mlpack` library’s official site: [https://www.mlpack.org/](B19849_08.xhtml#_idTextAnchor488)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Armadillo` library’s official site: [http://arma.sourceforge.net/](B19849_08.xhtml#_idTextAnchor489)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Variational Autoencoders for Collaborative Filtering,* by Dawen Liang, Rahul
    G. Krishnan, Matthew D. Hoffman, and Tony Jebara: [https://arxiv.org/abs/1802.05814](B19849_08.xhtml#_idTextAnchor492)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deep Learning-Based Recommender System: A Survey and New Perspectives*, by
    Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay: [https://arxiv.org/abs/1707.07435](B19849_08.xhtml#_idTextAnchor495)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Training Deep AutoEncoders for Collaborative Filtering*, by Oleksii Kuchaiev,
    and Boris Ginsburg: [https://arxiv.org/abs/1708.01715](B19849_08.xhtml#_idTextAnchor438)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
