- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Recommender Systems
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统
- en: 'Recommender systems are algorithms, programs, and services that are designed
    to use data to predict which objects (goods or services) are of interest to a
    user. There are two main types of recommender systems: *content-based* and *collaborative
    filtering*. **Content-based recommender systems** are based on data that’s been
    collected from specific products. They recommend objects to a user that are similar
    to ones the user has previously acquired or shown interest in. **Collaborative
    filtering recommender systems** filter out objects that a user might like based
    on the reaction history of other, similar users of these systems. They also usually
    consider the user’s previous reactions.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是设计用来使用数据预测用户可能感兴趣的对象（商品或服务）的算法、程序和服务。主要有两种类型的推荐系统：*基于内容的*和*协同过滤*。**基于内容的推荐系统**基于从特定产品收集的数据。它们向用户推荐与用户之前获取或表现出兴趣的对象相似的对象。**协同过滤推荐系统**根据其他类似用户的反应历史过滤掉用户可能喜欢的对象。它们通常还会考虑用户的先前反应。
- en: 'In this chapter, we’ll learn how to implement recommender system algorithms
    based on both content and collaborative filtering. We’re going to discuss different
    approaches for implementing collaborative filtering algorithms, implement systems
    using only the linear algebra library, and learn how to use the `mlpack` library
    to solve collaborative filtering problems. We’ll be using the MovieLens dataset
    provided by GroupLens from a research lab in the Department of Computer Science
    and Engineering at the University of Minnesota: [https://grouplens.org/datasets/movielens/](B19849_08.xhtml#_idTextAnchor473).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何根据内容和协同过滤实现推荐系统算法。我们将讨论实现协同过滤算法的不同方法，使用仅包含线性代数库的系统实现系统，并学习如何使用`mlpack`库解决协同过滤问题。我们将使用明尼苏达大学计算机科学与工程学院一个研究实验室提供的MovieLens数据集：[https://grouplens.org/datasets/movielens/](B19849_08.xhtml#_idTextAnchor473)。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: An overview of recommender system algorithms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统算法概述
- en: Understanding the collaborative filtering method
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解协同过滤方法
- en: Examples of item-based collaborative filtering with C++
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于C++的基于物品的协同过滤示例
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To complete this chapter, you’ll need the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成本章，你需要以下内容：
- en: The `Eigen` library
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Eigen`库'
- en: The `Armadillo` library
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Armadillo`库'
- en: The `mlpack` library
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlpack`库'
- en: A modern C++ compiler with C++20 support
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 C++20 的现代C++编译器
- en: CMake build system version >= 3.10
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CMake构建系统版本 >= 3.10
- en: 'The code files for this chapter can be found in this book’s GitHub repository:
    [https://github.com/PacktPublishing/Hands-On-Machine-Learning-with-C-Second-Edition/tree/main/Chapter08](B19849_08.xhtml#_idTextAnchor470).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在本书的GitHub仓库中找到：[https://github.com/PacktPublishing/Hands-On-Machine-Learning-with-C-Second-Edition/tree/main/Chapter08](B19849_08.xhtml#_idTextAnchor470)。
- en: An overview of recommender system algorithms
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统算法概述
- en: A recommender system’s task is to inform a user about an object that could be
    the most interesting to them at a given time. Often, such an object is a product
    or service, but it may be information—for example, in the form of a recommended
    news article.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统的任务是通知用户在特定时间可能对他们最有兴趣的对象。通常，这样的对象是产品或服务，但它也可能是信息——例如，以推荐新闻文章的形式。
- en: 'Before we dive into the technicalities of the recommender system, let’s look
    at some real-world scenarios where recommender systems are used to improve user
    experience and increase sales. The following are the most common applications:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨推荐系统的技术细节之前，让我们看看一些实际场景，在这些场景中，推荐系统被用来改善用户体验并增加销售额。以下是最常见的应用：
- en: Recommender systems help online retailers suggest products that might interest
    a customer based on their past purchases, browsing history, and other data. This
    helps customers find relevant products more easily and increases the likelihood
    of conversion.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统帮助在线零售商根据客户的过去购买、浏览历史和其他数据建议可能感兴趣的产品。这有助于客户更容易地找到相关产品，并增加转换的可能性。
- en: Music and video streaming services use recommender systems to suggest music
    or videos based on a user’s listening or viewing history. The goal is to provide
    personalized content recommendations that keep users engaged with the platform.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音乐和视频流媒体服务使用推荐系统根据用户的收听或观看历史推荐音乐或视频。目标是提供个性化的内容推荐，以保持用户对平台的参与度。
- en: Social media platforms such as Meta and Instagram use recommender systems to
    show users content from friends and pages they might be interested in. This keeps
    users engaged and spending time on the platform.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交媒体平台如Meta和Instagram使用推荐系统向用户展示他们可能感兴趣的朋友和页面内容。这有助于保持用户活跃并花费更多时间在平台上。
- en: Advertisers use recommender systems to target adverts at specific audiences
    based on their interests, demographics, and behavior. This improves the effectiveness
    of advertising campaigns.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广告商利用推荐系统，根据他们的兴趣、人口统计和行为，针对特定受众投放广告。这提高了广告活动的有效性。
- en: News websites, blogs, and search engines use recommender systems to recommend
    articles, stories, or search results based on user preferences and search history.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新闻网站、博客和搜索引擎利用推荐系统，根据用户偏好和搜索历史推荐文章、故事或搜索结果。
- en: Recommender systems can be used to suggest treatments, medications, or medical
    procedures based on patient data and medical research.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统可以根据患者数据和医学研究，建议治疗方案、药物或医疗程序。
- en: Travel websites and hotel booking platforms use recommender systems to suggest
    travel destinations, accommodations, and activities based on a traveler’s preferences,
    budget, and travel history.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旅行网站和酒店预订平台利用推荐系统，根据旅行者的偏好、预算和旅行历史，推荐旅行目的地、住宿和活动。
- en: Educational platforms and online courses use recommender systems to personalize
    learning experiences by suggesting courses, materials, and learning paths based
    on student performance, interests, and goals.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教育平台和在线课程利用推荐系统，根据学生的表现、兴趣和目标，推荐课程、材料和学习路径，以实现个性化学习体验。
- en: Video game platforms use recommender systems to suggest games based on player
    preferences, play style, and gaming history.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频游戏平台利用推荐系统，根据玩家的偏好、游戏风格和游戏历史推荐游戏。
- en: These are just a few examples of how recommender systems are applied in real-life
    scenarios. They’ve become an essential tool for businesses looking to improve
    customer engagement, increase sales, and provide personalized experiences.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是推荐系统在实际场景中应用的一些例子。它们已成为企业寻求提高客户参与度、增加销售额和提供个性化体验的必备工具。
- en: 'Despite the many existing algorithms, we can divide recommender systems into
    several basic approaches. The most common are as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在许多现有算法，我们仍然可以将推荐系统分为几种基本方法。最常见的方法如下：
- en: '**Summary-based**: Non-personal models based on the average product rating'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于总结**：基于平均产品评分的非个性化模型'
- en: '**Content-based**: Models based on the intersection of product descriptions
    and user interests'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于内容**：基于产品描述与用户兴趣交集的模型'
- en: '**Collaborative filtering**: Models based on interests of similar user groups'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协同过滤**：基于相似用户群体兴趣的模型'
- en: '**Matrix factorization**: Methods based on the preferences matrix’s decomposition'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**矩阵分解**：基于偏好矩阵分解的方法'
- en: 'The basis of any recommender system is the preferences matrix. It has all users
    of the service laid on one of the axes and recommendation objects on the other.
    The recommendation objects are usually called **items**. At the intersection of
    rows and columns (user, item), this matrix is filled with ratings that indicate
    user interest in a product, expressed on a given scale (for example, from 1 to
    5), as illustrated in the following table:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 任何推荐系统的基础是偏好矩阵。它将服务的所有用户放在一个轴上，推荐对象放在另一个轴上。推荐对象通常被称为**项目**。在行和列（用户、项目）的交叉处，这个矩阵填充了表示用户对产品的兴趣的评分，这些评分是在给定的尺度上表达的（例如，从1到5），如下表所示：
- en: '|  | **item1** | **item 2** | **item3** |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | **item1** | **item 2** | **item3** |'
- en: '| user1 | 1 |  |  |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| user1 | 1 |  |  |'
- en: '| user2 |  | 2 | 4 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| user2 |  | 2 | 4 |'
- en: '| user3 | 1 | 1 | 1 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| user3 | 1 | 1 | 1 |'
- en: '| user4 |  |  | 5 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| user4 |  |  | 5 |'
- en: '| user5 | 3 | 1 |  |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| user5 | 3 | 1 |  |'
- en: '| user6 |  | 4 |  |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| user6 |  | 4 |  |'
- en: Table 8.1 – User interest count
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.1 – 用户兴趣计数
- en: Users usually evaluate only a small number of the items in the catalog; the
    task of the recommender system is to summarize this information and predict the
    attitude the user might have toward other items. In other words, you need to fill
    in all the blank cells in the preceding table.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 用户通常只评估目录中少量项目；推荐系统的任务是总结这些信息并预测用户可能对其他项目的态度。换句话说，你需要填写前面表格中的所有空白单元格。
- en: 'People’s consumption patterns are different, and new products don’t have to
    be recommended all the time. You can show repeated items—for example, when a user
    has bought something they’ll need again. According to this principle, there are
    two groups of items:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 人们的消费模式各不相同，不必总是推荐新产品。您可以在用户需要再次购买某物时展示重复的物品——例如，当用户购买了一些他们将来还会需要的东西时。根据这一原则，存在两类物品：
- en: '**Repeatable**: For example, shampoos or razors, which are always needed'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重复的**：例如，洗发水或剃须刀，总是需要使用的'
- en: '**Unrepeatable**: For example, books or films, which are rarely purchased repeatedly'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不可重复的**：例如，书籍或电影，很少会重复购买'
- en: If the product can’t be attributed to one of these groups, it makes sense to
    determine the group type of repetitive purchases individually (someone usually
    buys only a specific brand, but someone else might try everything in the catalog).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果产品不能归入这些类别之一，那么确定重复购买的产品类型就很有意义（有人通常只购买特定品牌的产品，但其他人可能会尝试目录中的所有产品）。
- en: Determining what product *interests* a user is also subjective. Some users need
    things only from their favorite category (conservative recommendations), while
    others respond more to non-standard goods (risky recommendations). For example,
    a video-hosting service may only recommend new series from their favorite TV series
    (conservative) but may periodically recommend new shows or new genres. Ideally,
    you should choose a strategy for displaying recommendations for each client separately
    by using generalized information about the client’s preferences.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 确定什么产品会吸引用户也是主观的。一些用户只需要他们最喜欢的类别的物品（保守型推荐），而其他人则对非标准商品（风险型推荐）反应更强烈。例如，一个视频托管服务可能只会推荐他们最喜欢的电视剧的新系列（保守型），但可能会定期推荐新的节目或新的类型。理想情况下，您应该使用客户偏好的泛化信息，为每个客户分别选择显示推荐策略。
- en: 'The essential part of datasets that are used to build recommendation models
    is user reactions to different objects or items. These reactions are typically
    called user ratings of objects. We can obtain user ratings in the following ways:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 用于构建推荐模型的必要数据集部分是用户对不同对象或物品的反应。这些反应通常被称为对象的用户评分。我们可以通过以下方式获取用户评分：
- en: '**Explicit ratings**: The user gives their rating for the product, leaves a
    review, or *likes* the page.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**显式评分**：用户对产品进行评分，留下评论，或*点赞*页面。'
- en: '**Implicit ratings**: The user doesn’t express their attitude, but an indirect
    conclusion can be made from their actions. For example, if they bought a product,
    it means they like it; if they read the description for a long time, it means
    they have serious interest.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐式评分**：用户没有表达他们的态度，但可以从他们的行为中得出间接结论。例如，如果他们购买了一个产品，这意味着他们喜欢它；如果他们长时间阅读描述，这意味着他们有浓厚的兴趣。'
- en: Of course, explicit preferences are better. However, in practice, not all services
    allow users to express their interests clearly, and not all users have the desire
    to do so. Both types of assessments are often used in tandem and complement each
    other well.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，显式偏好更好。然而，在实践中，并非所有服务都允许用户清楚地表达他们的兴趣，并非所有用户都有此愿望。这两种评估类型通常同时使用，并且很好地相互补充。
- en: It’s also essential to distinguish between the terms *prediction* (the prediction
    of the degree of interest) and the *recommendation* itself (showing the recommendation).
    How to show something is a separate task from the task of *what to show*. *How
    to show* is a task that uses the estimates obtained in the prediction step, and
    can be implemented in different ways.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 区分术语*预测*（预测兴趣程度）和*推荐*本身（展示推荐）也是非常重要的。如何展示是一个独立于*展示什么*的任务。*如何展示*是一个使用预测步骤中获得的估计的任务，并且可以以不同的方式实现。
- en: In this section, we discussed the basics of recommender systems. In the following
    sections, we’ll look at the essential building blocks of recommender systems.
    Let’s begin by looking at the main principles of content-based filtering, user
    and item-based collaborative filtering, and collaborative filtering based on matrix
    factorization.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了推荐系统的基础知识。在接下来的章节中，我们将探讨推荐系统的基本构建块。让我们首先看看基于内容的过滤、基于用户和物品的协同过滤以及基于矩阵分解的协同过滤的主要原则。
- en: Non-personalized recommendations
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非个性化推荐
- en: 'For non-personalized recommendations, the potential interest of the user is
    determined by the average rating of the product: *if everyone likes it, you’ll
    like it too*. According to this principle, most services work when the user isn’t
    authorized on the system.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非个性化推荐，用户的潜在兴趣由产品的平均评分决定：*如果每个人都喜欢它，你也会喜欢它*。根据这个原则，大多数服务在用户未在系统上授权时工作。
- en: Content-based recommendations
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于内容的推荐
- en: Personal recommendations use the maximum information available about the user—primarily,
    information about their previous purchases. Content-based filtering was one of
    the first approaches to be developed for personalized recommendations. In this
    approach, the product’s description (content) is compared with the interests of
    the user, which are obtained from their previous assessments. The more the product
    meets these interests, the higher the potential interest of the user. The obvious
    requirement here is that all products in the catalog should have a description.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 个人推荐使用关于用户可用的最大信息——主要是他们之前购买的信息。基于内容的过滤是用于个性化推荐最早开发的方法之一。在这种方法中，产品的描述（内容）与用户的兴趣进行比较，这些兴趣是从他们之前的评估中获得的。产品越能满足这些兴趣，用户的潜在兴趣就越高。这里的一个明显要求是，目录中的所有产品都应该有描述。
- en: 'Historically, the subject of content-based recommendations was products with
    unstructured descriptions: films, books, or articles. Their features may be, for
    example, text descriptions, reviews, or casts. However, nothing prevents the use
    of usual numerical or categorical features.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，基于内容的推荐的主题是具有无结构描述的产品：电影、书籍或文章。它们的特征可能是，例如，文本描述、评论或演员阵容。然而，没有任何东西阻止使用常规的数值或分类特征。
- en: Unstructured features are described in a text-typical way—vectors in the space
    of words (vector-space model). Each element of a vector is a feature that potentially
    characterizes the interest of the user. Similarly, an item (product) is a vector
    in the same space.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 无结构特征以文本典型的方式进行描述——词空间中的向量（向量空间模型）。向量的每个元素都是一个特征，它可能表征了用户的兴趣。同样，一个项目（产品）是这个空间中的向量。
- en: As users interact with the system (say, they buy films), the vector descriptions
    of the goods they’ve purchased merge (sum up and normalize) into a single vector
    and, thus, form the vector of a user’s interests. Using this vector of interests,
    we can find the product and the description of which is closest to it—that is,
    we can solve the problem of finding the nearest neighbors.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户与系统互动时（例如，他们购买电影），他们购买的商品的向量描述会合并（求和并归一化）成一个单一的向量，从而形成用户兴趣的向量。使用这个兴趣向量，我们可以找到与它最接近的产品和描述——即，我们可以解决寻找最近邻的问题。
- en: When forming the vector space of a product presentation, instead of individual
    words, you can use shingles or n-grams (successive pairs of words, triples of
    words, or other numbers of words). This approach makes the model more detailed,
    but more data is required for training.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在形成产品展示的向量空间时，你不仅可以使用单个单词，还可以使用shingles或n-grams（连续的单词对、三词组或其他数量的单词）。这种方法使模型更加详细，但需要更多的数据进行训练。
- en: In different places of the description of the product, the weight of keywords
    may differ (for example, the description of the film may consist of a title, a
    brief description, and a detailed description). Product descriptions from different
    users can be weighed differently. For example, we can give more weight to active
    users who have many ratings. Similarly, you can weigh them by item. The higher
    the average rating of an object, the greater its weight (similar to PageRank).
    If the product description allows links to external sources, then you can also
    analyze all third-party information related to the product.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在产品描述的不同位置，关键词的权重可能不同（例如，电影的描述可能包括标题、简短描述和详细描述）。来自不同用户的商品描述可以有不同的权重。例如，我们可以给评分多的活跃用户更多的权重。同样，你也可以按项目来权衡。一个对象的平均评分越高，其权重就越大（类似于PageRank）。如果产品描述允许链接到外部来源，那么你还可以分析与产品相关的所有第三方信息。
- en: The cosine distance is often used to compare product representation vectors.
    This distance measures the value of proximity between two vectors.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦距离常用于比较产品表示向量。这个距离衡量了两个向量之间接近度的值。
- en: When adding a new assessment, the vector of interests is updated incrementally
    (only for those elements that have changed). During the update, it makes sense
    to give a bit more weight to new estimates since the user’s preferences may change.
    You’ll notice that content-based filtering almost wholly repeats the query-document
    matching mechanism used in search engines such as Google. The only difference
    lies in the form of a search query—content filtering systems use a vector that
    describes the interests of the user, whereas search engines use keywords of the
    requested document. When search engines began to add personalization, this distinction
    was erased even more.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加新的评估时，兴趣向量会增量更新（仅针对那些发生变化的元素）。在更新过程中，由于用户的偏好可能会改变，因此给予新的估计更多权重是有意义的。你会注意到基于内容的过滤几乎完全重复了搜索引擎如Google所使用的查询-文档匹配机制。唯一的区别在于搜索查询的形式——内容过滤系统使用描述用户兴趣的向量，而搜索引擎使用请求文档的关键词。当搜索引擎开始添加个性化时，这种区别被进一步抹去。
- en: User-based collaborative filtering
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于用户的协同过滤
- en: This class of system began to develop in the 90s. Under this approach, recommendations
    are generated based on the interests of other, similar users. Such recommendations
    are the result of the **collaboration** of many users, hence the name of the method.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这类系统在90年代开始发展。在这种方法下，推荐是基于其他相似用户的兴趣生成的。这种推荐是许多用户**协作**的结果，因此得名该方法。
- en: The classical implementation of the algorithm is based on the principle of **k-nearest
    neighbors** (**kNN**). For every user, we look for the **k** most similar to them
    (in terms of preferences). Then, we supplement the information about the user
    with known data from their neighbors. So, for example, if it’s known that your
    neighbors are delighted with a movie, and you haven’t watched it for some reason,
    this is a great reason to recommend this movie.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的经典实现基于**k最近邻**（**kNN**）的原则。对于每个用户，我们寻找与他们最相似的前**k**个（就偏好而言）。然后，我们使用已知的数据补充用户的信息。例如，如果已知你的邻居对一部电影感到非常满意，而你由于某种原因没有看过，这是一个很好的推荐这部电影的理由。
- en: The similarity is, in this case, a synonym for a *correlation* of interests
    and can be considered in many ways—Pearson’s correlation, cosine distance, Jaccard
    distance, Hamming distance, and other types of distances.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，相似性是兴趣**相关性**的同义词，可以从许多方面考虑——皮尔逊相关系数、余弦距离、Jaccard距离、汉明距离以及其他类型的距离。
- en: The classical implementation of the algorithm has one distinct disadvantage—it’s
    poorly applicable in practice due to the quadratic complexity of the calculations.
    As with any nearest neighbor method, it requires all pairwise distances between
    users to be calculated (and there may be millions of users). It’s easy to calculate
    that the complexity of calculating the distance matrix is ![](img/B19849_08_01.png),
    where ![](img/B19849_Formula_001.png) is the number of users, and ![](img/B19849_08_03.png)
    is the number of items (goods).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的经典实现有一个明显的缺点——由于计算的二次复杂性，它在实践中应用得不好。与任何最近邻方法一样，它需要计算用户之间的所有成对距离（可能有数百万用户）。很容易计算出计算距离矩阵的复杂度是
    ![](img/B19849_08_01.png)，其中 ![](img/B19849_Formula_001.png) 是用户的数量，而 ![](img/B19849_08_03.png)
    是物品（商品）的数量。
- en: 'This problem can be partly mitigated by purchasing high-performance hardware.
    But if you approach it wisely, then it’s better to introduce some corrections
    to the algorithm in the following way:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通过购买高性能硬件可以部分缓解这个问题。但如果你明智地处理，那么最好是以下这种方式对算法进行一些修正：
- en: Update distances not with every purchase but with batches (for example, once
    a day)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要在每次购买时更新距离，而是以批量（例如，每天一次）更新
- en: Don’t recalculate the distance matrix completely, but update it incrementally
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要完全重新计算距离矩阵，而是增量更新
- en: Choose some iterative and approximate algorithms (for example, **Alternating
    Least** **Squares** (**ALS**))
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一些迭代和近似算法（例如，**交替最小二乘法**（**ALS**））
- en: 'Fulfill the following assumptions to make the algorithm more practical:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 满足以下假设可以使算法更加实用：
- en: The tastes of people don’t change over time (or they do change, but they’re
    the same for everyone)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人们的品味不会随时间改变（或者它们会改变，但每个人都是相同的）
- en: If people’s tastes are the same, then they’re the same in everything
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果人们的品味相同，那么他们在所有事情上都是相同的
- en: For example, if two clients prefer the same films, then they also like the same
    book. This assumption is often the case when the recommended products are homogeneous
    (for example, films only). If this isn’t the case, then a couple of clients may
    well have the same eating habits but their political views might be the opposite;
    here, the algorithm is less efficient.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果两个客户喜欢相同的电影，那么他们也会喜欢相同的书籍。当推荐的产品是同质化的（例如，仅限电影）时，这种假设通常是成立的。如果情况不是这样，那么一对客户可能有相同的饮食习惯，但他们的政治观点可能正好相反；在这种情况下，算法的效率较低。
- en: The neighborhood of the user in the space of preferences (the user’s neighbors),
    which we analyze to generate new recommendations, can be chosen in different ways.
    We can work with all users of the system; we can set a certain proximity threshold;
    we can choose several neighbors at random; or we can take the **k** most similar
    neighbors (this is the most popular approach). If we take too many neighbors,
    we get a higher chance of random noise, and vice versa. If we take too little,
    we get more accurate recommendations, but fewer goods can be recommended.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析以生成新推荐的偏好空间中的用户邻域（用户的邻居），可以选择不同的方式。我们可以与系统中的所有用户一起工作；我们可以设置一个特定的接近度阈值；我们可以随机选择几个邻居；或者我们可以选择**k**个最相似的邻居（这是最流行的方法）。如果我们选择太多的邻居，我们得到更高的随机噪声机会，反之亦然。如果我们选择太少的邻居，我们得到更准确的推荐，但可以推荐的商品更少。
- en: An interesting development in the collaborative approach is trust-based recommendations,
    which take into account not only the proximity of people according to their interests
    but also their *social* proximity and the degree of trust between them. If, for
    example, we see that on Facebook, a girl occasionally visits a page that has her
    friend’s audio recordings, then she trusts her musical taste. Therefore, when
    making recommendations to the girl, you can add new songs from her friend’s playlist.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤方法中的一个有趣的发展是基于信任的推荐，它不仅考虑了人们根据兴趣的接近程度，还考虑了他们之间的社会接近程度以及他们之间的信任程度。例如，如果我们看到在Facebook上，一个女孩偶尔访问一个有她朋友音频录音的页面，那么她信任她的音乐品味。因此，在向这个女孩推荐时，你可以添加她朋友播放列表中的新歌曲。
- en: Item-based collaborative filtering
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于项目的协同过滤
- en: The item-based approach is a natural alternative to the classic user-based approach
    described previously and almost repeats it, except for one thing—it applies to
    the transposed preference matrix, which looks for similar products instead of
    users.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 基于项目的这种方法是之前描述的经典基于用户方法的自然替代品，几乎重复了它，除了一个方面——它适用于转置的偏好矩阵，寻找类似的产品而不是用户。
- en: For each client, a user-based collaborative filtering system searches a group
    of customers who are similar to this user in terms of previous purchases, and
    then the system averages their preferences. These average preferences serve as
    recommendations for the user. In the case of item-based collaborative filtering,
    the nearest neighbors are searched for on a variety of products (items) using
    the columns of a preference matrix, and the averaging occurs precisely according
    to them.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个客户，基于用户的协同过滤系统会搜索一组与该用户在以往购买方面相似的客户，然后系统平均他们的偏好。这些平均偏好作为对用户的推荐。在基于项目的协同过滤的情况下，使用偏好矩阵的列在各种产品（项目）上搜索最近邻，平均也正好根据这些最近邻进行。
- en: If some products are meaningfully similar to each other, then users’ reactions
    to these products will be the same. Therefore, when we see that some products
    have a strong correlation between their estimates, this may indicate that these
    products are equivalent to each other.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果某些产品之间在意义上相似，那么用户对这些产品的反应也将相同。因此，当我们看到某些产品在其估计之间存在强烈的关联时，这可能表明这些产品彼此之间是等效的。
- en: The main advantage of the item-based approach over the user-based approach is
    lower computation complexity. When there are many users (almost always), the task
    of finding the nearest neighbor becomes poorly computable. For example, for 1
    million users, you need to calculate and store ~500 billion distances. If the
    distance is encoded in 8 bytes, this results in 4 **terabytes** (**TB**) for the
    distance matrix alone. If we take an item-based approach, then the computational
    complexity decreases from ![](img/B19849_08_04.png) to ![](img/B19849_08_05.png),
    and the distance matrix has a dimension no longer than 1 million per 1 million
    but 100 by 100, as per the number of items (goods).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于用户的方案相比，基于物品的方法的主要优势是计算复杂度更低。当用户数量很多（几乎总是如此）时，找到最近邻的任务变得难以计算。例如，对于100万用户，你需要计算和存储大约5000亿个距离。如果距离用8个字节编码，这仅距离矩阵就需要4
    **太字节**（**TB**）。如果我们采用基于物品的方法，那么计算复杂度将从 ![](img/B19849_08_04.png) 降低到 ![](img/B19849_08_05.png)，并且距离矩阵的维度不再是每100万用户就有100万，而是根据商品（物品）的数量，是100乘以100。
- en: Estimating the proximity of products is much more accurate than assessing the
    proximity of users. This assumption is a direct consequence of the fact that there
    are usually many more users than items, and therefore the standard error in calculating
    the correlation of items is significantly less because we have more information
    to work from.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 估计产品的邻近度比评估用户的邻近度要准确得多。这个假设是这样一个事实的直接后果：通常用户比物品多得多，因此计算物品相关性的标准误差显著较小，因为我们有更多的工作信息。
- en: In the user-based version, the description of users usually has a very sparse
    distribution (there are many goods, but only a few evaluations). On the one hand,
    this helps to optimize the calculation—we multiply only those elements where an
    intersection exists. But, on the other hand, the list of items that a system can
    recommend to a user is minimal due to the limited number of user neighbors (users
    who have similar preferences). Also, user preferences may change over time, but
    the descriptions of the goods are much more stable.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于用户的版本中，用户的描述通常具有非常稀疏的分布（有很多商品，但只有少数评价）。一方面，这有助于优化计算——我们只乘那些存在交集的元素。但另一方面，由于用户邻居（具有相似偏好的用户）的数量有限，系统可以向用户推荐的商品列表非常有限。此外，用户偏好可能会随时间变化，但商品的描述则要稳定得多。
- en: 'The rest of the algorithm almost wholly repeats the user-based version: it
    uses the same cosine distance as the primary measure of proximity and has the
    same need for data normalization. Since the correlation of items is considered
    on a higher number of observations, it isn’t as critical to recalculate it after
    each new assessment, and this can be done periodically in a batch mode.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的其余部分几乎完全重复了基于用户的版本：它使用相同的余弦距离作为距离的主要度量，并且需要相同的数据归一化。由于在更多的观察上考虑了物品的相关性，因此不需要在每次新的评估后重新计算它，这可以通过批量模式定期完成。
- en: Now, let’s look at another approach to generalizing user interests based on
    matrix factorization methods.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看另一种基于矩阵分解方法来泛化用户兴趣的方法。
- en: Factorization algorithms
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分解算法
- en: It would be nice to describe the interests of the user with more extensive features—not
    in the format of *they love movies X, Y, and Z*, but in the format of *they love
    romantic comedies*. Besides the fact that it increases the generalizability of
    the model, it also solves the problem of having a large data dimension—after all,
    the interests are described not by the items vector, but by a significantly smaller
    preference vector.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，如果能用更广泛的特征来描述用户的兴趣那就更好了——不是用*他们喜欢电影X、Y和Z*这样的格式，而是用*他们喜欢浪漫喜剧*这样的格式。除了增加模型的可泛化性之外，这还能解决数据维度大的问题——毕竟，兴趣不是由物品向量来描述的，而是由一个显著更小的偏好向量来描述的。
- en: Such approaches are also called **spectral decomposition** or **high-frequency
    filtering** (since we remove the noise and leave the useful signal). There are
    many different types of matrix decomposition in algebra, and one of the most commonly
    used is called **singular value** **decomposition** (**SVD**).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法也被称为**谱分解**或**高频滤波**（因为我们去除了噪声，留下了有用的信号）。代数中有许多不同的矩阵分解类型，其中最常用的一种被称为**奇异值分解**（**SVD**）。
- en: Initially, the SVD method was used to select pages that are similar in meaning
    but not in content. More recently, it has started being used in recommendations.
    The method is based on decomposing the original *R* rating matrix into a product
    of three matrices, ![](img/B19849_08_06.png), where the sizes of the matrices
    are ![](img/B19849_08_07.png) and *r* is the rank of the decomposition, which
    is the parameter characterizing the degree of detail decomposition.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，奇异值分解（SVD）方法用于选择在意义上相似但在内容上不同的页面。最近，它开始被用于推荐。该方法基于将原始的 *R* 评分矩阵分解为三个矩阵的乘积，![](img/B19849_08_06.png)，其中矩阵的大小是
    ![](img/B19849_08_07.png)，*r* 是分解的秩，它是描述分解详细程度的参数。
- en: 'Applying this decomposition to our matrix of preferences, we can get the following
    two matrices of factors (abbreviated descriptions):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 将这种分解应用于我们的偏好矩阵，我们可以得到以下两个因素矩阵（简称为描述）：
- en: '**U**: A compact description of user preferences'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**U**：对用户偏好的紧凑描述'
- en: '**S**: A compact description of the characteristics of the product'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S**：对产品特性的紧凑描述'
- en: When using this approach, we can’t know which particular characteristics correspond
    to the factors in the reduced descriptions; for us, they’re encoded with some
    numbers. Therefore, SVD is an uninterpreted model. It’s sufficient to multiply
    the matrix of factors to obtain an approximation of the matrix of preferences.
    By doing this, we get a rating for all customer-product pairs.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用这种方法时，我们无法知道哪些特定的特性对应于简化描述中的因素；对我们来说，它们被编码为一些数字。因此，奇异值分解（SVD）是一个未解释的模型。通过乘以因素矩阵，我们可以获得偏好矩阵的近似值。通过这样做，我们得到了所有客户-产品对的评分。
- en: 'A typical family of such algorithms is called **non-negative matrix factorization**
    (**NMF**). As a rule, the calculation of such expansions is very computationally
    expensive. Therefore, in practice, they often resort to their approximate iterative
    variants. ALS is a popular iterative algorithm for decomposing a matrix of preferences
    into a product of two matrices: **user factors** (**U**) and **product factors**
    (**I**). It works on the principle of minimizing the **root mean square error**
    (**RMSE**) on the affixed ratings. Optimization takes place alternately—first
    by user factors, then by product factors. Also, to avoid retraining, the regularization
    coefficients are added to the RMSE.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的算法族通常被称为**非负矩阵分解**（**NMF**）。通常，这种展开的计算非常耗时。因此，在实践中，他们经常求助于它们的近似迭代变体。交替最小二乘法（ALS）是一种流行的迭代算法，用于将偏好矩阵分解为两个矩阵的乘积：**用户因素**（**U**）和**产品因素**（**I**）。它基于最小化固定评分的**均方根误差**（**RMSE**）。优化是交替进行的——首先通过用户因素，然后通过产品因素。此外，为了避免重新训练，正则化系数被添加到RMSE中。
- en: If we supplement the matrix of preferences with a new dimension containing information
    about the user or product, then we can work not with the matrix of preferences,
    but with the tensor. Thus, we use more available information and possibly get
    a more accurate model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在偏好矩阵中补充一个包含有关用户或产品信息的新维度，那么我们就可以不与偏好矩阵，而与张量一起工作。因此，我们使用更多可用的信息，并可能得到一个更精确的模型。
- en: In this section, we considered different approaches to solving recommender systems’
    tasks. Now, we’re going to discuss methods for estimating the similarity of user
    preferences.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们考虑了解决推荐系统任务的不同方法。现在，我们将讨论估计用户偏好相似性的方法。
- en: Similarity or preferences correlation
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相似性或偏好相关性
- en: We can consider the similarity or correlation of two user preferences in different
    ways, but in general, we need to compare two vectors. Let’s look at some of the
    most popular vector comparison measures.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从不同的角度考虑两个用户偏好的相似性或相关性，但通常我们需要比较两个向量。让我们看看一些最流行的向量比较度量。
- en: Pearson’s correlation coefficient
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 皮尔逊相关系数
- en: 'This measure is a classic coefficient that can be applied when comparing vectors.
    Its primary disadvantage is that when the intersection is estimated as low, then
    the correlation can be high by accident. To combat accidental high correlation,
    you can multiply by a factor of 50/min (50, rating intersection) or any other
    damping factor, the effect of which decreases with an increasing number of estimates.
    An example is shown here:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这个度量是一个经典的系数，可以在比较向量时应用。它的主要缺点是，当交集被估计为低时，相关性可能会意外地很高。为了对抗意外的过高相关性，你可以乘以50/min（50，评分交集）或任何其他阻尼因子，其效果随着估计数量的增加而降低。这里有一个例子：
- en: '![](img/B19849_08_08.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19849_08_08.jpg)'
- en: Spearman’s correlation
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 斯皮尔曼相关系数
- en: 'The main difference compared to Pearson’s correlation is the rank factor—that
    is, it doesn’t work with absolute values of ratings, but with their sequence numbers.
    In general, the result is very close to Pearson’s correlation. An example is shown
    here:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_09.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: Cosine distance
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Cosine distance is another classic measuring factor. If you look closely, the
    cosine of the angle between the standardized vectors is Pearson’s correlation,
    the same formula. This distance uses cosine properties: if the two vectors are
    co-directed (that is, the angle between them is 0), then the cosine of the angle
    between them is 1\. Conversely, the cosine of the angle between perpendicular
    vectors is 0\. An example is shown here:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_10.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: With that, we’ve discussed methods we can use to estimate the similarity of
    user preferences. The next important issue we’ll discuss is preparing data so
    that it can be used in recommender system algorithms.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Data scaling and standardization
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All users evaluate (rate) items differently. If someone puts 5s in a row, instead
    of waiting for 4s from someone else, it’s better to normalize the data before
    calculating it—that is, convert the data into a single scale so that the algorithm
    can compare the results correctly. After, the predicted estimate needs to be converted
    into the original scale via inverse transformation (and, if necessary, rounded
    to the nearest whole number).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several ways to normalize data:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '**Centering (mean-centering)**: From the user’s ratings, subtract their average
    rating. This type of normalization is only relevant for non-binary matrices.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standardization (z-score)**: In addition to centering, this divides the user’s
    rating by the standard deviation of the user. But in this case, after the inverse
    transformation, the rating can go beyond the scale (for example, six on a five-point
    scale), but such situations are quite rare and can be solved by rounding to the
    nearest acceptable estimate.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Double standardization**: The first time data is normalized by user ratings;
    the second time, by item ratings.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The details of these normalization techniques were provided in [*Chapter 2*](B19849_02.xhtml#_idTextAnchor075),
    *Data Processing*. The following section will describe a problem with recommender
    systems known as the **cold start problem**, which appears in the early stages
    of system work when the system doesn’t have enough data to make predictions.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Cold start problem
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A cold start is a typical situation when a sufficient amount of data hasn’t
    been accumulated for the correct operation of the recommender system yet (for
    example, when a product is new or is just rarely bought). If the ratings of only
    three users estimate the average rating, such an assessment isn’t reliable, and
    users understand this. In such situations, ratings are often artificially adjusted.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: The first way to do this is to show not the average value, but the smoothed
    average (damped mean). With a small number of ratings, the displayed rating leans
    more toward a specific safe *average* indicator, and as soon as a sufficient number
    of new ratings are typed, the *averaging* adjustment stops operating.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Another approach is to calculate confidence intervals for each rating. Mathematically,
    the more estimates we have, the smaller the variation of the average will be and,
    therefore, the more confidence we have in its accuracy.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: For example, we can display the lower limit of the interval (low **confidence
    interval** (**CI**) bound) as a rating. At the same time, it’s clear that such
    a system is quite conservative, with a tendency to underestimate ratings for new
    items.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Since the estimates are limited to a specific scale (for example, from 0 to
    1), the usual methods for calculating the confidence interval are poorly applicable
    here due to the distribution tails that go to infinity, and the symmetry of the
    interval itself. There’s a more accurate way to calculate it—the Wilson CI.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: The cold start problem is also relevant for non-personalized recommendations.
    The general approach here is to replace what currently can’t be calculated by
    different heuristics—for example, replace it with an average rating, use a simpler
    algorithm, or not use the product at all until the data has been collected.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Another issue that should be considered when we develop a recommender system
    is the relevance of recommendations, which considers factors other than the user’s
    interests—for example, it can be the freshness of a publication or a user’s rating.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Relevance of recommendations
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In some cases, it’s also essential to consider the *freshness* of the recommendation.
    This consideration is especially important for articles or posts on forums. Fresh
    entries should often get to the top. The correction factors (damping factors)
    are usually used to make such updates. The following formulas are used for calculating
    the rating of articles on media sites.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of a rating calculation in the *Hacker* news magazine:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_11.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
- en: Here, *U* denotes upvotes, *D* denotes downvotes, *P* denotes penalty (additional
    adjustment for the implementation of other business rules), and *T* denotes recording
    time.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'The following equation shows a *Reddit* rating calculation:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_12.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
- en: Here, *U* denotes the number of upvotes, *D* denotes the number of downvotes,
    and *T* denotes the recording time. The first term evaluates the *quality of the
    record*, and the second corrects for the time.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: There’s no universal formula, and each service invents the formula that best
    solves its problem; it can only be tested empirically.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: The following section will discuss the existing approaches to testing recommender
    systems. This isn’t a straightforward task because it’s usually hard to estimate
    the quality of a recommendation without having exact target values in a training
    dataset.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Assessing system quality
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Testing a recommender system is a complicated process that always poses many
    questions, mainly due to the ambiguity of the concept of *quality*.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, in machine learning problems, there are two main approaches to
    testing:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Offline model testing on historical data using retro tests
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing the model using A/B testing (we run several options and see which one
    gives the best result)
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these approaches are actively used in developing recommender systems.
    The main limitation that we have to face is that we can only evaluate the accuracy
    of the forecast on those products that the user has already evaluated or rated.
    The standard approach is to use cross-validation alongside the **leave-one-out**
    and **leave-p-out** methods. Repeating the test and averaging the results provides
    a more stable assessment of quality.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: The *leave-one-out* approach uses the model that’s been trained on all items
    except one and is evaluated by the user. This excluded item is used for model
    testing. This procedure is done for all *n* items, and an average is calculated
    among the obtained *n* quality estimates.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: The *leave-p-out* approach is the same, but at each step, ![](img/B19849_Formula_119.png)
    points are excluded.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'We can divide all quality metrics into the following three categories:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '**Prediction accuracy**: Estimates the accuracy of the predicted rating'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decision support**: Evaluates the relevance of the recommendations'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rank accuracy metrics**: Evaluates the quality of the ranking of recommendations
    issued'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unfortunately, there’s no single recommended metric for all occasions, and everyone
    who’s involved in testing a recommender system selects it to fit their goals.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we’ll formalize the collaborative filtering method
    and show the math behind it.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the collaborative filtering method
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll formalize the recommender system problem. We have a set
    of users, ![](img/B19849_08_14.png), a set of items, ![](img/B19849_08_15.png)
    (movies, tracks, products, and so on), and a set of estimates, ![](img/B19849_08_16.png).
    Each estimate is given by a user ![](img/B19849_08_17.png), an object ![](img/B19849_Formula_0721.png),
    its result ![](img/B19849_08_19.png), and, possibly, some other characteristics.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re required to predict preference as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_20.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: 'We’re required to predict personal recommendations as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_21.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
- en: 'We’re required to predict similar objects as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_22.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: 'Remember that the main idea behind collaborative filtering is that similar
    users usually like similar objects. Let’s start with the simplest method:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Select some conditional measures of similarity of users according to their history
    of ![](img/B19849_08_23.png) ratings.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Unite users into groups (clusters) so that similar users will end up in the
    same cluster: ![](img/B19849_08_24.png).'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Predict the item’s user rating as the cluster’s average rating for this object:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B19849_08_25.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
- en: 'This algorithm has several problems:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: There’s nothing to recommend to new or atypical users. For such users, there’s
    no suitable cluster with similar users.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It ignores the specificity of each user. In a sense, we divide all users into
    classes (templates).
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no one in the cluster has rated the item, the prediction won’t work.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can improve this method and replace hard clustering with the following formula:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_26.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
- en: 'For an item-based version, the formula will be symmetrical, as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_27.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
- en: 'These approaches have the following disadvantages:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Cold start problem
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bad predictions for new and atypical users or items
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trivial recommendations
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resource intensity calculations
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To overcome these problems, you can use SVD. The preference (ratings) matrix
    can be decomposed into the product of three matrices, ![](img/B19849_08_28.png).
    Let’s denote the product of the first two matrices for one matrix, ![](img/B19849_08_29.png),
    where *R* is the matrix of preferences, *U* is the matrix of parameters of users,
    and *V* is the matrix of parameters of items.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: 'To predict the user rating, *U*, for an item, ![](img/B19849_08_30.png), we
    take a vector, ![](img/B19849_08_31.png) (parameter set), for a given user and
    a vector for a given item, ![](img/B19849_08_32.png). Their scalar product is
    the prediction we need: ![](img/B19849_08_33.png). Using this approach, we can
    identify the hidden features of items and user interests by user history. For
    example, it may happen that at the first coordinate of the vector, each user has
    a number indicating whether the user is more likely to be a boy or a girl, and
    the second coordinate is a number reflecting the approximate age of the user.
    In the item, the first coordinate shows whether it’s more interesting to boys
    or girls, and the second one shows the age group of users this item appeals to.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: However, there are also several problems. The first one is the preferences matrix,
    *R*, which isn’t entirely known to us, so we can’t merely take its SVD decomposition.
    Secondly, the SVD decomposition isn’t the only one we have, so even if we find
    at least some decomposition, it’s unlikely that it’s optimal for our task.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we need machine learning. We can’t find the SVD decomposition of the
    matrix since we don’t know the matrix itself. However, we can take advantage of
    this idea and come up with a prediction model that works like SVD. Our model depends
    on many parameters—vectors of users and items. For the given parameters, to predict
    the estimate, we must take the user vector, the vector of the item, and get their
    scalar product, ![](img/B19849_08_34.png). However, since we don’t know vectors,
    they still need to be obtained. The idea is that we have user ratings with which
    we can find optimal parameters so that our model can predict these estimates as
    accurately as possible using the following equation: ![](img/B19849_08_35.png).
    We want to find such parameters’ *θ* values so that the square error is as small
    as possible. We also want to make fewer mistakes in the future, but we don’t know
    what estimates we need. Accordingly, we can’t optimize parameters’ *θ* values.
    We already know the ratings given by users, so we can try to choose parameters
    based on the estimates we already have to minimize the error. We can also add
    another term, the *regularizer*, as shown here:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_36.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
- en: 'Regularization is needed to combat overfitting. To find the optimal parameters,
    you need to optimize the following function:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_37.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
- en: 'There are many parameters: for each user and item, we have the vector that
    we want to optimize. The most well-known method for optimizing functions is **gradient
    descent** (**GD**). Suppose we have a function of many variables, and we want
    to optimize it. We take an initial value, and then we look at where we can move
    to minimize this value. The GD method is an iterative algorithm—it takes the parameters
    of a certain point repeatedly, looks at the gradient, and steps against its direction,
    as shown here:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_38.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: 'There are various problems with this method: it works very slowly and it finds
    local, rather than global, minima. The second problem isn’t so bad for us because
    in our case, the value of the function in local minima is close to the global
    optimum.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the GD method isn’t always necessary. For example, if we need to calculate
    the minimum for a parabola, there’s no need to act by this method as we know precisely
    where its minimum is. It turns out that the functionality that we’re trying to
    optimize—the sum of the squares of errors plus the sum of the squares of all the
    parameters—is also a quadratic function, which is very similar to a parabola.
    For each specific parameter, if we fix all the others, it’s just a parabola. For
    those, we can accurately determine at least one coordinate. The ALS method is
    based on this assumption. We alternate between accurately finding minima in one
    coordinate or another, as shown here:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_39.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
- en: 'We fix all the parameters of the items, optimize the parameters of users, fix
    the parameters of users, and then optimize the parameters of items. We act iteratively,
    as shown here:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_40.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
- en: 'This method works reasonably quickly, and you can parallelize each step. However,
    there’s still a problem with implicit data because we have neither full user data
    nor full item data. So, we can penalize the items that don’t have ratings in the
    update rule. By doing so, we depend only on the items that have ratings from the
    users and don’t make any assumptions about the items that aren’t rated. So, let’s
    define a weight matrix, ![](img/B19849_08_41.png), as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_42.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
- en: 'The cost functions that we’re trying to minimize look like this:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_43.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
- en: 'Note that we need regularization terms to avoid overfitting the data. We can
    use the following solutions for factor vectors:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_44.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
- en: Here, ![](img/B19849_08_45.png) and ![](img/B19849_08_46.png)are diagonal matrices.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: 'Another approach for dealing with implicit data is to introduce confidence
    levels. Let’s define a set of binary observation variables:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_47.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
- en: 'Now, we can define confidence levels for each ![](img/B19849_08_48.png) value.
    When ![](img/B19849_08_49.png), we have low confidence. This can be because the
    user has never been exposed to that item or it may be unavailable at the time.
    For example, it could be explained by the user buying a gift for someone else.
    Hence, we would have *low confidence*. When ![](img/B19849_08_50.png) is larger,
    we should have much more confidence. For example, we can define confidence as
    follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_51.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/B19849_08_52.png) is a hyperparameter that should be tuned for
    a given dataset. The updated optimization function is as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_53.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: 'Here, ![](img/B19849_08_54.png) is a diagonal matrix with ![](img/B19849_08_55.png)
    values. The following solutions are for user and item ratings:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_56.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
- en: 'However, it’s an expensive computational problem to calculate the ![](img/B19849_08_57.png)
    expression. However, it can be optimized in the following way:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19849_08_58.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
- en: This means that ![](img/B19849_08_59.png) can be precomputed at each of the
    steps, and ![](img/B19849_08_60.png) only contains the non-zero entries where
    ![](img/B19849_08_61.png) was non-zero. Now that we’ve learned about collaborative
    filtering in detail, let’s understand it further practically by considering a
    few examples of how to implement a collaborative filtering recommender system.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we’ll learn how to use different C++ libraries for
    developing recommender systems.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Examples of item-based collaborative filtering with C++
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s look at how we can implement a collaborative filtering recommender system.
    We’ll be using the MovieLens dataset provided by GroupLens from the research lab
    in the Department of Computer Science and Engineering at the University of Minnesota:
    [https://grouplens.org/datasets/movielens/](B19849_08.xhtml#_idTextAnchor473).
    They’ve provided a full dataset containing 20 million movie ratings and a smaller
    one for education that contains 100,000 ratings. We recommend starting with the
    smaller one because it allows us to see results earlier and detect implementation
    errors faster.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'This dataset consists of several files, but we’re only interested in two of
    them: `ratings.csv` and `movies.csv`. The rating file contains lines with the
    following format: the user ID, the movie ID, the rating, and the timestamp. In
    this dataset, users made ratings on a 5-star scale, with half-star increments
    (0.5 stars to 5.0 stars). The movie’s file contains lines with the following format:
    the movie ID, the title, and the genre. The movie ID is the same in both files
    so that we can see which movies users are rating.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Using the Eigen library
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let’s learn how to implement a collaborative filtering recommender system
    based on matrix factorization with ALS and with a pure linear algebra library
    as a backend. In the following sample, we’re using the `Eigen` library. The steps
    to implement a collaborative filtering recommender system are as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must make base type definitions, as follows:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'These definitions allow us to write less source code for matrices’ types and
    to quickly change floating-point precision. Next, we must define and initialize
    the ratings (preferences) matrix, list of movie titles, and binary rating flags
    matrix, as follows:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We have a particular helper function, `LoadMovies`, which loads files into
    the map container, as shown in the following code snippet:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once the data has been loaded, we can initialize matrix objects so that they’re
    the right size:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: However, because we’ve loaded data into the map, we need to move the required
    rating values to the matrix object.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we must initialize the movie titles list, convert user IDs into our zero-based
    sequential order, and initialize the binary rating matrix (this is used in the
    algorithm to deal with implicit data), as follows:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the rating matrix has been initialized, we must define and initialize
    our training variables:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, we must define and initialize the regularization matrix and identity
    matrices, which are constant during all learning cycles:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Additionally, because we’re implementing an algorithm version that can handle
    implicit data, we need to convert our rating matrix into another format to decrease
    computational complexity. Our version of the algorithm needs user ratings in the
    form of ![](img/B19849_08_62.png) and diagonal matrices for every user and item
    so that we can make two containers with corresponding matrix objects. The code
    for this can be seen in the following block:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now, we’re ready to implement the main learning loop. As discussed previously,
    the ALS algorithm can be easily parallelized, so we use the `OpenMP` compiler
    extension to calculate user and item parameters in parallel.
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let’s define the main learning cycle, which runs for a specified number of
    iterations:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following code shows how to update item parameters:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following code shows how to update users’ preferences:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here, we have two parts of the loop body that are pretty much the same. First,
    we updated item parameters with frizzed user options, and then we updated user
    preferences with frizzed item parameters. Notice that all matrix objects were
    moved outside of the internal loop body to reduce memory allocations and significantly
    improve program performance. Also, notice that we parallelized the user and item
    parameters’ calculations separately because one of them should always be frizzed
    when the other is being calculated. To calculate exact values for user preferences
    and item parameters, we must use the following formula:'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B19849_08_63.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: '*X T X* and *Y T Y* are precomputed at each step. Also, notice that these formulas
    are expressed in the form of the linear equation system, *X = AB*. We use the
    `colPivHouseholderQr` function from the `Eigen` library to solve it and get exact
    values for the user and item parameters. This linear equation system can also
    be solved with other methods. The `colPivHouseholderQr` function was chosen because
    it shows a better ratio between computational speed and accuracy in the `Eigen`
    library implementation.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'To estimate the progress of the learning process of our system, we can calculate
    the **mean squared error** (**MSE**) between the original rating matrix and a
    predicted one. To calculate the predicted rating matrix, we must define another
    function:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To calculate the MSE, we can use the ![](img/B19849_08_64.png) expression from
    our optimization function:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Please note that we have to use weights and binary ratings to get a meaningful
    value for the error because a similar approach was used during the learning process.
    Direct error calculation gives the wrong result because the predicted matrix has
    non-zero predictions, whereas the original rating matrix has zeros. It’s essential
    to understand that this algorithm doesn’t learn the original scale of ratings
    (from 0 to 5); instead, it learns prediction values in a range from 0 to 1\. It
    follows on from the function we optimize, as shown here:'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/B19849_08_65.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
- en: 'We can use the previously defined movies list to show movie recommendations.
    The following function shows user preferences and system recommendations. To identify
    what a user likes, we’ll show movie titles that the user has rated with a rating
    value of more than 3\. We’ll also show movies that the system rates as equal to
    or higher than a 0.8 rating coefficient to identify which movie the system recommends
    to the user by running the following code:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This function can be used as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using the mlpack library
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `mlpack` library is a general-purpose machine learning library that provides
    a lot of different algorithms and command-line tools to process the data and learn
    these algorithms without explicit programming. As a basis, this library uses the
    `Armadillo` linear algebra library for math calculations. Other libraries we’ve
    used in previous chapters don’t have collaborative filtering algorithm implementations.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'To load the `MovieLens` dataset, use the same loading helper function that
    you did in the previous section. Once the data has been loaded, convert it into
    a format suitable for an object of the `mlpack::cf::CFType` type. This type implements
    a collaborative filtering algorithm and can be configured with different types
    of matrix factorization approaches. An object of this type can use dense as well
    as sparse rating matrices. In the case of a dense matrix, it should have three
    rows. The first row corresponds to users, the second row corresponds to items,
    and the third row corresponds to the rating. This structure is called a `arma::SpMat<DataType>`
    type from the `Armadillo` library, as illustrated in the following code block:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we can initialize the `mlpack::cf::CFType` class object. It takes the
    next parameters in the constructor: the rating matrix, the matrix decomposition
    policy, the number of neighbors, the number of target factors, the number of iterations,
    and the minimum value of learning error, after which the algorithm can stop.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'For this object, only perform the nearest neighbor search on the **H** matrix.
    This means you avoid calculating the full rating matrix, using the observation
    that if the rating matrix is **X = W H**, then the following applies:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This expression can be seen as the nearest neighbor search on the **H** matrix
    with the Mahalanobis distance, as illustrated in the following code block:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Notice that as a decomposition policy, the object of the `mlpack::NMFPolicy`
    type was used. This shows how to implement the non-negative matrix factorization
    algorithm with the ALS approach. There are several decomposition algorithms in
    the `mlpack` library. For example, batch SVD decomposition is implemented in the
    `mlpack::BatchSVDPolicy` type. The constructor of this object also does the complete
    training, so after its call has finished, we can use this object to get recommendations.
    Recommendations can be retrieved with the `GetRecommendations` method. This method
    gets the number of recommendations you want to get, the output matrix for recommendations,
    and the list of user IDs for users you want to get recommendations from, as shown
    in the following code block:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Notice that the `GetRecommendations` method returns the item IDs as its output.
    So, we can see that using this library for implementing a recommender system is
    much easier than writing it from scratch. Also, there are many more configuration
    options in the `mlpack` library for building such systems—for example, we can
    configure the neighbor detection policy and which distance measure to use. These
    configurations can significantly improve the quality of the system you build because
    you can make them according to your particular task.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we discussed what recommender systems are and the types that
    exist today. We studied two main approaches to building recommender systems: content-based
    recommendations and collaborative filtering. We identified two types of collaborative
    filtering: user-based and item-based. Then, we looked at how to implement these
    approaches, as well as their pros and cons. We found out that an important issue
    we must rectify when implementing recommender systems is the amount of data and
    the associated large computational complexity of algorithms. We considered approaches
    to overcome computational complexity problems, such as partial data updates and
    approximate iterative algorithms such as ALS. We found out how matrix factorization
    can help to solve the problem with incomplete data, improve the generalizability
    of the model, and speed up the calculations. We also implemented a system of collaborative
    filtering based on the linear algebra library and used the `mlpack` general-purpose
    machine learning library.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: It makes sense to look at new methods that can be applied to recommender system
    tasks, such as autoencoders, variational autoencoders, or deep collaborative approaches.
    In recent research papers, these approaches show more impressive results than
    classical methods such as ALS. All these new methods are non-linear models, so
    they can potentially beat the limited modeling capacity of linear factor models.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll discuss ensemble learning techniques. The main idea
    of these techniques is to combine either different types of machine learning algorithms
    or use a set of the same kind of algorithms to obtain better predictive performance.
    Combining several algorithms into one ensemble allows us to get the best characteristics
    of each so that we can cover the disadvantages in a single algorithm.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Collaborative Filtering for Implicit Feedback* *Datasets*: [http://yifanhu.net/PUB/cf.pdf](B19849_08.xhtml#_idTextAnchor476)'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ALS Implicit Collaborative* *Filtering*: [https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe](B19849_08.xhtml#_idTextAnchor482)'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Collaborative* *Filtering*: [https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/](B19849_08.xhtml#_idTextAnchor485)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `mlpack` library’s official site: [https://www.mlpack.org/](B19849_08.xhtml#_idTextAnchor488)'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Armadillo` library’s official site: [http://arma.sourceforge.net/](B19849_08.xhtml#_idTextAnchor489)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Variational Autoencoders for Collaborative Filtering,* by Dawen Liang, Rahul
    G. Krishnan, Matthew D. Hoffman, and Tony Jebara: [https://arxiv.org/abs/1802.05814](B19849_08.xhtml#_idTextAnchor492)'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deep Learning-Based Recommender System: A Survey and New Perspectives*, by
    Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay: [https://arxiv.org/abs/1707.07435](B19849_08.xhtml#_idTextAnchor495)'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Training Deep AutoEncoders for Collaborative Filtering*, by Oleksii Kuchaiev,
    and Boris Ginsburg: [https://arxiv.org/abs/1708.01715](B19849_08.xhtml#_idTextAnchor438)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
