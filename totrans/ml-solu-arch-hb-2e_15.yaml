- en: '15'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '15'
- en: Navigating the Generative AI Project Lifecycle
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索生成式人工智能项目生命周期
- en: As briefly mentioned in *Chapter 3*, *Exploring ML Algorithms*, generative AI
    represents a category of AI focused on generating new data, such as text, images,
    videos, music, or other content, based on input data. This technology has the
    potential to transform numerous industries, offering capabilities previously unattainable.
    From entertainment to healthcare to financial services, generative AI exhibits
    a wide range of practical applications capable of solving intricate problems and
    creating innovative solutions.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如在第3章*探索机器学习算法*中简要提到的，生成式人工智能代表了一类人工智能，它专注于根据输入数据生成新的数据，如文本、图像、视频、音乐或其他内容。这项技术有潜力改变众多行业，提供以前无法实现的能力。从娱乐到医疗保健到金融服务，生成式人工智能展示了广泛的应用，能够解决复杂问题并创造创新解决方案。
- en: 'In this chapter, we will embark on a practical journey, guiding you through
    the process of turning a generative AI project from a business concept to deployment.
    We will delve into the various stages of a generative AI project’s lifecycle,
    exploring different generative technologies, methodologies, and best practices.
    Specifically, we will cover the following key topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将开始一段实用的旅程，引导您将生成式人工智能项目从商业概念到部署的过程。我们将深入研究生成式人工智能项目生命周期的各个阶段，探索不同的生成技术、方法和最佳实践。具体来说，我们将涵盖以下关键主题：
- en: The advancement and economic impact of generative AI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式人工智能的进步和经济效益
- en: What industries are doing with generative AI
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各行业如何使用生成式人工智能
- en: The lifecycle of a generative AI project and the core technology
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式人工智能项目的生命周期和核心技术
- en: The limitations and challenges of generative AI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式人工智能的限制和挑战
- en: The advancement and economic impact of generative AI
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式人工智能的进步和经济效益
- en: Over the past decade, there has been remarkable progress in the field of generative
    AI, which involves the creation of realistic images, audio, video, and text. This
    advancement has been driven by increased computational power, access to vast internet
    datasets, and advancement in ML algorithms. Both open-source communities and commercial
    entities have played pivotal roles in pushing the boundaries of generative AI.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 过去十年间，在生成式人工智能领域取得了显著的进步，这涉及到现实图像、音频、视频和文本的创建。这一进步得益于计算能力的提升、对大量互联网数据集的访问以及机器学习算法的进步。开源社区和商业实体在推动生成式人工智能边界扩展方面发挥了关键作用。
- en: Prominent organizations like OpenAI, Stability AI, Meta, Google, the **Technology
    Innovation Institute** (**TII**), Hugging Face, and EleutherAI have contributed
    by open sourcing models such as GPT-2, OPT, LlaMA, Falcon, BLOOM, and GPT-J, fostering
    innovation within the community. On the commercial front, companies like OpenAI,
    Anthropics, Cohere, Amazon, and Google have made substantial investments in proprietary
    models like GPT-4, Claude, Cohere, Titan, and PaLM, leveraging cutting-edge transformer
    architectures and massive computational resources.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如OpenAI、Stability AI、Meta、Google、**技术创新研究所**（**TII**）、Hugging Face和EleutherAI等知名组织通过开源模型如GPT-2、OPT、LlaMA、Falcon、BLOOM和GPT-J等方式做出了贡献，促进了社区内的创新。在商业方面，OpenAI、Anthropics、Cohere、Amazon和Google等公司对GPT-4、Claude、Cohere、Titan和PaLM等专有模型进行了大量投资，利用了最尖端的Transformer架构和庞大的计算资源。
- en: The pace of development in generative AI is unprecedented. For instance, in
    November 2022, OpenAI released ChatGPT, a conversational chatbot based on LLM
    GPT3.5 turbo. Four months later, they released GPT-4, showcasing significant advancements.
    Similarly, Anthropics’ generative AI model, Claude, expanded its text processing
    capabilities from around 9,000 tokens per single API call when it debuted in March
    2023 to processing 100,000 tokens by May 2023, and to 200,000 tokens in November
    2023\. In the open-source realm, Meta launched Llama 2 in July 2023, building
    upon the success of LLaMA introduced in February 2023\. TII introduced its Falcon
    model with 40 billion parameters in May 2023, followed by a more advanced 180
    billion parameters model in September 2023, demonstrating a continuous evolution.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能的发展速度前所未有。例如，2022年11月，OpenAI发布了基于LLM GPT3.5 turbo的对话聊天机器人ChatGPT。四个月后，他们发布了GPT-4，展示了显著的进步。同样，Anthropics的生成式人工智能模型Claude，在2023年3月首次亮相时，单个API调用处理能力约为9,000个标记，到2023年5月增加到100,000个标记，到2023年11月达到200,000个标记。在开源领域，Meta于2023年7月推出了Llama
    2，这是在2023年2月引入的LLaMA成功的基础上进行的。TII于2023年5月推出了拥有400亿参数的Falcon模型，随后在2023年9月推出了参数更先进的1,800亿参数模型，展示了持续的发展。
- en: Generative AI is poised to have a profound impact across various industry sectors,
    potentially contributing trillions of dollars to the global economy. Industries
    such as banking, high tech, and life sciences stand to benefit significantly,
    with generative AI playing a substantial role in their revenue streams.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能预计将在各个行业领域产生深远的影响，可能为全球经济贡献数万亿美元。如银行、高科技和生命科学等行业将显著受益，生成式人工智能将在它们的收入流中扮演重要角色。
- en: While the excitement surrounding generative AI is palpable, its full potential
    will take time to realize. Leaders in both business and society face substantial
    challenges, including managing the inherent risks associated with generative AI,
    identifying the new skills and capabilities required by the workforce, and reevaluating
    core business processes. It’s also essential to acknowledge that while generative
    AI is a rapidly advancing technology, ML continues to account for the majority
    of the overall potential value within the field of AI.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管围绕生成式人工智能的兴奋情绪明显，但其全部潜力需要时间才能实现。商业和社会的领导者面临着重大挑战，包括管理生成式人工智能固有的风险、确定劳动力所需的新技能和能力、以及重新评估核心业务流程。同时，也必须承认，尽管生成式人工智能是一项快速发展的技术，但机器学习（ML）仍然占人工智能领域整体潜在价值的多数。
- en: What industries are doing with generative AI
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 各行业如何使用生成式人工智能
- en: Enterprises across diverse sectors are actively engaging in the exploration
    of potential applications for generative AI technology, even though it is still
    early days in the adoption of generative AI. These enterprises are looking into
    this innovative technology to drive tangible business outcomes including increased
    productivity, enhanced customer experiences, novel business insights, and the
    creation of new products and services. With all the excitement surrounding this
    technology, it is also important to understand what’s practical and what is aspirational.
    With that in mind, let’s delve into some active areas of exploration of the adoption
    of generative AI.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 各个行业的企业都在积极探索生成式人工智能技术的潜在应用，尽管生成式人工智能的采用还处于早期阶段。这些企业正在研究这项创新技术，以推动可衡量的业务成果，包括提高生产力、增强客户体验、新颖的业务洞察以及新产品和服务的创造。鉴于围绕这项技术的兴奋情绪，了解哪些是实际可行的，哪些是具有抱负的也同样重要。考虑到这一点，让我们深入了解一些生成式人工智能采用的活跃探索领域。
- en: Financial services
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 金融服务业
- en: As leaders in technology adoption, financial services firms are actively exploring
    generative AI use cases across banking, capital markets, insurance, and financial
    data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作为技术采纳的领导者，金融服务业公司正在积极探索生成式人工智能在银行、资本市场、保险和金融数据等领域的应用案例。
- en: The majority of current generative AI applications focus on document analysis,
    knowledge search, insight generation, and content creation. For example, some
    financial services firms are building generative-AI-powered financial research
    applications to rapidly analyze public and proprietary data to identify investment
    opportunities and risks. Other financial firms are using generative AI to create
    summaries of vast amounts of proprietary research reports for a quick understanding
    of key investment insights. Insurance companies are piloting generative AI to
    extract required information from various sources to streamline underwriting and
    claims processing and provide underwriters the ability to interactively query
    documents.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当前大多数生成式人工智能应用集中在文档分析、知识搜索、洞察生成和内容创作上。例如，一些金融服务业公司正在构建由生成式人工智能驱动的金融研究应用，以快速分析公开和专有数据，以识别投资机会和风险。其他金融公司正在使用生成式人工智能来创建大量专有研究报告的摘要，以便快速了解关键投资洞察。保险公司正在试点使用生成式人工智能从各种来源提取所需信息，以简化承保和索赔处理，并使承保人能够交互式地查询文档。
- en: Generative AI is proving valuable in investigating financial fraud scenarios.
    Payment companies, for instance, are applying these models to streamline fraud
    alert validation. For example, when an internal system flags a suspicious transaction,
    the generative model can rapidly correlate this alert with relevant external data.
    This may involve scanning the news and public records to uncover negative events
    related to the transacting entities. Moreover, the model can uncover hidden relationships
    in the transaction path that suggest illegitimate activity. By augmenting fraud
    analysts with an AI assistant that can quickly surface supporting contextual insights
    from large, disparate sources, cases can be prioritized and validated more efficiently.
    This allows a faster response to prevent fraudulent transactions while reducing
    false positives and manual review overhead.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 生成人工智能在调查金融欺诈场景中证明非常有价值。例如，支付公司正在应用这些模型来简化欺诈警报验证。例如，当一个内部系统标记可疑交易时，生成模型可以迅速将此警报与相关外部数据相关联。这可能涉及扫描新闻和公共记录，以揭露与交易实体相关的负面事件。此外，该模型可以发现交易路径中的隐藏关系，这表明存在非法活动。通过为欺诈分析师配备一个能够快速从大量不同来源中提取支持性上下文洞察的人工智能助手，可以更有效地优先处理和验证案例。这允许更快地响应以防止欺诈交易，同时减少误报和人工审查的负担。
- en: Financial services institutions are deploying conversational AI and generative
    models to enhance customer support interactions. Virtual assistants powered by
    these models can understand customer queries and automatically provide answers
    to common questions. They can also generate personalized product or service recommendations
    based on customer needs and transaction history. For complex customer inquiries,
    generative models help point users to relevant articles or offer next-best actions
    to resolve issues. For task fulfillment, these AI agents can guide customers through
    processes, collect necessary information, and complete end-to-end fulfillment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 金融服务机构正在部署对话式人工智能和生成模型来增强客户支持互动。由这些模型驱动的虚拟助手能够理解客户查询并自动提供常见问题的答案。它们还可以根据客户需求和交易历史生成个性化的产品或服务推荐。对于复杂的客户咨询，生成模型有助于引导用户查找相关文章或提供最佳下一步行动以解决问题。对于任务履行，这些人工智能代理可以指导客户完成流程，收集必要信息，并完成端到端履行。
- en: Leading-edge financial institutions are piloting the use of generative AI to
    automatically formulate new market hypotheses and trading strategies. By analyzing
    a large volume of historical market data, research, and event narratives, these
    models can help identify hidden relationships, patterns, and insights. The generated
    hypotheses can highlight promising new signals, strategies, and relationships
    that complement conventional quantitative analysis. This enables institutions
    to combine ML with human intelligence to create innovative, differentiated investing
    and trading approaches.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 领先的金融机构正在试点使用生成人工智能来自动制定新的市场假设和交易策略。通过分析大量历史市场数据、研究和事件叙述，这些模型可以帮助识别隐藏的关系、模式和见解。生成的假设可以突出有希望的新信号、策略和关系，这些可以补充传统的定量分析。这使得机构能够将机器学习与人类智能相结合，创造创新、差异化的投资和交易方法。
- en: Healthcare and life sciences
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 医疗保健和生命科学
- en: Generative AI holds tremendous potential across healthcare and life sciences,
    from providers to payers, and pharmaceutical **research and development** (**R&D**)
    to medical device makers. Its unique capabilities are enabling innovations in
    drug discovery, clinical care, customer engagement, and more.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 生成人工智能在医疗保健和生命科学领域具有巨大的潜力，从提供者到支付者，以及从药物研发（R&D）到医疗设备制造商。其独特的功能正在推动药物发现、临床护理、客户参与等方面的创新。
- en: Pharmaceutical companies are exploring generative AI to accelerate and enhance
    drug development in various ways. Powerful protein folding algorithms such as
    AlphaFold enable predicting protein structures directly from amino acid sequences.
    These 3D protein models provide insights to guide targeted drug design. Generative
    models can also propose completely novel molecular structures and compounds with
    desired pharmaceutical properties. This expands the drug candidate space for testing
    beyond incremental tweaks to existing therapies. Additionally, by reading, comprehending,
    and summarizing massive volumes of biomedical research, generative AI can assist
    researchers in extracting relevant findings and knowledge from research literature.
    This augmented intelligence helps inform R&D strategy and drug discovery by synthesizing
    insights from across huge corpora of domain knowledge.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 药物公司正在探索生成式人工智能以多种方式加速和增强药物开发。强大的蛋白质折叠算法，如AlphaFold，可以直接从氨基酸序列预测蛋白质结构。这些3D蛋白质模型提供了指导，以指导靶向药物设计。生成式模型还可以提出具有所需药物特性的全新分子结构和化合物。这扩大了药物候选空间，使其超越了对现有疗法的增量调整。此外，通过阅读、理解和总结大量生物医学研究，生成式人工智能可以帮助研究人员从研究文献中提取相关发现和知识。这种增强智能通过综合来自大量领域知识库的见解，有助于指导研发策略和药物发现。
- en: Healthcare providers are exploring numerous applications of generative AI to
    augment clinical workflows and care. In diagnosis, these models can analyze medical
    scans, lab tests, and patient history to provide condition assessments and triage
    recommendations. Generative models can even summarize doctor-patient conversation
    details into structured medical notes for easy maintenance and understanding.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗服务提供者正在探索生成式人工智能的多种应用，以增强临床工作流程和护理。在诊断方面，这些模型可以分析医学扫描、实验室检测和患者病史，以提供状况评估和分级推荐。生成式模型甚至可以将医生与患者对话的细节总结成结构化医疗记录，以便于维护和理解。
- en: To assist physicians at the point of care, AI assistants can respond to medical
    questions by searching knowledge bases and research to retrieve helpful information.
    Generative models also show potential for automated report writing, such as synthesizing
    patient discharge summaries.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了协助医护人员在诊疗点，人工智能助手可以通过搜索知识库和研究来回答医学问题，从而检索到有用的信息。生成式模型在自动撰写报告方面也显示出潜力，例如合成患者出院总结。
- en: Health insurance payers are assessing generative AI applications to improve
    customer and claims processing workflows. Virtual assistants and chatbots can
    understand customer queries and provide conversational support to promptly resolve
    inquiries. Generative models are also being tested to automate elements of claims
    adjudication. By analyzing claim forms, attached documentation, provider info,
    and payer guidelines, these models can extract relevant details to validate claims
    and determine appropriate payment. This could significantly reduce manual review
    and speed up claim settlement timelines.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 健康保险公司正在评估生成式人工智能应用，以改善客户和索赔处理工作流程。虚拟助手和聊天机器人可以理解客户查询并提供对话支持，以便及时解决疑问。生成式模型还在测试中，以自动化索赔裁决的某些要素。通过分析索赔表格、附件文件、提供者信息和支付者指南，这些模型可以提取相关细节以验证索赔并确定适当的支付。这可能会显著减少人工审查并加快索赔结算时间表。
- en: Medical device and pharmaceutical manufacturers are piloting the use of generative
    AI for automated manufacturing and production oversight. By analyzing written
    standard operating procedures and process documentation, generative models can
    validate that critical manufacturing processes adhere to regulatory compliance
    standards and internal policies. Any deviations or missing steps can be flagged
    to ensure protocols meet requirements before reaching inspection. This proactive
    auditing can identify compliance gaps upstream and enable corrective actions sooner.
    With the ability to thoroughly scan extensive documentation and compare them to
    guidelines at scale, generative AI can strengthen quality assurance and streamline
    production oversight in medical product manufacturing.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗设备和制药制造商正在试点使用生成式人工智能进行自动化制造和生产监管。通过分析书面标准操作程序和流程文件，生成式模型可以验证关键制造过程是否符合监管合规标准和内部政策。任何偏差或缺失步骤都可以被标记出来，以确保在达到检查之前协议符合要求。这种主动审计可以识别上游的合规差距，并使纠正措施能够更早实施。通过能够彻底扫描大量文件并与规模化的指南进行比较，生成式人工智能可以加强质量保证并简化医疗产品制造的监管。
- en: Media and entertainment
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 媒体和娱乐
- en: The media and entertainment sector presents tremendous opportunities to apply
    generative AI across the entire content value chain and consumer touchpoints.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 媒体和娱乐行业为在整个内容价值链和消费者接触点上应用生成式人工智能提供了巨大的机遇。
- en: For content production, media companies are exploring the use of generative
    models to autonomously synthesize completely new images, videos, and other multimedia
    from textual prompts. These models can also meaningfully enhance existing assets,
    such as increasing image and video resolution, colorizing black-and-white content,
    or restoring corrupted and damaged files.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于内容制作，媒体公司正在探索使用生成模型来自动合成完全新的图像、视频和其他多媒体，这些多媒体由文本提示生成。这些模型还可以有意义的增强现有资产，例如提高图像和视频分辨率、为黑白内容上色或恢复损坏的文件。
- en: In content distribution, generative AI can unlock capabilities like automated
    metadata tagging, hyper-relevant search, and customized recommendations that can
    substantially improve media discovery and engagement. Marketing campaigns can
    also leverage dynamically generated, personalized content tailored to individual
    user interests and localized preferences. With contextually relevant experiences
    powered by generative AI, media companies can deepen audience relationships, improve
    retention, and better monetize content catalogs.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在内容分发方面，生成式人工智能可以解锁自动化元数据标记、高度相关的搜索和定制推荐等功能，这些功能可以显著改善媒体发现和参与度。营销活动还可以利用动态生成的个性化内容，这些内容针对个人用户兴趣和本地化偏好进行定制。借助由生成式人工智能驱动的上下文相关体验，媒体公司可以加深观众关系，提高留存率，并更好地货币化内容目录。
- en: Media companies are piloting the use of generative AI to enrich customer experience
    such as automating live sports commentary and reporting. By ingesting real-time
    data and narratives around games, generative models can provide customized play-by-play
    and analysis as engaging, conversational outputs. When applied to customer service,
    conversational AI interfaces leveraging these models could deliver highly responsive,
    natural interactions to resolve subscriber issues and queries.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 媒体公司正在试点使用生成式人工智能来丰富客户体验，例如自动化现场体育解说和报道。通过摄取关于比赛的实时数据和叙述，生成模型可以提供定制化的逐点分析和对话式输出。当应用于客户服务时，利用这些模型的会话式人工智能界面可以提供高度响应和自然的交互，以解决订阅者问题和查询。
- en: Automotive and manufacturing
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 汽车和制造业
- en: The automotive and manufacturing industries are exploring generative AI across
    customer experience, product engineering, and smart manufacturing use cases.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 汽车和制造业正在探索生成式人工智能在客户体验、产品工程和智能制造用例中的应用。
- en: For instance, some automakers are evaluating conversational AI to power interactive
    digital owner’s manuals in the car or on mobile devices. This would enable voice-guided
    vehicle troubleshooting and contextual search for repair procedures. Generative
    AI call center analytics can also help summarize transcripts to address customer
    issues faster and improve agent training.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一些汽车制造商正在评估会话式人工智能，以在汽车或移动设备上提供交互式数字车主手册。这将实现语音引导的车辆故障排除和针对维修程序的上下文搜索。生成式人工智能呼叫中心分析还可以帮助总结录音，以更快地解决客户问题和改善代理培训。
- en: In product engineering, generative models are being explored to ideate exterior
    and interior styling concepts balanced with considerations like aerodynamics,
    space utilization, and ergonomics. These models can also predict simulation outcomes
    to complement physics-based testing.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在产品工程领域，生成模型正在被探索用于构思外观和内饰设计概念，同时平衡考虑空气动力学、空间利用和人体工程学等因素。这些模型还可以预测模拟结果，以补充基于物理的测试。
- en: For smart manufacturing, generative AI can assist by producing detailed machine
    troubleshooting guides using maintenance manuals, issue patterns, and repair procedures.
    This can enable self-guided maintenance and reduced downtime.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于智能制造，生成式人工智能可以通过使用维护手册、问题模式和维修程序来生成详细的机器故障排除指南。这可以实现自我引导的维护和减少停机时间。
- en: With the potential benefit and impact promised by generative AI, what does it
    take to turn an idea into a practical generative AI solution? How do we navigate
    the various stages of the generative AI project lifecycle? What are the different
    science and technology options available for consideration? What challenges and
    risks should we be keeping a watchful eye on? In this next section, we will explore
    and try to answer these questions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式AI所承诺的潜在利益和影响，将一个想法转化为实用的生成式AI解决方案需要什么？我们如何导航生成式AI项目生命周期的各个阶段？有哪些不同的科学技术选项可供考虑？我们应该密切关注哪些挑战和风险？在下一节中，我们将探讨并尝试回答这些问题。
- en: The lifecycle of a generative AI project and the core technologies
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI项目的生命周期和核心技术
- en: The lifecycle for developing and deploying generative AI solutions spans multiple
    stages, with some variations from traditional ML projects, such as model customization
    and model evaluation. While certain phases like use case definition and data preparation
    align closely, stages including model development, training, evaluation, and adaptation
    take on unique characteristics for generative models.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 开发和部署生成式AI解决方案的生命周期跨越多个阶段，与传统ML项目相比有一些变化，例如模型定制和模型评估。虽然某些阶段如用例定义和数据准备与生成式模型紧密相关，但包括模型开发、训练、评估和适应的阶段在生成式模型中具有独特的特征。
- en: '![](img/B20836_15_01.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B20836_15_01.png)'
- en: 'Figure 15.1: Generative AI project lifecycle'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.1：生成式AI项目生命周期
- en: At a high level, a generative AI project consists of a series of stages, including
    identification of business use cases, model selection or pre-training, domain
    adaptation and model customization, post-customization model evaluation, and model
    deployment. It’s important to recognize that while a generative AI project places
    significant emphasis on the capabilities and quality of the model itself, the
    model constitutes just one facet within the broader development of a generative
    AI solution.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，一个生成式AI项目包括一系列阶段，包括识别商业用例、模型选择或预训练、领域适应和模型定制、定制后模型评估以及模型部署。重要的是要认识到，尽管生成式AI项目对模型本身的能力和质量给予了高度重视，但模型只是生成式AI解决方案更广泛发展中的一个方面。
- en: 'Before delving into the lifecycle details, it’s crucial to grasp the various
    adoption approaches that different organizations take, as they significantly impact
    project execution. Based on their business objectives, organizations typically
    fall into one of three categories for generative AI adoption:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨生命周期细节之前，了解不同组织采用的多种采用方法至关重要，因为它们对项目执行有重大影响。根据他们的商业目标，组织通常分为三个类别之一来采用生成式AI：
- en: '**Model consumers**: Direct consumers of **foundation models** (**FMs**) typically
    leverage them as-is to address specific business challenges. While they may employ
    techniques like prompt engineering for customization, they don’t invest resources
    in teaching the model new domains or tasks. Their primary focus is on solving
    immediate business problems for internal or external customers seeking end-user
    applications rather than building foundational technology blocks. Additionally,
    these organizations generally don’t prioritize enhancing existing FMs with proprietary
    datasets. An example of a model consumer is a generative AI application developer
    who builds a customer support chatbot that directly consumes the OpenAI GPT model
    or Claude model from Anthropic via application APIs.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型消费者**：**基础模型**（**FMs**）的直接消费者通常直接利用它们来解决特定的商业挑战。虽然他们可能会使用如提示工程等技术进行定制，但他们不会投入资源去教授模型新的领域或任务。他们的主要关注点是解决寻求端用户应用的内部或外部客户的即时商业问题，而不是构建基础技术模块。此外，这些组织通常不会优先考虑使用专有数据集来增强现有的FMs。一个模型消费者的例子是一个生成式AI应用程序开发者，他构建了一个客户支持聊天机器人，该机器人直接通过应用程序API消耗OpenAI
    GPT模型或Anthropic的Claude模型。'
- en: '**Model tuners**: FM tuners are organizations aiming to fine-tune existing
    FMs for specific business purposes. This refinement can involve domain adaptation,
    enriching the model with domain-specific data (e.g., finance or medicine), or
    teaching the model new tasks (e.g., writing in a specific style). These organizations
    typically have distinct business goals, including generating revenue, reducing
    costs, improving productivity, or enhancing customer experiences. They possess
    proprietary datasets that offer a competitive edge, as well as the scientific
    and engineering expertise needed to tailor an existing model to meet their unique
    business needs. An example of a model tuner could be a financial services organization
    enriching an open-source LLM with their proprietary dataset such as a financial
    research report, so the model can perform better with research report summarization
    tasks.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型调优师**：FM调优师是指那些旨在针对特定商业目的对现有FM进行微调的组织。这种优化可能包括领域适应性，通过添加特定领域的数据（例如，金融或医学）来丰富模型，或者教授模型新的任务（例如，以特定风格写作）。这些组织通常具有明确的企业目标，包括创造收入、降低成本、提高生产率或提升客户体验。它们拥有专有数据集，这为它们提供了竞争优势，以及调整现有模型以满足其独特商业需求所需的科学和工程专业知识。一个模型调优师的例子可能是一个金融服务组织，它使用其专有的数据集（如金融研究报告）来丰富开源LLM，从而使模型在研究报告摘要任务上表现更佳。'
- en: '**Model developers**: FM developers are organizations dedicated to constructing
    FMs from the ground up. These models are subsequently provided to other organizations
    for either commercial purposes or for contribution to the open-source community,
    promoting the advancement and widespread adoption of this technology. Notable
    examples of FM developers include OpenAI, Anthropic, Google, Meta, Amazon, open-source
    communities, and government entities. These models typically serve as fundamental
    building blocks for a variety of general-purpose capabilities, including text
    generation, summarization, text-to-image generation, question answering, mathematics,
    planning, and reasoning. The primary audience for these FMs consists of other
    organizations and developers aiming to create applications powered by generative
    AI technology, in addition to their internal use. Organizations in this category
    are characterized by their substantial expertise in data sciences and ML engineering,
    as well as robust financial backing for these endeavors.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型开发者**：FM开发者是指那些致力于从头开始构建FM的组织。这些模型随后被提供给其他组织，用于商业目的或贡献给开源社区，以促进该技术的进步和广泛应用。知名的FM开发者包括OpenAI、Anthropic、Google、Meta、Amazon、开源社区和政府实体。这些模型通常作为各种通用能力的基本构建块，包括文本生成、摘要、文本到图像生成、问答、数学、规划推理等。这些FM的主要受众是其他组织和开发者，他们旨在创建由生成式AI技术驱动的应用程序，以及他们的内部使用。这类组织的特点是他们在数据科学和机器学习工程方面拥有丰富的专业知识，以及为这些努力提供强大的财务支持。'
- en: While there are three distinct user personas in generation adoption, it is worth
    noting that many organizations can take on more than one persona. For example,
    while a model tuner might tune some existing FMs with its proprietary dataset
    for specific needs or competitive advantage, it might also just use an existing
    model as it is for some other needs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在生成式采纳中存在三个不同的用户角色，但值得注意的是，许多组织可以承担多个角色。例如，一个模型调优师可能会使用其专有数据集对一些现有的FM进行调优，以满足特定需求或获得竞争优势，但它也可能仅为了其他需求而直接使用现有模型。
- en: It is important to highlight that the generative AI project lifecycle varies
    among the personas mentioned earlier, based on distinct business objectives associated
    with each approach. Next, let’s delve into the specifics of each key step, starting
    with business use case selection.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '需要强调的是，生成式AI项目生命周期在前面提到的角色之间有所不同，这取决于与每种方法相关的不同商业目标。接下来，让我们深入了解每个关键步骤的细节，从业务用例选择开始。 '
- en: Business use case selection
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务用例选择
- en: 'This is the first step in a generative AI project. In this pivotal stage, organizations
    typically chart the course for their generative AI endeavors by selecting the
    right business case by aligning technology with specific business objectives.
    The selection of use cases not only shapes the trajectory of the project but also
    determines the impact on internal and external stakeholders. Choosing the right
    business use case for a generative AI initiative involves several key considerations.
    Here are some factors to weigh when deciding which business use cases to pursue:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是生成式AI项目的第一步。在这个关键阶段，组织通常通过选择合适的企业案例，通过将技术与特定的商业目标对齐，来规划其生成式AI的路径。用例的选择不仅塑造了项目的轨迹，还决定了内部和外部利益相关者的影响。为生成式AI项目选择正确的商业用例涉及几个关键考量。以下是在决定追求哪些商业用例时需要权衡的一些因素：
- en: '**Business value and ROI assessment**: Like any AI initiative, generative AI
    projects require clearly defined business objectives and metrics to measure value.
    In the excitement of new possibilities, organizations should pragmatically validate
    that generative AI products and services deliver tangible benefits. Despite many
    opportunities, not all generative AI applications can translate to positive business
    impact. With proper goal-setting and outcome-driven guidance, enterprises can
    strategically unlock real business value.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**商业价值和投资回报评估**：与任何AI项目一样，生成式AI项目需要明确定义的商业目标和衡量价值的指标。在新可能性带来的兴奋中，组织应务实验证生成式AI产品和服务的实际效益。尽管有许多机会，但并非所有生成式AI应用都能转化为积极的商业影响。通过适当的设定目标和以结果为导向的指导，企业可以战略性地释放真正的商业价值。'
- en: '**Technical capability assessment**: When selecting use cases, companies must
    consider their technical capabilities. For instance, training a novel FM from
    scratch promises potentially high value but requires skills and computational
    and data resources that many organizations may lack. Tailoring use cases to build
    upon existing competencies is key for successful execution.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术能力评估**：在选择用例时，公司必须考虑其技术能力。例如，从头开始训练一个新颖的FM可能具有潜在的高价值，但需要技能、计算和数据资源，许多组织可能缺乏。根据现有能力定制用例对于成功执行至关重要。'
- en: '**Data availability consideration**: An organization also needs to assess what
    dataset it has to determine whether a certain use case is feasible. For example,
    an organization may consider fine-tuning FMs with unique knowledge to be competitive,
    but if the organization does not have access to a proprietary dataset, then it
    is also not a feasible use case.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据可用性考量**：组织还需要评估其拥有的数据集，以确定某个用例是否可行。例如，一个组织可能考虑通过微调具有独特知识的FM来保持竞争力，但如果组织无法访问专有数据集，那么这也不是一个可行的用例。'
- en: '**Regulatory and compliance consideration**: While generative AI enables many
    new product possibilities, companies must evaluate potential regulatory constraints
    and compliance risks. For instance, investment advice applications may require
    specific licensing, preventing unrestrained deployment. A pragmatic assessment
    of the regulatory landscape for each use case is prudent to avoid pitfalls.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监管和合规考量**：虽然生成式AI使许多新产品成为可能，但公司必须评估潜在的监管约束和合规风险。例如，投资建议应用可能需要特定的许可，防止无限制部署。对每个用例的监管环境进行务实评估是谨慎的，以避免陷阱。'
- en: '**Ethics consideration**: Ethics should guide use case selection. Applications
    should avoid disenfranchising groups or causing harm. Generative AI’s responsibilities
    extend beyond business value to societal impact.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理考量**：伦理应指导用例选择。应用应避免使群体失去权利或造成伤害。生成式AI的责任不仅限于商业价值，还扩展到社会影响。'
- en: '**Risk assessment**: Organizations should carefully evaluate the risks that
    might arise from the implementation of generative AI applications. For example,
    consider the risk the solution may cause to a patient if generative AI makes a
    wrong decision for medical diagnosis. If mitigations are lacking for high-severity
    risks, it may be advisable to avoid certain use cases altogether.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**风险评估**：组织应仔细评估生成式AI应用实施可能出现的风险。例如，考虑如果生成式AI在医疗诊断中做出错误决定，解决方案可能对患者的风险。如果缺乏对高严重性风险的缓解措施，可能建议完全避免某些用例。'
- en: '**Automated decision versus assistive augmentation**: Organizations should
    weigh whether use cases require fully automated decisions versus AI assistance
    where humans retain control. Limitations can be mitigated by keeping the human
    in the loop for final decisions rather than fully autonomous generative AI.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化决策与辅助增强**：组织应权衡用例是否需要完全自动化的决策，还是需要人类保留控制权的AI辅助。通过在最终决策中保持人类参与而不是完全自主的生成式AI，可以减轻限制。'
- en: Generative AI is still an emerging field. Most organizations are still evaluating
    and doing **proofs of concept** (**POCs**) for different business use cases to
    assess the production deployment readiness for real-world applications.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI仍然是一个新兴领域。大多数组织仍在评估和进行不同商业用例的**概念验证**（**POCs**），以评估实际应用的部署准备情况。
- en: FM selection and evaluation
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FM选择和评估
- en: FMs are large, pre-trained, and/or tuned ML models designed to adapt to various
    downstream tasks like translation, summarization, question answering, and image
    generation. These models are pre-trained using self-supervised training on very
    large datasets with trillions of tokens, including internet text and images, encoding
    a wealth of knowledge in their parameters.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: FM是大型、预训练的以及/或调整的ML模型，旨在适应各种下游任务，如翻译、摘要、问答和图像生成。这些模型使用在包含数十万亿个标记的非常大的数据集上进行自监督训练进行预训练，包括互联网文本和图像，其参数中编码了丰富的知识。
- en: This knowledge can be fine-tuned for different tasks, allowing for versatile
    reuse. Notable examples of FMs include GPT, LLaMA, and Stable Diffusion. Since
    FMs serve as the core components of generative AI applications, choosing the appropriate
    FMs for your chosen use case becomes a crucial next step in your generative AI
    project lifecycle.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种知识可以根据不同的任务进行微调，从而实现灵活的重用。显著的FM例子包括GPT、LLaMA和Stable Diffusion。由于FM是生成式AI应用的核心组件，因此为您的选择用例选择合适的FM成为您生成式AI项目生命周期中的关键下一步。
- en: 'For organizations new to FM adoption, choosing the right FMs can be challenging
    due to numerous proprietary and open-source options. At a high level, there are
    five key focus areas for FM quality evaluation:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对于刚开始采用FM的组织来说，由于存在众多专有和开源选项，选择合适的FM可能具有挑战性。在高级别上，FM质量评估有五个关键关注领域：
- en: '**Factuality**: This is one of the most important model qualities to be evaluated.
    A high-quality model should return factually accurate information with or without
    a given context.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事实性**：这是要评估的最重要模型质量之一。一个高质量的模型应该能够返回事实准确的信息，无论是否有给定上下文。'
- en: '**Task completion**: A model should be able to complete the desired tasks when
    provided with clear instructions.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务完成**：模型应在提供明确指令的情况下能够完成所需任务。'
- en: '**Responsible AI enforcement**: Does the model exhibit unresponsible behaviors
    such as bias and harmful content?'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负责任的AI执行**：模型是否表现出不负责任的行为，如偏见和有害内容？'
- en: '**Reasoning/logical thinking**: A high-quality model should be able to perform
    complex analyses with sound logical reasoning.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理/逻辑思维**：一个高质量的模型应该能够通过合理的逻辑推理执行复杂分析。'
- en: '**Creativity**: How creative is the response when completing a task with specific
    instruction?'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创造力**：在完成具有特定指令的任务时，响应有多具创造性？'
- en: Additionally, non-model quality factors like inference latency and hosting costs
    must be weighed as part of the overall model selection decision.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，作为整体模型选择决策的一部分，必须权衡非模型质量因素，如推理延迟和托管成本。
- en: 'Now, let’s explore the essential dimensions of the model evaluation process
    and techniques. There are four primary stages of model selection at a high level:
    initial screening via manual assessment, automated model evaluation, human expert
    evaluation, and AI risk assessment. Let’s discuss them in more detail.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探讨模型评估过程和技术的基本维度。在高级别上，模型选择有四个主要阶段：通过人工评估的初步筛选、自动化模型评估、人工专家评估和AI风险评估。让我们更详细地讨论它们。
- en: Initial screening via manual assessment
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过人工评估的初步筛选
- en: The primary goal of this stage is to come up with a short list of FMs for further
    evaluation. There are many existing open-source and proprietary FMs and new ones
    are being created continuously. For example, in the Hugging Face platform alone,
    there are over 120K open-source models currently, of which many are FMs, and the
    number is expected to grow much larger. Furthermore, many proprietary model developers,
    including Amazon, Google, Anthropics, Cohere, and AI21, also offer proprietary
    FMs for commercial use.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 本阶段的主要目标是制定一个FM短名单以供进一步评估。目前存在许多开源和专有FM，并且新的FM正在不断被创建。例如，仅在Hugging Face平台上，目前就有超过120K个开源模型，其中许多是FM，预计数量还将大幅增长。此外，包括亚马逊、谷歌、Anthropics、Cohere和AI21在内的许多专有模型开发者也提供专有FM以供商业使用。
- en: To create a shortlist from available models, establish selection criteria based
    on factors like modality (e.g., text, image, video, code, etc.), model size, supported
    use cases (e.g., summarization, question answering, reasoning, etc.), training
    data (e.g., general-purpose or domain-specific), and performance expectations.
    Hugging Face and proprietary providers provide FM model cards with these details.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要从可用模型中创建短名单，应根据因素如模态（例如，文本、图像、视频、代码等）、模型大小、支持的用例（例如，摘要、问答、推理等）、训练数据（例如，通用或特定领域）和性能预期等因素建立选择标准。Hugging
    Face和专有提供商提供了包含这些详细信息的FM模型卡片。
- en: Public benchmarks (e.g., **Holistic Evaluation of Language Models** (**HELM**)
    for task-specific performance and HumanEval for code generation correctness) and
    leaderboards (e.g., Hugging Face LLM leaderboard) offer valuable information.
    Combine model card data and benchmark insights to compile a shortlist of suitable
    FMs. You can also run HELM to run benchmarks on FMs directly. HELM supports multi-metric
    measurement including accuracy, calibration, robustness, fairness, bias, toxicity,
    and efficiency for a set of scenarios. HELM provides command-line tools for running
    benchmarks (helm-run), summarizing results (helm-summarize), and visualizing results
    (helm-server).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 公共基准（例如，针对特定任务性能的**整体语言模型评估**（HELM）和针对代码生成正确性的HumanEval）以及排行榜（例如，Hugging Face
    LLM排行榜）提供了有价值的信息。结合模型卡片数据和基准洞察，编制一份合适的FM短名单。您还可以直接运行HELM对FM进行基准测试。HELM支持包括准确性、校准、鲁棒性、公平性、偏差、毒性和效率等多指标测量，适用于一系列场景。HELM提供用于运行基准测试（helm-run）、总结结果（helm-summarize）和可视化结果（helm-server）的命令行工具。
- en: With this initial list, you should create a small testing dataset consisting
    of input-output pairs and conduct a manual assessment of the FMs. Hugging Face
    and proprietary model providers offer model playgrounds or **software development
    kits** (**SDKs**) that facilitate this assessment process. Alternatively, you
    can deploy these models in your own environment for testing purposes. Through
    this manual testing phase, the goal is to identify a manageable number of FMs
    for the next stage of evaluation. If you intend to fine-tune the FMs using your
    own data, ensure that the FMs can support further fine-tuning.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个初始列表，您应该创建一个包含输入-输出对的少量测试数据集，并对FM进行手动评估。Hugging Face和专有模型提供商提供模型游乐场或**软件开发工具包**（SDKs），以简化评估过程。或者，您也可以将这些模型部署到自己的环境中进行测试。通过这个手动测试阶段，目标是确定下一阶段评估的可管理数量的FM。如果您打算使用自己的数据进行微调FM，请确保FM可以支持进一步的微调。
- en: Automated model evaluation
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动模型评估
- en: The aim of this stage is to perform extensive automated testing of the short-listed
    FMs using evaluation metrics to identify the final two to three models for human
    expert evaluation before adoption. It is important to know that each evaluation
    metric only assesses one aspect of a model. As FMs can often perform many different
    tasks, it is recommended to evaluate metrics holistically for the final decision.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 本阶段的目标是使用评估指标对短名单中的FM进行广泛的自动化测试，以确定最终的两个或三个模型供人类专家评估并采纳。重要的是要知道，每个评估指标只评估模型的一个方面。由于FM通常可以执行许多不同的任务，因此建议在最终决策时全面评估指标。
- en: FMs present a unique challenge in automated model evaluation, particularly for
    generative tasks like text generation. Unlike traditional supervised ML, where
    ground truth labels and training data distribution are known, FMs often lack visibility
    into their training data distribution and lack ground truth for output. This raises
    questions about which metrics to use for accuracy, factual correctness, tone,
    and style assessment of generated text, as well as considerations like creativity
    and output format. While public benchmarks provide useful insights, they may not
    cover specific data and workflows. So, let’s address these challenges by categorizing
    them based on task types, objectives, and data availability. Specifically, we
    will cover tasks with discrete outputs and tasks with continuous text outputs.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: FM在自动模型评估中提出了独特的挑战，尤其是在文本生成等生成性任务中。与传统的监督机器学习不同，在传统的监督机器学习中，真实标签和训练数据分布是已知的，而FM通常缺乏对其训练数据分布的可见性，并且缺乏输出的真实标签。这引发了关于使用哪些指标来评估生成文本的准确性、事实正确性、语气和风格的问题，以及考虑创造性和输出格式等问题。虽然公开基准提供了有用的见解，但它们可能不会涵盖特定的数据和流程。因此，让我们通过根据任务类型、目标和数据可用性对这些挑战进行分类来解决这个问题。具体来说，我们将涵盖具有离散输出的任务和具有连续文本输出的任务。
- en: Tasks with discrete outputs
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 具有离散输出的任务
- en: Tasks with discrete outputs involve generating or predicting categorical or
    discrete values as the output, as opposed to continuous values (discussed in the
    upcoming section). Common examples of tasks with discrete outputs in the NLP domain
    include text classification, named entity extraction, intent recognition, part-of-speech
    tagging, and spam detection. These may also include text generation tasks that
    produce specific items (e.g., an exact textual answer to a question) such as words,
    characters, or tokens.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 具有离散输出的任务涉及生成或预测作为输出的分类或离散值，而不是连续值（将在下一节中讨论）。在NLP领域，具有离散输出的常见任务包括文本分类、命名实体提取、意图识别、词性标注和垃圾邮件检测。这些也可能包括生成特定项目（例如，对问题的精确文本答案）的任务，如单词、字符或标记。
- en: For these types of tasks, the objective is to have FMs produce responses that
    match the expected labels precisely. Therefore, the recommended evaluation method
    involves creating a test dataset consisting of input-output label pairs and assessing
    the FMs’ performance using established metrics like accuracy and F1\. There are
    also public benchmarks and datasets available for the evaluation of specific NLP
    tasks such as entity resolution. For example, the **General Language Understanding
    Evaluation** (**GLUE**) benchmark consists of a collection of nine representative
    NLP tasks, including sentence classification, sentiment analysis, and question
    answering. Each task in the benchmark comes with a training set, a development
    set for fine-tuning the models, and an evaluation set for testing the performance
    of the models.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些类型的任务，目标是让FM产生与预期标签精确匹配的响应。因此，推荐的评估方法包括创建一个包含输入-输出标签对的测试数据集，并使用如准确性和F1等既定指标来评估FM的性能。还有针对特定NLP任务（如实体解析）评估的公开基准和数据集可用。例如，**通用语言理解评估**（**GLUE**）基准包括九个代表性的NLP任务，包括句子分类、情感分析和问答。基准中的每个任务都附带一个训练集、一个用于微调模型的开发集以及一个用于测试模型性能的评估集。
- en: Tasks with continuous text outputs
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 具有连续文本输出的任务
- en: Tasks with continuous text outputs involve generating text as the output, which
    can be a sequence of words, characters, or tokens, rather than discrete labels
    or categories. Some examples of tasks with continuous text outputs include text
    summarization, machine translation, image captioning, question answering, and
    text generation tasks for creative stories and poems. For tasks of this nature,
    the main objective is to generate coherent and contextually relevant text that
    is factually correct. To measure the performance of this type of task, conventional
    evaluation NLP metrics such as **Bilingual Evaluation Understudy** (**BLEU**)
    and **Recall-Oriented Understudy for Gisting Evaluation** (**ROUGE**) remain relevant
    for FMs, assuming the availability of a suitable testing dataset. There are public
    datasets available for the evaluation of NLP tasks with continuous outputs. For
    example, the **Stanford Question Answering Dataset** (**SQuAD**) is a reading
    comprehension dataset that can be used for question-answering tasks. However,
    while these metrics help measure the similarity between the machine-generated
    text and human-generated reference text, these metrics focus on n-gram overlapping
    and matching, and they lack semantic understanding of the generated text, sensitivity
    of word order, and consideration of the overall text quality.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及连续文本输出的任务涉及生成文本作为输出，这可以是单词、字符或标记的序列，而不是离散的标签或类别。具有连续文本输出的任务的一些例子包括文本摘要、机器翻译、图像描述、问答以及用于创意故事和诗歌的文本生成任务。对于这类任务，主要目标是生成连贯且与上下文相关的文本，且内容真实。为了衡量这类任务的表现，假设有合适的测试数据集，传统的评估NLP指标如**双语评估助手**（**BLEU**）和**基于理解评估的召回率助手**（**ROUGE**）对于FM仍然相关。对于评估具有连续输出的NLP任务，有可用的公共数据集。例如，**斯坦福问答数据集**（**SQuAD**）是一个阅读理解数据集，可用于问答任务。然而，尽管这些指标有助于衡量机器生成文本与人类生成参考文本之间的相似性，但这些指标主要关注n-gram重叠和匹配，缺乏对生成文本的语义理解、对词序的敏感性以及整体文本质量的考虑。
- en: 'To address certain limitations of conventional metrics, the approach of utilizing
    other more powerful LLMs to assist in the automated evaluation of the target FMs
    has been explored. Specifically, the approach involves employing LLMs in the following
    evaluation processes:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决传统指标的一些局限性，已经探索了利用其他更强大的LLM（大型语言模型）来协助自动评估目标FM（功能模块）的方法。具体来说，这种方法包括在以下评估过程中使用LLM：
- en: '**Semantic similarity assessment**: Powerful LLMs like GPT4 and Claude are
    known for having a strong semantic understanding of text. This capability can
    be used to assess the semantic similarity between machine-generated text and human-generated
    reference text. For example, you can ask an LLM to measure the semantic similarity
    using a cosine similarity score or return a response of a yes or no for similarity
    measure.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义相似性评估**：像GPT4和Claude这样的强大LLM以其对文本的强大语义理解能力而闻名。这种能力可以用来评估机器生成文本与人类生成参考文本之间的语义相似性。例如，你可以要求一个LLM使用余弦相似度分数来衡量语义相似性，或者返回一个表示相似性测量的是或否的响应。'
- en: '**Language coherence assessment**: Powerful LLMs are known for having a strong
    ability to analyze the certain structure of text such as consistency, relevance,
    transition, and clarity. As such, they can help assess the coherence of the generated
    text. For example, you can directly ask an LLM to rate the coherence of a generated
    text.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言连贯性评估**：强大的LLM以其分析文本结构（如一致性、相关性、过渡和清晰度）的能力而闻名。因此，它们可以帮助评估生成文本的连贯性。例如，你可以直接要求一个LLM对生成文本的连贯性进行评分。'
- en: '**Ranking of generated responses**: One approach to assess the quality of a
    generated text is to compare it with another piece of text. LLMs can be used to
    rank the quality of generated text with reference text using different criteria
    such as clarity or overall text quality.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成响应的排名**：评估生成文本质量的一种方法是将它与另一篇文本进行比较。LLM可以用来根据不同的标准（如清晰度或整体文本质量）使用参考文本对生成文本的质量进行排名。'
- en: '**Test data generation**: Powerful LLMs have the capability to generate input-output
    test data for specific language tasks when given specific instructions. If necessary,
    these pieces of test data should be subsequently refined or adjusted to align
    with specific requirements. For example, you can design a prompt to ask an LLM
    to generate a list of questions and answers from a body of input text.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试数据生成**：强大的LLM在给定特定指令的情况下，能够为特定的语言任务生成输入-输出测试数据。如果需要，这些测试数据应随后进行细化或调整，以符合特定要求。例如，您可以设计一个提示，要求LLM从一个输入文本体中生成问题列表和答案。'
- en: The open-source community has been actively creating automated evaluators utilizing
    LLMs. One such example is AlpacaEval, which employs LLMs to evaluate instruction-following
    language models. It is crucial to know that while employing LLMs for automated
    assessment has demonstrated utility based on empirical experiments, it does not
    have the same precision as conventional metrics. Therefore, it is imperative to
    recognize its limitations and employ additional human evaluation when necessary.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 开源社区一直在积极创建利用LLM的自动化评估器。其中一个例子是AlpacaEval，它使用LLM来评估遵循指令的语言模型。重要的是要知道，虽然基于LLM的自动化评估在基于经验实验的基础上已经证明了其效用，但它并不具备传统指标那样的精确度。因此，认识到其局限性并在必要时进行额外的人工评估是至关重要的。
- en: Human evaluation
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工评估
- en: 'Once the final candidate FMs have been selected from the automated evaluation
    stage, the subsequent phase in the FM selection and evaluation process involves
    engaging human evaluators for a more comprehensive assessment, addressing aspects
    that may not have been adequately covered by manual screening and automated assessments
    for the target use case. It’s important to emphasize that organizations have the
    flexibility to choose human evaluation independently of automated evaluation methods,
    depending on their specific requirements. In the case of FM evaluation, the human
    evaluator plays a critical role in the selection of a high-quality model. Here
    are some scenarios where human expert evaluation can be particularly valuable:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦从自动化评估阶段选出了最终的候选FM，FM选择和评估过程中的下一阶段将涉及聘请人工评估人员进行更全面的评估，以解决可能未充分涵盖的目标用例的手动筛选和自动化评估的方面。重要的是强调，组织可以根据其具体需求独立于自动化评估方法选择人工评估。在FM评估的情况下，人工评估人员在选择高质量模型中扮演着关键角色。以下是一些人工专家评估特别有价值的场景：
- en: Lack of testing data for automated evaluation.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动评估缺乏测试数据。
- en: Lack of robust evaluation metrics for automated evaluation.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动评估缺乏稳健的评估指标。
- en: Factual correctness assessment.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事实正确性评估。
- en: Assessment of creativity, tone, style, and fluency of the generated content.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对生成内容的创造力、语气、风格和流畅性的评估。
- en: Assessment of soundness of reasoning and logical thinking.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对推理和逻辑思维的稳健性评估。
- en: Assessment of ethical consideration.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对伦理考量的评估。
- en: Human behavior imitation in performing certain tasks.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在执行某些任务时模仿人类行为。
- en: Cybersecurity risk exposure assessment such as red teaming.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络安全风险暴露评估，如红队行动。
- en: 'Establishing and executing a human evaluation workflow can be a complicated
    process. In addition to providing the right tooling and recruiting the right evaluators,
    there are other process-related tasks to complete, such as the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 建立和执行人工评估工作流程可能是一个复杂的过程。除了提供合适的工具和招募合适的评估人员之外，还需要完成其他与流程相关的任务，例如以下内容：
- en: '**Defining evaluation goals**: During this step, it is essential to specify
    the aspects of model performance that will be assessed by humans. For instance,
    in the case of language FMs, these aspects may encompass language coherence, fluency,
    bias, factual accuracy, style and tone, logical reasoning, or the presence of
    toxic content. In the context of image-based FMs, the focus might be on evaluating
    bias and accuracy in representing textual inputs. It is also important to define
    the downstream tasks and evaluate the FMs against the downstream tasks.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义评估目标**：在这一步骤中，必须明确人类将评估的模型性能方面。例如，在语言FM的案例中，这些方面可能包括语言连贯性、流畅性、偏见、事实准确性、风格和语气、逻辑推理，或有害内容的出现。在基于图像的FM的背景下，重点可能在于评估对文本输入的偏见和准确性。同时，也很重要定义下游任务，并评估FM与下游任务的一致性。'
- en: '**Defining clear rating schemes and rubrics**: To ensure consistency across
    human evaluators, it is essential to define clear rating schemes and rubrics to
    score model outputs for the different evaluation criteria such as factual correctness
    or language coherence.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义清晰的评分方案和评分标准**：为确保人类评估者之间的一致性，定义清晰的评分方案和评分标准来对模型输出进行评分，例如事实正确性或语言连贯性等不同评估标准。'
- en: '**Designing diverse prompts for evaluation**: Design prompts with varying contexts,
    knowledge domains, and user perspectives to help ensure FMs can handle diverse
    requirements.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设计多样化的评估提示**：设计具有不同背景、知识领域和用户视角的提示，以确保FM能够处理多样化的需求。'
- en: '**Collecting feedback and assessing model performance**: Collect and aggregate
    feedback from evaluators to assess intended aspects of model performance. Incorporate
    human feedback into potential model fine-tuning.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集反馈和评估模型性能**：收集并汇总评估者的反馈以评估模型性能的预期方面。将人类反馈纳入潜在模型微调。'
- en: While human evaluation is extremely important to model selection, it comes with
    its own set of challenges. Human evaluation is slow and costly and can be difficult
    to implement at scale. In addition, individual evaluators can have subjective
    viewpoints, which can lead to skewed evaluation results. Different human evaluators
    might assess output differently even with clear rating rubrics, resulting in discrepancies
    in their evaluation. Furthermore, recruiting diverse evaluators covering different
    demographics, cultural backgrounds, and expertise can be difficult due to the
    scarcity of these resources.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然人类评估对于模型选择至关重要，但它也带来了一系列挑战。人类评估过程缓慢且成本高昂，且难以在大规模上实施。此外，个别评估者可能会有主观观点，这可能导致评估结果偏差。即使有明确的评分标准，不同的评估者对输出的评估也可能不同，从而导致评估结果不一致。由于这些资源的稀缺，招募涵盖不同人口统计、文化背景和专长的多样化评估者可能很困难。
- en: Assessing AI risks for FMs
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估FM的AI风险
- en: 'Assessing the functional aspects of FMs represents just one facet of the comprehensive
    evaluation. What is equally important is ensuring that FMs exhibit behaviors in
    accordance with AI risk considerations, which can include operational risks such
    as FM hallucination and generating irrelevant answers, ethics risks such as producing
    harmful output and bias, and security risks such as data privacy leakage and FM
    input (a.k.a. prompt) manipulation. AI risk management is a large topic, and it
    is covered in greater detail in *Chapter 12*, *AI Risk Management*. In this section,
    however, we will take a high-level approach to understanding how to automate risk
    detection for FMs, which mainly revolves around test prompt generation and output
    validation. The goal is to assess whether an FM exhibits unethical behaviors,
    an operational risk, or a security risk in its response when presented with different
    input prompts:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 评估FM的功能方面只是全面评估的一个方面。同样重要的是确保FM在AI风险考虑方面表现出符合行为，这可能包括操作风险，如FM的幻觉和生成无关的答案，伦理风险，如产生有害输出和偏见，以及安全风险，如数据隐私泄露和FM输入（即提示）操纵。AI风险管理是一个大主题，在*第12章*，*AI风险管理*中有更详细的介绍。然而，在本节中，我们将从高层次的角度了解如何自动化FM的风险检测，这主要围绕测试提示生成和输出验证。目标是评估FM在呈现不同的输入提示时，其响应是否表现出不道德的行为、操作风险或安全风险：
- en: '**Test prompt generation**: To create effective prompts to test the FMs, you
    need to determine what risks to assess and design the prompt appropriately. For
    example, if you want to detect harmful content in the output of an FM, then the
    prompt should instruct the FM to perform this specific task. If you want to detect
    bias in the output, then you want to design your prompt with different terms and
    keywords, such as the names of certain ethnic groups, and see how the response
    will be different. These test prompts can be used to generate outputs from the
    FMs.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试提示生成**：为了创建有效的提示来测试FM，你需要确定要评估的风险并相应地设计提示。例如，如果你想检测FM输出中的有害内容，那么提示应指示FM执行这个特定任务。如果你想检测偏见，那么你希望设计包含不同术语和关键词的提示，例如某些民族群体的名称，并观察响应将如何不同。这些测试提示可以用来从FM生成输出。'
- en: '**Output validation**: This is mainly about building ML models or rule engines
    that detect specific risks using the test prompt generated. For example, you can
    train a harmful content detection model using a hate speech and offensive language
    dataset and use the model on output generated from a specifically designed test
    prompt for harmful content. If you would like to detect bias in the output, then
    you can build an ML model to detect whether the FM produces an output that is
    disproportionally biased against a certain group.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出验证**：这主要是指构建ML模型或规则引擎，使用生成的测试提示来检测特定的风险。例如，您可以使用仇恨言论和攻击性语言数据集训练一个有害内容检测模型，并使用该模型对从专门设计的测试提示生成的输出进行检测。如果您想检测输出中的偏差，则可以构建一个ML模型来检测FM是否产生了一个对某一群体不成比例偏见的输出。'
- en: It is important to know that AI risk detection for FMs is still an ongoing research
    area, and there are still many unknowns and gaps. For example, hallucination and
    lack of interpretability remain a challenge with the adoption of FMs. Furthermore,
    you need to balance the need for AI risk detection and the specific use case requirements.
    For example, some use cases might require less restrictive guardrails on offensive
    language due to its actual applications such as movie script generation.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 需要知道的是，FM的AI风险检测仍然是一个正在进行的研究领域，还有很多未知和空白。例如，虚构和缺乏可解释性仍然是采用FM时的挑战。此外，您需要平衡AI风险检测和特定用例需求之间的关系。例如，某些用例可能由于其实际应用，如电影剧本生成，而对攻击性语言的限制较少。
- en: Other evaluation consideration
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他评估考虑因素
- en: Beyond assessing the functional capabilities and quality of a model, several
    other factors come into play when determining which model to deploy in production.
    Considerations such as cost and inference latency also play a crucial role in
    this decision-making process.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 除了评估模型的功能能力和质量外，在确定生产中部署哪个模型时，还有其他几个因素需要考虑。成本和推理延迟等因素在决策过程中也起着至关重要的作用。
- en: Deploying large FMs can be cost prohibitive due to the substantial infrastructure
    needed to host them. As a result, there may be a need to opt for smaller and less
    resource-intensive models in production to strike a balance between cost and model
    performance. Additionally, certain applications, like those related to fraud detection,
    demand low inference latency. This requirement further narrows down the pool of
    models that are suitable for production deployment, as low-latency models are
    preferred in such scenarios.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 部署大型FM可能会因为需要大量基础设施来托管而成本高昂。因此，在生产中可能需要选择更小、资源消耗更少的模型，以在成本和模型性能之间取得平衡。此外，某些应用，如与欺诈检测相关的应用，需要低推理延迟。这一需求进一步缩小了适合生产部署的模型范围，因为在这些场景中，低延迟模型更受欢迎。
- en: In conclusion, model selection can be a highly iterative process based on different
    considerations and potential changes in requirements. It is important, therefore,
    to consider different models and sizes for different needs based on model performance,
    running cost, and latency for the different use cases.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，模型选择可能是一个高度迭代的流程，基于不同的考虑和需求的变化。因此，根据模型性能、运行成本和不同用例的延迟，考虑不同模型和大小以满足不同需求是很重要的。
- en: Building FMs from scratch via pre-training
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从头开始构建FM（因子模型）通过预训练
- en: 'Organizations that want to build their own FMs would skip the model selection
    process and follow a model training process called pre-training, which is the
    process of training an ML model on a large dataset. It is a key technique in developing
    FMs and it requires large datasets, significant compute resources, and advanced
    model training techniques. The primary objective of pre-training is to acquire
    robust, general representations of the data that can be effectively applied to
    other tasks subsequently. Pre-training is typically done in a self-supervised
    manner on unlabeled data. The datasets used are very large, usually hundreds of
    gigabytes to terabytes, to teach comprehensive representations. The following
    are several techniques for LLM pre-training:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 想要自己构建FM的组织会跳过模型选择过程，转而遵循一个称为预训练的模型训练过程，即在大型数据集上训练ML模型的过程。这是开发FM的关键技术，需要大量数据集、显著的计算资源和高级模型训练技术。预训练的主要目标是获取稳健、通用的数据表示，这些表示可以有效地应用于后续的其他任务。预训练通常在未标记数据上以自监督的方式进行。所使用的数据集非常大，通常为数百吉字节到太字节，以教授全面的数据表示。以下是一些LLM（大型语言模型）预训练的技术：
- en: '**Causal language modeling**: Causal language modeling is a technique employed
    in training generative language models like GPT-3, characterized by predicting
    the next token solely based on the preceding context without access to future
    tokens. This ensures that the model learns meaningful sequential dependencies,
    promoting coherent and logical text generation during inference. During training,
    the previous context is limited by a fixed window length, and the model must predict
    tokens sequentially in a forward direction. This differs from standard bidirectional
    language modeling, where both the left and right context is seen. While more challenging,
    causal modeling enhances generation quality and equips the model to handle open-ended
    text generation tasks effectively.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**因果语言模型**：因果语言模型是训练像GPT-3这样的生成语言模型时采用的一种技术，其特点是仅根据先前的上下文预测下一个标记，而不访问未来的标记。这确保了模型学习到有意义的序列依赖关系，在推理过程中促进连贯和逻辑的文本生成。在训练过程中，先前的上下文被限制在一个固定的窗口长度内，模型必须按顺序向前预测标记。这与标准的双向语言模型不同，双向语言模型可以看到左右两个上下文。虽然更具挑战性，但因果建模提高了生成质量，并使模型能够有效地处理开放式的文本生成任务。'
- en: '**Masked language model**: Masked language model pre-training is a common technique
    for training extensive language models such as BERT. This method involves taking
    a text dataset intended for training and randomly masking a portion of tokens,
    usually around 15%, within each training example. These masked tokens are substituted
    with a distinct `[MASK]` token. The model then processes this altered input and
    is trained to forecast the original identities of the masked words. This prediction
    leverages the contextual information from nearby unmasked tokens. The model’s
    optimization is guided by a loss function that incentivizes accurate predictions
    of the originally masked words. Consequently, the model’s parameters are iteratively
    adjusted to minimize this prediction loss, leading to improved language understanding
    and generation capabilities.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**掩码语言模型**：掩码语言模型预训练是训练像BERT这样的广泛语言模型的一种常见技术。这种方法涉及取一个用于训练的文本数据集，并在每个训练示例中随机掩码大约15%的标记。这些掩码标记被替换为一个独特的`[MASK]`标记。然后模型处理这个修改后的输入，并被训练来预测掩码单词的原始身份。这种预测利用了附近未掩码标记的上下文信息。模型的优化由一个损失函数引导，该函数鼓励准确预测原始掩码的单词。因此，模型的参数被迭代调整以最小化这种预测损失，从而提高语言理解和生成能力。'
- en: '**Next sentence prediction**: Next sentence prediction pre-training is a technique
    used in natural language processing, particularly in the training of language
    models like BERT. The objective of this technique is to enhance the model’s understanding
    of sentence relationships and context. In this approach, the model is trained
    to predict whether two consecutive sentences in a text corpus are logically connected
    or not. During training, pairs of sentences are sampled, and the model learns
    to predict whether the second sentence follows the first one coherently. This
    task encourages the model to capture semantic relationships between sentences
    and understand discourse flow. By exposing the model to this binary classification
    task, it gains the ability to comprehend sentence-level context and relationships,
    which in turn improves its performance on a wide range of downstream tasks, such
    as question answering, sentiment analysis, and text classification.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下一句预测**：下一句预测预训练是自然语言处理中的一种技术，尤其在训练像BERT这样的语言模型时使用。这种技术的目标是增强模型对句子关系和上下文的理解。在这种方法中，模型被训练来预测文本语料库中连续的两个句子是否在逻辑上相连。在训练过程中，成对的句子被采样，模型学习预测第二个句子是否连贯地跟随第一个句子。这个任务鼓励模型捕捉句子之间的语义关系并理解话语流。通过让模型接触到这个二元分类任务，它获得了理解句子级上下文和关系的能力，这反过来又提高了它在广泛下游任务上的性能，例如问答、情感分析和文本分类。'
- en: '**Diffusion**: In this technique, a dataset of images paired with text captions
    is used. The model consists of an encoder and decoder, and images are incrementally
    corrupted with noise during multiple iterations. At each step, the encoder encodes
    the noisy image, and the decoder attempts to reverse the noise and recover the
    original image, facilitating denoising autoencoder training for valuable image
    representations. The process involves hyperparameters like the number of diffusion
    steps and noise levels, often trained through numerous denoising cycles. The encoder
    learns semantic image representations from noise, while the decoder learns to
    generate clean pixels from these representations. Post pre-training, the decoder
    enables image generation, and the encoder encodes images into a latent space for
    manipulation, often guided by text captions for conditional input.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩散**：在这种技术中，使用图像数据集和文本标题配对。模型由编码器和解码器组成，图像在多次迭代中逐渐被噪声破坏。在每一步中，编码器对噪声图像进行编码，解码器尝试反转噪声并恢复原始图像，从而促进用于有价值图像表示的降噪自编码器训练。该过程涉及超参数，如扩散步骤的数量和噪声水平，通常通过多次降噪周期进行训练。编码器从噪声中学习语义图像表示，而解码器学习从这些表示中生成干净的像素。预训练后，解码器能够生成图像，编码器将图像编码到潜在空间以进行操作，通常由文本标题指导条件输入。'
- en: After FMs are pre-trained with a vast amount of training data, they would display
    a number of abilities in solving text-based or image-based problems such as fluent
    text generation or image generation.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用大量训练数据对FM进行预训练后，它们在解决基于文本或图像的问题方面会显示出多种能力，如流畅的文本生成或图像生成。
- en: Language models, post pre-training, accumulate substantial world knowledge and
    encode a vast range of information, concepts, and relationships from their pre-training
    data. They possess a deep understanding of language, facilitating the analysis
    of syntax, semantics, and text structure. These models excel in generating meaningful
    text with strong coherence and logical consistency. Another notable feature of
    LLMs is their capacity to efficiently tackle diverse tasks using a single model
    with various conditioning inputs. Additionally, they are adaptable to downstream
    tasks by transferring their acquired foundational knowledge.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型在预训练后积累了大量的世界知识，并从其预训练数据中编码了广泛的信息、概念和关系。它们对语言有深刻的理解，有助于分析句法、语义和文本结构。这些模型在生成具有强烈连贯性和逻辑一致性的有意义文本方面表现出色。LLMs的另一个显著特点是它们能够使用单个模型和不同的条件输入高效地处理各种任务。此外，它们可以通过转移其获得的基础知识来适应下游任务。
- en: For image-based FMs after pre-training on large image datasets, diffusion models
    like DALL-E and Stable Diffusion have exhibited capabilities in many image tasks.
    For example, these models can be used for synthesizing highly realistic, coherent
    images that match the semantics of the prompts. You can also use these models
    to provide fine-grained control over image attributes and composition, and creatively
    recombine different concepts into novel images. Other image-related capabilities
    such as inpainting (replacing or restoring missing sections of an image), outpainting
    (expanding and filling missing parts of an image), and style transfer (tuning
    the style of images by manipulating the text inputs) also become available after
    pre-training.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在大图像数据集上预训练后的基于图像的FM，扩散模型如DALL-E和Stable Diffusion在许多图像任务中展示了能力。例如，这些模型可以用于合成与提示语义相匹配的高度逼真、连贯的图像。您还可以使用这些模型来提供对图像属性和组成的精细控制，并创造性地将不同的概念重新组合成新颖的图像。其他图像相关能力，如修复（替换或恢复图像的缺失部分）、扩展（扩展并填充图像的缺失部分）和风格迁移（通过操纵文本输入来调整图像风格），在预训练后也变得可用。
- en: Pre-training an FM demands complex engineering effort as well as significant
    compute resources and the availability of a large amount of training. Training
    these models can take weeks or months with modern compute and data infrastructures.
    The following diagram shows the high-level flow of model pre-training for LLMs.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练FM需要复杂的工程努力以及大量的计算资源和大量训练数据的可用性。使用现代计算和数据基础设施，训练这些模型可能需要数周或数月。以下图表显示了LLMs模型预训练的高级流程。
- en: '![A diagram of a model  Description automatically generated](img/B20836_15_02.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![模型图示 自动生成描述](img/B20836_15_02.png)'
- en: 'Figure 15.2: Pre-training an LLM'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.2：预训练LLM
- en: 'At a high level, Pre-training involves the following key steps:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，预训练包括以下关键步骤：
- en: '**Data collection and preprocessing**: Gather massive text corpora from diverse
    sources like books, common crawl, web pages, and Wikipedia. Consider a mixture
    of general-purpose data and specialized data. Specialized data such as scientific
    data and code data give the model specific problem-solving capabilities. A legal
    review of collected datasets might be required to ensure compliance with any license
    or IP restrictions.'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据收集和预处理**：从书籍、通用爬虫、网页和维基百科等不同来源收集大量文本语料库。考虑通用数据和专业数据的混合。如科学数据和代码数据等特定数据赋予模型特定的解决问题的能力。可能需要对收集的数据集进行法律审查，以确保符合任何许可或IP限制。'
- en: '**Data preprocessing**: Raw data needs to be preprocessed to ensure high quality
    as it is pivotal to the ultimate performance of the FM. The steps normally include
    data quality checks and filtering, deduplication, privacy redaction (PII), and
    tokenization, which are important steps in data preprocessing. Unlike training
    for smaller models, it is crucial to have high-quality data before the Pre-training
    process starts, as it is very expensive to repeatedly pre-train FMs due to high
    compute resource requirements and the long time pre-training takes.'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据预处理**：原始数据需要预处理以确保高质量，因为它是FM最终性能的关键。通常包括数据质量检查和过滤、去重、隐私编辑（PII）和标记化，这些是数据预处理的重要步骤。与为较小模型训练相比，在预训练过程开始之前拥有高质量数据至关重要，因为由于高计算资源需求和漫长的预训练时间，重复预训练FM的成本非常高。'
- en: '**Model architecture selecting**: Design a transformer-based architecture like
    BERT or GPT for LLMs pre-training. There are three main variations of transformer
    architecture to consider, including encoder-only architecture, decoder-only architecture,
    and encode-decoder architecture. Each architecture has its own benefits, limitations,
    and targeted use cases. So, it is important to consider these architectures based
    on your intended objectives. For an image-based model, consider a diffusion-based
    architecture.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型架构选择**：为LLM的预训练设计一个基于transformer的架构，如BERT或GPT。需要考虑transformer架构的三个主要变体，包括仅编码器架构、仅解码器架构和编码器-解码器架构。每种架构都有其自身的优点、局限性和目标用例。因此，根据您的预期目标考虑这些架构是很重要的。对于基于图像的模型，考虑基于扩散的架构。'
- en: '**Pre-training technique selection**: Pick a pre-training technique such as
    casual language modeling, masked language modeling, or diffusion modeling depending
    on the model type.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预训练技术选择**：根据模型类型选择预训练技术，如因果语言建模、掩码语言建模或扩散建模。'
- en: '**Training infrastructure provisioning and distributed training setup**: Provision
    TPUs/GPU clusters for accelerated parallel training. Split data over many machines
    and devices.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练基础设施配置和分布式训练设置**：为加速并行训练提供TPU/GPU集群。将数据分散到多台机器和设备上。'
- en: '**Training loop**: Iterate through data batches, apply masking, predict targets,
    compute loss, and update weights. Periodically save model parameters throughout
    training. Track validation performance and stop if overfitting.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练循环**：迭代数据批次，应用掩码，预测目标，计算损失，并更新权重。在整个训练过程中定期保存模型参数。跟踪验证性能，并在过拟合时停止。'
- en: '**Evaluation**: Assess pre-trained models on metrics such as perplexity and
    entropy for LLMs, and CLIP score and Fréchet inception distance for text-to-image
    diffusion models.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估**：评估预训练模型在LLM的困惑度和熵等指标上，以及文本到图像扩散模型的CLIP分数和Fréchet inception距离。'
- en: '**Iteration**: Repeat this process until you achieve the desired outcome.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代**：重复此过程，直到达到预期结果。'
- en: There are many commercial and open-source efforts in building pre-trained FMs,
    covering a wide range of domains. While most of the FMs are general purpose FMs
    to solve general purpose problems, some organizations are realizing the value
    of domain-specific FMs and building FMs for a particular domain such as medicine
    and finance.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建预训练FM方面，有许多商业和开源的努力，涵盖了广泛的领域。虽然大多数FM都是通用目的FM，用于解决通用问题，但一些组织正在认识到特定领域FM的价值，并为特定领域如医学和金融构建FM。
- en: 'The following is a list of sample pre-trained open-source FMs that have been
    adopted by various organizations for building generative AI solutions:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些被各种组织采用以构建生成式AI解决方案的样本预训练开源FM列表：
- en: '| **Model name** | **Description** | **Modality** | **Provider** |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| **模型名称** | **描述** | **模态** | **提供者** |'
- en: '| T5 | **T5** (**Text-to-Text Transfer Transformer**) was developed by Google.
    It is an encoder-decoder Transformer model trained on a multi-task mixture of
    unsupervised and supervised data.T5 converts all language tasks into a unified
    text-to-text format, which simplifies model training and inference.It uses a scaled-down
    transformer architecture compared to predecessors like BERT. T5 comes in different
    sizes as large as 11 B. It is trained on the **Colossal Clean Crawled Corpus**
    (**C4**) dataset, containing hundreds of gigabytes of text from the web. It permits
    transfer learning by fine-tuning downstream tasks using standard text-to-text
    formatting. | Language | Google |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| T5 | **T5**（**文本到文本迁移 Transformer**）是由 Google 开发的。它是一个在无监督和监督数据的多任务混合上训练的编码器-解码器
    Transformer 模型。T5 将所有语言任务转换为统一的文本到文本格式，从而简化了模型训练和推理。与 BERT 等前辈相比，T5 使用的是缩小的 Transformer
    架构。T5 有不同的大小，最大可达 11 B。它是在 **Colossal Clean Crawled Corpus**（**C4**）数据集上训练的，包含来自网络的数百
    GB 的文本。它允许通过使用标准的文本到文本格式微调下游任务来进行迁移学习。 | 语言 | Google |'
- en: '| Stable Diffusion | Stable Diffusion is an open-source text-to-image generative
    model developed by Stability AI. It is based on a convolutional autoencoder with
    latent diffusion-based sampling. Stable Diffusion can generate realistic images
    and art from text descriptions and prompts. The model was trained on LAION-5B,
    a large dataset of image-text pairs from the internet. | Image | Stability AI
    |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| Stable Diffusion | Stable Diffusion 是由 Stability AI 开发的一个开源的文本到图像生成模型。它基于基于潜在扩散采样的卷积自编码器。Stable
    Diffusion 可以根据文本描述和提示生成逼真的图像和艺术作品。该模型是在 LAION-5B 上训练的，这是一个包含来自互联网的大量图像-文本对的数据库。
    | 图像 | Stability AI |'
- en: '| Falcon | Falcon is an LLM with 40 billion parameters trained on one trillion
    tokens. Pre-training data was collected from public crawls of the web. To broaden
    Falcon’s abilities, this dataset was then extended with a few curated sources
    such as research papers and conversations from social media. | Language | TII
    |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| Falcon | Falcon 是一个拥有 400 亿参数的 LLM，在 1000 亿个标记上进行了训练。预训练数据是从公共网络爬取中收集的。为了扩展
    Falcon 的能力，这个数据集后来还扩展了一些精选来源，如研究论文和社交媒体上的对话。 | 语言 | TII |'
- en: '| Llama 2 7B | Llama 2 is an LLM developed by Meta. Llama 2 was pre-trained
    on publicly available online data sources using transformer architecture. It comes
    in different sizes from 7B to 70B parameters. It is an open-source model that
    can be used for commercial usage. | Language | Meta |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| Llama 2 7B | Llama 2 是 Meta 开发的一个大型语言模型。Llama 2 使用 Transformer 架构在公开可用的在线数据源上进行预训练。它从
    70 亿参数到 70 亿参数不等。它是一个开源模型，可用于商业用途。 | 语言 | Meta |'
- en: '| GPT-J 6B | GPT-J is a transformer-based model with 6 billion parameters.
    It is an autoregressive decoder-only model for NLP tasks. | Language | EleutherAI
    |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| GPT-J 6B | GPT-J 是一个拥有 60 亿参数的基于 Transformer 的模型。它是一个仅用于 NLP 任务的自动回归解码器模型。
    | 语言 | EleutherAI |'
- en: '| Segment Anything Model (SAM) | A model that can cut out objects in any image.
    | Computer vision | Meta |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| Segment Anything Model (SAM) | 一种可以在任何图像中裁剪出物体的模型。 | 计算机视觉 | Meta |'
- en: 'Table 15.1: Example pre-trained FMs'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 表 15.1：示例预训练 FM
- en: 'The pre-training process allows models to learn representations of language
    as well as encode world knowledge within their parameters. As this model is specifically
    trained to predict the next token given an input text, its primary capability
    lies in completing sentences with a high likelihood. As a result, it is already
    capable of completing certain tasks such as completing a sentence and answering
    some questions. The following is an example of input and out using the Llama 2
    model with 7B parameters:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练过程允许模型学习语言表示，并在其参数中编码世界知识。由于这个模型专门训练用于根据输入文本预测下一个标记，因此其主要能力在于以高概率完成句子。因此，它已经能够完成某些任务，例如完成句子和回答一些问题。以下是一个使用具有
    70 亿参数的 Llama 2 模型的输入和输出示例：
- en: '[PRE0]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, while the model provides the correct answer, Paris, it also
    generates additional unasked-for text. So, the question is, how can we make a
    pre-trained model perform a task with more precision? We will try to answer this
    question in the section on *Instruction fine-tuning*.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，虽然模型提供了正确的答案，巴黎，但它也生成了额外的未询问的文本。因此，问题是，我们如何使预训练模型在更精确的任务上表现？我们将在关于 *指令微调*
    的章节中尝试回答这个问题。
- en: Due to the high cost associated with pre-training really large FMs and the demand
    for specialized engineering and scientific expertise, only a limited number of
    organizations have the resources to undertake the pre-training of foundational
    models. Consequently, many organizations opt for adaptation and customization
    approaches to align the model with their requirements.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 由于预训练真正大型FM的高成本以及需要专门的工程和科学专业知识，只有少数组织有资源进行基础模型的预训练。因此，许多组织选择适应和定制方法，以使模型与他们的需求相一致。
- en: Adaptation and customization
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 适应性和定制化
- en: 'While pre-trained large FMs already come with many capabilities that meet diverse
    requirements, they are mainly trained using general-purpose datasets and might
    not have knowledge about niche domains, such as medicine and legal, or they might
    not know how to perform a specific task. In addition, you might have your own
    proprietary data and workflow that you need the model to be aware of. In these
    cases, you will need to refine models by incorporating domain or proprietary expertise
    or improving their effectiveness in specific tasks. To accomplish this, four primary
    options are available:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然预训练的大型FM已经具备许多满足多样化需求的能力，但它们主要是使用通用数据集进行训练的，可能没有关于特定领域（如医学和法律）的知识，或者可能不知道如何执行特定任务。此外，你可能有自己的专有数据和流程，需要模型了解。在这些情况下，你需要通过结合领域或专有专业知识或提高它们在特定任务中的有效性来细化模型。为此，有四种主要选项可用：
- en: Domain adaptation training
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域适应性训练
- en: Fine-tuning
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调
- en: Reinforcement learning with human feedback
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有人工反馈的强化学习
- en: Prompt engineering
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程
- en: Let’s explore each of these alternatives in more detail.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地探讨这些替代方案。
- en: Domain adaptation pre-training
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 领域适应性预训练
- en: 'Pre-trained language models are trained on broad universal language data and
    they only hold general knowledge, as such they might underperform in niche domains
    such as finance or medicine. For example, these models might not understand niche
    vocabulary, jargon, or name entities in a highly technical or esoteric domain.
    The technique to teach model learn new knowledge in a new domain is called domain
    adaptation pre-trained. The following example shows the results from a GPT-J 6B
    model before domain adaptation and after domain adaption using SEC 10K filings:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练语言模型是在广泛的通用语言数据上训练的，它们只持有一般知识，因此它们可能在特定领域（如金融或医学）中表现不佳。例如，这些模型可能不理解高度技术或神秘领域的特定词汇、术语或命名实体。教授模型在新领域学习新知识的技巧称为领域适应性预训练。以下是一个GPT-J
    6B模型在领域适应性前和领域适应性后的结果示例：
- en: '[PRE1]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As evident, domain adaptation makes the model more familiar with financial terminologies,
    and able to come back with more contextual and coherent responses.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如所示，领域适应性使模型更熟悉金融术语，并能提供更多上下文和连贯的响应。
- en: 'The process of domain adaptation is very similar to that of pre-training, also
    following the *self-supervised learning* approach using an unlabeled dataset.
    Here are the general stages encompassed in the process of domain adaptation fine-tuning
    for an LLM:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 领域适应的过程与预训练非常相似，也遵循使用未标记数据集的*自监督学习*方法。以下是LLM领域适应微调过程的一般阶段：
- en: '**Data collection for target domain**: Acquire relevant text data that accurately
    represents the target domain.'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**目标领域数据收集**：获取准确代表目标领域的相关文本数据。'
- en: '**Data preprocessing**: Clean, deduplicate, tokenize, normalize special characters,
    and redact privacy information within the collected data. This is similar to the
    pre-training process.'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据预处理**：在收集的数据中进行清理、去重、分词、规范化特殊字符和删除隐私信息。这与预训练过程类似。'
- en: '**Base pre-trained model selection**: Choose an appropriate pre-trained model
    architecture as the foundation.'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**基础预训练模型选择**：选择合适的预训练模型架构作为基础。'
- en: '**Model initialization**: Initialize the model’s weights using a pre-trained
    checkpoint.'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型初始化**：使用预训练的checkpoint初始化模型的权重。'
- en: '**Domain-specific training**: Train the model using the domain-specific data
    for a predetermined number of epochs and assess training performance.'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特定领域训练**：使用特定领域的数据进行预定的epoch数训练，并评估训练性能。'
- en: '**In-domain testing**: Evaluate the trained model on a test dataset from the
    same domain.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**领域内测试**：在来自同一领域的测试数据集上评估训练好的模型。'
- en: '**Iterative optimization**: Reiterate the training process to progressively
    enhance model performance.'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代优化**：重复训练过程，逐步提高模型性能。'
- en: Self-supervised learning is an ML paradigm where a model learns to generate
    its own labels from the input data, allowing it to learn meaningful representations
    and features without relying on externally provided labeled datasets.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习是一种机器学习范式，其中模型学会从输入数据中生成自己的标签，这使得它能够在不依赖外部提供的标记数据集的情况下学习有意义的表示和特征。
- en: There are many examples of domain-adapted pre-trained models. For example, FinBERT
    is the result of domain adaption of BERT for the finance domain, and LEGAL-BERT
    is a family of BERT models for the legal domain, intended to assist legal NLP
    research, computational law, and legal technology applications. Some of the more
    recent domain-adapted models include Med-PaLM 2 from Google for medical NLP tasks.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多领域自适应预训练模型的例子。例如，FinBERT是针对金融领域对BERT进行领域自适应的结果，而LEGAL-BERT是一系列针对法律领域的BERT模型，旨在协助法律NLP研究、计算法学和法律技术应用。一些较新的领域自适应模型包括谷歌为医疗NLP任务开发的Med-PaLM
    2。
- en: Although domain adaptation can enhance a model’s comprehension of a new target
    domain, it might lead to diminished performance in broader, general-purpose domains.
    To address some of these constraints, strategies like importance sampling of data
    and multi-stage domain adaptation have been investigated to mitigate such drawbacks.
    An in-depth exploration of these techniques is beyond the scope of this book.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管领域自适应可以增强模型对新目标领域的理解，但它可能导致在更广泛、通用领域的性能下降。为了解决这些限制，已经研究了诸如数据重要性采样和多阶段领域自适应等策略来减轻这些缺点。对这些技术的深入探讨超出了本书的范围。
- en: Fine-tuning
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微调
- en: FMs such as Llama 2, GPT, and Falcon are trained on diverse datasets to acquire
    general representations rather than being specialized for specific tasks. Fine-tuning
    is the process of adapting these FMs to the specific nuances and patterns present
    in particular datasets and tasks.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 2、GPT和Falcon等FM是在多样化的数据集上训练的，以获取通用表示，而不是针对特定任务进行专门化。微调是将这些FM适应特定数据集和任务中存在的特定细微差别和模式的过程。
- en: This approach capitalizes on the extensive knowledge gained during the initial
    pre-training of FMs and produces models that excel at target tasks beyond the
    general capabilities.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法利用了在FM的初始预训练期间获得的大量知识，并产生了在目标任务上超越一般能力的模型。
- en: In the following sections, we will discuss instruction fine-tuning and parameter-efficient
    fine-tuning. Let’s get into it!
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将讨论指令微调和参数高效微调。让我们开始吧！
- en: Instruction fine-tuning
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指令微调
- en: One technique to enhance an FM’s ability to perform new tasks or improve its
    ability to perform an existing task by teaching it to follow an instruction. This
    is where instruction fine-tuning comes in. Instruction fine-tuning teaches a pre-trained
    model to perform an existing task better or learn a new task such as summarization
    or reasoning. Compared to pre-training, instruction fine-tuning requires significantly
    less data.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 一种增强FM执行新任务或提高其执行现有任务能力的技术是通过教授它遵循指令。这就是指令微调的用武之地。指令微调教会预训练模型更好地执行现有任务或学习新任务，如摘要或推理。与预训练相比，指令微调需要的数据量显著减少。
- en: 'Instruction fine-tuning is a supervised approach where you need to provide
    a labeled training dataset in the form of a prompt and the expected output from
    the prompt. The following is an example of instruction fine-tuning a dataset called
    `Dolly from Databricks`:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 指令微调是一种监督方法，您需要以提示的形式提供标记的训练数据集以及从提示中期望的输出。以下是一个对名为“Dolly from Databricks”的数据集进行指令微调的示例：
- en: '[PRE2]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can see the complete Dolly dataset at [https://huggingface.co/datasets/databricks/databricks-dolly-15k.](https://huggingface.co/datasets/databricks/databricks-dolly-15k)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://huggingface.co/datasets/databricks/databricks-dolly-15k.](https://huggingface.co/datasets/databricks/databricks-dolly-15k)查看完整的Dolly数据集。
- en: 'After instruction fine-tuning with a labeled dataset such as Dolly-15K, the
    model should be able to generate responses with greater precision for the same
    question. For example, if we fine-tune the Llama 2 7B model with the Dolly-15k
    dataset, you will get the following output for the same text completion task from
    the previous section:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用如Dolly-15K这样的标记数据集进行指令微调后，模型应该能够对相同问题生成更精确的响应。例如，如果我们使用Dolly-15k数据集微调Llama
    2 7B模型，您将得到以下来自上一节文本补全任务的输出：
- en: '[PRE3]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The process of instruction fine-tuning is very similar to any supervised ML,
    where you provide labeled training data, and the model learns to predict the output
    and minimize the loss between the predicted value and labels. You can also perform
    additional fine-tuning on models already fine-tuned to further improve their performance.
    The following diagram illustrates the flow of instruction fine-tuning:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 指令微调的过程与任何监督机器学习非常相似，其中你提供标记的训练数据，模型学习预测输出并最小化预测值与标签之间的损失。你还可以对已经微调的模型进行额外的微调，以进一步提高其性能。以下图表说明了指令微调的流程：
- en: '![A diagram of a model  Description automatically generated](img/B20836_15_03.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![一个模型的图表  自动生成的描述](img/B20836_15_03.png)'
- en: 'Figure 15.3: Instruction fine-tuning of pre-trained LLM model'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.3：预训练LLM模型的指令微调
- en: Several existing public datasets are available for instruction fine-tuning,
    such as Dolly and TriviaQA. However, when dealing with proprietary knowledge and
    specific capabilities, it becomes necessary to curate and prepare custom datasets
    for instruction fine-tuning. Depending on the domains and use cases, subject-matter
    experts may be required to assist in assembling these datasets, including crafting
    domain-specific prompts and defining desired answers. To ensure the high quality
    and standards of these datasets, a combination of human expert evaluation and
    automated scoring mechanisms should be employed. This approach ensures that the
    datasets meet rigorous criteria for accuracy and reliability.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 几个现有的公共数据集可用于指令微调，例如Dolly和TriviaQA。然而，当处理专有知识和特定能力时，有必要为指令微调创建和准备定制的数据集。根据领域和用例，可能需要领域专家协助组装这些数据集，包括制作特定领域的提示和定义期望的答案。为确保这些数据集的高质量和标准，应采用人类专家评估和自动化评分机制的组合。这种方法确保数据集满足严格的准确性和可靠性标准。
- en: In terms of automated scoring and evaluation of fine-tuned models, one can leverage
    powerful models like Claude from Anthropics or GPT-4\. These models contribute
    to the robustness and precision of the evaluation process.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动化评分和评估微调模型方面，可以利用Anthropics的Claude或GPT-4等强大模型。这些模型有助于提高评估过程的稳健性和精确性。
- en: Fine-tuning an LLM is not without complexities. Challenges include issues such
    as overfitting, where the model excels on the training data but struggles to apply
    its knowledge to unfamiliar data, as well as the risk of catastrophic forgetting,
    which involves the model erasing its original pre-training knowledge. In order
    to tackle these obstacles, various strategies can be employed to alleviate the
    potential constraints associated with conventional fine-tuning for LLMs. These
    include implementing cautious regularization techniques such as dropout, L2 normalization,
    and early stopping to curb overfitting tendencies. The approach of gradual unfreezing
    can be adopted as well, involving a gradual release of lower layers over time
    to keep the model’s pre-existing knowledge. Engaging in multi-task training offers
    another avenue, where simultaneous fine-tuning is carried out across multiple
    datasets or objectives, fostering broader adaptability. Additionally, the method
    of continual pre-training can be integrated, supplementing fine-tuning batches
    with the initial pre-training objective to sustain foundational learning.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 微调LLM并非没有复杂性。挑战包括诸如过拟合等问题，模型在训练数据上表现出色，但难以将其知识应用于未知数据，以及灾难性遗忘的风险，这涉及模型删除其原始预训练知识。为了克服这些障碍，可以采用各种策略来减轻与LLM传统微调相关的潜在约束。这包括实施谨慎的正则化技术，如dropout、L2归一化和提前停止，以抑制过拟合倾向。还可以采用逐步解冻的方法，随着时间的推移逐渐释放底层，以保持模型现有的知识。参与多任务训练提供另一条途径，在多个数据集或目标上同时进行微调，促进更广泛的适应性。此外，可以整合持续预训练的方法，通过补充预训练批次以初始预训练目标来维持基础学习。
- en: Fine-tuning can provide differentiating capabilities for organizations seeking
    a competitive edge with custom datasets and unique knowledge, without the heavy
    investment of training models from scratch.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 微调可以为寻求通过定制数据集和独特知识获得竞争优势的组织提供区分能力，而无需对从头开始训练模型进行大量投资。
- en: Parameter-efficient fine-tuning
  id: totrans-191
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参数高效的微调
- en: Regular instruction fine-tuning requires the full pre-trained model to be fine-tuned
    and all its parameters need to be available for potential updates. This requires
    significant compute resources, especially when the models are large. To address
    this challenge, a new technique called **parameter-efficient fine-tuning** (**PEFT**)
    has been introduced. PEFT refers to techniques to adapt large pre-trained language
    models to downstream tasks by introducing a small new set of trainable parameters
    instead of updating the original parameters of the model.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 定规的指令微调需要微调完整的预训练模型，并且所有参数都需要可用于潜在的更新。这需要大量的计算资源，尤其是在模型很大时。为了解决这一挑战，引入了一种名为**参数高效微调**（**PEFT**）的新技术。PEFT指的是通过引入一小组新的可训练参数来适应大型预训练语言模型到下游任务的技术，而不是更新模型的原始参数。
- en: This approach significantly reduces both computational requirements and storage
    demands. Additionally, PEFT mitigates the challenges posed by catastrophic forgetting—a
    phenomenon encountered during comprehensive LLM fine-tuning, whereby an LLM fails
    to perform tasks that it knew how to perform previously after fine-tuning.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法显著降低了计算需求和存储需求。此外，PEFT缓解了灾难性遗忘带来的挑战——这是在全面LLM微调过程中遇到的现象，即在微调后，LLM无法执行之前知道如何执行的任务。
- en: 'There are several PEFT techniques available, including **Low-Rank Adaptation**
    (**LoRA**), prefix tuning, and prompt tuning. You can find out how these techniques
    work by visiting the related online resources directly. With these libraries,
    performing PEFT is a very straightforward process. For example, using LoRA for
    PEFT involves adding the following three main steps:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的PEFT技术包括**低秩适应**（**LoRA**）、前缀调整和提示调整。您可以直接访问相关在线资源了解这些技术的工作原理。使用这些库，执行PEFT是一个非常直接的过程。例如，使用LoRA进行PEFT涉及以下三个主要步骤：
- en: 'Import the necessary library packages:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的库包：
- en: '[PRE4]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create a configuration corresponding to the PEFT method:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建与PEFT方法对应的配置：
- en: '[PRE5]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Wrap the base model by calling `get_peft_model`:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用`get_peft_model`来包装基础模型：
- en: '[PRE6]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The rest of the model training steps are the same as regular training. After
    the model is fine-tuned, you can save the model by calling the following command:'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型训练的其他步骤与常规训练相同。模型微调后，您可以通过调用以下命令保存模型：
- en: '[PRE7]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This will only save the incremental PEFT weights that were trained. During inference
    time, you use the **PeftModel** package to load the base model and PEFT weights
    together as the combined model for serving. You can also merge the PEFT weights
    with the base model prior to deployment.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这将仅保存训练的增量PEFT权重。在推理时间，您使用**PeftModel**包将基础模型和PEFT权重一起作为服务时的组合模型加载。您也可以在部署之前将PEFT权重与基础模型合并。
- en: Reinforcement learning from human feedback
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 来自人类反馈的强化学习
- en: With domain adaption and instruction fine-tuning, LLMs can generate compelling
    and diverse text from input prompts. However, how does an LLM know that it has
    generated a good response?
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 通过领域适应和指令微调，LLM可以从输入提示生成引人入胜且多样化的文本。然而，LLM如何知道它已经生成了一个好的响应？
- en: What makes a text good is hard to define as it is subjective and context dependent.
    Loss functions, such as cross-entropy, measure the accuracy of a model predicting
    the next token; however, it cannot tell whether the overall response is aligned
    with human preferences. Other metrics such as ROUGE and BLEU are designed to better
    capture human preferences by optimizing the overlap of n-grams with human-generated
    reference text, however, it does not capture semantic context.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 文本的好坏难以定义，因为它具有主观性和依赖性。损失函数，如交叉熵，衡量模型预测下一个标记的准确性；然而，它无法判断整体响应是否与人类偏好一致。其他指标，如ROUGE和BLEU，通过优化与人类生成参考文本的n-gram重叠来更好地捕捉人类偏好，然而，它并不捕捉语义上下文。
- en: To address the limitation of human alignment for the generated text from an
    LLM, **reinforcement learning from human feedback** (**RLHF**) was introduced
    as an additional tuning paradigm to help an LLM align with human preferences and
    values. RLHF also helps address the scaling challenges associated with human-generated
    training data for instruction fine-tuning, as it is easier for a human to rate/rank
    responses to prompts than create new prompt and response pairs.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决从LLM生成的文本中人类对齐的限制，**从人类反馈中进行强化学习**（**RLHF**）被引入作为一种额外的微调范式，以帮助LLM与人类偏好和价值观对齐。RLHF还有助于解决与人类生成的训练数据相关的指令微调的扩展挑战，因为人类对提示的响应进行评分/排名比创建新的提示和响应对更容易。
- en: 'With RLHF, human evaluators rank or vote on the response generated by the target
    LLM for a prompt. The ratings collected from a human can be used to train a reward
    model (usually based on the LLM model) to score the model response (a scalar value
    indicating how good a response is), and this model is then incorporated into the
    fine-tuning of the model to achieve performance that’s more aligned to human value
    or preferences. This helps with the tone, style, and creativity of output, and
    it can be used to detect ethical issues such as harmful language in the responses.
    The following diagram illustrates the flow of RLHF:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RLHF，人类评估者对目标LLM生成的针对提示的响应进行排名或投票。从人类收集的评分可以用来训练奖励模型（通常基于LLM模型），以评分模型响应（表示响应有多好的标量值），然后该模型被纳入模型的微调中，以实现更符合人类价值观或偏好的性能。这有助于输出的语气、风格和创造力，并且可以用来检测响应中的道德问题，如有害语言。以下图示说明了RLHF的流程：
- en: '![A diagram of a model  Description automatically generated](img/B20836_15_04.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![模型图  描述自动生成](img/B20836_15_04.png)'
- en: 'Figure 15.4: RLHF flow'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.4：RLHF流程
- en: There are many examples of RLHF-tuned FMs, including ChatGPT from OpenAI, Claude
    from Anthropic, and LLAMA-2-Chat from Meta. As many of us have experienced, these
    models have all produced compelling and human-aligned results on a wide range
    of tasks.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多经过RLHF微调的FM示例，包括OpenAI的ChatGPT、Anthropic的Claude和Meta的LLAMA-2-Chat。正如我们许多人所经历的，这些模型在广泛的任务上都产生了令人信服且符合人类的结果。
- en: RLHF is a complex and iterative process that requires careful design and implementation
    to effectively leverage human feedback for training. Some of the known challenges
    include bias in human feedback, lack of subject-matter expertise in feedback providers,
    difficulty in designing rewards for the reward model, and challenges in combining
    multiple pieces of feedback. As this is highly human-effort dependent, it is also
    a very expensive and time-consuming process.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: RLHF是一个复杂且迭代的过程，需要仔细设计和实施，才能有效地利用人类反馈进行训练。一些已知挑战包括人类反馈中的偏差、反馈提供者缺乏专业知识、为奖励模型设计奖励的困难以及结合多份反馈的挑战。由于这高度依赖于人力，它也是一个非常昂贵且耗时的过程。
- en: Prompt engineering
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示工程
- en: 'With FMs fine-tuned, they can perform a multitude of tasks such as summarization,
    question answering, and entity extraction tasks when appropriate inputs (a.k.a.
    prompts) are provided. The following are some examples of prompts for performing
    different tasks:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 当FMs经过微调后，它们可以在提供适当的输入（即提示）时执行多种任务，例如摘要、问答和实体抽取任务。以下是一些执行不同任务的提示示例：
- en: '**Question answering**: What is the capital of France?'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问答**：法国的首都是哪里？'
- en: '**Summarization**: `<text to summarize>` Summarize the proceeding text into
    one sentence.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**摘要**：`<要总结的文本>`将以下文本总结成一句话。'
- en: '**Classification**: `<text to predict>` Predict the sentiment of the proceeding
    sentence.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：`<要预测的文本>`预测下一句句子的情感。'
- en: '**Mathematics**: How much does 2 + 2 equal to?'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数学**：2 + 2等于多少？'
- en: '**Reasoning/Logical thinking**: `<text that describes a problem>` Solve this
    problem and provide a step-by-step explanation.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理/逻辑思维**：`<描述问题的文本>`解决这个问题，并提供逐步解释。'
- en: '**Text generation**: Write a blog about AI/ML.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本生成**：写一篇关于人工智能/机器学习的博客。'
- en: '**Code generation**: Write a piece of Python code to sort a list.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码生成**：编写一段Python代码来排序一个列表。'
- en: However, since different FMs are trained differently using different techniques
    and datasets, they could react to prompts differently. Poor prompts can result
    in models generating inaccurate, biased, or nonsensical text. In this section,
    we will focus our discussion on prompt engineering for LLMs.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于不同的FM使用不同的技术和数据集进行训练，它们对提示的反应可能不同。差的提示可能导致模型生成不准确、有偏见或无意义的文本。在本节中，我们将重点讨论LLMs的提示工程。
- en: 'A prompt consists of several key components that together influence how a model
    will react. There are several core components that make up a prompt, including
    action, context, input, and output indicators:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 一个提示由几个关键组件组成，这些组件共同影响模型如何反应。构成提示的几个核心组件包括动作、上下文、输入和输出指示器：
- en: '**Action**: This is the directive given to the model that details what is expected
    in terms of the task to be performed. This could range from “classify the text
    into positive or negative” to “generate a list of ideas for a vacation in Europe.”
    Depending on the model, the instruction is usually the first part or the last
    part of the prompt and sets the overall task for the model to perform.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动作**: 这是给予模型的指令，详细说明了在执行任务方面期望得到什么。这可能从“将文本分类为正面或负面”到“为欧洲度假生成一系列想法”不等。根据模型的不同，指令通常是提示的第一部分或最后一部分，并设定模型要执行的整体任务。'
- en: '**Context**: This element supplies additional information to guide the model’s
    response. For instance, in a text summarization task, you might provide some background
    on the text to be summarized (like it’s a text from an academic research paper).
    The context can help the model understand the style, tone, and specifics of the
    input data.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文**: 此元素为模型响应提供额外信息以进行指导。例如，在文本摘要任务中，你可能需要提供一些关于要摘要的文本的背景信息（比如它是一篇学术论文的文本）。上下文有助于模型理解输入数据的风格、语气和具体细节。'
- en: '**Input data:** This refers to the actual data that the model will be working
    with. In a summarization task, this would be the text to be summarized. In a question-answering
    task, this would be text from which questions are being asked.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入数据**: 这指的是模型将要处理的实际数据。在摘要任务中，这将是需要摘要的文本。在问答任务中，这将是提出问题的文本。'
- en: '**Output indicator**: This element instructs the model on which format of the
    output should be used. For instance, you might specify that you want the model’s
    response in the form of a list, a paragraph, a single sentence, or any other specific
    structure. This can help narrow down the model’s output and guide it towards more
    useful responses.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出指示器**: 此元素指导模型使用哪种格式的输出。例如，你可能指定你希望模型的响应以列表、段落、单个句子或任何其他特定结构的形式呈现。这有助于缩小模型的输出范围，并引导其向更有用的响应方向发展。'
- en: 'The following example shows a prompt with all these core components:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了包含所有这些核心组件的提示：
- en: '[PRE8]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Depending on the task and the intended result, not all components are needed
    in every prompt. For example, a basic prompt might only need action and input
    data such as:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 根据任务和预期结果，并非每个提示都需要所有组件。例如，一个基本的提示可能只需要动作和输入数据，如下所示：
- en: '[PRE9]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In addition to the prompt, many models also have support for different settings
    to help configure their output, such as the **Temperature**, `Top_p`, and `Top_k`
    parameters.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提示之外，许多模型还支持不同的设置来帮助配置它们的输出，例如**温度**、`Top_p`和`Top_k`参数。
- en: The **Temperature parameter** controls the randomness of the model’s output.
    Lower values make the model’s output more deterministic, favoring the most probable
    next token. This is useful for tasks requiring precise and factual answers, like
    a fact-based question-answer system. On the other hand, increasing the **Temperature**
    value induces more randomness in the model’s responses, allowing for more creative
    and diverse results. This is beneficial for creative tasks like poem generation.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**温度参数**控制模型输出的随机性。较低的值使模型的输出更加确定，更倾向于最可能的下一个标记。这对于需要精确和事实性答案的任务很有用，如基于事实的问题-答案系统。另一方面，增加**温度**值会在模型的响应中引入更多的随机性，允许产生更多创意和多样化的结果。这对于诗歌生成等创意任务有益。'
- en: The `Top_p` **parameter** is used in the sampling technique by the model. It
    influences the determinism of the model’s response. It tells the model to include
    only possible outputs whose combined probability does not exceed the probability
    specified by `Top_p`. A lower `Top_p` value results in more exact and factual
    answers, while a higher value increases the diversity of the responses.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型在采样技术中使用`Top_p` **参数**。它影响模型响应的确定性。它告诉模型只包括组合概率不超过`Top_p`指定的可能输出。较低的`Top_p`值会导致更精确和事实性的答案，而较高的值会增加响应的多样性。
- en: The `Top_k` **parameter** is also used to influence the determinism of the model’s
    response. It tells the model to include only possible outputs in the top k number
    determined by their probability. Similar to `Top_p`, a lower value of `Top_k`
    also results in more exact and factual answers.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Top_k` **参数**也用于影响模型响应的确定性。它告诉模型只包括由它们的概率决定的top k数量的可能输出。与`Top_p`类似，`Top_k`的较低值也会导致更精确和事实性的答案。'
- en: In addition to performing tasks that an LLM has been trained or tuned for, instruction
    fine-tuned LLMs can also perform new tasks without explicitly being trained on
    or learn to perform new tasks by dynamically providing them with examples. In
    the following sections, we will discuss zero-shot prompting/learning and few-shot
    prompting/learning.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 除了执行LLM被训练或调整过的任务外，指令微调的LLM还可以执行新的任务，而无需明确地针对这些任务进行训练，或者通过动态提供示例来学习执行新任务。在接下来的章节中，我们将讨论零样本提示/学习和少样本提示/学习。
- en: Zero-shot prompting/learning
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 零样本提示/学习
- en: The ability for instruction fine-tuned LLMs to perform new tasks without explicitly
    being trained is referred to as zero-shot learning/prompting. LLMs can display
    this capability because it has already acquired extensive knowledge and learned
    how to perform a multitude of tasks from specific fine-tuning. This is a very
    important capability of LLMs because it is not always feasible to train LLMs on
    all different kinds of tasks. An LLM’s ability to perform zero-shot learning is
    often a strong indicator of the LLM’s overall capability. To use zero-shot, you
    simply provide a prompt to an LLM to perform a new task that it has not been trained
    on. However, due to a lack of prior training in specific tasks, the performance
    of zero-shot prompting/learning might be limited.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 指令微调的LLM能够执行新任务而无需明确训练的能力被称为零样本学习/提示。LLM可以展示这种能力，因为它已经获得了广泛的知识，并学会了如何从特定的微调中执行多种任务。这是LLM的一个重要能力，因为并不是所有不同类型的任务都可以对LLM进行训练。LLM执行零样本学习的能力通常是LLM整体能力的强烈指标。要使用零样本，你只需向LLM提供一个提示来执行它尚未训练过的新任务。然而，由于在特定任务上缺乏先前的训练，零样本提示/学习的性能可能有限。
- en: Few-shot prompting/learning
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 少样本提示/学习
- en: 'Another capability of many LLMs is the ability to learn from examples that
    are directly provided in the prompts. For example, in addition to telling the
    model to perform an action, you can include a few examples of how it should be
    done in the context section, and LLMs would be able to learn from these examples
    and learn to perform the action on the actual input data. This is formally known
    as few-shot prompt/learning. It is also referred to as in-context learning. The
    following is an example of teaching an LLM to perform sentiment analysis by providing
    some examples:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 许多LLM的另一个能力是从提示中直接提供的示例中学习。例如，除了告诉模型执行一个动作外，你还可以在上下文部分包含一些如何执行的动作示例，LLM将能够从这些示例中学习并学会在实际输入数据上执行该动作。这正式称为少样本提示/学习。它也被称为上下文学习。以下是一个通过提供一些示例来教授LLM执行情感分析的例子：
- en: '[PRE10]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Few-shot learning, a key feature of LLMs, enables them to perform new tasks
    without extensive fine-tuning. However, it does have limitations, including reduced
    performance due to a small number of examples provided in each prompt, challenges
    in handling complex tasks accurately, high compute cost (examples are needed in
    every call), and potential struggles in highly specialized domains.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习是LLM的关键特性，它使它们能够在不进行大量微调的情况下执行新任务。然而，它确实有一些限制，包括由于每个提示中提供的示例数量较少而导致的性能降低、准确处理复杂任务的挑战、高计算成本（每个调用都需要示例）以及在高度专业化的领域可能遇到的困难。
- en: Prompt engineering best practices
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示工程最佳实践
- en: Prompt engineering is the process of crafting the prompts using different structures,
    phrases, contexts, and modifiers to achieve the best possible output from the
    models. It is a science as much as it is an art. Knowing the specific capability
    of a model and the data used for training and tuning is often very important when
    it comes to designing the prompts for the different models. Next, let’s take a
    look at some of the general best practices as well as LLM-specific techniques
    for designing effective prompts.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是使用不同的结构、短语、上下文和修饰符来构建提示的过程，以从模型中获得最佳输出。它既是科学也是艺术。了解模型的特定能力和用于训练和调整的数据通常在设计不同模型的提示时非常重要。接下来，让我们看看一些设计有效提示的一般最佳实践以及
    LLM 特定的技术。
- en: '**Be very specific with the instruction**: LLM models are very capable, but
    they are also imperfect and can misinterpret the prompt if it is vague. Always
    be very specific about the length (e.g., number of words, sentences) and format
    of the output (e.g., list, table, paragraph) and the actions (e.g., summarize,
    classify, analyze) to be performed. Incorporate specific keywords relevant to
    the task domain.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对指令非常具体**：LLM 模型非常强大，但它们也不完美，如果提示不明确，它们可能会误解。始终要非常具体地说明输出的长度（例如，单词数、句子数）和格式（例如，列表、表格、段落）以及要执行的操作（例如，总结、分类、分析）。结合与任务领域相关的特定关键词。'
- en: '**Utilize context**: Incorporate contextual details within your prompts to
    enable the model to comprehensively grasp your inquiries. Contextual prompts can
    encompass factors like emulating a persona or providing background insights on
    the input data. By establishing a specific tone (e.g., formal, conversational,
    etc.) and perspective for the AI model, you’re essentially providing it with a
    framework that outlines the desired tone, style, and specialized expertise. This
    practice can elevate the relevance and efficacy of the generated output. If the
    context has all the information, you can explicitly instruct the model to use
    the knowledge from the context in response generation.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用上下文**：在你的提示中结合上下文细节，使模型能够全面理解你的查询。上下文提示可以包括模仿一个角色或提供关于输入数据的背景见解等因素。通过为
    AI 模型建立特定的语气（例如，正式的、对话的等）和视角，你实际上是在为其提供一个框架，概述了所需的语气、风格和专业知识。这种做法可以提高生成输出的相关性和有效性。如果上下文包含了所有信息，你可以明确指示模型在响应生成中使用上下文中的知识。'
- en: '**Provide examples**: When formulating prompts for AI models, incorporating
    examples proves very helpful. This is because prompts serve as directives for
    the model, and examples help the model understand your requirements. The following
    is an instance of providing examples for sentiment analysis:'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提供示例**：在为 AI 模型制定提示时，加入示例非常有帮助。这是因为提示作为模型的指令，而示例有助于模型理解你的要求。以下是一个为情感分析提供示例的例子：'
- en: '[PRE11]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Experiment with prompts to learn model behaviors**: Different models have
    different capabilities and may interpret prompts differently. A well-crafted prompt
    might work well for one model, but it may not transfer well with other models.
    Try out model behaviors with different action words, sentence structures, and
    modifiers to discover how a particular model would behave. This is the art aspect
    of prompt engineering.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过提示实验来学习模型行为**：不同的模型有不同的能力，可能对提示有不同的解释。精心设计的提示可能对一个模型效果很好，但对其他模型可能不适用。尝试使用不同的动作词、句子结构和修饰符来测试模型的行为，以发现特定模型会如何表现。这是提示工程的艺术方面。'
- en: '**Ask the models to explain steps**: Some models can produce individual steps
    when providing responses to a prompt. This is also known as **chain-of-thought**
    (**CoT**) prompting. Breaking down a problem into individual steps can help improve
    the correctness of the responses. This is especially useful for reasoning and
    mathematical tasks.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**要求模型解释步骤**：一些模型在提供对提示的响应时可以生成单个步骤。这也被称为**思维链**（**CoT**）提示。将问题分解成单个步骤可以帮助提高响应的正确性。这对于推理和数学任务特别有用。'
- en: '**Split a complex task into a collection of smaller tasks**: If a task request
    is overly complex (i.e., having multiple tasks), a FM might not handle it effectively.
    Consider creating a number of simpler tasks and completing them separately.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将复杂任务分解成一系列小任务**：如果一个任务请求过于复杂（即包含多个任务），一个 FM 可能无法有效地处理它。考虑创建多个更简单的任务并分别完成它们。'
- en: '**Ask the model to use known knowledge**: Instruct the model not to return
    anything if it does not know the answer. This helps with issues such as hallucination.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**要求模型使用已知知识**：指导模型在不知道答案时不返回任何内容。这有助于解决诸如幻觉等问题。'
- en: '**Instruct the model for clarification**: Sometimes, the model might not truly
    understand the instruction in the prompt and return an incorrect response. Instruct
    the model to respond with clarifying questions if it does not understand the instruction.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指导模型进行澄清**：有时，模型可能并不真正理解提示中的指令，并返回错误的响应。如果模型不理解指令，指导模型以澄清问题进行响应。'
- en: '**Use variation to test consistency**: Use different rephrases of a prompt
    to check model output consistency. Inconsistent outputs across different prompt
    variations indicate an error or factual inaccuracy.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用变化来测试一致性**：使用提示的不同表述来检查模型输出的连贯性。不同提示变体之间的不一致输出表明存在错误或事实不准确。'
- en: '**Start simple**: Start with simple prompts to evaluate the responses before
    adding more elements or contexts.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从简单开始**：从简单的提示开始，评估响应，然后再添加更多元素或上下文。'
- en: '**Build an inventory of templates**: Create an inventory of curated prompt
    templates that have proven to be useful and effective for the rest of the organization
    to share and reuse.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**建立模板清单**：创建一个经过精选的提示模板清单，这些模板已被证明对组织中的其他成员有用且有效，以便共享和重复使用。'
- en: In addition to these common best practices, there are also model-specific best
    practices which are usually provided by different model providers. For example,
    you can learn more about prompt engineering guidance for Anthropic at [https://docs.anthropic.com/claude/docs/guide-to-anthropics-prompt-engineering-resources](https://docs.anthropic.com/claude/docs/guide-to-anthropics-prompt-engineering-resources).
    OpenAI also provides its prompt engineering guide at [https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些常见的最佳实践之外，还有针对特定模型的最佳实践，这些通常由不同的模型提供商提供。例如，您可以在[https://docs.anthropic.com/claude/docs/guide-to-anthropics-prompt-engineering-resources](https://docs.anthropic.com/claude/docs/guide-to-anthropics-prompt-engineering-resources)上了解更多关于Anthropic提示工程指南的信息。OpenAI也提供了其提示工程指南，请参阅[https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)。
- en: So, in essence, prompt engineering is an empirical, iterative process of crafting
    instructions tuned to each model and application. The human plays a key role in
    actively honing prompts. In addition, a number of commercial and free tools have
    been developed for automated prompt optimization.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本质上，提示工程是一个针对每个模型和应用进行调优的经验性、迭代过程。人类在积极优化提示方面发挥着关键作用。此外，还开发了许多商业和免费工具，用于自动提示优化。
- en: Adversarial prompting
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对抗性提示
- en: As with many ML technologies, generative AI and its prompting approaches have
    potential vulnerabilities from adversarial attacks. Bad actors can intentionally
    manipulate prompts to exploit vulnerabilities or biases in language models, resulting
    in unintended or harmful outputs. This is also known as adversarial prompting.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多机器学习技术一样，生成式AI及其提示方法可能存在来自对抗性攻击的潜在漏洞。恶意行为者可能会故意操纵提示以利用语言模型中的漏洞或偏见，从而导致意外的或有害的输出。这也被称为对抗性提示。
- en: 'The following are a few known examples of adversarial prompting techniques
    that can exploit vulnerabilities:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些已知可以利用漏洞的对抗性提示技术示例：
- en: '**Prompt injection** is a technique used in adversarial prompting where additional
    instructions or content are inserted into the prompt to influence the model’s
    behavior. By injecting specific keywords, phrases, or instructions, the model’s
    output can be manipulated to produce desired or undesired outcomes. Prompt injection
    can be used to introduce biases, generate offensive or harmful content, or manipulate
    the model’s understanding of the task. The following is an example of prompt injection:'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示注入**是对抗性提示中的一种技术，其中将额外的指令或内容插入到提示中，以影响模型的行为。通过注入特定的关键词、短语或指令，可以操纵模型的输出以产生期望的或非期望的结果。提示注入可用于引入偏见、生成冒犯性或有害内容，或操纵模型对任务的了解。以下是一个提示注入的示例：'
- en: '[PRE12]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Prompt leaking** occurs when sensitive or confidential information unintentionally
    gets exposed in the model’s response. This can happen when the model incorporates
    parts of the prompt, including personally identifiable information, into its generated
    output. Prompt leaking poses privacy and security risks, as it may disclose sensitive
    data to unintended recipients or expose vulnerabilities in the model’s handling
    of input prompts. The following is an example of prompt leaking:'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示泄露**发生在敏感或机密信息无意中在模型的响应中暴露。这可能会发生当模型将提示的部分，包括个人身份信息，纳入其生成的输出中时。提示泄露可能导致隐私和安全风险，因为它可能向意外收件人披露敏感数据或暴露模型处理输入提示的漏洞。以下是一个提示泄露的示例：'
- en: '[PRE13]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Jailbreaking**, in the context of prompt engineering, refers to bypassing
    or overriding safety mechanisms put in place to restrict or regulate the behavior
    of language models. It involves manipulating the prompt in a way that allows the
    model to generate outputs that may be inappropriate, unethical, or against the
    intended guidelines. Jailbreaking can lead to the generation of offensive content,
    misinformation, or other undesirable outcomes. The following is an example jailbreaking
    prompt:'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**越狱**，在提示工程的背景下，指的是绕过或覆盖为限制或规范语言模型行为而设置的安全机制。这涉及到以允许模型生成可能不适当、不道德或违反预期指南的输出的方式操纵提示。越狱可能导致生成冒犯性内容、错误信息或其他不良后果。以下是一个越狱提示的示例：'
- en: '[PRE14]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Overall, adversarial prompting techniques like prompt injection, prompt leaking,
    and jailbreaking highlight the importance of responsible and ethical prompt engineering
    practices. It is essential to be aware of the potential risks and vulnerabilities
    associated with language models and to take precautions to mitigate these risks
    such as adversarial prompt detectors while ensuring the safe and responsible use
    of these powerful AI systems.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，像提示注入、提示泄露和越狱等对抗性提示技术突出了负责任和道德的提示工程实践的重要性。了解与语言模型相关的潜在风险和漏洞至关重要，并采取预防措施来减轻这些风险，例如使用对抗性提示检测器，同时确保这些强大AI系统的安全、负责任的使用。
- en: Model management and deployment
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型管理和部署
- en: 'With the generative AI model trained, tuned, tested, and the potential risks
    mitigated or accepted, the next step is to place it under proper model management
    and deploy the model for application and user consumption. The management for
    generative AI models is largely similar to that of traditional ML models, with
    some new process and management considerations:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成AI模型经过训练、调整、测试，并减轻或接受潜在风险之后，下一步是将模型置于适当的模型管理之下，并将模型部署以供应用和用户使用。生成AI模型的管理在很大程度上类似于传统ML模型，有一些新的流程和管理考虑因素：
- en: '**Process for capturing additional data**: FMs are designed for downstream
    tasks as well as direct consumption. Consequently, it is imperative to capture
    additional information, such as a dataset for pre-trained, data for fine-tuning,
    a dataset for testing, and the associated model performance metrics (both automated
    and human evaluation) across various tasks. Other information such as intended
    usage and limitations of these FMs need to be captured and documented. This will
    help with the model selection process for the different downstream tasks.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**捕获额外数据的流程**：FM旨在用于下游任务以及直接消费。因此，捕获额外信息至关重要，例如用于预训练的数据集、用于微调的数据、用于测试的数据集以及跨各种任务的关联模型性能指标（包括自动和人工评估）。其他信息，如FM的预期用途和限制，也需要被捕获和记录。这将有助于不同下游任务的模型选择过程。'
- en: '**Process for usage review and approval**: The usage of powerful FMs should
    be governed for proper use to avoid unintended risks. An enhanced or new FM model
    review and approval process should be established.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用审查和批准流程**：为了防止意外风险，应规范使用强大的FM。应建立增强或新的FM模型审查和批准流程。'
- en: '**New technology capability**: New or enhanced technology capabilities such
    as model registry need to be implemented to support the technical management of
    FMs and human processes and workflows. For example, FMs and their respective PEFT-tuned
    adapters need to be properly stored and tracked, and, if needed, a technical capability
    to combine an FM and an adapter can be implemented to support FM distribution.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新技术能力**：需要实施新技术能力，如模型注册，以支持FM的技术管理和人类流程。例如，FM及其相应的PEFT调整适配器需要得到适当的存储和跟踪，如果需要，可以实施将FM和适配器结合的技术能力，以支持FM的分发。'
- en: Due to the requirements for accelerated computation and large GPU memory, hosting
    generative AI models presents unique challenges across several dimensions.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 由于对加速计算和大量GPU内存的需求，托管生成式AI模型在多个维度上面临着独特的挑战。
- en: Given the large size of many of the generative models (hundreds of GBs in size),
    they require expensive hardware with a large amount of memory and compute resources.
    Hence, it could get very expensive to run these models. Also, many of these models
    cannot fit into a single GPU or single node, so they will need to be split up
    across multiple GPU devices. In addition, large models are also slower with inferences
    in general.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多生成模型（大小为数百GB）的庞大体积，它们需要配备大量内存和计算资源的昂贵硬件。因此，运行这些模型可能会非常昂贵。此外，许多这些模型无法适应单个GPU或单个节点，因此需要将它们分割到多个GPU设备上。此外，大型模型在一般推理中通常也较慢。
- en: To help address these challenges, several engineering approaches have been developed
    to support the deployment of these large models.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助解决这些挑战，已经开发了几种工程方法来支持这些大型模型的部署。
- en: As we discussed in *Chapter 10*, *Advanced ML Engineering*, model size can be
    reduced through techniques such as pruning (selectively removing non-critical
    structures in a model), model weights quantization (e.g., reducing the precision
    from 32-bit to 16-bit), distillation (training a smaller model to mimic the behaviors
    of a large model), and model optimization. The goal of this approach is to fit
    the model into a single GPU or a smaller number of GPUs with a reduced size. While
    all these approaches can be used, the post-training quantization method is the
    most popular one due to its broad support in various ML frameworks and libraries.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在第10章“高级机器学习工程”中讨论的那样，可以通过剪枝（选择性地从模型中移除非关键结构）、模型权重量化（例如，将精度从32位降低到16位）、蒸馏（训练一个较小的模型来模仿大型模型的行为）和模型优化等技术来减小模型大小。这种方法的目的是将模型的大小减小到单个GPU或更少的GPU上。虽然所有这些方法都可以使用，但由于其在各种机器学习框架和库中的广泛支持，后训练量化方法是其中最受欢迎的一种。
- en: If the model with a reduced size still does not fit into a single GPU memory,
    then another deployment approach is to split the model across multiple GPU devices
    in a single node. This is also referred to as tensor parallelism. SageMaker **large
    model inference** (**LMI**) **deep learning containers** (**DLCs**) can help with
    hosting LLMs across multiple devices. LMI DLCs are a complete end-to-end solution
    for hosting LLMs. At the frontend, they include a high-performance model server
    (DJL Serving) designed for large model inference with features such as token streaming
    and automatic model replication within an instance to increase throughput. On
    the backend, LMI DLCs also include several high-performance model parallel engines,
    such as DeepSpeed and FasterTransformer, which can shard and manage model parameters
    across multiple GPUs.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 如果减小尺寸后的模型仍然无法适应单个GPU内存，那么另一种部署方法是在单个节点中将模型分割到多个GPU设备上。这也被称为张量并行。SageMaker的**大型模型推理**（**LMI**）**深度学习容器**（**DLCs**）可以帮助在多个设备上托管LLM。LMI
    DLCs是托管LLM的完整端到端解决方案。在前端，它们包括专为大型模型推理设计的高性能模型服务器（DJL Serving），具有令牌流和实例内自动模型复制等特性，以提高吞吐量。在后端，LMI
    DLCs还包括几个高性能模型并行引擎，如DeepSpeed和FasterTransformer，它们可以在多个GPU之间分割和管理模型参数。
- en: These engines also include optimized kernels for popular transformer models,
    which can accelerate inference by up to three times faster. Another popular technology
    for hosting large models is the **Text Generation Interference** (**TGI**) from
    Hugging Face.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这些引擎还包括针对流行变压器模型的优化内核，可以加速推理速度，最高可达三倍。用于托管大型模型的另一种流行技术是来自Hugging Face的**文本生成干扰**（**TGI**）。
- en: With the ability to fine-tune large FMs using techniques such as PEFT, it is
    now also possible to dynamically attach different fine-tuned adapters to common
    pre-trained FMs to reduce hosting costs.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 利用PEFT（参数高效微调）等技术对大型FM进行微调的能力，现在还可以动态地将不同的微调适配器附加到常见的预训练FM上，以降低托管成本。
- en: The limitations, risks, and challenges of adopting generative AI
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 采用生成式AI的局限性、风险和挑战
- en: As powerful as generative AI technology is, it comes with its own set of limitations
    and challenges across multiple dimensions. In this section, we will delve into
    some of these concerns.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生成式AI技术非常强大，但它也带来了一系列的限制和挑战，涉及多个维度。在本节中，我们将深入探讨一些这些担忧。
- en: As most generative AI technologies such as LLMs generate responses based on
    conditioned probabilities, the outputs can be factually inaccurate or self-contradictory.
    They can even generate factually inaccurate responses with fluency and convincing
    tones, leading to difficulty in detecting misinformation by humans. This can create
    a multitude of problems, including erroneous decision making and negative social
    influence from misinformation. Moreover, it’s challenging to determine the source
    documents for the responses generated by generative AI models, which leads to
    difficulties in verifying facts and providing proper attribution.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数生成式AI技术（如LLMs）基于条件概率生成响应，因此输出可能存在事实上的不准确或自相矛盾。它们甚至可以以流畅和令人信服的语调生成事实上的不准确响应，导致人类难以检测到虚假信息。这可能导致众多问题，包括错误的决策和由虚假信息引起的负面社会影响。此外，确定由生成式AI模型生成的响应的源文档是一项挑战，这导致在核实事实和提供适当归属时遇到困难。
- en: Despite their impressive performance on standardized tests like BAR or SAT,
    LLMs have limitations in certain aspects of cognitive abilities. One notable limitation
    is their inability to engage in complex reasoning and long-range strategic planning.
    While they excel at processing and generating text based on patterns and existing
    knowledge, they struggle with tasks that require a deep understanding of context
    and the ability to make nuanced decisions. These models also lack the fundamental
    understanding of common-sense knowledge that humans take for granted. As a result,
    these models may perform well in structured assessments but fall short when faced
    with real-world scenarios that demand higher-order thinking and contextual reasoning.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLMs在标准化测试（如BAR或SAT）中表现出色，但在某些认知能力方面仍存在局限性。一个显著的局限性是它们无法进行复杂的推理和长期战略规划。虽然它们擅长根据模式和现有知识处理和生成文本，但在需要深入理解上下文和做出细微决策的任务上，它们会遇到困难。这些模型也缺乏人类视为理所当然的常识性知识。因此，这些模型可能在结构化评估中表现良好，但在面对需要高级思维和情境推理的现实世界场景时可能会不足。
- en: Generative AI technologies have also raised many ethical and social concerns
    such as copyrights and displacement of jobs. Ownership and copyright of synthetic
    media generated are legally ambiguous. Since generative AI models are pre-trained
    with vast amounts of data, including potentially copyrighted data from the internet,
    the content generated by generative models can potentially raise copyright concerns.
    It is also challenging to attribute the generated text to the original training
    data. Just like traditional AI/ML technology, generative AI has the potential
    to displace many known jobs such as content creators and document analysts. Moreover,
    generative AI can contain personal data and can potentially output that data,
    leading to privacy leaks.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI技术也引发了许多伦理和社会问题，如版权和就业岗位的替代。合成媒体的所有权和版权在法律上是不明确的。由于生成式AI模型是在包含大量数据的基础上进行预训练的，包括可能来自互联网的潜在版权数据，因此由生成模型生成的内容可能会引发版权问题。将生成的文本归因于原始训练数据也很困难。就像传统的AI/ML技术一样，生成式AI有可能取代许多已知的工作，如内容创作者和文档分析师。此外，生成式AI可能包含个人数据，并可能输出这些数据，导致隐私泄露。
- en: Typically, training, fine-tuning, and performing inferences with large generative
    AI models can be costly due to their substantial computational resource requirements.
    However, there have been advancements in developing techniques to enhance their
    efficiency. As generative AI is so new and evolving quickly, both public and private
    policies and governance are lagging behind to effectively and appropriately guide
    the development and deployment of generative AI technology and solutions. In addition,
    generative AI technologies do not provide good ways to deal with interpretability.
    It is very difficult, if not impossible, to know how generative AI comes to certain
    responses and decisions. This limits what kind of use cases generative AI can
    be applied to.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，由于大型生成式AI模型对计算资源的大量需求，训练、微调和进行推理可能会非常昂贵。然而，在提高其效率的技术方面已经取得了一些进展。由于生成式AI如此新颖且发展迅速，无论是公共还是私人政策和管理都落后于有效地和适当地引导生成式AI技术和解决方案的发展与部署。此外，生成式AI技术没有提供很好的方法来处理可解释性。了解生成式AI如何得出某些响应和决策是非常困难的，甚至可能是不可能的。这限制了生成式AI可以应用的使用案例。
- en: Many of the limits and challenges are yet to have practical solutions. So, it
    is essential to assess and understand the risks before deploying generative AI
    solutions for the intended use cases. Consider mitigating measures, such as the
    human-in-the-loop method, for decision making and grounding of generative AI with
    curated data sources to reduce hallucination.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 许多限制和挑战尚未有实际解决方案。因此，在部署用于预期用例的生成式AI解决方案之前，评估和理解风险至关重要。考虑缓解措施，例如在决策和生成式AI的基于精选数据源的基础上加入人工方法，以减少幻觉。
- en: Summary
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we provided a comprehensive overview of the generative AI project
    lifecycle, from identifying business use cases to model deployment. We explored
    major generative technologies like FMs and key techniques for customization including
    domain adaptation, instruction tuning, reinforcement learning with human feedback,
    and prompt engineering.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们提供了生成式AI项目生命周期的全面概述，从识别业务用例到模型部署。我们探讨了主要生成技术，如FM以及包括领域适应、指令调整、带人类反馈的强化学习和提示工程在内的定制关键技术。
- en: The chapter also covered specialized engineering considerations around large
    model hosting and mitigating risks like factual inaccuracies. While limitations
    exist, responsible development and governance can allow enterprises across industries
    to harness generative AI’s immense potential for creating business value. With
    an understanding of the end-to-end lifecycle, practitioners can thoughtfully architect
    and deliver innovative yet practical generative AI solutions.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还涵盖了围绕大型模型托管和减轻如事实不准确等风险的专门工程考虑。虽然存在局限性，但负责任的发展和治理可以使各行业的公司利用生成式AI在创造商业价值方面的巨大潜力。通过理解端到端的生命周期，从业者可以深思熟虑地设计和交付创新且实用的生成式AI解决方案。
- en: In the next chapter, we will talk about the key considerations for building
    a generative AI platform, **retrieval-augmented generation** (**RAG**) solutions,
    and practical generative AI applications.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论构建生成式AI平台的关键考虑因素，**检索增强生成**（**RAG**）解决方案，以及实际的生成式AI应用。
- en: Join our community on Discord
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的社区Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/mlsah](https://packt.link/mlsah )'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/mlsah](https://packt.link/mlsah)'
- en: '![](img/QR_Code70205728346636561.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code70205728346636561.png)'
