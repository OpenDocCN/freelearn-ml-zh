- en: Optimizing the Model through Hyperparameter Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Neural networks constitute multiple parameters that can affect the ultimate
    accuracy in predicting an event or a label. The typical parameters include:'
  prefs: []
  type: TYPE_NORMAL
- en: Batch size used for training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of epochs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of hidden layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of hidden units in each hidden layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The activation function applied in the hidden layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The optimizer used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From the preceding list, we can see that the number of parameters that can be
    tweaked is very high. This makes finding the optimal combination of hyperparameters
    a challenge. Hyperparameter tuning as a service provided by Cloud ML Engine comes
    in handy in such a scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will go through:'
  prefs: []
  type: TYPE_NORMAL
- en: Why hyperparameter tuning is required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of how hyperparameter tuning works
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing hyperparameter tuning in the cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The intuition of hyperparameter tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to gain a practical intuition of the need for hyperparameter tuning,
    let''s go through the following scenario in predicting the accuracy of a given
    neural network architecture on the MNIST dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scenario 1**: High number of epochs and low learning rate'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scenario 2**: Low number of epochs and high learning rate'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let us create the train and test datasets in a Google Cloud environment, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code creates a new folder named `data`, downloads the MNIST dataset,
    and moves it into the `data` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open Python in Terminal and import the required packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Import the MNIST dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Extract the train and test datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the estimator functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Specify the type of column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Build a DNN classifier using the parameters in scenario 1; that is, the learning
    rate is `0.1` and the number of steps is `200`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The test accuracy in such a scenario comes out to be 96.49%.
  prefs: []
  type: TYPE_NORMAL
- en: 'In scenario 2, we will build another DNN classifier using different parameters;
    now the learning rate is `0.01` and the number of steps is `2000`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The accuracy on the test dataset in scenario 2 is nearly 98.2%.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding two scenarios show us the importance of how various values of
    different hyperparameters affect the final result.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud ML engine comes in handy in such scenarios, where we can be more
    intelligent in selecting the more optimal set of hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of hyperparameter tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hyperparameter tuning works by running multiple trials in a single training
    job. Each trial is a complete execution of your training application, with values
    for your chosen hyperparameters set within the limits you specify. The Cloud ML
    Engine training service keeps track of the results of each trial and makes adjustments
    for subsequent trials. When the job is finished, you can get a summary of all
    the trials, along with the most effective configuration of values according to
    the criteria you specify.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to select those hyperparameters that give the best performance. This
    amounts to an optimization problem, specifically, the problem of optimizing a
    function *f(x)* (that is, performance as a function of hyperparameter values)
    over a compact set *A.* We can write this mathematically as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1b2c95c0-1900-4be2-942a-1c35f559a5be.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's take the example of the function *(1-x)^(ex)*, which has a maximum value
    *f(x) = 1* at *x = 0*, and so *arg max* is *0*.
  prefs: []
  type: TYPE_NORMAL
- en: Many optimization settings, like this one, assume that the objective function
    *f(x)* has a known mathematical form, is convex, or is easy to evaluate. But these
    characteristics do not apply to the problem of finding hyperparameters where the
    function is unknown and expensive to evaluate. This is where Bayesian optimization
    comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: In order to implement hyperparameter tuning, Google uses an algorithm called
    **Gaussian process bandits**, which is a form of Bayesian optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian optimization is an extremely powerful technique when the mathematical
    form of the function is unknown or expensive to compute. The main idea behind
    it is to compute a posterior distribution over the objective function based on
    the data (using the famous Bayes, theorem), and then select good points to try
    with respect to this distribution.
  prefs: []
  type: TYPE_NORMAL
- en: To use Bayesian optimization, we need a way to flexibly model distributions
    over objective functions. This is a bit trickier than modeling a distribution
    over, say, real numbers, since we'll need one such distribution to represent our
    beliefs about *f(x)* for each *x*. If *x* contains continuous hyperparameters,
    there will be infinitely many *x* for which we must model *f(x)*, that is, construct
    a distribution for it. For this problem, Gaussian processes are a particularly
    elegant technique. In effect, they generalize multidimensional Gaussian distributions,
    and versions that are flexible enough to model any objective function do exist.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding process typically works as described in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/920da612-d83c-42ae-9ae5-3f4a61a250e1.png)'
  prefs: []
  type: TYPE_IMG
- en: We update the Gaussian model with the results of an iteration, which further
    helps in identifying the right next sample set of hyperparameters to be tested
    for the model; the result further improves our Gaussian model to identify the
    right set of hyperparameters to be picked.
  prefs: []
  type: TYPE_NORMAL
- en: Details of Gaussian distributions are out of the scope of this book, but for
    this exercise, we will take Google's approach as it is (as a black box) and implement
    hyperparameter tuning using Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning in Google Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order for the just-laid-out Gaussian process to run, we have to allow our
    model builds to be run on Google Cloud so that hyperparameter tuning can be carried
    out.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to run hyperparameter tuning, the following are essential components:'
  prefs: []
  type: TYPE_NORMAL
- en: Data file and its location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyperparameter configuration file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setup file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__init__` file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given that we are running the model on Google Cloud ML engine, the data should
    be residing in a Cloud bucket so that it becomes accessible to ML engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be done by performing the following in the Cloud shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that, using the preceding steps, we have created a bucket named `my-mnist-bucket`
    and copied our data to that bucket. The preceding code should result in creating
    a directory named `data` and the `mnist.pkl` file in that directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/59110e1b-da58-43b9-87c7-27a8b80cb10c.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The model file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The model file should be located in a folder that also contains the `__init__.py`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us create a folder named `trainer` that contains both the model file and
    the `__init__` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code creates the `trainer` folder and changes directory to the
    newly-created folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us go ahead and create the model file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Insert the following code into the previously-created file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Configuration file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the model file is set up, we need to provide the configuration file in
    the same trainer folder so that ML engine knows the parameters that need to be
    tuned, as well as the typical min and max values of the parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create the configuration file as follows in the `trainer` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code is inserted into the preceding file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding block of code, we have specified the Python version to be run
    on and have also specified whether it is to be run on a CPU or a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: In the `hyperparameters` section, we have specified that the metric we need
    to optimize is accuracy (note that the output of `model.evaluate` is `accuracy`,
    `loss`, `average loss`, and `global step`); the goal is to maximize it.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we have specified the maximum number of trials to be run and the maximum
    number of parallel trials that can be run (changes when the Cloud configuration
    has multiple cores associated with it).
  prefs: []
  type: TYPE_NORMAL
- en: The `params` section contains the parameters that need to be modified, the type
    of variable it is, and the minimum and maximum values.
  prefs: []
  type: TYPE_NORMAL
- en: '`ScaleType` indicates the type of scaling that would be applied to the parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Value** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `UNIT_LINEAR_SCALE` | Scales the feasible space to (0, 1) linearly. |'
  prefs: []
  type: TYPE_TB
- en: '| `UNIT_LOG_SCALE` | Scales the feasible space logarithmically to (0, 1). The
    entire feasible space must be strictly positive. |'
  prefs: []
  type: TYPE_TB
- en: '| `UNIT_REVERSE_LOG_SCALE` | Scales the feasible space reverse logarithmically
    to (0, 1). The result is that values close to the top of the feasible space are
    spread out more than points near the bottom. The entire feasible space must be
    strictly positive. |'
  prefs: []
  type: TYPE_TB
- en: Setup file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In some instances, we might have to install packages that do not come prebuilt.
    The `setup.py` file comes in handy in such scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, one could include the additional packages that are needed
    to run the model file.
  prefs: []
  type: TYPE_NORMAL
- en: The __init__ file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For Cloud ML engine to create a package for the module we are building, it needs
    to create a package for the module. For the package to be created, it needs to
    create the `__init__.py` file in the `trainer` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'For that, we would run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the whole setup is ready, we run the job as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note that we specify the bucket name in which data exists, and the job name
    and directory in which the logs need to be stored. The region needs to be set
    and the configuration file is specified.
  prefs: []
  type: TYPE_NORMAL
- en: Also, set the `--module-name` argument to the name of your application's main
    module using your package's namespace dot notation.
  prefs: []
  type: TYPE_NORMAL
- en: Note that, after specifying region, we have a blank, indicating that it is the
    start of arguments now (they are the training file location, number of steps,
    and learning rate).
  prefs: []
  type: TYPE_NORMAL
- en: The number of steps and learning rate that we have specified in the preceding
    code are the default versions, which are changed once passed to the ML engine
    job.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of the code can be visualized in the training output of the job
    that we ran, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a8a1fc4e-70ba-476f-9e52-f1eba7f6b915.png)'
  prefs: []
  type: TYPE_IMG
- en: The optimal hyperparameters can then be selected from the preceding output.
    We can see that a learning rate of **0.0149** and number of steps as **7658**
    result in a higher test dataset accuracy than the two scenarios that we tested
    earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we understood how different parameter combinations affect the
    final accuracy measure and how hyperparameter tuning using Cloud ML engine helps
    in improving the accuracy further.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to identify overfitting and make our
    models more robust to previously-unseen data by setting the right parameters and
    defining the proper architectures.
  prefs: []
  type: TYPE_NORMAL
