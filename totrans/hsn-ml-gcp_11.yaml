- en: Optimizing the Model through Hyperparameter Tuning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过超参数调整优化模型
- en: 'Neural networks constitute multiple parameters that can affect the ultimate
    accuracy in predicting an event or a label. The typical parameters include:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络包含多个参数，这些参数可以影响预测事件或标签的最终准确度。典型的参数包括：
- en: Batch size used for training
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练时使用的批量大小
- en: Number of epochs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周期数量
- en: Learning rate
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习率
- en: Number of hidden layers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏层数量
- en: Number of hidden units in each hidden layer
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个隐藏层中的隐藏单元数量
- en: The activation function applied in the hidden layer
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏层中应用的激活函数
- en: The optimizer used
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用的优化器
- en: From the preceding list, we can see that the number of parameters that can be
    tweaked is very high. This makes finding the optimal combination of hyperparameters
    a challenge. Hyperparameter tuning as a service provided by Cloud ML Engine comes
    in handy in such a scenario.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的列表中，我们可以看到可以调整的参数数量非常高。这使得找到最佳的超参数组合具有挑战性。在这种情况下，Cloud ML Engine 提供的超参数调整服务非常有用。
- en: 'In this chapter, we will go through:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍：
- en: Why hyperparameter tuning is required
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么需要超参数调整
- en: An overview of how hyperparameter tuning works
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数调整工作概述
- en: Implementing hyperparameter tuning in the cloud
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云端实现超参数调整
- en: The intuition of hyperparameter tuning
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数调整的直觉
- en: 'In order to gain a practical intuition of the need for hyperparameter tuning,
    let''s go through the following scenario in predicting the accuracy of a given
    neural network architecture on the MNIST dataset:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得超参数调整的实用直觉，让我们通过以下场景来预测给定神经网络架构在 MNIST 数据集上的准确率：
- en: '**Scenario 1**: High number of epochs and low learning rate'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**场景 1**：大量周期和低学习率'
- en: '**Scenario 2**: Low number of epochs and high learning rate'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**场景 2**：少量周期和高的学习率'
- en: 'Let us create the train and test datasets in a Google Cloud environment, as
    follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 Google Cloud 环境中创建训练集和测试集，如下所示：
- en: 'Download the dataset:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载数据集：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding code creates a new folder named `data`, downloads the MNIST dataset,
    and moves it into the `data` folder.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码创建了一个名为 `data` 的新文件夹，下载了 MNIST 数据集，并将其移动到 `data` 文件夹中。
- en: 'Open Python in Terminal and import the required packages:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中打开 Python 并导入所需的包：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Import the MNIST dataset:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 MNIST 数据集：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Extract the train and test datasets:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取训练集和测试集：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create the estimator functions:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建估算函数：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Specify the type of column:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定列的类型：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Build a DNN classifier using the parameters in scenario 1; that is, the learning
    rate is `0.1` and the number of steps is `200`:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用场景 1 中的参数构建 DNN 分类器；即学习率为 `0.1`，步数为 `200`：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The test accuracy in such a scenario comes out to be 96.49%.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，测试准确率达到 96.49%。
- en: 'In scenario 2, we will build another DNN classifier using different parameters;
    now the learning rate is `0.01` and the number of steps is `2000`:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在场景 2 中，我们将使用不同的参数构建另一个 DNN 分类器；现在学习率为 `0.01`，步数为 `2000`：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The accuracy on the test dataset in scenario 2 is nearly 98.2%.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 场景 2 中测试集上的准确率接近 98.2%。
- en: The preceding two scenarios show us the importance of how various values of
    different hyperparameters affect the final result.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的两个场景表明了不同超参数值如何影响最终结果的重要性。
- en: Google Cloud ML engine comes in handy in such scenarios, where we can be more
    intelligent in selecting the more optimal set of hyperparameters.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Google Cloud ML 引擎非常有用，我们可以更智能地选择更优的超参数集。
- en: Overview of hyperparameter tuning
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数调整概述
- en: Hyperparameter tuning works by running multiple trials in a single training
    job. Each trial is a complete execution of your training application, with values
    for your chosen hyperparameters set within the limits you specify. The Cloud ML
    Engine training service keeps track of the results of each trial and makes adjustments
    for subsequent trials. When the job is finished, you can get a summary of all
    the trials, along with the most effective configuration of values according to
    the criteria you specify.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调整通过在一个训练作业中运行多个试验来实现。每个试验是您训练应用程序的完整执行，其中选择的超参数值在您指定的范围内设置。Cloud ML Engine
    训练服务会跟踪每个试验的结果，并为后续试验进行调整。作业完成后，您可以获取所有试验的摘要，以及根据您指定的标准确定的最有效配置值。
- en: 'We want to select those hyperparameters that give the best performance. This
    amounts to an optimization problem, specifically, the problem of optimizing a
    function *f(x)* (that is, performance as a function of hyperparameter values)
    over a compact set *A.* We can write this mathematically as:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望选择那些能给出最佳性能的超参数。这相当于一个优化问题，具体来说，是优化一个函数 *f(x)*（即性能作为超参数值的函数）在紧致集 *A* 上的问题。我们可以用数学公式表示为：
- en: '![](img/1b2c95c0-1900-4be2-942a-1c35f559a5be.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/1b2c95c0-1900-4be2-942a-1c35f559a5be.png)'
- en: Let's take the example of the function *(1-x)^(ex)*, which has a maximum value
    *f(x) = 1* at *x = 0*, and so *arg max* is *0*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以函数 *(1-x)^(ex)* 为例，它在 *x = 0* 处达到最大值 *f(x) = 1*，因此 *arg max* 是 *0*。
- en: Many optimization settings, like this one, assume that the objective function
    *f(x)* has a known mathematical form, is convex, or is easy to evaluate. But these
    characteristics do not apply to the problem of finding hyperparameters where the
    function is unknown and expensive to evaluate. This is where Bayesian optimization
    comes into play.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 许多优化设置，如这个例子，假设目标函数 *f(x)* 有已知的数学形式，是凸的，或者容易评估。但这些特征不适用于寻找超参数的问题，其中函数是未知的且难以评估。这就是贝叶斯优化发挥作用的地方。
- en: In order to implement hyperparameter tuning, Google uses an algorithm called
    **Gaussian process bandits**, which is a form of Bayesian optimization.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现超参数调整，Google使用了一种称为**高斯过程探险家**的算法，这是一种贝叶斯优化的形式。
- en: Bayesian optimization is an extremely powerful technique when the mathematical
    form of the function is unknown or expensive to compute. The main idea behind
    it is to compute a posterior distribution over the objective function based on
    the data (using the famous Bayes, theorem), and then select good points to try
    with respect to this distribution.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当函数的数学形式未知或计算成本高昂时，贝叶斯优化是一种极其强大的技术。其背后的主要思想是基于数据（使用著名的贝叶斯定理）计算目标函数的后验分布，然后根据这个分布选择好的点进行尝试。
- en: To use Bayesian optimization, we need a way to flexibly model distributions
    over objective functions. This is a bit trickier than modeling a distribution
    over, say, real numbers, since we'll need one such distribution to represent our
    beliefs about *f(x)* for each *x*. If *x* contains continuous hyperparameters,
    there will be infinitely many *x* for which we must model *f(x)*, that is, construct
    a distribution for it. For this problem, Gaussian processes are a particularly
    elegant technique. In effect, they generalize multidimensional Gaussian distributions,
    and versions that are flexible enough to model any objective function do exist.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用贝叶斯优化，我们需要一种灵活地建模目标函数分布的方法。这比建模实数分布要复杂一些，因为我们需要一个这样的分布来表示我们对每个 *x* 的 *f(x)*
    的信念。如果 *x* 包含连续超参数，那么将会有无限多个 *x* 需要建模 *f(x)*，即为其构建一个分布。对于这个问题，高斯过程是一种特别优雅的技术。实际上，它们推广了多维高斯分布，并且确实存在足够灵活以建模任何目标函数的版本。
- en: 'The preceding process typically works as described in the following diagram:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 上述过程通常如以下图所示：
- en: '![](img/920da612-d83c-42ae-9ae5-3f4a61a250e1.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/920da612-d83c-42ae-9ae5-3f4a61a250e1.png)'
- en: We update the Gaussian model with the results of an iteration, which further
    helps in identifying the right next sample set of hyperparameters to be tested
    for the model; the result further improves our Gaussian model to identify the
    right set of hyperparameters to be picked.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过迭代的结果更新高斯模型，这有助于进一步确定要测试的正确下一组超参数集；结果进一步提高了我们的高斯模型，以识别要选择正确的超参数集。
- en: Details of Gaussian distributions are out of the scope of this book, but for
    this exercise, we will take Google's approach as it is (as a black box) and implement
    hyperparameter tuning using Google Cloud.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯分布的细节超出了本书的范围，但为了这个练习，我们将采用Google的方法（作为一个黑盒）并使用Google Cloud实现超参数调整。
- en: Hyperparameter tuning in Google Cloud
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google Cloud中的超参数调整
- en: In order for the just-laid-out Gaussian process to run, we have to allow our
    model builds to be run on Google Cloud so that hyperparameter tuning can be carried
    out.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让刚刚设置的高斯过程运行，我们必须允许我们的模型构建在Google Cloud上运行，以便进行超参数调整。
- en: 'In order to run hyperparameter tuning, the following are essential components:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行超参数调整，以下组件是必不可少的：
- en: Data file and its location
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据文件及其位置
- en: Model file
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型文件
- en: Hyperparameter configuration file
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数配置文件
- en: Setup file
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置文件
- en: '`__init__` file'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__init__` 文件'
- en: Given that we are running the model on Google Cloud ML engine, the data should
    be residing in a Cloud bucket so that it becomes accessible to ML engine.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在Google Cloud ML引擎上运行模型，数据应位于云存储桶中，以便ML引擎可以访问。
- en: 'This can be done by performing the following in the Cloud shell:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过在云壳中执行以下操作来完成：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Note that, using the preceding steps, we have created a bucket named `my-mnist-bucket`
    and copied our data to that bucket. The preceding code should result in creating
    a directory named `data` and the `mnist.pkl` file in that directory:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，使用前面的步骤，我们已经创建了一个名为`my-mnist-bucket`的存储桶，并将我们的数据复制到该存储桶中。前面的代码应该会在该目录中创建一个名为`data`的目录和该目录中的`mnist.pkl`文件：
- en: '![](img/59110e1b-da58-43b9-87c7-27a8b80cb10c.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/59110e1b-da58-43b9-87c7-27a8b80cb10c.jpg)'
- en: The model file
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型文件
- en: The model file should be located in a folder that also contains the `__init__.py`
    file.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 模型文件应位于包含`__init__.py`文件的文件夹中。
- en: 'Let us create a folder named `trainer` that contains both the model file and
    the `__init__` file:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个名为`trainer`的文件夹，其中包含模型文件和`__init__`文件：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preceding code creates the `trainer` folder and changes directory to the
    newly-created folder.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码创建了`trainer`文件夹并将目录更改为新创建的文件夹。
- en: 'Let us go ahead and create the model file as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续创建模型文件，如下所示：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Insert the following code into the previously-created file:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下代码插入到之前创建的文件中：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Configuration file
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置文件
- en: Once the model file is set up, we need to provide the configuration file in
    the same trainer folder so that ML engine knows the parameters that need to be
    tuned, as well as the typical min and max values of the parameter.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型文件设置好，我们需要在同一个`trainer`文件夹中提供配置文件，以便ML引擎知道需要调整的参数以及参数的典型最小和最大值。
- en: 'We create the configuration file as follows in the `trainer` folder:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`trainer`文件夹中创建配置文件如下：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following code is inserted into the preceding file:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码被插入到前面的文件中：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In the preceding block of code, we have specified the Python version to be run
    on and have also specified whether it is to be run on a CPU or a GPU.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们指定了要运行的Python版本，并指定了它是在CPU上运行还是在GPU上运行。
- en: In the `hyperparameters` section, we have specified that the metric we need
    to optimize is accuracy (note that the output of `model.evaluate` is `accuracy`,
    `loss`, `average loss`, and `global step`); the goal is to maximize it.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在`hyperparameters`部分，我们指定了需要优化的指标是准确率（请注意，`model.evaluate`的输出是`accuracy`、`loss`、`average
    loss`和`global step`）；目标是最大化它。
- en: Also, we have specified the maximum number of trials to be run and the maximum
    number of parallel trials that can be run (changes when the Cloud configuration
    has multiple cores associated with it).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还指定了要运行的试验的最大次数以及可以并行运行的试验的最大次数（当云配置与多个核心相关联时，此值会发生变化）。
- en: The `params` section contains the parameters that need to be modified, the type
    of variable it is, and the minimum and maximum values.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`params`部分包含需要修改的参数、变量的类型以及最小和最大值。'
- en: '`ScaleType` indicates the type of scaling that would be applied to the parameter:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`ScaleType`指示将对参数应用哪种缩放类型：'
- en: '| **Value** | **Description** |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| **Value** | **描述** |'
- en: '| `UNIT_LINEAR_SCALE` | Scales the feasible space to (0, 1) linearly. |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `UNIT_LINEAR_SCALE` | 线性地将可行空间缩放到（0，1）。|'
- en: '| `UNIT_LOG_SCALE` | Scales the feasible space logarithmically to (0, 1). The
    entire feasible space must be strictly positive. |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `UNIT_LOG_SCALE` | 对数地将可行空间缩放到（0，1）。整个可行空间必须是严格正的。|'
- en: '| `UNIT_REVERSE_LOG_SCALE` | Scales the feasible space reverse logarithmically
    to (0, 1). The result is that values close to the top of the feasible space are
    spread out more than points near the bottom. The entire feasible space must be
    strictly positive. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `UNIT_REVERSE_LOG_SCALE` | 将可行空间反向对数缩放到（0，1）。结果是，接近可行空间顶部的值比接近底部的点分散得更多。整个可行空间必须是严格正的。|'
- en: Setup file
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置文件
- en: 'In some instances, we might have to install packages that do not come prebuilt.
    The `setup.py` file comes in handy in such scenarios:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们可能需要安装未预构建的包。在这种情况下，`setup.py`文件很有用：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In the preceding code, one could include the additional packages that are needed
    to run the model file.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，可以包含运行模型文件所需的额外包。
- en: The __init__ file
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: __init__文件
- en: For Cloud ML engine to create a package for the module we are building, it needs
    to create a package for the module. For the package to be created, it needs to
    create the `__init__.py` file in the `trainer` folder.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让Cloud ML引擎为我们正在构建的模块创建一个包，它需要在`trainer`文件夹中创建一个`__init__.py`文件。
- en: 'For that, we would run the following code:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将运行以下代码：
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now that the whole setup is ready, we run the job as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一切设置就绪，我们按照以下方式运行作业：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note that we specify the bucket name in which data exists, and the job name
    and directory in which the logs need to be stored. The region needs to be set
    and the configuration file is specified.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们指定了数据存在的数据桶名称，以及需要存储日志的作业名称和目录。需要设置区域，并指定配置文件。
- en: Also, set the `--module-name` argument to the name of your application's main
    module using your package's namespace dot notation.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用你的包的命名空间点表示法将`--module-name`参数设置为应用程序主模块的名称。
- en: Note that, after specifying region, we have a blank, indicating that it is the
    start of arguments now (they are the training file location, number of steps,
    and learning rate).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在指定区域后，我们有一个空格，表示现在开始是参数（它们是训练文件位置、步数和学习率）。
- en: The number of steps and learning rate that we have specified in the preceding
    code are the default versions, which are changed once passed to the ML engine
    job.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中指定的步数和学习率是默认版本，一旦传递给ML引擎作业，就会进行更改。
- en: 'The output of the code can be visualized in the training output of the job
    that we ran, as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的输出可以在我们运行的作业的训练输出中可视化，如下所示：
- en: '![](img/a8a1fc4e-70ba-476f-9e52-f1eba7f6b915.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a8a1fc4e-70ba-476f-9e52-f1eba7f6b915.png)'
- en: The optimal hyperparameters can then be selected from the preceding output.
    We can see that a learning rate of **0.0149** and number of steps as **7658**
    result in a higher test dataset accuracy than the two scenarios that we tested
    earlier.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最优的超参数可以从前面的输出中选择。我们可以看到，学习率设置为**0.0149**，步数设置为**7658**，比我们之前测试的两个场景在测试数据集上的准确率更高。
- en: Summary
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we understood how different parameter combinations affect the
    final accuracy measure and how hyperparameter tuning using Cloud ML engine helps
    in improving the accuracy further.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了不同的参数组合如何影响最终的准确度度量，以及如何使用Cloud ML引擎进行超参数调整来进一步提高准确度。
- en: In the next chapter, we will learn how to identify overfitting and make our
    models more robust to previously-unseen data by setting the right parameters and
    defining the proper architectures.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何通过设置正确的参数和定义适当的架构来识别过拟合，并使我们的模型对之前未见过的数据更加鲁棒。
