- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Federated Learning Client-Side Implementation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联邦学习客户端实现
- en: The client-side modules of a **federated learning** (**FL**) system can be implemented
    based on the system architecture, sequence, and procedure flow, as discussed in
    [*Chapter 3*](B18369_03.xhtml#_idTextAnchor058), *Workings of the Federated Learning
    System*. FL client-side functionalities can connect distributed **machine learning**
    (**ML**) applications that conduct local training and testing with an aggregator,
    through a communications module embedded in the client-side libraries.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 根据系统架构、顺序和流程，如第[*3章*](B18369_03.xhtml#_idTextAnchor058)“联邦学习系统的工作原理”中所述，**联邦学习**（**FL**）系统的客户端模块可以基于系统架构、顺序和流程实现。FL客户端功能可以将进行本地训练和测试的分布式**机器学习**（**ML**）应用程序与聚合器通过客户端库中嵌入的通信模块连接起来。
- en: In the example of using the FL client libraries in a local ML engine, the minimal
    engine package example will be discussed, with dummy ML models to understand the
    process of integration with the FL client libraries that are designed in this
    chapter. By following the example code about integration, you will understand
    how to actually enable the whole process related to the FL client side, as discussed
    in [*Chapter 3*](B18369_03.xhtml#_idTextAnchor058), *Workings of the Federated
    Learning System*, while an analysis on what will happen with the minimal example
    will be discussed in [*Chapter 6*](B18369_06.xhtml#_idTextAnchor156), *Running
    the Federated Learning System and Analyzing the Results*.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用FL客户端库的本地ML引擎示例中，将讨论最小引擎包示例，使用虚拟ML模型来理解与本章设计的FL客户端库集成的过程。通过遵循集成示例代码，您将了解如何实际启用与FL客户端相关的整个流程，如第[*3章*](B18369_03.xhtml#_idTextAnchor058)“联邦学习系统的工作原理”中所述，同时将在第[*6章*](B18369_06.xhtml#_idTextAnchor156)“运行联邦学习系统并分析结果”中讨论最小示例将发生什么。
- en: In this chapter, an overview of the design and implementation principle of FL
    client-side functionalities used in local ML engines will be discussed. By going
    through this chapter, you will be able to code the FL client-side modules and
    libraries as well as distributed local ML engines, such as image classification
    with **Convolutional Neural Networks** (**CNNs**).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将讨论在本地ML引擎中使用的FL客户端功能的设计和实现原理概述。通过阅读本章，您将能够编写FL客户端模块和库以及分布式本地ML引擎的代码，例如使用**卷积神经网络**（**CNNs**）进行图像分类。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: An overview of FL client-side components
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FL客户端组件概述
- en: Implementing FL client-side main functionalities
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现FL客户端主要功能
- en: Designing FL client libraries
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计FL客户端库
- en: Local ML engine integration into an FL system
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地ML引擎集成到FL系统中
- en: An example of integrating image classification into an FL system
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像分类集成到FL系统中的示例
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the code files introduced in this chapter can be found on GitHub ([https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中介绍的所有代码文件都可以在GitHub上找到（[https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl)）。
- en: Important note
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You can use the code files for personal or educational purposes. Please note
    that we will not support deployments for commercial use and will not be responsible
    for any errors, issues, or damages caused by using the code.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用代码文件用于个人或教育目的。请注意，我们不会支持商业部署，并且不对使用代码造成的任何错误、问题或损害负责。
- en: An overview of FL client-side components
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FL客户端组件概述
- en: 'The architecture of an FL client as an agent was introduced in [*Chapter 3*](B18369_03.xhtml#_idTextAnchor058),
    *Workings of the Federated Learning System*. Here, we will introduce code that
    realizes the basic functionalities of an FL client. The client side of software
    architecture is simplified here, where only the `client.py` file can be used in
    this example, together with supporting functions from the `lib/util` folder, as
    shown in *Figure 5.1*:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[*3章*](B18369_03.xhtml#_idTextAnchor058)“联邦学习系统的工作原理”中介绍了FL客户端作为代理的架构。在此，我们将介绍实现FL客户端基本功能的代码。在此处，软件架构的客户端被简化，仅可以使用此示例中的`client.py`文件，以及来自`lib/util`文件夹的支持函数，如图*5.1*所示：
- en: '![Figure 5.1 – Python software components for an FL client as an agent'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1 – 作为代理的FL客户端的Python软件组件'
- en: '](img/B18369_05_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18369_05_01.jpg]'
- en: Figure 5.1 – Python software components for an FL client as an agent
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 – 作为代理的FL客户端的Python软件组件
- en: The following section gives a brief description of the Python files for an agent
    of the FL system.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分简要描述了FL系统代理的Python文件。
- en: Distributed agent-side code
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式代理端代码
- en: For the agent side, there is one main file, `client.py`, in the `fl_main/agent`
    directory that deals with most of the FL client-side functionalities.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代理端，`fl_main/agent`目录中有一个主要文件`client.py`，它处理大多数FL客户端功能。
- en: FL client code (client.py)
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FL客户端代码（client.py）
- en: The `client.py` file in the `agent` folder has functions to participate in an
    FL cycle, an ML model exchange framework with an aggregator, and *push* and *polling*
    mechanisms to communicate with the aggregator. The client’s functions can also
    serve as interfaces between the local ML application and the FL system itself,
    providing FL client-side libraries to the ML engine. This is the main code that
    connects locally trained ML models to the FL server and aggregator. You need to
    prepare a local ML application by yourself, and we will help you understand how
    to integrate your ML engine into an FL system using the FL client libraries, which
    is another main topic of this chapter.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`agent`文件夹中的`client.py`文件包含参与FL周期、与聚合器进行ML模型交换的框架以及*推送*和*轮询*机制以与聚合器通信的功能。客户端的功能还可以作为本地ML应用程序与FL系统本身的接口，为ML引擎提供FL客户端库。这是将本地训练的ML模型连接到FL服务器和聚合器的主要代码。您需要自己准备一个本地ML应用程序，我们将帮助您了解如何使用FL客户端库将您的ML引擎集成到FL系统中，这是本章的另一个主要主题。'
- en: lib/util code
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: lib/util 代码
- en: An explanation of the supporting Python code (`communication_handler.py`, `data_struc.py`,
    `helpers.py`, `messengers.py`, and `states.py`) as internal libraries will be
    covered in *Appendix, Exploring Internal Libraries*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 将对支持Python代码（`communication_handler.py`、`data_struc.py`、`helpers.py`、`messengers.py`和`states.py`）作为内部库的解释包含在*附录，探索内部库*中。
- en: Configuration of an agent
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理配置
- en: 'The following is an example of client-side configuration parameters saved as
    `config_agent.json` in the code we are using:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们使用的代码中保存为`config_agent.json`的客户端配置参数示例：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The aggregator’s IP (`aggr_ip`) and its port number (`reg_socket`) are used
    to get connected to the FL server, where the aggregation of the local models happens.
    In addition, the model path parameter, `model_path`, specifies the location of
    both the local model (named `local_model_file_name`) and the global model (named
    `global_model_file_name`). The local and global models are stored as binary files
    (`lms.binaryfile` and `gms.binaryfile` in this example). The state file (named
    `state_file_name`) writes the local state of the client that defines waiting for
    the global models, training the models, sending the trained models, and so on.
    `init_weights_flag` is used when the system operator wants to initialize the global
    model with certain weights. If the flag is `1`, the agent will send the pre-configured
    model; otherwise, the model will be filled with zeros on the aggregator side.
    The polling flag (`polling`) concerns whether to utilize the polling method or
    not for communication between agents and an aggregator.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合器的IP（`aggr_ip`）和端口号（`reg_socket`）用于连接到FL服务器，在那里进行本地模型的聚合。此外，模型路径参数`model_path`指定了本地模型（命名为`local_model_file_name`）和全局模型（命名为`global_model_file_name`）的位置。本地和全局模型存储为二进制文件（本例中为`lms.binaryfile`和`gms.binaryfile`）。状态文件（命名为`state_file_name`）记录客户端的本地状态，定义了等待全局模型、训练模型、发送训练好的模型等。`init_weights_flag`在系统操作员希望使用某些权重初始化全局模型时使用。如果标志为`1`，代理将发送预配置的模型；否则，模型将在聚合器端填充为零。轮询标志（`polling`）涉及是否在代理和聚合器之间使用轮询方法进行通信。
- en: Now that we’ve discussed FL client-side modules, let’s look into the actual
    implementation and some code to realize the functionalities of an FL client.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了FL客户端模块，让我们来看看实际的实现和一些代码，以实现FL客户端的功能。
- en: Implementing FL client-side main functionalities
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现FL客户端主要功能
- en: In this section, we will explain how you can implement basic FL client-side
    code, which is described in the `client.py` file in the `agent` directory. Please
    refer to [*Chapter 3*](B18369_03.xhtml#_idTextAnchor058), *Workings of the Federated
    Learning System*, for an explanation of FL client-side architecture, sequence,
    and procedure flow. By learning about this client-side code, you will understand
    how to implement an agent’s registration process, model exchange synchronization,
    and *push*/*polling* mechanisms, as well as the communication protocol between
    the agent and aggregator, with some functions that will be called from other ML
    applications as **Application Programming Interfaces** (**APIs**).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将解释如何实现基本的联邦学习客户端代码，该代码在 `agent` 目录下的 `client.py` 文件中有描述。请参阅[*第3章*](B18369_03.xhtml#_idTextAnchor058)，*联邦学习系统的工作原理*，以了解联邦学习客户端架构、序列和流程。通过学习这段客户端代码，您将了解如何实现智能体的注册过程、模型交换同步以及*推送*/*轮询*机制，以及智能体和聚合器之间的通信协议，以及一些将在其他机器学习应用中作为**应用程序编程接口**（**API**）调用的函数。
- en: Let’s first see what libraries will be imported for implementing FL client functions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看实现联邦学习客户端功能需要导入哪些库。
- en: Importing libraries for an agent
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为智能体导入库
- en: 'In this `client.py` file example, the agent imports general libraries such
    as `asyncio` and `time` (a detailed explanation of which is out of scope for this
    book):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个 `client.py` 文件示例中，智能体导入了通用库，例如 `asyncio` 和 `time`（关于这些库的详细解释超出了本书的范围）：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As for the `communication_handler`, `helpers`, `states`, and `messengers` libraries
    imported from `fl_main.lib.util` that are designed for enabling the FL general
    functionalities, please refer to the *Appendix, Exploring Internal Libraries*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 至于从 `fl_main.lib.util` 导入的 `communication_handler`、`helpers`、`states` 和 `messengers`
    库，它们旨在启用联邦学习的一般功能，请参阅*附录，探索内部库*。
- en: After importing the necessary libraries, you will define the `Client` class.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入必要的库之后，您将定义 `Client` 类。
- en: Defining the Client class
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义客户端类
- en: 'Let’s define the `Client` class that implements the core functionalities of
    an FL client, including the participation mechanism of the agent itself, the model
    exchange framework, and a communication interface between the agent and an aggregator,
    as well as libraries provided for use in the agent-side local ML engine:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义实现联邦学习客户端核心功能的 `Client` 类，包括智能体自身的参与机制、模型交换框架以及智能体和聚合器之间的通信接口，以及为在智能体端本地机器学习引擎中使用提供的库：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Then, you will initialize the `Client` class under the `__init__` function,
    as discussed in the next section.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您将在 `__init__` 函数下初始化 `Client` 类，如下一节所述。
- en: Initializing the client
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化客户端
- en: 'The following code inside the `__init__` constructor is an example of the initialization
    process of the client:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `__init__` 构造函数中的代码是客户端初始化过程的示例：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: First, the client generates a unique ID for itself as an identifier that will
    be used in many scenarios to conduct FL.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，客户端为自己生成一个唯一的ID作为标识符，该标识符将在许多场景中用于执行联邦学习。
- en: Second, the client gets its own IP address by using the `get_ip()` function.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，客户端通过使用 `get_ip()` 函数获取自己的IP地址。
- en: Also, simulation runs are supported in this implementation exercise, where we
    can run all the FL system components of a database, server, and multiple agents
    within one machine. If simulation needs to be done, then the `simulation_flag`
    parameter needs to be `True` (refer to the `README` file on GitHub for how to
    set up a simulation mode).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本实现练习支持模拟运行，其中我们可以在一台机器上运行数据库、服务器和多个智能体的所有联邦学习系统组件。如果需要进行模拟，则 `simulation_flag`
    参数需要设置为 `True`（有关如何设置模拟模式的说明，请参阅GitHub上的 `README` 文件）。
- en: Then, `self.cofig` reads and stores the information of `config_agent.json`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`self.cofig` 读取并存储 `config_agent.json` 的信息。
- en: The client then configures the aggregator’s information to connect to its server,
    where `self.aggr_ip` reads the IP address of the aggregator machine or instance
    from the agent configuration file.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，客户端配置聚合器的信息以连接到其服务器，其中 `self.aggr_ip` 从智能体配置文件中读取聚合器机器或实例的IP地址。
- en: After that, the `reg_socket` port will be set up, where `reg_socket` is used
    for registration of the agent, together with an aggregator IP address stored as
    `self.aggr_ip`. The `reg_socket` value in this example can be read from the agent
    configuration file as well.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，将设置 `reg_socket` 端口，其中 `reg_socket` 用于智能体的注册，以及存储为 `self.aggr_ip` 的聚合器IP地址。在这个示例中，`reg_socket`
    的值也可以从智能体配置文件中读取。
- en: '`msend_socket`, which is used in the model exchange routine to send the local
    ML models to the aggregator, will be configured after participating in the FL
    process by sending a message to the FL server and receiving the response.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 用于在模型交换例程中发送本地机器学习模型的 `msend_socket`，将在代理通过向联邦学习服务器发送消息并接收响应后参与联邦学习过程时进行配置。
- en: '`exch_socket` is used when communication is not in *polling* mode for receiving
    global models sent from the aggregator, together with an agent IP address stored
    as `self.agent_ip`.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当通信不是在 *轮询* 模式下时，`exch_socket` 用于接收来自聚合器的全局模型，同时与存储为 `self.agent_ip` 的代理 IP
    地址一起使用。
- en: '`exch_socket` in this example can either be read from the arguments from the
    command line or decided by the aggregator, depending on the simulation mode.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，`exch_socket` 可以根据模拟模式从命令行参数读取或由聚合器决定。
- en: In this example, when the aggregator is set to be able to push messages to the
    connected agents, which is not the case when polling mode is on, `exch_socket`
    can be dynamically configured by the aggregator.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，当聚合器被设置为能够向连接的代理推送消息时，这在轮询模式下是不成立的，`exch_socket` 可以由聚合器动态配置。
- en: '`self.model_path` stores the path to the local and global models and can either
    be read from the agent configuration file or arguments from the command line,
    depending on the simulation mode as well. If there is no directory to save those
    model files, it makes sure to create the directory.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.model_path` 存储本地和全局模型的路径，可以根据模拟模式从代理配置文件或命令行参数中读取。如果没有目录来保存这些模型文件，它将确保创建该目录。'
- en: '`self.lmfile`, `self.gmfile`, and `self.statefile` are the filenames for local
    models, global models, and the state of the client respectively, and read from
    the configuration file of the agent. In particular, in `self.statefile`, the value
    of `ClientState` is saved. `ClientState` is the enumeration value of the client
    itself where there is a state waiting for the global model (`waiting_gm`), a state
    for local training (`training`), a state for sending local models (`sending`),
    and a state for having the updated global models (`gm_ready`).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.lmfile`, `self.gmfile`, 和 `self.statefile` 分别是本地模型、全局模型和客户端状态的文件名，它们从代理的配置文件中读取。特别是，在
    `self.statefile` 中，保存了 `ClientState` 的值。`ClientState` 是客户端自身的枚举值，其中有一个等待全局模型的状态（`waiting_gm`），一个用于本地训练的状态（`training`），一个用于发送本地模型的状态（`sending`），以及一个拥有更新后的全局模型的状态（`gm_ready`）。'
- en: The round information of the FL process, defined as `self.round`, is initialized
    as `0` and later updated as the FL round proceeds with model aggregation, where
    the aggregator will notify the change of the round usually.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习过程的轮次信息，定义为 `self.round`，初始化为 `0`，并在模型聚合过程中随着联邦学习轮次的进行而更新，通常聚合器会通知轮次的变化。
- en: '`self.init_weights_flag` is the flag used when a system operator wants to initialize
    a global model with certain parameters, as explained in the configuration of the
    agent.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.init_weights_flag` 是当系统操作员想要使用某些参数初始化全局模型时使用的标志，如代理配置中所述。'
- en: The `self.is_polling` flag concerns whether to use the polling method in communication
    between the agents and aggregator or not. The polling flag must be the same as
    the one set up on the aggregator side.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`self.is_polling` 标志涉及是否在代理和聚合器之间的通信中使用轮询方法。轮询标志必须与聚合器端设置的标志相同。'
- en: The code about the `__init__` constructor discussed here can be found in `client.py`
    in the `fl_main/agent` folder on GitHub ([https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl)).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里讨论的关于 `__init__` 构造函数的代码可以在 GitHub 上的 `fl_main/agent` 文件夹中的 `client.py` 文件中找到
    ([https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl))。
- en: Now that we have discussed how to initialize a client-side module, in the next
    section, we will look into how the participation mechanism works with some sample
    code.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了如何初始化客户端模块，在下一节中，我们将探讨参与机制是如何与一些示例代码一起工作的。
- en: Agent participation in an FL cycle
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理参与联邦学习周期
- en: This participation or registration process is needed for an agent to be able
    to participate in an FL process together with other agents. Therefore, the agent
    needs to be added to the list of authorized agents that can send locally trained
    ML models to an aggregator.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个参与或注册过程是代理能够与其他代理一起参与联邦学习过程所必需的。因此，代理需要被添加到可以发送本地训练的机器学习模型到聚合器的授权代理列表中。
- en: The asynchronous `participate` function sends the first message to an aggregator
    to join the FL cycle and will receive state and communication information, such
    as socket numbers from the aggregator.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 异步的 `participate` 函数向聚合器发送第一条消息以加入 FL 循环，并将接收状态和通信信息，例如来自聚合器的套接字编号。
- en: 'An agent knows the IP address and port number to join the FL platform through
    the `config_agent.json` file. When joining the FL platform, an agent sends a participation
    message that contains the following information:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 代理通过 `config_agent.json` 文件知道加入 FL 平台的 IP 地址和端口号。当加入 FL 平台时，代理发送包含以下信息的参与消息：
- en: '`agent_name`: A unique name of an agent itself.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`agent_name`：代理自身的唯一名称。'
- en: '`id`: A unique identifier of an agent itself.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id`：代理自身的唯一标识符。'
- en: '`model_id`: A unique identifier of models to be sent to an aggregator.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_id`：要发送给聚合器的模型的唯一标识符。'
- en: '`models`: A dictionary of models keyed by model names. The weights of models
    need not be trained if `init_flag` is `False`, since it is only used by an aggregator
    to remember the shapes of models.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`models`：按模型名称键控的模型字典。如果 `init_flag` 为 `False`，则模型权重不需要训练，因为它仅由聚合器用于记住模型的形状。'
- en: '`init_weights_flag`: A Boolean flag to indicate whether the sent model weights
    should be used as a base model. If it is `True` and there are no global models
    ready, an aggregator sets this set of local models as the first global models
    and sends it to all agents.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init_weights_flag`：一个布尔标志，表示发送的模型权重是否应作为基础模型使用。如果为 `True` 且没有准备好的全局模型，聚合器将此组本地模型作为第一个全局模型，并发送给所有代理。'
- en: '`simulation_flag`: This is `True` if it is a simulation run; otherwise, it
    is `False`.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`simulation_flag`：如果是模拟运行，则为 `True`；否则为 `False`。'
- en: '`exch_socket`: The port number waiting for global models from the aggregator.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exch_socket`：等待从聚合器接收全局模型的端口号。'
- en: '`gene_time`: The time that models are generated.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gene_time`：模型生成的时间。'
- en: '`performance_dict`: Performance data related to models in a dictionary format.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`performance_dict`：以字典格式存储与模型相关的性能数据。'
- en: '`agent_ip`: The IP address of an agent itself.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`agent_ip`：代理自身的 IP 地址。'
- en: 'With all the aforementioned participation messages defined, the agent is ready
    to exchange models with the aggregator, and the code to realize the participation
    process is as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了所有上述参与消息后，代理准备好与聚合器交换模型，实现参与过程的代码如下：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The agent reads the local models to tell the structure of the ML models to the
    aggregator, and the initial model does not necessarily need to be trained. `data_dict`
    and `performance_dict` store the models and their performance data respectively.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 代理读取本地模型以告知聚合器 ML 模型的结构，初始模型不一定需要训练。`data_dict` 和 `performance_dict` 分别存储模型及其性能数据。
- en: Then, a message, `msg`, containing information such as the ML `models` and its
    `model_id`, is packaged using the `generate_agent_participation_message` function.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用 `generate_agent_participation_message` 函数包装包含如 ML `models` 和其 `model_id`
    等信息的消息 `msg`。
- en: When sending the message, in this example, the WebSocket is constructed using
    the aggregator’s IP address (`aggr_ip`) and the registration port number (`reg_socket`)
    to be connected to the aggregator.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在发送消息时，在这个例子中，使用聚合器的 IP 地址 (`aggr_ip`) 和注册端口号 (`reg_socket`) 构建WebSocket以连接到聚合器。
- en: After sending the message to the aggregator via an asynchronous `send` function
    imported from `communication_handler`, the agent receives a response message,
    `resp`, from the aggregator. The response will include the round info, the port
    number to receive the global models’ `exch_socket`, the port number to send the
    local models to the aggregator’s `msend_socket`, and an updated agent ID.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从 `communication_handler` 导入的异步 `send` 函数向聚合器发送消息后，代理从聚合器接收响应消息 `resp`。响应将包括轮次信息、接收全局模型
    `exch_socket` 的端口号、将本地模型发送到聚合器 `msend_socket` 的端口号以及更新的代理 ID。
- en: Finally, the global model within the response message is saved locally by calling
    the `save_model_from_message` function.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过调用 `save_model_from_message` 函数将响应消息中的全局模型保存在本地。
- en: The participation mechanism of an agent has been explained. In the next section,
    we will learn about the framework of model exchange synchronization.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 代理的参与机制已经解释。在下一节中，我们将学习模型交换同步的框架。
- en: Model exchange synchronization
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型交换同步
- en: 'Model exchange synchronization, as shown in the following code, is for checking
    the state of the agent and calling a proper function based on the state:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 模型交换同步，如下面的代码所示，是为了检查代理的状态并根据状态调用适当的函数：
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Basically, this process is always running while the client is alive, whereas
    the `while` loop is used periodically to check the client’s `state` and proceed
    with the next steps if necessary.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，当客户端存活时，这个过程始终在运行，而`while`循环则定期用来检查客户端的`状态`，并在必要时进行下一步操作。
- en: In the `while` loop, after waiting a few seconds, it first checks the client
    state by the `read_state` function. The parameters in the `read_state` function
    are to locate the `state` file stored in the local environment.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在`while`循环中，等待几秒钟后，它首先通过`read_state`函数检查客户端状态。`read_state`函数中的参数是用来定位存储在本地环境中的`状态`文件。
- en: As mentioned, `ClientState` has the enumeration value of the client state itself,
    defining a state for sending local models (`sending`), a state waiting for the
    global model (`waiting_sgm`), a state for local training (`training`), and a state
    for receiving the updated global models (`gm_ready`).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正如所述，`ClientState`具有客户端状态的枚举值，定义了发送本地模型的状态（`发送`）、等待全局模型的状态（`等待_sgm`）、本地训练的状态（`训练`）和接收更新后的全局模型的状态（`gm_ready`）。
- en: If the client is in the `sending` state (`state == ClientState.sending`), it
    means it is ready to send the locally trained model to the aggregator. Therefore,
    the agent calls the `send_models` function to send the locally trained ML model
    to the aggregator.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果客户端处于`发送`状态（`state == ClientState.sending`），这意味着它已准备好将本地训练的模型发送到聚合器。因此，代理调用`send_models`函数将本地训练的机器学习模型发送到聚合器。
- en: When the state is `waiting_gm` (`state == ClientState.waiting_gm`), it either
    proceeds with `process_polling` to poll from the agent to the aggregator if polling
    mode is on, or just does nothing if polling mode is off.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当状态是`等待全局模型`（`state == ClientState.waiting_gm`）时，如果开启轮询模式，则通过`process_polling`从代理向聚合器进行轮询；如果轮询模式关闭，则什么都不做。
- en: If the client is in the `training` state (`state == ClientState.training`),
    it means that the client is training the local model now and just waits for a
    few seconds, printing the training status if necessary. You can also add any procedure
    if needed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果客户端处于`训练`状态（`state == ClientState.training`），这意味着客户端现在正在训练本地模型，只需等待几秒钟，如果需要的话打印训练状态。也可以根据需要添加任何程序。
- en: If the client is in the `gm_ready` state (`state == ClientState.gm_ready`),
    it means that the client received the global model. This state will be handled
    by a local ML application, and it does nothing but show the readiness of the global
    models.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果客户端处于`gm_ready`状态（`state == ClientState.gm_ready`），这意味着客户端已收到全局模型。此状态将由本地机器学习应用程序处理，它除了显示全局模型的就绪状态外，不做任何事情。
- en: In the next section, we will talk about how the *push* and *polling* mechanisms
    can be implemented for an FL cycle.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论如何实现联邦学习周期中的*推送*和*轮询*机制。
- en: Push and polling implementation
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推送和轮询实现
- en: 'Once an agent is initialized and confirmed for participation in an FL process,
    it starts waiting for the global models sent from an aggregator. There are two
    ways to receive global models from the aggregator: the `push` method and the `polling`
    method. Although the **Secure Sockets Layer** (**SSL**) or **Transport Layer Security**
    (**TSL**) frameworks are not implemented in FL client-side code here for simplification,
    it is recommended to support them to secure constant communication.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦代理初始化并确认参与联邦学习过程，它就开始等待从聚合器发送的全局模型。从聚合器接收全局模型有两种方式：推送方法和轮询方法。尽管为了简化，这里没有在联邦学习客户端代码中实现**安全套接字层**（**SSL**）或**传输层安全性**（**TSL**）框架，但建议支持它们以确保持续的通信安全。
- en: Let’s look into the mechanism for each communication framework.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看每个通信框架的机制。
- en: The push method from aggregator to agent
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从聚合器到代理的推送方法
- en: With the `push` method, the aggregator will push the message that includes global
    models to all the connected agents right after the global models are generated.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用推送方法，聚合器将在全局模型生成后立即将包含全局模型的消息推送到所有连接的代理。
- en: 'The following code shows the *push* mechanism accepting and saving global models
    from the aggregator:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了从聚合器接受和保存全局模型的*推送*机制：
- en: '[PRE6]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `wait_models` asynchronous function accepts `websocket` as a parameter.
    When the aggregator sends a message to the agent, it receives the `gm_msg` message
    through `await recieve(websocket)` and saves the global models locally by calling
    the `save_model_from_message` function, as defined in the *Toward designing FL
    client libraries* section.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`wait_models`异步函数接受`websocket`作为参数。当聚合器向代理发送消息时，它通过`await recieve(websocket)`接收`gm_msg`消息，并通过调用在*设计FL客户端库*部分定义的`save_model_from_message`函数，将全局模型本地保存。'
- en: The polling method from agent to aggregator
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代理到聚合器的轮询方法
- en: With the `polling` method, an agent will keep asking (polling) an aggregator
    to see whether global models are already formed or not. Once it has been created
    and is ready to be sent to the connected agents, the polled message will be returned
    to the agent with the updated global models in the response.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`polling`方法，代理将持续询问（轮询）聚合器，以查看全局模型是否已经形成。一旦创建并准备好发送给连接的代理，轮询的消息将返回给代理，并在响应中包含更新的全局模型。
- en: 'The following code about the `process_polling` asynchronous function illustrates
    the `polling` method:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下关于`process_polling`异步函数的代码说明了`polling`方法：
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It first generates the polling message with the `generate_polling_message` function
    to be sent to the aggregator. After receiving the response message, `resp`, from
    the aggregator, if the message type is `AggMsgType.update`, meaning the response
    message contains the updated global models, it calls the `save_model_from_message`
    function. Otherwise, it does nothing.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 它首先使用`generate_polling_message`函数生成要发送给聚合器的轮询消息。在收到聚合器发送的响应消息`resp`后，如果消息类型是`AggMsgType.update`，意味着响应消息包含更新的全局模型，它将调用`save_model_from_message`函数。否则，它不执行任何操作。
- en: The aforementioned functions are the basic but core features of an FL client,
    and those functions need to be efficiently used by a user-side ML application
    as libraries.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 上述函数是FL客户端的基本但核心功能，这些函数需要作为库被用户端的ML应用程序高效地使用。
- en: Now that FL client design, including initialization, participation, and model
    exchanges, has been explained, we will learn about how to design FL client libraries.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在FL客户端设计，包括初始化、参与和模型交换，已经解释过了，我们将学习如何设计FL客户端库。
- en: Designing FL client libraries
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计FL客户端库
- en: In this section, we will explain how to package essential functions to be provided
    as libraries to users. In this example, the simplest way to package them as libraries
    will be discussed. This will need to be expanded, depending on your needs and
    the design of your own FL client framework. By packaging FL client-side modules
    as libraries, developers will be easily able to integrate the FL client’s functions
    into the local ML engine.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将解释如何封装基本函数作为库提供给用户。在本例中，将它们作为库封装的最简单方法将被讨论。这需要根据你的需求和自己的FL客户端框架设计进行扩展。通过将FL客户端模块作为库封装，开发者将能够轻松地将FL客户端的功能集成到本地ML引擎中。
- en: Let’s start with how to define a library to start and register an FL client.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从如何定义一个库来启动和注册FL客户端开始。
- en: Starting FL client core threads
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动FL客户端核心线程
- en: For local ML application developers to be able to integrate FL client-related
    functions, they sometimes need to be packaged as threading functions.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使本地ML应用开发者能够集成FL客户端相关的函数，有时需要将它们封装为线程函数。
- en: 'The following code to register an agent in the FL system simply puts a `participate`
    function into the `run_until_complete` function of an `asyncio.get_event_loop`
    function:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下注册FL系统中代理的代码简单地将一个`participate`函数放入`asyncio.get_event_loop`函数的`run_until_complete`函数中：
- en: '[PRE8]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Also, the `start_wait_model_server` function is packaged, as shown in the following
    code block, where the `Thread` function takes care of the constant run. This way,
    you will be able to run the local ML module in parallel and receive global models
    in the `wait_models` thread when the FL system is in *push* communication mode:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`start_wait_model_server`函数被封装，如下面的代码块所示，其中`Thread`函数负责持续运行。这样，你将能够在并行运行本地ML模块的同时，在FL系统处于*推送*通信模式时，在`wait_models`线程中接收全局模型：
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Similarly, the `start_model_exhange_server` function can be a thread to run
    a model exchange routine to synchronize the local and global models, while the
    local ML module is running in parallel. You can just call the following `start_model_exchange_server`
    function as a library to enable this functionality:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，`start_model_exhange_server` 函数可以是一个线程，用于运行模型交换例程以同步本地和全局模型，同时本地机器学习模块并行运行。您只需调用以下
    `start_model_exchange_server` 函数作为库来启用此功能：
- en: '[PRE10]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, it may be helpful to package all these three functions to execute
    at the same time when they are called outside the `Client` class. Therefore, we
    introduce the following code concerning `start_fl_client` that aggregates the
    functions of registering agents, waiting for global models and a model exchange
    routine to start the FL client core functions:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当它们在 `Client` 类外部被调用时，同时执行所有这三个函数可能是有帮助的。因此，我们引入了以下关于 `start_fl_client` 的代码，该代码聚合了注册代理、等待全局模型和模型交换例程以启动FL客户端核心功能的功能：
- en: '[PRE11]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The initiation of the FL client is now packaged into `start_fl_client`. Next,
    we will define the libraries of saved ML models.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: FL客户端的初始化现在被封装到 `start_fl_client` 中。接下来，我们将定义保存的机器学习模型库。
- en: Saving global models
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存全局模型
- en: While the `load` and `save` model functions are provided by the helper functions
    in `lib/util`, which will be explained later in the *Appendix*, *Exploring Internal
    Libraries*, it is helpful to provide an interface for ML developers to save global
    models from a message sent from an aggregator.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `load` 和 `save` 模型函数由 `lib/util` 中的辅助函数提供，这些将在后面的 *附录*，*探索内部库* 中解释，但为机器学习开发者提供一个从聚合器发送的消息中保存全局模型的接口是有帮助的。
- en: 'The following `save_model_from_message` function is one that extracts and saves
    global models in an agent and also changes the client state to `gm_ready`. This
    function takes the message (`msg`) and message location (`MSG_LOC`) information
    as parameters:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `save_model_from_message` 函数是一个从代理中提取并保存全局模型，并更改客户端状态为 `gm_ready` 的函数。此函数将消息（`msg`）和消息位置（`MSG_LOC`）信息作为参数：
- en: '[PRE12]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The global models, model ID, and aggregator ID are extracted from the message
    and put into a dictionary using the `create_data_dict_from_models` library. The
    round information is also updated based on the received message.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `create_data_dict_from_models` 库从消息中提取全局模型、模型ID和聚合器ID，并将它们放入字典中。根据接收到的消息，也更新了轮次信息。
- en: Then, the received global models are saved to the local file using the `save_model_file`
    library, in which the data dictionary, model path, and global model file name
    are specified to save the models.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用 `save_model_file` 库将接收到的全局模型保存到本地文件中，其中指定了数据字典、模型路径和全局模型文件名以保存模型。
- en: After receiving the global models, it changes the client state to `gm_ready`,
    the state indicating that the global model is ready for the local ML to be utilized
    by calling the `tran_state` function, which will be explained in the next section.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 接收到全局模型后，它通过调用 `tran_state` 函数将客户端状态更改为 `gm_ready`，该状态表示全局模型已准备好由本地机器学习使用，`tran_state`
    函数将在下一节中解释。
- en: With the function of saving global models defined, we are ready to move on to
    how to manipulate the client state in the next section.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了保存全局模型的函数后，我们就可以继续下一节，了解如何操作客户端状态。
- en: Manipulating client state
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作客户端状态
- en: In order to manipulate the client state so that it can logically handle local
    and global models, we prepare the `read_state` and `tran_state` functions, which
    can be accessed both from inside and outside the code.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了操作客户端状态以便它可以逻辑地处理本地和全局模型，我们准备了 `read_state` 和 `tran_state` 函数，这些函数可以从代码内部和外部访问。
- en: 'The following `read_state` function reads the value written in `statefile`,
    stored in the location specified by `model_path`. The enumeration value of `ClientState`
    is used to change the client state:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `read_state` 函数读取存储在 `statefile` 中、由 `model_path` 指定位置的值。使用 `ClientState`
    的枚举值来更改客户端状态：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following `tran_state` function changes the state of the agent. In this
    code sample, the state is maintained in the local `state` file only:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `tran_state` 函数更改代理的状态。在这个代码示例中，状态仅在本地 `state` 文件中维护：
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Next, let’s define the functions that can send local models to an aggregator.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义可以将本地模型发送到聚合器的函数。
- en: Sending local models to aggregator
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将本地模型发送到聚合器
- en: 'The following asynchronous `send_models` function is about sending models that
    have been saved locally to the aggregator:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 以下异步的 `send_models` 函数是关于将本地保存的模型发送到聚合器的：
- en: '[PRE15]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: It first extracts `data_dict` and `performance_dict` using the `load_model_file`
    helper function and then pulls out the models and their ID from `data_dict`, based
    on the `compatible_data_dict_read` function. Then, the message is packaged with
    the `generate_lmodel_update_message` library and sent to the aggregator, with
    the `send` function from `communication_handler`. After that, the client state
    is changed to `waiting_gm` by the `tran_state` function. Again, the SSL/TSL framework
    can be added to secure communication, which is not implemented here to keep the
    FL client-side coding simple.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 它首先使用`load_model_file`辅助函数提取`data_dict`和`performance_dict`，然后根据`compatible_data_dict_read`函数从`data_dict`中提取模型及其ID。然后，使用`generate_lmodel_update_message`库包装消息，并通过`communication_handler`的`send`函数发送到聚合器。之后，通过`tran_state`函数将客户端状态更改为`waiting_gm`。再次强调，可以添加SSL/TSL框架来确保通信安全，但在此处未实现，以保持联邦学习客户端编码的简单性。
- en: 'The following `send_initial_model` function is called when you want to send
    the initial *base model* to an aggregator of the model architecture for registration
    purposes. It takes initial models, the number of samples, and performance value
    as input and calls `setup_sending_model`, which will be explained later in this
    section:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想将初始*基础模型*发送到模型架构的聚合器以进行注册目的时，会调用以下`send_initial_model`函数。它接受初始模型、样本数量和性能值作为输入，并调用将在本节后面解释的`setup_sending_model`：
- en: '[PRE16]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The following `send_trained_model` function is called when you want to send
    trained local models to the aggregator during the FL cycle. It takes trained models,
    the number of samples, and performance value as input and only calls `setup_sending_model`
    if the client state is *not* `gm_ready`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在联邦学习周期内想要向聚合器发送训练好的本地模型时，会调用以下`send_trained_model`函数。它接受训练好的模型、样本数量和性能值作为输入，并且只有在客户端状态不是`gm_ready`时才调用`setup_sending_model`：
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following `setup_sending_models` function is designed to serve as an internal
    library to set up sending locally trained models to the aggregator. It takes parameters
    of models as `np.array`, the number of samples as an integer, and performance
    data as a float value:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下`setup_sending_models`函数被设计为内部库，用于设置将本地训练的模型发送到聚合器的过程。它接受模型的参数作为`np.array`，样本数量作为整数，以及性能数据作为浮点值：
- en: '[PRE18]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Basically, this function creates a unique model ID with the `generate_model_id`
    helper function, `data_dict` to store the local ML models data created with the
    `create_data_dict_from_models` helper function, and `meta_data_dict` to store
    the performance data created with the `create_meta_data_dict` helper function.
    And then, all the aforementioned data related to the models and performance is
    saved locally with the `save_model_file` function, in the location specified with
    `self.model_path`. Then, it changes the client state to `sending` so that the
    `mode_exchange_routine` function can note the change in the client state and start
    sending trained local models to the aggregator.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，这个函数使用`generate_model_id`辅助函数创建一个唯一的模型ID，使用`create_data_dict_from_models`辅助函数创建的`data_dict`来存储本地机器学习模型数据，以及使用`create_meta_data_dict`辅助函数创建的`meta_data_dict`来存储性能数据。然后，所有与模型和性能相关的上述数据都使用`save_model_file`函数保存在由`self.model_path`指定的位置。接着，它将客户端状态更改为`sending`，以便`mode_exchange_routine`函数可以注意客户端状态的改变，并开始向聚合器发送训练好的本地模型。
- en: Now that we know about the libraries to send ML models to the aggregator, let’s
    learn about an important function to wait for a global model on the agent side.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了将机器学习模型发送到聚合器的库，那么让我们来了解一个在代理端等待全局模型的重要函数。
- en: Waiting for global models from an aggregator
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 等待聚合器提供的全局模型
- en: 'The following `wait_for_global_model` function is very important to conduct
    an FL cycle consistently:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下`wait_for_global_model`函数对于持续进行联邦学习周期非常重要：
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The principle is that the function waits until the client state becomes `gm_ready`.
    The transition of the client state to `gm_ready` happens when the global model
    is received on the agent side. Once the client state changes to `gm_ready`, it
    proceeds to load global models from `data_dict`, extracted with the `load_model_file`
    function, changes the client state to `training`, and returns the global models
    to the local ML module.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，该函数会等待客户端状态变为`gm_ready`。当代理端接收到全局模型时，客户端状态会变为`gm_ready`。一旦客户端状态变为`gm_ready`，它将继续从`data_dict`中加载全局模型，使用`load_model_file`函数提取，将客户端状态更改为`training`，并将全局模型返回到本地机器学习模块。
- en: We have discussed how to design the libraries of FL client-side functions. In
    the next section, we will discuss how to integrate those libraries into a local
    ML process.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了如何设计FL客户端函数的库。在下一节中，我们将讨论如何将这些库集成到本地机器学习过程中。
- en: Local ML engine integration into an FL system
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地机器学习引擎集成到FL系统中
- en: The successful integration of FL client libraries into a local ML engine is
    key to conducting FL in distributed environments later on.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 将FL客户端库成功集成到本地机器学习引擎中，对于后续在分布式环境中进行联邦学习至关重要。
- en: 'The `minimal_MLEngine.py` file in the `examples/minimal` directory found in
    the GitHub repository at [https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl),
    as shown in *Figure 5.2*, provides an example of integrating FL client-side libraries
    into a minimal ML engine package:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图5.2*所示，GitHub仓库[https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl)中`examples/minimal`目录下的`minimal_MLEngine.py`文件提供了一个将FL客户端库集成到最小化ML引擎包的示例：
- en: '![Figure 5.2 – The minimal ML engine package'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.2 – 最小化机器学习引擎包'
- en: '](img/B18369_05_02.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18369_05_02.jpg)'
- en: Figure 5.2 – The minimal ML engine package
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – 最小化机器学习引擎包
- en: Next, we will explain what libraries need to be imported into the local ML engine
    in the following section.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将解释需要将哪些库导入到本地机器学习引擎中。
- en: Importing libraries for a local ML engine
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入本地机器学习引擎的库
- en: The following code shows the importing process, where general libraries such
    as `numpy`, `time`, and `Dict` are imported first. The key part of this process
    is that `Client` is imported from the `client.py` file in the `fl_main.agent`
    folder. This way, a developer does not need to know too much about the code inside
    an FL system and just calls the important functionalities defined as libraries,
    as discussed in the *Toward designing FL client libraries* section.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了导入过程，其中首先导入了通用库，如`numpy`、`time`和`Dict`。这个过程的关键部分是，从`fl_main.agent`文件夹中的`client.py`文件导入`Client`。这样，开发者不需要了解FL系统内部太多的代码，只需调用作为库定义的重要功能，正如在*设计FL客户端库的方向*一节中讨论的那样。
- en: 'We will not cover the `pip` installation packaging here in this book, but it
    is possible to host the client-side code with either a private or public PyPI
    server:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将不会介绍`pip`安装打包的内容，但可以使用私有或公共PyPI服务器托管客户端代码：
- en: '[PRE20]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: After importing the necessary libraries, let’s look at the functions defined
    for local training and testing.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入必要的库之后，让我们看看为本地训练和测试定义的函数。
- en: Defining the ML models, training, and test functions
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义机器学习模型、训练和测试函数
- en: You first define the models, training, and testing functions to be integrated
    into the FL system. In this code example, we will use dummy models and training/testing
    functions, allowing users to be able to understand the minimal FL procedure without
    being bothered by specific ML complications.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 您首先定义要集成到FL系统中的模型、训练和测试函数。在本代码示例中，我们将使用虚拟模型和训练/测试函数，使用户能够理解最小化FL流程，而无需被特定的机器学习复杂性所困扰。
- en: 'The following function called `init_models` returns the templates of models
    (in a dictionary format) to inform the ML model structure. The models do not need
    to be trained necessarily. In this case, the models have two layers defined by
    `model1` and `model2`, where some random NumPy array is assigned to each layer,
    as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 被称为`init_models`的以下函数返回模型的模板（以字典格式），以告知ML模型结构。模型不一定需要训练。在这种情况下，模型由`model1`和`model2`定义了两个层，每个层分配了一些随机的NumPy数组，如下所示：
- en: '[PRE21]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'After initializing the models, you will design the following `training` function
    that can be a placeholder function for each ML application:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始化模型后，您将设计以下`training`函数，它可以作为每个ML应用的占位符函数：
- en: '[PRE22]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The logic of this function should be in the order of taking models as input,
    training them, and returning trained local models. As input parameters, it takes
    models with the `Dict[str,np.array]` format and the `init_flag` Boolean value,
    indicating whether it is the initialization step or not.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数的逻辑顺序应该是接收模型作为输入，训练它们，并返回训练后的本地模型。作为输入参数，它接受具有`Dict[str,np.array]`格式的模型和`init_flag`布尔值，指示是否是初始化步骤。
- en: '`init_flag` is `True` when you want to call and return the predefined `init_models`,
    and it is `False` if it’s an actual training step.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想要调用并返回预定义的`init_models`时，`init_flag`为`True`，如果是实际的训练步骤，则为`False`。
- en: Eventually, this function returns the trained models that are decomposed into
    NumPy arrays, with a dictionary of `Dict[str,np.array]` in this example.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，此函数返回分解为NumPy数组的训练模型，在这个例子中是一个 `Dict[str,np.array]` 字典。
- en: In this dummy example, we are just giving you dummy models that skip the actual
    training process.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个虚拟例子中，我们只是提供了虚拟模型，跳过了实际的训练过程。
- en: 'Then, the following `compute_performance` function is designed to compute the
    performance of models given a set of models and a test dataset:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，以下 `compute_performance` 函数被设计用来计算给定一组模型和测试数据集的模型性能：
- en: '[PRE23]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Again, in this example, just a dummy accuracy value is given, `0.5`, to keep
    things simple.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，在这个例子中，只提供了一个虚拟准确度值 `0.5`，以保持事情简单。
- en: 'Then, you may want to define the following `judge_termination` function to
    decide the criteria to finish the training process and exit from the FL process:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可能想要定义以下 `judge_termination` 函数来决定结束训练过程并退出联邦学习过程的准则：
- en: '[PRE24]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: It is up to you how to design this termination condition. This function takes
    parameters such as the number of completed training processes (`training_count`),
    the number of times it received global models (`global_arrival_count`), and so
    on, returning a Boolean value where the flag is `True` if it continues the FL
    process and `False` if it stops. Here, it just gives a `True` Boolean value, meaning
    the FL process will not stop unless the agent is forced to stop outside of this
    function.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如何设计这个终止条件取决于你。这个函数接受诸如完成训练过程的数量（`training_count`）、接收全局模型的次数（`global_arrival_count`）等参数，返回一个布尔值，其中标志为
    `True` 表示继续联邦学习过程，`False` 表示停止。在这里，它只提供了一个 `True` 布尔值，意味着除非代理被强制在函数外部停止，否则联邦学习过程不会停止。
- en: 'If preparing the test data is needed, you can define a function such as `prep_test_data`:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要准备测试数据，你可以定义一个如 `prep_test_data` 的函数：
- en: '[PRE25]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In this example, it is just set as `0`.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，它被设置为 `0`。
- en: Now that the necessary functions for testing and training are defined, we will
    integrate client libraries into the local ML engine to run the FL agent working
    with the FL server-side components, such as an aggregator and a database.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在测试和训练所需的函数已经定义，我们将客户端库集成到本地机器学习（ML）引擎中，以运行与联邦服务器端组件（如聚合器和数据库）一起工作的联邦学习代理。
- en: Integration of client libraries into your local ML engine
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将客户端库集成到您的本地ML引擎中
- en: Now, everything is ready to start your very first FL process, although the models,
    training, and testing functions are set with dummy variables.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一切准备就绪，可以开始你的第一个联邦学习（FL）过程，尽管模型、训练和测试函数都使用虚拟变量设置。
- en: 'The very first thing to do is to create a `Client` instance as follows so that
    you can call its libraries:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 首要任务是创建一个 `Client` 实例，如下所示，以便你可以调用其库：
- en: '[PRE26]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Second, you create the `initial_models` with the training function, as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，你使用训练函数创建 `initial_models`，如下所示：
- en: '[PRE27]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'After that, it sends the initial models to the FL aggregator by calling `cl.send_initial_model`,
    with `initial_models` as a parameter:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，通过调用 `cl.send_initial_model` 并将 `initial_models` 作为参数，它将初始模型发送到联邦聚合器：
- en: '[PRE28]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Then, let’s just start the client-side FL process by calling `cl.start_fl_client()`.
    As explained earlier in the *Starting FL client core threads* section, this function
    can start three processes at the same time: registering the agent, waiting for
    global models, and the model exchange routine:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们通过调用 `cl.start_fl_client()` 来启动客户端的联邦学习过程。正如在 *启动联邦客户端核心线程* 部分中解释的那样，此函数可以同时启动三个过程：注册代理、等待全局模型以及模型交换例程：
- en: '[PRE29]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, we design the client-side FL cycle of local training/testing and sending/receiving
    models by effectively integrating the several FL client libraries, as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过有效地集成几个联邦客户端库，设计客户端的本地训练/测试和发送/接收模型的联邦学习周期：
- en: '[PRE30]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We use a `while` loop and the `judge_termination` function to check whether
    the system needs to leave the loop. It is up to you to use `training_count` and
    `gm_arrival_count` to judge the termination of the FL cycle.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `while` 循环和 `judge_termination` 函数来检查系统是否需要退出循环。是否使用 `training_count` 和
    `gm_arrival_count` 来判断联邦学习周期的终止取决于你。
- en: Then, the agent proceeds to wait for the global models with `cl.wait_for_global_model()`.
    Upon the arrival of the global models from the aggregator, it extracts `global_models`,
    increments `gm_arrival_count`, and sets the client state to the `training` state
    in the `wait_for_global_model` function.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，代理通过 `cl.wait_for_global_model()` 继续等待全局模型。当从聚合器接收到全局模型后，它提取 `global_models`，增加
    `gm_arrival_count`，并在 `wait_for_global_model` 函数中将客户端状态设置为 `training` 状态。
- en: Next, `global_model_performance_data` is calculated with the `compute_performance`
    function, taking `global_models` and `prep_test_data` as input.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用 `compute_performance` 函数计算 `global_model_performance_data`，输入为 `global_models`
    和 `prep_test_data`。
- en: While executing `training(global_models)` in the `training` state, the client
    might receive new global models from the aggregator. This scenario happens when
    the client’s local training was too slow, and the aggregator decided to utilize
    other local models to create a new set of global models. If the new global models
    have already arrived at the agent, the client’s state is changed to `gm_ready`
    and the current ML model being trained will be discarded.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当在 `training` 状态下执行 `training(global_models)` 时，客户端可能会从聚合器接收新的全局模型。这种情况发生在客户端的本地训练速度过慢，聚合器决定利用其他本地模型来创建一组新的全局模型。如果新的全局模型已经到达代理，客户端的状态将变为
    `gm_ready`，并且当前正在训练的 ML 模型将被丢弃。
- en: After the local training phase has finished with `models` generated by `training(global_models)`,
    an agent increments `training_count` and calculates the performance data, `perf_value`,
    of the current ML model with the `compute_performance` function.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地训练阶段完成，并生成 `models` 后，代理通过 `compute_performance` 函数增加 `training_count` 并计算当前
    ML 模型的性能数据 `perf_value`。
- en: Then, the agent tries to upload the trained local models to the aggregator via
    `cl.send_trained_model`, taking the trained models and the performance value calculated
    previously as parameters.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，代理尝试通过 `cl.send_trained_model` 将训练好的本地模型上传到聚合器，并将训练好的模型和之前计算的性能值作为参数。
- en: In the `send_trained_model` function, the client state is set to `sending`.
    Once the client’s `model_exchange_routine` observes the state transition to the
    `sending` state, it sends the trained local models (stored as a binary file) to
    the aggregator. After sending the models, it goes back to the `waiting_gm` state
    in the `send_models` function.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `send_trained_model` 函数中，客户端状态被设置为 `sending`。一旦客户端的 `model_exchange_routine`
    观察到状态转换为 `sending` 状态，它将训练好的本地模型（以二进制文件的形式存储）发送给聚合器。发送模型后，它回到 `send_models` 函数中的
    `waiting_gm` 状态。
- en: After sending the local models, the aggregator stores the uploaded local models
    in its buffers and waits for another round of global model aggregation, until
    enough local models are uploaded by agents.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在发送本地模型后，聚合器将其存储在缓冲区中，并等待下一轮全局模型聚合，直到有足够的本地模型由代理上传。
- en: In the next section, we will briefly talk about how to integrate image classification
    ML into the FL system we have discussed.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将简要介绍如何将图像分类机器学习集成到我们讨论过的联邦学习系统中。
- en: "An example of integrating image classification \Linto an FL system"
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将图像分类集成到联邦系统中的示例
- en: We learned about how to initiate an FL process with a minimal example. In this
    section, we will give a brief example of FL with **image classification** (**IC**)
    using a CNN.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过一个最小示例学习了如何启动一个联邦学习过程。在本节中，我们将给出使用 CNN 进行图像分类（**IC**）的联邦学习的一个简要示例。
- en: 'First, the package that contains the image classification example code is found
    in the `examples/image_classification/` folder in the GitHub repository at [https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl),
    as shown in *Figure 5.3*:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，包含图像分类示例代码的包位于 GitHub 仓库 [https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl)
    中的 `examples/image_classification/` 文件夹，如图 5.3 所示：
- en: '![Figure 5.3 – The image classification package'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.3 – 图像分类包'
- en: '](img/B18369_05_03.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B18369_05_03.jpg](img/B18369_05_03.jpg)'
- en: Figure 5.3 – The image classification package
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – 图像分类包
- en: The main code in charge of integrating the IC algorithms into the FL systems
    is found in the `classification_engine.py` file.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 负责将 IC 算法集成到 FL 系统中的主要代码位于 `classification_engine.py` 文件中。
- en: When importing the libraries, we use a couple of extra files that include CNN
    models, converter functions, and data managers related to IC algorithms. The details
    are provided in the GitHub code at [https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 当导入库时，我们使用一些额外的文件，包括与 IC 算法相关的 CNN 模型、转换函数和数据管理器。详细信息请参阅 GitHub 代码 [https://github.com/tie-set/simple-fl](https://github.com/tie-set/simple-fl)。
- en: 'Next, let’s import some standard ML libraries as well as client libraries from
    the FL code we discussed:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们导入一些标准的 ML 库以及我们讨论过的 FL 代码中的客户端库：
- en: '[PRE31]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In this case, we define `TrainingMetaData`, which just gives you the amount
    of training data that will be sent to the aggregator and used when conducting
    the `FedAvg` algorithm. The aggregation algorithm was discussed in [*Chapter 4*](B18369_04.xhtml#_idTextAnchor085),
    *Federated Learning Server Implementation with Python*, as well as in [*Chapter
    7*](B18369_07.xhtml#_idTextAnchor176), *Model Aggregation*:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们定义 `TrainingMetaData`，它只提供了将要发送给聚合器并在执行 `FedAvg` 算法时使用的数据量。聚合算法在 [*第
    4 章*](B18369_04.xhtml#_idTextAnchor085) *使用 Python 的联邦学习服务器实现* 以及在 [*第 7 章*](B18369_07.xhtml#_idTextAnchor176)
    *模型聚合* 中进行了讨论：
- en: '[PRE32]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The content of the `init_models` function is now replaced with a CNN that is
    converted into a NumPy array. It returns the template of the CNN in a dictionary
    format to inform the structure:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`init_models` 函数的内容现在被替换为一个转换为 NumPy 数组的 CNN。它以字典格式返回 CNN 的模板以告知结构：'
- en: '[PRE33]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The training function, `training`, is now filled with actual training algorithms
    using the CIFAR-10 dataset. It takes the models and `init_flag` as parameters
    and returns the trained models as `Dict[str,np.array]`. The `init_flag` is a `bool`
    value, where it is `True` if it’s at the initial step and `False` if it’s an actual
    training step. When preparing for the training data, we use a certain threshold
    for training due to batch size. In this case, the threshold is `4`.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 训练函数 `training` 现在填充了使用 CIFAR-10 数据集的实际训练算法。它以模型和 `init_flag` 作为参数，并将训练后的模型作为
    `Dict[str,np.array]` 返回。`init_flag` 是一个 `bool` 值，如果是初始步骤则为 `True`，如果是实际训练步骤则为
    `False`。在准备训练数据时，由于批量大小，我们使用一定的阈值进行训练。在这种情况下，阈值是 `4`。
- en: Then, we create a CNN-based cluster global model with `net = Converter.cvtr().convert_dict_nparray_to_nn(models)`.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 `net = Converter.cvtr().convert_dict_nparray_to_nn(models)` 创建一个基于 CNN
    的聚类全局模型。
- en: 'We define the loss function and optimizer as the following:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义损失函数和优化器如下：
- en: '[PRE34]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Then, the actual training will be conducted with `trained_net = execute_ic_training(DataManger.dm(),
    net, criterion, optimizer)`, where the actual code of the IC training can be found
    in the `ic_training.py` file.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，实际的训练将通过 `trained_net = execute_ic_training(DataManger.dm(), net, criterion,
    optimizer)` 进行，其中 IC 训练的实际代码可以在 `ic_training.py` 文件中找到。
- en: After the training, the converted models will be returned.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，将返回转换后的模型。
- en: 'The algorithm is summarized as follows:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 算法总结如下：
- en: '[PRE35]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following `compute_performance` function is filled with an algorithm to
    calculate the accuracy, which is simple enough – just divide the number of correct
    outcomes by the number of total labels. With a given set of models and a test
    dataset, it computes the performance of the models, with `models` and `testdata`
    as parameters:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的 `compute_performance` 函数填充了一个用于计算准确率的算法，这个算法足够简单——只需将正确结果的数量除以总标签的数量。给定一组模型和测试数据集，它使用
    `models` 和 `testdata` 作为参数计算模型的性能：
- en: '[PRE36]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The `judge_termination` and `prep_test_data` functions are the same as the functions
    of the minimal examples.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '`judge_termination` 和 `prep_test_data` 函数与最小示例中的函数相同。'
- en: Integration of client libraries into the IC example
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客户端库集成到 IC 示例中
- en: Now, everything is ready to start the IC algorithm, and all the code to integrate
    the preceding functions is the same as that used in the previous *Integration
    of client libraries into your local ML engine* section. Please look into the `classification_engine.py`
    file to make sure the code is the same, except for the part that shows the actual
    number of data samples that we are sending. This way, by just rewriting the preceding
    functions, you will be able to easily connect your own local ML application to
    the FL system that we have discussed here. Please refer to the *Running image
    classification and its analysis* section of [*Chapter 6*](B18369_06.xhtml#_idTextAnchor156),
    *Running the Federated Learning System and Analyzing the Results*, to check the
    results of running the code discussed in this section.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一切准备就绪，可以开始 IC 算法了，整合前面函数的所有代码与之前 *将客户端库集成到您的本地 ML 引擎* 部分中使用的代码相同。请查看 `classification_engine.py`
    文件，确保代码相同，除了显示我们实际发送的数据样本数量的部分。这样，通过仅重写前面的函数，您就可以轻松地将自己的本地 ML 应用程序连接到我们在这里讨论的
    FL 系统。请参阅 [*第 6 章*](B18369_06.xhtml#_idTextAnchor156) *运行联邦学习系统并分析结果* 中的 *运行图像分类及其分析*
    部分，以检查本节讨论的代码的运行结果。
- en: Summary
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed FL client-side implementation. There are three
    basic but important functionalities when participating in the FL process, receiving
    global models sent from an aggregator with a push or polling mechanism, and sending
    local models to an aggregator after the local training process. In order to effectively
    implement the client-side ML engines that cooperate with the FL aggregator, understanding
    the client state is important. The client states include a state waiting for the
    global model, a state indicating that local training is happening, a state showing
    the readiness to send local models, and a state for having the updated global
    models.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了联邦学习（FL）的客户端实现。在参与FL过程中有三个基本但重要的功能：通过推送或轮询机制接收来自聚合器的全局模型，以及在本地训练过程结束后向聚合器发送本地模型。为了有效地实现与FL聚合器合作的客户端机器学习引擎，理解客户端状态非常重要。客户端状态包括等待全局模型的状态、表示本地训练正在进行的状态、显示准备发送本地模型的状态，以及拥有更新后的全局模型的状态。
- en: We also discussed the design philosophy of FL client-side libraries, where the
    core functions need to be effectively packaged to provide user-friendly interfaces
    for ML developers and engineers.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了FL客户端库的设计理念，其中核心功能需要有效地打包，以提供对机器学习开发人员和工程师友好的接口。
- en: Last but not least, we learned how to actually use the FL client libraries to
    integrate a local ML engine into an FL system, where we used the minimal dummy
    example and IC example to understand the integration process itself.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我们学习了如何实际使用FL客户端库将本地机器学习引擎集成到FL系统中，其中我们使用了最小示例和IC示例来理解集成过程本身。
- en: In the next chapter, we will actually run the code that was introduced in this
    and previous chapters so that we can dig into what is happening with the models,
    which are aggregated with a minimal example as well as an IC example.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将实际运行本章和前几章中介绍过的代码，以便我们可以深入了解模型的情况，这些模型通过最小示例以及IC示例进行聚合。
