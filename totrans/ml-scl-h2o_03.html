<html><head></head><body>
		<div id="_idContainer019">
			<h1 id="_idParaDest-25"><em class="italic"><a id="_idTextAnchor024"/>Chapter 2</em>: Platform Components and Key Concepts</h1>
			<p>In this chapter, we will gain a fundamental understanding of the components of H2O's machine learning at scale technology. We will view a simple code example of H2O machine learning, understand what it does, and identify any problems the example has with machine learning at an enterprise scale. This <em class="italic">Hello World</em> code example will serve as a simple representation in which to build our understanding further. </p>
			<p>We will overview each H2O component of machine learning at scale, identify how each component achieves scale, and identify how each component relates to our simple code snippet. Then, we will tie these components together into a reference machine learning workflow using these components. Finally, we will focus on the underlying key concepts that arise from these components. The understanding obtained in this chapter will be foundational to the rest of the book, where we will be implementing H2O technology to build and deploy state-of-the-art machine learning models at scale in an enterprise setting.</p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Hello World – the H2O machine learning code</li>
				<li>The components of H2O machine learning at scale </li>
				<li>The machine learning workflow using these H2O components</li>
				<li>H2O key concepts</li>
			</ul>
			<h1 id="_idParaDest-26"><a id="_idTextAnchor025"/>Technical requirements</h1>
			<p>For this chapter, you will need to install H2O-3 locally to run through a bare minimum <em class="italic">Hello World</em> workflow. To implement it, follow the instructions in the <a href="B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268"><em class="italic">Appendix</em></a>. Note that we will use the Python API throughout the book, so follow the instructions to install it in Python.</p>
			<h1 id="_idParaDest-27"><a id="_idTextAnchor026"/>Hello World – the H2O machine learning code</h1>
			<p>H2O Core is <a id="_idIndexMarker042"/>designed for machine learning at scale; however, it can also be used on small datasets on a user's laptop. In the following section, we will use a minimal code example of H2O-3 to build a machine learning model and export it as a deployable artifact. We will use this example to serve as the most basic unit to understand H2O machine learning code, much like viewing a human stick figure to begin learning about human biology.</p>
			<h2 id="_idParaDest-28"><a id="_idTextAnchor027"/>Code example</h2>
			<p>Take a look at the<a id="_idIndexMarker043"/> code examples that follow. Here, we are writing in Python, which could be from Jupyter, PyCharm, or another Python client. We will learn that R and Java/Scala are alternative languages in which to write H2O code.</p>
			<p>Let's start by importing the H2O library:</p>
			<pre class="source-code">import h2o</pre>
			<p>Recall from the documentation that this has been downloaded from H2O and installed in the client or an IDE environment. This <strong class="source-inline">h2o</strong> package allows us to run H2O in-memory distributed machine learning from the IDE using the H2O API written in Python. </p>
			<p>Next, we create an H2O cluster:</p>
			<pre class="source-code">h2o.init(ip="localhost", port=54323)</pre>
			<p>The preceding line of code creates what is<a id="_idIndexMarker044"/> called An <strong class="bold">H2O cluster</strong>. This is a key concept underlying H2O's model building technology. It is a distributed in-memory architecture. In the <em class="italic">Hello World</em> case, the H2O cluster will be created on the laptop as localhost and will not be distributed. We will learn more about the H2O cluster in the <em class="italic">H2O key concepts</em> section of this chapter.</p>
			<p>The <strong class="source-inline">ip</strong> and <strong class="source-inline">port</strong> configurations that are used to start the H2O cluster should provide sufficient clues that the H2O code will be sent via an API to the compute environment, which could be inside a data center or the cloud for an enterprise environment. However, here, it is on our localhost.</p>
			<p>Then, we import a dataset:</p>
			<pre class="source-code">loans = h2o.import_file("https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/main/chapt2/loans-lite.csv")</pre>
			<p>Now we explore the dataset: </p>
			<pre class="source-code">loans.describe()</pre>
			<p>This is a <a id="_idIndexMarker045"/>minimal amount of data exploration. It simply returns the number of rows and columns.</p>
			<p>Okay, now let's prepare the data for our model:</p>
			<pre class="source-code">train, validation = loans.split_frame(ratios=[0.75])</pre>
			<pre class="source-code">label = "bad_loan"</pre>
			<pre class="source-code">predictors = loans.col_names</pre>
			<pre class="source-code">predictors.remove(label)</pre>
			<p>We have split the data into training and validation sets, with a <strong class="source-inline">0.75</strong> proportion for training. We are going to predict whether a loan will be bad or not (that is, whether it will default or not) and have identified this column as the label. Finally, we define the columns used to predict bad loans by using all columns in the dataset except the bad loan column.</p>
			<p>Now, we build the model:</p>
			<pre class="source-code">from h2o.estimators import H2OXGBoostEstimator</pre>
			<pre class="source-code">param = {"ntrees" : 25, "nfolds" : 10}</pre>
			<pre class="source-code">xgboost_model = H2OXGBoostEstimator(**param)</pre>
			<pre class="source-code">xgboost_model.train(x = predictors,</pre>
			<pre class="source-code">                    y = label,</pre>
			<pre class="source-code">                    training_frame = train,</pre>
			<pre class="source-code">                    validation_frame = validation)</pre>
			<p>We have imported H2O's <strong class="bold">XGBoost</strong> module <a id="_idIndexMarker046"/>and configured two hyperparameters for it. Then, we started the model training by inputting references into the predictor column, label column, training data, and testing data.</p>
			<p>XGBoost is <a id="_idIndexMarker047"/>one of many widely recognized and extensively used machine learning algorithms packaged in the <strong class="source-inline">h2o</strong> module. The H2O API exposed by this module will run the XGBoost model in H2O's architecture on the enterprise infrastructure, as we will learn later. Regarding hyperparameters, we will discover that H2O offers an extensive set of hyperparameters to configure for each model. </p>
			<p>When the model finishes, we can export the model using one line of code:</p>
			<pre class="source-code">xgboost_model.download_mojo(path="~/loans-model", get_genmodel_jar=True)</pre>
			<p>The exported scoring artifact is now ready to pass to DevOps to deploy. The <strong class="source-inline">get_genmodel_jar=True</strong> parameter triggers the download to include <strong class="source-inline">h2o-genmodel.jar</strong>. This is a library used by the model for scoring outside of an H2O cluster, that is, in a production environment. We will learn more about productionizing H2O models in <em class="italic">Section 3 – Deploying Your Models to Production Environments</em>.</p>
			<p>We are done with model building, for now. So, we will shut down the cluster:</p>
			<pre class="source-code">h2o.cluster().shutdown()</pre>
			<p>This frees up the resources that the H2O cluster has been using.</p>
			<p>Bear in mind that this is a simple <em class="italic">Hello World</em> H2O model building example. It is meant to do both of the following: </p>
			<ul>
				<li>Give a bare minimum introduction to H2O model building.</li>
				<li>Serve as a basis to discuss issues of scale in the enterprise, which we will do in the next section. </li>
			</ul>
			<p>In <em class="italic">Section 2 – Building State-of-the-Art Models on Large Data Volumes Using H2O</em>, we will explore extensive techniques to build highly predictive and explainable models at scale. Let's start our journey by discussing some issues of scale that our <em class="italic">Hello World</em> example exposes.</p>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor028"/>Some issues of scale</h2>
			<p>This<a id="_idIndexMarker048"/> <em class="italic">Hello World</em> code will not scale well in an enterprise setting. Let's revisit the code to better understand these scaling constraints.</p>
			<p>We import the library in our IDE code:</p>
			<pre class="source-code">import h2o</pre>
			<p>Most enterprises want to have some control over the versions of libraries that are used. Additionally, they usually want to provide a central platform to host and authenticate all users of a piece of technology and to have administrators manage that platform. We will discover that Enterprise Steam plays a key role in centrally managing users and H2O environments.</p>
			<p>We initialize the H2O cluster:</p>
			<pre class="source-code">h2o.init(ip="localhost", port=54323)</pre>
			<p>Machine learning at scale requires the distribution of compute resources across a server cluster to achieve horizontal scaling (that is, divide-and-conquer compute resources across many servers). Therefore, the IP address and port should point to a member of a server cluster and not to a single computer, as demonstrated in this example. We will see that H2O Core creates its own self-organized cluster that distributes and horizontally scales model building.</p>
			<p>Since scaling is on the enterprise server cluster, which, typically, is used by many individuals and groups, enterprises want to control user access to this environment along with the number of resources consumed by users. But then what would prevent a user from launching multiple H2O clusters, using as many resources as possible on each, and thus, blocking resource availability from other users? Enterprise Steam manages H2O user and H2O resource consumption on the enterprise server cluster.</p>
			<p>We import the dataset:</p>
			<pre class="source-code">loans = h2o.import_file("https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/main/chapt2/loans-lite.csv")</pre>
			<p>Data at large volumes takes an exceedingly long time to move over the network, taking hours or days to complete a transfer, or it could time out beforehand. Computation during model building at scale should occur where the data resides to prevent this bottleneck in data movement. We will discover that H2O clusters that are launched on the enterprise system ingest data from the storage layer directly into server memory. Because data is partitioned across the servers that comprise an H2O cluster, data ingest occurs in parallel to those partitions.</p>
			<p>We will see <a id="_idIndexMarker049"/>how Enterprise Steam centralizes user authentication and how the user's identity is passed to the enterprise system where its native authorization mechanism is honored. </p>
			<p>We train the model:</p>
			<pre class="source-code">xgboost_model.train(x = predictors,</pre>
			<pre class="source-code">                    y = label,</pre>
			<pre class="source-code">                    training_frame = train,</pre>
			<pre class="source-code">                    validation_frame = validation)</pre>
			<p>Of course, this is the heart of the model building process and, likewise, the focus of much of this book: how to build world-class machine learning models against large data volumes using H2O's extensive machine learning algorithm and model building capabilities.</p>
			<p>We download the deployable model:</p>
			<pre class="source-code">xgboost_model.download_mojo(path="~/loans-model", get_genmodel_jar=True)</pre>
			<p>Bear in mind that, from a business standpoint, value is not achieved until a model is exported and deployed into production. Doing so involves the complexities of multiple enterprise stakeholders. We will learn how the design and capabilities of the exported <strong class="bold">MOJO</strong> (<strong class="bold">Model Object, Optimized</strong>) facilitate<a id="_idIndexMarker050"/> the ease of deployment to diverse software systems involving these stakeholders. </p>
			<p>We shut down the H2O cluster:</p>
			<pre class="source-code">h2o.cluster().shutdown()</pre>
			<p>An H2O cluster uses resources and should be shut down when not in use. If this is not done, other users or jobs on the enterprise system could be competing for these resources and, consequently, become impacted. Additionally, fewer new users can be added to the system before the infrastructure must be expanded. We will see that Enterprise Steam governs how H2O users consume resources on the enterprise system. The resulting gain in resource efficiency allows H2O users and their work to scale more effectively on a <a id="_idIndexMarker051"/>given allocation of infrastructure.</p>
			<p>Now that we have run our <em class="italic">Hello World</em> example and explored some of its issues regarding scale, let's move on to gain an understanding of H2O components for machine learning model building and deployment at scale.</p>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor029"/>The components of H2O machine learning at scale</h1>
			<p>As introduced <a id="_idIndexMarker052"/>in the previous chapter and emphasized throughout this book, H2O machine learning overcomes problems of scale. The following is a brief introduction of each component of H2O machine learning at scale and how each overcomes these challenges. </p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor030"/>H2O Core – in-memory distributed model building</h2>
			<p>H2O Core <a id="_idIndexMarker053"/>allows a data scientist to write code to build <a id="_idIndexMarker054"/>models using well-known machine learning algorithms. The coding experience is through an H2O API expressed in Python, R, or Java/Scala language and written in their favorite client or IDE, for example Python in a Jupyter notebook. The actual computation of model building, however, takes place on an enterprise server cluster (not the IDE environment) and leverages the server cluster's vast pool of memory and CPUs needed to run machine learning algorithms against massive data volumes.  </p>
			<p>So, how does this work? First, data used for model building is partitioned and distributed in memory by H2O on the server cluster. The IDE sends H2O instructions to the server cluster. A server in the cluster receives these instructions and distributes them to the other servers in the cluster. The instructions are run in parallel on the partitioned in-memory data. The server that received the instructions gathers and combines the results and sends them back to the IDE. This is done repeatedly as code is sequenced through the IDE.</p>
			<p>This <em class="italic">divide and conquer</em> approach<a id="_idIndexMarker055"/> is fundamental to H2O model building at scale. A unit of H2O divide and conquer architecture is called an H2O cluster and is elaborated as a <em class="italic">key concept</em> later in the chapter. The result is rapid model building on large volumes of data.</p>
			<h3>The key features of H2O Core </h3>
			<p>Some of the<a id="_idIndexMarker056"/> key features of H2O Core are as follows:</p>
			<ul>
				<li><strong class="bold">Horizontal scaling</strong>: Data operations <a id="_idIndexMarker057"/>and machine learning algorithms are distributed in parallel and in memory, with additional optimizations such as a distributed key/value store to rapidly access data and objects during model building.</li>
				<li><strong class="bold">Familiar experience</strong>: Data<a id="_idIndexMarker058"/> scientists use familiar languages and IDEs to write H2O API code, as we have just done.</li>
				<li><strong class="bold">Open source</strong>: H2O Core <a id="_idIndexMarker059"/>is open source.</li>
				<li><strong class="bold">Wide range of file formats</strong>: H2O<a id="_idIndexMarker060"/> supports a wide range of source data formats.</li>
				<li><strong class="bold">Data manipulation</strong>: The <a id="_idIndexMarker061"/>H2O API includes a wide range of tasks commonly performed to prepare data for machine learning. Sparkling Water (covered in the next section) extends data engineering techniques to Spark.</li>
				<li><strong class="bold">Well-recognized machine learning algorithms</strong>: H2O uses a wide range of well-recognized <a id="_idIndexMarker062"/>supervised and unsupervised machine learning algorithms.</li>
				<li><strong class="bold">Training, testing, and evaluation</strong>: Extensive techniques in cross-validation, grid search, variable<a id="_idIndexMarker063"/> importance, and performance<a id="_idIndexMarker064"/> metrics are used to train, test, and <a id="_idIndexMarker065"/>evaluate models; this also includes model checkpointing capabilities. </li>
				<li><strong class="bold">Automatic Machine Learning (AutoML)</strong>: The H2O Core AutoML API provides a<a id="_idIndexMarker066"/> simple wrapper function to concisely automate the training and tuning of multiple models, including stacked ensembling, and present results in a leaderboard.</li>
				<li><strong class="bold">Model explainability</strong>: It <a id="_idIndexMarker067"/>offers extensive local and global explainability methods and visualizations for single models or those involved in AutoML, all from a single wrapper function.</li>
				<li><strong class="bold">AutoDoc</strong>: It <a id="_idIndexMarker068"/>enables <a id="_idIndexMarker069"/>the automated generation of standardized Word documents, extensively describing model building and explainability in detail; note that AutoDoc is not available as a free open source platform.</li>
				<li><strong class="bold">Exportable scoring artifact (MOJO)</strong>: It uses a single line of code to export the model as a<a id="_idIndexMarker070"/> deployable scoring artifact (model deployment will be discussed in greater detail in <em class="italic">Section 3 – Deploying Your Models to Production Environments</em>). </li>
				<li><strong class="bold">H2O Flow Web UI</strong>: This<a id="_idIndexMarker071"/> is an optional web-based interactive UI to guide users through the model building workflow in an easy yet rich point-and-click experience, which is useful for the rapid experimentation and prototyping of H2O models. </li>
			</ul>
			<h3>H2O-3 and H2O Sparkling Water</h3>
			<p>H2O Core comes in<a id="_idIndexMarker072"/> two flavors: <strong class="bold">H2O-3</strong> and <strong class="bold">H2O Sparkling Water</strong>.</p>
			<p>H2O-3 is H2O Core, as<a id="_idIndexMarker073"/> described in the previous section. H2O Sparkling Water is H2O-3 wrapped <a id="_idIndexMarker074"/>by Spark integration. It is identical to H2O-3 along with the<a id="_idIndexMarker075"/> following additional capabilities:</p>
			<ul>
				<li><strong class="bold">Seamless integration of Spark and H2O API code</strong>: The user writes both Spark and H2O code in the same IDE; for example, using SparkSQL code to engineer data and H2O code to build world-class models.</li>
				<li><strong class="bold">Conversion between H2O and Spark DataFrames</strong>: H2O and Spark DataFrames <a id="_idIndexMarker076"/>interconvert as part of the seamless integration; therefore, the results of SparkSQL data munging can be used as input to H2O model building.</li>
				<li><strong class="bold">Spark engine</strong>: Sparkling Water runs as a native Spark application on the Spark framework.</li>
			</ul>
			<p>H2O-3 and Sparkling Water <a id="_idIndexMarker077"/>are the model building alternatives of the more general H2O Core. The concept of the H2O cluster launched on the larger enterprise server cluster is similar for <a id="_idIndexMarker078"/>both<a id="_idIndexMarker079"/> H2O Core flavors, though some implementation details differ, which are essentially invisible to the data scientist. As mentioned, Sparkling Water is particularly useful for integrating Spark data engineering and H2O model building workflows.</p>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor031"/>H2O Enterprise Steam – a managed, self-provisioning portal</h2>
			<p>Enterprise Steam<a id="_idIndexMarker080"/> provides a centralized web UI and<a id="_idIndexMarker081"/> API for data scientists to initialize and terminate their H2O environments (called H2O clusters) and for administrators to manage H2O users and H2O integration with the enterprise server cluster. </p>
			<h3>The key features of Enterprise Steam </h3>
			<p>The key features<a id="_idIndexMarker082"/> of Enterprise steam are as follows:</p>
			<ul>
				<li><strong class="bold">Data science self-provisioning</strong>: This<a id="_idIndexMarker083"/> is an easy, UI-based way for data scientists to manage their H2O environments.</li>
				<li><strong class="bold">Central access point for all H2O users</strong>: This creates the ease of H2O user management and a<a id="_idIndexMarker084"/> single entry point for H2O access to the enterprise server cluster.</li>
				<li><strong class="bold">Govern user resource consumption</strong>: Administrators build profiles of resource<a id="_idIndexMarker085"/> usage boundaries that are assigned to users or user groups. This places limits on the number of resources a user can allocate on the enterprise server cluster. </li>
				<li><strong class="bold">Seamless security</strong>: User <a id="_idIndexMarker086"/>authentication<a id="_idIndexMarker087"/> to Enterprise Steam flows through to the authorization of resources on the enterprise server cluster. Enterprise Steam authenticates against the same identity provider (for example, LDAP) that is used by the enterprise server cluster.</li>
				<li><strong class="bold">Configure integration</strong>: The <a id="_idIndexMarker088"/>administrator configures the integration of H2O with the enterprise server cluster and identity provider.</li>
				<li><strong class="bold">Manage H2O Core versions</strong>: The<a id="_idIndexMarker089"/> administrator manages one or more H2O Core versions that data scientists use to create H2O clusters for model building.</li>
			</ul>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor032"/>The H2O MOJO – a flexible, low-latency scoring artifact</h2>
			<p>The<a id="_idIndexMarker090"/> models<a id="_idIndexMarker091"/> built from H2O Core are exported as deployable scoring artifacts called H2O MOJOs. MOJOs can run in any JVM environment (except, perhaps, the very smallest edge devices). </p>
			<p>In <em class="italic">Section 3 – Deploying Your Models to Production Environments</em>, we will learn that MOJOs are ready to deploy directly to H2O software as well as many third-party scoring solutions with no coding required. However, if you wish to directly embed MOJOs into your own software, there is a MOJO Java API to build Java helper classes to expose MOJO capabilities (for example, output reason codes in addition to a prediction) and to provide flexible integration with your scoring input and output. </p>
			<p>MOJOs, out of all models, regardless of the machine learning algorithm used to build the model, are identical in<a id="_idIndexMarker092"/> construct. Therefore, deployment from a DevOps perspective is repeatable and automatable.</p>
			<h3>The key features of MOJOs </h3>
			<p>The <a id="_idIndexMarker093"/>key features of the MOJO are as follows:</p>
			<ul>
				<li><strong class="bold">Low latency</strong>: Typically, this is less than 100 milliseconds for each scoring.</li>
				<li><strong class="bold">Flexible data speeds</strong>: Mojos can make predictions on batch, real time, and streaming data (for example on entire database tables, as REST endpoints and Kafka topics, respectively, to name a few examples).</li>
				<li><strong class="bold">Flexible target systems</strong>: This fits into JVM runtimes, including JDBC clients, <strong class="bold">REST servers</strong>, <strong class="bold">AWS Lambda</strong>, <strong class="bold">AWS SageMaker</strong>, <strong class="bold">Kafka queues</strong>, <strong class="bold">Flink streams</strong>, Spark<a id="_idIndexMarker094"/> pipelines<a id="_idIndexMarker095"/> including streaming, Hive UDF, Snowflake's external functions, and more. Target systems can be <a id="_idIndexMarker096"/>specialized <a id="_idIndexMarker097"/>H2O scoring software, third-party scoring <a id="_idIndexMarker098"/>software, or your own software. A common pattern is to deploy the MOJO to a REST server and consume its predictions via REST calls from a client application (for example, an Excel spreadsheet).</li>
				<li><strong class="bold">Explainability features</strong>: In addition to predictions, you can receive K-Lime or Shapley reason codes from the MOJO during live scoring, and you can load the MOJO into H2O Core to score and inspect MOJO attributes.</li>
				<li><strong class="bold">Repeatable deployments</strong>: MOJOs are easy to integrate into existing deployment automation (CI/CD) pipelines used by the organization for software deployment.</li>
			</ul>
			<p>Note that there is an alternative to the<a id="_idIndexMarker099"/> H2O MOJO, called <strong class="bold">POJO</strong>, which is used for infrequent edge cases. This will be explored further in <a href="B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137"><em class="italic">Chapter 8</em></a>, <em class="italic">Putting It All Together</em>.</p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor033"/>The workflow using H2O components</h1>
			<p>Now that we understand the roles and key features of H2O's machine learning at scale components, let's <a id="_idIndexMarker100"/>tie them together into a high-level workflow, as represented in the following diagram: </p>
			<div>
				<div id="_idContainer013" class="IMG---Figure">
					<img src="image/B16721_Figure_2.1.jpg" alt="Figure 2.1 – A high-level machine learning at scale workflow with H2O&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1 – A high-level machine learning at scale workflow with H2O</p>
			<p>The workflow occurs in the following sequence:</p>
			<ol>
				<li>The administrator configures <strong class="bold">H2O Enterprise Steam</strong>.</li>
				<li>The data scientist logs into <strong class="bold">H2O Enterprise Steam</strong> and launches the <strong class="bold">H2O Core</strong> cluster (choosing either <strong class="bold">H2O-3</strong> or <strong class="bold">H2O Sparkling Water</strong>).</li>
				<li>The data scientist uses their favorite client to build models using the Python, R, or Java/Scala language flavor of the H2O model building API. The data scientist uses a UI or IDE to authenticate to <strong class="bold">H2O Enterprise Steam</strong> and connect to the <strong class="bold">H2O cluster</strong> that was started on H2O Enterprise Steam.</li>
				<li>The data scientist uses the IDE to iterate through the model building steps with H2O.</li>
				<li>After the data scientist decides on the model to be deployed, <strong class="bold">H2O</strong> <strong class="bold">AutoDoc</strong> is generated, and <strong class="bold">H2O MOJO</strong> is exported from the IDE.</li>
				<li>The data scientist either terminates the <strong class="bold">H2O cluster</strong> or waits for <strong class="bold">H2O Enterprise Steam</strong> to do so after the idle or absolute uptime duration has been exceeded. These durations have been configured in a resource profile assigned to the user by the administrator. Note that the terminated cluster checkpoints do work, and a new <strong class="bold">H2O cluster</strong> can always be launched to continue working from the termination point.</li>
				<li>The model<a id="_idIndexMarker101"/> is exported as <strong class="bold">H2O MOJO</strong> and is deployed to any of a diverse set of hosting targets. The model is consumed in a business context and achievement of the business value begins.</li>
			</ol>
			<h1 id="_idParaDest-35"><a id="_idTextAnchor034"/>H2O key concepts</h1>
			<p>In the following sections, we will identify and describe the key concepts of H2O that underlie the workflow steps of the previous section. These concepts are necessary to understand the rest of the book.</p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor035"/>The data scientist's experience</h2>
			<p>The <a id="_idIndexMarker102"/>data scientist has a familiar experience in building H2O models at scale while being abstracted from the complexities of the infrastructure and architecture on the enterprise server cluster. This is further detailed in the following diagram:</p>
			<div>
				<div id="_idContainer014" class="IMG---Figure">
					<img src="image/B16721_Figure_2.2.jpg" alt="Figure 2.2 – Details of the data scientist's experience with H2O Core&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2 – Details of the data scientist's experience with H2O Core</p>
			<p>Data scientists <a id="_idIndexMarker103"/>use well-known unsupervised and supervised machine learning techniques that scale across the enterprise's distributed infrastructure and architecture. These techniques are written with the H2O model building API, which is written in familiar languages (such as Python, R, or Java) using familiar IDEs (for example, Jupyter or RStudio). </p>
			<p class="callout-heading">H2O Flow – A Convenient, Optional UI</p>
			<p class="callout">H2O generates its own web UI called H2O Flow, which is optional to use during model building. H2O Flow's UI focus and richness of features can be used for a full model building workflow or to leverage for handy tricks, as we will demonstrate in <a href="B16721_05_Final_SK_ePub.xhtml#_idTextAnchor082"><em class="italic">Chapter 5</em></a>, <em class="italic">Advanced Model Building – Part 1</em>. </p>
			<p>Therefore, the data scientist works in a familiar world that connects to a complex architecture to scale model building to large or massive datasets. We will explore this architecture in the next section.</p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor036"/>The H2O cluster</h2>
			<p>The <a id="_idIndexMarker104"/>H2O cluster is perhaps the most central concept for all stakeholders to understand. It is how H2O creates its unit of architecture for building machine learning models on the enterprise server cluster. We can understand this <a id="_idIndexMarker105"/>concept using the following diagram: </p>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B16721_Figure_2.3.jpg" alt="Figure 2.3 – The architecture of the H2O cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3 – The architecture of the H2O cluster</p>
			<p>When a data scientist launches an H2O cluster, they specify the number of servers to distribute the work across (which is also known as the number of <em class="italic">nodes</em>), along with the amount of memory and CPUs to use for each node. We will learn that this can be done by configuring manually or by allowing Enterprise Steam to auto compute these specifications based on the volume of training data.</p>
			<p>When the H2O cluster is launched, the IDE pushes H2O software (a single JAR file) to each specified number of nodes in the enterprise server cluster, where each node allocates the specified memory and CPU. Then, the H2O software organizes into a self-communicating cluster with one node elected as the leader that communicates with the IDE and coordinates with the remainder of the H2O cluster.</p>
			<p>The data scientist connects to the launched H2O cluster from the IDE. Then, the data scientist writes the model building code. Each part of the code is translated by the H2O library in the IDE into instructions to the H2O cluster. Each instruction is sent, in sequence, to the leader node on the H2O cluster, which distributes it to other H2O cluster members where the instructions are executed in parallel. The leader node gathers and combines the results and sends them back to the IDE. </p>
			<p>Here are<a id="_idIndexMarker106"/> some important notes to bear in mind:</p>
			<ul>
				<li>Data is ingested directly from the data source to the memory of the H2O nodes. Source data is partitioned between the H2O nodes and not duplicated among them. Data ingested from the storage layer (for example, S3, HDFS, and more) is done in parallel and, therefore, is fast. Data from external sources (for example, the GitHub repository and the JDBC database tables) is not done in parallel. In all cases, data does not pass through the IDE or the client.</li>
				<li>Each H2O cluster is independent and isolated from the others, including the data ingested into them. Thus, two users launching a cluster and using the same data source do not share data.</li>
				<li>We will<a id="_idIndexMarker107"/> see that administrators of Enterprise Steam assign upper limits on the number of concurrent clusters that users can launch, along with the amount of memory, CPU, and other resources a user can specify when launching a cluster.</li>
				<li>H2O clusters are static. Once launched, the number of nodes and the number of resources per node do not change until they are terminated, in which case the H2O cluster is torn down. If one of the nodes goes down, the H2O cluster must be restarted and model building steps from the IDE started from the beginning. For longer durations of work, H2O's checkpointing feature helps you to continue from a restore point.</li>
			</ul>
			<p>Let's look at the<a id="_idIndexMarker108"/> life cycle of an H2O cluster, as shown in the following diagram:</p>
			<div>
				<div id="_idContainer016" class="IMG---Figure">
					<img src="image/B16721_Figure_2.4.jpg" alt="Figure 2.4 – The life cycle of the H2O cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4 – The life cycle of the H2O cluster</p>
			<p>Let's look at each of <a id="_idIndexMarker109"/>the stages of the life cycle, one by one, to understand how they work:</p>
			<ol>
				<li value="1"><strong class="bold">Launch</strong>: The data scientist launches an H2O cluster from the Enterprise Steam UI or API. H2O-3 or Sparkling Water is chosen. The H2O cluster size and resources (that is, the number of nodes, memory per node, and other configurations) are manually input, or they are automatically generated by Enterprise Steam based on the data volume input by the user. The H2O cluster is formed as described earlier. </li>
				<li><strong class="bold">Connect to</strong>: The data scientist switches to their IDE and connects to the H2O cluster by specifying its name.</li>
				<li><strong class="bold">Build models on</strong>: The data scientist builds models using H2O. The H2O library used in the IDE translates the H2O API code for each model building iteration into instructions. These are sent to the leader node and distributed across the H2O cluster.</li>
				<li><strong class="bold">Stop</strong>: The H2O cluster is shut down. Resources are released, and the H2O software is removed from each node of the H2O cluster. This can be done by the user from the IDE or can occur automatically after a duration of idle time or when the absolute running time of the H2O cluster has been exceeded (these durations were specified in the H2O cluster launch during step 1 of the life cycle). Though not running, information regarding this cluster is still available to the user (for example, the name, the H2O version, and the size). </li>
			</ol>
			<p><strong class="bold">Stop/Save Data &amp; Restart</strong>: This is an alternative to <strong class="bold">Stop</strong> and is possible when the Enterprise Steam administrator configures this option for a user or user group. In this case, when the H2O cluster is stopped, it saves data from the model <a id="_idIndexMarker110"/>building steps (that is, it saves the model building state) to the storage layer. When the cluster is restarted (using the same name as when it was launched), the cluster is launched and returned to its previous state. </p>
			<ol>
				<li value="5"><strong class="bold">Delete</strong>: This stops the cluster (if running) and permanently deletes all references to the H2O cluster. If it has been stopped with the model building state saved, this data will be permanently deleted as well. </li>
			</ol>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor037"/>Enterprise Steam as an H2O gateway</h2>
			<p>All<a id="_idIndexMarker111"/> H2O administration activities occur on Enterprise Steam, and users must launch H2O clusters through Steam. This <em class="italic">all roads lead to Enterprise Steam</em> approach means that Steam governs users and their H2O clusters before they are launched on the enterprise system. This is detailed in the following diagram:</p>
			<div>
				<div id="_idContainer017" class="IMG---Figure">
					<img src="image/B16721_Figure_2.5.jpg" alt="Figure 2.5 – Enterprise Steam viewed as an H2O gateway to the enterprise cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.5 – Enterprise Steam viewed as an H2O gateway to the enterprise cluster</p>
			<p>Administrators <a id="_idIndexMarker112"/>configure settings to manage H2O users and integrate Enterprise Steam with the enterprise server cluster. Additionally, administrators store H2O software versions that will be pushed to the server cluster when H2O clusters are launched and removed when the cluster is stopped and the resources are released. Administrators also have access to user usage data. This is all done through an administration-only UI.</p>
			<p>Administrators configure users and how users launch H2O clusters in the enterprise environment. These configurations define limits on the number of concurrent clusters a user can launch simultaneously, the size (that is, the number of nodes), and the number of resources (for example, memory per node) allocated for each H2O cluster that is launched. Configurations also define when the cluster will stop or delete if the user does not do so manually from the H2O model building code in the IDE. A set of such configurations is defined as a profile, and one or more profiles are assigned to users or user groups. Therefore, administrators can assign some users as power users and others as light users.</p>
			<p>Users authenticate to Enterprise Steam via the same identity provider (for example, LDAP) that was implemented to authorize access to resources on the enterprise server cluster environment (for example, S3 buckets). Enterprise Steam passes the user identity when<a id="_idIndexMarker113"/> the user launches a cluster, and this identity is used during authorization challenges on the enterprise system. Users in their IDEs must authenticate against the Enterprise Steam API to connect to the clusters they have launched.</p>
			<p class="callout-heading">Does H2O Core Require Enterprise Steam?</p>
			<p class="callout">Note that H2O core does not require Enterprise Steam. Enterprise administrators can configure their enterprise server cluster infrastructure to allow H2O clusters to be launched on this infrastructure. </p>
			<p class="callout">However, this approach is not a sound enterprise practice. It introduces a loss of control and governance that Enterprise Steam provides as a centralized H2O gateway to secure, manage, and log users, as elaborated in this section. Additionally, Enterprise Steam provides benefits to users by freeing them from the technical steps involved with integrating H2O Core with the enterprise cluster when launching H2O clusters, for example, Kerberos security requirements. The enterprise benefits of Enterprise Steam are explored in greater detail in <a href="B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207"><em class="italic">Chapter 11</em></a>, <em class="italic">The Administrator and Operations Views</em>, and in <a href="B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226"><em class="italic">Chapter 12</em></a>, <em class="italic">The Enterprise Architect and Security Views</em>.</p>
			<p class="callout">Also, bear in mind that H2O Core is free and open source, whereas Enterprise Steam is not.</p>
			<h2 id="_idParaDest-39"><a id="_idTextAnchor038"/>Enterprise Steam and the H2O Core high-level architecture</h2>
			<p>Now that<a id="_idIndexMarker114"/> we know how H2O clusters are formed and the role Enterprise Steam plays in administering H2O users and launching H2O clusters, let's understand Enterprise Steam and the H2O Core architecture from a high-level deployment perspective. The following diagram describes this deployment architecture:</p>
			<div>
				<div id="_idContainer018" class="IMG---Figure">
					<img src="image/B16721_Figure_2.6.jpg" alt="Figure 2.6 – Enterprise Steam and the H2O Core high-level deployment architecture&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.6 – Enterprise Steam and the H2O Core high-level deployment architecture</p>
			<p>Enterprise Steam<a id="_idIndexMarker115"/> runs on its own dedicated server that communicates with the enterprise server cluster via HTTP(S). As mentioned earlier, Enterprise Steam stores the H2O Core (H2O-3 or Sparkling Water) JAR file that is pushed to the server cluster, which then self-organizes into a coordinated but distributed H2O cluster. This H2O cluster can be a native YARN or Kubernetes job, depending on which backend is implemented. Note that H2O-3 is run on a Map-Reduce framework, and Sparkling Water is run on the Spark framework.</p>
			<p>An H2O-3 or Sparkling Water API library is installed to the data science IDE (for example, a <strong class="source-inline">pip install</strong> of the H2O-3 package in the Jupyter environment). It must match the version that is used to launch the cluster from Enterprise Steam. As mentioned previously, data scientists use the IDE to authenticate to Enterprise Steam, connect to the H2O cluster, and write H2O model building code. The H2O model building code is translated by the H2O client library into a REST message that is sent to the H2O cluster's leader node. Then, the work is distributed across the H2O cluster, and the results are returned to the IDE.</p>
			<p>Note that enterprise clusters can be on-premise, cloud infrastructure-as-a-service, or managed service implementations. They can be, for example, Kubernetes or Cloudera CDH on-premise or in the cloud, or Cloudera CDP or Amazon EMR in the cloud. The full deployment<a id="_idIndexMarker116"/> possibilities are discussed in more detail in <a href="B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226"><em class="italic">Chapter 12</em></a>, <em class="italic">The Enterprise Architect and Security Views</em>.</p>
			<p class="callout-heading">H2O Platform Choices</p>
			<p class="callout">H2O At Scale technology in this book is referred to as comprising: H2O Enterprise Steam + H2O Core (H2O-3, H2O Sparkling Water) + H2O MOJO. H2O At Scale integrates with an enterprise server cluster for model building and an enterprise scoring environment for model deployment.</p>
			<p class="callout">H2O At Scale can be implemented with the just mentioned components alone. Alternatively, H2O At Scale can be implemented as a subset of the larger H2O machine learning platform and capability set called H2O AI Cloud. The H2O AI Cloud platform is described in greater detail in <em class="italic">Section 5 – Broadening the View – Data to AI Applications with the H2O AI Cloud Platform</em>. </p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor039"/>Sparkling Water allows users to code in H2O and Spark seamlessly </h2>
			<p>The following code shows a simple example of Spark and H2O integrated in the same H2O code<a id="_idIndexMarker117"/> using H2O Sparkling Water:</p>
			<pre class="source-code"># import data</pre>
			<pre class="source-code">loans_spark = spark.read.load("loans.csv", format="csv", sep=",", inferSchema="true", header="true")</pre>
			<pre class="source-code"># Spark data engineering code</pre>
			<pre class="source-code">loans_spark = # any Spark SQL or Spark DataFrame code</pre>
			<pre class="source-code"># Convert Spark DataFrame to H2O Frame</pre>
			<pre class="source-code">loans = h2oContext.asH2OFrame(loans_spark)</pre>
			<pre class="source-code"># Continue with H2O model building steps as in previous code example</pre>
			<pre class="source-code">loans.describe()</pre>
			<p>The <a id="_idIndexMarker118"/>code shows Spark importing data, which is held as <a id="_idIndexMarker119"/>a <strong class="bold">Spark DataFrame</strong>. <strong class="bold">Spark SQL</strong> or the <strong class="bold">Spark DataFrame</strong> API is used to engineer this data into a new DataFrame and then this Spark DataFrame <a id="_idIndexMarker120"/>is converted into<a id="_idIndexMarker121"/> an <strong class="bold">H2OFrame</strong> from which H2O model building is performed. Therefore, the user is iterating seamlessly from Spark to H2O code in the same API language and IDE.</p>
			<p>The idea of the H2O cluster is still fundamentally true for Sparkling Water. It now expresses the H2O cluster architecture within the Spark framework. Details of this architecture are elaborated in <a href="B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226"><em class="italic">Chapter 12</em></a>, <em class="italic">The Enterprise Architect and Security Views</em>.</p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor040"/>MOJOs export as DevOps-friendly artifacts</h2>
			<p>Data scientists <a id="_idIndexMarker122"/>build models, but the end goal is to put models into a production environment where predictions are made in a business context. MOJOs make this last mile of deployment easy. MOJOs are exported by a single line of code. For example, whether the model was built using Python, R, or using a generalized linear model, an XGBoost model, or stacked ensemble, all MOJOs are identical from a DevOps perspective. This makes model deployment repeatable and, thus, capable of fitting into existing automated CI/CD pipelines that are used throughout the organization.</p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor041"/>Summary</h1>
			<p>In this chapter, we laid the foundation for understanding H2O machine learning at scale. We started by reviewing a bare minimum <em class="italic">Hello World</em> code example and discussed the problems of scale around it. Then, we introduced the H2O Core, Enterprise Steam, and MOJO technology components and how these can overcome problems of scale. Finally, we extracted a set of key concepts from these technologies to deepen our understanding.</p>
			<p>In the next chapter, we will use this understanding to begin our journey of learning how to build and deploy world-class models at scale. Let the coding begin!</p>
		</div>
	</body></html>