- en: Organizing Data with Datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In his story “The Adventure of the Copper Breeches”, Arthur Conan Doyle has
    Sherlock Holmes shout “*Data! Data! Data! I cannot make bricks without clay*”—and
    this mindset, which served the most famous detective in literature so well, should
    be adopted by every data scientist. For that reason, we begin the more technical
    part of this book with a chapter dedicated to data: specifically, in the Kaggle
    context, leveraging the power of Kaggle Datasets functionality for our purposes.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In principle, any data you can use (subject to limitations—see the legal caveats
    section below), you can upload to Kaggle. The specific limits at the time of writing
    this book are: 20 gigabytes per dataset and 100 gb total quota. Keep in mind that
    the size limit per single dataset is calculated uncompressed—uploading compressed
    versions speeds up the transfer but does not help against the limits. You can
    check the most recent documentation of the datasets at this link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/docs/datasets](https://www.kaggle.com/docs/datasets)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kaggle promotes itself as a “home of open data science” and the impressive
    collection of datasets available from the site certainly lends some credence to
    that claim: before uploading the data for your project into a dataset, make sure
    to check the existing content—for several popular applications, there is a chance
    it has already been stored there:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For the sake of this introduction, let us assume the kind of data you will
    be using in your project is not already there—so you need to create a new one.
    When you head to the menu with three lines on the left-hand side and click on
    **Data** you will be redirected to the dataset page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When you click on **New Dataset** you will be prompted for the basics: uploading
    the actual data and giving it a title:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file3.png)'
  prefs: []
  type: TYPE_IMG
- en: Keep in mind that Kaggle is a popular platform, so numerous people upload their
    data there—including private (not publicly visible) ones—so try to think of a
    non-generic title.
  prefs: []
  type: TYPE_NORMAL
- en: 'Voila! Your first dataset is ready. You can then head to the **Data** tab:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In principle you do not have to fill out all the fields—your newly created
    dataset is perfectly usable without them (and if it is a private one, you probably
    do not care—after all you know what is in it). However, the community etiquette
    would suggest filling the info for the ones you make public: the more you specify,
    the more usable the data will be to others (and measured by the usability score,
    displayed in the upper right corner).'
  prefs: []
  type: TYPE_NORMAL
- en: Gathering the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Apart from legal aspect (see the last section of this chapter), there is no
    real limit on the kind of content you can store in the datasets: tabular data,
    images, text—if you fit within the size requirements, you can store it. This includes
    data harvested from other sources: tweets by hashtag or topic are among the popular
    datasets at the time of writing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file5.png)'
  prefs: []
  type: TYPE_IMG
- en: Discussion of the different frameworks for harvesting data from social media
    (Twitter, Reddit etc) is outside the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Kaggle datasets outside of Kaggle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Kaggle kernels are free to use, but not without limits (more on that in *Chapter
    4*)—and the first one you are likely to hit is the time limit of 8 hours. A popular
    alternative is to move to Google Colab a free Jupyter notebook environment that
    runs entirely in the cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://colab.research.google.com](https://colab.research.google.com)'
  prefs: []
  type: TYPE_NORMAL
- en: But even once we move the computations there, we might still want to have access
    to the Kaggle datasets—so importing them into Colab is a rather handy feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we do—since you are reading this, we assume you already are
    registered on Kaggle—is head to the account page to generate the API token:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to “your account” and click on **Create New API Token**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A file named `kaggle.json` containing your username and token will be created
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/file6.png)'
  prefs: []
  type: TYPE_IMG
- en: Next step is to create a folder named “`Kaggle`” in your drive and upload the
    `.json` there
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once done, you need to create a new Colab notebook and mount your drive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Get the authorization code from the URL prompt and provide in the empty box,
    then execute the following code to prove the path to the `.json` config:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file9.png)![](img/file10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can download the dataset now: begin by going to Kaggle and copying the API
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Run the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file12.png)'
  prefs: []
  type: TYPE_IMG
- en: The dataset will be downloaded as a `.zip` archive—unpack it and you are good
    to go.
  prefs: []
  type: TYPE_NORMAL
- en: Building around datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you have created a dataset, you probably want to use in your analysis.
    You can start a kernel using your dataset as a primary source: go to the **Activity**
    tab in the upper menu of your dataset page and scroll to this block:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file13.png)'
  prefs: []
  type: TYPE_IMG
- en: Alternatively, you can start a conversation around the data by clicking on **Create
    a discussion**.
  prefs: []
  type: TYPE_NORMAL
- en: Legal caveats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just because you can put some data on Kaggle does not necessarily mean that
    you should—excellent example would be the “People of Tinder dataset”: in 2017,
    a developer used the Tinder API to scrape the website for semi-private profiles
    and uploaded the data on Kaggle. After the issue became known, Kaggle ended up
    taking the dataset down. You can read the full story here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454](https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, before you upload anything to Kaggle ask yourself two questions:
    is it legal (from a copyright standpoint—always check the licenses) and are there
    any risks associated with this dataset (privacy or otherwise).'
  prefs: []
  type: TYPE_NORMAL
