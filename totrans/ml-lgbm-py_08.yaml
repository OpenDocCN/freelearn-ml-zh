- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Machine Learning Pipelines and MLOps with LightGBM
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LightGBM的机器学习流程和MLOps
- en: This chapter shifts the focus from data science and modeling problems to building
    production services for our ML solutions. We introduce the concept of machine
    learning pipelines, a systematic approach to processing data, and building models
    that ensure consistency and correctness.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点从数据科学和建模问题转移到为我们的机器学习解决方案构建生产服务。我们介绍了机器学习流程的概念，这是一种处理数据并构建确保一致性和正确性的模型的系统方法。
- en: We also introduce the concept of MLOps, a practice that blends DevOps and ML
    and addresses the need to deploy and maintain production-capable ML systems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还介绍了MLOps的概念，这是一种结合DevOps和ML的实践，旨在解决部署和维护生产级ML系统的需求。
- en: The chapter includes an example of building an ML pipeline using scikit-learn,
    encapsulating data processing, model building, and tuning. We show how to wrap
    the pipeline in a web API, exposing a secure endpoint for prediction. Finally,
    we also look at the containerization of the system and deployment to Google Cloud.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括使用scikit-learn构建机器学习流程的示例，封装数据处理、模型构建和调整。我们展示了如何将流程包装在Web API中，暴露一个安全的预测端点。最后，我们还探讨了系统的容器化和部署到Google
    Cloud。
- en: 'The main topics of this chapter are as follows:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要内容包括以下几方面：
- en: Machine learning pipelines
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习流程
- en: An overview of MLOps
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLOps概述
- en: Deploying an ML pipeline for customer churn
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署客户流失的机器学习流程
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The chapter includes examples of creating scikit-learn pipelines, training LightGBM
    models, and building a FastAPI application. The requirements for setting up your
    environment can be found alongside the complete code examples at [https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-8](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-8).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括创建scikit-learn流程、训练LightGBM模型和构建FastAPI应用的示例。设置环境的要求可以在[https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-8](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-8)的完整代码示例旁边找到。
- en: Introducing machine learning pipelines
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍机器学习流程
- en: 'In [*Chapter 6*](B16690_06.xhtml#_idTextAnchor094), *Solving Real-World Data
    Science Problems with LightGBM*, we gave a detailed overview of the data science
    life cycle, which includes various steps to train an ML model. If we were to focus
    only on the steps required to train a model, given data that has already been
    collected, those would be as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第6章*](B16690_06.xhtml#_idTextAnchor094)《使用LightGBM解决现实世界数据科学问题》中，我们详细概述了数据科学生命周期，其中包括训练ML模型的各种步骤。如果我们只关注训练模型所需的步骤，给定已经收集的数据，那么这些步骤如下：
- en: Data cleaning and preparation
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据清洗和准备
- en: Feature engineering
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征工程
- en: Model training and tuning
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练和调整
- en: Model evaluation
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型评估
- en: Model deployment
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型部署
- en: In previous case studies, we applied these steps manually while working through
    a Jupyter notebook. However, what would happen if we shifted the context to a
    long-term ML project? If we had to repeat the process when new data becomes available,
    we’d have to follow the same procedure to build a model successfully.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的案例研究中，我们在处理Jupyter笔记本时手动应用了这些步骤。然而，如果我们把背景转移到长期机器学习项目中，会发生什么呢？如果我们需要在有新数据可用时重复该过程，我们就必须遵循相同的程序来成功构建模型。
- en: Similarly, when we want to use the model to score new data, we must apply the
    steps correctly and with the correct parameters and configuration every time.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，当我们想要使用模型对新数据进行评分时，我们必须每次都正确地应用这些步骤，并使用正确的参数和配置。
- en: 'In a sense, these steps form a pipeline for data: data enters the pipeline,
    and a deployable model results from its completion.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种意义上说，这些步骤形成了一个数据处理流程：数据进入流程，完成时产生一个可部署的模型。
- en: Formally, an ML pipeline is a systematic and automated process that guides the
    workflow of an ML project. It involves several interconnected stages, encapsulating
    the steps listed previously.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，机器学习流程是一个系统化和自动化的过程，指导机器学习项目的流程。它涉及几个相互关联的阶段，封装了之前列出的步骤。
- en: An ML pipeline aims to ensure that these tasks are structured, reproducible,
    and efficient, making it easier to manage complex ML tasks. Pipelines are particularly
    beneficial when working with large datasets or when the steps to transform raw
    data into usable inputs for ML models are complex and must be repeated frequently,
    such as in a production environment.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道旨在确保这些任务是有结构的、可重复的且高效的，从而更容易管理复杂的机器学习任务。当处理大型数据集或当将原始数据转换为机器学习模型可用的输入步骤复杂且必须频繁重复时，例如在生产环境中，管道特别有益。
- en: 'There is some fluidity in the steps involved in a pipeline: steps may be added
    or removed depending on how the pipeline is utilized. Some pipelines include a
    data collection step, pulling data from various data sources or databases, and
    staging the data for ML modeling.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 管道中涉及的步骤具有一定的灵活性：根据管道的使用方式，步骤可以添加或删除。一些管道包括数据收集步骤，从各种数据源或数据库中提取数据，并为机器学习建模准备数据。
- en: Many ML services and frameworks provide functionality and utilities to implement
    ML pipelines. Scikit-learn provides this functionality through its `Pipeline`
    class, which we will look at next.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习服务和框架提供功能和方法来实现机器学习管道。Scikit-learn通过其`Pipeline`类提供此功能，我们将在下一节中探讨。
- en: Scikit-learn pipelines
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scikit-learn管道
- en: Scikit-learn provides the `Pipeline` class as a tool to implement ML pipelines.
    The `Pipeline` class provides a unified interface to perform a sequence of data-
    and model-related tasks. Pipelines rely on scikit-learn’s standard `fit` and `transform`
    interfaces to enable the chaining of operations. Each pipeline consists of any
    number of intermediate steps, which must be `transforms`. A transform must implement
    both `fit` and `transform`, and the `Pipeline` class each transform in turn, first
    passing the data to `fit` and then to `transform`. The final step, which usually
    entails fitting the model to the data, only needs to implement the `fit` method.
    The transformations are usually preprocessing steps that transform or augment
    the data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn提供`Pipeline`类作为实现机器学习管道的工具。`Pipeline`类提供了一个统一的接口来执行一系列与数据和模型相关的任务。管道依赖于scikit-learn的标准`fit`和`transform`接口来实现操作的链式调用。每个管道由任意数量的中间步骤组成，这些步骤必须是`transforms`。一个转换必须实现`fit`和`transform`，`Pipeline`类依次对每个转换进行操作，首先将数据传递给`fit`，然后传递给`transform`。最后的步骤，通常涉及将模型拟合到数据上，只需要实现`fit`方法。转换通常是预处理步骤，用于转换或增强数据。
- en: The primary advantage of using scikit-learn pipelines is ensuring that the workflow
    is implemented clearly and in a reproducible manner. It helps avoid common mistakes,
    such as leaking statistics from the test data into the trained model during the
    preprocessing steps. By including the preprocessing steps within the pipeline,
    we ensure that the same steps are applied consistently during training and when
    the model is used to predict new data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用scikit-learn管道的主要优势是确保工作流程被清晰地实现，并且是可重复的。这有助于避免常见的错误，例如在预处理步骤中将测试数据的统计信息泄露到训练模型中。通过在管道中包含预处理步骤，我们确保在训练期间以及当模型用于预测新数据时，应用相同的步骤。
- en: Furthermore, scikit-learn pipelines can be combined with tools for model selection
    and hyperparameter tuning, such as grid search and cross-validation. We can use
    grid search to automatically select the best parameters across the entire pipeline
    by defining a grid of parameters for the preprocessing steps and the final estimator.
    This can significantly simplify the code and reduce errors in a complex ML workflow.
    Tools such as FLAML also feature integration with scikit-learn pipelines.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，scikit-learn管道可以与模型选择和超参数调整工具结合使用，例如网格搜索和交叉验证。我们可以通过定义预处理步骤和最终估计器的参数网格来使用网格搜索自动选择整个管道中最佳参数。这可以显著简化代码并减少复杂机器学习工作流程中的错误。FLAML等工具也具备与scikit-learn管道的集成功能。
- en: 'For example, a simple pipeline can be created as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，可以创建一个简单的管道如下：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here, the pipeline consists of two steps: a scaling step that standardizes
    the data and a final step that fits a linear regression model.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，该流程由两个步骤组成：一个缩放步骤，用于标准化数据，以及一个最终步骤，用于拟合线性回归模型。
- en: 'The power of scikit-learn’s `Pipeline` is that it can, in turn, be used as
    we would any other estimator or model:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn的`Pipeline`的强大之处在于它可以像使用任何其他估计器或模型一样使用：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This provides us with a unified interface to all the steps encapsulated in
    the pipeline and makes reproducibility trivial. Furthermore, we can export the
    pipeline as we do for other scikit-learn models to enable deployment of the pipeline
    and all the steps it encapsulates:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了一个统一的接口，用于封装在管道中的所有步骤，并使可重复性变得简单。此外，我们可以像其他scikit-learn模型一样导出管道，以便部署管道及其封装的所有步骤：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We will show more examples of using scikit-learn pipelines next.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中展示更多使用scikit-learn管道的示例。
- en: Although we have spent much time addressing the concerns of working with data
    and building and tuning models, we haven’t yet taken an in-depth look at what
    happens after a model is trained. It’s here that the world of MLOps comes into
    play. The next section provides a detailed overview.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们花费了大量时间解决与数据处理、构建和调整模型相关的问题，但我们还没有深入探讨模型训练后的情况。正是在这里，MLOps的世界发挥了作用。下一节将提供详细的概述。
- en: Understanding MLOps
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解MLOps
- en: '**Machine Learning Operations** (**MLOps**) is a practice that blends the fields
    of ML and system operations. It is designed to standardize and streamline the
    life cycle of ML model development and deployment, thus increasing the efficiency
    and effectiveness of ML solutions within a business setting. In many ways, MLOps
    can be considered a response to the challenges associated with operationalizing
    ML, bringing DevOps principles into the ML world.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习运维**（**MLOps**）是一种将机器学习和系统运维领域融合的实践。它旨在标准化和简化机器学习模型开发和部署的生命周期，从而提高业务环境中机器学习解决方案的效率和效果。在许多方面，MLOps可以被视为对将机器学习投入运营所面临的挑战的回应，将DevOps原则引入机器学习世界。'
- en: MLOps aims to bring together data scientists, who typically focus on model creation,
    experimentation, and evaluation, and operations professionals, who deal with deployment,
    monitoring, and maintenance. The goal is to facilitate better collaboration between
    these groups, leading to faster, more robust model deployment.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps旨在将数据科学家（他们通常专注于模型创建、实验和评估）和运维专业人员（他们处理部署、监控和维护）聚集在一起。目标是促进这些团队之间的更好协作，从而实现更快、更稳健的模型部署。
- en: The importance of MLOps is underscored by the unique challenges presented by
    ML systems. Machine learning systems are more dynamic and less predictable than
    traditional software systems, leading to potential challenges in reliability and
    robustness, especially in a rapidly changing production environment.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps的重要性通过机器学习系统所提出的独特挑战得到了强调。与传统的软件系统相比，机器学习系统更加动态且难以预测，这可能导致在可靠性、鲁棒性方面出现潜在挑战，尤其是在快速变化的生产环境中。
- en: A central goal of MLOps is to accelerate the ML life cycle, facilitating faster
    experimentation and deployment. This is achieved through the automation of ML
    pipelines. **Automation** can cover various stages, including data preprocessing,
    feature engineering, model training, model validation, and deployment. Another
    crucial aspect of MLOps is ensuring reproducibility. Given the dynamic nature
    of ML models, it can be challenging to replicate results exactly, especially when
    models are retrained with new data. MLOps emphasizes the importance of versioning
    code, data, and model configurations, which ensures that every experiment can
    be precisely reproduced, which is crucial for debugging and auditing.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps的核心目标是通过自动化机器学习管道来加速机器学习生命周期，从而促进更快地进行实验和部署。这通过自动化多个阶段来实现，包括数据预处理、特征工程、模型训练、模型验证和部署。MLOps的另一个关键方面是确保可重复性。鉴于机器学习模型的动态特性，精确复制结果可能具有挑战性，尤其是在使用新数据进行模型重新训练时。MLOps强调代码、数据和模型配置版本控制的重要性，这确保了每个实验都可以精确重现，这对于调试和审计至关重要。
- en: '**Monitoring** is also a vital part of MLOps. Once a model is deployed, *monitoring
    its performance and continuously validating its predictions is critical*. MLOps
    emphasizes the need for robust monitoring tools that can track model performance,
    input data quality, and other vital metrics. Anomalies in these metrics may indicate
    that a model needs to be retrained or debugged.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**监控**也是MLOps的一个关键部分。一旦模型部署，*监控其性能和持续验证其预测至关重要*。MLOps强调需要强大的监控工具，这些工具可以跟踪模型性能、输入数据质量和其他关键指标。这些指标中的异常可能表明模型需要重新训练或调试。'
- en: MLOps also encourages the use of robust testing practices for ML. ML testing
    includes traditional software testing practices, such as unit tests and integration
    tests, but also more ML-specific tests, such as validating the statistical properties
    of model predictions.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps还鼓励使用稳健的ML测试实践。ML测试包括传统的软件测试实践，如单元测试和集成测试，但也包括更多ML特定的测试，如验证模型预测的统计属性。
- en: MLOps also focuses on managing and scaling ML deployments. In the real world,
    ML models may need to serve thousands or even millions of predictions per second.
    DevOps practices such as containerization and serverless computing platforms come
    into play here to facilitate deployment and scaling automation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps还侧重于管理和扩展ML部署。在现实世界中，ML模型可能需要每秒处理数千甚至数百万个预测。在这里，容器化和无服务器计算平台等DevOps实践发挥作用，以促进部署和扩展自动化。
- en: It’s important to note how MLOps fits into the broader software ecosystem. Just
    like DevOps has bridged the gap between development and operations in software
    engineering, MLOps aims to do the same for ML. By promoting shared understanding
    and responsibilities, MLOps can lead to more successful ML projects.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意MLOps如何融入更广泛的软件生态系统。就像DevOps在软件工程中弥合了开发和运维之间的差距一样，MLOps旨在为ML做同样的事情。通过促进共同理解和责任，MLOps可以导致更成功的ML项目。
- en: MLOps is a rapidly evolving field becoming increasingly important as more businesses
    adopt ML. By applying principles from DevOps to the unique challenges of ML, MLOps
    provides a framework for managing the end-to-end ML life cycle, from initial experimentation
    to robust, scalable deployment. MLOps emphasizes standardization, automation,
    reproducibility, monitoring, testing, and collaboration to enable high-throughput
    ML systems.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps是一个快速发展的领域，随着更多企业采用ML，其重要性日益增加。通过将DevOps的原则应用于ML的独特挑战，MLOps提供了一个从初始实验到稳健、可扩展部署的端到端ML生命周期的框架。MLOps强调标准化、自动化、可重复性、监控、测试和协作，以实现高吞吐量的ML系统。
- en: We’ll now look at a practical example of creating an ML pipeline using scikit-learn
    and deploying the pipeline behind a REST API.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将通过一个实际示例来查看使用scikit-learn创建ML管道并将其部署在REST API背后的情况。
- en: Deploying an ML pipeline for customer churn
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署客户流失的ML管道
- en: For our practical example, we’ll use the telecommunication (**telco**) Customer
    Churn dataset we worked with in [*Chapter 5*](B16690_05.xhtml#_idTextAnchor083),
    *LightGBM Parameter Optimization with Optuna*. The dataset consists of descriptive
    information for each customer (such as gender, billing information, and charges)
    and whether the customer has left the telco provider (churn is *yes* or *no*).
    Our task is to build a classification model to predict churn.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实际示例中，我们将使用我们在[*第五章*](B16690_05.xhtml#_idTextAnchor083)中使用的电信(**telco**)客户流失数据集，即*使用Optuna进行LightGBM参数优化*。该数据集包含每个客户的描述性信息（例如性别、账单信息和费用），以及客户是否已离开电信提供商（流失为*是*或*否*）。我们的任务是构建一个分类模型来预测流失。
- en: Further, we’d like to deploy the model behind a REST API such that it can be
    integrated into a more extensive software system. The REST API should have an
    endpoint that makes predictions for data passed to the API.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们希望将模型部署在REST API后面，以便它可以集成到一个更广泛的软件系统中。REST API应该有一个端点，用于对传递给API的数据进行预测。
- en: We’ll use **FastAPI**, a modern, high-performance Python web framework, to build
    our API. Finally, we’ll deploy our model and API to Google Cloud Platform using
    Docker.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**FastAPI**，一个现代、高性能的Python网络框架来构建我们的API。最后，我们将使用Docker将我们的模型和API部署到Google
    Cloud Platform。
- en: Building an ML pipeline using scikit-learn
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用scikit-learn构建ML管道
- en: We will start by building an ML pipeline using scikit-learn’s `Pipeline` toolset.
    Our pipeline should encapsulate data cleaning and feature engineering steps, then
    build and tune an appropriate model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用scikit-learn的`Pipeline`工具集构建一个ML管道。我们的管道应该封装数据清洗和特征工程步骤，然后构建和调整适当的模型。
- en: 'We’ll evaluate two algorithms for modeling: LightGBM and random forest, and
    as such, it’s unnecessary to perform any scaling or normalization of the data.
    However, the dataset has a unique identifier for each customer, `customerID`,
    which we need to remove.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将评估两种建模算法：LightGBM和随机森林，因此，无需对数据进行任何缩放或归一化。然而，数据集为每个客户都有一个唯一的标识符，即`customerID`，我们需要将其删除。
- en: Further, the dataset consists of numerical and categorical features, and we
    must implement one-hot encoding for the categorical features.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，数据集包括数值和分类特征，我们必须对分类特征实现独热编码。
- en: Pipeline preprocessing steps
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管道预处理步骤
- en: To perform these steps within a scikit-learn pipeline, we’ll use `ColumnTransformer`.
    `ColumnTransformer` is a `Pipeline` transformer that operates only on a subset
    of the columns in the dataset. The transformer accepts a list of tuples in the
    form (`name, transformer, columns`). It applies the sub-transformers to the specified
    columns and concatenates the results such that all resultant features form part
    of the same result set.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要在scikit-learn管道中执行这些步骤，我们将使用 `ColumnTransformer`。`ColumnTransformer` 是一个仅对数据集的子集列操作的
    `Pipeline` 转换器。转换器接受一个元组列表，形式为 (`name, transformer, columns`)。它将子转换器应用于指定的列，并将结果连接起来，使得所有结果特征都成为同一个结果集的一部分。
- en: 'For example, consider the following DataFrame and `ColumnTransformer`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下DataFrame和 `ColumnTransformer`：
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, we have a DataFrame with two columns: `price` and `description`. A column
    transformer is created with two sub-transformers: a scaling transformer and a
    vectorizer. The scaling transformer applies min-max scaling only to the `price`
    column. The vectorizer applies TF-IDF vectorization only to the `description`
    column. When `fit_transform` is called, a *single* array is returned with a column
    for the scaled price and the columns representing the word vectors.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们有一个包含两列的DataFrame：`price` 和 `description`。创建了一个包含两个子转换器的列转换器：一个缩放转换器和向量器。缩放转换器仅对
    `price` 列应用最小-最大缩放。向量器仅对 `description` 列应用TF-IDF向量化。当调用 `fit_transform` 时，返回一个
    *单个* 数组，包含缩放后的价格列和表示词向量的列。
- en: Note
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '**TF-IDF**, or **term frequency-inverse document frequency**, is just one way
    of extracting a feature from text. Analyzing and extracting features from text,
    and natural language processing in general, is a broad field within ML that we
    won’t be delving into deeply here. You are encouraged to read further on the topic
    at [https://scikit-learn.org/stable/modules/feature_extraction.xhtml#text-feature-extraction](https://scikit-learn.org/stable/modules/feature_extraction.xhtml#text-feature-extraction).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**TF-IDF**，或**词频-逆文档频率**，只是从文本中提取特征的一种方式。分析和提取文本特征，以及自然语言处理，是机器学习中的一个广泛领域，我们在这里不会深入探讨。我们鼓励您进一步阅读有关该主题的内容，请参阅[https://scikit-learn.org/stable/modules/feature_extraction.xhtml#text-feature-extraction](https://scikit-learn.org/stable/modules/feature_extraction.xhtml#text-feature-extraction)。'
- en: 'We can set up our preprocessing for the Customer Churn dataset as a single
    `ColumnTransformer`. We first define the two individual transformers, `id_transformer`
    and `encode_transformer`, that apply to the ID columns and the categorical features:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将Customer Churn数据集的预处理设置为一个单独的 `ColumnTransformer`。我们首先定义两个单独的转换器，`id_transformer`
    和 `encode_transformer`，它们应用于ID列和分类特征：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And then combine the separate transformers into `ColumnTransformer`:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将单独的转换器组合成 `ColumnTransformer`：
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`ColumnTransformer` is defined with the `remainder=''passthrough''` parameter.
    The `remainder` parameter specifies what happens to the columns that `ColumnTransformer`
    does not transform. These columns are dropped by default, but we would like to
    pass them through, untouched, to include them in the dataset.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`ColumnTransformer` 使用 `remainder=''passthrough''` 参数定义。`remainder` 参数指定了 `ColumnTransformer`
    不转换的列的处理方式。默认情况下，这些列会被删除，但我们需要将它们原样传递，以便包含在数据集中。'
- en: The encoding transformer creates and applies `OneHotEncoder` to the categorical
    features.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 编码转换器创建并应用 `OneHotEncoder` 到分类特征上。
- en: For illustrative purposes, we have created a custom transformer class to maintain
    the list of ID columns and drop them from the data during transformation.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明目的，我们创建了一个自定义的转换器类来维护ID列的列表，并在转换过程中从数据中删除它们。
- en: 'The class is shown here:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 类在这里展示：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As we can see, the class extends `BaseEstimator` and `TranformerMixin` from
    the scikit-learn base classes and must implement `fit` and `transform`. Implementing
    these methods also makes it suitable as a transformer in a pipeline. Implementing
    `fit` is optional if required; in our case, nothing is done during `fit`. Our
    transformation step drops the relevant columns.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，该类扩展了scikit-learn基础类 `BaseEstimator` 和 `TransformerMixin`，并且必须实现 `fit`
    和 `transform` 方法。实现这些方法也使其适合作为管道中的转换器。如果需要，实现 `fit` 是可选的；在我们的情况下，`fit` 过程中没有任何操作。我们的转换步骤会删除相关列。
- en: Note
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: It’s important to encapsulate the functionality to drop irrelevant columns (in
    this case, the ID column) within the pipeline itself. When deploying the pipeline
    for production use, we expect these columns to be passed to the pipeline when
    making a prediction. Removing them as part of the pipeline simplifies our pipeline’s
    usage for our model’s consumers and reduces the chance of user mistakes.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在管道中封装删除无关列（在这种情况下，ID 列）的功能很重要。当将管道部署到生产使用时，我们期望在做出预测时将这些列传递给管道。作为管道的一部分删除它们简化了模型消费者对管道的使用，并减少了用户出错的机会。
- en: 'This completes the transformations required for preprocessing, and we are ready
    to move on to the following steps: fitting and tuning the models.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了预处理所需的转换，我们现在可以继续下一步：拟合和调整模型。
- en: Pipeline modeling steps
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管道建模步骤
- en: 'For the pipeline modeling part, we’ll use FLAML. We’ll also use the opportunity
    to show how parameters may be passed to steps within a pipeline. First, we define
    the settings for our AutoML model:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于管道建模部分，我们将使用 FLAML。我们也将利用这个机会展示如何将参数传递给管道内的步骤。首先，我们定义我们的 AutoML 模型的设置：
- en: '[PRE7]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The preceding code sets our time budget, optimization metric, and classification
    task for AutoML. We also limit the estimators to LightGBM and a random forest
    model. Finally, we customize the search space by specifying that `n_estimators`
    should be uniformly sampled between 20 and 500.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码设置了我们的时间预算、优化指标和分类任务，并将估计器限制在 LightGBM 和随机森林模型。最后，我们通过指定 `n_estimators`
    应该在 20 到 500 之间均匀采样来自定义搜索空间。
- en: 'The pipeline requires the parameter for constituent steps to be prefixed with
    the step’s name and a double underscore. We can set up a dictionary to pass these
    parameters to the AutoML class within our pipeline:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 管道需要将构成步骤的参数以步骤名称和双下划线为前缀。我们可以在管道中设置一个字典，将这些参数传递给 AutoML 类：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here, `automl` is the name of the step in the pipeline. As such, for example,
    the parameters for time budget and metric are set as `automl__time_budget: 120`
    and `automl__metric:` `accuracy`, respectively.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，`automl` 是管道中步骤的名称。因此，例如，时间预算和指标的参数分别设置为 `automl__time_budget: 120` 和 `automl__metric:`
    `accuracy`。'
- en: 'Finally, we can add FLAML’s AutoML estimator:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以添加 FLAML 的 AutoML 估计器：
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The final pipeline is shown in the following figure:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了最终的管道：
- en: '![Figure 8.1 – Final ML pipeline for Customer Churn prediction](img/B16690_08_01.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – 客户流失预测的最终 ML 管道](img/B16690_08_01.jpg)'
- en: Figure 8.1 – Final ML pipeline for Customer Churn prediction
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 客户流失预测的最终 ML 管道
- en: '*Figure 8**.1* shows a *ColumnTransformer* that consists of two sub-transformers,
    feeding into the AutoML estimator.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 8**.1* 显示了一个由两个子转换器组成的 *ColumnTransformer*，它们将数据输入到 AutoML 估计器中。'
- en: Model training and validation
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练和验证
- en: 'We are now ready to fit the pipeline to our data, passing the pipeline settings
    we set up earlier. Pipelines support the standard scikit-learn API so that we
    can call on the pipeline itself:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好将管道拟合到我们的数据中，传递我们之前设置的管道设置。管道支持标准的 scikit-learn API，因此我们可以调用管道本身：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Running `fit` executes all the preprocessing steps and then passes the data
    for AutoML modeling and tuning. The single `Pipeline` object illustrates the power
    of an ML pipeline: the entire end-to-end     process, including a trained and tuned model, is encapsulated and portable, and
    we can utilize the pipeline as we could a single model. For example, the following
    code performs F1 scoring for the training data:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `fit` 执行所有预处理步骤，然后将数据传递给 AutoML 建模和调整。单个 `Pipeline` 对象展示了 ML 管道的强大功能：包括训练和调整后的模型在内的整个端到端过程被封装并便携，我们可以像使用单个模型一样使用管道。例如，以下代码对训练数据执行
    F1 分数：
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To export the pipeline, we `joblib` to serialize the model to a file:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 要导出管道，我们使用 `joblib` 将模型序列化到文件中：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Exporting the pipeline allows us to re-instantiate and use it within our production
    code. Next, we’ll look at building an API for our model.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 导出管道允许我们在生产代码中重新实例化并使用它。接下来，我们将探讨为我们的模型构建 API。
- en: At this stage, our pipeline (which encapsulates preprocessing, training, optimization,
    and validation) is defined, and we are ready to deploy it to a system. We’ll accomplish
    this by wrapping our model in an API with FastAPI.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们的管道（它封装了预处理、训练、优化和验证）已经定义，我们准备将其部署到系统中。我们将通过用 FastAPI 包装我们的模型来实现这一点。
- en: Building an ML API using FastAPI
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 FastAPI 构建 ML API
- en: We will now look at building a REST API around our pipeline, enabling consumers
    of our pipeline to get predictions via web requests. Building a web API for a
    model also simplifies integration with other systems and services and is the standard
    method for integration in a microservices architecture.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将探讨围绕我们的流水线构建REST API，使流水线的消费者可以通过Web请求获取预测。为模型构建Web API也简化了与其他系统和服务的集成，并且是微服务架构中集成标准的方法。
- en: To build the API, we use the Python library FastAPI.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建API，我们使用Python库FastAPI。
- en: FastAPI
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FastAPI
- en: FastAPI is a modern, high-performance web framework for building APIs with Python
    3.6+. It was designed from the ground up to be easy to use and enable high-performance
    API development. The key features of FastAPI are its speed and ease of use, making
    it an excellent choice for developing robust, production-ready APIs. FastAPI widely
    adopts Python’s type checking, which aids in catching errors early in the development
    process. It also uses these type hints to provide data validation, serialization,
    and documentation, reducing the boilerplate code developers need to write.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: FastAPI是一个现代、高性能的Web框架，用于使用Python 3.6+构建API。它从头开始设计，易于使用并支持高性能的API开发。FastAPI的关键特性是其速度和易用性，使其成为开发健壮、生产就绪API的绝佳选择。FastAPI广泛采用Python的类型检查，有助于在开发过程中早期捕获错误。它还使用这些类型提示来提供数据验证、序列化和文档，减少了开发者需要编写的样板代码。
- en: The performance of FastAPI is one of its defining features. It is on par with
    Node.js and significantly faster than traditional Python frameworks. This speed
    is achieved due to its use of Starlette for the web parts and Pydantic for the
    data parts, and its non-blocking nature makes it suitable for handling many concurrent
    requests.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: FastAPI的性能是其定义性的特征之一。它与Node.js相当，并且比传统的Python框架快得多。这种速度是通过其使用Starlette进行Web部分和Pydantic进行数据部分，以及其非阻塞特性来实现的，这使得它适合处理大量并发请求。
- en: FastAPI provides automatic interactive API documentation, a considerable advantage
    while developing complex APIs. Using FastAPI, developers gain access to automatically
    generated interactive API docs via Swagger UI. Swagger UI also provides functionality
    to interact with the REST resources without writing code or using external tooling.
    This feature makes FastAPI very developer-friendly and accelerates the development
    process.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: FastAPI提供了自动交互式API文档，这在开发复杂API时是一个很大的优势。使用FastAPI，开发者可以通过Swagger UI访问自动生成的交互式API文档。Swagger
    UI还提供了与REST资源交互的功能，无需编写代码或使用外部工具。这一特性使FastAPI非常适用于开发者，并加速了开发过程。
- en: FastAPI also supports industry-standard security protocols, such as OAuth2,
    and provides tooling to ease implementation. Much of FastAPI’s tooling relies
    on its dependency injection system, allowing developers to manage dependencies
    and handle shared resources efficiently.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: FastAPI还支持行业标准的安全协议，如OAuth2，并提供工具以简化实现。FastAPI的大部分工具都依赖于其依赖注入系统，允许开发者高效地管理依赖项和处理共享资源。
- en: FastAPI is well suited to building web APIs and microservices for ML models
    due to its ease of use and high performance, allowing ML engineers to focus on
    the myriad of other concerns surrounding production ML deployments.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: FastAPI因其易用性和高性能，非常适合构建用于机器学习模型的Web API和微服务，这使得机器学习工程师可以专注于生产机器学习部署的其他众多问题。
- en: Building with FastAPI
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用FastAPI进行构建
- en: 'To create a REST API with FastAPI, we can create a new Python script and instantiate
    the FastAPI instance. After the instance starts, we can load our model from the
    file:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用FastAPI创建REST API，我们可以创建一个新的Python脚本并实例化FastAPI实例。实例启动后，我们可以从文件中加载我们的模型：
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Loading the model at the start of the application increases the startup time
    but ensures that the API is ready to serve requests when the application startup
    completes.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序启动时加载模型会增加启动时间，但确保API在应用程序启动完成后即可准备就绪以处理请求。
- en: 'Next, we need to implement a REST endpoint to make predictions. Our endpoint
    accepts input data and returns the predictions as JSON. The input JSON is an array
    of JSON objects, as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要实现一个REST端点以进行预测。我们的端点接受输入数据，并以JSON格式返回预测。输入JSON是一个JSON对象的数组，如下所示：
- en: '[PRE14]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'With FastAPI, we implement a REST endpoint by creating a function that takes
    the input data as parameters. FastAPI serializes the preceding JSON structure
    to a Python list of dictionaries. Therefore, our function signature is implemented
    as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用FastAPI，我们通过创建一个接受输入数据作为参数的函数来实现REST端点。FastAPI将前面的JSON结构序列化为Python字典列表。因此，我们的函数签名实现如下：
- en: '[PRE15]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We decorate the function using a FastAPI `post` decorator, specifying the endpoint
    path (`'/predict'`).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用FastAPI的`post`装饰器装饰该函数，指定端点路径（`'/predict'`）。
- en: 'To make the actual predictions for the model, we convert the dictionaries to
    a DataFrame and perform the predictions:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对模型进行实际预测，我们将字典转换为DataFrame并执行预测：
- en: '[PRE16]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We use `predict_proba` to get the probabilities for each class (Yes or No) since
    we want to send this additional information to the consumers of our API. Returning
    probabilities alongside predictions is a recommended practice, as this affords
    the API consumer more control over the use of the predictions. API consumers can
    decide what probability threshold is good enough for their application based on
    how the predictions are used.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`predict_proba`来获取每个类（是或否）的概率，因为我们希望将此附加信息发送给我们的API消费者。在预测的同时返回概率是一种推荐的做法，因为这使API消费者在使用预测时拥有更多的控制权。API消费者可以根据预测的使用方式来决定什么概率阈值对于他们的应用程序来说是足够的。
- en: 'To return the results as JSON, we construct a dictionary that FastAPI then
    serializes to JSON. We use NumPy’s `argmax` to get the index of the highest probability
    to determine the predicted class and `amax` to get the highest probability itself:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了以JSON格式返回结果，我们构建一个字典，然后FastAPI将其序列化为JSON。我们使用NumPy的`argmax`来获取最高概率的索引以确定预测的类别，并使用`amax`来获取最高的概率本身：
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The preceding code produces a `prediction` object for each data instance in
    the input list, using the position in the list as an index. When the endpoint
    is called, the following JSON is returned:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码为输入列表中的每个数据实例生成一个`prediction`对象，使用列表中的位置作为索引。当端点被调用时，将返回以下JSON：
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We have now built the core of the API endpoint. However, we must also pay attention
    to non-functional concerns such as security. Often, ML engineers neglect aspects
    such as security or performance and focus only on ML concerns. We mustn’t make
    this mistake and must ensure we give these concerns the necessary attention.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经构建了API端点的核心。然而，我们还得注意非功能性关注点，例如安全性。通常，机器学习工程师会忽视诸如安全性或性能等方面的内容，而只关注机器学习相关的问题。我们不应犯这样的错误，必须确保我们给予这些关注点必要的关注。
- en: Securing the API
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保护API
- en: To secure our endpoint, we’ll make use of HTTP Basic authentication. We use
    a preset username and password, which we read from the environment. This allows
    us to securely pass these credentials to the application during deployment and
    avoids pitfalls such as hardcoding the credentials. Our endpoint also needs to
    be enhanced to accept credentials from the user. HTTP Basic authentication credentials
    are sent as an HTTP header.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保护我们的端点，我们将使用HTTP基本认证。我们使用预置的用户名和密码，这些我们从环境中读取。这允许我们在部署期间安全地传递这些凭证到应用程序中，避免了硬编码凭证等陷阱。我们的端点还需要增强以接受用户的凭证。HTTP基本认证凭证作为HTTP头发送。
- en: 'We can implement this as follows. We first set up security for FastAPI and
    read the credentials from the environment:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按以下方式实现。我们首先为FastAPI设置安全措施并从环境中读取凭证：
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We then add the following to the `endpoint` function:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在`endpoint`函数中添加以下内容：
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The `authenticate` function validates the received credentials against the
    API credentials we got from the environment. We can use Python’s secrets library
    to do the validation:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`authenticate`函数验证接收到的凭证是否与我们从环境中获取的API凭证匹配。我们可以使用Python的secrets库来进行验证：'
- en: '[PRE21]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: If the credentials are invalid, we throw an exception with HTTP status code
    `401`, signaling that the consumer is not authorized.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果凭证无效，我们将抛出一个带有HTTP状态码`401`的异常，表示消费者未授权。
- en: Our API endpoint is now fully implemented, secured, and ready for deployment.
    To deploy our API, we’ll containerize it using Docker.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的API端点现在已完全实现、安全并准备好部署。为了部署我们的API，我们将使用Docker进行容器化。
- en: Containerizing our API
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器化我们的API
- en: 'We can build a Docker container for our API with the following Dockerfile:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下Dockerfile为我们的API构建一个Docker容器：
- en: '[PRE22]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The Dockerfile is straightforward: we start with a base Python 3.10 image and
    install some OS dependencies that LightGBM needs (`libgomp1`). We then set up
    the FastAPI app: we copy the Python `requirements` file, install all of them,
    and then copy the necessary source files (using `COPY . .` ).'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile非常简单：我们从一个基于Python 3.10的基础镜像开始，安装LightGBM需要的某些操作系统依赖项（`libgomp1`）。然后我们设置FastAPI应用程序：我们复制Python的`requirements`文件，安装所有依赖项，然后复制必要的源文件（使用`COPY
    . .`）。
- en: Finally, we run a Uvicorn server, listening on all addresses on port `8080`.
    Uvicorn is an ASGI web server implementation for Python that supports async I/O,
    significantly increasing the web server’s throughput. We bind to port `8080`,
    our deployment platform’s default port.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们运行一个监听所有地址的端口`8080`的Uvicorn服务器。Uvicorn是Python的ASGI网络服务器实现，支持异步I/O，显著提高了网络服务器的吞吐量。我们绑定到端口`8080`，这是我们的部署平台默认的端口。
- en: 'We can build and run the Docker image using the following commands, passing
    the username and password environment variables:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令构建和运行Docker镜像，传递用户名和密码环境变量：
- en: '[PRE23]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The API should now be available on your localhost, on port `8080`, secured behind
    the credentials you provide in the environment variables.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: API现在应该可以在你的本地主机上通过端口`8080`访问，并受到你在环境变量中提供的凭证的保护。
- en: With our application containerized, we are ready to deploy our application to
    any platform that supports containers. For the churn application, we’ll deploy
    it to Google Cloud Platform.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的应用程序容器化后，我们就可以将应用程序部署到任何支持容器的平台。对于churn应用程序，我们将将其部署到Google Cloud Platform。
- en: Deploying LightGBM to Google Cloud
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将LightGBM部署到Google Cloud
- en: We’ll leverage the **Google Cloud Run** platform to deploy our application to
    Google Cloud Platform.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将利用**Google Cloud Run**平台将我们的应用程序部署到Google Cloud Platform。
- en: Google Cloud Run is a serverless platform that allows you to develop and run
    applications without worrying about infrastructure management. Cloud Run allows
    developers to run their applications in a secure, scalable, and zero-ops environment.
    Cloud Run is fully managed, meaning all infrastructure (such as servers and load
    balancers) is abstracted away, allowing users to focus on running their applications.
    Cloud Run also supports full autoscaling, and the number of running containers
    automatically increases to respond to increasing load. Cloud Run is also very
    cost-effective, as you are only charged when the container runs and serves requests.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud Run是一个无服务器平台，允许你在不担心基础设施管理的情况下开发和运行应用程序。Cloud Run允许开发者在一个安全、可扩展、零运维的环境中运行他们的应用程序。Cloud
    Run是完全管理的，这意味着所有基础设施（如服务器和负载均衡器）都被抽象化，使用户能够专注于运行他们的应用程序。Cloud Run还支持完全自动扩展，运行中的容器数量会自动增加以响应增加的负载。Cloud
    Run也非常经济高效，因为你只有在容器运行并处理请求时才会被收费。
- en: 'To use Cloud Run, you need a Google Cloud account and need to create a Google
    Cloud project, enable billing, and set up and initialize the **Google Cloud CLI**.
    The following resources guide you through these steps:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Cloud Run，你需要一个Google Cloud账户，并需要创建一个Google Cloud项目，启用计费，并设置和初始化**Google
    Cloud CLI**。以下资源将指导你完成这些步骤：
- en: '[https://console.cloud.google.com/getting-started](https://console.cloud.google.com/getting-started)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://console.cloud.google.com/getting-started](https://console.cloud.google.com/getting-started)'
- en: '[https://cloud.google.com/resource-manager/docs/creating-managing-projects](https://cloud.google.com/resource-manager/docs/creating-managing-projects)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/resource-manager/docs/creating-managing-projects](https://cloud.google.com/resource-manager/docs/creating-managing-projects)'
- en: '[https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install)'
- en: '[https://cloud.google.com/sdk/docs/initializing](https://cloud.google.com/sdk/docs/initializing)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/sdk/docs/initializing](https://cloud.google.com/sdk/docs/initializing)'
- en: 'Once the Google Cloud setup is completed, we can deploy our API using the CLI.
    This can be accomplished using a single command:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成Google Cloud的设置，我们就可以使用CLI部署我们的API。这可以通过单个命令完成：
- en: '[PRE24]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Running the command prompts you for a service name and a region to deploy your
    service. We also set the environment variables needed for the security credentials.
    For deployment, Cloud Run creates Cloud Build for you, which automatically builds
    and stores the Docker container and then deploys it to Cloud Run.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 运行命令会提示你输入服务名称和部署服务所在的区域。我们还会设置用于安全凭证所需的环境变量。对于部署，Cloud Run会为你创建Cloud Build，它会自动构建和存储Docker容器，然后将其部署到Cloud
    Run。
- en: Once the Cloud Run command completes, we have deployed a secure, scalable, RESTful
    web API serving our customer churn ML pipeline.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦Cloud Run命令完成，我们就部署了一个安全、可扩展的RESTful Web API，该API为我们客户的流失ML管道提供服务。
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter introduced ML pipelines, illustrating their advantages in enabling
    consistency, correctness, and portability when implementing ML solutions.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了ML管道，说明了其在实现ML解决方案时的一致性、正确性和可移植性的优势。
- en: An overview was given on the nascent MLOps field, a practice combining DevOps
    and ML to realize tested, scalable, secure, and observable production ML systems.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 对新兴的MLOps领域进行了概述，这是一个结合DevOps和ML以实现经过测试、可扩展、安全且可观察的生产ML系统的实践。
- en: Further, we discussed the scikit-learn `Pipeline` class, a toolset to implement
    ML pipelines using the familiar scikit-learn API.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还讨论了scikit-learn的`Pipeline`类，这是一个使用熟悉的scikit-learn API实现ML管道的工具集。
- en: A practical, end-to-end example of implementing an ML pipeline for customer
    churn was also given. We showed how to create a scikit-learn pipeline that performs
    preprocessing, modeling, and tuning and is exportable for a software system. We
    then built a secure RESTful web API using FastAPI that provides an endpoint for
    getting predictions from our customer churn pipeline. Finally, we deployed our
    API to Google Cloud Platform using the Cloud Run service.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 还提供了一个实现客户流失ML管道的端到端示例。我们展示了如何创建一个scikit-learn管道，该管道执行预处理、建模和调优，并且可以导出用于软件系统。然后，我们使用FastAPI构建了一个安全的RESTful
    Web API，该API提供了一个从我们的客户流失管道获取预测的端点。最后，我们使用Cloud Run服务将我们的API部署到Google Cloud Platform。
- en: 'Although our deployment is secure and fully scalable, with observability, metrics,
    and logs provided by Cloud Run, there are some ML-specific aspects our deployment
    does not address: model drift, model performance monitoring, and retraining.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的部署是安全的且完全可扩展的，Cloud Run提供了可观察性、指标和日志，但我们的部署没有解决一些ML特定的方面：模型漂移、模型性能监控和重新训练。
- en: In the next chapter, we look at a specialized ML cloud service with AWS SageMaker,
    which provides a platform-specific solution for building and hosting cloud-based
    ML pipelines.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨一个专门的ML云服务——AWS SageMaker，它提供了一个针对特定平台构建和托管基于云的ML管道的解决方案。
