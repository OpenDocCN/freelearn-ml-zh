<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">When in Doubt, Use Random Forests</h1>
                </header>
            
            <article>
                
<p class="CDPAlignLeft3"><span class="calibre5">In this chapter, we will cover the following recipes:</span></p>
<ul class="calibre10">
<li class="calibre11">Introduction to random forests</li>
<li class="calibre11">Implementing a random forest for predicting credit card defaults using scikit-learn</li>
<li class="calibre11">Implementing a random forest for predicting credit card defaults using H2O</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to random forests</h1>
                </header>
            
            <article>
                
<p class="calibre2">A random forest is a supervised machine learning algorithm based on ensemble learning. It is used for both regression and classification problems. The general idea behind random forests is to build multiple decision trees and aggregate them to get an accurate result. <span class="calibre5">A decision tree is a deterministic algorithm, which means if the same data is given to it, the same tree will be produced each time. They have a tendency to overfit, because they build the best tree possible with the given data, but may fail to generalize when unseen data is provided. </span><span class="calibre5">All the decision trees that make up a random forest are different because we build </span>each tree on a different random subset of our data. A <span class="calibre5">random forest</span><span class="calibre5"> tends to be more accurate than a single decision tree because it minimizes overfitting.</span> </p>
<p class="calibre2">The following diagram demonstrates bootstrap sampling being done from the source sample. Models are built on each of the samples and then the predictions are combined to arrive at a final result:</p>
<p class="CDPAlignCenter"><img class="aligncenter75" src="assets/b7a368ae-ce16-47db-96c7-5ab98ab0b289.png"/></p>
<p class="calibre2">Each tree in a random forest is built using the following steps where A represents the entire forest, a represents a single tree, for <em class="calibre13">a = 1</em> to <em class="calibre13">A</em>:</p>
<ol class="calibre14">
<li class="calibre11">Create a bootstrap sample with replacement, <em class="calibre23">D</em> training from <em class="calibre23">x</em>, <em class="calibre23">y</em> label these <em class="calibre23">X<sub class="calibre32">a</sub></em><sub class="calibre32">, </sub><em class="calibre23">Y<sub class="calibre32">a</sub></em></li>
<li class="calibre11">Train the tree <em class="calibre23">f<sub class="calibre32">a</sub></em> on <em class="calibre23">X<sub class="calibre32">a</sub></em>, <em class="calibre23">Y<sub class="calibre32">a</sub></em></li>
<li class="calibre11">Average the predictions or take the majority vote to arrive at a final prediction</li>
</ol>
<p class="calibre2"><span class="calibre5">In a regression problem, predictions for the test instances</span><span class="calibre5"> are made by taking the mean of the predictions made by all trees. This can be represented as follows: </span></p>
<p class="CDPAlignCenter"><img class="fm-editor-equation62" src="assets/b058aa6d-f242-48e0-ab2c-e20bca7feca3.png"/></p>
<p class="calibre2">Here, <em class="calibre13">N</em> is the total number of trees in the random forest. <em class="calibre13">a=1</em> represents the first tree in a forest, while the last tree in the forest is <em class="calibre13">A</em>. <img class="fm-editor-equation63" src="assets/b6820836-5f23-4996-b72c-86e17bcfbed3.png"/>(<img class="fm-editor-equation64" src="assets/d7f322ac-15d3-4190-bea7-6b3f7250eba4.png"/>) represents the prediction from a single tree.</p>
<p class="calibre2">If we have a classification problem,<span class="calibre5"> majority voting or the most common answer is used. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing a random forest for predicting credit card defaults using scikit-learn</h1>
                </header>
            
            <article>
                
<p class="calibre2">The scikit-learn library implements<span class="calibre5"> </span><span class="calibre5">random forests by providing two estimators:</span> <kbd class="calibre12">RandomForestClassifier</kbd><kbd class="calibre12"><span> </span></kbd><span class="calibre5">and <kbd class="calibre12">RandomForestRegressor</kbd>. They take various parameters, some of which are explained as follows:</span></p>
<ul class="calibre10">
<li class="calibre11"><kbd class="calibre12"><span> </span>n_estimators</kbd>:<strong class="calibre1"> </strong>This parameter is the number of trees the algorithm builds before taking a maximum vote or the average prediction. In general, the higher the number of trees the better the performance and the accuracy of the predictions, but it also costs more in terms of computation.</li>
<li class="calibre11"><kbd class="calibre12">max_features</kbd>: This parameter <span><span>is the maximum number of features that the random forest is allowed to try in an individual tree. </span></span></li>
<li class="calibre11"><kbd class="calibre12">min_sample_leaf</kbd>:<strong class="calibre1"> </strong><span>This parameter determines the minimum number of leaves that are required to split an internal node.</span></li>
<li class="calibre11"><kbd class="calibre12">n_jobs</kbd>:<span> This</span> <span>hyperparameter tells the engine how many jobs to run in parallel for both fitting the model and predicting new instances. If it has a value of <kbd class="calibre12">None</kbd> or <kbd class="calibre12">1</kbd>, it runs only one job. A value of <kbd class="calibre12">-1</kbd> means it will use all the processors.</span></li>
<li class="calibre11"><kbd class="calibre12">random_state</kbd>:<strong class="calibre1"> </strong><span>This parameter will always produce the same results when it has a definite value of <kbd class="calibre12">random_state</kbd> and if it has been given the same hyperparameters and the same training data.</span></li>
<li class="calibre11"><kbd class="calibre12">oob_score</kbd>: This parameter is <span>also known as</span> <strong class="calibre1"><span>out-of-the-bag</span><span> </span></strong><span><strong class="calibre1">sampling</strong>, and is a random forest cross-validation method. In this sampling method, about one-third of the data is not used to train the model and can be used to evaluate its performance. These samples are called the </span><strong class="calibre1"><span>out-of-the-bag</span></strong> <span><strong class="calibre1">samples</strong>. </span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="calibre2">In this example, we use a dataset from the UCI ML repository on credit card defaults. This dataset contains the following information:</p>
<ul class="calibre10">
<li class="calibre11">Default payments</li>
<li class="calibre11">Demographic factors</li>
<li class="calibre11">Credit data</li>
<li class="calibre11">History of payments</li>
<li class="calibre11">Bill statements of credit card clients</li>
</ul>
<p class="calibre2">The data and the data descriptions are provided in the GitHub folder:</p>
<p class="calibre2">We will start by loading the required libraries and reading our dataset:</p>
<pre class="calibre15">import os<br class="title-page-name"/>import numpy as np<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>%matplotlib inline<br class="title-page-name"/>import seaborn as sns</pre>
<p class="calibre2">We set our working folder as follows:</p>
<pre class="calibre15"># Set your working directory according to your requirement<br class="title-page-name"/>os.chdir(".../Chapter 6/Random Forest")<br class="title-page-name"/>os.getcwd()</pre>
<p class="calibre2">Let's now read our data. We will prefix the DataFrame name with <kbd class="calibre12">df_</kbd> so that we can understand it easily:</p>
<pre class="calibre15">df_creditcarddata = pd.read_csv("UCI_Credit_Card.csv")</pre>
<p class="calibre2">We check the shape of the dataset:</p>
<pre class="calibre15">df_creditcarddata.shape</pre>
<p class="calibre2">We check the datatypes:</p>
<pre class="calibre15">df_creditcarddata.dtypes</pre>
<p class="calibre2">We drop the <kbd class="calibre12">ID</kbd> column, as this is not required:</p>
<pre class="calibre15">df_creditcarddata = df_creditcarddata.drop("ID", axis= 1) </pre>
<p class="calibre2"/>
<p class="calibre2">We can explore our data in various ways. Let's take a look at a couple of different methods:</p>
<pre class="calibre15">selected_columns = df_creditcarddata[['AGE','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6', 'LIMIT_BAL']]<br class="title-page-name"/><br class="title-page-name"/>selected_columns.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);</pre>
<div class="packttip">Note that we have used a semicolon in the last line in the preceding code block. The semicolon helps to hide the verbose information produced by Matplotlib. <kbd class="calibre19">xlabelsize</kbd> and <kbd class="calibre19">ylabelsize</kbd> are used to adjust the font size in the x-axis and the y-axis.</div>
<p class="calibre2">The following plot shows the distribution of the numeric variables:</p>
<p class="CDPAlignCenter"><img src="assets/9ea0dcfd-9bd1-47c3-9207-8d476ce78ee0.png" class="calibre33"/></p>
<p class="calibre2">We will now explore the payment defaults by age group. We bucket the <kbd class="calibre12">age</kbd> variable and store the binned values in a new variable, <kbd class="calibre12">age_group</kbd>, in <kbd class="calibre12">df_creditcarddata</kbd>:</p>
<pre class="calibre15">df_creditcarddata['agegroup'] = pd.cut(df_creditcarddata['AGE'], range(0, 100, 10), right=False)<br class="title-page-name"/>df_creditcarddata.head()</pre>
<p class="calibre2">We then use our new <kbd class="calibre12">age_group</kbd> <span class="calibre5">variable</span><span class="calibre5"> </span><span class="calibre5">to plot the number of defaults per age group:</span></p>
<pre class="calibre15"># Default vs Age<br class="title-page-name"/>pd.crosstab(df_creditcarddata.age_group, \<br class="title-page-name"/>           df_creditcarddata["default.payment.next.month"]).plot(kind='bar',stacked=False, grid=True) <br class="title-page-name"/><br class="title-page-name"/>plt.title('Count of Defaults by AGE')<br class="title-page-name"/>plt.xlabel('AGE')<br class="title-page-name"/>plt.ylabel('# of Default')<br class="title-page-name"/>plt.legend(loc='upper left')</pre>
<p class="calibre2">The following screenshot shows the amount of defaults per age:</p>
<p class="CDPAlignCenter"><img src="assets/a01f25a0-5db7-469d-b4b7-e1638ac2ed03.png" class="calibre34"/></p>
<p class="calibre2"><span class="calibre5">We can drop the <kbd class="calibre12">age_group</kbd> variable from <kbd class="calibre12">df_creditcarddata</kbd> since we do not need it anymore:</span></p>
<pre class="calibre15">df_creditcarddata = df_creditcarddata.drop(columns = ['age_group'])<br class="title-page-name"/>df_creditcarddata.head()</pre>
<p class="calibre2"><span class="calibre5">We will now look at the payment defaults according to the credit limits of the account holders:</span></p>
<pre class="calibre15">fig_facetgrid = sns.FacetGrid(df_creditcarddata, hue='default.payment.next.month', aspect=4)<br class="title-page-name"/>fig_facetgrid.map(sns.kdeplot, 'LIMIT_BAL', shade=True)<br class="title-page-name"/>max_limit_bal = df_creditcarddata['LIMIT_BAL'].max()<br class="title-page-name"/>fig_facetgrid.set(xlim=(0,max_limit_bal));<br class="title-page-name"/>fig_facetgrid.set(ylim=(0.0,0.000007));<br class="title-page-name"/>fig_facetgrid.set(title='Distribution of limit balance by default.payment')<br class="title-page-name"/>fig_facetgrid.add_legend()</pre>
<p class="calibre2">The preceding code gives us the following plot:</p>
<p class="CDPAlignCenter"><img src="assets/8ca04a04-c2dc-4bac-bbf1-55319d9dee18.png" class="calibre33"/></p>
<p class="calibre2">We can also assign labels to some of our variables to make the interpretations better. We assign labels for the <kbd class="calibre12">Gender</kbd>, <kbd class="calibre12">Marriage</kbd>, and <kbd class="calibre12">Education</kbd> variables.</p>
<p class="calibre2">We also change the datatype of the <kbd class="calibre12">pay</kbd> variables to the string:</p>
<pre class="calibre15">GenderMap = {2:'female', 1:'male'}<br class="title-page-name"/>MarriageMap = {1:'married', 2:'single', 3:'other', 0: 'other'}<br class="title-page-name"/>EducationMap = {1:'graduate school', 2:'university', 3:'high school', 4:'others', 5:'unknown', 6:'unknown', 0:'unknown'}<br class="title-page-name"/><br class="title-page-name"/>df_creditcarddata['SEX'] = df_creditcarddata.SEX.map(GenderMap)<br class="title-page-name"/>df_creditcarddata['MARRIAGE'] = df_creditcarddata.MARRIAGE.map(MarriageMap) <br class="title-page-name"/>df_creditcarddata['EDUCATION'] = df_creditcarddata.EDUCATION.map(EducationMap)<br class="title-page-name"/>df_creditcarddata['PAY_0'] = df_creditcarddata['PAY_0'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_2'] = df_creditcarddata['PAY_2'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_3'] = df_creditcarddata['PAY_3'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_4'] = df_creditcarddata['PAY_4'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_5'] = df_creditcarddata['PAY_5'].astype(str) <br class="title-page-name"/>df_creditcarddata['PAY_6'] = df_creditcarddata['PAY_6'].astype(str) </pre>
<p class="calibre2"><span class="calibre5">There are more explorations available in the code bundle provided with this book. We now move on to training our random forest model.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">We will now look at how to use a random forest to train our model:</span></p>
<ol class="calibre14">
<li class="calibre11">We start by splitting our target and feature variables:</li>
</ol>
<pre class="calibre18">predictor= df_creditcarddata.iloc[:, df_creditcarddata.columns != 'default.payment.next.month']<br class="title-page-name"/>target= df_creditcarddata.iloc[:, df_creditcarddata.columns == 'default.payment.next.month']</pre>
<ol start="2" class="calibre14">
<li class="calibre11">We separate the numerical and non-numerical variables in our feature set:</li>
</ol>
<pre class="calibre18"># save all categorical columns in list<br class="title-page-name"/>categorical_columns = [col for col in predictor.columns.values if predictor[col].dtype == 'object']<br class="title-page-name"/><br class="title-page-name"/># dataframe with categorical features<br class="title-page-name"/>df_categorical = predictor[categorical_columns]<br class="title-page-name"/><br class="title-page-name"/># dataframe with numerical features<br class="title-page-name"/>df_numeric = predictor.drop(categorical_columns, axis=1)</pre>
<ol start="3" class="calibre14">
<li class="calibre11">We dummy code the categorical variables:</li>
</ol>
<pre class="calibre18">dummy_code_cat_vars = pd.get_dummies(df_categorical,drop_first=True)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">We concatenate the dummy code variables to our DataFrame:</li>
</ol>
<pre class="calibre18">df_predictor = pd.concat([df_numeric, dummy_code_cat_vars], axis=1)<br class="title-page-name"/>df_predictor.head()</pre>
<ol start="5" class="calibre14">
<li class="calibre11">We split our dataset into training and testing subsets:</li>
</ol>
<pre class="calibre18">from sklearn.model_selection import train_test_split<br class="title-page-name"/>X_train,X_test, y_train, y_test = train_test_split(df_predictor, target, test_size = 0.30, random_state=0)<br class="title-page-name"/>print("x_train ",X_train.shape)<br class="title-page-name"/>print("x_test ",X_test.shape)<br class="title-page-name"/>print("y_train ",y_train.shape)<br class="title-page-name"/>print("y_test ",y_test.shape)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">We scale the features with <kbd class="calibre12">StandardScaler()</kbd>:</li>
</ol>
<pre class="calibre18">from sklearn.preprocessing import StandardScaler<br class="title-page-name"/>scaler = StandardScaler()</pre>
<ol start="7" class="calibre14">
<li class="calibre11">We might notice that the column names have been changed to numbers. We assign the columns names and index values back to the scaled <span>DataFrame</span>:</li>
</ol>
<pre class="calibre18">X_train_scaled.columns = X_train.columns.values<br class="title-page-name"/>X_test_scaled.columns = X_test.columns.values<br class="title-page-name"/>X_train_scaled.index = X_train.index.values<br class="title-page-name"/>X_test_scaled.index = X_test.index.values<br class="title-page-name"/><br class="title-page-name"/>X_train = X_train_scaled<br class="title-page-name"/>X_test = X_test_scaled</pre>
<ol start="8" class="calibre14">
<li class="calibre11">We import <kbd class="calibre12">RandomForestClassifier()</kbd> from <kbd class="calibre12">sklearn.ensemble</kbd>. We will then build our random forest classifier model:</li>
</ol>
<pre class="calibre18">from sklearn.ensemble import RandomForestClassifier<br class="title-page-name"/><br class="title-page-name"/>classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\<br class="title-page-name"/> criterion = 'entropy', max_leaf_nodes= 20,oob_score = True, n_jobs = -1 )<br class="title-page-name"/><br class="title-page-name"/># fit the model<br class="title-page-name"/>model_RF = classifier.fit(X_train, y_train)</pre>
<ol start="9" class="calibre14">
<li class="calibre11">After that, we calculate the accuracy of our training model:</li>
</ol>
<pre class="calibre18">acc_random_forest = round(classifier.score(X_train, y_train) * 100, 2)<br class="title-page-name"/>print(round(acc_random_forest,2,), "%")</pre>
<ol start="10" class="calibre14">
<li class="calibre11">We get the <strong class="calibre1">f</strong><span><strong class="calibre1">alse positive rate</strong> </span>(<strong class="calibre1"><span>FPR</span></strong>) and <strong class="calibre1">t</strong><span><strong class="calibre1">rue positive rate</strong> </span>(<strong class="calibre1"><span>TPR</span></strong>) by passing <kbd class="calibre12">y_test</kbd> and <kbd class="calibre12">y_pred_proba</kbd> to <kbd class="calibre12">roc_curve()</kbd>. We also get the <kbd class="calibre12"><span>auc </span></kbd>value using <kbd class="calibre12">roc_auc_score()</kbd>. Using the FPR, TPR, and the AUC value, we plot the ROC curve with the AUC value annotated on the plot:</li>
</ol>
<pre class="calibre18">from sklearn import metrics<br class="title-page-name"/><br class="title-page-name"/>y_pred_proba = model_RF.predict_proba(X_test)[::,1]<br class="title-page-name"/>fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)<br class="title-page-name"/>auc = metrics.roc_auc_score(y_test, y_pred_proba)<br class="title-page-name"/>plt.plot(fpr,tpr,label="AUC="+str(auc))<br class="title-page-name"/>plt.legend(loc=4)<br class="title-page-name"/>plt.show()</pre>
<p class="calibre20">The following graph shows the ROC curve with the AUC value annotated on it:</p>
<p class="CDPAlignCenter"><img class="aligncenter76" src="assets/43c5f4c5-d916-4f76-a3b4-8bf301a6926f.png"/></p>
<ol start="11" class="calibre14">
<li class="calibre11">We can also evaluate other scores, as shown here:</li>
</ol>
<pre class="calibre18"># predict the model<br class="title-page-name"/>y_pred_RF = model_RF.predict(X_test)<br class="title-page-name"/><br class="title-page-name"/># evaluate other scores<br class="title-page-name"/>evaluation_scores = pd.Series({'Model': " Random Forest Classifier ",<br class="title-page-name"/>'ROC Score' : metrics.roc_auc_score(y_test, y_pred_RF),<br class="title-page-name"/>'Precision Score': metrics.precision_score(y_test, y_pred_RF),<br class="title-page-name"/>'Recall Score': metrics.recall_score(y_test, y_pred_RF),<br class="title-page-name"/>'Accuracy Score': metrics.accuracy_score(y_test, y_pred_RF),<br class="title-page-name"/>'Kappa Score':metrics.cohen_kappa_score(y_test, y_pred_RF)})<br class="title-page-name"/><br class="title-page-name"/>print(evaluation_scores)</pre>
<p class="calibre20">The preceding code produces the following evaluation scores:</p>
<p class="CDPAlignCenter"><img class="aligncenter77" src="assets/dac2941b-1804-4d74-977b-f9878a69d72a.png"/></p>
<ol start="12" class="calibre14">
<li class="calibre11"><span>We can also evaluate a few statistics based on the class of the target variable, which in this case is <kbd class="calibre12">0</kbd> or <kbd class="calibre12">1</kbd>:</span></li>
</ol>
<pre class="calibre18">from sklearn.metrics import classification_report<br class="title-page-name"/>print(classification_report(y_test, y_pred_RF))</pre>
<p class="calibre20"><kbd class="calibre12">classification_report</kbd> from <kbd class="calibre12">sklearn.metrics</kbd> gives us the following scores based on each class of the target variable:</p>
<p class="CDPAlignCenter"><img class="aligncenter78" src="assets/eb489a75-2234-4f49-86ce-191e94fd501c.png"/></p>
<p class="calibre2"/>
<ol start="13" class="calibre14">
<li class="calibre11">We can plot the top 10 variables by feature importance to see which variables are important for the model:</li>
</ol>
<pre class="calibre18">feature_importances = pd.Series(classifier.feature_importances_, index=X_train.columns)<br class="title-page-name"/>feature_importances.nlargest(10).plot(kind='barh') #top 10 features</pre>
<p class="calibre20">The following screenshot shows the top 10 variables with their relative importance:</p>
<p class="CDPAlignCenter"><img src="assets/152d22d8-51d0-4861-9e34-66ac936652a2.png" class="calibre35"/></p>
<p class="calibre2">We can change the hyperparameters to see how the model can perform better. We can also perform a grid search over combinations of hyperparameter values to fine-tune our model.</p>
<p class="calibre2"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="calibre2">In <em class="calibre13">Step 1</em>, we split our target and feature variables. In <em class="calibre13">Step 2</em>, in our feature set, we separated the numeric and non-numeric variables. In <em class="calibre13">Step 3</em> and <em class="calibre13">Step 4</em>, we converted the non-numeric variables to dummy coded variables and added them back to the <span class="calibre5">DataFrame</span>. In <em class="calibre13">Step 5</em>, we split our dataset into training and testing subsets, and in <em class="calibre13">Step 6</em>, we imported <kbd class="calibre12">StandardScaler()</kbd> from <kbd class="calibre12">sklearn.preprocessing</kbd> and applied the same scale to our features. </p>
<p class="calibre2">After executing the commands in <em class="calibre13">Step 6</em>, we noticed that the column names had changed to sequential numbers. For this reason, in <em class="calibre13">Step 7</em>, we assigned the column names and the index values back to the scaled DataFrame. In <em class="calibre13">Step 8</em>, <span class="calibre5">we imported <kbd class="calibre12">RandomForestClassifier()</kbd> from</span> <kbd class="calibre12">sklearn<span>.ensemble</span></kbd> <span class="calibre5">and built our first random forest classifier model. After that, in</span><span class="calibre5"> <em class="calibre13">Step 9</em> and <em class="calibre13">Step 10</em>, we used our model to calculate the accuracy of our training model and plotted the ROC curve respectively. We also annotated the ROC Curve with the AUC value. </span></p>
<p class="calibre2">In <em class="calibre13">Step 11</em>, we evaluated other scores, including the kappa value, the precision, the recall, and the accuracy.</p>
<p class="calibre2">In <em class="calibre13">Step 12</em>, we also evaluated these scores based on each class of the target variable, <span class="calibre5">which in this case is <kbd class="calibre12">0</kbd> or <kbd class="calibre12">1</kbd>,</span><span class="calibre5"> </span>using <span class="calibre5"><kbd class="calibre12">classification_report</kbd> from <kbd class="calibre12">sklearn.metrics</kbd>. There, </span><kbd class="calibre12">classification_report()</kbd><span class="calibre5"> provides us with</span> metrics such as precision, recall, and f1-score by each class, as well as the average of each of the metrics.</p>
<p class="calibre2"><kbd class="calibre12"><span>classification_report()</span></kbd> <span class="calibre5">reports averages, including averaging the total true positives, false negatives and false positives, averaging the unweighted mean per label, and averaging the support-weighted mean per label. It also reports sample averages for multi-label classification.</span></p>
<p class="calibre2">Finally, in <em class="calibre13">Step 13</em>, we looked at the relative variable importance of the top 10 features. This can help in feature selection to build the models with the right features.</p>
<div class="packtinfobox"><span>There are various feature selection methods available, such as averaged variable, importance, Boruta, </span><span>recursive feature selection, and </span><span>variable selection using RF.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">Isolation forest is another algorithm that is built on the basis of decision trees, and </span><span class="calibre5">it's used for anomaly and outlier detection. This algorithm is based on the assumption that the outlier data points are rare.</span></p>
<p class="calibre2">The algorithm works a bit differently to the random forest. It creates a bunch of decision trees, then it calculates the path length necessary to isolate an observation in the tree. The idea is that isolated observations, or anomalies, are easier to separate because there are fewer conditions necessary to distinguish them from normal cases. Thus, the anomalies will have shorter paths than normal observations and will, therefore, reside closer to the root of the tree. When several decision trees are created, the scores are averaged, which gives us a good idea about which observations are truly anomalies. As a result, isolation forests are used for outliers and anomaly detection. </p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2"><span class="calibre5">Also, an isolation forest does not utilize any distance or density measures to detect an anomaly. This reduces the computational cost significantly compared to the distance-based and density-based methods.</span></p>
</div>
</div>
</div>
<p class="calibre2">In scikit-learn, <kbd class="calibre12">sklearn.ensemble.IsolationForest</kbd> provides an implementation of the isolation forest algorithm.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul class="calibre10">
<li class="calibre11">The scikit-learn implementation of the isolation forest algorithm can be found here: <a href="https://bit.ly/2DCjGGF" class="calibre9">https://bit.ly/2DCjGGF</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing random forest for predicting credit card defaults using H2O</h1>
                </header>
            
            <article>
                
<p class="calibre2">H2O is an open source and distributed machine learning platform that allows you to build machine learning models on large datasets. H2O supports both supervised and unsupervised algorithms and is extremely fast, scalable, and easy to implement. H2O's REST API <span class="calibre5">allows us to access all its functionalities from external programs such as R and Python.</span> <span class="calibre5">H2O in Python is designed to be very similar to scikit-learn. </span>At the time of writing this book, the latest version of H2O is H2O v3.</p>
<p class="calibre2">The reason why H2O brought lightning-fast machine learning to enterprises is given by the following explanation:</p>
<div class="packtquote"><span>"H2O's core code is written in Java. Inside H2O, a distributed key/value store is used to access and reference data, models, objects, and so on, across all nodes and machines. The algorithms are implemented on top of H2O's distributed Map/Reduce framework and utilize the Java fork/join framework for multi-threading. The data is read in parallel and is distributed across the cluster and stored in memory in a columnar format in a compressed way. H2O's data parser has built-in intelligence to guess the schema of the incoming dataset and supports data ingest from multiple sources in various formats"</span></div>
<div class="packtquote2"><span>- from h2o.ai</span></div>
<p class="calibre2">H2O provides us with distributed random forests, which are a powerful tool used for classification and regression tasks. This generates multiple trees, rather than single trees. In a distributed random forest, we use the average predictions of both the classification and regression models to reach a final result.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="calibre2">Java is an absolute must for H2O to run. Make sure you have Java installed with the following command in Jupyter:</p>
<pre class="calibre15"><strong class="calibre1">! apt-get install default-jre</strong><br class="title-page-name"/><strong class="calibre1">! java -version</strong></pre>
<p class="calibre2">You will <span class="calibre5">now</span><span class="calibre5"> </span><span class="calibre5">need to install H2O. To install this from Jupyter, use the following command:</span></p>
<pre class="calibre15"><strong class="calibre1">! pip install h2o</strong></pre>
<p class="calibre2">Import the required libraries:</p>
<pre class="calibre15">import h2o<br class="title-page-name"/>import seaborn as sns<br class="title-page-name"/>import numpy as np<br class="title-page-name"/>import pandas as pd<br class="title-page-name"/>import seaborn<br class="title-page-name"/>import matplotlib.pyplot as plt<br class="title-page-name"/>%matplotlib inline<br class="title-page-name"/><br class="title-page-name"/>from h2o.estimators.random_forest import H2ORandomForestEstimator<br class="title-page-name"/>from sklearn import metrics</pre>
<p class="calibre2"><span class="calibre5">To use H2O, we need to initialize an instance and connect to it. We can do that as follows:</span></p>
<pre class="calibre15">h2o.init()</pre>
<p class="calibre2">By default, the preceding command tries to connect to an instance. If it fails to do so, it will attempt to start an instance and then connect to it. Once connected to an instance, we will see the details of that instance, as follows:</p>
<p class="CDPAlignCenter"><img src="assets/845d5994-fe6f-4d56-abfe-db1c235d5142.png" class="calibre36"/></p>
<p class="calibre2">We read our data into a <kbd class="calibre12">pandas</kbd> <span class="calibre5">DataFrame</span>:</p>
<pre class="calibre15">df_creditcarddata = pd.read_csv("UCI_Credit_Card.csv")</pre>
<p class="calibre2">We change our <kbd class="calibre12">pandas</kbd> DataFrame to an H2O <span class="calibre5">DataFrame </span>using <kbd class="calibre12">h2o.H2OFrame()</kbd>. We name the <kbd class="calibre12">df_creditcarddata</kbd> <span class="calibre5">H2O DataFrame</span>:</p>
<pre class="calibre15">hf_creditcarddata = h2o.H2OFrame(df_creditcarddata)</pre>
<p class="calibre2">Check whether the data in the H2O <span class="calibre5">DataFrame </span>is properly loaded as follows:</p>
<pre class="calibre15">hf_creditcarddata.head()</pre>
<p class="calibre2">We can see the summary statistics with the <kbd class="calibre12">describe()</kbd> method:</p>
<pre class="calibre15">hf_creditcarddata.describe()</pre>
<p class="calibre2"/>
<p class="calibre2">We drop the ID column, as this will not be required for our model building exercise:</p>
<pre class="calibre15">hf_creditcarddata = hf_creditcarddata.drop(["ID"], axis = 1) </pre>
<p class="calibre2">We will now move on to explore our data and build our model. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p class="calibre2"><span class="calibre5">We have performed various explorations on our data in the previous section. There is no limit to the ways in which we can explore our data. In this section, we are going to look at a few more techniques:</span></p>
<ol start="1" class="calibre14">
<li class="calibre11">We check the correlation of each of our feature variables with the target variable:</li>
</ol>
<pre class="calibre18">df_creditcarddata.drop(['default.payment.next.month'], \<br class="title-page-name"/>     axis = 1).corrwith(df_creditcarddata['default.payment.next.month']).\<br class="title-page-name"/>     plot.bar(figsize=(20,10), \<br class="title-page-name"/>     title = 'Correlation with Response variable', \<br class="title-page-name"/>     fontsize = 15, rot = 45, grid = True)</pre>
<p class="calibre20">The following plot shows how each of the features is correlated with the target variable:</p>
<p class="CDPAlignCenter"><img src="assets/fac4a15a-c60d-4fca-9ae4-01edb2638f15.png" class="calibre33"/></p>
<ol start="2" class="calibre14">
<li class="calibre11">We check the datatypes in the H2O <span>DataFrame</span>. Note that for the <kbd class="calibre12">pandas</kbd> <span>DataFrame, </span>we used <kbd class="calibre12">dtypes</kbd>. For the H2O <span>DataFrame</span>, we use types:</li>
</ol>
<pre class="calibre18">hf_creditcarddata.types</pre>
<ol start="3" class="calibre14">
<li class="calibre11">We notice that they are all of the integer datatype. We will convert them to factor type, which is categorical in nature:</li>
</ol>
<pre class="calibre18">hf_creditcarddata['SEX'] = hf_creditcarddata['SEX'].asfactor()<br class="title-page-name"/>hf_creditcarddata['EDUCATION'] = hf_creditcarddata['EDUCATION'].asfactor()<br class="title-page-name"/>hf_creditcarddata['MARRIAGE'] = hf_creditcarddata['MARRIAGE'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_0'] = hf_creditcarddata['PAY_0'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_2'] = hf_creditcarddata['PAY_2'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_3'] = hf_creditcarddata['PAY_3'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_4'] = hf_creditcarddata['PAY_4'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_5'] = hf_creditcarddata['PAY_5'].asfactor()<br class="title-page-name"/>hf_creditcarddata['PAY_6'] = hf_creditcarddata['PAY_6'].asfactor()</pre>
<p class="calibre20">We can check the datatypes with <kbd class="calibre12">hf_creditcarddata.types</kbd> to see that the datatype conversion has taken place.</p>
<ol start="4" class="calibre14">
<li class="calibre11">We will encode the binary target variable as a factor type variable:</li>
</ol>
<pre class="calibre18">hf_creditcarddata['default.payment.next.month'] = \<br class="title-page-name"/>             hf_creditcarddata['default.payment.next.month'].asfactor() <br class="title-page-name"/>hf_creditcarddata['default.payment.next.month'].levels() </pre>
<ol start="5" class="calibre14">
<li class="calibre11">We select the features and the <kbd class="calibre12">target</kbd> variable:</li>
</ol>
<pre class="calibre18">predictors = ['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']<br class="title-page-name"/><br class="title-page-name"/>target = 'default.payment.next.month'</pre>
<ol start="6" class="calibre14">
<li class="calibre11">We now split the H2O <span>DataFrame</span> into training and testing subsets. We use 70% of our data for training the model and the remaining 30% for validation:</li>
</ol>
<pre class="calibre18">splits = hf_creditcarddata.split_frame(ratios=[0.7], seed=123) <br class="title-page-name"/>train = splits[0]<br class="title-page-name"/>test = splits[1] </pre>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2"/>
<ol start="7" class="calibre14">
<li class="calibre11">We build our random forest model with the default settings. You can check the model performance on the test data with the following commands:</li>
</ol>
<pre class="calibre18">from h2o.estimators.random_forest import H2ORandomForestEstimator<br class="title-page-name"/><br class="title-page-name"/>RF_D = H2ORandomForestEstimator(model_id = 'RF_D',seed = 123)<br class="title-page-name"/>RF_D.train(x = predictors, y = target, training_frame = train)<br class="title-page-name"/><br class="title-page-name"/>print(RF_D.model_performance(test))</pre>
<p class="calibre20">This gives us the following performance metrics:</p>
<p class="CDPAlignCenter"><img class="aligncenter79" src="assets/1b237e8e-a899-4125-8590-a66ef4baa7a0.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="calibre2">In the <em class="calibre13">Getting ready</em> section, we installed JRE and H2O. We initialized and connected to an H2O instance with <kbd class="calibre12">h2o.init()</kbd>. We then read our data using <kbd class="calibre12">pandas</kbd> and converted it to an H2O <span class="calibre5">DataFrame</span>. We used the <kbd class="calibre12">head()</kbd> and <kbd class="calibre12">describe()</kbd> methods on the H2O <span class="calibre5">DataFrame</span>, just like we used them on a <kbd class="calibre12">pandas</kbd> <span class="calibre5">DataFrame</span>. We then dropped the <kbd class="calibre12">ID</kbd> column from the H2O <span class="calibre5">DataFrame</span>. </p>
<p class="calibre2">After we did these data explorations in the <em class="calibre13">Getting ready</em> section, we moved on to the next steps. In <em class="calibre13">Step 1,</em> we checked the correlation of each of the features with the <kbd class="calibre12">target</kbd> variable. In <em class="calibre13">Step 2</em>, we used the <kbd class="calibre12">h2o</kbd> <span class="calibre5">DataFrame </span>and checked the datatypes. </p>
<p class="calibre2"/>
<div class="packtinfobox">Note that for the <kbd class="calibre19">pandas</kbd> <span>DataFrame</span> we used <kbd class="calibre19">dtypes</kbd>, whereas we used <kbd class="calibre19">types</kbd> with the <kbd class="calibre19">h2o </kbd><span>DataFrame</span>.</div>
<p class="calibre2">In <em class="calibre13">Step 3</em>, we used <kbd class="calibre12">asfactor()</kbd> to convert the numeric variables to the categorical type. We performed this on variables that were supposed to be of a categorical type but were appearing as numeric. </p>
<div class="packtinfobox">In previous examples, we used the <kbd class="calibre19">astype()</kbd> method on a <kbd class="calibre19">pandas</kbd> <span>DataFrame</span>. With an H2O <span>DataFrame</span>, we used the <kbd class="calibre19">asfactor()</kbd> method.</div>
<p class="calibre2">In <em class="calibre13">Step 4</em>, we used <kbd class="calibre12">asfactor()</kbd> on our <kbd class="calibre12">target</kbd> variable to convert it to a categorical variable.</p>
<p class="calibre2">In <em class="calibre13">Step 5</em>, we separated our features and the <kbd class="calibre12">target</kbd> variable. In <em class="calibre13">Step</em> 6, <span class="calibre5">we split the H2O DataFrame into training and testing subsets using </span><span class="calibre5"><kbd class="calibre12">split_frame()</kbd> on our H2O DataFrame. We used the <kbd class="calibre12">ratios</kbd> parameter and set it to <kbd class="calibre12">ratios=[0.7]</kbd> for</span> <span class="calibre5"><kbd class="calibre12">split_frame()</kbd> to allocate 70% of the data to the training set and 30% of the data to the testing set.</span></p>
<p class="calibre2">In <em class="calibre13">Step 7</em>, we <span class="calibre5">imported <kbd class="calibre12">H2ORandomForestEstimator</kbd> from <kbd class="calibre12">h2o.estimators.random_forest</kbd>. We passed <kbd class="calibre12">model_id</kbd></span> <span class="calibre5">and then referred to it to call the <kbd class="calibre12">train()</kbd> function and pass the predictor and the <kbd class="calibre12">target</kbd> variables. We then looked at the performance metrics by passing the test subset to</span> <span class="calibre5"><kbd class="calibre12">model_performance()</kbd>. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p class="calibre2">In our preceding example, we have an AUC of <kbd class="calibre12">0.76</kbd> and a log loss of <kbd class="calibre12"><span><span>0.44</span></span></kbd>:</p>
<ol class="calibre14">
<li class="calibre11">We can apply cross-validation by passing <kbd class="calibre12">nfolds</kbd> as a parameter to <kbd class="calibre12">H2ORandomForestEstimator()</kbd>:</li>
</ol>
<pre class="calibre18">RF_cv = H2ORandomForestEstimator(model_id = 'RF_cv', <br class="title-page-name"/>                                 seed = 12345, <br class="title-page-name"/>                                 ntrees = 500, <br class="title-page-name"/>                                 sample_rate = 0.9, <br class="title-page-name"/>                                 col_sample_rate_per_tree = 0.9, <br class="title-page-name"/>                                 nfolds = 10)<br class="title-page-name"/>                                            <br class="title-page-name"/>RF_cv.train(x = predictors, y = target, training_frame = train)<br class="title-page-name"/>print(RF_cv.model_performance(test))</pre>
<p class="calibre20">We notice that the AUC has slightly improved to <kbd class="calibre12">0.77</kbd> and that the log loss has dropped to <kbd class="calibre12">0.43</kbd>:</p>
<p class="CDPAlignCenter"><img class="aligncenter80" src="assets/ee005306-9054-40e0-b54f-eb0931b04b2d.png"/></p>
<p class="calibre2"/>
<ol start="2" class="calibre14">
<li class="calibre11">We can also apply a grid search to extract the best model from the given options. We set our options as follows:</li>
</ol>
<pre class="calibre18">search_criteria = {'strategy': "RandomDiscrete"}<br class="title-page-name"/><br class="title-page-name"/>hyper_params = {'sample_rate': [0.5, 0.6, 0.7],\<br class="title-page-name"/>                'col_sample_rate_per_tree': [0.7, 0.8, 0.9],\<br class="title-page-name"/>                'max_depth': [3, 5, 7]}</pre>
<ol start="3" class="calibre14">
<li class="calibre11">We build the model with the preceding search parameters:</li>
</ol>
<pre class="calibre18">from h2o.grid.grid_search import H2OGridSearch<br class="title-page-name"/><br class="title-page-name"/>RF_Grid = H2OGridSearch(<br class="title-page-name"/>                    H2ORandomForestEstimator(<br class="title-page-name"/>                        model_id = 'RF_Grid', <br class="title-page-name"/>                        ntrees = 200, <br class="title-page-name"/>                        nfolds = 10,<br class="title-page-name"/>                        stopping_metric = 'AUC', <br class="title-page-name"/>                        stopping_rounds = 25), <br class="title-page-name"/>                    search_criteria = search_criteria, # full grid search<br class="title-page-name"/>                    hyper_params = hyper_params)<br class="title-page-name"/>RF_Grid.train(x = predictors, y = target, training_frame = train)</pre>
<ol start="4" class="calibre14">
<li class="calibre11">We now sort all models by AUC in a descending manner and then pick the first model, which has the highest AUC:</li>
</ol>
<pre class="calibre18">RF_Grid_sorted = RF_Grid.get_grid(sort_by='auc',decreasing=True)<br class="title-page-name"/>print(RF_Grid_sorted)<br class="title-page-name"/><br class="title-page-name"/>best_RF_model = RF_Grid_sorted.model_ids[0]<br class="title-page-name"/>best_RF_from_RF_Grid = h2o.get_model(best_RF_model)</pre>
<ol start="5" class="calibre14">
<li class="calibre11">We apply the best model for our test data:</li>
</ol>
<pre class="calibre18">best_RF_from_RF_Grid.model_performance(test)</pre>
<ol start="6" class="calibre14">
<li class="calibre11">We can plot the variable importance from the best model that we have achieved so far:</li>
</ol>
<ol start="6" class="calibre14"/>
<pre class="calibre18">best_RF_from_RF_G<br class="title-page-name"/>rid.varimp_plot()</pre>
<p class="calibre20">This gives us the following plot:</p>
<p class="CDPAlignCenter"><img src="assets/1014ef94-8e46-46df-af56-802e3ba9589f.png" class="calibre37"/></p>
<p class="calibre2"/>
<p class="calibre2"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p class="calibre2">You may want to look into extremely randomized trees, which have a slightly different implementation but can sometimes perform better than random forests.</p>
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<div class="title-page-name">
<p class="calibre2"><span class="calibre5">In ensemble methods, each model learns differently in terms of the subset of the dataset and the subset of the feature vector used for training. These subsets are taken randomly. </span><span class="calibre5">Extremely randomized trees</span> possess <span class="calibre5">a high randomness factor in the way they compute the splits and </span>the subset <span class="calibre5">of the features</span> <span class="calibre5">selected. Unlike random forests, in which </span>the splitting <span class="calibre5">threshold is chosen randomly, in extremely randomized</span> trees, <span class="calibre5">a discriminative threshold is used as the splitting rule. Due to this, the overall variance of the ensemble decreases and the overall performance may be better.</span></p>
<p class="calibre2">The scikit-learn implementation of <span class="calibre5">extremely randomized</span><span class="calibre5"> trees can be found at the following link: <a href="https://bit.ly/2zWsNNS" class="calibre9">https://bit.ly/2zWsNNS</a><a href="https://bit.ly/2zWsNNS" class="calibre9">. H2O also supports extremely randomized trees. </a></span></p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    </body></html>