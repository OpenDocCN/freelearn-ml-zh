<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;6.&#xA0;Filtering the Images"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06" class="calibre1"/>Chapter 6. Filtering the Images</h1></div></div></div><p class="calibre8">In this chapter, we will cover the following recipes:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Filtering images using low-pass filters</li><li class="listitem">Filtering images using a median filter</li><li class="listitem">Applying directional filters to detect edges</li><li class="listitem">Computing the Laplacian of an image</li></ul></div></div>

<div class="book" title="Chapter&#xA0;6.&#xA0;Filtering the Images">
<div class="book" title="Introduction"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch06lvl1sec41" class="calibre1"/>Introduction</h1></div></div></div><p class="calibre8">Filtering is <a id="id484" class="calibre1"/>one of the fundamental tasks in signal and image processing. It is a process aimed at selectively extracting certain aspects of an image that are considered to convey important information in the context of a given application. Filtering removes noise in images, extracts interesting visual features, allows image resampling, and so on. It finds its roots in the general <a id="id485" class="calibre1"/>
<span class="strong"><strong class="calibre2">Signals and Systems</strong></span> theory. We will not cover this theory in detail here. However, this chapter will present some of the important concepts related to filtering and will show you how filters can be used in image-processing applications. But first, let's begin with a brief explanation of the concept of frequency domain analysis.</p><p class="calibre8">When we look at an image, we observe how the different gray-levels (or colors) are distributed over the image. Images differ from each other because they have a different gray-level distribution. However, there exists another point of view under which an image can be analyzed. We can look at the gray-level variations that are present in an image. Some images contain large areas of almost constant intensity (for example, a blue sky) while in other images, the gray-level intensities vary rapidly over the image (for example, a busy scene crowded with many small objects). Therefore, observing the frequency of these variations in an image constitutes another way of characterizing an image. This point of view is referred to as the <a id="id486" class="calibre1"/>
<span class="strong"><strong class="calibre2">frequency domain</strong></span>, while characterizing an image by observing its gray-level distribution is referred to as the <a id="id487" class="calibre1"/>
<span class="strong"><strong class="calibre2">spatial domain</strong></span>.</p><p class="calibre8">The frequency domain analysis<a id="id488" class="calibre1"/> decomposes an image into its frequency content from the lowest to the highest frequencies. Areas where the image intensities vary slowly contain only low frequencies, while high frequencies are generated by rapid changes in intensities. Several well-known transformations exist, such as the Fourier transform or the Cosine transform, which can be used to explicitly show the frequency content of an image. Note that since an image is a two-dimensional entity, it is made of both vertical frequencies (variations in the vertical directions) and horizontal frequencies (variations in the horizontal directions).</p><p class="calibre8">Under the frequency domain analysis framework, a <span class="strong"><strong class="calibre2">filter</strong></span><a id="id489" class="calibre1"/> is an operation that amplifies certain bands of frequencies of an image while blocking (or reducing) other image frequency bands. A low-pass filter is, therefore, a filter that eliminates the high-frequency components of an image and reciprocally, a high-pass filter eliminates the low-pass components. This chapter will present some filters that are frequently used in image processing and will explain their effect when applied on an image.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Filtering images using low-pass filters"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec42" class="calibre1"/>Filtering images using low-pass filters</h1></div></div></div><p class="calibre8">In this first recipe, we <a id="id490" class="calibre1"/>will present some very basic low-pass filters. In the introductory section of this chapter, we learned that the objective <a id="id491" class="calibre1"/>of such filters is to reduce the amplitude of the image variations. One simple way to achieve this goal is to replace each pixel by the average value of the pixels around it. By doing this, the rapid intensity variations will be smoothed out and thus replaced by a more gradual transition.</p></div>

<div class="book" title="Filtering images using low-pass filters">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch06lvl2sec120" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">The objective of the<a id="id492" class="calibre1"/> <code class="email">cv::blur</code> function is to smooth an image by replacing each pixel with the average pixel value computed over a rectangular neighborhood. This low-pass filter is applied as follows:</p><div class="informalexample"><pre class="programlisting">   cv::blur(image,result,
            cv::Size(5,5)); // size of the filter</pre></div><p class="calibre8">This kind of filter is also called a box filter. Here, we applied it by using a <code class="email">5x5</code> filter in order to make the filter's effect more visible. Take a look at the following screenshot:</p><div class="mediaobject"><img src="../images/00074.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The<a id="id493" class="calibre1"/> result <a id="id494" class="calibre1"/>of the filter being applied on the preceding image is the following screenshot:</p><div class="mediaobject"><img src="../images/00075.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">In some<a id="id495" class="calibre1"/> cases, it might be desirable to give more importance to the closer pixels in the neighborhood <a id="id496" class="calibre1"/>of a pixel. Therefore, it is possible to compute a weighted average in which nearby pixels are assigned a larger weight than ones that are further away. This can be achieved by using a weighted scheme that follows a Gaussian function (a "bell-shaped" function). The <code class="email">cv::GaussianBlur</code> function<a id="id497" class="calibre1"/> applies such a filter and it is called as follows:</p><div class="informalexample"><pre class="programlisting">cv::GaussianBlur(image,
        result, cv::Size(5,5), // size of the filter
        1.5);   // parameter controlling 
                // the shape of the Gaussian</pre></div><p class="calibre8">The result is then shown in the following screenshot:</p><div class="mediaobject"><img src="../images/00076.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div class="book" title="Filtering images using low-pass filters">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch06lvl2sec121" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">A filter is said <a id="id498" class="calibre1"/>to be linear if its application corresponds to replacing a pixel with a weighted sum of neighboring pixels. This is the case of the mean <a id="id499" class="calibre1"/>filter in which a pixel is replaced by the sum of all pixels in a rectangular neighborhood and divided by the size of this neighborhood (to get the average value). This is like multiplying each neighboring pixel by <code class="email">1</code> over the total number of pixels and summing all of these values. The different weights of a filter can be represented using a matrix that shows the multiplying factors associated with each pixel position in the considered neighborhood. The central element of the matrix corresponds to the pixel on which the filter is currently applied. Such a matrix is sometimes called a <a id="id500" class="calibre1"/>
<span class="strong"><strong class="calibre2">kernel</strong></span> or a <a id="id501" class="calibre1"/>
<span class="strong"><strong class="calibre2">mask</strong></span>. For a <code class="email">3x3</code> mean filter, the corresponding kernel would be as follows:</p><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">1/9</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1/9</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1/9</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">1/9</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1/9</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1/9</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">1/9</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1/9</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1/9</p>
</td></tr></tbody></table></div><p class="calibre8">The <code class="email">cv::boxFilter</code> function<a id="id502" class="calibre1"/> filters an image with a square kernel made of many <code class="email">1</code> only. It is similar to the mean filter but without dividing the result by the number of coefficients.</p><p class="calibre8">Applying a linear filter then <a id="id503" class="calibre1"/>corresponds to moving a kernel over each pixel of an image and multiplying each corresponding pixel by its associated weight. Mathematically, this operation is called a <span class="strong"><strong class="calibre2">convolution</strong></span><a id="id504" class="calibre1"/> and can formally be written as follows:</p><div class="mediaobject"><img src="../images/00077.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The preceding<a id="id505" class="calibre1"/> double summation aligns the current pixel at (x,y) with the center of the <a id="id506" class="calibre1"/>K kernel, which is assumed to be at coordinate (0,0).</p><p class="calibre8">Looking at the output images produced in this recipe, it can be observed that the net effect of a low-pass filter is to blur or smooth the image. This is not surprising since this filter attenuates the high-frequency components that correspond to the rapid variations visible on an object's edge.</p><p class="calibre8">In the case of a Gaussian filter, the weight associated with a pixel is proportional to its distance from the central pixel. Recall that the <a id="id507" class="calibre1"/>1D Gaussian function has the following form:</p><div class="mediaobject"><img src="../images/00078.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The normalizing coefficient A is chosen such that the different weights sum to one. The σ (sigma) value controls the width of the resulting Gaussian function. The greater this value is, the flatter the function will be. For example, if we compute the coefficients of the 1D Gaussian filter for the interval [-4, 0, 4] with σ = 0.5, we obtain the following coefficients:</p><div class="informalexample"><pre class="programlisting">[0.0 0.0 0.00026 0.10645 0.78657 0.10645 0.00026 0.0 0.0]</pre></div><p class="calibre8">For σ=1.5, these coefficients are as follows:</p><div class="informalexample"><pre class="programlisting">[0.00761 0.036075 0.10959 0.21345 0.26666 
 0.21345 0.10959 0.03608 0.00761 ]</pre></div><p class="calibre8">Note that these values were obtained by calling the <code class="email">cv::getGaussianKernel</code> function with the appropriate σ value:</p><div class="informalexample"><pre class="programlisting">cv::Mat gauss= cv::getGaussianKernel(9, sigma,CV_32F);</pre></div><p class="calibre8">The symmetrical bell shape of the Gaussian function makes it a good choice for filtering. Refer to the following screenshot:</p><div class="mediaobject"><img src="../images/00079.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Pixels farther from the center have a lower weight, which makes the pixel-to-pixel transitions smoother. This contrasts with the flat mean filter where pixels far away can cause sudden changes in the current mean value. In terms of frequencies, this implies that the mean filter does not remove all the high frequency components.</p><p class="calibre8">To apply a 2D Gaussian filter<a id="id508" class="calibre1"/> on an image, one can simply apply a 1D Gaussian filter on the image lines first (to filter the horizontal frequencies), followed by the application of another 1D Gaussian filter on the image columns (to filter the vertical frequencies). This is possible because the Gaussian filter is a separable filter (that is, the 2D kernel can be decomposed into two 1D filters). The <code class="email">cv::sepFilter2D</code> function<a id="id509" class="calibre1"/> can be used to apply a general separable filter. It is also possible to directly apply a 2D kernel using the <code class="email">cv::filter2D</code> function. In general, separable filters are faster to compute than non-separable ones because they require less multiplication operations.</p><p class="calibre8">With OpenCV, the Gaussian filter to be applied on an image is specified by providing both the number of coefficients (the third parameter, which is an odd number) and the value of σ (the fourth parameter) to <code class="email">cv::GaussianBlur</code>. You can also simply set the value of σ and let OpenCV determine the appropriate number of coefficients (you then input a value of <code class="email">0</code> for the filter size). The opposite is also possible, where you input a size and a value of <code class="email">0</code> for σ. The σ value that best fits the given size will be determined.</p></div></div>

<div class="book" title="Filtering images using low-pass filters">
<div class="book" title="There's more..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch06lvl2sec122" class="calibre1"/>There's more...</h2></div></div></div><p class="calibre8">Low-pass filters<a id="id510" class="calibre1"/> are also used when an image is resized; this section explains why. The resizing of an image might also require interpolating pixel value; this aspect is also discussed in this section.</p><div class="book" title="Downsampling an image"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch06lvl3sec27" class="calibre1"/>Downsampling an image</h3></div></div></div><p class="calibre8">You might <a id="id511" class="calibre1"/>think that you can reduce the size of an image by simply eliminating some of the columns and rows of the image. Unfortunately, the resulting image will not look very nice. The following figure illustrates this fact by showing you a test <a id="id512" class="calibre1"/>image that is reduced by a factor of <code class="email">4</code> with respect to its original size by simply keeping <code class="email">1</code> of every <code class="email">4</code> columns and rows. Note that to make the defects in this image more apparent, we zoom in on the image by displaying it with pixels that are two times larger (the next section explains how this can be done). Refer to the following screenshot:</p><div class="mediaobject"><img src="../images/00080.jpeg" alt="Downsampling an image" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Clearly, one can see that the image quality has degraded. For example, the oblique edges of the castle's roof in the original image now appear as a staircase on the reduced image. Other jagged distortions are also visible on the textured parts of the image (the brick walls, for instance).</p><p class="calibre8">These undesirable artifacts are caused by a phenomenon called <span class="strong"><strong class="calibre2">spatial aliasing</strong></span><a id="id513" class="calibre1"/> that occurs when you try to include high-frequency components in an image that is too small to contain them. Indeed, smaller images (that is, images with fewer pixels) cannot <a id="id514" class="calibre1"/>represent fine textures and sharp edges as nicely as the higher resolution images (think of the difference between high-definition TV versus conventional TV). Since fine details in an image correspond to high frequencies, we need to remove these higher frequency components in an image before reducing its size. We learned in this recipe that this can be done through a low-pass filter. Consequently, to reduce the size of an image by <code class="email">4</code> without adding annoying artifacts, you must first apply a low-pass filter to the original image before throwing away columns and rows. Here is how you would do this using OpenCV:</p><div class="informalexample"><pre class="programlisting">  // first remove high frequency component
  cv::GaussianBlur(image,image,cv::Size(11,11),2.0);
  // keep only 1 of every 4 pixels
  cv::Mat reduced2(image.rows/4,image.cols/4,CV_8U);
  for (int i=0; i&lt;reduced2.rows; i++)
    for (int j=0; j&lt;reduced2.cols; j++)
      reduced2.at&lt;uchar&gt;(i,j)= image.at&lt;uchar&gt;(i*4,j*4);</pre></div><p class="calibre8">The resulting image is as follows:</p><div class="mediaobject"><img src="../images/00081.jpeg" alt="Downsampling an image" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Of course, some of the fine details of the image have been lost, but globally, the visual quality of the image is better preserved than in the previous case.</p><p class="calibre8">A special OpenCV function also performs image reduction. This is the <code class="email">cv::pyrDown</code> function:</p><div class="informalexample"><pre class="programlisting">cv::Mat reducedImage;  // to contain reduced image
cv::pyrDown(image,reducedImage); // reduce image size by half</pre></div><p class="calibre8">The preceding<a id="id515" class="calibre1"/> function uses a <code class="email">5x5</code> Gaussian filter to low-pass the image before reducing it by a factor of two. The reciprocal <code class="email">cv::pyrUp</code> function that doubles the size of an image also exists. It is interesting to note that in this case, the upsampling is done by inserting the <code class="email">0</code> values between every two columns and rows and then by applying the same <code class="email">5x5</code> Gaussian filter (but with the coefficients multiplied by <code class="email">4</code>) on the expanded image. Obviously, if you downsize an image and then upsize it, you will not recover the exact original image. What was lost during the downsizing process cannot be recovered. These two functions are used to create <a id="id516" class="calibre1"/>
<span class="strong"><strong class="calibre2">image pyramids</strong></span>. This is a data structure made of stacked versions of an image at different sizes (here, each level is 2 times smaller than the previous level, but the reduction factor can be less, for example, <code class="email">1.2</code>) that is often built for efficient image analysis. For example, if you want to detect an object in an image, the detection can be first accomplished on the small image at the top of the pyramid, and as you locate the object of interest, you can refine the search by moving to the lower levels of the pyramid that contains the higher resolution versions of the image.</p><p class="calibre8">Note that there is also a more general <code class="email">cv::resize</code> function that allows you to specify the size you want for the resulting image. You simply call it by specifying a new size that could be smaller or larger than the original image:</p><div class="informalexample"><pre class="programlisting">cv::Mat resizedImage;  // to contain resized image
cv::resize(image,resizedImage,
     cv::Size(image.cols/4,image.rows/4)); // 1/4 resizing</pre></div><p class="calibre8">It is also possible to specify resizing in terms of scale factors. In this case, an empty size instance is given as an argument followed by the desired scale factors:</p><div class="informalexample"><pre class="programlisting">cv::resize(image,resizedImage,
           cv::Size(), 1.0/4.0, 1.0/4.0); // 1/4 resizing</pre></div><p class="calibre8">A last parameter allows you to select the interpolation method that is to be used in the resampling process. This is discussed in the following section.</p></div><div class="book" title="Interpolating pixel values"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch06lvl3sec28" class="calibre1"/>Interpolating pixel values</h3></div></div></div><p class="calibre8">When <a id="id517" class="calibre1"/>an image is resized by a factional factor, it becomes necessary to perform some pixel interpolation in order to produce new pixel values at locations that fall in between the existing ones. General image remapping, as discussed in the <span class="strong"><em class="calibre9">Remapping an image</em></span> recipe of <a class="calibre1" title="Chapter 2. Manipulating Pixels" href="part0019_split_000.html#page">Chapter 2</a>, <span class="strong"><em class="calibre9">Manipulating Pixels</em></span>, is another situation where pixel interpolation is required.</p><p class="calibre8">The most basic approach to perform interpolation is to use a <a id="id518" class="calibre1"/>
<span class="strong"><strong class="calibre2">nearest neighbor strategy</strong></span>. The new grid of pixels that must be produced is placed on top of the existing image, and each new <a id="id519" class="calibre1"/>pixel is assigned the value of its closest pixel in the original image. In the case of image upsampling (that is, when using a new grid denser than the original one), this implies that more than one pixel of the new grid will receive its value from the same original pixel.</p><p class="calibre8">For example, if we rescale the reduced image of the previous section by <code class="email">3</code> using nearest neighbor interpolation (which is done by using the interpolation flag <code class="email">cv::INTER_NEAREST</code>), we obtain the following code:</p><div class="informalexample"><pre class="programlisting">  cv::resize(reduced, newImage, 
               cv::Size(), 3, 3,cv::INTER_NEAREST);</pre></div><p class="calibre8">The result is shown in the following screenshot:</p><div class="mediaobject"><img src="../images/00082.jpeg" alt="Interpolating pixel values" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">In this case, the interpolation corresponds to simply multiplying the size of each pixel by <code class="email">3</code> (this is how we produced the images of the previous section). A better approach consists of interpolating a new pixel value by combining the values of several neighboring pixels. Hence, we can linearly interpolate a pixel value by considering the four pixels around it, as illustrated by the following figure:</p><div class="mediaobject"><img src="../images/00083.jpeg" alt="Interpolating pixel values" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">This is done by first vertically interpolating two pixel values to the left- and right-hand side of the <a id="id520" class="calibre1"/>added pixel. Then, these two interpolated pixels (drawn in gray in the preceding figure) are used to horizontally interpolate the pixel value at the desired location. This bilinear interpolation scheme is the default approach used by <code class="email">cv::resize</code> (that can also be explicitly specified by the flag <code class="email">cv::INTER_LINEAR</code>):</p><div class="informalexample"><pre class="programlisting">  cv::resize(reduced2, newImage, 
               cv::Size(), 3, 3, cv::INTER_LINEAR);</pre></div><p class="calibre8">The following is the result:</p><div class="mediaobject"><img src="../images/00084.jpeg" alt="Interpolating pixel values" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">There also exist other approaches that can produce superior results. With <a id="id521" class="calibre1"/>
<span class="strong"><strong class="calibre2">bicubic interpolation</strong></span>, a neighborhood of <code class="email">4x4</code> pixels is considered to perform the interpolation. However, since the approach <a id="id522" class="calibre1"/>uses more pixels and implies the computation of cubic terms, it is slower than bilinear interpolation.</p></div></div></div>

<div class="book" title="Filtering images using low-pass filters">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch06lvl2sec123" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">The <span class="strong"><em class="calibre9">There's more…</em></span> section of the <span class="strong"><em class="calibre9">Scanning an image with neighbor access</em></span> recipe in <a class="calibre1" title="Chapter 2. Manipulating Pixels" href="part0019_split_000.html#page">Chapter 2</a>, <span class="strong"><em class="calibre9">Manipulating Pixels</em></span>, introduces the <code class="email">cv::filter2D</code> function. This function lets you apply a linear filter to an image by inputting the kernel of your choice.</li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Filtering images using a median filter"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec43" class="calibre1"/>Filtering images using a median filter</h1></div></div></div><p class="calibre8">The first recipe<a id="id523" class="calibre1"/> of this chapter introduced the concept <a id="id524" class="calibre1"/>of linear filters. Non-linear filters also exist and can be advantageously used in image processing. One such filter is the median filter that we present in this recipe.</p><p class="calibre8">Since median filters are particularly useful in order to combat salt-and-pepper noise (or salt-only, in our case), we will use the image we created in the first recipe of <a class="calibre1" title="Chapter 2. Manipulating Pixels" href="part0019_split_000.html#page">Chapter 2</a>, <span class="strong"><em class="calibre9">Manipulating Pixels</em></span>, and that is reproduced here:</p><div class="mediaobject"><img src="../images/00085.jpeg" alt="Filtering images using a median filter" class="calibre10"/></div><p class="calibre11"> </p></div>

<div class="book" title="Filtering images using a median filter">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch06lvl2sec124" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">The call to the median filtering function is done in a way that is similar to the other filters:</p><div class="informalexample"><pre class="programlisting">   cv::medianBlur(image,result,5); // size of the filter</pre></div><p class="calibre8">The resulting image is as follows:</p><div class="mediaobject"><img src="../images/00086.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div class="book" title="Filtering images using a median filter">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch06lvl2sec125" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">Since the <a id="id525" class="calibre1"/>median filter is not a linear filter, it cannot be represented by a kernel matrix. However, it also operates on a pixel's neighborhood in order to determine the output pixel value. The pixel <a id="id526" class="calibre1"/>and its neighborhood form a set of values and, as the name suggests, the median filter will simply compute the median value of this set, and the current pixel is then replaced with this median value (the median of a set is the value at the middle position when the set is sorted).</p><p class="calibre8">This explains why the filter is so efficient in eliminating the salt-and-pepper noise. Indeed, when an outlier black or white pixel is present in a given pixel neighborhood, it is never selected as the median value (rather, it is the maximal or minimal value), so it is always replaced by a neighboring value. In contrast, a simple mean filter would be greatly affected by such noise as it can be observed in the following image that represents the mean filtered version of our salt-and-pepper corrupted image:</p><div class="mediaobject"><img src="../images/00087.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Clearly, the noisy<a id="id527" class="calibre1"/> pixels shifted the mean value of neighboring pixels. As a result, the noise is still visible even if it has been blurred by the mean filter.</p><p class="calibre8">The median filter <a id="id528" class="calibre1"/>also has the advantage of preserving the sharpness of the edges. However, it washes out the textures in uniform regions (for example, the trees in the background). Because of the visual impact it has on images, the median filter is often used to create special effects in photo-editing software tools. You should test it on a color image to see how it can produce <span class="strong"><em class="calibre9">cartoon-like</em></span> images.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Applying directional filters to detect edges"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec44" class="calibre1"/>Applying directional filters to detect edges</h1></div></div></div><p class="calibre8">The first recipe of this chapter introduced the idea of linear filtering using kernel matrices. The<a id="id529" class="calibre1"/> filters<a id="id530" class="calibre1"/> that were used had the effect of blurring an image by removing or attenuating its high-frequency components. In this recipe, we will perform the opposite transformation, that is, amplifying the high-frequency content of an image. As a result, the high-pass filters introduced here<a id="id531" class="calibre1"/> will perform <span class="strong"><strong class="calibre2">edge detection</strong></span>.</p></div>

<div class="book" title="Applying directional filters to detect edges">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch06lvl2sec126" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">The filter that we will use here is <a id="id532" class="calibre1"/>called the <a id="id533" class="calibre1"/>
<span class="strong"><strong class="calibre2">Sobel</strong></span> filter. It is said to be a directional filter, because it <a id="id534" class="calibre1"/>only affects <a id="id535" class="calibre1"/>the vertical or the horizontal image frequencies depending on which kernel of the filter is used. OpenCV has a function that applies the <span class="strong"><strong class="calibre2">Sobel</strong></span> operator<a id="id536" class="calibre1"/> on an image. The horizontal filter is called as follows:</p><div class="informalexample"><pre class="programlisting">  cv::Sobel(image,    // input
           sobelX,    // output
           CV_8U,     // image type
           1, 0,      // kernel specification
           3,         // size of the square kernel 
           0.4, 128); // scale and offset</pre></div><p class="calibre8">Vertical filtering is achieved by the following (and very similar to the horizontal filter) call:</p><div class="informalexample"><pre class="programlisting">  cv::Sobel(image,    // input
           sobelY,    // output
           CV_8U,     // image type
           0, 1,      // kernel specification
           3,         // size of the square kernel 
           0.4, 128); // scale and offset</pre></div><p class="calibre8">Several integer parameters are provided to the function, and these will be explained in the next section. Note that these have been chosen to produce an 8-bit image (<code class="email">CV_8U</code>) representation of the output.</p><p class="calibre8">The result of the horizontal Sobel operator is as follows:</p><div class="mediaobject"><img src="../images/00088.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Since, as it will be seen in the next section, the kernels of the Sobel operator contain both positive and <a id="id537" class="calibre1"/>negative values, the result of the Sobel filter is generally computed in a 16-bit signed integer image (<code class="email">CV_16S</code>). To make the <a id="id538" class="calibre1"/>results displayable as an 8-bit image, as shown in the preceding figure, we used a representation in which a zero value corresponds to gray-level 128. Negative values are represented by darker pixels, while positive values are represented by brighter pixels. The vertical Sobel image is as follows:</p><div class="mediaobject"><img src="../images/00089.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">If you are familiar with photo-editing <a id="id539" class="calibre1"/>software, the <a id="id540" class="calibre1"/>preceding images might remind you of the <a id="id541" class="calibre1"/>
<span class="strong"><strong class="calibre2">image emboss</strong></span> effect, and indeed, this image transformation is generally based on the use of directional filters.</p><p class="calibre8">The two results (vertical and horizontal) can then be combined to obtain the norm of the Sobel filter:</p><div class="informalexample"><pre class="programlisting">   // Compute norm of Sobel
   cv::Sobel(image,sobelX,CV_16S,1,0);
   cv::Sobel(image,sobelY,CV_16S,0,1);
   cv::Mat sobel;
   //compute the L1 norm
   sobel= abs(sobelX)+abs(sobelY);</pre></div><p class="calibre8">The Sobel norm can be conveniently displayed in an image using the optional rescaling parameter of the <code class="email">convertTo</code> method in order to obtain an image in which zero values correspond to white, and higher values are assigned darker gray shades:</p><div class="informalexample"><pre class="programlisting">   // Find Sobel max value
   double sobmin, sobmax;
   cv::minMaxLoc(sobel,&amp;sobmin,&amp;sobmax);
   // Conversion to 8-bit image
   // sobelImage = -alpha*sobel + 255
   cv::Mat sobelImage;
   sobel.convertTo(sobelImage,CV_8U,-255./sobmax,255);</pre></div><p class="calibre8">The result can be seen in the following screenshot:</p><div class="mediaobject"><img src="../images/00090.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Looking at <a id="id542" class="calibre1"/>this image, it is now clear why these<a id="id543" class="calibre1"/> kind of operators are called edge detectors. It is then possible to threshold this image in order to obtain a binary map that shows you the image contour. The following snippet creates the image that follows it:</p><div class="informalexample"><pre class="programlisting">   cv::threshold(sobelImage, sobelThresholded, 
                      threshold, 255, cv::THRESH_BINARY);</pre></div><div class="mediaobject"><img src="../images/00091.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div class="book" title="Applying directional filters to detect edges">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch06lvl2sec127" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">The Sobel operator<a id="id544" class="calibre1"/> is a classic edge-detection linear filter that is based on two simple <code class="email">3x3</code> kernels that have the following structure:</p><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-2</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">2</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td></tr></tbody></table></div><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-2</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">2</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td></tr></tbody></table></div><p class="calibre8">If we view the image as a two-dimensional function, the Sobel operator can then be seen as a measure of<a id="id545" class="calibre1"/> the variation of the image in the vertical <a id="id546" class="calibre1"/>and horizontal directions. In mathematical terms, this measure is called a <a id="id547" class="calibre1"/>
<span class="strong"><strong class="calibre2">gradient</strong></span>, and it is defined as a 2D vector that is made from the function's first derivatives in two orthogonal directions:</p><div class="mediaobject"><img src="../images/00092.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Therefore, the Sobel operator gives you an approximation of the image gradient by differencing pixels in <a id="id548" class="calibre1"/>the horizontal and vertical directions. It operates on a window around the pixel of interest in order to reduce the influence of noise. The <code class="email">cv::Sobel</code> function computes the result of the convolution of the image with a Sobel kernel. Its complete specification is as follows:</p><div class="informalexample"><pre class="programlisting">   cv::Sobel(image,  // input
             sobel,  // output
             image_depth,   // image type
             xorder,yorder, // kernel specification
             kernel_size,   // size of the square kernel 
             alpha, beta);  // scale and offset</pre></div><p class="calibre8">Therefore, you decide whether you wish to have the result written in an unsigned characters, a signed integer, or <a id="id549" class="calibre1"/>a floating point image. Of course, if the result falls outside of the domain of the image pixel, saturation will be applied. This is where the last two parameters can be useful. Before storing the result in the image, the result can be scaled (multiplied) by <code class="email">alpha</code> and an offset, <code class="email">beta</code>, can be added. This is how, in the previous section, we generated an image for which the Sobel value <code class="email">0</code> was represented by the mid-gray level <code class="email">128</code>. Each Sobel mask corresponds to a derivative in one direction. Therefore, two parameters are used to specify the kernel that will be applied, the order of the derivative in the <code class="email">x</code>, and the <code class="email">y</code> directions. For instance, the horizontal Sobel kernel is obtained by specifying <code class="email">1</code> and <code class="email">0</code> for the <code class="email">xorder</code> and <code class="email">yorder</code> parameters, and the vertical kernel will be generated with <code class="email">0</code> and <code class="email">1</code>. Other combinations are also possible, but these two are the ones that will be used most often (the case of second-order derivatives is discussed in the next recipe). Finally, it is also possible to use kernels of a size that is larger than <code class="email">3x3</code>. Values <code class="email">1</code>, <code class="email">3</code>, <code class="email">5</code>, and <code class="email">7</code> are possible choices for the kernel size. A kernel of size 1 corresponds to a 1D Sobel filter (<code class="email">1x3</code> or <code class="email">3x1</code>). See the following <span class="strong"><em class="calibre9">There's more…</em></span> section to learn why using a larger kernel might be useful.</p><p class="calibre8">Since the gradient is a 2D vector, it has a norm and a direction. The norm of the gradient vector tells you what the amplitude of the variation is, and it is <a id="id550" class="calibre1"/>normally computed as a Euclidean norm (also called <span class="strong"><strong class="calibre2">L2 norm</strong></span>):</p><div class="mediaobject"><img src="../images/00093.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">However, in image processing, this norm is often computed as the sum of the absolute values. This is called the <span class="strong"><strong class="calibre2">L1 norm</strong></span>, and it gives values that are close to the L2 norm but at a lower computational cost. This is what we did in this recipe:</p><div class="informalexample"><pre class="programlisting">   //compute the L1 norm
   sobel= abs(sobelX)+abs(sobelY);</pre></div><p class="calibre8">The gradient <a id="id551" class="calibre1"/>vector always points in the direction <a id="id552" class="calibre1"/>of the steepest variation. For an image, this means that the gradient direction will be orthogonal to the edge, pointing in the darker to brighter direction. Gradient angular direction is given by the following formula:</p><div class="mediaobject"><img src="../images/00094.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Most often, for edge detection, only the norm is computed. However, if you require both the norm and the direction, then the following OpenCV function can be used:</p><div class="informalexample"><pre class="programlisting">   // Sobel must be computed in floating points
   cv::Sobel(image,sobelX,CV_32F,1,0);
   cv::Sobel(image,sobelY,CV_32F,0,1);
   // Compute the L2 norm and direction of the gradient
   cv::Mat norm, dir;   
   cv::cartToPolar(sobelX,sobelY,norm,dir);</pre></div><p class="calibre8">By default, the direction is computed in radians. Just add <code class="email">true</code> as an additional argument in order to have them computed in degrees.</p><p class="calibre8">A binary edge map<a id="id553" class="calibre1"/> has been obtained by applying a threshold on the gradient magnitude. Choosing the right threshold is not an obvious task. If the threshold value is too low, too many (thick) edges will be retained, while if we select a more severe (higher) threshold, then broken edges will be obtained. As an illustration of this trade-off situation, compare the preceding binary edge map with the following, which is obtained using a higher threshold value:</p><div class="mediaobject"><img src="../images/00095.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">One way to<a id="id554" class="calibre1"/> get the best of both lower and higher<a id="id555" class="calibre1"/> thresholds is to use the concept of hysteresis thresholding. This will be explained in the next chapter where we introduce the Canny operator.</p></div></div>

<div class="book" title="Applying directional filters to detect edges">
<div class="book" title="There's more..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch06lvl2sec128" class="calibre1"/>There's more...</h2></div></div></div><p class="calibre8">Other gradient operators also exist. We present some of them in this section. It is also possible to apply a Gaussian smoothing filter before applying a derivative filter. This makes it less sensitive to noise, as explained in this section.</p><div class="book" title="Gradient operators"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch06lvl3sec29" class="calibre1"/>Gradient operators</h3></div></div></div><p class="calibre8">To estimate the gradient<a id="id556" class="calibre1"/> at a pixel location, the<a id="id557" class="calibre1"/> Prewitt operator<a id="id558" class="calibre1"/> defines the following kernels:</p><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td></tr></tbody></table></div><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td></tr></tbody></table></div><p class="calibre8">The <a id="id559" class="calibre1"/>Roberts operator<a id="id560" class="calibre1"/> is based on these simple <code class="email">2x2</code> kernels:</p><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td></tr></tbody></table></div><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td></tr></tbody></table></div><p class="calibre8">The <a id="id561" class="calibre1"/>Scharr operator<a id="id562" class="calibre1"/> is preferred when more accurate estimates of the gradient orientation are required:</p><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-3</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">3</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-10</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">10</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-3</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">3</p>
</td></tr></tbody></table></div><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-3</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-10</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-3</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">3</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">10</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">3</p>
</td></tr></tbody></table></div><p class="calibre8">Note that it is possible to use the Scharr kernels with the <code class="email">cv::Sobel</code> function by calling it with the <code class="email">CV_SCHARR</code> argument:</p><div class="informalexample"><pre class="programlisting">   cv::Sobel(image,sobelX,CV_16S,1,0, CV_SCHARR);</pre></div><p class="calibre8">Or, equivalently, you can call the <code class="email">cv::Scharr</code> function:</p><div class="informalexample"><pre class="programlisting">   cv::Scharr(image,scharrX,CV_16S,1,0,3);</pre></div><p class="calibre8">All of these directional filters try to estimate the first-order derivative of the image function. Therefore, high values are obtained at areas where large intensity variations in the filter direction are present, while flat areas produce low values. This is why filters that compute image derivatives are high-pass filters.</p></div><div class="book" title="Gaussian derivatives"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch06lvl3sec30" class="calibre1"/>Gaussian derivatives</h3></div></div></div><p class="calibre8">Derivative filters<a id="id563" class="calibre1"/> are high-pass filters. As such, they tend to amplify noise and small highly-contrasted details in an image. In order to reduce the impact of these higher frequency elements, it is a good practice to first smooth the image before applying a derivative filter. You might think that this would be done in two steps, which are smoothing the image and then computing the derivative. However, a closer look at these operations reveals that it is possible to combine these two steps into one with a proper choice of the smoothing kernel. We learned previously that the convolution of an image with a filter can be expressed as a summation of terms. Interestingly, a well-known mathematical property is that the derivative of a summation of terms is <a id="id564" class="calibre1"/>equal to the summation of the terms' derivative.</p><p class="calibre8">Consequently, instead of applying the derivative on the result of the smoothing, it is possible to derivate the kernel and then convolute it with the image. Since the Gaussian kernel is continuously derivable, it represents a particularly appropriate choice. This is what is done when you call the <code class="email">cv::sobel</code> function with different kernel sizes. The function will compute a Gaussian derivative kernel with different σ values. As an example, if we select the <code class="email">7x7</code> Sobel filter (that is <code class="email">kernel_size=7</code>) in the x direction, the following result is obtained:</p><div class="mediaobject"><img src="../images/00096.jpeg" alt="Gaussian derivatives" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">If you compare this image with the one shown earlier, it can be seen that many fine details have been removed, giving them more emphasis on the more significant edges. Note that we now have a band-pass filter, the higher frequencies being removed by the Gaussian filter and the lower frequencies being removed by the Sobel filter.</p></div></div></div>

<div class="book" title="Applying directional filters to detect edges">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch06lvl2sec129" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">The <span class="strong"><em class="calibre9">Detecting image contours with the Canny operator</em></span> recipe in <a class="calibre1" title="Chapter 7. Extracting Lines, Contours, and Components" href="part0052_split_000.html#page">Chapter 7</a>, <span class="strong"><em class="calibre9">Extracting Lines, Contours, and Components</em></span>, shows you how to obtain a binary edge map using two different threshold values</li></ul></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Computing the Laplacian of an image"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec45" class="calibre1"/>Computing the Laplacian of an image</h1></div></div></div><p class="calibre8">The Laplacian<a id="id565" class="calibre1"/> is another high-pass linear filter that is based on the computation of the image derivatives. As it will be explained, it computes second-order derivatives to measure the curvature of the image function.</p></div>

<div class="book" title="Computing the Laplacian of an image">
<div class="book" title="How to do it..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch06lvl2sec130" class="calibre1"/>How to do it...</h2></div></div></div><p class="calibre8">The OpenCV function, <code class="email">cv::Laplacian</code>, computes <a id="id566" class="calibre1"/>the Laplacian of <a id="id567" class="calibre1"/>an image. It is very similar to the <code class="email">cv::Sobel</code> function. In fact, it uses the same basic function, <code class="email">cv::getDerivKernels</code>, in <a id="id568" class="calibre1"/>order to obtain its kernel matrix. The only difference is that there are no derivative order parameters since these ones are, by definition, second order derivatives.</p><p class="calibre8">For this operator, we will create a simple class that will encapsulate some useful operations related to the Laplacian. The basic methods are as follows:</p><div class="informalexample"><pre class="programlisting">class LaplacianZC {

  private:
    // laplacian
    cv::Mat laplace;
    // Aperture size of the laplacian kernel
    int aperture;

  public:

     LaplacianZC() : aperture(3) {}

     // Set the aperture size of the kernel
     void setAperture(int a) {
        aperture= a;
     }

     // Compute the floating point Laplacian
     cv::Mat computeLaplacian(const cv::Mat&amp; image) {

        // Compute Laplacian
        cv::Laplacian(image,laplace,CV_32F,aperture);
        return laplace;
     }</pre></div><p class="calibre8">The computation of the Laplacian is done here on a floating point image. To get an image of the result, we perform<a id="id569" class="calibre1"/> a rescaling, as shown in the previous recipe. This rescaling is based on the Laplacian maximum absolute value, where value <code class="email">0</code> is assigned gray-level <code class="email">128</code>. A method of our class allows the following image representation to be obtained:</p><div class="informalexample"><pre class="programlisting">     // Get the Laplacian result in 8-bit image 
     // zero corresponds to gray level 128
     // if no scale is provided, then the max value will be
     // scaled to intensity 255
     // You must call computeLaplacian before calling this
     cv::Mat getLaplacianImage(double scale=-1.0) {
        if (scale&lt;0) {
           double lapmin, lapmax;
           // get min and max laplacian values
           cv::minMaxLoc(laplace,&amp;lapmin,&amp;lapmax);
           // scale the laplacian to 127
           scale= 127/ std::max(-lapmin,lapmax);
        }

        // produce gray-level image
        cv::Mat laplaceImage;
        laplace.convertTo(laplaceImage,CV_8U,scale,128);
        return laplaceImage;
     }</pre></div><p class="calibre8">Using this class, the Laplacian image computed from a <code class="email">7x7</code> kernel is obtained as follows:</p><div class="informalexample"><pre class="programlisting">   // Compute Laplacian using LaplacianZC class
   LaplacianZC laplacian;
   laplacian.setAperture(7); // 7x7 laplacian
   cv::Mat flap= laplacian.computeLaplacian(image);
   laplace= laplacian.getLaplacianImage();</pre></div><p class="calibre8">The resulting image is as follows:</p><div class="mediaobject"><img src="../images/00097.jpeg" alt="How to do it..." class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div class="book" title="Computing the Laplacian of an image">
<div class="book" title="How it works..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch06lvl2sec131" class="calibre1"/>How it works...</h2></div></div></div><p class="calibre8">Formally, the Laplacian of a 2D function is defined as the sum of its second derivatives:</p><div class="mediaobject"><img src="../images/00098.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">In its simplest form, it can be approximated by the following 3x3 kernel:</p><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-4</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">1 </p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0 </p>
</td></tr></tbody></table></div><p class="calibre8">As for the Sobel operator, it is also possible to compute the Laplacian using larger kernels, and since <a id="id570" class="calibre1"/>this operator is even more sensitive to image noise, it is desirable to do so (unless computational efficiency is a concern). Since these larger kernels are computed using the second derivatives of the Gaussian function, the corresponding operator is often called<a id="id571" class="calibre1"/> <span class="strong"><strong class="calibre2">Laplacian of Gaussian</strong></span> (<span class="strong"><strong class="calibre2">LoG</strong></span>). Note that the kernel values of a Laplacian always sum up to <code class="email">0</code>. This guarantees that the Laplacian will be zero in areas of constant intensities. Indeed, since the Laplacian measures the curvature of the image function, it should be equal to <code class="email">0</code> on flat areas.</p><p class="calibre8">At first glance, the effect of the Laplacian might be difficult to interpret. From the definition of the <a id="id572" class="calibre1"/>kernel, it is clear that any isolated pixel value (that is, a value that's very different from its neighbors) will be amplified by the operator. This is a consequence of the operator's high sensitivity to noise. However, it is more interesting to look at the Laplacian values around an image edge. The presence of an edge in an image is the result of a rapid transition between areas of different gray-level intensities. Following the evolution of the image function along an edge (for example, caused by a transition from dark to bright), one can observe that the gray-level ascension necessarily implies a gradual transition from a positive curvature (when the intensity values start to rise) to a negative curvature (when the intensity is about to reach its high plateau). Consequently, a transition between a positive and a negative Laplacian value (or reciprocally) constitutes a good indicator of the presence of an edge. Another way to express this fact is to say that edges will be located at the <span class="strong"><strong class="calibre2">zero-crossings</strong></span> of the Laplacian function. We will illustrate this idea by looking at the values of a Laplacian in a small window of our test image. We select one that corresponds to an edge created by the bottom part of the roof of one of the castle's tower. A white box has been drawn in the following image to show you the exact location of this region of interest:</p><div class="mediaobject"><img src="../images/00099.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Now, looking at the Laplacian values (<code class="email">7x7</code> kernel) inside this window, we have the following figure:</p><div class="mediaobject"><img src="../images/00100.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">If, as illustrated, you carefully follow the zero-crossings of the Laplacian (located between pixels of different signs), you obtain a curve that corresponds to the edge that is visible in the <a id="id573" class="calibre1"/>image window. In the preceding figure, we drew dotted lines along the zero-crossings that correspond to the edge of the tower that is visible in the selected image window. This implies that, in principle, you can even detect the image edges at sub-pixel accuracy.</p><p class="calibre8">Following the zero-crossing curves in a Laplacian image is a delicate task. However, a simplified algorithm can be used to detect the approximate zero-crossing locations. This one proceeds by first thresholding the Laplacian at <code class="email">0</code> such that it obtains a partition between the positive and negative values. The contours between these two partitions then correspond to our zero-crossings. Therefore, we use a morphological operation to extract these contours, that is, we subtract the dilated image from the Laplacian image (this is the Beucher gradient presented in the <span class="strong"><em class="calibre9">Detecting edges and corners using morphological filters</em></span> recipe in <a class="calibre1" title="Chapter 5. Transforming Images with Morphological Operations" href="part0040_split_000.html#page">Chapter 5</a>, <span class="strong"><em class="calibre9">Transforming Images with Morphological Operations</em></span>). This algorithm is implemented by the following method, which generates a binary image of zero-crossings:</p><div class="informalexample"><pre class="programlisting">    // Get a binary image of the zero-crossings
    // laplacian image should be CV_32F
    cv::Mat getZeroCrossings(cv::Mat laplace) {

      // threshold at 0
      // negative values in black
      // positive values in white
      cv::Mat signImage;
      cv::threshold(laplace,signImage,0,255,cv::THRESH_BINARY);

      // convert the +/- image into CV_8U
      cv::Mat binary;
      signImage.convertTo(binary,CV_8U);
      // dilate the binary image of +/- regions
      cv::Mat dilated;
      cv::dilate(binary,dilated,cv::Mat());
  
      // return the zero-crossing contours
      return dilated-binary;
    }</pre></div><p class="calibre8">The result is the following binary map:</p><div class="mediaobject"><img src="../images/00101.jpeg" alt="How it works..." class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">As you can see, the zero-crossings of the Laplacian detect all edges. No distinction is made between <a id="id574" class="calibre1"/>strong edges and weaker edges. We also mentioned that the Laplacian is very sensitive to noise. Finally, some of these edges are due to compression artifacts. All these factors explain why so many edges are detected by the operator. In practice, the Laplacian is only used in conjunction with other operators to detect edges (for example, edges can be declared at zero-crossing locations of strong gradient magnitude). We will also learn in <a class="calibre1" title="Chapter 8. Detecting Interest Points" href="part0058_split_000.html#page">Chapter 8</a>, <span class="strong"><em class="calibre9">Detecting Interest Points</em></span>, that the Laplacian and other second-order operators are very useful in order to detect interest points at multiple scales.</p></div></div>

<div class="book" title="Computing the Laplacian of an image">
<div class="book" title="There's more..."><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch06lvl2sec132" class="calibre1"/>There's more...</h2></div></div></div><p class="calibre8">The Laplacian<a id="id575" class="calibre1"/> is a high-pass filter. It is possible to approximate it by using a combination of low-pass filters. But before that, let's have a word about image enhancement, which is a topic we already discussed in <a class="calibre1" title="Chapter 2. Manipulating Pixels" href="part0019_split_000.html#page">Chapter 2</a>, <span class="strong"><em class="calibre9">Manipulating Pixels</em></span>.</p><div class="book" title="Enhancing the contrast of an image using the Laplacian"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch06lvl3sec31" class="calibre1"/>Enhancing the contrast of an image using the Laplacian</h3></div></div></div><p class="calibre8">The contrast <a id="id576" class="calibre1"/>of an image can be enhanced by<a id="id577" class="calibre1"/> subtracting its Laplacian from it. This is what we did in the Scanning an image with neighbor access recipe of <a class="calibre1" title="Chapter 2. Manipulating Pixels" href="part0019_split_000.html#page">Chapter 2</a>, <span class="strong"><em class="calibre9">Manipulating Pixels</em></span>, where we introduced the kernel:</p><div class="informalexample"><table border="1" class="calibre13"><colgroup class="calibre14"><col class="calibre15"/><col class="calibre15"/><col class="calibre15"/></colgroup><tbody class="calibre16"><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">5</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td></tr><tr class="calibre17"><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">-1</p>
</td><td valign="top" class="calibre18">
<p class="calibre19">0</p>
</td></tr></tbody></table></div><p class="calibre8">This is equal to 1 minus the Laplacian kernel (that is, the original image minus its Laplacian).</p></div><div class="book" title="Difference of Gaussians"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch06lvl3sec32" class="calibre1"/>Difference of Gaussians</h3></div></div></div><p class="calibre8">The<a id="id578" class="calibre1"/> Gaussian filter presented in the first recipe of this chapter extracts the low frequencies of an image. We learned that the range of frequencies that are filtered by a Gaussian filter depend on the parameter σ, which controls the width of the filter. Now, if we subtract the two images that result from the filtering of an image by two Gaussian filters of different bandwidths, then the resulting image will be composed of those higher frequencies that one filter has preserved, and not the other. This operation is called <span class="strong"><strong class="calibre2">Difference of Gaussians</strong></span> (<span class="strong"><strong class="calibre2">DoG</strong></span>) and is computed as follows:</p><div class="informalexample"><pre class="programlisting">  cv::GaussianBlur(image,gauss20,cv::Size(),2.0);
  cv::GaussianBlur(image,gauss22,cv::Size(),2.2);

  // compute a difference of Gaussians 
  cv::subtract(gauss22, gauss20, dog, cv::Mat(), CV_32F);

  // Compute the zero-crossings of DoG 
  zeros= laplacian.getZeroCrossings(dog);</pre></div><p class="calibre8">In addition, we also compute the zero-crossings of the DoG operator and we obtain the following screenshot:</p><div class="mediaobject"><img src="../images/00102.jpeg" alt="Difference of Gaussians" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">In fact, it can be demonstrated that with the proper choice of σ values, DoG operators can constitute a good <a id="id579" class="calibre1"/>approximation of LoG filters. Also, if you compute a series of difference of Gaussians from consecutive pair values in an increasing sequence of σ values, you obtain a scale-space representation of the image. This multiscale representation is useful, for example, for scale-invariant image feature detection, as it will be explained in <a class="calibre1" title="Chapter 8. Detecting Interest Points" href="part0058_split_000.html#page">Chapter 8</a>, <span class="strong"><em class="calibre9">Detecting Interest Points</em></span>.</p></div></div></div>

<div class="book" title="Computing the Laplacian of an image">
<div class="book" title="See also"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch06lvl2sec133" class="calibre1"/>See also</h2></div></div></div><div class="book"><ul class="itemizedlist"><li class="listitem">The Detecting scale-invariant features recipe in <a class="calibre1" title="Chapter 8. Detecting Interest Points" href="part0058_split_000.html#page">Chapter 8</a>, <span class="strong"><em class="calibre9">Detecting Interest Points</em></span> uses the Laplacian and DoG for the detection of scale-invariant features</li></ul></div></div></div></body></html>