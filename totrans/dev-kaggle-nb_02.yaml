- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Getting Ready for Your Kaggle Environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned how to create your Kaggle account, and what
    is most important to know about Competitions, Datasets, Code (Notebooks), Discussions,
    and Kaggle Learn and Models. In this chapter, we will explore the Kaggle Notebooks
    functionality. Kernels and Code are used as alternative names sometimes to refer
    to Notebooks, Kernels being the old name and Code being the new menu name for
    Notebooks. Both terms, the old one and the new one, illustrate something important
    about a notebook on Kaggle.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by introducing what a Kaggle Notebook is and explaining the difference
    between Kaggle Scripts and Kaggle Notebooks. We will then show how we can create
    a notebook, either from scratch or derived from an existing one. After you start
    to edit a notebook, you have multiple options, and we will review each of them
    in this chapter, starting with the most common (editing data sources and models,
    changing computing resources, etc.) and then following with the remaining ones
    (setting a notebook as script, adding utility scripts to the notebook, adding
    and using secrets, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, the following main topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What is a Kaggle Notebook?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to create notebooks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring Notebook capabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Kaggle API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is a Kaggle Notebook?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kaggle Notebooks are integrated development environments that allow you to write
    code, version it, run it (using Kaggle platform computational resources), and
    produce the results in various forms. When you initiate work on a notebook, you
    start a coding editor. This, in turn, starts a Docker container, provisioned with
    the most used Python packages for data analysis and machine learning, running
    in a virtual machine allocated in Google Cloud. The code itself is linked to a
    code repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can write code in one of two languages: Python or R. Currently, Python
    is used by most of the users on Kaggle, and all examples in this book will only
    be in Python.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The term **Notebooks** is used generically, but there are two types of Kaggle
    Notebooks: Scripts and Notebooks.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Kaggle Scripts**: Scripts are files that will execute all code sequentially.
    The output of the scripts’ execution will be printed in the console. If you want,
    you can also execute a part of the script only, by selecting a few lines and pressing
    the **Run** button. If you are using the R language for development, you can use
    a special type of script, RMarkdown script. The environment to develop it is similar
    to the one for Python or R scripts, but you can use the syntax for RMarkdown,
    and the output will be a combination of the R code execution results and the RMarkdown
    syntax for text and graphical effects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kaggle Notebooks**: Notebooks have a similar look and feel as Jupyter Notebooks.
    They are similar but not identical. Kaggle Notebooks have multiple additional
    options to support integration with a Kaggle environment and a better user experience.
    Notebooks are composed of a succession of cells with either code or Markdown content,
    and each cell can be executed independently. You can code using either R or Python
    while using Notebooks. When running a cell, the output generated is displayed
    right under the cell in the case of code cells.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With a brief overview of Kaggle Notebooks and their essential components, let’s
    see now how you can create a notebook.
  prefs: []
  type: TYPE_NORMAL
- en: How to create notebooks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several ways to start a notebook. You can start it from the main menu
    **Code** (*Figure 2.1*), from the context of a dataset (*Figure 2.2*), a Competition
    (*Figure 2.3*), or by forking (copying and editing) an existing notebook.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: Create a new notebook from the Code menu'
  prefs: []
  type: TYPE_NORMAL
- en: When you create a new notebook from the **Code** menu, this new notebook will
    appear in your list of notebooks but will not be added to any Dataset or Competition
    context.
  prefs: []
  type: TYPE_NORMAL
- en: If you choose to start it from a Kaggle Dataset, the dataset will be already
    added to the list of data associated with the notebook, and you will see it in
    the right-side panel (refer to *Figure 2.5*) when you edit the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Create a new notebook in the context of a Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: The same is true in the case of a Competition. The Dataset associated with it
    will be already present in the list of datasets when you initialize the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Create a new notebook in the context of a Competition'
  prefs: []
  type: TYPE_NORMAL
- en: To fork (copy and edit) an existing notebook, press the three vertical dots
    next to the **Edit** button of that notebook, and then select the **Copy & edit
    notebook** menu item from the drop-down list.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Fork a notebook from an existing one'
  prefs: []
  type: TYPE_NORMAL
- en: Once created, the notebook will be open for editing, as you can see in the following
    screenshot. On the upper-left side, there is a regular menu (**File**, **Edit**,
    **View**, **Run**, **Add-ons**, and **Help**), with quick-action icons for editing
    and running under it. On the right-hand side, there is a retractable panel with
    more quick actions.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated](img/B20963_02_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Main edit window for Kaggle Notebooks with the right-side panel
    with quick menus'
  prefs: []
  type: TYPE_NORMAL
- en: The **File** menu is complex and offers options for input and output, as well
    as various settings for interactions with other resources on the platform (Models,
    Utility Scripts, and Notebooks). It has menu items to import an external notebook
    or export your current notebook, and to even add data or models to the notebook.
    You can also either save the current notebook as a utility script or add a utility
    script to the notebook. You can choose to set the language (to R or Python; by
    default, is set to Python). There is an option to set the current notebook as
    a script or a notebook (notebook is the default).
  prefs: []
  type: TYPE_NORMAL
- en: Additional options are for publishing and sharing the notebook on GitHub. To
    publish the notebook on GitHub, you will have to link your Kaggle account with
    the GitHub account by authorizing Kaggle to access your GitHub account. Once you
    perform this operation, updates of the notebook will be mirrored on GitHub as
    well. Using the **Share menu** item, you can set who can view or edit the notebook.
    Initially, you will be the only user with read and write access, but once you
    add contributors, they can also be assigned with both read or write access, or
    only with read (view) access. If you publish your notebook, then everyone will
    have access to read it, be able to fork (copy and edit) it, and then edit the
    work.
  prefs: []
  type: TYPE_NORMAL
- en: The **Edit** menu allows you to move cells around (up and down) or delete a
    selected cell. In **View**, you have options to adjust the look and feel of the
    editor (adding or removing themes, line numbers, and setting the editor layout)
    and the resulting output HTML content (see or hide input or output for selected
    cells, or collapse or extend cells).
  prefs: []
  type: TYPE_NORMAL
- en: The **Run** menu item provides controls to run one cell, all cells, all cells
    before or after, and to start/stop a session. At the restart of the session, the
    Kernel (i.e., the Docker container in which the notebook is running) is restarted,
    and all context data initialized when we run some of the cells is reset. This
    is a very useful option when, while editing, you want to reset the environment
    with all the variables. Add-ons menu groups, secret management, Google Cloud services,
    and the Google Cloud SDK — each of those extends the functionality of notebooks
    and will be presented under the *Advanced capabilities* section later in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve learned how to create, edit, and run notebooks, let’s continue
    by exploring more notebook features.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring notebook capabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Notebooks serve as powerful tools for data exploration, model training, and
    running inferences. In this section, we will examine the various capabilities
    that Kaggle Notebooks have to offer.
  prefs: []
  type: TYPE_NORMAL
- en: We will start off with the most frequently used features of notebooks. We will
    go through the options to add various resources to a notebook (data and models)
    and to modify the execution environment. Then, we continue with more advanced
    features, which will include setting up utility scripts, adding or using secrets,
    using Google Cloud services, or upgrading a notebook to a Google Cloud AI Notebook.
    Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Basic capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On the right-side panel, we have quick menu actions for access to frequently
    used features of notebooks. In the following screenshot, we take a more detailed
    look at these quick menu actions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Zoomed-in view of the right-side panel with quick menus'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the first quick menu actions are grouped under the **Data**
    section. Here, you have buttons to add or remove datasets from the notebook. By
    clicking on the **Add Data** button, you can add one existing dataset. You have
    the search text box and quick buttons to select from your datasets, competition
    datasets, and notebooks. When you select your notebooks, you can include the output
    of notebooks as data sources for the current notebook. You also have an upload
    button next to the **Add Data** button, and you can use it to upload a new dataset
    before adding it to the notebook. In the same **Data** section on the panel, you
    have the input and output folder browser, and buttons next to each item so that
    you can copy the path to either folders or files.
  prefs: []
  type: TYPE_NORMAL
- en: Right under the **Data** section, we have the **Models** section (see *Figure
    2.6*). Here, we can add models to the notebook. **Models** is a new feature on
    the platform, and it allows you to use powerful pretrained models in your notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the **Notebook options** section, we can configure the accelerator, the
    language, the persistence option, the environment, and internet access as per
    our preferences (see *Figure 2.6*). By default, the notebook will use a **Central
    Processing Unit** (**CPU**) only. See the following screenshot for the expanded
    view of **Add Data**, **Add Models**, and **Notebook options** in the right-hand
    side panel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: Right-side panel menus to add data and models and for Notebook
    options'
  prefs: []
  type: TYPE_NORMAL
- en: You can search datasets by their name or path, and you have speed filters to
    search in competitions or the output of your notebooks. For **Models** as well,
    you can search by name and filter by type (text, image, computer vision, or video).
    **Notebook options** allows the selection of an accelerator type (**None** means
    CPU-only), the programming language, the persistence type, and the option for
    the environment.
  prefs: []
  type: TYPE_NORMAL
- en: By choosing the accelerator, you can switch to using one of the two hardware
    accelerator options for **Graphical Processing Unit** (**GPU**) or **Tensor Processing
    Unit** (**TPU**). The technical specifications for CPU configuration and accelerator
    configurations, at the time of writing, are given in *Table 2.1*. For all these
    specifications, either with CPU or GPU, you have a maximum of 12 hours of continuous
    execution time. In the case of TPUs, the execution time is limited to 9 hours.
    The input data size, however, is not limited. The output is limited to 20 GB.
    An additional 20 GB can be used only temporarily, during runtime, but it will
    not be saved after the run.
  prefs: []
  type: TYPE_NORMAL
- en: By default, your notebook is set to not use any persistence. You can opt to
    ensure persistence for files and variables, files only, or variables only.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Configuration** | **Cores** | **RAM** |'
  prefs: []
  type: TYPE_TB
- en: '| CPU | 4 CPU cores | 30 GB |'
  prefs: []
  type: TYPE_TB
- en: '| P100 GPU | 1 Nvidia Tesla P100 GPU 2 CPU cores | 13 GB |'
  prefs: []
  type: TYPE_TB
- en: '| T4 x 2 GPU | 2 Nvidia Tesla T4 GPUs 2 CPU cores | 13 GB |'
  prefs: []
  type: TYPE_TB
- en: '| TPU | 1 TPU 4 CPU cores | 16 GB |'
  prefs: []
  type: TYPE_TB
- en: '| TPU 1VM | 96 CPU cores | 330 GB |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.1: Technical specification for CPU or accelerator specs'
  prefs: []
  type: TYPE_NORMAL
- en: You can set your notebook to always use the original environment or to pin to
    the latest environment. Depending on what libraries you use and what data processing
    you perform, it might be useful to choose to work with the original environment
    or use the latest available environment. When you select the original environment,
    the settings of the original environment will be kept every time you run new versions
    of the notebook. With the alternative option to use the latest available environment,
    the environment (with predefined library versions) will be updated to the latest
    version.
  prefs: []
  type: TYPE_NORMAL
- en: The internet access is preset to “On,” but in some cases, you would like to
    set it “Off.” For certain code competitions, internet access is not allowed. In
    such cases, you will be able to download dynamic resources from the internet in
    your training notebook, but you will have to make sure that every needed resource
    is either internal to the notebook or in one of the attached models, utility scripts,
    or datasets, when running the inference notebook for that code competition.
  prefs: []
  type: TYPE_NORMAL
- en: We saw what the basic features of notebooks are and how to add data, models,
    and configure the running environment. Let’s see now what the more advanced features
    are.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Basic notebook functionality allows us to perform quick experiments, test ideas,
    and prototype solutions. If we want to build more complex functionalities, however,
    we will need to write reusable code, separate configurations (including secrets,
    like API keys) from code, and even integrate our code with external systems or
    components.
  prefs: []
  type: TYPE_NORMAL
- en: The Kaggle environment offers generous computational resources, but these are
    limited. We might want to combine Kaggle Notebooks with external resources, or
    we might want to integrate components from Kaggle (notebooks, datasets) with other
    components, Google Cloud, or our local environment. In the upcoming sections,
    we will learn how to achieve all these.
  prefs: []
  type: TYPE_NORMAL
- en: Setting a notebook as a utility script or adding utility scripts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In most cases, you will write all the code for your notebook in successive cells
    in the same file. For more complex code, and especially when you would like to
    reuse some of the code, without copying code between notebooks, you can choose
    to develop utility modules. Kaggle Notebooks offers a useful feature for this
    purpose, namely **Utility scripts**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Utility scripts** are created in the same way notebooks are. You will have
    to start a notebook and then choose the **Set as Utility Script** menu item from
    the **File** menu. If you want to use a utility script in your current notebook,
    you need to select the **Add utility script** menu item from the **File** menu.
    This will open a selector window for utility scripts on the right-side panel,
    and here, you can choose from your existing utility scripts and add one or more
    to your notebook. As you can see in the following screenshot, added utility scripts
    appear with the **+** button next to them (seen on the left panel) and are added
    to the notebook under a separate group, **usr/lib (Utility Scripts)**, just under
    the **Input** data section and before the **Output** data section (seen on the
    right panel):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: Selecting a utility script'
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the utility script within your code, you will have to import the module
    in the same way you import Python packages. In the following code snippet, we
    import the modules or functions included in one utility script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the function `missing_data` is defined in the utility script
    `data_quality_stats`.
  prefs: []
  type: TYPE_NORMAL
- en: Adding and using secrets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes, you might need to add environment variables in your notebook, and
    you would want to keep them secret, especially if you make the notebook public.
    Examples of such variables could be your connection token for an experiment tracking
    service, like Neptune.ai or Weights & Biases, or various API secret keys or tokens.
    In this case, you would most probably like to use one of the add-ons, **Kaggle
    Secrets**.
  prefs: []
  type: TYPE_NORMAL
- en: Upon selection of the **Kaggle Secrets** menu item, a window like the one in
    the following screenshot will appear. In this pop-up window, you can add new secrets
    by pressing the button **Add a new secret**. To include the secrets with the current
    notebook, just check the checkboxes near the secrets you want to include.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.9: Add and select secrets'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, three secrets (two for a Twitter API connection
    and one for Weights & Biases experiment tracking) are selected. For each selected
    secret, there is an additional generated line like in the **Code Snippet** on
    the lower side of the window. You can copy all the generated lines to a clipboard
    to include in your notebook code. After you press **Done**, you will be able to
    paste the code into your notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Once defined, the secret will be available to be included in any of your notebooks.
    You can modify the text of one secret using the **Edit** button next to its name.
    Note that when you fork one notebook that has secrets added, the secrets won’t
    be associated anymore with the new notebook. To make available the secrets to
    a new or forked notebook, it is enough to enter the **Secrets** windows and press
    **Done**, in the context of editing that notebook. Of course, if someone else
    is copying your notebook, that Kaggler (Kaggle user) will have to set their own
    secrets. And if that Kaggler chooses to use different names for the variables
    associated with the secrets, they will also need to operate the change in the
    code. This feature allows you to not only manage useful environment variables
    but also easily configure your notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: Using Google Cloud services in Kaggle Notebooks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To take advantage of Google Cloud services in your notebook, from the **Add-ons**
    menu, select **Google Cloud Services**. In the dialog window that opens, you can
    sync your Google account with your notebook by clicking on **Attach to Notebook**.
    You can also select which Google Cloud services you want to integrate with your
    Kaggle environment.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, Kaggle offers integration with Google Cloud Storage, BigQuery, and
    AutoML. When using these services through Kaggle Notebooks, you need to know that
    this will incur charges, according to the plan you have. If you choose to use
    only public data with BigQuery, you will not incur any charges.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, we show how you can select these services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.10: Kaggle integration options'
  prefs: []
  type: TYPE_NORMAL
- en: Select what Google Cloud services to use in Kaggle Notebooks. As mentioned,
    you will need to link your Google Cloud account to Kaggle. In the selection screen,
    you can choose from **BigQuery**, **Cloud Storage**, and **Google Cloud AI Platform**
    (Vertex AI Workbench). In our example, two out of the three available services
    were selected.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading your Kaggle Notebook to Google Cloud AI Notebooks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you reach the limit of resources available for Kaggle Notebooks (RAM, the
    number of cores, or execution time), you can choose to promote your notebook to
    Google Cloud AI Notebooks by exporting your notebook to Google Cloud. Google Cloud
    AI Notebooks is a paid service from Google Cloud, and it gives you access to computing
    resources in Google Cloud for machine learning, using a notebook as an **integrated
    development environment** (**IDE**). For this action, select **File** | **Upgrade
    to Google AI Notebooks**, and you will be directed to the following window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.11: Upgrade to Goole Cloud AI Platform Notebooks'
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow this three-step process: set up a billing-enabled Google Cloud project,
    set up your network instance, and run your code. Your code can run without the
    resource limits now.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see now how we can use a notebook to automatize the update of a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Using a Notebook to automatically update a Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can automatize the generation of a Dataset using Kaggle Notebooks by combining
    two features: a scheduled rerun of notebooks and an update of a Dataset upon a
    Notebook run.'
  prefs: []
  type: TYPE_NORMAL
- en: First, create the Notebook that will collect the data. It can be, for example,
    a Notebook that crawls pages of a certain site to retrieve RSS News feeds or connect
    to the Twitter API (as in the previous example) to download tweets. Set as the
    Notebook output the collected data.
  prefs: []
  type: TYPE_NORMAL
- en: After the notebook runs for the first time, initialize a Dataset with the output
    of the notebook by selecting **Output** | **Create Dataset**, and set the option
    for the Dataset to be updated every time the notebook is running.
  prefs: []
  type: TYPE_NORMAL
- en: Then, edit the notebook again, and schedule it to run with the frequency that
    you want your data to be refreshed, as you can see in the following screenshot.
    Once you set it like that, you will have the notebook running automatically, and
    because the Dataset has the setting to be updated when running the notebook, the
    update of the Dataset will happen automatically going forward.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20963_02_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.12: Scheduling a Notebook to run daily, starting from August 7, 2023'
  prefs: []
  type: TYPE_NORMAL
- en: The mechanism described here allows you to perform the entire automatization
    process, using only Kaggle tools available from the user interface. For more complex
    processes, you can always use the Kaggle API to define and automatically perform
    your tasks. In the next subsection, we will describe the basic functionality available
    with the Kaggle API, with a focus on manipulating notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Kaggle API to create, update, download, and monitor your notebooks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Kaggle API is a powerful tool that extends the functionality available
    in the Kaggle user interface. You can use it for various tasks: define, update,
    and download datasets, submit to competitions, define new notebooks, push or pull
    versions of notebooks, or verify a run status.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are just two simple steps for you to start using the Kaggle API. Let’s
    get started:'
  prefs: []
  type: TYPE_NORMAL
- en: First, you will need to create an authentication token. Navigate to your account,
    and from the right-side icon, select the menu item **Account**. Then go to the
    **API** section. Here, click on the **Create new API token** button to download
    your authentication token (it is a file named `kaggle.json`). If you will be using
    the Kaggle API from a Windows machine, its location is `C:\Users\<your_name>\.kaggle\kaggle.json`.
    On a Mac or Linux machine, the path to the file should be `~/.kaggle/kaggle.json`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, you will have to install the Kaggle API Python module. Run the following
    in your selected Python or conda environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With these two steps, you are ready to start using the Kaggle API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The API also provides multiple options to list notebooks in your account, check
    notebook status, download a copy, create the first version of a notebook, run
    it, and more. Let’s look at each of these options:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To list all notebooks based on a certain name pattern, run the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The command will return a table with the `{username}/{kernel-slug}`, which matches
    the name pattern, the last runtime, the number of votes, the notebook title, and
    the author-readable name.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To verify the status of a certain notebook in your environment, run the following
    command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, `{username}/{kernel-slug}` is not the entire path to the notebook on Kaggle
    but the part of the path that will follow the platform path `https://www.kaggle.com`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The preceding command will return the kernel status. For example, if the kernel
    execution was complete, it will return:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can download a notebook by running the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this case, a Jupyter Notebook with the name `{kernel-slug}.ipynb` will be
    downloaded in the folder specified by `/path/to/download`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To create the first version of a notebook and run it, first define a Kaggle
    metadata file with the command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Your generated Kaggle metadata file will look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For the purpose of this demonstration, I edited the metadata file to generate
    a notebook called `Test Kaggle API`, which uses Python. For your convenience,
    I replaced my own username with `{username}`. You need to take care to correlate
    the `{kernel-slug}` with the real title, since normally the `{kernel-slug}` is
    generated as the lowercase version, without special characters and replacing spaces
    with dashes. Here is the result:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After you edit the metadata file, you can initiate the notebook with the following
    command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you also created the prototype of your notebook in the `/path/to/kernel`
    folder and it is named `test_kaggle_api.ipynb`, you will receive the following
    answer to your command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can also use the API to download the output of an existing notebook. For
    this, use the following code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will download a file called `{kernel-slug}.log` in the current folder.
    Alternatively, you can specify the path to the following destination:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The file contains the execution logs of the kernel’s last run.
  prefs: []
  type: TYPE_NORMAL
- en: We have learned how to create an authentication token and install the Kaggle
    API. Then, we saw how to use the Kaggle API to create a notebook, update it, and
    download it.
  prefs: []
  type: TYPE_NORMAL
- en: More details about how to use the Kaggle API to boost your platform usage can
    be found in the Kaggle documentation section about the API at [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned what Kaggle Notebooks are, what types we can use,
    and with what programming languages. We also learned how to create, run, and update
    notebooks. We then visited some of the basic features for using notebooks, which
    will allow you to start using notebooks in an effective way, to ingest and analyze
    data from datasets or competitions, to start training models, and to prepare submissions
    for competitions. Additionally, we also reviewed some of the advanced features
    and even introduced the use of the Kaggle API to further extend your usage of
    notebooks, allowing you to build external data and ML pipelines that integrate
    with your Kaggle environment.
  prefs: []
  type: TYPE_NORMAL
- en: The more advanced features give you more flexibility in using Kaggle Notebooks.
    With Utility scripts, you can create modular code, with specialized Python modules
    for ingesting data, performing statistical analysis on it, preparing visualizations,
    generating features, and building models. You can reuse these modules between
    notebooks, without the need to copy code from one notebook to another. With secrets,
    on the other hand, you can make public your notebooks that use API keys to access
    external services, without exposing your personal keys; it is the Kaggle equivalent
    of a password vault.
  prefs: []
  type: TYPE_NORMAL
- en: With the integration with Google Cloud, you can expand your compute or storage
    resources, and surpass the limitations for such resources on the Kaggle platform.
    We also learned the basics of the Kaggle API. You know now how to use the Kaggle
    API to search for an existing notebook, create a new notebook, or download the
    output of an existing notebook. This gives you the flexibility to define hybrid
    pipelines that integrate Kaggle, Google Cloud, and local resources. You can also
    control your Kaggle Notebooks from external scripts.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will start our journey around the data world with a
    first stop: a classical exploration of the **Titanic** competition dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/kaggle](https://packt.link/kaggle)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code9220780366773140.png)'
  prefs: []
  type: TYPE_IMG
