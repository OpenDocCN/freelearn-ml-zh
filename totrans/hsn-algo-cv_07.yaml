- en: Object Detection – Features and Descriptors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned about processing videos and how to perform
    the operations and algorithms from all of the previous chapters on frames read
    from cameras or video files. We learned that each video frame can be treated as
    an individual image, so we can easily use algorithms, such as filtering, on videos
    in almost the same way as we did with images. After learning how to process videos
    using algorithms that work on single individual frames, we moved on to learn about
    video processing algorithms that require a set of consecutive video frames to
    perform object detection, tracking, and so on. We learned about how to use the
    magic of the Kalman filter to improve object-tracking results, and ended the chapter
    by learning about background and foreground extraction.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: The object detection (and tracking) algorithms that we learned about in the
    previous chapter rely heavily on the color of an object, which has proven not
    to be too reliable, especially if the object and the environment we are working
    with are not controlled in terms of lighting. We all know that the brightness
    and color of an object can easily (and sometimes extremely) change under sunlight
    and moonlight, or if a light of a different color is near the object, such as
    a red traffic light. These difficulties are the reason why the detection of objects
    is more reliable when their physical shape and features are used as a basis for
    object detection algorithms. Obviously, the shape of an image is independent of
    its color. A circular object will remain circular during the day or night, so
    an algorithm that is capable of extracting the shape of such an object would be
    more reliable to be used for detecting that object.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we're going to learn about computer vision algorithms, functions,
    and classes that can be used to detect and recognize objects using their features.
    We'll learn about a number of algorithms that can be used for shape extraction
    and analysis, and then we'll proceed to learning about key-point detection and
    descriptor-extraction algorithms. We'll also learn how to match descriptors from
    two images to detect objects of known shapes in an image. In addition to the topics
    that we just mentioned, this chapter will also include the required functions
    for proper visualization of key points and matching results.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you''ll learn about the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Template matching for object detection
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting contours and using them for shape analysis
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating and analyzing contours
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting lines and circles using the Hough transformation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting, descripting, and matching features
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An IDE to develop C++ or Python applications
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The OpenCV library
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refer to [Chapter 2](part0030.html#SJGS0-15c05657f8254d318ea883ef10fc67f4),
    *Getting Started with OpenCV*, for more information about how to set up a personal
    computer and make it ready for developing computer vision applications using the
    OpenCV library.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考[第2章](part0030.html#SJGS0-15c05657f8254d318ea883ef10fc67f4)，《使用OpenCV入门》，以获取更多关于如何设置个人电脑并使其准备好使用OpenCV库开发计算机视觉应用程序的信息。
- en: 'You can use the following URL to download the source code and examples for
    this chapter:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下网址下载本章的源代码和示例：
- en: '[https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter07).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter07](https://github.com/PacktPublishing/Hands-On-Algorithms-for-Computer-Vision/tree/master/Chapter07).'
- en: Template matching for object detection
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对象检测的模板匹配
- en: 'Before we start with the shape-analysis and feature-analysis algorithms, we
    are going to learn about an easy-to-use, extremely powerful method of object detection
    called **template matching**. Strictly speaking, this algorithm does not fall
    into the category of algorithms that use any knowledge about the shape of an object,
    but it uses a previously acquired template image of an object that can be used
    to extract a template-matching result and consequently objects of known look,
    size, and orientation. You can use the `matchTemplate` function in OpenCV to perform
    a templating-matching operation. Here''s an example that demonstrates the complete
    usage of the `matchTemplate` function:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始形状分析和特征分析算法之前，我们将学习一种易于使用且功能强大的对象检测方法，称为**模板匹配**。严格来说，这个算法不属于使用任何关于对象形状知识的算法类别，但它使用了一个先前获取的对象模板图像，该图像可以用来提取模板匹配结果，从而识别出已知外观、大小和方向的对象。您可以使用OpenCV中的`matchTemplate`函数执行模板匹配操作。以下是一个演示`matchTemplate`函数完整使用的示例：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`method` must be an entry from the `TemplateMatchModes` enum, which can be
    any of the following values:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`method`必须是从`TemplateMatchModes`枚举中的一项，可以是以下任何值：'
- en: '`TM_SQDIFF`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TM_SQDIFF`'
- en: '`TM_SQDIFF_NORMED`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TM_SQDIFF_NORMED`'
- en: '`TM_CCORR`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TM_CCORR`'
- en: '`TM_CCORR_NORMED`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TM_CCORR_NORMED`'
- en: '`TM_CCOEFF`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TM_CCOEFF`'
- en: '`TM_CCOEFF_NORMED`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TM_CCOEFF_NORMED`'
- en: 'For detailed information about each template-matching method, you can refer
    to the OpenCV documentation. For our practical examples, and to learn how the
    `matchTemplate` function is used in practice, it is important to note that each
    method will result in a different type of result, and consequently a different
    interpretation of the result is required, which we''ll learn about in this section.
    In the preceding example, we are trying to detect an object in a scene by using
    an object image and a scene image. Let''s assume the following images are the
    object (left-hand side) and the scene (right-hand side) that we''ll be using:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 关于每种模板匹配方法的详细信息，您可以参考OpenCV文档。对于我们的实际示例，以及了解`matchTemplate`函数在实际中的应用，重要的是要注意，每种方法都会产生不同类型的结果，因此需要对结果进行不同的解释，我们将在本节中学习这些内容。在前面的例子中，我们试图通过使用对象图像和场景图像来检测场景中的对象。让我们假设以下图像是我们将使用的对象（左侧）和场景（右侧）：
- en: '![](img/00080.jpeg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00080.jpeg)'
- en: 'The very simple idea in template matching is that we are searching for a point
    in the scene image on the right-hand side that has the highest possibility of
    containing the image on the left-hand side, or in other words, the template image.
    The `matchTemplate` function, depending on the method that is used, will provide
    a probability distribution. Let''s visualize the result of the `matchTemplate`
    function to better understand this concept. Another important thing to note is
    that we can only properly visualize the result of the `matchTemplate` function
    if we use any of the methods ending with `_NORMED`, which means they contain a
    normalized result, otherwise we have to use the normalize method to create a result
    that contains values in the displayable range of the OpenCV `imshow` function.
    Here is how it can be done:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 模板匹配中的一个非常简单的想法是我们正在寻找场景图像右侧的一个点，该点有最高可能性包含左侧的图像，换句话说，就是模板图像。`matchTemplate`函数，根据所使用的方法，将提供一个概率分布。让我们可视化`matchTemplate`函数的结果，以更好地理解这个概念。另一个需要注意的重要事情是，我们只能通过使用以`_NORMED`结尾的任何方法来正确可视化`matchTemplate`函数的结果，这意味着它们包含归一化的结果，否则我们必须使用归一化方法来创建一个包含OpenCV
    `imshow`函数可显示范围内的值的输出。以下是实现方法：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This function call will translate all the values in `result` to the range of
    `0.0` and `1.0`, which can then be properly displayed. Here is how the resulting
    image will look if it is displayed using the `imshow` function:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数调用将`result`中的所有值转换为`0.0`和`1.0`的范围，然后可以正确显示。以下是使用`imshow`函数显示的结果图像的外观：
- en: '![](img/00081.jpeg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00081.jpeg)'
- en: 'As mentioned previously, the result of the `matchTemplate` function and how
    it should be interpreted depends completely on the template matching method that
    is used. In the case that we use the `TM_SQDIFF` or `TM_SQDIFF_NORMED` methods
    for template matching, we need to look for the global minimum point in the result
    (it is shown using an arrow in the preceding image), which has the highest possibility
    of containing the template image. Here''s how we can find the global minimum point
    (along with global maximum, and so on) in the template matching result:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`matchTemplate`函数的结果及其解释完全取决于所使用的模板匹配方法。在我们使用`TM_SQDIFF`或`TM_SQDIFF_NORMED`方法进行模板匹配的情况下，我们需要在结果中寻找全局最小点（前一张图中的箭头所示），它最有可能是包含模板图像的点。以下是我们在模板匹配结果中找到全局最小点（以及全局最大点等）的方法：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Since the template-matching algorithm works only with objects of a fixed size
    and orientation, we can assume that a rectangle that has an upper-left point that
    is equal to the `minLoc` point and has a size that equals the template image is
    the best possible bounding rectangle for our object. We can draw the result on
    the scene image, for better comparison, using the following sample code:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模板匹配算法仅与固定大小和方向的物体工作，我们可以假设一个矩形，其左上角等于`minLoc`点，且大小等于模板图像，是我们对象的最佳可能边界矩形。我们可以使用以下示例代码在场景图像上绘制结果，以便更好地比较：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following image depicts the result of the object detection operation that
    was performed using the `matchTemplate` function:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了使用`matchTemplate`函数执行的对象检测操作的结果：
- en: '![](img/00082.jpeg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00082.jpeg)'
- en: 'If we use `TM_CCORR`, `TM_CCOEFF`, or their normalized versions, we must use
    the global maximum point as the point with the highest possibility of containing
    our template image. The following image depicts the result of the `TM_CCOEFF_NORMED`
    method used with the `matchTemplate` function:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用`TM_CCORR`、`TM_CCOEFF`或它们的归一化版本，我们必须使用全局最大点作为包含我们的模板图像可能性最高的点。以下图像展示了使用`matchTemplate`函数的`TM_CCOEFF_NORMED`方法的结果：
- en: '![](img/00083.jpeg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00083.jpeg)'
- en: As you can see, the brightest point in the resultant image corresponds to the
    upper-left point of the template image in the scene image.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，结果图像中最亮的点对应于场景图像中模板图像的左上角。
- en: Before ending our template matching lesson, let's also note that the width and
    height of the template matching resultant image is smaller than the scene image.
    This is because the template matching resultant image can only contain the upper-left
    point of the template image, so the template image width and height are subtracted
    from the scene image's width and height to determine the resultant image's width
    and height in the template-matching algorithm.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束我们的模板匹配课程之前，我们也要注意，模板匹配结果的宽度和高度小于场景图像。这是因为模板匹配结果图像只能包含模板图像的左上角，因此从场景图像的宽度和高度中减去模板图像的宽度和高度，以确定模板匹配算法中结果图像的宽度和高度。
- en: Detecting corners and edges
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测角点和边缘
- en: It is not always possible to just compare images pixel-wise and decide whether
    an object is present in an image or not, or whether an object has the expected
    shape or not, and many more similar scenarios that we can't even begin to list
    here. That is why the smarter way of interpreting the contents of an image is
    to look for meaningful features in it, and then base our interpretation on the
    properties of those features. In computer vision, a feature is synonymous with
    a keypoint, so don't be surprised if we use them interchangeably in this book.
    In fact, the word keypoint is better suited to describe the concept, since the
    most commonly used features in an image are usually *key points* in that image
    where there is a sudden change in color intensity, which can happen in corners
    and edges of shapes and objects in an image.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 并非总是可以仅仅通过像素级比较图像并决定一个物体是否存在于图像中，或者一个物体是否具有预期的形状，以及许多我们甚至无法一一列举的类似场景。这就是为什么更智能的方法是寻找图像中的有意义特征，然后根据这些特征的性质进行解释。在计算机视觉中，特征与关键点同义，所以如果我们在这本书中交替使用它们，请不要感到惊讶。实际上，关键词汇更适合描述这个概念，因为图像中最常用的特征通常是图像中的*关键点*，在这些点上颜色强度发生突然变化，这可能在图像中形状和物体的角点和边缘处发生。
- en: In this section, we'll learn about some of the most important and widely used
    keypoint-detection algorithms, namely the corner- and edge-detection algorithms
    that are the basis of almost all of the feature-based object detection algorithms
    we'll be learning about in this chapter.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解一些最重要且最广泛使用的特征点检测算法，即角点和边缘检测算法，这些算法是我们在本章中将学习的几乎所有基于特征的物体检测算法的基础。
- en: Learning the Harris corner-detection algorithm
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习Harris角点检测算法
- en: 'One of the most well-known corner- and edge-detection algorithms is the Harris
    corner-detection algorithm, which is implemented in the `cornerHarris` function
    in OpenCV. Here is how this function is used:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的角点和边缘检测算法之一是Harris角点检测算法，该算法在OpenCV的`cornerHarris`函数中实现。以下是该函数的使用方法：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`blockSize` determines the width and height of the square block over which
    the Harris corner-detection algorithm will calculate a 2 x 2 gradient-covariance
    matrix. `ksize` is the kernel size of the Sobel operator internally used by the
    Harris algorithm. The preceding example demonstrates one of the most commonly
    used sets of Harris algorithm parameters, but for more detailed information about
    the Harris corner-detection algorithm and its internals mathematics, you can refer
    to the OpenCV documentation. It''s important to note that the `result` object
    from the preceding example code is not displayable unless it is normalized using
    the following example code:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`blockSize`决定了Harris角点检测算法将计算2 x 2梯度协方差矩阵的正方形块的宽度和高度。`ksize`是Harris算法内部使用的Sobel算子的核大小。前一个示例演示了最常用的Harris算法参数集之一，但有关Harris角点检测算法及其内部数学的更详细信息，您可以参考OpenCV文档。需要注意的是，前一个示例代码中的`result`对象除非使用以下示例代码进行归一化，否则是不可显示的：'
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here is the result of the Harris corner-detection algorithm from the preceding
    example, when normalized and displayed using the OpenCV `imshow` function:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是前一个示例中Harris角点检测算法的结果，当使用OpenCV的`imshow`函数进行归一化和显示时：
- en: '![](img/00084.jpeg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00084.jpeg)'
- en: 'The OpenCV library includes another famous corner-detection algorithm, called
    **Good Features to Track** (**GFTT**). You can use the `goodFeaturesToTrack` function
    in OpenCV to use the GFTT algorithm to detect corners, as seen in the following
    example:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV库还包括另一个著名的角点检测算法，称为**Good Features to Track**（**GFTT**）。您可以使用OpenCV中的`goodFeaturesToTrack`函数来使用GFTT算法检测角点，如下面的示例所示：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, this function requires a single-channel image, so, before doing
    anything else, we have converted our BGR image to grayscale. Also, this function
    uses the `maxCorners` value to limit the number of detected corners based on how
    strong they are as candidates, and setting `maxCorners` to a negative value or
    to zero means all detected corners should be returned, which is not a good idea
    if you are looking for the best corners in an image, so make sure you set a reasonable
    value for this based on the environment in which you'll be using it. `qualityLevel`
    is the internal threshold value for accepting detected corners. `minDistance`
    is the minimum allowed distance between returned corners. This is another parameter
    that is completely dependent on the environment this algorithm will be used in.
    You have already seen  the remaining parameters in the previous algorithms from
    this chapter and the preceding one. It's important to note that this function
    also incorporates the Harris corner-detection algorithm, so, by setting `useHarrisDetector`
    to `true`, the resultant features will be calculated using the Harris corner-detection
    algorithm.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个函数需要一个单通道图像，因此，在执行任何其他操作之前，我们已经将我们的BGR图像转换为灰度图。此外，这个函数使用`maxCorners`值来根据它们作为候选者的强度限制检测到的角点的数量，将`maxCorners`设置为负值或零意味着应返回所有检测到的角点，如果你在寻找图像中的最佳角点，这不是一个好主意，所以请确保根据你将使用它的环境设置一个合理的值。`qualityLevel`是接受检测到的角点的内部阈值值。`minDistance`是返回角点之间允许的最小距离。这是另一个完全依赖于该算法将用于的环境的参数。你已经在上一章和前一章的先前算法中看到了剩余的参数。重要的是要注意，此函数还结合了Harris角点检测算法，因此，通过将`useHarrisDetector`设置为`true`，结果特征将使用Harris角点检测算法计算。
- en: 'You might have already noticed that the `goodFeaturesToTrack` function returns
    a set of `Point` objects (`Point2f` to be precise) instead of a `Mat` object.
    The returned `corners` vector simply contains the best possible corners detected
    in the image using the GFTT algorithm, so we can use the `drawMarker` function
    to visualize the results properly, as seen in the following example:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，`goodFeaturesToTrack`函数返回一组`Point`对象（确切地说是`Point2f`对象）而不是`Mat`对象。返回的`corners`向量仅包含使用GFTT算法在图像中检测到的最佳可能角点，因此我们可以使用`drawMarker`函数来正确地可视化结果，如下面的例子所示：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here is the result of the preceding example and detecting corners using the
    `goodFeaturesToTrack` function:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是前面例子中使用`goodFeaturesToTrack`函数检测角点得到的结果：
- en: '![](img/00085.jpeg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00085.jpeg)'
- en: 'You can also use the `GFTTDetector` class to detect corners in a similar way
    as you did with the `goodFeaturesToTrack` function. The difference here is that
    the returned type is a vector of `KeyPoint` objects. Many OpenCV functions and
    classes use the `KeyPoint` class to return various properties of detected keypoints,
    instead of just a `Point` object that corresponds to the location of the keypoint.
    Let''s see what this means with the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用`GFTTDetector`类以与`goodFeaturesToTrack`函数类似的方式检测角点。这里的区别在于返回的类型是`KeyPoint`对象的向量。许多OpenCV函数和类使用`KeyPoint`类来返回检测到的关键点的各种属性，而不是仅对应于关键点位置的`Point`对象。让我们通过以下内容来看看这意味着什么：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The parameters passed to the `GFTTDetector::create` function are no different
    from the parameters we used with the `goodFeaturesToTrack` function. You can also
    omit all of the given parameters and simply write the following to use the default
    and optimal values for all parameters:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给`GFTTDetector::create`函数的参数与我们使用`goodFeaturesToTrack`函数时使用的参数没有不同。你也可以省略所有给定的参数，只需简单地写下以下内容即可使用所有参数的默认和最佳值：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'But let''s get back to the `KeyPoint` class and the result of the `detect`
    function from the previous example. Recall that we used a loop to go through all
    of the detected points and draw them on the image. There is no need for this if
    we use the `GFTTDetector` class, since we can use an existing OpenCV function
    called `drawKeypoints` to properly visualize all of the detected keypoints. Here''s
    how this function is used:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们回到之前的例子中的`KeyPoint`类和`detect`函数的结果。回想一下，我们使用循环遍历所有检测到的点并在图像上绘制它们。如果我们使用`GFTTDetector`类，则不需要这样做，因为我们可以使用现有的OpenCV函数`drawKeypoints`来正确地可视化所有检测到的关键点。以下是这个函数的使用方法：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `drawKeypoints` function goes through all `KeyPoint` objects in the `keypoints`
    vector and draws them using random colors on `image` and saves the result in the `outImg`
    object, which we can then display by calling the `imshow` function. The following
    image is the result of the `drawKeypoints` function when it is called using the
    preceding example code:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00086.jpeg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: The `drawKeypoints` function can be provided with an additional (optional) color
    parameter in case we want to use a specific color instead of random colors. In
    addition, we can also provide a flag parameter that can be used to further enhance
    the visualized result of the detected keypoints. For instance, if the flag is
    set to `DRAW_RICH_KEYPOINTS`, the `drawKeypoints` function will also use the size
    and orientation values in each detected keypoint to visualize more properties
    of keypoints.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'Each `KeyPoint` object may contain the following properties, depending on the
    algorithm used for calculating it:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '- `pt`: A `Point2f` object containing the coordinates of the keypoint.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '- `size`: The diameter of the meaningful keypoint neighborhood.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '- `angle`: The orientation of the keypoint in degrees, or -1 if not applicable.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '- `response`: The strength of the keypoint determined by the algorithm.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '- `octave`: The octave or pyramid layer from which the keypoint was extracted.
    Using octaves allows us to deal with keypoints detected from the same image but
    in different scales. Algorithms that set this value usually require an input octave
    parameter, which is used to define the number of octaves (or scales) of an image
    that is used to extract keypoints.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '- `class_id`: This integer parameter can be used to group keypoints, for instance,
    when keypoints belong to a single object, they can have the same optional `class_id`
    value.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: In addition to Harris and GFTT algorithms, you can also use the FAST corner-detection
    algorithm using the `FastFeatureDetector` class, and the AGAST corner-detection
    algorithm (**Adaptive and Generic Corner Detection Based on the Accelerated Segment
    Test**) using the `AgastFeatureDetector` class, quite similar to how we used the `GFTTDetector`
    class. It's important to note that all of these classes belong to the `features2d`
    module in the OpenCV library and they are all subclasses of the `Feature2D` class,
    therefore all of them contain a static `create` function that creates an instance
    of their corresponding classes and a `detect` function that can be used to extract
    the keypoints from an image.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example code demonstrating the usage of `FastFeatureDetector` using
    all of its default parameters:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Try increasing the `threshold` value if too many corners are detected. Also,
    make sure to check out the OpenCV documentation for more information about the
    `type` parameter used in the `FastFeatureDetector` class. As mentioned previously,
    you can simply omit all of the parameters in the preceding example code to use
    the default values for all parameters.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `AgastFeatureDetector` class is extremely similar to using `FastFeatureDetector`.
    Here is an example:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `AgastFeatureDetector` 类与使用 `FastFeatureDetector` 非常相似。以下是一个示例：
- en: '[PRE12]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Before moving on to edge-detection algorithms, it''s worth noting that OpenCV
    also contains the `AGAST` and `FAST` functions, which can be employed to directly
    use their corresponding algorithms and avoid dealing with creating an instance
    to use them; however, using the class implementation of these algorithms has the
    huge advantage of switching between algorithms using polymorphism. Here''s a simple
    example that demonstrates how we can use polymorphism to benefit from the class
    implementations of corner-detection algorithms:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续学习边缘检测算法之前，值得注意的是 OpenCV 还包含 `AGAST` 和 `FAST` 函数，可以直接使用它们对应的算法，避免处理创建实例来使用它们；然而，使用这些算法的类实现具有使用多态在算法之间切换的巨大优势。以下是一个简单的示例，演示了我们可以如何使用多态从角点检测算法的类实现中受益：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`algorithm`, in the preceding example, is an integer value that can be set
    at run-time and will change the type of the corner-detection algorithm assigned
    to the `detector` object, which has the `Feature2D` type, or in other words, the
    base class of all corner-detection algorithms.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，`algorithm` 是一个可以在运行时设置的整数值，它将改变分配给 `detector` 对象的角点检测算法的类型，该对象具有 `Feature2D`
    类型，换句话说，是所有角点检测算法的基类。
- en: Edge-detection algorithms
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘检测算法
- en: 'Now that we''ve gone through corner-detection algorithms, let''s take a look
    at edge-detection algorithms, which are crucial when it comes to shape analysis
    in computer vision. OpenCV contains a number of algorithms that can be used to
    extract edges from images. The first edge-detection algorithm that we''re going
    to learn about is called the **line-segment-detection algorithm**, and it can
    be performed by using the `LineSegmentDetector` class, as seen in the following
    example:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了角点检测算法，让我们来看看边缘检测算法，这在计算机视觉中的形状分析中至关重要。OpenCV 包含了许多可以用于从图像中提取边缘的算法。我们将要学习的第一个边缘检测算法被称为
    **线段检测算法**，可以通过使用 `LineSegmentDetector` 类来实现，如下面的示例所示：
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As you can see, the `LineSegmentDetector` class requires a single-channel image
    as the input and produces a `vector` of lines. Each line in the result is `Vec4f`,
    or four floating-point values that represent *x1*, *y1*, *x2*, and *y2* values,
    or in other words, the coordinates of the two points that form each line. You
    can use the `drawSegments` function to visualize the result of the `detect` function
    of the `LineSegmentDetector` class, as seen in the following example:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`LineSegmentDetector` 类需要一个单通道图像作为输入，并生成一个 `vector` 的线条。结果中的每条线都是 `Vec4f`，即代表
    *x1*、*y1*、*x2* 和 *y2* 值的四个浮点数，换句话说，就是构成每条线的两个点的坐标。您可以使用 `drawSegments` 函数来可视化
    `LineSegmentDetector` 类的 `detect` 函数的结果，如下面的示例所示：
- en: '[PRE15]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To have more control over how the resultant lines are visualized, you might
    want to manually draw the lines vector, as seen in the following example:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地控制结果线条的可视化，您可能需要手动绘制线条向量，如下面的示例所示：
- en: '[PRE16]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The following image demonstrates the result of the line-segment-detection algorithm
    that was used in the preceding example codes:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了前面示例代码中使用的线段检测算法的结果：
- en: '![](img/00087.jpeg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00087.jpeg)'
- en: For more details about how to customize the behavior of the `LineSegmentDetector`
    class, make sure to view the documentation of `createLineSegmentDetector` and
    its parameters. In our example, we simply omitted all of its input parameters
    and used the `LineSegmentDetector` class with the default values set for its parameters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解更多关于如何自定义 `LineSegmentDetector` 类的行为的详细信息，请确保查看 `createLineSegmentDetector`
    的文档及其参数。在我们的示例中，我们简单地省略了所有输入参数，并使用默认值设置了 `LineSegmentDetector` 类的参数。
- en: 'Another function of the `LineSegmentDetector` class is comparing two sets of
    lines to find the number of non-overlapping pixels, and at the same time drawing
    the result of the comparison on an output image for visual comparison. Here''s
    an example:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`LineSegmentDetector` 类的另一个功能是比较两组线条以找到非重叠像素的数量，同时将比较结果绘制在输出图像上以进行可视化比较。以下是一个示例：'
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the preceding code, `imageSize` is a `Size` object that contains the size
    of the input image where the lines were extracted from. The result is an integer
    value that contains the result of the comparison function, or the `compareSegments`
    function, which will be zero in the case of the complete overlapping of pixels.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`imageSize` 是一个 `Size` 对象，它包含从其中提取线条的输入图像的大小。结果是包含比较函数或 `compareSegments`
    函数结果的整数值，在像素完全重叠的情况下将为零。
- en: 'The next edge-detection algorithm is probably one of the most widely used and
    cited edge-detection algorithms in computer vision, called the **Canny algorithm**,
    which has a function of the same name in OpenCV. The biggest advantage of the
    `Canny` function is the simplicity of its input parameters. Let''s first see an
    example of how it''s used, and then walk through its details:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个边缘检测算法可能是计算机视觉中最广泛使用和引用的边缘检测算法之一，称为 **Canny 算法**，在 OpenCV 中具有相同名称的函数。`Canny`
    函数的最大优点是其输入参数的简单性。让我们首先看看它的一个示例用法，然后详细说明其细节：
- en: '[PRE18]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The threshold values (`threshold1` and `threshold2`) are the lower and higher
    bound values for thresholding the input image. `apertureSize` is the internal
    Sobel operator aperture size, and `L2gradient` is used to enable or disable the
    more accurate L2 norm when calculating the gradient image. The result of the `Canny`
    function is a grayscale image that contains white pixels where edges are detected
    and black pixels for the rest of the pixels. This makes the result of the `Canny`
    function a suitable mask wherever such a mask is needed, or, as you'll see later
    on, a suitable set of points to extract contours from.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值值（`threshold1` 和 `threshold2`）是用于阈值化输入图像的下限和上限值。`apertureSize` 是内部 Sobel 运算符的孔径大小，而
    `L2gradient` 用于在计算梯度图像时启用或禁用更精确的 L2 范数。`Canny` 函数的结果是一个灰度图像，其中包含检测到边缘处的白色像素和其余像素的黑色像素。这使得
    `Canny` 函数的结果在需要此类掩模的地方非常适合，或者，如你稍后所看到的，提取轮廓的合适点集。
- en: 'The following image depicts the result of the `Canny` function used in the
    previous example:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像描述了前面示例中使用的 `Canny` 函数的结果：
- en: '![](img/00088.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00088.jpeg)'
- en: As we mentioned before, the result of the `Canny` function is suitable to use
    as the input to algorithms that require a binary image, or in other words, a grayscale
    image containing only absolute black and absolute white pixel values. The next
    algorithm that we'll learn about is one where the result of a previous `Canny`
    function must be used as the input, and it is called the **Hough transformation**.
    The Hough transformation can be used to extract lines from an image, and it is
    implemented in a function called `HoughLines` in the OpenCV library.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，`Canny` 函数的结果适合用作需要二值图像的算法的输入，换句话说，是一个只包含绝对黑色和绝对白色像素值的灰度图像。我们将学习下一个算法，其中必须使用先前
    `Canny` 函数的结果作为输入，它被称为 **霍夫变换**。霍夫变换可以用于从图像中提取线条，并在 OpenCV 库中的 `HoughLines` 函数中实现。
- en: 'Here is a complete example that demonstrates how the `HoughLines` function
    is used in practice:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个完整的示例，展示了如何在实际中使用 `HoughLines` 函数：
- en: 'Call the `Canny` function to detect edges in the input image, as seen here:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 `Canny` 函数检测输入图像中的边缘，如下所示：
- en: '[PRE19]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Call the `HoughLines` function to extract lines from the detected edges:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 `HoughLines` 函数从检测到的边缘中提取线条：
- en: '[PRE20]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Use the following code to extract points in the standard coordinate system,
    and draw them over the input image:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码在标准坐标系中提取点，并在输入图像上绘制它们：
- en: '[PRE21]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following images depict the result of the preceding example from left to
    right, starting with the original image, edges detected using the `Canny` function,
    lines detected using the `HoughLines` function, and finally the output image:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像从左到右描述了前面示例的结果，首先是原始图像，然后是使用 `Canny` 函数检测到的边缘，接着是使用 `HoughLines` 函数检测到的线条，最后是输出图像：
- en: '![](img/00089.jpeg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00089.jpeg)'
- en: 'To avoid having to deal with the coordinate-system change, you can use the `HoughLinesP`
    function to directly extract the points forming each detected line. Here''s an
    example:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免处理坐标系统变化，你可以使用 `HoughLinesP` 函数直接提取形成每个检测到的线条的点。以下是一个示例：
- en: '[PRE22]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The Hough transformation is extremely powerful, and OpenCV contains more variations
    of the Hough transformation algorithm that we'll leave for you to discover using
    the OpenCV documentation and online resources. Note that using the Canny algorithm
    is a prerequisite of the Hough transformation, and, as you'll see in the next
    section, a prerequisite of many algorithms that deal with the shape of objects
    in an image.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Hough 变换非常强大，OpenCV 包含更多 Hough 变换算法的变体，我们将留给您使用 OpenCV 文档和在线资源去发现。请注意，使用 Canny
    算法是 Hough 变换的前提，正如您将在下一节中看到的，也是处理图像中物体形状的许多算法的前提。
- en: Contour calculation and analysis
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 轮廓计算和分析
- en: Contours of shapes and objects in an image are an important visual property
    that can be used to describe and analyze them. Computer vision is no exception,
    so there are quite a few algorithms in computer vision that can be used to calculate
    the contours of objects in an image or calculate their area and so on.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图像中形状和物体的轮廓是一个重要的视觉属性，可以用来描述和分析它们。计算机视觉也不例外，因此计算机视觉中有相当多的算法可以用来计算图像中物体的轮廓或计算它们的面积等。
- en: 'The following image depicts two contours that are extracted from two 3D objects:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了从两个 3D 物体中提取的两个轮廓：
- en: '![](img/00090.jpeg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00090.jpeg)'
- en: 'OpenCV includes a function, called `findContours`, that can be used to extract
    contours from an image. This function must be provided with a proper binary image
    that contains the best candidate pixels for contours; for instance, the result
    of the `Canny` function is a good choice. The following example demonstrates the
    steps required to calculate the contours of an image:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV 包含一个名为 `findContours` 的函数，可以用来从图像中提取轮廓。此函数必须提供一个合适的二值图像，其中包含轮廓的最佳候选像素；例如，`Canny`
    函数的结果是一个不错的选择。以下示例演示了计算图像轮廓所需的步骤：
- en: 'Find the edges using the `Canny` function, as seen here:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `Canny` 函数找到边缘，如下所示：
- en: '[PRE23]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Use the `findContours` function to calculate the contours using the detected
    edges. It''s worth noting that each contour is a `vector` of `Point` objects,
    making all contours a `vector` of `vector` of `Point` objects, as seen here:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `findContours` 函数通过检测到的边缘来计算轮廓。值得注意的是，每个轮廓都是一个 `Point` 对象的 `vector`，因此所有轮廓都是一个
    `vector` 的 `vector` 的 `Point` 对象，如下所示：
- en: '[PRE24]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the preceding example, the contour-retrieval mode is set to `CV_RETR_TREE`
    and the contour-approximation method is set to `CV_CHAIN_APPROX_TC89_KCOS`. Make
    sure to go through the list of possible modes and methods by yourself, and compare
    the results to find the best parameters for your use case.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，轮廓检索模式设置为 `CV_RETR_TREE`，轮廓近似方法设置为 `CV_CHAIN_APPROX_TC89_KCOS`。请确保自己查看所有可能的模式和方法的列表，并比较结果以找到最适合您用例的最佳参数。
- en: 'A common method of visualizing detected contours is by using the `RNG` class,
    or the Random Number Generator class, to generate random colors for each detected
    contour. The following example demonstrates how you can use the `RNG` class in
    combination with the `drawContours` function to properly visualize the result
    of the `findContours` function:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化检测到的轮廓的常见方法是通过使用 `RNG` 类，即随机数生成器类，为每个检测到的轮廓生成随机颜色。以下示例演示了如何结合使用 `RNG` 类和
    `drawContours` 函数来正确可视化 `findContours` 函数的结果：
- en: '[PRE25]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following image demonstrates the result of the `Canny` and `findContours`
    functions:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了 `Canny` 和 `findContours` 函数的结果：
- en: '![](img/00091.jpeg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00091.jpeg)'
- en: Note the different colors in the image on the right-hand side, which correspond
    to one complete contour detected by using the `findContours` function.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 注意右侧图像中的不同颜色，它们对应于使用 `findContours` 函数检测到的完整轮廓。
- en: 'After calculating the contours, we can use contour-analysis functions to further
    modify them or analyze the shape of the object in an image. Let''s start with
    the `contourArea` function, which can be used to calculate the area of a given
    contour. Here is how this function is used:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 计算轮廓之后，我们可以使用轮廓分析函数进一步修改它们或分析图像中物体的形状。让我们从 `contourArea` 函数开始，该函数可以用来计算给定轮廓的面积。以下是该函数的使用方法：
- en: '[PRE26]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You can use area as a threshold for ignoring the detected contours that do
    not pass certain criteria. For example, in the preceding example code where we
    used the `drawContours` function, we could get rid of contours with smaller areas
    than some predefined threshold value. Here''s an example:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用面积作为阈值来忽略不符合某些标准的检测到的轮廓。例如，在前面的示例代码中，我们使用了`drawContours`函数，我们可以去除面积小于某个预定义阈值值的轮廓。以下是一个示例：
- en: '[PRE27]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Setting the second parameter of the `contourArea` function (which is a Boolean
    parameter) to `true` would result in the orientation being considered in the contour
    area, which means you can get positive or negative values of the area depending
    on the orientation of the contour.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 将`contourArea`函数的第二个参数（这是一个布尔参数）设置为`true`会导致考虑轮廓的朝向，这意味着你可以根据轮廓的朝向得到正或负的面积值。
- en: 'Another contour-analysis function that can be quite handy is the `pointPolygonTest`
    function. As you can guess from its name, this function is used to perform a point-in-polygon
    test, or in other words, a point-in-contour test. Here is how this function is
    used:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个非常有用的轮廓分析函数是`pointPolygonTest`函数。从其名称可以猜到，这个函数用于执行点在多边形内测试，换句话说，就是点在轮廓内测试。以下是该函数的使用方法：
- en: '[PRE28]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: If the result is zero, it means the test point is right on the edge of the contour.
    A negative result would mean the test point is outside, and a positive result
    would mean the test point is inside the contour. The value itself is the distance
    between the test point and the nearest contour edge.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果结果是零，这意味着测试点正好在轮廓的边缘上。一个负的结果意味着测试点在轮廓外部，而一个正的结果意味着测试点在轮廓内部。这个值本身是测试点到最近的轮廓边缘的距离。
- en: 'To be able to check whether a contour is convex or not, you can use the `isContourConvex`
    function, as seen in the following example:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查一个轮廓是否是凸的，你可以使用`isContourConvex`函数，如下例所示：
- en: '[PRE29]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Being able to compare two contours with each other is probably the most essential
    algorithm that you''ll need when dealing with contour and shape analysis. You
    can use the `matchShapes` function in OpenCV to compare and try to match two contours.
    Here is how this function is used:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 能够比较两个轮廓是处理轮廓和形状分析时最基本的需求之一。你可以使用OpenCV中的`matchShapes`函数来比较并尝试匹配两个轮廓。以下是该函数的使用方法：
- en: '[PRE30]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '`method` can take any of the following values, while the last parameter must
    always be set to zero, unless specified by the method used:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`method`可以取以下任何值，而最后一个参数必须始终设置为零，除非使用的方法有特殊指定：'
- en: '`CONTOURS_MATCH_I1`'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CONTOURS_MATCH_I1`'
- en: '`CONTOURS_MATCH_I2`'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CONTOURS_MATCH_I2`'
- en: '`CONTOURS_MATCH_I3`'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CONTOURS_MATCH_I3`'
- en: For details about the mathematical difference between the preceding list of
    contour-matching methods, you can refer to the OpenCV documentation.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 关于前面列出的轮廓匹配方法之间的数学差异的详细信息，你可以参考OpenCV文档。
- en: 'Being able to find the boundaries of a contour is the same as being able to
    correctly localize it, for instance to find a region that can be used for tracking
    or performing any other computer vision algorithm. Let''s assume we have the following
    image and its single contour detected using the `findContours` function:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 能够找到轮廓的边界等同于能够正确地定位它，例如，找到一个可以用于跟踪或执行其他计算机视觉算法的区域。假设我们有一个以下图像及其使用`findContours`函数检测到的单个轮廓：
- en: '![](img/00092.jpeg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00092.jpeg)'
- en: 'Having this contour, we can perform any of the contour- and shape-analysis
    algorithms that we''ve learned about. In addition, we can use a number of OpenCV
    functions to localize the extracted contour. Let''s start with the `boundingRect`
    function, which is used to find the minimal upright rectangle (`Rect` object)
    that contains a given point set or contour. Here''s how this function is used:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个轮廓，我们可以执行我们所学到的任何轮廓和形状分析算法。此外，我们可以使用许多OpenCV函数来定位提取的轮廓。让我们从`boundingRect`函数开始，该函数用于找到包含给定点集或轮廓的最小直立矩形（`Rect`对象）。以下是该函数的使用方法：
- en: '[PRE31]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following is the result of drawing the upright rectangle acquired by using
    `boundingRect` in the preceding sample code:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 下图是使用前一个示例代码中的`boundingRect`函数获取的直立矩形的绘制结果：
- en: '![](img/00093.jpeg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00093.jpeg)'
- en: 'Similarly, you can use the `minAreaRect` function to find the minimal rotated
    rectangle that contains a given set of points or a contour. Here''s an example:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，你可以使用`minAreaRect`函数来找到包含给定点集或轮廓的最小旋转矩形。以下是一个示例：
- en: '[PRE32]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You can use the following code to visualize the resultant rotated rectangle:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下代码来可视化结果旋转矩形：
- en: '[PRE33]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'You can draw an ellipse instead, using the `ellipse` function, or you can do
    both, which would result in something similar to the following:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`ellipse`函数绘制椭圆，或者两者都做，结果将类似于以下内容：
- en: '![](img/00094.jpeg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00094.jpeg)'
- en: 'In addition to algorithms for finding the minimal upright and rotated bounding
    rectangles of contours, you can also use the `minEnclosingCircle` and `minEnclosingTriangle`
    functions to find the minimal bounding circle and rectangle of a given set of
    points or a contour. Here''s an example of how these functions can be used:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 除了用于寻找轮廓的最小垂直和旋转边界矩形的算法外，您还可以使用`minEnclosingCircle`和`minEnclosingTriangle`函数来找到给定点集或轮廓的最小边界圆和矩形。以下是如何使用这些函数的示例：
- en: '[PRE34]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: There is no end to the list of possible use cases of contours, but we will name
    just a few of them before moving on to the next section. You can try using contour-detection
    and shape-analysis algorithms in conjunction with thresholding algorithms or back-projection
    images, for instance, to make sure your tracking algorithm uses the shape information
    in addition to the color and intensity values of pixels. You can also use contours
    to count and analyze shapes of objects on a production line, where the background
    and the visual environment is more controlled.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 轮廓的可能用例清单没有尽头，但在进入下一部分之前，我们将列举其中的一些。您可以尝试将轮廓检测和形状分析算法与阈值算法或后投影图像结合使用，例如，以确保您的跟踪算法除了像素的颜色和强度值外，还使用形状信息。您还可以使用轮廓来计数和分析生产线上的物体形状，在那里背景和视觉环境更加可控。
- en: The final section of this chapter will teach you how to use feature detection,
    descriptor extraction, and descriptor-matching algorithms to detect known objects,
    but with rotation, scale, and even perspective invariance.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最后部分将教授您如何使用特征检测、描述符提取和描述符匹配算法来检测已知对象，但具有旋转、缩放甚至透视不变性。
- en: Detecting, descripting, and matching features
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测、描述和匹配特征
- en: As we learned earlier in this chapter, features or keypoints can be extracted
    from images using various feature-extraction (detection) algorithms, most of which
    rely on detecting points with a significant change in intensity, such as corners.
    Detecting the right keypoints is the same as being able to correctly determine
    which parts of an image are helpful in identifying it. But just a keypoint, or
    in other words the location of a significant point in an image, by itself is not
    useful. One might argue that the collection of keypoint locations in an image
    is enough, but even then, another object with a totally different look can have
    keypoints in the exact same locations in an image, say, by chance.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章前面学到的，可以使用各种特征提取（检测）算法从图像中提取特征或关键点，其中大多数依赖于检测强度发生显著变化的点，例如角点。检测正确的关键点等同于能够正确确定哪些图像部分有助于识别它。但仅仅一个关键点，或者说图像中一个显著点的位置，本身并没有什么用处。有人可能会争辩说，图像中关键点位置的集合就足够了，但即便如此，另一个外观完全不同的物体也可能在图像中具有相同位置的关键点，比如说，偶然之间。
- en: This is where feature descriptors, or simply descriptors, come into play. A
    descriptor, as you can guess from the name, is an algorithm-dependent method of
    describing a feature, for instance, by using its neighboring pixel values, gradients,
    and so on. There are many different descriptor-extraction algorithms, each one
    with its own advantages and disadvantages, and going through all of them would
    not be a fruitful endeavor, especially for a hands-on book, but it's worth noting
    that most of them simply take a list of keypoints and produce a vector of descriptors.
    After a set of descriptors are extracted from sets of keypoints, we can use descriptor-matching
    algorithms to find the matching features from two different images, for instance,
    an image of an object and a scene where that object exists.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是特征描述符，或者简单地称为描述符，发挥作用的地方。从名称中你可以猜到，描述符是一种算法依赖的方法，用于描述一个特征，例如，通过使用其相邻像素值、梯度等。有许多不同的描述符提取算法，每个都有自己的优缺点，逐一研究它们并不会带来太多成果，尤其是对于一本实践性书籍来说，但值得注意的是，大多数算法只是从一组关键点中生成一个描述符向量。从一组关键点中提取了一组描述符后，我们可以使用描述符匹配算法来从两张不同的图像中找到匹配的特征，例如，一个物体的图像和该物体存在的场景图像。
- en: 'OpenCV contains a large number of feature detectors, descriptor extractors,
    and descriptor matchers. All feature-detector and descriptor-extractor algorithms
    in OpenCV are subclasses of the `Feature2D` class, and they are located in either
    the `features2d` module, which is included by default in OpenCV packages, or the `xfeatures2d`
    (extra module) module. You should use these algorithms with care and always refer
    to the OpenCV documentation, since some of them are actually patented and require
    permission from their owners to be used in commercial projects. The following
    is a list of some of the main feature-detector and descriptor-extractor algorithms
    that are included in OpenCV by default:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '**BRISK** (**Binary Robust Invariant Scalable Keypoints**)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**KAZE**'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AKAZE** (**Accelerated KAZE**)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ORB**, or Oriented **BRIEF** (**Binary Robust Independent Elementary Features**)'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these algorithms are implemented in classes of exactly the same title
    in OpenCV, and to repeat once more, they are all subclasses of the `Feature2D`
    class. They are extremely simple to use, especially when no parameters are modified.
    In all of them, you can simply use the static `create` method to create an instance
    of them, call the `detect` method to detect the keypoints, and finally call `computer`
    to extract descriptors of the detected keypoints.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'As for descriptor-matcher algorithms, OpenCV contains the following matching
    algorithms by default:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '`FLANNBASED`'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BRUTEFORCE`'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BRUTEFORCE_L1`'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BRUTEFORCE_HAMMING`'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BRUTEFORCE_HAMMINGLUT`'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BRUTEFORCE_SL2`'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use the `DescriptorMatcher` class, or its subclasses, namely `BFMatcher`
    and `FlannBasedMatcher`, to perform various matching algorithms. You simply need
    to use the static `create` method of these classes to create an instance of them,
    and then use the `match` method to match two sets of descriptors.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s walk through all of what we''ve discussed in this section with a complete
    example, since breaking apart the feature detection, descriptor extraction, and
    matching is impossible, and they are all parts of a chain of processes that lead
    to the detection of an object in a scene using its features:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'Read the image of the object, and the scene that will be searched for the object,
    using the following code:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In the following picture, let''s assume the image on the left is the object
    we are looking for, and the image on the right is the scene that contains the
    object:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00095.jpeg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
- en: 'Extract the keypoints from both of these images, which are now stored in `object`
    and `scene`. We can use any of the aforementioned algorithms for feature detection,
    but let''s assume we''re using KAZE for our example, as seen here:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We have the keypoints of both the object image and the scene image. We can
    go ahead and view them using the `drawKeypoints` function, as we learned previously
    in this chapter. Try that on your own, and then use the same `KAZE` class to extract
    descriptors from the keypoints. Here''s how it''s done:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '`objDesc` and `scnDesc` correspond to the descriptors of the keypoints extracted
    from the object and scene images. As mentioned previously, descriptors are algorithm-dependent,
    and interpreting the exact values in them requires in-detail knowledge about the
    specific algorithm that was used to extract them. Make sure to refer to the OpenCV
    documentation to gain more knowledge about them, however, in this step, we''re
    going to simply use a brute-force matcher algorithm to match the descriptors extracted
    from both images. Here''s how:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`objDesc`和`scnDesc`对应于从物体和场景图像中提取的关键点的描述符。如前所述，描述符是算法相关的，要解释它们中的确切值需要深入了解用于提取它们的特定算法。确保参考OpenCV文档以获取更多关于它们的知识，然而，在本步骤中，我们将简单地使用穷举匹配器算法来匹配从两张图像中提取的描述符。以下是操作方法：'
- en: '[PRE38]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The `BFMatcher` class, which is a subclass of the `DescriptorMatcher` class,
    implements the brute-force matching algorithm. The result of descriptor matching
    is stored in a `vector` of `DMatch` objects. Each `DMatch` object contains all
    the necessary information for matched features, from the object descriptors to
    the scene descriptors.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`BFMatcher`类是`DescriptorMatcher`类的子类，实现了穷举匹配算法。描述符匹配的结果存储在一个`DMatch`对象`vector`中。每个`DMatch`对象包含匹配特征所需的所有必要信息，从物体描述符到场景描述符。'
- en: 'You can now try to visualize the result of matching by using the `drawMatches`
    function, as seen here:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您现在可以尝试使用`drawMatches`函数可视化匹配结果，如下所示：
- en: '[PRE39]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'As you can see, some of the matched features are obviously incorrect, some
    at the top of the scene image and a few at the bottom:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，一些匹配的特征显然是不正确的，一些位于场景图像的顶部，还有一些位于底部：
- en: '![](img/00096.jpeg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00096.jpeg)'
- en: 'The bad matches can be filtered out by using a threshold on the `distance`
    value of the `DMatch` objects. The threshold value depends on the algorithm and
    the type of image content, but in our example case, and with the KAZE algorithm,
    a value of `0.1` seems to be enough for us. Here''s how the thresholding is done
    to get good matches out of all the matches:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以通过在`DMatch`对象的`distance`值上设置阈值来过滤掉不良匹配。阈值取决于算法和图像内容类型，但在我们的示例案例中，使用KAZE算法，`0.1`的值似乎对我们来说足够了。以下是过滤阈值以从所有匹配中获取良好匹配的方法：
- en: '[PRE40]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The following image depicts the result of the `drawMatches` function on the `goodMatches`
    vector:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了在`goodMatches`向量上`drawMatches`函数的结果：
- en: '![](img/00097.jpeg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00097.jpeg)'
- en: 'Obviously, the result of the filtered matches is much better now. We can use
    the `findHomography` function to find the transformation between good matched
    keypoints from the object image to the scene image. Here''s how:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显然，经过过滤的匹配结果现在要好得多。我们可以使用`findHomography`函数来找到物体图像到场景图像之间良好的匹配关键点的变换。以下是操作方法：
- en: '[PRE41]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'As we''ve already seen in the preceding chapters, the result of the `findHomography`
    function can be used to transform a set of points. We can abuse this fact to create
    four points using the four corners of the object image, and then transform those
    points using the `perspectiveTransform` function to get the location of those
    points in the scene image. Here is an example:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中已经看到的，`findHomography`函数的结果可以用来变换一组点。我们可以利用这个事实，使用物体图像的四个角来创建四个点，然后使用`perspectiveTransform`函数变换这些点，以获取场景图像中这些点的位置。以下是一个示例：
- en: '[PRE42]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The transformed points can be used to draw four lines that localize the detected
    object in the scene image, as seen here:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 变换后的点可以用来绘制四条线，以定位场景图像中检测到的物体，如下所示：
- en: '[PRE43]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'It''s important to also change the *x* values of the resultant points to account
    for the width of the object image, if you are going to draw the four lines that
    localize the object, over the `drawMatches` image result. Here''s an example:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您打算在`drawMatches`图像结果上绘制定位物体的四条线，那么也很重要的是要更改结果点的*x*值，以考虑物体图像的宽度。以下是一个示例：
- en: '[PRE44]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The following image depicts the final result of our detection operation:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了我们检测操作的最终结果：
- en: '![](img/00098.jpeg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00098.jpeg)'
- en: 'Make sure to try the rest of the feature-detection, descriptor-extraction,
    and matching algorithms by yourself and compare their results. Also, try to measure
    the time of the calculations for each one. For instance, you might notice that
    AKAZE is much faster than KAZE, or that BRISK is better suited to some images,
    while KAZE or ORB is better with others. As mentioned before, the feature-based
    methods of object detection are much more reliable with scale, rotation, and even
    perspective change. Try different views of the same objects to figure out the
    best parameters and algorithms for your own project and use case. For instance,
    here''s another example that demonstrates the rotation and scale invariance of
    the AKAZE algorithm and brute-force matching:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 确保亲自尝试其余的特征检测、描述符提取和匹配算法，并比较它们的结果。同时，尝试测量每个算法的计算时间。例如，你可能注意到AKAZE比KAZE快得多，或者BRISK更适合某些图像，而KAZE或ORB则更适合其他图像。如前所述，基于特征的目标检测方法在尺度、旋转甚至透视变化方面更加可靠。尝试不同视角的同一物体，以确定你自己的项目和用例的最佳参数和算法。例如，这里有一个演示AKAZE算法的旋转和尺度不变性的另一个示例，以及暴力匹配：
- en: '![](img/00099.jpeg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/00099.jpeg)'
- en: Note that the source code used for producing the preceding output is created
    by using exactly the same set of instructions we went through in this section.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，生成前面输出的源代码是使用本节中我们讨论的完全相同的指令集创建的。
- en: Summary
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: We started this chapter by learning about a template-matching algorithm and
    an object detection algorithm that, despite its popularity, lacks some of the
    most essential aspects of a proper object detection algorithm, such as scale and
    rotation invariance; moreover, it's a pure pixel-based object detection algorithm.
    Building upon that, we learned how to use global maximum- and minimum-detection
    algorithms to interpret the template-matching algorithm result. Then, we learned
    about corner- and edge-detection algorithms, or in other words, algorithms that
    detect points and areas of significance in images. We learned how to visualize
    them, and then moved on to learn about contour-detection and shape-analysis algorithms.
    The final section of this chapter included a complete tutorial on how to detect
    keypoints in an image, extract descriptors from those keypoints, and use matcher
    algorithms to detect an object in a scene. We're now familiar with a huge set
    of algorithms that can be used to analyze images based not only on their pixel
    colors and intensity values, but also their content and existing keypoints.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从学习模板匹配算法和目标检测算法开始这一章，尽管它很受欢迎，但它缺乏一些适当目标检测算法的最基本方面，如尺度和旋转不变性；此外，它是一个纯像素级目标检测算法。在此基础上，我们学习了如何使用全局最大值和最小值检测算法来解释模板匹配算法的结果。然后，我们学习了关于角点和边缘检测算法，或者换句话说，检测图像中点和重要区域的算法。我们学习了如何可视化它们，然后转向学习轮廓检测和形状分析算法。本章的最后部分包括了一个完整的教程，介绍如何在图像中检测关键点，从这些关键点中提取描述符，并使用匹配器算法在场景中检测目标。我们现在熟悉了一整套算法，可以用来分析图像，不仅基于它们的像素颜色和强度值，还基于它们的内容和现有的关键点。
- en: The final chapter of this book will take us through computer vision and machine
    learning algorithms in OpenCV and how they are employed to detect objects using
    a previously existing set of their images, among many other interesting artificial-intelligence-related
    topics.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 本书最后一章将带我们了解OpenCV中的计算机视觉和机器学习算法，以及它们如何被用于检测使用先前存在的一组图像来检测对象，以及其他许多有趣的人工智能相关主题。
- en: Questions
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: The template-matching algorithm is not scale- and rotation-invariant by itself.
    How can we make it so for a) double the scale of the template image, and b) a
    90-degrees-rotated version of the template image?
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模板匹配算法本身不具有尺度和旋转不变性。我们如何使其对于以下情况成立？a) 模板图像的尺度加倍，b) 模板图像旋转90度？
- en: Use the `GFTTDetector` class to detect keypoints with the Harris corner-detection
    algorithm. You can set any values for the corner-detection algorithm.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`GFTTDetector`类通过Harris角点检测算法检测关键点。你可以为角点检测算法设置任何值。
- en: The Hough transformation can also be used to detect circles in an image, using
    the `HoughCircles` function. Search for it in the OpenCV documentation and write
    a program to detect circles in an image.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hough变换也可以用于检测图像中的圆，使用`HoughCircles`函数。在OpenCV文档中搜索它，并编写一个程序来检测图像中的圆。
- en: Detect and draw the convex contours in an image.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在图像中检测并绘制凸轮廓。
- en: Use the `ORB` class to detect keypoints in two images, extract their descriptors,
    and match them.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ORB`类在两张图像中检测关键点，提取它们的描述符，并将它们进行匹配。
- en: Which feature-descriptor-matching algorithm is incompatible with the ORB algorithm,
    and why?
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种特征描述符匹配算法与ORB算法不兼容，以及原因是什么？
- en: 'You can use the following OpenCV functions and the given sample to calculate
    the time required to run any number of lines of code. Use it to calculate the
    time it takes for the matching algorithms on your computer:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用以下OpenCV函数和提供的示例来计算执行任意多行代码所需的时间。用它来计算您计算机上匹配算法所需的时间：
- en: '[PRE45]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
