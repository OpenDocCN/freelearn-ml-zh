- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: AI Risk Management
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI风险管理
- en: As organizations increasingly rely on AI for critical decision-making and incorporate
    it into different areas of their businesses, effective AI risk management should
    be a top priority. Ensuring the safe and compliant deployment of ML systems is
    essential to establish trustworthiness in AI solutions. However, many organizations
    and individuals have very limited understanding of the risks associated with AI
    systems, often resulting in outcomes that may negatively impact organizations
    financially or legally. In this chapter, we will explore key AI risk scenarios,
    highlight the differences between AI risk management and traditional software
    risk management, and emphasize the importance of having a robust AI risk management
    practice. We will present a risk management framework that organizations can consider
    for managing AI risks. Finally, we will discuss how to manage risks at different
    stages of the ML lifecycle and design ML platforms that support risk management
    and AI governance.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随着组织越来越依赖AI进行关键决策并将AI纳入其业务的各个领域，有效的AI风险管理应成为首要任务。确保ML系统的安全合规部署对于建立AI解决方案的可信度至关重要。然而，许多组织和个人对AI系统相关的风险了解非常有限，这往往会导致可能对组织造成财务或法律上负面影响的后果。在本章中，我们将探讨关键的AI风险场景，突出AI风险管理与传统软件风险管理的差异，并强调拥有稳健的AI风险管理实践的重要性。我们将提出一个组织可以考虑用于管理AI风险的风险管理框架。最后，我们将讨论如何在ML生命周期的不同阶段管理风险，并设计支持风险管理和AI治理的ML平台。
- en: 'Specifically, we will cover the following key topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将涵盖以下关键主题：
- en: Understanding AI risk scenarios
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解AI风险场景
- en: The regulatory landscape around AI risk management
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI风险管理监管环境
- en: Understanding AI risk management
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解AI风险管理
- en: Applying risk management across the AI lifecycle
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在AI生命周期中应用风险管理
- en: Designing ML platforms with governance and risk management considerations
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑治理和风险管理的ML平台设计
- en: Understanding AI risk scenarios
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解AI风险场景
- en: Many of the organizations I have worked with have very limited knowledge about
    the risks presented in their AI systems. They often treat AI risks the same way
    they deal with risks associated with traditional software. In reality, AI systems
    present a new set of risks that we do not normally see in traditional software.
    With traditional software, the risk is mainly about software vulnerability, a
    legacy technology stack, malware, misconfiguration, and unauthorized access to
    data. AI systems are exposed to many of the same software risks; additionally,
    AI systems can present new kinds of risks such as bias and misinformation. These
    risks can have significant negative consequences for organizations and individuals
    that rely on AI systems for business operations and decision-making. AI risks
    can manifest in many different ways, such as displaying biased behavior or producing
    unexpected prediction results. Many of the AI risk scenarios are also silent risks
    that are difficult to detect.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我合作过的许多组织对它们AI系统中呈现的风险了解非常有限。他们通常将AI风险处理方式与传统软件相关的风险处理方式相同。实际上，AI系统呈现的是一套我们在传统软件中通常看不到的新风险。在传统软件中，风险主要关于软件漏洞、遗留技术栈、恶意软件、配置错误以及数据未授权访问。AI系统面临着许多相同的软件风险；此外，AI系统还可以呈现新的风险类型，如偏见和错误信息。这些风险可能对依赖AI系统进行业务运营和决策的组织和个人产生重大的负面影响。AI风险可以以许多不同的方式表现出来，例如表现出偏见行为或产生意外的预测结果。许多AI风险场景也是难以检测的沉默风险。
- en: 'The following are some scenarios where AI risks may arise:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些AI风险可能出现的场景：
- en: '**Bias and discrimination**: One of the most well-known risks associated with
    AI is the potential for displaying bias and discrimination in AI systems. This
    can occur when ML algorithms are trained on biased data or when the algorithms
    themselves are susceptible to biased behaviors. In these cases, the algorithms
    may learn to discriminate against certain groups, leading to unfair or discriminatory
    outcomes. For example, a bank can have an ML model that’s trained using biased
    datasets, such as including gender and ethnic groups as inputs, resulting in discrimination
    against certain gender or ethnic groups and potential violation of laws and regulations,
    such as the Equal Credit Opportunity Act. Nowadays, many organizations use AI
    to screen resumes, and it has been found that some of these AI systems have displayed
    preferences and biases toward certain types of candidates. In 2018, researchers
    from MIT revealed that facial recognition systems from several major technology
    companies exhibited significant racial bias, misidentifying darker-skinned individuals
    at higher rates compared to lighter-skinned individuals. This incident raised
    concerns about the potential for AI systems to perpetuate and amplify societal
    biases, leading to discriminatory outcomes.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏见和歧视**：与人工智能相关联的最知名的风险之一是人工智能系统中可能表现出偏见和歧视。这可能会发生在机器学习算法在具有偏见的数据上训练或当算法本身容易受到偏见行为的影响时。在这些情况下，算法可能会学会歧视某些群体，导致不公平或歧视性的结果。例如，一家银行可能有一个使用具有偏见的数据集（如包括性别和种族群体作为输入）训练的机器学习模型，这可能导致对某些性别或种族群体的歧视，并可能违反诸如平等信贷机会法等法律法规。如今，许多组织使用人工智能筛选简历，发现其中一些人工智能系统对某些类型的候选人表现出偏好和偏见。2018年，麻省理工学院的研究人员揭示了多家主要科技公司的人脸识别系统表现出显著的种族偏见，对深色皮肤个体的误识别率高于浅色皮肤个体。这一事件引发了关于人工智能系统可能持续和放大社会偏见、导致歧视性结果的担忧。'
- en: '**Misinformation and misinterpretation**: Another risk associated with AI is
    the potential for generating misinformation and misinterpretation of facts. This
    can occur when ML algorithms are used to process large amounts of data, but the
    data contains errors or inconsistencies that are not easily detected. As a result,
    the algorithms may generate inaccurate or misleading results, leading to potential
    wrong decision-making. With the fast rise of generative AI technologies, such
    as ChatGPT and Stable Diffusion models, it is also becoming more difficult for
    humans to distinguish reality from hallucination.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**虚假信息和误解释**：与人工智能相关联的另一项风险是生成虚假信息和事实误解释的可能性。这可能会发生在机器学习算法用于处理大量数据时，但数据中包含的错误或不一致性不易被发现。结果，算法可能会生成不准确或误导性的结果，导致可能的错误决策。随着生成式人工智能技术，如ChatGPT和Stable
    Diffusion模型的快速崛起，人类区分现实与幻觉也变得越来越困难。'
- en: For example, the rapid advancement of deepfake technologies, which use AI to
    generate highly realistic synthetic audio, video, and images, has raised concerns
    about their potential misuse for spreading misinformation, impersonation, and
    manipulation. Incidents of deepfake videos being used to impersonate public figures
    and spread false narratives have already been reported.
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，深度伪造技术的快速进步，这些技术利用人工智能生成高度逼真的合成音频、视频和图像，引发了对其潜在误用的担忧，包括传播虚假信息、冒充和操纵。已经报道了使用深度伪造视频冒充公众人物和传播虚假叙述的事件。
- en: '**Lack of interpretability**: Many ML algorithms, such as neural networks,
    can be complex and difficult to understand, even for trained experts. This lack
    of transparency can make it difficult to identify the causes of problems when
    they arise, making it harder to develop effective mitigation to address the problem.
    For example, when ChatGPT provides incorrect responses to user prompts, it is
    often impossible to understand why it made the mistake. For regulated industries,
    this presents a significant challenge when organizations want to adopt more advanced
    black-box algorithms such as neural networks, as these organizations often need
    to provide deterministic responses to specific inputs and questions, and how the
    decisions are made.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性不足**：许多机器学习算法，如神经网络，可能非常复杂且难以理解，即使是训练有素的专家也如此。这种缺乏透明度使得在问题出现时难以识别问题的原因，从而使得开发有效的缓解措施来解决问题变得更加困难。例如，当ChatGPT对用户提示提供错误响应时，通常无法理解它为什么会犯这样的错误。对于受监管的行业来说，当组织希望采用更先进的黑盒算法，如神经网络时，这构成了一个重大挑战，因为这些组织通常需要为特定的输入和问题提供确定的响应，以及决策是如何做出的。'
- en: '**Unintended consequences**: ML algorithms can sometimes produce unintended
    consequences or side effects that were not foreseen during the development process.
    The reason for this is that AI models are often optimized for a specific objective,
    such as increasing company profit, while ignoring other factors such as gender
    and race. For example, an AI-based target marketing system might target a subset
    of customers with incentives and benefits, while discriminating against minority
    or low-income customers, in its pursuit of profit maximization.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**意外后果**：机器学习算法有时会产生在开发过程中未预见到的意外后果或副作用。这是因为AI模型通常是为了优化特定目标而优化的，例如增加公司利润，而忽略了其他因素，如性别和种族。例如，一个基于AI的目标营销系统可能会通过激励和优惠来针对一部分客户，而在追求利润最大化的过程中歧视少数族裔或低收入客户。'
- en: '**Adversarial attacks**: ML algorithms can be vulnerable to adversarial attacks,
    which involve deliberately manipulating the input data to produce unexpected or
    undesirable outcomes, or planting backdoor access to ML models. For example, an
    attacker could use an adversarial attack to trick an AI-based fraud detection
    system into classifying fake financial transactions as legitimate transactions.
    ML models can also be compromised to reveal training data by using adversarial
    techniques such as membership inference attacks. There have been real-world examples
    of adversarial attacks. In 2017, researchers from the University of Michigan demonstrated
    a method to generate small, innocuous-looking patches that could be placed on
    physical objects, such as stop signs or pedestrians, to cause state-of-the-art
    object detection models to misclassify or fail to detect those objects. In another
    example, a chatbot implemented by a car dealership faced disruptions when mischievous
    users exploited a loophole, which, at times, prompted the bot to unintentionally
    propose extraordinary deals like acquiring brand-new cars for minimal costs.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对抗攻击**：机器学习算法可能容易受到对抗攻击，这涉及故意操纵输入数据以产生意外或不希望的结果，或者为机器学习模型植入后门访问。例如，攻击者可能使用对抗攻击欺骗基于AI的欺诈检测系统，将其分类为合法交易。ML模型也可能被破坏，通过使用如成员推断攻击等对抗技术来揭示训练数据。已经有一些对抗攻击的实例。在2017年，密歇根大学的研究人员展示了一种方法，可以生成小而看似无害的补丁，这些补丁可以放置在物理对象上，如停车标志或行人，导致最先进的对象检测模型误分类或无法检测这些对象。在另一个例子中，一家汽车经销商实施的聊天机器人因恶意用户利用漏洞而面临中断，有时这会导致机器人无意中提出非常规交易，如以最低成本购买全新的汽车。'
- en: '**Privacy violation and sensitive data exposure**: Nowadays, many of the state-of-the-art
    models are trained using enormous amounts of data from many different sources,
    and, sometimes, personal or sensitive information is used in the development of
    these models. This inherently increases the risk of potential privacy violations
    and unintended disclosure of sensitive data. For example, to train a medical imaging
    model for cancer detection, you often need real patient data such as CT scans
    and other **protected health information** (**PHI**) or **personal identifiable
    information** (**PII**). If not handled correctly, this information can be exposed
    to people who are not authorized to access it. Also, as part of the model training,
    some sensitive data can be memorized by the trained model, and the model can potentially
    disclose this information when making predictions. In 2020, an investigative report
    by the New York Times revealed that people’s images were used in AI model training
    without their consent and knowledge.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐私侵犯和敏感数据泄露**：如今，许多最先进的模型都是使用来自许多不同来源的大量数据进行训练的，有时，个人或敏感信息会被用于这些模型的开发中。这本质上增加了潜在隐私侵犯和敏感数据意外泄露的风险。例如，为了训练用于癌症检测的医疗影像模型，你通常需要真实的患者数据，如CT扫描和其他**受保护的个人信息**（**PHI**）或**个人可识别信息**（**PII**）。如果处理不当，这些信息可能会被未经授权访问的人接触到。此外，作为模型训练的一部分，一些敏感数据可能会被训练模型记住，并且模型在做出预测时可能会泄露这些信息。2020年，纽约时报的一项调查报告揭示了人们在没有同意和知情的情况下，他们的图像被用于AI模型训练。'
- en: '**Third-party risks**: While third-party risks also exist with traditional
    software from third-party vendors, AI systems elevate these risks in areas that
    we have not seen before. With the advent of ML techniques such as transfer learning
    and fine-tuning from pre-trained models, more and more organizations are building
    custom models based on existing pre-trained models. However, given the black-box
    nature of these pre-trained models, it increases the uncertainty of the models’
    behavior and unknowns around the scientific validity of the models. Since the
    pre-trained models were outside of the security and process controls of the consuming
    organizations, the consuming organization may inherit risks that may already exist
    in the pre-trained models such as bias or backdoor attack vulnerabilities. For
    example, models with vulnerabilities such as arbitrary code execution and file
    writes have been detected in model hubs such as Hugging Face.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第三方风险**：虽然第三方风险也存在于第三方供应商的传统软件中，但AI系统在之前未见过的领域提高了这些风险。随着迁移学习、从预训练模型进行微调等ML技术的出现，越来越多的组织正在基于现有的预训练模型构建定制模型。然而，鉴于这些预训练模型的黑盒性质，它增加了模型行为的不确定性和关于模型科学有效性的未知因素。由于预训练模型超出了消费组织的安保和流程控制范围，消费组织可能会继承预训练模型中可能存在的风险，如偏差或后门攻击漏洞。例如，在Hugging
    Face等模型中心检测到具有诸如任意代码执行和文件写入等漏洞的模型。'
- en: '**Model testing risks**: Compared to traditional software, the testing standards
    and tools for AI-based software and models are underdeveloped. Traditional software
    testing mainly focuses on functional components such as user interface flow or
    business logic that’s well defined, and non-functional areas such as scalability
    and latency. With AI/ML testing, in addition to many of the traditional software
    testing requirements, there are new testing concepts such as error analysis of
    different failure modes, model sensitivity, model robustness, and adversarial
    testing, which are more difficult to perform than traditional software testing.
    The available testing tools in this domain are also very limited; often, data
    scientists and testers need to manually prepare different testing scenarios and
    testing data.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型测试风险**：与传统的软件相比，基于AI/ML的软件和模型的测试标准和工具尚未充分发展。传统的软件测试主要关注定义良好的功能组件，如用户界面流程或业务逻辑，以及非功能性领域，如可扩展性和延迟。在AI/ML测试中，除了许多传统的软件测试要求外，还有新的测试概念，如不同故障模式的错误分析、模型敏感性、模型鲁棒性和对抗性测试，这些测试比传统的软件测试更难执行。该领域可用的测试工具也非常有限；通常，数据科学家和测试人员需要手动准备不同的测试场景和测试数据。'
- en: As you can see, the capabilities of AI systems extend far beyond traditional
    software, introducing many new potential risks and challenges. As these advanced
    technologies gain wide adoption and integration into critical domains, concerns
    over their responsible development and deployment have come to the forefront.
    Recognizing the unique complexities and far-reaching implications of AI, various
    regulatory bodies have taken proactive steps to establish guidelines and regulations
    aimed at mitigating these risks and ensuring the ethical and trustworthy use of
    AI systems.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，人工智能系统的能力远远超出了传统软件，引入了许多新的潜在风险和挑战。随着这些先进技术被广泛采用并整合到关键领域，对其负责任的发展和部署的关注已上升至首位。鉴于人工智能的独特复杂性和深远影响，各个监管机构已采取积极措施，制定旨在减轻这些风险的指南和法规，以确保人工智能系统的道德和可信使用。
- en: The regulatory landscape around AI risk management
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能风险管理监管环境
- en: With the fast advancement of AI technologies and adoption in critical business
    decision-making, and the negative impacts that AI systems can potentially have
    on individuals, organizations, and societies, many countries and jurisdictions
    have established policies, guidance, and regulations to help manage the risks
    of AI adoption. It is also expected that more and more legislation will be proposed
    and passed by different countries and jurisdictions at a fast rate.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能技术在关键业务决策中的应用和快速进步，以及人工智能系统可能对个人、组织和社会产生的负面影响，许多国家和司法管辖区已制定政策、指南和法规，以帮助管理人工智能采用的风险。预计不同国家和司法管辖区将以较快的速度提出和通过更多立法。
- en: In the **United States** (**US**), the Federal Reserve and the **Office of the
    Comptroller of the Currency** (**OCC**) published the Supervisory Guidance on
    Model Risk Management (OCC 2011-2012/SR 11-7) as early as 2011\. SR 11-7 has become
    the key regulatory guidance for model risk management in the US. This guidance
    establishes the main principles for model risk management covering governance,
    policies and controls, model development, implementation and use, and model validation
    processes. In the governance and policy area, it provides guidance on model inventory
    management, risk rating, roles, and responsibilities. In the model development
    and implementation area, it covers topics such as the design process, data assessment,
    model testing, and documentation. In the validation area, it provides guidance
    on validation procedures, monitoring, and finding resolutions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在**美国**（**US**），联邦储备银行和**货币监理署**（**OCC**）早在2011年就发布了关于模型风险管理的监管指南（OCC 2011-2012/SR
    11-7）。SR 11-7已成为美国模型风险管理的关键监管指南。该指南确立了模型风险管理的核心原则，涵盖了治理、政策和控制、模型开发、实施和使用，以及模型验证流程。在治理和政策领域，它提供了关于模型清单管理、风险评级、角色和职责的指导。在模型开发和实施领域，它涵盖了设计过程、数据评估、模型测试和文档等主题。在验证领域，它提供了关于验证程序、监控和解决问题的指导。
- en: In Europe, the **European Central Bank** (**ECB**) Banking Supervision launched
    the **Targeted Review of Internal Models** (**TRIM**) guideline in 2016 to provide
    guidance on the **model risk management** (**MRM**) framework. Specifically, the
    guideline states that an MRM framework needs to have a model inventory to allow
    a holistic view of the models and their applications, a guideline for identifying
    and mitigating known model deficiencies, definitions of roles and responsibilities,
    and definitions of policies, measurement procedures, and reporting.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在欧洲，**欧洲中央银行**（**ECB**）银行监管在2016年发布了**内部模型针对性审查**（**TRIM**）指南，以提供关于**模型风险管理**（**MRM**）框架的指导。具体来说，该指南指出，一个MRM框架需要有一个模型清单，以便全面了解模型及其应用，一个用于识别和缓解已知模型缺陷的指南，以及角色和职责的定义，以及政策和测量程序的定义。
- en: More recently, in 2021, the **European Union** (**EU**) introduced the EU AI
    Act to promote the benefits of AI, while also ensuring the safe and responsible
    use of AI in the EU. The Act takes a risk-based approach to regulating AI, with
    different requirements based on the level of risks associated with AI systems.
    For example, AI systems supporting critical infrastructure would be rated with
    the highest risk designation and require the strictest oversight and regulations.
    The regulation also proposes provisions for AI transparency and accountability
    in the AI decision-making process, such as requirements for explainability and
    the ability to challenge the decisions made by AI systems. It also has new rules
    for AI use in biometric identification and surveillance.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，在2021年，**欧盟**（**EU**）推出了欧盟人工智能法案，旨在推广人工智能的好处，同时确保欧盟人工智能的安全和负责任使用。该法案采用基于风险的方法来监管人工智能，根据与人工智能系统相关的风险水平提出不同的要求。例如，支持关键基础设施的人工智能系统将被评为最高风险等级，并需要最严格的监督和法规。该法规还提出了人工智能透明度和问责制的规定，例如对可解释性和挑战人工智能系统做出的决策的能力的要求。它还对生物识别识别和监控中的人工智能使用制定了新的规则。
- en: Understanding AI risk management
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解人工智能风险管理
- en: To address the various risks associated with AI and to comply with different
    compliance regulations, many organizations, especially in the regulated industry,
    have developed and implemented AI risk management programs. In short, AI risk
    management is the process of identifying, assessing, and mitigating the risk associated
    with the use of AI in automated decision-making. The ultimate goal of AI risk
    management is to establish trust in the AI/ML systems and ensure compliance with
    applicable rules and regulations.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对与人工智能相关的各种风险并遵守不同的合规法规，许多组织，尤其是在受监管的行业中，已经开发和实施了人工智能风险管理计划。简而言之，人工智能风险管理是识别、评估和缓解与人工智能在自动化决策中使用相关的风险的过程。人工智能风险管理的最终目标是建立对人工智能/机器学习系统的信任，并确保符合适用的规则和法规。
- en: Trusting an AI system requires rigorous assessment and consideration of the
    AI system across many different dimensions and criteria. Functionally, a trusted
    AI system needs to provide valid predictions/responses reliably for its intended
    use. This means that generated predictions/responses are consistently valid and
    can be trusted for reliable decision-making. Ethically, a trusted AI system needs
    to be safe to use, explainable, privacy-protected, and fair with bias properly
    managed and mitigated. From a cybersecurity perspective, a trusted AI system also
    needs to be secure and resilient against adversarial attacks. Lastly, a trustworthy
    AI system needs to provide transparency such as what and how data, algorithms,
    and models are used in the system. It is worth noting that it is often a balancing
    act and trade-off across these different dimensions when building and operating
    a trustworthy system, based on the needs and objectives of an organization. For
    example, to protect privacy, an organization might need to make sacrifices in
    model accuracy or prediction speed.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 信任一个人工智能系统需要对人工智能系统进行严格的评估和考虑，涉及许多不同的维度和标准。从功能上讲，一个值得信赖的人工智能系统需要可靠地提供有效的预测/响应，以满足其预期用途。这意味着生成的预测/响应始终有效，可以信赖用于可靠的决策。从伦理上讲，一个值得信赖的人工智能系统需要安全使用、可解释、隐私保护，并且公平，对偏见进行适当的管理和缓解。从网络安全的角度来看，一个值得信赖的人工智能系统还需要安全且能够抵御对抗性攻击。最后，一个值得信赖的人工智能系统需要提供透明度，例如系统如何以及使用哪些数据、算法和模型。值得注意的是，在构建和运营一个值得信赖的系统时，通常需要在这些不同维度之间进行权衡和取舍，这取决于组织的需要和目标。例如，为了保护隐私，一个组织可能需要在模型精度或预测速度上做出牺牲。
- en: Now we understand what it takes to have trust in AI systems, let’s explore and
    dive deep into the AI risk management framework and its various components. The
    following figure illustrates the key components of AI risk management, which mainly
    consists of applying MRM, enterprise risk management, and third-party risk management
    across the AI lifecycle, governed by a set of AI risk governance principles. In
    this chapter, our exclusive focus will be on MRM. Enterprise risk and third-party
    risk management extend beyond the realm of AI and are universal considerations.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了在人工智能系统中建立信任所需的因素，让我们来探索并深入了解人工智能风险管理框架及其各个组成部分。以下图示展示了人工智能风险管理的关键组成部分，它主要涉及在人工智能生命周期中应用风险管理、企业风险管理和第三方风险管理，并受一套人工智能风险管理原则的指导。在本章中，我们将专注于风险管理。企业风险和第三方风险管理超出了人工智能的范畴，是普遍的考虑因素。
- en: '![Diagram  Description automatically generated](img/B20836_12_01.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B20836_12_01.png)'
- en: 'Figure 12.1: AI risk management components'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1：人工智能风险管理组件
- en: Next, we will delve into the details of governance oversight principles and
    the AI risk framework. We will focus mainly on the understanding of AI risk governance
    and MRM, with the understanding that traditional enterprise security and third-party
    risk management are also part of the overall AI risk management considerations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入探讨治理监督原则和人工智能风险框架的细节。我们将主要关注对人工智能风险治理和风险管理（MRM）的理解，同时认识到传统企业安全和第三方风险管理也是整体人工智能风险管理考虑的一部分。
- en: Governance oversight principles
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 治理监督原则
- en: 'Implementing AI risk management starts with establishing key governance principles.
    The principles clarify the ultimate goals for what needs to be accomplished with
    risk management programs. Depending on the business and the regulatory environment
    an organization is in, an organization can make a decision on whether it should
    be included in its risk management framework. The following are some of the key
    areas for consideration:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 实施人工智能风险管理始于建立关键治理原则。这些原则明确了风险管理计划需要达成的最终目标。根据组织所在的业务和监管环境，组织可以决定是否将其纳入其风险管理框架。以下是一些需要考虑的关键领域：
- en: '**Transparency**: AI systems should be designed in a way that allows stakeholders
    to understand how decisions are made and why. This may include the ability to
    explain the ML model predictions, as well as transparency on what and how the
    data and algorithms are used and implemented.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**透明度**：人工智能系统应设计为允许利益相关者理解决策是如何做出的以及为什么这么做。这可能包括解释机器学习模型预测的能力，以及对数据和使用算法的透明度，包括如何使用和实施。'
- en: '**Accountability**: Organizations should be accountable for the decisions made
    by AI systems, including any negative consequences that may arise from their use.
    This accountability will ensure the owning organizations are incentivized to institute
    relevant policies and processes to govern the ML lifecycle.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问责制**：组织应对人工智能系统做出的决策负责，包括其使用可能产生的任何负面后果。这种问责制将确保拥有组织有动力制定相关政策和流程来治理机器学习生命周期。'
- en: '**Data governance**: Organizations should ensure that the data used to train
    AI systems is accurate, representative, ethical, and unbiased. Without proper
    data governance, it would be highly challenging to trust AI systems that are built
    with ungoverned data.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据治理**：组织应确保用于训练人工智能系统的数据是准确、代表性、道德和公正的。如果没有适当的数据治理，将很难信任使用未受管制的数据进行构建的人工智能系统。'
- en: '**Human oversight**: While AI systems are meant to make decisions automatically
    in most cases without human intervention, organizations should have the ability
    to implement human oversight where required, meaning that humans should be involved
    in decision-making where it makes sense and should have the ability to override
    decisions when necessary.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工监督**：尽管人工智能系统旨在在大多数情况下自动做出决策而无需人工干预，但组织应具备在需要时实施人工监督的能力，这意味着在合理的情况下，人类应参与决策，并在必要时有权推翻决策。'
- en: '**Privacy and security**: Appropriate policies and processes should be established
    to ensure AI systems are designed to protect the privacy and security of assets
    according to laws and regulations. Privacy and security breaches can have significant
    financial and non-financial implications for an organization.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐私和安全**：应建立适当的政策和流程，以确保人工智能系统根据法律和法规设计为保护资产隐私和安全。隐私和安全漏洞可能对组织产生重大的财务和非财务影响。'
- en: '**Fairness**: AI systems should not discriminate against certain individuals
    or groups based on attributes such as race and gender.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公平性**：人工智能系统不应基于种族和性别等属性歧视某些个人或群体。'
- en: '**Validity and reliability**: AI systems should be designed to produce reliable
    and valid results. Appropriate model validation and testing frameworks and processes
    need to be implemented to ensure highly reliable and predictable behaviors are
    displayed by AI systems in production. Mechanisms should be established to monitor
    system behaviors with processes for mitigation and rollback when abnormal behaviors
    are observed.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效性和可靠性**：人工智能系统应设计为产生可靠和有效的结果。需要实施适当的模型验证和测试框架及流程，以确保人工智能系统在生产中表现出高度可靠和可预测的行为。应建立机制来监控系统行为，并在观察到异常行为时实施缓解和回滚流程。'
- en: With governance oversight, organizations should also consider requirements for
    regulatory compliance, policies and guidelines around roles and responsibility,
    and standards and processes around AI systems and model inventory and risk classification,
    as well as how to deal with lifecycle and change management.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在治理监督下，组织还应考虑监管合规性要求、关于角色和责任的政策和指南，以及围绕人工智能系统和模型库存以及风险分类的标准和流程，以及如何处理生命周期和变更管理。
- en: AI risk management framework
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能风险管理框架
- en: With the AI governance oversight principles defined, organizations can move
    forward to establish a formalized AI risk management framework and detailed mechanisms
    for risk identification, risk assessment, and risk mitigation across the end-to-end
    ML lifecycle. One of the common frameworks adopted by many organizations is the
    Three Lines of Defense MRM model that is commonly used in the financial services
    industry. This framework focuses on establishing policies, roles, responsibilities,
    and processes designed to identify, assess, mitigate, and audit potential model
    risks associated with business problem identification, data management, and model
    development, deployment, and uses.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了人工智能治理监督原则后，组织可以向前推进，建立正式的人工智能风险管理框架，以及在整个机器学习生命周期中识别、评估和缓解风险的详细机制。许多组织采用的一个常见框架是金融服务业中常用的三道防线风险管理模型。该框架侧重于建立旨在识别、评估、缓解和审计与业务问题识别、数据管理、模型开发、部署和使用相关的潜在模型风险的策略、角色、责任和流程。
- en: The first line of defense is owned by business operations. This line of defense
    focuses on the development and use of ML models. Business operations are responsible
    for creating and retaining all data and model assumptions, model behavior, and
    model performance metrics in structured documents, based on model classification
    and risk exposure. Models are tested and registered, the associated artifacts
    are persisted, and results can be reproduced. Once models are deployed, system
    issues, model outputs, model bias, and data and model drifts are monitored and
    addressed according to the established procedures and guidelines.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 第一道防线由业务运营拥有。这一道防线专注于机器学习模型的发展和运用。业务运营负责在结构化的文档中创建和保留所有数据、模型假设、模型行为和模型性能指标，基于模型分类和风险暴露。模型经过测试和注册，相关的工件被保存，结果可以重现。一旦模型部署，将根据既定的程序和指南监控和解决系统问题、模型输出、模型偏差以及数据和模型漂移。
- en: The second line of defense is owned by the risk management function, and it
    focuses on model validation. The risk management function is responsible for independently
    reviewing and validating the documents generated by the first line. This line
    of defense introduces standards on controls and documentation, making sure that
    documents are self-contained, results are reproducible, and the limitations of
    models are well-understood by stakeholders.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第二道防线由风险管理职能拥有，它专注于模型验证。风险管理职能负责独立审查和验证第一道防线生成的文档。这一道防线引入了关于控制和文档的标准，确保文档是自包含的，结果可重现，并且利益相关者对模型的局限性有充分的理解。
- en: The internal audit owns the third line of defense. The third line of defense
    focuses more on control and processes and less on model artifacts and theories.
    Specifically, this line of defense is responsible for auditing the first and second
    lines of defense to ensure all established processes and guidelines are effectively
    followed and implemented. This line of defense provides independent validation
    of internal controls and reviews the documentation, timeliness, frequency, and
    completeness of the MRM activities.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 内部审计拥有第三道防线。第三道防线更多地关注控制和流程，而不是模型工件和理论。具体来说，这一道防线负责审计第一道和第二道防线，以确保所有既定流程和指南得到有效遵循和实施。这一道防线提供独立验证内部控制，并审查风险管理活动的及时性、频率和完整性。
- en: The MRM alone mainly addresses the risks associated with model development and
    the development lifecycle. However, a comprehensive AI risk management framework
    also needs to cover other risks such as system scalability and reliability, unauthorized
    access of systems, denial of access, and third-party failure risks. MRM should
    also be combined with enterprise technology risk, cybersecurity management, and
    third-party risks to ensure comprehensive coverage of AI risks.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: MRM仅主要解决与模型开发和开发生命周期相关的风险。然而，一个全面的AI风险管理框架还需要涵盖其他风险，如系统可扩展性和可靠性、系统未授权访问、访问拒绝和第三方故障风险。MRM还应与企业技术风险、网络安全管理和第三方风险相结合，以确保对AI风险进行全面覆盖。
- en: Applying risk management across the AI lifecycle
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在人工智能生命周期中应用风险管理
- en: AI risks can exist in any stage of the AI lifecycle, spanning from business
    problem identification to the uses of AI systems. In the following sections, we
    will explore the various risks that can arise at each stage of the AI lifecycle
    (as illustrated in *Figure 12.1*) and suggest effective strategies and considerations
    to mitigate them.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能风险可能存在于人工智能生命周期的任何阶段，从业务问题识别到人工智能系统的使用。在接下来的章节中，我们将探讨人工智能生命周期每个阶段可能出现的各种风险（如图12.1所示），并提出有效的策略和考虑因素以减轻这些风险。
- en: Business problem identification and definition
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 业务问题识别和定义
- en: In this initial stage of the AI lifecycle, organizations develop a comprehensive
    understanding of the business problems that AI can address. They also outline
    the overall solution approach and data prerequisites. It is critical during this
    phase to verify that the AI solution aligns with governance principles, standards,
    and requirements while achieving specific business objectives.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能生命周期的这个初始阶段，组织对人工智能可以解决的业务问题有一个全面的理解。他们还概述了整体解决方案方法和数据需求。在这个阶段，验证人工智能解决方案是否符合治理原则、标准和要求，同时实现特定的业务目标，这是至关重要的。
- en: One significant risk is the regulatory compliance risk, which arises when there
    is a lack of consideration for potential regulatory requirements. Organizations
    must understand applicable regulatory requirements related to AI projects, such
    as the EU AI Act, and take appropriate measures to address them in the problem
    identification phase. Failure to do so can result in non-compliance, impacting
    the entire project. Another critical consideration is the ethical risk. Ethics
    can play a vital role in an organization’s values and brand reputation. If not
    integrated into business problem identification, the final system may cause misalignment
    with core values and the brand, leading to reputational damage.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一个显著的风险是合规性风险，它出现在对潜在监管要求缺乏考虑的情况下。组织必须了解与人工智能项目相关的适用监管要求，如欧盟人工智能法案，并在问题识别阶段采取适当的措施来应对。未能这样做可能导致不合规，影响整个项目。另一个关键考虑因素是道德风险。道德在一个组织的价值观和品牌声誉中可以发挥至关重要的作用。如果未在业务问题识别中整合，最终系统可能会导致与核心价值观和品牌不一致，从而造成声誉损害。
- en: Unexpected consequences can arise if the system is not designed for the intended
    use. Misuse can result in unforeseen negative consequences, emphasizing the need
    for careful consideration of system design. Risk rating and classification help
    determine potential impacts and guide different levels of risk management. Without
    this, AI systems and their data may be mishandled, leading to unexpected consequences
    and potential adverse outcomes. Additionally, security and privacy requirement
    risks emphasize the need for implementing security and privacy measures. Without
    these requirements, organizations are at risk of privacy violations and adversarial
    manipulation of AI systems, compromising data integrity and security.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统未针对预期用途进行设计，可能会出现意外后果。误用可能导致不可预见的负面后果，强调了对系统设计进行仔细考虑的必要性。风险评估和分类有助于确定潜在影响并指导不同级别的风险管理。如果没有这些，人工智能系统和其数据可能会被不当处理，导致意外后果和潜在的负面结果。此外，安全和隐私要求风险强调了实施安全和隐私措施的需要。如果没有这些要求，组织可能会面临隐私侵犯和人工智能系统被敌对操纵的风险，损害数据完整性和安全性。
- en: For each of the potential risks identified at this stage, it is important to
    conduct an assessment to determine the severity and likelihood of the risk happening
    and the resulting impact. Determine whether any mitigation measures should be
    considered to reduce the risk, based on the risk tolerance level of each individual
    organization. Only move forward with the project if the key risks are understood,
    mitigated, or accepted.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段识别出的每个潜在风险，进行评估以确定风险发生的严重性和可能性以及由此产生的后果都至关重要。根据每个组织的风险承受能力，确定是否应考虑任何缓解措施以降低风险。只有当关键风险得到理解、缓解或接受时，才能继续推进项目。
- en: Data acquisition and management
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据获取和管理
- en: During this phase of the project lifecycle, it is crucial for organizations
    to identify appropriate data sources, establish a data acquisition strategy, and
    assess their technology capabilities for data processing and management. AI systems
    present a distinct set of data acquisition and processing risks, in addition to
    their exposure to many common data-related risks. These risks span from selecting
    the appropriate dataset to managing data end to end. These risks encompass every
    aspect, from the careful selection of datasets to the comprehensive management
    of data throughout its lifecycle.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目生命周期的这个阶段，对于组织来说，确定适当的数据来源、建立数据获取策略以及评估其数据处理和管理的技术能力至关重要。除了面临许多常见的数据相关风险外，AI系统还呈现一组独特的数据获取和处理风险。这些风险从选择适当的数据集到端到端的数据管理，涵盖了每个方面。这些风险包括从仔细选择数据集到在整个生命周期中对数据进行全面管理。
- en: Risk considerations
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险考量
- en: One key risk is the data selection risk, where an incorrect or inadequately
    sampled dataset may introduce significant data relevancy or bias issues. This
    can lead to the development of a biased model or a model that fails to effectively
    address the problem at hand. For instance, in a credit scoring project, if certain
    demographic groups are underrepresented in the dataset during data collection,
    the resulting model may exhibit bias toward the overrepresented groups.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键风险是数据选择风险，不正确或采样不足的数据集可能引入重大的数据相关或偏差问题。这可能导致开发出有偏差的模型或无法有效解决实际问题的模型。例如，在一个信用评分项目中，如果在数据收集期间某些人口群体在数据集中代表性不足，那么产生的模型可能对代表性过高的群体表现出偏差。
- en: Data quality and missing data pose significant challenges for data scientists,
    affecting the development of high-quality ML models. Ensuring data accuracy and
    addressing missing data issues is crucial for the successful development of robust
    models.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量和缺失数据对数据科学家来说是一个重大挑战，影响高质量机器学习模型的发展。确保数据准确性和解决缺失数据问题是成功开发稳健模型的关键。
- en: Data labeling risks emerge as a concern due to the predominantly manual nature
    of data labeling processes. This not only becomes a bottleneck in model development
    but can also lead to poor model accuracy if mislabeling mistakes occur.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据标注过程主要依赖人工，数据标注风险成为一个关注点。这不仅成为模型开发的瓶颈，如果发生错误标注，还可能导致模型准确性下降。
- en: Regulatory and compliance data checks are vital for projects falling under specific
    regulatory compliance requirements. Enforcing regulatory and compliance data checks,
    such as data sovereignty rules, is essential to avoid potential fines and lawsuits
    resulting from violations, safeguarding the organization’s financial and reputational
    standing.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于符合特定合规要求的工程项目，监管和合规数据检查至关重要。执行监管和合规数据检查，例如数据主权规则，对于避免因违规而产生的潜在罚款和诉讼，保护组织的财务和声誉至关重要。
- en: Data privacy becomes pertinent as AI capabilities improve with increased data,
    including personal information. The ethical use of personal data for analysis
    and model training requires careful consideration to prevent privacy infringements.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据量，包括个人信息，的增加，随着人工智能能力的提升，数据隐私变得相关。在分析模型训练中，对个人数据的道德使用需要仔细考虑，以防止侵犯隐私。
- en: The adversarial attack risk introduces a new dimension of threats, wherein malicious
    actors can manipulate training data to cause the resulting model to behave incorrectly
    in targeted scenarios. For instance, manipulation of training data labels can
    lead to models learning incorrectly and producing inaccurate results. These data-related
    risks demand meticulous attention and mitigation strategies to ensure the successful
    and ethical deployment of AI systems.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗攻击风险引入了新的威胁维度，恶意行为者可以操纵训练数据，导致生成的模型在特定场景中表现不正确。例如，操纵训练数据标签可能导致模型学习错误并产生不准确的结果。这些与数据相关的风险需要细致的关注和缓解策略，以确保AI系统的成功和道德部署。
- en: Risk mitigations
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险缓解
- en: To effectively mitigate data-related risks, comprehensive strategies and mechanisms
    must be in place to address issues related to data quality, bias, human errors,
    and regulatory compliance requirements. These mechanisms encompass various initiatives,
    including the implementation of robust data validation methods, the establishment
    of consistent definitions and standards for data selection and sampling, regular
    reviews of data quality and completeness, and the provision of guidance on mitigation
    approaches.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地缓解数据相关风险，必须建立全面的策略和机制，以解决与数据质量、偏见、人为错误和监管合规性要求相关的问题。这些机制包括各种倡议，包括实施强大的数据验证方法、建立数据选择和抽样的统一定义和标准、定期审查数据质量和完整性，以及提供缓解方法的指导。
- en: To address data selection and sampling risks, it is crucial to establish standards
    and consistent definitions for different data types and sources, ensuring uniformity
    in data selection across various sources. These standards should encompass considerations
    for relevancy, data gaps, bias, and representation, providing guidance on mitigation
    approaches such as extending data sources, employing synthetic data, and utilizing
    appropriate sampling techniques.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决数据选择和抽样风险，建立不同数据类型和来源的标准和一致定义至关重要，以确保在各种来源中数据选择的统一性。这些标准应包括对相关性、数据缺口、偏见和代表性的考虑，并提供关于缓解方法（如扩展数据来源、使用合成数据以及利用适当的抽样技术）的指导。
- en: For mitigating data quality risks, stringent measures should be taken to verify
    that the minimum data quality standards are met to support high-quality data processing
    and model training. This includes the establishment of rules and sample data reviews
    for accuracy, completeness, consistency, and the valid representation of the target
    population.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解数据质量风险，应采取严格的措施来验证是否满足最低的数据质量标准，以支持高质量的数据处理和模型训练。这包括建立规则和样本数据审查，以确保准确性、完整性、一致性以及目标人群的有效代表性。
- en: To address data labeling risks, controls should be implemented in the data labeling
    process to ensure consistency and mitigate subjective bias. Additionally, sample
    testing the validity of dataset labels can further enhance the quality and accuracy
    of the labeled data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决数据标注风险，应在数据标注过程中实施控制措施，以确保一致性并减轻主观偏见。此外，对数据集标签的有效性进行样本测试可以进一步提高标注数据的品质和准确性。
- en: In terms of regulatory compliance and privacy checks, a robust set of checks
    should be integrated into the MRM process. This involves establishing enhanced
    controls around data access, ownership, collection, storage, transmission, and
    assessment to satisfy regulatory requirements. Additionally, comprehensive regulatory
    compliance checks for data privacy protection should be embedded in the MRM process,
    linking these controls to the enterprise access and authentication platform for
    centralized governance. The enforcement of data encryption and data masking should
    be applied where necessary to bolster privacy
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在监管合规性和隐私检查方面，应将一套强大的检查机制整合到MRM（营销资源管理）流程中。这包括建立增强的数据访问、所有权、收集、存储、传输和评估控制，以满足监管要求。此外，应将全面的数据隐私保护监管合规性检查嵌入到MRM流程中，将这些控制与企业的访问和身份验证平台联系起来，以实现集中治理。在必要时，应实施数据加密和数据掩码，以加强隐私保护
- en: Ultimately, the mitigation strategy and mechanisms for data-related risks should
    be tailored to the specific needs of the organization and continuously reviewed
    and updated to keep up with the evolving landscape of AI/ML technologies and their
    associated risks.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，数据相关风险的缓解策略和机制应根据组织的具体需求量身定制，并持续审查和更新，以跟上AI/ML技术及其相关风险不断发展的格局。
- en: Experimentation and model development
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验和模型开发
- en: During this phase of the project lifecycle, data scientists utilize various
    algorithms and datasets to experiment and develop models to address business problems.
    The risks associated with this phase of the project lifecycle are mostly specific
    to AI/ML. They encompass a wide range of topics, such as algorithm selection and
    associated assumptions, limitations, model validation and robustness, model transparency
    and explainability, model fairness, compliance, and intended model use.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目生命周期的这个阶段，数据科学家利用各种算法和数据集进行实验和开发模型，以解决业务问题。与这个项目生命周期阶段相关的风险主要针对AI/ML。它们涵盖了广泛的主题，如算法选择及其相关假设、限制、模型验证和鲁棒性、模型透明度和可解释性、模型公平性、合规性和预期模型使用。
- en: Risk considerations
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险考虑
- en: The risk associated with model assumptions and limitations arises from the potential
    inaccuracies, incompleteness, or inconsistencies in assumptions and limitations,
    leading the model to inadequately fit the situation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 模型假设和限制相关的风险源于假设和限制中的潜在不准确、不完整或不一致，导致模型无法充分适应情况。
- en: For instance, the linear regression algorithm assumes a linear relationship
    between predictor and response variables, and if such a relationship doesn’t exist,
    the predictions may be incorrect or biased. Certain algorithms may also have limitations
    on data sample size, impacting their performance with small datasets.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，线性回归算法假设预测变量和响应变量之间存在线性关系，如果不存在这种关系，预测可能会错误或存在偏差。某些算法也可能对数据样本大小有限制，影响其在小数据集上的性能。
- en: Model selection introduces risks related to overfitting when models are chosen
    based solely on training performance and a lack of interpretability when there’s
    a requirement for explainability. Inadequate sensitivity and scenario analysis
    pose risks to model robustness, as a failure to understand the sensitivity of
    a credit risk model may lead to incorrect predictions. Similarly, financial forecast
    models that consider only a limited range of economic scenarios may fail to function
    correctly during unexpected events.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 模型选择引入了当模型仅基于训练性能选择时与过拟合相关的风险，以及在需要可解释性时与缺乏可解释性相关的风险。不充分敏感性和情景分析对模型鲁棒性构成风险，因为未能理解信用风险模型的敏感性可能导致预测错误。同样，仅考虑有限经济情景的财务预测模型在意外事件发生时可能无法正常工作。
- en: Model transparency risk arises from a lack of transparency hindering the explainability
    and verification of model decisions, potentially leaving organizations legally
    vulnerable if they cannot justify AI-driven decisions. Model fairness risk acknowledges
    that both data and the model itself can introduce bias, impacting the fairness
    of the AI system. For instance, Naïve Bayes algorithms may introduce bias if they
    assume independence among features, leading to incorrect predictions when features
    are correlated.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 模型透明度风险源于透明度不足，阻碍了模型决策的可解释性和验证，如果组织无法证明其基于AI的决策是合理的，可能会在法律上处于脆弱状态。模型公平性风险承认数据和模型本身都可能引入偏差，影响AI系统的公平性。例如，朴素贝叶斯算法如果假设特征之间相互独立，那么当特征相关时，可能会导致预测错误。
- en: Model evaluation risk stems from inadequate independent validation or the use
    of incorrect validation methods or metrics, posing the threat of unexpected behavior
    when models are not thoroughly tested. Model use and impact risk encompass the
    potential negative consequences arising from real-world deployment, as models
    trained on historical data may perform poorly if the future differs significantly
    from the past.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估风险源于独立验证不足或使用错误的验证方法或指标，当模型未经过充分测试时，可能会出现意外行为。模型使用和影响风险包括现实世界部署可能产生的潜在负面影响，因为基于历史数据训练的模型如果未来与过去差异显著，可能会表现不佳。
- en: Missing lineage risk emphasizes the importance of understanding the lineage
    from the data source to model artifacts, including all transformations and experimentations
    during the modeling process, to comprehend model behavior and identify the root
    cause of issues.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失血缘风险强调了解从数据源到模型工件（包括建模过程中的所有转换和实验）的来源的重要性，以理解模型行为并识别问题的根本原因。
- en: Risk mitigations
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险缓解
- en: 'To mitigate these risks, organizations must establish comprehensive MRM standards
    that cover model evaluation, validation, selection, and fairness. Additionally,
    the organization should enhance its capabilities and best practices for recognizing
    assumptions and limitations, addressing known gaps, and ensuring model transparency
    and lineage through the following approaches:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: For model assumption and limitation risk, it is crucial to clearly define and
    validate the underlying assumptions of algorithms. Test difficult-to-validate
    assumptions with various techniques, ensuring completeness, and calculate model
    uncertainty to determine confidence levels in outputs.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To mitigate risks associated with model selection, data scientists should develop
    a robust set of candidate models, undergo diverse team reviews, and involve technical,
    business, and target audience representatives to ensure the selected model effectively
    addresses problems. The modeling approach should be assessed on whether it is
    fit for purpose, explainable, reproducible, and robust, with documented decisions
    and supporting evidence.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To address deficiencies in sensitivity and scenario testing, standards for model
    sensitivity and scenario testing should be established within the MRM framework.
    These procedures, integral to the development process, offer insights into boundary
    conditions impacting model robustness, minimize errors, and enhance comprehension
    of input-output interplay.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To tackle model transparency risks, establish standards promoting communication
    and feedback within the development team, ensuring transparency throughout the
    model development process. Thorough documentation, including model validation
    techniques, serves as corroborating evidence for transparency.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For model fairness issues, define and incorporate model fairness standards.
    Embed fairness checks in the model lifecycle, involve stakeholders in issue mitigation,
    enhance governance techniques, and recognize the ongoing process of fixing discrimination
    in algorithmic systems.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorporate model performance evaluation standards within MRM for validation,
    involving business and technical stakeholders in issue discovery and mitigation.
    Employ standardized validation tools and techniques for consistent procedures,
    and conduct an end-to-end evaluation against agreed-upon standards, monitoring
    metrics during retraining.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate model use and impact risks within MRM by verifying the understanding
    of decisions during design/deployment/validation. Conduct an impact assessment
    to assess risks against preset thresholds, and verify model outcomes for precision,
    consistency, relevance, and alignment with trustworthy AI criteria.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish mechanisms and technology capabilities to track model lineage from
    data source to deployment. Implement comprehensive metadata management, version
    control for relevant artifacts, a model registry, and auditing/logging mechanisms
    to understand changes made, by whom, and for what purpose.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, a comprehensive MRM framework that includes technical standards, ongoing
    monitoring and updates, and a culture of ethical decision-making is crucial for
    organizations to effectively manage the risks associated with model development
    so they can be used in a trustworthy manner.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，一个包含技术标准、持续监控和更新以及道德决策文化的综合MRM框架对于组织有效管理模型开发相关的风险至关重要，以便它们可以以可信的方式使用。
- en: AI system deployment and operations
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI系统部署和运营
- en: During this stage of the lifecycle, organizations design and build technology
    environments for AI system/model deployment in production to handle real-world
    business workflows in the broader application ecosystem and establish operational
    processes and standards to monitor the environments and remediate production issues
    ranging from basic system failure to model performance degradation.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个生命周期阶段，组织设计和构建AI系统/模型在生产中的部署技术环境，以处理更广泛的应用生态系统中的现实世界业务工作流程，并建立监控环境和修复从基本系统故障到模型性能退化的生产问题的操作流程和标准。
- en: Risk considerations
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险考虑
- en: Human supervision risk involves the crucial practice of subjecting AI models
    to human review before deployment into production to ensure ongoing suitability
    for their intended purpose, preventing the deployment of inadequately prepared
    systems that may lead to production problems or unforeseen outcomes.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 人类监督风险涉及在将AI模型部署到生产之前对其进行人类审查的关键实践，以确保其持续适合其预期目的，防止部署准备不足的系统导致生产问题或不可预见的结果。
- en: Technology integration risk arises as AI systems are typically integrated into
    the broader technology ecosystem, supporting multiple business functions. Challenges
    may emerge when integrating with upstream and downstream systems for data transfer,
    model integration, or API integration, potentially causing compatibility issues,
    such as the wrong model version impacting different systems.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 技术集成风险出现在AI系统通常集成到更广泛的技术生态系统中，支持多个业务功能。在集成上游和下游系统进行数据传输、模型集成或API集成时可能会出现挑战，可能造成兼容性问题，例如错误的模型版本影响不同的系统。
- en: Technology scalability risk is associated with unexpected spikes in data volumes,
    business users, and customers after AI system/model deployment. Failure to handle
    scalability scenarios can negatively impact business and user experiences.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 技术可扩展性风险与AI系统/模型部署后数据量、业务用户和客户的意外激增相关。无法处理可扩展性场景可能会对业务和用户体验产生负面影响。
- en: Model performance and behavior change risk stems from AI systems being developed
    using historical data. Unexpected changes in real-world environments, like data
    drift and outlier conditions, can cause the model to behave differently from the
    original assumption.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 模型性能和行为变化风险源于使用历史数据开发的AI系统。现实世界环境中数据漂移和异常条件等意外变化可能导致模型的行为与原始假设不同。
- en: Fallback procedure risk underscores the importance of well-established fallback
    procedures when production issues are detected. Inadequate fallback protocols
    can jeopardize system operation continuity.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 回退程序风险强调了在检测到生产问题时建立良好的回退程序的重要性。不充分的回退协议可能会危及系统操作的连续性。
- en: Adversarial attacks present new threats to AI systems. Adversarial attacks such
    as feeding bad data to AI systems can lead to incorrect predictions and faulty
    downstream decisions.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗攻击对AI系统提出了新的威胁。对抗攻击，如向AI系统提供不良数据，可能导致预测错误和下游决策错误。
- en: Risk mitigations
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险缓解
- en: To effectively manage risks during deployment and operations, robust mitigation
    mechanisms and technological capabilities are essential. Rigorous testing and
    operational checks, integration standards, model performance monitoring, established
    issue resolution processes, and adversarial monitoring and remediation throughout
    the AI lifecycle are key focus areas.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在部署和运营期间有效管理风险，强大的缓解机制和技术能力是必不可少的。严格的测试和操作检查、集成标准、模型性能监控、建立的问题解决流程以及在整个AI生命周期中的对抗监控和修复是关键关注领域。
- en: Let’s explore specific recommendations in depth.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨具体建议。
- en: A crucial element for effective AI risk management is a model management system
    with a model registry. Providing details about models, performance metrics, uses,
    and related metadata, this system should incorporate MRM standards and embed operationalization
    checks. Stress testing and scaling simulation are vital to understanding behavior
    under heavy loads. Organizations should establish processes and tools for model
    owners to monitor, manage, govern, and analyze results.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有效的AI风险管理来说，一个具有模型注册库的模型管理系统是一个关键要素。该系统应提供有关模型、性能指标、用途和相关元数据的详细信息，并应纳入MRM标准并嵌入操作化检查。压力测试和扩展模拟对于理解在重负载下的行为至关重要。组织应建立流程和工具，以便模型所有者可以监控、管理、治理和分析结果。
- en: To mitigate AI integration risks, organizations need to incorporate integration
    standards and requirements in risk management. Ensuring interoperability among
    platforms and conducting robust integration testing is crucial. Verification of
    proper configuration and integration into the production environment is essential
    to prevent errors during migration or upgrading.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解AI集成风险，组织需要在风险管理中纳入集成标准和要求。确保平台间的互操作性并进行稳健的集成测试至关重要。验证适当的配置和生产环境中的集成对于防止迁移或升级过程中的错误是必不可少的。
- en: Establishing model deployment review and approval standards is crucial, encompassing
    a detailed review of design, algorithms, testing results, and performance metrics.
    It should outline steps for mitigating potential deployment risks.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 建立模型部署审查和批准标准至关重要，包括对设计、算法、测试结果和性能指标进行详细审查。它应概述缓解潜在部署风险的步骤。
- en: For operational continuity regarding performance and behavior changes, MRM should
    include model monitoring, performance issue tracking, and resolution standards.
    Continuous monitoring of statistical, technical, and business metrics, along with
    real-time circuit breakers, helps ensure the model operates as intended. Pre-specifying
    benchmark or legacy models for fallback options is useful in case performance
    boundaries are breached.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保性能和行为变化的运营连续性，MRM应包括模型监控、性能问题跟踪和解决标准。持续监控统计、技术和业务指标，以及实时断路器，有助于确保模型按预期运行。预先指定基准或旧模型作为后备选项，在性能边界被突破时是有用的。
- en: Adversarial attack monitoring standards in MRM are crucial to prevent malicious
    input from causing model malfunctions. Effective testing, auditing techniques,
    and certification programs are needed to address AI model vulnerabilities. Leveraging
    research on adversarial attacks and model data leakage for vulnerability testing
    and ensuring robustness and resilience to various attacks is essential. Proactive
    cyber threat hunting should be instituted to detect and isolate advanced threats
    in networks.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在MRM中的对抗性攻击监控标准对于防止恶意输入导致模型故障至关重要。有效的测试、审计技术和认证计划是解决AI模型漏洞所必需的。利用对抗性攻击和模型数据泄露的研究进行漏洞测试，并确保对各种攻击的鲁棒性和弹性是至关重要的。应建立积极的网络威胁狩猎，以检测和隔离网络中的高级威胁。
- en: What we have covered so far does not include all the risks we might encounter
    throughout the AI lifecycle and new emergent risks are coming up regularly. It
    is also not possible and potentially counterproductive to mitigate all the risks
    in practice. Organizations should determine the tolerance levels for the different
    risks, which are going to be highly contextual and application- and use case-specific.
    Other factors such as policies established by system owners and regulators, organizational
    priority, and resource considerations can also influence risk tolerance. It is
    also worth noting that risk tolerance is likely to change over time as the influencing
    factors evolve.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止我们所涵盖的内容并不包括在整个AI生命周期中可能遇到的所有风险，而且新的风险也在不断出现。在实践中，完全缓解所有风险也是不可能的，并且可能适得其反。组织应确定不同风险的容忍度，这些容忍度将高度依赖于具体的应用场景和用例。其他因素，如系统所有者和监管机构制定的政策、组织优先级和资源考虑，也可能影响风险容忍度。值得注意的是，随着影响因素的变化，风险容忍度可能会随时间而变化。
- en: It is also important to prioritize the risk identified in the AI lifecycle.
    Organizations should recognize that not all risks are the same, and scarce resources
    should be allocated appropriately to address the different risks. The assessed
    risk levels and potential impact of an AI system should be used to prioritize
    the resource allocation to mitigate these risks.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Finally, AI risks are not isolated risks and should be considered and incorporated
    into the broader enterprise risk management strategies and processes. The roles
    and responsibilities of different players in managing risks will span different
    functional domains such as engineering, data science, cybersecurity, audit, and
    compliance.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Designing ML platforms with governance and risk management considerations
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML technology systems play a crucial role in the AI risk management process
    and activities. To begin with, these systems must be developed and constructed
    to comply with both internal and external policies and guidelines. Additionally,
    technology can aid in streamlining and automating ML governance procedures. The
    following figure illustrates the different ML governance touchpoints in an enterprise
    ML platform. It is important to know that ML technology alone can only help address
    a subset of AI risks; other enterprise security technology needs to be incorporated
    to form a more comprehensive governance and defense mechanism.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20836_12_02.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.2: ML platform and ML governance'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding figure, the ML governance touchpoints have been integrated
    into the MLOps architecture depicted in *Figure 9.4* of *Chapter 9*, *Designing
    an Enterprise ML Architecture with AWS ML Services*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: When an ML platform is built with AI risk management and governance in mind,
    it can gather and furnish the information to support the MRM programs while optimizing
    the risk management workflows. Online data stores, workflow applications, document-sharing
    systems, and model inventory databases are among the technology solutions employed
    for AI governance. In the following sections, let’s delve deeper into some of
    the core ML governance components and see where an ML platform or technology can
    fit in.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Data and model documentation
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the essential elements of AI governance is documentation. All models
    used for decision-making should be properly documented. The scope of the documentation
    may include the following:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Data overview, data quality report on the valuation, and assessment of the input
    data
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model development document including methodology and assumption, model usage
    instructions, performance and validation results, and other qualitative and quantitative
    analysis
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model validation strategy and report by the second and third lines of defense
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model performance monitoring results and data drift reports
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model implementation and user acceptance testing reports
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The role of the ML platform in ML governance documentation is usually to provide
    data points that feed into the formal risk management documentation or generate
    some ready-to-use reports. Specifically, an ML platform should be able to track,
    store, and report the following data points:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Data quality metrics such as data description, statistics, bias, and errors
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model metrics and validation results in development and testing
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model bias and explainability reports
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model performance monitoring results in production
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model description and intended use
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Risk rating and classification details
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Different ML platforms have varying capabilities supporting the AI governance
    documentation requirements. Here, we will discuss the various capabilities of
    SageMaker in supporting these requirements. SageMaker can produce data and documents
    to be incorporated into model risk documentation. This includes tracking and producing
    information that is relevant for AI governance documentation, such as:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '**Model metrics**: The SageMaker training service tracks model metrics such
    as training errors and validation errors.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data and model bias reports**: SageMaker Clarify is the bias detection component
    in SageMaker. If you enable SageMaker Clarify, you can get data and model bias
    reports for the training data and trained model. The data and model bias reports
    have details such as imbalances in training data and prediction behavior across
    different age groups and genders.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model explainability reports**: SageMaker Clarify also provides a model explainability
    feature. It uses SHAP to explain the contribution of each input to the final decision.
    You can get more details about SHAP at [https://shap.readthedocs.io/en/latest/index.html](https://shap.readthedocs.io/en/latest/index.html).'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model Card**: SageMaker Model Card can be used to document critical information
    about ML models, such as the intended use of the model, risk rating, and detailed
    descriptions of model training and performance.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Both open-source and managed model registry platforms are available for managing
    model registries. For example, the MLflow Model Registry is an open-source option,
    while Amazon SageMaker offers a managed model registry service. The SageMaker
    Model Registry has several key capabilities that can aid in ML governance activities
    and processes:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '**Model inventory**: All versions of the different models belong to a respective
    model group in the SageMaker Model Registry. You can view all the model groups
    and different versions of a model here. Metadata such as model metrics, training
    job details, hyperparameters used for training, and training data sources are
    important data points for the model reviews and model audit processes. Depending
    on specific business requirements, you can set up a central model registry for
    a single enterprise view, or distributed model registries if that will meet the
    governance and audit requirements.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model approval and lifecycle tracking**: You can track the approval of models
    and model stages directly inside the SageMaker Model Registry. This detail helps
    the business operations and audit to ensure the proper processes are followed.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Monitoring models after deployment is crucial to identify any potential failures
    and take prompt remedial action to mitigate risks. To ensure smooth functioning,
    models must be monitored for system availability and errors, as well as data and
    model drift and prediction failure. Amazon SageMaker offers a model monitoring
    feature that can detect both data drift and model drift. SageMaker Model Monitor
    provides the following capabilities:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '**Data drift**: With SageMaker Model Monitor, you can monitor data quality
    issues and data distribution skews (aka data drift) in production. To use this
    feature, you create a baseline using a baseline dataset, such as a model training
    dataset, to get data statistics and data types and suggest constraints for monitoring.
    SageMaker Model Monitor can capture live inference traffic, calculate data statistics,
    examine data types, verify them against constraints, and trigger alerts. For example,
    if a feature’s mean and standard deviation change significantly from the baseline,
    an alert can be triggered.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model performance drift**: You can use SageMaker Model Monitor to detect
    model performance changes in production. To use this feature, you create a model
    performance baseline job using a baseline dataset that contains both the inputs
    and labels. The baseline job will suggest constraints, which are the metrics thresholds
    that Model Monitor will monitor against the metrics to be calculated with ground
    truth data collected in production. Metrics can be optionally sent to CloudWatch
    for visualization.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feature attribution drift**: When enabled with SageMaker Clarify, SageMaker
    Model Monitor can report feature attribution drift. Feature attributions are indicators
    of feature importance to the prediction output. Similar to data and model drift,
    you create a SHAP baseline job using baseline data to generate constraint suggestions.
    The separate monitoring job is then scheduled to monitor predictions in production
    against the baseline.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lineage and reproducibility
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'MRM requires establishing lineage across data and models to ensure reproducibility.
    Lineage is the systematic tracking and documentation of the origin, transformations,
    and dependencies of data, as well as the development and evolution of ML models,
    providing transparency and accountability throughout the entire process. Lineage
    information includes training data sources, algorithm selection, hyperparameter
    configurations, and the model training script. SageMaker offers several features
    that aid in establishing lineage:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker training jobs keep lineage data such as the training data source,
    training job container (contains the algorithm and training script), hyperparameter
    configuration, and model artifact location. Historical training job data is immutable
    in the SageMaker environment for record retention purposes.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SageMaker Experiments and ML Lineage Tracking can contain additional component
    details such as data processing for more complete lineage tracking.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SageMaker hosting has information on the location of the original model artifact
    and the inference container to trace the lineage from the model to the endpoint.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These lineage data points, such as training data source and training configurations,
    are available by calling the SageMaker API; an external application can call the
    SageMaker API directly to extract this data for review purposes. Alternatively,
    a data extraction job can be developed to extract these data points and load them
    into a purpose-built risk management store for analysis.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'The significance of ML privacy is growing rapidly in the implementation of
    ML systems. To comply with data privacy regulations or internal data privacy controls,
    ML systems must have fundamental infrastructure security features, such as data
    encryption, network isolation, compute isolation, and private connectivity. By
    utilizing a SageMaker-based ML platform, you can enable the following essential
    security controls:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '**Private networking**: As SageMaker is a fully managed service, it runs in
    an AWS-owned account. By default, resources in your own AWS account communicate
    with SageMaker APIs via the public internet. To enable private connectivity to
    SageMaker components from your own AWS environment, you can attach them to a subnet
    in your own **virtual private cloud** (**VPC**).'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage encryption**: Data-at-rest encryption can be enabled by providing
    an encryption key when you create a SageMaker notebook, a training job, a processing
    job, or a hosting endpoint.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disabling internet access**: By default, the SageMaker notebook, training
    job, and hosting service have access to the internet. Internet access can be disabled
    via configuration.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Observability and auditing
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Auditing primarily concentrates on process verification and artifact collection
    to support audit activities. The platform on which the process takes place usually
    functions as an information source for collecting artifacts. For instance, suppose
    there is an MRM policy that necessitates approval before deploying a model into
    production. In that case, the audit will require access to the system of records
    to ensure that the required data is collected and retained.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'SageMaker and other related services can be a data source in support of the
    overall audit process. Specifically, it provides the following information that
    can be relevant for auditing purposes:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '**Activity and access audit trail**: SageMaker sends all audit trail data to
    CloudWatch Logs, which can be retained and analyzed for audit purposes.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model approval tracking**: Model deployment approvals are tracked in the
    SageMaker Model Registry. This can be provided to the auditor as evidence that
    required approval processes are followed.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lineage tracking**: SageMaker Experiments and ML Lineage Tracking components
    can track and retain model lineages such as data processing, model training, and
    model deployment. Lineage Tracking information helps the auditor verify that the
    model can be reproduced using its original data and configuration dependencies.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuration changes**: System configuration data is captured in AWS CloudTrail
    as change events. For example, when a SageMaker endpoint is deleted, there will
    be an entry in CloudTrail indicating this change.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability and performance
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To mitigate the potential scalability risk, AI systems should be designed to
    handle dynamic and unexpected loads. For an ML platform, this usually means that
    the training infrastructure is designed and implemented to support a single large
    training job as well as many training jobs running in parallel. Similarly, the
    model hosting infrastructure should be capable of handling a large number of models
    running in parallel as well as running a large number of model instances across
    many nodes.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'If your platform of choice is SageMaker, then the following capabilities can
    help mitigate training and hosting scaling challenges:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '**Training infrastructure scaling**: SageMaker has support for large-scale
    distributed training, with the ability to utilize hundreds of nodes and thousands
    of CPUs/GPUs. Additionally, SageMaker provides a purpose-built library for running
    both data-parallel and model-parallel training jobs. For storage scaling, high-performance
    storage solutions like **Elastic File System** (**EFS**) and FSx can be mounted
    onto SageMaker training nodes to accommodate training jobs that require a large-scale
    dataset exceeding 1 TB. AWS accounts can run multiple training jobs in parallel,
    and the soft limit can be increased upon request.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hosting infrastructure scaling:** SageMaker offers several options to scale
    model hosting needs. The **Multi-Model Endpoint** (**MME**) capability allows
    you to host multiple models behind a single endpoint while reducing costs. SageMaker’s
    automatic scaling feature enables you to define a scaling policy based on metrics
    such as the number of invocations per host, which can increase the number of instances
    running the same model automatically when the traffic increases. Additionally,
    the serverless inference option allows you to run a single model concurrently
    up to the maximum number supported by SageMaker.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data quality
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data quality checks should take place in multiple phases of the lifecycle, including
    data acquisition and processing, exploratory data analysis and data wrangling,
    feature engineering, and model inference. The checks should cover many aspects
    of data quality, such as missing data, data accuracy, inconsistency across different
    sources, incorrect format, incompleteness, imbalanced data, and duplication.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'From an AWS technology perspective, there are several purpose-built tools and
    features that can help with data quality management:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS Glue DataBrew offers a range of data quality features that can help ensure
    the accuracy and reliability of data used for analysis or model training. DataBrew
    is mainly used by data engineers who are responsible for sourcing and cleaning
    the data during the data acquisition and processing phase for downstream users
    such as data scientists. Some of these features include:'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data profiling**: DataBrew can automatically profile datasets to identify
    data quality issues, such as missing or inconsistent values, outliers, or duplicates.'
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data cleaning**: DataBrew provides a range of data cleaning transformations
    that can be applied to address common data quality issues, such as filling in
    missing values, removing duplicates, or standardizing data formats.'
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data validation**: DataBrew can perform data validation checks to ensure
    that data values fall within expected ranges or conform to predefined standards
    or formats.'
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data lineage**: DataBrew tracks the lineage of data transformations to help
    ensure that data is being processed correctly and that any changes can be traced
    back to their source.'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data versioning**: DataBrew supports the versioning of datasets, making it
    easy to track changes and roll back to previous versions if necessary.'
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: SageMaker Data Wrangler offers some similar data quality capabilities, targeting
    mainly data scientists who are doing data exploratory analysis and feature engineering
    in the SageMaker environment. The Data Quality and Insights report in Data Wrangler
    can automatically verify data quality (such as missing values, duplicate rows,
    and data types) and help detect anomalies (such as outliers, class imbalance,
    and data leakage) in your data.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In conclusion, ML technology systems serve as pivotal assets in the AI risk
    management landscape. The foundational step involves aligning these systems with
    internal and external policies, ensuring robust compliance.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, leveraging tools like SageMaker and MLOps systems emerges as a
    strategic approach, offering substantial support in documentation, lineage tracking,
    data management, and quality assurance. By enhancing observability and enabling
    thorough auditing, these technologies enable organizations to navigate the complexities
    of AI risk management with efficiency and precision.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter delved into several areas related to AI risk management and the
    technology platforms that support it. By now, you should have a solid understanding
    of the key AI-related risk scenarios, why AI risk management is critical, and
    how to detect and address potential risks throughout the AI lifecycle. Additionally,
    you should be aware of the significance of ML platforms in supporting AI risk
    management. It is worth noting that AI risk is a vast and complex domain with
    many unresolved risk challenges and new emergent risks arising rapidly. Moreover,
    the fast advancement in AI technology and adoption is also creating new risk exposure
    that risk management professionals must constantly address.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive deeper into several specific AI risk topics
    and mitigation techniques, including bias, model explainability, model robustness,
    and adversarial attacks.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Leave a review!
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enjoying this book? Help readers like you by leaving an Amazon review. Scan
    the QR code below to get a free eBook of your choice.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Review_Copy.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
- en: '**Limited Offer*'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
