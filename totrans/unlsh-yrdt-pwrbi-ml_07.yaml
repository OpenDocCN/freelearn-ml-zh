- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying Data Ingestion and Transformation Components to the Power BI Cloud
    Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B19500_06.xhtml#_idTextAnchor089), you finalized the base design
    for your ML queries, which will be migrated to the Power BI cloud service to train
    and test ML models. You focused on using R and Python visuals within Power BI
    Desktop to visualize and evaluate potential features for these ML queries.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will be an adventure into the Power BI cloud service. You will
    migrate your work in Power Query to dataflows and publish your Power BI dataset
    and report to a Power BI workspace. The process of moving these queries is a repetitive
    but necessary step for your end-to-end project, the workshop that runs in parallel
    with this book. An experienced Power BI developer can probably move through this
    chapter quickly by cutting and pasting the M queries from GitHub. By the end of
    this chapter, your content will be fully migrated to the Power BI cloud service
    and ready for Power BI ML.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you’ll need the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: Power BI Desktop April 2023 or later (no licenses required)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FAA Wildlife Strike data files from either the FAA website or the Packt GitHub
    site
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Power BI Pro license
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the following Power BI licensing options for access to Power BI dataflows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Power BI Premium
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Power BI Premium Per User
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the following options for getting data into the Power BI cloud service:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft OneDrive (with connectivity to the Power BI cloud service)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Access and Power BI Gateway
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Data Lake (with connectivity to the Power BI cloud service)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Power BI workspace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start importing content into the Power BI cloud service, you will
    need a **workspace** for the project. A workspace is a way to organize, secure,
    and govern content in the Power BI cloud service. For this project, you need a
    workspace that supports the use of both dataflows and ML, which at the time of
    writing requires either **Power BI Premium** with a **Pro** license or a **Premium
    Per User** license. If you do not have either of these licenses, you can still
    follow along with this book for learning purposes and explore the code samples
    in the Packt GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Workspaces can be extended to include integration with security capabilities,
    information protection, deployment pipelines for life cycle management, and more.
    This book will only cover how to create a basic workspace since extensive documentation
    about workspaces is available online. A tutorial for creating workspaces can be
    found at [https://learn.microsoft.com/en-us/power-bi/collaborate-share/service-create-the-new-workspaces](https://learn.microsoft.com/en-us/power-bi/collaborate-share/service-create-the-new-workspaces).
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to create a new workspace in Power BI:'
  prefs: []
  type: TYPE_NORMAL
- en: Log into the Power BI cloud service by going to [https://app.powerbi.com/](https://app.powerbi.com/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ensure that you have either a Pro or Premium Per User license: [https://powerbi.microsoft.com/en-us/pricing/](https://powerbi.microsoft.com/en-us/pricing/).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will also need to ensure that your Power BI administrators have given you
    access to create workspaces.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the left-hand side vertical pane, select **Workspaces** | **+** **New Workspace**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose a name for your workspace, describe it, and then select either **Premium
    Per User** or **Premium Per Capacity** for the **license** **mode** option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, you are ready to go with a Power BI workspace, which supports reports,
    datasets, dataflows, and ML for your FAA Wildlife Strike data project!
  prefs: []
  type: TYPE_NORMAL
- en: Publishing your Power BI Desktop dataset and report to the Power BI cloud service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, you must import your dataset and report from Power BI Desktop into the
    Power BI cloud service. Once published to the cloud service, you will be able
    to share the analytical report with others who are stakeholders in the project.
    You will also be able to view the reports on the Power BI mobile app if you want
    to dive into the data while on the go.
  prefs: []
  type: TYPE_NORMAL
- en: 'The work that you have done up to this point used Power BI Desktop on your
    local machine. You have two options for migrating this content to the Power BI
    cloud service:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Publish from Power BI Desktop: [https://learn.microsoft.com/en-us/power-bi/create-reports/desktop-upload-desktop-files](https://learn.microsoft.com/en-us/power-bi/create-reports/desktop-upload-desktop-files)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Import the `.pbix` file from the Power BI service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both options are equally simple. For this tutorial, you will import the `.pbix`
    file from the Power BI service.
  prefs: []
  type: TYPE_NORMAL
- en: 'From your newly created Power BI workspace, select `.pbix` file that you have
    created. If you do not use OneDrive, you can also upload from other file locations
    too. Once you’ve uploaded the `.pbix` file, you’ll see that the dataset has been
    separated from the report and that they are now two separate artifacts. Upon clicking
    on the report, you can validate that all the pages can now be browsed in the Power
    BI cloud service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – The FAA Wildlife Strike report can now be browsed in the Power
    BI cloud service](img/B19500_07_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – The FAA Wildlife Strike report can now be browsed in the Power
    BI cloud service
  prefs: []
  type: TYPE_NORMAL
- en: Eventually, you may revisit this report and allow it to be refreshed with new
    data. Since you are working with a snapshot in time of FAA Wildlife Strike data
    for your ML efforts, you do not want to change the data in this report. The data
    in this report needs to reflect the data that you use to train your ML models
    during the initial training and testing phases of the project. That way, you can
    revisit this report to explore or validate the exact data used for ML.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Power BI dataflows with connections to source data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Power BI Desktop Power Query work from previous chapters is connected to
    data sources from your local machine. Power BI dataflows is a very similar tool
    to Power Query, but connectivity happens from the Power BI cloud service. When
    creating your dataflows, you will need to consider connectivity to the data sources.
    Earlier in this book, you determined that the sources of data for the FAA Wildlife
    Strike database were as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`wildlife.accdb`: All of the historical FAA Wildlife Strike reports. This file
    is an Access database that’s been downloaded in ZIP file format from the FAA website.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`read_me.xls`: Descriptive information about the data in the `Database.accdb`
    database file. This file is an Excel file that was downloaded within the same
    ZIP file as the Access database. The file has been changed to a `.xlsx` extension
    in the Packt GitHub repository and is available in the folder at [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-01](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-01).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Date`: For this project, the Date table will be created using custom M code
    in Power Query and dataflows. The code is named `12 Date Table .M` and is available
    on the Packt GitHub site in the folder at [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When using Power Query in Power BI Desktop, you created groups of queries to
    organize your project. Raw Data, Curated Reporting Queries, Curated Dataset Tables,
    and ML Queries were logical groupings based on the intended use of the queries
    within. With Power BI dataflows, you can break these down into smaller groups
    of queries so that you can monitor them, troubleshoot issues, and keep the logic
    in bitesize chunks. Your dataflows will have an architecture that looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 7.2 – The logic from Power Query will be migrated to four Power BI\
    \ \uFEFFdataflows](img/B19500_07_002.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – The logic from Power Query will be migrated to four Power BI dataflows
  prefs: []
  type: TYPE_NORMAL
- en: You will start by creating **Dataflow 1**, which will bring the reference data
    into the Power BI cloud service.
  prefs: []
  type: TYPE_NORMAL
- en: Dataflow 1 – reference data from the read_me.xls file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You must start your adventure with Power BI dataflows using the data contained
    within the `read_me.xlsx` file, which contains descriptive information about the
    reported data from the FAA Wildlife Strike database. First, you will need to decide
    how to connect to the `read_me.xlsx` file. You have many options, including, but
    not limited to, the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Store the file in OneDrive and connect from Power BI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Store the file in SharePoint Online and connect from Power BI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connect to the file using a Power BI Gateway to your local machine or another
    storage location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Store the file in an Azure Data Lake and connect from Power BI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can find extensive documentation about all of these approaches with simple
    online searches. For the example in this book, we will be using OneDrive since
    it is simple and requires minimal configuration. Follow these steps to get started:'
  prefs: []
  type: TYPE_NORMAL
- en: From your newly created Power BI workspace, from the ribbon, select **New**
    | **Dataflow**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Define new tables** | **Add** **new tables**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **Excel Workbook**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select `read_me.xlsx` file. This file was copied from the following folder
    location on the Packt GitHub site: [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-01](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-01).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Select**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next** to proceed to table selection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select `Aircraft Type`, `Engine Codes`, and `Engine Position`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Transform Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Your browser should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Dataflows displaying three tables from the read_me.xls file](img/B19500_07_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Dataflows displaying three tables from the read_me.xls file
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can begin migrating the logic from Power Query to dataflows. Rather
    than replicate the steps from previous chapters in this book, **M scripts** that
    can be copied from the Packt GitHub site can be found at [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07).
    M scripts are the code created by the Power Query SaaS interface, which can be
    pasted into the **Advanced editor** area or Power Query or dataflows.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can cut and paste these scripts into dataflows to save time. The following
    is an example for the first query, **Engine Codes**:'
  prefs: []
  type: TYPE_NORMAL
- en: Copy the **01 Raw Data - Engine Codes.M** M code from the GitHub repository
    folder at [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click on the **Engine Codes** query in your new dataflow and select **Advanced
    editor**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Paste the M code into the `YOUR_ONEDRIVE_URL` in the M code to reflect your
    OneDrive URL. The **Advanced editor** area should look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 7.4 – Code pasted into your \uFEFFdataflow query](img/B19500_07_004.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – Code pasted into your dataflow query
  prefs: []
  type: TYPE_NORMAL
- en: 'For clarity, *Figure 7**.4* has also been enlarged and presented as two images.
    *Figure 7**.5* shows the left side of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 7.5 – Code pasted into your \uFEFFdataflow query](img/B19500_07_005.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – Code pasted into your dataflow query
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7**.6* shows the right side of the code.'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 7.6 – Code pasted into your \uFEFFdataflow query](img/B19500_07_006.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 – Code pasted into your dataflow query
  prefs: []
  type: TYPE_NORMAL
- en: 'Click **OK**; your query should look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.7 – The Engine Codes query with applied steps](img/B19500_07_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 – The Engine Codes query with applied steps
  prefs: []
  type: TYPE_NORMAL
- en: Notice that these additional steps make some changes to the data formatting.
    These additional steps of cleanup are unique to the Engine Codes query due to
    some formatting issues with the Excel file. In a perfect architecture, the Raw
    Data queries would not have any transformations or formatting changes. Since you
    are working with real data in the real world, this compromise was necessary in
    this particular instance.
  prefs: []
  type: TYPE_NORMAL
- en: The queries for `text` for **Data Type**. In the same GitHub folder, you can
    also get M code for the **02 Raw Data - Aircraft Type.M** and **03 Raw Data –
    Engine** **Position.M** queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now add the queries for `Chapter-07` folder of the GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '`04 Raw Data – Engine Codes` `Added Data.M`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`05 Raw Data – Aircraft Type` `Added Data.M`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`06 Raw Data – Engine Position` `Added Data.M`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Right-click in the `Raw Data`, and add all six of the queries you created.
    Your dataflow should now look like this in your browser:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 7.8 – Queries in the Raw Data group of a \uFEFFdataflow](img/B19500_07_008.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 – Queries in the Raw Data group of a dataflow
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, create a new group in the dataflow named **Curated Reporting Queries**.
    You need to add three new queries to this group for **Aircraft Type Info**, **Engine
    Codes Info**, and **Engine Position Info**. To do this in the dataflow, select
    **Get data** | **Blank query**. Paste the corresponding M code into the **Connect
    to data** source window for the new blank query. The M code can be found in the
    Packt GitHub folder at [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07).
    The following example shows the M code for **Aircraft** **Type Info**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.9 – M code for Aircraft Type Info](img/B19500_07_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 – M code for Aircraft Type Info
  prefs: []
  type: TYPE_NORMAL
- en: 'After selecting **Next**, validate that the dataflows query works and looks
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.10 – New query for Aircraft Type Info in the Curated Reporting Queries
    group](img/B19500_07_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 – New query for Aircraft Type Info in the Curated Reporting Queries
    group
  prefs: []
  type: TYPE_NORMAL
- en: 'Repeat the same process for the **Engine Codes Info** and **Engine Position
    Info** queries and ensure that all three queries are in the new **Curated Reporting
    Queries** group. The M code for all three queries are named as follows on the
    Packt GitHub site:'
  prefs: []
  type: TYPE_NORMAL
- en: '`07 Curated Data - Aircraft` `Type Info.M`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`08 Curated Data – Engine` `Codes Info.M`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`09 Curated Data - Engine` `Position Info.M`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once completed, **Save & close** your dataflow and name it **Reference Data**.
    Your first dataflow is complete!
  prefs: []
  type: TYPE_NORMAL
- en: Dataflow 2 – Wildlife Strike data from the database.accdb file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, you can move on to the second dataflow, which will bring in the report-level
    data for the FAA Wildlife Strike database. The `database.accdb` file contains
    incident-level data from the FAA Wildlife Strike database. The file is in a Microsoft
    Access database format. Official documentation for connecting to an Access database
    can be found at [https://learn.microsoft.com/en-us/power-query/connectors/accessdatabase](https://learn.microsoft.com/en-us/power-query/connectors/accessdatabase).
    You have a few options, including, but not limited to, the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Connect to the Access file using a Power BI Gateway.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use an ELT/ETL tool such as Azure Data Factory to extract the data from the
    Access file and drop it in a Data Lake or database: [https://learn.microsoft.com/en-us/azure/data-factory/connector-microsoft-access?tabs=data-factory](https://learn.microsoft.com/en-us/azure/data-factory/connector-microsoft-access?tabs=data-factory).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Export the data to a flat file from the Access database and use the extracted
    file as your source.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For this book, the data will be exported from Access to a flat text file. If
    you do not have Microsoft Access, you can also download the extract from the Packt
    GitHub site at [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you must extract the data from Access to a text file:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `wildlife.accdb` file using Microsoft Access.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click on the **STRIKE_REPORTS** table and select **Export** | **Text File**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose a destination for storing the text file, such as OneDrive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s a screenshot of the export process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.11 – Exporting to a text file from Microsoft Access](img/B19500_07_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 – Exporting to a text file from Microsoft Access
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you can create a dataflow named Strike Reports by following similar steps
    that you followed for your dataflow for Reference Data:'
  prefs: []
  type: TYPE_NORMAL
- en: From your newly created Power BI workspace, from the ribbon, select **New**
    | **Dataflow**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Define new tables** | **Add** **new tables**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose **Text/CSV**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select `STRIKE_REPORTS.txt` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Select**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next** to move to the next screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Transform Data**. to bring the table into the editing view.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Depending on the source, dataflows might automatically change some of the data
    types. For the Raw Data layer, keep the text file unformatted by removing the
    **Changed column** **type** step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.12 – Automatic column type changes are not needed in the Raw Data
    layer](img/B19500_07_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.12 – Automatic column type changes are not needed in the Raw Data layer
  prefs: []
  type: TYPE_NORMAL
- en: Next, create two new groups in the dataflow for **Raw Data** and **Curated Reporting
    Queries**. Name the new query that you created **Strike Reports** and move it
    to the **Raw** **Data** group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The curated version of **Strike Reports** includes a join to the **Engine Codes
    Info** query so that a primary key value can be added to **Strike Reports** that
    references **Engine Codes Info**. To reference **Engine Codes Info** from your
    new dataflow, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click **Get data** | **Dataflows**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand **Workspaces**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand your Power BI workspace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand the **Reference** **Data** dataflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check **Engine Codes Info** and click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Move the **Engine Codes Info** query to **Curated Reporting Queries**, and
    then right-click it and unselect **Load**. Your browser screen should look like
    this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 7.13 – Engine Codes Info can be referenced in the \uFEFFdataflow](img/B19500_07_013.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 – Engine Codes Info can be referenced in the dataflow
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you can add the M code for the curated version of Strike Reports. The
    M code is available on the Packt GitHub site and has also been included here:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Get data** | **Blank query**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste in the `11 Curated Data - Strike Reports Info.M` M code from the folder
    at [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07)
    and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the query **Strike** **Reports Curated**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move it to the **Curated Reporting** **Queries** group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you’ve validated that all of the data appears as it does in Power BI Desktop,
    you can **Save & close** the dataflow, name the dataflow **Strike Reports**, and
    then refresh it! You’re now ready to move on to your third dataflow, which will
    be a Date table.
  prefs: []
  type: TYPE_NORMAL
- en: Dataflow 3 – the Date table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creating a separate dataflow for your Date table may seem unnecessary from
    the perspective of this individual project, but it will allow you to reuse the
    Date table with other future projects. Follow these steps to create a **Date table**
    dataflow that begins on January 1, 1990 (the first year of FAA Wildlife Strike
    data) and runs through 2024:'
  prefs: []
  type: TYPE_NORMAL
- en: From your newly created Power BI workspace, from the ribbon, select **New**
    | **Dataflow**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Define new tables** | **Add** **new tables**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Blank query**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste in the **12 Date Table.M** M code, which can be found on the Packt GitHub
    site at [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the query **Date**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Save &** **close**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name your new dataflow **Date Table**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Refresh the dataflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, you are ready to pull everything you’ve created together for your fourth
    dataflow, which will contain the data for populating a Power BI dataset!
  prefs: []
  type: TYPE_NORMAL
- en: Dataflow 4 – data to populate a Power BI dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Your fourth dataflow will combine all of the queries that you’ve created and
    organize them in a single place so that they can be used with a Power BI dataset.
    You won’t be making any transformations to the source tables, but having a separate
    dataflow gives you the flexibility to add new transformations if needed without
    impacting queries that will also be used to populate ML queries in the next chapter.
    Creating this dataflow should be straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: From your newly created Power BI workspace, from the ribbon, select **New**
    | **Dataflow**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Define new tables** | **Link tables from** **other dataflows**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sign in and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand your workspace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand the **Date Table** dataflow and check **Date**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand the **Strike Reports** dataflow and check **Strike** **Reports Curated**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand the **Reference Data** dataflow and check **Aircraft Type Info**, **Engine
    Codes Info**, and **Engine** **Position Info**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Transform Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the queries **Date**, **Strike Reports**, **Aircraft Type**, **Engine
    Codes**, and **Engine Position**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Save &** **close**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name the dataflow **FAA Wildlife Strike** **Dataset Tables**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save and refresh the dataflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With that, you’ve migrated your primary ingestion and transformation queries
    from Power BI Desktop to dataflows in the Power BI service. Later in this project,
    you can circle back to redirect your Power BI dataset to the new FAA Wildlife
    Strike dataset tables. For now, you have what you need to start building out your
    ML queries in Power BI dataflows. These will be used to train and test your Power
    BI ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a dataflow for ML queries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you’ve ingested, cleaned up, and transformed the data from the FAA
    Wildlife Strike database, you can build out your specialized queries for Power
    BI ML models. Before you get started, note that Power BI ML is a version of Azure
    AutoML that has been built into Power BI as a SaaS offering. Data science teams
    using advanced tools will often apply transformations to data, such as imputing
    missing values, normalizing numeric ranges, and weighting features within a model.
    The advanced transformations of features won’t be covered in this book since AutoML
    has featurization capabilities to optimize data for ML. The queries you will be
    creating could probably be improved upon with advanced featurization techniques,
    but for this project, we will keep things simple and let the AutoML featurization
    capabilities in Power BI ML handle some of the advanced feature transformations.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the Predict Damage ML query to a dataflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You will now create a fifth dataflow that contains the logic for the ML queries.
    The expanded architecture will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.14 – ML Queries added to a Power BI dataflow](img/B19500_07_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.14 – ML Queries added to a Power BI dataflow
  prefs: []
  type: TYPE_NORMAL
- en: 'You will start by migrating the Predict Damage ML query you created in Power
    Query to a new dataflow:'
  prefs: []
  type: TYPE_NORMAL
- en: From your newly created Power BI workspace, from the ribbon, select **New**
    | **Dataflow**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Define new tables |** **Link tables from other dataflows** | **Add**
    **linked tables**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sign in and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand your workspace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Expand the **Strike Reports** dataflow and check **Strike** **Reports Curated**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Transform Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a group named **Sources** and move **Strike Reports Curated** into that
    group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click **Strike Reports Curated** and unselect **Enable load**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, you must add a new query for **Predict Damage** that has been built using
    the **Strike Reports** **Curated** query:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Get data** | **Blank query**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste in the **13 Predict Damage.M** M code. This can be found on the Packt
    GitHub site at [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the query **Predict Damage**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new group named **ML Queries** and move **Predict Damage** to that
    group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Your dataflow should now look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 7.15 – The Predict Damage query added to Power BI \uFEFFdataflows](img/B19500_07_015.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.15 – The Predict Damage query added to Power BI dataflows
  prefs: []
  type: TYPE_NORMAL
- en: Before you move on to the next query, save and process your dataflow to ensure
    that you do not lose your work.
  prefs: []
  type: TYPE_NORMAL
- en: Click **Save &** **close**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name your new dataflow **ML Queries**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Refresh the dataflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, you are ready to add another ML query to your dataflow!
  prefs: []
  type: TYPE_NORMAL
- en: Adding the Predict Size ML query to a dataflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **Predict Size** ML query that you created in Power Query for Power BI
    can also be added to the **ML Queries** dataflow you created. Open the **Edit
    tables** view for the dataflow and proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Get data** | **Blank query**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Paste in the **14 Predict Size.M** M code. This can be found on the Packt GitHub
    site for the **Predict Size** query: [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the query **Predict Size**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move **Predict Size** to the **ML** **Queries** group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you’ve validated that the data previews correctly, you can **Save & close**
    the dataflow to ensure that you don’t lose your work. Now, you are ready to add
    your third ML query for predicting height!
  prefs: []
  type: TYPE_NORMAL
- en: Adding the Predict Height ML query to a dataflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, you must add a query for predicting height to the ML Queries dataflow.
    The query can be added similarly to the other two queries:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Get data** | **Blank query**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Paste in the **15 Predict Height.M** M code. This can be found on the Packt
    GitHub site for the **Predict Height** query: [https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07](https://github.com/PacktPublishing/Unleashing-Your-Data-with-Power-BI-Machine-Learning-and-OpenAI/tree/main/Chapter-07).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename the query **Predict Height**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move **Predict Height** to the **ML** **Queries** group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once your query has been added, your dataflow should look as follows in your
    browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.16 – All three ML queries have been added to a dataflow](img/B19500_07_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.16 – All three ML queries have been added to a dataflow
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can **Save & close** your dataflow, and then refresh it in the Power
    BI cloud service. With that, you are ready to move on to ML in Power BI!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you migrated queries from Power BI Desktop Power Query to dataflows
    in the Power BI cloud service. These queries ingest, prep, and create tables designed
    for your Power BI dataset. Then, you migrated your ML queries from Power Query
    for Power BI Desktop to dataflows in the Power BI cloud service. In doing so,
    you created a new dataflow that is populated by the dataflows you created in the
    previous chapter. The new ML Queries dataflow was saved and refreshed in your
    Power BI workspace.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 8*](B19500_08.xhtml#_idTextAnchor118), you will begin working with
    Power BI ML in the cloud. You will use the three ML queries you created here to
    build and test the Binary Prediction, Categorical, and Regression ML models in
    Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 3: Machine Learning in Power BI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, you will build an ML model in Power BI, evaluate the model, and
    then configure it to work with new and updated data.
  prefs: []
  type: TYPE_NORMAL
- en: 'This process will be covered in the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B19500_08.xhtml#_idTextAnchor118), *Building Machine Learning
    Models with Power BI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B19500_09.xhtml#_idTextAnchor125), *Evaluating Trained and Tested
    ML Models*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B19500_10.xhtml#_idTextAnchor139), *Iterating Power BI Machine
    Learning Models*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B19500_11.xhtml#_idTextAnchor152), *Applying Power BI Machine
    Learning Models*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
