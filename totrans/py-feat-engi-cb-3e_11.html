<html><head></head><body>
<div id="_idContainer205">
<h1 class="chapter-number" id="_idParaDest-297"><a id="_idTextAnchor1459"/><span class="koboSpan" id="kobo.1.1" xmlns:="http://www.w3.org/1999/xhtml">11</span></h1>
<h1 id="_idParaDest-298"><a id="_idTextAnchor1460"/><a id="_idTextAnchor1461"/><span class="koboSpan" id="kobo.2.1" xmlns:="http://www.w3.org/1999/xhtml">Extracting Features from Text Variables</span></h1>
<p><span class="koboSpan" id="kobo.3.1" xmlns:="http://www.w3.org/1999/xhtml">Text can be one of the variables in our datasets. </span><span class="koboSpan" id="kobo.3.2" xmlns:="http://www.w3.org/1999/xhtml">For example, in insurance, information describing the circumstances of an incident can come from free text fields in a form. </span><span class="koboSpan" id="kobo.3.3" xmlns:="http://www.w3.org/1999/xhtml">If a company gathers customer reviews, this information will be collected as short pieces of text provided by the users. </span><span class="koboSpan" id="kobo.3.4" xmlns:="http://www.w3.org/1999/xhtml">Text data does not show</span><a id="_idIndexMarker827"/><span class="koboSpan" id="kobo.4.1" xmlns:="http://www.w3.org/1999/xhtml"> the </span><strong class="bold"><span class="koboSpan" id="kobo.5.1" xmlns:="http://www.w3.org/1999/xhtml">tabular</span></strong><span class="koboSpan" id="kobo.6.1" xmlns:="http://www.w3.org/1999/xhtml"> pattern of the datasets that we have worked with throughout this book. </span><span class="koboSpan" id="kobo.6.2" xmlns:="http://www.w3.org/1999/xhtml">Instead, information in texts can vary in length and content, as well as writing style. </span><span class="koboSpan" id="kobo.6.3" xmlns:="http://www.w3.org/1999/xhtml">We can extract a lot of information from text variables to use as predictive features in machine learning models. </span><span class="koboSpan" id="kobo.6.4" xmlns:="http://www.w3.org/1999/xhtml">The techniques we will cover in this chapter belong to the realm of </span><strong class="bold"><span class="koboSpan" id="kobo.7.1" xmlns:="http://www.w3.org/1999/xhtml">Natural Language Processing</span></strong><span class="koboSpan" id="kobo.8.1" xmlns:="http://www.w3.org/1999/xhtml"> (</span><strong class="bold"><span class="koboSpan" id="kobo.9.1" xmlns:="http://www.w3.org/1999/xhtml">NLP</span></strong><span class="koboSpan" id="kobo.10.1" xmlns:="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.10.2" xmlns:="http://www.w3.org/1999/xhtml">NLP is a subfield of linguistics and computer science. </span><span class="koboSpan" id="kobo.10.3" xmlns:="http://www.w3.org/1999/xhtml">It is</span><a id="_idIndexMarker828"/><span class="koboSpan" id="kobo.11.1" xmlns:="http://www.w3.org/1999/xhtml"> concerned with the interactions between computer and human language, or, in other words, how to program computers to understand human language. </span><span class="koboSpan" id="kobo.11.2" xmlns:="http://www.w3.org/1999/xhtml">NLP includes a multitude of techniques to understand the syntax, semantics, and discourse of text. </span><span class="koboSpan" id="kobo.11.3" xmlns:="http://www.w3.org/1999/xhtml">Therefore, to do this field justice would require an </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1" xmlns:="http://www.w3.org/1999/xhtml">entire book.</span></span></p>
<p><span class="koboSpan" id="kobo.13.1" xmlns:="http://www.w3.org/1999/xhtml">In this chapter, we will discuss the methods that will allow us to quickly extract features from short pieces of text to complement our predictive models. </span><span class="koboSpan" id="kobo.13.2" xmlns:="http://www.w3.org/1999/xhtml">Specifically, we will discuss how to capture a piece of text’s complexity by looking at some statistical parameters of the text, such as the word length and count, the number of words and unique words used, the number of sentences, and so on. </span><span class="koboSpan" id="kobo.13.3" xmlns:="http://www.w3.org/1999/xhtml">We will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.14.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.15.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.16.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.17.1" xmlns:="http://www.w3.org/1999/xhtml"> libraries, and we will make a shallow dive into a very useful Python NLP toolkit</span><a id="_idIndexMarker829"/><span class="koboSpan" id="kobo.18.1" xmlns:="http://www.w3.org/1999/xhtml"> called the </span><strong class="bold"><span class="koboSpan" id="kobo.19.1" xmlns:="http://www.w3.org/1999/xhtml">Natural Language </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.20.1" xmlns:="http://www.w3.org/1999/xhtml">Toolkit</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.21.1" xmlns:="http://www.w3.org/1999/xhtml"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.22.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.23.1" xmlns:="http://www.w3.org/1999/xhtml">).</span></span></p>
<p><span class="koboSpan" id="kobo.24.1" xmlns:="http://www.w3.org/1999/xhtml">This chapter includes the </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1" xmlns:="http://www.w3.org/1999/xhtml">following recipes:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.26.1" xmlns:="http://www.w3.org/1999/xhtml">Counting characters, words, </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1" xmlns:="http://www.w3.org/1999/xhtml">and vocabulary</span></span></li>
<li><span class="koboSpan" id="kobo.28.1" xmlns:="http://www.w3.org/1999/xhtml">Estimating text complexity by </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1" xmlns:="http://www.w3.org/1999/xhtml">counting sentences</span></span></li>
<li><span class="koboSpan" id="kobo.30.1" xmlns:="http://www.w3.org/1999/xhtml">Creating features with bag-of-words </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1" xmlns:="http://www.w3.org/1999/xhtml">and n-grams</span></span></li>
<li><span class="koboSpan" id="kobo.32.1" xmlns:="http://www.w3.org/1999/xhtml">Implementing term frequency-inverse </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1" xmlns:="http://www.w3.org/1999/xhtml">document frequency</span></span></li>
<li><span class="koboSpan" id="kobo.34.1" xmlns:="http://www.w3.org/1999/xhtml">Cleaning and stemming </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1" xmlns:="http://www.w3.org/1999/xhtml">text variabl</span><a id="_idTextAnchor1462"/><a id="_idTextAnchor1463"/><span class="koboSpan" id="kobo.36.1" xmlns:="http://www.w3.org/1999/xhtml">es</span></span></li>
</ul>
<h1 id="_idParaDest-299"><a id="_idTextAnchor1464"/><span class="koboSpan" id="kobo.37.1" xmlns:="http://www.w3.org/1999/xhtml">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.38.1" xmlns:="http://www.w3.org/1999/xhtml">In this chapter, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.39.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.40.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.41.1" xmlns:="http://www.w3.org/1999/xhtml">matplotlib</span></strong><span class="koboSpan" id="kobo.42.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.43.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.44.1" xmlns:="http://www.w3.org/1999/xhtml"> Python libraries. </span><span class="koboSpan" id="kobo.44.2" xmlns:="http://www.w3.org/1999/xhtml">We will also use </span><strong class="source-inline"><span class="koboSpan" id="kobo.45.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.46.1" xmlns:="http://www.w3.org/1999/xhtml">, a comprehensive Python library for NLP and text analysis. </span><span class="koboSpan" id="kobo.46.2" xmlns:="http://www.w3.org/1999/xhtml">You can find the instructions to install </span><strong class="source-inline"><span class="koboSpan" id="kobo.47.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.48.1" xmlns:="http://www.w3.org/1999/xhtml">at </span></span><a href="http://www.nltk.org/install.html"><span class="No-Break"><span class="koboSpan" id="kobo.49.1" xmlns:="http://www.w3.org/1999/xhtml">http://www.nltk.org/install.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.50.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.51.1" xmlns:="http://www.w3.org/1999/xhtml">If you are using the Python Anaconda distribution, follow the instructions to install </span><strong class="source-inline"><span class="koboSpan" id="kobo.52.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.53.1" xmlns:="http://www.w3.org/1999/xhtml">at </span></span><a href="https://anaconda.org/anaconda/nltk"><span class="No-Break"><span class="koboSpan" id="kobo.54.1" xmlns:="http://www.w3.org/1999/xhtml">https://anaconda.org/anaconda/nltk</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.55.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.56.1" xmlns:="http://www.w3.org/1999/xhtml">After you have installed </span><strong class="source-inline"><span class="koboSpan" id="kobo.57.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.58.1" xmlns:="http://www.w3.org/1999/xhtml">, open up a Python console and execute </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1" xmlns:="http://www.w3.org/1999/xhtml">the following:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.60.1" xmlns:="http://www.w3.org/1999/xhtml">
import nltk
nltk.download('punkt')
nltk.download('stopwords')</span></pre> <p><span class="koboSpan" id="kobo.61.1" xmlns:="http://www.w3.org/1999/xhtml">These commands will download the necessary data for you to be able to run the recipes in this </span><span class="No-Break"><span class="koboSpan" id="kobo.62.1" xmlns:="http://www.w3.org/1999/xhtml">chapter successfully.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.63.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.64.1" xmlns:="http://www.w3.org/1999/xhtml">If you haven’t downloaded these or the other data sources necessary for </span><strong class="source-inline"><span class="koboSpan" id="kobo.65.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.66.1" xmlns:="http://www.w3.org/1999/xhtml"> functionality, </span><strong class="source-inline"><span class="koboSpan" id="kobo.67.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.68.1" xmlns:="http://www.w3.org/1999/xhtml"> will raise an error. </span><span class="koboSpan" id="kobo.68.2" xmlns:="http://www.w3.org/1999/xhtml">Read the error message carefully because it will direct you to download the data required to run the command that you are trying </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1" xmlns:="http://www.w3.org/1999/xhtml">to execut</span><a id="_idTextAnchor1465"/><a id="_idTextAnchor1466"/><span class="koboSpan" id="kobo.70.1" xmlns:="http://www.w3.org/1999/xhtml">e.</span></span></p>
<h1 id="_idParaDest-300"><a id="_idTextAnchor1467"/><span class="koboSpan" id="kobo.71.1" xmlns:="http://www.w3.org/1999/xhtml">Counting characters, words, and vocabulary</span></h1>
<p><span class="koboSpan" id="kobo.72.1" xmlns:="http://www.w3.org/1999/xhtml">One of the </span><a id="_idIndexMarker830"/><span class="koboSpan" id="kobo.73.1" xmlns:="http://www.w3.org/1999/xhtml">sal</span><a id="_idTextAnchor1468"/><span class="koboSpan" id="kobo.74.1" xmlns:="http://www.w3.org/1999/xhtml">ient</span><a id="_idIndexMarker831"/><span class="koboSpan" id="kobo.75.1" xmlns:="http://www.w3.org/1999/xhtml"> characteri</span><a id="_idTextAnchor1469"/><span class="koboSpan" id="kobo.76.1" xmlns:="http://www.w3.org/1999/xhtml">stics of text i</span><a id="_idTextAnchor1470"/><span class="koboSpan" id="kobo.77.1" xmlns:="http://www.w3.org/1999/xhtml">s its </span><a id="_idIndexMarker832"/><span class="koboSpan" id="kobo.78.1" xmlns:="http://www.w3.org/1999/xhtml">complexity. </span><span class="koboSpan" id="kobo.78.2" xmlns:="http://www.w3.org/1999/xhtml">Long descriptions are more likely to contain more information than short descriptions. </span><span class="koboSpan" id="kobo.78.3" xmlns:="http://www.w3.org/1999/xhtml">Texts rich in different, unique words are more likely to be richer in detail than texts that repeat the same words over and over. </span><span class="koboSpan" id="kobo.78.4" xmlns:="http://www.w3.org/1999/xhtml">In the same way, when we speak, we use many short words such as articles and prepositions to build the sentence structure, yet the main concept is often derived from the nouns and adjectives we use, which tend to be longer words. </span><span class="koboSpan" id="kobo.78.5" xmlns:="http://www.w3.org/1999/xhtml">So, as you can see, even without reading the text, we can start inferring how much information the text provides by determining the number of words, the number of unique words (non-repeated occurrences of a word), the lexical diversity, and the length of those words. </span><span class="koboSpan" id="kobo.78.6" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will learn how to extract these features from a text variable </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1" xmlns:="http://www.w3.org/1999/xhtml">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.80.1" xmlns:="http://www.w3.org/1999/xhtml">pa</span><a id="_idTextAnchor1471"/><a id="_idTextAnchor1472"/><span class="koboSpan" id="kobo.81.1" xmlns:="http://www.w3.org/1999/xhtml">ndas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.82.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-301"><a id="_idTextAnchor1473"/><span class="koboSpan" id="kobo.83.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.84.1" xmlns:="http://www.w3.org/1999/xhtml">We are</span><a id="_idTextAnchor1474"/><span class="koboSpan" id="kobo.85.1" xmlns:="http://www.w3.org/1999/xhtml"> going to use the </span><strong class="bold"><span class="koboSpan" id="kobo.86.1" xmlns:="http://www.w3.org/1999/xhtml">20 Newsgroup</span></strong><span class="koboSpan" id="kobo.87.1" xmlns:="http://www.w3.org/1999/xhtml"> datase</span><a id="_idTextAnchor1475"/><span class="koboSpan" id="kobo.88.1" xmlns:="http://www.w3.org/1999/xhtml">t that come</span><a id="_idTextAnchor1476"/><span class="koboSpan" id="kobo.89.1" xmlns:="http://www.w3.org/1999/xhtml">s with </span><strong class="source-inline"><span class="koboSpan" id="kobo.90.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.91.1" xmlns:="http://www.w3.org/1999/xhtml">, which comprises around 18,000 news posts on 20 different topics. </span><span class="koboSpan" id="kobo.91.2" xmlns:="http://www.w3.org/1999/xhtml">More details about this dataset can be found on the </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1" xmlns:="http://www.w3.org/1999/xhtml">following sites:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.93.1" xmlns:="http://www.w3.org/1999/xhtml">The scikit</span><a id="_idTextAnchor1477"/><span class="koboSpan" id="kobo.94.1" xmlns:="http://www.w3.org/1999/xhtml">-learn dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1" xmlns:="http://www.w3.org/1999/xhtml">website: </span></span><a href="https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset"><span class="No-Break"><span class="koboSpan" id="kobo.96.1" xmlns:="http://www.w3.org/1999/xhtml">https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset</span></span></a></li>
<li><span class="koboSpan" id="kobo.97.1" xmlns:="http://www.w3.org/1999/xhtml">The hom</span><a id="_idTextAnchor1478"/><span class="koboSpan" id="kobo.98.1" xmlns:="http://www.w3.org/1999/xhtml">e page for the 20 Newsgroup </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1" xmlns:="http://www.w3.org/1999/xhtml">dataset: </span></span><a href="http://qwone.com/~jason/20Newsgroups/"><span class="No-Break"><span class="koboSpan" id="kobo.100.1" xmlns:="http://www.w3.org/1999/xhtml">http://qwone.com/~jason/20Newsgroups/</span></span></a></li>
</ul>
<p><span class="koboSpan" id="kobo.101.1" xmlns:="http://www.w3.org/1999/xhtml">Before jumping into the recipe, let’s discuss the features that we are going to derive from these </span><a id="_idIndexMarker833"/><span class="koboSpan" id="kobo.102.1" xmlns:="http://www.w3.org/1999/xhtml">text </span><a id="_idIndexMarker834"/><span class="koboSpan" id="kobo.103.1" xmlns:="http://www.w3.org/1999/xhtml">pieces. </span><span class="koboSpan" id="kobo.103.2" xmlns:="http://www.w3.org/1999/xhtml">We mentioned that longer descriptions, more </span><a id="_idIndexMarker835"/><span class="koboSpan" id="kobo.104.1" xmlns:="http://www.w3.org/1999/xhtml">words in the article, a greater variety of unique words, and longer words tend to correlate with the amount of information that the article provides. </span><span class="koboSpan" id="kobo.104.2" xmlns:="http://www.w3.org/1999/xhtml">Hence, we can capture text complexity by extracting the following information about </span><span class="No-Break"><span class="koboSpan" id="kobo.105.1" xmlns:="http://www.w3.org/1999/xhtml">the text:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.106.1" xmlns:="http://www.w3.org/1999/xhtml">The total number </span><span class="No-Break"><span class="koboSpan" id="kobo.107.1" xmlns:="http://www.w3.org/1999/xhtml">of characters</span></span></li>
<li><span class="koboSpan" id="kobo.108.1" xmlns:="http://www.w3.org/1999/xhtml">The total number </span><span class="No-Break"><span class="koboSpan" id="kobo.109.1" xmlns:="http://www.w3.org/1999/xhtml">of words</span></span></li>
<li><span class="koboSpan" id="kobo.110.1" xmlns:="http://www.w3.org/1999/xhtml">The total number of </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1" xmlns:="http://www.w3.org/1999/xhtml">unique words</span></span></li>
<li><span class="koboSpan" id="kobo.112.1" xmlns:="http://www.w3.org/1999/xhtml">Lexical diversity (total number of words divided by number of </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1" xmlns:="http://www.w3.org/1999/xhtml">unique words)</span></span></li>
<li><span class="koboSpan" id="kobo.114.1" xmlns:="http://www.w3.org/1999/xhtml">Word average length (number of characters divided by number </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1" xmlns:="http://www.w3.org/1999/xhtml">of words)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.116.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will extract these numerical features using </span><strong class="source-inline"><span class="koboSpan" id="kobo.117.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.118.1" xmlns:="http://www.w3.org/1999/xhtml">, which has extensive string processing functionalities that can be accessed via the </span><strong class="source-inline"><span class="koboSpan" id="kobo.119.1" xmlns:="http://www.w3.org/1999/xhtml">str</span></strong><span class="koboSpan" id="kobo.120.1" xmlns:="http://www.w3.org/1999/xhtml"> vectorized string functions </span><span class="No-Break"><span class="koboSpan" id="kobo.121.1" xmlns:="http://www.w3.org/1999/xhtml">for</span><a id="_idTextAnchor1479"/><a id="_idTextAnchor1480"/><span class="koboSpan" id="kobo.122.1" xmlns:="http://www.w3.org/1999/xhtml"> series.</span></span></p>
<h2 id="_idParaDest-302"><a id="_idTextAnchor1481"/><span class="koboSpan" id="kobo.123.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.124.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by loading </span><strong class="source-inline"><span class="koboSpan" id="kobo.125.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.126.1" xmlns:="http://www.w3.org/1999/xhtml"> and getting the </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1" xmlns:="http://www.w3.org/1999/xhtml">dataset ready:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.128.1" xmlns:="http://www.w3.org/1999/xhtml">Load </span><strong class="source-inline"><span class="koboSpan" id="kobo.129.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.130.1" xmlns:="http://www.w3.org/1999/xhtml"> and the dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1" xmlns:="http://www.w3.org/1999/xhtml">from </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.132.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.133.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.134.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from sklearn.datasets import fetch_20newsgroups</span></pre></li> <li><span class="koboSpan" id="kobo.135.1" xmlns:="http://www.w3.org/1999/xhtml">L</span><a id="_idTextAnchor1482"/><span class="koboSpan" id="kobo.136.1" xmlns:="http://www.w3.org/1999/xhtml">et’s load </span><a id="_idTextAnchor1483"/><span class="koboSpan" id="kobo.137.1" xmlns:="http://www.w3.org/1999/xhtml">the train set part of the 20 Newsgrou</span><a id="_idTextAnchor1484"/><span class="koboSpan" id="kobo.138.1" xmlns:="http://www.w3.org/1999/xhtml">p dataset into a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.139.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.140.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.141.1" xmlns:="http://www.w3.org/1999/xhtml">
data = fetch_20newsgroups(subset='train')
df = pd.DataFrame(data.data, columns=['text'])</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.142.1" xmlns:="http://www.w3.org/1999/xhtml">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.143.1" xmlns:="http://www.w3.org/1999/xhtml">You can print an example of a text from the DataFrame by executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.144.1" xmlns:="http://www.w3.org/1999/xhtml">print(df['text'][1])</span></strong><span class="koboSpan" id="kobo.145.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.145.2" xmlns:="http://www.w3.org/1999/xhtml">Change the number between </span><strong class="source-inline"><span class="koboSpan" id="kobo.146.1" xmlns:="http://www.w3.org/1999/xhtml">[</span></strong><span class="koboSpan" id="kobo.147.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.148.1" xmlns:="http://www.w3.org/1999/xhtml">]</span></strong><span class="koboSpan" id="kobo.149.1" xmlns:="http://www.w3.org/1999/xhtml"> to display different texts. </span><span class="koboSpan" id="kobo.149.2" xmlns:="http://www.w3.org/1999/xhtml">Note how every text description is a single string composed of letters, numbers, punctuation, and spaces. </span><span class="koboSpan" id="kobo.149.3" xmlns:="http://www.w3.org/1999/xhtml">You can check the datatype by </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1" xmlns:="http://www.w3.org/1999/xhtml">executing </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.151.1" xmlns:="http://www.w3.org/1999/xhtml">type(df["text"][1])</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.152.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.153.1" xmlns:="http://www.w3.org/1999/xhtml">Now </span><a id="_idIndexMarker836"/><span class="koboSpan" id="kobo.154.1" xmlns:="http://www.w3.org/1999/xhtml">that </span><a id="_idIndexMarker837"/><span class="koboSpan" id="kobo.155.1" xmlns:="http://www.w3.org/1999/xhtml">we </span><a id="_idIndexMarker838"/><span class="koboSpan" id="kobo.156.1" xmlns:="http://www.w3.org/1999/xhtml">have the text variable in a </span><strong class="source-inline"><span class="koboSpan" id="kobo.157.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.158.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame, we are ready to extract </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1" xmlns:="http://www.w3.org/1999/xhtml">the features.</span></span></p>
<ol>
<li value="3"><span class="koboSpan" id="kobo.160.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s capture the number of characters in each text piece in a </span><span class="No-Break"><span class="koboSpan" id="kobo.161.1" xmlns:="http://www.w3.org/1999/xhtml">new column:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.162.1" xmlns:="http://www.w3.org/1999/xhtml">
df['num_char'] = df['text'].str.len()</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.163.1" xmlns:="http://www.w3.org/1999/xhtml">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.164.1" xmlns:="http://www.w3.org/1999/xhtml">You can remove trailing white spaces in a string, including those from new lines, before counting the number of characters by adding the </span><strong class="source-inline"><span class="koboSpan" id="kobo.165.1" xmlns:="http://www.w3.org/1999/xhtml">strip()</span></strong><span class="koboSpan" id="kobo.166.1" xmlns:="http://www.w3.org/1999/xhtml"> method before the </span><strong class="source-inline"><span class="koboSpan" id="kobo.167.1" xmlns:="http://www.w3.org/1999/xhtml">len()</span></strong><span class="koboSpan" id="kobo.168.1" xmlns:="http://www.w3.org/1999/xhtml"> method, as shown here: </span><strong class="source-inline"><span class="koboSpan" id="kobo.169.1" xmlns:="http://www.w3.org/1999/xhtml">df['num_char'] = </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.170.1" xmlns:="http://www.w3.org/1999/xhtml">df['text'].str.strip().str.len()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.171.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.172.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s capture the number of words in each text in a </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1" xmlns:="http://www.w3.org/1999/xhtml">new column:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.174.1" xmlns:="http://www.w3.org/1999/xhtml">
df['num_words'] = df['text'].str.split().str.len()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.175.1" xmlns:="http://www.w3.org/1999/xhtml">To count words, we use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.176.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.177.1" xmlns:="http://www.w3.org/1999/xhtml"> library’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.178.1" xmlns:="http://www.w3.org/1999/xhtml">split()</span></strong><span class="koboSpan" id="kobo.179.1" xmlns:="http://www.w3.org/1999/xhtml"> method, which splits a text at white spaces. </span><span class="koboSpan" id="kobo.179.2" xmlns:="http://www.w3.org/1999/xhtml">Check out the output of </span><strong class="source-inline"><span class="koboSpan" id="kobo.180.1" xmlns:="http://www.w3.org/1999/xhtml">split()</span></strong><span class="koboSpan" id="kobo.181.1" xmlns:="http://www.w3.org/1999/xhtml"> by executing, for instance, </span><strong class="source-inline"><span class="koboSpan" id="kobo.182.1" xmlns:="http://www.w3.org/1999/xhtml">df["text"].loc[1].split()</span></strong><span class="koboSpan" id="kobo.183.1" xmlns:="http://www.w3.org/1999/xhtml"> to separate the words of the second text of </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1" xmlns:="http://www.w3.org/1999/xhtml">the DataFrame.</span></span></p></li> <li><span class="koboSpan" id="kobo.185.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s capture the number of </span><em class="italic"><span class="koboSpan" id="kobo.186.1" xmlns:="http://www.w3.org/1999/xhtml">unique</span></em><span class="koboSpan" id="kobo.187.1" xmlns:="http://www.w3.org/1999/xhtml"> words in each text in a </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1" xmlns:="http://www.w3.org/1999/xhtml">new column:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.189.1" xmlns:="http://www.w3.org/1999/xhtml">
df['num_vocab']df[
    'text'].str.lower().str.split().apply(
        set).str.len()</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.190.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.191.1" xmlns:="http://www.w3.org/1999/xhtml">Python interprets the same word as two different words if one has a capital letter. </span><span class="koboSpan" id="kobo.191.2" xmlns:="http://www.w3.org/1999/xhtml">To avoid this behavior, we can apply the </span><strong class="source-inline"><span class="koboSpan" id="kobo.192.1" xmlns:="http://www.w3.org/1999/xhtml">lower()</span></strong><span class="koboSpan" id="kobo.193.1" xmlns:="http://www.w3.org/1999/xhtml"> method before the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.194.1" xmlns:="http://www.w3.org/1999/xhtml">split()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.195.1" xmlns:="http://www.w3.org/1999/xhtml"> method.</span></span></p>
<ol>
<li value="6"><a id="_idTextAnchor1485"/><span class="koboSpan" id="kobo.196.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create</span><a id="_idIndexMarker839"/><span class="koboSpan" id="kobo.197.1" xmlns:="http://www.w3.org/1999/xhtml"> a </span><a id="_idIndexMarker840"/><span class="koboSpan" id="kobo.198.1" xmlns:="http://www.w3.org/1999/xhtml">feature that captures </span><a id="_idIndexMarker841"/><span class="koboSpan" id="kobo.199.1" xmlns:="http://www.w3.org/1999/xhtml">the lexical diversity – that is, t</span><a id="_idTextAnchor1486"/><span class="koboSpan" id="kobo.200.1" xmlns:="http://www.w3.org/1999/xhtml">he total number of words (</span><em class="italic"><span class="koboSpan" id="kobo.201.1" xmlns:="http://www.w3.org/1999/xhtml">step</span><a id="_idTextAnchor1487"/><span class="koboSpan" id="kobo.202.1" xmlns:="http://www.w3.org/1999/xhtml"> 4</span></em><span class="koboSpan" id="kobo.203.1" xmlns:="http://www.w3.org/1999/xhtml">) compare</span><a id="_idTextAnchor1488"/><span class="koboSpan" id="kobo.204.1" xmlns:="http://www.w3.org/1999/xhtml">d to the number of unique words (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.205.1" xmlns:="http://www.w3.org/1999/xhtml">step 5</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.206.1" xmlns:="http://www.w3.org/1999/xhtml">):</span></span><pre class="source-code"><span class="koboSpan" id="kobo.207.1" xmlns:="http://www.w3.org/1999/xhtml">
df['lexical_div'] = df['num_words'] / df['num_vocab']</span></pre></li> <li><span class="koboSpan" id="kobo.208.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s calculate the average word length by dividing the number of characters (</span><em class="italic"><span class="koboSpan" id="kobo.209.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.210.1" xmlns:="http://www.w3.org/1999/xhtml">) by the number of words (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.211.1" xmlns:="http://www.w3.org/1999/xhtml">step 4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.212.1" xmlns:="http://www.w3.org/1999/xhtml">):</span></span><pre class="source-code"><span class="koboSpan" id="kobo.213.1" xmlns:="http://www.w3.org/1999/xhtml">
df['ave_word_length'] = df[
    'num_char'] / df['num_words']</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.214.1" xmlns:="http://www.w3.org/1999/xhtml">If we execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.215.1" xmlns:="http://www.w3.org/1999/xhtml">df.head()</span></strong><span class="koboSpan" id="kobo.216.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the first five rows of data with the text and the newly </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1" xmlns:="http://www.w3.org/1999/xhtml">crea</span><a id="_idTextAnchor1489"/><span class="koboSpan" id="kobo.218.1" xmlns:="http://www.w3.org/1999/xhtml">ted features:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer196">
<span class="koboSpan" id="kobo.219.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 11.1 – A DataFrame with the text variable and features that summarize some of the text’s characteristics" src="image/B22396_11_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.220.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 11.1 – A DataFrame with the text variable and features that summarize some of the text’s characteristics</span></p>
<p><span class="koboSpan" id="kobo.221.1" xmlns:="http://www.w3.org/1999/xhtml">With that, we have extracted five different features that capture the text complexity, which we can use </span><a id="_idIndexMarker842"/><span class="koboSpan" id="kobo.222.1" xmlns:="http://www.w3.org/1999/xhtml">as </span><a id="_idIndexMarker843"/><span class="koboSpan" id="kobo.223.1" xmlns:="http://www.w3.org/1999/xhtml">inputs for our machine </span><span class="No-Break"><span class="koboSpan" id="kobo.224.1" xmlns:="http://www.w3.org/1999/xhtml">learning </span></span><span class="No-Break"><a id="_idIndexMarker844"/></span><span class="No-Break"><span class="koboSpan" id="kobo.225.1" xmlns:="http://www.w3.org/1999/xhtml">algorithms.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.226.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.227.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we created new features from the raw data straight away without doing any data cleaning, removing punctuation, or even stemming words. </span><span class="koboSpan" id="kobo.227.2" xmlns:="http://www.w3.org/1999/xhtml">Note that these are steps that are performed ahead of most standard NLP procedures. </span><span class="koboSpan" id="kobo.227.3" xmlns:="http://www.w3.org/1999/xhtml">To learn more about this, visit the </span><em class="italic"><span class="koboSpan" id="kobo.228.1" xmlns:="http://www.w3.org/1999/xhtml">Cleaning and stemming text variables</span></em><span class="koboSpan" id="kobo.229.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe at the end </span><a id="_idTextAnchor1490"/><a id="_idTextAnchor1491"/><span class="koboSpan" id="kobo.230.1" xmlns:="http://www.w3.org/1999/xhtml">of </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1" xmlns:="http://www.w3.org/1999/xhtml">this chapter.</span></span></p>
<h2 id="_idParaDest-303"><span class="koboSpan" id="kobo.232.1" xmlns:="http://www.w3.org/1999/xhtml">How it</span><a id="_idTextAnchor1492"/><span class="koboSpan" id="kobo.233.1" xmlns:="http://www.w3.org/1999/xhtml"> works...</span></h2>
<p><span class="koboSpan" id="kobo.234.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we created </span><a id="_idTextAnchor1493"/><span class="koboSpan" id="kobo.235.1" xmlns:="http://www.w3.org/1999/xhtml">five new features that captur</span><a id="_idTextAnchor1494"/><span class="koboSpan" id="kobo.236.1" xmlns:="http://www.w3.org/1999/xhtml">e text complexity by utilizing pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.237.1" xmlns:="http://www.w3.org/1999/xhtml">str</span></strong><span class="koboSpan" id="kobo.238.1" xmlns:="http://www.w3.org/1999/xhtml"> to access the built-in </span><strong class="source-inline"><span class="koboSpan" id="kobo.239.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.240.1" xmlns:="http://www.w3.org/1999/xhtml"> functionality to work with strings. </span><span class="koboSpan" id="kobo.240.2" xmlns:="http://www.w3.org/1999/xhtml">We worked with the text column of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.241.1" xmlns:="http://www.w3.org/1999/xhtml">train</span></strong><span class="koboSpan" id="kobo.242.1" xmlns:="http://www.w3.org/1999/xhtml"> subset of the 20 Newsgroup dataset that comes with </span><strong class="source-inline"><span class="koboSpan" id="kobo.243.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.244.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.244.2" xmlns:="http://www.w3.org/1999/xhtml">Each row in this dataset is composed of a string </span><span class="No-Break"><span class="koboSpan" id="kobo.245.1" xmlns:="http://www.w3.org/1999/xhtml">with text.</span></span></p>
<p><span class="koboSpan" id="kobo.246.1" xmlns:="http://www.w3.org/1999/xhtml">We used pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.247.1" xmlns:="http://www.w3.org/1999/xhtml">str</span></strong><span class="koboSpan" id="kobo.248.1" xmlns:="http://www.w3.org/1999/xhtml">, followed by </span><strong class="source-inline"><span class="koboSpan" id="kobo.249.1" xmlns:="http://www.w3.org/1999/xhtml">len()</span></strong><span class="koboSpan" id="kobo.250.1" xmlns:="http://www.w3.org/1999/xhtml">, to count the number of characters in each string – that is, the total number of letters, numbers, symbols, and spaces. </span><span class="koboSpan" id="kobo.250.2" xmlns:="http://www.w3.org/1999/xhtml">We also combined </span><strong class="source-inline"><span class="koboSpan" id="kobo.251.1" xmlns:="http://www.w3.org/1999/xhtml">str.len()</span></strong><span class="koboSpan" id="kobo.252.1" xmlns:="http://www.w3.org/1999/xhtml"> with </span><strong class="source-inline"><span class="koboSpan" id="kobo.253.1" xmlns:="http://www.w3.org/1999/xhtml">str.strip()</span></strong><span class="koboSpan" id="kobo.254.1" xmlns:="http://www.w3.org/1999/xhtml"> to remove trailing white spaces at the beginning and end of the string and in new lines, before counting the number </span><span class="No-Break"><span class="koboSpan" id="kobo.255.1" xmlns:="http://www.w3.org/1999/xhtml">of characters.</span></span></p>
<p><span class="koboSpan" id="kobo.256.1" xmlns:="http://www.w3.org/1999/xhtml">To count the number of words, we used pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.257.1" xmlns:="http://www.w3.org/1999/xhtml">str</span></strong><span class="koboSpan" id="kobo.258.1" xmlns:="http://www.w3.org/1999/xhtml">, followed by </span><strong class="source-inline"><span class="koboSpan" id="kobo.259.1" xmlns:="http://www.w3.org/1999/xhtml">split()</span></strong><span class="koboSpan" id="kobo.260.1" xmlns:="http://www.w3.org/1999/xhtml">, to divide the string into a list of words. </span><span class="koboSpan" id="kobo.260.2" xmlns:="http://www.w3.org/1999/xhtml">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.261.1" xmlns:="http://www.w3.org/1999/xhtml">split()</span></strong><span class="koboSpan" id="kobo.262.1" xmlns:="http://www.w3.org/1999/xhtml"> method creates a list of words by breaking the string at the white spaces between words. </span><span class="koboSpan" id="kobo.262.2" xmlns:="http://www.w3.org/1999/xhtml">Next, we counted those words with </span><strong class="source-inline"><span class="koboSpan" id="kobo.263.1" xmlns:="http://www.w3.org/1999/xhtml">str.len()</span></strong><span class="koboSpan" id="kobo.264.1" xmlns:="http://www.w3.org/1999/xhtml">, obtaining the number of words </span><span class="No-Break"><span class="koboSpan" id="kobo.265.1" xmlns:="http://www.w3.org/1999/xhtml">per string.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.266.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.267.1" xmlns:="http://www.w3.org/1999/xhtml">We can change the behavior of </span><strong class="source-inline"><span class="koboSpan" id="kobo.268.1" xmlns:="http://www.w3.org/1999/xhtml">str.split()</span></strong><span class="koboSpan" id="kobo.269.1" xmlns:="http://www.w3.org/1999/xhtml"> by passing a string or character that we would like to use to split the string. </span><span class="koboSpan" id="kobo.269.2" xmlns:="http://www.w3.org/1999/xhtml">For example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.270.1" xmlns:="http://www.w3.org/1999/xhtml">df['text'].str.split(';')</span></strong><span class="koboSpan" id="kobo.271.1" xmlns:="http://www.w3.org/1999/xhtml"> divides a string at each occurrence </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1" xmlns:="http://www.w3.org/1999/xhtml">of </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.273.1" xmlns:="http://www.w3.org/1999/xhtml">;</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.274.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.275.1" xmlns:="http://www.w3.org/1999/xhtml">To determine the number of unique words, we used pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.276.1" xmlns:="http://www.w3.org/1999/xhtml">str.split()</span></strong><span class="koboSpan" id="kobo.277.1" xmlns:="http://www.w3.org/1999/xhtml"> function to divide the string into a list of words. </span><span class="koboSpan" id="kobo.277.2" xmlns:="http://www.w3.org/1999/xhtml">Next, we applied the built-in Python </span><strong class="source-inline"><span class="koboSpan" id="kobo.278.1" xmlns:="http://www.w3.org/1999/xhtml">set()</span></strong><span class="koboSpan" id="kobo.279.1" xmlns:="http://www.w3.org/1999/xhtml"> method within pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.280.1" xmlns:="http://www.w3.org/1999/xhtml">apply()</span></strong><span class="koboSpan" id="kobo.281.1" xmlns:="http://www.w3.org/1999/xhtml"> to return a set of words. </span><span class="koboSpan" id="kobo.281.2" xmlns:="http://www.w3.org/1999/xhtml">Remember that a set contains </span><em class="italic"><span class="koboSpan" id="kobo.282.1" xmlns:="http://www.w3.org/1999/xhtml">unique occurrences</span></em><span class="koboSpan" id="kobo.283.1" xmlns:="http://www.w3.org/1999/xhtml"> of the elements in a list – that is, unique words. </span><span class="koboSpan" id="kobo.283.2" xmlns:="http://www.w3.org/1999/xhtml">Next, we counted those words with pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.284.1" xmlns:="http://www.w3.org/1999/xhtml">str.len()</span></strong><span class="koboSpan" id="kobo.285.1" xmlns:="http://www.w3.org/1999/xhtml"> function to return the </span><strong class="bold"><span class="koboSpan" id="kobo.286.1" xmlns:="http://www.w3.org/1999/xhtml">vocabulary</span></strong><span class="koboSpan" id="kobo.287.1" xmlns:="http://www.w3.org/1999/xhtml">, or in other words, the number of unique words in the string. </span><span class="koboSpan" id="kobo.287.2" xmlns:="http://www.w3.org/1999/xhtml">Python interprets words that are written in uppercase differently from those in lowercase; therefore, we introduced pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.288.1" xmlns:="http://www.w3.org/1999/xhtml">lower()</span></strong><span class="koboSpan" id="kobo.289.1" xmlns:="http://www.w3.org/1999/xhtml"> function to set all the characters to lowercase before splitting the string and counting the number of </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1" xmlns:="http://www.w3.org/1999/xhtml">unique words.</span></span></p>
<p><span class="koboSpan" id="kobo.291.1" xmlns:="http://www.w3.org/1999/xhtml">To create the</span><a id="_idIndexMarker845"/><span class="koboSpan" id="kobo.292.1" xmlns:="http://www.w3.org/1999/xhtml"> lexical </span><a id="_idIndexMarker846"/><span class="koboSpan" id="kobo.293.1" xmlns:="http://www.w3.org/1999/xhtml">diversity and average word length </span><a id="_idTextAnchor1495"/><span class="koboSpan" id="kobo.294.1" xmlns:="http://www.w3.org/1999/xhtml">features, </span><a id="_idTextAnchor1496"/><span class="koboSpan" id="kobo.295.1" xmlns:="http://www.w3.org/1999/xhtml">we</span><a id="_idIndexMarker847"/><span class="koboSpan" id="kobo.296.1" xmlns:="http://www.w3.org/1999/xhtml"> simply pe</span><a id="_idTextAnchor1497"/><span class="koboSpan" id="kobo.297.1" xmlns:="http://www.w3.org/1999/xhtml">rformed a vectorized di</span><a id="_idTextAnchor1498"/><span class="koboSpan" id="kobo.298.1" xmlns:="http://www.w3.org/1999/xhtml">vision of two </span><strong class="source-inline"><span class="koboSpan" id="kobo.299.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.300.1" xmlns:="http://www.w3.org/1999/xhtml"> s</span><a id="_idTextAnchor1499"/><span class="koboSpan" id="kobo.301.1" xmlns:="http://www.w3.org/1999/xhtml">eries. </span><span class="koboSpan" id="kobo.301.2" xmlns:="http://www.w3.org/1999/xhtml">That’s it; we created five new features with information about the comp</span><a id="_idTextAnchor1500"/><a id="_idTextAnchor1501"/><span class="koboSpan" id="kobo.302.1" xmlns:="http://www.w3.org/1999/xhtml">lexity of </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1" xmlns:="http://www.w3.org/1999/xhtml">the text.</span></span></p>
<h2 id="_idParaDest-304"><a id="_idTextAnchor1502"/><span class="koboSpan" id="kobo.304.1" xmlns:="http://www.w3.org/1999/xhtml">There’s more...</span></h2>
<p><span class="koboSpan" id="kobo.305.1" xmlns:="http://www.w3.org/1999/xhtml">We can check out the distribution of the features extracted from text in each of the 20 different news topics present in the dataset by </span><span class="No-Break"><span class="koboSpan" id="kobo.306.1" xmlns:="http://www.w3.org/1999/xhtml">using visualizations</span><a id="_idTextAnchor1503"/><span class="koboSpan" id="kobo.307.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.308.1" xmlns:="http://www.w3.org/1999/xhtml">To make histogram plots of the newly created features, after you run all of the steps in the </span><em class="italic"><span class="koboSpan" id="kobo.309.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></em><span class="koboSpan" id="kobo.310.1" xmlns:="http://www.w3.org/1999/xhtml"> section of this recipe, follow </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1" xmlns:="http://www.w3.org/1999/xhtml">these steps:</span></span></p>
<ol>
<li><span class="No-Break"><span class="koboSpan" id="kobo.312.1" xmlns:="http://www.w3.org/1999/xhtml">Import </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.313.1" xmlns:="http://www.w3.org/1999/xhtml">matplotlib</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.314.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.315.1" xmlns:="http://www.w3.org/1999/xhtml">
import matplotlib.pyplot as plt</span></pre></li> <li><span class="koboSpan" id="kobo.316.1" xmlns:="http://www.w3.org/1999/xhtml">Add the target with the news topics to the 20 </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1" xmlns:="http://www.w3.org/1999/xhtml">Newsgroup DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.318.1" xmlns:="http://www.w3.org/1999/xhtml">
df['target'] = data.target</span></pre></li> <li><span class="koboSpan" id="kobo.319.1" xmlns:="http://www.w3.org/1999/xhtml">Create a function that displays a histogram of a feature of your choice for each of the </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1" xmlns:="http://www.w3.org/1999/xhtml">news topics:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.321.1" xmlns:="http://www.w3.org/1999/xhtml">
def plot_features(df, text_var):
    nb_rows = 5
    nb_cols = 4
    fig, axs = plt.subplots(
        nb_rows, nb_cols,figsize=(12, 12))
    plt.subplots_adjust(wspace=None, hspace=0.4)
    n = 0
    for i in range(0, nb_rows):
        for j in range(0, nb_cols):
            axs[i, j].hist(
                df[df.target==n][text_var], bins=30)
            axs[i, j].set_title(
                text_var + ' | ' + str(n))
                 n += </span><a id="_idTextAnchor1504"/><span class="koboSpan" id="kobo.322.1" xmlns:="http://www.w3.org/1999/xhtml">1
    plt.show()</span></pre></li> <li><span class="koboSpan" id="kobo.323.1" xmlns:="http://www.w3.org/1999/xhtml">Run the function </span><a id="_idIndexMarker848"/><span class="koboSpan" id="kobo.324.1" xmlns:="http://www.w3.org/1999/xhtml">for </span><a id="_idIndexMarker849"/><span class="koboSpan" id="kobo.325.1" xmlns:="http://www.w3.org/1999/xhtml">the number of </span><a id="_idIndexMarker850"/><span class="No-Break"><span class="koboSpan" id="kobo.326.1" xmlns:="http://www.w3.org/1999/xhtml">words feature:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.327.1" xmlns:="http://www.w3.org/1999/xhtml">
plot_features(df, 'num_words')</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.328.1" xmlns:="http://www.w3.org/1999/xhtml">The previous command returns the following plot, where you can see the distribution of the number of words in each of the 20 news topics, numbered from 0 to </span><a id="_idTextAnchor1505"/><span class="koboSpan" id="kobo.329.1" xmlns:="http://www.w3.org/1999/xhtml">19 in the </span><span class="No-Break"><span class="koboSpan" id="kobo.330.1" xmlns:="http://www.w3.org/1999/xhtml">plot title:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer197">
<span class="koboSpan" id="kobo.331.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 11.2 – Histograms showing the distribution of the number of words per text, segregated by topic discussed in each text" src="image/B22396_11_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.332.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 11.2 – Histograms showing the distribution of the number of words per text, segregated by topic discussed in each text</span></p>
<p><span class="koboSpan" id="kobo.333.1" xmlns:="http://www.w3.org/1999/xhtml">The number of </span><a id="_idIndexMarker851"/><span class="koboSpan" id="kobo.334.1" xmlns:="http://www.w3.org/1999/xhtml">words</span><a id="_idIndexMarker852"/><span class="koboSpan" id="kobo.335.1" xmlns:="http://www.w3.org/1999/xhtml"> shows a different </span><a id="_idIndexMarker853"/><span class="koboSpan" id="kobo.336.1" xmlns:="http://www.w3.org/1999/xhtml">distribution across the different news topics</span><a id="_idTextAnchor1506"/><span class="koboSpan" id="kobo.337.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.337.2" xmlns:="http://www.w3.org/1999/xhtml">Therefore, this feature is likely useful in a classification algorithm to predic</span><a id="_idTextAnchor1507"/><a id="_idTextAnchor1508"/><span class="koboSpan" id="kobo.338.1" xmlns:="http://www.w3.org/1999/xhtml">t the topic of </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1" xmlns:="http://www.w3.org/1999/xhtml">the text.</span></span></p>
<h2 id="_idParaDest-305"><a id="_idTextAnchor1509"/><span class="koboSpan" id="kobo.340.1" xmlns:="http://www.w3.org/1999/xhtml">See also</span></h2>
<p><span class="koboSpan" id="kobo.341.1" xmlns:="http://www.w3.org/1999/xhtml">To learn more about pandas’ b</span><a id="_idTextAnchor1510"/><span class="koboSpan" id="kobo.342.1" xmlns:="http://www.w3.org/1999/xhtml">uilt-in string processing functionality </span><span class="No-Break"><span class="koboSpan" id="kobo.343.1" xmlns:="http://www.w3.org/1999/xhtml">visit </span></span><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#method-summary"><span class="No-Break"><span class="koboSpan" id="kobo.344.1" xmlns:="http://www.w3.org/1999/xhtml">https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#method-summary</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.345.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h1 id="_idParaDest-306"><span class="koboSpan" id="kobo.346.1" xmlns:="http://www.w3.org/1999/xhtml">Estimating text complexity by counting senten</span><a id="_idTextAnchor1511"/><span class="koboSpan" id="kobo.347.1" xmlns:="http://www.w3.org/1999/xhtml">ces</span></h1>
<p><span class="koboSpan" id="kobo.348.1" xmlns:="http://www.w3.org/1999/xhtml">One aspect of a</span><a id="_idIndexMarker854"/><span class="koboSpan" id="kobo.349.1" xmlns:="http://www.w3.org/1999/xhtml"> piece of text that </span><a id="_idTextAnchor1512"/><span class="koboSpan" id="kobo.350.1" xmlns:="http://www.w3.org/1999/xhtml">we can capture in features is its complexity. </span><span class="koboSpan" id="kobo.350.2" xmlns:="http://www.w3.org/1999/xhtml">Usually, longer descriptions that contain multiple sentences spread over several paragraphs tend to provide more information than descriptions with very few sentences. </span><span class="koboSpan" id="kobo.350.3" xmlns:="http://www.w3.org/1999/xhtml">Therefore, capturing the number of sentences may provide some insight into the amou</span><a id="_idTextAnchor1513"/><span class="koboSpan" id="kobo.351.1" xmlns:="http://www.w3.org/1999/xhtml">nt of information provided by the text. </span><span class="koboSpan" id="kobo.351.2" xmlns:="http://www.w3.org/1999/xhtml">This process is</span><a id="_idIndexMarker855"/><span class="koboSpan" id="kobo.352.1" xmlns:="http://www.w3.org/1999/xhtml"> called </span><strong class="bold"><span class="koboSpan" id="kobo.353.1" xmlns:="http://www.w3.org/1999/xhtml">sentence tokenization</span></strong><span class="koboSpan" id="kobo.354.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.354.2" xmlns:="http://www.w3.org/1999/xhtml">Tokenization is the process of splitting a string into a list of pieces or tokens. </span><span class="koboSpan" id="kobo.354.3" xmlns:="http://www.w3.org/1999/xhtml">In the </span><em class="italic"><span class="koboSpan" id="kobo.355.1" xmlns:="http://www.w3.org/1999/xhtml">Counting characters, words, and vocabulary</span></em><span class="koboSpan" id="kobo.356.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe, we did word tokenization – that is, we divided the string into words. </span><span class="koboSpan" id="kobo.356.2" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will divide the string into sentences, and then we will count them. </span><span class="koboSpan" id="kobo.356.3" xmlns:="http://www.w3.org/1999/xhtml">We will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.357.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.358.1" xmlns:="http://www.w3.org/1999/xhtml"> Python library, which pr</span><a id="_idTextAnchor1514"/><a id="_idTextAnchor1515"/><span class="koboSpan" id="kobo.359.1" xmlns:="http://www.w3.org/1999/xhtml">ovides </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1" xmlns:="http://www.w3.org/1999/xhtml">this functionality.</span></span></p>
<h2 id="_idParaDest-307"><a id="_idTextAnchor1516"/><span class="koboSpan" id="kobo.361.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.362.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.363.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.364.1" xmlns:="http://www.w3.org/1999/xhtml"> Python library. </span><span class="koboSpan" id="kobo.364.2" xmlns:="http://www.w3.org/1999/xhtml">For guidelines on how to install </span><strong class="source-inline"><span class="koboSpan" id="kobo.365.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.366.1" xmlns:="http://www.w3.org/1999/xhtml">, check out the </span><em class="italic"><span class="koboSpan" id="kobo.367.1" xmlns:="http://www.w3.org/1999/xhtml">Technical requirement</span><a id="_idTextAnchor1517"/><a id="_idTextAnchor1518"/><span class="koboSpan" id="kobo.368.1" xmlns:="http://www.w3.org/1999/xhtml">s</span></em><span class="koboSpan" id="kobo.369.1" xmlns:="http://www.w3.org/1999/xhtml"> section of </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1" xmlns:="http://www.w3.org/1999/xhtml">this chapter.</span></span></p>
<h2 id="_idParaDest-308"><a id="_idTextAnchor1519"/><span class="koboSpan" id="kobo.371.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.372.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by importing the required libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1" xmlns:="http://www.w3.org/1999/xhtml">and dataset:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.374.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load </span><strong class="source-inline"><span class="koboSpan" id="kobo.375.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.376.1" xmlns:="http://www.w3.org/1999/xhtml">, the sentence tokenizer from </span><strong class="source-inline"><span class="koboSpan" id="kobo.377.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.378.1" xmlns:="http://www.w3.org/1999/xhtml">, and the dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1" xmlns:="http://www.w3.org/1999/xhtml">from </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.380.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.381.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.382.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from nltk.tokenize import sent_tokenize
from sklearn.datasets import fetch_20newsgroups</span></pre></li> <li><span class="koboSpan" id="kobo.383.1" xmlns:="http://www.w3.org/1999/xhtml">To understand the functionality of the sentence tokenizer from </span><strong class="source-inline"><span class="koboSpan" id="kobo.384.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.385.1" xmlns:="http://www.w3.org/1999/xhtml">, let’s create a variable that contains a string with </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1" xmlns:="http://www.w3.org/1999/xhtml">multiple sentences:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.387.1" xmlns:="http://www.w3.org/1999/xhtml">
text = """
The alarm rang at 7 in the morning as it usually did on Tuesdays. </span><span class="koboSpan" id="kobo.387.2" xmlns:="http://www.w3.org/1999/xhtml">She rolled over, stretched her arm, and stumbled to the button till she finally managed to switch it off. </span><span class="koboSpan" id="kobo.387.3" xmlns:="http://www.w3.org/1999/xhtml">Reluctantly, she got up and went for a shower. </span><span class="koboSpan" id="kobo.387.4" xmlns:="http://www.w3.org/1999/xhtml">The water was cold as the day before the engineers did not manage to get the boiler working. </span><span class="koboSpan" id="kobo.387.5" xmlns:="http://www.w3.org/1999/xhtml">Good thing it was still summer.
</span><span class="koboSpan" id="kobo.387.6" xmlns:="http://www.w3.org/1999/xhtml">Upstairs, her cat waited eagerly for his morning snack. </span><span class="koboSpan" id="kobo.387.7" xmlns:="http://www.w3.org/1999/xhtml">Miaow! </span><span class="koboSpan" id="kobo.387.8" xmlns:="http://www.w3.org/1999/xhtml">He voiced with excitement as he saw her climb the stai</span><a id="_idTextAnchor1520"/><span class="koboSpan" id="kobo.388.1" xmlns:="http://www.w3.org/1999/xhtml">rs.
</span><span class="koboSpan" id="kobo.388.2" xmlns:="http://www.w3.org/1999/xhtml">"""</span></pre></li> <li><span class="koboSpan" id="kobo.389.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s </span><a id="_idIndexMarker856"/><span class="koboSpan" id="kobo.390.1" xmlns:="http://www.w3.org/1999/xhtml">separate the string from </span><em class="italic"><span class="koboSpan" id="kobo.391.1" xmlns:="http://www.w3.org/1999/xhtml">step 2</span></em><span class="koboSpan" id="kobo.392.1" xmlns:="http://www.w3.org/1999/xhtml"> into sentences using </span><strong class="source-inline"><span class="koboSpan" id="kobo.393.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.394.1" xmlns:="http://www.w3.org/1999/xhtml"> library‘s </span><span class="No-Break"><span class="koboSpan" id="kobo.395.1" xmlns:="http://www.w3.org/1999/xhtml">sentence tokenizer:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.396.1" xmlns:="http://www.w3.org/1999/xhtml">
sent_tokenize(text)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.397.1" xmlns:="http://www.w3.org/1999/xhtml">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.398.1" xmlns:="http://www.w3.org/1999/xhtml">If you encounter an error in </span><em class="italic"><span class="koboSpan" id="kobo.399.1" xmlns:="http://www.w3.org/1999/xhtml">step 3</span></em><span class="koboSpan" id="kobo.400.1" xmlns:="http://www.w3.org/1999/xhtml">, read the error message carefully and download the data source required by </span><strong class="source-inline"><span class="koboSpan" id="kobo.401.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.402.1" xmlns:="http://www.w3.org/1999/xhtml">, as described in the error message. </span><span class="koboSpan" id="kobo.402.2" xmlns:="http://www.w3.org/1999/xhtml">For more details, check out the </span><em class="italic"><span class="koboSpan" id="kobo.403.1" xmlns:="http://www.w3.org/1999/xhtml">Technical </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.404.1" xmlns:="http://www.w3.org/1999/xhtml">requirements</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.405.1" xmlns:="http://www.w3.org/1999/xhtml"> section.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.406.1" xmlns:="http://www.w3.org/1999/xhtml">The sentence tokenizer returns the list of sentences shown in the </span><span class="No-Break"><span class="koboSpan" id="kobo.407.1" xmlns:="http://www.w3.org/1999/xhtml">following output:</span></span></p>
<pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.408.1" xmlns:="http://www.w3.org/1999/xhtml">['\nThe alarm rang at 7 in the morning as it usually did on Tuesdays.',</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.409.1" xmlns:="http://www.w3.org/1999/xhtml"> 'She rolled over,\nstretched her arm, and stumbled to the button till she finally managed to switch it off.',</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.410.1" xmlns:="http://www.w3.org/1999/xhtml"> 'Reluctantly, she got up and went for a shower.',</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.411.1" xmlns:="http://www.w3.org/1999/xhtml"> 'The water was cold as the day before the engineers\ndid not manage to get the boiler working.',</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.412.1" xmlns:="http://www.w3.org/1999/xhtml"> 'Good thing it was still summer.',</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.413.1" xmlns:="http://www.w3.org/1999/xhtml"> 'Upstairs, her cat waited eagerly for his morning snack.',</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.414.1" xmlns:="http://www.w3.org/1999/xhtml"> 'Miaow!',</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.415.1" xmlns:="http://www.w3.org/1999/xhtml"> 'He voiced with excitement\nas he saw her climb the stairs.']</span></strong></pre> <p class="callout-heading"><span class="koboSpan" id="kobo.416.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.417.1" xmlns:="http://www.w3.org/1999/xhtml">The escape character followed by the letter, </span><strong class="source-inline"><span class="koboSpan" id="kobo.418.1" xmlns:="http://www.w3.org/1999/xhtml">\n</span></strong><span class="koboSpan" id="kobo.419.1" xmlns:="http://www.w3.org/1999/xhtml">, indic</span><a id="_idTextAnchor1521"/><span class="koboSpan" id="kobo.420.1" xmlns:="http://www.w3.org/1999/xhtml">ates a </span><span class="No-Break"><span class="koboSpan" id="kobo.421.1" xmlns:="http://www.w3.org/1999/xhtml">new line.</span></span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.422.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s c</span><a id="_idTextAnchor1522"/><span class="koboSpan" id="kobo.423.1" xmlns:="http://www.w3.org/1999/xhtml">ount the number of sentences in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.424.1" xmlns:="http://www.w3.org/1999/xhtml">text</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.425.1" xmlns:="http://www.w3.org/1999/xhtml"> variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.426.1" xmlns:="http://www.w3.org/1999/xhtml">
len(sent_tokenize(text))</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.427.1" xmlns:="http://www.w3.org/1999/xhtml">The previous command returns </span><strong class="source-inline"><span class="koboSpan" id="kobo.428.1" xmlns:="http://www.w3.org/1999/xhtml">8</span></strong><span class="koboSpan" id="kobo.429.1" xmlns:="http://www.w3.org/1999/xhtml">, which is the number of sentences in our </span><strong class="source-inline"><span class="koboSpan" id="kobo.430.1" xmlns:="http://www.w3.org/1999/xhtml">text</span></strong><span class="koboSpan" id="kobo.431.1" xmlns:="http://www.w3.org/1999/xhtml"> variable. </span><span class="koboSpan" id="kobo.431.2" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s determine the number of sentences in an </span><span class="No-Break"><span class="koboSpan" id="kobo.432.1" xmlns:="http://www.w3.org/1999/xhtml">entire DataFrame.</span></span></p></li> <li><span class="koboSpan" id="kobo.433.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load </span><a id="_idIndexMarker857"/><span class="koboSpan" id="kobo.434.1" xmlns:="http://www.w3.org/1999/xhtml">the </span><strong class="source-inline"><span class="koboSpan" id="kobo.435.1" xmlns:="http://www.w3.org/1999/xhtml">train</span></strong><span class="koboSpan" id="kobo.436.1" xmlns:="http://www.w3.org/1999/xhtml"> subset of the 20 Newsgroup dataset into a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.437.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.438.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.439.1" xmlns:="http://www.w3.org/1999/xhtml">
data = fetch_20newsgroups(subset='train')
df = pd.DataFrame(data.data, columns=['text'])</span></pre></li> <li><span class="koboSpan" id="kobo.440.1" xmlns:="http://www.w3.org/1999/xhtml">To speed up the following steps, we will only work with the first </span><strong class="source-inline"><span class="koboSpan" id="kobo.441.1" xmlns:="http://www.w3.org/1999/xhtml">10</span></strong><span class="koboSpan" id="kobo.442.1" xmlns:="http://www.w3.org/1999/xhtml"> rows of </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1" xmlns:="http://www.w3.org/1999/xhtml">the DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.444.1" xmlns:="http://www.w3.org/1999/xhtml">
df = df.loc[1:10]</span></pre></li> <li><span class="koboSpan" id="kobo.445.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s also remove the first part of the text, which contains information about the email sender, subject, and other details that we are not interested in. </span><span class="koboSpan" id="kobo.445.2" xmlns:="http://www.w3.org/1999/xhtml">Most of this information comes before the word </span><strong class="source-inline"><span class="koboSpan" id="kobo.446.1" xmlns:="http://www.w3.org/1999/xhtml">Lines</span></strong><span class="koboSpan" id="kobo.447.1" xmlns:="http://www.w3.org/1999/xhtml"> followed by </span><strong class="source-inline"><span class="koboSpan" id="kobo.448.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></strong><span class="koboSpan" id="kobo.449.1" xmlns:="http://www.w3.org/1999/xhtml">, so let’s split the string at </span><strong class="source-inline"><span class="koboSpan" id="kobo.450.1" xmlns:="http://www.w3.org/1999/xhtml">Lines:</span></strong><span class="koboSpan" id="kobo.451.1" xmlns:="http://www.w3.org/1999/xhtml"> and capture the second part of </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1" xmlns:="http://www.w3.org/1999/xhtml">the string:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.453.1" xmlns:="http://www.w3.org/1999/xhtml">
df['text'] = df['text'].str.split('Lines:').apply(
    lambda x: x[1])</span></pre></li> <li><span class="koboSpan" id="kobo.454.1" xmlns:="http://www.w3.org/1999/xhtml">Fin</span><a id="_idTextAnchor1523"/><span class="koboSpan" id="kobo.455.1" xmlns:="http://www.w3.org/1999/xhtml">ally, let’s create a v</span><a id="_idTextAnchor1524"/><span class="koboSpan" id="kobo.456.1" xmlns:="http://www.w3.org/1999/xhtml">ariable containing the number of sentences </span><span class="No-Break"><span class="koboSpan" id="kobo.457.1" xmlns:="http://www.w3.org/1999/xhtml">per </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.458.1" xmlns:="http://www.w3.org/1999/xhtml">text</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.459.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.460.1" xmlns:="http://www.w3.org/1999/xhtml">
df['num_sent'] = df['text'].apply(
    sent_tokenize).apply(len)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.461.1" xmlns:="http://www.w3.org/1999/xhtml">With the </span><strong class="source-inline"><span class="koboSpan" id="kobo.462.1" xmlns:="http://www.w3.org/1999/xhtml">df</span></strong><span class="koboSpan" id="kobo.463.1" xmlns:="http://www.w3.org/1999/xhtml"> command, you can display the entire DataFrame with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.464.1" xmlns:="http://www.w3.org/1999/xhtml">text</span></strong><span class="koboSpan" id="kobo.465.1" xmlns:="http://www.w3.org/1999/xhtml"> variable and the new feature containing the nu</span><a id="_idTextAnchor1525"/><span class="koboSpan" id="kobo.466.1" xmlns:="http://www.w3.org/1999/xhtml">mber of sentences </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1" xmlns:="http://www.w3.org/1999/xhtml">per text:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer198">
<span class="koboSpan" id="kobo.468.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 11.3 – A DataFrame with the text variable and the number of sentences per text" src="image/B22396_11_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.469.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 11.3 – A DataFrame with the text variable and the number of sentences per text</span></p>
<p><span class="koboSpan" id="kobo.470.1" xmlns:="http://www.w3.org/1999/xhtml">Now, we can use this</span><a id="_idIndexMarker858"/><span class="koboSpan" id="kobo.471.1" xmlns:="http://www.w3.org/1999/xhtml"> new feature as input to </span><a id="_idTextAnchor1526"/><a id="_idTextAnchor1527"/><span class="koboSpan" id="kobo.472.1" xmlns:="http://www.w3.org/1999/xhtml">machine </span><span class="No-Break"><span class="koboSpan" id="kobo.473.1" xmlns:="http://www.w3.org/1999/xhtml">learning algorithms.</span></span></p>
<h2 id="_idParaDest-309"><a id="_idTextAnchor1528"/><span class="koboSpan" id="kobo.474.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.475.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we separated a string with text into sentences using </span><strong class="source-inline"><span class="koboSpan" id="kobo.476.1" xmlns:="http://www.w3.org/1999/xhtml">sent_tokenizer</span></strong><span class="koboSpan" id="kobo.477.1" xmlns:="http://www.w3.org/1999/xhtml"> from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.478.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.479.1" xmlns:="http://www.w3.org/1999/xhtml"> library. </span><strong class="source-inline"><span class="koboSpan" id="kobo.480.1" xmlns:="http://www.w3.org/1999/xhtml">sent_tokenizer</span></strong><span class="koboSpan" id="kobo.481.1" xmlns:="http://www.w3.org/1999/xhtml"> has been pre-trained to recognize capitalization and different types of punctuation that signal the beginning and the end of </span><span class="No-Break"><span class="koboSpan" id="kobo.482.1" xmlns:="http://www.w3.org/1999/xhtml">a sentence.</span></span></p>
<p><span class="koboSpan" id="kobo.483.1" xmlns:="http://www.w3.org/1999/xhtml">First, we applied </span><strong class="source-inline"><span class="koboSpan" id="kobo.484.1" xmlns:="http://www.w3.org/1999/xhtml">sent_tokenizer</span></strong><span class="koboSpan" id="kobo.485.1" xmlns:="http://www.w3.org/1999/xhtml"> to a manually created string to become familiar with its functionality. </span><span class="koboSpan" id="kobo.485.2" xmlns:="http://www.w3.org/1999/xhtml">The tokenizer divided the text into a list of eight sentences. </span><span class="koboSpan" id="kobo.485.3" xmlns:="http://www.w3.org/1999/xhtml">We combined the tokenizer with the built-in Python </span><strong class="source-inline"><span class="koboSpan" id="kobo.486.1" xmlns:="http://www.w3.org/1999/xhtml">len()</span></strong><span class="koboSpan" id="kobo.487.1" xmlns:="http://www.w3.org/1999/xhtml"> method to count the number of sentences in </span><span class="No-Break"><span class="koboSpan" id="kobo.488.1" xmlns:="http://www.w3.org/1999/xhtml">the string.</span></span></p>
<p><span class="koboSpan" id="kobo.489.1" xmlns:="http://www.w3.org/1999/xhtml">Next, we loaded a dataset with text and, to speed up the computation, we only retained the first 10 rows of the DataFrame using pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.490.1" xmlns:="http://www.w3.org/1999/xhtml">loc[]</span></strong><span class="koboSpan" id="kobo.491.1" xmlns:="http://www.w3.org/1999/xhtml"> function. </span><span class="koboSpan" id="kobo.491.2" xmlns:="http://www.w3.org/1999/xhtml">Next, we removed the first part of the text, which contained information about the email sender and subject. </span><span class="koboSpan" id="kobo.491.3" xmlns:="http://www.w3.org/1999/xhtml">To do this, we split the string at </span><strong class="source-inline"><span class="koboSpan" id="kobo.492.1" xmlns:="http://www.w3.org/1999/xhtml">Lines:</span></strong><span class="koboSpan" id="kobo.493.1" xmlns:="http://www.w3.org/1999/xhtml"> using pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.494.1" xmlns:="http://www.w3.org/1999/xhtml">str.split("Lines:")</span></strong><span class="koboSpan" id="kobo.495.1" xmlns:="http://www.w3.org/1999/xhtml"> function, which returned a list with two elements: the strings before and after </span><strong class="source-inline"><span class="koboSpan" id="kobo.496.1" xmlns:="http://www.w3.org/1999/xhtml">Lines:</span></strong><span class="koboSpan" id="kobo.497.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.497.2" xmlns:="http://www.w3.org/1999/xhtml">Utilizing a lambda function within </span><strong class="source-inline"><span class="koboSpan" id="kobo.498.1" xmlns:="http://www.w3.org/1999/xhtml">apply()</span></strong><span class="koboSpan" id="kobo.499.1" xmlns:="http://www.w3.org/1999/xhtml">, we retained the second part of the text – that is, the second string in the list returned </span><span class="No-Break"><span class="koboSpan" id="kobo.500.1" xmlns:="http://www.w3.org/1999/xhtml">by </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.501.1" xmlns:="http://www.w3.org/1999/xhtml">split()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.502.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.503.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, we applied </span><strong class="source-inline"><span class="koboSpan" id="kobo.504.1" xmlns:="http://www.w3.org/1999/xhtml">sent_tokenizer</span></strong><span class="koboSpan" id="kobo.505.1" xmlns:="http://www.w3.org/1999/xhtml"> to each row in the DataFrame with the pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.506.1" xmlns:="http://www.w3.org/1999/xhtml">apply()</span></strong><span class="koboSpan" id="kobo.507.1" xmlns:="http://www.w3.org/1999/xhtml"> method to separate the strings into sentences, and then applied the built-</span><a id="_idTextAnchor1529"/><span class="koboSpan" id="kobo.508.1" xmlns:="http://www.w3.org/1999/xhtml">in Python </span><strong class="source-inline"><span class="koboSpan" id="kobo.509.1" xmlns:="http://www.w3.org/1999/xhtml">len()</span></strong><span class="koboSpan" id="kobo.510.1" xmlns:="http://www.w3.org/1999/xhtml"> method to th</span><a id="_idTextAnchor1530"/><span class="koboSpan" id="kobo.511.1" xmlns:="http://www.w3.org/1999/xhtml">e list of sentences to return the number of sentences per string. </span><span class="koboSpan" id="kobo.511.2" xmlns:="http://www.w3.org/1999/xhtml">This way, we </span><a id="_idIndexMarker859"/><span class="koboSpan" id="kobo.512.1" xmlns:="http://www.w3.org/1999/xhtml">created a new feature that contained the </span><a id="_idTextAnchor1531"/><a id="_idTextAnchor1532"/><span class="koboSpan" id="kobo.513.1" xmlns:="http://www.w3.org/1999/xhtml">number of sentences </span><span class="No-Break"><span class="koboSpan" id="kobo.514.1" xmlns:="http://www.w3.org/1999/xhtml">per text.</span></span></p>
<h2 id="_idParaDest-310"><span class="koboSpan" id="kobo.515.1" xmlns:="http://www.w3.org/1999/xhtml">There’s mo</span><a id="_idTextAnchor1533"/><span class="koboSpan" id="kobo.516.1" xmlns:="http://www.w3.org/1999/xhtml">re...</span></h2>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.517.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.518.1" xmlns:="http://www.w3.org/1999/xhtml"> has functionalities </span><a id="_idIndexMarker860"/><span class="koboSpan" id="kobo.519.1" xmlns:="http://www.w3.org/1999/xhtml">for word tokenization among other useful features, which we can use instead of </span><strong class="source-inline"><span class="koboSpan" id="kobo.520.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.521.1" xmlns:="http://www.w3.org/1999/xhtml"> to count and return the number of words. </span><span class="koboSpan" id="kobo.521.2" xmlns:="http://www.w3.org/1999/xhtml">You can find out more about </span><strong class="source-inline"><span class="koboSpan" id="kobo.522.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.523.1" xmlns:="http://www.w3.org/1999/xhtml">’s </span><span class="No-Break"><span class="koboSpan" id="kobo.524.1" xmlns:="http://www.w3.org/1999/xhtml">functionality here:</span></span></p>
<ul>
<li><em class="italic"><span class="koboSpan" id="kobo.525.1" xmlns:="http://www.w3.org/1999/xhtml">Python 3 Text Processing with NLTK 3 Cookbook</span></em><span class="koboSpan" id="kobo.526.1" xmlns:="http://www.w3.org/1999/xhtml">, by Jacob Per</span><a id="_idTextAnchor1534"/><span class="koboSpan" id="kobo.527.1" xmlns:="http://www.w3.org/1999/xhtml">kins, </span><span class="No-Break"><span class="koboSpan" id="kobo.528.1" xmlns:="http://www.w3.org/1999/xhtml">Packt Publishing</span></span></li>
<li><span class="koboSpan" id="kobo.529.1" xmlns:="http://www.w3.org/1999/xhtml">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.530.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.531.1" xmlns:="http://www.w3.org/1999/xhtml"> document</span><a id="_idTextAnchor1535"/><a id="_idTextAnchor1536"/><span class="koboSpan" id="kobo.532.1" xmlns:="http://www.w3.org/1999/xhtml">ation </span><span class="No-Break"><span class="koboSpan" id="kobo.533.1" xmlns:="http://www.w3.org/1999/xhtml">at </span></span><a href="http://www.nltk.org/"><span class="No-Break"><span class="koboSpan" id="kobo.534.1" xmlns:="http://www.w3.org/1999/xhtml">http://www.nltk.org/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.535.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></li>
</ul>
<h1 id="_idParaDest-311"><a id="_idTextAnchor1537"/><span class="koboSpan" id="kobo.536.1" xmlns:="http://www.w3.org/1999/xhtml">Creating features with bag-of-words and n-grams</span></h1>
<p><span class="koboSpan" id="kobo.537.1" xmlns:="http://www.w3.org/1999/xhtml">A </span><strong class="bold"><span class="koboSpan" id="kobo.538.1" xmlns:="http://www.w3.org/1999/xhtml">Bag-of-Words</span></strong><span class="koboSpan" id="kobo.539.1" xmlns:="http://www.w3.org/1999/xhtml"> (</span><strong class="bold"><span class="koboSpan" id="kobo.540.1" xmlns:="http://www.w3.org/1999/xhtml">BoW</span></strong><span class="koboSpan" id="kobo.541.1" xmlns:="http://www.w3.org/1999/xhtml">)</span><a id="_idTextAnchor1538"/><span class="koboSpan" id="kobo.542.1" xmlns:="http://www.w3.org/1999/xhtml"> is a </span><a id="_idIndexMarker861"/><span class="koboSpan" id="kobo.543.1" xmlns:="http://www.w3.org/1999/xhtml">simplified</span><a id="_idIndexMarker862"/><span class="koboSpan" id="kobo.544.1" xmlns:="http://www.w3.org/1999/xhtml"> representation</span><a id="_idTextAnchor1539"/> <a id="_idIndexMarker863"/><span class="koboSpan" id="kobo.545.1" xmlns:="http://www.w3.org/1999/xhtml">of a piece of</span><a id="_idTextAnchor1540"/><span class="koboSpan" id="kobo.546.1" xmlns:="http://www.w3.org/1999/xhtml"> text that </span><a id="_idIndexMarker864"/><a id="_idTextAnchor1541"/><span class="koboSpan" id="kobo.547.1" xmlns:="http://www.w3.org/1999/xhtml">captures the wor</span><a id="_idTextAnchor1542"/><span class="koboSpan" id="kobo.548.1" xmlns:="http://www.w3.org/1999/xhtml">ds that are present in the text and the number of times each word appears in the text. </span><span class="koboSpan" id="kobo.548.2" xmlns:="http://www.w3.org/1999/xhtml">So, for the text string </span><em class="italic"><span class="koboSpan" id="kobo.549.1" xmlns:="http://www.w3.org/1999/xhtml">Dogs like cats, but cats do not like dogs</span></em><span class="koboSpan" id="kobo.550.1" xmlns:="http://www.w3.org/1999/xhtml">, the derived BoW is </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1" xmlns:="http://www.w3.org/1999/xhtml">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer199">
<span class="koboSpan" id="kobo.552.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 11.4 – The BoW derived from the sentence Dogs like cats, but cats do not﻿ like dogs" src="image/B22396_11_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.553.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 11.4 – The BoW derived from the sentence Dogs like cats, but cats do not</span><a id="_idTextAnchor1543"/><span class="koboSpan" id="kobo.554.1" xmlns:="http://www.w3.org/1999/xhtml"> like dogs</span></p>
<p><span class="koboSpan" id="kobo.555.1" xmlns:="http://www.w3.org/1999/xhtml">Here, each word</span><a id="_idTextAnchor1544"/><span class="koboSpan" id="kobo.556.1" xmlns:="http://www.w3.org/1999/xhtml"> becomes a variable, and th</span><a id="_idTextAnchor1545"/><span class="koboSpan" id="kobo.557.1" xmlns:="http://www.w3.org/1999/xhtml">e value of the varia</span><a id="_idTextAnchor1546"/><span class="koboSpan" id="kobo.558.1" xmlns:="http://www.w3.org/1999/xhtml">ble represents the number of times the word appears in the string. </span><span class="koboSpan" id="kobo.558.2" xmlns:="http://www.w3.org/1999/xhtml">As you can see, the BoW captures multiplicity but does not retain word order or grammar. </span><span class="koboSpan" id="kobo.558.3" xmlns:="http://www.w3.org/1999/xhtml">That is why it is a simple, yet useful way of extracting features and capturing some information about the texts we are </span><span class="No-Break"><span class="koboSpan" id="kobo.559.1" xmlns:="http://www.w3.org/1999/xhtml">working with.</span></span></p>
<p><span class="koboSpan" id="kobo.560.1" xmlns:="http://www.w3.org/1999/xhtml">To capture some syntax, BoW can be used together with </span><strong class="bold"><span class="koboSpan" id="kobo.561.1" xmlns:="http://www.w3.org/1999/xhtml">n-grams</span></strong><span class="koboSpan" id="kobo.562.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.562.2" xmlns:="http://www.w3.org/1999/xhtml">An n-gram is a contiguous </span><a id="_idIndexMarker865"/><span class="koboSpan" id="kobo.563.1" xmlns:="http://www.w3.org/1999/xhtml">sequence of </span><em class="italic"><span class="koboSpan" id="kobo.564.1" xmlns:="http://www.w3.org/1999/xhtml">n</span></em><span class="koboSpan" id="kobo.565.1" xmlns:="http://www.w3.org/1999/xhtml"> items in a </span><a id="_idIndexMarker866"/><span class="koboSpan" id="kobo.566.1" xmlns:="http://www.w3.org/1999/xhtml">given </span><a id="_idIndexMarker867"/><span class="koboSpan" id="kobo.567.1" xmlns:="http://www.w3.org/1999/xhtml">text. </span><span class="koboSpan" id="kobo.567.2" xmlns:="http://www.w3.org/1999/xhtml">Continuing</span><a id="_idIndexMarker868"/><span class="koboSpan" id="kobo.568.1" xmlns:="http://www.w3.org/1999/xhtml"> with the sentence </span><em class="italic"><span class="koboSpan" id="kobo.569.1" xmlns:="http://www.w3.org/1999/xhtml">Dogs like cats, but cats do not like dogs</span></em><span class="koboSpan" id="kobo.570.1" xmlns:="http://www.w3.org/1999/xhtml">, the derived 2-grams are </span><span class="No-Break"><span class="koboSpan" id="kobo.571.1" xmlns:="http://www.w3.org/1999/xhtml">as follows:</span></span></p>
<ul>
<li><span class="No-Break"><span class="koboSpan" id="kobo.572.1" xmlns:="http://www.w3.org/1999/xhtml">Dogs like</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.573.1" xmlns:="http://www.w3.org/1999/xhtml">like cats</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.574.1" xmlns:="http://www.w3.org/1999/xhtml">cats but</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.575.1" xmlns:="http://www.w3.org/1999/xhtml">but do</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.576.1" xmlns:="http://www.w3.org/1999/xhtml">do not</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.577.1" xmlns:="http://www.w3.org/1999/xhtml">like dogs</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.578.1" xmlns:="http://www.w3.org/1999/xhtml">We can create, together with a BoW, a bag of n-grams, where the additional variables are given by the 2-grams and the values for each 2-gram are the number of times they appear in each string; for this example, the value is 1. </span><span class="koboSpan" id="kobo.578.2" xmlns:="http://www.w3.org/1999/xhtml">So, our final BoW with 2-grams would look </span><span class="No-Break"><span class="koboSpan" id="kobo.579.1" xmlns:="http://www.w3.org/1999/xhtml">like this:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer200">
<span class="koboSpan" id="kobo.580.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 11.5 – The BoW with 2-grams" src="image/B22396_11_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.581.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 11.5 – The BoW with 2-grams</span></p>
<p><span class="koboSpan" id="kobo.582.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will learn how to create BoWs with or</span><a id="_idTextAnchor1547"/><a id="_idTextAnchor1548"/><span class="koboSpan" id="kobo.583.1" xmlns:="http://www.w3.org/1999/xhtml"> without n-grams </span><span class="No-Break"><span class="koboSpan" id="kobo.584.1" xmlns:="http://www.w3.org/1999/xhtml">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.585.1" xmlns:="http://www.w3.org/1999/xhtml">sciki</span><a id="_idTextAnchor1549"/><span class="koboSpan" id="kobo.586.1" xmlns:="http://www.w3.org/1999/xhtml">t-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.587.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-312"><a id="_idTextAnchor1550"/><span class="koboSpan" id="kobo.588.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.589.1" xmlns:="http://www.w3.org/1999/xhtml">Before jumping into this</span><a id="_idTextAnchor1551"/><span class="koboSpan" id="kobo.590.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe, let’s get familiar with some o</span><a id="_idTextAnchor1552"/><span class="koboSpan" id="kobo.591.1" xmlns:="http://www.w3.org/1999/xhtml">f the parameters of a B</span><a id="_idTextAnchor1553"/><span class="koboSpan" id="kobo.592.1" xmlns:="http://www.w3.org/1999/xhtml">oW that we can adjust to make the BoW comprehensive. </span><span class="koboSpan" id="kobo.592.2" xmlns:="http://www.w3.org/1999/xhtml">When creating a BoW over several pieces of text, a new feature is created for each unique word that appears at least once in </span><em class="italic"><span class="koboSpan" id="kobo.593.1" xmlns:="http://www.w3.org/1999/xhtml">any</span></em><span class="koboSpan" id="kobo.594.1" xmlns:="http://www.w3.org/1999/xhtml"> of the text pieces we are analyzing. </span><span class="koboSpan" id="kobo.594.2" xmlns:="http://www.w3.org/1999/xhtml">If the word appears only in one piece of text, it will show a value of 1 for that particular text and 0 for all of the others. </span><span class="koboSpan" id="kobo.594.3" xmlns:="http://www.w3.org/1999/xhtml">Therefore, BoWs tend to be sparse matrices, where most of the values </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1" xmlns:="http://www.w3.org/1999/xhtml">are zeros.</span></span></p>
<p><span class="koboSpan" id="kobo.596.1" xmlns:="http://www.w3.org/1999/xhtml">The number of columns – that is, the number of words – in a BoW can be quite large if we work with huge text corpora, and even larger if we also include n-grams. </span><span class="koboSpan" id="kobo.596.2" xmlns:="http://www.w3.org/1999/xhtml">To limit the number of columns and the sparsity of the returned matrix, we can retain words that appear across multiple texts; or, in better words, we can retain words that appear in, at least, a certain percentage </span><span class="No-Break"><span class="koboSpan" id="kobo.597.1" xmlns:="http://www.w3.org/1999/xhtml">of texts.</span></span></p>
<p><span class="koboSpan" id="kobo.598.1" xmlns:="http://www.w3.org/1999/xhtml">To reduce the number of columns and sparsity of the BoW, we should also work with words in the </span><a id="_idIndexMarker869"/><span class="koboSpan" id="kobo.599.1" xmlns:="http://www.w3.org/1999/xhtml">same</span><a id="_idIndexMarker870"/><span class="koboSpan" id="kobo.600.1" xmlns:="http://www.w3.org/1999/xhtml"> case – for </span><a id="_idIndexMarker871"/><span class="koboSpan" id="kobo.601.1" xmlns:="http://www.w3.org/1999/xhtml">example, lowercase – as </span><a id="_idIndexMarker872"/><span class="koboSpan" id="kobo.602.1" xmlns:="http://www.w3.org/1999/xhtml">Python identifies words in a different case as different words. </span><span class="koboSpan" id="kobo.602.2" xmlns:="http://www.w3.org/1999/xhtml">We can also reduce the number of columns and sparsity by </span><a id="_idIndexMarker873"/><span class="koboSpan" id="kobo.603.1" xmlns:="http://www.w3.org/1999/xhtml">removing </span><a id="_idTextAnchor1554"/><strong class="bold"><span class="koboSpan" id="kobo.604.1" xmlns:="http://www.w3.org/1999/xhtml">stop words</span></strong><span class="koboSpan" id="kobo.605.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.605.2" xmlns:="http://www.w3.org/1999/xhtml">Stop words are very frequently used words that make sentences flow, but that do not, per se, carry any useful information. </span><span class="koboSpan" id="kobo.605.3" xmlns:="http://www.w3.org/1999/xhtml">Examples of stop words are pronouns such as I, you, and he, as well as prepositions </span><span class="No-Break"><span class="koboSpan" id="kobo.606.1" xmlns:="http://www.w3.org/1999/xhtml">and articles.</span></span></p>
<p><span class="koboSpan" id="kobo.607.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will learn how to set words in lowercase, remove stop words, retain words with a minimum acceptable frequency, and capture n-grams all together with a single transfor</span><a id="_idTextAnchor1555"/><a id="_idTextAnchor1556"/><span class="koboSpan" id="kobo.608.1" xmlns:="http://www.w3.org/1999/xhtml">mer from </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.609.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.610.1" xmlns:="http://www.w3.org/1999/xhtml">: </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.611.1" xmlns:="http://www.w3.org/1999/xhtml">CountVectorizer()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.612.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-313"><a id="_idTextAnchor1557"/><span class="koboSpan" id="kobo.613.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.614.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by loading the necessary libraries and getting the </span><span class="No-Break"><span class="koboSpan" id="kobo.615.1" xmlns:="http://www.w3.org/1999/xhtml">dataset ready:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.616.1" xmlns:="http://www.w3.org/1999/xhtml">Load </span><strong class="source-inline"><span class="koboSpan" id="kobo.617.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.618.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.619.1" xmlns:="http://www.w3.org/1999/xhtml">CountVectorizer</span></strong><span class="koboSpan" id="kobo.620.1" xmlns:="http://www.w3.org/1999/xhtml">, and the dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.621.1" xmlns:="http://www.w3.org/1999/xhtml">from </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.622.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.623.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.624.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import (
</span><a id="_idTextAnchor1558"/><span class="koboSpan" id="kobo.625.1" xmlns:="http://www.w3.org/1999/xhtml">    Count</span><a id="_idTextAnchor1559"/><span class="koboSpan" id="kobo.626.1" xmlns:="http://www.w3.org/1999/xhtml">Vectorizer
)</span></pre></li> <li><span class="koboSpan" id="kobo.627.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the </span><a id="_idTextAnchor1560"/><span class="koboSpan" id="kobo.628.1" xmlns:="http://www.w3.org/1999/xhtml">train set part</span><a id="_idTextAnchor1561"/><span class="koboSpan" id="kobo.629.1" xmlns:="http://www.w3.org/1999/xhtml"> of the 20 Newsgroup dataset into a </span><span class="No-Break"><span class="koboSpan" id="kobo.630.1" xmlns:="http://www.w3.org/1999/xhtml">pandas DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.631.1" xmlns:="http://www.w3.org/1999/xhtml">
data = fetch_20newsgroups(subset='train')
df = pd.DataFrame(data.data, columns=['text'])</span></pre></li> <li><span class="koboSpan" id="kobo.632.1" xmlns:="http://www.w3.org/1999/xhtml">To make interpreting the results easier, let’s remove punctuation and numbers from the </span><span class="No-Break"><span class="koboSpan" id="kobo.633.1" xmlns:="http://www.w3.org/1999/xhtml">text variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.634.1" xmlns:="http://www.w3.org/1999/xhtml">
df['text'] = df['text'].str.replace(
    ‹[^\w\s]›,››, regex=True).str.replace(
    ‹\d+›,››, regex=True)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.635.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.636.1" xmlns:="http://www.w3.org/1999/xhtml">To learn more about regex with Python, follow this </span><span class="No-Break"><span class="koboSpan" id="kobo.637.1" xmlns:="http://www.w3.org/1999/xhtml">link: </span></span><a href="https://docs.python.org/3/howto/regex.html"><span class="No-Break"><span class="koboSpan" id="kobo.638.1" xmlns:="http://www.w3.org/1999/xhtml">https://docs.python.org/3/howto/regex.html</span></span></a></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.639.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s </span><a id="_idIndexMarker874"/><span class="koboSpan" id="kobo.640.1" xmlns:="http://www.w3.org/1999/xhtml">set up </span><strong class="source-inline"><span class="koboSpan" id="kobo.641.1" xmlns:="http://www.w3.org/1999/xhtml">CountVectorizer()</span></strong><span class="koboSpan" id="kobo.642.1" xmlns:="http://www.w3.org/1999/xhtml"> so </span><a id="_idIndexMarker875"/><span class="koboSpan" id="kobo.643.1" xmlns:="http://www.w3.org/1999/xhtml">that, before </span><a id="_idIndexMarker876"/><span class="koboSpan" id="kobo.644.1" xmlns:="http://www.w3.org/1999/xhtml">creating </span><a id="_idIndexMarker877"/><span class="koboSpan" id="kobo.645.1" xmlns:="http://www.w3.org/1999/xhtml">the BoW, it puts the text in lowercase, removes stop words, and retains words that appear in, at least, 5% of the </span><span class="No-Break"><span class="koboSpan" id="kobo.646.1" xmlns:="http://www.w3.org/1999/xhtml">text pieces:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.647.1" xmlns:="http://www.w3.org/1999/xhtml">
vectorizer = CountVectorizer(
    lowercase=True,
    stop_words='english',
    ngram_range=(1, 1),
    min_df=0.05)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.648.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.649.1" xmlns:="http://www.w3.org/1999/xhtml">To introduce n-grams as part of the returned columns, we can change the value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.650.1" xmlns:="http://www.w3.org/1999/xhtml">ngrams_range</span></strong><span class="koboSpan" id="kobo.651.1" xmlns:="http://www.w3.org/1999/xhtml"> to, for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.652.1" xmlns:="http://www.w3.org/1999/xhtml">(1,2)</span></strong><span class="koboSpan" id="kobo.653.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.653.2" xmlns:="http://www.w3.org/1999/xhtml">The tuple provides the lower and upper boundaries of the range of n-values for different n-grams. </span><span class="koboSpan" id="kobo.653.3" xmlns:="http://www.w3.org/1999/xhtml">In the case of </span><strong class="source-inline"><span class="koboSpan" id="kobo.654.1" xmlns:="http://www.w3.org/1999/xhtml">(1,2)</span></strong><span class="koboSpan" id="kobo.655.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.656.1" xmlns:="http://www.w3.org/1999/xhtml">CountVectorizer()</span></strong><span class="koboSpan" id="kobo.657.1" xmlns:="http://www.w3.org/1999/xhtml"> will return single words and arrays of two </span><span class="No-Break"><span class="koboSpan" id="kobo.658.1" xmlns:="http://www.w3.org/1999/xhtml">consecutive words.</span></span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.659.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit </span><strong class="source-inline"><span class="koboSpan" id="kobo.660.1" xmlns:="http://www.w3.org/1999/xhtml">CountVectorizer()</span></strong><span class="koboSpan" id="kobo.661.1" xmlns:="http://www.w3.org/1999/xhtml"> so that it learns which words should be used in </span><span class="No-Break"><span class="koboSpan" id="kobo.662.1" xmlns:="http://www.w3.org/1999/xhtml">the BoW:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.663.1" xmlns:="http://www.w3.org/1999/xhtml">
vectorizer.fit(df['text'])</span></pre></li> <li><span class="koboSpan" id="kobo.664.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s create </span><span class="No-Break"><span class="koboSpan" id="kobo.665.1" xmlns:="http://www.w3.org/1999/xhtml">the BoW:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.666.1" xmlns:="http://www.w3.org/1999/xhtml">
X = vectorizer.</span><a id="_idTextAnchor1562"/><span class="koboSpan" id="kobo.667.1" xmlns:="http://www.w3.org/1999/xhtml">transform(df['text'])</span><a id="_idTextAnchor1563"/></pre></li> <li><span class="koboSpan" id="kobo.668.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s capture</span><a id="_idTextAnchor1564"/><span class="koboSpan" id="kobo.669.1" xmlns:="http://www.w3.org/1999/xhtml"> the BoW</span><a id="_idTextAnchor1565"/><span class="koboSpan" id="kobo.670.1" xmlns:="http://www.w3.org/1999/xhtml"> in a DataFrame with the corresponding </span><span class="No-Break"><span class="koboSpan" id="kobo.671.1" xmlns:="http://www.w3.org/1999/xhtml">feature names:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.672.1" xmlns:="http://www.w3.org/1999/xhtml">
bagofwords = pd.DataFrame(
    X.toarray(),
    columns = vectorizer.get_feature_names_out()
)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.673.1" xmlns:="http://www.w3.org/1999/xhtml">With </span><a id="_idIndexMarker878"/><span class="koboSpan" id="kobo.674.1" xmlns:="http://www.w3.org/1999/xhtml">that, we</span><a id="_idIndexMarker879"/><span class="koboSpan" id="kobo.675.1" xmlns:="http://www.w3.org/1999/xhtml"> have</span><a id="_idIndexMarker880"/><span class="koboSpan" id="kobo.676.1" xmlns:="http://www.w3.org/1999/xhtml"> created </span><a id="_idIndexMarker881"/><span class="koboSpan" id="kobo.677.1" xmlns:="http://www.w3.org/1999/xhtml">a </span><strong class="source-inline"><span class="koboSpan" id="kobo.678.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.679.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame that contains words as columns and the number of times they appeared in each text as values. </span><span class="koboSpan" id="kobo.679.2" xmlns:="http://www.w3.org/1999/xhtml">You can in</span><a id="_idTextAnchor1566"/><span class="koboSpan" id="kobo.680.1" xmlns:="http://www.w3.org/1999/xhtml">spect the result by </span><span class="No-Break"><span class="koboSpan" id="kobo.681.1" xmlns:="http://www.w3.org/1999/xhtml">executing </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.682.1" xmlns:="http://www.w3.org/1999/xhtml">bagofwords.head()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.683.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer201">
<span class="koboSpan" id="kobo.684.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 11.6 – A DataFrame with the BoW resulting from the 20 Newsgroup dataset" src="image/B22396_11_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.685.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 11.6 – A DataFrame with the BoW resulting from the 20 Newsgroup dataset</span></p>
<p><span class="koboSpan" id="kobo.686.1" xmlns:="http://www.w3.org/1999/xhtml">We can use</span><a id="_idTextAnchor1567"/><a id="_idTextAnchor1568"/><span class="koboSpan" id="kobo.687.1" xmlns:="http://www.w3.org/1999/xhtml"> this BoW as input for a machine </span><span class="No-Break"><span class="koboSpan" id="kobo.688.1" xmlns:="http://www.w3.org/1999/xhtml">learning model.</span></span></p>
<h2 id="_idParaDest-314"><a id="_idTextAnchor1569"/><span class="koboSpan" id="kobo.689.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.690.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.691.1" xmlns:="http://www.w3.org/1999/xhtml">CountVectorizer()</span></strong><span class="koboSpan" id="kobo.692.1" xmlns:="http://www.w3.org/1999/xhtml"> converts a collection of text documents into a matrix of token counts. </span><span class="koboSpan" id="kobo.692.2" xmlns:="http://www.w3.org/1999/xhtml">These tokens can be individual words or arrays of two or more consecutive words – that is, n-grams. </span><span class="koboSpan" id="kobo.692.3" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we created a B</span><a id="_idTextAnchor1570"/><span class="koboSpan" id="kobo.693.1" xmlns:="http://www.w3.org/1999/xhtml">oW from a text variable in </span><span class="No-Break"><span class="koboSpan" id="kobo.694.1" xmlns:="http://www.w3.org/1999/xhtml">a D</span><a id="_idTextAnchor1571"/><span class="koboSpan" id="kobo.695.1" xmlns:="http://www.w3.org/1999/xhtml">ataFrame.</span></span></p>
<p><span class="koboSpan" id="kobo.696.1" xmlns:="http://www.w3.org/1999/xhtml">We loaded the 20 Newsgroup text data</span><a id="_idTextAnchor1572"/><span class="koboSpan" id="kobo.697.1" xmlns:="http://www.w3.org/1999/xhtml">set from </span><strong class="source-inline"><span class="koboSpan" id="kobo.698.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-l</span><a id="_idTextAnchor1573"/><span class="koboSpan" id="kobo.699.1" xmlns:="http://www.w3.org/1999/xhtml">earn</span></strong><span class="koboSpan" id="kobo.700.1" xmlns:="http://www.w3.org/1999/xhtml"> and removed punctuation and numbers from the text rows using pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.701.1" xmlns:="http://www.w3.org/1999/xhtml">replace()</span></strong><span class="koboSpan" id="kobo.702.1" xmlns:="http://www.w3.org/1999/xhtml"> function, which can be accessed through pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.703.1" xmlns:="http://www.w3.org/1999/xhtml">str</span></strong><span class="koboSpan" id="kobo.704.1" xmlns:="http://www.w3.org/1999/xhtml"> module, to replace digits, </span><strong class="source-inline"><span class="koboSpan" id="kobo.705.1" xmlns:="http://www.w3.org/1999/xhtml">'\d+'</span></strong><span class="koboSpan" id="kobo.706.1" xmlns:="http://www.w3.org/1999/xhtml">, or symbols, </span><strong class="source-inline"><span class="koboSpan" id="kobo.707.1" xmlns:="http://www.w3.org/1999/xhtml">'[^\w\s]'</span></strong><span class="koboSpan" id="kobo.708.1" xmlns:="http://www.w3.org/1999/xhtml">, with empty strings, </span><strong class="source-inline"><span class="koboSpan" id="kobo.709.1" xmlns:="http://www.w3.org/1999/xhtml">''</span></strong><span class="koboSpan" id="kobo.710.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.710.2" xmlns:="http://www.w3.org/1999/xhtml">Then, we used </span><strong class="source-inline"><span class="koboSpan" id="kobo.711.1" xmlns:="http://www.w3.org/1999/xhtml">CountVectorizer()</span></strong><span class="koboSpan" id="kobo.712.1" xmlns:="http://www.w3.org/1999/xhtml"> to create the BoW. </span><span class="koboSpan" id="kobo.712.2" xmlns:="http://www.w3.org/1999/xhtml">We set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.713.1" xmlns:="http://www.w3.org/1999/xhtml">lowercase</span></strong><span class="koboSpan" id="kobo.714.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter to </span><strong class="source-inline"><span class="koboSpan" id="kobo.715.1" xmlns:="http://www.w3.org/1999/xhtml">True</span></strong><span class="koboSpan" id="kobo.716.1" xmlns:="http://www.w3.org/1999/xhtml"> to put the words in lowercase before extracting the BoW. </span><span class="koboSpan" id="kobo.716.2" xmlns:="http://www.w3.org/1999/xhtml">We set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.717.1" xmlns:="http://www.w3.org/1999/xhtml">stop_words</span></strong><span class="koboSpan" id="kobo.718.1" xmlns:="http://www.w3.org/1999/xhtml"> argument to </span><strong class="source-inline"><span class="koboSpan" id="kobo.719.1" xmlns:="http://www.w3.org/1999/xhtml">english</span></strong><span class="koboSpan" id="kobo.720.1" xmlns:="http://www.w3.org/1999/xhtml"> to ignore stop words – that is, to avoid stop words in the BoW. </span><span class="koboSpan" id="kobo.720.2" xmlns:="http://www.w3.org/1999/xhtml">We set </span><strong class="source-inline"><span class="koboSpan" id="kobo.721.1" xmlns:="http://www.w3.org/1999/xhtml">ngram_range</span></strong><span class="koboSpan" id="kobo.722.1" xmlns:="http://www.w3.org/1999/xhtml"> to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.723.1" xmlns:="http://www.w3.org/1999/xhtml">(1,1)</span></strong><span class="koboSpan" id="kobo.724.1" xmlns:="http://www.w3.org/1999/xhtml"> tuple to return only single words as columns. </span><span class="koboSpan" id="kobo.724.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, we set </span><strong class="source-inline"><span class="koboSpan" id="kobo.725.1" xmlns:="http://www.w3.org/1999/xhtml">min_df</span></strong><span class="koboSpan" id="kobo.726.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.727.1" xmlns:="http://www.w3.org/1999/xhtml">0.05</span></strong><span class="koboSpan" id="kobo.728.1" xmlns:="http://www.w3.org/1999/xhtml"> to return words that appeared in at least 5% of the texts, or, in other words, in 5% of the rows in </span><span class="No-Break"><span class="koboSpan" id="kobo.729.1" xmlns:="http://www.w3.org/1999/xhtml">the DataFrame.</span></span></p>
<p><span class="koboSpan" id="kobo.730.1" xmlns:="http://www.w3.org/1999/xhtml">After </span><a id="_idIndexMarker882"/><span class="koboSpan" id="kobo.731.1" xmlns:="http://www.w3.org/1999/xhtml">setting </span><a id="_idIndexMarker883"/><span class="koboSpan" id="kobo.732.1" xmlns:="http://www.w3.org/1999/xhtml">up</span><a id="_idIndexMarker884"/><span class="koboSpan" id="kobo.733.1" xmlns:="http://www.w3.org/1999/xhtml"> the</span><a id="_idIndexMarker885"/><span class="koboSpan" id="kobo.734.1" xmlns:="http://www.w3.org/1999/xhtml"> transformer, we used the </span><strong class="source-inline"><span class="koboSpan" id="kobo.735.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.736.1" xmlns:="http://www.w3.org/1999/xhtml"> method to allow the transformer to find the words that fulfill the preceding criteria. </span><span class="koboSpan" id="kobo.736.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.737.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.738.1" xmlns:="http://www.w3.org/1999/xhtml"> method, the transformer returned an object containing the BoW with its fea</span><a id="_idTextAnchor1574"/><a id="_idTextAnchor1575"/><span class="koboSpan" id="kobo.739.1" xmlns:="http://www.w3.org/1999/xhtml">ture names, which we captured in a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.740.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.741.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame.</span></span></p>
<h2 id="_idParaDest-315"><a id="_idTextAnchor1576"/><span class="koboSpan" id="kobo.742.1" xmlns:="http://www.w3.org/1999/xhtml">See also</span></h2>
<p><span class="koboSpan" id="kobo.743.1" xmlns:="http://www.w3.org/1999/xhtml">For more de</span><a id="_idTextAnchor1577"/><span class="koboSpan" id="kobo.744.1" xmlns:="http://www.w3.org/1999/xhtml">tails about </span><strong class="source-inline"><span class="koboSpan" id="kobo.745.1" xmlns:="http://www.w3.org/1999/xhtml">CountVectorizer()</span></strong><span class="koboSpan" id="kobo.746.1" xmlns:="http://www.w3.org/1999/xhtml">, visit the </span><strong class="source-inline"><span class="koboSpan" id="kobo.747.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.748.1" xmlns:="http://www.w3.org/1999/xhtml"> library’s documentation </span><span class="No-Break"><span class="koboSpan" id="kobo.749.1" xmlns:="http://www.w3.org/1999/xhtml">at </span></span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"><span class="No-Break"><span class="koboSpan" id="kobo.750.1" xmlns:="http://www.w3.org/1999/xhtml">https://scikit-learn.org/stable/modules/generated/s</span><span id="_idTextAnchor1578"/><span id="_idTextAnchor1579"/><span class="koboSpan" id="kobo.751.1" xmlns:="http://www.w3.org/1999/xhtml">klearn.feature_extraction.text.CountVectorizer.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.752.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h1 id="_idParaDest-316"><a id="_idTextAnchor1580"/><span class="koboSpan" id="kobo.753.1" xmlns:="http://www.w3.org/1999/xhtml">Implementing term frequency-inverse document frequency</span></h1>
<p><strong class="bold"><span class="koboSpan" id="kobo.754.1" xmlns:="http://www.w3.org/1999/xhtml">Term Frequency-Inverse Document Freq</span><a id="_idTextAnchor1581"/><span class="koboSpan" id="kobo.755.1" xmlns:="http://www.w3.org/1999/xhtml">uency</span></strong><span class="koboSpan" id="kobo.756.1" xmlns:="http://www.w3.org/1999/xhtml"> (</span><strong class="bold"><span class="koboSpan" id="kobo.757.1" xmlns:="http://www.w3.org/1999/xhtml">TF-IDF</span></strong><span class="koboSpan" id="kobo.758.1" xmlns:="http://www.w3.org/1999/xhtml">) is a numerical statistic that captures </span><a id="_idIndexMarker886"/><span class="koboSpan" id="kobo.759.1" xmlns:="http://www.w3.org/1999/xhtml">how relevant a word is in a document considering the entire collection of documents. </span><span class="koboSpan" id="kobo.759.2" xmlns:="http://www.w3.org/1999/xhtml">What does this mean? </span><span class="koboSpan" id="kobo.759.3" xmlns:="http://www.w3.org/1999/xhtml">Some words will appear a lot within a text document as well as across documents, such as the English words </span><em class="italic"><span class="koboSpan" id="kobo.760.1" xmlns:="http://www.w3.org/1999/xhtml">the</span></em><span class="koboSpan" id="kobo.761.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><em class="italic"><span class="koboSpan" id="kobo.762.1" xmlns:="http://www.w3.org/1999/xhtml">a</span></em><span class="koboSpan" id="kobo.763.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><em class="italic"><span class="koboSpan" id="kobo.764.1" xmlns:="http://www.w3.org/1999/xhtml">is</span></em><span class="koboSpan" id="kobo.765.1" xmlns:="http://www.w3.org/1999/xhtml">, for example. </span><span class="koboSpan" id="kobo.765.2" xmlns:="http://www.w3.org/1999/xhtml">These words generally convey little information about the actual content of the document and don’t make the text stand out from the crowd. </span><span class="koboSpan" id="kobo.765.3" xmlns:="http://www.w3.org/1999/xhtml">TF-IDF provides a way to </span><em class="italic"><span class="koboSpan" id="kobo.766.1" xmlns:="http://www.w3.org/1999/xhtml">weigh</span></em><span class="koboSpan" id="kobo.767.1" xmlns:="http://www.w3.org/1999/xhtml"> the importance of a word by considering how many times it appears in a document with regards to how often it appears across documents. </span><span class="koboSpan" id="kobo.767.2" xmlns:="http://www.w3.org/1999/xhtml">Hence, commonly occurring words such as </span><em class="italic"><span class="koboSpan" id="kobo.768.1" xmlns:="http://www.w3.org/1999/xhtml">the</span></em><span class="koboSpan" id="kobo.769.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><em class="italic"><span class="koboSpan" id="kobo.770.1" xmlns:="http://www.w3.org/1999/xhtml">a</span></em><span class="koboSpan" id="kobo.771.1" xmlns:="http://www.w3.org/1999/xhtml">, or </span><em class="italic"><span class="koboSpan" id="kobo.772.1" xmlns:="http://www.w3.org/1999/xhtml">is</span></em><span class="koboSpan" id="kobo.773.1" xmlns:="http://www.w3.org/1999/xhtml"> will have a low weight, and words that are more specific to a topic, such as </span><em class="italic"><span class="koboSpan" id="kobo.774.1" xmlns:="http://www.w3.org/1999/xhtml">leopard</span></em><span class="koboSpan" id="kobo.775.1" xmlns:="http://www.w3.org/1999/xhtml">, will have a </span><span class="No-Break"><span class="koboSpan" id="kobo.776.1" xmlns:="http://www.w3.org/1999/xhtml">higher weight.</span></span></p>
<p><span class="koboSpan" id="kobo.777.1" xmlns:="http://www.w3.org/1999/xhtml">TF-IDF is the product of two </span><a id="_idIndexMarker887"/><span class="koboSpan" id="kobo.778.1" xmlns:="http://www.w3.org/1999/xhtml">statistics: </span><strong class="bold"><span class="koboSpan" id="kobo.779.1" xmlns:="http://www.w3.org/1999/xhtml">Term Frequency</span></strong><span class="koboSpan" id="kobo.780.1" xmlns:="http://www.w3.org/1999/xhtml"> (</span><strong class="bold"><span class="koboSpan" id="kobo.781.1" xmlns:="http://www.w3.org/1999/xhtml">tf</span></strong><span class="koboSpan" id="kobo.782.1" xmlns:="http://www.w3.org/1999/xhtml">) and </span><strong class="bold"><span class="koboSpan" id="kobo.783.1" xmlns:="http://www.w3.org/1999/xhtml">Inverse Document Frequency</span></strong><span class="koboSpan" id="kobo.784.1" xmlns:="http://www.w3.org/1999/xhtml"> (</span><strong class="bold"><span class="koboSpan" id="kobo.785.1" xmlns:="http://www.w3.org/1999/xhtml">idf</span></strong><span class="koboSpan" id="kobo.786.1" xmlns:="http://www.w3.org/1999/xhtml">), represented </span><a id="_idIndexMarker888"/><span class="koboSpan" id="kobo.787.1" xmlns:="http://www.w3.org/1999/xhtml">as follows: </span><strong class="bold"><span class="koboSpan" id="kobo.788.1" xmlns:="http://www.w3.org/1999/xhtml">tf-idf = td × idf</span></strong><span class="koboSpan" id="kobo.789.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.789.2" xmlns:="http://www.w3.org/1999/xhtml">tf is, in its simplest form, the count of the word in an individual text. </span><span class="koboSpan" id="kobo.789.3" xmlns:="http://www.w3.org/1999/xhtml">So, for term </span><em class="italic"><span class="koboSpan" id="kobo.790.1" xmlns:="http://www.w3.org/1999/xhtml">t</span></em><span class="koboSpan" id="kobo.791.1" xmlns:="http://www.w3.org/1999/xhtml">, the tf is calculated as </span><em class="italic"><span class="koboSpan" id="kobo.792.1" xmlns:="http://www.w3.org/1999/xhtml">tf(t) = count(t)</span></em><span class="koboSpan" id="kobo.793.1" xmlns:="http://www.w3.org/1999/xhtml"> and is determined on a text-by-text basis. </span><span class="koboSpan" id="kobo.793.2" xmlns:="http://www.w3.org/1999/xhtml">The idf is a measure of how common the word is across </span><em class="italic"><span class="koboSpan" id="kobo.794.1" xmlns:="http://www.w3.org/1999/xhtml">all</span></em><span class="koboSpan" id="kobo.795.1" xmlns:="http://www.w3.org/1999/xhtml"> documents and is usually calculated on a logarithmic scale. </span><span class="koboSpan" id="kobo.795.2" xmlns:="http://www.w3.org/1999/xhtml">A common implementation is given by </span><span class="No-Break"><span class="koboSpan" id="kobo.796.1" xmlns:="http://www.w3.org/1999/xhtml">the following:</span></span></p>
<p><span class="koboSpan" id="kobo.797.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mfrac&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/48.png" style="vertical-align:-0.767em;height:2.041em;width:8.193em"/></span></p>
<p><span class="koboSpan" id="kobo.798.1" xmlns:="http://www.w3.org/1999/xhtml">Here, </span><em class="italic"><span class="koboSpan" id="kobo.799.1" xmlns:="http://www.w3.org/1999/xhtml">n</span></em><span class="koboSpan" id="kobo.800.1" xmlns:="http://www.w3.org/1999/xhtml"> is the total number of documents, and </span><em class="italic"><span class="koboSpan" id="kobo.801.1" xmlns:="http://www.w3.org/1999/xhtml">df(t)</span></em><span class="koboSpan" id="kobo.802.1" xmlns:="http://www.w3.org/1999/xhtml"> is the number of documents in which the term </span><em class="italic"><span class="koboSpan" id="kobo.803.1" xmlns:="http://www.w3.org/1999/xhtml">t</span></em><span class="koboSpan" id="kobo.804.1" xmlns:="http://www.w3.org/1999/xhtml"> appears. </span><span class="koboSpan" id="kobo.804.2" xmlns:="http://www.w3.org/1999/xhtml">The bigger the value of </span><em class="italic"><span class="koboSpan" id="kobo.805.1" xmlns:="http://www.w3.org/1999/xhtml">df(t)</span></em><span class="koboSpan" id="kobo.806.1" xmlns:="http://www.w3.org/1999/xhtml">, the lower the weighting for the term. </span><span class="koboSpan" id="kobo.806.2" xmlns:="http://www.w3.org/1999/xhtml">The importance of a word will be high if it appears a lot of times in a text (high </span><em class="italic"><span class="koboSpan" id="kobo.807.1" xmlns:="http://www.w3.org/1999/xhtml">tf</span></em><span class="koboSpan" id="kobo.808.1" xmlns:="http://www.w3.org/1999/xhtml">) or few times a</span><a id="_idTextAnchor1582"/><span class="koboSpan" id="kobo.809.1" xmlns:="http://www.w3.org/1999/xhtml">cross texts (</span><span class="No-Break"><span class="koboSpan" id="kobo.810.1" xmlns:="http://www.w3.org/1999/xhtml">high </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.811.1" xmlns:="http://www.w3.org/1999/xhtml">idf</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.812.1" xmlns:="http://www.w3.org/1999/xhtml">).</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.813.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.814.1" xmlns:="http://www.w3.org/1999/xhtml">TF-IDF can be used together with n-grams. </span><span class="koboSpan" id="kobo.814.2" xmlns:="http://www.w3.org/1999/xhtml">Similarly, to weigh an n-gram, we compound the n-gram frequency in a certain document with the frequency of the n-gram </span><span class="No-Break"><span class="koboSpan" id="kobo.815.1" xmlns:="http://www.w3.org/1999/xhtml">across documents.</span></span></p>
<p><span class="koboSpan" id="kobo.816.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will learn how to extract features u</span><a id="_idTextAnchor1583"/><a id="_idTextAnchor1584"/><span class="koboSpan" id="kobo.817.1" xmlns:="http://www.w3.org/1999/xhtml">sing TF-IDF with or without n-grams </span><span class="No-Break"><span class="koboSpan" id="kobo.818.1" xmlns:="http://www.w3.org/1999/xhtml">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.819.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.820.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-317"><a id="_idTextAnchor1585"/><span class="koboSpan" id="kobo.821.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></h2>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.822.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.823.1" xmlns:="http://www.w3.org/1999/xhtml"> uses a slightly different way to calculate the </span><span class="No-Break"><span class="koboSpan" id="kobo.824.1" xmlns:="http://www.w3.org/1999/xhtml">IDF statistic:</span></span></p>
<p><span class="koboSpan" id="kobo.825.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:m=&quot;http://schemas.openxmlformats.org/officeDocument/2006/math&quot; display=&quot;block&quot;&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;log&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;⁡&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mfenced separators=&quot;|&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mfrac&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mi&gt;d&lt;/mml:mi&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mfrac&gt;&lt;/mml:mrow&gt;&lt;/mml:mfenced&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:math&gt;" src="image/49.png" style="vertical-align:-0.817em;height:1.841em;width:10.479em"/></span></p>
<p><span class="koboSpan" id="kobo.826.1" xmlns:="http://www.w3.org/1999/xhtml">This formulation ensures that a word that appears in all texts receives the lowest weight of 1. </span><span class="koboSpan" id="kobo.826.2" xmlns:="http://www.w3.org/1999/xhtml">In addition, after calculating the TF-IDF for every word, </span><strong class="source-inline"><span class="koboSpan" id="kobo.827.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.828.1" xmlns:="http://www.w3.org/1999/xhtml"> normalizes the feature vector (that wit</span><a id="_idTextAnchor1586"/><span class="koboSpan" id="kobo.829.1" xmlns:="http://www.w3.org/1999/xhtml">h all the words) to its Euclidean norm. </span><span class="koboSpan" id="kobo.829.2" xmlns:="http://www.w3.org/1999/xhtml">For more details on the exact formula, visit the </span><strong class="source-inline"><span class="koboSpan" id="kobo.830.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.831.1" xmlns:="http://www.w3.org/1999/xhtml"> documentation </span><span class="No-Break"><span class="koboSpan" id="kobo.832.1" xmlns:="http://www.w3.org/1999/xhtml">at </span></span><a href="https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting"><span class="No-Break"><span class="koboSpan" id="kobo.833.1" xmlns:="http://www.w3.org/1999/xhtml">https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.834.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.835.1" xmlns:="http://www.w3.org/1999/xhtml">TF-IDF shares the characteristics of BoW when creating the term matrix – that is, high feature space and sparsity. </span><span class="koboSpan" id="kobo.835.2" xmlns:="http://www.w3.org/1999/xhtml">To reduce the number of features and sparsity, we can remove stop words, set the characters to lowercase, and retain words that appear in a minimum percentage</span><a id="_idIndexMarker889"/><span class="koboSpan" id="kobo.836.1" xmlns:="http://www.w3.org/1999/xhtml"> of observations. </span><span class="koboSpan" id="kobo.836.2" xmlns:="http://www.w3.org/1999/xhtml">If you are unfamiliar with these terms, visit the </span><em class="italic"><span class="koboSpan" id="kobo.837.1" xmlns:="http://www.w3.org/1999/xhtml">Creating features with bag-of-words and n-grams</span></em><span class="koboSpan" id="kobo.838.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe in this chapter for </span><span class="No-Break"><span class="koboSpan" id="kobo.839.1" xmlns:="http://www.w3.org/1999/xhtml">a recap.</span></span></p>
<p><span class="koboSpan" id="kobo.840.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will learn how to set words into lowercase, remove stop words, retain words with a minimum acceptable frequency, capture n-grams, and then return the TF-IDF statistic of words, all using a </span><a id="_idTextAnchor1587"/><a id="_idTextAnchor1588"/><span class="koboSpan" id="kobo.841.1" xmlns:="http://www.w3.org/1999/xhtml">single transformer from </span><span class="No-Break"><span class="koboSpan" id="kobo.842.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn: </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.843.1" xmlns:="http://www.w3.org/1999/xhtml">TfidfVectorizer()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.844.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-318"><a id="_idTextAnchor1589"/><span class="koboSpan" id="kobo.845.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.846.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by loading the necessary libraries and getting the </span><span class="No-Break"><span class="koboSpan" id="kobo.847.1" xmlns:="http://www.w3.org/1999/xhtml">dataset ready:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.848.1" xmlns:="http://www.w3.org/1999/xhtml">Load </span><strong class="source-inline"><span class="koboSpan" id="kobo.849.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.850.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.851.1" xmlns:="http://www.w3.org/1999/xhtml">TfidfVectorizer()</span></strong><span class="koboSpan" id="kobo.852.1" xmlns:="http://www.w3.org/1999/xhtml">, and the dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.853.1" xmlns:="http://www.w3.org/1999/xhtml">from </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.854.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.855.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.856.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.</span><a id="_idTextAnchor1590"/><span class="koboSpan" id="kobo.857.1" xmlns:="http://www.w3.org/1999/xhtml">text import (
    TfidfVectorizer
)</span></pre></li> <li><span class="koboSpan" id="kobo.858.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the train set part of the 20 Newsgroup dataset into a </span><span class="No-Break"><span class="koboSpan" id="kobo.859.1" xmlns:="http://www.w3.org/1999/xhtml">pandas DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.860.1" xmlns:="http://www.w3.org/1999/xhtml">
data = fetch_20newsgroups(subset='train')
df = pd.DataFrame(data.data, columns=['text'])</span></pre></li> <li><span class="koboSpan" id="kobo.861.1" xmlns:="http://www.w3.org/1999/xhtml">To make interpreting the results easier, let’s remove punctuation and numbers from the </span><span class="No-Break"><span class="koboSpan" id="kobo.862.1" xmlns:="http://www.w3.org/1999/xhtml">text variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.863.1" xmlns:="http://www.w3.org/1999/xhtml">
df['text'] = df['text'].str.replace(
    ‹[^\w\s]›,››, regex=True).str.replace(
    '\d+','', regex=True)</span></pre></li> <li><span class="koboSpan" id="kobo.864.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s set up </span><strong class="source-inline"><span class="koboSpan" id="kobo.865.1" xmlns:="http://www.w3.org/1999/xhtml">TfidfVectorize</span><a id="_idTextAnchor1591"/><span class="koboSpan" id="kobo.866.1" xmlns:="http://www.w3.org/1999/xhtml">r()</span></strong><span class="koboSpan" id="kobo.867.1" xmlns:="http://www.w3.org/1999/xhtml"> from </span><strong class="source-inline"><span class="koboSpan" id="kobo.868.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.869.1" xmlns:="http://www.w3.org/1999/xhtml"> so that, before creating the TF-IDF metrics, it puts all text in lowercase, removes stop words, and </span><a id="_idIndexMarker890"/><span class="koboSpan" id="kobo.870.1" xmlns:="http://www.w3.org/1999/xhtml">retains words that appear in at least 5% of the </span><span class="No-Break"><span class="koboSpan" id="kobo.871.1" xmlns:="http://www.w3.org/1999/xhtml">text pieces:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.872.1" xmlns:="http://www.w3.org/1999/xhtml">
vectorizer = TfidfVectorizer(
    lowercase=True,
    stop_words='english',
    ngram_range=(1, 1),
    min_df=0.05)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.873.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.874.1" xmlns:="http://www.w3.org/1999/xhtml">To introduce n-grams as part of the returned columns, we can change the value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.875.1" xmlns:="http://www.w3.org/1999/xhtml">ngrams_range</span></strong><span class="koboSpan" id="kobo.876.1" xmlns:="http://www.w3.org/1999/xhtml"> to, for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.877.1" xmlns:="http://www.w3.org/1999/xhtml">(1,2)</span></strong><span class="koboSpan" id="kobo.878.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.878.2" xmlns:="http://www.w3.org/1999/xhtml">The tuple provides the lower and upper boundaries of the range of n-values for different n-grams. </span><span class="koboSpan" id="kobo.878.3" xmlns:="http://www.w3.org/1999/xhtml">In the case of </span><strong class="source-inline"><span class="koboSpan" id="kobo.879.1" xmlns:="http://www.w3.org/1999/xhtml">(1,2)</span></strong><span class="koboSpan" id="kobo.880.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.881.1" xmlns:="http://www.w3.org/1999/xhtml">TfidfVectorizer()</span></strong><span class="koboSpan" id="kobo.882.1" xmlns:="http://www.w3.org/1999/xhtml"> will return single words and arrays of two consecutive words </span><span class="No-Break"><span class="koboSpan" id="kobo.883.1" xmlns:="http://www.w3.org/1999/xhtml">as columns.</span></span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.884.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit </span><strong class="source-inline"><span class="koboSpan" id="kobo.885.1" xmlns:="http://www.w3.org/1999/xhtml">TfidfVectorizer()</span></strong><span class="koboSpan" id="kobo.886.1" xmlns:="http://www.w3.org/1999/xhtml"> so that it learns which words should be introduced as columns of the TF-IDF matrix and determines the </span><span class="No-Break"><span class="koboSpan" id="kobo.887.1" xmlns:="http://www.w3.org/1999/xhtml">words’ </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.888.1" xmlns:="http://www.w3.org/1999/xhtml">idf</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.889.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.890.1" xmlns:="http://www.w3.org/1999/xhtml">
vectorizer.fit(df['text'])</span></pre></li> <li><span class="koboSpan" id="kobo.891.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s create the </span><span class="No-Break"><span class="koboSpan" id="kobo.892.1" xmlns:="http://www.w3.org/1999/xhtml">TF-IDF matrix:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.893.1" xmlns:="http://www.w3.org/1999/xhtml">
X</span><a id="_idTextAnchor1592"/><span class="koboSpan" id="kobo.894.1" xmlns:="http://www.w3.org/1999/xhtml"> = vectorizer.transform(df['text'])</span></pre></li> <li><span class="koboSpan" id="kobo.895.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s capture the TF-IDF matrix in a DataFrame with the corresponding </span><span class="No-Break"><span class="koboSpan" id="kobo.896.1" xmlns:="http://www.w3.org/1999/xhtml">feature names:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.897.1" xmlns:="http://www.w3.org/1999/xhtml">
tfidf = pd.DataFrame(
    X.toarray(),
    columns = vectorizer.get_feature_names_out()
)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.898.1" xmlns:="http://www.w3.org/1999/xhtml">With that, we </span><a id="_idIndexMarker891"/><span class="koboSpan" id="kobo.899.1" xmlns:="http://www.w3.org/1999/xhtml">have created a </span><strong class="source-inline"><span class="koboSpan" id="kobo.900.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.901.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame that contains words as columns and the TF-IDF as valu</span><a id="_idTextAnchor1593"/><span class="koboSpan" id="kobo.902.1" xmlns:="http://www.w3.org/1999/xhtml">es. </span><span class="koboSpan" id="kobo.902.2" xmlns:="http://www.w3.org/1999/xhtml">You can inspect the result by </span><span class="No-Break"><span class="koboSpan" id="kobo.903.1" xmlns:="http://www.w3.org/1999/xhtml">executing </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.904.1" xmlns:="http://www.w3.org/1999/xhtml">tfidf.head()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.905.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer204">
<span class="koboSpan" id="kobo.906.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 11.7 – A DataFrame with features resulting from TF-IDF" src="image/B22396_11_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.907.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 11.7 – A DataFrame with features resulting from TF-IDF</span></p>
<p><span class="koboSpan" id="kobo.908.1" xmlns:="http://www.w3.org/1999/xhtml">Now, we can use this t</span><a id="_idTextAnchor1594"/><a id="_idTextAnchor1595"/><span class="koboSpan" id="kobo.909.1" xmlns:="http://www.w3.org/1999/xhtml">erm frequency DataFrame to train machine </span><span class="No-Break"><span class="koboSpan" id="kobo.910.1" xmlns:="http://www.w3.org/1999/xhtml">lea</span><a id="_idTextAnchor1596"/><span class="koboSpan" id="kobo.911.1" xmlns:="http://www.w3.org/1999/xhtml">rning models.</span></span></p>
<h2 id="_idParaDest-319"><a id="_idTextAnchor1597"/><span class="koboSpan" id="kobo.912.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.913.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we extracted the TF-IDF values of words present in at least 5% of the documents by utilizing </span><strong class="source-inline"><span class="koboSpan" id="kobo.914.1" xmlns:="http://www.w3.org/1999/xhtml">TfidfVectorizer()</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.915.1" xmlns:="http://www.w3.org/1999/xhtml">from scikit-learn.</span></span></p>
<p><span class="koboSpan" id="kobo.916.1" xmlns:="http://www.w3.org/1999/xhtml">We loaded the 20 Newsgroup text dataset from </span><strong class="source-inline"><span class="koboSpan" id="kobo.917.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.918.1" xmlns:="http://www.w3.org/1999/xhtml"> and then removed punctuation and numbers from the text rows using pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.919.1" xmlns:="http://www.w3.org/1999/xhtml">replace()</span></strong><span class="koboSpan" id="kobo.920.1" xmlns:="http://www.w3.org/1999/xhtml">, which can be accessed through pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.921.1" xmlns:="http://www.w3.org/1999/xhtml">str</span></strong><span class="koboSpan" id="kobo.922.1" xmlns:="http://www.w3.org/1999/xhtml">, to replace digits, </span><strong class="source-inline"><span class="koboSpan" id="kobo.923.1" xmlns:="http://www.w3.org/1999/xhtml">'\d+'</span></strong><span class="koboSpan" id="kobo.924.1" xmlns:="http://www.w3.org/1999/xhtml">, or symbols, </span><strong class="source-inline"><span class="koboSpan" id="kobo.925.1" xmlns:="http://www.w3.org/1999/xhtml">'[^\w\s]'</span></strong><span class="koboSpan" id="kobo.926.1" xmlns:="http://www.w3.org/1999/xhtml">, with empty strings, </span><strong class="source-inline"><span class="koboSpan" id="kobo.927.1" xmlns:="http://www.w3.org/1999/xhtml">''</span></strong><span class="koboSpan" id="kobo.928.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.928.2" xmlns:="http://www.w3.org/1999/xhtml">Then, we used </span><strong class="source-inline"><span class="koboSpan" id="kobo.929.1" xmlns:="http://www.w3.org/1999/xhtml">TfidfVectorizer()</span></strong><span class="koboSpan" id="kobo.930.1" xmlns:="http://www.w3.org/1999/xhtml"> to create TF-IDF statistics for words. </span><span class="koboSpan" id="kobo.930.2" xmlns:="http://www.w3.org/1999/xhtml">We set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.931.1" xmlns:="http://www.w3.org/1999/xhtml">lowercase</span></strong><span class="koboSpan" id="kobo.932.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter to </span><strong class="source-inline"><span class="koboSpan" id="kobo.933.1" xmlns:="http://www.w3.org/1999/xhtml">True</span></strong><span class="koboSpan" id="kobo.934.1" xmlns:="http://www.w3.org/1999/xhtml"> to put words into lowercase before making the calculations. </span><span class="koboSpan" id="kobo.934.2" xmlns:="http://www.w3.org/1999/xhtml">We set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.935.1" xmlns:="http://www.w3.org/1999/xhtml">stop_words</span></strong><span class="koboSpan" id="kobo.936.1" xmlns:="http://www.w3.org/1999/xhtml"> argument to </span><strong class="source-inline"><span class="koboSpan" id="kobo.937.1" xmlns:="http://www.w3.org/1999/xhtml">english</span></strong><span class="koboSpan" id="kobo.938.1" xmlns:="http://www.w3.org/1999/xhtml"> to avoid stop words in the returned matrix. </span><span class="koboSpan" id="kobo.938.2" xmlns:="http://www.w3.org/1999/xhtml">We set </span><strong class="source-inline"><span class="koboSpan" id="kobo.939.1" xmlns:="http://www.w3.org/1999/xhtml">ngram_range</span></strong><span class="koboSpan" id="kobo.940.1" xmlns:="http://www.w3.org/1999/xhtml"> to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.941.1" xmlns:="http://www.w3.org/1999/xhtml">(1,1)</span></strong><span class="koboSpan" id="kobo.942.1" xmlns:="http://www.w3.org/1999/xhtml"> tuple to return single words as features. </span><span class="koboSpan" id="kobo.942.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, we set the </span><strong class="source-inline"><span class="koboSpan" id="kobo.943.1" xmlns:="http://www.w3.org/1999/xhtml">min_df</span></strong><span class="koboSpan" id="kobo.944.1" xmlns:="http://www.w3.org/1999/xhtml"> argument to </span><strong class="source-inline"><span class="koboSpan" id="kobo.945.1" xmlns:="http://www.w3.org/1999/xhtml">0.05</span></strong><span class="koboSpan" id="kobo.946.1" xmlns:="http://www.w3.org/1999/xhtml"> to return words that appear at least in 5% of the texts or, in other words, in 5% of </span><span class="No-Break"><span class="koboSpan" id="kobo.947.1" xmlns:="http://www.w3.org/1999/xhtml">the rows.</span></span></p>
<p><span class="koboSpan" id="kobo.948.1" xmlns:="http://www.w3.org/1999/xhtml">After setting up the transformer, we applied the </span><strong class="source-inline"><span class="koboSpan" id="kobo.949.1" xmlns:="http://www.w3.org/1999/xhtml">fi</span><a id="_idTextAnchor1598"/><span class="koboSpan" id="kobo.950.1" xmlns:="http://www.w3.org/1999/xhtml">t()</span></strong><span class="koboSpan" id="kobo.951.1" xmlns:="http://www.w3.org/1999/xhtml"> method to let the transformer find the words to</span><a id="_idIndexMarker892"/><span class="koboSpan" id="kobo.952.1" xmlns:="http://www.w3.org/1999/xhtml"> retain in the final term matrix. </span><span class="koboSpan" id="kobo.952.2" xmlns:="http://www.w3.org/1999/xhtml">With the </span><strong class="source-inline"><span class="koboSpan" id="kobo.953.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.954.1" xmlns:="http://www.w3.org/1999/xhtml"> method, the transformer returned an object with the words and their TF-IDF values, which we then captured in a pandas DataFrame with the appropriate feature names. </span><span class="koboSpan" id="kobo.954.2" xmlns:="http://www.w3.org/1999/xhtml">We </span><a id="_idTextAnchor1599"/><a id="_idTextAnchor1600"/><span class="koboSpan" id="kobo.955.1" xmlns:="http://www.w3.org/1999/xhtml">can now use these features in machine </span><span class="No-Break"><span class="koboSpan" id="kobo.956.1" xmlns:="http://www.w3.org/1999/xhtml">learning algorithms.</span></span></p>
<h2 id="_idParaDest-320"><span class="koboSpan" id="kobo.957.1" xmlns:="http://www.w3.org/1999/xhtml">See als</span><a id="_idTextAnchor1601"/><span class="koboSpan" id="kobo.958.1" xmlns:="http://www.w3.org/1999/xhtml">o</span></h2>
<p><span class="koboSpan" id="kobo.959.1" xmlns:="http://www.w3.org/1999/xhtml">For more details</span><a id="_idIndexMarker893"/><span class="koboSpan" id="kobo.960.1" xmlns:="http://www.w3.org/1999/xhtml"> on </span><strong class="source-inline"><span class="koboSpan" id="kobo.961.1" xmlns:="http://www.w3.org/1999/xhtml">TfidfVectorizer()</span></strong><span class="koboSpan" id="kobo.962.1" xmlns:="http://www.w3.org/1999/xhtml">, visit scikit-learn’s </span><span class="No-Break"><span class="koboSpan" id="kobo.963.1" xmlns:="http://www.w3.org/1999/xhtml">documentation: </span></span><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"><span class="No-Break"><span class="koboSpan" id="kobo.964.1" xmlns:="http://www.w3.org/1999/xhtml">https://scikit-learn.org/stable/modules/gen</span><span id="_idTextAnchor1602"/><span id="_idTextAnchor1603"/><span class="koboSpan" id="kobo.965.1" xmlns:="http://www.w3.org/1999/xhtml">erated/sklearn.feature_extraction.text.TfidfVectori</span><span id="_idTextAnchor1604"/><span class="koboSpan" id="kobo.966.1" xmlns:="http://www.w3.org/1999/xhtml">zer.html</span></span></a></p>
<h1 id="_idParaDest-321"><span class="koboSpan" id="kobo.967.1" xmlns:="http://www.w3.org/1999/xhtml">Cleani</span><a id="_idTextAnchor1605"/><span class="koboSpan" id="kobo.968.1" xmlns:="http://www.w3.org/1999/xhtml">ng and stemming text variables</span></h1>
<p><span class="koboSpan" id="kobo.969.1" xmlns:="http://www.w3.org/1999/xhtml">Some variables in our</span><a id="_idIndexMarker894"/><span class="koboSpan" id="kobo.970.1" xmlns:="http://www.w3.org/1999/xhtml"> dataset come from free text fields, which are manually </span><a id="_idIndexMarker895"/><span class="koboSpan" id="kobo.971.1" xmlns:="http://www.w3.org/1999/xhtml">completed by users. </span><span class="koboSpan" id="kobo.971.2" xmlns:="http://www.w3.org/1999/xhtml">People have different writing styles, and we use a variety of punctuation marks, capitalization patterns, and verb conjugations to convey the content, as well as the emotions surrounding it. </span><span class="koboSpan" id="kobo.971.3" xmlns:="http://www.w3.org/1999/xhtml">We can extract (some) information from text without taking the trouble to read it by creating statistical parameters that summarize the text’s complexity, keywords, and relevance of words in a document. </span><span class="koboSpan" id="kobo.971.4" xmlns:="http://www.w3.org/1999/xhtml">We discussed these methods in the previous recipes of this chapter. </span><span class="koboSpan" id="kobo.971.5" xmlns:="http://www.w3.org/1999/xhtml">However, to derive these statistics and aggregated features, we should clean the</span><a id="_idTextAnchor1606"/><span class="koboSpan" id="kobo.972.1" xmlns:="http://www.w3.org/1999/xhtml"> text </span><span class="No-Break"><span class="koboSpan" id="kobo.973.1" xmlns:="http://www.w3.org/1999/xhtml">variables first.</span></span></p>
<p><span class="koboSpan" id="kobo.974.1" xmlns:="http://www.w3.org/1999/xhtml">Text cleaning or preprocessing involves punctuation removal, stop word elimination, character case setting, and word stemming. </span><span class="koboSpan" id="kobo.974.2" xmlns:="http://www.w3.org/1999/xhtml">Punctuation removal consists of deleting characters that are not letters, numbers, or spaces; in some cases, we also remove numbers. </span><span class="koboSpan" id="kobo.974.3" xmlns:="http://www.w3.org/1999/xhtml">The elimination of stop words refers to removing common words that are used in our language to allow for the sentence structure and flow, but that individually convey little or no information. </span><span class="koboSpan" id="kobo.974.4" xmlns:="http://www.w3.org/1999/xhtml">Examples of stop words include articles such as </span><em class="italic"><span class="koboSpan" id="kobo.975.1" xmlns:="http://www.w3.org/1999/xhtml">the</span></em><span class="koboSpan" id="kobo.976.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><em class="italic"><span class="koboSpan" id="kobo.977.1" xmlns:="http://www.w3.org/1999/xhtml">a</span></em><span class="koboSpan" id="kobo.978.1" xmlns:="http://www.w3.org/1999/xhtml"> for the English language, as well as pronouns such as </span><em class="italic"><span class="koboSpan" id="kobo.979.1" xmlns:="http://www.w3.org/1999/xhtml">I</span></em><span class="koboSpan" id="kobo.980.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><em class="italic"><span class="koboSpan" id="kobo.981.1" xmlns:="http://www.w3.org/1999/xhtml">you</span></em><span class="koboSpan" id="kobo.982.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><em class="italic"><span class="koboSpan" id="kobo.983.1" xmlns:="http://www.w3.org/1999/xhtml">they</span></em><span class="koboSpan" id="kobo.984.1" xmlns:="http://www.w3.org/1999/xhtml">, and commonly used verbs in their various conjugations, such as the verbs </span><em class="italic"><span class="koboSpan" id="kobo.985.1" xmlns:="http://www.w3.org/1999/xhtml">to be</span></em><span class="koboSpan" id="kobo.986.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><em class="italic"><span class="koboSpan" id="kobo.987.1" xmlns:="http://www.w3.org/1999/xhtml">to have</span></em><span class="koboSpan" id="kobo.988.1" xmlns:="http://www.w3.org/1999/xhtml">, as well as the auxiliary verbs </span><em class="italic"><span class="koboSpan" id="kobo.989.1" xmlns:="http://www.w3.org/1999/xhtml">would</span></em> <span class="No-Break"><span class="koboSpan" id="kobo.990.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.991.1" xmlns:="http://www.w3.org/1999/xhtml">do</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.992.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.993.1" xmlns:="http://www.w3.org/1999/xhtml">To allow computers to identify words correctly, it is also necessary to set all the words in the same case, since the words </span><em class="italic"><span class="koboSpan" id="kobo.994.1" xmlns:="http://www.w3.org/1999/xhtml">Toy</span></em><span class="koboSpan" id="kobo.995.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><em class="italic"><span class="koboSpan" id="kobo.996.1" xmlns:="http://www.w3.org/1999/xhtml">toy</span></em><span class="koboSpan" id="kobo.997.1" xmlns:="http://www.w3.org/1999/xhtml"> would be identified as being different by a computer due to the uppercase </span><em class="italic"><span class="koboSpan" id="kobo.998.1" xmlns:="http://www.w3.org/1999/xhtml">T</span></em><span class="koboSpan" id="kobo.999.1" xmlns:="http://www.w3.org/1999/xhtml"> in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1000.1" xmlns:="http://www.w3.org/1999/xhtml">first one.</span></span></p>
<p><span class="koboSpan" id="kobo.1001.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, to focus on the </span><em class="italic"><span class="koboSpan" id="kobo.1002.1" xmlns:="http://www.w3.org/1999/xhtml">message</span></em><span class="koboSpan" id="kobo.1003.1" xmlns:="http://www.w3.org/1999/xhtml"> of the text, we don’t want computers to consider words differently if they show different conjugations. </span><span class="koboSpan" id="kobo.1003.2" xmlns:="http://www.w3.org/1999/xhtml">Hence, we would use word stemming as part of the preprocessing pipeline. </span><span class="koboSpan" id="kobo.1003.3" xmlns:="http://www.w3.org/1999/xhtml">Word stemming refers to reducing each word to its root or base so that the words </span><em class="italic"><span class="koboSpan" id="kobo.1004.1" xmlns:="http://www.w3.org/1999/xhtml">playing</span></em><span class="koboSpan" id="kobo.1005.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><em class="italic"><span class="koboSpan" id="kobo.1006.1" xmlns:="http://www.w3.org/1999/xhtml">plays</span></em><span class="koboSpan" id="kobo.1007.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><em class="italic"><span class="koboSpan" id="kobo.1008.1" xmlns:="http://www.w3.org/1999/xhtml">played</span></em><span class="koboSpan" id="kobo.1009.1" xmlns:="http://www.w3.org/1999/xhtml"> become </span><em class="italic"><span class="koboSpan" id="kobo.1010.1" xmlns:="http://www.w3.org/1999/xhtml">play</span></em><span class="koboSpan" id="kobo.1011.1" xmlns:="http://www.w3.org/1999/xhtml">, which, in essence, conveys the same or very </span><span class="No-Break"><span class="koboSpan" id="kobo.1012.1" xmlns:="http://www.w3.org/1999/xhtml">similar meaning.</span></span></p>
<p><span class="koboSpan" id="kobo.1013.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will learn how to remove punctuation and stop words, set words </span><a id="_idTextAnchor1607"/><a id="_idTextAnchor1608"/><span class="koboSpan" id="kobo.1014.1" xmlns:="http://www.w3.org/1999/xhtml">in lowercase, and perform word stemming with pandas </span><span class="No-Break"><span class="koboSpan" id="kobo.1015.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1016.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1017.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-322"><a id="_idTextAnchor1609"/><span class="koboSpan" id="kobo.1018.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.1019.1" xmlns:="http://www.w3.org/1999/xhtml">We are going to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1020.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.1021.1" xmlns:="http://www.w3.org/1999/xhtml"> stem package to perform word stemming, which incorporates different algorithms to stem words from English and other languages. </span><span class="koboSpan" id="kobo.1021.2" xmlns:="http://www.w3.org/1999/xhtml">Each method differs in the algorithm it uses to find the </span><em class="italic"><span class="koboSpan" id="kobo.1022.1" xmlns:="http://www.w3.org/1999/xhtml">root</span></em><span class="koboSpan" id="kobo.1023.1" xmlns:="http://www.w3.org/1999/xhtml"> of the word; therefore, they may output slightly different results. </span><span class="koboSpan" id="kobo.1023.2" xmlns:="http://www.w3.org/1999/xhtml">I recommend reading more about it, trying different methods, and </span><a id="_idIndexMarker896"/><span class="koboSpan" id="kobo.1024.1" xmlns:="http://www.w3.org/1999/xhtml">choosing </span><a id="_idIndexMarker897"/><span class="koboSpan" id="kobo.1025.1" xmlns:="http://www.w3.org/1999/xhtml">the </span><a id="_idTextAnchor1610"/><span class="koboSpan" id="kobo.1026.1" xmlns:="http://www.w3.org/1999/xhtml">one that serves the project you are </span><span class="No-Break"><span class="koboSpan" id="kobo.1027.1" xmlns:="http://www.w3.org/1999/xhtml">working on.</span></span></p>
<p><span class="koboSpan" id="kobo.1028.1" xmlns:="http://www.w3.org/1999/xhtml">More information about NLTK st</span><a id="_idTextAnchor1611"/><a id="_idTextAnchor1612"/><span class="koboSpan" id="kobo.1029.1" xmlns:="http://www.w3.org/1999/xhtml">emmers can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.1030.1" xmlns:="http://www.w3.org/1999/xhtml">at </span></span><a href="https://www.nltk.org/api/nltk.stem.html"><span class="No-Break"><span class="koboSpan" id="kobo.1031.1" xmlns:="http://www.w3.org/1999/xhtml">https://www.nlt</span><span id="_idTextAnchor1613"/><span class="koboSpan" id="kobo.1032.1" xmlns:="http://www.w3.org/1999/xhtml">k.org/api/nltk.stem.html</span></span></a><span class="No-Break"><a id="_idTextAnchor1614"/></span><span class="No-Break"><span class="koboSpan" id="kobo.1033.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-323"><a id="_idTextAnchor1615"/><span class="koboSpan" id="kobo.1034.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.1035.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by loading the necessary libraries and getting the </span><span class="No-Break"><span class="koboSpan" id="kobo.1036.1" xmlns:="http://www.w3.org/1999/xhtml">dataset ready:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.1037.1" xmlns:="http://www.w3.org/1999/xhtml">Load </span><strong class="source-inline"><span class="koboSpan" id="kobo.1038.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.1039.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1040.1" xmlns:="http://www.w3.org/1999/xhtml">stopwords</span></strong><span class="koboSpan" id="kobo.1041.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1042.1" xmlns:="http://www.w3.org/1999/xhtml">SnowballStemmer</span></strong><span class="koboSpan" id="kobo.1043.1" xmlns:="http://www.w3.org/1999/xhtml"> from </span><strong class="source-inline"><span class="koboSpan" id="kobo.1044.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.1045.1" xmlns:="http://www.w3.org/1999/xhtml"> and the dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.1046.1" xmlns:="http://www.w3.org/1999/xhtml">from </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1047.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1048.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1049.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer
from sklearn.datasets import fetch_20newsgroups</span></pre></li> <li><span class="koboSpan" id="kobo.1050.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the train set part of the 20 Newsgroup dataset into a </span><span class="No-Break"><span class="koboSpan" id="kobo.1051.1" xmlns:="http://www.w3.org/1999/xhtml">pandas DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1052.1" xmlns:="http://www.w3.org/1999/xhtml">
data = fetch_20newsgroups(subset='train')
df = pd.DataFrame(data.data, columns=['text'])</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1053.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s begin with the </span><span class="No-Break"><span class="koboSpan" id="kobo.1054.1" xmlns:="http://www.w3.org/1999/xhtml">text cleaning.</span></span></p></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.1055.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1056.1" xmlns:="http://www.w3.org/1999/xhtml">After executing each of the commands in this recipe, print some example texts by executing, for example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1057.1" xmlns:="http://www.w3.org/1999/xhtml">print(df['text'][10])</span></strong><span class="koboSpan" id="kobo.1058.1" xmlns:="http://www.w3.org/1999/xhtml"> so that you can visualize the changes introduced to the text. </span><span class="koboSpan" id="kobo.1058.2" xmlns:="http://www.w3.org/1999/xhtml">Go ahead and do it now, and then repeat the command after </span><span class="No-Break"><span class="koboSpan" id="kobo.1059.1" xmlns:="http://www.w3.org/1999/xhtml">each step.</span></span></p>
<ol>
<li value="3"><span class="koboSpan" id="kobo.1060.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by removing </span><span class="No-Break"><span class="koboSpan" id="kobo.1061.1" xmlns:="http://www.w3.org/1999/xhtml">the punctuation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1062.1" xmlns:="http://www.w3.org/1999/xhtml">
df["text"] = df['text'].str.replace('[^\w\s]','')</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.1063.1" xmlns:="http://www.w3.org/1999/xhtml">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1064.1" xmlns:="http://www.w3.org/1999/xhtml">You can also remove the punctuation using the built-in </span><strong class="source-inline"><span class="koboSpan" id="kobo.1065.1" xmlns:="http://www.w3.org/1999/xhtml">string</span></strong><span class="koboSpan" id="kobo.1066.1" xmlns:="http://www.w3.org/1999/xhtml"> module from Python. </span><span class="koboSpan" id="kobo.1066.2" xmlns:="http://www.w3.org/1999/xhtml">First, import the module by executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.1067.1" xmlns:="http://www.w3.org/1999/xhtml">import string</span></strong><span class="koboSpan" id="kobo.1068.1" xmlns:="http://www.w3.org/1999/xhtml"> and then execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.1069.1" xmlns:="http://www.w3.org/1999/xhtml">df['text'] = </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1070.1" xmlns:="http://www.w3.org/1999/xhtml">df['text'].str.replace('[{}]</span><a id="_idTextAnchor1616"/><span class="koboSpan" id="kobo.1071.1" xmlns:="http://www.w3.org/1999/xhtml">'.format(string.punctuatio</span><a id="_idTextAnchor1617"/><span class="koboSpan" id="kobo.1072.1" xmlns:="http://www.w3.org/1999/xhtml">n), '')</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1073.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.1074.1" xmlns:="http://www.w3.org/1999/xhtml">We can also</span><a id="_idIndexMarker898"/><span class="koboSpan" id="kobo.1075.1" xmlns:="http://www.w3.org/1999/xhtml"> remove </span><a id="_idIndexMarker899"/><span class="koboSpan" id="kobo.1076.1" xmlns:="http://www.w3.org/1999/xhtml">characters that are numbers, leaving only letters, </span><span class="No-Break"><span class="koboSpan" id="kobo.1077.1" xmlns:="http://www.w3.org/1999/xhtml">as follows:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1078.1" xmlns:="http://www.w3.org/1999/xhtml">
df['text'] = df['text'].str.replace(
    '\d+', '', regex=True)</span></pre></li> <li><span class="koboSpan" id="kobo.1079.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s set all words </span><span class="No-Break"><span class="koboSpan" id="kobo.1080.1" xmlns:="http://www.w3.org/1999/xhtml">into lowercase:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1081.1" xmlns:="http://www.w3.org/1999/xhtml">
df['text'] = df['text'].str.lower()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1082.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s start the p</span><a id="_idTextAnchor1618"/><span class="koboSpan" id="kobo.1083.1" xmlns:="http://www.w3.org/1999/xhtml">rocess of removing </span><span class="No-Break"><span class="koboSpan" id="kobo.1084.1" xmlns:="http://www.w3.org/1999/xhtml">stop words.</span></span></p></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.1085.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><em class="italic"><span class="koboSpan" id="kobo.1086.1" xmlns:="http://www.w3.org/1999/xhtml">Step 6</span></em><span class="koboSpan" id="kobo.1087.1" xmlns:="http://www.w3.org/1999/xhtml"> may fail if you did not download the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1088.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.1089.1" xmlns:="http://www.w3.org/1999/xhtml"> library’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.1090.1" xmlns:="http://www.w3.org/1999/xhtml">stopwords</span></strong><span class="koboSpan" id="kobo.1091.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1091.2" xmlns:="http://www.w3.org/1999/xhtml">Visit the </span><em class="italic"><span class="koboSpan" id="kobo.1092.1" xmlns:="http://www.w3.org/1999/xhtml">Technical requirements</span></em><span class="koboSpan" id="kobo.1093.1" xmlns:="http://www.w3.org/1999/xhtml"> section in this chapter for </span><span class="No-Break"><span class="koboSpan" id="kobo.1094.1" xmlns:="http://www.w3.org/1999/xhtml">more details.</span></span></p>
<ol>
<li value="6"><span class="koboSpan" id="kobo.1095.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create a function that splits a string into a list of words, removes the stop words, and finally concatenates the remaining words back into </span><span class="No-Break"><span class="koboSpan" id="kobo.1096.1" xmlns:="http://www.w3.org/1999/xhtml">a string:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1097.1" xmlns:="http://www.w3.org/1999/xhtml">
def remove_stopwords(text):
    stop = set(stopwords.words('english'))
    text = [word
    for word in text.split() if word not in stop]
    text = ‹ ‹.join(x for x in text)
    return text</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.1098.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1099.1" xmlns:="http://www.w3.org/1999/xhtml">To be able to process the data with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1100.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn</span></strong><span class="koboSpan" id="kobo.1101.1" xmlns:="http://www.w3.org/1999/xhtml"> librar</span><a id="_idTextAnchor1619"/><span class="koboSpan" id="kobo.1102.1" xmlns:="http://www.w3.org/1999/xhtml">y’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.1103.1" xmlns:="http://www.w3.org/1999/xhtml">CountVectorizer()</span></strong><span class="koboSpan" id="kobo.1104.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.1105.1" xmlns:="http://www.w3.org/1999/xhtml">TfidfVecto</span><a id="_idTextAnchor1620"/><span class="koboSpan" id="kobo.1106.1" xmlns:="http://www.w3.org/1999/xhtml">rizer()</span></strong><span class="koboSpan" id="kobo.1107.1" xmlns:="http://www.w3.org/1999/xhtml">, we need the text to be in string format. </span><span class="koboSpan" id="kobo.1107.2" xmlns:="http://www.w3.org/1999/xhtml">Therefore, after removing the stop words, we need to return the words as a single string. </span><span class="koboSpan" id="kobo.1107.3" xmlns:="http://www.w3.org/1999/xhtml">We have transformed the NLTK library’s stop words list into a set because sets are faster to scan than lists. </span><span class="koboSpan" id="kobo.1107.4" xmlns:="http://www.w3.org/1999/xhtml">This improves the </span><span class="No-Break"><span class="koboSpan" id="kobo.1108.1" xmlns:="http://www.w3.org/1999/xhtml">computation time.</span></span></p>
<ol>
<li value="7"><span class="koboSpan" id="kobo.1109.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s use</span><a id="_idIndexMarker900"/><span class="koboSpan" id="kobo.1110.1" xmlns:="http://www.w3.org/1999/xhtml"> the </span><a id="_idIndexMarker901"/><span class="koboSpan" id="kobo.1111.1" xmlns:="http://www.w3.org/1999/xhtml">function from </span><em class="italic"><span class="koboSpan" id="kobo.1112.1" xmlns:="http://www.w3.org/1999/xhtml">step 6</span></em><span class="koboSpan" id="kobo.1113.1" xmlns:="http://www.w3.org/1999/xhtml"> to remove stop words from the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1114.1" xmlns:="http://www.w3.org/1999/xhtml">text</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1115.1" xmlns:="http://www.w3.org/1999/xhtml"> variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1116.1" xmlns:="http://www.w3.org/1999/xhtml">
df['text'] = df['text'].apply(remove_stopwords)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1117.1" xmlns:="http://www.w3.org/1999/xhtml">If you want to know which words are</span><a id="_idTextAnchor1621"/><span class="koboSpan" id="kobo.1118.1" xmlns:="http://www.w3.org/1999/xhtml"> stop word</span><a id="_idTextAnchor1622"/><span class="koboSpan" id="kobo.1119.1" xmlns:="http://www.w3.org/1999/xhtml">s, </span><span class="No-Break"><span class="koboSpan" id="kobo.1120.1" xmlns:="http://www.w3.org/1999/xhtml">execute </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1121.1" xmlns:="http://www.w3.org/1999/xhtml">stopwords.words('english')</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1122.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.1123.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s stem the words in our data. </span><span class="koboSpan" id="kobo.1123.2" xmlns:="http://www.w3.org/1999/xhtml">We will use </span><strong class="source-inline"><span class="koboSpan" id="kobo.1124.1" xmlns:="http://www.w3.org/1999/xhtml">SnowballStemmer</span></strong><span class="koboSpan" id="kobo.1125.1" xmlns:="http://www.w3.org/1999/xhtml"> from </span><strong class="source-inline"><span class="koboSpan" id="kobo.1126.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.1127.1" xmlns:="http://www.w3.org/1999/xhtml"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.1128.1" xmlns:="http://www.w3.org/1999/xhtml">do so.</span></span></p></li> <li><span class="koboSpan" id="kobo.1129.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create an instance of </span><strong class="source-inline"><span class="koboSpan" id="kobo.1130.1" xmlns:="http://www.w3.org/1999/xhtml">SnowballStemer</span></strong><span class="koboSpan" id="kobo.1131.1" xmlns:="http://www.w3.org/1999/xhtml"> for the </span><span class="No-Break"><span class="koboSpan" id="kobo.1132.1" xmlns:="http://www.w3.org/1999/xhtml">English language:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1133.1" xmlns:="http://www.w3.org/1999/xhtml">
stemmer = SnowballStemmer("english")</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.1134.1" xmlns:="http://www.w3.org/1999/xhtml">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1135.1" xmlns:="http://www.w3.org/1999/xhtml">Try the stemmer in a single word to see how it works; for example, run </span><strong class="source-inline"><span class="koboSpan" id="kobo.1136.1" xmlns:="http://www.w3.org/1999/xhtml">stemmer.stem('running')</span></strong><span class="koboSpan" id="kobo.1137.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1137.2" xmlns:="http://www.w3.org/1999/xhtml">You should see </span><strong class="source-inline"><span class="koboSpan" id="kobo.1138.1" xmlns:="http://www.w3.org/1999/xhtml">run</span></strong><span class="koboSpan" id="kobo.1139.1" xmlns:="http://www.w3.org/1999/xhtml"> as the result of that command. </span><span class="koboSpan" id="kobo.1139.2" xmlns:="http://www.w3.org/1999/xhtml">Try </span><span class="No-Break"><span class="koboSpan" id="kobo.1140.1" xmlns:="http://www.w3.org/1999/xhtml">different words!</span></span></p>
<ol>
<li value="9"><span class="koboSpan" id="kobo.1141.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s create a function that splits a string into a list of words, applies </span><strong class="source-inline"><span class="koboSpan" id="kobo.1142.1" xmlns:="http://www.w3.org/1999/xhtml">stemmer</span></strong><span class="koboSpan" id="kobo.1143.1" xmlns:="http://www.w3.org/1999/xhtml"> to each word, and finally concatenates the stemmed word list back into </span><span class="No-Break"><span class="koboSpan" id="kobo.1144.1" xmlns:="http://www.w3.org/1999/xhtml">a string:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1145.1" xmlns:="http://www.w3.org/1999/xhtml">
def stemm_words(text):
    text = [
        stemmer.stem(word) for word in text.split()
    ]
    text = ‹ ‹.join(x for x in text)
    return text</span></pre></li> <li><span class="koboSpan" id="kobo.1146.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s use</span><a id="_idIndexMarker902"/><span class="koboSpan" id="kobo.1147.1" xmlns:="http://www.w3.org/1999/xhtml"> the </span><a id="_idIndexMarker903"/><span class="koboSpan" id="kobo.1148.1" xmlns:="http://www.w3.org/1999/xhtml">function from </span><em class="italic"><span class="koboSpan" id="kobo.1149.1" xmlns:="http://www.w3.org/1999/xhtml">step 9</span></em><span class="koboSpan" id="kobo.1150.1" xmlns:="http://www.w3.org/1999/xhtml"> to stem the words in </span><span class="No-Break"><span class="koboSpan" id="kobo.1151.1" xmlns:="http://www.w3.org/1999/xhtml">our data:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.1152.1" xmlns:="http://www.w3.org/1999/xhtml">
df['text'] = df['text'].apply(stemm_words)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.1153.1" xmlns:="http://www.w3.org/1999/xhtml">Now, our text is ready to create features based on character and word counts, as well as create BoWs or TF-IDF matrices, as described in the previous recipes of </span><span class="No-Break"><span class="koboSpan" id="kobo.1154.1" xmlns:="http://www.w3.org/1999/xhtml">this chapter.</span></span></p><p class="list-inset"><span class="koboSpan" id="kobo.1155.1" xmlns:="http://www.w3.org/1999/xhtml">If we execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.1156.1" xmlns:="http://www.w3.org/1999/xhtml">print(df['text'][10])</span></strong><span class="koboSpan" id="kobo.1157.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see a text example </span><span class="No-Break"><span class="koboSpan" id="kobo.1158.1" xmlns:="http://www.w3.org/1999/xhtml">after cleaning:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.1159.1" xmlns:="http://www.w3.org/1999/xhtml">irwincmptrclonestarorg irwin arnstein subject recommend duc summari what worth distribut usa expir sat may gmt organ computrac inc richardson tx keyword ducati gts much line line ducati gts model k clock run well paint bronzebrownorang fade leak bit oil pop st hard accel shop fix tran oil leak sold bike owner want think like k opinion pleas email thank would nice stabl mate beemer ill get jap bike call axi motor tuba irwin honk therefor computracrichardsontx irwincmptrclonestarorg dod r</span></strong></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.1160.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1161.1" xmlns:="http://www.w3.org/1999/xhtml">If you are counting sentences, you need to do that before removing punctuation, as punctuation and</span><a id="_idTextAnchor1623"/><a id="_idTextAnchor1624"/><span class="koboSpan" id="kobo.1162.1" xmlns:="http://www.w3.org/1999/xhtml"> capitalization are needed to define the b</span><a id="_idTextAnchor1625"/><span class="koboSpan" id="kobo.1163.1" xmlns:="http://www.w3.org/1999/xhtml">oundaries of </span><span class="No-Break"><span class="koboSpan" id="kobo.1164.1" xmlns:="http://www.w3.org/1999/xhtml">each sentence.</span></span></p>
<h2 id="_idParaDest-324"><a id="_idTextAnchor1626"/><span class="koboSpan" id="kobo.1165.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.1166.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we </span><a id="_idTextAnchor1627"/><span class="koboSpan" id="kobo.1167.1" xmlns:="http://www.w3.org/1999/xhtml">removed punctuation, numbers, and stop words from a text variable, set the words in lowercase, and finally, stemmed the words to their root. </span><span class="koboSpan" id="kobo.1167.2" xmlns:="http://www.w3.org/1999/xhtml">We removed punctuation and numbers from the text variable using pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.1168.1" xmlns:="http://www.w3.org/1999/xhtml">replace()</span></strong><span class="koboSpan" id="kobo.1169.1" xmlns:="http://www.w3.org/1999/xhtml">, which can be accessed through pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.1170.1" xmlns:="http://www.w3.org/1999/xhtml">str</span></strong><span class="koboSpan" id="kobo.1171.1" xmlns:="http://www.w3.org/1999/xhtml">, to replace digits, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1172.1" xmlns:="http://www.w3.org/1999/xhtml">'\d+'</span></strong><span class="koboSpan" id="kobo.1173.1" xmlns:="http://www.w3.org/1999/xhtml">, or symbols, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1174.1" xmlns:="http://www.w3.org/1999/xhtml">'[^\w\s]'</span></strong><span class="koboSpan" id="kobo.1175.1" xmlns:="http://www.w3.org/1999/xhtml">, with empty strings, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1176.1" xmlns:="http://www.w3.org/1999/xhtml">''</span></strong><span class="koboSpan" id="kobo.1177.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1177.2" xmlns:="http://www.w3.org/1999/xhtml">Alternatively, we can use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1178.1" xmlns:="http://www.w3.org/1999/xhtml">punctuation</span></strong><span class="koboSpan" id="kobo.1179.1" xmlns:="http://www.w3.org/1999/xhtml"> module from the built-in </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1180.1" xmlns:="http://www.w3.org/1999/xhtml">string</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1181.1" xmlns:="http://www.w3.org/1999/xhtml"> package.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.1182.1" xmlns:="http://www.w3.org/1999/xhtml">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1183.1" xmlns:="http://www.w3.org/1999/xhtml">Run </span><strong class="source-inline"><span class="koboSpan" id="kobo.1184.1" xmlns:="http://www.w3.org/1999/xhtml">string.punctuation</span></strong><span class="koboSpan" id="kobo.1185.1" xmlns:="http://www.w3.org/1999/xhtml"> in your Python console after importing </span><strong class="source-inline"><span class="koboSpan" id="kobo.1186.1" xmlns:="http://www.w3.org/1999/xhtml">string</span></strong><span class="koboSpan" id="kobo.1187.1" xmlns:="http://www.w3.org/1999/xhtml"> to check out the symbols that will be replaced with </span><span class="No-Break"><span class="koboSpan" id="kobo.1188.1" xmlns:="http://www.w3.org/1999/xhtml">empty strings.</span></span></p>
<p><span class="koboSpan" id="kobo.1189.1" xmlns:="http://www.w3.org/1999/xhtml">Next, utilizing</span><a id="_idIndexMarker904"/><span class="koboSpan" id="kobo.1190.1" xmlns:="http://www.w3.org/1999/xhtml"> pandas’ string </span><a id="_idIndexMarker905"/><span class="koboSpan" id="kobo.1191.1" xmlns:="http://www.w3.org/1999/xhtml">processing functionality through </span><strong class="source-inline"><span class="koboSpan" id="kobo.1192.1" xmlns:="http://www.w3.org/1999/xhtml">str</span></strong><span class="koboSpan" id="kobo.1193.1" xmlns:="http://www.w3.org/1999/xhtml">, we set all of the words to lowercase with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1194.1" xmlns:="http://www.w3.org/1999/xhtml">lower()</span></strong><span class="koboSpan" id="kobo.1195.1" xmlns:="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.1195.2" xmlns:="http://www.w3.org/1999/xhtml">To remove stop words from the text, we used the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1196.1" xmlns:="http://www.w3.org/1999/xhtml">stopwords</span></strong><span class="koboSpan" id="kobo.1197.1" xmlns:="http://www.w3.org/1999/xhtml"> module from </span><strong class="source-inline"><span class="koboSpan" id="kobo.1198.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.1199.1" xmlns:="http://www.w3.org/1999/xhtml">, which contains a list of words that are considered frequent – that is, the stop words. </span><span class="koboSpan" id="kobo.1199.2" xmlns:="http://www.w3.org/1999/xhtml">We created a function that takes a string and splits it into a list of words using pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.1200.1" xmlns:="http://www.w3.org/1999/xhtml">str.split()</span></strong><span class="koboSpan" id="kobo.1201.1" xmlns:="http://www.w3.org/1999/xhtml">, and then, with list comprehension, we looped over the words in the list and retained the non-stop words. </span><span class="koboSpan" id="kobo.1201.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1202.1" xmlns:="http://www.w3.org/1999/xhtml">join()</span></strong><span class="koboSpan" id="kobo.1203.1" xmlns:="http://www.w3.org/1999/xhtml"> method, we concatenated the retained words back into a string. </span><span class="koboSpan" id="kobo.1203.2" xmlns:="http://www.w3.org/1999/xhtml">We used the built-in Python </span><strong class="source-inline"><span class="koboSpan" id="kobo.1204.1" xmlns:="http://www.w3.org/1999/xhtml">set()</span></strong><span class="koboSpan" id="kobo.1205.1" xmlns:="http://www.w3.org/1999/xhtml"> method over the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1206.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.1207.1" xmlns:="http://www.w3.org/1999/xhtml"> stop words list to improve computation efficiency since it is faster to iterate over sets than over lists. </span><span class="koboSpan" id="kobo.1207.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, with pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.1208.1" xmlns:="http://www.w3.org/1999/xhtml">apply()</span></strong><span class="koboSpan" id="kobo.1209.1" xmlns:="http://www.w3.org/1999/xhtml">, we applied the function to each row of our </span><span class="No-Break"><span class="koboSpan" id="kobo.1210.1" xmlns:="http://www.w3.org/1999/xhtml">text data.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.1211.1" xmlns:="http://www.w3.org/1999/xhtml">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.1212.1" xmlns:="http://www.w3.org/1999/xhtml">Run </span><strong class="source-inline"><span class="koboSpan" id="kobo.1213.1" xmlns:="http://www.w3.org/1999/xhtml">stopwords.words('english')</span></strong><span class="koboSpan" id="kobo.1214.1" xmlns:="http://www.w3.org/1999/xhtml"> in your Python console after importing </span><strong class="source-inline"><span class="koboSpan" id="kobo.1215.1" xmlns:="http://www.w3.org/1999/xhtml">stopwords</span></strong><span class="koboSpan" id="kobo.1216.1" xmlns:="http://www.w3.org/1999/xhtml"> from </span><strong class="source-inline"><span class="koboSpan" id="kobo.1217.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.1218.1" xmlns:="http://www.w3.org/1999/xhtml"> to visualize the list with the stop words that will </span><span class="No-Break"><span class="koboSpan" id="kobo.1219.1" xmlns:="http://www.w3.org/1999/xhtml">be removed.</span></span></p>
<p><span class="koboSpan" id="kobo.1220.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, we stemmed the words using </span><strong class="source-inline"><span class="koboSpan" id="kobo.1221.1" xmlns:="http://www.w3.org/1999/xhtml">SnowballStemmer</span></strong><span class="koboSpan" id="kobo.1222.1" xmlns:="http://www.w3.org/1999/xhtml"> from </span><strong class="source-inline"><span class="koboSpan" id="kobo.1223.1" xmlns:="http://www.w3.org/1999/xhtml">NLTK</span></strong><span class="koboSpan" id="kobo.1224.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><strong class="source-inline"><span class="koboSpan" id="kobo.1225.1" xmlns:="http://www.w3.org/1999/xhtml">SnowballStemmer</span></strong><span class="koboSpan" id="kobo.1226.1" xmlns:="http://www.w3.org/1999/xhtml"> works one word at a time. </span><span class="koboSpan" id="kobo.1226.2" xmlns:="http://www.w3.org/1999/xhtml">Therefore, we created a function that takes a string and splits it into a list of words using pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.1227.1" xmlns:="http://www.w3.org/1999/xhtml">str.split()</span></strong><span class="koboSpan" id="kobo.1228.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.1228.2" xmlns:="http://www.w3.org/1999/xhtml">In a list comprehension, we applied </span><strong class="source-inline"><span class="koboSpan" id="kobo.1229.1" xmlns:="http://www.w3.org/1999/xhtml">SnowballStemmer</span></strong><span class="koboSpan" id="kobo.1230.1" xmlns:="http://www.w3.org/1999/xhtml"> word per word and then concatenated the list of stemmed words back into a string using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1231.1" xmlns:="http://www.w3.org/1999/xhtml">join()</span></strong><span class="koboSpan" id="kobo.1232.1" xmlns:="http://www.w3.org/1999/xhtml"> method. </span><span class="koboSpan" id="kobo.1232.2" xmlns:="http://www.w3.org/1999/xhtml">With pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.1233.1" xmlns:="http://www.w3.org/1999/xhtml">apply()</span></strong><span class="koboSpan" id="kobo.1234.1" xmlns:="http://www.w3.org/1999/xhtml">, we applied the</span><a id="_idTextAnchor1628"/><span class="koboSpan" id="kobo.1235.1" xmlns:="http://www.w3.org/1999/xhtml"> function to stem words to each row of </span><span class="No-Break"><span class="koboSpan" id="kobo.1236.1" xmlns:="http://www.w3.org/1999/xhtml">the DataFrame.</span></span></p>
<p><span class="koboSpan" id="kobo.1237.1" xmlns:="http://www.w3.org/1999/xhtml">The c</span><a id="_idTextAnchor1629"/><span class="koboSpan" id="kobo.1238.1" xmlns:="http://www.w3.org/1999/xhtml">leaning steps we performed in this recipe resulted in strings containing the original text, without punctuation or numbers, in lowercase, without common words, and with the root of the word instead of its conjugated form. </span><span class="koboSpan" id="kobo.1238.2" xmlns:="http://www.w3.org/1999/xhtml">The data, as it is returned, can be used to derive features, as described in the </span><em class="italic"><span class="koboSpan" id="kobo.1239.1" xmlns:="http://www.w3.org/1999/xhtml">Counting characters, words, and vocabulary</span></em><span class="koboSpan" id="kobo.1240.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe, or to create BoWs and TI-IDF matrices, as described in the </span><em class="italic"><span class="koboSpan" id="kobo.1241.1" xmlns:="http://www.w3.org/1999/xhtml">Creating features with bag-of-words and n-g</span><a id="_idTextAnchor1630"/><span class="koboSpan" id="kobo.1242.1" xmlns:="http://www.w3.org/1999/xhtml">rams</span></em><span class="koboSpan" id="kobo.1243.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><em class="italic"><span class="koboSpan" id="kobo.1244.1" xmlns:="http://www.w3.org/1999/xhtml">Implementing term frequency-inverse document </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1245.1" xmlns:="http://www.w3.org/1999/xhtml">frequency</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1246.1" xmlns:="http://www.w3.org/1999/xhtml"> recipes.</span></span></p>
<p><span class="koboSpan" id="kobo.1247.1" xmlns:="http://www.w3.org/1999/xhtml">Cleaning the texts as</span><a id="_idIndexMarker906"/><span class="koboSpan" id="kobo.1248.1" xmlns:="http://www.w3.org/1999/xhtml"> we </span><a id="_idIndexMarker907"/><span class="koboSpan" id="kobo.1249.1" xmlns:="http://www.w3.org/1999/xhtml">have shown in this recipe can incur data loss, depending on the characteristics of the text, and if we seek to interpret the models after creating BoW or TF-IDF matrices, understanding the importance of stemmed words may not be </span><span class="No-Break"><span class="koboSpan" id="kobo.1250.1" xmlns:="http://www.w3.org/1999/xhtml">so straightforward.</span></span></p>
</div>
</body></html>