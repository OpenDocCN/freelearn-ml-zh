- en: '*Chapter 7*: Model Understanding and Explainability'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we learned how to build models, and we will now learn how
    to use output generated by DataRobot to understand the models and also use this
    information to explain why a model provides a particular prediction. As we have
    discussed before, this aspect is critically important to ensure that we are using
    the results correctly. DataRobot automates much of the task of creating charts
    and plots to help someone understand a model, but you still need to know how to
    interpret what it is showing in the context of the problem you are trying to solve.
    This is another reason why we will need people involved in the process, even if
    much of a task has been automated. As you can imagine, the task of interpreting
    the results will therefore become more and more valuable as the degree of automation
    increases.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing and understanding model details
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assessing model performance and metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating model explanations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding model learning curves and trade-offs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing and understanding model details
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the last chapter, we created several models for different projects. DataRobot
    creates 10 to 20 models in a project, and it would be very onerous to look at
    and analyze the details of all of these models. You do not have to review each
    of these models, and it is common to review only the top few models before making
    a final selection. We will now look at the leaderboard for models in the `Automobile
    Example 2` project and select the top model, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Model information'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.1_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.1 – Model information
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding screenshot, we selected the **Model Info** tab within the
    **Describe** tab to get a view of how large the model is and the expected time
    it takes to create predictions. This information is useful in real-time applications
    that are time-sensitive and need to score thousands of transactions quickly. Let''s
    now go to the **Feature Impact** tab within the **Understand** tab, as shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Feature impacts'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.2_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.2 – Feature impacts
  prefs: []
  type: TYPE_NORMAL
- en: This is one of the most important charts for the model as it shows how much
    a feature contributes to this XGBoost model. We can see that the top contributors
    are `curb_weight`, `engine_size`, `horsepower`, `highway_mpg`, and `cylinder_count`.
    On the other hand, `cylinder_size` and `engine_type` contribute very little. While
    it is true that `cylinder_size` is not very predictive, we must not forget that
    prediction is not always the end objective. We know that `cylinder_size` has an
    effect on `engine_size`, an important feature. The objective might be to use this
    information to figure out ways to reduce costs. For that, we might want to reduce
    `engine_size`, but you cannot reduce `engine_size` directly. For that, you need
    to reduce the size or count of cylinders, which will lead to a reduction in `engine_size`.
    Having a causal diagram of this problem to guide you becomes very helpful in determining
    the best actions to take to achieve our objectives.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we take action, let''s inspect what the results look like for a **Generalized
    Additive Model** (**GAM**), as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Feature impacts for a GAM'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.3_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.3 – Feature impacts for a GAM
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7.3* shows the important features of the GAM. While many of the features
    look similar, we notice that `engine_type` is fairly high in importance for this
    model, whereas `engine_type` was very low in importance for the previous model.
    This is not an error—it points to the fact that many of the features are interrelated
    and different models can pick up signals from different features, and that predictive
    power is not necessarily the same as the root cause. To take action, we need to
    understand the root feature that leads to a change in the target feature. To put
    this another way, the feature that best predicts something is not always the feature
    that can be changed to create the desired change in the target.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To further understand how a feature affects the target, let''s select the **Feature
    Effects** tab within the **Understand** tab of the model, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – Feature effects'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.4_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.4 – Feature effects
  prefs: []
  type: TYPE_NORMAL
- en: The preceding screenshot shows partial dependence plots for various features.
    The selected plot is for `curb_weight`. The plot shows a fairly linear relationship
    between `curb_weight` and price. We do see some unusual dips in price in a few
    spots—for example, around a `curb_weight` value of `2700`. Before we take that
    too seriously, we notice that the amount of data around that is very limited.
    This tells us that this particular observation is likely due to a lack of data.
    This does raise the issue that our model is likely to predict a lower price in
    that small region, which in turn could result in lower revenue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at another feature in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5 – Partial dependence for engine_size'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.5_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.5 – Partial dependence for engine_size
  prefs: []
  type: TYPE_NORMAL
- en: The preceding screenshot shows a highly non-linear relationship between `engine_size`
    and price. We see a very dramatic rise in price around the `engine_size` value
    of `180`. It is hard to know how real this effect is without discussing it with
    domain experts. We can notice that the amount of data available for sizes greater
    than `130` is very small, hence the effects we see could be simply due to a lack
    of data. Taken as is, it indicates that prices stagnate beyond a size of `200`,
    and this could be an important insight for the business.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at another partial dependence plot for `highway_mpg` in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6 – Partial dependence plot for highway_mpg'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.6_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.6 – Partial dependence plot for highway_mpg
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7.6* shows another highly non-linear relationship, with a key transition
    point happening around a `highway_mpg` value of `28`. This clearly shows a big
    price drop around `28`, hence this is a critical point. This could be due to regulations,
    where going below `28` places you in a different type of vehicle or engine. We
    also notice that once you get above that threshold, any further change is not
    very meaningful from a price impact (however, it could still be very impactful
    from other perspectives). If you do not know why this is, it is important for
    you to discuss this with your **subject-matter experts** (**SMEs**).'
  prefs: []
  type: TYPE_NORMAL
- en: My main objective for showing and discussing these plots is to show you how
    important it is to spend your time analyzing and reviewing these plots rather
    than spending all of your time coding up these plots. Since DataRobot automatically
    creates these for you, you can now spend your time doing the more value-added
    work of analyzing these results to help improve your business.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s revisit the `engine_size` plot, but this time for the GAM, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7 – Partial dependence plot for the GAM'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.7_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.7 – Partial dependence plot for the GAM
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7.7* shows the partial dependence for the GAM. Comparing this with
    *Figure 7.5*, we see that *Figure 7.7* shows clearer thresholds around values
    `95` and `180`. Discussing this with domain experts could help you determine which
    model is a better representation of reality and which model helps you to better
    set pricing. One of the benefits of GAMs is that you can easily smooth out these
    curves and shape them for deployment. Remember—accurate prediction is not always
    the same as better intervention or action.'
  prefs: []
  type: TYPE_NORMAL
- en: 'GAMs are a lot easier to understand and explain. Let''s look at another chart
    here that helps in that understanding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 7.8 – Feature coefficients'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.8_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.8 – Feature coefficients
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7.8* shows the coefficients for different features in the GAM. You
    will notice that DataRobot has created some derived features. You can click on
    them to see more details. This provides a high-level view of the coefficients,
    but there is another view that provides a better view for understanding the model.
    For that, let''s click on the **Rating Table** tab within the **Describe** tab
    for the GAM, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.9 – Rating table for a GAM'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.9_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.9 – Rating table for a GAM
  prefs: []
  type: TYPE_NORMAL
- en: 'This view lets you download the rating table built by DataRobot; you can also
    modify this table and upload it back to use the modified table. This mechanism
    thus allows you to manually fine-tune your model based on your understanding of
    the problem. This feature is therefore very powerful as it allows you a lot of
    flexibility, but at the same time, you must use this carefully. Let''s click on
    the **Download table** button and download the **comma-separated values** (**CSV**)
    file. Once downloaded, we can open the file using **Excel**, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.10 – Rating table for a GAM'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.10_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.10 – Rating table for a GAM
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now see what the rating table looks like. Here, you see that DataRobot
    has created bins for various features. For each bin, it has assigned the coefficient
    and relativity as to how changes in a feature impact the target variable. To understand
    this a bit better, we can create plots for individual features in Excel, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.11 – Feature relativities'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.11_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.11 – Feature relativities
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 7.11*, you can see how a given feature such as `body_style` contributes
    to the price. The GAM model is essentially a sum of all the contributions from
    the selected features. Given the rating table, anyone can easily calculate the
    price, and this can also be implemented in a very simple manner. Given that the
    individual feature effects are non-linear (and still very understandable), this
    allows these models to perform very well while still being very easy to understand.
    It is no wonder that GAMs are becoming very popular.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one more chart that we want to look at that is frequently helpful
    in understanding the contributions of features. For this, we will click on the
    **Insights** menu item at the top of the page, which brings up the chart shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.12 – Model insights'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.12_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.12 – Model insights
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7.12* shows the variable effects using a DataRobot selected model that
    is built using constant splines (in this case, the `one` if the value falls within
    a specific interval; otherwise, it is `zero`. You can review this chart with reference
    to the feature effects for the models you have selected to see if there are any
    inconsistencies between these charts.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the model from the perspective of which features are
    important and how they contribute toward the target value, we can focus on how
    well the model is doing.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing model performance and metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will focus on how well a model is doing in trying to predict
    the target values. Let''s start by looking at the overall performance comparison
    across different models, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.13 – Performance across models'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.13_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.13 – Performance across models
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding screenshot shows the overall leaderboard, which we have seen
    before. Here, we can see the overall performance of different models based on
    the **Gamma Deviance** metric. We can also review the performance based on other
    metrics by clicking on the drop-down arrow near the metric, which shows us a list
    of metrics we can choose from, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.14 – Performance metrics'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.14_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.14 – Performance metrics
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7.14* shows the various metrics we can select from. You will typically
    see a similar trend across different metrics in terms of which models surface
    to the top spots. In general, the metric that DataRobot selects is a very good
    choice, if not the best choice. Let''s now inspect the performance details of
    specific models by clicking on the model and selecting the **Lift Chart** tab
    within the **Evaluate** tab, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.15 – Lift chart'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.15_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.15 – Lift chart
  prefs: []
  type: TYPE_NORMAL
- en: 'The lift chart illustrated in the preceding screenshot shows how the predictions
    stack up against the actual values. You can select the number of bins to aggregate
    the results. The maximum value is `60`, and that is normally a good starting point.
    This means that the predictions are first sorted in ascending order and then grouped
    into `60` bins. The results you see are the average values within that bin. The
    reason for binning is that if you look at the entire dataset, there will be so
    much data that you will not be able to make any sense out of it. You can see that
    the model does very well over the entire range of values, with some small pockets
    where the differences seem higher than the rest. We typically want to see lift
    charts for multiple models, to see if there are areas where one model does better
    than another model. Let''s now look at the lift chart for the GAM, as shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.16 – Lift chart for the GAM'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.16_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.16 – Lift chart for the GAM
  prefs: []
  type: TYPE_NORMAL
- en: 'The results in *Figure 7.16* look very similar to the results from *Figure
    7.15*, but we can see that the GAM did not do as well for higher values. We now
    know where specifically the GAM is weaker as compared to the XGBoost model. Let''s
    look further by clicking on the **Residuals** tab within the **Evaluate** tab,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.17 – Model residuals'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.17_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.17 – Model residuals
  prefs: []
  type: TYPE_NORMAL
- en: 'The residuals seem to be well distributed around the mean but with a small
    skew toward -ve values. Let''s also check how the residuals are distributed for
    the GAM. We can see the output in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.18 – Residuals for the GAM'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.18_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.18 – Residuals for the GAM
  prefs: []
  type: TYPE_NORMAL
- en: The residuals for the GAM are also well distributed but with a slightly larger
    skew compared to the XGBoost model. Overall, the performance of the models looks
    very good. We can now look into understanding individual predictions and their
    explanations.
  prefs: []
  type: TYPE_NORMAL
- en: Generating model explanations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another key capability of DataRobot is that it automatically generates instance-level
    explanations for each prediction. This is important in understanding why a particular
    prediction turned out the way it did. This is not only important for understanding
    the model; many times, this is needed for compliance purposes as well. I am sure
    you have seen explanations generated or offered if you are denied credit. The
    ability to generate these explanations is not straightforward and can be very
    time-consuming. Let''s first look at the explanations generated for the XGBoost
    model, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.19 – Model explanations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.19_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.19 – Model explanations
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we selected the `0` to `10000`. You can select some specific points and
    see the components that make up that prediction. In *Figure 7.19*, we have selected
    the prediction point of `27788.86`. We can see the top contributing elements on
    the right, where `engine_size` is contributing the most, and in this case, the
    value of `engine_size` is `183`. Notice that the relative contribution of features
    can vary on a case-by-case basis, and the ordering of features here will not exactly
    match the feature-impacts order we saw in the preceding section. Let''s compare
    this with explanations generated by the GAM, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.20 – Model explanations for GAM'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.20_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.20 – Model explanations for GAM
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, the point selected is for a prediction of `31465.18`.
    For this point, we can see the features that are the main contributors toward
    that price, and we also note that there was a reduction or -ve contribution due
    to the `engine_size` of `183` is much larger for the GAM.
  prefs: []
  type: TYPE_NORMAL
- en: The explanations for the entire dataset can be downloaded and analyzed for additional
    insights. You can also upload an entirely new dataset to score it and generate
    these explanations very easily, by clicking on the **Upload new dataset** button.
  prefs: []
  type: TYPE_NORMAL
- en: As you have seen in this chapter, different models have different performance,
    use the features a little bit differently, and have different levels of understandability.
    There are a few other dimensions that should be looked at before making a final
    selection of the model you want to use. Let's now look at model learning curves
    and some of the model trade-offs.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding model learning curves and trade-offs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In **machine learning** (**ML**) problems, we are always trying to find more
    data to improve our models, but as you can imagine, there comes a time when we
    reach a point of diminishing returns. It is very hard to know when you have reached
    that point, but you can get indications by looking at the learning curves. Fortunately,
    DataRobot makes that task easy by automatically building these learning curves.
    When DataRobot starts building models, it first tries a broad range of algorithms
    on small samples of data. Promising models are then built with bigger sample sizes,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this process, we discover how much performance improvement happens as more
    data is added. To look at the learning curves, you can click on the **Learning
    Curves** menu item at the top of the screen, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.21 – Model learning curves'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.21_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.21 – Model learning curves
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see the different model types on the right-hand side of the page. Here,
    you can click on the models you want to inspect and compare. After selecting the
    models, you click on the **+ Compute Learning Curves** button. This brings up
    a dialog box showing the selected models and corresponding sample sizes, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.22 – Models selected for comparison'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.22_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.22 – Models selected for comparison
  prefs: []
  type: TYPE_NORMAL
- en: 'If the selections in *Figure 7.22* look correct, you can click the **Compute**
    button. You will now see the learning curves for the selected models, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.23 – Comparison of learning curves'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.23_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.23 – Comparison of learning curves
  prefs: []
  type: TYPE_NORMAL
- en: You can now see the improvement in performance as the sample size increases.
    We can see that the GAM learns very rapidly, but as the sample size increases,
    the XGBoost model takes over. We can see that both models will benefit from additional
    data. We can also see that if we only had half of the data we currently have,
    then the GAM would have been the clear winner.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now look at another trade-off for models—namely, the trade-off between
    speed and accuracy. If you click on the **Speed vs Accuracy** menu item at the
    top of the page, you will see a chart, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.24 – Speed versus accuracy trade-off'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_7.24_B17159.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.24 – Speed versus accuracy trade-off
  prefs: []
  type: TYPE_NORMAL
- en: You will notice the DataRobot has built an AVG Blender model that seems to be
    the top model, but not by much. Blended models can sometimes produce substantial
    lift over individual models, so it is worthwhile exploring this option. We can
    select this model and click on the **Blueprint** tab within the **Describe** menu
    item.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered how to build and compare models by leveraging DataRobot's
    capabilities. As you saw, DataRobot makes it very easy to build many models quickly
    and helps us compare them. As you experienced, we tried many things and built
    dozens of models. This is DataRobot's key capability, and its importance to a
    data science team cannot be overstated. If you were to build these models on your
    own in Python, it would have taken a lot more time and effort. Instead, we used
    that time and thinking to experiment with different ideas and put more energy
    toward understanding the problem. We also learned about blueprints that encode
    best practices. These blueprints can be useful learning tools for new and experienced
    data scientists alike. We also learned how DataRobot can build ensemble or blended
    models for us.
  prefs: []
  type: TYPE_NORMAL
- en: It might be tempting to jump ahead and start deploying one of these models,
    but it is important to not directly jump to that without doing some analysis.
    In the next chapter, we will dig deeper into the models to understand them and
    see if we can gain more insights from them.
  prefs: []
  type: TYPE_NORMAL
