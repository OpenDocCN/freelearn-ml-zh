- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Enhancing Brand Presence with Few-Shot Learning and Transfer Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过少样本学习和迁移学习增强品牌影响力
- en: This chapter explores the capabilities of **few-shot learning** (**FSL**) and
    its value in enhancing brand presence through tailored marketing strategies. Building
    on the insights from **zero-shot learning** (**ZSL**) covered in the previous
    chapter, we now focus on how FSL, by utilizing a limited set of examples, enables
    rapid and effective adaptation of AI models to new tasks. This approach is particularly
    valuable in marketing, where the ability to swiftly adjust content to align with
    evolving consumer preferences and market trends is crucial.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了**少样本学习**（**FSL**）的能力及其通过定制营销策略增强品牌影响力的价值。在上一章中介绍了**零样本学习**（**ZSL**）的见解之后，我们现在关注FSL如何通过利用少量示例，使AI模型能够快速有效地适应新任务。这种方法在市场营销中尤其有价值，因为能够迅速调整内容以适应不断变化的消费者偏好和市场趋势至关重要。
- en: Initially, we will introduce some of the fundamental concepts of FSL in the
    context of meta-learning as an underlying technique that facilitates quick learning
    from small datasets. We will then explore the synergy between FSL and transfer
    learning using practical examples; while FSL is effective at quickly adapting
    to new tasks with few examples, transfer learning complements this by utilizing
    pre-trained models that are fine-tuned for specific tasks, reducing the need for
    extensive model retraining.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍FSL在元学习背景下的基本概念，作为促进从小数据集快速学习的技术。然后，我们将通过实际示例探索FSL与迁移学习之间的协同作用；虽然FSL在快速适应新任务时效果显著，但迁移学习通过利用针对特定任务微调的预训练模型来补充这一点，从而减少了大量模型重新训练的需求。
- en: 'This chapter highlights how combining FSL with related strategies can optimize
    marketing efforts, making them more responsive and efficient. This chapter equips
    you with the understanding to:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章强调了将FSL与相关策略相结合如何优化营销工作，使其更具响应性和效率。本章将为您提供以下理解：
- en: Grasp the core concepts of FSL and its similarities to and differences from
    transfer learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解FSL的核心概念及其与迁移学习的相似之处和不同之处
- en: Recognize the practical benefits of employing FSL to adapt quickly to new marketing
    conditions with limited data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 认识到在有限数据下快速适应新营销条件的FSL的实际好处
- en: Apply FSL and transfer learning techniques to real-world marketing scenarios
    to enhance brand messaging and consumer engagement
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将FSL和迁移学习技术应用于现实世界的营销场景，以增强品牌信息和消费者参与度
- en: Navigating FSL
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索FSL导航
- en: In the marketing domain, the agility to quickly tune content strategies to meet
    the evolving needs of a brand is invaluable. FSL stands out for its capacity to
    effectively learn and perform tasks with limited input data. While ZSL is designed
    to work without any specific examples of the new classes during inference, relying
    on a generalized, abstract understanding of the task derived from previously learned
    tasks, FSL uses a small number of examples to adapt to new tasks. This adaptation
    often relies on a more direct application of learned patterns and can be fine-tuned
    with data, making it particularly effective when some example data is available.
    This efficiency enables marketers to rapidly test new strategies, such as personalizing
    email campaigns for different customer segments or quickly adapting social media
    content to reflect emerging trends, without the long lead times associated with
    gathering and training on extensive datasets. For instance, a marketing manager
    might use FSL to generate tailored marketing copy that aligns with a company’s
    rebranding initiative, as we will discuss in the *Applying FSL to improve brand
    consistency section*, even when there are limited examples of such rebranded content
    available.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在市场营销领域，能够快速调整内容策略以满足品牌不断变化的需求是非常宝贵的。FSL因其能够有效地从有限的数据中学习和执行任务而脱颖而出。虽然ZSL旨在推理时无需任何新类别的具体示例，而是依赖于从先前学习任务中得出的对任务的通用、抽象理解，但FSL使用少量示例来适应新任务。这种适应通常依赖于对学习到的模式更直接的应用，并且可以通过数据微调，这使得在有示例数据的情况下特别有效。这种效率使得营销人员能够快速测试新的策略，例如为不同的客户细分市场个性化电子邮件活动或快速调整社交媒体内容以反映新兴趋势，而无需花费大量时间收集和训练大量数据集。例如，一位营销经理可能会使用FSL来生成符合公司品牌重塑计划的定制营销文案，正如我们将在*将FSL应用于提高品牌一致性部分*中讨论的那样，即使这种重塑内容的示例有限。
- en: As we further explore the utility of FSL for enhancing brand presence, it’s
    essential to build on our conceptual understanding of **Generative AI** (**GenAI**)
    introduced in the previous chapter. FSL hinges on the idea that intelligent systems
    can learn new concepts or tasks with only a small number of training examples,
    drawing heavily from prior knowledge and the application of sophisticated meta-learning
    algorithms. This discussion will extend your foundational knowledge of this concept,
    bridging the gap between high-level concepts and practical applications that are
    useful for understanding the hands-on examples given later in this chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们进一步探索FSL在增强品牌存在感方面的效用，构建对上一章中引入的概念**生成式AI（GenAI**）的概念理解至关重要。FSL基于这样一个观点，即智能系统可以通过仅使用少量训练示例来学习新的概念或任务，大量借鉴先前知识和应用复杂的元学习算法。这次讨论将扩展你对这一概念的基础知识，弥合高级概念与实际应用之间的差距，这些实际应用对于理解本章后面给出的实际例子非常有用。
- en: At its core, FSL is often facilitated by **meta-learning**, an approach that
    enables models to quickly adapt to new tasks by using learnings from a variety
    of prior tasks. However, meta-learning is just one possible approach, and others
    such as metric-based learning, whereby models are trained to compare new instances
    against a few labeled examples using a learned metric or distance function, can
    also be used. Given its broad applicability and effectiveness as an FSL approach,
    let’s explore meta-learning further in the next section.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，FSL通常通过**元学习**得到促进，这是一种使模型能够通过使用先前各种任务的学习来快速适应新任务的方法。然而，元学习只是众多可能方法中的一种，其他方法，如基于度量的学习，其中模型被训练去比较新实例与少数标记示例，使用学习到的度量或距离函数，也可以被使用。鉴于其作为FSL方法的广泛适用性和有效性，让我们在下一节进一步探讨元学习。
- en: Understanding FSL through meta-learning
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过元学习理解FSL
- en: FSL often involves meta-learning, or “learning to learn,” whereby models are
    designed to quickly adapt to new tasks based on learnings from a wide array of
    previous tasks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: FSL（元学习）通常涉及元学习，或称为“学习如何学习”，其中模型被设计成能够根据从大量先前任务中学习到的知识快速适应新任务。
- en: 'This is particularly crucial in marketing, where consumer behavior and preferences
    can be dynamic, requiring models that can pivot quickly without extensive retraining.
    Meta-learning frameworks in FSL train models on a variety of tasks, enabling them
    to develop a generalized understanding or an internal representation that can
    efficiently map to new tasks with minimal additional input. Some of the key components
    of meta-learning are:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这在营销领域尤为重要，因为消费者的行为和偏好可能是动态的，需要能够快速调整而无需大量重新训练的模型。FSL中的元学习框架在多种任务上训练模型，使它们能够发展出一种通用的理解或内部表示，可以高效地将新任务映射到最小额外的输入。元学习的一些关键组成部分包括：
- en: '**Task variety**: Meta-learning algorithms are exposed to a wide variety of
    learning tasks during the training phase. This exposure helps the model learn
    more robust features that are not overly specific to one task but are general
    enough to be applicable across a spectrum of future tasks. This is analogous to
    a marketing team working across different campaign types like email or social
    media and learning to identify core elements that predict success regardless of
    the specific product or audience.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务多样性**：元学习算法在训练阶段接触到广泛的学习任务。这种接触帮助模型学习到更稳健的特征，这些特征不是过于特定于某一任务，但足够通用，可以适用于一系列未来的任务。这类似于一个营销团队在不同的活动类型（如电子邮件或社交媒体）中工作，并学会识别无论具体产品或受众如何都能预测成功的核心元素。'
- en: '**Rapid adaptation**: The primary goal of meta-learning is to enable rapid
    learning on new tasks. This is achieved through the model’s ability to fine-tune
    itself to new conditions with minimal training data. For instance, if a model
    trained in a meta-learning framework is faced with a new product launch, it can
    quickly adjust its parameters to optimize marketing content for the product’s
    target demographic based on its prior knowledge of similar products.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速适应**：元学习的主要目标是实现对新任务的快速学习。这是通过模型能够使用最少量的训练数据对自己的条件进行微调来实现的。例如，如果一个在元学习框架中训练的模型面临一个新的产品发布，它可以快速调整其参数，根据其对类似产品的先前知识来优化产品的营销内容。'
- en: '**Optimization techniques**: Meta-learning involves special training schemes
    such as episodic training, whereby the model undergoes simulated training episodes.
    Each episode involves learning from a small set of data and then testing on a
    new set of data from the same task. This trains the model to generalize well from
    small data samples.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化技术**：元学习涉及特殊的训练方案，如周期性训练，其中模型经历模拟的训练周期。每个周期涉及从一小组数据中学习，然后在新的一组来自同一任务的数据上进行测试。这训练模型能够很好地从小的数据样本中泛化。'
- en: Now let’s look at these fundamentals in action in the following example.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在以下示例中看看这些基本原理的实际应用。
- en: Implementing model-agnostic meta-learning in marketing
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在营销中实现模型无关元学习
- en: Let’s consider an example meta-learning model using a simple adaptation of **model-agnostic
    meta-learning** (**MAML**) and how it can be applied to optimize marketing strategies.
    MAML works by optimizing a model’s parameters so that a small number of gradient
    updates will lead to fast learning on a new task.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个使用简单的**模型无关元学习**（**MAML**）适应的元学习模型示例，以及它如何应用于优化营销策略。MAML通过优化模型参数，使得少量梯度更新就能在新任务上实现快速学习。
- en: '**Learn more about MAML**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**了解更多关于MAML**'
- en: 'MAML is a widely recognized meta-learning algorithm introduced by Finn et al.
    in 2017 in the paper *Model-Agnostic Meta-Learning for Fast Adaptation of Deep
    Networks*. For a deeper dive into the topic, including interactive examples, check
    out the resource: https://interactive-maml.github.io/.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: MAML是由Finn等人于2017年在论文《模型无关元学习用于快速适应深度网络》中引入的广为人知的元学习算法。要深入了解该主题，包括交互式示例，请查看资源：https://interactive-maml.github.io/.
- en: 'In this simplified implementation, we’ll simulate a single marketing task as
    a training input as a proxy for the multiple tasks that would be considered in
    a full MAML deployment. We will then train a simple neural network model on the
    task and then use the result of our meta-training to improve the model’s adaptability
    on a different task. The following diagram provides an illustration of the mechanics
    of a meta-learning framework, as well as what it might look like when applied
    to multiple marketing tasks as examples:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简化的实现中，我们将模拟单个营销任务作为训练输入，作为在完整MAML部署中考虑的多个任务的代理。然后，我们将对任务训练一个简单的神经网络模型，然后使用我们的元训练结果来提高模型在不同任务上的适应性。以下图表提供了元学习框架的机制说明，以及将其应用于多个营销任务作为示例的可能外观：
- en: '![](img/B30999_10_01.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_10_01.png)'
- en: 'Figure 10.1: Key components of a possible MAML framework in the context of
    marketing campaigns'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：在营销活动背景下可能的MAML框架的关键组件
- en: '**Source code and data**:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**源代码和数据**：'
- en: '[https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.10](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.10)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.10](https://github.com/PacktPublishing/Machine-Learning-and-Generative-AI-for-Marketing/tree/main/ch.10)'
- en: 'Model-agnostic techniques are designed to be broadly applicable across a range
    of model architectures and tasks. To better understand the mechanics of the MAML
    approach, we will break down its application into several functions that are simplifications
    of what would be involved with a full implementation:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 模型无关技术旨在广泛适用于各种模型架构和任务。为了更好地理解MAML方法的机制，我们将将其应用分解为几个函数，这些函数是完整实现中可能涉及的简化：
- en: 'First, we have a function, `generate_task`, that creates simulated marketing
    tasks with its own set of coefficients representing campaign data, which, in this
    case, is represented as a quadratic relationship with noise. The randomly generated
    coefficients for each task dictate how input data (such as email campaign length,
    budget, or reach) affect the outcome (such as engagement or conversions). Then
    the `task` function computes the campaign’s success metrics based on the input
    and the coefficients. Note that we provide seed values so that your output should
    be consistent with what’s shown here, but your results may still vary due to randomness
    from parallel processing or GPU usage:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们有一个函数`generate_task`，它创建具有自己系数集的模拟营销任务，这些系数代表活动数据，在这种情况下，它被表示为带噪声的二次关系。每个任务随机生成的系数决定了输入数据（如电子邮件活动长度、预算或覆盖范围）如何影响结果（如参与度或转化率）。然后`task`函数根据输入和系数计算活动的成功指标。请注意，我们提供了种子值，以便您的输出应与这里显示的一致，但您的结果可能仍然会因并行处理或GPU使用中的随机性而有所不同：
- en: '[PRE0]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we have a function, `train_model_on_task`, that trains the model on one
    of the tasks generated by the previous function by performing short bursts of
    training on the task and using the `Adam` optimizer to update the model’s weights.
    Then TensorFlow `GradientTape` is used for automatic differentiation, calculating
    the gradients needed to minimize the loss, which measures how well the model’s
    predictions match the actual outcomes of the campaign:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们有一个函数`train_model_on_task`，它通过在任务上执行短时间段的训练并使用`Adam`优化器更新模型权重来在之前函数生成的任务之一上训练模型。然后使用TensorFlow的`GradientTape`进行自动微分，计算用于最小化损失的梯度，该损失衡量模型的预测与活动实际结果之间的匹配程度：
- en: '[PRE1]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then we have the `meta_train_model` function, which is at the heart of meta-learning.
    This handles the meta-training process by optimizing the model’s ability to quickly
    adapt to new tasks after minimal exposure. In practice, the model is first trained
    on a task, and then it is evaluated on new data from the same task.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们有`meta_train_model`函数，这是元学习的核心。这个函数通过优化模型在最小接触后快速适应新任务的能力来处理元训练过程。在实践中，模型首先在一个任务上接受训练，然后在新数据上对该任务进行评估。
- en: 'The loss calculated from this evaluation guides adjustment of the model’s initial
    parameters so that just a few updates lead to significant improvements on new
    tasks. Note that in a full implementation, we would likely use a `reset_weights`
    argument so that after each task the model’s weights are reset to their state
    before the task-specific training and a `meta_optimizer` that updates the model’s
    initial parameters based on the task performance. This ensures that the model
    does not overfit to a particular task and retains its ability to generalize across
    tasks:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从这次评估计算出的损失指导调整模型的初始参数，以便仅通过几次更新就能在新任务上带来显著的改进。请注意，在完整实现中，我们可能会使用`reset_weights`参数，以便在每个任务之后将模型的权重重置到任务特定训练之前的状态，并使用`meta_optimizer`根据任务性能更新模型的初始参数。这确保了模型不会过度拟合到特定任务，并保持其在任务之间的泛化能力：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To illustrate this simplified example in action, we can first initialize a
    very simple neural network with two layers to apply our meta-training function.
    Here, there is first a dense layer with 10 neurons and a sigmoid activation and
    then a final dense layer with just one neuron to capture the model’s prediction
    for the success of a marketing campaign based on the input feature:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了说明这个简化的示例在实际中的应用，我们可以首先初始化一个非常简单的神经网络，包含两层，以应用我们的元训练函数。在这里，首先是一个包含10个神经元的密集层，具有sigmoid激活，然后是一个最终只有一个神经元的密集层，用于捕捉模型基于输入特征的营销活动成功预测：
- en: '[PRE3]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This gives us the following summary:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下总结：
- en: '![](img/B30999_10_02.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_10_02.png)'
- en: 'Figure 10.2: Simple neural network model architecture'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：简单的神经网络模型架构
- en: 'Let’s now generate a proxy for a complex task using your quadratic function
    and plot the model’s performance on this task before training:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们使用你的二次函数生成一个复杂任务的代理，并在训练之前绘制模型在这个任务上的性能：
- en: '[PRE4]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following plot shows the performance of the model before undergoing meta-training.
    As we can see, the model is initially unable to accurately predict the true values,
    indicating the need for further training and optimization:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表显示了在经过元训练之前模型的性能。正如我们所见，模型最初无法准确预测真实值，这表明需要进一步的训练和优化：
- en: '![](img/B30999_10_03.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_10_03.png)'
- en: 'Figure 10.3: Model performance before meta-training on the task'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：在任务上进行元训练前的模型性能
- en: 'Now we can perform meta-training using our algorithm and then plot the model’s
    performance again on the same task after meta-training:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用我们的算法进行元训练，然后再次绘制模型在相同任务上的性能：
- en: '[PRE5]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This yields the following plot:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下图表：
- en: '![](img/B30999_10_04.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_10_04.png)'
- en: 'Figure 10.4: Model performance after meta-training on the task'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4：在任务上进行元训练后的模型性能
- en: As shown in *Figures 10.3* and *10.4*, the model initially fails to grasp any
    quadratic relationship in the data. After meta-training, however, the predictions
    improve. While this is a simplified implementation including only a simple task,
    this implementation framework gives a baseline for the mechanics of MAML as a
    tool for preparing your model for FSL.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图10.3*和*10.4*所示，模型最初无法掌握数据中的任何二次关系。然而，在元训练之后，预测得到了改善。虽然这是一个只包括简单任务的简化实现，但这个实现框架为MAML作为准备模型进行FSL的工具的机制提供了一个基准。
- en: Overcoming challenges in FSL
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 克服FSL中的挑战
- en: FSL aims to make the most out of minimal data, but this can come with inherent
    challenges such as overfitting and poor generalization. **Overfitting** occurs
    when a model, trained on a very small dataset, learns the noise and irrelevant
    details to the extent that it negatively impacts the performance on new data.
    To mitigate this, regularization techniques such as L2 regularization and dropout
    can be used to simplify the model complexity of neural networks, helping prevent
    the model from learning overly complex patterns that do not generalize well.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: FSL旨在充分利用最少的数据，但这可能伴随着固有的挑战，如过拟合和泛化能力差。**过拟合**发生在模型在非常小的数据集上训练时，学习到了噪声和不相关的细节，以至于它对新数据的性能产生了负面影响。为了减轻这一点，可以使用如L2正则化和dropout等正则化技术来简化神经网络模型的复杂度，帮助防止模型学习过于复杂的模式，这些模式泛化能力不佳。
- en: '**Regularization techniques to prevent overfitting**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**防止过拟合的正则化技术**'
- en: 'Two common regularization techniques in neural networks are:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中两种常见的正则化技术是：
- en: L2 regularization (weight decay) adds a penalty to the loss function based on
    the squared magnitude of the model’s weights. This discourages large weights,
    leading to simpler models that generalize better.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L2正则化（权重衰减）在损失函数中添加了一个基于模型权重平方大小的惩罚。这阻止了权重过大，导致更简单且泛化能力更好的模型。
- en: 'Learn more here, including how to compare learning curves to evaluate the impact
    of regularization: [https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization](https://developers.google.com/machine-learning/crash-course/overfitting/regularization).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里了解更多，包括如何比较学习曲线以评估正则化的影响：[https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization](https://developers.google.com/machine-learning/crash-course/overfitting/regularization)。
- en: Dropout randomly deactivates (“drops out”) neurons during training to prevent
    the model from becoming too reliant on specific pathways.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dropout随机地在训练过程中停用（“丢弃”）神经元，以防止模型过度依赖特定的路径。
- en: 'Learn more in the seminal paper *Dropout: a simple way to prevent neural networks
    from overfitting* by Srivastava et al.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '在Srivastava等人撰写的开创性论文《Dropout: a simple way to prevent neural networks from
    overfitting》中了解更多。'
- en: 'For instance, we could add these types of regularization while building a neural
    network model suitable for a regression task. As an illustration, the model is
    designed with a moderately complex architecture and includes several layers with
    both types of regularization:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在构建适合回归任务的神经网络模型时，我们可以添加这些类型的正则化。作为一个例子，该模型设计了一个适度的复杂架构，并包含具有两种类型正则化的多层：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This yields the following summary:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了以下总结：
- en: '![](img/B30999_10_05.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_10_05.png)'
- en: Figure 10.5\. Model architecture summary
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：模型架构摘要
- en: 'The model embeds L2 regularization within its dense layers to curb the weight
    size and encourage simpler models. A dropout of 0.3 is also applied after each
    dense layer, reducing overfitting by deactivating random neuron outputs during
    training. This regularization pattern is applied across the hidden layers to promote
    the model’s ability to generalize. The following figure provides a visualization
    of how dropout randomly deactivates neurons during training:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在其密集层中嵌入L2正则化，以控制权重大小并鼓励更简单的模型。在每个密集层之后也应用了0.3的dropout，通过在训练期间停用随机神经元输出，减少了过拟合。这种正则化模式应用于隐藏层，以促进模型泛化能力。以下图展示了dropout在训练期间如何随机停用神经元：
- en: '![](img/B30999_10_06.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_10_06.png)'
- en: 'Figure 10.6: Dropout neural net model. Left: A standard neural net with two
    hidden layers. Right: An example of a thinned net produced by applying dropout
    to the network on the left. Crossed units have been dropped. (source: https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6：Dropout神经网络模型。左：一个带有两个隐藏层的标准神经网络。右：对左侧网络应用dropout后产生的稀疏网络示例。交叉的单元已被丢弃。（来源：https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf）
- en: As alluded to earlier, **generalization** is another critical challenge. In
    the field of image processing, data augmentation techniques like image rotation,
    cropping, or color adjustment are often employed to artificially enhance the dataset’s
    size and variability, helping the model learn more general features that perform
    better on new tasks. In NLP applications, data augmentation techniques such as
    those presented in *Chapter 5* can be employed, along with others such as synonym
    replacement, in order to increase robustness and aid in better generalization
    across different contexts.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，**泛化**是另一个关键挑战。在图像处理领域，数据增强技术，如图像旋转、裁剪或颜色调整，通常被用来人为地增强数据集的大小和变异性，帮助模型学习更通用的特征，这些特征在新任务上表现更好。在NLP应用中，可以采用如第5章中所述的数据增强技术，以及其他如同义词替换等技术，以增加鲁棒性并帮助在不同上下文中更好地泛化。
- en: A significant challenge in FSL is also the difficulty of achieving robust performance
    with limited training data. Depending on the complexity of the pattern being learned,
    models may require larger datasets to generalize well and therefore struggle to
    learn useful patterns without it, leading to poor performance on new tasks. Transfer
    learning can be a powerful, complementary strategy to address this challenge.
    By starting with a model pre-trained on a large and diverse dataset, you can leverage
    the learned features and fine-tune the model on your specific FSL task. This approach
    enables rapid adaptation to new tasks with minimal data while retaining a broad
    knowledge base, complementing FSL by providing a rich initial set of features
    that need only slight adjustments rather than learning from scratch. This powerful
    approach has its limitations and challenges as well; however, these are topics
    we will discuss in the following section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在FSL（功能磁共振成像）中，一个显著的挑战也是如何在有限的训练数据下实现稳健的性能。根据学习模式的复杂性，模型可能需要更大的数据集来良好地泛化，因此如果没有这样的数据集，它们将难以学习有用的模式，导致在新任务上的表现不佳。迁移学习可以作为一种强大的、补充的策略来应对这一挑战。通过从在大规模和多样化的数据集上预训练的模型开始，你可以利用学习到的特征，并在你特定的FSL任务上微调模型。这种方法可以在最小数据量的情况下快速适应新任务，同时保留广泛的知识库，通过提供需要仅做轻微调整而不是从头开始学习的丰富初始特征集来补充FSL。这种强大的方法也有其局限性和挑战，然而，这些是我们将在下一节讨论的主题。
- en: '**Optimizing FSL techniques**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**优化FSL技术**'
- en: 'Key strategies for enhancing the efficacy of FSL models:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 提高FSL模型有效性的关键策略：
- en: '**Overfitting prevention**: Implement regularization techniques to help the
    model focus on simpler, more general patterns, rather than memorizing specific
    noise in the training data.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**防止过拟合**：实施正则化技术，帮助模型专注于更简单、更一般的模式，而不是记住训练数据中的特定噪声。'
- en: '**Enhancing generalization**: Employ data augmentation to expand the training
    dataset. For text, approaches like paraphrasing or injecting synonyms help the
    model learn language variations.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强泛化**：使用数据增强来扩展训练数据集。对于文本，像释义或注入同义词这样的方法有助于模型学习语言变体。'
- en: '**Leveraging transfer learning**: Utilize a model pre-trained on a comprehensive
    dataset and then fine-tune it for your specific FSL task.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用迁移学习**：利用在大规模数据集上预训练的模型，然后针对你特定的FSL任务进行微调。'
- en: Navigating transfer learning
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导航迁移学习
- en: Transfer learning can enhance how marketing professionals leverage AI by enabling
    the more effective use of pre-trained models on new tasks with only minor adjustments.
    While FSL uses a set of examples from the new task for quick adaptation, transfer
    learning focuses on repurposing an existing model without needing additional examples
    from the new domain.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习可以通过在新任务上仅进行少量调整来更有效地使用预训练模型来增强营销专业人士对AI的利用。虽然FSL使用新任务的一组示例进行快速适应，但迁移学习侧重于重新利用现有模型，而无需从新领域获取额外的示例。
- en: This approach capitalizes on the knowledge that models gain from large-scale
    data in previous tasks, applying it to enhance marketing efforts in completely
    different areas without the overhead of retraining the model from scratch. Put
    differently, FSL improves model adaptability using very limited data examples,
    whereas transfer learning excels in environments where the relationship between
    past and current tasks is strong but the availability of large enough labeled
    datasets for training a base model for the new task is difficult or costly to
    acquire.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法利用了模型从前一任务中从大规模数据中获取的知识，将其应用于完全不同的领域的营销努力，而无需从头开始重新训练模型。换句话说，FSL通过使用非常有限的数据示例来提高模型的适应性，而迁移学习在历史任务和当前任务之间关系强烈但为新任务训练基础模型所需的大规模标记数据集难以获得或成本高昂的环境中表现卓越。
- en: An additional advantage of transfer learning over FSL can come from a cost perspective.
    For example, when using paid API services for state-of-the-art GenAI models, pricing
    can be related to the input size used to generate the response. In the context
    of NLP applications, this is often captured by the token count. When fine-tuning
    via transfer learning, the base model only needs to be adjusted once. This means
    that the token count paid for during the fine-tuning phase does not recur with
    every usage of the model, as opposed to FSL, which may require the same relevant
    examples to be fed in each time.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习相较于FSL的另一个优势可能来自成本角度。例如，当使用付费API服务最先进的GenAI模型时，定价可能与生成响应所使用的输入大小相关。在NLP应用中，这通常由令牌计数来衡量。通过迁移学习进行微调时，基础模型只需调整一次。这意味着在微调阶段支付的令牌计数不会随着模型每次使用而重复，与FSL不同，FSL可能需要每次都输入相同的相关示例。
- en: With transfer learning, the initial cost of fine-tuning the model can be offset
    by the lower costs for each subsequent inference, as no additional examples need
    to be fed into the model. Transfer learning therefore becomes cost-effective when
    the number of inferences after fine-tuning exceeds a certain threshold, making
    it cheaper in the long run compared to FSL.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用迁移学习，模型微调的初始成本可以通过每次推理的较低成本来抵消，因为不需要向模型输入额外的示例。因此，当微调后的推理次数超过某个阈值时，迁移学习变得具有成本效益，从长远来看比FSL更便宜。
- en: 'As an example, here is a breakdown to illustrate the potential cost differences
    between FSL and transfer learning:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是一个分解，说明了FSL和迁移学习之间潜在成本差异：
- en: '**FSL API costs**:'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FSL API费用**：'
- en: '**Base cost**: Cost for tokens used in the prompt (Cost per token × Number
    of tokens in prompt)'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础成本**：提示中使用的令牌的成本（每个令牌的成本 × 提示中的令牌数）'
- en: '**Additional cost per example**: Cost per token × Number of tokens per example'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每个示例的额外成本**：每个令牌的成本 × 每个示例的令牌数'
- en: '**Transfer learning API costs**:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迁移学习API费用**：'
- en: '**Initial fine-tuning cost**: One-time cost for adjusting the pre-trained model
    using a larger set of example data'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**初始微调成本**：使用更大示例数据集调整预训练模型的一次性成本'
- en: '**Cost per inference**: Cost for each inference using the fine-tuned model'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每次推理的成本**：使用微调模型进行每次推理的成本'
- en: '**When to use transfer learning over FSL**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用迁移学习而非FSL**'
- en: 'Compared to FSL, transfer learning can be more advantageous under the following
    circumstances:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 与FSL相比，在以下情况下迁移学习可能更有优势：
- en: '**High frequency of usage**: The more frequently the model is used, the quicker
    the initial fine-tuning cost is amortized.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用频率高**：模型使用得越频繁，初始微调成本就越快摊销。'
- en: '**Stable task requirements**: New tasks must be similar enough for the fine-tuned
    model to perform well without further adjustment.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稳定的任务需求**：新任务必须足够相似，以便微调后的模型无需进一步调整就能表现良好。'
- en: '**Complex pattern adaption**: While requiring more extensive data, it can adapt
    deeper model layers to learn more complex patterns.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂模式适应**：虽然需要更多的数据，但它可以适应更深的模型层来学习更复杂的模式。'
- en: The mechanics of transfer learning
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习的工作原理
- en: At a high level, transfer learning and its fine-tuning processes are built upon
    similar foundations established by techniques like ZSL and FSL. Both ZSL and FSL
    are designed to apply pre-existing knowledge to new tasks. However, they differ
    primarily in the approach to adaptation. ZSL hypothesizes about *unseen tasks*
    based on learned abstract concepts without any specific examples, whereas FSL
    uses a *handful of examples* to guide the adaptation. Transfer learning extends
    these concepts by utilizing a base of extensively trained models that can be specifically
    fine-tuned to a new task, providing a practical balance between the broad generalization
    of ZSL and the rapid adaptation characteristic of FSL. Transfer learning is often
    the preferred approach when a robust, pre-trained model exists and there are examples
    from a highly related domain, but a lack of examples specifically related to the
    new task.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，迁移学习和其微调过程建立在类似于ZSL和FSL等技术建立的基础之上。ZSL和FSL都旨在将现有知识应用于新任务。然而，它们在适应方法上主要存在差异。ZSL基于学习到的抽象概念对*未见任务*进行假设，而不需要任何具体示例，而FSL使用*少量示例*来引导适应。迁移学习通过利用可以针对新任务进行特定微调的广泛训练的模型基础，扩展了这些概念，在ZSL的广泛泛化能力和FSL的快速适应特性之间提供了实用的平衡。当存在一个健壮的预训练模型，并且有来自高度相关领域的示例，但缺乏与新任务具体相关的示例时，迁移学习通常是首选的方法。
- en: At a more technical level, fine-tuning in transfer learning involves subtle
    yet significant adjustments to the model’s parameters that are already well-trained
    on large, diverse datasets. This fine-tuning adapts the learned features to the
    specifics of a new, related task, often involving adjustments to the deeper, more
    discriminative layers of the model. Such modifications enable the model to maintain
    its generalization capabilities while optimizing for performance on specific tasks
    within the new domain. This is different from FSL, where fine-tuning aims to quickly
    adapt the model using very few examples by making minimal adjustments, often only
    to the model’s final layers or via prompt engineering where there can be no adjustments
    to the trainable parameters.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在更技术层面上，迁移学习中的微调涉及对已经在大型、多样化的数据集上经过良好训练的模型参数进行微妙但重要的调整。这种微调使学习到的特征适应于新、相关任务的具体情况，通常涉及调整模型的更深、更具判别性的层。这些修改使模型能够在保持其泛化能力的同时，优化在新领域特定任务上的性能。这与FSL不同，FSL的微调旨在通过最小调整（通常仅限于模型的最终层或通过提示工程，其中无法调整可训练参数）使用非常少的示例快速适应模型。
- en: 'The following figure illustrates the differences between ZSL, FSL, and transfer
    learning:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了ZSL、FSL和迁移学习之间的差异：
- en: '![](img/B30999_10_07.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B30999_10_07.png)'
- en: 'Figure 10.7: Key differences between typical ZSL, FSL, and transfer learning
    implementations and their mechanics'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7：典型的ZSL、FSL和迁移学习实现及其机制之间的关键差异
- en: Transfer learning using Keras
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Keras的迁移学习
- en: In this section, in order to provide variety beyond applications just in the
    field of NLP, we will present a framework for how transfer learning can be implemented
    in an image classification task. This example will present a framework for how
    you can adapt a pre-trained image recognition model to a new marketing-relevant
    challenge of your choice, such as identifying desired product features.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，为了在自然语言处理领域之外提供多样性，我们将展示一个框架，说明如何将迁移学习应用于图像分类任务。本例将展示如何将预训练的图像识别模型适应于您选择的新的与营销相关的新挑战，例如识别所需的产品特征。
- en: The first step in the transfer learning process involves finding a pre-trained
    model that has been extensively trained on a large and diverse dataset. Here,
    we will use the VGG16 model, known for its robust performance in image recognition.
    VGG16 is a convolutional neural network that achieves this high performance through
    training on the ImageNet dataset using over a million images in order to classify
    them into a thousand image categories, as detailed by Simonyan and Zisserman in
    their 2014 paper, *Very deep convolutional networks for large-scale image recognition*.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习过程的第一步是寻找一个在大型和多样化的数据集上经过广泛训练的预训练模型。在这里，我们将使用VGG16模型，该模型以其在图像识别中的稳健性能而闻名。VGG16是一个卷积神经网络，通过在ImageNet数据集上使用超过一百万张图像进行训练，以将它们分类为一千个图像类别，如Simonyan和Zisserman在他们2014年的论文《非常深的卷积网络用于大规模图像识别》中详细描述的那样。
- en: 'First, we’ll summarize the full architecture of this model using `model.summary`
    to give us a better understanding of its layers and components:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用`model.summary`来总结这个模型的完整架构，以便更好地理解其层和组件：
- en: '[PRE7]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](img/B30999_10_08.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_10_08.png)'
- en: 'Figure 10.8: Model architecture summary'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8：模型架构摘要
- en: 'As shown here, the VGG16 architecture is a deep neural network consisting of
    multiple layers designed to process and transform the image into a form that is
    increasingly abstract and useful for classification tasks. Here’s a simple breakdown
    based on the preceding summary:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如此所示，VGG16架构是一个由多个层组成的深度神经网络，这些层被设计用来处理和将图像转换成越来越抽象的形式，这对于分类任务是有用的。以下是基于前面摘要的简单分解：
- en: '**Input layer**: This accepts images of size 224 x 224 pixels, which is a standard
    dimension for many image processing tasks. Each image has three color channels
    (Red, Green, and Blue), which explains the `3` in the shape given in *Figure 10.8*.
    The `None` given in each layer at the start is effectively a placeholder for the
    batch size, allowing for any number of images to be processed.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入层**：该层接受尺寸为224 x 224像素的图像，这是许多图像处理任务的标准化尺寸。每个图像有三个颜色通道（红色、绿色和蓝色），这解释了*图10.8*中给出的形状中的`3`。在开始时每个层中给出的`None`实际上是一个批量大小的占位符，允许处理任意数量的图像。'
- en: '**Convolutional layers (Conv2D)**: These perform the core of the work in the
    network. VGG16 has multiple convolutional layers stacked on top of each other,
    each with a set number of filters that detect different features in the image
    at various levels of granularity. For example, the first convolutional layer might
    detect edges, while deeper layers might identify more complex patterns like textures
    or specific objects. The progression in the number of filters from 64 to 512 reflects
    an increase in the complexity of features being detected in the image as it moves
    through the network.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积层（Conv2D）**：这些层在网络中执行核心工作。VGG16有多个卷积层堆叠在一起，每个层都有一定数量的过滤器，用于在图像的不同粒度级别检测不同的特征。例如，第一层卷积可能检测边缘，而深层层可能识别更复杂的模式，如纹理或特定对象。从64到512的过滤器数量增加反映了随着图像通过网络移动，检测到的图像特征复杂性的增加。'
- en: '**Max pooling layers (MaxPooling2D)**: These are interspersed with the convolutional
    layers and serve to reduce the spatial dimensions (width and height) of the input
    for the next convolutional layer. For instance, a pooling layer following a 224
    x 224 convolutional layer output reduces it to 112 x 112, thus reducing the computation
    required and helping in the detection of dominant features that are invariant
    to small shifts and rotations in the input image.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大池化层（MaxPooling2D）**：这些层与卷积层交错排列，用于减少输入到下一个卷积层的空间维度（宽度和高度）。例如，一个跟随224 x
    224卷积层输出的池化层将其减少到112 x 112，从而减少了所需的计算量，并有助于检测输入图像中小位移和旋转的不变主要特征。'
- en: '**Fully connected layers (Dense)**: Near the end of the network, the flattened
    output from the convolutional layers is fed into these densely connected layers.
    These are used to combine all features from the prior convolutional layers to
    eventually classify the image into one of the 1,000 categories.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全连接层（Dense）**：在网络接近末端，卷积层的展平输出被送入这些密集连接层。这些层用于结合先前卷积层中的所有特征，最终将图像分类为1,000个类别之一。'
- en: '**Output layer (predictions)**: The final layer outputs the probabilities of
    the image belonging to each of the 1,000 classes trained in the ImageNet dataset.
    The class with the highest probability is taken as the prediction of the model.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出层（预测）**：最后一层输出图像属于ImageNet数据集中训练的1,000个类别的概率。具有最高概率的类别被作为模型的预测。'
- en: 'The following is a visualization of this summary taken from a medical research
    article by Yang et al. ([https://www.nature.com/articles/s41598-021-99015-3](https://www.nature.com/articles/s41598-021-99015-3)):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的可视化是从杨等人发表在医学研究文章中的摘要（[https://www.nature.com/articles/s41598-021-99015-3](https://www.nature.com/articles/s41598-021-99015-3)）中提取的：
- en: '![](img/B30999_10_09.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_10_09.png)'
- en: 'Figure 10.9: Visualization of the architecture of the VGG16 deep neural network'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9：VGG16深度神经网络架构的可视化
- en: 'Let us now adapt this model for transfer learning:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将适应这个模型进行迁移学习：
- en: 'We will load the model into memory again, but this time with the option `include_top=False`
    in order to truncate the model after the last convolution layer. This will move
    the top layers responsible for classification into predefined categories and allow
    the model to serve as a feature extractor, which means it outputs a complex feature
    map that represents the input image’s key characteristics but doesn’t output a
    specific category prediction:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将再次将模型加载到内存中，但这次使用`include_top=False`选项，以便在最后一个卷积层之后截断模型。这将移动负责分类的顶层到预定义的类别中，并允许模型作为特征提取器，这意味着它输出一个复杂的特征图，代表输入图像的关键特征，但不输出特定的类别预测：
- en: '[PRE8]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can then adapt this feature-rich model to our new task of product classification
    by adding our own classification layers that will be trained on top of the feature
    extractor:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以在此基础上，通过添加自己的分类层来适应我们的新任务——产品分类，这些分类层将在特征提取器之上进行训练：
- en: '[PRE9]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, the model can be fine-tuned for transfer learning using new, task-specific
    data. This involves setting the pre-trained base model layers to non-trainable,
    thereby freezing the weights of the pre-trained layers, which is generally advised
    to avoid having the initial phase of training forget the majority of the base
    model’s initial feature extraction weights:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，可以使用新的、特定于任务的数据进行迁移学习来微调模型。这涉及到将预训练的基础模型层设置为不可训练的，从而冻结预训练层的权重，这通常建议避免训练的初始阶段忘记基础模型的大部分初始特征提取权重：
- en: '[PRE10]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Self-guided exercise: Fine-tuning VGG16 on your data**'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**自我引导练习：根据您的数据微调VGG16**'
- en: 'To apply transfer learning using the VGG16 model to classify images of product
    features, follow these steps:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要使用VGG16模型进行迁移学习并分类产品特征图像，请按照以下步骤操作：
- en: '**Collect images**: Gather images of products with features your company aims
    to classify. Sources can include online catalogs, social media, or direct captures
    of physical inventory.'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集图像**：收集您公司旨在分类的产品特征图像。来源可以包括在线目录、社交媒体或直接捕捉的实物库存。'
- en: '**Prepare the data**: Resize images to 224 x 224 pixels to match the VGG16
    input size and normalize pixel values to range `[0, 1]`.'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准备数据**：将图像调整大小为224 x 224像素，以匹配VGG16的输入大小，并将像素值归一化到范围 `[0, 1]`。'
- en: '**Train the model**: Use the compiled model and fit your images (`new_data`)
    and their binary labels `[0, 1]`, for instance using:'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练模型**：使用编译好的模型，并拟合您的图像（`new_data`）及其二进制标签 `[0, 1]`，例如使用：'
- en: '[PRE11]'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Evaluate and fine-tune**: Based on performance, consider adjusting your learning
    rate or gradually unfreezing layers in the base VGG16 model'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估和微调**：根据性能，考虑调整学习率或逐渐解冻基础VGG16模型中的层。'
- en: Transfer learning using API services
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用API服务进行迁移学习
- en: 'Transfer learning through API services offers a practical solution for marketing
    professionals who wish to utilize cutting-edge AI without the complexities of
    a local implementation. Some of the practical benefits of using an available API
    service for transfer learning are the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 通过API服务进行迁移学习为希望利用前沿AI而无需处理本地实现复杂性的市场营销专业人士提供了一个实用的解决方案。使用可用的API服务进行迁移学习的实际好处包括以下几方面：
- en: '**Access to advanced models**: Continuous updates and optimizations of API-accessible
    models ensure the use of cutting-edge technology that is more advanced than what
    may be publicly available.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**访问高级模型**：API可访问模型的持续更新和优化确保了使用比公开可用的技术更先进的前沿技术。'
- en: '**Computational efficiency**: Offloading the computational demands to cloud-based
    services removes the need for sophisticated hardware that may be inaccessible
    for individuals or small businesses.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算效率**：将计算需求卸载到基于云的服务中，消除了对可能对个人或小型企业不可及的复杂硬件的需求。'
- en: '**Simplified parameter management**: This refers to the automatic handling
    of learning rates, gradient adjustments, and other complex training parameters
    that can affect model performance.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简化参数管理**：这指的是自动处理学习率、梯度调整以及其他可能影响模型性能的复杂训练参数。'
- en: To apply transfer learning effectively, it’s crucial that the fine-tuning dataset
    mirrors the unique characteristics of your brand. This could include customer
    feedback or vetted marketing copy and product descriptions. If a proprietary dataset
    is unavailable, publicly accessible data such as reviews or social media posts
    about similar products or services could be used. The key is to compile this data
    into a single file, typically in CSV format, in a location that is accessible
    to the API. Each entry then needs to be clearly labeled according to its expected
    label or output.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地应用迁移学习，微调数据集必须反映您品牌独特的特征。这可能包括客户反馈或经过审查的营销文案和产品描述。如果无法获得专有数据集，可以使用公开可访问的数据，例如关于类似产品或服务的评论或社交媒体帖子。关键是将这些数据编译成一个单独的文件，通常以CSV格式，并放置在API可访问的位置。然后，每个条目都需要根据其预期的标签或输出进行清晰标注。
- en: 'The following is an example input in CSV format that gives the model a deeper
    understanding of what sustainability means in the context of our specific brand,
    setting the stage for what will be discussed in the hands-on example in the next
    section:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个CSV格式的示例输入，它使模型更深入地理解在我们特定品牌背景下可持续性的含义，为下一节中将要讨论的动手示例奠定了基础：
- en: '[PRE12]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we can initiate the model fine-tuning using OpenAI’s API with the GPT-4
    model, replacing `openai.api_key` with your actual key and `path/to/your/dataset.csv`
    with a path to the dataset’s location. Before executing this code, remember to
    consult the latest OpenAI API documentation ([https://beta.openai.com/docs/](https://beta.openai.com/docs/))
    for any updates or changes in the API usage:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用OpenAI的API和GPT-4模型启动模型微调，用您的实际密钥替换`openai.api_key`，并用数据集的位置路径替换`path/to/your/dataset.csv`。在执行此代码之前，请记得查阅最新的OpenAI
    API文档（[https://beta.openai.com/docs/](https://beta.openai.com/docs/)），以了解API使用方面的任何更新或更改：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Overcoming challenges in transfer learning
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 克服迁移学习中的挑战
- en: 'While transfer learning can be a powerful approach for fine-tuning pre-trained
    models to better perform better on new tasks, it is not without its challenges
    and limitations. The following are a couple of key challenges to consider when
    applying transfer learning:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然迁移学习可以是一种强大的方法，用于微调预训练模型以在新任务上表现更好，但它并非没有其挑战和局限性。以下是在应用迁移学习时需要考虑的几个关键挑战：
- en: '**Model drift**: In the context of transfer learning, model drift refers to
    the gradual decline in a model’s accuracy as the data it was fine-tuned on becomes
    less representative of the current environment or trends.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型漂移**：在迁移学习的背景下，模型漂移指的是随着用于微调的数据变得不再代表当前环境或趋势，模型准确性的逐渐下降。'
- en: For example, imagine using a model pre-trained on marketing data from 2019 to
    predict consumer preferences for 2024\. Initially, the model may perform well
    after being fine-tuned via transfer learning with more recent 2020 data. However,
    as consumer behavior shifts due to reasons such as new social media platforms
    like TikTok gaining in popularity or significant changes in economic conditions,
    the model may start recommending outdated messaging strategies.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象一下使用2019年营销数据预训练的模型来预测2024年的消费者偏好。最初，该模型在通过迁移学习使用更近期的2020年数据进行微调后可能表现良好。然而，由于像TikTok等新社交媒体平台越来越受欢迎或经济条件发生重大变化等原因，消费者行为发生变化，该模型可能开始推荐过时的信息策略。
- en: To address model drift, one needs to continuously update the model with recent
    data from the target domain and monitor its performance closely. This can be achieved
    by continuous learning techniques that allow the model to adjust dynamically as
    new data comes in. Further resources on continuous learning are given in the info
    box in this section.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决模型漂移问题，需要使用目标域的最新数据持续更新模型，并密切监控其性能。这可以通过允许模型随着新数据的到来而动态调整的持续学习技术来实现。本节中的信息框提供了有关持续学习的进一步资源。
- en: '**Domain mismatch**: Domain mismatch in transfer learning occurs when the source
    domain (where the model was initially trained) and the target domain (where the
    model is fine-tuned) differ significantly. In transfer learning, this means the
    pre-trained model’s knowledge may not generalize well to the new domain, leading
    to poor performance.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域不匹配**：在迁移学习中，当源领域（模型最初训练的地方）和目标领域（模型进行微调的地方）存在显著差异时，就会发生领域不匹配。在迁移学习中，这意味着预训练模型的知识可能无法很好地推广到新领域，从而导致性能不佳。'
- en: As an example, consider a model pre-trained on English-language customer reviews
    from an e-commerce platform, which is then fine-tuned to analyze reviews in Japanese
    for a local market. Even after fine-tuning, the model may struggle to capture
    cultural nuances and linguistic differences, leading to incorrect sentiment analysis.
    This may be because the pre-trained model’s reliance on patterns learned from
    English data makes it less effective when applied to Japanese reviews where the
    expressions and cultural references are different.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个在电子商务平台的英语语言客户评论上预训练的模型，然后微调以分析针对本地市场的日语评论。即使在微调之后，该模型可能也难以捕捉文化细微差别和语言差异，导致情感分析错误。这可能是因为预训练模型依赖于从英语数据中学习的模式，当应用于表达和文化参考不同的日语评论时，其效果较差。
- en: To address this, a more appropriate approach would be to fine-tune the model
    with a carefully curated dataset of Japanese customer reviews that specifically
    captures the specific linguistic and cultural nuances of the local market.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，一个更合适的方法是使用精心挑选的日本客户评论数据集来微调模型，这个数据集专门捕捉了当地市场的特定语言和文化细微差别。
- en: '**Staying ahead of model drift**'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**保持模型漂移的前沿**'
- en: To maintain the accuracy of your transfer learning models, especially as consumer
    behavior evolves, continuous learning is key.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持迁移学习模型的准确性，尤其是在消费者行为演变的情况下，持续学习是关键。
- en: Continuous learning is often implemented within the practices of MLOps. Learn
    more about MLOps principles and best practices at [https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning](https://cloud.google.com/architecture/ai-ml).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 持续学习通常在MLOps实践中得到实施。了解更多关于MLOps原则和最佳实践的信息，请访问[https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning](https://cloud.google.com/architecture/ai-ml)。
- en: Having introduced the fundamentals and techniques behind how FSL and transfer
    learning can adapt pre-trained models to better address new marketing tasks, we
    will now demonstrate the importance of FSL through a hands-on marketing example.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍了FSL和迁移学习如何将预训练模型适应以更好地解决新的营销任务的基本原理和技术之后，我们现在将通过一个实际营销示例来展示FSL的重要性。
- en: Applying FSL to improve brand consistency
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用FSL提高品牌一致性
- en: In our previous exploration of ZSL in *Chapter 9*, we demonstrated how a pre-trained
    model like GPT-4 could generate marketing copy for an e-commerce brand launching
    eco-friendly products. This ZSL approach, while powerful, primarily relied on
    the model’s ability to infer context and content from generalized pre-training
    using prompts emphasizing terms like *sustainable* and *eco-friendly*.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前对ZSL的探索中，*第9章*，我们展示了如何使用像GPT-4这样的预训练模型为推出环保产品的电子商务品牌生成营销文案。这种ZSL方法虽然强大，但主要依赖于模型从泛化预训练中推断上下文和内容的能力，这通过强调诸如*sustainable*和*eco-friendly*等术语的提示来实现。
- en: As the examples in this section will show, while ZSL provides a solid foundation
    for generating brand-relevant content, it often lacks the precision required for
    capturing the deeper, more nuanced aspects of a brand’s ethos. This is particularly
    true for brands whose identity is heavily tied to specific practices or principles
    that may not be well represented in the generalized training of the **large language
    model** (**LLM**).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如本节中的示例所示，虽然ZSL为生成与品牌相关的内内容提供了坚实的基础，但它往往缺乏捕捉品牌精神更深层次、更细微方面的精确度。这对于那些身份与特定实践或原则紧密相连的品牌尤其如此，这些实践或原则在**大型语言模型**（**LLM**）的泛化训练中可能没有得到很好的体现。
- en: '**Steps for effective FSL in marketing campaigns**'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**营销活动中有效FSL的步骤**'
- en: '**Prompt refinement and execution**: Begin with a basic prompt like one that
    would be used for ZSL, but now add a few examples of desired outputs or contexts
    that reflect the brand’s unique aspects.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示优化和执行**：从一个基本的提示开始，比如用于ZSL的提示，但现在添加一些期望的输出或上下文示例，这些示例反映了品牌的独特之处。'
- en: '**Output analysis**: Evaluate the content to ensure it maintains the necessary
    brand consistency. Note deviations from these expectations as they provide insights
    into areas needing further examples.'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输出分析**：评估内容以确保其保持必要的品牌一致性。注意与这些期望的偏差，因为它们提供了需要进一步示例的领域见解。'
- en: '**Iterative refinement**: Based on the feedback and performance of the initial
    outputs, refine the examples and prompts iteratively, continuing until you achieve
    your desired marketing KPIs (see *Chapter 2*).'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代优化**：根据初始输出的反馈和性能，迭代地优化示例和提示，直到达到你期望的营销KPIs（见*第2章*）。'
- en: Continuing our scenario from the section on *Zero-shot learning for marketing
    copy* in *Chapter 9*, we revisit our journey with the sustainability-focused e-commerce
    brand that we introduced earlier. Now, in response to evolving market trends and
    corporate directives, the company known for its eco-friendly kitchenware is undergoing
    a rebranding to align with the growing consumer demand for social responsibility.
    Recent insights reveal that consumers are increasingly interested in supporting
    brands that not only offer sustainable products but also demonstrate a tangible
    commitment to fair labor practices and positive community impact. This shift is
    particularly pronounced among affluent younger consumers who value ethical production
    and are willing to pay a premium for products that make a real difference in the
    lives of workers and communities. Furthermore, this demographic wants their products
    not just to have eco-friendly packaging but for them to be deemed “zero waste.”
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在第9章中“零样本学习用于营销文案”的部分，我们继续我们的场景，回顾我们之前介绍的关注可持续性的电子商务品牌。现在，为了应对不断变化的市场趋势和公司指令，以其环保厨房用品而闻名的公司正在进行品牌重塑，以适应日益增长的消费者对社会责任的需求。最新的洞察显示，消费者越来越有兴趣支持那些不仅提供可持续产品，而且表现出对公平劳动实践和积极社区贡献的实质性承诺的品牌。这种转变在富裕的年轻消费者中尤为明显，他们重视道德生产，并愿意为真正改变工人和社区生活的产品支付溢价。此外，这个群体希望他们的产品不仅要有环保包装，而且要被认为是“零浪费”。
- en: 'Let’s demonstrate how GPT-4 can effectively capture our newly defined sustainability
    campaign goals by enhancing output content through prompt engineering. This includes
    the subtle clarifications around sustainability mentioned earlier:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过增强输出内容并通过提示工程来展示GPT-4如何有效地捕捉我们新定义的可持续性营销目标。这包括对之前提到的可持续性的微妙澄清：
- en: A commitment to fair labor practices
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对公平劳动实践承诺
- en: Zero waste packaging
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零浪费包装
- en: Active community engagement
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活跃的社区参与
- en: We will exemplify this through a case study aimed at boosting an email marketing
    campaign. This involves iterative refinement of prompts, closely tied to monitoring
    key performance indicators previously discussed in *Chapter 2*, to ensure alignment
    with our rebranded marketing objectives.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一个旨在提升电子邮件营销活动的案例研究来展示这一点。这涉及到迭代地改进提示，与第2章中讨论的关键性能指标紧密相关，以确保与我们的重新定位营销目标保持一致。
- en: Benchmarking with ZSL and FSL
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ZSL和FSL进行基准测试
- en: 'Before integrating FSL into our email marketing campaign, it’s important to
    benchmark the effectiveness of ZSL at capturing the refined brand strategy for
    FSL is introduced. Here, we will compare a baseline response generated using ZSL
    that’s devoid of specific examples that align with our rebranded sustainability
    focus. We’ll define a function to execute the API completion and then illustrate
    how ZSL performs without the nuanced context of our updated campaign goals:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在将FSL整合到我们的电子邮件营销活动之前，评估ZSL在捕捉FSL新品牌战略方面的有效性是很重要的。在这里，我们将比较使用ZSL生成的基线响应，该响应没有与我们的重新定位的可持续性焦点相符合的具体例子。我们将定义一个函数来执行API补全，然后展示ZSL在没有我们更新后的营销目标细微背景的情况下如何表现：
- en: '[PRE14]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This gives us the following response:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下响应：
- en: '[PRE15]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see, while the response is clear, it is too generic and lacks the
    specificity and context needed to meet the specific goals of our rebranding initiative.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，虽然响应是清晰的，但它过于笼统，缺乏满足我们重新品牌化倡议特定目标所需的具体性和背景。
- en: 'To see the value FSL can provide, here, we revisit the exact same base prompt
    as earlier, but also include context specific to our updated campaign goals via
    FSL:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到FSL可以提供的价值，这里，我们回顾了之前完全相同的基线提示，但还通过FSL包括了针对我们更新后的营销目标的具体上下文：
- en: '[PRE16]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This produces the following output:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下输出：
- en: '[PRE17]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the preceding text, the aspects of the LLM-generated content that organically
    relate to our specific goals—environmental sustainability, fair labor practices,
    and community engagement—are highlighted for clarity. This comparison with ZSL
    underscores the capability of FSL to produce content that is more tailored and
    relevant to the strategic nuances of our rebrand by leveraging the initial contextual
    examples.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的文本中，与我们的特定目标——环境可持续性、公平劳动实践和社区参与——有机相关的LLM生成内容被突出显示以增强清晰度。这种与ZSL的比较强调了FSL通过利用初始上下文示例产生更符合我们重新品牌化战略细微差别的内容的能力。
- en: Developing an email marketing campaign
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 制定电子邮件营销活动
- en: 'Now, let’s explore the application of FSL in enhancing the personalization
    and relevance of email marketing campaigns, significantly boosting both customer
    engagement and conversion rates. The following is a concise guide on how to utilize
    FSL to optimize email campaigns effectively:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探讨FSL在增强电子邮件营销活动的个性化和相关性方面的应用，显著提高客户参与度和转化率。以下是如何有效利用FSL优化电子邮件活动的简要指南：
- en: '**Initial email creation**: Generate the initial batch of emails using FSL,
    specifically focusing on your core marketing goals—in this case, sustainability
    and ethical practices.'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始电子邮件创建**：使用FSL生成初始批次的电子邮件，特别关注您的核心营销目标——在本例中，是可持续性和道德实践。'
- en: '**Collect initial metrics and responses**: Analyze the initial reactions from
    customers to understand what aspects of the content resonate the most. This analysis
    is crucial in identifying successful elements and areas that may require additional
    refinement.'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集初始指标和反馈**：分析客户的初始反应，了解哪些内容方面最能引起共鸣。这种分析对于识别成功元素和可能需要额外优化的领域至关重要。'
- en: '**Iterative refinement**: Refine the content of the emails based on the engagement
    metrics and feedback received from customers.'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迭代优化**：根据从客户那里收到的参与指标和反馈，优化电子邮件的内容。'
- en: '**Continued feedback integration**: Continuously integrate new insights to
    keep the email marketing campaign dynamically aligned with evolving customer preferences
    and market trends.'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**持续反馈整合**：持续整合新的见解，使电子邮件营销活动动态地与不断变化的客户偏好和市场趋势保持一致。'
- en: Now let’s examine what these steps entail.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来审视这些步骤包含的内容。
- en: 'Step 1: Initial email creation'
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一步：初始电子邮件创建
- en: 'The first step in employing FSL in an email marketing campaign is to clearly
    define the campaign’s objectives. For our eco-friendly e-commerce brand, the objective
    might be to launch a new line of eco-friendly kitchenware that aligns with the
    rebrand goals. Let’s consider our objective for this scenario to be the following:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在电子邮件营销活动中采用FSL的第一步是明确界定活动的目标。对于我们这个环保型电子商务品牌来说，目标可能是推出一系列与品牌重塑目标相符的环保厨房用品。让我们假设这个场景的目标如下：
- en: '[PRE18]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: With the campaign’s objective clearly defined, the next step involves creating
    prompts that instruct the AI on the content that’s appropriate for the email message.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 活动目标明确后，下一步是创建提示，指导AI生成适合电子邮件信息的适当内容。
- en: '**Structuring the initial email for your marketing campaign**'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**构建营销活动的初始电子邮件结构**'
- en: 'The following general structure is helpful in creating an effective initial
    message for your email marketing campaign that increases engagement and conversion
    with your audience:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的一般结构有助于创建一个有效的初始信息，用于您的电子邮件营销活动，从而提高与受众的参与度和转化率：
- en: '**Introduction**: Greet the customer and introduce the new product line enthusiastically.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**介绍**：热情地问候客户并介绍新产品系列。'
- en: '**Body**: Provide detailed information about the core aspects of the product
    – in this case, the sustainability and ethical manufacturing aspects.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正文**：提供关于产品核心方面的详细信息——在本例中，是可持续性和道德制造方面。'
- en: '**Call to action**: Include a call to action that encourages the recipient
    to take specific steps such as making a purchase or visiting a website.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行动号召**：包含一个行动号召，鼓励收件人采取具体步骤，例如进行购买或访问网站。'
- en: '**Closing**: Conclude with a warm closing that reinforces the brand’s commitment
    to the core aspects of the product.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结束语**：以热情的结束语结束，强调品牌对产品核心方面的承诺。'
- en: 'We’ll define a starting prompt for the model, which will be used to generate
    the initial batch of emails. Similar to the earlier product description example,
    each element of the `fsl_prompts` is designed to progressively build a narrative
    around the brand’s commitment to sustainability, ethical practices, and community
    involvement, as required by the corporate rebrand, in the following way:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为模型定义一个起始提示，该提示将用于生成初始批次的电子邮件。类似于早期产品描述的例子，`fsl_prompts`的每个元素都旨在逐步构建围绕品牌对可持续性、道德实践和社区参与的承诺的叙事，如下所示：
- en: The first pair of prompts ensures the content appropriately emphasizes the eco-friendly
    and zero-waste aspect of the kitchenware
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一组提示确保内容适当地强调了厨房用品的环保和零浪费特性。
- en: The second set of prompts addresses the context expected when discussing the
    ethical labor practices involved in the production process
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二组提示针对的是讨论生产过程中涉及的道德劳动实践时的预期背景。
- en: The final two prompts tie the product to community engagement efforts, linking
    purchases to initiatives that are important to socially responsible consumers
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后两个提示将产品与社区参与努力联系起来，将购买与对社会负责任的消费者重要的倡议联系起来
- en: 'To ensure that the generated content aligns with our campaign goals, we’ll
    also adjust our base prompt to be more specific to an email campaign and increase
    the `max_tokens` to reflect the longer content:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保生成的内容与我们的活动目标一致，我们将调整我们的基本提示以更具体地针对电子邮件活动，并将`max_tokens`增加到反映更长的内容：
- en: '[PRE19]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This produces the following email content:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下电子邮件内容：
- en: '[PRE20]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Step 2: Collect and analyze initial metrics and responses'
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第2步：收集和分析初始指标和响应
- en: Following the deployment of our email campaign with the newly created content,
    it is crucial to assess its effectiveness using KPIs. For this evaluation, we
    assume we already have representative data from the first seven days post-launch
    that will allow us to examine the metrics of open rate, click-through rate, conversion
    rate, and unsubscribe rate. This analysis helps us identify areas for improvement
    by visualizing these KPIs over time.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署了新创建内容的电子邮件活动之后，评估其效果至关重要，使用关键绩效指标（KPIs）进行评估。为此评估，我们假设我们已经有了启动后前七天的代表性数据，这将使我们能够检查打开率、点击率、转化率和取消订阅率的指标。这种分析有助于我们通过可视化这些KPIs随时间的变化来识别改进的领域。
- en: '[PRE21]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the following graph, we can observe the trends in open rates, click-through
    rates, conversion rates, and unsubscribe rates over the first week following the
    campaign launch. This allows us to quickly identify patterns, which can be critical
    for diagnosing issues with the campaign’s content or delivery:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图表中，我们可以观察到活动启动后第一周内打开率、点击率、转化率和取消订阅率的变化趋势。这使我们能够快速识别模式，这对于诊断活动内容或交付的问题可能至关重要：
- en: '![](img/B30999_10_10.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_10_10.png)'
- en: 'Figure 10.10: Email campaign KPIs during the first week after launch'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10：启动后第一周的电子邮件活动KPIs
- en: '**Benchmarking your email campaign performance**'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**基准测试您的电子邮件活动表现**'
- en: Evaluating the performance of your marketing campaign metrics can be tricky,
    especially without industry benchmarks as a reference. To quickly assess whether
    your KPIs are on target, start by comparing them to established benchmarks.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 评估营销活动指标的表现可能很棘手，尤其是在没有行业基准作为参考的情况下。为了快速评估您的KPIs是否达标，首先将它们与既定的基准进行比较。
- en: 'Here is a recent comparison of email marketing benchmarks: [https://www.webfx.com/blog/marketing/email-marketing-benchmarks/](https://www.webfx.com/blog/marketing/email-marketing-benchmarks/).'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是最近电子邮件营销基准的比较：[https://www.webfx.com/blog/marketing/email-marketing-benchmarks/](https://www.webfx.com/blog/marketing/email-marketing-benchmarks/)。
- en: 'We can also calculate and review the average performance across these metrics:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以计算并审查这些指标的平均表现：
- en: '[PRE22]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This yields the following:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下结果：
- en: '[PRE23]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Based on these KPIs, the following are some observations and possible explanations
    that we may consider addressing in our next iteration of the email campaign:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些KPIs，以下是一些观察和可能的解释，我们可能在下一轮电子邮件活动中考虑解决：
- en: '**Low open rates**: This may suggest that the email subject lines are not sufficiently
    engaging.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低打开率**：这可能表明电子邮件的主题行不够吸引人。'
- en: '**Click-through rates**: Some recipients view the emails but do not click through
    at expected rates, possibly due to less compelling content or offers.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**点击率**：一些收件人查看电子邮件，但点击率低于预期，可能是由于内容或优惠不够吸引人。'
- en: '**Modest conversion rates**: This indicates a need for stronger calls to action
    or improvements in the effectiveness of landing pages.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低转化率**：这表明需要更强的行动号召或提高着陆页的有效性。'
- en: '**Rising unsubscribe rate**: This could point to issues with the frequency
    or relevance of the content.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**取消订阅率上升**：这可能表明内容频率或相关性存在问题。'
- en: 'In addition to these KPIs, assume we’ve collected feedback from email recipients
    who responded directly to this email with their questions and concerns. We can
    also gather information, for example, by employing sentiment analysis techniques
    discussed in *Chapter 5*, allowing us to determine the core topics and sentiments
    from product reviews and social media posts from customers who read our emails.
    Here’s an overview of the positive feedback that we will assume to have received:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些KPI之外，假设我们还收集了直接回复此电子邮件并表达他们的疑问和担忧的电子邮件收件人的反馈。我们还可以通过采用第5章中讨论的情感分析技术来收集信息，这样我们就可以确定阅读我们电子邮件的客户的产品评论和社交媒体帖子中的核心主题和情感。以下是我们将假设收到的积极反馈概述：
- en: 'Appreciation for **sustainable practices**: “I love that your kitchenware is
    made from recycled materials.”'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对**可持续实践**的赞赏：“我喜欢你们的厨房用品是用回收材料制成的。”
- en: 'Approval of **ethical manufacturing**: “It’s reassuring to see a brand commit
    to fair wages and safe working conditions.”'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对**道德制造**的认可：“看到品牌承诺公平工资和安全的劳动条件，让人感到放心。”
- en: 'Enthusiasm for the **product range**: “The stainless steel cookware looks fantastic!”'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对**产品系列**的热情：“不锈钢炊具看起来非常棒！”
- en: 'The following are the highlights of the negative feedback:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对负面反馈的要点：
- en: 'Desire for more **product variety**: “I wish that you advertised more color
    options for the product lines.”'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对更多**产品多样性**的渴望：“我希望你们为产品系列提供更多颜色选择。”
- en: 'Questions about **product care**: “I’m concerned about how I can care for these
    products to ensure they last longer.”'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对**产品保养**的疑问：“我担心如何保养这些产品以确保它们更耐用。”
- en: 'Concerns over **price points**: “The products are great, but they’re a bit
    pricey compared to non-eco-friendly alternatives.”'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对**价格点**的担忧：“产品很好，但与不环保的替代品相比，它们有点贵。”
- en: While the positive comments validate our campaign’s core messages, the criticisms
    and questions provide actionable insights for our future email messaging. Using
    this feedback, in the next section, we will hone in on how the negative critiques
    can be exploited to refine our email marketing strategies and improve our KPIs.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然积极的评论验证了我们的活动核心信息，但批评和问题为我们未来的电子邮件信息提供了可操作的见解。利用这些反馈，在下一节中，我们将专注于如何利用负面批评来优化我们的电子邮件营销策略并提高我们的KPI。
- en: 'Step 3: Iterative refinement'
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3步：迭代优化
- en: 'After reviewing the initial metrics and customer feedback from the previous
    sections, it’s clear that while some aspects of the campaign resonate well, there
    are key areas needing improvement. The next step is to refine our FSL prompts
    based on the initial metrics, address the specific criticisms from customer feedback,
    better meet customer expectations, and enhance the overall effectiveness of the
    campaign. The following are the new elements of the prompt, with commentary included
    after each element of the prompt, highlighting their value to our task:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查了前几部分的初始指标和客户反馈后，很明显，尽管一些方面与活动很好地产生了共鸣，但还有一些关键领域需要改进。下一步是根据初始指标优化我们的FSL提示，解决客户反馈中的具体批评，更好地满足客户期望，并提高活动的整体效果。以下是提示的新要素，每个要素后面都有注释，突出其对我们任务的价值：
- en: '[PRE24]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This prompt sets the tone for the email, capturing the key elements from our
    previous FSL attempt but also emphasizing the importance of an engaging subject
    line in direct response to the low open rate observed in the initial KPI metrics.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示为电子邮件设定了基调，捕捉了我们之前FSL尝试的关键要素，同时也强调了在直接回应初始KPI指标中观察到的低打开率时，一个吸引人的主题行的重要性。
- en: '[PRE25]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This response caters to feedback desiring more variety. It emphasizes the range
    of colors available, aiming to attract customers looking to personalize their
    purchases.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这个回应迎合了希望有更多样化的反馈。它强调了可用的颜色范围，旨在吸引那些希望个性化购买的客户。
- en: '[PRE26]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Addressing customer concerns about maintenance, this prompt reassures customers
    that the products are not only sustainable but also easy to care for, enhancing
    their appeal by ensuring longevity.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 针对客户对维护的担忧，这个提示向客户保证产品不仅可持续，而且易于保养，通过确保产品的耐用性来增强其吸引力。
- en: '[PRE27]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This prompt directly tackles the issue of price sensitivity noted in the feedback.
    It reframes the cost as an investment in quality and sustainability, arguing for
    long-term value and environmental impact.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示直接解决了反馈中提到的价格敏感性问题。它将成本重新定义为对质量和可持续性的投资，主张长期价值和环境影响。
- en: '[PRE28]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'After executing the API recall, we get the following result:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 执行API召回后，我们得到以下结果：
- en: '[PRE29]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'After deploying these updates emails on April 7, assume we collect the next
    seven days of KPI data and observe the following updated trends:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在4月7日部署这些更新后的电子邮件后，假设我们收集了接下来的七天KPI数据，并观察到以下更新趋势：
- en: '[PRE30]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This gives us the following plot, where we observe significant changes in the
    KPIs after FSL refinements:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下图表，其中我们观察到在FSL优化后KPI的显著变化：
- en: '![](img/B30999_10_11.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B30999_10_11.png)'
- en: 'Figure 10.11: Email campaign KPIs after campaign changes and improvements were
    made in response to customer feedback'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11：在针对客户反馈进行更改和改进后，电子邮件营销活动的KPI
- en: 'Based on this, we have the following average KPIs:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，我们有以下平均KPI：
- en: '[PRE31]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'By comparing these metrics to the previous ones, we see significant improvements
    across all areas. While attributing the exact origins of these improvements is
    not possible without techniques such as A/B testing (*Chapter 6*) or causal inference
    (*Chapter 3*), one can still speculate what may be behind these improved KPIs:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将这些指标与之前的指标进行比较，我们发现所有领域都取得了显著的改进。虽然没有使用如A/B测试（第6章）或因果推断（第3章）等技术来确定这些改进的确切原因，但人们仍然可以推测这些改进的KPI可能背后的原因：
- en: '**Open rate** improved significantly, which may reflect the more engaging subject
    lines, including “Revolutionize your Kitchen…”'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**打开率**显著提高，这可能反映了更具吸引力的主题行，包括“革命你的厨房…”'
- en: '**Click-through rate** saw an increase, which may be attributed to the inclusion
    of requested features like product variety and detailed care instructions, which
    increased customer engagement'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**点击率**有所上升，这可能归因于包括所需功能（如产品多样性和详细的护理说明）在内的内容，这些内容增加了客户参与度'
- en: '**Conversion rate** increased, indicating that the email content was not only
    more engaging but also more effective at convincing customers of the value and
    relevance of the products, especially after addressing price concerns'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转化率**提高，表明电子邮件内容不仅更具吸引力，而且更有效地说服客户产品的价值和相关性，尤其是在解决价格问题之后'
- en: '**Unsubscribe rate** decreased, reflecting higher content satisfaction'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**取消订阅率**下降，反映了更高的内容满意度'
- en: 'Step 4: Continued feedback integration'
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第4步：持续反馈整合
- en: The final step in utilizing FSL for email marketing campaigns is to establish
    a robust system for continuous feedback integration. This approach ensures that
    the campaign remains dynamic and responsive to the evolving needs and preferences
    of customers, as well as broader market trends. By integrating continuous feedback,
    the campaign not only maintains relevance but also strengthens customer engagement
    and promotes brand loyalty over time.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 利用FSL进行电子邮件营销活动的最后一步是建立一个强大的系统，用于持续反馈整合。这种方法确保活动保持动态，并能对客户不断变化的需求和偏好以及更广泛的市场趋势做出响应。通过整合持续反馈，活动不仅保持相关性，而且随着时间的推移加强了客户参与度和品牌忠诚度。
- en: Effective feedback integration requires mechanisms that allow customers to share
    their thoughts and experiences easily. This includes embedding quick survey links
    directly in emails, enabling direct email responses, and engaging with customers
    through social media interactions related to the campaign. These channels facilitate
    the flow of information from customers back to marketers, providing valuable insights
    that can be used to refine and improve the campaign continuously.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的反馈整合需要允许客户轻松分享他们的想法和经验的机制。这包括直接在电子邮件中嵌入快速调查链接，启用直接电子邮件回复，并通过与活动相关的社交媒体互动与客户互动。这些渠道促进了信息从客户流向营销人员，提供了有价值的见解，这些见解可用于持续改进和优化活动。
- en: '**Example feedback collection strategies**'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例反馈收集策略**'
- en: 'The following are additional ways to collect direct customer feedback:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些收集直接客户反馈的额外方法：
- en: '**Live chat feedback**: Implement live chat on your website to allow real-time
    interactions and immediate feedback.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时聊天反馈**：在您的网站上实施实时聊天，以允许实时互动和即时反馈。'
- en: '**Interactive content**: Use quizzes and polls in your emails or on digital
    platforms to make feedback collection engaging.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**互动内容**：在您的电子邮件或数字平台上使用测验和投票，使反馈收集更具吸引力。'
- en: '**Feedback QR codes**: QR codes on products or ads can link to feedback forms
    so customers can easily respond on their devices.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈二维码**：产品或广告上的二维码可以链接到反馈表单，以便客户可以轻松地在他们的设备上做出回应。'
- en: To effectively analyze and utilize ongoing feedback, setting up a real-time
    feedback dashboard can be immensely beneficial. This dashboard can serve as a
    central hub for monitoring and analyzing feedback alongside standard marketing
    KPIs, providing a comprehensive view of campaign performance. To build such a
    dashboard, consider using software solutions like Tableau, Microsoft Power BI,
    or Google Data Studio, which offer powerful tools and intuitive interfaces for
    creating interactive and real-time data visualizations.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地分析和利用持续的反馈，设置一个实时反馈仪表板可以带来巨大的好处。这个仪表板可以作为监控和分析反馈以及标准营销关键绩效指标的中心枢纽，提供对活动表现的全面视图。为了构建这样的仪表板，考虑使用像Tableau、Microsoft
    Power BI或Google Data Studio这样的软件解决方案，它们提供了创建交互式和实时数据可视化的强大工具和直观界面。
- en: 'The following are the steps for creating your own feedback dashboard:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是你创建自己的反馈仪表板的步骤：
- en: '**Select a dashboard tool**: Choose a platform that best fits your technical
    capabilities and budget. Tableau, Microsoft Power BI, and Google Data Studio are
    popular choices due to their robust features and scalability.'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择仪表板工具**：选择最适合你的技术能力和预算的平台。Tableau、Microsoft Power BI和Google Data Studio因其强大的功能和可扩展性而成为流行的选择。'
- en: '**Integrate data sources**: Connect the dashboard tool to the data sources
    that gather your marketing KPIs and feedback. This may include email campaign
    management tools, social media analytics, and customer feedback systems.'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**集成数据源**：将仪表板工具连接到收集你的营销关键绩效指标和反馈的数据源。这可能包括电子邮件活动管理工具、社交媒体分析和客户反馈系统。'
- en: '**Design the dashboard**: Create visualizations that clearly display the key
    metrics you need to track. Customize the dashboard to highlight trends, spikes,
    and dips in campaign performance.'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设计仪表板**：创建清晰显示你需要跟踪的关键指标的视觉呈现。根据活动表现的趋势、峰值和低谷定制仪表板。'
- en: '**Schedule regular reviews**: Set up regular intervals, bi-weekly or monthly,
    for example, to review the dashboard insights. Use these sessions to assess the
    effectiveness of recent changes and to plan further strategic adjustments based
    on the data insights.'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安排定期审查**：设定定期的时间间隔，例如每两周或每月，来审查仪表板洞察。利用这些会议来评估最近变化的有效性，并根据数据洞察规划进一步的策略调整。'
- en: '**Keeping your emails out of the spam folder**'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**防止你的电子邮件进入垃圾邮件文件夹**'
- en: 'To maximize the effectiveness of your email campaigns, it’s essential to prevent
    your messages from landing in the spam folder. Here are three key strategies for
    achieving this:'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了最大限度地提高你电子邮件活动的影响力，防止你的信息进入垃圾邮件文件夹至关重要。以下实现这一目标的三项关键策略：
- en: '**Set up email authentication**: Implement standards like SPF, DKIM, and DMARC
    to authenticate your emails. This helps establish trust with email providers to
    reduce the risk of your emails being marked as spam.'
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设置电子邮件认证**：实施SPF、DKIM和DMARC等标准来验证你的电子邮件。这有助于与电子邮件提供商建立信任，以降低你的电子邮件被标记为垃圾邮件的风险。'
- en: '**Maintain list hygiene**: Regularly clean your email list by removing inactive
    subscribers and ensuring that all recipients have opted in to receive your emails.
    This not only boosts engagement but also helps protect your sender reputation.'
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护名单卫生**：定期清理电子邮件名单，移除不活跃的订阅者，并确保所有收件人都已选择接收你的电子邮件。这不仅提高了参与度，还有助于保护你的发送者声誉。'
- en: '**Optimize email content**: Other optimization strategies include personalizing
    your emails using FSL, limiting the number of links, and maintaining a balanced
    image-to-text ratio.'
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化电子邮件内容**：其他优化策略包括使用FSL个性化你的电子邮件、限制链接数量以及保持图像与文本比例的平衡。'
- en: Summary
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter explored the potential of FSL and its promise for refining AI-driven
    marketing strategies to enhance brand presence. Building on the principles introduced
    through ZSL, we explored how FSL leverages a limited dataset to enable rapid adaptation
    of AI models to new tasks. This is crucial in the fast-paced marketing domain,
    where aligning quickly with evolving consumer preferences and market trends can
    have a significant impact on a brand’s relevance and engagement.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了FSL的潜力及其对改进AI驱动营销策略、增强品牌影响力的承诺。基于通过ZSL引入的原则，我们探讨了FSL如何利用有限的数据集，使AI模型能够快速适应新任务。这在营销领域尤为重要，因为快速适应不断变化的消费者偏好和市场趋势可以对品牌的关联性和参与度产生重大影响。
- en: While FSL focuses on quick adaptability using minimal examples, transfer learning
    complements this by applying pre-trained models fine-tuned for specific tasks,
    thereby minimizing the need for extensive retraining. The chapter emphasized practical
    strategies combining these methodologies to optimize your marketing efforts. Through
    approaches like the MAML approach, we demonstrated how you can use meta-learning
    frameworks for marketing.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 FSL 侧重于使用最小示例快速适应，但迁移学习通过应用针对特定任务微调的预训练模型来补充这一点，从而最小化大量重新训练的需求。本章强调了结合这些方法来优化您的营销努力的实用策略。通过如
    MAML 方法等途径，我们展示了您如何使用元学习框架进行营销。
- en: As we proceed, the next chapter will introduce the concept of **retrieval-augmented
    generation** (**RAG**). We will explore how RAG can dynamically produce content
    that reflects the latest available data by integrating generative models with
    advanced information retrieval techniques. This approach not only increases the
    relevance of the content generated but also enhances precision in consumer targeting,
    making your marketing efforts significantly more effective. The upcoming discussion
    will cover the technical setup of a knowledge retrieval system and practical applications
    of RAG in marketing, through which we aim to provide you with robust tools for
    writing precisely targeted marketing content that resonates with your current
    and potential customers.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续前进，下一章将介绍**检索增强生成**（**RAG**）的概念。我们将探讨如何通过将生成模型与高级信息检索技术相结合，RAG 可以动态生成反映最新可用数据的内容。这种方法不仅增加了生成内容的关联性，还提高了消费者定位的精确性，使您的营销工作显著更加有效。即将进行的讨论将涵盖知识检索系统的技术设置以及
    RAG 在营销中的实际应用，我们希望通过这些内容为您提供编写与您当前和潜在客户产生共鸣的精准营销内容的强大工具。
- en: Join our book’s Discord space
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的 Discord 空间
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 5000 members at:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区，与志同道合的人交流，并在以下地点与超过 5000 名成员一起学习：
- en: '[https://packt.link/genai](https://packt.link/genai)'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/genai](https://packt.link/genai)'
- en: '![](img/QR_Code12856128601808671.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code12856128601808671.png)'
