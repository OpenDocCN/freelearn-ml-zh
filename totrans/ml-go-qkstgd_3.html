<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Supervised Learning</h1>
                </header>
            
            <article>
                
<p class="mce-root">As we learned in the first chapter, supervised learning is one of two major branches of machine learning. In a way, it is similar to how humans learn a new skill: someone else shows us what to do, and we are then able to learn by following their example. In the case of supervised learning algorithms, we usually need lots of examples, that is, lots of data providing the <strong>input</strong> to our algorithm and what the <strong>expected output</strong> should be. The algorithm will learn from this data, and then be able to <strong>predict</strong> the output based on new inputs that it has not seen before.</p>
<p>A surprising number of problems can be addressed using supervised learning. Many email systems use it to classify emails as either important or unimportant automatically whenever a new message arrives in the inbox. More complex examples include image recognition systems, which can identify what an image contains purely from the input pixel values<sup>[1]</sup>. These systems start by learning from huge datasets of images that have been labelled manually by humans, but are then able to categorize completely new images automatically. It is even possible to use supervised learning to steer a car automatically around a racing track: the algorithm starts by learning how a human driver controls the vehicle, and is eventually able to replicate this behavior<sup><span>[2]</span></sup>. </p>
<p>By the end of this chapter, you will be able to use Go to implement two types of supervised learning:</p>
<ul>
<li><strong>Classification</strong>, where an algorithm must learn to classify the input into two or more discrete categories. We will build a simple image recognition system to demonstrate how this works.</li>
<li><strong>Regression</strong>, in which the algorithm must learn to predict a continuous variable, for example, the price of an item for sale on a website. For our example, we will predict house prices based on inputs, such as the location, size, and age of the house.</li>
</ul>
<p>In this chapter, we will be covering the following topics:</p>
<ul>
<li>When to use regression and classification</li>
<li>How to implement regression and classification using Go machine learning libraries</li>
<li>How to measure the performance of an algorithm</li>
</ul>
<p>We will cover the two stages involved in building a supervised learning system:</p>
<ul>
<li><strong>Training</strong>, which is the learning phase where we use labelled data to calibrate an algorithm</li>
<li><strong>Inference</strong> or <strong>prediction</strong>, where we use the trained algorithm for its intended purpose: to make predictions from input data</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Classification</h1>
                </header>
            
            <article>
                
<p class="mce-root">When starting any supervised learning problem, the first step is to load and prepare the data. We are going to start by loading the <strong>MNIST Fashion</strong> <strong>dataset</strong><sup><span>[3]</span></sup>, a collection of small, grayscale images showing different items of clothing. Our job is to build a system that can recognize what is in each image; that is, does it contain a dress, a shoe, a coat, and so on?</p>
<p>First, we need to download the dataset by running the <kbd><span>download-fashion-mnist.sh</span></kbd> script in the code repository. Then, we will load it into Go:</p>
<pre>import (<br/>    "fmt"<br/>     mnist "github.com/petar/GoMNIST"<br/>    "github.com/kniren/gota/dataframe"<br/>    "github.com/kniren/gota/series"<br/>    "math/rand"<br/>    "github.com/cdipaolo/goml/linear"<br/>    "github.com/cdipaolo/goml/base"<br/>    "image"<br/>    "bytes"<br/>    "math"<br/>    "github.com/gonum/stat"<br/>    "github.com/gonum/integrate"<br/>)<br/>set, err := mnist.ReadSet("../datasets/mnist/images.gz", "../datasets/mnist/labels.gz")</pre>
<p>Let's start by taking a look at a sample of the images. Each one is 28 x 28 pixels, and each pixel has a value between 0 and 255. We are going to use these pixel values as the inputs to our algorithm: our system will accept 784 inputs from an image and use them to classify the image according to which item of clothing it contains. In Jupyter, you can view an image as follows:</p>
<pre>set.Images[1]</pre>
<p>This will display one of the 28 x 28 images from the dataset, as shown in the following image:</p>
<p class="packt_figref CDPAlignCenter CDPAlign"><img src="assets/a4ddbc0b-b7bd-4a7e-b2e0-4e8730942184.png" style="font-size: 10pt;text-align: center;width:4.75em;height:4.75em;"/></p>
<p>To make this data suitable for a machine learning algorithm, we need to convert it into a dataframe format, as we learned in <a href="532d8304-b31d-41ef-81c1-b13f4c692824.xhtml" target="_blank">Chapter 2</a>, <em>Setting Up the Development Environment</em>. To start, we will load the first 1,000 images from the dataset:</p>
<pre>func MNISTSetToDataframe(st *mnist.Set, maxExamples int) dataframe.DataFrame {<br/> length := maxExamples<br/> if length &gt; len(st.Images) {<br/> length = len(st.Images)<br/> }<br/> s := make([]string, length, length)<br/> l := make([]int, length, length)<br/> for i := 0; i &lt; length; i++ {<br/> s[i] = string(st.Images[i])<br/> l[i] = int(st.Labels[i])<br/> }<br/> var df dataframe.DataFrame<br/> images := series.Strings(s)<br/> images.Name = "Image"<br/> labels := series.Ints(l)<br/> labels.Name = "Label"<br/> df = dataframe.New(images, labels)<br/> return df<br/>}<br/><br/>df := MNISTSetToDataframe(set, 1000)</pre>
<p>We also need a string array that contains the possible labels for each image:</p>
<pre>categories := []string{"tshirt", "trouser", "pullover", "dress", "coat", "sandal", "shirt", "shoe", "bag", "boot"}</pre>
<p>It is very important to start by reserving a small proportion of your data in order to test the finished algorithm. This allows us to measure how well the algorithm works on new data that was not used during training. If you do not do this, you will most likely build a system that works really well during training but performs badly when faced with new data. To start with, we are going to use 75% of the images to train our model and 25% of the images to test it.</p>
<div class="packt_tip">Splitting your data into a <strong>training set</strong> and a <strong>test set</strong> is crucial step when using supervised learning. It is normal to reserve 20-30% of the data for testing, but if your dataset is very large, you may be able to use less than this.</div>
<p>Use the <kbd>Split(df dataframe.DataFrame, valFraction float64)</kbd> function from the last chapter to prepare these two datasets:</p>
<pre>training, validation := Split(df, 0.75)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A simple model – the logistic classifier</h1>
                </header>
            
            <article>
                
<p>One of the simplest algorithms that solves our problem is a logistic classifier. This is what mathematicians call a <strong>linear model</strong>, which we can understand by thinking about a simple example where we are trying to classify the points on the following two charts as either circles or squares. A linear model will try to do this by drawing a straight line to separate the two types of point. This works very well on the left-hand chart, where the relationship between the inputs (on the chart axes) and the output (circle or square) is simple. However, it does not work on the right-hand chart, where it is not possible to split the points into two correct groups using a straight line:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-383 image-border" src="assets/28aa78cc-b28a-4a64-bb0d-815d13704964.png" style="width:38.08em;height:19.50em;"/></p>
<p>When faced with a new machine learning problem, it is advised that you start with a linear model as a <strong>baseline</strong>, and then compare other models to it. Although linear models ca not capture complex relationships in the input data, they are easy to understand and normally quick to implement and train. You might find that a linear model is good enough for the problem you are working on and save yourself time by not having to implement anything more complex. If not, you can try different algorithms and use the linear model to understand how much better they work. </p>
<div class="packt_infobox">A <strong>baseline</strong> is a simple model that you can use as a point of reference when comparing different machine learning algorithms. </div>
<p>Going back to our image dataset, we are going to use a logistic classifier to decide whether an image contains trousers or not. First, let's do some final data preparation: simplify the labels to be either trousers <span>(</span><kbd>true</kbd><span>)</span> or not-trousers (<kbd>false</kbd>):</p>
<pre>func EqualsInt(s series.Series, to int) (*series.Series, error) {<br/> eq := make([]int, s.Len(), s.Len())<br/> ints, err := s.Int()<br/> if err != nil {<br/> return nil, err<br/> }<br/> for i := range ints {<br/> if ints[i] == to {<br/> eq[i] = 1<br/> }<br/>    }<br/>    ret := series.Ints(eq)<br/>    return &amp;ret, nil<br/>}<br/><br/>trainingIsTrouser, err1 := EqualsInt(training.Col("Label"), 1)<br/>validationIsTrouser, err2 := EqualsInt(validation.Col("Label"), 1)<br/>if err1 != nil || err2 != nil {<br/>    fmt.Println("Error", err1, err2)<br/>}</pre>
<p>We are also going to normalize the pixel data so that, instead of being stored as integers between 0 and 255, it will be represented by floats between 0 and 1:</p>
<div class="packt_tip">Many supervised machine learning algorithms only work properly if the data is normalized, that is, rescaled so that it is between 0 and 1. If you are having trouble getting an algorithm to train properly, make sure that you have normalized the data properly.</div>
<pre>func NormalizeBytes(bs []byte) []float64 {<br/>    ret := make([]float64, len(bs), len(bs))<br/>    for i := range bs {<br/>        ret[i] = float64(bs[i])/255.<br/>    }<br/>    return ret<br/>}<br/><br/>func ImageSeriesToFloats(df dataframe.DataFrame, col string) [][]float64 {<br/>    s := df.Col(col)<br/>    ret := make([][]float64, s.Len(), s.Len())<br/>    for i := 0; i &lt; s.Len(); i++ {<br/>        b := []byte(s.Elem(i).String())<br/>        ret[i] = NormalizeBytes(b)<br/>    }<br/>    return ret<br/>}<br/><br/>trainingImages := ImageSeriesToFloats(training, "Image")<br/>validationImages := ImageSeriesToFloats(validation, "Image")</pre>
<p>After preparing the data properly, it is finally time to create a logistic classifier and train it:</p>
<pre>model := linear.NewLogistic(base.BatchGA, 1e-4, 1, 150, trainingImages, trainingIsTrouser.Float())<br/><br/>//Train<br/>err := model.Learn()<br/>if err != nil {<br/>  fmt.Println(err)<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Measuring performance</h1>
                </header>
            
            <article>
                
<p>Now that we have our trained model, we need to measure how well it is performing by comparing the predictions it makes on each image with the ground truth (whether or not the image is a pair of trousers). A simple way to do this is to measure <strong>accuracy</strong>.</p>
<div class="packt_infobox"><strong>Accuracy</strong> measures what proportion of the input data can be classified correctly by the algorithm, for example, 90%, if 90 out of 100 predictions from the algorithm are correct.</div>
<p>In our Go code example, we can test the model by looping over the validation dataset and counting how many images are classified correctly. This will output a model accuracy of 98.8%:</p>
<pre>//Count correct classifications<br/>var correct = 0.<br/>for i := range validationImages {<br/>  prediction, err := model.Predict(validationImages[i])<br/>  if err != nil {<br/>    panic(err)<br/>  }<br/><br/>  if math.Round(prediction[0]) == validationIsTrouser.Elem(i).Float() {<br/>    correct++<br/>  }<br/>}<br/><br/>//accuracy<br/>correct / float64(len(validationImages))</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Precision and recall</h1>
                </header>
            
            <article>
                
<p>Measuring accuracy can be very misleading. Suppose you are building a system to classify whether medical patients will test positive for a rare disease, and in the dataset only 0.1% of examples are in fact positive. A really bad algorithm might predict that nobody will test positive, and yet it has an accuracy of 99.9% simply because the disease is rare.</p>
<div class="packt_infobox">A dataset that has many more examples of one classification versus another is known as <strong>unbalanced</strong>. Unbalanced datasets need to be treated carefully when measuring algorithm performance.</div>
<p>A better way to measure performance starts by putting each prediction from the algorithm into one of the following four categories:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-384 image-border" src="assets/115c28b2-7254-4bea-b5c2-10cb3bdd4daa.png" style="width:29.83em;height:6.33em;"/></p>
<p>We can now define some new performance metrics:</p>
<ul>
<li class="CDPAlignLeft CDPAlign"><strong>Precision</strong> measures what fraction of the models true predictions are actually correct. In the following diagram, it is the true positives that are predicted from the model (the left-hand side of the circle) divided by all of the models positive predictions (everything in the circle).</li>
<li class="CDPAlignLeft CDPAlign"><strong>Recall</strong> measures how good the model is at identifying all the positive examples. In other words, the true positives (left-hand side of the circle) divided by all the datapoints that are actually positive (the entire left-hand side):</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-255 image-border" src="assets/5ff88538-985a-4a66-9574-ea896bd17ba2.png" style="width:27.58em;height:27.67em;"/></p>
<p>The preceding diagram shows datapoints that have been predicted as true by the model in the central circle. The points that are actually true are on the left half of the diagram.</p>
<div class="packt_tip"><strong>Precision</strong> and <strong>recall</strong> are more robust performance metrics when working with unbalanced datasets. Both range between 0 and 1, where 1 indicates perfect performance.</div>
<p>Following is the code for the total count of true positives and false negatives:</p>
<pre>//Count true positives and false negatives<br/>var truePositives = 0.<br/>var falsePositives = 0.<br/>var falseNegatives = 0.<br/>for i := range validationImages {<br/>  prediction, err := model.Predict(validationImages[i])<br/>  if err != nil {<br/>    panic(err)<br/>  }<br/>  if validationIsTrouser.Elem(i).Float() == 1 {<br/>    if math.Round(prediction[0]) == 0 {<br/>      // Predicted false, but actually true<br/>      falseNegatives++<br/>    } else {<br/>      // Predicted true, correctly<br/>      truePositives++<br/>    }<br/>  } else {<br/>    if math.Round(prediction[0]) == 1 {<br/>      // Predicted true, but actually false<br/>      falsePositives++<br/>    }<br/>  }<br/>}</pre>
<p><span><span>We can now calculate precision and recall with the following code:</span></span></p>
<pre>//precision<br/>truePositives / (truePositives + falsePositives)<br/>//recall<br/>truePositives / (truePositives + falseNegatives)</pre>
<p>For our linear model, we get 100% precision, meaning that there are no false positives, and a recall of 90.3%.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ROC curves</h1>
                </header>
            
            <article>
                
<p>Another way to measure performance involves looking at how the classifier works in more detail. Inside our model, two things happen:</p>
<ul>
<li>First, the model calculates a value between 0 and 1, indicating how likely it is that a given image should be classified as a pair of trousers.</li>
<li>A threshold is set, so that only images scoring more than the threshold get classified as trousers. Setting different thresholds can improve precision at the expense of recall and vice versa.</li>
</ul>
<p>If we look at the model output <em>across all the different thresholds from 0 to 1</em>, we can understand more about how useful it is. We do this using something called the <strong>receiver operating characteristic</strong> (<strong>ROC</strong>) curve, which is a plot of the true positive rate versus the false positive rate across the dataset for different threshold values. The following three examples show ROC curves for a bad, moderate, and very good classifier:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-385 image-border" src="assets/34189d2a-5b38-4024-8e0c-0eaa87b148d0.png" style="width:57.08em;height:18.25em;"/></div>
<p>By measuring the shaded area under these ROC curves, we get a simple metric of how good the model is, which is known as <strong>area under curve</strong> (<strong>AUC)</strong>. For the bad model, this is close to <strong>0.5</strong>, but for the very good model, it is close to <strong>1.0</strong>, indicating that the model can achieve <em>both</em> a high true positive rate and a low false positive rate.</p>
<p>The <kbd>gonum</kbd>/<kbd>stat</kbd> package provides a useful function for computing ROC curves, which we will use once we have extended the model to work with each of the different items of clothing in the dataset.</p>
<div class="packt_infobox">The <strong>receiver operating characteristic</strong>, or <strong>ROC curve</strong>, is a plot of true positive rate versus false positive rate for different threshold values. It allows us to visualize how good the model is at classification. The AUC gives a simple measure of how good the classifier is.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multi-class models</h1>
                </header>
            
            <article>
                
<p>Up until now, we have been using <strong>binary classification</strong>; that is, it should output <kbd>true</kbd> if the image shows a pair of trousers, and <kbd>false</kbd> otherwise. For some problems, such as detecting whether an email is important or not, this is all we need. But in this example, what we really want is a model that can identify all the different types of clothing in our dataset, that is, shirt, boot, dress, and so on.</p>
<p>With some algorithm implementations, you will need to start by applying one-hot encoding to the output, as demonstrated in <a href="532d8304-b31d-41ef-81c1-b13f4c692824.xhtml" target="_blank"/><a href="532d8304-b31d-41ef-81c1-b13f4c692824.xhtml" target="_blank">Chapter 2</a>, <em>Setting Up the Development Environment</em>. However, for our example, we will use <strong>softmax regression</strong> in <strong>goml/linear</strong>, which does this step automatically. We can train the model by simply feeding it with the input (pixel values) and the integer output (0, 1, 2, ... representing t-shirt, trouser, pullover, and so on): </p>
<pre>model2 := linear.NewSoftmax(base.BatchGA, 1e-4, 1, 10, 100, trainingImages, training.Col("Label").Float())<br/><br/>//Train<br/>err := model2.Learn()<br/>if err != nil {<br/>  fmt.Println(err)<br/>}</pre>
<p>When using this model for inference, it will output a vector of probabilities for each class; that is, it tells us what the probability that an input image is a t-shirt, trouser, and so on. This is exactly what we need for the ROC analysis, but, if we want a single prediction for each image, we can use the following func to find the class that has the <em>highest</em> probability:</p>
<pre>func MaxIndex(f []float64) (i int) {<br/>  var (<br/>    curr float64<br/>    ix int = -1<br/>  )<br/>  for i := range f {<br/>    if f[i] &gt; curr {<br/>      curr = f[i]<br/>      ix = i<br/>    }<br/>  }<br/>  return ix<br/>}</pre>
<p>Next, we can plot the ROC curve and the AUC for each individual class. The following code will loop over each example in the validation dataset and predict probabilities for each class using the new model:</p>
<pre>//create objects for ROC generation<br/>//as per https://godoc.org/github.com/gonum/stat#ROC<br/>y := make([][]float64, len(categories), len(categories))<br/>classes := make([][]bool, len(categories), len(categories))<br/>//Validate<br/>for i := 0; i &lt; validation.Col("Image").Len(); i++ {<br/>  prediction, err := model2.Predict(validationImages[i])<br/>  if err != nil {<br/>    panic(err)<br/>  }<br/>  for j := range categories {<br/>    y[j] = append(y[j], prediction[j])<br/>    classes[j] = append(classes[j], validation.Col("Label").Elem(i).Float() != float64(j))<br/>  }<br/>}<br/><br/>//Calculate ROC<br/>tprs := make([][]float64, len(categories), len(categories))<br/>fprs := make([][]float64, len(categories), len(categories))<br/><br/>for i := range categories {<br/>  stat.SortWeightedLabeled(y[i], classes[i], nil)<br/>  tprs[i], fprs[i] = stat.ROC(0, y[i], classes[i], nil)<br/>}<br/><br/></pre>
<p>We can now compute AUC values for each class, which shows that our model performs better on some classes than others:</p>
<pre>for i := range categories {<br/>  fmt.Println(categories[i])<br/>  auc := integrate.Trapezoidal(fprs[i], tprs[i])<br/>  fmt.Println(auc)<br/>}</pre>
<p><span>For trousers, the AUC value is <kbd>0.96</kbd>, showing that even a simple linear model works really well in this case. However, shirt and pullover both score close to <kbd>0.6</kbd>. This makes intuitive sense: shirts and pullovers look very similar, and are therefore much harder for the model to recognize correctly. We can see this more clearly by plotting the ROC curve for each class as separate lines: the model clearly performs the worst on shirts and pullovers, and the best on the clothes that have a very distinctive shape (boots, trousers, sandals, and so on).</span></p>
<p><span>The following code loads gonums plotting libraries, creates the ROC plot, and saves it as a JPEG image:</span></p>
<pre>import (<br/>  "gonum.org/v1/plot"<br/>  "gonum.org/v1/plot/plotter"<br/>  "gonum.org/v1/plot/plotutil"<br/>  "gonum.org/v1/plot/vg"<br/>  "bufio"<br/>)<br/><br/>func plotROCBytes(fprs, tprs [][]float64, labels []string) []byte {<br/>  p, err := plot.New()<br/>  if err != nil {<br/>    panic(err)<br/>  }<br/><br/>  p.Title.Text = "ROC Curves"<br/>  p.X.Label.Text = "False Positive Rate"<br/>  p.Y.Label.Text = "True Positive Rate"<br/><br/>  for i := range labels {<br/>    pts := make(plotter.XYs, len(fprs[i]))<br/>    for j := range fprs[i] {<br/>      pts[j].X = fprs[i][j]<br/>      pts[j].Y = tprs[i][j]<br/>    }<br/>    lines, points, err := plotter.NewLinePoints(pts)<br/>    if err != nil {<br/>      panic(err)<br/>    }<br/>    lines.Color = plotutil.Color(i)<br/>    lines.Width = 2<br/>    points.Shape = nil<br/><br/>    p.Add(lines, points)<br/>    p.Legend.Add(labels[i], lines, points)<br/>  }<br/><br/>  w, err := p.WriterTo(5*vg.Inch, 4*vg.Inch, "jpg")<br/>  if err != nil {<br/>    panic(err)<br/>  }<br/>  if err := p.Save(5*vg.Inch, 4*vg.Inch, "Multi-class ROC.jpg"); err != nil {<br/>    panic(err)<br/>  }<br/>  var b bytes.Buffer<br/>  writer := bufio.NewWriter(&amp;b)<br/>  w.WriteTo(writer)<br/>  return b.Bytes()<br/>}</pre>
<p>If we view the plot in Jupyter, we can see that the the worst classes follow the lines close to the diagonal, again indicating an AUC close to <kbd>0.5</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-436 image-border" src="assets/c384cecc-fbc7-4f0a-9daf-7377d5e36731.png" style="width:30.50em;height:24.58em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A non-linear model – the support vector machine</h1>
                </header>
            
            <article>
                
<p>To move forward, we need to use a different machine learning algorithm: one that is able to model more complex, non-linear relationships between the pixel inputs and the output classes. While some of<span><span> the mainstream Go machine learning libraries such as Golearn have support for basic algorithms like local least squares, there is not a single library that supports as broad a set of algorithms as Python's scikit-learn or R's standard library. For this reason, it is often necessary to search for alternative libraries that implement bindings to a widely used C library, or that contain a configurable implementation of an algorithm that is suited for a particular problem.</span></span> For this example, we are going to use an algorithm called the <strong>support vector machine</strong> (<strong>SVM</strong>).<strong> </strong>SVMs can be more difficult to use than linear models—they have more parameters to tune—but have the advantage of being able to model much more complex patterns in the data. </p>
<div class="packt_infobox">An SVM<strong> </strong>is a more advanced machine learning method that can be used both for classification and regression. They allow us to apply <strong>kernels</strong> to the input data, which means that they can model non-linear relationships between the inputs/outputs.</div>
<p>An important feature of SVM models is their ability to use a <strong>kernel function</strong>. Put simply, this means that the algorithm can apply a transformation to the input data so that non-linear patterns can be found. For our example, we will use the <strong>LIBSVM</strong> library to train an SVM on the image data. LIBSVM is an open source library with bindings for many different languages, meaning that it is also useful if you want to port a model that has been built in Python's popular scikit-learn library. First, we need to do some data preparation to make our input/output data suitable for feeding into the Go library:</p>
<pre>trainingOutputs := make([]float64, len(trainingImages))<br/>validationOutputs := make([]float64, len(validationImages))<br/><br/>ltCol:= training.Col("Label")<br/>for i := range trainingImages {<br/>    trainingOutputs[i] = ltCol.Elem(i).Float()<br/>}<br/><br/>lvCol:= validation.Col("Label")<br/>for i := range validationImages {<br/>    validationOutputs[i] = lvCol.Elem(i).Float()<br/>}<br/><br/>// FloatstoSVMNode converts a slice of float64 to SVMNode with sequential indices starting at 1<br/>func FloatsToSVMNode(f []float64) []libsvm.SVMNode {<br/>    ret := make([]libsvm.SVMNode, len(f), len(f))<br/>    for i := range f {<br/>        ret[i] = libsvm.SVMNode{<br/>            Index: i+1,<br/>            Value: f[i],<br/>        }<br/>    }<br/>    //End of Vector<br/>    ret = append(ret, libsvm.SVMNode{<br/>        Index: -1,<br/>        Value: 0,<br/>    })<br/>    return ret<br/>}</pre>
<p><span>Next, we can set up the SVM model and configure it with a <strong>radial basis function</strong> (<strong>RBF</strong>) <strong>kernel</strong>. RBF kernels are a common choice when using SVMs, but do take longer to train than linear models:</span></p>
<pre>var (<br/>  trainingProblem libsvm.SVMProblem<br/>  validationProblem libsvm.SVMProblem<br/>)<br/><br/>trainingProblem.L = len(trainingImages)<br/>validationProblem.L = len(validationImages)<br/>for i := range trainingImages {<br/>  trainingProblem.X = append(trainingProblem.X, FloatsToSVMNode(trainingImages[i]))<br/>}<br/>trainingProblem.Y = trainingOutputs<br/><br/>for i := range validationImages {<br/>  validationProblem.X = append(validationProblem.X, FloatsToSVMNode(validationImages[i]))<br/>}<br/>validationProblem.Y = validationOutputs<br/><br/>// configure SVM<br/>svm := libsvm.NewSvm()<br/>param := libsvm.SVMParameter{<br/>  SvmType: libsvm.CSVC,<br/>  KernelType: libsvm.RBF,<br/>  C: 100,<br/>  Gamma: 0.01,<br/>  Coef0: 0,<br/>  Degree: 3,<br/>  Eps: 0.001,<br/>  Probability: 1,<br/>}</pre>
<p class="mce-root"/>
<p><span>Finally, we can fit our model to the training data of 750 images, and then use <kbd>svm.SVMPredictProbability</kbd> to predict probabilities, like we did with the linear multi-class model:</span></p>
<pre>model := svm.SVMTrain(&amp;trainingProblem, &amp;param)</pre>
<p>As we did previously, we compute the AUC and ROC curves, which demonstrate that this model performs much better across the board, including the difficult classes, like shirt and pullover:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-438 image-border" src="assets/91329032-d01f-413b-8771-7773e3317475.png" style="width:32.83em;height:26.25em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overfitting and underfitting</h1>
                </header>
            
            <article>
                
<p class="mce-root">The SVM model is performing much better on our validation dataset than the linear model, but, in order to understand what to do next, we need to introduce two important concepts in machine learning: <strong>overfitting</strong> and <strong>underfitting</strong>. These both refer to problems that can occur when training a model.</p>
<div class="packt_infobox">If a model <strong>underfits</strong> the data, it is <em>too simple</em> to explain the patterns in the input data, and therefore performs poorly when evaluated against the training dataset and the validation dataset. Another term for this problem is that the model has <strong>high bias</strong>.<strong><br/>
<br/></strong> If a model <strong>overfits</strong> the data, it is <em>too complex</em>, and will not generalize well to new data points that were not included as part of training. This means that the model will perform well when evaluated against the training data, but poorly when evaluated against the validation dataset. <span>Another term for this problem is that the model has </span><strong>high variance</strong>.</div>
<p>An easy way to understand the difference between overfitting and underfitting is to look at the following simple example: when building a model, our aim is to build something that is just right for the dataset. The example on the left underfits because a straight line model can not accurately divide the circles and squares. The model on the right is too complex: it separates all the circles and squares correctly, but is unlikely to work well on new data:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-388 image-border" src="assets/6397e42b-9573-4cf2-b611-c61ad5259c07.png" style="width:57.08em;height:17.17em;"/></p>
<p>Our linear model suffered from underfitting: it was too simplistic to model the difference between all the classes. Looking at the accuracy of the SVM, we can see that it scores 100% on the training data, but only 82% on validation. This is a clear sign that it is overfitting: it is much worse at classifying new images compared with those on which it was trained.</p>
<div class="packt_tip">One way of dealing with overfitting is to use more training data: even a complex model will not be able to overfit if the training dataset is large enough. Another way to do this is to introduce regularization: many machine learning models have a parameter that you can adjust to reduce overfitting.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep learning</h1>
                </header>
            
            <article>
                
<p>So far, we have improved our model's performance using an SVM, but still face two problems:</p>
<ul>
<li>Our SVM is overfitting the training data.</li>
<li>It is also difficult to scale to the full dataset of 60,000 images: try training the last example with more images and you will find that it gets <em>much slower</em>. If we double the number of datapoints, the SVM algorithm takes <em>more than double</em> the amount of time.</li>
</ul>
<p>In this section, we are going to tackle this problem using a<span> </span><strong>deep neural network</strong>. These types of model have been able to achieve state-of-the-art performance on image classification tasks, as well many other machine learning problems. They are able to model complex non-linear patterns, and also scale well to large datasets.</p>
<p class="mce-root">Data scientists will often use Python to develop and train neural networks because it has access to extremely well-supported deep learning frameworks such as <strong>TensorFlow</strong> and <strong>Keras</strong>. These frameworks make it easier than ever to build complex neural networks and train them on large datasets. They are usually the best choice for building sophisticated deep learning models. In <a href="815e42bb-64e4-4f04-9dbd-c58af28f2580.xhtml" target="_blank">Chapter 5</a>, <em>Using Pre-Trained Models</em>, we will look at how to export a trained model from Python and then call it from Go for inference. In this section, we will build a much simpler neural network from scratch using the <kbd>go-deep</kbd><span> </span>library to demonstrate the key concepts.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural networks</h1>
                </header>
            
            <article>
                
<p>The basic building block of a neural network is a <strong>neuron</strong> (also known as a <strong>perceptron</strong>). This is actually just the same as our simple linear model: it combines all of its inputs, that is, <em>x<sub>1</sub>,x<sub>2</sub>,x<sub>3</sub>... </em>and so on into a single output, <em>y</em>, according to the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/02e2f192-2e94-4abe-8e73-bdabca624535.png" style="width:19.83em;height:1.33em;"/></p>
<p>The magic of neural networks comes from what happens when we combine these simple neurons:</p>
<ol>
<li>First, we create a <strong>layer</strong> of many neurons into which we feed the input data.</li>
<li>At the output of each neuron, we introduce an <strong>activation function</strong>.</li>
<li>The output of this <strong>input layer</strong> is then fed to another layer of neurons and activations, known as a <strong>hidden layer</strong>.</li>
<li>This gets repeated for multiple hidden layers—the more layers there are, the <strong>deeper</strong> the network is said to be.</li>
<li>A final <strong>output</strong> layer of neurons combines the result of the network into the final output.</li>
<li>Using a technique known as <strong>backpropagation</strong>, we can train the network by finding the weights, <em>w<sub><span>0</span></sub>,w<sub>1</sub>,w<sub>2</sub>...</em>, for each neural network that allows the whole network to fit the training data.</li>
</ol>
<p>The following diagram shows this layout: the arrows represent the output of each neuron, which are feeding into the input of the neurons in the next layer:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-137 image-border" src="assets/d68fe958-c58f-4f05-b0d9-e351c81c13da.png" style="width:37.25em;height:21.25em;"/></p>
<p>The neurons in this network are said to be arranged <strong>fully-connected</strong> or <strong>dense</strong> layers. Recent advances in both computing power and software have allowed researchers to build and train more complex neural network architectures than ever before. For instance, a state-of-the-art image recognition system might contain millions of individual weights, and require many days of computing time to train all of these parameters to fit a large dataset. They often contain different arrangements of neurons, for instance, in <strong>convolutional layers</strong>, which perform more specialized learning in these types of systems.</p>
<p>Much of the skill that is required to use deep learning successfully in practice involves a broad understanding of how to select and tune a network to get good performance. There are many blogs and online resources that provide more detail on how these networks work and the types of problems that they have been applied to.</p>
<div class="packt_infobox">A <strong>fully-connected</strong> layer in a neural network is one where the inputs of each neuron are connected to the outputs of all the neurons in the previous layer.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A simple deep learning model architecture</h1>
                </header>
            
            <article>
                
<p>Much of the skill in building a successful deep learning model involves choosing the correct model architecture: the number/size/type of layers, and the activation functions for each neuron. Before starting, it is worth researching to see if someone else has already tackled a similar problem to yours using deep learning and published an architecture that works well. As always, it is best to start with something simple and then modify the network iteratively to improve its performance. </p>
<p>For our example, we will start with the following architecture:</p>
<ul>
<li>An input layer</li>
<li>Two hidden layers containing 128 neurons each</li>
<li>An output layer of 10 neurons (one for each output class in the dataset)</li>
<li>Each neuron in the hidden layer will use a <strong>rectified linear unit</strong> (<strong>ReLU</strong>) as its output function</li>
</ul>
<div class="packt_tip">ReLUs are a common choice of activation function in neural networks. They are a very simple way to introduce non-linearity into a model. Other common activation functions include the <strong>logistic</strong> function and the <strong>tanh</strong> function.</div>
<p>The <kbd>go-deep</kbd> library lets us build this architecture very quickly:</p>
<pre>import (<br/> "github.com/patrikeh/go-deep"<br/> "github.com/patrikeh/go-deep/training"<br/>)<br/><br/>network := deep.NewNeural(&amp;deep.Config{<br/> // Input size: 784 in our case (number of pixels in each image)<br/> Inputs: len(trainingImages[0]),<br/> // Two hidden layers of 128 neurons each, and an output layer 10 neurons (one for each class)<br/> Layout: []int{128, 128, len(categories)},<br/> // ReLU activation to introduce some additional non-linearity<br/> Activation: deep.ActivationReLU,<br/> // We need a multi-class model<br/> Mode: deep.ModeMultiClass,<br/> // Initialise the weights of each neuron using normally distributed random numbers<br/> Weight: deep.NewNormal(0.5, 0.1),<br/> Bias: true,<br/>})</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural network training</h1>
                </header>
            
            <article>
                
<p>Training a neural network is another area in which you need to make skillful adjustments in order to get good results. The training algorithm works by calculating how well the model fits a small <strong>batch</strong> of training data (known as the <strong>loss</strong>), and then making small adjustments to the weights to improve the fit. This process then gets repeated over and over again on different batches of training data. The <strong>learning rate</strong> is an important parameter that controls how quickly the algorithm will adjust the neuron weights.</p>
<div class="packt_infobox">When training a neural network, the algorithm will feed all of the input data into the network repeatedly, and adjust the network weights as it goes. Each full pass through the data is known as an <strong>epoch</strong>. </div>
<div class="packt_tip">When training a neural network, monitor the <strong>accuracy</strong> and <strong>loss</strong> of the network after each epoch (accuracy should increase, while loss should decrease). If the accuracy is not improving, try lowering the learning rate. Keep training the network until accuracy stops improving: at this point, the network is said to have <strong>converged</strong>.</div>
<p>The following code trains our model using a learning rate of <kbd>0.006</kbd> for <kbd>500</kbd> iterations and prints out the accuracy after each epoch:</p>
<pre>// Parameters: learning rate, momentum, alpha decay, nesterov<br/>optimizer := training.NewSGD(0.006, 0.1, 1e-6, true)<br/>trainer := training.NewTrainer(optimizer, 1)<br/><br/>trainer.Train(network, trainingExamples, validationExamples, 500) <br/>// training, validation, iterations</pre>
<p>This neural network provides an accuracy of 80% on both the training and validation datasets, a good sign that the model is not overfitting. See if you can improve its performance by adjusting the network architecture and retraining. In <a href="815e42bb-64e4-4f04-9dbd-c58af28f2580.xhtml" target="_blank">Chapter 5</a>, <em>Using Pre-Trained Models</em>, we will revisit this example by building a more sophisticated neural network in Python and then exporting it to Go.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Regression</h1>
                </header>
            
            <article>
                
<p>Having mastered many of the key machine learning concepts in the <em>Classification</em> section, in this section, we will apply what we have learned to a regression problem. We will be using a dataset containing information about groups of houses in different locations in California<sup>[4]</sup>. Our goal will be to predict the median house price in each group using input data such as the latitude/longitude location, median house size, age, and so on.</p>
<p>Use the <kbd><span>download-housing.sh</span></kbd><span> </span>script to download the dataset and then load it into Go:</p>
<pre>import (<br/>    "fmt"<br/>    "github.com/kniren/gota/dataframe"<br/>    "github.com/kniren/gota/series"<br/>    "math/rand"<br/>    "image"<br/>    "bytes"<br/>    "math"<br/>    "github.com/gonum/stat"<br/>    "github.com/gonum/integrate"<br/>    "github.com/sajari/regression"<br/>    "io/ioutil"<br/>)<br/><br/>const path = "../datasets/housing/CaliforniaHousing/cal_housing.data"<br/><br/>columns := []string{"longitude", "latitude", "housingMedianAge", "totalRooms", "totalBedrooms", "population", "households", "medianIncome", "medianHouseValue"}<br/>b, err := ioutil.ReadFile(path)<br/>if err != nil {<br/>    fmt.Println("Error!", err)<br/>}<br/>df := dataframe.ReadCSV(bytes.NewReader(b), dataframe.Names(columns...))</pre>
<p>We need to carry out some data preparation to create columns in the dataframe that represent the average number of rooms and bedrooms for houses in each area, along with the average occupancy. We will also rescale the median house value into units of $100,000:</p>
<pre>// Divide divides two series and returns a series with the given name. The series must have the same length.<br/>func Divide(s1 series.Series, s2 series.Series, name string) series.Series {<br/>    if s1.Len() != s2.Len() {<br/>        panic("Series must have the same length!")<br/>    }<br/>    <br/>    ret := make([]interface{}, s1.Len(), s1.Len())<br/>    for i := 0; i &lt; s1.Len(); i ++ {<br/>        ret[i] = s1.Elem(i).Float()/s2.Elem(i).Float()<br/>    }<br/>    s := series.Floats(ret)<br/>    s.Name = name<br/>    return s<br/>}<br/><br/>// MultiplyConst multiplies the series by a constant and returns another series with the same name.<br/>func MultiplyConst(s series.Series, f float64) series.Series {<br/>    ret := make([]interface{}, s.Len(), s.Len())<br/>    for i := 0; i &lt; s.Len(); i ++ {<br/>        ret[i] = s.Elem(i).Float()*f<br/>    }<br/>    ss := series.Floats(ret)<br/>    ss.Name = s.Name<br/>    return ss<br/>}<br/><br/>df = df.Mutate(Divide(df.Col("totalRooms"), df.Col("households"), "averageRooms"))<br/>df = df.Mutate(Divide(df.Col("totalBedrooms"), df.Col("households"), "averageBedrooms"))<br/>df = df.Mutate(Divide(df.Col("population"), df.Col("households"), "averageOccupancy"))<br/>df = df.Mutate(MultiplyConst(df.Col("medianHouseValue"), 0.00001))<br/>df = df.Select([]string{"medianIncome", "housingMedianAge", "averageRooms", "averageBedrooms", "population", "averageOccupancy", "latitude", "longitude", "medianHouseValue" })</pre>
<p>Like we did previously, we need to split this data into training and validation sets:</p>
<pre>func Split(df dataframe.DataFrame, valFraction float64) (training dataframe.DataFrame, validation dataframe.DataFrame){<br/>    perm := rand.Perm(df.Nrow())<br/>    cutoff := int(valFraction*float64(len(perm)))<br/>    training = df.Subset(perm[:cutoff])<br/>    validation = df.Subset(perm[cutoff:])<br/>    return training, validation<br/>}<br/><br/>training, validation := Split(df, 0.75)<br/><br/>// DataFrameToXYs converts a dataframe with float64 columns to a slice of independent variable columns as floats<br/>// and the dependent variable (yCol). This can then be used with eg. goml's linear ML algorithms.<br/>// yCol is optional - if it does not exist only the x (independent) variables will be returned.<br/>func DataFrameToXYs(df dataframe.DataFrame, yCol string) ([][]float64, []float64){<br/>    var (<br/>        x [][]float64<br/>        y []float64<br/>        yColIx = -1<br/>    )<br/>    <br/>    //find dependent variable column index<br/>    for i, col := range df.Names() {<br/>        if col == yCol {<br/>            yColIx = i<br/>            break<br/>        }<br/>    }<br/>    if yColIx == -1 {<br/>        fmt.Println("Warning - no dependent variable")<br/>    }<br/>    x = make([][]float64, df.Nrow(), df.Nrow()) <br/>    y = make([]float64, df.Nrow())<br/>    for i := 0; i &lt; df.Nrow(); i++ {<br/>        var xx []float64<br/>        for j := 0; j &lt; df.Ncol(); j ++ {<br/>            if j == yColIx {<br/>                y[i] = df.Elem(i, j).Float()<br/>                continue<br/>            }<br/>            xx = append(xx, df.Elem(i,j).Float())<br/>        }<br/>        x[i] = xx <br/>    }<br/>    return x, y<br/>}<br/><br/>trainingX, trainingY := DataFrameToXYs(training, "medianHouseValue")<br/>validationX, validationY := DataFrameToXYs(validation, "medianHouseValue")</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Linear regression</h1>
                </header>
            
            <article>
                
<p>Like the classification example, we are going to start by using a linear model as a baseline. This time, though, we are predicting a <strong>continuous output variable</strong>, so we need a different performance metric. A common metric to use for regression is the <strong>mean squared error</strong> (<strong>MSE</strong>), that is, the sum of the squared differences between the model predictions and the true values. By using a <em>squared</em> error, we are making sure that the value increases for underestimates and overestimates are of the true value.</p>
<div class="packt_tip">A common alternative to MSE for regression problems is the <strong>mean absolute error</strong> (<strong>MAE</strong>). This can be useful when your input data contains outliers.</div>
<p>Using a Golang regression library, we can train the model as follows:</p>
<pre>model := new(regression.Regression)<br/><br/>for i := range trainingX {<br/>  model.Train(regression.DataPoint(trainingY[i], trainingX[i]))<br/>}<br/>if err := model.Run(); err != nil {<br/>  fmt.Println(err)<br/>}</pre>
<p>Finally, we can calculate the mean squared error from the validation set as <kbd>0.51</kbd>. This provides a benchmark level of performance that we can refer to when comparing other models:</p>
<pre>//On validation set<br/>errors := make([]float64, len(validationX), len(validationX))<br/>for i := range validationX {<br/>  prediction, err := model.Predict(validationX[i])<br/>  if err != nil {<br/>    panic(fmt.Println("Prediction error", err))<br/>  }<br/>  errors[i] = (prediction - validationY[i]) * (prediction - validationY[i])<br/>}<br/><br/>fmt.Printf("MSE: %5.2f\n", stat.Mean(errors, nil))</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random forest regression</h1>
                </header>
            
            <article>
                
<p>We know that house prices vary according to location, often in complicated ways that our linear model is unlikely to be able to capture. Therefore, we are going to introduce <strong>random forest regression</strong> as an alternative model.</p>
<div class="packt_infobox"><strong>Random forest regression</strong> is an example of an <strong>ensemble model</strong>: it works by training a large number of simple <strong>base models</strong> and then uses statistical averaging to output a final prediction. With random forests, the base models are decision trees, and, by adjusting the parameters of these trees and the number of models in the ensemble, you can control overfitting.</div>
<p>Using the <kbd>RF.go</kbd> library, we can train a random forest on the house price data. First, let's do some data preparation on the training and validation sets:</p>
<pre>func FloatsToInterfaces(f []float64) []interface{} {<br/>    iif := make([]interface{}, len(f), len(f))<br/>    for i := range f {<br/>        iif[i] = f[i]<br/>    }<br/>    return iif<br/>}<br/><br/>tx, trainingY := DataFrameToXYs(training, "medianHouseValue")<br/>vx, validationY := DataFrameToXYs(validation, "medianHouseValue")<br/><br/>var (<br/>    trainingX = make([][]interface{}, len(tx), len(tx))<br/>    validationX = make([][]interface{}, len(vx), len(vx))<br/>)<br/><br/>for i := range tx {<br/>    trainingX[i] = FloatsToInterfaces(tx[i])<br/>}<br/>for i := range vx {<br/>    validationX[i] = FloatsToInterfaces(vx[i])<br/>}</pre>
<p>Now, we can fit a random forest containing 25 underlying decision trees:</p>
<pre>model := Regression.BuildForest(trainingX, trainingY, 25, len(trainingX), 1)</pre>
<p>This gives a much improved MSE of <kbd>0.29</kbd> on the validation set, but shows signs of overfitting with an error of only <kbd>0.05</kbd> on the training data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Other regression models</h1>
                </header>
            
            <article>
                
<p>There are many other regression models you can try out on this dataset. In fact, the SVM and deep learning models that we used in the previous example can also be adapted for use on regression problems. See if you can improve on the performance of the random forest by using a different model. Remember that some of these models will require the data to be normalized so that they can be trained properly.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>We have covered a lot of ground in this chapter, and introduced many important machine learning concepts. The first step in tackling a supervised learning problem is to collect and preprocess the data, making sure that it is normalized, and split into training and validation sets. We covered a range of different algorithms for both classification and regression. In each example, there were two phases: training the algorithm, followed by inference; that is, using the trained model to make predictions from new input data. Whenever you try a new machine learning technique on your data, it is important to keep track of its performance against the training and validation datasets. This serves two main purposes: it helps you diagnose underfitting/overfitting and also provides an indication of how well your model is working. </p>
<p>It is usually best to choose the simplest model that provides good enough performance for the task that you are working on. Simple models are usually faster and easier to implement and use. In each example, we started with a simple linear model, and then evaluated more sophisticated techniques against this baseline.</p>
<p>There are many different implementations of machine learning models for Go that are available online. As we have done in this chapter, it is usually quicker to find and use an existing library rather than implementing an algorithm completely from scratch. Often, these libraries have slightly different requirements in terms of data preparation and tuning parameters, so be sure to read the documentation carefully in each case.</p>
<p>The next chapter will reuse many of the techniques for data loading and preparation that we have implemented here, but, instead, will focus on unsupervised machine learning.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further readings</h1>
                </header>
            
            <article>
                
<ol>
<li><a href="http://yann.lecun.com/exdb/lenet/">http://yann.lecun.com/exdb/lenet/</a>. Retrieved March 24, 2019.</li>
<li><a href="https://blogs.nvidia.com/blog/2016/05/06/self-driving-cars-3/">https://blogs.nvidia.com/blog/2016/05/06/self-driving-cars-3/</a>. Retrieved March 24, 2019.</li>
<li><a href="https://github.com/zalandoresearch/fashion-mnist">https://github.com/zalandoresearch/fashion-mnist</a>.<span> Retrieved March 24, 2019.</span></li>
<li><a href="http://colah.github.io/">http://colah.github.io/</a>. Retrieved May 15, 2019.</li>
<li><a href="https://karpathy.github.io/">https://karpathy.github.io/</a>. Retrieved May 15, 2019.</li>
<li><a href="http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html">http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html</a>. <span>Retrieved March 24,  2019.</span></li>
</ol>


            </article>

            
        </section>
    </body></html>