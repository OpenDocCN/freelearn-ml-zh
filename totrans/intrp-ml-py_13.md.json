["```py\nimport math\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport mldatasets\nimport numpy as np\nfrom sklearn import preprocessing\nimport tensorflow as tf\nfrom tensorflow.keras.utils import get_file\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\nfrom art.estimators.classification import KerasClassifier\nfrom art.attacks.evasion import FastGradientMethod,\\\n                      ProjectedGradientDescent, BasicIterativeMethod\nfrom art.attacks.evasion import CarliniLInfMethod\nfrom art.attacks.evasion import AdversarialPatchNumpy\nfrom art.defences.preprocessor import SpatialSmoothing\nfrom art.defences.trainer import AdversarialTrainer\nfrom tqdm.notebook import tqdm \n```", "```py\ntf.compat.v1.disable_eager_execution()\nprint('Eager execution enabled:', tf.executing_eagerly()) \n```", "```py\nX_train, X_test, y_train, y_test = mldatasets.load(\n    \"maskedface-net_thumbs_sampled\", prepare=True\n)\nX_train, X_test = X_train / 255.0, X_test / 255.0\nmin_ = X_train.min()\nmax_ = X_train.max() \n```", "```py\nprint('X_train dim:\\t%s' % (X_train.**shape**,))\nprint('X_test dim:\\t%s' % (X_test.**shape**,))\nprint('y_train dim:\\t%s' % (y_train.**shape**,))\nprint('y_test dim:\\t%s' % (y_test.**shape**,))\nprint('X_train min:\\t%s' % (**min_**))\nprint('X_train max:\\t%s' % (**max_**))\nprint('y_train labels:\\t%s' % (np.**unique**(y_train))) \nthat they are not one-hot encoded. Indeed, by printing the unique values (np.unique(y_train)), we can tell that labels are represented as text: Correct for correctly masked, Incorrect for incorrectly masked, and None for no mask:\n```", "```py\nX_train dim:    (16800, 128, 128, 3)\nX_test dim: (4200, 128, 128, 3)\ny_train dim:    (16800, 1)\ny_test dim: (4200, 1)\nX_train min:    0.0\nX_train max:    1.0\ny_train labels: ['Correct' 'Incorrect' 'None'] \n```", "```py\nohe = preprocessing.**OneHotEncoder**(sparse=False)\nohe.**fit**(y_train)\nlabels_l = ohe.**categories_**[0].tolist()\nprint(labels_l) \n```", "```py\nrand = 9\nos.environ['PYTHONHASHSEED'] = str(rand)\ntf.random.set_seed(rand)\nnp.random.seed(rand) \n```", "```py\nsampl_md_idxs = np.random.choice(X_test.shape[0], 200, replace=False)\nX_test_mdsample = X_test[sampl_md_idxs]\ny_test_mdsample = y_test[sampl_md_idxs]\nsampl_sm_idxs = np.random.choice(X_test.shape[0], 20, replace=False)\nX_test_smsample = X_test[sampl_sm_idxs]\ny_test_smsample = y_test[sampl_sm_idxs] \n```", "```py\nplt.subplots(figsize=(15,12))\nfor s in range(20):\n    plt.subplot(4, 5, s+1)\n    plt.title(y_test_smsample[s][0], fontsize=12)\n    plt.imshow(X_test_smsample[s], interpolation='spline16')\n    plt.axis('off')\nplt.show() \n```", "```py\nmodel_path = **get_file**('CNN_Base_MaskedFace_Net.hdf5',\\\n    'https://github.com/PacktPublishing/Interpretable-Machine- \\\n    Learning-with-Python/blob/master/models/ \\\n    CNN_Base_MaskedFace_Net.hdf5?raw=true')\nbase_model = tf.keras.models.**load_model**(model_path)\nbase_model.**summary**() \n```", "```py\nModel: \"CNN_Base_MaskedFaceNet_Model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 126, 126, 16)      448       _________________________________________________________________\nmaxpool2d_1 (MaxPooling2D)   (None, 63, 63, 16)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 61, 61, 32)        4640      \n_________________________________________________________________\nmaxpool2d_2 (MaxPooling2D)   (None, 30, 30, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n_________________________________________________________________\nmaxpool2d_3 (MaxPooling2D)   (None, 14, 14, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n_________________________________________________________________\nmaxpool2d_4 (MaxPooling2D)   (None, 6, 6, 128)         0         \n_________________________________________________________________\nflatten_6 (Flatten)          (None, 4608)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 768)               3539712   \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 768)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 2307      \n=================================================================\nTotal params: 3,639,459\nTrainable params: 3,639,459\nNon-trainable params: 0\n_________________________________________________________________ \n```", "```py\ny_test_pred, y_test_prob = mldatasets.**evaluate_multiclass_mdl**(\n    base_model,\n    X_test,\n    y_test,\n    labels_l,\n    ohe,\n    plot_conf_matrix=True,\n    predopts={\"verbose\":1}\n) \n```", "```py\nbase_classifier = **KerasClassifier**(\n    model=base_model, clip_values=(min_, max_)\n)\ny_test_mdsample_prob = np.**max**(\n    y_test_prob[sampl_md_idxs], axis=1\n)\ny_test_smsample_prob = np.**max**(\n    y_test_prob[sampl_sm_idxs], axis=1\n) \n```", "```py\nattack_fgsm = **FastGradientMethod**(base_classifier, eps=0.1) \n```", "```py\nX_test_fgsm = attack_fgsm.**generate**(X_test_mdsample) \n```", "```py\ny_test_fgsm_pred, y_test_fgsm_prob =\\\n    mldatasets.**evaluate_multiclass_mdl**(\\\n        base_classifier.model, X_test_fgsm, y_test_mdsample,\\\n        labels_l, ohe, plot_conf_matrix=False, plot_roc=False\n    )\ny_test_fgsm_prob = np.**max**(y_test_fgsm_prob, axis=1)\nmldatasets.**compare_image_predictions**(\n    X_test_fgsm, X_test_mdsample, y_test_fgsm_pred,\\\n    y_test_mdsample.flatten(), y_test_fgsm_prob,\\\n    y_test_mdsample_prob, title_mod_prefix=\"Attacked:\",\\\n    title_difference_prefix=\"FSGM Attack Average Perturbation:\",\\\n    num_samples=4\n) \n```", "```py\nattack_cw = **CarliniLInfMethod**(\n    base_classifier, batch_size=40\n)\nX_test_cw = attack_cw.**generate**(X_test_mdsample) \n```", "```py\ny_test_cw_pred, y_test_cw_prob =\\\n    mldatasets.**evaluate_multiclass_mdl**(\n        base_classifier.model, X_test_cw, y_test_mdsample, labels_l,\\\n        ohe, plot_conf_matrix=False, plot_roc=False\n    )\ny_test_cw_prob = np.**max**(y_test_cw_prob, axis=1)\nmldatasets.**compare_image_predictions**(\n    X_test_cw,\\\n    X_test_mdsample, y_test_cw_pred,\\\n    y_test_mdsample.flatten(), y_test_cw_prob,\\\n    y_test_mdsample_prob, title_mod_prefix=\"Attacked:\",\\\n    title_difference_prefix=\"C&W Inf Attack Average Perturbation\",\\\n    num_samples=4\n) \n```", "```py\nattack_ap = **AdversarialPatchNumpy**(\n    base_classifier, scale_min=0.4, scale_max=0.7,\\\n    learning_rate=5., max_iter=500,\\\n    batch_size=40, target=0\n) \n```", "```py\nplacement_mask = np.**zeros**((128,128))\nplacement_mask[**80****:****93****,****45****:****83**] = 1\nplacement_mask = np.**expand_dims**(placement_mask, axis=0).astype(bool)\npatch, patch_mask = attack_ap.**generate**(\n    x=X_test_smsample,\n    y=ohe.transform(y_test_smsample),\n    mask=placement_mask\n) \n```", "```py\nplt.**imshow**(patch * patch_mask) \n```", "```py\nX_test_ap = attack_ap.**apply_patch**(\n    X_test_smsample,\n    scale=0.55,\n    mask=placement_mask\n) \n```", "```py\ny_test_ap_pred, y_test_ap_prob =\\\n    mldatasets.evaluate_multiclass_mdl(\n        base_classifier.model, X_test_ap, y_test_smsample,\n        labels_l, ohe, plot_conf_matrix=False, plot_roc=False\n    )\ny_test_ap_prob = np.max(y_test_ap_prob, axis=1)\nmldatasets.compare_image_predictions(\n    X_test_ap, X_test_smsample, y_test_ap_pred,\\\n    y_test_smsample.flatten(), y_test_ap_prob,\n    y_test_smsample_prob, title_mod_prefix=\"Attacked:\",\\\n    title_difference_prefix=\"AP Attack Average Perturbation:\", num_samples=4\n) \n```", "```py\n**not_masked_idxs** = np.**where**(y_test_smsample != 'Correct')[0]\nX_test_notmasked = X_test_smsample[**not_masked_idxs**]\ny_test_notmasked = y_test_smsample[**not_masked_idxs**]\ny_test_notmasked_prob = y_test_smsample_prob[**not_masked_idxs**]\ny_test_masked = np.array(\n    ['Correct'] * X_test_notmasked.shape[0]\n).reshape(-1,1) \n```", "```py\nattack_pgd = **ProjectedGradientDescent**(\n    base_classifier, eps=0.3, eps_step=0.01,\\\n    max_iter=40, targeted=True\n)\nX_test_pgd = attack_pgd.**generate**(\n    X_test_notmasked, y=ohe.transform(y_test_masked)\n) \n```", "```py\ny_test_pgd_pred, y_test_pgd_prob =\\\n    mldatasets.**evaluate_multiclass_mdl**(\n        base_classifier.model, X_test_pgd, y_test_notmasked,\\\n        labels_l, ohe, plot_conf_matrix=True, plot_roc=False\n    )\ny_test_pgd_prob = np.**max**(y_test_pgd_prob, axis=1) \nFigure 13.9. The PGD attack was so effective that it produced an accuracy of 0%, making all unmasked and incorrectly masked examples appear to be masked:\n```", "```py\nmldatasets.**compare_image_predictions**(\n    X_test_pgd, X_test_notmasked, y_test_pgd_pred,\\\n    y_test_notmasked.flatten(), y_test_pgd_prob,\\\n    y_test_smsample_prob, title_mod_prefix=\"Attacked:\",\\\n    num_samples=4, title_difference_prefix=\"PGD Attack Average Perturbation:\"\n) \n```", "```py\ndefence_ss = **SpatialSmoothing**(window_size=11)\nX_test_pgd_ss, _ = **defence_ss**(X_test_pgd) \n```", "```py\ny_test_pgd_ss_pred, y_test_pgd_ss_prob =\\\n    mldatasets.**evaluate_multiclass_mdl**(\n        base_classifier.model, X_test_pgd_ss,\\\n        y_test_notmasked, labels_l, ohe,\\\n        plot_conf_matrix=False, plot_roc=False\n)\ny_test_pgd_ss_prob = np.**max**(y_test_pgd_ss_prob, axis=1)\nmldatasets.**compare_image_predictions**(\n    X_test_pgd_ss, X_test_notmasked, y_test_pgd_ss_pred,\\\n    y_test_notmasked.flatten(), y_test_pgd_ss_prob,\\\n    y_test_notmasked_prob, use_misclass=False,\\\n    title_mod_prefix=\"Attacked+Defended:\", num_samples=4,\\\n    title_difference_prefix=\"PGD Attack & Defended Average:\"\n) \n```", "```py\nrobust_model = tf.keras.models.**Sequential**([\n    tf.keras.layers.**InputLayer**(input_shape=X_train.shape[1:]),\n    tf.keras.layers.**Conv2D**(32, kernel_size=(3, 3), activation='relu'),\n    tf.keras.layers.**MaxPooling2D**(pool_size=(2, 2)),\n    tf.keras.layers.**Conv2D**(32, kernel_size=(3, 3), activation='relu'),\n    tf.keras.layers.**MaxPooling2D**(pool_size=(2, 2)),\n    tf.keras.layers.**Conv2D**(32, kernel_size=(3, 3), activation='relu'),\n    tf.keras.layers.**MaxPooling2D**(pool_size=(2, 2)),\n    tf.keras.layers.**Conv2D**(32, kernel_size=(3, 3), activation='relu'),\n    tf.keras.layers.**MaxPooling2D**(pool_size=(2, 2)),\n    tf.keras.layers.**Flatten**(),\n    tf.keras.layers.**Dense**(3072, activation='relu'),\n    tf.keras.layers.**Dropout**(0.2),\n    tf.keras.layers.**Dense**(3, activation='softmax')\n], name='CNN_Robust_MaskedFaceNet_Model')\nrobust_model.**compile**(\n    optimizer=tf.keras.optimizers.Adam(lr=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\nrobust_model.**summary**() \n```", "```py\nModel: \"CNN_Robust_MaskedFaceNet_Model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n_________________________________________________________________\nmaxpool2d_1 (MaxPooling2D)   (None, 63, 63, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 61, 61, 32)        9248      \n_________________________________________________________________\nmaxpool2d_2 (MaxPooling2D)   (None, 30, 30, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 28, 28, 32)        9248      \n_________________________________________________________________\nmaxpool2d_3 (MaxPooling2D)   (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 12, 12, 32)        9248      \n_________________________________________________________________\nmaxpool2d_4 (MaxPooling2D)   (None, 6, 6, 32)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1152)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 3072)              3542016   \n_________________________________________________________________\ndropout (Dropout)            (None, 3072)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 9219      \n=================================================================\nTotal params: 3,579,875\nTrainable params: 3,579,875\nNon-trainable params: 0\n_________________________________________________________________ \n```", "```py\nrobust_classifier = **KerasClassifier**(\n    model=robust_model, clip_values=(min_, max_)\n)\nattacks = **BasicIterativeMethod**(\n    robust_classifier, eps=0.3, eps_step=0.01, max_iter=20\n)\ntrainer = **AdversarialTrainer**(\n    robust_classifier, attacks, ratio=0.5\n)\ntrainer.fit(\n    X_train, ohe.transform(y_train), nb_epochs=30, batch_size=128\n) \n```", "```py\nmodel_path = **get_file**(\n    'CNN_Robust_MaskedFace_Net.hdf5',\n    'https://github.com/PacktPublishing/Interpretable-Machine- \\\n    Learning-with-Python/blob/master/models/ \\\n    CNN_Robust_MaskedFace_Net.hdf5?raw=true'\n)\nrobust_model = tf.keras.models.**load_model**(model_path)\nrobust_classifier = **KerasClassifier**(\n    model=robust_model, clip_values=(min_, max_)\n) \n```", "```py\ny_test_robust_pred, y_test_robust_prob =\\\nmldatasets.**evaluate_multiclass_mdl**(\n    robust_classifier.model, X_test, y_test, labels_l, ohe,\\\n    plot_conf_matrix=True, predopts={\"verbose\":1}\n) \n```", "```py\nattack_fgsm_robust = **FastGradientMethod**(\n    robust_classifier, eps=0.1\n)\nX_test_fgsm_robust = attack_fgsm_robust.**generate**(X_test_mdsample) \n```", "```py\ny_test_fgsm_robust_pred, y_test_fgsm_robust_prob =\\\n    mldatasets.**evaluate_multiclass_mdl**(\n        robust_classifier.model, X_test_fgsm_robust,\\\n        y_test_mdsample, labels_l, ohe,\\\n        plot_conf_matrix=False, plot_roc=False\n    )\ny_test_fgsm_robust_prob = np.**max**(\n    y_test_fgsm_robust_prob, axis=1\n)\nmldatasets.**compare_image_predictions**(\n    X_test_fgsm_robust, X_test_mdsample,\n    y_test_fgsm_robust_pred, num_samples=4,\\\n    y_test_mdsample.flatten(), y_test_fgsm_robust_prob,\\\n    y_test_mdsample_prob, title_mod_prefix=\"Attacked:\",\\\n    title_difference_prefix=\"FSGM Attack Average Perturbation:\"\n) \nbase_classifier, it yielded a 44% accuracy. That was quite an improvement! The preceding code also produces the image grid in *Figure 13.13*. You can tell how the FSGM attack against the robust model makes less grainy and more patchy images. On average, they are less perturbed than they were against the base model because so few of them were successful, but those that were significantly degraded. It appears as if the FSGM reduced their color depth from millions of possible colors (24+ bits) to 256 (8-bit) or 16 (4-bit) colors. Of course, an evasion attack can’t actually do that, but what happened was that the FSGM algorithm converged at the same shades of blue, brown, red, and orange that could fool the classifier! Other shades remain unaltered: \n```", "```py\naccuracy_base_0 = metrics.accuracy_score(\n    y_test, y_test_pred\n)\naccuracy_robust_0 = metrics.accuracy_score(\n    y_test, y_test_robust_pred\n) \n```", "```py\neps_range = np.**concatenate**(\n    (np.linspace(0.01, 0.09, 9), np.linspace(0.1, 0.9, 9)), axis=0\n).tolist()\naccuracy_base = [accuracy_base_0]\naccuracy_robust = [accuracy_robust_0]\nfor **eps** in tqdm(eps_range, desc='EPS'):\n    attack_fgsm.set_params(**{'eps': **eps**})\n    X_test_fgsm_base_i =attack_fgsm.**generate**(X_test_mdsample)\n    _, accuracy_base_i =\\\n    base_classifier.model.**evaluate**(\n        X_test_fgsm_base_i, ohe.transform(y_test_mdsample)\n    )\n    attack_fgsm_robust.set_params(**{'eps': **eps**})\n    X_test_fgsm_robust_i=attack_fgsm_robust.**generate**(\n        X_test_mdsample\n    )\n    _, accuracy_robust_i =\\\n        robust_classifier.model.**evaluate**(\n            X_test_fgsm_robust_i, ohe.transform(y_test_mdsample)\n            )\n    accuracy_base.append(accuracy_base_i)\n    accuracy_robust.append(accuracy_robust_i) \neps_range = [0] + eps_range \n```", "```py\nfig, ax = plt.subplots(figsize=(14,7))\nax.plot(\n    np.array(eps_range), np.array(accuracy_base),\\\n    'b–', label='Base classifier'\n)\nax.plot(\n    np.array(eps_range), np.array(accuracy_robust),\\\n    'r–', label='Robust classifier'\n)\nlegend = ax.legend(loc='upper center')\nplt.xlabel('Attack strength (eps)')\nplt.ylabel('Accuracy') \n```"]