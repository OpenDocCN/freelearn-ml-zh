- en: '2'
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Text Documents Using NLP
  prefs: []
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Use Amazon Comprehend to examine text, in order to determine its primary language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extract information such as entities (people or places), key phrases (noun phrases
    that are indicative of the content), emotional sentiments, and topics in a set
    of documents
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up a Lambda function to process and analyze the imported text using Comprehend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter describes the use of Amazon Comprehend to summarize the text documents
    and creating Lambda function to analyze the text.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Amazon Comprehend service continually learns from new data from Amazon.com
    product descriptions and consumer reviews, and thus, it perpetually improves its
    ability to understand a variety of topics from *Government*, *Health*, *Media*,
    *Education*, *Advertising*, and so on. Overall, Amazon Comprehend can analyze
    a collection of text documents and can organize the articles by topic, identify
    the most frequently mentioned features, and group articles by subject matter,
    to enable personalized recommendations to website visitors.
  prefs: []
  type: TYPE_NORMAL
- en: In the first part of this chapter, you learned how to use Amazon Comprehend
    to extract insights through using **Natural Language Processing (NLP)** from the
    contents of documents. Now, you will learn how to use the Amazon Comprehend API
    to produce insights by recognizing the language, entities, key phrases, sentiments,
    and topics in a document. This will allow you to understand deep learning-based
    NLP to build more complex applications, which we will do on Day 2\.
  prefs: []
  type: TYPE_NORMAL
- en: In the second part of this chapter, you will learn about AWS Lambda, and how
    to integrate this service with Amazon Comprehend. You will also integrate a database
    to provide the foundation to build scalable NLP processing applications.
  prefs: []
  type: TYPE_NORMAL
- en: What is Natural Language Processing?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon Comprehend is a Natural Language Processing (NLP) service. The overall
    goal of an NLP service is to make machines understand our spoken and written language.
    Virtual Assistants, such as Alexa or Siri, use NLP to produce insights from input
    data. The input data is structured by a language, which has a unique grammar,
    syntax, and vocabulary. Thus, processing text data requires identifying the language
    first, to apply subsequent rules to identify the document's information. NLP's
    general task is to capture this information as a numeral representation. The general
    task is further specified into specific tasks, such as identifying languages,
    entities, key phrases, emotional sentiments, and topics.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Comprehend processes any text file in UTF-8 format. It uses a pre-trained
    model to examine a document or set of documents, in order to gather insights about
    the document set. Amazon continuously trains the model so that there is no need
    to provide training data.
  prefs: []
  type: TYPE_NORMAL
- en: Using Amazon Comprehend to Inspect Text and Determine the Primary Language
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Amazon Comprehend is used to gather insights from a variety of topics (Health,
    Media, Telecom, Education, Government, and so on) and languages in text data.
    Thus, the first step to analyze text data and utilize more complex features (such
    as topic, entity, and sentiment analysis) is to determine the dominant language.
    Determining the dominant language ensures the accuracy of more in-depth analysis.
  prefs: []
  type: TYPE_NORMAL
- en: To examine the text in order to determine the primary language, there are two
    operations (`DetectDominantLanguage` and `BatchDetectDominantLanguage`).
  prefs: []
  type: TYPE_NORMAL
- en: '`DetectDominantLanguage` accepts a `UTF-8` text string that is at least 20
    characters in length and must contain fewer than 5,000 bytes of UTF-8 encoded
    characters. `BatchDetectDominantLanguage` accepts an array of strings as a list.
    The list can contain a maximum of 25 documents. Each document should have at least
    20 characters, and must contain fewer than 5,000 bytes of UTF-8 encoded characters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The response includes what language was identified using a two-letter code.
    The following table shows the language codes for different countries:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Check out https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html
    for an updated list of supported languages.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: Amazon Comprehend – supported languages'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0011.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.1: Amazon Comprehend supported languages'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The reaction also includes a score that indicates the certainty level that
    Amazon Comprehend has that a specific language is the dominant language in the
    document (see the following screenshot). The language scores are independent of
    other scores, and so reaction does not provide the percentage of the document
    that is represented by a particular language:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2: Dominant language score confidence output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.2: Dominant language score confidence output'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 5: Detecting the Dominant Language Using the Command-Line Interface
    in a text document'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, you will learn how to detect Comprehend''s using `detectDominantLanguage`
    function. The following steps describe how to detect the dominant language:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The source code is available via GitHub in the repository at: https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_a/detect_dominant_languages.py.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must import the AWS SDK for Python (boto3) http://boto3.readthedocs.io/en/latest/:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, import the JSON module to serialize the JSON https://docs.python.org/3.6/library/json.html
    :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace <`input region`> with your unique region (for example, `us-east-1`).
    The following instantiates a new Comprehend client:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we assign English and Spanish strings to be analyzed by Comprehend:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we print a string to indicate the respective variable that our script
    is about to execute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Lastly, call Comprehend''s `detect_dominant_language` method with the `engligh_string`
    and `spanish_string` variables https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html
    . `json.dumps()` writes the JSON data to a Python string in the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Save the changes to the file. Open a command prompt, if you haven't already,
    and activate your virtual environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Navigate to the `detect_dominant_languages.py` location. Type `python detect_dominant_languages.py`
    in the command prompt. Executing this command will produce the following output
    (see the following screenshot):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As expected, the `english_text` string is identified as English (with the "`en`"
    language code) with a ~0.99 confidence score (see the following output).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Also as expected, the `spanish_text` string is identified Spanish (with the
    "`es`" language code) with a ~0.99 confidence score (see the following output):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.3: Detecting the dominant language output – English and Spanish'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0031.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.3: Detecting the dominant language output – English and Spanish'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 6: Detecting the Dominant Language in Multiple Documents by Using
    the Command-Line Interface (CLI)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, you will learn how to detect Comprehend''s `detectDominantLanguage`
    operation for multiple documents. The following steps describe how to detect the
    dominant language:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The source code is available via GitHub in the repository at: https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_a/batch_detect_dominant_languages.py.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the AWS SDK for Python (boto3) http://boto3.readthedocs.io/en/latest/:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we import the JSON module to serialize the JSON https://docs.python.org/3.6/library/json.html
    :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace <`input region`> with your unique region (for example, ''us-east-1'').
    The following instantiates a new Comprehend client:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, assign a list of English and Spanish strings to be analyzed by Comprehend:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`english_string_list` = [''Machine Learning is fascinating.'', ''Studying Artificial
    Intelligence is my passion.'']'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`spanish_string_list` = [''El aprendizaje automático es fascinante.'', ''Estudiar
    Inteligencia Artificial es mi pasión.'']'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Lastly, we call Comprehend''s "`batch_detect_dominant_language`" method with
    the `engligh_string_list` and `spanish_string_list` variables https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html.
    Then, `json.dumps()` writes the JSON data to a Python string to the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The important concepts to remember are that Comprehend has the ability to detect
    different languages and can take text input as a single string or in batch format
    as
  prefs: []
  type: TYPE_NORMAL
- en: a list of strings.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we reviewed how Comprehend's `DetectDominantLanguage` method
    is structured, and how to pass in both strings and a list of strings. Next, we
    will extract entities, phrases, and sentiments from a set of documents.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting Information in a Set of Documents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At a business level, knowing if and why a customer is angry or happy when they
    text a Virtual assistant is extremely important, in order to retain the customer.
    At an NLP level, this requires more information to extract and a more complex
    algorithm. The additional information to extract, and quantify are `entities`,
    `key phrases`, `emotional sentiment`, and `topics`.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting Named Entities – AWS SDK for Python (boto3)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An entity is a textual reference to the unique name of a real-world object,
    such as people, places, commercial items, and precise references to measurements
    such as dates and quantities. For example, in the text "Martin lives at 27 Broadway
    St.", **Martin** might be detected as a **PERSON**, while **27 Broadway St** might
    be detected as a **LOCATION**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Entities also have a score to indicate the confidence level that the entity
    type was detected correctly. The following table shows a complete list of entity
    types and descriptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4: AWS Comprehend - entity types and descriptions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image004.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.4: AWS Comprehend entity types and descriptions'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: DetectEntites – Input and Output
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'DetectEntites takes a `LanguageCode` and string of text as an input, and then
    provides the following information about each entity within the input text: `BeginOffset`,
    `EndOffset`, `Score`, `Text`, and `Type`. The following table shows a complete
    list of AWS Comprehend DetectEntities, types, and descriptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5: AWS Comprehend - entity types and descriptions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0051.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.5: AWS Comprehend entity types and descriptions'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 7: Determining the Named Entities in a Document'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will determine the named entities in a document. For this,
    we will use Amazon Comprehend''s `DetectEntities` operation. The following are
    the steps for detecting the Named Entities:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The source code is available via GitHub in the repository at: https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_b/detect_entities.py.'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the `detect_entities.py` location, replace <`input region`> with
    your specific region, and save the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, import the AWS SDK for python (boto3) https://boto3.amazonaws.com/v1/documentation/api/latest/index.html
    by using the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, import the `JSON` module to serialize `JSON` from https://docs.python.org/3.6/library/json.html
    by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, instantiate a new Comprehend client:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, after instantiating a new Comprehend, provide `english_string = "I study
    Machine Learning in Seattle on Thursday.":`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, `json.dumps()` writes JSON data to a Python string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the code by executing the `detect_entities.py` command with `python`. The
    output of the preceding code is shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.6: AWS Comprehend – DetectEntities output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.6: AWS Comprehend DetectEntities output'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The confidence scores were both ~0.99, as the inputs were simple examples.
    As expected, **Seattle** was detected as a **LOCATION**, and **Thursday** was
    detected as the **DATE**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7: AWS Comprehend - BeginOffset and EndOffset review'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0071.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.7: AWS Comprehend BeginOffset and EndOffset review'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: DetectEntities in a Set of Documents (Text Files)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We are now going to extract entities from a set of documents (text files).
    Navigate to the https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_b/detect_entities_from_documents.py
    location, replace ''<`input region`>'' with your specific region, and save the
    file. Run the code by executing the command with `python detect_key_phrases.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8: detectKeyPhrases output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.8: DetectKeyPhrases output'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Detecting Key Phrases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A key phrase for AWS is analogous to a noun phrase, which represents an actual
    thing. In English when we put together different words that represent one concrete
    idea we call it a noun phrase. For example, "**A fast machine**" is a noun phrase
    because it consists of "**A**", the article, "**fast**", an adjective, and "**machine**"
    which is a noun. AWS looks for appropriate word combinations and gives scores
    that indicates the confidence that a string is actually a noun phrase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8: Determining the Key Phrase Detection.'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will determine the key phrase detection. To do so we will
    use Amazon Comprehend''s `DetectKeyPhrase` operation. The following are the steps
    for detecting the Named Entities:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The source code is available via GitHub in the repository at: https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_b/detect_key_phrases.py.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the `detect_key_phrases.py` location, replace `<input region>`
    with your specific region, and save the file. Import the AWS SDK for python (boto3)
    http://boto3.readthedocs.io/en/latest/ by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, import the JSON module to serialize the JSON from https://docs.python.org/3.6/library/json.html
    by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, instantiate a new Comprehend client by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, provide **English** text to analyze, using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the code by executing the command with `python detect_key_phrases.py`.
    You will see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.9: AWS Comprehend – DetectKeyPhrases output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0081.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.9: AWS Comprehend DetectKeyPhrases output'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Detecting Sentiments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Comprehend can be used to determine the sentiment of a document. You
    can determine whether the sentiment is positive, negative, neutral, or mixed.
    For example, you can use sentiment analysis to determine the sentiments of comments
    on a blog post, to determine whether your readers liked the post.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 9: Detecting Sentiment Analysis'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, We will determine the sentiment analysis. To do so, we will
    use Amazon Comprehend''s `DetectSentiment` operation. The following are the steps
    for detecting Sentiment Analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The source code is available via Github in the repository at: https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_b/detect_sentiment.py.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the `detect_sentiment.py` location, replace ''<`input region`>''
    with your specific region, and save the file. Import the `AWS SDK` for Python
    (boto3) from http://boto3.readthedocs.io/en/latest/ by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, import the `JSON` module to serialize JSON from https://docs.python.org/3.6/library/json.html
    by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, instantiate a new comprehend client, using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, provide a text string to analyze, using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the code by executing the command with: `python detect_seniment.py`. The
    output is shown as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.10: AWS Comprehend – DetectSentiment output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0091.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.10: AWS Comprehend – DetectSentiment output'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Setting up a Lambda function and Analyzing Imported Text Using Comprehend
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this topic, we will be integrating AWS Lambda functions to Comprehend, which
    provides a more powerful, scalable infrastructure. You can use AWS Lambda to run
    your code in response to events, such as changes to data in an Amazon S3 Bucket.
  prefs: []
  type: TYPE_NORMAL
- en: Executing code in response to events provides a real-world solution for developing
    scalable software architecture. Overall, this increases our data pipeline and
    provides the ability to handle more complex Big Data volumes and NLP operations.
  prefs: []
  type: TYPE_NORMAL
- en: What is AWS Lambda?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'AWS Lambda is a compute service that runs code without provisioning or managing
    servers. AWS Lambda executes the code only when needed, and scales automatically.
    AWS Lambda runs your code on high availability compute infrastructure, which performs
    the administration of the compute service. More specifically, AWS Lambda performs
    the following: server and operating system maintenance, capacity provisioning
    and automatic scaling, code monitoring, and logging.'
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the goal of a Lambda is to make short, simple, modular code segments
    that you can tie together into a larger processing infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: What does AWS Lambda do?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lambda allows users to run small segments of code (Java, Node, or Python) to
    complete a specific task. These specific tasks can be storing and then executing
    changes to your AWS setup, or responding to events in S3 (we will explore the
    latter later on in this topic). Before Lambda, you would typically need a separate
    EC2 server to run your entire code; however, Lambda allows small segments of the
    code to run without the need for EC2.
  prefs: []
  type: TYPE_NORMAL
- en: Lambda Function Anatomy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AWS Lambda provides two options for implementing Python code. First, you can
    upload a complete Python code file. Second, you can use the Lambda function editor
    entirely in-line, which means that you can enter and modify the code directly,
    without having to upload any files to AWS. The code that you enter will be executed
    when the Lambda function is invoked. The second option will allow for easier testing,
    so we will use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s examine the structure of the Lambda function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'When you create a function (for example, `s3_trigger`), AWS creates a folder
    named the same, with a Python file named `Lambda_function.py` within the `Lambda_handler`
    function, which is the entry point of our Lambda function. The entry point takes
    two parameters as arguments:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The event argument provides the value of the payload, which is sent to the function
    from the `calling` process. It typically takes the form of a Python `dict` type,
    although it could also be one of list, `str`, `int`, `float`, or `NoneType`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The context argument is of the type **LambdaContext** and contains runtime information.
    You will be using this parameter for an exercise in a later section. The return
    value of the function can be any type that is JSON serializable. This value gets
    returned to the calling application, after serializing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will incorporate Lambda, S3, and Amazon Comprehend, in order to automatically
    perform document analysis when a text document is uploaded to S3\. The architecture
    of a Lambda function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 2.11: Architecture diagram'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image010.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.11: Architecture diagram'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 10: Setting up a Lambda function for S3'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will integrate the following AWS services: S3, Lambda,
    and Amazon Comprehend. For performing this exercise, the architecture should be
    recollected. Upload a file (`test_s3trigger_configured.txt`) to S3 and view the
    results from Comprehend''s analysis. The following are the steps for setting up
    a Lambda function.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating the S3 Bucket**'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, navigate to the Amazon S3 service, https://console.aws.amazon.com/s3/,
    and click on **Create bucket**:![Figure 2.12: S3 Bucket creation for the Lambda
    trigger'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0111.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.12: S3 Bucket creation for the Lambda trigger'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'For the Bucket name, type `aws-ml-s3-trigger`, and then clickon **Create**:![Figure
    2.13: Creating an S3 Bucket'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image012.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.13: Creating an S3 Bucket'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Your `Bucket` will be created, and you will be redirected to the **Bucket list**:![Figure
    2.14: S3 Bucket list screen'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0131.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.14: S3 Bucket list screen'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Next, navigate to https://console.aws.amazon.com/Lambda/ and click on **Create
    a function**:![Figure 2.15: AWS Lambda home screen.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image014.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.15: AWS Lambda home screen.'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Choose Author from scratch from the options. For Name, `type s3_trigger`:![Figure
    2.16: AWS Lambda – Creating a function with the “author from scratch” selection'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0151.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.16: AWS Lambda – Creating a function with the "author from scratch"
    selection'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'For the runtime options, choose `Python 3.6` from the list:![Figure 2.17: AWS
    Lambda – Python 3.6 selection'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image016.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.17: AWS Lambda – Python 3.6 selection'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'For the Role field, choose `s3TriggerRole` in the Role name field. Then, click
    on the `Lambda function` in AWS:![Figure 2.18: AWS Lambda – Create function screen'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0171.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.18: AWS Lambda – Create function screen'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Then, click on the drop-down menu under **Policy templates**:![Figure 2.19:
    Policy template selection dropdown'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image018.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.19: Policy template selection drop-down menu'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Select **Amazon S3** object read-only permissions:![Figure 2.20: Amazon S3
    object read-only permissions selection'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0191.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.20: Amazon S3 object read-only permissions selection'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Then, click on the `Lambda function`:![Figure 2.21: Clicking on Create function'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image020.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.21: Clicking on Create function'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: If you receive a `NoSuchEntity` error, this is a temporary warning that occurs
    when Amazon creates the service role for the `s3_trigger`. AWS has a reference
    to the possible temporary issues under the Roles heading. This will not affect
    your ability to continue with the chapter. Refresh your screen, and in a few minutes
    the warning message should disappear.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You will know that the issues have been resolved when the `Logs` service becomes
    available as a resource for the function''s role:![Figure 2.22: Amazon CloudWatch
    Logs'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0211.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.22: Amazon CloudWatch Logs'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You should see a configuration screen, as follows:![Figure 2.23: AWS Lambda
    - Successful s3_trigger created verification screen'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image022.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.23: AWS Lambda successful s3_trigger verification screen'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, let''s add S3 as a trigger. Under **Add triggers**, scroll to S3:![Figure
    2.24: AWS Lambda – Adding S3 as a trigger selection screen'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0231.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.24: AWS Lambda – Adding S3 as a trigger selection screen'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Click `S3,` and it will auto-populate under the `s3_trigger`. After clicking
    `S3`, your screen will look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.25: Aws Lambda – S3 trigger selection, configuration required'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image024.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.25: AWS Lambda – S3 trigger selection, configuration required'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 11: Configuring the Trigger for an S3 Bucket'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will configure the trigger for the `Bucket` created in
    the preceding exercise. To configure the trigger, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scroll down the screen to the configure triggers section from `aws-ml-s3-trigger`.:![Figure
    2.26: AWS Lambda – Configuring S3 trigger, S3 Bucket selection'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0251.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.26: AWS Lambda – Configuring S3 trigger, S3 Bucket selection'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Leave the remaining default settings. Next, scroll down the screen and click on **Add**:![Figure
    2.27: AWS Lambda – Adding the S3 Bucket as a trigger'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0271.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.27: AWS Lambda – Adding the S3 Bucket as a trigger'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: The next step is to click on the **Save** button:![AWS Lambda – Saving the S3
    trigger
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0272.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: AWS Lambda – Saving the S3 trigger
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Next, scroll down the screen to the **Function code** section. The default
    code will be the same as or similar to, the following:![Figure 2.28: AWS Lambda
    – the default Lambda_function screen'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image028.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.28: AWS Lambda The default Lambda_function screen'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, we can enter and edit our code entirely within the Lambda function screen
    (as long as the Code entry type is set to Edit code inline, which is the default
    value in the drop-down menu).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: For this step, you may either follow along and type in the code, or obtain it
    from the source code folder at https://github.com/TrainingByPackt/Machine-Learning-with-AWS/blob/master/lesson2/topic_c/s3_trigger.py
    file.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'First, we import the **AWS SDK** for Python (boto3) http://boto3.readthedocs.io/en/latest/:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create a function that takes two parameters-event and context:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create the s3 client object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Add an `if` event to check whether an event occurs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, replace `<input Bucket name>` with the Bucket you created (`aws-ml-s3-trigger`,
    in my example):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, access the event `Records` first index to obtain the text file object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, assign the text `filename` to a variable, and print the filename:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create the file object by getting the Bucket and key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign the text to the `body_str_obj` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace <`input region name`> with your specific region. In addition, create
    the comprehend variable (us-east-1, in my example):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next three lines of code call the respective comprehend functions to detect
    the sentiment, entities, and key phrases from the text document. Then, the output
    is printed to the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final statement returns the string ''Hello from Lambda'', like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, click on the **Save** button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.29: AWS Lambda – Save screen'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0291.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.29: AWS Lambda – Save screen'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: From this exercise, the `s3_trigger` function has access to S3, but not Amazon
    Comprehend. We need to attach a policy to the `s3_trigger` function to allow it
    to access Amazon Comprehend to execute the text analysis functions (`detect_sentiment`,
    `detect_entities`, and `detect_key_phrases`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12: Assigning Policies to S3_trigger to Access Comprehend'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will attach the policies to the `S3_trigger` function,
    in order to allow it to access comprehend. The steps for completion for assigning
    the policies are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to the Identity and Access Management dashboard at https://console.aws.amazon.com/iam:![Figure
    2.30: IAM dashboard](img/image030.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 2.30: IAM dashboard'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, once you get to the IAM dashboard, click on **Roles**:![Figure 2.31: Left-hand
    side of the IAM dashboard'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0311.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.31: Left-hand side of the IAM dashboard'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, the screen will be populated with the Role list. Click on `s3TriggerRole`
    in the Role list:![Figure 2.32: Role list – selecting s3TriggerRole'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image032.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.32: Role list Selecting s3TriggerRole'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The option of `s3TriggerRole` will be enabled. Then, click on **Attach policies**:![Figure
    2.33: Permissions tab for s3TriggerRole'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0331.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.33: Permissions tab for s3TriggerRole'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Type `Comprehend` to filter the policies. Then, click the checkbox next to
    `ComprehendFullAccess`:![Figure 2.34: ComprehendFullAccess policy selection'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image034.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.34: ComprehendFullAccess policy selection'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Once you have selected the checkbox, click on **Attach policy** (located in
    the lower right-hand side of the screen):![Figure 2.35: Attaching the selected
    policies'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0351.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 2.35: Attaching the selected policies'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You will be redirected to the `s3TriggerRole` screen, and you will receive
    the following message:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.36: Successfully attached polices message'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image036.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2.36: Successfully attached polices message'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 3: Integrating Lambda with Amazon Comprehend to Perform Text Analysis'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this activity, we will integrate the Lambda function with Comprehend to perform
    text analysis (`detect_sentiment`, `detect_entities`, and `detect_key_phrases`)
    when a document is uploaded to S3.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that you are an entrepreneur creating a chatbot. You have identified
    a business topic and the corresponding text documents, with content that will
    allow the chatbot to make your business successful. Your next step is to integrate
    the Lambda function with Comprehend, for sentiment, key phrases, and entities.
    To ensure that this happens correctly, you will need to have `test_s3trigger_configured.txt`.
    Before you execute the `s3_trigger`, consider the output, based on the following
    aspects of the text: sentiment (positive, negative, or neutral), entities (quantity,
    person, place, and so on), and key phrases:'
  prefs: []
  type: TYPE_NORMAL
- en: First, navigate to the `S3_trigger` Lambda function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add `test_s3trigger_configured.txt` to the S3 Bucket, in order to verify the
    Lambda `S3_trigger` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, upload the file into the Bucket and monitor the file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, click on View logs in the `CloudWatch` by using the log stream.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, expand the output in a text format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following will be the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Sentiment_response` -> Classified as 60.0% likely to be a Positive'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`Sentiment_response:`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '`entity_response` --> Classified as 70.5% likely to be a Quantity'
  prefs: []
  type: TYPE_NORMAL
- en: '`entity_response:`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '`key_phases_response` -> Classified as 89.9% likely "a test file" and 98.5%
    likely ''the s3 trigger" are the key phrases:'
  prefs: []
  type: TYPE_NORMAL
- en: '`key_phases_response:`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To refer to the detailed steps, go to the *Appendix A* at the end of this book
    on Page no.198
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you learned how Comprehend's `DetectDominantLanguage` method
    is structured, and how to pass in both strings and a list of strings. You learned
    how to extract entities, sentiments, key phrases, and topics, which provide the
    data for complex NLP processing. This allows Amazon Comprehend to become more
    efficient, by automating text analysis upon a text document that's been uploaded
    to S3.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the culmination of these independent functions provides the foundation
    for building complex machine learning-based NLP applications (for example, Siri,
    Alexa, and so on). Knowing how and why the individual functions operate will allow
    you to build your own AWS-based NLP applications.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore Topic Modeling and perform theme extraction.
  prefs: []
  type: TYPE_NORMAL
