- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Data Processing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理
- en: 'One of the essential things in **machine learning** (**ML**) is the data that
    we use for training. We can gather training data from the processes we work with,
    or we can take already prepared training data from third-party sources. In any
    case, we have to store training data in a file format that should satisfy our
    development requirements. These requirements depend on the task we solve, as well
    as the data-gathering process. Sometimes, we need to transform data stored in
    one format to another to satisfy our needs. Examples of such needs are as follows:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在**机器学习**（**ML**）中，我们用于训练的数据是至关重要的。我们可以从我们所工作的流程中收集训练数据，或者我们可以从第三方来源获取已经准备好的训练数据。无论如何，我们必须将训练数据存储在满足我们开发要求的文件格式中。这些要求取决于我们解决的问题以及数据收集过程。有时，我们需要将存储在一个格式中的数据转换为另一个格式以满足我们的需求。以下是一些这样的需求的例子：
- en: Increasing human readability to ease communication with engineers
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高人类可读性，以便与工程师进行沟通
- en: The existence of compression possibility to allow data to occupy less space
    on secondary storage
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在压缩可能性，以便数据在辅助存储上占用更少的空间
- en: The use of data in the binary form to speed up the parsing process
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用二进制形式的数据来加速解析过程
- en: Supporting complex relations between different parts of data to make precise
    mirroring of a specific domain
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持数据不同部分之间的复杂关系，以便精确地映射特定领域
- en: Platform independence to be able to use the dataset in different development
    and production environments
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平台独立性，以便能够在不同的开发和生产环境中使用数据集
- en: Today, there exists a variety of file formats that are used for storing different
    kinds of information. Some of these are very specific, and some of them are general-purpose.
    There are software libraries that allow us to manipulate these file formats. There
    is rarely a need to develop a new format and parser from scratch. Using existing
    software for reading a format can significantly reduce development and testing
    time, which allows us to focus on particular tasks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，存在各种用于存储不同类型信息的文件格式。其中一些非常特定，而另一些则是通用目的的。有一些软件库允许我们操作这些文件格式。很少需要从头开始开发新的格式和解析器。使用现有的软件来读取格式可以显著减少开发和测试时间，这使我们能够专注于特定的任务。
- en: This chapter discusses how to process popular file formats that we use for storing
    data. It shows what libraries exist for working with `OpenCV` and `Dlib` libraries
    and how to convert the data format used in these libraries to data types used
    in linear algebra libraries. It also describes data normalization techniques such
    as feature scaling and standardization procedures to deal with heterogeneous data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了如何处理我们用于存储数据的流行文件格式。它展示了用于处理 `OpenCV` 和 `Dlib` 库的库，以及如何将这些库中使用的数据格式转换为线性代数库中使用的数据类型。它还描述了数据归一化技术，如特征缩放和标准化过程，以处理异构数据。
- en: 'This chapter will cover the following topics:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Parsing data formats to C++ data structures
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据格式解析为 C++ 数据结构
- en: Initializing matrix and tensor objects from C++ data structures
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 C++ 数据结构初始化矩阵和张量对象
- en: Manipulating images with the `OpenCV` and `Dlib` libraries
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `OpenCV` 和 `Dlib` 库操作图像
- en: Transforming images into matrix and tensor objects of various libraries
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像转换为各种库的矩阵和张量对象
- en: Normalizing data
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据归一化
- en: Technical requirements
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The required technologies and installations for this chapter are as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章所需的技术和安装如下：
- en: Modern C++ compiler with C++17/C++20 support
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 C++17/C++20 的现代 C++ 编译器
- en: CMake build system version >= 3.22
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CMake 构建系统版本 >= 3.22
- en: '`Dlib` library installation'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Dlib` 库安装'
- en: '`mlpack` library installation'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlpack` 库安装'
- en: '`Flashlight` library installation'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Flashlight` 库安装'
- en: '`Eigen` library installation'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Eigen` 库安装'
- en: '`hdf5lib` library installation'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hdf5lib` 库安装'
- en: '`HighFive` library installation'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HighFive` 库安装'
- en: '`nlohmann-json` library installation'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nlohmann-json` 库安装'
- en: '`Fast-CPP-CSV-Parser` library installation'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Fast-CPP-CSV-Parser` 库安装'
- en: 'The code for this chapter can be found at the following GitHub repo: [https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition](https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下 GitHub 仓库中找到：[https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition](https://github.com/PacktPublishing/Hands-on-Machine-learning-with-C-Second-Edition)
- en: Parsing data formats to C++ data structures
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据格式解析为 C++ 数据结构
- en: 'The most popular format for representing structured data is called **CSV**.
    This format is just a text file with a two-dimensional table in it whereby values
    in a row are separated with commas, and rows are placed on every new line. It
    looks like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 表示结构化数据最流行的格式被称为 **CSV**。这种格式只是一个包含二维表的文本文件，其中行中的值用逗号分隔，而行则放在每一行的开头。它看起来像这样：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The advantages of this file format are that it has a straightforward structure,
    many software tools can process it, it is human-readable, and it is supported
    on a variety of computer platforms. Disadvantages are a lack of support for multidimensional
    data and data with complex structuring, as well as slow parsing speed in comparison
    with binary formats.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这种文件格式的优点在于其结构简单，许多软件工具可以处理它，它是可读的，并且支持多种计算机平台。缺点是它不支持多维数据以及结构复杂的数据，并且与二进制格式相比，解析速度较慢。
- en: 'Another widely used format is **JSON**. Although the format contains JavaScript
    in its abbreviation, we can use it with almost all programming languages. This
    is a file format with name-value pairs and arrays of such pairs. It has rules
    on how to group such pairs into distinct objects and array declarations, and there
    are rules on how to define values of different types. The following code sample
    shows a file in JSON format:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种广泛使用的格式是 **JSON**。尽管该格式的缩写中包含 JavaScript，但我们几乎可以用所有编程语言使用它。这是一个具有名称-值对的文件格式，以及此类对的数组。它有关于如何将此类对分组为不同的对象和数组声明的规则，以及如何定义不同类型值的规则。以下代码示例展示了
    JSON 格式的文件：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The advantages of this format are human readability, software support on many
    computer platforms, and the possibility to store hierarchical and nested data
    structures. Disadvantages are its slow parsing speed in comparison with binary
    formats and the fact it is not very useful for representing numerical matrices.
    In terms of character reading, binary formats offer more direct access to the
    underlying data structure, allowing for faster and more precise character extraction.
    With text formats, additional steps may be required to convert the characters
    into their numerical representations, potentially introducing additional processing
    overhead.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这种格式的优点在于人眼可读性、许多计算机平台上的软件支持，以及存储分层和嵌套数据结构的可能性。缺点是，与二进制格式相比，其解析速度较慢，并且对于表示数值矩阵来说并不十分有用。在字符读取方面，二进制格式提供了对底层数据结构的直接访问，允许更快、更精确地提取字符。使用文本格式时，可能需要额外的步骤将字符转换为它们的数值表示，这可能会引入额外的处理开销。
- en: Often, we use a combination of file formats to represent a complex dataset.
    For example, we can describe object relations with JSON, and data/numerical data
    in the binary form can be stored in a folder structure on the filesystem with
    references to it in JSON files.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们会使用多种文件格式的组合来表示复杂的数据集。例如，我们可以用 JSON 描述对象关系，而二进制形式的数据/数值数据可以存储在文件系统上的文件夹结构中，并在
    JSON 文件中引用它。
- en: '**HDF5** is a specialized file format for storing scientific data. This file
    format was developed to store heterogeneous multidimensional data with a complex
    structure. It provides fast access to single elements because it has optimized
    data structures for using secondary storage. Furthermore, HDF5 supports data compression.
    In general, this file format consists of named groups that contain multidimensional
    arrays of multitype data. Each element of this file format can contain metadata,
    as illustrated in the following diagram:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**HDF5** 是一种专门用于存储科学数据的文件格式。这种文件格式是为了存储具有复杂结构的异构多维数据而开发的。因为它具有优化数据结构以使用辅助存储，所以它能够快速访问单个元素。此外，HDF5
    支持数据压缩。一般来说，这种文件格式由包含多类型多维数组的命名组组成。该文件格式的每个元素都可以包含元数据，如下面的图所示：'
- en: '![Figure 2.1 – HDF5 format structure](img/B19849_02_1.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – HDF5 格式结构](img/B19849_02_1.jpg)'
- en: Figure 2.1 – HDF5 format structure
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – HDF5 格式结构
- en: The advantages of this format are its high read-and-write speed, fast access
    to distinct elements, and its ability to support data with a complex structure
    and various types of data. Disadvantages are the requirement of specialized tools
    for editing and viewing by users, the limited support of type conversions among
    different platforms, and using a single file for the whole dataset. The last issue
    makes data restoration almost impossible in the event of file corruption. So,
    it makes sense to regularly back up your data to prevent data loss in case of
    hardware failure or accidental deletion.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这种格式的优点是其读写速度快，快速访问不同元素，以及支持复杂结构和多种类型的数据。缺点是用户需要专用工具进行编辑和查看，不同平台之间类型转换的支持有限，以及整个数据集使用单个文件。最后一个问题使得在文件损坏的情况下数据恢复几乎不可能。因此，定期备份数据以防止硬件故障或意外删除导致的数据丢失是有意义的。
- en: There are a lot of other formats for representing datasets for ML, but we found
    the ones mentioned to be the most useful.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习中的数据集表示，有许多其他格式，但我们发现提到的这些格式最有用。
- en: Reading CSV files with the Fast-CPP-CSV-Parser library
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Fast-CPP-CSV-Parser库读取CSV文件
- en: Consider how to deal with CSV format in C++. There are many different libraries
    for parsing CSV format with C++. They have different sets of functions and different
    ways to integrate them into applications. The easiest way to use C++ libraries
    is to use header-only libraries because this eliminates the need to build and
    link them. We propose to use the `Fast-CPP-CSV-Parser` library because it is a
    small single-file header-only library with the minimal required functionality,
    which can be easily integrated into a development code base. It also provides
    a fast and efficient way to read and write CSV data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑如何在C++中处理CSV格式。有多个不同的库可以用于解析CSV格式，它们有不同的函数集和集成到应用程序中的不同方式。使用C++库最简单的方法是使用仅包含头文件的库，因为这消除了构建和链接它们的需要。我们建议使用`Fast-CPP-CSV-Parser`库，因为它是一个小型单文件头文件库，具有所需的最小功能，可以轻松集成到开发代码库中。它还提供了一种快速高效地读取和写入CSV数据的方法。
- en: 'As an example of a CSV file format, we use the `Iris` dataset, which describes
    three different types of iris plants (*Iris setosa*, *Iris versicolor*, and *Iris
    virginica*) and was conceived by R.A. Fisher. Each row in the file contains the
    following fields: sepal length, sepal width, petal length, petal width, and a
    string with a class name. This dataset is used for examples of how to classify
    an unknown iris flower based on these four features.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作为CSV文件格式的示例，我们使用`Iris`数据集，它描述了三种不同的鸢尾花植物（*Iris setosa*、*Iris versicolor*和*Iris
    virginica*），由R.A. Fisher构想。文件中的每一行包含以下字段：花瓣长度、花瓣宽度、花萼长度、花萼宽度，以及一个带有类名的字符串。这个数据集用于展示如何根据这四个特征对未知鸢尾花进行分类的示例。
- en: Note
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The reference to the Iris dataset is the following: *Dua, D.* and *Graff, C.*
    (*2019*). *UCI Machine Learning Repository* [[https://archive.ics.uci.edu/static/public/53/iris.zip](https://archive.ics.uci.edu/static/public/53/iris.zip)].
    *Irvine, CA: University of California, School of Information and* *Computer Science*.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 'Iris数据集的引用如下：*Dua, D.* 和 *Graff, C.* (*2019*)。*UCI Machine Learning Repository*
    [[https://archive.ics.uci.edu/static/public/53/iris.zip](https://archive.ics.uci.edu/static/public/53/iris.zip)]。*Irvine,
    CA: University of California, School of Information and* *Computer Science*。'
- en: 'To read this dataset with the `Fast-CPP-CSV-Parser` library, we need to include
    a single header file, as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`Fast-CPP-CSV-Parser`库读取此数据集，我们需要包含一个单独的头文件，如下所示：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, we define an object of the type `io::CSVReader`. We must define the number
    of columns as a template parameter. This parameter is one of the library limitations
    because we need to be aware of the CSV file structure. The code for this is illustrated
    in the following snippet:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义一个`io::CSVReader`类型的对象。我们必须将列数定义为模板参数。这个参数是库的限制之一，因为我们需要了解CSV文件的结构。下面的代码片段展示了这一点：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we define containers for storing the values we read, as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义用于存储读取值的容器，如下所示：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, to make our code more generic and gather all information about column
    types in one place, we introduce the following helper types and functions. We
    define a tuple object that describes values for a row, like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了使我们的代码更通用，并将所有关于列类型的信息集中在一个地方，我们引入以下辅助类型和函数。我们定义了一个元组对象，用于描述一行中的值，如下所示：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The reason for using a tuple is that we can easily iterate it with metaprogramming
    techniques. Then, we define two helper functions. One is for reading a row from
    a file, and it uses the `read_row()` method of the `io::CSVReader` class. The
    `read_row()` method takes a variable number of parameters of different types.
    Our `RowType` type describes these values. We do automatic parameter filling by
    using the `std::index_sequence` type with the `std::get` function, as illustrated
    in the following code snippet:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用元组的原因是我们可以用元编程技术轻松迭代它。然后，我们定义两个辅助函数。一个是用于从文件中读取一行，它使用`io::CSVReader`类的`read_row()`方法。`read_row()`方法接受不同类型的不同数量的参数。我们的`RowType`类型描述了这些值。我们通过使用`std::index_sequence`类型和`std::get`函数来实现自动参数填充，如下面的代码片段所示：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The second helper function uses a similar technique for transforming a row
    tuple object to our value vectors, as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个辅助函数使用类似的技术将行元组对象转换为我们的值向量，如下所示：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, we can put all the parts together. We define a loop where we continuously
    read row values and move them to our containers. After we read a row, we check
    the return value of the `read_row()` method, which tells us if the read was successful
    or not. A `false` return value means that we have reached the end of the file.
    In the case of a parsing error, we catch an exception from the `io::error` namespace.
    There are exception types for different parsing failures. In the following example,
    we handle number parsing errors:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将所有部分组合在一起。我们定义一个循环，其中我们连续读取行值并将它们移动到我们的容器中。读取一行后，我们检查`read_row()`方法的返回值，它告诉我们读取是否成功。一个`false`的返回值意味着我们已经到达了文件的末尾。在解析错误的情况下，我们捕获来自`io::error`命名空间的异常。有不同解析失败类型的异常。在以下示例中，我们处理数字解析错误：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Also, notice that we moved only four values to our vector of doubles because
    the last column contains string objects that we put into another vector of categorical
    values.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，我们只将四个值移动到我们的双精度浮点数向量中，因为最后一列包含字符串对象，我们将它们放入另一个分类值向量中。
- en: 'In this code sample, we saw how to parse the particular dataset with string
    and numerical values into two containers: `std::vector<std::string> categorical_column`
    and `std::vector<double> values`.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码示例中，我们看到了如何将包含字符串和数值的特殊数据集解析到两个容器中：`std::vector<std::string> categorical_column`
    和 `std::vector<double> values`。
- en: Preprocessing CSV files
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理CSV文件
- en: Sometimes, the data we have comes in a format that’s incompatible with the libraries
    we want to use. For example, the Iris dataset file contains a column that contains
    strings. Many ML libraries cannot read such values because they assume that CSV
    files contain only numerical values that can be directly loaded into an internal
    matrix representation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们拥有的数据格式与我们要使用的库不兼容。例如，Iris数据集文件包含一个包含字符串的列。许多机器学习库无法读取这样的值，因为它们假设CSV文件只包含可以直接加载到内部矩阵表示的数值。
- en: 'So, before using such datasets, we need to preprocess them. In the case of
    the Iris dataset, we need to replace the `categorical` column containing string
    labels with numeric encoding. In the following code sample, we replace strings
    with distinct numbers, but in general, such an approach is a bad idea, especially
    for classification tasks. ML algorithms usually learn only numerical relations,
    so a more suitable approach would be to use specialized encoding—for example,
    one-hot encoding. One-hot encoding is a method used in ML to represent categorical
    data as numerical values. It involves creating a binary vector for each unique
    value in the categorical feature, where only one element in the vector is set
    to `1` and all others are set to `0`. The code can be seen in the following block:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在使用此类数据集之前，我们需要对它们进行预处理。在Iris数据集的情况下，我们需要将包含字符串标签的`categorical`列替换为数值编码。在下面的代码示例中，我们用不同的数字替换字符串，但一般来说，这种方法不是一个好主意，尤其是在分类任务中。机器学习算法通常只学习数值关系，因此一个更合适的方法是使用专门的编码——例如，独热编码。独热编码是机器学习中用来表示分类数据为数值的方法。它涉及为分类特征中的每个唯一值创建一个二进制向量，其中向量中只有一个元素设置为`1`，其余都设置为`0`。代码可以在下面的代码块中看到：
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We read the CSV file content to the `std::string` object with the `std::ifstream`
    object. Also, we use `std::regex` routines to replace string class names with
    numbers. Using `regex` functions allows us to reduce code size and make it more
    expressive in comparison with the loop approach, which typically uses the `std::string::find()`
    and `std::string::replace()` methods. After replacing all categorical class names
    in the file, we create a new file with the `std::ofstream` object.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`std::ifstream`对象将CSV文件内容读取到`std::string`对象中。此外，我们使用`std::regex`例程将字符串类名替换为数字。使用`regex`函数可以减少代码量，并使其与通常使用`std::string::find()`和`std::string::replace()`方法的循环方法相比更具表达性。在替换文件中的所有分类类名后，我们使用`std::ofstream`对象创建一个新的文件。
- en: Reading CSV files with the mlpack library
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用mlpack库读取CSV文件
- en: Many ML frameworks already have routines for reading the CSV file format to
    their internal representations. In the following code sample, we show how to load
    a CSV file with the `mlpack` library into the `matrix` object. The CSV parser
    in this library can automatically create numerical mappings for non-numeric values,
    so we easily load the Iris dataset without additional preprocessing.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习框架已经具有将CSV文件格式读取到其内部表示的例程。在以下代码示例中，我们展示了如何使用`mlpack`库将CSV文件加载到`matrix`对象中。该库中的CSV解析器可以自动为非数值值创建数值映射，因此我们可以轻松地加载Iris数据集而无需额外的预处理。
- en: 'To read a CSV file with the `mlpack` library, we have to include the corresponding
    headers, as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`mlpack`库读取CSV文件，我们必须包含相应的头文件，如下所示：
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can use the `data::Load` function to load the CSV data from a file, as illustrated
    in the following code snippet:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`data::Load`函数从文件中加载CSV数据，如下面的代码片段所示：
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Notice that the `data::Load` function takes the `dataset` matrix object to
    load data and the `info` object of the `DatasetInfo` type that can be used to
    get additional information about the loaded file. Also, the last Boolean `true`
    parameter was used to make the function throw an exception in the loading error
    case. For example, we can get the number of columns and an available mapping for
    non-numeric values, as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`data::Load`函数接受要加载数据的`dataset`矩阵对象和`DatasetInfo`类型的`info`对象，该对象可以用来获取有关加载文件的附加信息。此外，最后一个布尔参数`true`用于在加载错误情况下使函数抛出异常。例如，我们可以获取列数和用于非数值值的可用映射，如下所示：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Due to the fact that data is loaded as is, there are no automatic assumptions
    about dataset structure. So, to extract labels, we need to manually divide the
    loaded matrix object as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据是按原样加载的，因此没有关于数据集结构的自动假设。因此，为了提取标签，我们需要手动将加载的矩阵对象划分为以下形式：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We used the `arma::conv_to` function to create the standalone `arma::Row` object
    from the dataset row. Then, we deleted the last row from the dataset with the
    `shed_row` method.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`arma::conv_to`函数从数据集行创建独立的`arma::Row`对象。然后，我们使用`shed_row`方法从数据集中删除最后一行。
- en: Reading CSV files with the Dlib library
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Dlib库读取CSV文件
- en: The `Dlib` library can load CSV files directly to its matrix type, as the `mlpack`
    library does. For this operation, we can use a simple C++ streaming operator and
    a standard `std::ifstream` object.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dlib`库可以直接将CSV文件加载到其矩阵类型中，就像`mlpack`库一样。为此操作，我们可以使用简单的C++流操作符和标准的`std::ifstream`对象。'
- en: 'As a first step, we make the necessary `include` statements, as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们进行必要的`include`语句，如下所示：
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, we define a `matrix` object and load data from the file, like this:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义一个`matrix`对象并从文件中加载数据，如下所示：
- en: '[PRE15]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In the `Dlib` library, `matrix` objects are used for training ML algorithms
    directly without the need to transform them into intermediate dataset types.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Dlib`库中，`matrix`对象用于直接训练机器学习算法，无需将它们转换为中间数据集类型。
- en: Reading JSON files with the nlohmann-json library
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用nlohmann-json库读取JSON文件
- en: Some datasets come with structured annotations and can contain multiple files
    and folders. An example of such a complex dataset is the **Common Objects in Context**
    (**COCO**) dataset. This dataset contains a text file with annotations for describing
    relations between objects and their structural parts. This widely known dataset
    is used to train models for segmentation, object detection, and classification
    tasks. Annotations in this dataset are defined in the JSON file format. JSON is
    a widely used file format for objects’ (entities’) representations.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据集附带结构化注释，可以包含多个文件和文件夹。这类复杂数据集的一个例子是**上下文中的常见物体**（**COCO**）数据集。该数据集包含一个文本文件，用于描述物体及其结构部分之间的关系。这个广为人知的数据集被用于训练分割、物体检测和分类任务的模型。该数据集中的注释定义在
    JSON 文件格式中。JSON 是一种广泛使用的用于对象（实体）表示的文件格式。
- en: It is just a text file with special notations for describing relations between
    objects and their parts. In the following code samples, we show how to work with
    this file format using the `nlohmann-json` library. This library provides a simple
    and intuitive interface for working with JSON, making it easy to convert between
    JSON strings and C++ data structures such as maps, vectors, and custom classes.
    It also supports various features such as automatic type conversion, pretty printing,
    and error handling. However, we are going to use a more straightforward dataset
    that defines paper reviews. The authors of this dataset are Keith, B., Fuentes,
    E., and Meneses, C., and they made this dataset for their work titled *A Hybrid
    Approach for Sentiment Analysis Applied to Paper* *Reviews* (2017).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 它只是一个带有特殊符号来描述物体及其部分的文本文件。在下面的代码示例中，我们将展示如何使用 `nlohmann-json` 库来处理这种文件格式。这个库提供了一个简单直观的接口来处理
    JSON，使得在 JSON 字符串和 C++ 数据结构（如映射、向量和自定义类）之间进行转换变得容易。它还支持各种功能，如自动类型转换、格式化打印和错误处理。然而，我们将使用一个更直接的、定义论文评论的数据集。这个数据集的作者是
    Keith, B.、Fuentes, E. 和 Meneses, C.，他们为他们的工作《应用于论文*评论*的混合方法情感分析》（2017）创建了此数据集。
- en: 'The following sample shows a reduced part of this JSON-based dataset:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的示例展示了基于 JSON 的数据集的一部分：
- en: '[PRE16]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'There are two main approaches to parsing and processing JSON files, which are
    listed as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 解析和处理 JSON 文件主要有两种方法，如下列出：
- en: The first approach assumes the parsing of whole files at once and creating a
    **Document Object Model** (**DOM**). The DOM is a hierarchical structure of objects
    that represents entities stored in files. It is usually stored in computer memory,
    and, in the case of large files, it can occupy a significant amount of memory.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一种方法假设一次性解析整个文件并创建一个**文档对象模型**（**DOM**）。DOM 是一个表示存储在文件中的实体的分层对象结构。它通常存储在计算机内存中，在处理大文件的情况下，它可能占用大量的内存。
- en: Another approach is to parse the file continuously and provide an **application
    program interface** (**API**) for a user to handle and process each event related
    to the file-parsing process. This second approach is usually called **Simple API
    for XML** (**SAX**). Despite its name, it’s a general approach that is used with
    non-XML data too. SAX is faster than DOM for parsing large XML files because it
    doesn’t build a complete tree representation of the entire document in memory.
    However, it can be more difficult to use for complex operations that require accessing
    specific parts of the document.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一种方法是连续解析文件，并为用户提供一个**应用程序编程接口**（**API**）来处理和每个与文件解析过程相关的事件。这种第二种方法通常被称为**简单
    XML API**（**SAX**）。尽管它的名字叫 SAX，但它是一种通用的方法，也用于非 XML 数据。SAX 在解析大型 XML 文件时比 DOM 快，因为它不会在内存中构建整个文档的完整树形表示。然而，对于需要访问文档特定部分进行复杂操作的情况，它可能更难以使用。
- en: Using a DOM for working with training datasets usually requires a lot of memory
    for structures that are useless for ML algorithms. So, in many cases, it is preferable
    to use the SAX interface. It allows us to filter irrelevant data and initialize
    structures that we can use directly in our algorithms. In the following code sample,
    we use this approach.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DOM 处理训练数据集通常需要为对机器学习算法无用的结构分配大量内存。因此，在许多情况下，使用 SAX 接口更为可取。SAX 允许我们过滤无关数据并初始化可以直接在我们的算法中使用的结构。在下面的代码示例中，我们使用这种方法。
- en: 'As a preliminary step, we define types for `paper`/`review` entities, as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 作为初步步骤，我们定义了 `paper`/`review` 实体的类型，如下所示：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Then, we declare a type for the object, which will be used by the parser to
    handle parsing events. This type should be inherited from the `nlohmann::json::json_sax_t`
    base class, and we need to override virtual handler functions that the parser
    will call when a particular parsing event occurs, as illustrated in the following
    code block:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们声明一个用于对象的类型，该类型将由解析器用于处理解析事件。这个类型应该从`nlohmann::json::json_sax_t`基类继承，并且我们需要重写解析器在特定解析事件发生时将调用的虚拟处理函数，如下面的代码块所示：
- en: '[PRE18]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We have to override all methods, but we can provide real handler implementations
    only for objects, arrays parsing events, and events for parsing unsigned `int`/`string`
    values. Other methods can have trivial implementations as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须重写所有方法，但我们可以只为对象、数组解析事件和解析无符号`int`/`string`值的解析事件提供实际的处理函数实现。其他方法可以有简单的实现，如下所示：
- en: '[PRE19]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we can use the `nlohmann::json::sax_parse` method to load a JSON file;
    this method takes the `std::istream` object and a `handler` object as the second
    argument. The following code block shows how to use it:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`nlohmann::json::sax_parse`方法加载JSON文件；这个方法接受`std::istream`对象和一个`handler`对象作为第二个参数。下面的代码块显示了如何使用它：
- en: '[PRE20]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'When there are no parsing errors, we will have an initialized array of `Paper`
    type objects. Consider, more precisely, the event handler’s implementation details.
    Our event handler works as a state machine. In one state, we populate it with
    the `Review` objects, and in another one, with the `Paper` objects, and there
    are states for other events, as shown in the following code snippet:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当没有解析错误时，我们将有一个初始化的`Paper`类型对象数组。更精确地考虑，事件处理器的实现细节。我们的事件处理器作为一个状态机工作。在一个状态下，我们用`Review`对象填充它，在另一个状态下，我们用`Paper`对象填充，还有其他事件的状态，如下面的代码片段所示：
- en: '[PRE21]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We parse the unsigned `unit` values only for the `Id` attributes of the `Paper`
    and the `Review` objects, and we update these values according to the current
    state and the previously parsed key, as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只为`Paper`和`Review`对象的`Id`属性解析无符号`unit`值，并根据当前状态和之前解析的键更新这些值，如下所示：
- en: '[PRE22]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'String values also exist in both types of objects, so we do the same checks
    to update corresponding values, as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串值也存在于这两种类型的对象中，所以我们进行相同的检查来更新相应的值，如下所示：
- en: '[PRE23]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The event handler for the JSON `key` attribute stores the `key` value to the
    appropriate variable, which we use to identify a current object in the parsing
    process, as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: JSON `key`属性的事件处理器将`key`值存储到适当的变量中，我们使用这个变量在解析过程中识别当前对象，如下所示：
- en: '[PRE24]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `start_object` event handler switches states according to the current `key`
    value and the previous `state` value. We base the current implementation on the
    knowledge of the structure of the current JSON file: there is no array of `Paper`
    objects, and each `Paper` object includes an array of reviews. It is one of the
    limitations of the SAX interface—we need to know the structure of the document
    to implement all event handlers correctly. The code can be seen in the following
    block:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`start_object`事件处理器根据当前的`key`值和之前的`state`值切换状态。我们的当前实现基于对当前JSON文件结构的了解：没有`Paper`对象的数组，每个`Paper`对象包含一个评论数组。这是SAX接口的一个限制——我们需要知道文档的结构才能正确实现所有事件处理器。代码可以在下面的代码块中看到：'
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In the `end_object` event handler, we populate arrays of `Paper` and `Review`
    objects according to the current state. Also, we switch the current state back
    to the previous one by running the following code:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在`end_object`事件处理器中，我们根据当前状态填充`Paper`和`Review`对象的数组。同时，我们通过运行以下代码将当前状态切换回上一个状态：
- en: '[PRE26]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In the `start_array` event handler, we switch the current state to a new one
    according to the current `state` value by running the following code:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在`start_array`事件处理器中，我们通过运行以下代码根据当前的`state`值切换当前状态到新的一个：
- en: '[PRE27]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'In the `end_array` event handler, we switch the current state to the previous
    one based on our knowledge of the document structure by running the following
    code:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在`end_array`事件处理器中，我们通过运行以下代码根据我们对文档结构的了解将当前状态切换回上一个状态：
- en: '[PRE28]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The vital thing in this approach is to clear the current `key` value after object
    processing. This helps us to debug parsing errors, and we always have actual information
    about the currently processed entity.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，关键的事情是在对象处理完毕后清除当前的`key`值。这有助于我们调试解析错误，并且我们总是有关于当前处理实体的实际信息。
- en: For small files, using the DOM approach can be preferable because it leads to
    less code and cleaner algorithms.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 对于小文件，使用 DOM 方法可能更可取，因为它导致代码更少且算法更简洁。
- en: Writing and reading HDF5 files with the HighFive library
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 HighFive 库编写和读取 HDF5 文件
- en: HDF5 is a highly efficient file format for storing datasets and scientific values.
    The `HighFive` library provides a higher-level C++ interface for the C library
    provided by the HDF Group. In this example, we propose to look at its interface
    by transforming the dataset used in the previous section to HDF5 format.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: HDF5 是一种用于存储数据集和科学值的非常高效的文件格式。`HighFive` 库为 HDF Group 提供了一个高级 C++ 接口。在这个例子中，我们建议通过将上一节中使用的数据集转换为
    HDF5 格式来查看其接口。
- en: The main concepts of the HDF5 format are groups and datasets. Each group can
    contain other groups and have attributes of different types. Also, each group
    can contain a set of dataset entries. Each dataset is a multidimensional array
    of values of the same type, which also can have attributes of different types.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: HDF5 格式的核心概念是组和数据集。每个组可以包含其他组和不同类型属性。此外，每个组还可以包含一组数据集条目。每个数据集是相同类型值的多维数组，也可以具有不同类型的属性。
- en: 'Let’s start with including the required headers, as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从包含所需的头文件开始，如下所示：
- en: '[PRE29]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, we have to create a `file` object where we will write our dataset, as
    follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须创建一个 `file` 对象，我们将在此对象中写入数据集，如下所示：
- en: '[PRE30]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'After we have a `file` object, we can start creating groups. We define a group
    of papers that should hold all `paper` objects, as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们有一个 `file` 对象后，我们可以开始创建组。我们定义一个包含所有 `paper` 对象的论文组，如下所示：
- en: '[PRE31]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Then, we iterate through an array of papers (as shown in the previous section)
    and create a group for each `paper` object with two attributes: the numerical
    `id` attribute and the `preliminary_decision` attribute of the `string` type,
    as illustrated in the following code block:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们遍历一个论文数组（如前节所示），并为每个 `paper` 对象创建一个组，包含两个属性：数值 `id` 属性和 `preliminary_decision`
    属性，后者为 `string` 类型，如下面的代码块所示：
- en: '[PRE32]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'After we have created an attribute, we have to put in its value with the `write()`
    method. Notice that the `HighFive::DataSpace::From` function automatically detects
    the size of the attribute value. The size is the amount of memory required to
    hold the attribute’s value. Then, for each `paper_group` object, we create a corresponding
    group of reviews, as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们创建属性后，我们必须使用 `write()` 方法将其值放入其中。请注意，`HighFive::DataSpace::From` 函数会自动检测属性值的大小。大小是存储属性值所需的内存量。然后，对于每个
    `paper_group` 对象，我们创建相应的评论组，如下所示：
- en: '[PRE33]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We insert into each `reviews_group` object a dataset of numerical values of
    `confidence`, `evaluation`, and `orientation` fields. For the dataset, we define
    `DataSpace` (the number of elements in the dataset) of size `3` and define a storage
    type as a 32-bit integer, as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在每个 `reviews_group` 对象中插入一个包含 `confidence`、`evaluation` 和 `orientation` 字段数值的数据集。对于数据集，我们定义
    `DataSpace`（数据集中元素的数量）大小为 `3`，并将存储类型定义为 32 位整数，如下所示：
- en: '[PRE34]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: After we have created and initialized all objects, the Papers/Reviews dataset
    in HDF5 format is ready. When the `file` object leaves the scope, its destructor
    saves everything to the secondary storage.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们创建并初始化所有对象后，HDF5 格式的 Papers/Reviews 数据集就准备好了。当 `file` 对象离开作用域时，其析构函数会将所有内容保存到辅助存储中。
- en: Having the file in the HDF5 format, we can consider the `HighFive` library interface
    for file reading.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有 HDF5 格式的文件，我们可以考虑使用 `HighFive` 库的文件读取接口。
- en: 'As the first step, we again create a `HighFive::File` object, but with attributes
    for reading, as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们再次创建一个 `HighFive::File` 对象，但带有读取属性，如下所示：
- en: '[PRE35]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Then, we use the `getGroup()` method to get the top-level `papers_group` object,
    as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用 `getGroup()` 方法获取顶级 `papers_group` 对象，如下所示：
- en: '[PRE36]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The `getGroup` method allows us to get a specific group by its name, so it’s
    a type of navigation through the HDF5 file structure.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`getGroup` 方法允许我们通过名称获取一个特定的组，因此它是一种在 HDF5 文件结构中的导航方式。'
- en: 'We need to get a list of all nested objects in this group because we can access
    objects only by their names. We can do this by running the following code:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要获取此组中所有嵌套对象的列表，因为我们只能通过它们的名称来访问对象。我们可以通过运行以下代码来完成此操作：
- en: '[PRE37]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Using a loop, we iterate over all `papers_group` objects in the `papers_group`
    container, like this:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用循环，我们遍历 `papers_group` 容器中的所有 `papers_group` 对象，如下所示：
- en: '[PRE38]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'For each `paper` object, we read its attributes and the memory space required
    for the attribute value. Also, because each attribute can be multidimensional,
    we should take care of it and allocate an appropriate container, as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个`paper`对象，我们读取其属性和属性值所需的内存空间。由于每个属性可以是多维的，因此我们应该注意这一点，并分配一个合适的容器，如下所示：
- en: '[PRE39]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'For reading datasets, we can use the same approach: get the `reviews` group,
    then get a list of dataset names, and, finally, read each dataset in a loop, as
    follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 对于读取数据集，我们可以使用相同的方法：获取`reviews`组，然后获取数据集名称列表，最后在循环中读取每个数据集，如下所示：
- en: '[PRE40]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Notice that we use the `select()` method for the dataset, which allows us to
    read only a part of the dataset. We define this part with ranges given as arguments.
    There is the `read()` method in the `dataset` type to read a whole dataset at
    once.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用`select()`方法来处理数据集，这允许我们只读取数据集的一部分。我们通过作为参数给出的范围来定义这部分。`dataset`类型中有一个`read()`方法，可以一次性读取整个数据集。
- en: 'Using these techniques, we can read and transform any HDF5 dataset. This file
    format allows us to work only with part of the required data and not to load the
    whole file to the memory. Also, because this is a binary format, its reading is
    more efficient than reading large text files. Other useful features of HDF5 are
    the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些技术，我们可以读取和转换任何HDF5数据集。这种文件格式允许我们只处理所需数据的一部分，而不必将整个文件加载到内存中。此外，由于这是一个二进制格式，其读取效率比读取大型文本文件要高。HDF5的其他有用特性如下：
- en: Compression options for datasets and attributes, reducing storage space and
    transfer time.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集和属性的数据压缩选项，减少存储空间和传输时间。
- en: Parallelization of I/O operations, enabling multiple threads or processes to
    access the file simultaneously. This can greatly increase throughput and reduce
    processing time.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: I/O操作的并行化，允许多个线程或进程同时访问文件。这可以大大提高吞吐量并减少处理时间。
- en: In this section, we saw how to load different file formats with data into C++
    data structures provided by various C++ libraries. Especially we learned how to
    fill matrix and tensor objects that will be used in different ML algorithms. In
    the following section, we will see how to initialize the same data structures
    with values from regular C++ containers, which can be important when you implement
    your own data loader.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了如何使用各种C++库提供的C++数据结构将不同文件格式的数据加载进来。特别是，我们学习了如何填充将在不同机器学习算法中使用到的矩阵和张量对象。在下一节中，我们将看到如何使用常规C++容器中的值来初始化这些相同的数据结构，这在实现自己的数据加载器时可能很重要。
- en: Initializing matrix and tensor objects from C++ data structures
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从C++数据结构初始化矩阵和张量对象
- en: There are a variety of file formats used for datasets, and not all of them might
    be supported by libraries. For using data from unsupported formats, we might need
    to write custom parsers. After we read values to regular C++ containers, we usually
    need to convert them into object types used in the ML framework we use. As an
    example, let’s consider the case of reading matrix data from files into C++ objects.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 用于数据集的文件格式有很多种，并且并非所有这些格式都可能被库支持。对于使用不受支持的格式的数据，我们可能需要编写自定义解析器。在将值读取到常规C++容器之后，我们通常需要将它们转换成我们在使用的机器学习框架中使用的对象类型。作为一个例子，让我们考虑从文件中读取矩阵数据到C++对象的情况。
- en: Working with the Eigen library
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Eigen库
- en: 'Using the `Eigen` library, we can wrap a C++ array into an `Eigen::Matrix`
    object with the `Eigen::Map` type. The wrapped object will behave as a standard
    `Eigen` matrix. We have to parametrize the `Eigen::Map` type with the type of
    matrix that has the required behavior. Also, when we create the `Eigen::Map` object,
    it takes as arguments a pointer to the C++ array and matrix dimensions, as illustrated
    in the following code snippet:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Eigen`库，我们可以使用`Eigen::Map`类型将C++数组包装成`Eigen::Matrix`对象。包装后的对象将表现得像一个标准的`Eigen`矩阵。我们必须用具有所需行为的矩阵类型来参数化`Eigen::Map`类型。此外，当我们创建`Eigen::Map`对象时，它需要一个指向C++数组的指针和矩阵维度作为参数，如下面的代码片段所示：
- en: '[PRE41]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Working with the Blaze library
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Eigen库
- en: 'The `Blaze` library has special classes that can be used to create wrappers
    for C++ arrays. To wrap a C++ container with objects of these classes, we have
    to pass a pointer to the data and corresponding dimensions as arguments, as illustrated
    in the following code snippet:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`Blaze`库有特殊的类，可以用来为C++数组创建包装器。为了使用这些类的对象来包装一个C++容器，我们必须传递一个指向数据的指针和相应的维度作为参数，如下面的代码片段所示：'
- en: '[PRE42]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Notice that additional template parameters were used to specify memory layout,
    alignment, and padding.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，使用了额外的模板参数来指定内存布局、对齐和填充。
- en: Working with the Dlib library
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Dlib库
- en: 'The `Dlib` library has the `Dlib::mat()` function for wrapping C++ containers
    into the `Dlib` matrix object. It also takes a pointer to the data and matrix
    dimensions as arguments, as illustrated in the following code snippet:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dlib`库有`Dlib::mat()`函数，用于将C++容器包装到`Dlib`矩阵对象中。它也接受数据指针和矩阵维度作为参数，如下面的代码片段所示：'
- en: '[PRE43]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The `Dlib::mat` function has other overloads that can take other types of containers
    to create a matrix.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dlib::mat`函数有其他重载，可以接受其他类型的容器来创建矩阵。'
- en: Working with the ArrayFire library
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ArrayFire库
- en: 'The `ArrayFire` library has a single technique to initialize the array object
    with an external memory pointer. It can be used as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`ArrayFire`库有一种初始化数组对象的方法，即使用外部内存指针。它可以如下使用：'
- en: '[PRE44]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: In this example, we initialize the `2x3` matrix with the data from the `C` array
    object. We used the `array` type constructor. The first two arguments are matrix
    row and column numbers, and the last one is the pointer to the data. We can initialize
    the `array` type object with the CUDA pointer in the same, but the fourth argument
    should be the `afDevice` specification.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用`C`数组对象中的数据初始化了`2x3`矩阵。我们使用了`array`类型构造函数。前两个参数是矩阵的行数和列数，最后一个参数是数据指针。我们也可以使用CUDA指针以相同的方式初始化`array`类型对象，但第四个参数应该是`afDevice`指定。
- en: Working with the mlpack library
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用mlpack库
- en: 'The `mlpack` framework uses the `Armadillo` library for linear algebra objects.
    So, to wrap a C++ container into the `arma::mat` object, we can use the corresponding
    constructor that takes a pointer to the data and matrix dimensions, as illustrated
    in the following code snippet:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlpack`框架使用`Armadillo`库进行线性代数对象。因此，要将C++容器包装到`arma::mat`对象中，我们可以使用相应的构造函数，该构造函数接受数据指针和矩阵维度，如下面的代码片段所示：'
- en: '[PRE45]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: If the fourth parameter named `copy_aux_mem` is set to `false`, the data will
    be not copied into the matrix’s internal buffer.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将名为`copy_aux_mem`的第四个参数设置为`false`，则数据将不会复制到矩阵的内部缓冲区中。
- en: Notice that all of these functions only make a wrapper for the original C++
    array where the data is stored and don’t copy the values into a new location.
    If we want to copy values from a C++ array to a `matrix` object, we usually need
    to call a `clone()` method or an analog of it for the wrapper object.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，所有这些函数只为存储数据的原始C++数组创建了一个包装器，并没有将值复制到新位置。如果我们想将C++数组中的值复制到`matrix`对象中，我们通常需要调用`clone()`方法或其包装对象的类似方法。
- en: After we have a matrix object for an ML framework we use, we can initialize
    other specialized objects for training ML algorithms. Examples of such abstractions
    are the `fl::TensorDataset` class in the `Flashlight` library or the `torch::data::Dataset`
    class in the `libtorch` library.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们为所使用的机器学习框架创建了一个矩阵对象之后，我们可以初始化其他用于训练机器学习算法的专用对象。此类抽象的例子包括`Flashlight`库中的`fl::TensorDataset`类或`libtorch`库中的`torch::data::Dataset`类。
- en: 'In this section, we learned how to initialize matrix and tensor objects with
    regular C++ containers and pointers. The following section will move to another
    important topic: manipulation images.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何使用常规C++容器和指针初始化矩阵和张量对象。下一节将转向另一个重要主题：图像操作。
- en: Manipulating images with the OpenCV and Dlib libraries
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OpenCV和Dlib库操作图像
- en: Many ML algorithms are related to **computer vision** (**CV**) problems. Examples
    of such tasks are object detection in images, segmentation, image classification,
    and others. To be able to deal with such tasks, we need instruments for working
    with images. We usually need routines to load images to computer memory, as well
    as routines for image processing. For example, the standard operation is image
    scaling, because many ML algorithms are trained only on images of a specific size.
    This limitation follows from the algorithm structure or is a hardware requirement.
    For example, we cannot load large images to the **graphics processing unit** (**GPU**)
    memory because of its limited size.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法与**计算机视觉**（**CV**）问题相关。此类任务的例子包括图像中的目标检测、分割、图像分类等。为了能够处理此类任务，我们需要用于处理图像的工具。我们通常需要将图像加载到计算机内存的例程，以及图像处理的例程。例如，标准操作是图像缩放，因为许多机器学习算法仅在特定大小的图像上训练。这种限制源于算法结构或硬件要求。例如，由于**图形处理单元**（**GPU**）内存大小有限，我们不能将大图像加载到GPU内存中。
- en: Also, hardware requirements can lead to a limited range of numeric types that
    our hardware supports, so we will need to change the initial image representation
    to one that our hardware can efficiently process. Also, ML algorithms usually
    assume a predefined layout of image channels, which can be different from the
    layout in the original image file.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，硬件要求可能导致我们的硬件支持的数值类型范围有限，因此我们需要将初始图像表示更改为硬件可以高效处理的表示。此外，ML 算法通常假设图像通道的预定义布局，这可能与原始图像文件中的布局不同。
- en: Another type of image-processing task is the creation of training datasets.
    In many cases, we have a limited number of available images for a specific task.
    However, to make a machine algorithm train well, we usually need more training
    images. So, the typical approach is to augment existing images. Augmentation can
    be done with operations such as random scaling, cropping parts of images, rotations,
    and other operations that can be used to make different images from the existing
    set.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种图像处理任务是创建训练数据集。在许多情况下，我们针对特定任务只有有限数量的可用图像。然而，为了使机器算法训练良好，我们通常需要更多的训练图像。因此，典型的做法是对现有图像进行增强。增强可以通过随机缩放、裁剪图像部分、旋转以及其他可以用来从现有集合中生成不同图像的操作来完成。
- en: In this section, we show how to use two of the most popular libraries for image
    processing for C++. `OpenCV` is a framework for solving CV problems that includes
    many ready-to-use implementations of CV algorithms. Also, it has many functions
    for image processing. `Dlib` is a CV and ML framework with a large number of implemented
    algorithms, as well as a rich set of image-processing routines.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示如何使用两个最流行的图像处理库来处理 C++。`OpenCV` 是一个用于解决 CV 问题的框架，其中包含许多现成的 CV 算法实现。此外，它还提供了许多图像处理功能。`Dlib`
    是一个包含大量实现算法的 CV 和 ML 框架，以及丰富的图像处理例程。
- en: Using OpenCV
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 OpenCV
- en: 'In the `OpenCV` library, an image is treated as a multidimensional matrix of
    values. There is a special `cv::Mat` type for this purpose. There are two base
    functions: the `cv::imread()` function loads the image, and the `cv::imwrite()`
    function writes the image to a file, as illustrated in the following code snippet:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `OpenCV` 库中，图像被视为一个多维值矩阵。为此，有一个特殊的 `cv::Mat` 类型。有两个基本函数：`cv::imread()` 函数加载图像，`cv::imwrite()`
    函数将图像写入文件，如下面的代码片段所示：
- en: '[PRE46]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Also, there are functions to manage images located in a memory buffer. The `cv::imdecode()`
    function loads an image from the memory buffer, and the `cv::imencode()` function
    writes an image to the memory buffer.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有用于管理位于内存缓冲区中的图像的功能。`cv::imdecode()` 函数从内存缓冲区中加载图像，而 `cv::imencode()` 函数将图像写入内存缓冲区。
- en: 'Scaling operations in the `OpenCV` library can be done with the `cv::resize()`
    function. This function takes an input image, an output image, the output image
    size or scale factors, and an interpolation type as arguments. The interpolation
    type governs how the output image will look after the scaling. General recommendations
    are as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`OpenCV` 库中的缩放操作可以使用 `cv::resize()` 函数来完成。此函数接受输入图像、输出图像、输出图像大小或缩放因子以及插值类型作为参数。插值类型决定了缩放后的输出图像将如何显示。以下是一些一般性建议：'
- en: Use `cv::INTER_AREA` for shrinking
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `cv::INTER_AREA` 进行缩小
- en: Use `cv::INTER_CUBIC` (slow) or `cv::INTER_LINEAR` for zooming
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `cv::INTER_CUBIC`（较慢）或 `cv::INTER_LINEAR` 进行缩放
- en: Use `cv::INTER_LINEAR` for all resizing purposes because it is fast
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于速度快，使用 `cv::INTER_LINEAR` 进行所有缩放操作
- en: The main difference between linear and cubic scaling lies in their approach
    to scaling pixels. Linear scaling preserves the aspect ratio and is simpler, while
    cubic scaling attempts to maintain details and transitions. The choice between
    the two depends on the specific requirements of your project and the desired outcome.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 线性缩放和立方缩放之间的主要区别在于它们缩放像素的方法。线性缩放保持宽高比且更简单，而立方缩放则试图保持细节和过渡。选择哪种缩放取决于您项目的具体要求和期望的结果。
- en: 'The following code sample shows how to scale an image:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例展示了如何缩放图像：
- en: '[PRE47]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'There is no special function for image cropping in the `OpenCV` library, but
    the `cv::Mat` type overrides the `operator()` method, which takes a cropping rectangle
    as an argument and returns a new `cv::Mat` object with part of the image surrounded
    by the specified rectangle. Also, note that this object will share the same memory
    with the original image, so its modification will change the original image too.
    To make a deep copy of the `cv::Mat` object, we need to use the `clone()` method,
    as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `OpenCV` 库中没有专门用于图像裁剪的函数，但 `cv::Mat` 类型重载了 `operator()` 方法，该方法接受一个裁剪矩形作为参数，并返回一个包含指定矩形周围图像部分的新的
    `cv::Mat` 对象。此外，请注意，此对象将与原始图像共享相同的内存，因此其修改将改变原始图像。要创建 `cv::Mat` 对象的深度副本，我们需要使用
    `clone()` 方法，如下所示：
- en: '[PRE48]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Sometimes, we need to move or rotate an image. The `OpenCV` library supports
    translation and rotation operations for images through affine transformations.
    We have to manually—or with helper functions—create a matrix of 2D affine transformations
    and then apply it to our image. For the move (the translation), we can create
    such a matrix manually and then apply it to an image with the `cv::wrapAffine()`
    function, as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们需要移动或旋转图像。`OpenCV` 库通过仿射变换支持图像的平移和旋转操作。我们必须手动或使用辅助函数创建一个二维仿射变换矩阵，然后将其应用于我们的图像。对于移动（平移），我们可以手动创建这样的矩阵，然后使用
    `cv::wrapAffine()` 函数将其应用于图像，如下所示：
- en: '[PRE49]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We can create a rotation matrix with the `cv::getRotationMatrix2D()` function.
    This takes a point of origin and the rotation angle in degrees, as illustrated
    in the following code snippet:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `cv::getRotationMatrix2D()` 函数创建一个旋转矩阵。此函数接受一个原点和一个旋转角度（以度为单位），如下面的代码片段所示：
- en: '[PRE50]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Another useful operation is extending an image size without scaling but with
    added borders. There is the `cv::copyMakeBorder()` function in the `OpenCV` library
    for this purpose. This function has different options on how to create borders.
    It takes an input image, an output image, border sizes for the top, the bottom,
    the left, and the right sides, the type of the border, and the border color. Border
    types can be one of the following:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的操作是不缩放但添加边界来扩展图像大小。`OpenCV` 库中有 `cv::copyMakeBorder()` 函数用于此目的。此函数在创建边界方面有不同的选项。它接受输入图像、输出图像、顶部、底部、左侧和右侧的边界大小、边界类型以及边界颜色。边界类型可以是以下之一：
- en: '`BORDER_CONSTANT`:Make function fill borders with a single color'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BORDER_CONSTANT`: 使函数用单一颜色填充边界'
- en: '`BORDER_REPLICATE`: Make function fill borders with copies of the last pixel
    values on each side (for example, *aaaaaa|abcdefgh|hhhhhhh*)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BORDER_REPLICATE`: 使函数在每个边界侧用最后像素值的副本填充边界（例如，*aaaaaa|abcdefgh|hhhhhhh*）'
- en: '`BORDER_REFLECT`: Make function fill borders with copies of opposite pixel
    values on each side (for example, *fedcba|abcdefgh|hgfedcb*)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BORDER_REFLECT`: 使函数在每个边界侧用相反像素值的副本填充边界（例如，*fedcba|abcdefgh|hgfedcb*）'
- en: '`BORDER_WRAP`: Make function fill borders by simulating the image duplication
    (for example, *cdefgh|abcdefgh|abcdefg*)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BORDER_WRAP`: 通过模拟图像重复来填充边界，例如（*cdefgh|abcdefgh|abcdefg*）'
- en: 'The following example shows how to use this function:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了如何使用此函数：
- en: '[PRE51]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'When we are using this function, we should take care of the origin of the source
    image. The `OpenCV` documentation says: “*If the source image is a part of a bigger
    image, the function will try to use the pixels outside of the ROI (short for region
    of interest) to form a border. To disable this feature and always do extrapolation,
    as if the source image was not a part of another image, use border* *type* `BORDER_ISOLATED`.”'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用这个函数时，应该注意源图像的起点。`OpenCV` 文档中提到：“*如果源图像是大图像的一部分，该函数将尝试使用 ROI（区域兴趣）之外的像素来形成边界。要禁用此功能并始终进行外推，就像源图像不是另一图像的一部分一样，请使用边界*
    *类型* `BORDER_ISOLATED`。”
- en: The function described previously is very helpful when we need to adapt training
    images of different sizes to the one standard image size used in some ML algorithms
    because, with this function, we do not distort target image content.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 之前描述的函数在需要将不同大小的训练图像适应某些机器学习算法中使用的标准图像大小时非常有用，因为使用此函数，我们不会扭曲目标图像内容。
- en: 'There is the `cv::cvtColor()` function to convert different color spaces in
    the `OpenCV` library. The function takes an input image, an output image, and
    a conversion scheme type. For example, in the following code sample, we convert
    the **red, green, and blue** (**RGB**) color space to a grayscale one:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 存在 `cv::cvtColor()` 函数在 `OpenCV` 库中将不同的颜色空间进行转换。该函数接受一个输入图像、一个输出图像和一个转换方案类型。例如，在下面的代码示例中，我们将
    **红色、绿色和蓝色** （**RGB**） 颜色空间转换为灰度：
- en: '[PRE52]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This can be very handy in certain scenarios.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些场景下，这可以非常方便。
- en: Using Dlib
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Dlib
- en: '`Dlib` is another popular library for image processing. This library has different
    functions and classes for math routines and image processing. The library documentation
    recommends using the `Dlib::array2d` type for images. The `Dlib::array2d` type
    is a template type that has to be parametrized with a pixel type. Pixel types
    in the `Dlib` library are defined with pixel-type traits. There are the following
    predefined pixel types: `rgb_pixel`, `bgr_pixel`, `rgb_alpha_pixel`, `hsi_pixel`,
    `lab_pixel`, and any scalar type can be used for grayscaled pixels’ representation.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dlib` 是另一个流行的图像处理库。这个库有不同的函数和类用于数学运算和图像处理。库文档建议使用 `Dlib::array2d` 类型来表示图像。`Dlib::array2d`
    类型是一个模板类型，必须用像素类型进行参数化。`Dlib` 库中的像素类型是用像素类型特性定义的。有以下预定义的像素类型：`rgb_pixel`、`bgr_pixel`、`rgb_alpha_pixel`、`hsi_pixel`、`lab_pixel`，以及任何标量类型都可以用于灰度像素的表示。'
- en: 'We can use the `load_image()` function to load an image from disk, as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `load_image()` 函数从磁盘加载图像，如下所示：
- en: '[PRE53]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'For a scaling operation, there is the `Dlib::resize_image()` function. This
    function has two different overloads. One takes a single scale factor and a reference
    to an image object. The second one takes an input image, an output image, the
    desired size, and an interpolation type. To specify the interpolation type in
    the `Dlib` library, we should call special functions: the `interpolate_nearest_neighbor()`,
    the `interpolate_quadratic()`, and the `interpolate_bilinear()` functions. The
    criteria for choosing one of them are the same as for the ones that we discussed
    in the *Using OpenCV* section. Notice that the output image for the `resize_image()`
    function should be already preallocated, as illustrated in the following code
    snippet:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对于缩放操作，有 `Dlib::resize_image()` 函数。这个函数有两个不同的重载版本。一个接受一个缩放因子和一个图像对象的引用。另一个接受输入图像、输出图像、期望的大小和插值类型。要在
    `Dlib` 库中指定插值类型，我们应该调用特殊函数：`interpolate_nearest_neighbor()`、`interpolate_quadratic()`
    和 `interpolate_bilinear()` 函数。选择其中一个的标准与我们在 *使用 OpenCV* 部分讨论的标准相同。请注意，`resize_image()`
    函数的输出图像应该已经预先分配，如下面的代码片段所示：
- en: '[PRE54]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'To crop an image with `Dlib`, we can use the `Dlib::extract_image_chips()`
    function. This function takes an original image, rectangle-defined bounds, and
    an output image. Also, there are overloads of this function that take an array
    of rectangle bounds and an array of output images, as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 `Dlib` 裁剪图像，我们可以使用 `Dlib::extract_image_chips()` 函数。这个函数接受一个原始图像、矩形定义的边界和一个输出图像。此外，这个函数还有接受矩形边界数组和输出图像数组的重载版本，如下所示：
- en: '[PRE55]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The `Dlib` library supports image transformation operations through affine
    transformations. There is the `Dlib::transform_image()` function, which takes
    an input image, an output image, and an affine transformation object. An example
    of the transformation object could be an instance of the `Dlib::point_transform_affine`
    class, which defines the affine transformation with a rotation matrix and a translation
    vector. Also, the `Dlib::transform_image()` function can take an interpolation
    type as the last parameter, as illustrated in the following code snippet:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dlib` 库通过仿射变换支持图像变换操作。存在一个 `Dlib::transform_image()` 函数，它接受一个输入图像、一个输出图像和一个仿射变换对象。变换对象的例子可以是
    `Dlib::point_transform_affine` 类的实例，它使用旋转矩阵和变换向量定义仿射变换。此外，`Dlib::transform_image()`
    函数可以接受一个插值类型作为最后一个参数，如下面的代码片段所示：'
- en: '[PRE56]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'In case we only need to do a rotation, `Dlib` has the `Dlib::rotate_image()`
    function. The `Dlib::rotate_image()` function takes an input image, an output
    image, a rotation angle in degrees, and an interpolation type, as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只需要旋转，`Dlib` 有 `Dlib::rotate_image()` 函数。`Dlib::rotate_image()` 函数接受一个输入图像、一个输出图像、一个以度为单位的角度和一个插值类型，如下所示：
- en: '[PRE57]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'There is no complete analog of a function for adding borders to images in the
    `Dlib` library. There are two functions: `Dlib::assign_border_pixels()` and `Dlib::zero_border_pixels()`
    for filling image borders with specified values. Before using these routines,
    we should resize the image and place the content in the right position. The new
    image size should include the borders’ widths. We can use the `Dlib::transform_image()`
    function to move the image content into the right place. The following code sample
    shows how to add borders to an image:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `Dlib` 库中没有为添加图像边框的函数的完整对应物。有两个函数：`Dlib::assign_border_pixels()` 和 `Dlib::zero_border_pixels()`
    用于用指定的值填充图像边框。在使用这些例程之前，我们应该调整图像大小并将内容放置在正确的位置。新的图像大小应包括边框的宽度。我们可以使用 `Dlib::transform_image()`
    函数将图像内容移动到正确的位置。以下代码示例展示了如何向图像添加边框：
- en: '[PRE58]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'For color-space conversions, there exists the `Dlib::assign_image()` function
    in the `Dlib` library. This function uses color-type information from pixel-type
    traits we used for the image definition. So, to convert an image to another color
    space, we should define a new image with the desired type of pixels and pass it
    to this function. The following example shows how to convert the RGB image to
    a **blue, green, red** (**BGR**) one:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 对于颜色空间转换，`Dlib` 库中存在 `Dlib::assign_image()` 函数。此函数使用我们从图像定义中使用的像素类型信息。因此，要将图像转换为另一个颜色空间，我们应该定义一个新的图像，具有所需的像素类型，并将其传递给此函数。以下示例展示了如何将
    RGB 图像转换为 **蓝、绿、红** （**BGR**）图像：
- en: '[PRE59]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'To make a grayscale image, we can define an image with the `unsigned char`
    pixel type, as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建灰度图像，我们可以定义一个具有 `unsigned char` 像素类型的图像，如下所示：
- en: '[PRE60]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: In this section, we learned how to load and preprocess images with the `OpenCV`
    and `Dlib` libraries. The next important step is to convert images into matrix
    or tensor structures to be able to use them in ML algorithms; it will be described
    in the following section.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了如何使用 `OpenCV` 和 `Dlib` 库加载和预处理图像。下一步重要的步骤是将图像转换为矩阵或张量结构，以便能够在机器学习算法中使用它们；这将在下一节中描述。
- en: Transforming images into matrix or tensor objects of various libraries
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将图像转换为各种库的矩阵或张量对象
- en: 'In most cases, images are represented in computer memory in an interleaved
    format, which means that pixel values are placed one by one in linear order. Each
    pixel value consists of several numbers representing a color. For example, for
    the RGB format, there will be three values placed together. So, in the memory,
    we will see the following layout for a 4x4 image:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，图像在计算机内存中以交错格式表示，这意味着像素值按顺序逐个放置。每个像素值由表示颜色的几个数字组成。例如，对于 RGB 格式，将会有三个值放在一起。因此，在内存中，我们将看到以下布局，对于一个
    4x4 的图像：
- en: '[PRE61]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'For image-processing libraries, such a value layout is not a problem, but many
    ML algorithms require different ordering. For example, it’s a common approach
    for **neural networks** (**NNs**) to take image channels separately ordered, one
    by one. The following example shows how such a layout is usually placed in memory:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像处理库，这种值布局不是问题，但许多机器学习算法需要不同的顺序。例如，对于 **神经网络** （**NNs**），按顺序单独排列图像通道是一种常见的方法。以下示例展示了这种布局通常如何在内存中放置：
- en: '[PRE62]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: So, often, we need to deinterleave image representation before passing it to
    some ML algorithm. It means that we need to extract color channels into separate
    vectors.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通常，我们需要在将图像传递给某些机器学习算法之前解交错图像表示。这意味着我们需要将颜色通道提取到单独的向量中。
- en: Moreover, we usually need to convert a color’s value data type too. For example,
    `OpenCV` library users often use floating-point formats, which allows them to
    preserve more color information in image transformations and processing routines.
    The opposite case is when we use a 256-bit type for color-channel information,
    but then we need to convert it to a floating-point type. So, in many cases, we
    need to convert the underlying data type to another one more suitable for our
    needs.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们通常还需要转换颜色的值数据类型。例如，`OpenCV` 库的用户经常使用浮点格式，这使得他们在图像变换和处理程序中能够保留更多的颜色信息。相反的情况是，当我们使用
    256 位类型来表示颜色通道信息时，但此时我们需要将其转换为浮点类型。因此，在许多情况下，我们需要将底层数据类型转换为更适合我们需求的另一种类型。
- en: Deinterleaving in OpenCV
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenCV 中的解交错
- en: 'By default, when we load an image with the `OpenCV` library, it loads the image
    in the BGR format and with `char` as the underlying data type. So, we need to
    convert it to the RGB format, like this:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，当我们使用 `OpenCV` 库加载图像时，它以 BGR 格式加载图像，并以 `char` 作为底层数据类型。因此，我们需要将其转换为 RGB
    格式，如下所示：
- en: '[PRE63]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Then, we can convert the underlying data type to the `float` type, like this:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将底层数据类型转换为`float`类型，如下所示：
- en: '[PRE64]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Next, to deinterleave channels, we need to split them with the `cv::split()`
    function, like this:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了解交织通道，我们需要使用`cv::split()`函数将它们分割，如下所示：
- en: '[PRE65]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Then, we can place channels back to the `cv::Mat` object in the order we need
    with the `cv::vconcat()` function, which concatenates matrices vertically, as
    follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用`cv::vconcat()`函数将通道按所需顺序放回`cv::Mat`对象中，如下所示：
- en: '[PRE66]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: There is a useful method in the `cv::Mat` type named `isContinuous` that allows
    us to check if the matrix’s data is placed in memory with a single contiguous
    block. If that is `true`, we can copy this block of memory or pass it to routines
    that work with plain C arrays.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '`cv::Mat`类型中有一个有用的方法名为`isContinuous`，它允许我们检查矩阵的数据是否以单个连续块放置在内存中。如果是`true`，我们可以复制这个内存块或将它传递给处理原始C数组的程序。'
- en: Deinterleaving in Dlib
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Dlib中的解交织
- en: 'The `Dlib` library uses the `unsigned char` type for pixel color representation,
    and we can use floating-point types only for grayscaled images. The `Dlib` library
    stores pixels in row-major order with interleaved channels, and data is placed
    in memory continuously with a single block. There are no special functions in
    the `Dlib` library to manage image channels, so we cannot deinterleave them or
    mix them. However, we can use raw pixel data to manage color values manually.
    Two functions in the `Dlib` library can help us: the `image_data()` function to
    access raw pixel data, and the `width_step()` function to get the padding value.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dlib`库使用`unsigned char`类型来表示像素颜色，我们只能使用浮点类型来处理灰度图像。《Dlib》库以行主序存储像素，通道交错，数据在内存中连续放置在一个块中。`Dlib`库中没有特殊函数来管理图像通道，因此我们无法解交织它们或混合它们。然而，我们可以使用原始像素数据手动管理颜色值。`Dlib`库中的两个函数可以帮助我们：`image_data()`函数用于访问原始像素数据，`width_step()`函数用于获取填充值。'
- en: The most straightforward approach to deinterleave the `Dlib` image object is
    using a loop over all pixels. In such a loop, we can split each pixel value into
    separate colors.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 解交织`Dlib`图像对象的最直接方法是通过遍历所有像素的循环。在这样的循环中，我们可以将每个像素值分割成单独的颜色。
- en: 'As a first step, we define containers for each of the channels, as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们为每个通道定义了容器，如下所示：
- en: '[PRE67]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Then, we read color values for each pixel with two nested loops over image
    rows and columns, like this:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用两个嵌套循环遍历图像的行和列，读取每个像素的颜色值，如下所示：
- en: '[PRE68]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: The result is three containers with color-channel values, which we can use separately.
    They are suitable to initialize grayscaled images for use in image-processing
    routines. Alternatively, we can use them to initialize a matrix-type object that
    we can process with linear algebra routines.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是三个包含颜色通道值的容器，我们可以单独使用它们。它们适合用于初始化灰度图像以在图像处理程序中使用。或者，我们可以使用它们来初始化一个矩阵类型的对象，我们可以使用线性代数程序来处理它。
- en: We saw how to load and prepare images for use in linear algebra abstractions
    and ML algorithms. In the next section, we will learn general methods to prepare
    data for use in ML algorithms. Such methods will help us make learning procedures
    more stable and converge faster.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了如何加载和准备图像以用于线性代数抽象和机器学习算法。在下一节中，我们将学习准备数据以用于机器学习算法的一般方法。这些方法将帮助我们使学习过程更加稳定并更快地收敛。
- en: Normalizing data
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据归一化
- en: Data normalization is a crucial preprocessing step in ML. In general, data normalization
    is a process that transforms multiscale data to the same scale. Feature values
    in a dataset can have very different scales—for example, the height can be given
    in centimeters with small values, but the income can have large-value amounts.
    This fact has a significant impact on many ML algorithms.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 数据归一化是机器学习中的一个关键预处理步骤。通常，数据归一化是一个将多尺度数据转换为相同尺度的过程。数据集中的特征值可以具有非常不同的尺度——例如，高度可以以厘米为单位给出，数值较小，但收入可以有大数值。这一事实对许多机器学习算法有重大影响。
- en: For example, if some feature values differ from values of other features several
    times, then this feature will dominate over others in classification algorithms
    based on the Euclidean distance. Some algorithms have a strong requirement for
    normalization of input data; an example of such an algorithm is the **Support
    Vector Machine** (**SVM**) algorithm. NNs also usually require normalized input
    data. Also, data normalization has an impact on optimization algorithms. For example,
    optimizers based on the **gradient descent** (**GD**) approach can converge much
    quicker if data has the same scale.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果某些特征值与其他特征值相差几倍，那么在基于欧几里得距离的分类算法中，这个特征将主导其他特征。一些算法对输入数据的归一化有强烈的要求；这类算法的例子是**支持向量机**（**SVM**）算法。神经网络也通常需要归一化的输入数据。此外，数据归一化对优化算法也有影响。例如，基于**梯度下降**（**GD**）方法的优化器如果数据具有相同的尺度，可以更快地收敛。
- en: There are several methods of normalization, but from our point of view, the
    most popular are the standardization, the min-max, and the mean normalization
    methods.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化的方法有多种，但根据我们的观点，最流行的是标准化、最小-最大和均值归一化方法。
- en: '**Standardization** is a process of making data have a zero mean and a standard
    deviation equal to 1\. The formula for standardized vector is ![](img/B19849_Formula_01.png),
    where ![](img/B19849_Formula_02.png) is an original vector, ![](img/B19849_Formula_03.png)
    is an average value of ![](img/B19849_Formula_04.png) calculated with the formula
    ![](img/B19849_Formula_05.png), and ![](img/B19849_Formula_06.png) is the standard
    deviation of ![](img/B19849_Formula_07.png) calculated with the formula ![](img/B19849_Formula_08.png).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准化**是一个使数据具有零均值和标准差等于1的过程。标准化向量的公式为![公式01](img/B19849_Formula_01.png)，其中![公式02](img/B19849_Formula_02.png)是一个原始向量，![公式03](img/B19849_Formula_03.png)是使用公式![公式04](img/B19849_Formula_04.png)计算得到的![公式05](img/B19849_Formula_05.png)的平均值，而![公式06](img/B19849_Formula_06.png)是使用公式![公式07](img/B19849_Formula_07.png)计算得到的![公式08](img/B19849_Formula_08.png)的标准差。'
- en: '`[0, 1]`. We can do rescaling with the following formula:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`[0, 1]`。我们可以使用以下公式进行缩放：'
- en: '![](img/B19849_Formula_091.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![公式091](img/B19849_Formula_091.jpg)'
- en: Min-max scaling is useful when there are significant differences in the scale
    of different features in your dataset. It helps to make the features comparable,
    which is important for many ML models.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的数据集中不同特征的比例差异显著时，最小-最大缩放非常有用。它有助于使特征可比较，这对于许多机器学习模型来说非常重要。
- en: '`[-1, 1]` so that its mean becomes zero. We can use the following formula to
    do mean normalization:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '`[-1, 1]`，使其均值变为零。我们可以使用以下公式进行均值归一化：'
- en: '![](img/B19849_Formula_101.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![公式101](img/B19849_Formula_101.jpg)'
- en: This transformation helps to make the data more easily interpretable and improves
    the performance of some ML algorithms by reducing the impact of outliers and ensuring
    that all features are on a similar scale. Consider how we can implement these
    normalization techniques and which ML framework functions can be used to calculate
    them.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转换有助于使数据更容易解释，并通过减少异常值的影响并确保所有特征处于相似尺度上，从而提高某些机器学习算法的性能。考虑我们如何实现这些归一化技术以及哪些机器学习框架函数可以用来计算它们。
- en: We assume that each row of this matrix ![](img/B19849_Formula_11.png) is one
    training sample, and the value in each column is the value of one feature of the
    current sample.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设这个矩阵![公式11](img/B19849_Formula_11.png)的每一行是一个训练样本，每一列的值是当前样本的一个特征值。
- en: Normalizing with Eigen
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用特征值进行归一化
- en: There are no functions for data normalization in the `Eigen` library. However,
    we can implement them according to the provided formulas.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`Eigen`库中没有数据归一化的函数。然而，我们可以根据提供的公式实现它们。'
- en: 'For standardization, we first have to calculate the standard deviation, as
    follows:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标准化，我们首先必须计算标准差，如下所示：
- en: '[PRE69]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Notice that some reduction functions in the `Eigen` library work only with array
    representation; examples are the `sum()` and the `sqrt()` functions. We have also
    calculated the mean for each feature—we used the `x.colwise().mean()` function
    combination, which returns a vector of `mean`. We can use the same approach for
    other feature statistics’ calculations.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`Eigen`库中的一些减少函数仅与数组表示形式一起工作；例如，`sum()`和`sqrt()`函数。我们还计算了每个特征的均值——我们使用了`x.colwise().mean()`函数组合，它返回一个`mean`向量。我们可以用相同的方法来计算其他特征统计值。
- en: 'Having the standard deviation value, the rest of the formula for standardization
    will look like this:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在得到标准差值后，标准化公式的其余部分如下所示：
- en: '[PRE70]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Implementation of `min-max` normalization is very straightforward and does
    not require intermediate values, as illustrated in the following code snippet:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '`min-max`归一化的实现非常直接，不需要中间值，如下面的代码片段所示：'
- en: '[PRE71]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'We implement the mean normalization in the same way, like this:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以相同的方式实现均值归一化，如下所示：
- en: '[PRE72]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Notice that we implement formulas in a vectorized way without loops; this approach
    is more computationally efficient because it can be compiled for execution on
    a GPU or the **central processing unit’s** (**CPU’s**) **Single Instruction Multiple
    Data** (**SIMD**) instructions.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们以向量化方式实现公式，而不使用循环；这种方法在计算上更有效，因为它可以被编译为在GPU或**中央处理单元（CPU）的****单指令多数据（SIMD）**指令上执行。
- en: Normalizing with mlpack
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用mlpack进行归一化
- en: 'There are different classes for feature scaling in the `mlpack` library. The
    most interesting for us are `data::data::MinMaxScaler`, which implements min-max
    normalization (or rescaling), and `mlpack::data::StandardScaler`, which implements
    data standardization. We can reuse objects of those classes for scaling different
    data with the same learned statistics. It can be useful in cases when we train
    an ML algorithm on one data format with applied rescaling, and then we use the
    algorithm for predictions on new data. To make this algorithm work as we want,
    we have to rescale new data in the same way as we did in the training process,
    as follows:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlpack`库中有不同的类用于特征缩放。对我们来说最有趣的是`data::data::MinMaxScaler`，它实现了最小-最大归一化（或缩放），以及`mlpack::data::StandardScaler`，它实现了数据标准化。我们可以重用这些类的对象来对具有相同学习统计数据的不同的数据进行缩放。这在我们在一个应用了缩放的数据格式上训练ML算法，然后使用该算法对新数据进行预测的情况下可能很有用。为了使此算法按我们的意愿工作，我们必须以与训练过程中相同的方式缩放新数据，如下所示：'
- en: '[PRE73]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: To learn statistics values, we use the `Fit()` method, and for feature modification,
    we use the `Transform()` method of the `MinMaxScaler` class.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 要学习统计值，我们使用`MinMaxScaler`类的`Fit()`方法，而对于特征修改，我们使用`Transform()`方法。
- en: 'The `StandardScaler` class can be used in the same manner, as follows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 可以以相同的方式使用`StandardScaler`类，如下所示：
- en: '[PRE74]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'To print the matrix object in the `mlpack` library, the standard streaming
    operators can be used as follows:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 要在`mlpack`库中打印矩阵对象，可以使用以下标准流操作符：
- en: '[PRE75]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Also, to revert the applied scaling, these classes have the `InverseTransform`
    method.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了撤销应用缩放，这些类有`InverseTransform`方法。
- en: Normalizing with Dlib
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Dlib进行归一化
- en: 'The `Dlib` library provides functionality for feature standardization with
    the `Dlib::vector_normalizer` class. There is one limitation to using this class—we
    cannot use it with one big matrix containing all training samples. Alternatively,
    we should represent each sample with a separate vector object and put them into
    the C++ `std::vector` container, as follows:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dlib`库提供了`Dlib::vector_normalizer`类来提供特征标准化的功能。使用此类的一个限制是，我们无法使用它来处理包含所有训练样本的大矩阵。作为替代，我们应该用单独的向量对象表示每个样本，并将它们放入C++的`std::vector`容器中，如下所示：'
- en: '[PRE76]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'We see that the object of this class can be reused, but it should be trained
    first. The train method implementation can look like this:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，此类对象可以重用，但应该先进行训练。训练方法的实现可能如下所示：
- en: '[PRE77]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Notice that the `Dlib::mat()` function has different overloads for matrix creation
    from different sources. Also, we use the `reciprocal()` function that makes the
    ![](img/B19849_Formula_121.png) matrix if *m* is the input matrix.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`Dlib::mat()`函数有不同的重载，用于从不同来源创建矩阵。此外，我们还使用了`reciprocal()`函数，它将输入矩阵`m`转换为![](img/B19849_Formula_121.png)矩阵。
- en: 'Printing matrices for debugging purposes in the `Dlib` library can be done
    with the simple streaming operator, as illustrated in the following code snippet:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Dlib`库中，为了调试目的打印矩阵可以使用简单的流操作符，如下面的代码片段所示：
- en: '[PRE78]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: We can see that the `Dlib` library provides a rich interface for data preprocessing
    that can be easily used.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，`Dlib`库提供了一个丰富的数据预处理接口，可以轻松使用。
- en: Normalizing with Flashlight
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Flashlight进行归一化
- en: 'The `Flashlight` library doesn’t have particular classes to perform feature
    scaling. But it has functions to calculate basic statistics easily, so we can
    implement feature scaling algorithms as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '`Flashlight`库没有特定的类来执行特征缩放。但它有计算基本统计数据的函数，因此我们可以按照以下方式实现特征缩放算法：'
- en: '[PRE79]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: The `fl::amin` and `fl::amax` functions find the minimum and maximum values.
    The `fl::mean` and `fl::std` functions calculate the mean and standard deviation
    correspondingly. All these functions do their calculation along a specified dimension
    that comes as the second parameter. It means that we scale each `x` feature in
    thedataset separately.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '`fl::amin` 和 `fl::amax` 函数用于查找最小值和最大值。`fl::mean` 和 `fl::std` 函数分别计算平均值和标准差。所有这些函数都沿着指定的维度进行计算，该维度作为第二个参数。这意味着我们单独对数据集中的每个
    `x` 特征进行缩放。'
- en: 'We can print a `fl::Tensor` object with the standard C++ streaming operator,
    as follows:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用标准的 C++ 流操作符来打印 `fl::Tensor` 对象，如下所示：
- en: '[PRE80]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: We saw that despite the `FlashLight` library not providing special classes for
    data preprocessing, we can build them with linear algebra routines.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，尽管 `FlashLight` 库没有提供专门用于数据预处理的类，但我们可以使用线性代数例程构建它们。
- en: Summary
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we considered how to load data from CSV, JSON, and HDF5 formats.
    CSV is easy to read and write, making it suitable for small to medium-sized datasets.
    CSV files are often used for tabular data, such as customer information, sales
    records, or financial transactions. JSON is a lightweight data interchange format
    that is human-readable and easy to parse. It is commonly used for representing
    structured data, including objects, arrays, and key-value pairs. In ML, JSON can
    be used to store data for training models, such as feature vectors, labels, and
    metadata. HDF5 is a high-performance file format designed for scientific data
    storage and analysis. It supports large datasets with complex structures, allowing
    for efficient storage of multidimensional arrays and tables. HDF5 files are commonly
    used in applications where large amounts of data need to be stored and accessed
    efficiently.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何从 CSV、JSON 和 HDF5 格式加载数据。CSV 格式易于读写，使其适用于小型到中型数据集。CSV 文件通常用于表格数据，例如客户信息、销售记录或金融交易。JSON
    是一种轻量级的数据交换格式，可读性强且易于解析。它通常用于表示结构化数据，包括对象、数组和键值对。在机器学习中，JSON 可以用于存储用于训练模型的数据，例如特征向量、标签和元数据。HDF5
    是一种高性能的文件格式，专为科学数据存储和分析设计。它支持具有复杂结构的大型数据集，允许高效地存储多维数组和表格。HDF5 文件常用于需要高效存储和访问大量数据的应用程序。
- en: We saw how to convert the loaded data into objects suitable for use in different
    ML frameworks. We used the libraries’ APIs to convert raw C++ arrays into matrices
    and higher-level dataset objects for ML algorithms.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了如何将加载的数据转换为适用于不同机器学习框架的对象。我们使用了库的 API 将原始 C++ 数组转换为矩阵和更高层次的机器学习算法数据集对象。
- en: We looked at how to load and process images with the `OpenCV` and `Dlib` libraries.
    These libraries offer a wide range of functions and algorithms that can be used
    in various applications for CV. The libraries can be used for basic image preprocessing,
    as well as for more complicated systems that use ML for solving industry-important
    tasks such as face detection and recognition, which can be used to build security
    systems, and for access control or facial authentication. Object detection can
    be used for tasks such as counting objects in an image, detecting defects in products,
    identifying specific objects, or tracking their movement. This is useful in industrial
    automation, surveillance systems to identify suspicious activities, and autonomous
    vehicles. Image segmentation allows users to extract specific parts of an image
    for further analysis. This is essential for diagnosing diseases in medical imaging
    analysis. Motion tracking of objects over time is also used for sports analytics,
    traffic monitoring, and surveillance.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了如何使用 `OpenCV` 和 `Dlib` 库加载和处理图像。这些库提供了一系列函数和算法，可用于各种计算机视觉应用。这些库可用于基本的图像预处理，以及更复杂的系统，这些系统使用机器学习来解决行业重要任务，例如人脸检测和识别，这些可以用于构建安全系统、访问控制或面部认证。目标检测可用于图像中的对象计数、产品缺陷检测、特定对象的识别或其运动的跟踪。这在工业自动化、监控系统识别可疑活动以及自动驾驶汽车中非常有用。图像分割允许用户提取图像的特定部分以进行进一步分析。这在医学影像分析中诊断疾病时至关重要。随时间对物体进行运动跟踪也用于体育分析、交通监控和监控。
- en: We became familiar with the data normalization process, which is very important
    for many ML algorithms. Also, we saw which normalization techniques are available
    in ML libraries, and we implemented some normalization approaches with linear
    algebra functions from the `Eigen` library.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们熟悉了数据归一化过程，这对于许多机器学习算法非常重要。我们还看到了机器学习库中可用的归一化技术，并使用 `Eigen` 库的线性代数函数实现了某些归一化方法。
- en: In the following chapter, we will see how to measure a model’s performance on
    different types of data. We will look at special techniques that help us to understand
    how the model describes the training dataset well and how it performs on new data.
    Also, we will learn the different types of parameters ML models depend on and
    see how to select the best combination of them to improve the model’s performance.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到如何测量模型在不同类型数据上的性能。我们将探讨一些特殊技术，这些技术帮助我们理解模型如何很好地描述训练数据集以及它在新数据上的表现。此外，我们还将学习机器学习模型所依赖的不同类型参数，并了解如何选择最佳参数组合以提升模型性能。
- en: Further reading
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The HDF5® library and file format: [https://www.hdfgroup.org/solutions/hdf5/](https://www.hdfgroup.org/solutions/hdf5/)'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HDF5® 库和文件格式：[https://www.hdfgroup.org/solutions/hdf5/](https://www.hdfgroup.org/solutions/hdf5/)
- en: 'GitHub link for Fast-CPPCSV Parser: [https://github.com/ben-strasser/Fast-CPP-CSV-Parser](https://github.com/ben-strasser/Fast-CPP-CSV-Parser)'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fast-CPPCSV 解析器的 GitHub 链接：[https://github.com/ben-strasser/Fast-CPP-CSV-Parser](https://github.com/ben-strasser/Fast-CPP-CSV-Parser)
- en: '`OpenCV`: [https://opencv.org/](https://opencv.org/)'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OpenCV`：[https://opencv.org/](https://opencv.org/)'
- en: '`Dlib` C++ library: [http://Dlib.net/](http://Dlib.net/)'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Dlib` C++ 库：[http://Dlib.net/](http://Dlib.net/)'
- en: '`Flashlight` documentation: [https://fl.readthedocs.io/en/latest/index.html](https://fl.readthedocs.io/en/latest/index.html)'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Flashlight` 文档：[https://fl.readthedocs.io/en/latest/index.html](https://fl.readthedocs.io/en/latest/index.html)'
- en: '`nlohmann-json` documentation: [https://json.nlohmann.me/](https://json.nlohmann.me/)'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nlohmann-json` 文档：[https://json.nlohmann.me/](https://json.nlohmann.me/)'
- en: '`mlpack` documentation: [https://mlpack.org/doc/index.html](https://mlpack.org/doc/index.html)'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mlpack` 文档：[https://mlpack.org/doc/index.html](https://mlpack.org/doc/index.html)'
- en: '*A Hybrid Approach for Sentiment Analysis Applied to Paper Reviews* dataset:
    [https://archive.ics.uci.edu/static/public/410/paper+reviews.zip](https://archive.ics.uci.edu/static/public/410/paper+reviews.zip)'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*应用于论文评论的混合情感分析方法* 数据集：[https://archive.ics.uci.edu/static/public/410/paper+reviews.zip](https://archive.ics.uci.edu/static/public/410/paper+reviews.zip)'
