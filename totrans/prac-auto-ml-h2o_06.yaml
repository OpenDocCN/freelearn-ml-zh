- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Understanding H2O AutoML Leaderboard and Other Performance Metrics
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解H2O AutoML排行榜及其他性能指标
- en: 'When we train ML models, the statistical nuances of different algorithms often
    make it difficult to compare one model with another model that is trained using
    a different algorithm. From a professional standpoint, you will eventually need
    to select the right model to solve your ML problem. So, the question arises: how
    do you compare two different models solving the same ML problem and decide which
    one is better?'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们训练机器学习模型时，不同算法的统计细微差别往往使得比较使用不同算法训练的模型变得困难。从专业角度来看，你最终需要选择合适的模型来解决你的机器学习问题。因此，问题随之而来：你如何比较解决相同机器学习问题的两个不同模型，并决定哪个更好？
- en: This is where model performance metrics come in. Model performance metrics are
    certain numerical metrics that give an accurate measurement of a model’s performance.
    The performance of a model can mean various things and can also be measured in
    several ways. The way we evaluate a model, whether it is a classification model
    or a regression model, only differs by the metrics that we use for that evaluation.
    You can measure how accurately the model classifies objects by measuring the number
    of correct and incorrect predictions. You can measure how accurately the model
    predicted a stock price and note the magnitude of the error between the predicted
    value and the actual value. You can also compare how the model fairs with outliers
    in data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是模型性能指标发挥作用的地方。模型性能指标是一系列数值指标，可以准确衡量模型的表现。模型的表现可以意味着许多不同的事情，也可以用多种方式来衡量。我们评估模型的方式，无论是分类模型还是回归模型，只取决于我们用于评估的指标。你可以通过测量正确和错误预测的数量来衡量模型分类对象的准确性。你可以通过测量模型预测股票价格的准确性，并注意预测值与实际值之间的误差幅度。你也可以比较模型在数据异常值上的表现。
- en: H2O provides plenty of model performance measuring techniques. Most of them
    are automatically calculated and stored as the model metadata whenever a model
    is trained. H2O AutoML further automates the selection of models as well. It does
    so by presenting you with a leaderboard comparing the different performance metrics
    of the trained models. In this chapter, we will explore the different performance
    metrics that are used in the AutoML leaderboard, as well as some additional metrics
    that are important for users to know.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: H2O提供了大量的模型性能测量技术。其中大多数都是在模型训练时自动计算并存储为模型元数据的。H2O AutoML还进一步自动化了模型的选择。它通过向你展示一个比较训练模型不同性能指标的排行榜来实现这一点。在本章中，我们将探讨AutoML排行榜中使用的不同性能指标，以及一些对用户来说很重要的附加指标。
- en: 'We shall explore these performance metrics according to the following sections:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将根据以下章节来探讨这些性能指标：
- en: Exploring the H2O AutoML leaderboard performance metrics
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索H2O AutoML排行榜性能指标
- en: Exploring other important performance metrics
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索其他重要的性能指标
- en: By the end of this chapter, you should understand how a model’s performance
    is measured and how we can use these metrics to get an understanding of its prediction
    behavior.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该了解如何衡量模型的表现，以及我们如何使用这些指标来了解其预测行为。
- en: So, let’s begin by exploring and understanding the H2O AutoML leaderboard performance
    metrics.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们从探索和理解H2O AutoML排行榜性能指标开始。
- en: Exploring the H2O AutoML leaderboard performance metrics
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索H2O AutoML排行榜性能指标
- en: In [*Chapter 2*](B17298_02.xhtml#_idTextAnchor038), *Working with H2O Flow (H2O’s
    Web UI)*, once we trained the models on a dataset using H2O AutoML, the results
    of the models were stored in a leaderboard. The leaderboard was a table containing
    the model IDs and certain metric values for the respective models (*see Figure
    2.33*).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第二章*](B17298_02.xhtml#_idTextAnchor038) *使用H2O Flow (H2O的Web UI)* 中，一旦我们使用H2O
    AutoML在数据集上训练了模型，模型的成果就会存储在排行榜中。排行榜是一个包含模型ID和相应模型某些指标值的表格（*见图2.33*）。
- en: 'The leaderboard ranks the models based on a default metric, which is ideally
    the second column in the table. The ranking metrics depend on what kind of prediction
    problem the models are trained on. The following list represents the ranking metrics
    used for the respective ML problems:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 排行榜根据默认指标对模型进行排名，理想情况下是表格的第二列。排名指标取决于模型训练的预测问题类型。以下列表表示用于相应机器学习问题的排名指标：
- en: For binary classification problems, the ranking metric is **AUC**.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于二分类问题，排名指标是**AUC**。
- en: For multi-classification problems, the ranking metric is the **mean per-class
    error**.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于多分类问题，排名指标是**每类平均误差**。
- en: For regression problems, the ranking metric is **deviance**.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于回归问题，排名指标是**偏差**。
- en: Along with the ranking metrics, the leaderboard also provides some additional
    performance metrics for a better understanding of the model quality.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 除了排名指标外，排行榜还提供了一些额外的性能指标，以更好地理解模型质量。
- en: Let’s try to understand these performance metrics, starting with the mean squared
    error.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试理解这些性能指标，从均方误差开始。
- en: Understanding the mean squared error and the root mean squared error
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解均方误差和均方根误差
- en: '**Mean Squared Error** (**MSE**), also called **Mean Squared Deviation** (**MSD**),
    as the name suggests, is a metric that measures the mean of the squares of errors
    of the predicted value against the actual value.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**均方误差**（**MSE**），也称为**均方偏差**（**MSD**），正如其名所示，是一个指标，它衡量预测值与实际值误差的平方的平均值。'
- en: 'Consider the following regression scenario:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下回归场景：
- en: '![](img/B17298_06_001.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_001.jpg)'
- en: Figure 6.1 – The MSE in a regression scenario
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 - 回归场景中的MSE
- en: This is a generic regression scenario where the line of regression passes through
    the data points plotted on the graph. The trained model makes predictions based
    on this line of regression. The error values show the difference between the actual
    value and the predicted value, which lies on the line of regression, as denoted
    by the red lines. These errors are also called residuals. When calculating the
    MSE, we square these errors to remove any negative signs, as we are only concerned
    with the magnitude of the error and not its direction. The squaring also gives
    more weight to larger error values. Once all the squared errors have been calculated
    for all the data points, we calculate the mean, which gives us the final MSE value.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的回归场景，其中回归线穿过图表上绘制的数据点。训练好的模型根据这条回归线进行预测。误差值显示了实际值与预测值之间的差异，这些差异位于回归线上，如红色线条所示。这些误差也称为残差。在计算MSE时，我们平方这些误差以消除任何负号，因为我们只关心误差的大小，而不是其方向。平方也赋予了较大的误差值更多的权重。一旦计算了所有数据点的平方误差，我们就计算平均值，这给出了最终的MSE值。
- en: The MSE is a metric that tells you how close the line of regression is to the
    data points. Accordingly, the fewer error values the line of regression has against
    the data points, the lower your MSE value will be. Thus, when comparing the MSE
    of different models, the model with the lower MSE is ideally the more accurate
    one.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: MSE是一个指标，它告诉你回归线有多接近数据点。相应地，回归线与数据点之间的误差值越少，你的MSE值就越低。因此，在比较不同模型的MSE时，具有较低MSE的模型理想上是更准确的模型。
- en: 'The mathematical formula for the MSE is as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: MSE的数学公式如下：
- en: '![](img/Formula_B17298_06_001.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/Formula_B17298_06_001.png)'
- en: Here, *n* would be the number of data points in the dataset.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*n*将是数据集中的数据点数量。
- en: 'The **Root Mean Squared Error** (**RMSE**), as the name suggests, is the root
    value of the MSE. So accordingly, its mathematical formula is as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**均方根误差**（**RMSE**），正如其名所示，是均方误差的平方根。因此，其数学公式如下：'
- en: '![](img/Formula_B17298_06_002.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/Formula_B17298_06_002.png)'
- en: The difference between the MSE and the RMSE is straightforward. While the MSE
    is measured in the squared units of the response column, the RMSE is measured
    in the same units as the response column.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: MSE和RMSE之间的区别是直接的。虽然MSE是在响应列的平方单位中测量的，但RMSE是在与响应列相同的单位中测量的。
- en: For example, if you have a linear regression problem that predicts the price
    of its stock in terms of dollars, the MSE measures the errors in terms of squared
    dollars, while RMSE measures the error value as just dollars. Hence, the RMSE
    is often used over the MSE, as it is slightly easier to interpret the model quality
    from the RMSE than the MSE.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你有一个线性回归问题，它以美元为单位预测其股票的价格，MSE以平方美元为单位衡量误差，而RMSE将误差值仅以美元为单位衡量。因此，RMSE通常比MSE更容易解释模型质量。
- en: Congratulations – you are now aware of what MSE and RMSE metrics are and how
    they can be used to measure the performance of a regression model.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜——你现在已经了解了MSE和RMSE指标是什么以及它们如何用于衡量回归模型的性能。
- en: Let’s move on to the next important performance metric, which is the confusion
    matrix.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续到下一个重要的性能指标，即混淆矩阵。
- en: Working with the confusion matrix
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与混淆矩阵一起工作
- en: A classification problem is an ML problem where the ML model tries to classify
    the data inputs into the pre-specified classes. What makes the performance measurement
    of classification models different from regression models is that in classification
    problems, there is no numeric magnitude of the error between the predicted value
    and the actual value. The predicted value is either correctly classified into
    the right class or it is incorrectly classified. To measure model performance
    for classification problems, data scientists rely on certain performance metrics
    that are derived from a special type of matrix called a **confusion matrix**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 分类问题是一个机器学习问题，其中机器学习模型试图将数据输入分类到预指定的类别中。与回归模型相比，分类模型性能测量的不同之处在于，在分类问题中，预测值与实际值之间没有数值误差。预测值要么被正确分类到正确的类别，要么被错误分类。为了衡量分类问题的模型性能，数据科学家依赖于从称为**混淆矩阵**的特殊类型矩阵中派生出的某些性能指标。
- en: A confusion matrix is a tabular matrix that summarizes the correctness of the
    prediction results of a classification problem. The matrix presents the count
    of correct and incorrect predicted values alongside each other, as well as breaking
    them down by each class. This matrix is called a confusion matrix, as it shows
    how confused the model is when classifying the values.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵是一个表格矩阵，总结了分类问题的预测结果正确性。该矩阵并列展示了正确和错误的预测值，并按每个类别进行细分。这个矩阵被称为混淆矩阵，因为它显示了模型在分类值时的困惑程度。
- en: Consider the example of the heart disease prediction dataset we used. It is
    a binary classification problem where we want to predict whether a person with
    certain health conditions is likely to suffer from heart disease or not. In this
    case, the prediction is either **Yes**, also called a **positive classification**,
    meaning the person is likely to suffer from heart disease, or **No**, also called
    a **negative classification**, meaning the person is not likely to suffer from
    heart disease.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以我们使用的冠心病预测数据集为例。这是一个二元分类问题，我们想要预测具有某些健康条件的人是否可能患有冠心病。在这种情况下，预测结果是**是**，也称为**正分类**，意味着该人可能患有冠心病，或者**否**，也称为**负分类**，意味着该人不太可能患有冠心病。
- en: 'The confusion matrix of this scenario will be as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 该场景的混淆矩阵如下所示：
- en: '![](img/B17298_06_002.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_002.jpg)'
- en: Figure 6.2 – A binomial confusion matrix
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 二项式混淆矩阵
- en: The rows of the confusion matrix correspond to the classifications predicted
    by the model. The columns of the confusion matrix correspond to the actual class
    values of the model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵的行对应于模型预测的分类。混淆矩阵的列对应于模型的实际类值。
- en: In the top-left corner of the matrix, we have **true positives** – these are
    the number of **Yes** actuals that were correctly predicted as Yes. In the top-right
    corner, we have the **false positives** – these are the number of Yes actuals
    that were incorrectly predicted as **No**. In the bottom-left corner, we have
    **false negatives** – these are the number of No actuals that were incorrectly
    predicted as Yes values. And finally, we have the **true negative** – these are
    the number of No actuals that were correctly predicted as No.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在矩阵的左上角，我们有**真正例** – 这些是正确预测为“是”的实际“是”的数量。在右上角，我们有**假正例** – 这些是错误预测为“否”的实际“是”的数量。在左下角，我们有**假负例**
    – 这些是错误预测为“是”的实际“否”的数量。最后，我们还有**真负例** – 这些是正确预测为“否”的实际“否”的数量。
- en: 'The confusion matrix for a multinomial classification with six possible classes
    will look as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有六个可能类别的多项式分类，混淆矩阵将如下所示：
- en: '![](img/B17298_06_003.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_003.jpg)'
- en: Figure 6.3 – A multinomial confusion matrix
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – 多项式混淆矩阵
- en: Using the confusion matrix of two classification models, you can compare the
    number of true positives and true negatives that were predicted by the individual
    algorithms and select the one with the greater number of correct predictions as
    the better model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用两个分类模型的混淆矩阵，您可以比较个别算法预测的真正例和真负例的数量，并选择正确预测数量更多的模型作为更好的模型。
- en: Despite being very easy to interpret the prediction quality of a model using
    the confusion matrix, it is still difficult to compare two or more models solely
    based on the number of true positives and true negatives.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用混淆矩阵很容易解释模型的预测质量，但仅基于真正阳性和真正阴性的数量比较两个或多个模型仍然很困难。
- en: Consider a scenario where you want to classify some medical records to identify
    whether the patient has a brain tumor. Let’s assume that a specific model’s confusion
    matrix has a high number of true positives and true negatives compared to other
    models and also has a high number of false positives. In this case, the model
    will incorrectly flag a lot of normal medical records as indicative of a potential
    brain tumor. This might result in hospitals making incorrect decisions and performing
    risky surgeries that were never needed. In such a scenario, models with less accuracy
    but the smallest number of false positives are preferable.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个场景，你想要对一些医疗记录进行分类，以确定患者是否有脑瘤。假设一个特定模型的混淆矩阵相对于其他模型具有高数量的真正阳性和真正阴性，同时也有高数量的假阳性。在这种情况下，该模型将错误地将许多正常医疗记录标记为潜在脑瘤的迹象。这可能导致医院做出错误的决定，进行不必要的风险手术。在这种情况下，具有较低准确率但假阳性数量最少的模型更可取。
- en: 'Hence, more sophisticated metrics are developed on top of the confusion matrix.
    They are as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在混淆矩阵的基础上开发了更复杂的指标。它们如下：
- en: '**Accuracy**: Accuracy is a metric that measures the number of correctly predicted
    positive and negative predictions against the total number of predictions made.
    This is calculated as follows:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确度**：准确度是一个衡量与总预测数相比正确预测的阳性和阴性预测数的指标。计算方法如下：'
- en: '![](img/Formula_B17298_06_003.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/Formula_B17298_06_003.png)'
- en: 'Here, the abbreviations stand for the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，缩写代表以下内容：
- en: '**TP** stands for True Positive.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TP** 代表真正阳性。'
- en: '**TN** stands for True Negative.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TN** 代表真正阴性。'
- en: '**FP** stands for False Positive.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FP** 代表假阳性。'
- en: '**FN** stands for False Negative.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FN** 代表假阴性。'
- en: This metric is useful when you want to compare how well a classification model
    correctly makes predictions, irrespective of whether the prediction value is positive
    or negative.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想比较分类模型正确预测的能力，无论预测值是阳性还是阴性时，这个指标很有用。
- en: '**Precision**: Precision is a metric that measures the number of correct positive
    predictions made compared to the total number of positive predictions made. This
    is calculated as follows:'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确度**：精确度是一个衡量与总预测数相比正确阳性预测数的指标。计算方法如下：'
- en: '![](img/Formula_B17298_06_004.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/Formula_B17298_06_004.png)'
- en: This metric is especially useful when measuring the performance of a classification
    model that is trained on data with a high number of negative results and only
    a few positive results. Precision is not affected by the imbalance of positive
    and negative classification values, as it only considers positive values.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当测量在具有大量阴性结果和少量阳性结果的训练数据上训练的分类模型的性能时，这个指标特别有用。精确度不受正负分类值不平衡的影响，因为它只考虑阳性值。
- en: '**Sensitivity or recall**: Sensitivity, also known as recall, is a probability
    measurement for how well a model can predict true positives. Sensitivity is measured
    by identifying what percentage of predictions were correctly identified as positive
    in a binomial classification. This is calculated as follows:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**敏感性或召回率**：敏感性，也称为召回率，是衡量模型预测真正阳性的概率测量值。敏感性是通过识别在二项式分类中预测中被正确识别为阳性的预测百分比来衡量的。计算方法如下：'
- en: '![](img/Formula_B17298_06_005.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/Formula_B17298_06_005.png)'
- en: If your classification ML problem aims to accurately identify all the positive
    predictions, then the sensitivity of the model should be high.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的分类机器学习问题旨在准确识别所有正预测，那么模型的敏感性应该很高。
- en: '**Specificity**: While sensitivity is the probability measurement of how well
    a model can predict true positives, specificity is measured by identifying what
    percentage of predictions were correctly identified as negative in a binomial
    classification. This is calculated as follows:'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特异性**：虽然敏感性是衡量模型预测真正阳性的概率测量值，但特异性是通过识别在二项式分类中被正确识别为阴性的预测百分比来衡量的。计算方法如下：'
- en: '![](img/Formula_B17298_06_006.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/Formula_B17298_06_006.png)'
- en: If your classification ML problem aims to accurately identify all the negative
    predictions, then the specificity of the model should be high.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的分类机器学习问题旨在准确识别所有负预测，那么模型的特异性应该很高。
- en: There is always a trade-off between sensitivity and specificity. A model with
    high sensitivity will often have very low specificity and vice versa. Thus, the
    context of the ML problem plays a very important part in deciding whether you
    want a model with high sensitivity or high specificity to solve the problem.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感度和特异性之间始终存在权衡。一个具有高敏感度的模型通常具有非常低的特异性，反之亦然。因此，机器学习问题的上下文在决定你是否想要一个具有高敏感度或高特异性的模型来解决问题中起着非常重要的作用。
- en: For multinomial classification, you calculate the sensitivity and specificity
    for each class type. For sensitivity, your true positives will remain the same,
    but the false negatives will change depending on the number of incorrect predictions
    made for that class. Similarly, for specificity, the true negatives will remain
    the same – however, the false positives will change depending on the number of
    incorrect predictions made for that class.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多项式分类，你需要为每个类别类型计算敏感度和特异性。对于敏感度，你的真正例将保持不变，但假阴性将根据对该类别的错误预测数量而变化。同样，对于特异性，真正例将保持不变——然而，假阳性将根据对该类别的错误预测数量而变化。
- en: Now that you have understood how a confusion matrix is used for measuring classification
    models and how sensitivity and specificity are built on top of it, let’s now move
    on to the next metric, which is the receiver operating characteristic curve and
    its area under the curve.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了如何使用混淆矩阵来衡量分类模型，以及敏感度和特异性是如何建立在它之上的，那么我们现在继续到下一个指标，即受试者工作特征曲线及其曲线下面积。
- en: Calculating the receiver operating characteristic and its area under the curve
    (ROC-AUC)
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算受试者工作特征及其曲线下面积（ROC-AUC）
- en: Another good way of comparing classification models is via a visual representation
    of their performance. One of the most widely used visual evaluation metrics is
    the **Receiver Operating Characteristic** and its **Area Under the Curve** (**ROC-AUC**).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 比较分类模型的另一种好方法是通过对它们性能的视觉表示。最广泛使用的视觉评估指标之一是**受试者工作特征**及其**曲线下面积**（**ROC-AUC**）。
- en: 'The ROC-AUC metric is split into two concepts:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ROC-AUC指标分为两个概念：
- en: '**The ROC curve**: This is the graphical curve plotted on a graph that summarizes
    the model’s classification ability at various thresholds. The threshold is a classification
    value that separates the data points into different classes.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ROC曲线**：这是在图表上绘制的图形曲线，总结了模型在各个阈值下的分类能力。阈值是一个分类值，用于将数据点分为不同的类别。'
- en: '**AUC**: This is the area under the ROC curve that helps us compare which classification
    algorithm performed better depending on whose ROC curve covers the most area.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AUC**：这是ROC曲线下的面积，帮助我们比较哪个分类算法表现更好，取决于哪个ROC曲线覆盖的面积最大。'
- en: 'Let’s consider an example to better understand how ROC-AUC can help us compare
    classification models. Refer to the following sample dataset:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来更好地理解ROC-AUC如何帮助我们比较分类模型。参考以下样本数据集：
- en: '![](img/B17298_06_004.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_004.jpg)'
- en: Figure 6.4 – An obesity dataset
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 肥胖数据集
- en: 'This dataset has two columns:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集有两个列：
- en: '**Weight (kgs)**: This is a numerical column that contains the weight of a
    person in kilograms'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**体重（千克）**：这是一个数值列，包含一个人的体重（千克）'
- en: '**Obese**: This is a categorical column that contains either **1** or **0**,
    where **1** indicates the person is obese and **0** indicates that the person
    is not obese'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**肥胖**：这是一个分类列，包含**1**或**0**，其中**1**表示该人肥胖，**0**表示该人非肥胖'
- en: 'Let’s plot this dataset onto a graph where **Weight**, being the independent
    variable, is on the *x*-axis, and **Obese**, being the dependent variable, is
    on the *y*-axis. This simple dataset on a graph will look as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个数据集绘制到图表上，其中**体重**作为自变量位于*x*轴上，**肥胖**作为因变量位于*y*轴上。这个简单的数据集在图表上看起来如下：
- en: '![](img/B17298_06_005.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_005.jpg)'
- en: Figure 6.5 – The plotted obesity dataset
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 绘制的肥胖数据集
- en: Let’s fit a classification line through this data using one of the simplest
    classification algorithms called **logistic regression**. Logistic regression
    is an algorithm that predicts the probability that a given sample of data belongs
    to a certain class. In our example, the algorithm will predict the probability
    of whether the person is obese or not depending on their weight.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一种称为**逻辑回归**的简单分类算法之一，通过这些数据拟合一个分类线。逻辑回归是一种预测给定数据样本属于某个特定类的概率的算法。在我们的例子中，该算法将根据体重预测一个人是否肥胖的概率。
- en: 'The logistic regression line will look as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归线将如下所示：
- en: '![](img/B17298_06_006.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17298_06_006.jpg)'
- en: Figure 6.6 – A plotted obesity dataset with a classification line
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 – 使用分类线绘制的肥胖数据集
- en: Note that since logistic regression predicts the probability that data might
    belong to a certain class, we have converted the *y*-axis into the probability
    that the person is obese.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于逻辑回归预测数据可能属于某个特定类的概率，我们已经将*y*轴转换为一个人肥胖的概率。
- en: During prediction, we will first plot the sample weight data of the person on
    the *x*-axis. We will then find its respective *y* value on the line of classification.
    This value is the probability that the respective person is obese.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测期间，我们首先将人的样本体重数据绘制在*x*轴上。然后，我们将在分类线上找到其相应的*y*值。这个值是相应的人肥胖的概率。
- en: 'Now, to classify whether the person is obese or not, we will need to decide
    what the probability **cut-off line** that separates obese and not obese will
    be. This cut-off line is called the **threshold**. Any probability value above
    the threshold can be categorized as obese and any value below it can be categorized
    as not obese. The threshold can be any value between 0 and 1:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了判断一个人是否肥胖，我们需要决定将肥胖和非肥胖区分开来的概率**截止线**是什么。这条截止线被称为**阈值**。任何高于阈值的概率值都可以被归类为肥胖，而任何低于阈值的值都可以被归类为非肥胖。阈值可以是0到1之间的任何值：
- en: '![](img/B17298_06_007.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17298_06_007.jpg)'
- en: Figure 6.7 – An obesity dataset classification with a threshold line
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 – 使用阈值线对肥胖数据集进行分类
- en: As you can see from the diagram, multiple values are incorrectly classified.
    This is bound to happen in any classification problem. So, to keep a track of
    the correct and incorrect classification, we will create a confusion matrix and
    calculate sensitivity and specificity to evaluate how well the model performs
    for the selected threshold.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从图中可以看出，多个值被错误地分类。这在任何分类问题中都是不可避免的。因此，为了跟踪正确和错误的分类，我们将创建一个混淆矩阵，并计算灵敏度和特异性来评估模型在所选阈值下的表现。
- en: But as mentioned previously, there can be many thresholds for classification.
    Thresholds with high values will minimize the number of false positives but the
    trade-off is that classification for that class will become stricter, leading
    to more false negatives. Similarly, if the threshold value is too low, then we
    will end up with more False Positives.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 但如前所述，分类可以有多个阈值。具有高值的阈值将最小化假阳性的数量，但代价是分类将变得更加严格，导致更多的假阴性。同样，如果阈值值太低，那么我们最终会得到更多的假阳性。
- en: Which threshold performs best depends on your ML problem. However, a comparative
    study of different thresholds is needed to find a suitable value. Since you can
    create any number of thresholds, you will end up creating plenty of confusion
    matrices eventually. This is where the ROC-AUC metric comes in.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 哪个阈值表现最好取决于你的机器学习问题。然而，需要比较不同阈值的研究来找到一个合适的值。由于你可以创建任意数量的阈值，你最终会创建大量的混淆矩阵。这就是ROC-AUC指标发挥作用的地方。
- en: The ROC-AUC metric summarizes the performance of the model at different thresholds
    and plots them on a graph. In this graph, the *x*-axis is the False Positive rate,
    which is **1 - specificity**, while the *y*-axis is the true positive rate, which
    is nothing but **sensitivity**.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ROC-AUC指标总结了模型在不同阈值下的性能，并在图上绘制它们。在这个图中，*x*轴是**假阳性率**，即**1 - 特异性**，而*y*轴是**真阳性率**，也就是**灵敏度**。
- en: 'Let’s plot the ROC graph for our sample dataset. We will start by using a threshold
    that classifies all samples as obese. The threshold on the graph will look as
    follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制我们的样本数据集的ROC图。我们将从使用一个将所有样本归类为肥胖的阈值开始。图上的阈值将如下所示：
- en: '![](img/B17298_06_008.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17298_06_008.jpg)'
- en: Figure 6.8 – A plotted obesity classification with a very low threshold
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 – 使用非常低的阈值绘制的肥胖分类
- en: 'We will now need to calculate the sensitivity (and 1 - specificity) values
    needed to plot our ROC curve, so accordingly, we will need to create a confusion
    matrix first. The confusion matrix for this threshold will look as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要计算绘制ROC曲线所需的敏感性（和1 - 特异性）值，因此相应地，我们首先需要创建一个混淆矩阵。这个阈值的混淆矩阵看起来如下：
- en: '![](img/B17298_06_009.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17298_06_009.jpg)'
- en: Figure 6.9 – A confusion matrix with sensitivity and 1 - specificity
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9 – 包含敏感性和1 - 特异性的混淆矩阵
- en: 'Calculating the sensitivity and 1 - specificity values using the formula mentioned
    previously, we get a sensitivity equal to **1** and a 1 - specificity equal to
    **0.5**. Let’s plot this value in the ROC graph. The ROC graph will look as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前提到的公式计算敏感性和1 - 特异性值，我们得到一个等于**1**的敏感性和一个等于**0.5**的1 - 特异性。让我们在ROC图上绘制这个值。ROC图将看起来如下：
- en: '![](img/B17298_06_010.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17298_06_010.jpg)'
- en: Figure 6.10 – The ROC graph
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10 – ROC图
- en: The blue line in the diagram indicates that the sensitivity is equal to the
    1 - specificity – in other words, the true positive rate is equal to the False
    Positive rate. Any ROC points on this line indicate that the model trained using
    this threshold has an equal likelihood of predicting a correct positive as predicting
    an incorrect positive. So, to find the best threshold, we aim to find a ROC point
    that has as high a sensitivity as possible and as low a 1 - specificity as possible.
    This would indicate that the model has a high likelihood of predicting a correct
    positive prediction and a much smaller likelihood of predicting an incorrect positive
    prediction.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中的蓝色线表示敏感性等于1 - 特异性——换句话说，真正阳性率等于假阳性率。任何位于这条线上的ROC点都表明，使用此阈值训练的模型预测正确阳性的可能性与预测错误阳性的可能性相同。因此，为了找到最佳阈值，我们旨在找到一个具有尽可能高的敏感性和尽可能低的1
    - 特异性的ROC点。这将表明模型有很高的可能性预测正确的阳性预测，并且预测错误阳性的可能性要小得多。
- en: 'Let’s now raise the threshold and repeat the same process to calculate the
    ROC value for this new threshold. Let’s assume this new threshold has a sensitivity
    of 1 and a 1 - specificity of 0.25\. Plotting this value in the ROC graph, we
    get the following result:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们提高阈值并重复相同的过程来计算这个新阈值的ROC值。让我们假设这个新阈值的敏感性为1，1 - 特异性为0.25。在ROC图上绘制这个值，我们得到以下结果：
- en: '![](img/B17298_06_011.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17298_06_011.jpg)'
- en: Figure 6.11 – A ROC graph with the new threshold
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11 – 使用新阈值的ROC图
- en: The new ROC value for the new threshold is on the left side of the blue line
    and also of the previous ROC point. This indicates that it has a lower false positive
    rate compared to the previous threshold. Thus, the new threshold is better than
    the previous one.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 新阈值的ROC值位于蓝色线的左侧，也位于之前的ROC点。这表明它比之前的阈值具有更低的假阳性率。因此，新的阈值比之前的阈值更好。
- en: Raising the threshold value way too high will make the model predict that all
    the values are not obese. Basically, it will incorrectly predict all the values
    as false, increasing the number of false negatives. Based on the sensitivity equation,
    the higher the number of false negatives, the lower the sensitivity. So, this
    will eventually lower your sensitivity, reducing the model’s ability to predict
    the true positives.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 将阈值值调得过高会导致模型预测所有值都不是肥胖的。基本上，它将错误地将所有值预测为假，增加了假阴性的数量。根据敏感性方程，假阴性的数量越多，敏感性越低。因此，这最终会降低您的敏感性，减少模型预测真正阳性的能力。
- en: 'We repeat this same process for different threshold values and plot their ROC
    values on the ROC graph. If we connect all these dots, we get the ROC curve:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会为不同的阈值值重复进行相同的过程，并在ROC图上绘制它们的ROC值。如果我们连接所有这些点，我们得到ROC曲线：
- en: '![](img/B17298_06_012.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17298_06_012.jpg)'
- en: Figure 6.12 – The ROC graph with a ROC curve
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.12 – 包含ROC曲线的ROC图
- en: Just by looking at the ROC graph, you can identify which threshold values are
    better than the others, and depending on how many false positive predictions your
    ML problem can tolerate, you can select the ROC point with the right false positive
    rate as your final threshold value reference. This explains what the ROC curve
    does.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 只需通过观察ROC图，就可以确定哪些阈值值比其他阈值值更好，并且根据你的机器学习问题可以容忍多少假阳性预测，你可以选择具有正确假阳性率的ROC点作为你的最终阈值值参考。这解释了ROC曲线的作用。
- en: 'Now, suppose you have another algorithm trained with different thresholds and
    you plot its ROC points on this same graph. Assume the plots look as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设你有一个使用不同阈值训练的另一个算法，你将它的ROC点绘制到这个相同的图上。假设绘制结果如下：
- en: '![](img/B17298_06_013.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_013.jpg)'
- en: Figure 6.13 – A ROC graph with multiple ROC curves
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.13 – 带有多个ROC曲线的ROC图
- en: How would you compare which algorithm performed better? Which threshold is the
    optimum one for that algorithm’s model?
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 你会如何比较哪个算法表现更好？哪个阈值是该算法模型的最佳选择？
- en: 'This is where AUC helps us. AUC is nothing but the area under the ROC curve.
    The whole ROC graph will have a total area of *1*. The red line splits the area
    into half, so ideally, all potentially good algorithms should have an AUC greater
    than 0.5\. The greater the AUC is, the better the algorithm is:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是AUC帮助我们的地方。AUC不过是ROC曲线下的面积。整个ROC图将有一个总面积为*1*。红色线将面积分成两半，因此理想情况下，所有潜在的好算法都应该有大于0.5的AUC。AUC值越大，算法越好：
- en: '![](img/B17298_06_014.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_014.jpg)'
- en: Figure 6.14 – The AUC of the ROC curve
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.14 – ROC曲线的AUC
- en: Just by visualizing this, you can see which algorithm is better from its AUC.
    Similarly, the AUC values help engineers and scientists identify which algorithm
    to choose and which threshold to use as the optimal ML model for classification.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 只需通过可视化，你就可以看到哪个算法的AUC值更高。同样，AUC值帮助工程师和科学家确定选择哪个算法以及使用哪个阈值作为最佳机器学习模型进行分类。
- en: Congratulations, you just understood how the ROC-AUC metric works and how it
    can help you compare model performance. Let’s now move on to another similar performance
    metric called the **Precision-Recall curve** (**PR curve**).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你，你现在已经理解了ROC-AUC指标的工作原理以及它是如何帮助你比较模型性能的。现在，让我们继续介绍另一个类似性能指标，称为**精确率-召回率曲线**（**PR曲线**）。
- en: Calculating the precision-recall curve and its area under the curve (AUC-PR)
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算精确率-召回率曲线及其曲线下面积（AUC-PR）
- en: With ROC-AUC, despite being a very good metric to compare models, there is a
    minor drawback to relying on it exclusively. In a very imbalanced dataset, where
    there is a large number of true negative values, the *x*-axis of the ROC graph
    will be very small, as specificity has a true negative value as its denominator.
    This forces the ROC curve toward the left side of the graph, raising the ROC-AUC
    value toward 1, which is technically incorrect.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用ROC-AUC，尽管这是一个非常好的比较模型的指标，但完全依赖它也存在一些小缺点。在一个非常不平衡的数据集中，其中存在大量真实负值，ROC图的*x*轴将会非常小，因为特异性以真实负值为分母。这迫使ROC曲线向图的左侧移动，使得ROC-AUC值接近1，这在技术上是不正确的。
- en: This is where the **PR curve** proves beneficial. The PR curve is similar to
    the ROC curve, the only difference being that the PR curve is a function that
    uses precision on the *y*-axis and recall on the *x*-axis. Neither precision nor
    recall uses true negatives in their calculation. Hence, the PR curve and its AUC
    metric are suitable when there is an imbalance in the classes of the dataset that
    impacts the true negatives during prediction, or when your ML problem is not concerned
    with true negatives at all.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是PR曲线发挥作用的地方。PR曲线与ROC曲线类似，唯一的区别是PR曲线是一个函数，它在*y*轴上使用精确率，在*x*轴上使用召回率。精确率和召回率的计算都不使用真实负值。因此，当数据集的类别不平衡影响预测中的真实负值，或者当你的机器学习问题根本不关心真实负值时，PR曲线及其AUC指标是合适的。
- en: Let’s understand the PR curve further using an example. We will use the same
    sample obesity dataset that we used for understanding the ROC-AUC curve. The process
    of plotting the records of the dataset on the graph and creating its confusion
    matrix is the same as for the ROC-AUC curve.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子进一步了解PR曲线。我们将使用与理解ROC-AUC曲线相同的样本肥胖数据集。将数据集的记录绘制到图上并创建其混淆矩阵的过程与ROC-AUC曲线相同。
- en: 'Now, instead of calculating the sensitivity and 1 – specificity from the confusion
    matrix, this time, we shall calculate the precision and recall values:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不再从混淆矩阵中计算敏感度和1 – 特异性，而是这次我们将计算精确率和召回率值：
- en: '![](img/B17298_06_015.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_015.jpg)'
- en: Figure 6.15 – Calculating the precision and recall values
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.15 – 计算精确率和召回率值
- en: 'As you can see from the preceding diagram, we got precision values of **0.625**
    and recall values of **1**. Let’s plot these values onto the PR graph as shown
    in the following diagram:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，我们得到了精确率为**0.625**和召回率为**1**。让我们将这些值绘制到下面的PR图中，如图所示：
- en: '![](img/B17298_06_016.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_016.jpg)'
- en: Figure 6.16 – The PR graph
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.16 – PR图
- en: 'Similarly, by moving the threshold line and creating the new confusion matrix,
    the precision and recall values will change based on the distribution of the predictions
    in the confusion matrix. We repeat this same process for different threshold values,
    calculate the precision and recall values, and then plot them onto the PR graph:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，通过移动阈值线并创建新的混淆矩阵，精确度和召回率值将根据混淆矩阵中预测的分布而变化。我们重复这个过程，为不同的阈值值计算精确度和召回率值，然后将它们绘制到PR图上：
- en: '![](img/B17298_06_017.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_017.jpg)'
- en: Figure 6.17 – A PR graph and its PR curve
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.17 – PR图及其PR曲线
- en: The blue line that joins all the points is the PR curve. The point that represents
    a threshold value closest to the black point, so closest to having a precision
    value of 1 and a recall value of 1, is the ideal classifier.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 连接所有点的蓝色线是PR曲线。代表阈值值最接近黑色点的点，即最接近具有1的精确度和1的召回率的理想分类器。
- en: 'When comparing different algorithm models, you will have multiple PR curves
    in the PR graph:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当比较不同的算法模型时，你将在PR图中看到多个PR曲线：
- en: '![](img/B17298_06_018.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17298_06_018.jpg)'
- en: Figure 6.18 – A PR graph with multiple PR curves
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.18 – 包含多个PR曲线的PR图
- en: The preceding diagram shows you the multiple PR curves that can be plotted on
    the same graph to give you a better comparative view of the performances of different
    algorithms. With one glance, you can see that the algorithm represented by the
    blue line has a threshold value that is closest to the black point and should
    ideally be the best performing model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表显示了可以在同一图表上绘制的多个PR曲线，以提供不同算法性能的更好比较视图。只需一眼，你就可以看到代表蓝色线的算法的阈值值最接近黑色点，理想情况下应该是性能最好的模型。
- en: Just as with ROC-AUC, you can also use the AUC-PR to calculate the area under
    the PR curves to get a better understanding of the performances of different algorithms.
    Based on this, you know that the algorithm represented by the red PR curve is
    better than the one with the yellow curve and the algorithm represented by the
    blue PR curve is better than both the red and yellow curves.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 就像ROC-AUC一样，你也可以使用AUC-PR来计算PR曲线下的面积，以更好地理解不同算法的性能。基于此，你知道代表红色PR曲线的算法比代表黄色曲线的算法好，代表蓝色PR曲线的算法比红色和黄色曲线的算法都要好。
- en: Congratulations! You now understand the AUC-PR metric in the H2O AutoML leaderboard
    and how it can be another good model performance metric that you can refer to
    when comparing models trained by H2O AutoML.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你现在已经理解了H2O AutoML排行榜中的AUC-PR指标，以及它如何成为另一个良好的模型性能指标，在比较由H2O AutoML训练的模型时可以参考。
- en: Let’s now move on to the next performance metric, which is called log loss.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们继续讨论下一个性能指标，它被称为对数损失。
- en: Working with log loss
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对数损失的工作原理
- en: '**Log loss** is another important model performance metric for classification
    models. It is primarily used to measure the performance of binary classification
    models.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**对数损失**是分类模型的重要模型性能指标之一。它主要用于衡量二元分类模型的性能。'
- en: Log loss is a way of measuring the performance of a classification model that
    outputs classification results in the form of probability values. The probability
    values can range from *0*, which means that the data has zero probability that
    it belongs to a certain positive class, to *1*, which means the data has a 100%
    chance of belonging to a certain positive class. The log loss value can range
    from 0 to infinity and the goal of all ML models is to minimize the log loss as
    much as possible. Any model with a log loss value as close to 0 as possible is
    regarded as the better performing model.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失是衡量分类模型性能的一种方式，该模型以概率值的形式输出分类结果。概率值可以从*0*开始，表示数据属于某个特定正类的概率为零，到*1*结束，表示数据属于某个特定正类的概率为100%。对数损失值可以从0延伸到无穷大，所有机器学习模型的目的是尽可能最小化对数损失。任何对数损失值尽可能接近0的模型都被认为是性能更好的模型。
- en: Log loss calculation is entirely statistical. However, it is important to understand
    the intuition behind the mathematics to better understand its application when
    comparing model performances.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失的计算完全是统计性的。然而，理解数学背后的直觉对于更好地理解其在比较模型性能时的应用非常重要。
- en: Log loss is a metric that measures the divergence of the predicted probability
    from the actual value. So, if the predicted probability diverges very little from
    the actual value, then your log loss value will be forgiving – however, if the
    divergence is greater, the log loss value will be that much more punishing.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失是一个衡量预测概率与实际值之间差异的指标。因此，如果预测概率与实际值差异很小，那么你的对数损失值将会很宽容；然而，如果差异更大，对数损失值将会更加惩罚性。
- en: 'Let’s start by understanding what prediction probability is. We shall use the
    same obesity dataset that we used for the ROC-AUC curve. Assume we ran a classification
    algorithm that calculated the prediction probability that the person is obese
    and let’s add those values to a column in the dataset, as seen in the following
    screenshot:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先了解预测概率是什么。我们将使用与 ROC-AUC 曲线相同的肥胖数据集。假设我们运行了一个分类算法，计算了预测该人肥胖的概率，并将这些值添加到数据集的列中，如下截图所示：
- en: '![](img/B17298_06_019.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17298_06_019.jpg)'
- en: Figure 6.19 – The obesity dataset with the prediction probabilities added
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.19 – 添加了预测概率的肥胖数据集
- en: We will have a certain threshold value that decides what the prediction probability
    value has to be for us to classify the data as obese or not obese. Let’s assume
    the threshold is 0.5 – in this case, a prediction probability value above 0.5
    is classified as obese and anything below it is classified as not obese.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将有一个特定的阈值值，用于决定预测概率值必须是多少，我们才能将数据分类为肥胖或非肥胖。让我们假设阈值为 0.5 - 在这种情况下，预测概率值高于 0.5
    被分类为肥胖，任何低于它的都被分类为非肥胖。
- en: 'We now calculate the log loss value of each data point. The equation for calculating
    the log loss of each record is as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在计算每个数据点的对数损失值。计算每个记录对数损失的公式如下：
- en: '![](img/Formula_B17298_06_007.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B17298_06_007.png)'
- en: 'Here, the equation can be broken down as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，方程可以分解如下：
- en: '**y** is the actual classification value, that is, *0* or *1*.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**y** 是实际分类值，即 *0* 或 *1*。'
- en: '**p** is the prediction probability.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**p** 是预测概率。'
- en: '**log** is the natural logarithm of the number.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**log** 是数字的自然对数。'
- en: 'In our example, since we are using the obese class as a reference, we shall
    set *y* to *1*. Using this equation, we calculate the log loss value of individual
    data values as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，因为我们使用肥胖类别作为参考，所以我们将 *y* 设置为 *1*。使用这个公式，我们计算单个数据值的对数损失值如下：
- en: '![Figure 6.20 – An obesity dataset with the log loss values per record ](img/B17298_06_020.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 6.20 – 每条记录的对数损失值的肥胖数据集 ](img/B17298_06_020.jpg)'
- en: Figure 6.20 – An obesity dataset with the log loss values per record
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.20 – 每条记录的对数损失值的肥胖数据集
- en: 'Now, let’s plot these values into a log loss graph where we set the log loss
    values on the *y*-axis and the prediction probability on the *x*-axis:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将这些值绘制到对数损失图中，我们将对数损失值放在 *y* 轴上，预测概率放在 *x* 轴上：
- en: '![Figure 6.21 – A log loss graph where y = 1 ](img/B17298_06_021.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 6.21 – 对数损失图，其中 y = 1 ](img/B17298_06_021.jpg)'
- en: Figure 6.21 – A log loss graph where y = 1
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.21 – 对数损失图，其中 y = 1
- en: You will notice that the log loss value exponentially rises as the predicted
    probability diverges away from the actual value. The lesser the divergence, the
    less the increase in log loss will be. This is what makes log loss a good comparison
    metric, as it compares not only which model is good or bad but also how good or
    bad it is.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，随着预测概率偏离实际值，对数损失值呈指数增长。差异越小，对数损失的增幅就越小。这就是为什么对数损失是一个好的比较指标，因为它不仅比较哪个模型是好是坏，还比较它有多好或多坏。
- en: 'Similarly, if you wanted to use the not obese class as a reference for log
    loss, then you would inverse the prediction probabilities, calculate the log loss
    values, and plot the graph, or you could just calculate the log loss value by
    setting *y* to 0 and use the log loss values calculated to plot the log loss graph.
    This graph will be a mirror image of the previous graph (*see Figure 6.21*):'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果你想使用非肥胖类别作为对数损失的参考，那么你需要反转预测概率，计算对数损失值，并绘制图表，或者你也可以将 *y* 设置为 0 并使用计算出的对数损失值绘制对数损失图。这个图将是之前图的镜像（*见图
    6.21*）：
- en: '![Figure 6.22 – A log loss graph where y = 0 ](img/B17298_06_022.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 6.22 – 对数损失图，其中 y = 0 ](img/B17298_06_022.jpg)'
- en: Figure 6.22 – A log loss graph where y = 0
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.22 – 对数损失图，其中 y = 0
- en: 'The log loss value of the model, also called the **skill** of the model, is
    the average of the log loss values for all the records in the dataset. Accordingly,
    the equation for the log loss of the model is as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的 log 损失值，也称为模型的 **技能**，是数据集中所有记录的 log 损失值的平均值。因此，模型 log 损失的方程如下：
- en: '![](img/Formula_B17298_06_008.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/Formula_B17298_06_008.png)'
- en: 'Here, the equation can be broken down as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，方程可以分解如下：
- en: '**n** is the total number of records in the dataset.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**n** 是数据集中的总记录数。'
- en: '**y** is the actual classification value, that is, *0* or *1*.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**y** 是实际的分类值，即 *0* 或 *1*。'
- en: '**p** is the prediction probability.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**p** 是预测概率。'
- en: '**log** is the natural logarithm of the number.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**log** 是数字的自然对数。'
- en: In an ideal world, a model with perfect scoring capabilities and skills is said
    to have a log loss equal to *0*. To correctly apply log loss to compare models,
    both models must be trained using the same dataset.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个理想的世界里，具有完美评分能力和技能的模型被认为具有等于 *0* 的 log 损失。为了正确应用 log 损失来比较模型，两个模型都必须使用相同的训练数据集进行训练。
- en: Congratulations! We have just covered how log loss is statistically calculated.
    In the next section, we shall explore some other important metrics that are not
    a part of the H2O AutoML leaderboard but are nonetheless important in terms of
    understanding model performance.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！我们刚刚介绍了如何从统计角度计算 log 损失。在下一节中，我们将探讨一些其他重要的指标，这些指标虽然不是 H2O AutoML 排行榜的一部分，但在理解模型性能方面仍然很重要。
- en: Exploring other model performance metrics
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索其他模型性能指标
- en: The H2O AutoML leaderboard summarizes the model performances based on certain
    commonly used important metrics. However, there are still plenty of performance
    metrics in the field of ML that describe different skills of the ML model. These
    skills can often be the deciding factor in what works best for your given ML problem
    and hence, it is important that we are aware of how we can use these different
    metrics. H2O also provides us with these metrics values by computing them once
    training is finished and storing them as the model’s metadata. You can easily
    access them using built-in functions.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: H2O AutoML 排行榜基于某些常用的重要指标总结了模型性能。然而，在机器学习领域，仍然有许多性能指标描述了机器学习模型的不同技能。这些技能往往是你给定机器学习问题中什么工作得最好的决定因素，因此，了解我们如何使用这些不同的指标是很重要的。H2O
    还通过在训练完成后计算这些指标并将它们存储为模型的元数据来为我们提供这些指标值。你可以通过使用内置函数轻松访问它们。
- en: In the following subsections, we shall explore some of the other important model
    performance metrics, starting with F1.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将探讨一些其他重要的模型性能指标，从 F1 开始。
- en: Understanding the F1 score performance metric
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 F1 分数性能指标
- en: Precision and recall, despite being very good metrics to measure a classification
    model’s performance, have a trade-off. Precision and recall cannot both have high
    values at the same time. If you increase the precision by adjusting your classification
    threshold, then it impacts your recall, as the number of false negatives might
    increase, reducing your recall value, and vice versa.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 精确率和召回率，尽管是衡量分类模型性能的非常好的指标，但存在权衡。精确率和召回率不能同时具有高值。如果你通过调整分类阈值来提高精确率，那么它会影响你的召回率，因为假阴性的数量可能会增加，从而降低你的召回率值，反之亦然。
- en: The precision metric works to minimize incorrect predictions, while the recall
    metric works to find the greatest number of positive predictions. So, technically,
    we need to find the right balance between these two metrics.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度指标旨在最小化错误预测，而召回率指标旨在找到最多的积极预测。因此，技术上，我们需要在这两个指标之间找到正确的平衡。
- en: This is where the **F1 score** performance metric comes into the picture. The
    F1 score is a metric that tries to maximize both precision and recall at the same
    time and gives an overall score for the model’s performance.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 **F1 分数** 性能指标出现的地方。F1 分数是一个试图同时最大化精确率和召回率的指标，并为模型性能给出一个总体分数。
- en: The F1 score is the harmonic mean of the precision and recall values. **The
    harmonic mean** is just one of the variations for calculating the mean of values.
    With the harmonic mean, we calculate the reciprocal of the arithmetic mean of
    the reciprocals of all the observations. The reason we use a harmonic mean for
    calculating the F1 score is that using a general arithmetic mean would lead to
    the equation giving equal importance to all degrees of error. The harmonic mean,
    on the other hand, punishes high values of error by lowering the F1 score accordingly.
    This is the reason why the harmonic mean is used to generate the F1 score, as
    the score value calculated gives a better representation of the model’s performance.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数是精确度和召回率的调和平均值。**调和平均值**是计算值平均值的多种变体之一。使用调和平均值，我们计算所有观察值的倒数算术平均数的倒数。我们使用调和平均值来计算F1分数的原因是，使用一般的算术平均值会导致方程对所有程度的错误给予同等的重要性。另一方面，调和平均值通过相应地降低F1分数来惩罚高误差值。这就是为什么使用调和平均值生成F1分数的原因，因为计算出的分数值能更好地表示模型的性能。
- en: The F1 score ranges from 0 to 1, where 1 indicates that the model has perfect
    precision and recall values, while 0 indicates that either the precision or recall
    value is 0.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数的范围是0到1，其中1表示模型具有完美的精确度和召回率值，而0表示精确度或召回率值之一为0。
- en: 'The equation for calculating the F1 score is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 计算F1分数的公式如下：
- en: '![](img/Formula_B17298_06_009.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_009](img/Formula_B17298_06_009.png)'
- en: 'Let’s take the example of a confusion matrix as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个混淆矩阵为例：
- en: '![Figure 6.23 – An example confusion matrix with precision and recall values
    ](img/B17298_06_023.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图6.23 – 带有精确度和召回率的示例混淆矩阵](img/B17298_06_023.jpg)'
- en: Figure 6.23 – An example confusion matrix with precision and recall values
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.23 – 带有精确度和召回率的示例混淆矩阵
- en: 'Let’s calculate the precision value for the matrix:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算矩阵的精确度值：
- en: '![](img/Formula_B17298_06_010.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_010](img/Formula_B17298_06_010.png)'
- en: 'Similarly, lets now calculate the recall value of the matrix:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，现在让我们计算矩阵的召回率值：
- en: '![](img/Formula_B17298_06_011.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_011](img/Formula_B17298_06_011.png)'
- en: 'Now, plugging the precision and recall values into the F1 score equation, we
    get the following:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将精确度和召回率的值代入F1分数公式中，我们得到以下结果：
- en: '![](img/Formula_B17298_06_012.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_012](img/Formula_B17298_06_012.png)'
- en: We got an F1 score of *0.15*. You can now compare the performance of another
    model by similarly calculating its F1 score and comparing it to this one. If the
    F1 score of the new model is greater than *0.15*, then that model is more performant
    than this one.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一个F1分数为*0.15*。你现在可以通过类似地计算另一个模型的F1分数并将其与这个分数进行比较来比较另一个模型的性能。如果新模型的F1分数大于*0.15*，那么该模型比这个模型表现更好。
- en: The benefit of the F1 score is that when comparing classification models, you
    don’t need to balance the precision and recall values of multiple models and make
    a decision based on the comparisons between two contrasting metrics. The F1 score
    summarizes the optimum values of precision and recall, making it easier to identify
    which model is better.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数的好处是，在比较分类模型时，你不需要平衡多个模型的精确度和召回率值，并基于两个对比指标的比较做出决定。F1分数总结了精确度和召回率的最佳值，这使得更容易确定哪个模型更好。
- en: Despite being a good metric, the F1 score still has certain drawbacks. Firstly,
    the F1 score does not consider true negatives when calculating the score. Secondly,
    the F1 Score does not adequately capture the performance of a multi-class classification
    problem. You can technically calculate the F1 score for multi-class classification
    problems using macro-averaging – however, there are better metrics that can be
    used instead.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管是一个好的指标，但F1分数仍然存在某些缺点。首先，F1分数在计算分数时没有考虑真正的负例。其次，F1分数不足以捕捉多类分类问题的性能。技术上，你可以使用宏平均来计算多类分类问题的F1分数——然而，有更好的指标可以使用。
- en: Let’s look at one such metric that overcomes the drawbacks of the F1 score,
    which is the absolute Matthews correlation coefficient.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一种克服F1分数缺点的指标，即绝对马修斯相关系数。
- en: Calculating the absolute Matthews correlation coefficient
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算绝对马修斯相关系数
- en: 'Consider an example where we are trying to predict, based on a given fruit’s
    size, whether it is a grape or a watermelon. We have 200 samples, out of which
    180 are grapes and 20 are watermelon. Pretty simple, yes – the bigger the size,
    the more likely it is to be a watermelon, while a smaller size indicates it is
    a grape. Assume that we trained a classifier taking the grape as the positive
    class. This classifier was able to classify the fruits as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个例子，我们试图根据给定水果的大小预测它是否是葡萄还是西瓜。我们有200个样本，其中180个是葡萄，20个是西瓜。很简单，是的——越大，越可能是西瓜，而较小的尺寸则表明它是葡萄。假设我们训练了一个以葡萄为正类的分类器。这个分类器能够如下分类水果：
- en: '![Figure 6.24 – A fruit classification confusion matrix with the grape as the
    positive class ](img/B17298_06_024.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图6.24 – 以葡萄为正类的果实分类混淆矩阵](img/B17298_06_024.jpg)'
- en: Figure 6.24 – A fruit classification confusion matrix with the grape as the
    positive class
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.24 – 以葡萄为正类的果实分类混淆矩阵
- en: Let’s quickly calculate the scalar classification metrics that we previously
    covered.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速计算之前提到的标量分类度量。
- en: 'The accuracy of the classifier will be as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的准确度如下：
- en: '![](img/Formula_B17298_06_013.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_013](img/Formula_B17298_06_013.png)'
- en: 'The precision of the classifier will be as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的精确度如下：
- en: '![](img/Formula_B17298_06_014.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_014](img/Formula_B17298_06_014.png)'
- en: 'The recall of the classifier will be as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的召回率如下：
- en: '![](img/Formula_B17298_06_015.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_015](img/Formula_B17298_06_015.png)'
- en: 'The F1 score of the classifier will be as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的F1分数如下：
- en: '![](img/Formula_B17298_06_016.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_016](img/Formula_B17298_06_016.png)'
- en: 'Based on these metric values, it seems that our classifier is performing really
    well when making a prediction for grapes. So, what if we want to predict watermelons
    instead? Let’s change the positive class to watermelons instead of grapes. The
    confusion matrix for this scenario will be as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些度量值，我们的分类器在预测葡萄时似乎表现非常好。那么，如果我们想预测西瓜呢？让我们将正类从葡萄改为西瓜。这种情况下的混淆矩阵如下：
- en: '![Figure 6.25 – A fruit classification confusion matrix with watermelon as
    the positive class ](img/B17298_06_025.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图6.25 – 以西瓜为正类的果实分类混淆矩阵](img/B17298_06_025.jpg)'
- en: Figure 6.25 – A fruit classification confusion matrix with watermelon as the
    positive class
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.25 – 以西瓜为正类的果实分类混淆矩阵
- en: We’ll quickly calculate the scalar classification metrics that we previously
    covered.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将快速计算之前提到的标量分类度量。
- en: 'The accuracy of the classifier will be as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的准确度如下：
- en: '![](img/Formula_B17298_06_017.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_017](img/Formula_B17298_06_017.png)'
- en: 'The precision of the classifier will be as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的精确度如下：
- en: '![](img/Formula_B17298_06_018.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_018](img/Formula_B17298_06_018.png)'
- en: 'The recall of the classifier will be as follows:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的召回率如下：
- en: '![](img/Formula_B17298_06_019.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_019](img/Formula_B17298_06_019.png)'
- en: 'The F1 score of the classifier will be as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的F1分数如下：
- en: '![](img/Formula_B17298_06_020.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_020](img/Formula_B17298_06_020.png)'
- en: As we can see from the metric values, accuracy has remained the same but precision,
    recall, and the F1 score have drastically gone down. Accuracy, precision, recall,
    and the F1 score, despite being very good metrics for measuring classification
    performance, have some drawbacks when there is a class imbalance in the dataset.
    In our grape and watermelon dataset, we only had 20 samples of watermelon in the
    dataset but 180 samples of grape. This imbalance in data can cause asymmetry in
    the metric calculation, which can be misleading.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们从度量值中看到的那样，准确度保持不变，但精确度、召回率和F1分数急剧下降。尽管准确度、精确度、召回率和F1分数是衡量分类性能非常好的指标，但在数据集中存在类别不平衡时，它们也有一些缺点。在我们的葡萄和西瓜数据集中，我们只有20个西瓜样本，但葡萄有180个样本。这种数据不平衡会导致度量计算中的不对称，这可能具有误导性。
- en: Ideally, as data scientists and engineers, it is often advisable to keep the
    data as symmetrical as possible to keep the measurements of these metrics as relevant
    as possible. However, in a real-world dataset with millions of records, it will
    be difficult to maintain this symmetry. So, it would be beneficial to have some
    sort of metric that treats both the positive and negative class as equal and gives
    an overall picture of the classification model’s performance.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，作为数据科学家和工程师，我们通常建议尽可能保持数据对称，以使这些指标的测量尽可能相关。然而，在包含数百万条记录的现实世界数据集中，保持这种对称性将非常困难。因此，拥有某种将正负类别视为相等并给出分类模型整体性能总体图的指标将是有益的。
- en: 'This is where the **absolute Matthews Correlation Coefficient** (**MCC**),
    also called the **phi coefficient**, comes into play. The equation for the MCC
    is as follows:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是**绝对Matthews相关系数**（**MCC**），也称为**phi系数**，发挥作用的地方。MCC的方程如下：
- en: '![](img/Formula_B17298_06_021.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B17298_06_021.jpg)'
- en: During computation, it treats the actual class and the predicted class as two
    different variables and identifies the correlation coefficient between them. The
    correlation coefficient is nothing but a numerical value that represents some
    statistical relationship between the variables. The higher this correlation coefficient
    value, the better your classification model is.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算过程中，它将实际类别和预测类别视为两个不同的变量，并确定它们之间的相关系数。相关系数不过是一个数值，它代表了变量之间的某种统计关系。这个相关系数值越高，你的分类模型就越好。
- en: The MCC values range from -1 to 1\. 1 indicates that the classifier is perfect
    and will always classify the records correctly. A MCC of 0 indicates that there
    is no correlation between the classes and the prediction from the model is completely
    random. -1 indicates that the classifier will always incorrectly classify the
    records.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: MCC值范围从-1到1。1表示分类器是完美的，并且总是正确分类记录。MCC为0表示类别与模型预测之间没有相关性，模型预测完全随机。-1表示分类器总是错误地分类记录。
- en: A classifier with a MCC value of -1 does not mean the model is bad in any sense.
    It only indicates that the correlation coefficient between the predicted and the
    actual class is negative. So, if you just reverse the predictions of the classifier,
    you will always get the correct classification prediction. Also, the MCC is perfectly
    symmetrical – thus, it treats all the classes equally to provide a metric that
    considers the overall performance of the model. Switching the positive and negative
    classes does not affect the MCC value. Thus, if you just take the absolute value
    of the MCC, it still does not lose the value’s relevance. H2O often uses the absolute
    value of MCC for an easier understanding of the model’s performance.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: MCC值为-1并不意味着模型在任何一个方面都是不好的。它仅表示预测类别和实际类别之间的相关系数是负的。因此，如果你只是反转分类器的预测，你将总是得到正确的分类预测。此外，MCC是完全对称的——因此，它平等地对待所有类别，以提供一个考虑模型整体性能的指标。切换正负类别不会影响MCC值。因此，如果你只是取MCC的绝对值，它仍然不会失去其相关性的价值。H2O通常使用MCC的绝对值来更容易地理解模型的表现。
- en: 'Let’s calculate the MCC value of the fruit classification confusion matrix
    with grape as the positive class:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算以葡萄为正类的水果分类混淆矩阵的MCC值：
- en: '![](img/Formula_B17298_06_022.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B17298_06_022.png)'
- en: 'Similarly, let’s calculate the MCC value of the fruit classification confusion
    matrix with watermelon as the positive class:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，让我们计算以西瓜为正类的水果分类混淆矩阵的MCC值：
- en: '![](img/Formula_B17298_06_023.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B17298_06_023.png)'
- en: As you can see, the MCC value remains the same, at *0.277*, even if we switch
    the positive and negative classes. Also, A MCC of *0.277* indicates that the predicted
    class and the actual class are weakly correlated, which is correct considering
    the classifier was bad at classifying watermelons.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，即使我们切换正负类别，MCC值仍然保持不变，为*0.277*。一个MCC为*0.277*的值表明预测类别和实际类别之间相关性较弱，考虑到分类器在分类西瓜方面表现不佳，这是正确的。
- en: Congratulations, you now understand another important metric called the absolute
    MCC.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你，你现在理解了另一个重要的指标，称为绝对MCC（Matthews Correlation Coefficient）。
- en: Let’s now move to the next performance metric, which is R2.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转向下一个性能指标，即R2。
- en: Measuring the R2 performance metric
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量R2性能指标
- en: '**R2**, also called the coefficient of determination, is a regression model
    performance metric that aims to explain the relationship between the dependent
    variable and the independent variable in terms of how much of a change in the
    independent variable affects the dependent variable.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '**R2**，也称为确定系数，是一个回归模型性能指标，旨在通过独立变量变化对因变量影响的大小来解释自变量和因变量之间的关系。'
- en: The value of R2 ranges from 0 to 1, where 0 indicates that the regression line
    is not correctly capturing the trend in the data and 1 indicates that the regression
    line perfectly captures the trend in the data.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: R2 的值介于 0 到 1 之间，其中 0 表示回归线没有正确捕捉到数据中的趋势，而 1 表示回归线完美地捕捉到了数据中的趋势。
- en: 'Let’s better understand this metric using a graphical example of a dataset.
    Refer to the below image for the height-to-weight regression graph:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个数据集的图形示例更好地理解这个指标。请参考下面的图像，以了解身高与体重回归图：
- en: '![Figure 6.26 – A height-to-weight regression graph ](img/B17298_06_026.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.26 – 身高与体重回归图](img/B17298_06_026.jpg)'
- en: Figure 6.26 – A height-to-weight regression graph
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.26 – 身高与体重回归图
- en: 'The dataset has two columns:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集有两列：
- en: '**Height**: This is a numerical column that contains the height of a person
    in centimeters'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**身高**：这是一个数值列，包含一个人的身高（厘米）。'
- en: '**Weight**: This is a numerical column that contains the weight of a person
    in kilograms'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**体重**：这是一个数值列，包含一个人的体重（千克）。'
- en: Using this dataset, we are trying to predict someone’s weight based on their
    height.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个数据集，我们试图根据一个人的身高来预测他的体重。
- en: So firstly, let’s use the average of all the weights as a general regression
    line to predict the weights. Technically, it does make sense, as the majority
    of people will have an average range of weight for a grown adult body – even though
    there might be some errors, it is still a plausible way of predicting a person’s
    weight.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，首先，让我们使用所有体重的平均值作为一般的回归线来预测体重。从技术上讲，这确实是有意义的，因为大多数成年人都会有平均范围的体重——尽管可能会有一些误差，但这仍然是一种合理的预测一个人体重的办法。
- en: 'If we plot this dataset on a graph, the mean value used for prediction will
    look as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这个数据集绘制在图上，用于预测的平均值将看起来如下：
- en: '![Figure 6.27 – The height-to-weight regression graph with a mean line ](img/B17298_06_027.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.27 – 带有平均线的身高与体重回归图](img/B17298_06_027.jpg)'
- en: Figure 6.27 – The height-to-weight regression graph with a mean line
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.27 – 带有平均线的身高与体重回归图
- en: As you can see, there is definitely some error between the predicted values
    of the weight, which is the mean, and the actual values. As mentioned previously,
    this kind of error is called a residual. Calculating the square of the residuals
    gives us the squared error. The sum of these squared errors of all the records
    gives us the variation around the mean line.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，预测的体重值（即平均值）与实际值之间肯定存在一些误差。如前所述，这种误差称为残差。计算残差的平方给我们平方误差。所有记录的这些平方误差之和给我们提供了围绕平均线的变异。
- en: 'Now let’s perform linear regression and fit a line through the data so that
    we get another regression line. This regression line should ideally be a better
    predictor than using the mean value alone. The regression line on the graph should
    look as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来进行线性回归，并拟合一条通过数据的线，以便我们得到另一条回归线。这条回归线理想上应该比仅使用平均值作为预测指标有更好的预测能力。图上的回归线应该看起来如下：
- en: '![Figure 6.28 – The height-to-weight regression dataset with a regression line
    ](img/B17298_06_028.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.28 – 带有回归线的身高与体重回归数据集](img/B17298_06_028.jpg)'
- en: Figure 6.28 – The height-to-weight regression dataset with a regression line
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.28 – 带有回归线的身高与体重回归数据集
- en: Let’s calculate the residual square of errors for this line too – this gives
    us the variation around the regression line.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算这条线的残差平方误差——这给我们提供了围绕回归线的变异。
- en: 'Now, we need to figure out a way to identify which line is better, regression
    or mean, and by how much. This is where R2 can be used to compare the two regression
    lines. The equation for calculating R2 is as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要找出一种方法来识别哪条线更好，是回归线还是平均线，以及好多少。这正是 R2 可以用来比较两条回归线的地方。计算 R2 的公式如下：
- en: '![](img/Formula_B17298_06_024.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B17298_06_024.png)'
- en: 'Let’s assume the sum of squares of residuals around the regression line is
    *7* and the sum of squares of residuals around the mean line is *56*. Plugging
    these values into the R2 equation, we get the following value:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 假设回归线周围的残差平方和为 *7*，平均线周围的残差平方和为 *56*。将这些值代入 R2 公式，我们得到以下值：
- en: '![](img/Formula_B17298_06_025.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![公式 B17298_06_025](img/Formula_B17298_06_025.png)'
- en: The value *0.875* is a percentage. This value explains that 87.5 percent of
    the total variation in the values of *y* is described by the variations in values
    of *x*. The remaining 12.5 percent may be because of some other factors in the
    dataset such as muscle mass, fat content, or any other factor.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 值 *0.875* 是一个百分比。这个值解释了 87.5% 的 *y* 值的总变化是由 *x* 值的变化所描述的。剩余的 12.5% 可能是由于数据集中的一些其他因素，如肌肉量、脂肪含量或其他任何因素。
- en: From an ML perspective, a higher value of R2 indicates that the relationship
    between the two variables explains the variations in the data and as such, the
    linear model has captured the pattern of the dataset accurately. A lower R2 value
    indicates that the linear model has not fully captured the pattern of the dataset
    and there must be some other factors that contribute to the dataset’s pattern.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 从机器学习（ML）的角度来看，R2 值越高，表示两个变量之间的关系解释了数据中的变化，因此线性模型已经准确地捕捉了数据集的模式。R2 值越低，表示线性模型并没有完全捕捉到数据集的模式，并且一定存在其他一些因素对数据集的模式有贡献。
- en: This sums up how the R2 metric can be used to measure to what degree the linear
    model is correctly capturing the trends in the data.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这总结了 R2 指标可以用来衡量线性模型正确捕捉数据趋势的程度。
- en: Summary
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we focused on understanding how we can measure the performance
    of our ML models and how we can choose one model over the other depending on which
    is more performant. We started by exploring the H2O AutoML leaderboard metrics
    since they are the most readily available metrics that AutoML provides out of
    the box. We first covered what the MSE and the RMSE are, what the difference between
    them is, and how they are calculated. We then covered what a confusion matrix
    is and how we calculate accuracy, sensitivity, specificity, precision, and recall
    from the values in the confusion matrix. With our new understanding of sensitivity
    and specificity, we understood what a ROC curve and its AUC are, and how they
    can be used to visually measure the performance of different algorithms, as well
    as the performance of different models of the same algorithms trained on different
    thresholds. Building on the ROC-AUC metric, we explored the PR curve, its AUC,
    and how it overcomes the drawbacks faced by the ROC-AUC metric. And finally, within
    the leaderboard, we understood what log loss is and how we can use it to measure
    the performance of binary classification models.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们专注于了解如何衡量我们机器学习模型的性能，以及如何根据哪个模型表现更好来选择一个模型而不是另一个。我们首先从探索 H2O AutoML 排行榜指标开始，因为它们是
    AutoML 提供的最容易获得的指标。我们首先介绍了 MSE 和 RMSE 是什么，它们之间的区别是什么，以及它们是如何计算的。然后我们介绍了什么是混淆矩阵，以及如何从混淆矩阵中的值计算准确率、灵敏度、特异性、精确率和召回率。通过我们对灵敏度和特异性的新理解，我们了解了
    ROC 曲线和它的 AUC 是什么，以及它们如何被用来直观地衡量不同算法的性能，以及在不同阈值上训练的相同算法的不同模型性能。基于 ROC-AUC 指标，我们探讨了
    PR 曲线、它的 AUC 以及它如何克服 ROC-AUC 指标面临的缺点。最后，在排行榜中，我们了解了什么是对数损失，以及我们如何用它来衡量二元分类模型的性能。
- en: We then explored some important metrics outside of the realm of the leaderboard,
    starting with the F1 score. We understood how the F1 score incorporates both recall
    and precision into a single metric. We then understood the MCC and how it overcomes
    the drawbacks of precision, recall, and the F1 score when measured against imbalanced
    datasets. And finally, we explored the R2 metrics, which explain the relationship
    between the dependent variable and the independent variable in terms of how much
    of a change in the independent variable affects the dependent variable.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们探索了排行榜之外的一些重要指标，首先是 F1 分数。我们了解了 F1 分数如何将召回率和精确率结合成一个单一指标。然后我们了解了 MCC 以及它如何克服在衡量不平衡数据集时精确率、召回率和
    F1 分数的缺点。最后，我们探讨了 R2 指标，它解释了因变量和自变量之间的关系，即自变量变化多少会影响因变量。
- en: With this information in mind, we are now capable of correctly measuring and
    comparing models to find the most performant model to solve our ML problems. In
    the next chapter, we shall explore more about the various model explainability
    features that H2O provides, which give advanced details about a model and its
    features.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 带着这些信息，我们现在能够正确地测量和比较模型，以找到解决我们机器学习问题性能最佳的模型。在下一章中，我们将探讨H2O提供的各种模型可解释性功能，这些功能提供了关于模型及其特征的详细高级信息。
