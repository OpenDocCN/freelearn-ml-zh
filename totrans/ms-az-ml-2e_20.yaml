- en: '*Chapter 16*: Bringing Models into Production with MLOps'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we looked into model interoperability using ONNX, hardware
    optimization using FPGAs, and the integration of trained models into other services
    and platforms. So far, you have learned how to implement each step in an end-to-end
    machine learning pipeline with data cleansing, preprocessing, labeling, experimentation,
    model training, optimization, and deployment. In this chapter, we will connect
    the bits and pieces from all the previous chapters to integrate and automate them
    in a build and release pipeline. We will reuse all these concepts to build a version-controlled,
    reproducible, automated ML training and deployment process as a **continuous integration
    and continuous deployment** (**CI/CD**) pipeline in Azure. In analogy to the **DevOps**
    methodology in software development, we will refer to this topic as **MLOps**
    in ML.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will take a look at how to produce reproducible builds, environments,
    and deployments for ML projects. We will cover version control for code, as well
    as the versioning/snapshotting of data and building artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will learn how to automatically test our code and validate our code
    quality with a focus on ML projects. To do this, we will see how unit, integration,
    and end-to-end tests can be adapted for ensuring good quality of training data
    and ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you will build your own MLOps pipeline. First, you will learn how to
    set up Azure DevOps as your orchestration and coordination layer for MLOps, and
    then you will implement a build (CI) and release (CD) pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring reproducible builds and deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validating the code, data, and models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building an end-to-end MLOps pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will use the following Python libraries and versions to
    create MLOps pipelines in Azure DevOps:'
  prefs: []
  type: TYPE_NORMAL
- en: '`azureml-core 1.34.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`azureml-sdk` `1.34.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas 1.3.3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tensorflow 2.6.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pytest 7.1.1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pytest-cov 3.0.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mock 4.0.3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tox 3.24.5`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of the scripts and pipelines discussed in this chapter need to be scheduled
    to execute in Azure DevOps.
  prefs: []
  type: TYPE_NORMAL
- en: 'All code examples in this chapter can be found in the GitHub repository for
    this book: [https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter16](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter16).'
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring reproducible builds and deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DevOps has many different meanings but is usually about enabling rapid and high-quality
    deployments when the source code changes. One way of achieving high-quality operational
    code is by guaranteeing reproducible and predictable builds. While it seems obvious
    that the compiled binary will look and behave similarly for application development
    with only a few minor configuration changes, the same is not true for the development
    of ML pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'ML engineers and data scientists face many problems that make building reproducible
    deployments very difficult:'
  prefs: []
  type: TYPE_NORMAL
- en: The development process is often performed in notebooks and so it is not always
    linear.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refactoring notebook code often breaks older notebooks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are mismatching library versions and drivers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Source data can be changed or modified.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-deterministic optimization techniques can lead to completely different outputs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We discussed interactive notebooks (such as Jupyter, Databricks, Zeppelin, and
    Azure notebooks) in the first few chapters of this book, and you have probably
    seen them in a lot of places when implementing ML models and data pipelines. While
    interactive notebooks have the great advantage of executing cells to validate
    blocks of models iteratively, they also often encourage a user to run cells in
    a non-linear order. The main benefit of using a notebook environment becomes a
    pain when trying to productionize or automate a pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: The second issue that is common in ML is ensuring that the correct drivers,
    libraries, and runtimes are installed. While it is easy to run a small linear
    model based on scikit-learn in Python 2, it makes a big difference for deep learning
    models if the deployed CUDA, cuDNN, libgpu, Open MPI, Horovod, TensorFlow, PyTorch,
    and similar libraries match the versions from development. Containerization via
    Docker or similar technologies helps to build reproducible environments, but it's
    not straightforward to use them throughout the experimentation, training, optimization,
    and deployment processes.
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge faced by data scientists is that often data changes over time.
    Either a new batch of data is added during development or data is cleaned, written
    back to the storage, and reused as input for other experiments. Data, due to its
    variability in format, scale, and quality, can be one of the biggest issues when
    producing reproducible models. Versioning data similar to version-controlling
    code is essential, not only for reproducible builds but also for auditing purposes.
  prefs: []
  type: TYPE_NORMAL
- en: One more challenge that makes reproducible ML builds difficult is that they
    often contain an optimization step, as discussed in [*Chapter 11*](B17928_11_ePub.xhtml#_idTextAnchor178),
    *Hyperparameter Tuning and Automated Machine Learning*. While optimization is
    an essential step for ML (for example, for model selection, training, hyperparameter
    tuning, or stacking), it can add non-deterministic behavior to the training process.
    Let's find out how we can fight these problems step by step.
  prefs: []
  type: TYPE_NORMAL
- en: Version-controlling your code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Version-controlling source code is a best practice, not only for software development
    but also for data engineering, data science, and machine learning As an organization,
    you have the option to set up your own internal source code repository or use
    an external service. **GitHub**, **GitLab**, **Bitbucket**, and **Azure DevOps**
    are popular services for managing source control repositories. The benefit of
    these services is that some of them offer additional features, such as support
    for CI workers and workflows. We will use the CI runner integration of Azure DevOps
    later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Using version control for your code is more important than the version control
    system you use. Yes, **Git** works pretty well, but so does **Mercurial** and
    **Subversion** (**SVN**). For our example MLOps pipeline, we will use Git as it
    is the most widely used and supported. It's essential that you make yourself familiar
    with the basic workflows of the version control system that you choose. You should
    be able to create commits and branches, submit **pull requests** (**PRs**), comment
    on and review requests, and merge changes.
  prefs: []
  type: TYPE_NORMAL
- en: The power of version-controlling source code is to document changes. On each
    such change, we want to trigger an automatic pipeline that tests your changes,
    validates the code quality, and when successful and merged, trains your model
    and automatically deploys it to staging or production. Your commit and PR history
    will not only become a source of documenting changes but also triggering, running,
    and documenting whether these changes were tested and ready for production.
  prefs: []
  type: TYPE_NORMAL
- en: In order to work effectively with version control, it is essential that you
    try to move business logic out of your interactive notebooks as soon as possible.
    Notebooks store the code and output of each cell in custom data formats – for
    example, serialized to JSON files. This makes it very difficult to review changes
    in the serialized notebook. A good trade-off is to follow a hybrid approach, where
    you first test your code experiments in a notebook and gradually move the logic
    to a module that is imported into each file. Using auto-reload plugins, you can
    make sure that these modules get automatically reloaded whenever you change the
    logic, without needing to restart your kernel.
  prefs: []
  type: TYPE_NORMAL
- en: Moving code from notebooks to modules will not only make your code reusable
    for all other experiments (no need to copy utility functions from notebook to
    notebook) but it will also make your commits much more readable. When multiple
    people change a few lines of code in a massive JSON file (that's how your notebook
    environment stores the code and output of every cell), then the changes made to
    the file will be almost impossible to review and merge. However, if those changes
    are made in a module (a separate file containing only executable code), then these
    changes will be a lot easier to read, review, reason about, and merge.
  prefs: []
  type: TYPE_NORMAL
- en: Before we continue looking into the versioning of training data, this would
    be a good opportunity to brush up on your Git skills, create a (private) repository,
    and experiment with your version control features.
  prefs: []
  type: TYPE_NORMAL
- en: Registering snapshots of your data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your ML model is the output of your training code and your training data. If
    we version-control the training source code to create reproducible builds, we
    also need to version the training data. While it sounds reasonable to check small,
    text, non-binary, and non-compressed files into the version control system together
    with your source code, it doesn't sound reasonable for large binary or compressed
    data sources. In this section, we will discuss a solution on how to deal with
    the latter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s re-iterate the idea of reproducible builds: regardless of when the training
    is executed – it could run today, or a year from now – the output should be identical.
    This means that any modifications to the training data should create a new version
    of the dataset, and training should use a specific version of the dataset. We
    differentiate between operational transactional data and historical data. While
    the former is usually stateful and mutable, the latter is often immutable. Sometimes,
    we also see a mix of both, for example, mutable historical event data.'
  prefs: []
  type: TYPE_NORMAL
- en: When working with mutable data (for example, an operational database storing
    customer information), we need to create snapshots before pulling in the data
    for training. For ML, it's easier to use full snapshots than incremental snapshots,
    as each snapshot contains the complete dataset. While incremental snapshots are
    often created to save costs, full snapshots can also be stored cost-efficiently
    using column-compressed data formats and scalable blob storage systems (such as
    Azure Blob storage), even if you have multiple TBs of data.
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with historical or immutable data, we don't usually need to create
    full snapshots, since the data is partitioned—that is, organized in directories
    where directories correspond to the values of the partition key. Historical data
    is often partitioned by processing date or time, such as the time when the data
    ingestion was executed. Date or time partitions make it easier to point your training
    pipelines to a specific range of partitions instead of pointing to a set of files
    directly.
  prefs: []
  type: TYPE_NORMAL
- en: There are multiple ways to take snapshots of your training data. However, when
    working with the Azure Machine Learning workspace, it is recommended to wrap your
    data in Azure Machine Learning datasets, as discussed in [*Chapter 4*](B17928_04_ePub.xhtml#_idTextAnchor071),
    *Ingesting Data and Managing Datasets*. This makes it easy to take data snapshots
    or version your data. When processing and modifying data in Azure Machine Learning,
    you should make a habit of incrementing the dataset's version. In addition, you
    should pass a specific version of the dataset when fetching the data in the training
    script.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever you pass parameters to your training scripts, it is helpful to parameterize
    the pipeline using deterministic placeholders. Parameters such as dates and timestamps
    should be created in the pipeline scheduling step rather than in the code itself.
    This ensures you can always re-run failed pipelines with historical parameters,
    and it will create the same outputs.
  prefs: []
  type: TYPE_NORMAL
- en: So, make sure your input data is registered and versioned and your output data
    is registered and parameterized. This takes a bit of fiddling to set up properly
    but is worth it for the whole project life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking your model metadata and artifacts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Moving your code to modules, checking it into version control, and versioning
    your data will help to create reproducible models. If you are building an ML model
    for an enterprise, or you are building a model for your start-up, knowing which
    model version is deployed and with which dataset it was trained is essential.
    This is relevant for auditing, debugging, or resolving customers' inquiries about
    the predictions of your service.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen in the previous chapters that a few simple steps can enable you
    to track model artifacts and model versions in a model registry. Versioning the
    model artifacts is an essential step for continuous deployments. The model consists
    of artifacts, files that are generated while training, and metadata. Model assets
    contain the definition of the model architecture, parameters, and weights, whereas
    model metadata contains the dataset, commit hash, experiment and run IDs, and
    more of the training run.
  prefs: []
  type: TYPE_NORMAL
- en: Another important consideration is to specify and version-control the seed for
    your random number generators. During most training and optimization steps, algorithms
    will use pseudo-random numbers based on a random seed to shuffle data and parameter
    choices. So, in order to produce the same model after running your code multiple
    times, you need to ensure that you set a fixed random seed for every operation
    that uses randomized behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: Once you understand the benefit of source code version control for your application
    code and versioning your datasets, you will understand that it makes a lot of
    sense for your trained models as well. However, instead of readable code, you
    now store the model artifacts (binaries that contain the model weights and architecture)
    and metadata for each model.
  prefs: []
  type: TYPE_NORMAL
- en: Scripting your environments and deployments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Automating every operation that you perform during the training and deployment
    process will increase the initial time of development, testing, and deployment,
    but ultimately save you a ton of time when these steps have to be executed again.
    The benefit of cloud services, such as Azure Machine Learning and Azure DevOps,
    is that they provide you with all the necessary tools to automate every step of
    the development and deployment process.
  prefs: []
  type: TYPE_NORMAL
- en: If you haven't already done so, you should start organizing your Python in virtual
    environments. Popular options are `requirements`, `pyenv`, `Pipenv`, or `conda`
    files that help you to track development and test dependencies. This helps you
    to specify dependencies as part of the virtual environment and not rely on global
    packages or the global state of the development machine.
  prefs: []
  type: TYPE_NORMAL
- en: Azure DevOps and other CI runners will help you define dependencies because
    running integration tests will install all the defined dependencies automatically
    during the test. This is usually one of the first steps in a CI pipeline. Then,
    whenever you check in new code or tests to your version control system, the CI
    pipeline is executed and also tests the installation of your environment automatically.
    Therefore, it is good practice to add integration tests to all of your modules,
    so that you can never miss a package definition in your environment. If you miss
    declaring a dependency, the CI build will fail.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you also need to script, configure, and automate all your infrastructure.
    If you have followed the previous chapters in this book, you might have figured
    out by now why we did all the infrastructure automation and deployments through
    an authoring environment in Python. If you have scripted these steps previously,
    you can simply run and parameterize these scripts in your CI pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: If you run a CI pipeline that generates a model, you most likely want to spin
    up a fresh Azure Machine Learning cluster for this job so you don't interfere
    with other releases, build pipelines, or experimentation. While this level of
    automation is very hard to achieve on on-premises infrastructures, you can do
    this easily in the cloud. Many services, such as YAML files in Azure Machine Learning,
    ARM templates in Azure, or Terraform from HashiCorp, provide full control over
    your infrastructure and configuration.
  prefs: []
  type: TYPE_NORMAL
- en: The last part is to automate deployments within Azure Machine Learning. Performing
    deployments through code doesn't take much longer than through the UI but it gives
    you the benefit of a repeatable and reproducible deployment script. You will often
    be confronted to do the same operation in multiple ways; for example, deploying
    an ML model from Azure Machine Learning via the CLI, Python SDK, YAML, the Studio,
    or a plugin in Azure DevOps. It is recommended to pick whatever works for you,
    stick with one way of doing things, and perform all automation and deployments
    in the same way. Having said this, using Python as the scripting language for
    deployments and checking your deployment code in version control is a good and
    popular choice.
  prefs: []
  type: TYPE_NORMAL
- en: The key to reproducible builds and CI pipelines is to automate the infrastructure
    and environment from the beginning. In the cloud, especially in Azure, this should
    be very easy as most tools and services can be automated through the SDK. The
    Azure Machine Learning team put a ton of work into the SDK so that you can automate
    each step –from ingestion to deployment – from within Python.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's take a look into the validation of code and assets to ensure the
    code and trained model work as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Validating the code, data, and models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When implementing a CI/CD pipeline, you need to make sure you have all the necessary
    tests in place to deploy your newly created code with ease and confidence. Once
    you are running a CI or CI/CD pipeline, the power of automated tests will become
    immediately visible. It not only helps you to detect failures in your code, but
    it also helps to detect future issues in the whole ML process, including the environment
    setup, build dependencies, data requirements, model initialization, optimization,
    resource requirements, and deployment.
  prefs: []
  type: TYPE_NORMAL
- en: When implementing a validation pipeline for our ML process, we can take inspiration
    from traditional software development principles (for example, unit testing, integration
    testing, and end-to-end testing). We can translate these techniques directly to
    steps during the ML process, such as input data, models, and the application code
    of the scoring service. Let's understand how we can adapt these testing techniques
    for ML projects.
  prefs: []
  type: TYPE_NORMAL
- en: Testing data quality with unit tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unit tests are essential to writing good-quality code. A unit test aims to test
    the smallest unit of code (a function) independently of all other code. Each test
    should only test one thing at a time and should run and finish quickly. Many application
    developers run unit tests either every time they change the code, or at least
    every time they submit a new commit to version control.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple example of a unit test written in Python using the `unittest`
    module provided by the standard library in Python 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the code snippet, we run a single function and test whether
    the outcome matches a predefined variable. We can add more tests as additional
    methods to the test class.
  prefs: []
  type: TYPE_NORMAL
- en: In Python and many other languages, we differentiate between test frameworks
    and libraries that help us to author and organize tests, and libraries to execute
    tests and create reports. `pytest` and `tox` are great libraries to execute tests;
    `unittest` and `mock` help you to author and organize your tests in classes and
    mock out dependencies on other functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you write code for your ML model, you will also find units of code that
    can, and probably should, be unit tested on every commit. However, ML engineers,
    data engineers, and data scientists now deal with another source of errors in
    their development cycle: the data. Therefore, it is a good idea to rethink what
    unit tests could mean in terms of data quality.'
  prefs: []
  type: TYPE_NORMAL
- en: Once you get the hang of it, you will quickly understand the power of using
    unit tests to measure data quality. You can interpret feature dimensions of your
    input data as a single testable unit and write tests to ensure each unit is fulfilling
    the defined requirements. This is especially important when new training data
    is collected over time and it is planned to retrain the model in the future. In
    such a case, we always want to ensure that the data is clean and matches our assumptions
    before we start the training process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of what your unit tests can test in the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: Number of unique/distinct values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correlation of feature dimensions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Skewness
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimum and maximum values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most common value
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Values containing zero or undefined values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s put this into practice and write a unit test that ensures that the minimum
    value of a dataset is `0`. This simple test will ensure that your CI/CD pipeline
    will fail if your dataset contains unexpected values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we use `unittest` to organize the tests in multiple functions
    within the same class. Each class corresponds to a specific data source, and in
    each class, we can test all feature dimensions. Once set up, we can install `pytest`
    and simply execute it from the command line to run the test.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Azure DevOps, we can set up `pytest` or `tox` as a simple step in our build
    pipeline. For a build pipeline step, we can simply add the following block to
    the `azure-pipelines.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we first installed `pytest` and `pytest-cov` to create
    a `pytest` coverage report. In the next line, we executed the tests, which will
    now use the dataset and compute all the statistical requirements. If the requirements
    are not met according to the tests, the tests will fail, and we will see these
    errors in the UI for this build. This adds protection to your ML pipeline, as
    you can now make sure no unforeseen problems with the training data make it into
    the release without you noticing.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing is essential for software development, and so is unit testing for
    data. As with testing in general, it will take some initial effort to be implemented,
    which doesn't immediately turn into value. However, you will soon see that having
    these tests in place will give you good peace of mind when deploying new models
    faster, as it will catch errors with the training data at build time and not when
    the model is already deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Integration testing for ML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In software development, integration testing verifies individual so-called components
    often made up of multiple smaller units. You normally use a test driver to run
    the test suite and mock or stub other components in your tests that you don't
    want to test. In graphical applications, you could test a simple visual component
    while imitating the modules the component is interacting with. In the backend
    code, you test your business logic module while mocking all dependent persistence,
    configuration, and UI components.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests, therefore, help you to detect critical errors when combining
    multiple units together, without the expense of scaffolding the whole application
    infrastructure. They are placed between unit testing and end-to-end testing and
    are typically run per commit, branch, or PR on the CI runtime.
  prefs: []
  type: TYPE_NORMAL
- en: In ML, we can use the concept of integration testing to test the training process
    of an ML pipeline. This can help your training run to find potential bugs and
    errors during the build phase. Integration testing allows you to test whether
    your model, pre-trained weights, a piece of test data, and optimizer can yield
    a successful output. However, different algorithms require different integration
    tests to test whether something is wrong in the training process.
  prefs: []
  type: TYPE_NORMAL
- en: 'When training a **DNN** model, you can verify a lot of aspects of the model
    with integration tests. Here is a non-exhaustive list of steps to verify:'
  prefs: []
  type: TYPE_NORMAL
- en: Weights initialization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Default loss
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero input
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Single batch fitting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Default activations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Default gradients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a similar list, you can easily identify and catch cases where all activations
    are capped at the maximum value in a forward pass, or when all gradients are `0`
    during a backward pass. Theoretically, you can run any experiment, test, or check
    you would do manually before working with a fresh dataset and your model, continuously
    in your CI runtime. So, any time your model gets retrained or fine-tuned, these
    checks run automatically in the background.
  prefs: []
  type: TYPE_NORMAL
- en: A more general assumption is that when training a regression model, the default
    mean should be close to the mean prediction value. When training a classifier,
    you could test the distribution of the output classes. In both cases, you can
    detect issues due to modeling, data, or initialization error already, before starting
    the expensive training and optimization process.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of the runner and framework, you can choose the same libraries as used
    for unit testing because, in this case, integration testing differs only in the
    components that are tested and the way they are combined. Therefore, choosing
    `unittest`, `mock`, and `pytest` is a popular choice to scaffold your integration
    testing pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Integration testing is essential for application development and for running
    end-to-end ML pipelines. It will save you a lot of time and lowers your operational
    costs, if you can detect and avoid such problems automatically.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end testing using Azure Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In end-to-end testing, we want to verify all components involved in a request
    to a deployed and fully functional service. To do so, we need to deploy the complete
    service all together. End-to-end testing is critical for catching errors that
    are triggered only when combining all the components together and running the
    service in a staging or testing environment without mocking any of the other components.
  prefs: []
  type: TYPE_NORMAL
- en: 'In ML deployments, there are multiple steps where a lot of things can go very
    wrong if not tested properly. Let''s discard the easy ones where we need to make
    sure that the environment is correctly installed and configured. A more critical
    piece of the deployment in Azure Machine Learning is the code for the application
    logic itself: the scoring file. There is no easy way to test the scoring file,
    the format of the request, and the output together without a proper end-to-end
    test.'
  prefs: []
  type: TYPE_NORMAL
- en: As you might imagine, end-to-end tests are usually quite expensive to build
    and operate. First, you need to write code and deploy applications to only test
    the code, which requires extra work, effort, and costs. However, this is the only
    way to truly test the scoring endpoint in a production-like end-to-end environment.
  prefs: []
  type: TYPE_NORMAL
- en: The good thing is that by using Azure Machine Learning deployments, end-to-end
    testing becomes so easy that it should be part of everyone's pipeline. If the
    model allows it, we could even do a no-code deployment where we don't specify
    the deployment target. If this is not possible, we can specify an Azure Container
    Image as a compute target and deploy the model independently. This means taking
    the code from the previous chapter, wrapping it in a Python script, and including
    it as a step in the build process.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end testing is usually complicated and expensive. However, with Azure
    Machine Learning and automated deployments, a model deployment and sample request
    could just be part of the build pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous profiling of your model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Model profiling is an important step during your experimentation and training
    phase. This will give you a good understanding of the resources your model will
    require when used as a scoring service. This is critical information for designing
    and choosing a properly sized inference environment.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever training and optimization processes run continuously, the model requirements
    and profile evolve over time. If you use optimization for model stacking or automated
    ML, your resulting models could grow bigger to fit the new data. So, it is good
    to keep an eye on your model requirements to account for deviations from your
    initial resource choices.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, Azure Machine Learning provides a model profiling interface that you
    can feed with a model, scoring function, and test data. It will instantiate an
    inferencing environment for you, start the scoring service, run the test data
    through the service, and track the resource utilization. Let's bring all the pieces
    together and set up an end-to-end MLOps pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Building an end-to-end MLOps pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we want to set up an end-to-end MLOps pipeline. All required
    training code should be checked into version control, and the datasets and model
    will be versioned as well. We want to trigger a CI pipeline to build the code
    and retrain the model when the code or training data changes. Through unit and
    integration tests we will ensure that the training and inferencing code works
    in isolation and that the data and model fulfill all requirements and don't deviate
    from our initial assumptions. Therefore, the CI pipeline will be responsible for
    automatic continuous code builds, training, and tests.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will trigger the CD pipeline whenever a new model version is ready.
    This will deploy the model and inferencing configuration to a staging environment
    and run the end-to-end tests. After the tests have been completed successfully,
    we automatically want to deploy the model to production. Therefore, the CD pipeline
    will be responsible for the automatic deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The separation of the pipeline into CI and CD parts makes it easy to decouple
    the process of building assets from deploying assets. However, you can also combine
    both parts into a single CI/CD pipeline, and so build, train, optimize, and deploy
    it all with a single pipeline. It's up to you and your organization how to model
    the CI and CD components of your pipeline, and how to set up any triggers and
    (manual) approvals. You can choose between either deploying every commit to production
    or deploying a number of commits each day or week after manual approval.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will use Azure DevOps to author and execute the CI/CD pipelines
    and, therefore, to set up triggers, run the build, training, and testing steps,
    and handle the deployment of the trained model. Azure DevOps has built-in functionalities
    to automate the end-to-end CI/CD process. In general, it lets you run pieces of
    functionality, called tasks, grouped together in pipelines on a compute infrastructure
    that you define. You can either run pipelines that are triggered automatically
    through a new commit in your version control system or trigger them through a
    new revision of a build artifact or a button, for example, for semi-automated
    deployments. The former is called a **code pipeline** and refers to CI, while
    the latter is called a **release pipeline** and refers to CD.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start setting up an Azure DevOps project.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Azure DevOps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure DevOps will be the container for authoring, configuring, triggering, and
    executing all our CI/CD pipelines. It provides useful abstractions to work with
    version-controlled resources, such as code repositories and a connection to Azure
    and the Azure Machine Learning workspace, and lets you collaboratively access
    runners, pipelines, and build artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure DevOps** refers to the managed Azure DevOps Services accessible via
    [https://dev.azure.com/](https://dev.azure.com/). There also exists an on-premises
    offering for similar CI/CD integration capabilities called **Azure DevOps Server**,
    which was formerly known as Visual Studio **Team Foundation Server** (**TFS**).'
  prefs: []
  type: TYPE_NORMAL
- en: As a first step, we are going to set up the Azure DevOps workspace, so that
    we can author and execute Azure MLOps pipelines. Let's start by setting up the
    organization and projects.
  prefs: []
  type: TYPE_NORMAL
- en: Organization and projects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First, you need to set up your organization. An organization is a workspace
    to manage similar projects and collaborate with a group of people. You can create
    an organization by either using your Microsoft account, GitHub account, or even
    connecting to **Azure Active Directory** (**AAD**). To create an organization,
    you need to log into Azure DevOps ([https://dev.azure.com/](https://dev.azure.com/)),
    provide the slug name for your organization, and select a region to host your
    organization's assets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the screen for creating a new Azure DevOps organization:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.1 – Creating a new Azure DevOps organization ](img/B17928_16_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.1 – Creating a new Azure DevOps organization
  prefs: []
  type: TYPE_NORMAL
- en: Next, you can set up projects in your organization; we will start with one project
    that will contain the configuration and code to run your MLOps pipelines. A project
    is a place to keep all assets for a specific ML project logically grouped. You
    will be able to manage your code repositories, sprint boards, issues, PRs, build
    artifacts, test plans, and CI/CD pipelines within an Azure DevOps project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the process of creating a new Azure DevOps project.
    This will be the container for our pipelines, as well as testing and deployment
    configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.2 – Creating a new Azure DevOps project ](img/B17928_16_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.2 – Creating a new Azure DevOps project
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the organization and project set up, we need to add the Azure Machine
    Learning capabilities to Azure DevOps by installing the appropriate Azure DevOps
    extension.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Machine Learning extension
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Next, it is recommended to install the Azure Machine Learning extension for
    your Azure DevOps organization. This will tightly integrate your Azure Machine
    Learning workspace into Azure DevOps so that you can do the following things within
    Azure DevOps:'
  prefs: []
  type: TYPE_NORMAL
- en: Assign automatic permissions to access your Azure Machine Learning workspace
    resources automatically through Azure Resource Manager.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Trigger release pipelines for new model revisions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run Azure Machine Learning pipelines as tasks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set pre-configured tasks for model deployment and model profiling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It's fair to say that all the preceding things can also be set up manually using
    custom credentials and the Azure ML Python SDK, but the tight integration makes
    it a lot easier to set up.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: You can install the Azure Machine Learning extension for Azure DevOps from [https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will use the extension to set up the service connections and access
    permissions for your Azure and Azure Machine Learning workspace accounts.
  prefs: []
  type: TYPE_NORMAL
- en: Service connections
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You might remember from previous code examples that interacting with Azure and
    Azure Machine Learning resources requires the appropriate permissions, tenants,
    and subscriptions to be configured. Permissions to access these services and resources
    are often defined through **service principals**. In Azure DevOps, we can set
    up permissions for our Azure DevOps pipelines to access Azure and Azure Machine
    Learning resources, create compute resources, and submit ML experiments through
    **service connections**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In your Azure DevOps project, go to **Settings** | **Service connections**
    and configure a new Azure service connection with service principal authentication
    for your Azure Machine Learning workspace. The following figure shows how to set
    this up in Azure DevOps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.3 – Creating an Azure DevOps service connection ](img/B17928_16_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.3 – Creating an Azure DevOps service connection
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, you can also permit Azure DevOps pipelines to manage resources in
    an Azure resource group programmatically. It is recommended that you create both
    permissions through service principals and note the name of both newly created
    connections.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the next step, we want to store and manage all the variables and credentials
    outside of the actual CI/CD pipelines. We don't want to embed credentials or configuration
    parameters (such as subscription ID, workspace name, and tenant ID) into the pipeline,
    but pass them as parameters to the running pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: In Azure DevOps, you can achieve this by using **variable groups** and **secure
    files**. You can even connect a variable group to an Azure Key Vault instance
    to manage your secrets for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is recommended that you navigate to **Pipelines** | **Library** to set up
    a variable group that contains your subscription ID, tenant ID, names of your
    service connections, and so on as variables, so that they can be reused in pipelines.
    You can always come back later and add more variables if you need them. The following
    figure shows a sample variable group definition that can be included in your pipelines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.4 – Creating an Azure DevOps variable group ](img/B17928_16_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.4 – Creating an Azure DevOps variable group
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will set up a repository and write a code pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Agents and agent pools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Your CI and CD tasks will eventually check out the project, build it, train
    the model, run the tests, and deploy it. To do all this (and more), you need a
    compute infrastructure to run the CI/CD jobs. In Azure DevOps, these compute resources
    are called **agents**.
  prefs: []
  type: TYPE_NORMAL
- en: Azure DevOps Services provides Microsoft-hosted agents, which will execute your
    pipeline jobs either in VMs or Docker images. Both compute resources are ephemeral
    and torn down after each pipeline job.
  prefs: []
  type: TYPE_NORMAL
- en: When using Azure DevOps with public projects, Azure Pipelines is free and provides
    you with Microsoft-hosted agents for your CI/CD pipeline jobs. This allows you
    to run 10 parallel jobs for up to 6 hours each. For private projects, you are
    limited to one parallel job for up to 1 hour each with at most 30 hours per month.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: 'To prevent abuse, all free pipeline resources need to be requested for an organization
    via this form: [https://aka.ms/azpipelines-parallelism-request](https://aka.ms/azpipelines-parallelism-request).'
  prefs: []
  type: TYPE_NORMAL
- en: If more capacity is needed, we can either run self-hosted agents via Azure DevOps
    Server and/or Azure VM scale set agents or purchase additional Microsoft-hosted
    agents through Azure DevOps Services. For the purpose of this book, you should
    be able to start experimenting comfortably with the free capacity on private repositories.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous integration – building code with pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we can start to set up an automatic build, test, and training pipeline
    for our ML model using Azure DevOps pipelines. Conceptually, we will create or
    import a Git repository to Azure DevOps that serves as a container for our ML
    project and will contain the CI pipeline definitions. By convention, we will store
    the pipelines in the `.pipeline/` directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows how to set up or import a repository in Azure DevOps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.5 – Cloning or importing a repository ](img/B17928_16_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.5 – Cloning or importing a repository
  prefs: []
  type: TYPE_NORMAL
- en: Next, we open Visual Studio Code and start authoring our pipeline. Instead of
    constructing the CI pipeline from widgets and plugins, we will choose YAML to
    author the pipeline code. This is very similar to how GitHub CI or Jenkins workflows
    are written.
  prefs: []
  type: TYPE_NORMAL
- en: 'A pipeline contains a linear series of tasks to be executed to build, test,
    and train the ML model that can be triggered by a condition in the repository.
    In the Azure DevOps pipeline, tasks are organized in the following hierarchy:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Stage A:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Job 1:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 1.1
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 1.2
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Job 2:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 2.1
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Therefore, a pipeline is made up of stages, where each stage contains multiple
    jobs. Each job can contain multiple tasks called steps. Besides stages and jobs,
    the pipeline can contain the following sections:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pipeline definition:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`name`: The name of the pipeline'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pipeline triggers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`schedules`: Scheduling-based pipeline trigger configuration'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`trigger`: Code-based pipeline trigger configuration'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pr`: PR-based pipeline trigger configuration'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pipeline compute resources:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`resources`: Containers and repository configuration'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pool`: Agent pool configuration for pipeline compute resources'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pipeline customization:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`variables`: Pipeline variables'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`parameters`: Pipeline parameters'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pipeline job definition:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stages`: Grouping of pipeline jobs, can be skipped if the pipeline contains
    only a single stage'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jobs`: Pipeline jobs to be executed'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see in the preceding list, the Azure DevOps pipeline YAML schema
    allows you to customize pipeline triggers, compute resources, variables, and configurations,
    and lets you define the tasks to run in the pipeline. Azure DevOps pipelines also
    understand the concept of templating. You can use the `template` directive for
    stages, pipelines, jobs, steps, parameters, and variables to reference files from
    the template.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: You can find the documentation of the pipeline's YAML schema in the Microsoft
    documentation at [https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema/](https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use these step definitions and construct a simple pipeline to test the
    model code and start model training:'
  prefs: []
  type: TYPE_NORMAL
- en: ci-pipeline.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding pipeline, we define the trigger to start the pipeline for
    new commits on the `main` branch. For execution, we run each job on the Microsoft-hosted
    free agent pool using an Ubuntu VM. Then, we group the tasks into two stages:
    `CI` and `Train`. The former will build and test the code and datasets, whereas
    the latter will train the ML model and create a new version of the model in the
    model registry.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can add a commit to the repository and merge it to the `main` branch,
    and the CI pipeline will be triggered and train a new model version. You can use
    the preceding pipeline definition as a starting point to add additional steps,
    tests, configurations, and triggers to fully customize your CI pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: You can find an up-to-date example of an MLOps pipeline in the Microsoft GitHub
    repository at [https://github.com/microsoft/MLOpsPython](https://github.com/microsoft/MLOpsPython).
  prefs: []
  type: TYPE_NORMAL
- en: You can find more examples for MLOps starting points on the Azure MLOps repository
    [https://github.com/Azure/mlops-v2](https://github.com/Azure/mlops-v2)
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will take a look at a CD pipeline to deploy the trained model to production.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous deployment – deploying models with release pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An additional benefit of tracking model artifacts in a model registry (for example,
    in Azure Machine Learning) is that you can automatically trigger release pipelines
    in Azure DevOps when the artifacts change. Any artifact, such as a new ML model
    or version, can be configured to trigger a release in Azure DevOps. Therefore,
    code changes trigger CI build pipelines, and artifact changes trigger CD release
    pipelines. In this section, we will create a CD pipeline for our model and automatically
    roll the model out into staging and production.
  prefs: []
  type: TYPE_NORMAL
- en: While the triggering mechanism for release pipelines is different from build
    pipelines, most of the concepts for pipeline execution are very similar. Release
    pipelines also have pipeline stages, whereas each stage can have multiple tasks.
    One additional feature of release pipelines, since they deal with the deployment
    of artifacts, is that each stage can have additional **triggers**, as well as
    **pre-deployment** and **post-deployment conditions**, such as **manual approval**
    and **gates**.
  prefs: []
  type: TYPE_NORMAL
- en: Triggers will allow you to continue the pipeline execution during a specified
    schedule only. Manual approvals will halt the pipeline until it is approved by
    the defined user or user group, whereas gates will halt the pipeline for a predefined
    time before executing a programmatic check. Multiple stages, triggers, and pre-
    and post-deployment conditions are often combined to safely deploy artifacts to
    different environments.
  prefs: []
  type: TYPE_NORMAL
- en: If you have the Azure Machine Learning plugin installed, you can select triggers
    and deployment tasks specifically for Azure Machine Learning, such as artifacts
    based on ML model versions and Azure Machine Learning model deployment and profiling
    tasks. In this section, we will choose both the ML model artifact trigger and
    the ML model deployment task.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: You can find the available Azure DevOps tasks in the Microsoft documentation
    at [https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/](https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows you an Azure DevOps release pipeline, where we select
    an ML model as an artifact for the release pipeline trigger. We configure the
    pipeline with two stages, a deployment to staging and a deployment to production.
    In addition, we add a manual approval as a post-deployment condition of the staging
    deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 16.6 – Defining an Azure DevOps Release Pipeline ](img/B17928_16_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 16.6 – Defining an Azure DevOps Release Pipeline
  prefs: []
  type: TYPE_NORMAL
- en: By default, the release pipeline will require a user to create a release by
    pressing the **Create release** button in the top-right corner. This mode is intended
    to create releases only when an operator decides to trigger a deployment, and
    helps us avoid any automated deployments while configuring the release pipeline.
    However, once the operator is confident that the pipeline and release process
    are working as intended, we can enable automated deployments by toggling the flash
    icon on the asset in the release pipeline. This will enable the CD trigger and,
    therefore, trigger a release and deployment whenever the asset has changed. As
    a final task in this chapter, you can go ahead and activate the CD trigger to
    fully automate your CD pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced MLOps, a DevOps-like workflow for developing,
    deploying, and operating ML services. DevOps stands for a quick and high-quality
    way of making changes to code and deploying these changes to production.
  prefs: []
  type: TYPE_NORMAL
- en: We first learned that Azure DevOps gives us all the features to run powerful
    CI/CD pipelines. We can run either build pipelines, where steps are coded in YAML,
    or release pipelines, which are configured in the UI. Release pipelines can have
    manual or multiple automatic triggers (for example, a commit in the version control
    repository or if the artifact of a model registry was updated) and create an output
    artifact for release or deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Version-controlling your code is necessary, but it's not enough to run proper
    CI/CD pipelines. In order to create reproducible builds, we need to make sure
    that the dataset is also versioned and pseudo-random generators are seeded with
    a specified parameter. Environments and infrastructure should also be automated,
    and deployments can be done from the authoring environment.
  prefs: []
  type: TYPE_NORMAL
- en: In order to keep the code quality high, you need to add tests to the ML pipeline.
    In application development, we differentiate between unit, integration, and end-to-end
    tests, where they test different parts of the code, either independently or together
    with other services. For data pipelines with changing or increasing data, unit
    tests should test the data quality as well as units of code in the application.
    Integration tests are great for loading a model or performing a forward or backward
    pass through a model independently from other components. With Azure Machine Learning,
    writing end-to-end tests becomes a real joy as they can be completely automated
    with very low effort and costs.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you have learned how to set up continuous pipelines that can retrain and
    optimize your models and then automatically build and redeploy the models to production.
    In the last chapter, we will look at what's next for you, your company, and your
    ML services in Azure.
  prefs: []
  type: TYPE_NORMAL
