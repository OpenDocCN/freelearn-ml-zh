- en: Predictions and Performances
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is time to make some predictions! In [Chapter 4](08d9b49a-a25c-4706-8846-36be9538b087.xhtml),
    *Loading and Preparing the Dataset,* we did split the `Titanic` dataset into two
    subsets, the training and held-out subsets, respectively consisting of 70% and
    30% of the original dataset randomly shuffled. We have used variations of the training
    subset extensively in [chapter 5](b71d5007-58a0-4b79-9446-4a36e7476037.xhtml) *Model
    Creation,* to train and select the best classification model. But so far, we have
    not used the held-out subset at all. In this chapter, we apply our models to this
    held-out subset to make predictions on unseen data and make a final assessment
    of the performance and robustness of our models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon ML offers two types of predictions: batch and streaming. Batch prediction
    requires a datasource. The samples you want to predict are given to the model
    all at once in batch mode. Streaming, also known as real-time or online predictions,
    requires the creation of an API endpoint and consists of submitting sequences
    of samples, one by one, via HTTP requests. Real-time predictions do not involve
    the creation of a datasource.'
  prefs: []
  type: TYPE_NORMAL
- en: We will start with batch predictions on the Titanic held-out set. We will confirm
    that our different models perform similarly on the held-out dataset as they did
    on the validation subsets, assuming that all the subsets have a similar variable
    distribution. In [Chapter 5](b71d5007-58a0-4b79-9446-4a36e7476037.xhtml), *Model
    Creation*, we concluded that out of our three datasources — suggested recipe with
    quantile binning (QB), recipe without QB, and the extended dataset — the one with extra
    variables (`deck`, `title`, `log_fare`, and so on) resulted in the best score
    on the validation subset. We will verify that this is also the case on the held-out
    subset.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is organized in two parts. In the first part, we look at batch
    predictions on the `Titanic` dataset. In the second part, we look at real-time,
    streaming predictions, with a new text-based quantile binning from the UCI repository.
    The `Spam` dataset is large enough to simulate streaming data. We will create
    an Amazon ML endpoint and use the Python SDK to send and retrieve classification
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Making batch predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making real-time predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In real-world classification problems or regression problems, the previously
    unseen data you want to make predictions on will not include the target values.
    In our case, the held-out datasets do contain the solution, and this allows us
    to assess the model performance on previously unseen data. But with real-world
    problems, you do not have that luxury and you will have to trust your model.
  prefs: []
  type: TYPE_NORMAL
- en: Making batch predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Making batch predictions on Amazon ML is straightforward and follows this process:'
  prefs: []
  type: TYPE_NORMAL
- en: From the dashboard, create a new Batch prediction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the datasource on which to apply the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the prediction output folder and grant permissions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review and launch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We call the `prediction` dataset or datasource, the data on which we want to
    make predictions. In this chapter, we are in a testing context and the `prediction`
    dataset is the `held-out` dataset we extracted from the whole original dataset.
    In a real-world context, the prediction dataset refers to entirely new data and
    does not include the target variable.
  prefs: []
  type: TYPE_NORMAL
- en: The prediction can only work if the distribution of the prediction dataset is
    similar to the distribution of the training dataset on which the model has been
    trained. The prediction datasource and the training datasource must also share
    the same schema, with one difference the prediction dataset does not need to include
    the target variable. Amazon ML will verify that the schema defined for your training
    data is relevant to your prediction data and will issue a warning if the datasets
    are not similar.
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of convenience, we have recreated the datasets, datasources, and
    models for this chapter. All datasets and scripts are available in the GitHub
    repository at [https://github.com/alexperrier/packt-aml/tree/master/ch6](https://github.com/alexperrier/packt-aml/tree/master/ch6).
    Since we reshuffled the original Titanic data, the evaluation scores will be different
    from the ones obtained previously for the same dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the batch prediction job
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To create a batch prediction, go to the Amazon ML dashboard and click on Create
    new batch prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then select the model. We choose the original model related to the `Titanic`
    dataset, the one using the Amazon ML suggested recipe with quantile binning:'
  prefs: []
  type: TYPE_NORMAL
- en: Quantile binning of all numeric variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: L2 mild regularization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B05028_06_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After the model selection comes the datasource selection. If you have not yet
    created a datasource for the held-out set, you can do so now. First, upload your
    prediction dataset to S3 and specify the S3 path for the source of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When you click on Verify, Amazon ML will check that the prediction dataset
    follows the same schema as the training dataset on which the model was trained:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_04.png)'
  prefs: []
  type: TYPE_IMG
- en: Interpreting prediction outputs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The output of the Amazon ML prediction job will consists of two files: the
    manifest file and the actual prediction results given in a compressed CSV file.
    Amazon ML will create the files on S3 in an S3 location, `s3://bucket/folder`,
    which you must specify. We use the same path as our data path: `s3://aml.packt/data/`.
    Amazon ML will create a `/batch_prediction` folder, where it will write the manifest
    file as well as an extra subfolder `/results`, where the CSV file with the actual
    predictions will be written. To recap, in our context, the manifest file will
    be in the  `s3://aml.packt/data/batch_prediction` folder, and the compressed CSV
    results file will be in the `s3://aml.packt/data/batch_prediction/results/` folder.The
    name given to the batch prediction will dictate the naming of the manifest and
    results files:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_05.png)**Prediction pricing**: If you just created the datasource
    for the batch prediction, Amazon ML does not yet have access to the data statistics
    that it needs to calculate the prediction costs. In that case, it will simply
    inform you of the price, of $0.10 per 1,000 predictions. If the prediction datasource
    has already been validated and Amazon ML knows the number of records, the estimated
    price will be the number of rows times the price per prediction rounded up to
    the nearest cent. You are not billed for the invalid samples Amazon ML fails to
    predict. More information is available at [http://docs.aws.amazon.com/machine-learning/latest/dg/pricing.html](http://docs.aws.amazon.com/machine-learning/latest/dg/pricing.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Review and click on the Create batch prediction button. The batch prediction
    job will take a few minutes to complete. When finished, it will have created the
    manifest and results files in S3 and will show up as completed in the Batch Prediction
    section of the Amazon ML dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Reading the manifest file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The manifest file contains JSON-formatted data that maps the input file to
    the prediction results file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In our context, the manifest file contains the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Multiple input files**: If your input data is split into several files, all
    stored in the same S3 location `s3://examplebucket/input/`, all the input files
    will be considered by the batch prediction job. The manifest file will then contain
    the mapping from the different input files to the associated results files. For
    instance, if you have three input files named `data1.csv`, `data2.csv`, and `data3.csv`,
    and they are all stored in the S3 location `s3://examplebucket/input/`, you will see
    a mapping string that looks like as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Maximum size for predictions**: Amazon ML allows up to 1TB of data for prediction
    files. If the data on which you want to make predictions is larger, it is possible
    to split your data into several files, upload them to a specific S3 location,
    and Amazon ML will handle the different files and generate as many prediction
    result files as there are input files by running several batches in parallel.
    The manifest file will contain all the different input/output pairs, `{input_file.csv
    : prediction_results.csv.gz}` for your different batch prediction files.'
  prefs: []
  type: TYPE_NORMAL
- en: Reading the results file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The output results file is compressed with gzip, originates from the UNIX world,
    and offers better compression than the more common zip compression. A simple click
    should be sufficient to open and decompress the gzipped results file into a readable
    CSV file. Alternatively, a call to the gunzip command from the command line should
    work. Take a look at [http://www.gzip.org/](http://www.gzip.org/) for installation
    on different systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'For binary classification, the decompressed results file contains two or three
    columns, depending on whether the initial input file contained the target or not.
    In our case of binary classification, the result file has the following columns:
    `trueLabel`, `bestAnswer`, and `score`, where `trueLabel` is the initial `survived`
    column. If your initial batch prediction dataset did not include the target values,
    the results file will only have the bestAnswer and score columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`trueLabel` is the original target value contained in the input file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bestAnswer` is the classification result: 0 or 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Score` is the probability for that classification written in scientific notation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The classification cutoff threshold for the score probability is 0.5 by default,
    or set to the threshold value you chose while evaluating the model.
  prefs: []
  type: TYPE_NORMAL
- en: For multiclass classification with *N* potential target classes, the results
    file will have *N+1* or *N+2* columns. The `trueLabel`, `bestAnswer`, and `N`
    columns each with the probability scores for each one of the N classes. The chosen
    class will be the one that bears the highest probability score.
  prefs: []
  type: TYPE_NORMAL
- en: For a regression model, the results file will only contain one/two score columns
    with the predicted value, and possibly the `trueLabel` column.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing our predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we know the real class of our held-out samples, we can calculate the **ROC-AUC**
    score and other metrics to see how close our prediction and validation scores
    are. Assuming that our data subsets have very similar distributions, both scores
    should end up very close. The difference only comes from randomness in the samples
    for the validation and held-out sets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Python script uses the `scikit-learn` library ([http://scikit-learn.org/](http://scikit-learn.org/))
    as well as the pandas library. It takes a few lines of Python to calculate the
    AUC score of the model on that prediction dataset. First, download the gzipped
    file from S3 and then, in a Python Notebook or console, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Python environment**: All the Python code in this book is for Python 3.5
    or above. For more information on the Anaconda library, take a look at [https://www.continuum.io/downloads](https://www.continuum.io/downloads).
    Anaconda is an amazingly powerful open source data science platform in Python.
    It contains the most important libraries (`numpy`, `pandas`, `scikit-learn`, `matplotlib`,
    and many others) as well as the Jupyter Notebooks environment. We use the IPython
    console for its simplicity of use and many magic commands ([http://ipython.readthedocs.io/en/stable/interactive/magics.html](http://ipython.readthedocs.io/en/stable/interactive/magics.html)).'
  prefs: []
  type: TYPE_NORMAL
- en: Running the previous Python script on the predictions results, we obtain an
    AUC of 0.84 on our held-out dataset, which is very close to the AUC (0.85) we
    obtained on the validation set in [Chapter 5](b71d5007-58a0-4b79-9446-4a36e7476037.xhtml),
    *Model Creation*. We can conclude that our model is pretty stable and robust when
    facing new, previously unforeseen data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following plot shows both the ROC curves for the validation (dotted line)
    and held-out (solid-line) sets for the chosen model. The validation set is slightly
    better for higher values of the threshold. This difference is a reflection of
    the different data distributions in the two datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_06.png)'
  prefs: []
  type: TYPE_IMG
- en: Evaluating the held-out dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 5](b71d5007-58a0-4b79-9446-4a36e7476037.xhtml), *Model Creation*,
    we evaluated the performance of our different models on a slice of the training
    datasource. We obtained for each model an AUC score, and selected the AUC with
    the best AUC score. We relied on Amazon ML to create the validation set, by splitting
    the training dataset into two, with 70% for training and 30% of the data for validation.
    We could have done that split ourselves, created the validation datasource, and
    specified which datasource to use for the evaluation of the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, nothing prevents us from running a model evaluation on the held-out
    dataset. If you go to the model summary page, you will notice a Perform another
    Evaluation button in the Evaluation section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click on it. You are asked to select the datasource for the evaluation. Select
    the held-out dataset; Amazon ML will verify that the data follows the same schema
    and is similar to the training data. You end up with two evaluations on the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And as expected, the evaluation AUC for the held-out dataset is equal to the
    AUC we obtained by downloading the results and calculating the AUC in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_17.png)'
  prefs: []
  type: TYPE_IMG
- en: Finding out who will survive
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The true value of predictions, however, is not about validating the robustness
    of our model; it's about making predictions on our prediction dataset, in our
    context, getting survival predictions on this `new` list of passengers contained
    in the held-out dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rows in the results file follow the exact same order as the rows in the
    prediction file. We can put side by side the first rows of the held-out file and the
    first rows of the results file, and see that the `survived` and the `trueLabel`
    columns are identical:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_13.png)'
  prefs: []
  type: TYPE_IMG
- en: Multiplying trials
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The evaluation scores on the various models and dataset version are, to a certain
    extent, dependent on the samples contained in the evaluation sets. If we run the
    following experiment several times on the three datasets, we see certain variations
    in the scores:'
  prefs: []
  type: TYPE_NORMAL
- en: Shuffle and split the dataset into three -- training, validation, and held-out
    and create the respective datasources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train a model on the training dataset, keeping the default Amazon ML settings
    (mild L2 regularization)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate the model on the evaluation and held-out datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following plot shows the respective performances of the three models for
    several trials. The average AUC is written on the graph. We see that on average,
    the extended dataset performs better (*AUC = 0.87*) than the original dataset
    with the default recipe (*AUC = 0.84*) and the original dataset without quantile
    binning (*AUC = 0.83*). We also notice that in some trials, the extended dataset
    performs worse than the original one. For trial 3, the default recipe is even
    slightly less performant than the no quantile binning one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_14.png)'
  prefs: []
  type: TYPE_IMG
- en: This shows the importance of inner data distribution variability. When trying
    out several variants of your datasets with different features and processing,
    it's important to base your conclusions on several runs of your models. A single evaluation
    may lead to missing the best model.
  prefs: []
  type: TYPE_NORMAL
- en: Making real-time predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With batch predictions, you submit all the samples you want the model to predict
    at once to Amazon ML by creating a datasource. With real-time predictions, also
    called streaming or online predictions, the idea is to send one sample at a time
    to an API endpoint, a URL, via HTTP queries, and receive back predictions and
    information for each one of the samples.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up real-time predictions on a model consists of knowing the prediction
    API endpoint URL and writing a script that can read your data, send each new sample to
    that API URL, and retrieve the predicted class or value. We will present a Python-based
    example in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon ML also offers a way to make predictions on data you create on the fly
    on the prediction page. We can input the profile of a would-be passenger on the
    `Titanic` and see whether that profile would have survived or not. It is a great
    way to explore the influence of the dataset variables on the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Before setting up API for streaming, let’s see what we can gather from submitting
    several single passenger profiles. We can even try to answer the question – *W**ould
    you have survived on the Titanic?*
  prefs: []
  type: TYPE_NORMAL
- en: Manually exploring variable influence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Go to the model summary page and click on the Try real-time predictions link
    on the left side of the page. The following page shows a form where you can fill
    out values for the variables in our dataset except for the target.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see if Alex Mr. Perrier, a first-class passenger who embarked at Southhampton
    with his family (3 sibsp and 2 parch) and who paid a fare of 100 pounds, would
    have survived. Well, in that case, the model gives a very low probability of survival
    (0.001), meaning that the model predicts with confidence that this passenger would
    not have survived. His 12 year old daughter would have had better chances of surviving
    (*probability 0.56*), though the model is less sure of it. However, if that same
    girl was traveling alone (*sibsp = parch = 0*), her chance of survival would surge
    to 0.98 under the condition that she traveled in 1st class. In 3rd class, she
    would have been less fortunate (*probability: 0.28*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_18.png)'
  prefs: []
  type: TYPE_IMG
- en: So, by changing one variable at a time in the data, we can have a better understanding
    of the impact of each variable on the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up real-time predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To demonstrate real-time predictions, we will use the `Spam` dataset from the
    UCI repository. This dataset is composed of 5,574 SMS messages annotated spam
    or ham (non-spam). There are no missing values and only two variables: the nature
    of the SMS (ham or spam) and the text message of the SMS, nothing else.  The `Spam`
    dataset is available at [https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) in
    its raw form, and in the book''s GitHub repository at [https://github.com/alexperrier/packt-aml/tree/master/ch6](https://github.com/alexperrier/packt-aml/tree/master/ch6).
    We have simply transformed the target from categorical: `spam` and `ham` values
    to binary: 1 (for spam) and 0 (for ham) so that Amazon ML understands the prediction
    to be of the binary-classification type.'
  prefs: []
  type: TYPE_NORMAL
- en: AWS SDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS offers several APIs and **Software Development Kits (SDKs)** to its many
    services. You can programmatically manage your files on S3, set up EC2 instances,
    and create datasources, models, and evaluations on Amazon ML without using the
    web-based user interface. The AWS APIs are low-level endpoints. In general, it
    is simpler and more efficient to use the SDKs, which are wrappers around the APIs
    and are available for several languages (Python, Ruby, Java, C++, and so on).
    In this book, we will use the Python SDK based on the `Boto3` library. We explore
    in detail the use of the Python SDK in [Chapter 7](efe6f699-a4eb-4c88-8e81-1408d6c3c5c4.xhtml),
    *Command Line and SDK.* For now, we will only use the `predict()` method necessary
    for real-time predictions. But first, we need to enable access to AWS by setting
    up AWS credentials on our local machine.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up AWS credentials
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to access AWS programmatically, we first need to access AWS via the
    command line. This requires the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating access keys on AWS IAM for your user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing the `AWS-CLI` command-line interface on local
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring `AWS-CLI` with the AWS access keys
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS access keys
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you recall from [Chapter 3](5938ed0c-9243-49cc-bf67-314ffb5f9386.xhtml),
    *Overview of an Amazon Machine Learning Workflow*, we had created access keys
    for our `AML@Packt` user. Access keys are user-based and composed of two parts:
    the **Access Key ID**, which is always available in the user security credentials
    tab in IAM, and the **Secret Access Key**, which is only shown at creation time.
    When creating these access keys, you are given the possibility of downloading
    them. If you did not do so at that time, you can recreate access keys for your
    user now. Go to the IAM console at  [https://console.aws.amazon.com/iam](https://console.aws.amazon.com/iam),
    click on your user profile, select the Security Credentials tab, and click on
    the Create Access Key button. This time make sure you download the keys on your
    local machine or copy them somewhere. Note that there’s a limit of two sets of
    access keys per user. You will have to delete existing keys before creating new
    ones if you already have two keys associated to your user:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_03_03.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting up AWS CLI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have only worked with the AWS web interface, clicking from page to
    page on the AWS website. Another way to interact with AWS services is via the
    command line in a terminal window, using the `aws cli` library. CLI stands for
    Command Line Interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the `aws cli` library, open a terminal window. For a Python-based
    environment (Python 2 version 2.6.5+ or Python 3 version 3.3+), installing `aws
    cli` consists of running the following command in a terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Full instructions for installation in other environments are available at [http://docs.aws.amazon.com/cli/latest/userguide/installing.html](http://docs.aws.amazon.com/cli/latest/userguide/installing.html).
     Once AWS-CLI is installed, run the following command to configure it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You will be asked for your access keys, the default region, and format. See
    [http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html#cli-quick-configuration](http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html#cli-quick-configuration)
    for more in-depth explanations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, AWS-CLI commands follow this syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Test your setup by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a list of your buckets, folders, and files in your s3 account.
    This is what my output looks like when I list the file and folders in the `aml.packt`
    bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_07.png)'
  prefs: []
  type: TYPE_IMG
- en: We will explore in detail how to run your Amazon ML projects using CLI in [Chapter
    7](efe6f699-a4eb-4c88-8e81-1408d6c3c5c4.xhtml), C*ommand Line and SDK*.
  prefs: []
  type: TYPE_NORMAL
- en: Python SDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will not use the AWS-CLI any further in this chapter, but instead switch
    to the Python SDK. We needed to setup the credentials for the AWS CLI in order
    for our SDKs scripts to be able to access our AWS account. To use the Python SDK,
    we need to install the `Boto3` library, which comes bundled in the Anaconda distribution.
    If you use Anaconda as your Python environment, you should already have the `boto3`
    package installed. If not, you can install it using `pip` with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**Boto3** will use the credentials we configured for the AWS CLI. There’s no
    need for a specific setup. Boto3 is available for most AWS services. The full
    documentation is available at [https://boto3.readthedocs.io/](https://boto3.readthedocs.io/).
    Our minimal use of `Boto3` only requires to specify the service we want, Machine
    Learning, and then use the `predict()` method to send the proper data to the model.
    In return, we obtain the predictions we wanted. The following Python code initiates
    a client to access the machine learning service.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `predict()` method requires the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MLModelId`: The ID of the model your want to use to predict'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PredictEndpoint`*:* The URL of the Amazon ML endpoint for your model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Record`*:* A JSON-formatted version of the sample'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `MLModelId` and `PredictEndpoint` URL can be obtained from the model summary
    page. The `Record` is a JSON-formatted string. We will simulate a streaming application
    by opening a held-out set of samples, looping through each sample and sending
    it via the `predict()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have split the initial dataset into a training set of 4,400 samples and
    a held-out set of 1,174 samples. These subsets are available at the GitHub repository. We
    create a datasource for the training subset, and create a model and its evaluation
    with default settings (mild L2 regularization). We keep the inferred schema (binary
    and text), the suggested recipe (no transformation besides tokenization of the
    text variable), and use the default model parameters (10 passes and mild L2 regularization).
    The training dataset is further split by Amazon ML into a smaller training dataset
    and a validation dataset, respectively 70% and 30% of the initial *4,400* samples.
    The AUC score obtained on the validation set is very high at *0.98*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To get the `ModelID` and the `endpoint` URL, go to your summary page for the
    model. Copy the `ModelID` from the top of the page. Then scroll down to get to
    the prediction section and click on the Create endpoint button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_09.png)'
  prefs: []
  type: TYPE_IMG
- en: At that point, you will be given an estimate of the real-time prediction pricing
    for your model and asked to confirm the creation of the endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: The size of your model is 502.1 KB. You will incur the reserved capacity charge
    of $0.001 for every hour your endpoint is active. The prediction charge for real-time
    predictions is $0.0001 per prediction, rounded up to the nearest penny**.**
  prefs: []
  type: TYPE_NORMAL
- en: 'After a few minutes, the endpoint will be created and you will have the endpoint
    URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_10.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we know the endpoint URL, we can write a simple Python code that sends
    an SMS message, a simple text, to our prediction model and see whether this message is
    predicted to be spam or ham. We send the text `Hello world, my name is Alex` to
    be classified as ham, while the text `Call now to get dating contacts for free,
    no cash no credit card` should probably be detected as spam due to the presence
    of the words *free*, *cash*, *dating*, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: 'The initialization/declaration part of the code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We now use the `predict()` function of the machine learning service SDK:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, pretty print the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns the following JSON-formatted string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The JSON response is composed of two parts: the first part is related to the
    request itself, `ResponseMetadata`, and the second is related to the `Prediction`.
    The `HTTPStatusCode` in the `*ResponseMetadata*` part tells us that our query was
    successful `("HTTPStatusCode": 200)`.'
  prefs: []
  type: TYPE_NORMAL
- en: The interpretation of the Prediction part is straightforward. The SMS was predicted
    to be spam with a very low probability of 0.12%, hence it was classified as ham,
    which is what we expected for the text `Hello world, my name is Alex`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We expect the text `Call now to get dating contacts for free, no cash no credit
    card` to be classified as spam, the words `free`, `call`, and `dating` usually
    being strong indicators of spam messages. We get the following in return:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The text is classified as spam, which is what we expected. As far as we can
    tell from these two simple examples, our model seems to be working fine. Once
    we can obtain prediction via API calls on a sample-by-sample basis, it becomes
    feasible to hook an incoming stream of data into the endpoint and obtain real-time
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: To simulate that pipeline, we can use Python to read a whole file of new samples,
    send each one to the model, and capture the results. Let’s do that with the held-out
    set of Spam samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Python code reads the file, loads it into a panda dataframe,
    and loops over each row of the dataframe. We use `iterrows()` to loop over each
    row of the dataframe. This method is slower than `itertuples()`, but has better
    code readability. The following code is not optimized:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The responses from Amazon ML are blazingly fast. Thousands of samples are processed
    in a few seconds. This is an extract of the results we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, each line is formatted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Notice that, out of the three SMS detected as spam, only two were actually spam
    SMS. The text "*Money i have won wining number 946 wot do i do next*" was probably
    detected as spam due to the presence of the words "Money" or "wining" but was
    in fact a ham message.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, across the whole predictions, the probabilities are very close to
    either 0 or 1, indicating that the model is very decisive in its classification.
    No hesitation. The ROC curve for the held-out dataset shows that high level of
    accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B05028_06_12.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the final step in the Amazon ML workflow, the predictions.
    Amazon ML offers several ways to apply your models to new datasets in order to
    make predictions. Batch mode involves submitting all the new data at once to the
    model and returning the actual predictions in a csv file on S3\. Real-time predictions,
    on the other hand, are based on sending samples one by one to an API and getting
    prediction results in return. We looked at how to create an API on the Amazon
    ML platform. We also started using the command line and the Python SDK to interact
    with the Amazon ML service -- something we will explore in more depth in [Chapter
    7](efe6f699-a4eb-4c88-8e81-1408d6c3c5c4.xhtml), *Command Line and SDK*.
  prefs: []
  type: TYPE_NORMAL
- en: As explained in the previous chapters, the Amazon ML service is built around
    the Stochastic Gradient Descent (SGD) algorithm. This algorithm has been around
    for many years and is used in many different domains and applications, from signal
    processing and adaptive filtering to predictive analysis or deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will present the algorithm and some if its versions,
    and bring to light its behavior when dealing with different types of data and
    prediction problems. We will explain why quantile binning of numeric values, which
    is often frowned upon, is such a performance and stability booster in our case.
  prefs: []
  type: TYPE_NORMAL
