["```py\nimport numpy as np\n\nfrom scipy.spatial.distance import pdist\n\nnb_samples = 100\nnb_bins = 100\n\ndef max_min_mean(p=1.0, d=2):\n    Xs = np.random.uniform(0.0, 1.0, size=(nb_bins, nb_samples, d))\n\n    pd_max = np.zeros(shape=(nb_bins, ))\n    pd_min = np.zeros(shape=(nb_bins, ))\n\n    for i in range(nb_bins):\n        pd = pdist(Xs[i], metric='minkowski', p=p)\n        pd_max[i] = np.max(pd)\n        pd_min[i] = np.min(pd)\n\n    return np.mean(pd_max - pd_min)\n\nprint('P=1 -> {}'.format(max_min_mean(p=1.0)))\nprint('P=2 -> {}'.format(max_min_mean(p=2.0)))\nprint('P=10 -> {}'.format(max_min_mean(p=10.0)))\nprint('P=100 -> {}'.format(max_min_mean(p=100.0)))\n\nP=1 -> 1.79302317381\nP=2 -> 1.27290283592\nP=10 -> 0.989257369005\nP=100 -> 0.983016242436\n\nprint('P=1 -> {}'.format(max_min_mean(p=1.0, d=100)))\nprint('P=2 -> {}'.format(max_min_mean(p=2.0, d=100)))\nprint('P=10 -> {}'.format(max_min_mean(p=10.0, d=100)))\nprint('P=100 -> {}'.format(max_min_mean(p=100.0, d=100)))\n\nP=1 -> 17.1916057948\nP=2 -> 1.76155714836\nP=10 -> 0.340453945928\nP=100 -> 0.288625281313\n\nprint('P=1 -> {}'.format(max_min_mean(p=1.0, d=1000)))\nprint('P=2 -> {}'.format(max_min_mean(p=2.0, d=1000)))\nprint('P=10 -> {}'.format(max_min_mean(p=10.0, d=1000)))\nprint('P=100 -> {}'.format(max_min_mean(p=100.0, d=1000)))\n\nP=1 -> 55.2865105705\nP=2 -> 1.77098913218\nP=10 -> 0.130444336657\nP=100 -> 0.0925427145923\n```", "```py\nimport numpy as np\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\nX_train = digits['data'] / np.max(digits['data'])\n```", "```py\nfrom sklearn.neighbors import NearestNeighbors\n\nknn = NearestNeighbors(n_neighbors=50, algorithm='ball_tree')\nknn.fit(X_train)\n```", "```py\ndistances, neighbors = knn.kneighbors(X_train[100].reshape(1, -1), return_distance=True)\n\nprint(distances[0])\n\n[ 0\\.          0.91215747  1.16926793  1.22633855  1.24058958  1.32139841\n  1.3564084   1.36645069  1.41972709  1.43341812  1.45236875  1.50130152\n  1.52709897  1.5499496   1.62379763  1.62620148  1.6345871   1.64292993\n  1.66770801  1.70934929  1.71619128  1.71619128  1.72187216  1.73317808\n  1.74888357  1.75445861  1.75668367  1.75779514  1.76555586  1.77878118\n  1.788636    1.79408751  1.79626348  1.80169191  1.80277564  1.80385871\n  1.80494113  1.8125      1.81572988  1.83498978  1.84771819  1.87291551\n  1.87916205  1.88020112  1.88538789  1.88745861  1.88952706  1.90906554\n  1.91213232  1.92333532]\n```", "```py\nimport numpy as np\n\nfrom sklearn.cluster import KMeans\n\nmin_nb_clusters = 2\nmax_nb_clusters = 20\n\ninertias = np.zeros(shape=(max_nb_clusters - min_nb_clusters + 1,))\n\nfor i in range(min_nb_clusters, max_nb_clusters + 1):\n    km = KMeans(n_clusters=i, random_state=1000)\n    km.fit(X_train)\n    inertias[i - min_nb_clusters] = km.inertia_\n```", "```py\nkm = KMeans(n_clusters=10, random_state=1000)\nY = km.fit_predict(X_train)\n```", "```py\nfrom sklearn.manifold import TSNE\n\ntsne = TSNE(n_components=2, perplexity=20.0, random_state=1000)\nX_tsne = tsne.fit_transform(X_train)\n```", "```py\nfrom sklearn.metrics import homogeneity_score\n\nprint(homogeneity_score(digits['target'], Y))\n0.739148799605\n```", "```py\nfrom sklearn.metrics import completeness_score\n\nprint(completeness_score(digits['target'], Y))\n0.747718831945\n```", "```py\nfrom sklearn.metrics import adjusted_rand_score\n\nprint(adjusted_rand_score(digits['target'], Y))\n0.666766395716\n```", "```py\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\nimport numpy as np\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples\n\nfig, ax = plt.subplots(2, 2, figsize=(15, 10))\n\nnb_clusters = [3, 5, 10, 12]\nmapping = [(0, 0), (0, 1), (1, 0), (1, 1)]\n\nfor i, n in enumerate(nb_clusters):\n    km = KMeans(n_clusters=n, random_state=1000)\n    Y = km.fit_predict(X_train)\n\n    silhouette_values = silhouette_samples(X_train, Y)\n\n    ax[mapping[i]].set_xticks([-0.15, 0.0, 0.25, 0.5, 0.75, 1.0])\n    ax[mapping[i]].set_yticks([])\n    ax[mapping[i]].set_title('%d clusters' % n)\n    ax[mapping[i]].set_xlim([-0.15, 1])\n    ax[mapping[i]].grid()\n    y_lower = 20\n\n    for t in range(n):\n        ct_values = silhouette_values[Y == t]\n        ct_values.sort()\n\n        y_upper = y_lower + ct_values.shape[0]\n\n        color = cm.Accent(float(t) / n)\n        ax[mapping[i]].fill_betweenx(np.arange(y_lower, y_upper), 0, ct_values, facecolor=color, edgecolor=color)\n\n        y_lower = y_upper + 20\n```", "```py\nfrom skfuzzy.cluster import cmeans\n\nfc, W, _, _, _, _, pc = cmeans(X_train.T, c=10, m=1.25, error=1e-6, maxiter=10000, seed=1000)\n```", "```py\nprint(pc)\n0.632070870735\n```", "```py\nprint(W[:, 7])\n[ 0.00373221  0.01850326  0.00361638  0.01032591  0.86078292  0.02926149\n  0.03983662  0.00779066  0.01432076  0.0118298 ]\n```", "```py\nimport numpy as np\n\nfrom skfuzzy.cluster import cmeans_predict\n\nnew_sample = np.expand_dims(X_train[7], axis=1)\nWn, _, _, _, _, _ = cmeans_predict(new_sample, cntr_trained=fc, m=1.25, error=1e-6, maxiter=10000, seed=1000)\n\nprint(Wn.T)\n[[ 0.00373221  0.01850326  0.00361638  0.01032591  0.86078292  0.02926149\n   0.03983662  0.00779066  0.01432076  0.0118298 ]]\n```", "```py\nimport numpy as np\n\nfrom sklearn.preprocessing import StandardScaler\n\nnb_samples = 1000\n\nX = np.zeros(shape=(nb_samples, 2))\n\nfor i in range(nb_samples):\n    X[i, 0] = float(i)\n\n    if i % 2 == 0:\n        X[i, 1] = 1.0 + (np.random.uniform(0.65, 1.0) * np.sin(float(i) / 100.0))\n    else:\n        X[i, 1] = 0.1 + (np.random.uniform(0.5, 0.85) * np.sin(float(i) / 100.0))\n\nss = StandardScaler()\nXs = ss.fit_transform(X)\n```", "```py\nfrom sklearn.cluster import KMeans\n\nkm = KMeans(n_clusters=2, random_state=1000)\nY_km = km.fit_predict(Xs)\n```", "```py\nfrom sklearn.cluster import SpectralClustering\n\nsc = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', n_neighbors=20, random_state=1000)\nY_sc = sc.fit_predict(Xs)\n```"]