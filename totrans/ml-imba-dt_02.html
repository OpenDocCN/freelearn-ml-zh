<html><head></head><body>
		<div id="_idContainer034">
			<h1 id="_idParaDest-38" class="chapter-number"><a id="_idTextAnchor042"/>2</h1>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor043"/>Oversampling Methods</h1>
			<p>In machine learning, we often don’t have enough samples of the minority class. One solution might be to gather more samples of such a class. For example, in the problem of detecting whether a patient has cancer or not, if we don’t have enough samples of the cancer class, we can wait for some time to gather more samples. However, such a strategy is not always feasible or sensible and can be time-consuming. In such cases, we can augment our data by using various techniques. One such technique <span class="No-Break">is oversampling.</span></p>
			<p>In this chapter, we will introduce the concept of oversampling, discuss when to use it, and the various techniques to perform it. We will also demonstrate how to utilize these techniques through the <strong class="source-inline">imbalanced-learn</strong> library APIs and compare their performance using some classical machine learning models. Finally, we will conclude with some practical advice on which techniques tend to work best under specific <span class="No-Break">real-world conditions.</span></p>
			<p>In this chapter, we will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li><span class="No-Break">Random oversampling</span></li>
				<li><span class="No-Break">SMOTE</span></li>
				<li><span class="No-Break">SMOTE variants</span></li>
				<li><span class="No-Break">ADASYN</span></li>
				<li>Model performance comparison of various <span class="No-Break">oversampling methods</span></li>
				<li>Guidance for using various <span class="No-Break">oversampling techniques</span></li>
				<li>Oversampling in <span class="No-Break">multi-class classification</span></li>
			</ul>
			<h1 id="_idParaDest-40"><a id="_idTextAnchor044"/>Technical requirements</h1>
			<p>In this chapter, we will utilize common libraries such as <strong class="source-inline">numpy</strong>, <strong class="source-inline">scikit-learn</strong>, and <strong class="source-inline">imbalanced-learn</strong>. The code and notebooks for this chapter are available on GitHub at <a href="https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter02">https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter02</a>. You can just fire up the GitHub notebook using Google Colab by clicking on the <strong class="bold">Open in Colab</strong> icon at the top of this chapter’s notebook or by launching it from <a href="https://colab.research.google.com">https://colab.research.google.com</a> using the GitHub URL of <span class="No-Break">the notebook.</span></p>
			<h1 id="_idParaDest-41"><a id="_idTextAnchor045"/>What is oversampling?</h1>
			<p><strong class="bold">Sampling</strong> involves selecting a subset of observations from a larger set of observations. In this chapter, we’ll initially focus on binary classification problems with two classes: the positive class and the negative class. The minority class has significantly fewer instances than<a id="_idIndexMarker110"/> the majority class. Later in this chapter, we will explore multi-class classification problems. Toward the end of this chapter, we will look into oversampling for multi-class <span class="No-Break">classification problems.</span></p>
			<p><strong class="bold">Oversampling</strong> is a data<a id="_idIndexMarker111"/> balancing technique that generates more samples of the minority class. However, this can be easily scaled to work for any number of classes where there are multiple classes with an imbalance. <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.1</em> shows how samples of minority and majority classes are imbalanced (<strong class="bold">a</strong>) initially and balanced (<strong class="bold">b</strong>) after applying an <span class="No-Break">oversampling technique:</span></p>
			<div>
				<div id="_idContainer018" class="IMG---Figure">
					<img src="image/B17259_02_01.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.1 – An increase in the number of minority class samples after oversampling</p>
			<p><em class="italic">Why is oversampling needed</em>, you ask? It is<a id="_idIndexMarker112"/> required so that we give the model enough samples of the minority class to learn from it. If we offer too few instances of the minority class, the model may choose to ignore these minority class examples and focus solely on the <a id="_idIndexMarker113"/>majority class examples. This, in turn, would lead to the model not being able to learn the decision <span class="No-Break">boundary well.</span></p>
			<p>Let’s generate a two-class imbalanced dataset with a 1:99 ratio using the <strong class="source-inline">sklearn</strong> library’s <strong class="source-inline">make_classification</strong> API, which creates a normally distributed set of points for each class. This will generate an imbalanced dataset of two classes: one being the minority class with label 1 and the other being the majority class with label 0. We will apply various oversampling techniques throughout this chapter to balance <span class="No-Break">this dataset:</span></p>
			<pre class="source-code">
from collections import Counter
from sklearn.datasets import make_classification
X, y = make_classification(n_samples=10000, n_features=2,\
    n_redundant=0, n_classes=2, flip_y=0, n_clusters_per_class=2,\
    class_sep=0.79, weights=[0.99], random_state=81)</pre>			<p>This code generates 100 examples of class 1 and 9,900 examples of class 0 with an imbalance ratio <a id="_idIndexMarker114"/>of 1:99. By plotting the dataset, we can see how the examples <span class="No-Break">are distributed:</span></p>
			<div>
				<div id="_idContainer019" class="IMG---Figure">
					<img src="image/B17259_02_02.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.2 – The dataset with an imbalance ratio of 1:99</p>
			<p>In this section, we understood the need for oversampling. We also generated a synthetic imbalanced binary classification dataset to demonstrate the application of various <span class="No-Break">oversampling technique<a id="_idTextAnchor046"/>s.</span></p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor047"/>Random oversampling</h1>
			<p>The simplest strategy to balance<a id="_idIndexMarker115"/> the imbalance in a dataset is to randomly choose samples<a id="_idIndexMarker116"/> of the minority class and repeat or duplicate them. This is also called <strong class="bold">random oversampling </strong><span class="No-Break"><strong class="bold">with replacement</strong></span><span class="No-Break">.</span></p>
			<p>To increase the number of minority class observations, we can replicate the minority class data observations enough times to balance the two classes. Does this sound too trivial? Yes, but it works. By increasing the number of minority class samples, random oversampling reduces the bias toward the majority class. This helps the model learn the patterns and characteristics of the minority class <span class="No-Break">more effectively.</span></p>
			<p>We will use random oversampling from the <strong class="source-inline">imbalanced-learn</strong> library. The <strong class="source-inline">fit_resample</strong> API from the <strong class="source-inline">RandomOverSampler</strong> class resamples the original dataset and balances it. The <strong class="source-inline">sampling_strategy</strong> parameter is used to specify the new ratio of various classes. For example, we could say <strong class="source-inline">sampling_strategy=1.0</strong> to have an equal number of the <span class="No-Break">two classes.</span></p>
			<p>There are various ways to specify <strong class="source-inline">sampling_strategy</strong>, such as a float value, string value, or <strong class="source-inline">dict</strong> – for example, {0: 50, <span class="No-Break">1: 50}:</span></p>
			<pre class="source-code">
from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(sampling_strategy=1.0, random_state=42)
X_res, y_res = ros.fit_resample(X, y)
print('Resampled dataset shape %s' % Counter(y_res))</pre>			<p>Here is <span class="No-Break">the output:</span></p>
			<pre class="source-code">
Resampled dataset shape Counter({0: 9900, 1: 9900})</pre>			<p>So, we went from a <a id="_idIndexMarker117"/>ratio of 1:99 to 1:1, which is what we expected <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">sampling_strategy=1.0</strong></span><span class="No-Break">.</span></p>
			<p>Let’s plot the <span class="No-Break">oversampled dataset:</span></p>
			<div>
				<div id="_idContainer020" class="IMG---Figure">
					<img src="image/B17259_02_03.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.3 – Dataset oversampled using RandomOverSampler (label 1 examples appear unchanged due to overlap)</p>
			<p>After applying random oversampling, the examples with label 1 overlap each other, creating the impression that nothing has changed. Repeating the same data point over and over can cause the model to memorize the specific data points and not be able to generalize to new, unseen examples. The <strong class="source-inline">shrinkage</strong> parameter in <strong class="source-inline">RandomOverSampler</strong> lets us perturb or shift each point by a <span class="No-Break">small amount.</span></p>
			<p>The value of the <strong class="source-inline">shrinkage</strong> parameter has<a id="_idIndexMarker118"/> to be greater than or equal to 0 and can be <strong class="source-inline">float</strong> or <strong class="source-inline">dict</strong>. If a <strong class="source-inline">float</strong> data type is used, the same shrinkage factor will be used for all classes. If a <strong class="source-inline">dict</strong> data type is used, the shrinkage factor will be specific for <span class="No-Break">each class.</span></p>
			<p>In <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.4</em>, we can observe the impact of random oversampling <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">shrinkage=0.2</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/B17259_02_04.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.4 – Result of applying random oversampling with shrinkage=0.2</p>
			<p>Toward the end of this chapter, we will compare the performance of random oversampling with various other oversampling techniques across multiple models and datasets. This will provide insights into their effectiveness in <span class="No-Break">real-world applications.</span></p>
			<p class="callout-heading">🚀 Random oversampling in production at Grab</p>
			<p class="callout">Grab, a ride-hailing and food delivery service in Southeast Asia, developed an image collection platform [1] for storing and retrieving imagery and map data. A key feature of this platform was its ability to automatically <a id="_idIndexMarker119"/>detect and blur <strong class="bold">Personally Identifiable Information</strong> (<strong class="bold">PII</strong>), such as faces and license plates, in street-level images. This was essential for maintaining user privacy. The dataset that was used for this purpose had a significant imbalance, with far more negative samples (images without PII) than positive ones (images with PII). Manual annotation was not feasible, so they turned to machine learning to solve <span class="No-Break">this problem.</span></p>
			<p class="callout">To address the data<a id="_idIndexMarker120"/> imbalance, Grab employed the random oversampling technique to increase the number of positive samples, thereby enhancing the performance of their machine <span class="No-Break">learning m<a id="_idTextAnchor048"/>odel.</span></p>
			<h2 id="_idParaDest-43"><a id="_idTextAnchor049"/>Problems with random oversampling</h2>
			<p>Random oversampling can <a id="_idIndexMarker121"/>often lead to overfitting of the model since the generated synthetic observations get repeated, and the model sees the same observations again and again. Shrinkage tries to handle that in some sense, but it may be challenging to come up with an apt value of shrinkage, and shrinkage doesn’t care if the generated synthetic samples overlap with the majority class samples, which can lead to <span class="No-Break">other problems.</span></p>
			<p>In the previous section, we learned about the most basic and practical technique for applying oversampling to balance a dataset and reduce bias toward the majority class. Many times, random oversampling itself might give us such a high boost to our model’s performance that we may not even need to apply more advanced techniques. In production settings, it would also be beneficial to keep things plain and simple until we are ready to introduce more complexity in the pipeline. As they say, “premature optimization is the root of all evil,” so we start with something simple, so long as it does improve our <span class="No-Break">model’s performance.</span></p>
			<p>In the subsequent sections, we will explore some alternative techniques, such as SMOTE and ADASYN, which adopt a different approach to oversampling and alleviate some of the problems associated with the random <span class="No-Break">oversampling tech<a id="_idTextAnchor050"/>nique.</span></p>
			<h1 id="_idParaDest-44"><a id="_idTextAnchor051"/>SMOTE</h1>
			<p>The main problem with random oversampling is that it duplicates the observations from the minority class. This can often cause overfitting. <strong class="bold">Synthetic Minority Oversampling Technique</strong> (<strong class="bold">SMOTE</strong>) [2] solves this<a id="_idIndexMarker122"/> problem of duplication by using a technique <span class="No-Break">called </span><span class="No-Break"><strong class="bold">interpolation</strong></span><span class="No-Break">.</span></p>
			<p>Interpolation involves creating new <a id="_idIndexMarker123"/>data points in the range of known data points. Think of interpolation as being similar to the process of reproduction in biology. In reproduction, two individuals come together to produce a new individual with traits of both of them. Similarly, in interpolation, we pick two observations from the dataset and create a new observation by choosing a random point on the line joining the two <span class="No-Break">selected points.</span></p>
			<p>We oversample the minority class by interpolating synthetic examples. That prevents the duplication of minority samples while generating new synthetic observations similar to the known points. <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.5</em> depicts how <span class="No-Break">SMOTE works:</span></p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B17259_02_05.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.5 – Working of SMOTE</p>
			<p>Here, we can see <span class="No-Break">the following:</span></p>
			<ul>
				<li>The majority and minority class samples are <span class="No-Break">plotted (left)</span></li>
				<li>The synthetic samples are generated by taking a random point on the line joining a minority sample to two nearest neighbor majority class <span class="No-Break">samples (right)</span></li>
			</ul>
			<p>SMOTE was originally designed for continuous inputs. To keep the explanations simple, we’ll start with continuous inputs and discuss other kinds of <span class="No-Break">inputs later.</span></p>
			<p>First, we will <a id="_idIndexMarker124"/>examine the functioning of SMOTE and explore any potential disadvantages associated with <span class="No-Break">this te<a id="_idTextAnchor052"/>chnique.</span></p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor053"/>How SMOTE works</h2>
			<p>The SMOTE algorithm<a id="_idIndexMarker125"/> works <span class="No-Break">as follows:</span></p>
			<ol>
				<li>It considers only the samples from the <span class="No-Break">minority class.</span></li>
				<li>It trains KNN on the <a id="_idIndexMarker126"/>minority samples. A typical value of <strong class="source-inline">k</strong> <span class="No-Break">is 5.</span></li>
				<li>For each minority sample, a line is drawn between the point and each of its <span class="No-Break">KNN examples.</span></li>
				<li>For each such line segment, a point on the segment is randomly picked to create a new <span class="No-Break">synthetic example.</span></li>
			</ol>
			<p>Let’s use SMOTE using APIs from the <span class="No-Break"><strong class="source-inline">imbalanced-learn</strong></span><span class="No-Break"> library:</span></p>
			<pre class="source-code">
from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=0)
X_res, y_res = sm.fit_resample(X, y)
print('Resampled dataset shape %s' % Counter(y_res))</pre>			<p>Here is <span class="No-Break">the output:</span></p>
			<pre class="source-code">
Resampled dataset shape Counter({0: 9900, 1: 9900})</pre>			<p>The oversampled dataset looks <span class="No-Break">like this:</span></p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B17259_02_06.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.6 – Oversampling using SMOTE</p>
			<p class="callout-heading">🚀 Oversampling techniques in production at Microsoft</p>
			<p class="callout">In a real-world application at Microsoft [3], machine learning<a id="_idIndexMarker127"/> was employed to forecast <strong class="bold">Live Site Incidents</strong> (<strong class="bold">LSIs</strong>) for early detection and escalation of incidents for engineering teams. Every day, a high volume of incidents was<a id="_idIndexMarker128"/> being generated, most of which started as low-severity issues. Due to limited resources, it was impractical for engineering teams to investigate all incidents, leading to potential delays in mitigating critical issues until they had a significant <span class="No-Break">customer impact.</span></p>
			<p class="callout">To address this, Microsoft employed machine learning to forecast which LSIs could escalate into severe problems, aiming for proactive identification and early resolution. The challenge was the data imbalance in the training set: out of approximately 40,000 incidents, fewer than 2% escalated to high severity. Microsoft used two different oversampling techniques— bagged classification (covered in <a href="B17259_04.xhtml#_idTextAnchor120"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Ensemble Methods</em>), and SMOTE, which were the most effective in improving the model’s performance. They used a two-step pipeline for balancing classes: first, oversampling with <strong class="bold">SMOTE</strong> and then<a id="_idIndexMarker129"/> undersampling with <strong class="bold">RandomUnderSampler</strong> (covered in <a href="B17259_03.xhtml#_idTextAnchor079"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Undersampling Methods</em>). The pipeline automatically selected the optimal sampling ratios for both steps, and SMOTE performed better when combined with undersampling. The resulting end-to-end automated model was designed to be generic, making it applicable across different teams within or outside Microsoft, provided historical incidents were available for learning. The LSI insight tool used this model, which was adopted by various <span class="No-Break">engineering teams.</span></p>
			<p>Next, we will look at<a id="_idIndexMarker130"/> the limitations of <a id="_idTextAnchor054"/><span class="No-Break">using SMOTE.</span></p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor055"/>Problems with SMOTE</h2>
			<p>SMOTE has its pitfalls – for example, it can<a id="_idIndexMarker131"/> add noise to an already noisy dataset. It can also lead to class overlap issues <span class="No-Break">as follows:</span></p>
			<ul>
				<li>SMOTE generates minority class samples without considering the majority class distribution, which may increase the overlap between the classes. In <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.7</em>, we’re plotting the binary classification imbalanced dataset before and after applying SMOTE. We can see a lot of overlap between the two classes after <span class="No-Break">applying SMOTE:</span></li>
			</ul>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B17259_02_07.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.7 – Binary classification dataset before (left) and after (right) applying SMOTE (see the overlap between two classes on the right)</p>
			<ul>
				<li>The other case may be that you have a huge amount of data, and running SMOTE may increase the runtime of <span class="No-Break">your pipeline.</span></li>
			</ul>
			<p>Problem 1 can be solved by using the SMOTE variant Borderline-SMOTE (discussed in the <span class="No-Break">next section).</span></p>
			<p>In this section, we learned about SMOTE, which uses the nearest neighbor technique to generate synthetic samples of the minority class. Sometimes, SMOTE may perform better than random<a id="_idIndexMarker132"/> oversampling since it exploits the proximity to other minority class samples to generate <a id="_idTextAnchor056"/><span class="No-Break">new samples.</span></p>
			<h1 id="_idParaDest-47"><a id="_idTextAnchor057"/>SMOTE variants</h1>
			<p>Now, let’s look at some of the <a id="_idIndexMarker133"/>SMOTE variants, such as Borderline-SMOTE, SMOTE-NC, and SMOTEN. These variants apply the SMOTE algorithm to samples of a certain kind and may not always <span class="No-Break">be applicable.</span></p>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor058"/>Borderline-SMOTE</h2>
			<p>Borderline-SMOTE [4] is a variation<a id="_idIndexMarker134"/> of SMOTE that generates synthetic samples from the minority class samples that are near the<a id="_idIndexMarker135"/> classification boundary, which divides the majority class from the <span class="No-Break">minority class.</span></p>
			<h3>Why consider samples on the classification boundary?</h3>
			<p>The idea is that the examples near the classification boundary are more prone to misclassification than those far away from the decision boundary. Producing more such minority samples along the<a id="_idIndexMarker136"/> boundary would help the model learn better about the minority class. Intuitively, it is also true that the points away from the classification boundary likely won’t make the model a <span class="No-Break">better classifier.</span></p>
			<p>Here’s a step-by-step algorithm <span class="No-Break">for Borderline-SMOTE:</span></p>
			<ol>
				<li>We run a KNN algorithm over the <span class="No-Break">whole dataset.</span></li>
				<li>Then, we divide the minority class points into <span class="No-Break">three categories:</span><ul><li><em class="italic">Noise</em> points are minority class examples that have all the neighbors from the majority class. These points are buried among majority-class neighbors. They are likely outliers and can safely be ignored <span class="No-Break">as “noise.”</span></li><li><em class="italic">Safe</em> points have more minority-class neighbors than majority-class neighbors. Such observations don’t contain much information and can be <span class="No-Break">safely ignored.</span></li><li><em class="italic">Danger</em> points have <a id="_idIndexMarker137"/>more majority-class neighbors than minority-class neighbors. This implies that such observations are on or close to the boundary between the <span class="No-Break">two classes.</span></li></ul></li>
				<li>Then, we train a KNN model only on the minority <span class="No-Break">class examples.</span></li>
				<li>Finally, we apply the SMOTE algorithm to the <strong class="source-inline">Danger</strong> points. Note that the neighbors of these <strong class="source-inline">Danger</strong> points may or may not be marked <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">Danger</strong></span><span class="No-Break">.</span></li>
			</ol>
			<p>As shown in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.8</em>, Borderline-SMOTE focuses on the danger class points for synthetic <span class="No-Break">data generation:</span></p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/B17259_02_08.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.8 – The Borderline-SMOTE algorithm uses only danger points to generate synthetic samples. Danger points have more majority-class neighbors than minority-class ones</p>
			<p><span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.9</em> shows how Borderline-SMOTE focuses on the minority class samples that are near the classification boundary, which separates the majority and <span class="No-Break">minority classes:</span></p>
			<div>
				<div id="_idContainer026" class="IMG---Figure">
					<img src="image/B17259_02_09.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.9 – Illustrating Borderline-SMOTE</p>
			<p>Here, we can see <span class="No-Break">the following:</span></p>
			<p class="list-inset">a) Plots of majority<a id="_idIndexMarker138"/> and minority <span class="No-Break">class samples</span></p>
			<p class="list-inset">b) Synthetic samples generated using neighbors near the <span class="No-Break">classification boundary</span></p>
			<p>Let’s see how we can use Borderline-SMOTE from the <strong class="source-inline">imbalanced-learn</strong> library to perform oversampling of <span class="No-Break">the data:</span></p>
			<pre class="source-code">
print("Before: ", sorted(Counter(y).items()))
from imblearn.over_sampling import BorderlineSMOTE
X_resampled, y_resampled = BorderlineSMOTE().fit_resample(X, y)
print("After: ", sorted(Counter(y_resampled).items()))</pre>			<p>Here is <span class="No-Break">the output:</span></p>
			<pre class="source-code">
Before: [(0, 9900), (1, 100)]
After:  [(0, 9900), (1, 9900)]</pre>			<p>Can you guess the problem with focusing solely on data points on the decision boundary of the <span class="No-Break">two classes?</span></p>
			<p>Since this technique focuses so heavily on a very small number of points on the boundary, the points inside<a id="_idIndexMarker139"/> the minority class clusters are not sampled <span class="No-Break">at all:</span></p>
			<div>
				<div id="_idContainer027" class="IMG---Figure">
					<img src="image/B17259_02_10.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.10 – The Borderline-SMOTE algorithm utilizing danger points, with more majority- than minority-class neighbors, to generate synthetic samples</p>
			<p>In this section, we learned about Borderline-SMOTE, which generates synthetic minority class samples by focusing on the samples that are close to the classification boundary of the majority and minority classes, which, in turn, may help in improving the discrimination power of <span class="No-Break">the model.</span></p>
			<p class="callout-heading">🚀 Oversampling techniques in production at Amazon</p>
			<p class="callout">In a real-world application, Amazon <a id="_idIndexMarker140"/>used machine learning to optimize packaging types for products, aiming to reduce waste while ensuring product safety [5]. In their training dataset, which featured millions of product and package combinations, Amazon faced a significant class imbalance, with as few as 1% of the examples representing unsuitable product-package pairings (<span class="No-Break">minority class).</span></p>
			<p class="callout">To tackle this imbalance, Amazon used various <span class="No-Break">oversampling techniques:</span></p>
			<p class="callout">- Borderline-SMOTE oversampling, which resulted in a 4%-7% increase in PR-AUC but increased the training time <span class="No-Break">by 25%-35%.</span></p>
			<p class="callout">- A hybrid of random oversampling and<a id="_idIndexMarker141"/> random undersampling, where they randomly oversampled the minority class and undersampled the majority class. It led to a 6%-10% improvement in PR-AUC and increased the training time by up <span class="No-Break">to 25%.</span></p>
			<p class="callout">The best-performing technique was two-phase learning with random undersampling (discussed in <a href="B17259_07.xhtml#_idTextAnchor205"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Data-Level Deep Learning Methods)</em>, which improved PR-AUC by 18%-24% with no increase in <span class="No-Break">training time.</span></p>
			<p class="callout">They mentioned that the effectiveness of a technique in dealing with dataset imbalance is both domain- and dataset-specific. This real-world example underscores the effectiveness of oversampling techniques in tackling class <span class="No-Break">imbalance issues.</span></p>
			<p>Next, we will learn about another oversampling technique, called ADASYN, that oversamples examples <a id="_idIndexMarker142"/>near boundaries and in other low-density regions without completely ignoring data points that do not li<a id="_idTextAnchor059"/>e on <span class="No-Break">the boundary.</span></p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor060"/>ADASYN</h1>
			<p>While SMOTE doesn’t distinguish between the density distribution of minority class samples, <strong class="bold">Adaptive Synthetic Sampling</strong> (<strong class="bold">ADASYN</strong>) [6] focuses on harder-to-classify minority class samples since they are in a<a id="_idIndexMarker143"/> low-density area. ADASYN uses a weighted distribution of the minority class based on the difficulty of classifying the observations. This way, more synthetic data is generated from <span class="No-Break">harder samples:</span></p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/B17259_02_11.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.11 – Illustration of how ADASYN works</p>
			<p>Here, we can see <span class="No-Break">the following:</span></p>
			<ul>
				<li>a) The majority and minority class samples <span class="No-Break">are plotted</span></li>
				<li>b) Synthetic samples are generated depending on the hardness factor (<span class="No-Break">explained later)</span></li>
			</ul>
			<p>While SMOTE uses all <a id="_idIndexMarker144"/>samples from the minority class for oversampling uniformly, in ADASYN, the observations that are harder to classify are used <span class="No-Break">more often.</span></p>
			<p>Another difference between the two techniques is that, unlike SMOTE, ADASYN also uses the majority class observations while training KNN. It then decides the hardness of samples based on how many majority observations <a id="_idTextAnchor061"/>are <span class="No-Break">its <a id="_idTextAnchor062"/>neighbors.</span></p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor063"/>Working of ADASYN</h2>
			<p>ADASYN follows a<a id="_idIndexMarker145"/> simple algorithm. Here is the step-by-step working <span class="No-Break">of ADASYN:</span></p>
			<ol>
				<li value="1">First, it trains a KNN on the <span class="No-Break">entire dataset.</span></li>
				<li>For each observation of the minority class, we find the hardness factor. This factor tells us how difficult it is to classify that data point. The hardness factor, denoted by <span class="_-----MathTools-_Math_Variable">r</span>, is the ratio of the number of majority class neighbors with the total number of neighbors. Here, <span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">M</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">K</span><span class="_-----MathTools-_Math_Variable"> </span>, where <span class="_-----MathTools-_Math_Variable">M</span> is the count of majority class neighbors and <span class="_-----MathTools-_Math_Variable">K</span> is the total number of <span class="No-Break">nearest neighbors.</span></li>
				<li>For each minority observation, we generate synthetic samples proportional to the hardness factor by drawing a line between the minority observation and its neighbors (neighbors could be from the majority class or minority class). The harder it is to <a id="_idIndexMarker146"/>classify a data point, the more synthetic samples will be created <span class="No-Break">for it.</span></li>
			</ol>
			<p>Let’s see how we can use the ADASYN API from the <strong class="source-inline">imbalanced-learn</strong> library to perform oversampling of <span class="No-Break">the data:</span></p>
			<pre class="source-code">
from imblearn.over_sampling import ADASYN
X_resampled, y_resampled = ADASYN().fit_resample(X, y)
print(sorted(Counter(y_resampled).items()))</pre>			<p>Here is <span class="No-Break">the output:</span></p>
			<pre class="source-code">
<a id="_idTextAnchor064"/>[(0, 9900), (1, 9900)]</pre>			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B17259_02_12.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.12 – ADASYN prioritizes harder samples and incorporates majority class examples in KNN to assess sample hardness</p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B17259_02_13.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.13 – A memory aid summarizing various oversampling techniques</p>
			<p>In this section, we learned about ADASYN. Next, let’s see how we can deal with cases when our data<a id="_idIndexMarker147"/> contains <span class="No-Break">categorical features.</span></p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor065"/>Categorical features and SMOTE variants (SMOTE-NC and SMOTEN)</h2>
			<p>What if your data contains <a id="_idIndexMarker148"/>categorical features? A categorical feature can take one of a limited or fixed number of possible values, and it’s a parallel to enumerations (enums) in computer science. These could be nominal categorical features that lack a natural order (for example, hair color, ethnicity, and so on) or ordinal categorical features that have an inherent order (for example, low, medium, <span class="No-Break">and high):</span></p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B17259_02_14.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.14 – Categorical data and its types with examples</p>
			<ul>
				<li>For ordinal features, we can just encode them via sklearn’s <strong class="source-inline">OrdinalEncoder</strong>, which assigns the<a id="_idIndexMarker149"/> categories to the values 0, 1, 2, and <span class="No-Break">so on.</span></li>
				<li>For nominal features, none of the SMOTE variants we have learned so far will work. However, <strong class="source-inline">RandomOverSampler</strong> can handle nominal <span class="No-Break">features too:</span><pre class="source-code">
from imblearn.over_sampling import RandomOverSampler
X_cat_mix = np.array([["abc", 1], ["def", 2],\
    ["ghi", 3]], dtype=object)
y_cat_mix = np.array([0, 0, 1])
print('X_cat_mix:', X_cat_mix, '\n y_cat_mix: ', y_cat_mix)
X_resampled, y_resampled = RandomOverSampler().fit_resample(\
    X_cat_mix, y_cat_mix)
print('X_resampled:', X_resampled, '\n y_resampled: ',\
    y_resampled)</pre><p class="list-inset">Here is <span class="No-Break">the</span><span class="No-Break"><a id="_idIndexMarker150"/></span><span class="No-Break"> output:</span></p><pre class="source-code">X_cat_mix: [['abc' 1]
 ['def' 2]
 ['ghi' 3]]
 y_cat_mix:  [0 0 1]
X_resampled: [['abc' 1]
 ['def' 2]
 ['ghi' 3]
 ['ghi' 3]]
 y_resampled:  [0 0 1 1]</pre></li>			</ul>
			<p>However, SMOTE, by default, works only on continuous data and cannot be directly used on categorical data. <em class="italic">Why?</em> That’s<a id="_idIndexMarker151"/> because SMOTE works by generating a random point on the line joining two different data points of the minority class (also called interpolation). If our <a id="_idIndexMarker152"/>data is categorical and has values of “yes” and “no,” we would first need to transform such values into numbers. Even when we do so, say “yes” is mapped to 1 and “no” is mapped to 0, the interpolation via SMOTE may end up producing a new point of 0.3, which does not map to any <span class="No-Break">real category.</span></p>
			<p>Also, we cannot use the <strong class="source-inline">shrinkage</strong> parameter in <strong class="source-inline">RandomOverSampler</strong> with categorical data because this parameter is designed only for <span class="No-Break">continuous values.</span></p>
			<p>However, two variants of SMOTE can deal with <span class="No-Break">categorical features:</span></p>
			<ul>
				<li><strong class="bold">Synthetic Minority Oversampling TEchnique-Nominal Continuous</strong> (<strong class="bold">SMOTE-NC</strong>) [1] is used <a id="_idIndexMarker153"/>when we have both categorical (nominal – for example, T-shirt size, hair color, and so on) and numerical (continuous – for<a id="_idIndexMarker154"/> example, age, salary, and so on) features in the data. However, it’s important to note that SMOTE-NC doesn’t work with only categorical features; it requires some numerical features as well. The reason for this is the way the SMOTE-NC algorithm works. For the new synthetic minority sample, the continuous features are created using SMOTE’s usual method. The nominal (categorical) feature takes the value most common among <span class="No-Break">the KNNs.</span><p class="list-inset">Let’s use the SMOTENC API from <strong class="source-inline">imbalanced-learn</strong> to oversample our dataset. The first item in the dataset is categorical, and the second item <span class="No-Break">is continuous:</span></p><pre class="source-code">
from imblearn.over_sampling import SMOTENC
X_cat_mix = np.array([["small", 1],\
    ["medium", 2],\
    ["large", 3],\
    ["large", 4],\
    ["large", 5]], dtype=object)
y_cat_mix = np.array([0, 0, 1, 0, 1])
print('X_cat_mix:', X_cat_mix, '\n y_cat_mix: ', y_cat_mix)
X_resampled, y_resampled = SMOTENC(
    categorical_features=[0], k_neighbors=1, random_state=1
).fit_resample(X_cat_mix, y_cat_mix)
print('X_resampled:', X_resampled, '\ny_resampled: ', \
    y_resampled)</pre><p class="list-inset">Here is <span class="No-Break">the output:</span></p><pre class="source-code">X_cat_mix: [['small' 1]
           ['medium' 2]
           ['large' 3]
           ['large' 4]
           ['large' 5]]
y_cat_mix: [0 0 1 0 1]
X_resampled: [['small' 1.0]
             ['medium' 2.0]
             ['large' 3.0]
             ['large' 4.0]
             ['large' 5.0]
             ['large' 3.005630378122263]]
y_resampled:  [0 0 1 0 1 1]</pre></li>				<li><strong class="bold">Synthetic Minority Oversampling Technique for Nominal</strong> (<strong class="bold">SMOTEN</strong>) is used for nominal categorical <a id="_idIndexMarker155"/>data. SMOTEN performs the majority vote similar to <a id="_idIndexMarker156"/>SMOTE-NC for all the features. It considers all features as nominal categorical, and the feature value of new samples is decided by taking the most frequent category of the nearest neighbors. The distance metric that’s used for calculating the nearest neighbors is called the <strong class="bold">Value Distance Metric</strong> (<strong class="bold">VDM</strong>). VDM <a id="_idIndexMarker157"/>computes the distance between two attribute values by considering the distribution of class labels associated with each value. It is based on the idea that two attribute values are more similar if they have similar distributions of class labels. This way, VDM can capture the underlying relationships between categorical attributes and their corresponding <span class="No-Break">class labels.</span><p class="list-inset">Let’s look at some example code that <span class="No-Break">uses SMOTEN:</span></p><pre class="source-code">
from imblearn.over_sampling import SMOTEN
X_original = np.array([["abc"], \
                       ["def"], \
                       ["ghi"], \
                       ["ghi"], \
                       ["ghi"]], dtype=object)
y_original = np.array([0, 0, 1, 1, 1])
print('X_original:', X_original, '\ny_original: ', y_original)
X_resampled, y_resampled = \
    SMOTEN(k_neighbors=1).fit_resample(X_original, y_original)
print('X_resampled:', X_resampled, '\ny_resampled:', \
    y_resampled)</pre><p class="list-inset">Here is <span class="No-Break">the</span><span class="No-Break"><a id="_idIndexMarker158"/></span><span class="No-Break"> output:</span></p><pre class="source-code">X_original: [['abc']
             ['def']
             ['ghi']
             ['ghi']
             ['ghi']]
y_original:  [0 0 1 1 1]
X_resampled: [['abc']
              ['def']
              ['ghi']
              ['ghi']
              ['ghi']
              ['abc']]
y_resampled:  [0 0 1 1 1 0]</pre></li>			</ul>
			<p>In <em class="italic">Table 2.1</em>, we can <a id="_idIndexMarker159"/>see SMOTE, SMOTEN, and SMOTENC, with a few examples for each technique to demonstrate the difference <span class="No-Break">between them:</span></p>
			<table id="table001-2" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Type </strong><span class="No-Break"><strong class="bold">of SMOTE</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Features Supported</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Example Data</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">SMOTE</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Only numerical</span></p>
						</td>
						<td class="No-Table-Style">
							<p>features: [2.3, 4.5, 1.2], <span class="No-Break">label: 0</span></p>
							<p>features: [3.4, 2.2, 5.1], <span class="No-Break">label: 1</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">SMOTEN</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Categorical</span></p>
							<p>(nominal <span class="No-Break">or ordinal)</span></p>
						</td>
						<td class="No-Table-Style">
							<p>features: [‘green’, ‘square’], <span class="No-Break">label: 0</span></p>
							<p>features: [‘red’, ‘circle’], <span class="No-Break">label: 1</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">SMOTENC</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Numerical <span class="No-Break">or categorical</span></p>
							<p>(nominal <span class="No-Break">or ordinal)</span></p>
						</td>
						<td class="No-Table-Style">
							<p>features: [2.3, ‘green’, ‘small’, ‘square’], <span class="No-Break">label: 0</span></p>
							<p>features: [3.4, ‘red’, ‘large’, ‘circle’], <span class="No-Break">label: 1</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 2.1 – SMOTE and some of its common variants with example data</p>
			<p>In summary, we should use SMOTENC when we have a mix of categorical and continuous data types, while SMOTEN can only be used when all the columns are categorical. You might be <a id="_idIndexMarker160"/>curious about how the various oversampling methods compare with each other in terms of model performance<a id="_idTextAnchor066"/>. We’ll explore this topic in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor067"/>Model performance comparison of various oversampling methods</h1>
			<p>Let’s examine how some <a id="_idIndexMarker161"/>popular models perform with the different oversampling techniques we’ve discussed. We’ll use two datasets for this comparison: one synthetic and one real-world dataset. We’ll evaluate the performance of four oversampling techniques, as well as no sampling, using logistic regression and random <span class="No-Break">forest models.</span></p>
			<p>You can find all the related code in this book’s GitHub repository. In <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.15</em> and <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.16</em>, we can see the average precision score values for both models on the <span class="No-Break">two datasets:</span></p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B17259_02_15.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.15 – Performance comparison of various oversampling techniques on a synthetic dataset</p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B17259_02_16.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.16 – Performance comparison of various oversampling techniques on the thyroid_sick dataset</p>
			<p>Based on these plots, we <a id="_idIndexMarker162"/>can draw some <span class="No-Break">useful conclusions:</span></p>
			<ul>
				<li><strong class="bold">Effectiveness of oversampling</strong>: In general, using oversampling techniques seems to improve the average precision score compared to not using any <span class="No-Break">sampling (NoSampling).</span></li>
				<li><strong class="bold">Algorithm sensitivity</strong>: The effectiveness of oversampling techniques varies depending on the machine learning algorithm used. For example, random forest seems to benefit more from oversampling techniques than logistic regression, especially on <span class="No-Break">synthetic data.</span></li>
				<li><strong class="bold">Data sensitivity</strong>: The effectiveness also depends on the type of data. For instance, all oversampling techniques performed similarly on the <strong class="source-inline">thyroid_sick</strong> dataset but showed variations in the <span class="No-Break">synthetic data.</span></li>
				<li><span class="No-Break"><strong class="bold">Best performers</strong></span><span class="No-Break">:</span><ul><li>For logistic regression, all the oversampling techniques had a similar performance on the <span class="No-Break"><strong class="source-inline">thyroid_sick</strong></span><span class="No-Break"> data</span></li><li>For random forest, Borderline-SMOTE had the highest average precision score on <span class="No-Break">synthetic data</span></li></ul></li>
				<li><strong class="bold">Borderline-SMOTE special case</strong>: Borderline-SMOTE performed exceptionally well with random forest on synthetic data but was on par with other techniques on the <span class="No-Break"><strong class="source-inline">thyroid_sick</strong></span><span class="No-Break"> data.</span></li>
				<li><strong class="bold">No clear winner</strong>: There is no single oversampling technique that outperforms all others across all conditions. The choice of technique may depend on the specific algorithm and dataset <span class="No-Break">being used.</span></li>
			</ul>
			<p>Please note that the models<a id="_idIndexMarker163"/> used here are not tuned with the <span class="No-Break">best hyperparameters.</span></p>
			<p>Tuning the hyperparameters of random forest and logistic regression models may improve the models' <span class="No-Break">performance further.</span></p>
			<p>In general, there is no single technique that will always do better than the rest. We have multiple variables at play here, namely the “model” and the “data.” Most of the time, the only way to know is to try out a bunch of these techniques and find the one that works the best for our model and data. You may find yourself curious about how to choose from the numerous oversampling <span class="No-Break">options available<a id="_idTextAnchor068"/>.</span></p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor069"/>Guidance for using various oversampling techniques</h1>
			<p>Now, let’s review some guidelines on how to navigate through the various oversampling techniques we went over and how these <a id="_idIndexMarker164"/>techniques differ from <span class="No-Break">each other:</span></p>
			<ol>
				<li>Train a model without applying any sampling techniques. This will be our model with baseline performance. Any oversampling technique we apply is expected to give a boost to <span class="No-Break">this performance.</span></li>
				<li>Start with random oversampling and add some shrinkage too. We may have to play with some values of shrinkage to see if the model’s <span class="No-Break">performance improves.</span></li>
				<li>When we have categorical features, we have a couple <span class="No-Break">of options:</span><ol><li class="upper-roman">Convert all categorical features into numerical features first using one-hot encoding, label encoding, feature hashing, or other feature <span class="No-Break">transformation techniques.</span></li><li class="upper-roman">(Only for nominal categorical features) Use SMOTENC and SMOTEN directly on <span class="No-Break">the data.</span></li></ol></li>
				<li>Apply various oversampling techniques – random oversampling, SMOTE, Borderline-SMOTE, and ADASYN – and measure the model’s performance on metrics applicable to your problem, such as the average precision score, ROC-AUC, precision, recall, F1 score, <span class="No-Break">and more.</span></li>
				<li>Since oversampling alters the distribution of the training dataset, which is not the case for the test set or the real world, using oversampling can potentially generate biased predictions. After using oversampling, it can be essential to recalibrate our model’s probability scores depending on the application. Recalibration of the<a id="_idIndexMarker165"/> model corrects any bias introduced by altering the class distribution, ensuring more reliable decision-making when deployed. Similarly, adjusting the classification threshold is key for accurate model interpretation, especially with imbalanced datasets. For more details on recalibration and threshold adjustment, please see <a href="B17259_10.xhtml#_idTextAnchor279"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, <em class="italic">Model Calibration</em>, and <a href="B17259_05.xhtml#_idTextAnchor151"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <em class="italic">Cost-Sensitive </em><span class="No-Break"><em class="italic">Learning</em></span><span class="No-Break">, respectively.</span></li>
			</ol>
			<h2 id="_idParaDest-54"><a id="_idTextAnchor070"/>When to avoid oversampling</h2>
			<p>In <a href="B17259_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Introduction to Data Imbalance in Machine Learning</em>, we discussed scenarios where data imbalance may not be a concern. Those considerations should be revisited before you opt for oversampling techniques. Despite criticisms, the applicability of oversampling <a id="_idIndexMarker166"/>should be evaluated on a case-by-case basis. Here are some additional technical considerations to keep in mind when choosing to apply <span class="No-Break">oversampling techniques:</span></p>
			<ul>
				<li><strong class="bold">Computational cost</strong>: Oversampling increases the dataset’s size, leading to higher computational demands in terms of processing time and <span class="No-Break">hardware resources.</span></li>
				<li><strong class="bold">Data quality</strong>: If the minority class data is noisy or has many outliers, oversampling can introduce more noise, reducing <span class="No-Break">model reliability.</span></li>
				<li><strong class="bold">Classifier limitations</strong>: In scenarios with system constraints, such as extremely low latency, or when dealing with legacy systems, the use of strong classifiers (complex and more accurate models) may not be feasible. In these cases, we may be limited to using weak classifiers. Weak classifiers are simpler and less accurate but require fewer computational resources and have lower runtime latency. In such situations, oversampling can be beneficial [7]. For strong classifiers, oversampling <a id="_idIndexMarker167"/>may offer diminishing returns, and optimizing the decision threshold could sometimes serve as a simpler, less <span class="No-Break">resource-intensive alternative.</span></li>
			</ul>
			<p>Consider these factors when deciding whether to use oversampling methods for <span class="No-Break">imbalanced datasets.</span></p>
			<p><em class="italic">Table 2.2</em> summarizes the key ideas, pros, and cons of various oversampling techniques. This can help you better evaluate which oversampling method <span class="No-Break">to choose:</span></p>
			<table id="table002-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">SMOTE</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Borderline-SMOTE</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">ADASYN</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">SMOTE-NC </strong><span class="No-Break"><strong class="bold">and SMOTEN</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Key idea</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Choose random points on the line joining the nearest neighbors of minority <span class="No-Break">class examples.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Choose the minority samples on the boundary between the majority and minority classes. Perform SMOTE for such samples on <span class="No-Break">the boundary.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Automatically decides the number of minority class samples to generate according to density distribution. More points are generated where the density distribution <span class="No-Break">is low.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>It performs a majority vote for the categorical <span class="No-Break">features.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Pro</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Usually reduces <span class="No-Break">false negatives.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Creates synthetic samples that are not naïve copies of the <span class="No-Break">known data.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>It cares about the density distribution of <span class="No-Break">different classes.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>It works with <span class="No-Break">categorical data.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Con</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Overlapping classes may occur and can introduce more noise to data. This may not work well with high-dimensional data or multi-class <span class="No-Break">classification problems.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>It does not care about the distribution of minority <span class="No-Break">class examples.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>It focuses on areas where there is overlap between classes. It may focus too much on outliers, resulting in poor <span class="No-Break">model performance.</span></p>
						</td>
						<td class="No-Table-Style">
							<p>The same <span class="No-Break">as SMOTE.</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Figure"><a id="_idTextAnchor071"/></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 2.2 – Summarizing the various oversampling techniques that were discussed in this chapter</p>
			<p>In this section, we <a id="_idIndexMarker168"/>looked at some general guidelines to apply the various oversampling techniques we learned about in this chapter and the pros and cons of using them. Next, we will look at how to extend the various oversampling methods to multi-class <span class="No-Break">classification problems.</span></p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor072"/>Oversampling in multi-class classification</h1>
			<p>In multi-class classification <a id="_idIndexMarker169"/>problems, we have more than two <a id="_idIndexMarker170"/>classes or labels to be predicted, and hence more than one class may be imbalanced. This adds some more complexity to the problem. However, we can apply the same techniques to multi-class classification problems as well. The <strong class="source-inline">imbalanced-learn</strong> library provides the option to deal with multi-class classification in almost all the supported methods. We can choose from various sampling strategies using the <strong class="source-inline">sampling_strategy</strong> parameter. For multi-class classification, we can pass some fixed string values (called built-in strategies) to the <strong class="source-inline">sampling_strategy</strong> parameter in the SMOTE API. We can also pass a dictionary <a id="_idIndexMarker171"/>with <span class="No-Break">the following:</span></p>
			<ul>
				<li>Keys as the <span class="No-Break">class labels</span></li>
				<li>Values as the number of samples of <span class="No-Break">that class</span></li>
			</ul>
			<p>Here are the built-in strategies for <strong class="source-inline">sampling_strategy</strong> when using the parameter as <span class="No-Break">a string:</span></p>
			<ul>
				<li>The <strong class="source-inline">minority</strong> strategy resamples only the <span class="No-Break">minority class.</span></li>
				<li>The <strong class="source-inline">not minority</strong> strategy resamples all classes except the minority class. This may be helpful in the<a id="_idIndexMarker172"/> case of multi-class imbalance, where we have more than two classes and multiple classes are imbalanced, but we don’t want to touch the <span class="No-Break">minority class.</span></li>
				<li>The <strong class="source-inline">not majority</strong> strategy resamples all classes except the <span class="No-Break">majority class.</span></li>
				<li>The <strong class="source-inline">all</strong> strategy resamples <span class="No-Break">all classes.</span></li>
				<li>The <strong class="source-inline">auto</strong> strategy is the same as the <strong class="source-inline">not </strong><span class="No-Break"><strong class="source-inline">majority</strong></span><span class="No-Break"> strategy.</span></li>
			</ul>
			<p>The following code shows the usage of SMOTE for multi-class classification using various <span class="No-Break">sampling strategies.</span></p>
			<p>First, let’s create a dataset containing 100 samples with three classes that have weights of 0.1, 0.4, <span class="No-Break">and 0.5:</span></p>
			<pre class="source-code">
X, y = make_classification(n_classes=3, class_sep=2, \
    weights=[0.1, 0.4, 0.5], n_clusters_per_class=1, \
    n_samples=100, random_state=10)
print('Original dataset shape %s' % Counter(y))</pre>			<p>Here is <span class="No-Break">the output:</span></p>
			<pre class="source-code">
Original dataset shape Counter({2: 50, 1: 40, 0: 10})</pre>			<p>As expected, our dataset contains the three classes in the ratio 10:40:50 for classes 0, 1, and <span class="No-Break">2, respectively.</span></p>
			<p>Now, let’s apply SMOTE with the “<em class="italic">minority</em>” sampling strategy. This will oversample the class with the least number <span class="No-Break">of samples:</span></p>
			<pre class="source-code">
over_sampler = SMOTE(sampling_strategy='minority')
X_res, y_res = over_sampler.fit_resample(X, y)
print('Resampled dataset shape using minority strategy: %s'% \
    Counter(y_res))</pre>			<p>Here is <span class="No-Break">the output:</span></p>
			<pre class="source-code">
Resampled dataset shape using minority strategy: Counter({0: 50, 2: 50, 1: 40})</pre>			<p>Since class 0 previously had<a id="_idIndexMarker173"/> the least number of samples, the “<em class="italic">minority</em>” sampling strategy only oversampled class 0, making the number of samples <a id="_idIndexMarker174"/>equal to the number of samples in the <span class="No-Break">majority class.</span></p>
			<p>In the following code, we’re using a dictionary for oversampling. Here, for each class label (0, 1, or 2) as <strong class="source-inline">key</strong> in the <strong class="source-inline">sampling_strategy</strong> dictionary, we have the number of desired samples for each targeted class <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">value</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
print('Original dataset shape %s' % Counter(y))
over_sampler = SMOTE(sampling_strategy={
                             0 : 40,
                             1 : 40,
                             2 : 50})
X_res, y_res = over_sampler.fit_resample(X, y)
print('Resampled dataset shape using dict strategy: %s\n'% \
    Counter(y_res))</pre>			<p>Here is <span class="No-Break">the output:</span></p>
			<pre class="source-code">
Original dataset shape Counter({2: 50, 1: 40, 0: 10})
Resampled dataset shape using dict strategy:
         Counter({2: 50, 0: 40, 1: 40})</pre>			<p class="callout-heading">Tip</p>
			<p class="callout">Please note that when using <strong class="source-inline">dict</strong> within <strong class="source-inline">sampling_strategy</strong>, the number of desired samples for each class should be greater than or equal to the original number of samples. Otherwise, the <strong class="source-inline">fit_resample</strong> API will throw <span class="No-Break">an exception.</span></p>
			<p>In this section, we saw<a id="_idIndexMarker175"/> how to extend oversampling strategies to<a id="_idIndexMarker176"/> handle cases when we have imbalanced datasets with more than two classes. Most of the time, the “auto” <strong class="source-inline">sampling_strategy</strong> would be good enough and would balance all <span class="No-Break">the <a id="_idTextAnchor073"/>classes.</span></p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor074"/>Summary</h1>
			<p>In this chapter, we went through various oversampling techniques for dealing with imbalanced datasets and applied them using Python’s <strong class="source-inline">imbalanced-learn</strong> library (also called <strong class="source-inline">imblearn</strong>). We also saw the internal workings of some of the techniques by implementing them from scratch. While random oversampling generates new minority class samples by duplicating them, SMOTE-based techniques work by choosing random samples in the direction of nearest neighbors of the minority class samples. Though oversampling can potentially overfit the model on your data, it usually has more pros than cons, depending on the data <span class="No-Break">and model.</span></p>
			<p>We applied them to some of the synthesized and publicly available datasets and benchmarked their performance and effectiveness. We saw how different oversampling techniques may lead to model performance on a varying scale, so it becomes crucial to try a few different oversampling techniques to decide on the one that’s most optimal for <span class="No-Break">our data.</span></p>
			<p>If you feel intrigued by the prospect of discovering oversampling approaches relevant to deep learning models, we invite you to check out <a href="B17259_07.xhtml#_idTextAnchor205"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Data-Level Deep Learning Methods</em>, where we’ll discuss data-level techniques within the realm of <span class="No-Break">deep learning.</span></p>
			<p>In the next chapter, we will go over various <span class="No-Break">undersampling tec<a id="_idTextAnchor075"/>hniques.</span></p>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor076"/>Exercises</h1>
			<ol>
				<li>Explore the two variants of SMOTE, namely KMeans-SMOTE and SVM-SMOTE, from the <strong class="source-inline">imbalanced-learn</strong> library, not discussed in this chapter. Compare their performance with vanilla SMOTE, Borderline-SMOTE, and ADASYN using the logistic regression and random <span class="No-Break">forest models.</span></li>
				<li>For a classification problem with two classes, let’s say the minority class to majority class ratio is 1:20. How should we balance this dataset? Should we apply the balancing technique at test or evaluation time? Please provide a reason for <span class="No-Break">your answer.</span></li>
				<li>Let’s say we are trying to build a model that can estimate whether a person can be granted a bank loan or not. Out of the 5,000 observations we have, only 500 people got the loan approved. To balance the dataset, we duplicate the approved people data and then split it into train, test, and validation datasets. Are there any issues with using <span class="No-Break">this approach?</span></li>
				<li>Data normalization helps in dealing with data imbalance. Is this true? Why or <span class="No-Break">why not?</span></li>
				<li>Explore the various oversampling APIs available from the <strong class="source-inline">imbalanced-learn</strong> library here: <a href="https://imbalanced-learn.org/stable/references/over_sampling.html">https://imbalanced-learn.org/stable/references/over_sampling.html</a>. Pay attention to the various parameters of each of <span class="No-Break">t<a id="_idTextAnchor077"/>he APIs.</span></li>
			</ol>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor078"/>References</h1>
			<ol>
				<li value="1"><em class="italic">Protecting Personal Data in Grab’s Imagery</em> (<span class="No-Break">2021), </span><a href="https://engineering.grab.com/protecting-personal-data-in-grabs-imagery"><span class="No-Break">https://engineering.grab.com/protecting-personal-data-in-grabs-imagery</span></a><span class="No-Break">.</span></li>
				<li>N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, <em class="italic">SMOTE: Synthetic Minority Over-sampling Technique</em>, jair, vol. 16, pp. 321–357, Jun. 2002, <span class="No-Break">doi: </span><span class="No-Break">10.1613/jair.953</span><span class="No-Break">.</span></li>
				<li><em class="italic">Live Site Incident escalation forecast</em> (<span class="No-Break">2023), </span><a href="https://medium.com/data-science-at-microsoft/live-site-incident-escalation-forecast-566763a2178"><span class="No-Break">https://medium.com/data-science-at-microsoft/live-site-incident-escalation-forecast-566763a2178</span></a><span class="No-Break">.</span></li>
				<li>H. Han, W.-Y. Wang, and B.-H. Mao, <em class="italic">Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning</em>, in Advances in Intelligent Computing, D.-S. Huang, X.-P. Zhang, and G.-B. Huang, Eds., in Lecture Notes in Computer Science, vol. 3644. Berlin, Heidelberg: Springer Berlin Heidelberg, 2005, pp. 878–887. <span class="No-Break">doi: </span><span class="No-Break">10.1007/11538059_91</span><span class="No-Break">.</span></li>
				<li>P. Meiyappan and M. Bales, <em class="italic">Position Paper: Reducing Amazon’s packaging waste using multimodal deep learning</em>, (2021), article: <a href="https://www.amazon.science/latest-news/deep-learning-machine-learning-computer-vision-applications-reducing-amazon-package-waste">https://www.amazon.science/latest-news/deep-learning-machine-learning-computer-vision-applications-reducing-amazon-package-waste</a>, <span class="No-Break">paper: </span><a href="https://www.amazon.science/publications/position-paper-reducing-amazons-packaging-wasteusing-multimodal-deep-learning"><span class="No-Break">https://www.amazon.science/publications/position-paper-reducing-amazons-packaging-wasteusing-multimodal-deep-learning</span></a><span class="No-Break">.</span></li>
				<li>Haibo He, Yang Bai, E. A. Garcia, and Shutao Li, <em class="italic">ADASYN: Adaptive synthetic sampling approach for imbalanced learning</em>, in 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence), Hong Kong, China: IEEE, Jun. 2008, pp. 1322–1328. <span class="No-Break">doi: </span><span class="No-Break">10.1109/IJCNN.2008.4633969</span><span class="No-Break">.</span></li>
				<li>Y. Elor and H. Averbuch-Elor, <em class="italic">To SMOTE, or not to SMOTE?</em>, arXiv, May 11, 2022. Accessed: Feb. 19, 2023. [Online]. Available <span class="No-Break">at </span><a href="http://arxiv.org/abs/2201.08528"><span class="No-Break">http://arxiv.org/abs/2201.08528</span></a><span class="No-Break">.</span></li>
			</ol>
		</div>
	</body></html>