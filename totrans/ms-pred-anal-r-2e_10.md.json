["```py\n> adjacency_m\n  1 2 3 4 5 6 7\n1 0 0 0 0 0 1 0\n2 1 0 0 0 0 0 0\n3 0 0 0 0 0 0 1\n4 0 0 1 0 1 0 1\n5 0 0 0 0 0 0 0\n6 0 0 0 1 1 0 1\n7 0 0 0 0 1 0 0\n```", "```py\n> path_to_neg_folder <- \"~/aclImdb/train/neg\"\n> path_to_pos_folder <- \"~/aclImdb/train/pos\"\n> library(\"tm\")\n> nb_pos <- Corpus(DirSource(path_to_pos_folder), \n                   readerControl = list(language = \"en\"))\n> nb_neg <- Corpus(DirSource(path_to_neg_folder), \n                  readerControl = list(language = \"en\"))\n> nb_all <- c(nb_pos, nb_neg, recursive = T)\n```", "```py\n> meta(nb_all[[1]])\nMetadata:\n  author       : character(0)\n  datetimestamp: 2015-04-19 09:17:48\n  description  : character(0)\n  heading      : character(0)\n  id           : 0_9.txt\n  language     : en\n  origin       : character(0)\n```", "```py\n> ids <- sapply( 1 : length(nb_all),\n                 function(x) meta(nb_all[[x]], \"id\"))\n> head(ids)\n[1] \"0_9.txt\"     \"1_7.txt\"     \"10_9.txt\"    \"100_7.txt\"\n[5] \"1000_8.txt\"  \"10000_8.txt\"\n```", "```py\n> scores <- as.numeric(sapply(ids,\n            function(x) sub(\"[0-9]+_([0-9]+)\\\\.txt\", \"\\\\1\", x)))\n> scores <- factor(ifelse(scores >= 5, \"positive\", \"negative\"))\n> summary(scores)\nnegative positive\n   12500    12500\n```", "```py\n> nb_all <- tm_map(nb_all, content_transformer(removeNumbers))\n> nb_all <- tm_map(nb_all, content_transformer(removePunctuation))\n> nb_all <- tm_map(nb_all, content_transformer(tolower))\n> nb_all <- tm_map(nb_all, content_transformer(removeWords), \n                           stopwords(\"english\"))\n> nb_all <- tm_map(nb_all, content_transformer(stripWhitespace))\n```", "```py\n> nb_dtm <- DocumentTermMatrix(nb_all)\n> dim(nb_dtm)\n[1]  25000 117473\n```", "```py\n> nb_dtm\n<<DocumentTermMatrix (documents: 25000, terms: 117473)>>\nNon-/sparse entries: 2493414/2934331586\nSparsity           : 100%\nMaximal term length: 64\nWeighting          : term frequency (tf)\n```", "```py\n> nb_dtm <- removeSparseTerms(x = nb_dtm, sparse = 0.99)\n> dim(nb_dtm)\n[1] 25000  1603\n```", "```py\n> nb_dtm <- weightBin(nb_dtm)\n```", "```py\n> inspect(nb_dtm[10:16, 1:6])\n<<DocumentTermMatrix (documents: 7, terms: 6)>>\nNon-/sparse entries: 2/40\nSparsity           : 95%\nMaximal term length: 10\nWeighting          : binary (bin)\n             Terms\nDocs          ability able absolute absolutely absurd academy\n  10004_8.txt       0    1        0          0      0       0\n  10005_7.txt       0    0        0          0      0       0\n  10006_7.txt       0    0        0          0      0       0\n  10007_7.txt       0    0        0          0      0       0\n  10008_7.txt       0    0        0          0      0       1\n  10009_9.txt       0    0        0          0      0       0\n  1001_8.txt        0    0        0          0      0       0\n```", "```py\n> nb_df <- as.data.frame(as.matrix(nb_dtm))\n> library(caret)\n> set.seed(443452342)\n> nb_sampling_vector <- createDataPartition(scores, p = 0.80, \n                                            list = FALSE)\n> nb_df_train <- nb_df[nb_sampling_vector,]\n> nb_df_test <- nb_df[-nb_sampling_vector,]\n> scores_train = scores[nb_sampling_vector]\n> scores_test = scores[-nb_sampling_vector]\n```", "```py\n> library(\"e1071\")\n> nb_model <- naiveBayes(nb_dtm_train, scores_train)\n```", "```py\n> nb_train_predictions <- predict(nb_model, nb_df_train)\n> mean(nb_train_predictions == scores_train)\n[1] 0.83015\n> table(actual = scores_train, predictions = nb_train_predictions)\n          predictions\nactual     negative positive\n  negative     8442     1558\n  positive     1839     8161\n```", "```py\n> nb_test_predictions <- predict(nb_model, nb_df_test)\n> mean(nb_test_predictions == scores_test)\n[1] 0.8224\n> table(actual = scores_test, predictions = nb_test_predictions)\n          predictions\nactual     negative positive\n  negative     2090      410\n  positive      478     2022\n```", "```py\n> nb_all <- tm_map(nb_all, stemDocument, language = \"english\")\n> nb_dtm <- DocumentTermMatrix(nb_all) \n> nb_dtm <- removeSparseTerms(x = nb_dtm, sparse = 0.99)\n> nb_dtm <- weightBin(nb_dtm)\n> nb_df_train <- nb_df[nb_sampling_vector,]\n> nb_df_test <- nb_df[-nb_sampling_vector,]\n> dim(nb_dtm)\n[1] 25000  1553\n```", "```py\n> nb_model_stem <- naiveBayes(nb_df_train, scores_train)\n> nb_test_predictions_stem <- predict(nb_model_stem, nb_df_test)\n> mean(nb_test_predictions_stem == scores_test)\n[1] 0.8\n> table(actual = scores_test, predictions = \n                              nb_test_predictions_stem)\n          predictions\nactual     negative positive\n  negative     2067      433\n  positive      567     1933\n```", "```py\n> emotion_words <- c(\"good\", \"bad\", \"enjoyed\", \"hated\", \"like\")\n> nb_dtm <- DocumentTermMatrix(nb_all, list(dictionary = \n                                            emotion_words))\n```", "```py\n> promoters <- read.csv(\"promoters.data\", header = F, dec = \",\", \n               strip.white = TRUE, stringsAsFactors = FALSE)\n> promoters[1,]\n  V1  V2                                                        V3\n1  + S10 tactagcaatacgcttgcgttcggtggttaagtatgtataatgcgcgggcttgtcgt\n```", "```py\n> positive_observations <- subset(promoters, V1 == '+', 3)\n> negative_observations <- subset(promoters, V1 == '-', 3)\n```", "```py\n> positive_observations <- sapply(positive_observations, \n                           function(x) paste(\"S\", x, \"X\", sep=\"\"))\n> negative_observations <- sapply(negative_observations, \n                           function(x) paste(\"S\", x, \"X\", sep=\"\"))\n> positive_observations[1]\n[1] \"StactagcaatacgcttgcgttcggtggttaagtatgtataatgcgcgggcttgtcgtX\"\n```", "```py\n> positive_observations <- strsplit(positive_observations, \"\")\n> negative_observations <- strsplit(negative_observations, \"\")\n> head(positive_observations[[1]], n = 15)\n [1] \"S\" \"t\" \"a\" \"c\" \"t\" \"a\" \"g\" \"c\" \"a\" \"a\" \"t\" \"a\" \"c\" \"g\" \"c\"\n```", "```py\n> states <- c(\"S\", \"X\", \"a\", \"c\", \"g\", \"t\")\n> symbols <- c(\"S\", \"X\", \"a\", \"c\", \"g\", \"t\")\n> startingProbabilities <- c(1,0,0,0,0,0)\n> emissionProbabilities <- diag(6)\n> colnames(emissionProbabilities) <- states\n> rownames(emissionProbabilities) <- symbols\n> emissionProbabilities\n  S X a c g t\nS 1 0 0 0 0 0\nX 0 1 0 0 0 0\na 0 0 1 0 0 0\nc 0 0 0 1 0 0\ng 0 0 0 0 1 0\nt 0 0 0 0 0 1\n```", "```py\ncalculateTransitionProbabilities <- function(data, states) {\n  transitionProbabilities <- matrix(0, length(states), length(states))\n  colnames(transitionProbabilities) <- states\n  rownames(transitionProbabilities) <- states\n  for (index in 1:(length(data) - 1)) {\n    current_state <- data[index]\n    next_state <- data[index + 1]\n    transitionProbabilities[current_state, next_state] <- \n           transitionProbabilities[current_state, next_state] + 1\n  }\n  transitionProbabilities <- sweep(transitionProbabilities, 1, \n           rowSums(transitionProbabilities), FUN = \"/\")\n  return(transitionProbabilities)\n}\n```", "```py\n> negative_observation<-Reduce(function(x, y) c(x, y), \n                               negative_observations, c())\n> (transitionProbabilitiesNeg <- \n   calculateTransitionProbabilities(negative_observation, states))\n  S          X         a         c         g         t\nS 0 0.00000000 0.2264151 0.2830189 0.1320755 0.3584906\nX 1 0.00000000 0.0000000 0.0000000 0.0000000 0.0000000\na 0 0.02168022 0.2113821 0.2696477 0.2506775 0.2466125\nc 0 0.01256983 0.2500000 0.1634078 0.2667598 0.3072626\ng 0 0.01958225 0.3133159 0.2480418 0.1919060 0.2271540\nt 0 0.01622971 0.1885144 0.2434457 0.2946317 0.2571785\n```", "```py\n> library(\"HMM\")\n> negative_hmm <- initHMM(states, symbols, startProbs = \n  startingProbabilities, transProbs = transitionProbabilitiesNeg,\n  emissionProbs = emissionProbabilities)\n```", "```py\n> incorrect <- 0\n> for (obs in 1 : length(positive_observations)) {\n     positive_observation <- Reduce(function(x, y) c(x, y), \n                             positive_observations[-obs], c())\n     transitionProbabilitiesPos  <- \n    calculateTransitionProbabilities(positive_observation, states)\n     positive_hmm <- initHMM(states, symbols, \n                          startProbs = startingProbabilities, \n                          transProbs = transitionProbabilitiesPos, \n                          emissionProbs = emissionProbabilities)\n     test_observation <- positive_observations[[obs]]\n     final_index <- length(test_observation)\n     pos_probs <- exp(forward(positive_hmm, test_observation))\n     neg_probs <- exp(forward(negative_hmm, test_observation))\n     pos_seq_prob <- sum(pos_probs[, final_index])\n     neg_seq_prob <- sum(neg_probs[, final_index])\n     if (pos_seq_prob < neg_seq_prob) incorrect <- incorrect + 1\n }\n```", "```py\n> incorrect\n[1] 13\n```", "```py\n> positive_observation <- Reduce(function(x, y) c(x, y), \n                                 positive_observations, c())\n> transitionProbabilitiesPos  <- \n  calculateTransitionProbabilities(positive_observation, states)\n> positive_hmm = initHMM(states, symbols, startProbs = \n  startingProbabilities, transProbs = transitionProbabilitiesPos, \n  emissionProbs = emissionProbabilities)\n```", "```py\n> for (obs in 1:length(negative_observations)) {\n     negative_observation<-Reduce(function(x, y) c(x, y), \n                           negative_observations[-obs], c())\n     transitionProbabilitiesNeg <- \n    calculateTransitionProbabilities(negative_observation, states)\n     negative_hmm <- initHMM(states, symbols, \n                         startProbs = startingProbabilities, \n                         transProbs = transitionProbabilitiesNeg, \n                         emissionProbs = emissionProbabilities)\n     test_observation <- negative_observations[[obs]]\n     final_index <- length(test_observation)\n     pos_probs <- exp(forward(positive_hmm,test_observation))\n     neg_probs <- exp(forward(negative_hmm,test_observation))\n     pos_seq_prob <- sum(pos_probs[, final_index])\n     neg_seq_prob <- sum(neg_probs[, final_index])\n     if (pos_seq_prob > neg_seq_prob) incorrect <- incorrect+1\n }\n```", "```py\n> incorrect\n[1] 25\n> (cross_validation_accuracy <- 1 - (incorrect/nrow(promoters)))\n [1] 0.7641509\n```", "```py\n> library(\"tm\")\n> nb_pos <- Corpus(DirSource(path_to_pos_folder), \n                   readerControl = list(language = \"en\"))\n> nb_neg <- Corpus(DirSource(path_to_neg_folder), \n                  readerControl = list(language = \"en\"))\n> nb_all <- c(nb_pos, nb_neg, recursive = T)\n> nb_all <- tm_map(nb_all, content_transformer(tolower))\n```", "```py\n> texts <- sapply(1 : length(nb_all), function(x) nb_all[[x]])\n```", "```py\n> texts <- sapply(texts, function(x) gsub(\"\\\\s\", \"W\", x))\n> texts <- sapply(texts, function(x) gsub(\"[0-9]\", \"N\", x))\n> texts <- sapply(texts, function(x) gsub(\"[[:punct:]]\", \"P\", x))\n> texts <- sapply(texts, function(x) gsub(\"[^a-zWNP]\", \"O\", x))\n```", "```py\n> big_text_splits <- lapply(texts[1:100], \n                            function(x) strsplit(x, \"\"))\n> big_text_splits <- unlist(big_text_splits, use.names = F)\n```", "```py\n> states <- c(\"s1\", \"s2\", \"s3\")\n> numstates <- length(states)\n> symbols <- c(letters, \"W\", \"N\", \"P\", \"O\")\n> numsymbols <- length(symbols)\n```", "```py\n> set.seed(124124) \n> startingProbabilities <- matrix(runif(numstates), 1, numstates)\n> startingProbabilities <- sweep(startingProbabilities, 1, \n                           rowSums(startingProbabilities), FUN = \"/\")\n> set.seed(454235) \n> transitionProbabilities <- matrix(runif(numstates * numstates), \n                      numstates, numstates)\n> transitionProbabilities <- sweep(transitionProbabilities, 1, \n                      rowSums(transitionProbabilities), FUN = \"/\")\n> set.seed(923501) \n> emissionProbabilities <- matrix(runif(numstates * numsymbols), \n                      numstates, numsymbols)\n> emissionProbabilities <- sweep(emissionProbabilities, 1, \n                      rowSums(emissionProbabilities), FUN = \"/\")\n```", "```py\n> hmm <- initHMM(states, symbols,  startProbs =  \n      startingProbabilities, transProbs = transitionProbabilities, \n      emissionProbs = emissionProbabilities)\n> hmm_trained <- baumWelch(hmm, big_text_splits)\n```", "```py\n> (trained_transition_probabilities <- hmm_trained$hmm$transProbs)\n    to\nfrom           s1           s2         s3\n  s1 1.244568e-01 5.115204e-01 0.36402279\n  s2 7.739387e-05 2.766151e-01 0.72330746   s3 9.516911e-01 5.377194e-06 0.04830349\n```", "```py\n> set.seed(987987)\n> simHMM(hmm_trained$hmm, 30)\n$states\n [1] \"s2\" \"s3\" \"s1\" \"s3\" \"s3\" \"s1\" \"s3\" \"s3\" \"s1\" \"s1\" \"s2\" \"s3\"\n[13] \"s3\" \"s1\" \"s2\" \"s3\" \"s1\" \"s2\" \"s2\" \"s2\" \"s3\" \"s1\" \"s2\" \"s2\"\n[25] \"s3\" \"s1\" \"s2\" \"s3\" \"s1\" \"s2\"\n$observation\n [1] \"h\" \"o\" \"P\" \"P\" \"a\" \"n\" \"W\" \"i\" \"r\" \"r\" \"h\" \"e\" \"i\" \"n\" \"h\"\n[16] \"o\" \"n\" \"l\" \"W\" \"h\" \"e\" \"s\" \"t\" \"W\" \"e\" \"t\" \"c\" \"e\" \"P\" \"W\"\n```", "```py\n> library(\"markovchain\")\n> simpleMc<-new(\"markovchain\", states = c(\"s1\", \"s2\", \"s3\"), \n                transitionMatrix = trained_transition_probabilities, \n                name = \"simpleMc\")\n> steadyStates(simpleMc)\n            s1       s2        s3\n[1,] 0.3806541 0.269171 0.3501748\n```"]