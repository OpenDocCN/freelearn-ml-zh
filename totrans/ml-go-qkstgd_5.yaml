- en: Using Pretrained Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous two chapters, you learned how to use supervised ML algorithms
    ([Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised Learning*)
    and unsupervised ML algorithms ([Chapter 4](26788e93-3614-413f-bcde-5580516f9c5f.xhtml),
    *Unsupervised Learning*) to solve a wide range of problems. The solutions created
    models from scratch and consisted only of Go code. We did not use models that
    had already been trained, nor did we attempt to call Matlab, Python, or R code
    from Go. However, there are several situations in which this can be beneficial.
    In this chapter, we will present several strategies aimed at using pretrained
    models and creating polyglot ML applications – that is, where the main application
    logic is written in Go but where specialist techniques and models may have been
    written in other languages.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn about the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: How to load a pretrained GoML model and use it to generate a prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to consider using a pure-Go solution or polyglot solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use the os/exec package to invoke ML models written in other languages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use HTTP to invoke ML models written in other languages, where they may
    reside on a different machine or even across the internet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to run TensorFlow models using the TensorFlow API for Go
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to restore a saved GoML model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you have put the hard work into creating a ML model, you may need to shut
    down your computer. What happens to your model when the computer is restarted?
    Unless you have persisted it to disk, it will disappear and you will need to start
    the training process again. Even if you have saved the model hyperparameters in
    a gophernotes notebook, the model itself will not have been saved. And if the
    training process is a long one, you may need to wait a long time before your model
    is ready to use again.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we will explain how to restore the model we created
    in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised Learning*,
    and persist it to the local filesystem in a `model.dat` file using its `PersistToFile` method,
    which is provided by the GoML API. We will restore it using its `RestoreFromFile` method.
    We will assume that all the other funcs we created in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised
    Learning*, are available to us, such as converting an image into a slice of floats:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use this code within gophernotes to generate a prediction and compare
    it to the ground truth in the `Label` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the preceding code cell in gophernotes will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We could also use the same validation techniques we introduced in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml),* Supervised
    Learning*, to check that the quality of the output is as expected. This approach
    works very well when the model was written in Go and persisted to be reused at
    a later time. However, if the model was written in Python and not recoverable
    directly in Go (such is the case for `scikit-learn` models, for example), the
    only way to use it to make a prediction may be to engineer some communication
    between a Python model and a Go application. While this increases the overall
    complexity of the applications, it has significant advantages, as we will discuss
    in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Deciding when to adopt a polyglot approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen in the previous chapters, the Go ecosystem provides ample opportunities
    to solve machine learning problems natively. However, being obstinate in requiring
    the solution to remain pure-Go can lead to increased development time or even
    reduced training performance, as other, more specialized ML libraries can provide
    higher-level APIs or performance optimizations that have not been implemented
    in the corresponding Go libraries yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'A good example of both is the Python ML library, Keras. The aim of this library
    is to provide a high-level API that allows the author to perform a wide range
    of ML tasks, such as data preprocessing, model training, model validation, and
    persistence. Its abstractions have concrete implementations in various backends,
    such as TensorFlow, which are known to be extremely performant. For these reasons,
    Keras is one of the most popular ML libraries in any language: its MIT-licensed
    GitHub repository has over 40,000 stars and a search on GitHub reveals that over
    20,000 repositories match the search term keras, meaning that the name of the
    repository includes that word. A search of the code content reveals that over
    one million files on GitHub contain the search term keras.'
  prefs: []
  type: TYPE_NORMAL
- en: However, to write the entire application in Python just to make use of one library
    fails to take advantage of the benefits offered by Go, which we enumerated in
    [Chapter 1](cefdc727-5b16-4942-8adb-a2d476e9d546.xhtml), *Introducing Machine
    Learning with Go*. If these factors are not important in the development of your
    application, then by all means create it in Python, but, in what follows, we will
    assume that you want the best of both worlds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, two options present themselves: first, develop the application entirely
    in Go. Second, develop the ML model in Python and invoke this model from your
    Go code, which will contain the main application and business logic. Within a
    commercial setting where the goal is to produce a production-ready product, the
    advantages of both options are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pure-Go application**:'
  prefs: []
  type: TYPE_NORMAL
- en: Easier to maintain over a polyglot solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less complexity in application component interactions, because there is no need
    to manage invocation of an external ML component
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easier to on-board team members
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less dependencies to update
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Existing libraries may offer the required functionality out of the box with
    sufficient performance, obviating any advantage gained from using specialized
    libraries in other languages.
  prefs: []
  type: TYPE_NORMAL
- en: '**Polyglot application**:'
  prefs: []
  type: TYPE_NORMAL
- en: Drastically reduce the amount of code for complex ML problems using high-level
    abstractions from specialist libraries in other languages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In some cases, performance advantages, as some GoML libraries are not designed
    for out-and-out speed (deep learning is a good example of this)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can suit a multi-team approach better, as data science teams are more familiar
    with Python or R libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage preexisting models—academic research papers typically publish Caffe
    or TensorFlow models with Python or Lua scripts to invoke them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In conclusion, for ML applications where existing Go libraries offer what you
    need out of the box or with little modification, a native Go solution will reduce
    complexity in the application and enhance maintainability. However, if this is
    not the case, particularly for very complex problems such as deep learning and
    computer vision, combining Go with the latest tools from other languages is worth
    the added complexity.
  prefs: []
  type: TYPE_NORMAL
- en: In the examples that follow, we will invoke a variety of Python ML models from
    a Go application. Our reason for using Python specifically is that Python is preinstalled
    in most Linux distributions and is also the most popular language for ML^([4][5]).
    The solutions we will describe can be applied to a model written in any programming
    language.
  prefs: []
  type: TYPE_NORMAL
- en: Example – invoking a Python model using os/exec
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get started with polyglot ML applications, we will revisit the logistic regression
    example from [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised
    Learning*. We will assume that, instead of Go, the model was written in Python
    and that we wish to invoke it from our Go application. To do this, we will use
    command-line arguments to pass inputs to the model and read the model's prediction
    from **standard output** (**STDOUT**).
  prefs: []
  type: TYPE_NORMAL
- en: To exchange data between Python and Go, we will use strings formatted using
    **JavaScript Object Notation** (**JSON**). This choice is arbitrary of course^([6]),
    and we could have chosen any one of the other formats for which the Go and Python
    standard libraries have support, such as XML, or invented our own. JSON has the
    advantage that it takes very little effort to use in both languages.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process we will follow to communicate with the Python subprocess is as
    follows. Generally, there are three steps: serialization of the request, executing
    the subprocess, and deserialization of the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c2271a0-d0ce-448b-bd00-dc17353a7b93.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig.1: The process we use to communicate with a Python subprocess that runs
    a pretrained logistic regression model'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by loading the MNIST dataset and converting it into a dataframe.
    You can find the code for this in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml),
    *Supervised Learning*. This time, however, we will convert the image data into
    a slice of ints, with each int between 0 and 255 (the value of each pixel), rather
    than a slice of floats. This is to ensure alignment with the Python model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will introduce a function that will allow us to start the Python subprocess
    and wait for it to finish:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to assemble our prediction function, which will serialize
    the image data, pass it to the subprocess as an argument when it starts, wait
    for the subprocess to finish, and deserialize the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use this code within gophernotes to generate a prediction and compare
    it to the ground truth in the `Label` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this in a gophernotes cell provides the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As expected, this outputs `true`. We can repeat this for several different images
    to get some confidence that everything is working as it should. Both the Go and
    Python code use the `predict` argument to signify which action should be performed
    – we could also have a `test` action that checks that the image the Python code
    reconstructs from its arguments is the correct one, further increasing our confidence
    that the subprocess communication is correct.
  prefs: []
  type: TYPE_NORMAL
- en: Subprocess communication can be operating system-specific, particularly when
    output redirection is involved. One advantage of Go is that the pipe method we
    present here works equally well across operating systems, with no extra modification
    needed, whereas, in other languages such as Python, additional work is sometimes
    required.
  prefs: []
  type: TYPE_NORMAL
- en: While the code is succinct and easy to debug, the need to start a new Python
    process to handle every request can impact performance for applications with smaller,
    quicker models. Furthermore, it creates a fairly tight coupling between the Go
    application and its Python model. This could pose an issue in larger teams where
    a data science team creates a model and a software development team creates the
    rest of the application. It could also create issues where the model should be
    exposed to multiple applications, not just one – what should you do then? Have
    one copy of the model for each application? This could lead to maintainability
    issues. In the following example, we will look at one way to decouple the Go application
    from its Python model.
  prefs: []
  type: TYPE_NORMAL
- en: Example – invoking a Python model using HTTP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What if the model resides on a different machine, we need to decouple the Go
    and model logic, or if there are multiple actions we may wish to perform, such
    as training a user-specific model based on user data, and later use this model
    to generate a prediction? In those cases, our previous solution using command-line
    arguments will become more complex as we add more arguments to distinguish between
    actions and return codes. This type of invocation is generally known as **Remote
    Procedure Call** (**RPC**), and solutions such as SOAP or JSON-RPC have been known
    to the industry for decades^([7]).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we will use a more universal and generic protocol:
    HTTP. Strictly speaking, HTTP is a data transfer protocol, and one that is often
    used as the plumbing for RPC protocols. However, with very little effort, we can
    create our own minimal RPC on top of HTTP by exposing a single endpoint that will
    accept POST requests. This has the advantage that no dependencies beyond the standard
    library in either Python or Go are required, and that debugging protocol errors
    are particularly straightforward. The downside is that it requires a bit more
    work to handle concerns such as serialization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The request/response process we will follow is illustrated in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6df6714f-40d5-4529-89fe-b80f27b22285.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 2: The request/reply process for a GoML application to communicate with
    a pretrained Python model using HTTP'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike the previous example, we assume that the Python HTTP server is already
    running. If you are following along with the companion repository, you can start
    the Python server with the `python3 model_http.py` command after installing its
    dependencies using `install-python-dependencies.sh`. This means that the Go code
    is particularly short:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'As we did previously, we can generate some predictions to ensure communication
    between Go and Python processes is working as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'As expected, we get back the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We can continue this process for several other images to ensure that the response
    matches the ground truth value, as defined by the `df.Col("Label")` series. We
    could also create multiple HTTP endpoints on our Python HTTP server to allow testing
    of various kinds, further enhancing our confidence in interprocess communication.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the likely event that you ever need to debug communication with an HTTP
    server, a great tool is Postman, a free GUI tool that lets you create HTTP requests
    and inspect the responses. You can get Postman at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.getpostman.com/](https://www.getpostman.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: In the previous examples, we assumed that the model was created in a different
    programming language (Python) and could only be accessed from that language. However,
    there are a few popular deep learning libraries that have striven to become more
    polyglot and, therefore, provide means to create a model using one language and
    use it using another. In the following examples, we will look at two of these
    libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Example – deep learning using the TensorFlow API for Go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning is a subfield of machine learning that employs neural networks,
    usually with many layers, to solve complex problems such image or speech recognition.
    In this example, we will look at how to leverage TensorFlow, a popular deep learning
    framework, using its Go bindings.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is a highly optimized library that was created by Google to perform
    calculations on objects called tensors^([8]). If a vector is a collection of scalar
    entries (numbers) and a matrix a collection of vectors, then a tensor can be thought
    of as a higher-dimensional matrix, of which scalars, vectors, and matrices are
    special cases. While this may seem a bit abstract, tensors are natural objects
    to use when describing neural networks, and this is why TensorFlow has become
    one of the most popular libraries—even *the* most popular, according to some commentators—for
    commercial and academic deep learning development^([9][10]).
  prefs: []
  type: TYPE_NORMAL
- en: In 2011, the team at Google Brain built a proprietary deep learning system called
    DistBelief^([11]). A number of prominent computer scientists such as Jeff Dean
    and Geoffrey Hinton worked on its backpropagation and other neural network-related
    algorithms, leading to an increased uptake of the framework across many projects
    at Google. In 2017, the second generation of this framework, now called TensorFlow,
    was released under an open source license^([12]).
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is at its core a low-level API, also known as a backend for deep
    learning computations. Practically speaking, a data scientist working a commercial
    problem does not usually need to interact directly with the TensorFlow API on
    a daily basis. Instead, a number of frontends, such as Keras, which we introduced
    previously, are available as higher-level abstractions over TensorFlow and offer
    the best of both the performance and ease-of-use worlds. On the other hand, academic
    research where new types of neural architectures are invented is often performed
    using the low-level API, because no abstractions exist for the new constructs
    yet. The objects you create in TensorFlow, called **graphs**, can be persisted
    and reused in other languages, thanks to recent efforts to make the framework
    more polyglot^([13]).
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will explain how to install TensorFlow and how to use its
    Go API to load a pretrained TensorFlow model and use it to make a prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Installing TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The TensorFlow experience is usually a slick one—that is, after you have managed
    to install it correctly. The TensorFlow team recognized that this was a difficult
    step, and that building TensorFlow from source usually took hours in the best
    case, and as a result they now provide several easy installation options. It is
    worth noting that, if you have a compatible GPU on your system, you should install
    a GPU option as this will usually accelerate the software significantly, something
    particularly noticeable in the training phase:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Install with pip**: TensorFlow is aimed at Python programmers who will typically
    use `pip` to manage their packages. At the time of writing, this method has been
    tested with Ubuntu Linux 16.04 or later, macOS 10.12.6 (Sierra) or later (albeit
    with no GPU support), Raspbian 9.0 or later, and Windows 7 or later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use a Docker image**: This will work with a wide range of systems that support
    Docker. There are two images to choose from: a vanilla TensorFlow image and one
    that also includes Jupyter, allowing you to have the same experience as gophernotes
    but with Python only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Build from source**: This is best option if you are using a non-standard
    configuration or want to exert specific control over part of the build process
    (perhaps take advantage of some optimization that will only work for your particular
    configuration).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is also a fourth option, which is to use Google Colaboratory to run TensorFlow-based
    code in Google's cloud, but we will not delve into this option, as it currently
    only works with Python.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will use a Docker image. Docker can be seen as a solution
    for packaging and running multiple applications (called containers) on the same
    machine while keeping them from interfering with one another. If you are not already
    familiar with it, head to [https://docs.docker.com/get-started/](https://docs.docker.com/get-started/)
    for a five-minute tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the vanilla TensorFlow-on-Ubuntu image called `tensorflow/tensorflow`,
    which does not include Jupyter. We will need to install Go on top of this image
    so that we can run our code. Because our code will depend on TensorFlow bindings
    for Go, we will also install them according to the official instructions^([14]).
    This will require us to install the TensorFlow C bindings, too. Our Dockerfile
    will thus look as follows. Some steps have been omitted for brevity – you can
    find the full Dockerfile in the companion repository for this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Import the pretrained TensorFlow model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised Learning*,
    we explained how to create a deep learning model in pure Go using the go-deep
    library. While this worked as a toy example, it was quite slow to train and required
    a lot of superfluous code. It would have been much easier, and resulted in more
    performance code, to use one of the industry-leading deep learning libraries,
    but unfortunately they are written in other languages. Using the Python library
    Keras, we have created a deep learning model that will serve as a classifier in
    the same problem that we looked at previously: *Is the given image of a pair of
    trousers?* We will now write some Go code to import our pretrained model.'
  prefs: []
  type: TYPE_NORMAL
- en: What if only the weights of the model were saved, rather than the more complete
    SavedModel format? In that case, you can still import it using the `graph.Import` func,
    but, subsequently, more work is required to tell TensorFlow about all the operations
    and variables. There is an example in the TensorFlow API godocs that illustrates
    this process^([15]).
  prefs: []
  type: TYPE_NORMAL
- en: What follows assumes that the model was saved in the `SavedModel` format and
    that we know the names of the input and output `Ops`. If the model was created
    by someone else using Keras or another third-party library, this can sometimes
    be tricky. One option is to use the `SavedModel` command-line interface tool to
    inspect the model^([16]).
  prefs: []
  type: TYPE_NORMAL
- en: If the model was created in Keras and you have access to the Python code, just
    inspect its `input` and `output` properties to see the names of the corresponding
    tensors. They may have a `:0` appended to them, which you can ignore.
  prefs: []
  type: TYPE_NORMAL
- en: 'To restore a `SavedModel` in Go, simply use the `LoadSavedModel` func. This
    will return a Graph and Session object that you can then operate on, passing inputs
    and retrieving outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the second argument, called the tag, is often set to serve by convention.
    We can now access the input and output operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: If either the input or output is nil at this stage, this means that you do not
    have the correct names, so you will need to return to inspecting the model to
    find out what they should be. It can also be useful to look at `savedModel.Graph.Operations`,
    which is a slice of `Operation`, and filter the list of operations down by those
    containing the search string input in their `Name()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now access the restored session and graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can run this code inside our TensorFlow Docker container and see the
    result. We will build the Docker image from its Dockerfile and run it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything goes well, we should see some output while the container is being
    built (this will run much faster the second time) with the following messages
    at the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The first two lines tell us that our Docker image was successfully built, and
    the last line comes from our Go code and lets us know that the model import operation
    worked without resulting in any errors.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on how you installed Docker, you may need superuser privileges to
    run these commands, so just prefix them with `sudo` if required.
  prefs: []
  type: TYPE_NORMAL
- en: Creating inputs to the TensorFlow model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we are able to recreate the TensorFlow graph and session from a `SavedModel`,
    we will create a procedure that will accept an image from the MNIST fashion dataset
    as a slice of bytes and use these bytes to populate the inputs of the model we
    loaded previously. Then, we will be able to run the model to get an output prediction.
  prefs: []
  type: TYPE_NORMAL
- en: We must create a procedure that will accept an image from the MNIST fashion
    dataset and return a tensor of the correct shape. We know from Chapter 3, *Supervised
    Learning*, that the model will expect a slice of 784 floats, and an inspection
    of the model (using `model.summary` in Python, or the `SavedModel` CLI) will reveal
    that the inputs should be a 1 x 784 tensor of `float32` values.
  prefs: []
  type: TYPE_NORMAL
- en: When constructing tensors by passing slices of slices as an argument to the
    `NewTensor` func, make sure that they are all the same length. For example, you
    can pass 3 slices containing 7 elements each, and this will create a (3,7) tensor,
    but not 3 slices containing 5, 6, and 7 elements, respectively—the second dimension
    must be the same for all slices.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can construct a blank (zero) tensor with the right shape like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: While this is not very useful on its own, it illustrates the use of the `NewTensor` func,
    which can infer the correct tensor shape and value type from the Go `interface{}` it
    is passed. Using the `ImageSeriesToFloats` func we introduced in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml),
    *Supervised Learning*, we can easily convert an image into a slice of `float32`
    and thus make the input tensor.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can run the model to get a prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, when running this with a blank tensor as the input, the last few
    lines of output are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the following chapter, we will explore the pattern of using Docker to deploy
    ML application workloads in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we compared Go-only and polyglot ML solutions from a practical
    point of view, contrasting their drawbacks and advantages. We then presented two
    generic solutions to develop polyglot ML solutions: the os/exec package and JSON-RPC.
    Finally, we looked at two highly-specialized libraries that come with their own
    RPC-based integration solutions: TensorFlow and Caffe. You have learned how to
    decide whether to use a Go-only or polyglot approach to ML in your application,
    how to implement an RPC-based polyglot ML application, and how to run TensorFlow
    models from Go.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will cover the last step of the ML development life
    cycle: taking an ML application written in Go to production.'
  prefs: []
  type: TYPE_NORMAL
- en: Further readings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Ke**ras GitHub repository*: [https://github.com/keras-team/keras](https://github.com/keras-team/keras).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*GitHub search for keras*: [https://github.com/search?utf8=%E2%9C%93&amp;q=keras&amp;type=](https://github.com/search?utf8=%E2%9C%93&q=keras&type=).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*GitHub content search for keras*: [https://github.com/search?q=keras&amp;type=Code](https://github.com/search?q=keras&type=Code).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Python is Becoming the World''s Most Popular Coding Language*, The Economist.
    July 26, 2018: [https://www.economist.com/graphic-detail/2018/07/26/python-is-becoming-the-worlds-most-popular-coding-language.](https://www.economist.com/graphic-detail/2018/07/26/python-is-becoming-the-worlds-most-popular-coding-language) Retrieved
    April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Using Python on Unix Platforms*: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*JSON*: [https://www.json.org/](https://www.json.org/). Retrieved April 30,
    2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Cover Pages – SOAP*: [http://xml.coverpages.org/soap.html](http://xml.coverpages.org/soap.html).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*TensorFlow Core*: [https://www.tensorflow.org/overview/](https://www.tensorflow.org/overview/).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Deep Learning Framework Power Scores*: [https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a](https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Ranking Popular Deep Learning Frameworks*: [https://blog.thedataincubator.com/2017/10/ranking-popular-deep-learning-libraries-for-data-science/](https://blog.thedataincubator.com/2017/10/ranking-popular-deep-learning-libraries-for-data-science/).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Dean, Jeff et. al. *Large-Scale Machine Learning on Heterogeneous Distributed
    Systems*. Nov. 9, 2015. [http://download.tensorflow.org/paper/whitepaper2015.pdf](http://download.tensorflow.org/paper/whitepaper2015.pdf).
    Retrieved April 30, 2019.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*TensorFlow* `RELEASE.md`: [https://github.com/tensorflow/tensorflow/blob/07bb8ea2379bd459832b23951fb20ec47f3fdbd4/RELEASE.md](https://github.com/tensorflow/tensorflow/blob/07bb8ea2379bd459832b23951fb20ec47f3fdbd4/RELEASE.md).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*TensorFlow in Other Languages*: [https://www.tensorflow.org/guide/extend/bindings](https://www.tensorflow.org/guide/extend/bindings).
    Retrieved April 30, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Installing TensorFlow for Go*: [https://www.tensorflow.org/install/lang_go ](https://www.tensorflow.org/install/lang_go).
    Retrieved May 1, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*TensorFlow—godocs*: [https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go](https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go).
    Retrieved May 3, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Save and Restore*: [https://www.tensorflow.org/guide/saved_model#install_the_savedmodel_cli](https://www.tensorflow.org/guide/saved_model#install_the_savedmodel_cli).
    Retrieved May 3, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Tag constants*: [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/tag_constants.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/tag_constants.py).
    Retrieved May 22, 2019.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
