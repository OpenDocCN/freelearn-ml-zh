- en: Using Pretrained Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous two chapters, you learned how to use supervised ML algorithms
    ([Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised Learning*)
    and unsupervised ML algorithms ([Chapter 4](26788e93-3614-413f-bcde-5580516f9c5f.xhtml),
    *Unsupervised Learning*) to solve a wide range of problems. The solutions created
    models from scratch and consisted only of Go code. We did not use models that
    had already been trained, nor did we attempt to call Matlab, Python, or R code
    from Go. However, there are several situations in which this can be beneficial.
    In this chapter, we will present several strategies aimed at using pretrained
    models and creating polyglot ML applications – that is, where the main application
    logic is written in Go but where specialist techniques and models may have been
    written in other languages.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn about the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: How to load a pretrained GoML model and use it to generate a prediction
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to consider using a pure-Go solution or polyglot solution
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use the os/exec package to invoke ML models written in other languages
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use HTTP to invoke ML models written in other languages, where they may
    reside on a different machine or even across the internet
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to run TensorFlow models using the TensorFlow API for Go
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to restore a saved GoML model
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you have put the hard work into creating a ML model, you may need to shut
    down your computer. What happens to your model when the computer is restarted?
    Unless you have persisted it to disk, it will disappear and you will need to start
    the training process again. Even if you have saved the model hyperparameters in
    a gophernotes notebook, the model itself will not have been saved. And if the
    training process is a long one, you may need to wait a long time before your model
    is ready to use again.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we will explain how to restore the model we created
    in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised Learning*,
    and persist it to the local filesystem in a `model.dat` file using its `PersistToFile` method,
    which is provided by the GoML API. We will restore it using its `RestoreFromFile` method.
    We will assume that all the other funcs we created in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised
    Learning*, are available to us, such as converting an image into a slice of floats:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can now use this code within gophernotes to generate a prediction and compare
    it to the ground truth in the `Label` column:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Running the preceding code cell in gophernotes will produce the following output:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s check the output:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We could also use the same validation techniques we introduced in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml),* Supervised
    Learning*, to check that the quality of the output is as expected. This approach
    works very well when the model was written in Go and persisted to be reused at
    a later time. However, if the model was written in Python and not recoverable
    directly in Go (such is the case for `scikit-learn` models, for example), the
    only way to use it to make a prediction may be to engineer some communication
    between a Python model and a Go application. While this increases the overall
    complexity of the applications, it has significant advantages, as we will discuss
    in the following sections.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用在第3章中介绍的相同验证技术，即*监督学习*，来检查输出质量是否符合预期。当模型是用Go编写的并且被持久化以便稍后重用时，这种方法非常有效。然而，如果模型是用Python编写的且无法直接在Go中恢复（例如`scikit-learn`模型就是这样），使用该模型进行预测的唯一方法可能是设计一些Python模型和Go应用之间的通信。虽然这增加了应用程序的整体复杂性，但它具有显著的优势，我们将在接下来的章节中讨论。
- en: Deciding when to adopt a polyglot approach
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决定何时采用多语言方法
- en: As we have seen in the previous chapters, the Go ecosystem provides ample opportunities
    to solve machine learning problems natively. However, being obstinate in requiring
    the solution to remain pure-Go can lead to increased development time or even
    reduced training performance, as other, more specialized ML libraries can provide
    higher-level APIs or performance optimizations that have not been implemented
    in the corresponding Go libraries yet.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如前几章所见，Go生态系统提供了丰富的机会来原生地解决机器学习问题。然而，固执地要求解决方案保持纯Go可能会增加开发时间，甚至降低训练性能，因为其他更专业的ML库可以提供更高层次的API或性能优化，而这些优化尚未在相应的Go库中实现。
- en: 'A good example of both is the Python ML library, Keras. The aim of this library
    is to provide a high-level API that allows the author to perform a wide range
    of ML tasks, such as data preprocessing, model training, model validation, and
    persistence. Its abstractions have concrete implementations in various backends,
    such as TensorFlow, which are known to be extremely performant. For these reasons,
    Keras is one of the most popular ML libraries in any language: its MIT-licensed
    GitHub repository has over 40,000 stars and a search on GitHub reveals that over
    20,000 repositories match the search term keras, meaning that the name of the
    repository includes that word. A search of the code content reveals that over
    one million files on GitHub contain the search term keras.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的例子是Python ML库Keras。这个库的目的是提供一个高级API，允许作者执行各种ML任务，如数据预处理、模型训练、模型验证和持久化。它的抽象在多个后端有具体的实现，例如TensorFlow，这些后端都以其高性能而闻名。因此，Keras是任何语言中最受欢迎的ML库之一：其MIT许可的GitHub仓库有超过40,000颗星，在GitHub上的搜索结果显示，超过20,000个仓库匹配搜索词keras，这意味着仓库的名称包含这个词。对代码内容的搜索显示，GitHub上超过一百万个文件包含搜索词keras。
- en: However, to write the entire application in Python just to make use of one library
    fails to take advantage of the benefits offered by Go, which we enumerated in
    [Chapter 1](cefdc727-5b16-4942-8adb-a2d476e9d546.xhtml), *Introducing Machine
    Learning with Go*. If these factors are not important in the development of your
    application, then by all means create it in Python, but, in what follows, we will
    assume that you want the best of both worlds.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅为了使用一个库而将整个应用程序用Python编写，无法充分利用Go提供的优势，这些优势我们在第1章中已列举，即*用Go介绍机器学习*。如果这些因素对您应用程序的开发并不重要，那么当然可以创建一个Python应用程序，但在接下来的内容中，我们将假设您希望两者兼得。
- en: 'Therefore, two options present themselves: first, develop the application entirely
    in Go. Second, develop the ML model in Python and invoke this model from your
    Go code, which will contain the main application and business logic. Within a
    commercial setting where the goal is to produce a production-ready product, the
    advantages of both options are as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，出现了两种选择：首先，完全用Go开发应用程序。其次，用Python开发ML模型，然后从您的Go代码中调用这个模型，其中将包含主要的应用程序和业务逻辑。在一个以生产就绪产品为目标的企业环境中，这两种选择的优点如下：
- en: '**Pure-Go application**:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**纯Go应用**：'
- en: Easier to maintain over a polyglot solution
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比多语言解决方案更容易维护
- en: Less complexity in application component interactions, because there is no need
    to manage invocation of an external ML component
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用组件交互的复杂性降低，因为不需要管理外部ML组件的调用
- en: Easier to on-board team members
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less dependencies to update
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Existing libraries may offer the required functionality out of the box with
    sufficient performance, obviating any advantage gained from using specialized
    libraries in other languages.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '**Polyglot application**:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Drastically reduce the amount of code for complex ML problems using high-level
    abstractions from specialist libraries in other languages
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In some cases, performance advantages, as some GoML libraries are not designed
    for out-and-out speed (deep learning is a good example of this)
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can suit a multi-team approach better, as data science teams are more familiar
    with Python or R libraries
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leverage preexisting models—academic research papers typically publish Caffe
    or TensorFlow models with Python or Lua scripts to invoke them
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In conclusion, for ML applications where existing Go libraries offer what you
    need out of the box or with little modification, a native Go solution will reduce
    complexity in the application and enhance maintainability. However, if this is
    not the case, particularly for very complex problems such as deep learning and
    computer vision, combining Go with the latest tools from other languages is worth
    the added complexity.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: In the examples that follow, we will invoke a variety of Python ML models from
    a Go application. Our reason for using Python specifically is that Python is preinstalled
    in most Linux distributions and is also the most popular language for ML^([4][5]).
    The solutions we will describe can be applied to a model written in any programming
    language.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Example – invoking a Python model using os/exec
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To get started with polyglot ML applications, we will revisit the logistic regression
    example from [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised
    Learning*. We will assume that, instead of Go, the model was written in Python
    and that we wish to invoke it from our Go application. To do this, we will use
    command-line arguments to pass inputs to the model and read the model's prediction
    from **standard output** (**STDOUT**).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: To exchange data between Python and Go, we will use strings formatted using
    **JavaScript Object Notation** (**JSON**). This choice is arbitrary of course^([6]),
    and we could have chosen any one of the other formats for which the Go and Python
    standard libraries have support, such as XML, or invented our own. JSON has the
    advantage that it takes very little effort to use in both languages.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'The process we will follow to communicate with the Python subprocess is as
    follows. Generally, there are three steps: serialization of the request, executing
    the subprocess, and deserialization of the response:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c2271a0-d0ce-448b-bd00-dc17353a7b93.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
- en: 'Fig.1: The process we use to communicate with a Python subprocess that runs
    a pretrained logistic regression model'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by loading the MNIST dataset and converting it into a dataframe.
    You can find the code for this in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml),
    *Supervised Learning*. This time, however, we will convert the image data into
    a slice of ints, with each int between 0 and 255 (the value of each pixel), rather
    than a slice of floats. This is to ensure alignment with the Python model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先加载 MNIST 数据集并将其转换为数据框。您可以在 [第 3 章](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml)，*监督学习*
    中找到此代码。然而，这一次，我们将图像数据转换为整数的切片，每个整数介于 0 和 255（每个像素的值）之间，而不是浮点数的切片。这是为了确保与 Python
    模型保持一致：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, we will introduce a function that will allow us to start the Python subprocess
    and wait for it to finish:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一个函数，它将允许我们启动 Python 子进程并等待其完成：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we are ready to assemble our prediction function, which will serialize
    the image data, pass it to the subprocess as an argument when it starts, wait
    for the subprocess to finish, and deserialize the response:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好组装我们的预测函数，该函数将序列化图像数据，在启动时将其作为参数传递给子进程，等待子进程完成，并反序列化响应：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can now use this code within gophernotes to generate a prediction and compare
    it to the ground truth in the `Label` column:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在 gophernotes 中使用此代码生成预测，并将其与 `Label` 列中的真实值进行比较：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Running this in a gophernotes cell provides the following output:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在 gophernotes 单元中运行此代码提供以下输出：
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s check the output:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查输出：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As expected, this outputs `true`. We can repeat this for several different images
    to get some confidence that everything is working as it should. Both the Go and
    Python code use the `predict` argument to signify which action should be performed
    – we could also have a `test` action that checks that the image the Python code
    reconstructs from its arguments is the correct one, further increasing our confidence
    that the subprocess communication is correct.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期，这输出了 `true`。我们可以对几个不同的图像重复此操作，以获得一些信心，确保一切按预期工作。Go 和 Python 代码都使用 `predict`
    参数来表示应该执行哪个操作 - 我们也可以有一个 `test` 操作，该操作检查 Python 代码从其参数重构的图像是否正确，这进一步增加了我们对子进程通信正确的信心。
- en: Subprocess communication can be operating system-specific, particularly when
    output redirection is involved. One advantage of Go is that the pipe method we
    present here works equally well across operating systems, with no extra modification
    needed, whereas, in other languages such as Python, additional work is sometimes
    required.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 子进程通信可能具有操作系统特定的特性，尤其是在涉及输出重定向时。Go 的一个优点是，我们在这里提出的管道方法在所有操作系统上都能同样很好地工作，无需额外修改，而其他语言如
    Python 有时需要额外的工作。
- en: While the code is succinct and easy to debug, the need to start a new Python
    process to handle every request can impact performance for applications with smaller,
    quicker models. Furthermore, it creates a fairly tight coupling between the Go
    application and its Python model. This could pose an issue in larger teams where
    a data science team creates a model and a software development team creates the
    rest of the application. It could also create issues where the model should be
    exposed to multiple applications, not just one – what should you do then? Have
    one copy of the model for each application? This could lead to maintainability
    issues. In the following example, we will look at one way to decouple the Go application
    from its Python model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然代码简洁且易于调试，但每次请求都需要启动一个新的 Python 进程来处理，这可能会影响具有较小、较快的模型的应用程序的性能。此外，它还在 Go 应用程序和其
    Python 模型之间创建了一个相当紧密的耦合。在较大的团队中，这可能是一个问题，其中数据科学团队创建模型，而软件开发团队创建应用程序的其他部分。它也可能在模型应该暴露给多个应用程序，而不仅仅是单个应用程序的情况下造成问题
    - 那时你应该怎么做？为每个应用程序保留模型的一个副本？这可能导致可维护性问题。在下面的示例中，我们将探讨一种将 Go 应用程序与其 Python 模型解耦的方法。
- en: Example – invoking a Python model using HTTP
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 - 使用 HTTP 调用 Python 模型
- en: What if the model resides on a different machine, we need to decouple the Go
    and model logic, or if there are multiple actions we may wish to perform, such
    as training a user-specific model based on user data, and later use this model
    to generate a prediction? In those cases, our previous solution using command-line
    arguments will become more complex as we add more arguments to distinguish between
    actions and return codes. This type of invocation is generally known as **Remote
    Procedure Call** (**RPC**), and solutions such as SOAP or JSON-RPC have been known
    to the industry for decades^([7]).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we will use a more universal and generic protocol:
    HTTP. Strictly speaking, HTTP is a data transfer protocol, and one that is often
    used as the plumbing for RPC protocols. However, with very little effort, we can
    create our own minimal RPC on top of HTTP by exposing a single endpoint that will
    accept POST requests. This has the advantage that no dependencies beyond the standard
    library in either Python or Go are required, and that debugging protocol errors
    are particularly straightforward. The downside is that it requires a bit more
    work to handle concerns such as serialization.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'The request/response process we will follow is illustrated in the following
    diagram:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6df6714f-40d5-4529-89fe-b80f27b22285.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 2: The request/reply process for a GoML application to communicate with
    a pretrained Python model using HTTP'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike the previous example, we assume that the Python HTTP server is already
    running. If you are following along with the companion repository, you can start
    the Python server with the `python3 model_http.py` command after installing its
    dependencies using `install-python-dependencies.sh`. This means that the Go code
    is particularly short:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As we did previously, we can generate some predictions to ensure communication
    between Go and Python processes is working as expected:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As expected, we get back the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We can continue this process for several other images to ensure that the response
    matches the ground truth value, as defined by the `df.Col("Label")` series. We
    could also create multiple HTTP endpoints on our Python HTTP server to allow testing
    of various kinds, further enhancing our confidence in interprocess communication.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'In the likely event that you ever need to debug communication with an HTTP
    server, a great tool is Postman, a free GUI tool that lets you create HTTP requests
    and inspect the responses. You can get Postman at:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.getpostman.com/](https://www.getpostman.com/).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: In the previous examples, we assumed that the model was created in a different
    programming language (Python) and could only be accessed from that language. However,
    there are a few popular deep learning libraries that have striven to become more
    polyglot and, therefore, provide means to create a model using one language and
    use it using another. In the following examples, we will look at two of these
    libraries.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Example – deep learning using the TensorFlow API for Go
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning is a subfield of machine learning that employs neural networks,
    usually with many layers, to solve complex problems such image or speech recognition.
    In this example, we will look at how to leverage TensorFlow, a popular deep learning
    framework, using its Go bindings.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is a highly optimized library that was created by Google to perform
    calculations on objects called tensors^([8]). If a vector is a collection of scalar
    entries (numbers) and a matrix a collection of vectors, then a tensor can be thought
    of as a higher-dimensional matrix, of which scalars, vectors, and matrices are
    special cases. While this may seem a bit abstract, tensors are natural objects
    to use when describing neural networks, and this is why TensorFlow has become
    one of the most popular libraries—even *the* most popular, according to some commentators—for
    commercial and academic deep learning development^([9][10]).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: In 2011, the team at Google Brain built a proprietary deep learning system called
    DistBelief^([11]). A number of prominent computer scientists such as Jeff Dean
    and Geoffrey Hinton worked on its backpropagation and other neural network-related
    algorithms, leading to an increased uptake of the framework across many projects
    at Google. In 2017, the second generation of this framework, now called TensorFlow,
    was released under an open source license^([12]).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is at its core a low-level API, also known as a backend for deep
    learning computations. Practically speaking, a data scientist working a commercial
    problem does not usually need to interact directly with the TensorFlow API on
    a daily basis. Instead, a number of frontends, such as Keras, which we introduced
    previously, are available as higher-level abstractions over TensorFlow and offer
    the best of both the performance and ease-of-use worlds. On the other hand, academic
    research where new types of neural architectures are invented is often performed
    using the low-level API, because no abstractions exist for the new constructs
    yet. The objects you create in TensorFlow, called **graphs**, can be persisted
    and reused in other languages, thanks to recent efforts to make the framework
    more polyglot^([13]).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will explain how to install TensorFlow and how to use its
    Go API to load a pretrained TensorFlow model and use it to make a prediction.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Installing TensorFlow
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The TensorFlow experience is usually a slick one—that is, after you have managed
    to install it correctly. The TensorFlow team recognized that this was a difficult
    step, and that building TensorFlow from source usually took hours in the best
    case, and as a result they now provide several easy installation options. It is
    worth noting that, if you have a compatible GPU on your system, you should install
    a GPU option as this will usually accelerate the software significantly, something
    particularly noticeable in the training phase:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '**Install with pip**: TensorFlow is aimed at Python programmers who will typically
    use `pip` to manage their packages. At the time of writing, this method has been
    tested with Ubuntu Linux 16.04 or later, macOS 10.12.6 (Sierra) or later (albeit
    with no GPU support), Raspbian 9.0 or later, and Windows 7 or later.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use a Docker image**: This will work with a wide range of systems that support
    Docker. There are two images to choose from: a vanilla TensorFlow image and one
    that also includes Jupyter, allowing you to have the same experience as gophernotes
    but with Python only.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Build from source**: This is best option if you are using a non-standard
    configuration or want to exert specific control over part of the build process
    (perhaps take advantage of some optimization that will only work for your particular
    configuration).'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is also a fourth option, which is to use Google Colaboratory to run TensorFlow-based
    code in Google's cloud, but we will not delve into this option, as it currently
    only works with Python.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we will use a Docker image. Docker can be seen as a solution
    for packaging and running multiple applications (called containers) on the same
    machine while keeping them from interfering with one another. If you are not already
    familiar with it, head to [https://docs.docker.com/get-started/](https://docs.docker.com/get-started/)
    for a five-minute tutorial.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the vanilla TensorFlow-on-Ubuntu image called `tensorflow/tensorflow`,
    which does not include Jupyter. We will need to install Go on top of this image
    so that we can run our code. Because our code will depend on TensorFlow bindings
    for Go, we will also install them according to the official instructions^([14]).
    This will require us to install the TensorFlow C bindings, too. Our Dockerfile
    will thus look as follows. Some steps have been omitted for brevity – you can
    find the full Dockerfile in the companion repository for this book:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Import the pretrained TensorFlow model
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml), *Supervised Learning*,
    we explained how to create a deep learning model in pure Go using the go-deep
    library. While this worked as a toy example, it was quite slow to train and required
    a lot of superfluous code. It would have been much easier, and resulted in more
    performance code, to use one of the industry-leading deep learning libraries,
    but unfortunately they are written in other languages. Using the Python library
    Keras, we have created a deep learning model that will serve as a classifier in
    the same problem that we looked at previously: *Is the given image of a pair of
    trousers?* We will now write some Go code to import our pretrained model.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: What if only the weights of the model were saved, rather than the more complete
    SavedModel format? In that case, you can still import it using the `graph.Import` func,
    but, subsequently, more work is required to tell TensorFlow about all the operations
    and variables. There is an example in the TensorFlow API godocs that illustrates
    this process^([15]).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: What follows assumes that the model was saved in the `SavedModel` format and
    that we know the names of the input and output `Ops`. If the model was created
    by someone else using Keras or another third-party library, this can sometimes
    be tricky. One option is to use the `SavedModel` command-line interface tool to
    inspect the model^([16]).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: If the model was created in Keras and you have access to the Python code, just
    inspect its `input` and `output` properties to see the names of the corresponding
    tensors. They may have a `:0` appended to them, which you can ignore.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'To restore a `SavedModel` in Go, simply use the `LoadSavedModel` func. This
    will return a Graph and Session object that you can then operate on, passing inputs
    and retrieving outputs:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Note that the second argument, called the tag, is often set to serve by convention.
    We can now access the input and output operations:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If either the input or output is nil at this stage, this means that you do not
    have the correct names, so you will need to return to inspecting the model to
    find out what they should be. It can also be useful to look at `savedModel.Graph.Operations`,
    which is a slice of `Operation`, and filter the list of operations down by those
    containing the search string input in their `Name()`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now access the restored session and graph:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we can run this code inside our TensorFlow Docker container and see the
    result. We will build the Docker image from its Dockerfile and run it:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If everything goes well, we should see some output while the container is being
    built (this will run much faster the second time) with the following messages
    at the end:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The first two lines tell us that our Docker image was successfully built, and
    the last line comes from our Go code and lets us know that the model import operation
    worked without resulting in any errors.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Depending on how you installed Docker, you may need superuser privileges to
    run these commands, so just prefix them with `sudo` if required.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Creating inputs to the TensorFlow model
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we are able to recreate the TensorFlow graph and session from a `SavedModel`,
    we will create a procedure that will accept an image from the MNIST fashion dataset
    as a slice of bytes and use these bytes to populate the inputs of the model we
    loaded previously. Then, we will be able to run the model to get an output prediction.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: We must create a procedure that will accept an image from the MNIST fashion
    dataset and return a tensor of the correct shape. We know from Chapter 3, *Supervised
    Learning*, that the model will expect a slice of 784 floats, and an inspection
    of the model (using `model.summary` in Python, or the `SavedModel` CLI) will reveal
    that the inputs should be a 1 x 784 tensor of `float32` values.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: When constructing tensors by passing slices of slices as an argument to the
    `NewTensor` func, make sure that they are all the same length. For example, you
    can pass 3 slices containing 7 elements each, and this will create a (3,7) tensor,
    but not 3 slices containing 5, 6, and 7 elements, respectively—the second dimension
    must be the same for all slices.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'We can construct a blank (zero) tensor with the right shape like so:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: While this is not very useful on its own, it illustrates the use of the `NewTensor` func,
    which can infer the correct tensor shape and value type from the Go `interface{}` it
    is passed. Using the `ImageSeriesToFloats` func we introduced in [Chapter 3](48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml),
    *Supervised Learning*, we can easily convert an image into a slice of `float32`
    and thus make the input tensor.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'We can run the model to get a prediction:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'For example, when running this with a blank tensor as the input, the last few
    lines of output are as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In the following chapter, we will explore the pattern of using Docker to deploy
    ML application workloads in more detail.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we compared Go-only and polyglot ML solutions from a practical
    point of view, contrasting their drawbacks and advantages. We then presented two
    generic solutions to develop polyglot ML solutions: the os/exec package and JSON-RPC.
    Finally, we looked at two highly-specialized libraries that come with their own
    RPC-based integration solutions: TensorFlow and Caffe. You have learned how to
    decide whether to use a Go-only or polyglot approach to ML in your application,
    how to implement an RPC-based polyglot ML application, and how to run TensorFlow
    models from Go.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will cover the last step of the ML development life
    cycle: taking an ML application written in Go to production.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Further readings
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Ke**ras GitHub repository*: [https://github.com/keras-team/keras](https://github.com/keras-team/keras).
    Retrieved April 30, 2019.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*GitHub search for keras*: [https://github.com/search?utf8=%E2%9C%93&amp;q=keras&amp;type=](https://github.com/search?utf8=%E2%9C%93&q=keras&type=).
    Retrieved April 30, 2019.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*GitHub content search for keras*: [https://github.com/search?q=keras&amp;type=Code](https://github.com/search?q=keras&type=Code).
    Retrieved April 30, 2019.'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Python is Becoming the World''s Most Popular Coding Language*, The Economist.
    July 26, 2018: [https://www.economist.com/graphic-detail/2018/07/26/python-is-becoming-the-worlds-most-popular-coding-language.](https://www.economist.com/graphic-detail/2018/07/26/python-is-becoming-the-worlds-most-popular-coding-language) Retrieved
    April 30, 2019.'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Using Python on Unix Platforms*: [https://docs.python.org/2/using/unix.html](https://docs.python.org/2/using/unix.html).
    Retrieved April 30, 2019.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*JSON*: [https://www.json.org/](https://www.json.org/). Retrieved April 30,
    2019.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Cover Pages – SOAP*: [http://xml.coverpages.org/soap.html](http://xml.coverpages.org/soap.html).
    Retrieved April 30, 2019.'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*TensorFlow Core*: [https://www.tensorflow.org/overview/](https://www.tensorflow.org/overview/).
    Retrieved April 30, 2019.'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Deep Learning Framework Power Scores*: [https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a](https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a).
    Retrieved April 30, 2019.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Ranking Popular Deep Learning Frameworks*: [https://blog.thedataincubator.com/2017/10/ranking-popular-deep-learning-libraries-for-data-science/](https://blog.thedataincubator.com/2017/10/ranking-popular-deep-learning-libraries-for-data-science/).
    Retrieved April 30, 2019.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Dean, Jeff et. al. *Large-Scale Machine Learning on Heterogeneous Distributed
    Systems*. Nov. 9, 2015. [http://download.tensorflow.org/paper/whitepaper2015.pdf](http://download.tensorflow.org/paper/whitepaper2015.pdf).
    Retrieved April 30, 2019.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*TensorFlow* `RELEASE.md`: [https://github.com/tensorflow/tensorflow/blob/07bb8ea2379bd459832b23951fb20ec47f3fdbd4/RELEASE.md](https://github.com/tensorflow/tensorflow/blob/07bb8ea2379bd459832b23951fb20ec47f3fdbd4/RELEASE.md).
    Retrieved April 30, 2019.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*TensorFlow in Other Languages*: [https://www.tensorflow.org/guide/extend/bindings](https://www.tensorflow.org/guide/extend/bindings).
    Retrieved April 30, 2019.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Installing TensorFlow for Go*: [https://www.tensorflow.org/install/lang_go ](https://www.tensorflow.org/install/lang_go).
    Retrieved May 1, 2019.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*TensorFlow—godocs*: [https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go](https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go).
    Retrieved May 3, 2019.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Save and Restore*: [https://www.tensorflow.org/guide/saved_model#install_the_savedmodel_cli](https://www.tensorflow.org/guide/saved_model#install_the_savedmodel_cli).
    Retrieved May 3, 2019.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Tag constants*: [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/tag_constants.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/tag_constants.py).
    Retrieved May 22, 2019.'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
