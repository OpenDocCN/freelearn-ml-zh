- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Case Study 1 – Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will be introduced to a multitude of industrial applications
    of computer vision. You will discover some of the key problems that were successfully
    solved using computer vision. In parallel to this, you will grasp the major issues
    with traditional computer vision solutions. Additionally, you will explore and
    comprehend thought-provoking examples of using synthetic data to improve computer
    vision solutions in practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Industrial revolutions – computer vision as a solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthetic data and computer vision – examples from industry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transforming industries – the power of computer vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll briefly discuss the main four industrial revolutions
    as they help us to better comprehend the historical context of AI, data, and computer
    vision. Then, we will learn why computer vision is becoming an integral component
    of our modern industries.
  prefs: []
  type: TYPE_NORMAL
- en: The four waves of the industrial revolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Industrial revolution** refers to a global and rapid transformation in the
    economy. Usually, this transformation brings and utilizes new inventions, discoveries,
    and technologies to make manufacturing and production processes more efficient.
    The history of the industrial revolutions can be summarized into four stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Industrial revolutions](img/Figure_10_01_B18494.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Industrial revolutions
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s discuss each of the industrial revolutions shown in *Figure 10**.1*
    in greater depth.
  prefs: []
  type: TYPE_NORMAL
- en: Industry 1.0
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This refers to the first industrial revolution, which happened in the early
    19th century. It supplemented, supported, and enhanced existing labor processes
    by incorporating machinery; animals and manual labor were mostly replaced with
    water and steam engines. It was a great shift toward using machinery to carry
    out mostly the same tasks but more efficiently. This opened the door for new industries,
    such as iron production, which significantly influenced the development of industries
    such as construction, transportation, and manufacturing. Industry 1.0 changed
    the way products were produced, which laid the foundation for the next revolution
    in industry.
  prefs: []
  type: TYPE_NORMAL
- en: Industry 2.0
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Electricity was the major driver of the substantial shift in production that
    happened with Industry 2.0\. Assembly line production and the widespread adoption
    of electricity as a power source facilitated mass production. In parallel to that,
    the great advancement in steelmaking and production enabled the building of more
    sophisticated and powerful machinery. This set the stage for the following industrial
    revolution.
  prefs: []
  type: TYPE_NORMAL
- en: Industry 3.0
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Electricity was one of the discoveries that changed our civilization dramatically,
    including communication and industry. With mass production, which is considered
    one of the main themes of Industry 2.0, there was an urgent need for automation
    to minimize errors and maximize efficiency. Thus, computers were utilized by manufacturers
    to achieve yet more precise and efficient productions.
  prefs: []
  type: TYPE_NORMAL
- en: Industry 4.0
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The digital transformations of most industries, great competition between global
    companies, and scarce resources all opened the door for cyber-physical systems
    and thus **smart factories**. Consequently, AI, robotics, and **big data** started
    to attract more attention in industry and academia. Since the main properties
    of this industrial revolution are great efficiency, customized products, and services,
    ML and data are the gems of achieving these aims.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will see why computer vision is the backbone of many of our current
    industries.
  prefs: []
  type: TYPE_NORMAL
- en: Industry 4.0 and computer vision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Computer vision is an interdisciplinary field that enables machines to understand
    images. Computer vision is an essential component of our current industrial revolution.
    It has been widely applied for quality control, safety assurance, predictive maintenance,
    and other essential and critical applications. Next, let’s discuss the main uses
    of computer vision in the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: Manufacturing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autonomous driving
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Healthcare
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agriculture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Surveillance and security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manufacturing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In manufacturing industries, human error can cause significant delays that affect
    the entire production pipeline. It may even cause damage to machines and infrastructures,
    injuries, and death. Computer vision comes as a solution to complement, support,
    or replace the human element in the process. Computer vision can be utilized to
    guide the assembly and manufacturing processes to achieve higher throughput with
    lower costs and higher quality.
  prefs: []
  type: TYPE_NORMAL
- en: Contact lens manufacturers worked with *ADLINK* and *LEDA* that have used computer
    vision to automate the contact lens inspection process. This task was usually
    performed by human inspectors where thousands of lenses were visually inspected
    each day. It was a time-consuming process where errors were not avoidable. By
    deploying ADLINK and LEDA’s computer vision-based solution, the company which
    manufactures contact lenses was able to make its inspection process 3 times more
    accurate and 50 times faster! Their novel solution removes the human element from
    the process, which substantially increases the scalability and quality of the
    inspection process. For more information about this use case, please refer to
    *ADLINK and LEDA Technology Create AI-Enabled Contact Lens Inspection* *Solution*
    ([https://data.embeddedcomputing.com/uploads/articles/whitepapers/13328.pdf](https://data.embeddedcomputing.com/uploads/articles/whitepapers/13328.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: Autonomous driving
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is one of the main sectors that is closely associated with computer vision.
    **Autonomous driving** technology can reduce human errors in driving and thus
    minimize accidents, injuries, and death. In 2022, the number of road traffic fatalities
    exceeded 46,200 cases in the US ([https://www.statista.com/statistics/192575/road-traffic-fatalities-in-the-united-states](https://www.statista.com/statistics/192575/road-traffic-fatalities-in-the-united-states)).
    Thus, computer vision presents a promising safe, efficient, and productive solution.
    Self-driving companies such as *Tesla*, *Waymo*, and *Mobileye* have already started
    utilizing computer vision for lane detection and tracking, pedestrian detection,
    object recognition, and traffic sign detection and recognition. As you may guess,
    the failure of such computer vision algorithms can cause damage to property, severe
    injuries, or death. Thus, training and developing a robust computer vision algorithm
    is a hot topic for ML researchers and is gaining more momentum and receiving more
    attention.
  prefs: []
  type: TYPE_NORMAL
- en: '**Tesla cars** have developed a computer vision system based on neural networks
    that takes video inputs from different cameras. Then, it processes the visual
    information and predicts the road layout, static objects, pedestrians, and other
    vehicles in the scene. For more information, please refer to *Tesla – AI &* *Robotics*
    ([https://www.tesla.com/AI](https://www.tesla.com/AI)).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Aurora Driver** is a computer vision system that can be utilized for autonomous
    driving. The system learns to fuse information collected from various sensors,
    such as lidar, radar, and cameras, to provide an understanding of the driving
    environment. For more information, check out *Perception at Aurora: No measurement
    left* *behind* ([https://blog.aurora.tech/engineering/perception-at-aurora-no-measurement-left-behind](https://blog.aurora.tech/engineering/perception-at-aurora-no-measurement-left-behind)).'
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s move on to computer vision applications in the healthcare sector.
  prefs: []
  type: TYPE_NORMAL
- en: Healthcare
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Computer vision revolutionized the field of healthcare thanks to its great ability
    to analyze large amounts of patient data and provide quick, accurate, and efficient
    diagnoses. Computer vision algorithms can assist healthcare practitioners, surgeons,
    and physicians in making accurate and timely decisions that can reduce costs,
    improve treatments and operations, and reduce human errors.
  prefs: []
  type: TYPE_NORMAL
- en: A multitude of healthcare providers have already started harnessing computer
    vision’s potential in this field. Let’s highlight two examples from *Viz.ai* and
    *Paige*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Viz.ai** utilizes computer vision algorithms to identify signs of a stroke
    by analyzing patients’ medical images. They deploy these algorithms to efficiently
    analyze **Computerized Tomography** (**CT**) and **Magnetic Resonance Imaging**
    (**MRI**) scans and notify neurologists if a sign of a stroke is present to take
    the appropriate action.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Paige** is another company that has deployed computer vision to improve diagnostics
    and predictive tests of pathologists. In a recent study by *Yale Medicine* on
    the effectiveness of Paige Prostate (the name of their computer vision tool),
    1,876 predictions by this system classified as “suspicious” were reviewed by professional
    pathologists. The study concluded that only 31.4% of biopsies had to be reviewed
    by pathologists. Thus, this tool can indeed improve the productivity of pathologists.
    Additionally, it demonstrated that this tool could improve the detection of prostate
    cancer especially when being reviewed by non-genitourinary specialized pathologists.
    For more details, refer to *An independent assessment of AI for prostate cancer*
    *detection* ([https://paige.ai/case-study/an-independent-assessment-of-ai-for-prostate-cancer-detection](https://paige.ai/case-study/an-independent-assessment-of-ai-for-prostate-cancer-detection)).'
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, let’s examine computer vision applications in the
    agriculture field.
  prefs: []
  type: TYPE_NORMAL
- en: Agriculture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A recent report published by the **Food Security Information Network** (**FSIN**)
    titled *Global Report on Food Crises 2023* ([https://www.fsinplatform.org/sites/default/files/resources/files/GRFC2023-hi-res.pdf](https://www.fsinplatform.org/sites/default/files/resources/files/GRFC2023-hi-res.pdf))
    raised a red flag about the current and future food insecurity in 58 countries.
    The report highlighted that almost 250 million people were facing severe food
    insecurity in 2022, which was a large increase from 2021, when the number was
    around 190 million. According to experts, the situation is just going to become
    worse in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Many companies, such as *Taranis* and *Prospera,* utilize computer vision to
    guide farmers to better optimize resources, analyze crop data, continuously monitor
    crops, and detect potential issues, such as pests and diseases. Let’s talk in
    more detail about Taranis and Prospera.
  prefs: []
  type: TYPE_NORMAL
- en: '**Taranis** is a company focused on developing technologies that help agriculture
    businesses and farmers to improve their crop quality, yield, and profit. It utilizes
    drones and computer vision to analyze farms and make the treatment more efficient.
    The technology developed is used to efficiently control large farms at the leaf
    level, which is almost impossible without computer vision. For more information,
    please refer to the company website ([https://www.taranis.com](https://www.taranis.com)).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prospera** is another company that relies on computer vision to support farmers.
    The technology helps them control pivots, pumps, and other aspects of the irrigation
    system. Additionally, it continuously monitors crop health and instantly detects
    any issues. For more details, refer to the company website ([https://prospera.ag](https://prospera.ag)).'
  prefs: []
  type: TYPE_NORMAL
- en: As you may expect, these key traditional computer vision solutions can be further
    enhanced by utilizing synthetic data as a complementary or alternative to real
    data. Now, let’s delve into the main issues with these computer vision solutions,
    stemming from their significant reliance on real data.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have discussed in previous chapters, computer vision algorithms that
    are based on real data usually suffer from the following issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Insufficient training data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data quality issues and bias
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limited variability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, you will learn how and why industries have started incorporating
    synthetic data in their computer vision-based solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Surveillance and security
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One of the main key capabilities of computer vision is accurately and efficiently
    analyzing visual information, such as images and videos. For example, it can be
    leveraged for the following aims:'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting unusual behaviors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying suspicious people, items, or actions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: License plate recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Biometric identification: face, iris, palm print, vein, voice, and fingerprint
    recognition'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thus, computer vision can be leveraged to prevent unauthorized access, protect
    people and assets, and identify security threats and risks in real time. Computer
    vision is used these days to ensure public safety. For example, it is used in
    airports, public transport, streets, parks, and other public spaces. Many companies
    have been successfully deploying computer vision for security and surveillance
    problems, such as Hikvision ([https://www.hikvision.com](https://www.hikvision.com)),
    Avigilon ([https://www.avigilon.com](https://www.avigilon.com)), Verkada ([https://www.verkada.com](https://www.verkada.com)),
    Huawei, Google, Microsoft, and Amazon. Let’s delve into one interesting case study
    with Fujitsu and its interesting use of computer vision to monitor and smooth
    traffic flows in Montreal.
  prefs: []
  type: TYPE_NORMAL
- en: The city of Montreal struggled with many issues related to traffic flow because
    of factors such as limited entry and exit points, insufficient road infrastructure,
    and an inadequate traffic management system. As a solution, Fujitsu proposed a
    computer vision-based solution for most traffic issues. The system collects data
    from CCTV cameras, more than 2,500 traffic lights, and other sensors. Then, the
    system makes a real-time decision to optimize the traffic flow. The computer vision-based
    solution has reduced travel time, air pollution, and other traffic-related issues.
    For more details, please refer to *Smoothing traffic flows with AI* *analysis*
    ([https://www2.fujitsu.com/global/customer-stories/cs-city-of-montreal-20210701](https://www2.fujitsu.com/global/customer-stories/cs-city-of-montreal-20210701)).
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic data and computer vision – examples from industry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will learn about and understand how companies have just
    started using synthetic data-based computer vision solutions to stand out from
    competitors and overcome real data limitations and issues.
  prefs: []
  type: TYPE_NORMAL
- en: Neurolabs using synthetic data in retail
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'According to *Getting Availability Right: Bringing Out-of-Stocks Under Control*
    ([https://www.oliverwyman.com/content/dam/oliver-wyman/global/en/2014/aug/2012_CEU_POV_Getting%20Availability%20Right_ENG.pdf](https://www.oliverwyman.com/content/dam/oliver-wyman/global/en/2014/aug/2012_CEU_POV_Getting%20Availability%20Right_ENG.pdf)),
    out-of-stock items cause heavy financial losses and dissatisfied customers. The
    consequences can be dramatic on businesses and revenues. At the same time, collecting
    and annotating large-scale real data for this task is an expensive and time-consuming
    process. Neurolabs, an ML company specializing in providing solutions in retail
    automation, investigated an elegant solution using synthetic data for this issue.
    They utilized Unity and their own synthetic data generator to generate 1,200 images
    of 129 unique **Stock Keeping Units** (**SKUs**) on shelves. The dataset is named
    CPGDet-129 and can be downloaded from this link ([https://dl.orangedox.com/SampleRetailSyntheticDataset](https://dl.orangedox.com/SampleRetailSyntheticDataset))
    . Additionally, for more details about the dataset and license, please refer to
    the GitHub repository ([https://github.com/neurolaboratories/reshelf-detection](https://github.com/neurolaboratories/reshelf-detection)).
    The dataset was automatically generated and labeled. Moreover, it specifically
    supports object detection tasks. Training a state-of-the-art object detection
    algorithm on their synthetic dataset alone, without using any real data, they
    were able to achieve 60% **Mean Average Precision** (**mAP**) on a real test dataset.
    mAP is a metric used to tell us how accurate the object detection model is at
    predicting the bounding boxes around the objects of interest. Higher values of
    the mAP score indicate that our model is making accurate predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: This is a perfect example showing how synthetic data can be deployed to solve
    complex computer vision problems in practice.
  prefs: []
  type: TYPE_NORMAL
- en: For more details, please refer to [https://neurolabs.medium.com/using-neurolabs-retail-specific-synthetic-dataset-in-production-bbfdd3c653d5](https://neurolabs.medium.com/using-neurolabs-retail-specific-synthetic-dataset-in-production-bbfdd3c653d5)
    and [https://www.neurolabs.ai/post/using-neurolabs-retail-specific-synthetic-dataset-in-production](https://www.neurolabs.ai/post/using-neurolabs-retail-specific-synthetic-dataset-in-production).
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft using synthetic data alone for face analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Face analysis such as face parsing and landmark localization is fundamental
    for modern industry. The applications range from security and advertising to medical
    diagnosis. Using synthetic data for face analysis seems inescapable as annotating
    real images for these tasks not only is extremely hard but also brings ethical
    and privacy issues. You can refer to [*Chapter 3*](B18494_03.xhtml#_idTextAnchor049),
    where we discussed these issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Microsoft is one of the pioneer companies in face recognition technologies.
    They have many years of research and development in this area. *Face API* is just
    one example ([https://azure.microsoft.com/en-gb/products/cognitive-services/face](https://azure.microsoft.com/en-gb/products/cognitive-services/face)).
    Their recent work, titled *Fake it till you make it: face analysis in the wild
    using synthetic data alone* ([https://openaccess.thecvf.com/content/ICCV2021/papers/Wood_Fake_It_Till_You_Make_It_Face_Analysis_in_the_ICCV_2021_paper.pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Wood_Fake_It_Till_You_Make_It_Face_Analysis_in_the_ICCV_2021_paper.pdf)),
    is an excellent demonstration of how synthetic data can be deployed in computer
    vision.'
  prefs: []
  type: TYPE_NORMAL
- en: The researchers in this work first procedurally generated photorealistic synthetic
    faces. They used a template face and then randomized the hair, clothes, expression,
    and, essentially, identity. They simulated these faces in random environments.
    The synthetic dataset they have generated contains 100,000 synthetic faces with
    ground-truth annotations, including 2D dense face landmarks and per-pixel face
    parts semantic segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: They trained face parsing and landmark localization ML models on their generated
    synthetic data alone without using any real images. Their experimental results
    show that the trained ML models were able to achieve superior results on real
    datasets. For example, their synthetic-data-trained ML model was able to predict
    10 times more landmarks as compared to real-data-trained ML ones. They claim that
    this success is due to the superiority of their synthetic training data. They
    emphasize that it is impossible for human annotators to accurately label that
    many landmarks in practice. Additionally, they show that their synthetic data
    generation pipeline can be easily adapted to generate synthetic training data
    for other computer vision tasks, such as eye-tracking. They simply add a virtual
    eye-tracking camera and generate training images with the corresponding ground
    truth. To download the dataset, you can refer to their GitHub repository ([https://microsoft.github.io/FaceSynthetics](https://microsoft.github.io/FaceSynthetics)).
  prefs: []
  type: TYPE_NORMAL
- en: Synthesis AI using synthetic data for virtual try-on
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Virtual fashion is gaining more momentum because it provides a sustainable
    solution that, unlike traditional fashion, reduces cost and effort. Additionally,
    it provides a scalable and more personalized solution for companies and customers.
    Furthermore, it opens more opportunities for creativity, collaboration, and social
    impact. For this industry to flourish and achieve the intended outcomes, computer
    vision technologies need to excel at a number of tasks, such as pose estimation,
    semantic segmentation, visual object detection, and tracking. *Synthesis AI* proposed
    an elegant solution by using synthetic photorealistic 3D humans with huge variations
    in body type, gender, ethnicity, age, height, and other attributes. They were
    able to generate depth maps, surface normals, segmentation maps, and many other
    annotations. For more details, please refer to *Synthesis AI Virtual Try-on* ([https://synthesis.ai/applications/virtual-try-on](https://synthesis.ai/applications/virtual-try-on)).
    Additionally, they experimentally demonstrated the usability of the generated
    synthetic data for a number of tasks, such as face segmentation, background matting,
    and facial landmark detection. They found that fine-tuning on real data after
    pretraining on synthetic data achieves the best results as compared to training
    on real data or synthetic data alone or even a mixture of both. To explore the
    case study in more detail, please refer to *Synthetic Data Case Studies: It Just*
    *Works* ([https://synthesis.ai/2021/06/17/synthetic-data-case-studies-it-just-works](https://synthesis.ai/2021/06/17/synthetic-data-case-studies-it-just-works)).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In summary, you were introduced to various industrial applications of computer
    vision. You learned why and how computer vision is shaping the future of our modern
    industry. Moreover, you explored two case studies of companies that started to
    utilize synthetic data for their computer vision-based solutions.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will delve into another set of interesting case studies
    in the field of natural language processing.
  prefs: []
  type: TYPE_NORMAL
