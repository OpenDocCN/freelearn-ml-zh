- en: Chapter 5. Selecting and Evaluating Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章. 选择和评估数据
- en: 'In the previous chapter, we studied **Artificial Neural Networks** (**ANNs**)
    and how they can be used to effectively model nonlinear sample data. So far, we''ve
    discussed several machine learning techniques that can be used to model a given
    training set of data. In this chapter, we will explore the following topics that
    focus on how to select appropriate features from the sample data:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了**人工神经网络**（**ANNs**）以及它们如何有效地对非线性样本数据进行建模。到目前为止，我们已经讨论了几种可以用来对给定的训练数据集进行建模的机器学习技术。在本章中，我们将探讨以下主题，重点关注如何从样本数据中选择合适的特征：
- en: We will study methods to evaluate or quantify how accurately a formulated model
    fits the supplied training data. These techniques will be useful when we have
    to extend or debug an existing model.
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将研究评估或量化制定模型与提供的训练数据拟合准确性的方法。当我们需要扩展或调试现有模型时，这些技术将非常有用。
- en: We will also explore how we can use the `clj-ml` library to perform this process
    on a given machine learning model.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还将探索如何使用`clj-ml`库在给定的机器学习模型上执行此过程。
- en: Towards the end of the chapter, we will implement a working spam classifier
    that incorporates a model evaluation technique.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本章的末尾，我们将实现一个包含模型评估技术的有效垃圾邮件分类器。
- en: The term **machine learning diagnostic** is often used to describe a test that
    can be run to gain insight about what is and isn't working in a machine learning
    model. This information generated by the diagnostic can then be used to improve
    the performance of the given model. Generally, when designing a machine learning
    model, it's advisable to formulate a diagnostic for the model in parallel. Implementing
    a diagnostic for a given model can take around the same time as formulating the
    model itself, but implementing a diagnostic is a good investment of time since
    it would help in quickly determining what needs to be changed in the model in
    order to improve it. Thus, machine learning diagnostics are helpful in saving
    time with respect to debugging or improving a formulated learning model.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: “**机器学习诊断**”这个术语通常用来描述一种可以运行的测试，以获得关于机器学习模型中哪些工作得好，哪些工作得不好的洞察。诊断生成的信息可以用来提高给定模型的表现。一般来说，在设计机器学习模型时，建议并行地为模型制定一个诊断。为给定模型实现诊断可能需要与制定模型本身相同的时间，但实现诊断是值得投入时间的，因为它有助于快速确定模型中需要改变什么才能改进它。因此，机器学习诊断有助于在调试或改进制定的学习模型方面节省时间。
- en: 'Another interesting aspect of machine learning is that without knowing the
    nature of the data we are trying to fit, we can make no assumption about which
    machine learning model we can use to fit the sample data. This axiom is known
    as the **No Free Lunch** theorem, and can be summarized as follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的另一个有趣方面是，如果我们不知道我们试图拟合的数据的性质，我们就无法对可以使用哪种机器学习模型来拟合样本数据做出任何假设。这个公理被称为**没有免费午餐**定理，可以总结如下：
- en: '"Without prior assumptions about the nature of a learning algorithm, no learning
    algorithm is superior or inferior to any other (or even random guessing)."'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “如果没有关于学习算法性质的前置假设，没有任何学习算法比其他任何（甚至随机猜测）更优越或更劣。”
- en: Understanding underfitting and overfitting
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解欠拟合和过拟合
- en: In the previous chapters, we've talked about minimizing the error or cost function
    of a formulated machine learning model. It's apt for the overall error of the
    estimated model to be low, but a low error is generally not enough to determine
    how well the model fits the supplied training data. In this section, we will revisit
    the concepts of *overfitting* and *underfitting*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们讨论了最小化一个机器学习模型的误差或损失函数。估计模型的总体误差低是合适的，但低误差通常不足以确定模型与提供的训练数据拟合得有多好。在本节中，我们将重新审视**过拟合**和**欠拟合**的概念。
- en: An estimated model is said to be **underfit** if it exhibits a large error in
    prediction. Ideally, we should strive to minimize this error in the model. However,
    a formulated model with a low error or cost function could also indicate that
    the model doesn't understand the underlying relationship between the given features
    of the model. Rather, the model is *memorizing* the supplied data, and this could
    even result in modeling random noise. In this case, the model is said to be **overfit**.
    A general symptom of an overfit model is failure to correctly predict the output
    variable from unseen data. An underfit model is also said to exhibit **high bias**
    and an overfit model is said to have **high variance**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果估计模型在预测中表现出较大的误差，则称其为**欠拟合**。理想情况下，我们应该努力最小化模型中的这个误差。然而，具有低误差或成本函数的公式化模型也可能表明模型不理解模型给定特征之间的潜在关系。相反，模型是*记忆*提供的数据，这甚至可能导致对随机噪声的建模。在这种情况下，该模型被称为**过拟合**。过拟合模型的一般症状是未能从未见过的数据中正确预测输出变量。欠拟合模型也被称为表现出**高偏差**，而过拟合模型则被认为具有**高方差**。
- en: Suppose we are modeling a single dependent and independent variable in our model.
    Ideally, the model should fit the training data while generalizing on data that
    hasn't yet been observed in the training data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在模型中建模一个单一的自变量和因变量。理想情况下，模型应该拟合训练数据，同时在尚未观察到的训练数据上泛化。
- en: 'The variance of the dependent variables with the independent variable in an
    underfit model can be represented using the following plot:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在欠拟合模型中，可以使用以下图表表示因变量与自变量之间的方差：
- en: '![Understanding underfitting and overfitting](img/4351OS_05_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![理解欠拟合和过拟合](img/4351OS_05_01.jpg)'
- en: In the preceding diagram, the red crosses represent data points in our sample
    data. As shown in the diagram, an underfit model will exhibit a large overall
    error, and we must try to reduce this error by appropriately selecting the features
    for our model and using regularization.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在前图中，红色交叉表示样本数据中的数据点。如图所示，欠拟合模型将表现出较大的总体误差，我们必须通过适当选择模型的特征和使用正则化来尝试减少这个误差。
- en: 'On the other hand, a model could also be overfit, in which the overall error
    in the model has a low value, but the estimated model fails to correctly predict
    the dependent variable from previously unseen data. An overfit model can be depicted
    using the following plot:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，模型也可能过拟合，在这种情况下，模型的总体误差值很低，但估计的模型无法从先前未见过的数据中正确预测因变量。可以使用以下图表来表示过拟合模型：
- en: '![Understanding underfitting and overfitting](img/4351OS_05_03.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![理解欠拟合和过拟合](img/4351OS_05_03.jpg)'
- en: As shown in the preceding diagram, the estimated model plot closely but inappropriately
    fits the training data and thus has a low overall error. But, the model fails
    to respond correctly to new data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，估计的模型图紧密但不适当地拟合了训练数据，因此总体误差较低。但是，模型无法对新数据做出正确响应。
- en: 'The model that describes a good fit for the sample data will have a low overall
    error and can predict the dependent variable correctly from previously unseen
    values for the independent variables in our model. An appropriately fit model
    should have a plot similar to the following diagram:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 描述样本数据的良好拟合模型的总体误差将很低，并且可以从模型中独立变量的先前未见过的值正确预测因变量。一个适当拟合的模型应该有一个类似于以下图表的图形：
- en: '![Understanding underfitting and overfitting](img/4351OS_05_05.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![理解欠拟合和过拟合](img/4351OS_05_05.jpg)'
- en: ANNs can also be underfit or overfit on the provided sample data. For example,
    an ANN with a few hidden nodes and layers could be an underfit model, while an
    ANN with a large number of hidden nodes and layers could exhibit overfitting.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络也可能在提供的样本数据上欠拟合或过拟合。例如，具有少量隐藏节点和层的神经网络可能是一个欠拟合模型，而具有大量隐藏节点和层的神经网络可能表现出过拟合。
- en: Evaluating a model
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估模型
- en: We can plot the variance of the dependent and independent variables of a model
    to determine if the model is underfit or overfit. However, with a larger number
    of features, we need a better way to visualize how well the model generalizes
    the relationship of the dependent and independent variables of the model over
    the training data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以绘制模型的因变量和自变量的方差图，以确定模型是欠拟合还是过拟合。然而，随着特征数量的增加，我们需要更好的方法来可视化模型在训练数据上对模型因变量和自变量关系的泛化程度。
- en: We can evaluate a trained machine learning model by determining the cost function
    of the model on some different data. Thus, we need to split the available sample
    data into two subsets—one for training the model and another for testing it. The
    latter subset is also called the **test set** of our model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'The cost function is then calculated for the ![Evaluating a model](img/4351OS_05_06.jpg)
    samples in the test set. This gives us a measure of the overall error in the model
    when used on previously unseen data. This value is represented by the term ![Evaluating
    a model](img/4351OS_05_07.jpg) of the estimated model ![Evaluating a model](img/4351OS_05_08.jpg)
    and is also called the **test error** of the formulated model. The overall error
    in the training data is called the **training error** of the model and is represented
    by the term ![Evaluating a model](img/4351OS_05_09.jpg). A linear regression model''s
    test error can be calculated as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluating a model](img/4351OS_05_10.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, the test error in a binary classification model can be formally
    expressed as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluating a model](img/4351OS_05_11.jpg)![Evaluating a model](img/4351OS_05_12.jpg)![Evaluating
    a model](img/4351OS_05_13.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: The problem of determining the features of a model such that the test error
    is low is termed as **model selection** or **feature selection**. Also, to avoid
    overfitting, we must measure how well the model generalizes over the training
    data. The test error on its own is an optimistic estimate of the generalization
    error in the model over the training data. However, we must also measure the generalization
    error in data that hasn't yet been seen by the model. If the model has a low error
    over unseen data as well, we can be certain that the model does not overfit the
    data. This process is termed as **cross-validation**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Thus, to ensure that the model can perform well on unseen data, we will require
    an additional set of data, called the **cross-validation set**. The number of
    samples in the cross-validation set is represented by the term ![Evaluating a
    model](img/4351OS_05_14.jpg). Typically, the sample data is partitioned into the
    training, test, and cross-validation sets such that the number of samples in the
    training data are significantly greater than those in the test and cross-validate
    sets. The error in generalization, or rather the cross-validation error ![Evaluating
    a model](img/4351OS_05_15.jpg), thus indicates how well the estimated model fits
    unseen data. Note that we don't modify the estimated model when we use the cross-validation
    and test sets on it. We will study more about cross-validation in the following
    sections of this chapter. As we will see later, we can also use cross-validation
    to determine the features of a model from some sample data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose we have 100 samples in our training data. We partition
    this sample data into three sets. The first 60 samples will be used to estimate
    a model that fits the data appropriately. Out of the 40 remaining samples, 20
    will be used to cross-validate the estimated model, and the other 20 will be used
    to finally test the cross-validated model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: In the context of classification, a good representation of the accuracy of a
    given classifier is a *confusion matrix*. This representation is often used to
    visualize the performance of a given classifier based on a supervised machine
    learning algorithm. Each column in this matrix represents the number of samples
    that belong to a particular class as predicted by the given classifier. The rows
    of the confusion matrix represent the actual classes of the samples. The confusion
    matrix is also called the **contingency matrix** or the **error matrix** of the
    trained classifier.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, say we have two classes in a given classification model. The confusion
    matrix of this model might look like the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '|   | Predicted class |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: '| A | B |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
- en: '| **Actual class** | A | 45 | 15 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
- en: '| B | 30 | 10 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
- en: In a confusion matrix, the predicted classes in our model are represented by
    vertical columns and the actual classes are represented by horizontal rows. In
    the preceding example of a confusion matrix, there are a total of 100 samples.
    Out of these, 45 samples from class A and 10 samples from class B were predicted
    to have the correct class. However, 15 samples of class A have been classified
    as class B and similarly 30 samples of class B have been predicted to have class
    A.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the following confusion matrix of a different classifier that
    uses the same data as the previous example:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '|   | Predicted class |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| A | B |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: '| **Actual class** | A | 45 | 5 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
- en: '| B | 0 | 50 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: In the preceding confusion matrix, the classifier classifies all samples of
    class B correctly. Also, only 5 samples of class A are classified incorrectly.
    Thus, this classifier better understands the distinction between the two classes
    of data when compared to the classifier used in the previous example. In practice,
    we must strive to train a classifier such that it has values close to *0* for
    all the elements other than the diagonal elements in its confusion matrix.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Understanding feature selection
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we mentioned earlier, we need to determine an appropriate set of features
    from the sample data on which we must base our model. We can use cross-validation
    to determine which set of features to use from the training data, which can be
    explained as follows.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'For each set or combination of feature variables, we determine the training
    and cross-validation error of a model based on the selected set of features. For
    example, we might want to add polynomial features derived from the independent
    variables of our model. We evaluate the training and cross-validation errors for
    each set of features depending on the highest degree of polynomial used to model
    the training data. We can plot the variance of these error functions over the
    degree of polynomial used, similar to the following diagram:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding feature selection](img/4351OS_05_16.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: From the preceding diagram, we can determine which set of features produce an
    underfit or overfit estimated model. If a selected model has a high value for
    both the training and cross-validation errors, which is found towards the left
    of the plot, then the model is underfitting the supplied training data. On the
    other hand, a low training error and a high cross-validation error, as shown towards
    the right of the plot, indicates that the model is overfit. Ideally, we must select
    the set of features with the lowest possible values of the training and cross-validation
    errors.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Varying the regularization parameter
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To produce a better fit of the training data, we can use regularization to
    avoid the problem of overfitting our data. The value ![Varying the regularization
    parameter](img/4351OS_05_17.jpg) of a given model must be appropriately selected
    depending on the behavior of the model. Note that a high regularization parameter
    could result in a high training error, which is an undesirable effect. We can
    vary the regularization parameter in a formulated machine learning model to produce
    the following plot of the error values over the value of the regularization parameter
    in our model:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![Varying the regularization parameter](img/4351OS_05_18.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: Thus, as shown in the preceding plot, we can also minimize the training and
    cross-validation error in the model by changing the regularization parameter.
    If a model exhibits a high value for both these error values, we must consider
    reducing the value of the regularization parameter until both the error values
    are significantly low for the supplied sample data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Understanding learning curves
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another useful way to visualize the performance of a machine learning model
    is to use learning curves. A **learning curve** is essentially a plot of the error
    values in a model over the number of samples by which it is trained and cross-validated.
    For example, a model could have the following learning curve for the training
    and cross-validation errors:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding learning curves](img/4351OS_05_19.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: 'Learning curves can be used to diagnose an underfit and overfit model. For
    example, the training error could be observed to increase quickly and converge
    towards a value close to the cross-validation with the number of samples provided
    to the model. Also, both the error values in our model have a significantly high
    value. A model that exhibits this kind of variance of error with the number of
    samples is underfit and has a learning curve similar to the following plot:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding learning curves](img/4351OS_05_20.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
- en: 'On the other hand, a model''s training error could be observed to increase
    slowly with the number of samples provided to the model, and there might also
    be a large difference between the training and cross-validation errors in the
    model. This model is said to be overfit and has a learning curve similar to the
    following plot:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding learning curves](img/4351OS_05_21.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
- en: Thus, learning curve is a good supplementary tool to cross-validation for determining
    what is not working and what needs to be changed in a given machine learning model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Improving a model
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have determined whether a model is underfit or overfit over the given
    sample data, we must decide on how to improve the model''s understanding of the
    relationship between the independent and dependent variables in our model. Let''s
    briefly discuss a few of these techniques, as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Add or remove some features. As we will explore later, this technique can be
    used to improve both an underfit and an overfit model.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vary the value of the regularization parameter ![Improving a model](img/4351OS_05_17.jpg).
    Like adding or removing features, this method can be applied to both underfit
    and overfit models.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gather more training data. This method is a fairly obvious solution for improving
    an overfit model as it's needed to formulate a more generalized model to fit the
    training data.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add features which are polynomial terms of other features in the model. This
    method can be used to improve an underfit model. For example, if we are modeling
    two independent feature variables, ![Improving a model](img/4351OS_05_22.jpg)
    and ![Improving a model](img/4351OS_05_23.jpg), we could add the terms ![Improving
    a model](img/4351OS_05_24.jpg) as additional features to improve the model. The
    polynomial terms could be of even higher degrees, such as ![Improving a model](img/4351OS_05_25.jpg)
    and ![Improving a model](img/4351OS_05_26.jpg) , although this could result in
    overfitting the training data.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using cross-validation
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we briefly mentioned earlier, cross-validation is a common validation technique
    that can be used to evaluate machine learning models. Cross-validation essentially
    measures how well the estimated model will generalize some given data. This data
    is different from the training data supplied to our model, and is called the **cross-validation
    set**, or simply **validation set**, of our model. Cross-validation of a given
    model is also called **rotation estimation**.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: If an estimated model performs well during cross-validation, we can assume that
    the model can understand the relationship between its various independent and
    dependent variables. The goal of cross-validation is to provide a test to determine
    if a formulated model is overfit on the training data. In the perspective of implementation,
    cross-validation is a kind of unit test for a machine learning system.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果估计模型在交叉验证期间表现良好，我们可以假设该模型可以理解其各种独立和依赖变量之间的关系。交叉验证的目的是提供一个测试，以确定所提出的模型是否在训练数据上过度拟合。从实施的角度来看，交叉验证是机器学习系统的一种单元测试。
- en: A single round of cross-validation generally involves partitioning all the available
    sample data into two subsets and then performing training on one subset and validation
    and/or testing on the other subset. Several such rounds, or *folds*, of cross-validation
    must be performed using different sets of data to reduce the variance of the overall
    cross-validation error of the given model. Any particular measure of the cross-validation
    error should be calculated as the average of this error over the different folds
    in cross-validation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 单轮交叉验证通常涉及将所有可用的样本数据划分为两个子集，然后在其中一个子集上进行训练，在另一个子集上进行验证和/或测试。必须使用不同的数据集进行多个这样的交叉验证轮次，或称为“折”，以减少给定模型的整体交叉验证误差的方差。任何特定的交叉验证误差度量都应该计算为不同折在交叉验证中的平均误差。
- en: 'There are several types of cross-validation we can implement as a diagnostic
    for a given machine learning model or system. Let''s briefly explore a few of
    them as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于给定的机器学习模型或系统，我们可以实现多种类型的交叉验证作为诊断。以下简要探讨其中几种：
- en: A common type is *k-fold* cross-validation, in which we partition the cross-validation
    data into *k* equal subsets. The training of the model is then performed on ![Using
    cross-validation](img/4351OS_05_27.jpg) subsets of the data and the cross-validation
    is performed on a single subset.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种常见类型是*k-折交叉验证*，其中我们将交叉验证数据划分为*k*个相等的子集。然后，在数据的一个子集上执行模型的训练，在另一个子集上进行交叉验证。
- en: A simple variation of *k-fold* cross-validation is *2-fold* cross-validation,
    which is also called the *holdout method*. In *2-fold* cross-validation, the training
    and cross-validation subsets of data will be almost equal in proportion.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k-折交叉验证*的一种简单变体是*2-折交叉验证*，也称为*留出法*。在*2-折交叉验证中，训练和交叉验证数据子集的比例几乎相等。'
- en: '**Repeated random subsampling** is another simple variant of cross-validation
    in which the sample data is first randomized or shuffled and then used as training
    and cross-validation data. This method is notably not dependent on the number
    of folds used for cross-validation.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重复随机子采样**是交叉验证的另一种简单变体，其中首先对样本数据进行随机化或洗牌，然后将其用作训练和交叉验证数据。这种方法特别不依赖于交叉验证中使用的折数。'
- en: Another form of *k-fold* cross-validation is **leave-one-out** cross-validation,
    in which only a single record from the available sample data is used for cross-validation.
    Leave-one-out cross-validation is essentially *k-fold* cross-validation in which
    *k* is equal to the number of samples or observations in the sample data.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k-折交叉验证*的另一种形式是**留一法交叉验证*，其中仅使用可用样本数据中的一个记录进行交叉验证。留一法交叉验证本质上等同于*k-折交叉验证*，其中*k*等于样本数据中的样本或观察数量。'
- en: 'Cross-validation basically treats the estimated model as a black box, that
    is, it makes no assumptions about the implementation of the model. We can also
    use cross-validation to select features in a given model by using cross-validation
    to determine the feature set that produces the best fit model over the given sample
    data. Of course, there are a couple of limitations of classification, which can
    be summarized as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证基本上将估计模型视为一个黑盒，即它不对模型的实现做出任何假设。我们还可以使用交叉验证来通过确定在给定样本数据上产生最佳拟合模型的特征集来选择给定模型中的特征。当然，分类有一些局限性，可以总结如下：
- en: If a given model is needed to perform feature selection internally, we must
    perform cross-validation for each selected feature set in the given model. This
    can be computationally expensive depending on the amount of available sample data.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要给定的模型进行内部特征选择，我们必须对给定模型中每个选定的特征集进行交叉验证。这可能会根据可用样本数据的数量而变得计算成本高昂。
- en: Cross-validation is not very useful if the sample data comprises exactly or
    nearly equal samples.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, it's a good practice to implement cross-validation for any machine
    learning system that we build. Also, we can choose an appropriate cross-validation
    technique depending on the problem we are trying to model as well as the nature
    of the collected sample data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For the example that will follow, the namespace declaration should look similar
    to the following declaration:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can use the `clj-ml` library to cross-validate the classifier we built for
    the fish packaging plant in [Chapter 3](ch03.html "Chapter 3. Categorizing Data"),
    *Categorizing Data*. Essentially, we built a classifier to determine whether a
    fish is a salmon or a sea bass using the `clj-ml` library. To recap, a fish is
    represented as a vector containing the category of the fish and values for the
    various features of the fish. The attributes of a fish are its length, width,
    and lightness of skin. We also described a template for a sample fish, which is
    defined as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `fish-template` vector defined in the preceding code can be used to train
    a classifier with some sample data. For now, we will not bother about which classification
    algorithm we have used to model the given training data. We can only assume that
    the classifier was created using the `make-classifier` function from the `clj-ml`
    library. This classifier is stored in the `*classifier*` variable as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Suppose the classifier was trained with some sample data. We must now evaluate
    this trained classification model. To do this, we must first create some sample
    data to cross-validate. For the sake of simplicity, we will use randomly generated
    data in this example. We can generate this data using the `make-sample-fish` function,
    which we defined in [Chapter 3](ch03.html "Chapter 3. Categorizing Data"), *Categorizing
    Data*. This function simply creates a new vector of some random values representing
    a fish. Of course, we must not forget the fact that the `make-sample-fish` function
    has an in-built partiality, so we create a meaningful pattern in a number of samples
    created using this function as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We will need to use a dataset from the `clj-ml` library, and we can create
    one using the `make-dataset` function, as shown in the following code:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To cross-validate the classifier, we must use the `classifier-evaluate` function
    from the `clj-ml.classifiers` namespace. This function essentially performs *k-fold*
    cross-validation on the given data. Other than the classifier and the cross-validation
    dataset, this function requires the number of folds that we must perform on the
    data to be specified as the last parameter. Also, we will first need to set the
    class field of the records in `fish-cv-dataset` using the `dataset-set-class`
    function. We can define a single function to perform these operations as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will use 10 folds of cross-validation on the classifier. Since the `classifier-evaluate`
    function returns a map, we bind this return value to a variable for further use,
    as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在分类器上使用10折交叉验证。由于`classifier-evaluate`函数返回一个映射，我们将此返回值绑定到一个变量以供进一步使用，如下所示：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can fetch and print the summary of the preceding cross-validation using
    the `:summary` keyword as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`:summary`关键字获取并打印前面交叉验证的摘要，如下所示：
- en: '[PRE7]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As shown in the preceding code, we can view several statistical measures of
    performance for our trained classifier. Apart from the correctly and incorrectly
    classified records, this summary also describes the **Root Mean Squared Error**
    (**RMSE**) and several other measures of error in our classifier. For a more detailed
    view of the correctly and incorrectly classified instances in the classifier,
    we can print the confusion matrix of the cross-validation using the `:confusion-matrix`
    keyword, as shown in the following code:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码所示，我们可以查看我们训练好的分类器的多个性能统计指标。除了正确和错误分类的记录外，此摘要还描述了分类器中的**均方根误差**（**RMSE**）和其他几个误差度量。为了更详细地查看分类器中正确和错误分类的实例，我们可以使用`:confusion-matrix`关键字打印交叉验证的混淆矩阵，如下所示：
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As shown in the preceding example, we can use the `clj-ml` library's `classifier-evaluate`
    function to perform a *k-fold* cross-validation on any given classifier. Although
    we are restricted to using classifiers from the `clj-ml` library when using the
    `classifier-evaluate` function, we must strive to implement similar diagnostics
    in any machine learning system we build.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如前例所示，我们可以使用`clj-ml`库的`classifier-evaluate`函数对任何给定的分类器执行*k*折交叉验证。尽管在使用`classifier-evaluate`函数时我们被限制只能使用`clj-ml`库中的分类器，但我们必须努力在我们构建的任何机器学习系统中实现类似的诊断。
- en: Building a spam classifier
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建垃圾邮件分类器
- en: Now that we are familiar with cross-validation, we will build a working machine
    learning system that incorporates cross-validation. The problem at hand will be
    that of **spam classification**, in which we will have to determine the likelihood
    of a given e-mail being a spam e-mail. Essentially, the problem boils down to
    binary classification with a few tweaks to make the machine learning system more
    sensitive to spam (for more information, refer to *A Plan for Spam*). Note that
    we will not be implementing a classification engine that is integrated with an
    e-mail server, but rather we will be concentrating on the aspects of training
    the engine with some data and classifying a given e-mail.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了交叉验证，我们将构建一个包含交叉验证的工作机器学习系统。当前的问题将是**垃圾邮件分类**，其中我们必须确定一封给定邮件是否为垃圾邮件的可能性。本质上，这个问题归结为二元分类，并做了一些调整以使机器学习系统对垃圾邮件更加敏感（更多信息，请参阅*垃圾邮件计划*）。请注意，我们不会实现一个与电子邮件服务器集成的分类引擎，而是将专注于使用一些数据训练引擎和分类给定邮件的方面。
- en: The way this would be used in practice can be briefly explained as follows.
    A user will receive and read a new e-mail, and will decide whether to mark the
    e-mail as spam or not. Depending on the user's decision, we must train the e-mail
    service's spam engine using the new e-mail as data.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这种在实际中的使用方法可以简要说明如下。用户将接收并阅读一封新邮件，并决定是否将该邮件标记为垃圾邮件。根据用户的决定，我们必须使用新邮件作为数据来训练邮件服务的垃圾邮件引擎。
- en: In order to train our spam classifier in a more automated manner, we'll have
    to simply gather data to feed into the classifier. We will need a large amount
    of data to effectively train a classifier with the English language. Luckily for
    us, sample data for spam classification can be found easily on the Web. For this
    implementation, we will use data from the **Apache SpamAssassin** project.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了以更自动化的方式训练我们的垃圾邮件分类器，我们只需简单地收集数据以供分类器使用。我们需要大量的数据才能有效地用英语训练一个分类器。幸运的是，垃圾邮件分类的样本数据在互联网上很容易找到。对于这个实现，我们将使用来自**Apache
    SpamAssassin**项目的数据。
- en: Note
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: The Apache SpamAssassin project is an open source implementation of a spam classification
    engine in Perl. For our implementation, we will use the sample data from this
    project. You can download this data from [http://spamassassin.apache.org/publiccorpus/](http://spamassassin.apache.org/publiccorpus/).
    For our example, we have used the `spam_2` and `easy_ham_2` datasets. A Clojure
    Leiningen project housing our spam classifier implementation will require that
    these datasets be extracted and placed in the `ham/` and `spam/` subdirectories
    of the `corpus/` folder. The `corpus/` folder should be placed in the root directory
    of the Leiningen project that is the same folder of the `project.clj` file.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: The features of our spam classifier will be the number of occurrences of all
    previously encountered words in spam and ham e-mails. By the term **ham**, we
    mean "not spam". Thus, there are effectively two independent variables in our
    model. Also, each word has an associated probability of occurrence in e-mails,
    which can be calculated from the number of times it's found in spam and ham e-mails
    and the total number of e-mails processed by the classifier. A new e-mail would
    be classified by finding all known words in the e-mail's header and body and then
    somehow combining the probabilities of occurrences of these words in spam and
    ham e-mails.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: For a given word feature in our classifier, we must calculate the total probability
    of occurrence of the word by taking into account the total number of e-mails analyzed
    by the classifier (for more information, refer to *Better Bayesian Filtering*).
    Also, an unseen term is neutral in the sense that it is neither spam nor ham.
    Thus, the initial probability of occurrence of any word in the untrained classifier
    is 0.5\. Hence, we use a **Bayesian probability** function to model the occurrence
    of a particular word.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to classify a new e-mail, we also need to combine the probabilities
    of occurrences of all the known words found in it. For this implementation, we
    will use **Fisher''s method**, or **Fisher''s combined probability test**, to
    combine the calculated probabilities. Although the mathematical proof of this
    test is beyond the scope of this book, it''s important to know that this method
    essentially estimates the probabilities of several independent probabilities in
    a given model as a ![Building a spam classifier](img/4351OS_05_28.jpg) (pronounced
    as **chi-squared**) distribution (for more information, refer to *Statistical
    Methods for Research Workers*). Such a distribution has an associated number of
    degrees of freedom. It can be shown that an ![Building a spam classifier](img/4351OS_05_28.jpg)
    distribution with degrees of freedom equal to twice the number of combined probabilities
    *k* can be formally expressed as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![Building a spam classifier](img/4351OS_05_29.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: This means that using an ![Building a spam classifier](img/4351OS_05_28.jpg)
    distribution with ![Building a spam classifier](img/4351OS_05_30.jpg) degrees
    of freedom, the **Cumulative Distribution Function** (**CDF**), of the probabilities
    of the e-mail being a spam or a ham can be combined to reflect a total probability
    that is high when there are a large number of probabilities with values close
    to 1.0\. Thus, an e-mail is classified as spam only when most of the words in
    the e-mail have been previously found in spam e-mails. Similarly, a large number
    of ham keywords would indicate the e-mail is in fact a ham e-mail. On the other
    hand, a low number of occurrences of spam keywords in an e-mail would have a probability
    closer to 0.5, in which case the classifier will be unsure of whether the e-mail
    is spam or ham.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着使用具有![构建垃圾邮件分类器](img/4351OS_05_28.jpg)自由度的![构建垃圾邮件分类器](img/4351OS_05_30.jpg)分布，电子邮件是垃圾邮件或正常邮件的概率的**累积分布函数**（**CDF**）可以结合起来反映一个总概率，当有大量值接近1.0的概率时，这个总概率会很高。因此，只有当电子邮件中的大多数单词之前都曾在垃圾邮件中找到时，电子邮件才会被分类为垃圾邮件。同样，大量正常邮件的关键词也会表明该电子邮件实际上是一封正常邮件。另一方面，电子邮件中垃圾邮件关键词出现的次数较少时，其概率会更接近0.5，在这种情况下，分类器将不确定该电子邮件是垃圾邮件还是正常邮件。
- en: Note
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'For the example that will follow, we will require the `file` and `cdf-chisq`
    functions from the `clojure.java.io` and `Incanter` libraries, respectively. The
    namespace declaration of the example should look similar to the following declaration:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于接下来的示例，我们需要从`clojure.java.io`和`Incanter`库中分别获取`file`和`cdf-chisq`函数。示例的命名空间声明应类似于以下声明：
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'A classifier trained using Fisher''s method, as described earlier, will be
    very sensitive to new spam e-mails. We represent the dependent variable of our
    model by the probability of a given e-mail being spam. This probability is also
    termed as the **spam score** of the e-mail. A low score indicates that an e-mail
    is ham, while a high score indicates that the e-mail is spam. Of course, we must
    also include a third class to represent an unknown value in our model. We can
    define some reasonable limits for the scores of these categories as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面描述的Fisher方法训练的分类器将非常敏感于新的垃圾邮件。我们用给定电子邮件是垃圾邮件的概率来表示我们模型的因变量。这个概率也被称为电子邮件的**垃圾邮件分数**。低分数表示电子邮件是正常邮件，而高分数表示电子邮件是垃圾邮件。当然，我们还需要在我们的模型中包含一个第三类来表示未知值。我们可以为这些类别的分数定义一些合理的限制，如下所示：
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As defined earlier, if an e-mail has a score of 0.7 or more, it's a spam e-mail.
    And a score of 0.5 or less indicates that the e-mail is ham. Also, if the score
    lies between these two values, we can't effectively decide whether the e-mail
    is spam or not. We represent these three categories using the keywords `:ham`,
    `:spam`, and `:unsure`.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，如果电子邮件的分数为0.7或更高，则它是垃圾邮件。分数为0.5或更低的电子邮件表示它是正常邮件。此外，如果分数介于这两个值之间，我们无法有效地决定电子邮件是垃圾邮件还是正常邮件。我们使用关键词`:ham`、`:spam`和`:unsure`来表示这三个类别。
- en: 'The spam classifier must read several e-mails, determine all the words, or
    *tokens*, in the e-mails'' text and header, and store this information as empirical
    knowledge to use later. We need to store the number of occurrences a particular
    word is found in spam and ham e-mails. Thus, every word that the classifier has
    encountered represents a feature. To represent this information for a single word,
    we will use a record with three fields as shown in the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾邮件分类器必须读取几封电子邮件，确定电子邮件文本和标题中的所有单词或*标记*，并将这些信息作为经验知识存储起来以供以后使用。我们需要存储特定单词在垃圾邮件和正常邮件中出现的次数。因此，分类器遇到的每个单词都代表一个特征。为了表示单个单词的信息，我们将使用具有三个字段的记录，如下面的代码所示：
- en: '[PRE11]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The record `TokenFeature` defined in the preceding code can be used to store
    the needed information for our spam classifier. The `new-token` function simply
    creates a new record for a given token by invoking the records, constructor. Obviously,
    a word is initially seen zero times in both spam and ham e-mails. We will also
    need to update these values, and we define the `inc-count` function to perform
    an update on the record using the `update-in` function. Note that the `update-in`
    function expects a function to apply to a particular field in the record as the
    last parameter. We are already dealing with a small amount of a mutable state
    in our implementation, so let''s delegate access to this state through an agent.
    We would also like to keep track of the total number of ham and spam e-mails;
    so, we''ll wrap these values with agents as well, as shown in the following code:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `feature-db` agent defined in the preceding code will be used to store
    all word features. We define a simple error handler for this agent using the `:error-handler`
    keyword parameter. The agent''s `total-ham` and `total-spam` functions will keep
    track of the total number of ham and spam e-mails, respectively. We will now define
    a couple of functions to access these agents as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In case you are not familiar with agents in Clojure, we can use the `send` function
    to alter the value contained in an agent. This function expects a single argument,
    that is, the function to apply to its encapsulated value. The agent applies this
    function on its contained value and updates it if there are no errors. The `clear-db`
    function simply initializes all the agents we've defined with an initial value.
    This is done by using the `constantly` function that wraps a value in a function
    that returns the same value. The `update-feature!` function modifies the value
    of a given token in the `feature-db` map and creates a new token if the supplied
    token is not present in the map of `feature-db`. Since we will only be incrementing
    the number of occurrences of a given token, we will pass the `inc-count` function
    as a parameter to the `update-feature!` function.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s define how the classifier will extract words from a given e-mail.
    We''ll use regular expressions to do this. If we want to extract all the words
    from a given string, we can use the regular expression `[a-zA-Z]{3,}`. We can
    define this regular expression using a literal syntax in Clojure, as shown in
    the following code. Note that we could also use the `re-pattern` function to create
    a regular expression. We will also define all the MIME header fields from which
    we should also extract tokens. We will do all this with the help of the following
    code:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To match tokens with the regular expression defined by `token-regex`, we will
    use the `re-seq` function, which returns all matching tokens in a given string
    as a sequence of strings. For the MIME headers of an e-mail, we need to use a
    different regular expression to extract tokens. For example, we can extract tokens
    from the `"From"` MIME header as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note the use of the newline character at the end of the regular expression,
    which is used to indicate the end of a MIME header in an e-mail.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then proceed to extract words from the values returned by matching the
    regular expression defined in the preceding code. Let''s define the following
    few functions to extract tokens from a given e-mail''s headers and body using
    this logic:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `header-token-regex` function defined in the preceding code returns a regular
    expression for a given header, such as `From:(.*)\n` for the `"From"` header.
    The `extract-tokens-from-headers` function uses this regular expression to determine
    all words in the various header fields of an e-mail and appends the header name
    to all the tokens found in the header text. The `extract-tokens` function applies
    the regular expression over the text and headers of an e-mail and then flattens
    the resulting lists into a single list using the `apply` and `concat` functions.
    Note that the `extract-tokens-from-headers` function returns empty lists for the
    headers defined in `header-fields`, which are not present in the supplied e-mail
    header. Let''s try this function out in the REPL with the help of the following
    code:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Using the `extract-tokens-from-headers` function and the regular expression
    defined by `token-regex`, we can extract all words comprising of three or more
    characters from an e-mail''s header and text. Now, let''s define a function to
    apply the `extract-tokens` function on a given e-mail and update the feature map
    using the `update-feature!` function with all the words found in the e-mail. We
    will do all this with the help of the following code:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Using the `update-features!` function in the preceding code, we can train our
    spam classifier with a given e-mail. In order to keep track of the total number
    of spam and ham e-mails, we will have to send the `inc` function to the `total-spam`
    or `total-ham` agents depending on whether a given e-mail is spam or ham. We will
    do this with the help of the following code:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `inc-total-count!` function defined in the preceding code updates the total
    number of spam and ham e-mails in our feature database. The `train!` function
    simply calls the `update-features!` and `inc-total-count!` functions to train
    our spam classifier with a given e-mail and its type. Note that we pass the `inc-count`
    function to the `update-features!` function. Now, in order to classify a new e-mail
    as spam or ham, we must first define how to extract the known features from a
    given e-mail using our trained feature database. We will do this with the help
    of the following code:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The `extract-features` function defined in the preceding code looks up all known
    features in a given e-mail by dereferencing the map stored in `feature-db` and
    applying it as a function to all the values returned by the `extract-tokens` function.
    As mapping the closure `#(@feature-db %1)` can return `()` or `nil` for all tokens
    that are not present in a `feature-db` agent, we will need to remove all empty
    values from the list of extracted features. To do this, we will use the `keep`
    function, which expects a function to apply to the non-nil values in a collection
    and the collection from which all nil values must be filtered out. Since we do
    not intend to transform the known features from the e-mail, we will pass the `identity`
    function, which returns its argument itself as the first parameter to the `keep`
    function.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have extracted all known features from a given e-mail, we must
    calculate all the probabilities of these features occurring in a spam e-mail.
    We must then combine these probabilities using Fisher''s method we described earlier
    to determine the spam score of a new e-mail. Let''s define the following functions
    to implement the Bayesian probability and Fisher''s method:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `spam-probability` function defined in the preceding code calculates the
    probability of occurrence of a given word feature in a spam e-mail using the number
    of occurrences of the word in spam and ham e-mails and the total number of spam
    and ham e-mails processed by the classifier. To avoid division-by-zero errors,
    we ensure that the value of the number of spam and ham e-mails is at least 1 before
    performing division. The `bayesian-spam-probability` function uses this probability
    returned by the `spam-probability` function to calculate a weighted average with
    the initial probability of 0.5 or *1/2*.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now implement Fisher''s method of combining the probabilities returned
    by the `bayesian-spam-probability` function for all the known features found in
    an e-mail. We will do this with the help of the following code:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `fisher` function defined in the preceding code uses the `cdf-chisq` function
    from the `Incanter` library to calculate the CDF of the several probabilities
    transformed by the expression ![Building a spam classifier](img/4351OS_05_31.jpg).
    We specify the number of degrees of freedom to this function using the `:df` optional
    parameter. We now need to apply the `fisher` function to the combined Bayesian
    probabilities of an e-mail being spam or ham, and combine these values into a
    final spam score. These two probabilities must be combined such that only a high
    number of occurrences of high probabilities indicate a strong probability of spam
    or ham. It has been shown that the simplest way to do this is to average the probability
    of a spam e-mail and the negative probability of a ham e-mail (or 1 minus the
    probability of a ham e-mail). We will do this with the help of the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Hence, the `score` function will return the final spam score of a given e-mail.
    Let''s define a function to extract the known word features from a given e-mail,
    combine the probabilities of occurrences of these features to produce the e-mail''s
    spam score, and finally classify this spam score as a ham or spam e-mail, represented
    by the keywords `:ham` and `:spam` respectively, as shown in the following code:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'So far, we have implemented how we train our spam classifier and use it to
    classify a new e-mail. Now, let''s define some functions to load the sample data
    from the project''s `corpus/` folder and use this data to train and cross-validate
    our classifier, as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `populate-emails` function defined in the preceding code returns a sequence
    of vectors to represent all the ham e-mails from the `ham/` folder and the spam
    e-mails from the `spam/` folder in our sample data. Each vector in this returned
    sequence has two elements. The first element in this vector is a given e-mail's
    relative file path and the second element is either `:spam` or `:ham` depending
    on whether the e-mail is spam or ham. Note the use of the `file-seq` function
    to read the files in a directory as a sequence.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now use the `train!` function to feed the content of all e-mails into
    our spam classifier. To do this, we can use the `slurp` function to read the content
    of a file as a string. For cross-validation, we will classify each e-mail in the
    supplied cross-validation data using the `classify` function and return a list
    of maps representing the test result of the cross-validation. We will do this
    with the help of the following code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The `train-from-corpus!` function defined in the preceding code will train
    our spam classifier with all e-mails found in the `corpus/` folder. The `cv-from-corpus`
    function classifies the supplied e-mails as spam or ham using the trained classifier
    and returns a sequence of maps indicating the results of the cross-validation
    process. Each map in the sequence returned by the `cv-from-corpus` function contains
    the file of the e-mail, the actual type (spam or ham) of the e-mail, the predicted
    type of the e-mail, and the spam score of the e-mail. Now, we need to call these
    two functions on two appropriately partitioned subsets of the sample data as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `test-classifier!` function defined in the preceding code will randomly
    shuffle the sample data and select a specified fraction of this randomized data
    as the cross-validation set for our classifier. The `test-classifier!` function
    then calls the `train-from-corpus!` and `cv-from-corpus` functions to train and
    cross-validate the data. Note that the use of the `await` function is to wait
    until the `feature-db` agent has finished applying all functions that have been
    sent to it via the `send` function.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we need to analyze the results of cross-validation. We must first determine
    the number of incorrectly classified and missed e-mails from the actual and expected
    class of a given e-mail as returned by the `cv-from-corpus` function. We will
    do this with the help of the following code:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要分析交叉验证的结果。我们必须首先确定由 `cv-from-corpus` 函数返回的给定电子邮件的实际和预期类别中的错误分类和遗漏的电子邮件数量。我们将使用以下代码来完成这项工作：
- en: '[PRE28]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The `result-type` function will determine the number of incorrectly classified
    and missed e-mails in the cross-validation process. We can now apply the `result-type`
    function to all the maps in the results returned by the `cv-from-corpus` function
    and print a summary of the cross-validation results with the help of the following
    code:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`result-type` 函数将确定交叉验证过程中错误分类和遗漏的电子邮件数量。现在，我们可以将 `result-type` 函数应用于 `cv-from-corpus`
    函数返回的结果中的所有映射，并使用以下代码帮助打印交叉验证结果的摘要：'
- en: '[PRE29]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The `analyze-results` function defined in the preceding code simply applies
    the `result-type` function to all the map values in the sequence returned by the
    `cv-from-corpus` function, while maintaining the total number of incorrectly classified
    and missed e-mails. The `print-result` function simply prints the analyzed result
    as a string. Finally, let''s define a function to load all the e-mails using the
    `populate-emails` function and then use this data to train and cross-validate
    our spam classifier. Since the `populate-emails` function will return an empty
    list, or `nil` when there are no e-mails, we will check this condition to avoid
    failing at a later stage in our program:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中定义的 `analyze-results` 函数简单地将 `result-type` 函数应用于 `cv-from-corpus` 函数返回的序列中的所有映射值，同时保持错误分类和遗漏的电子邮件总数。`print-result`
    函数简单地将分析结果打印为字符串。最后，让我们定义一个函数，使用 `populate-emails` 函数加载所有电子邮件，然后使用这些数据来训练和交叉验证我们的垃圾邮件分类器。由于
    `populate-emails` 函数在没有电子邮件时将返回一个空列表或 `nil`，我们将检查这个条件以避免在程序后续阶段失败：
- en: '[PRE30]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In the `train-and-cv-classifier` function shown in the preceding code, we first
    call the `populate-emails` function and convert the result to a sequence using
    the `seq` function. If the sequence has any elements, we train and cross-validate
    the classifier. If there are no e-mails found, we simply throw an error. Note
    that the `if-let` function is used to check whether the sequence returned by the
    `seq` function has any elements.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面代码中显示的 `train-and-cv-classifier` 函数中，我们首先调用 `populate-emails` 函数，并使用 `seq`
    函数将结果转换为序列。如果序列有任何元素，我们训练并交叉验证分类器。如果没有找到电子邮件，我们简单地抛出一个错误。请注意，`if-let` 函数用于检查 `seq`
    函数返回的序列是否有任何元素。
- en: 'We have all the parts needed to create and train a spam classifier. Initially,
    as the classifier hasn''t seen any e-mails, the probability of any e-mail or text
    being spam is 0.5\. This can be verified by using the `classify` function, as
    shown in the following code, which initially classifies any text as the `:unsure`
    type:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经拥有了创建和训练垃圾邮件分类器所需的所有部分。最初，由于分类器尚未看到任何电子邮件，任何电子邮件或文本被分类为垃圾邮件的概率是 0.5。这可以通过以下代码验证，该代码最初将任何文本分类为
    `:unsure` 类型：
- en: '[PRE31]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We now train the classifier and cross-validate it using the `train-and-cv-classifier`
    function. We will use one-fifth of all the available sample data as our cross-validation
    set. This is shown in the following code:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用 `train-and-cv-classifier` 函数训练分类器并交叉验证它。我们将使用所有可用样本数据的一分之一作为我们的交叉验证集。这如下面的代码所示：
- en: '[PRE32]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Cross-validating our spam classifier asserts that it''s appropriately classifying
    e-mails. Of course, there is still a small amount of error, which can be corrected
    by using more training data. Now, let''s try to classify some text using our trained
    spam classifier, as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证我们的垃圾邮件分类器断言它适当地分类了电子邮件。当然，仍然存在一小部分错误，这可以通过使用更多的训练数据来纠正。现在，让我们尝试使用我们的训练好的垃圾邮件分类器对一些文本进行分类，如下所示：
- en: '[PRE33]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Interestingly, the text `"Make money fast"` is classified as spam and the text
    `"Job interview … GNU project"` is classified as ham, as shown in the preceding
    code. Let''s have a look at how the trained classifier extracts features from
    some text using the `extract-features` function. Since the classifier will initially
    have read no tokens, this function will obviously return an empty list or `nil`
    when the classifier is untrained, as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As shown in the preceding code, each `TokenFeature` record will contain the
    number of times a given word is seen in spam and ham e-mails. Also, the word `"to"`
    is not recognized as a feature since we only consider words comprising of three
    or more characters.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s check how sensitive to spam e-mail our spam classifier actually
    is. We''ll first have to select some text or a particular term that is classified
    as neither spam nor ham. For the training data selected for this example, the
    word `"Job"` fits this requirement, as shown in the following code. Let''s train
    the classifier with the word `"Job"` while specifying the type of the text as
    ham. We can do this using the `train!` function, as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'After training the classifier with the given text as ham, the probability of
    the term being spam is observed to decrease by a small amount. If the term `"Job"`
    occurred in several more e-mails that were ham, the classifier would eventually
    classify this word as ham. Thus, the classifier doesn''t show much of a reaction
    to a new ham e-mail. On the contrary, the classifier is observed to be very sensitive
    to spam e-mails, as shown in the following code:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: An occurrence of a particular word in a single spam e-mail is observed to greatly
    increase a classifier's predicted probability of the given term belonging to a
    spam e-mail. The term `"Job"` will subsequently be classified as spam by our classifier,
    at least until it's seen to appear in a sufficiently large number of ham e-mails.
    This is due to the nature of the chi-squared distribution that we are modeling.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also improve the overall error of our spam classifier by supplying it
    with more training data. To demonstrate this, let''s cross-validate the classifier
    with only one-tenth of the sample data. Thus, the classifier would be effectively
    trained with nine-tenths of the available data, as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As shown in the preceding code, the number of misses and wrongly classified
    e-mails is observed to reduce when we use more training data. Of course, this
    is only shown as an example, and we should instead collect more e-mails to feed
    into the classifier as training data. Using a significant amount of the sample
    data for cross-validation is a good practice.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: In summary, we have effectively built a spam classifier that is trained using
    Fisher's method. We have also implemented a cross-validation diagnostic, which
    serves as a kind of unit test for our classifier.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the exact values produced by the `train-and-cv-classifier` function
    will vary depending on the spam and ham emails used as training data.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`train-and-cv-classifier`函数产生的确切值将取决于用作训练数据的垃圾邮件和正常邮件。
- en: Summary
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we have explored techniques that can be used to diagnose and
    improve a given machine learning model. The following are some of the other points
    that we have covered:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了可以用来诊断和改进给定机器学习模型的技巧。以下是我们已经涵盖的一些其他要点：
- en: We have revisited the problems of underfitting and overfitting of sample data
    and also discussed how we can evaluate a formulated model to diagnose whether
    it's underfit or overfit.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们重新审视了样本数据欠拟合和过拟合的问题，并讨论了如何评估一个已制定模型以诊断它是否欠拟合或过拟合。
- en: We have explored cross-validation and how it can be used to determine how well
    a formulated model will respond to previously unseen data. We have also seen that
    we can use cross-validation to select the features and the regularization parameter
    of a model. We also studied a few kinds of cross-validation that we can implement
    for a given model.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经探讨了交叉验证及其如何被用来确定一个已制定模型对之前未见过的数据的响应效果。我们还看到，我们可以使用交叉验证来选择模型的特征和正则化参数。我们还研究了几种可以针对给定模型实现的交叉验证方法。
- en: We briefly explored learning curves and how they can be used to diagnose the
    underfit and overfit models.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们简要探讨了学习曲线及其如何被用来诊断欠拟合和过拟合模型。
- en: We've explored the tools provided by the `clj-ml` library to cross-validate
    a given classifier.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经探讨了`clj-ml`库提供的工具，用于对给定分类器进行交叉验证。
- en: Lastly, we've built an operational spam classifier that incorporates cross-validation
    to determine whether the classifier is appropriately classifying e-mails as spam.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们构建了一个操作性的垃圾邮件分类器，该分类器结合交叉验证来确定分类器是否适当地将电子邮件分类为垃圾邮件。
- en: In the following chapters, we will continue exploring more machine learning
    models, and we'll also study **Support Vector Machines** (**SVMs**) in detail.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将继续探索更多的机器学习模型，并且我们还将详细研究**支持向量机**（**SVMs**）。
