<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer063">
<h1 class="chapter-number" id="_idParaDest-116"><a id="_idTextAnchor116"/>5 </h1>
<h1 id="_idParaDest-117"><a id="_idTextAnchor117"/>Understanding Neural Networks and Deep Learning</h1>
<p>Since its debut in 2012, <strong class="bold">Deep Learning</strong> (<strong class="bold">DL</strong>) has made a huge breakthrough and has been applied in many research and industrial areas including computer vision, <strong class="bold">Natural Language Processing</strong> (<strong class="bold">NLP</strong>), and so on. In this chapter, we will introduce basic concepts, including the following:</p>
<ul>
<li>Neural networks and DL </li>
<li>The cost function</li>
<li>The optimizer algorithm</li>
<li>The activation functions</li>
</ul>
<p>After we master the concepts, we will discuss several neural network models and their business use cases, including the following:</p>
<ul>
<li><strong class="bold">Convolutional Neural Networks</strong> (<strong class="bold">CNNs</strong>)</li>
<li><strong class="bold">Recurrent Neural Networks</strong> (<strong class="bold">RNNs</strong>)</li>
<li><strong class="bold">L</strong><strong class="bold">ong Short-Term Memory</strong> (<strong class="bold">LSTM</strong>) networks</li>
<li><strong class="bold">Generative Adversarial Networks</strong> (<strong class="bold">GANs</strong>)</li>
</ul>
<p>Understanding neural networks and DL concepts, common models, and business use cases is extremely important in our cloud ML journey. Let’s get started.</p>
<h1 id="_idParaDest-118"><a id="_idTextAnchor118"/>Neural networks and DL</h1>
<p>In the history of us <a id="_idIndexMarker300"/>human beings, there are many interesting milestones, from vision development and language development to making and using tools. How did humans evolve and how can we train a computer to <em class="italic">see</em>, <em class="italic">speak</em>, and <em class="italic">use</em> tools? Looking for answers to these questions has led us to the modern AI arena. </p>
<p>How do our brains work? Modern science reveals that in the brain, there is a layered neural network <a id="_idIndexMarker301"/>consisting of a set of neurons. A typical neuron collects electrical signals from others through a fine structure called <strong class="bold">dendrites</strong> and sends out spikes <a id="_idIndexMarker302"/>of signals through a conducting structure called an <strong class="bold">axon</strong>, which splits into <a id="_idIndexMarker303"/>many branches. At the end of each branch, a synapse converts the signals from the axon into electrical effects to excite activity on the target <a id="_idIndexMarker304"/>neuron. <em class="italic">Figure 5.1</em> shows the working mechanism of a biological neuron:</p>
<div>
<div class="IMG---Figure" id="_idContainer053">
<img alt="Figure 5.1 – How a biological neuron works " height="922" src="image/Figure_5.1.jpg" width="1627"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – How a biological neuron works </p>
<p>Inspired by the biological neural network model, an <strong class="bold">Artificial Neural Network</strong> (<strong class="bold">ANN</strong>) model consists <a id="_idIndexMarker305"/>of artificial neurons called <strong class="bold">perceptrons</strong>. A perceptron receives <a id="_idIndexMarker306"/>weighted inputs from the other perceptrons, applies the transfer function, which is the sum of the weighted inputs, and the activation function, which adds nonlinear activation to the sum, and outputs to excite the next perceptron. <em class="italic">Figure 5.2</em> shows the working mechanism of an artificial neuron (perceptron):</p>
<div>
<div class="IMG---Figure" id="_idContainer054">
<img alt="Figure 5.2 – How an artificial neuron (perceptron) works " height="596" src="image/Figure_5.2.jpg" width="1353"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – How an artificial neuron (perceptron) works</p>
<p>ANNs consist <a id="_idIndexMarker307"/>of perceptrons working together via layers. <em class="italic">Figure 5.3 </em>shows the structure of a multilayer ANN where each circular node represents a perceptron, and a line represents the connection from the output of one perceptron to the input of another. There are three types of layers in a neural network: an input layer, one or more hidden layers, and an output layer. The neural network <a id="_idIndexMarker308"/>in <em class="italic">Figure 5.3</em> has one input layer, two hidden layers, and an output layer:</p>
<div>
<div class="IMG---Figure" id="_idContainer055">
<img alt="Figure 5.3 – A multilayer ANN " height="753" src="image/Figure_5.3.jpg" width="1198"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – A multilayer ANN</p>
<p>Using neural <a id="_idIndexMarker309"/>networks to perform ML model <a id="_idIndexMarker310"/>training, the data flows in the network as follows:</p>
<ol>
<li>A dataset (<em class="italic">x</em><span class="superscript">1</span><em class="italic">, x</em><span class="superscript">2</span><em class="italic">, x</em><span class="superscript">3</span><em class="italic">, ..., x</em><span class="superscript">n</span>) is prepared and sent to the input layer, which has the same amount of perceptrons as the number of features of the dataset. </li>
<li>The data then moves through to the hidden layers. At each hidden layer, the perceptron processes the weighted inputs (sum and activate, as described earlier), and sends the output to the neurons at the next hidden layer. </li>
<li>After the hidden layers, the data finally moves to the output layer, which provides the outputs. </li>
</ol>
<p>The objective of the neural network is to determine the weights that minimize the cost function (average prediction error for the dataset). Similar to the regression model training process we discussed in the previous chapters, DL model training is implemented by iterations of a two-part process, forward propagation and backpropagation, as follows: </p>
<ul>
<li><strong class="bold">Forward propagation</strong> is the path that information flows from the input layer to the output <a id="_idIndexMarker311"/>layer, through the hidden layers. At the beginning of the training process, data arrives at the input layer where they are multiplied with the weights randomly initialized, then passed to the first hidden layer. Since the input layer has multiple nodes, each one is connected to each node in the first hidden layer; a node in the hidden layer sums up the weighted values to it and applies an activation function (adds nonlinearity). It then sends the output to the nodes of the next layer, where the nodes do the same, till the output of the last hidden layer is multiplied by the weights and becomes the input to the final output layer, where further functions are applied to generate the output. </li>
<li><strong class="bold">Backpropagation</strong> is the path information flows from the output layer all the way back to the input <a id="_idIndexMarker312"/>layer. During this process, the neural network compares the predicted output to the actual output as the first step of backpropagation and calculates the cost function or prediction error. If the cost function is not good enough, it moves back to adjust the weights based on algorithms <a id="_idIndexMarker313"/>such as <strong class="bold">Gradient Descent</strong> (<strong class="bold">GD</strong>) and then starts the forward propagation again with the new weights.</li>
</ul>
<p>Forward propagation and backpropagation are repeated multiple times—each time the network adjusts the <a id="_idIndexMarker314"/>weights, trying to get a better cost function value—until the network <a id="_idIndexMarker315"/>gets a good cost function (an acceptable accuracy) at the output layer. At this time, the model training is completed and we have got the optimized weights, which are the results of the training.</p>
<p>DL is training ML models with neural networks. If you compare the preceding DL model training process using <a id="_idIndexMarker316"/>neural networks with the ML model training process we discussed in the <em class="italic">Training the model</em> section in <a href="B18333_04.xhtml#_idTextAnchor094"><em class="italic">Chapter 4</em></a>, <em class="italic">Developing and Deploying ML Models</em>, you will find that the concepts of ML and DL are very similar. Via iterative forward propagation and backward propagation, both are trying to minimize the cost function of the model—ML is more about computers learning from data with traditional algorithms, while DL is more about computers learning from data mimicking the human brain and neural networks. Relatively speaking, ML requires less computing power and DL needs less human intervention. In the following sections, we will take a close look at the cost function, the optimizer algorithm, and the activation function for DL with neural networks.</p>
<h1 id="_idParaDest-119"><a id="_idTextAnchor119"/>The cost function </h1>
<p>We introduced the concept of the cost function in the <em class="italic">Linear regression</em> section in <a href="B18333_04.xhtml#_idTextAnchor094"><em class="italic">Chapter 4</em></a>. The cost function <a id="_idIndexMarker317"/>gives us a mathematical way of determining how much error the current model has—it assigns a cost for making an incorrect prediction and provides a way to measure the model performance. The cost function is a key metric in ML model training—choosing the right cost function can improve model performance dramatically. </p>
<p>The common cost functions for regression models are MAE and MSE. As we have discussed in previous chapters, MAE defines a summation of the absolute differences between the <a id="_idIndexMarker318"/>prediction values and the label values. MSE defines the summation <a id="_idIndexMarker319"/>of squares of the differences between the prediction values and the label values. </p>
<p>The cost functions for classification models are quite different. Conceptually, the cost function for a classification <a id="_idIndexMarker320"/>model is the difference between the probability distributions for different classes. For binary classification models where the model outputs <a id="_idIndexMarker321"/>are binary, 1 for yes or 0 for no, we use <strong class="bold">binary cross entropy</strong>. For multi-class <a id="_idIndexMarker322"/>classification models, depending <a id="_idIndexMarker323"/>on the dataset labels, we use <strong class="bold">categorical cross entropy</strong> and <strong class="bold">sparse categorical cross entropy</strong> as follows:</p>
<ul>
<li>If the labels are integers, for example, to classify an image of a dog, a cat, or a cow, then we use sparse categorical cross entropy since the output is one exclusive class. </li>
<li>Otherwise, if the labels are encoded as a series of zeros and ones for each class (same for the one-hot-encoding format that we have discussed in the previous chapters), we’ll use categorical cross entropy. For example, given an image, you need to detect whether there exists a driver’s license, a passport, or a social security card, we will use categorical cross entropy as cost functions since the output has a combination of classes.</li>
</ul>
<p>The cost function is a way of measuring our models so we can adjust the model parameters to minimize them—the model optimization process. In the following section, we’ll talk about the optimizer algorithms that minimize the cost function.</p>
<h1 id="_idParaDest-120"><a id="_idTextAnchor120"/>The optimizer algorithm</h1>
<p>In the <em class="italic">Linear regression</em> section in <a href="B18333_04.xhtml#_idTextAnchor094"><em class="italic">Chapter 4</em></a>, we discussed the <strong class="bold">GD</strong> algorithm, which <a id="_idIndexMarker324"/>optimizes the linear regression cost <a id="_idIndexMarker325"/>function. In neural networks, the optimizer is an algorithm used to minimize <a id="_idIndexMarker326"/>the cost function in model training. The <a id="_idIndexMarker327"/>commonly used <a id="_idIndexMarker328"/>optimizers <a id="_idIndexMarker329"/>are <strong class="bold">Stochastic Gradient Descent</strong> (<strong class="bold">SGD</strong>), <strong class="bold">RMSprop</strong>, and <strong class="bold">Adam</strong> as follows:</p>
<ul>
<li><strong class="bold">SGD</strong> is useful for very large datasets. Instead of GD, which runs through all of the samples in your <a id="_idIndexMarker330"/>training dataset to update parameters, SGD uses one or a subset of training samples. </li>
<li><strong class="bold">RMSprop</strong> improves SGD by introducing variable learning rates. The learning rate, as we discussed in <a href="B18333_04.xhtml#_idTextAnchor094"><em class="italic">Chapter 4</em></a>, impacts model performances—larger learning rates can <a id="_idIndexMarker331"/>reduce training time but may lead to model oscillation and may miss the optimal model parameter values. Lower learning rates can make the training process longer. In SGD, the learning rate is fixed. RMSprop adapts the learning rate as training progresses, and thus it allows you to start with big learning rates when the model has a high cost function, but it gradually reduces the learning rate when the cost function decreases.</li>
<li><strong class="bold">Adam</strong> stands for <strong class="bold">Adaptive Moment Estimation</strong> and is one of the most widely used <a id="_idIndexMarker332"/>optimizers. Adam adds momentum to the adaptive learning rate from RMSprop, and thus it allows changes to the model to accelerate while moving in the same direction during training, making the model training process quicker and better.</li>
</ul>
<p>Choosing the right <a id="_idIndexMarker333"/>cost function and optimizer algorithms is very important for model performance and training speed. Google’s TensorFlow framework <a id="_idIndexMarker334"/>provides many optimizer algorithms. For further details, please refer to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers</a>.</p>
<p>Other important features for neural networks are non-linearity and output normalization, which are provided by the activation functions. We will examine them in the following section.</p>
<h1 id="_idParaDest-121"><a id="_idTextAnchor121"/>The activation functions</h1>
<p>As you can see from the preceding section, the activation function is part of the training process. The purpose <a id="_idIndexMarker335"/>of the activation function is to transform the weighted-sum input to the nodes: non-linearize and change the output range. There are many activation functions in neural networks. We will discuss some of the most used ones: the sigmoid function, the tanh activation function, the ReLu function, and the LeakyReLU function. <em class="italic">Figure 5.4</em> shows the curves of these functions:</p>
<div>
<div class="IMG---Figure" id="_idContainer056">
<img alt="Figure 5.4 – Activation functions " height="452" src="image/Figure_5.4.jpg" width="625"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Activation functions</p>
<p>Let’s inspect each of the preceding activation functions as follows:</p>
<ul>
<li>The sigmoid activation function was discussed earlier ithe T<em class="italic">he cost function</em> section. We use <a id="_idIndexMarker336"/>the sigmoid <a id="_idIndexMarker337"/>function to change continuous values to a range between 0 and 1, which fits the models to predict the probability as an output. </li>
<li>The tanh activation function is <a id="_idIndexMarker338"/>very similar to sigmoid, but the output is from -1 to +1 and thus it is preferred <a id="_idIndexMarker339"/>to sigmoid due to the output being zero-centered. </li>
<li>The ReLU activation function stands for Rectified Linear Unit. It is widely used since it <a id="_idIndexMarker340"/>converts the negative <a id="_idIndexMarker341"/>values to 0 and keeps the positive values as such. Its range is between 0 and infinity. Because the gradient value is 0 in the negative area, the weights and biases for some neurons may not be updated during the training process, causing dead neurons that never get activated.</li>
<li>The LeakyReLU is an improved version of the ReLU function to solve the dying ReLU problem <a id="_idIndexMarker342"/>as it has a small <a id="_idIndexMarker343"/>positive slope in the negative area. The advantages of LeakyReLU are the same as that of the ReLU, in addition to the fact that it enables training even for negative input values. </li>
</ul>
<p>Another activation function is the <em class="italic">softmax</em> function, which is often used in the output layer for multi-class <a id="_idIndexMarker344"/>classifications. The softmax activation function <a id="_idIndexMarker345"/>converts the output layer values into probabilities summing up to 1 and thus outputs probabilities for each class in multi-class classification problems.</p>
<p>Among all of these activation functions, which shall we choose? The answer depends on factors such as the type of predictions, the architecture of the network, the number of layers, the current <a id="_idIndexMarker346"/>layer in the network, and so on. For example, sigmoid is more used for binary classification use cases, whereas softmax is often applied for multi-classifications, and regression problems may or may not use activation functions. While there will be trial and error involved at the beginning, experience will build up good practices. </p>
<p>Now that we have introduced the concepts of neural networks and activation functions, let’s examine some neural networks that are commonly used in computer vision, <strong class="bold">Natural Language Processing</strong> (<strong class="bold">NLP</strong>), and other areas.</p>
<h1 id="_idParaDest-122"><a id="_idTextAnchor122"/>Convolutional Neural Networks </h1>
<p>Now that we have learned about neural networks and DL, let’s look at some business use cases.</p>
<p>The first case is image <a id="_idIndexMarker347"/>recognition. How can we teach a computer to recognize an image? It is an easy task for a human being but a very difficult one for a computer. The first thing we need to do, since computers are only good at working with 1s and 0s, is to transform the image into a numerical matrix using pixels. As an example, <em class="italic">Figure 5.5</em> shows a black and white image for a single digit number, <em class="italic">8</em>, represented by a 28x28 pixel matrix. While human beings can easily recognize the image as a number <em class="italic">8</em> by some <em class="italic">magic sensors</em> in our eyes, a computer needs to input all of the 28x28=784 pixels, each having a <strong class="bold">pixel value—a</strong> single number representing the brightness of the pixel. The pixel value has possible values from 0 to 255, with 0 as black and 255 as <a id="_idIndexMarker348"/>white. Values in between make up the different shades of gray. If we have a <a id="_idIndexMarker349"/>color image, the pixel will have three numerical RGB values (red, green, and blue) to represent its color instead of one black value.</p>
<div>
<div class="IMG---Figure" id="_idContainer057">
<img alt="Figure 5.5 – Representing the number 8 with pixel values " height="498" src="image/Figure_5.5.jpg" width="719"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Representing the number 8 with pixel values</p>
<p>After we have a pixel matrix representation of the image, we can start developing a <strong class="bold">Multi-Layer Perceptron</strong> (<strong class="bold">MLP</strong>) network for training. We will construct the input layer with 784 nodes and <a id="_idIndexMarker350"/>input 784 pixel values, one for each. Each node from the input layer will then output to each node in the next layer (a hidden layer), and so on. When the number of layers increases, the total number of calculations will be huge for the entire network. To decrease the total calculations, the idea of feature filtering comes into play and leads to the concept of a <strong class="bold">CNN</strong>.</p>
<p>CNNs are widely used in computer vision, especially in image recognition and processing. A CNN consists <a id="_idIndexMarker351"/>of three layers: the convolutional layer, the pooling layer, and the fully connected layer. The convolutional layer convolutes the inputs and filters the image features, the pooling layer compresses <a id="_idIndexMarker352"/>the filtered features, and the fully connected layer, which is basically an MLP, does the model training. Let’s examine each of these layers in detail.</p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor123"/>The convolutional layer</h2>
<p>A <strong class="bold">convolutional layer</strong> performs <a id="_idIndexMarker353"/>convolution, which is applied to the input data to filter the information and <a id="_idIndexMarker354"/>produce a feature map. The filter is used as a sliding window to scan the entire image and autonomously recognize features in the images. As shown in <em class="italic">Figure 5.6</em>, a 3x3 filter, which <a id="_idIndexMarker355"/><a id="_idIndexMarker356"/>is also called the <strong class="bold">Kernel</strong> (<strong class="bold">K</strong>), scans the whole <strong class="bold">Image</strong> (<strong class="bold">I</strong>) and generates a feature map, denoted as <em class="italic">I*K</em> since its element comes from the product of <em class="italic">I</em> and <em class="italic">K</em> (in the example of <em class="italic">Figure 5.6</em>: <em class="italic">1x1+0x0+1x0+0x1+1x1+0x0+1x1+0x1+1x1=4</em>).</p>
<div>
<div class="IMG---Figure" id="_idContainer058">
<img alt=" Figure 5.6 – The convolution operation " height="353" src="image/Figure_5.6.jpg" width="750"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 5.6 – The convolution operation</p>
<p>Going through the convolution process extracts the image features and generates a feature map that still has a large amount of data and makes it hard to train the neural network. To compress the data, we go through the pooling layer.</p>
<h2 id="_idParaDest-124"><a id="_idTextAnchor124"/>The pooling layer</h2>
<p>A <strong class="bold">pooling layer</strong> receives the <a id="_idIndexMarker357"/>results from a convolutional layer, the feature map, and <a id="_idIndexMarker358"/>compresses it using a filter. Depending on the function used for calculation, it can either be maximum pooling or average pooling. As shown in <em class="italic">Figure 5.7</em>, a 2x2 filter patch scans the feature map and compresses it. With max pooling, it takes the maximum <a id="_idIndexMarker359"/>value from the scanning windows, <em class="italic">max(15,8,20,9) = 20</em>, and so on. With <a id="_idIndexMarker360"/>average pooling, it takes the average value, <em class="italic">average(15,8,20,9) = 13</em>. As you can see, the filter of a pooling layer is always smaller than a feature map.</p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<img alt="Figure 5.7 – The pooling layer " height="284" src="image/Figure_5.7.jpg" width="606"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7 – The pooling layer</p>
<p>From the input image, the process of convolution and pooling iterates, and the final result is input to a fully connected layer (MLP) to process.</p>
<h2 id="_idParaDest-125"><a id="_idTextAnchor125"/>The fully connected layer</h2>
<p>After the convolution <a id="_idIndexMarker361"/>and pooling <a id="_idIndexMarker362"/>layers, we need to flatten the result and pass it to an MLP, a fully connected neural network, for classification. The final result will then be activated with the softmax activation function to yield the final output – an understanding of the image. </p>
<h1 id="_idParaDest-126"><a id="_idTextAnchor126"/>Recurrent Neural Networks</h1>
<p>The second type of neural network is an RNN. RNNs are widely <a id="_idIndexMarker363"/>used in time series analysis, such as NLP. The concept of an RNN came about in the 1980s, but it’s not until recently that it gained its momentum in DL.</p>
<p>As we can see, in traditional feedforward neural networks such as CNNs, a node in the neural network only counts the current input and does not memorize the precious inputs. Therefore, it cannot handle time series data, which needs the previous inputs. For example, to predict the next word of a sentence, the previous words will be required to do the inference. By introducing a hidden state, which remembers some information about the sequence, RNNs solved this issue. </p>
<p>Different from feedforward networks, RNNs are a type of neural network where the output from the <a id="_idIndexMarker364"/>previous step is fed as the input to the current step; using a loop structure to keep the information allows the neural network to take the sequence of input. As shown in <em class="italic">Figure 5.8</em>, a loop for node <em class="italic">A</em> is unfolded to explain its process; first, node <em class="italic">A</em> takes <em class="italic">X</em><span class="subscript">0</span> from the sequence of input, and then it outputs <em class="italic">h</em><span class="subscript">0</span>, which, together with <em class="italic">X</em><span class="subscript">1</span>, is the input for the next step. Similarly, <em class="italic">h</em><span class="subscript">1</span> and <em class="italic">X</em><span class="subscript">2</span> are inputs for the next step, and so on and so forth. Using the loop, the network keeps remembering the context while training:</p>
<div>
<div class="IMG---Figure" id="_idContainer060">
<img alt="Figure 5.8 – The RNN unrolled loop (source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/) " height="151" src="image/Figure_5.8.jpg" width="542"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8 – The RNN unrolled loop (source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/)</p>
<p>The drawback for a simple <a id="_idIndexMarker365"/>RNN model is the vanishing gradient problem, which is caused by the fact that the same weights are used to calculate a node’s output at each time step during training and also done during backpropagation. When we move backward further, the error signal becomes bigger or smaller, thus causing difficulty in memorizing the contexts that are further away in <a id="_idIndexMarker366"/>the sequence. To overcome this drawback, the <strong class="bold">LSTM</strong> neural network was developed.</p>
<h1 id="_idParaDest-127"><a id="_idTextAnchor127"/>Long Short-Term Memory Networks</h1>
<p>An LSTM network <a id="_idIndexMarker367"/>was designed to overcome the vanishing gradient problem. LSTMs have feedback connections, and the key to LSTMs is the cell state—a horizontal line running through the entire chain with only minor linear interactions, which persists the context information. LSTM adds or removes information to the cell state by gates, which are composed of activation functions, such as sigmoid or tanh, and a pointwise multiplication operation. </p>
<div>
<div class="IMG---Figure" id="_idContainer061">
<img alt="Figure 5.9 – An LSTM model (source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/) " height="266" src="image/Figure_5.9.jpg" width="725"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.9 – An LSTM model (source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/)</p>
<p><em class="italic">Figure 5.9</em> shows an LSTM that has the gates to protect and control the cell state. Using the cell state, LSTM solves the issue of vanishing gradients and thus is particularly good at processing time series sequences of data, such as text and speech inference. </p>
<h1 id="_idParaDest-128"><a id="_idTextAnchor128"/>Generative Adversarial networks</h1>
<p><strong class="bold">GANs</strong> are algorithmic architectures that are used to generate <a id="_idIndexMarker368"/>new synthetic instances of data that can pass for real data. As shown in <em class="italic">Figure 5.10</em>, GAN is a generative model that trains the following two models simultaneously: </p>
<ul>
<li>A <strong class="bold">Generative</strong> (<strong class="bold">G</strong>) model that captures the data distribution to generate plausible data. The latent <a id="_idIndexMarker369"/>space input and random noise can be sampled and fed into the generator network to generate samples that become the negative training examples for the discriminator.</li>
<li>A <strong class="bold">Discriminative</strong> (<strong class="bold">D</strong>) model that compares the generated image with a real image and tries <a id="_idIndexMarker370"/>to identify whether the given image is fake or real. It estimates the probability that a sample came from the training data rather than the real data to distinguish the generator’s fake data from real data. The discriminator penalizes the generator <a id="_idTextAnchor129"/>for producing implausible results. </li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer062">
<img alt="Figure 5.10 – The GAN (source: https://developers.google.com/machine-learning/recommendation) " height="897" src="image/Figure_5.10.jpg" width="1316"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.10 – The GAN (source: https://developers.google.com/machine-learning/recommendation)</p>
<p>The model training <a id="_idIndexMarker371"/>starts with the generator generating fake data and the discriminator learns to tell that it’s false by comparing it with real samples. The GAN then sends the results to the generator and the discriminator to update the model. This fine tuning training process iterates and finally produces some extremely real-looking data. GANs can be used to generate text, images, <a id="_idIndexMarker372"/>and video, and color or denoise images. </p>
<h1 id="_idParaDest-129"><a id="_idTextAnchor130"/>Summary</h1>
<p>Neural networks and DL have added the modern color to the traditional ML spectrum. In this chapter, we started by learning the concepts of neural networks and DL by examining the cost functions, optimizer algorithms, and activation functions. Then, we introduced advanced neural networks, including CNN, RNN, LSTM, and GAN. As we can see, by introducing neural networks, DL extended ML concepts and made a breakthrough in many applications such as computer vision, NLP, and others. </p>
<p>This chapter concludes part two of the book: <em class="italic">Machine Learning and Deep Learning</em>. In part three, we will focus on <em class="italic">Machine Learning the Google Way</em>, where we will talk about how Google does ML and DL in Google Cloud. We will start part three with learning about BQML, Google TensorFlow, and Keras in the following chapter.</p>
<h1 id="_idParaDest-130"><a id="_idTextAnchor131"/>Further reading</h1>
<p>For further insights on the topics learned in this chapter, you can refer to the following links:</p>
<ul>
<li><a href="https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/anatomy">https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/anatomy</a></li>
<li><a href="https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks">https://www.ibm.com/cloud/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks</a></li>
<li><a href="https://aws.amazon.com/what-is/neural-network/">https://aws.amazon.com/what-is/neural-network/</a></li>
<li><a href="https://developers.google.com/machine-learning/gan">https://developers.google.com/machine-learning/gan</a></li>
</ul>
</div>
<div>
<div id="_idContainer064">
</div>
</div>
</div>


<div id="sbo-rt-content"><div class="Content" id="_idContainer065">
<h1 id="_idParaDest-131"><a id="_idTextAnchor132"/>Part 3: Mastering ML in GCP</h1>
<p>In this part, we learn how Google does ML in the Google Cloud Platform. First, we discover Google’s BigQuery ML for structured data, and then we look at Google’s ML frameworks, TensorFlow and Keras. We examine Google’s end-to-end ML suite, Vertex AI, and the ML services it provides. We then look at the Google pre-trained model APIs for ML development: GCP ML APIs. We end this part with a summary of the ML implementation best practices in Google Cloud.</p>
<p>This part comprises the following chapters:</p>
<ul>
<li><a href="B18333_06.xhtml#_idTextAnchor133"><em class="italic">Chapter 6</em></a>, Learning BQML, TensorFlow, and Keras </li>
<li><a href="B18333_07.xhtml#_idTextAnchor143"><em class="italic">Chapter 7</em></a>, Exploring Google Cloud Vertex AI </li>
<li><a href="B18333_08.xhtml#_idTextAnchor159"><em class="italic">Chapter 8</em></a>, Discovering Google Cloud ML API </li>
<li><a href="B18333_09.xhtml#_idTextAnchor168"><em class="italic">Chapter 9</em></a>, Using Google Cloud ML Best Practices</li>
</ul>
</div>
</div>
</body></html>