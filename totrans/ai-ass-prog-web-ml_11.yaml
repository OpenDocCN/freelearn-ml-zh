- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data Exploration with ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data exploration is an integral first step in machine learning, entailing a
    thorough examination of a dataset to identify its structure and uncover initial
    patterns and anomalies. This process is critical for setting the stage for any
    further detailed statistical analysis and the development of machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, the focus is on delineating the process of data exploration,
    aiming to solidify the understanding for newcomers to machine learning while providing
    a refresher for the adept. The chapter will navigate through the techniques to
    load and inspect a dataset comprised of Amazon book reviews, summarize its characteristics,
    and probe into its variables.
  prefs: []
  type: TYPE_NORMAL
- en: You will be guided through practical exercises on categorical data evaluation,
    distribution visualization, and correlation analysis, with the support of Python’s
    pandas and `Matplotlib` libraries. The chapter will also detail how to employ
    ChatGPT effectively for data exploration, including both the freely available
    version and the subscription-based plus version, which offers enhanced functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that the responses from ChatGPT will depend on how effectively
    you communicate your needs through prompts. This variability is a part of the
    learning curve and illustrates the interactive nature of working with AI in data
    exploration. Our goal is to equip you with the knowledge to navigate these tools
    confidently and to begin making data-driven decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Business problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In e-commerce, effectively analyzing customer feedback is crucial for identifying
    key factors that influence purchasing decisions. This analysis supports targeted
    marketing strategies and helps optimize both the user experience and website design,
    ultimately enhancing service and product offerings to customers.
  prefs: []
  type: TYPE_NORMAL
- en: Problem and data domain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will focus exclusively on detailed data exploration using
    the Amazon product review dataset. Our goal is to deeply explore this dataset
    to unearth insights and discern patterns that can enhance decision-making. We’ll
    leverage ChatGPT to generate Python code for data manipulation and visualization,
    providing a hands-on approach to understanding complex data analysis techniques.
    Additionally, we will explore methods to effectively prompt ChatGPT to deliver
    tailored insights and code snippets that aid in our exploration tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will work with the Amazon product review dataset, which includes a broad
    range of information reflecting consumer feedback and product evaluations. Key
    features of this dataset encompass identifiers such as marketplace, customer,
    review, and product details, as well as product titles, categories, ratings, and
    the textual content of reviews. For this exploration, we’ll concentrate on the
    `review_body` and `review_headline` fields, which provide rich textual data for
    analysis. To streamline our focus and enhance clarity in our findings, we will
    omit neutral sentiments and focus solely on analyzing positive and negative feedback.
  prefs: []
  type: TYPE_NORMAL
- en: 'Features in the dataset include:'
  prefs: []
  type: TYPE_NORMAL
- en: '`marketplace` (`string`): The location of the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`customer_id` (`string`): A unique identifier for customers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_id` (`string`): A unique identifier for reviews.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_id` (`string`): A unique identifier for products.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_parent` (`string`): A parent product identifier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_title` (`string`): The title of the reviewed product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_category` (`string`): The category of the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`star_rating` (`int`): The rating of the product on a scale of 1 to 5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`helpful_votes` (`int`): The number of helpful votes received for the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`total_votes` (`int`): The total number of votes received for the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_headline` (`string`): The headline of the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_body` (`string`): The content of the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_date` (`string`): The date of the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sentiments` (`string`): The sentiment of the review (positive or negative).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This targeted exploration will allow us to perform in-depth sentiment analysis,
    evaluate the impact of product ratings, and delve into customer feedback dynamics.
    By focusing on these elements, we aim to fully leverage the dataset to improve
    strategic decision-making in e-commerce environments.
  prefs: []
  type: TYPE_NORMAL
- en: Feature breakdown
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the Amazon product review dataset and a focus on detailed data exploration,
    we will outline the following features to guide users through understanding and
    analyzing customer feedback effectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Loading the Dataset**: We’ll start by importing the dataset into a pandas
    DataFrame. This is a powerful data manipulation structure in Python that facilitates
    convenient data handling.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Inspecting the Data**: Our initial exploration will involve displaying the
    first few entries of the DataFrame to get a feel for the data. We’ll review the
    column names, understand the types of data that each column contains, and check
    for any missing values that need to be addressed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Summary Statistics**: To grasp the numerical data’s distribution, we’ll compute
    summary statistics, including mean, median, minimum, and maximum values and quartiles.
    This step helps in understanding the central tendency and spread of the numerical
    data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Exploring Categorical Variables**: For categorical data such as marketplace,
    product category, and sentiment, we’ll examine the different categories and count
    the number of entries for each. Visual aids like bar charts will be particularly
    useful here to illustrate the frequency of each category.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Distribution of Ratings**: We will visualize the distribution of star ratings
    using histograms or bar charts. This visual representation helps in understanding
    the general opinion of the reviewers and how ratings are skewed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Temporal Analysis**: By analyzing the `review_date` column, we’ll explore
    any trends, seasonality, or other temporal patterns in the data. This analysis
    can reveal insights into how sentiments or product popularity change over time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Review Length Analysis**: We’ll examine the `review_body` to understand the
    amount of information provided in the reviews by calculating descriptive statistics
    for review length, such as mean, median, and maximum lengths. This step provides
    insights into the depth of feedback that customers provide.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Correlation Analysis**: Lastly, we will investigate the correlation between
    numeric variables like star ratings, helpful votes, and total votes, using correlation
    matrices or scatter plots. This analysis helps in identifying potential relationships
    between different quantitative aspects of the data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By systematically breaking down these features, we will thoroughly understand
    the dataset, uncovering insights that can enhance decision-making and strategy
    formulation in e-commerce contexts.
  prefs: []
  type: TYPE_NORMAL
- en: Prompting strategy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To utilize ChatGPT effectively for data exploration of the Amazon product review
    dataset, we need to establish clear prompting strategies tailored to generate
    Python code and data insights. Here’s how we can approach this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Strategy 1: Task-Actions-Guidelines (TAG) prompt strategy'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**1.1 – Task**: The specific goal is to explore the Amazon product review dataset
    thoroughly using various statistical and visualization techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: '**1.2 – Actions**: The key steps in exploring this dataset include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Loading**: Load the dataset into a pandas DataFrame.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Inspection**: Check for missing data, understand data types, and inspect
    the first few entries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Statistical Summaries**: Calculate summary statistics for numerical data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Categorical Analysis**: Analyze categorical variables using counts and visualizations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rating Distribution**: Create histograms or bar charts to visualize the distribution
    of star ratings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Temporal Trends**: Examine trends over time from the review dates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Review Text Analysis**: Analyze the length and sentiment of review texts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Correlation Study**: Assess correlations between numerical variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**1.3 – Guidelines**: We will provide the following guidelines to ChatGPT in
    our prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: Code should be compatible with a Jupyter Notebook
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that there are detailed comments for each line of code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have to explain each line of code in detail, covering each method used in
    the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Strategy 2: Persona-Instructions-Context (PIC) prompt strategy'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**2.1 – Persona**: Assume the persona of a data analyst seeking to uncover
    actionable insights from the Amazon product review dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '**2.2 – Instructions**: Request ChatGPT to generate code for each specific
    analysis, proceeding sequentially and waiting for user validation before moving
    to the next task.'
  prefs: []
  type: TYPE_NORMAL
- en: '**2.3 – Context**: Given that the focus is on sentiment analysis using the
    Amazon product review dataset, ChatGPT is not aware of the dataset and its characteristics,
    so additional context will be necessary.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Strategy 3: Learn-Improvise-Feedback-Evaluate (LIFE) prompt strategy'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**3.1 – Learn**:'
  prefs: []
  type: TYPE_NORMAL
- en: Highlight the need to understand data through various analytical techniques,
    from basic statistics to complex correlations and temporal analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3.2 – Improvise**:'
  prefs: []
  type: TYPE_NORMAL
- en: Adapt the analysis based on initial findings. For instance, if certain categories
    of products show unusual trends, deepen the analysis in these areas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3.3 – Feedback**:'
  prefs: []
  type: TYPE_NORMAL
- en: Share code and model outputs for feedback to ensure effective learning and understanding.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorporate suggestions and critiques to refine the model and the approach.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide errors to troubleshoot and resolve the issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3.4 – Evaluate**:'
  prefs: []
  type: TYPE_NORMAL
- en: Execute the code provided by ChatGPT to ensure accuracy and validity. This is
    used throughout the chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data exploration of the Amazon review dataset using the free version of ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ChatGPT premium version has a code interpreter, but first, we will use the free
    version of ChatGPT. We will craft our initial prompt carefully to include all
    the features, but we will instruct it to wait for user feedback after providing
    code for each feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature 1: Loading the dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s craft our initial prompt to load the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'I want to explore the Amazon product review dataset thoroughly using various
    statistical and visualization techniques (TAG 1.1), which consists of the following
    fields (PIC 2.3):'
  prefs: []
  type: TYPE_NORMAL
- en: '`marketplace` (`string`): The location of the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`customer_id` (`string`): A unique identifier for customers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_id` (`string`): A unique identifier for reviews.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_id` (`string`): A unique identifier for products.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_parent` (`string`): A parent product identifier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_title` (`string`): The title of the reviewed product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_category` (`string`): The category of the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`star_rating` (`int`): The rating of the product on a scale of 1 to 5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`helpful_votes` (`int`): The number of helpful votes received for the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`total_votes` (`int`): The total number of votes received for the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_headline` (`string`): The headline of the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_body` (`string`): The content of the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`review_date` (`string`): The date of the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sentiments` (`string`): The sentiment of the review (positive or negative).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This should consist of the following steps (TAG 1.2):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Loading**: Load the dataset into a pandas DataFrame.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data Inspection**: Check for missing data, understand data types, and inspect
    the first few entries.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Statistical Summaries**: Calculate summary statistics for numerical data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Categorical Analysis**: Analyze categorical variables using counts and visualizations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Rating Distribution**: Create histograms or bar charts to visualize the distribution
    of star ratings.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Temporal Trends**: Examine trends over time from the review dates.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Review Text Analysis**: Analyse the length and sentiment of review texts.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Correlation Study**: Assess correlations between numerical variables.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'I am a data analyst seeking to uncover actionable insights (PIC 2.1), so please
    provide detailed code and strictly follow the below instructions (TAG 1.3):'
  prefs: []
  type: TYPE_NORMAL
- en: Code should be compatible with a Jupyter Notebook.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that there are detailed comments for each line of code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You have to explain each line of code, which will then be copied into the text
    block of the notebook in detail for each method used in the code before it is
    provided. Also note that the dataset is placed in Google Drive at this path: `./Chapter05/amazon_product_review_data.csv`.
    So, add the code to mount the drive and load the dataset (PIC 2.2).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide one step at a time and wait for user feedback (PIC 2.2).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: You should receive a response similar to below, where ChatGPT has provided us
    with the code for Step 1 – Data Loading, along with detailed comments and explanations.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sure, let’s start with the first step: loading the dataset into a pandas DataFrame
    from Google Drive. Here’s how we can proceed:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1: Data Loading**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To load the dataset from Google Drive into a pandas DataFrame, we’ll follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mount Google Drive**: Connect to your Google Drive where the dataset is located.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load the Dataset**: Read the dataset file into a pandas DataFrame.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Detailed Code Explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mount Google Drive**: This step allows us to access files stored in Google
    Drive directly from a Google Colab or Jupyter Notebook environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the `google.colab` import drive: Import the drive module from the `google.colab`
    package.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`drive.mount` (`"/content/drive"`): Mounts your Google Drive at the specified
    path (`/content/drive` in this case). Follow the instructions to authorize and
    obtain an access code.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load the Dataset**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`import pandas as pd`: Import the pandas library as `pd` for data manipulation.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`file_path = ''/content/drive/My Drive/Chapter05/amazon_product_review_data.csv''`:
    Define the path to your CSV file in Google Drive.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`df = pd.read_csv(file_path)`: Use `pd.read_csv()` to read the CSV file into
    a DataFrame named `df`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s the complete code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'User Feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: Please execute this code in your Jupyter Notebook environment after replacing
    `file_path` with the correct path to your dataset. Let me know if you encounter
    any issues or if you’re ready to proceed to the next step!
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: We will now apply the evaluate prompting strategy (LIFE 3.4) and validate the
    code by executing the code in Google Colab for every step. The code loads the
    dataset from Google Drive. It will also request permission to access Google Drive.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the notebook “Data Exploration with ChatGPT.ipynb” for the executable
    code snippets, or copy the code from the prompt response.
  prefs: []
  type: TYPE_NORMAL
- en: You should see a message saying “Permit this Notebook to access Google Drive.”
  prefs: []
  type: TYPE_NORMAL
- en: The code runs perfectly fine without applying any modifications or any errors
    and displays the first few rows of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: You should see the content of the Notebook and customer reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature 2: Inspecting the data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now instruct ChatGPT to proceed to the next step:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s proceed to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '[**End of prompt**]'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response like below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Let’s move on to the next step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Data Inspection'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this step, we will inspect the loaded dataset to:'
  prefs: []
  type: TYPE_NORMAL
- en: Check for missing data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the data types of each column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inspect the first few entries to get a sense of the data structure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Detailed Code Explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Check for Missing Data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`df.info()`: This method provides a concise summary of the DataFrame, including
    the number of non-null entries in each column. It also shows the data types of
    each column, which helps us understand how to manipulate the data.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understand Data Types**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By examining the output of `df.info()`, we can identify if any columns have
    incorrect data types (e.g., numerical columns mistakenly stored as strings).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inspect the First Few Entries**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**df.head()**: This method displays the first few rows of the DataFrame. It
    allows us to visually inspect the columns, their values, and get an initial understanding
    of what the dataset contains.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s the code for data inspection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'User Feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: Execute this code in your Jupyter Notebook environment. After running this step,
    you should be able to see a summary of the dataset and the first few rows. Let
    me know if everything looks okay or if you have any specific questions!
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: We evaluate the output from ChatGPT and execute the code (LIFE 3.4) in the notebook,
    and it displays the information.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will utilize the prompting strategy to provide the output for ChatGPT (LIFE
    3.3) to interpret:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response like below, where ChatGPT provides an explanation
    and findings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[P**rompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'It seems like the dataset has been successfully loaded, and here’s what we
    can infer from the output of `df.info()` and `df.head()`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Inspection Findings:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Basic Information**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The dataset contains 500 entries (rows) and 15 columns.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: There are both numerical (`int64`) and categorical (`object`) data types.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All columns have 500 non-null entries, indicating there are no missing values.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Column Details**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`market_place`, `customer_id`, `review_id`, `product_id`, `product_parent`,
    `product_title`, `product_category`, `verified_purchase`, `review_headline`, `review_body`,
    `review_date`, and `sentiments` are all identified as object (string) types, which
    aligns with their expected content based on their descriptions.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`star_rating`, `helpful_votes`, and `total_votes` are correctly identified
    as `int64` (integer) types.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Initial Data Preview**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `df.head()` output shows the first few rows of the dataset, giving us a
    glimpse into the structure and content of each column. We can see examples of
    the `market_place`, `customer_id`, `star_rating`, `helpful_votes`, `total_votes`,
    `review_headline`, `review_body`, `review_date`, and `sentiments` columns.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Next Steps:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this inspection:'
  prefs: []
  type: TYPE_NORMAL
- en: The dataset appears to be clean with no missing values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have a clear understanding of the columns and their data types.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, we can proceed with Step 3: Statistical Summaries to calculate summary
    statistics for the numerical data (`star_rating`, `helpful_votes`, and `total_votes`).
    Would you like to continue with that? Let me know if there’s anything specific
    you’d like to explore further or if we should proceed to the next step!'
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature 3: Summary statistics'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As there are no missing or null values, we will now instruct ChatGPT to proceed
    to the next step to display summary statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s proceed to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response like below where ChatGPT provides the code to
    display summary statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[P**rompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Let’s move on to Step 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3: Statistical Summaries**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this step, we will calculate summary statistics for the numerical columns
    in our dataset. Specifically, we will focus on:'
  prefs: []
  type: TYPE_NORMAL
- en: '`star_rating`: Rating of the product on a scale of 1 to 5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`helpful_votes`: Number of helpful votes received for the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`total_votes`: Total number of votes received for the review.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Detailed Code Explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use of** `describe()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`df.describe()` computes summary statistics for numerical columns. It provides:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Count: Number of non-null values.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mean: Average value.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Std: Standard deviation.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Min: Minimum value.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '25%, 50%, and 75%: Percentiles.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Max: Maximum value.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Selecting Specific Columns**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We use `df[['star_rating', 'helpful_votes', 'total_votes']].describe()` to limit
    the output to only the numerical columns we are interested in (`star_rating`,
    `helpful_votes`, and `total_votes`).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s the code to calculate and display summary statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'User Feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: Execute this code in your Jupyter Notebook environment. It will provide statistical
    insights into the distribution and central tendencies of the numerical variables
    in your dataset. Let me know if you have any questions or if you’re ready to proceed
    to the next step!
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We execute the code, which shows the summary statistics, and we provide the
    output to ChatGPT for interpretation and to understand the stats:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response like below where ChatGPT provides an explanation
    of the summary statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the summary statistics for the numerical columns (`star_rating`, `helpful_votes`,
    and `total_votes`), here are the insights we can gather:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Summary Statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**star_rating**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mean**: 0.796'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard Deviation**: 0.403'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Min**: 0 (indicating the lowest rating)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**25th Percentile (Q1)**: 1'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Median (50th Percentile)**: 1'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**75th Percentile (Q3)**: 1'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Max**: 1 (indicating the highest rating)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interpretation**: The `star_rating` column primarily contains a single value
    of 1 (which typically represents positive reviews in binary sentiment data), indicating
    that most reviews are positive. This is supported by the mean being close to 1
    and a low standard deviation, suggesting little variability in ratings.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**helpful_votes**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mean**: 0.764'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard Deviation**: 2.843'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Min**: 0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**25th Percentile (Q1)**: 0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Median (50th Percentile)**: 0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**75th Percentile (Q3)**: 1'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Max**: 36'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interpretation**: The `helpful_votes` column has a mean of 0.764, indicating
    that on average, reviews receive less than one helpful vote. The standard deviation
    of 2.843 suggests variability in the number of helpful votes received, with some
    reviews receiving as many as 36 helpful votes.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**total_votes**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mean**: 1.068'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Standard Deviation**: 3.698'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Min**: 0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**25th Percentile (Q1)**: 0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Median (50th Percentile)**: 0'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**75th Percentile (Q3)**: 1'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Max**: 47'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interpretation**: The `total_votes` column has a mean of 1.068, indicating
    that on average, reviews receive slightly more than one total vote (helpful or
    unhelpful). The standard deviation of 3.698 suggests variability in the total
    number of votes received, with some reviews receiving as many as 47 votes in total.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next Steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Based on these statistics, we see that the dataset predominantly consists of
    positive reviews (a `star_rating` of 1). The `helpful_votes` and `total_votes`
    metrics show varying levels of engagement with the reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can move on to Step 4: Categorical Analysis, where we will analyze
    the categorical variables (`market_place`, `product_category`, `verified_purchase`,
    and `sentiments`) using counts and visualizations. Would you like to proceed with
    that? Let me know if you have any questions or if you’re ready for the next step!'
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature 4: Exploring categorical variables'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we will proceed to explore the categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s proceed to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response like below where ChatGPT provides the code for
    the visualization of the categorical variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Let’s proceed to Step 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4: Categorical Analysis**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this step, we will analyze the categorical variables in our dataset using
    counts and visualizations. The categorical variables we’ll focus on are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`market_place`: Location of the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`product_category`: Category of the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`verified_purchase`: Whether the purchase was verified (Y/N).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sentiments`: Sentiment of the review (positive or negative).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Detailed Code Explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Counting Unique Values**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`df[''column_name''].value_counts()`: This method counts the occurrences of
    each unique value in a categorical column.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visualizing Categorical Data**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will use bar charts (from the `matplotlib` library) to visualize the distribution
    of categorical variables.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s the code to perform categorical analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Explanation of the Visualizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Market Place**: Shows the distribution of products across different marketplaces
    (`market_place`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Product Category**: Displays the distribution of products across various
    categories (`product_category`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Verified Purchase**: Indicates how many reviews are from verified purchases
    (`verified_purchase`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sentiments**: Illustrates the distribution of review sentiments (`sentiments`),
    whether they are positive or negative.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'User Feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: Execute this code in your Jupyter Notebook environment to visualize and analyze
    the categorical variables in your dataset. This will provide insights into the
    distribution and characteristics of different aspects related to the reviews and
    products. Let me know if you have any questions or if you’re ready to move on
    to the next step!
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: We execute the code, which runs perfectly fine, and then visualize the variables.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21232_11_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: Categorical variables – visualization'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the reviews are all from a single marketplace and have equal
    number of reviews of all product categories, but there is an imbalance of positive
    and negative reviews as well as the distribution of verified purchases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature 5: Rating distribution'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will move on to the rating distribution and instruct ChatGPT to move on
    to the next step:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s proceed to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response like below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Let’s proceed to Step 5:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 5: Rating Distribution'
  prefs: []
  type: TYPE_NORMAL
- en: In this step, we will create histograms or bar charts to visualize the distribution
    of star ratings (`star_rating`). This will help us understand how ratings are
    distributed among the reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'Detailed Code Explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Histogram or Bar Chart**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will use `sns.countplot()` from the Seaborn library to create a bar chart.
    This is suitable for visualizing the count of each rating value (1 to 5).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visualization Parameters**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adjustments such as setting the figure size (`figsize`) and title (`set_title`)
    are done to enhance the clarity and readability of the plot.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s the code to visualize the rating distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Explanation of the Visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: The `sns.countplot()` function is used to create a bar chart of the `star_rating`
    column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *x*-axis represents the star ratings (1 to 5), and the *y*-axis represents
    the count of reviews with each rating.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The title, *x*-label (`Star Rating`), and *y*-label (`Count`) are added to provide
    context and clarity to the plot.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'User Feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: Execute this code in your Jupyter Notebook environment. It will display a visual
    representation of how star ratings are distributed among the reviews in your dataset.
    This step will provide insights into the overall sentiment expressed through ratings.
    Let me know if you have any questions or if you’re ready to proceed to the next
    step!
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: We will execute the code, which produces the ratings graph.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21232_11_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Ratings distribution'
  prefs: []
  type: TYPE_NORMAL
- en: Based on these results, there are majorly positive ratings. We will move on
    to the next feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature 6: Temporal trends'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s understand the temporal trends in our dataset for the review date
    column. Our dataset doesn’t have much variation, but this will help us understand
    how to use ChatGPT for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s proceed to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response like below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! Let’s move on to Step 6:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 6: Temporal Trends**'
  prefs: []
  type: TYPE_NORMAL
- en: In this step, we will examine temporal trends from the `review_date` column
    to understand how the reviews are distributed over time. This will help us identify
    any patterns or trends in the review activity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Detailed Code Explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Convert** `review_date` **to** `datetime`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that the `review_date` column is in the datetime format for proper temporal
    analysis.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Plotting Temporal Trends**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use `sns.lineplot()` or `sns.histplot()` to visualize the distribution of reviews
    over time.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on the analysis goal, you can choose to plot the count of reviews
    per month, per year, or any other relevant time interval.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s the code to analyze temporal trends:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Explanation of the Visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Datetime Conversion**: `pd.to_datetime()` function is used to convert the
    `review_date` column from a string to the datetime format, ensuring accurate temporal
    analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Histogram Plot**: `sns.histplot()` is used to create a histogram of review
    counts over time (`review_date`). This helps in visualizing the distribution and
    frequency of reviews across different dates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjustments**: Adjustments such as setting the figure size (`figsize`), title
    (`title`), *x*-label (`xlabel`), *y*-label (`ylabel`), and rotating *x*-axis ticks
    (`xticks(rotation=45)`) are made to improve the clarity and readability of the
    plot.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'User Feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: Execute this code in your Jupyter Notebook environment. It will provide insights
    into how reviews are distributed over time, allowing you to observe any trends
    or patterns in review activity. Let me know if you have any questions or if you’re
    ready to proceed to the next step!
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: We will execute the code, which produces a plot that shows the distribution
    of reviews over time.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21232_11_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: Temporal trend'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the reviews are shown only for two dates, so let’s move to the
    next feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature 7: Review length analysis'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: The reviews are shown for just two dates, 10-2013 and 08-2015\.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: We should receive a response like below where ChatGPT provides the code, explains
    the significance of the review dates, and proceeds with the next step of review
    length analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: If the reviews in your dataset are concentrated on just two dates (October 2013
    and August 2015), it suggests that the dataset may not have a wide temporal spread
    of reviews. This information is crucial for understanding the context of the data
    and its limitations in temporal analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Given this observation, we can still proceed to analyze the review text and
    sentiment in Step 7, as planned. This step will focus on examining the length
    and sentiment of the review texts, which can provide additional insights beyond
    temporal trends.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 7: Review Text Analysis**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this step, we will analyze the review text (`review_body`) to:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate the length of each review.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determine the sentiment of each review using the provided `sentiments` column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Detailed Code Explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Review Length Calculation**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a new column `review_length` to the DataFrame to store the character count
    of each review (`review_body`).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sentiment Analysis**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `sentiments` column to categorize reviews as positive or negative based
    on the provided labels.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s the code to perform review the text analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Explanation of the Code:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Review Length Calculation**: `df[''review_body''].apply(len)` computes the
    length of each review in characters and stores it in a new column `review_length`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sentiment Analysis**: `df[''sentiments''].value_counts()` counts the occurrences
    of each sentiment category (`positive` or `negative`) in the `sentiments` column.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Average Review Length**: `df[''review_length''].mean()` calculates the average
    length of reviews in the dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'User Feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: Execute this code in your Jupyter Notebook environment. It will provide insights
    into the length and sentiment distribution of the review texts in your dataset.
    Let me know if you have any questions or if you’re ready to proceed to the next
    step after reviewing the outputs!
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We execute the code in Jupyter Colab, which works fine, so we provide the output
    to ChatGPT to interpret it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response from ChatGPT explaining the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'It seems like the sentiment analysis and review length calculations have been
    successfully performed. Here are the insights from the analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sentiment Analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sentiment Counts**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Positive reviews: 398'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Negative reviews: 102'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Review Length Analysis:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Average Review Length**: 243.75 characters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sentiment Counts**: The dataset contains predominantly positive reviews,
    with 398 positive reviews and 102 negative reviews.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Average Review Length**: The average length of a review in the dataset is
    approximately 243.75 characters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example Data Inspection:'
  prefs: []
  type: TYPE_NORMAL
- en: The example snippet you provided shows a sample of the dataset, where we can
    see details such as marketplace, customer ID, review ID, product details, star
    rating, review text, review date, sentiment, and review length for the first few
    entries.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next Steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Based on this analysis, we have insights into the distribution of sentiments
    and the average length of reviews. If there are specific further analyses or visualizations
    you’d like to explore, such as a correlation study or any other aspect of the
    dataset, please let me know! We can proceed accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Feature 8: Correlation study'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will move on to the last feature, which is a correlation study.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s proceed to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response like below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Certainly! Let’s proceed to Step 8:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 8: Correlation Study**'
  prefs: []
  type: TYPE_NORMAL
- en: In this step, we will assess the correlations between numerical variables in
    the dataset. Specifically, we will examine how `star_rating`, `helpful_votes`,
    and `total_votes` correlate with each other. This analysis will help us understand
    any relationships or dependencies between these variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Detailed Code Explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Correlation Calculation**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `.corr()` method on the DataFrame to compute the correlation coefficients
    between numerical columns.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visualization of Correlation**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can visualize the correlations using a heatmap to provide a clear and intuitive
    representation of the relationships.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s the code to perform the correlation study:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Explanation of the Code:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Correlation Matrix**: `df[[''star_rating'', ''helpful_votes'', ''total_votes'']].corr()`
    computes the correlation coefficients between `star_rating`, `helpful_votes`,
    and `total_votes`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heatmap Visualization**: `sns.heatmap()` from the Seaborn library is used
    to create a heatmap of the correlation matrix. The `annot=True` parameter adds
    numeric annotations to the heatmap cells for clarity. The `cmap=''coolwarm''`
    parameter sets the color scheme for the heatmap, where colors range from blue
    (negative correlation) to red (positive correlation).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Interpretation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The heatmap will display correlations ranging from -1 to 1, where:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Values closer to 1 indicate a strong positive correlation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Values closer to -1 indicate a strong negative correlation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Values close to 0 indicate no significant correlation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'User Feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: Execute this code in your Jupyter Notebook environment. It will provide insights
    into how `star_rating`, `helpful_votes`, and `total_votes` are related within
    your dataset. Let me know if you have any questions or if you’re ready to proceed
    to the next step after reviewing the correlation heatmap!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: We will execute the code, which plots the correlation matrix and prints the
    results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21232_11_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Correlation matrix'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that helpful votes and total votes are strongly correlated but the
    rating is not.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes data exploration with ChatGPT-3.5; now, let’s see how to use
    ChatGPT-4o.
  prefs: []
  type: TYPE_NORMAL
- en: Data exploration of the Amazon review dataset using ChatGPT-4o
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ChatGPT’s premium version has a code interpreter, which is accessible using
    both ChatGPT-4o and ChatGPT 4\. For this section, we will use GPT-4o, and this
    time, we will get the code in a single step.
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT has access to several models, at present, you can use GPT-3.5, GPT-4,
    and GPT-4o.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s craft our prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'I want to explore the Amazon product review dataset thoroughly using various
    statistical and visualization techniques (TAG 1.1) for the attached dataset (PIC
    2.3). It should consist of the following steps (TAG 1.2):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Loading**: Load the dataset into a pandas DataFrame.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data Inspection**: Check for missing data, understand data types, and inspect
    the first few entries.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Statistical Summaries**: Calculate the summary statistics for numerical data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Categorical Analysis**: Analyze categorical variables using counts and visualizations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Rating Distribution**: Create histograms or bar charts to visualize the distribution
    of star ratings.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Temporal Trends**: Examine trends over time from the review dates.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Review Text Analysis**: Analyze the length and sentiment of review texts.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Correlation Study**: Assess correlations between numerical variables'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I am a data analyst seeking to uncover actionable insights (PIC 2.1), so please
    provide detailed code.
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of prompt]**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We should receive a response similar to below where ChatGPT performs all the
    necessary steps, performs a data exploration, and produces the relevant charts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Prompt response]**'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Product Review Dataset Analysis
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll follow the steps you outlined to explore the dataset thoroughly. Let’s
    proceed step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Data Loading'
  prefs: []
  type: TYPE_NORMAL
- en: We have loaded the dataset into a pandas DataFrame.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 2: Data Inspection'
  prefs: []
  type: TYPE_NORMAL
- en: 'We checked for missing data, understood data types, and inspected the first
    few entries. The dataset consists of 500 entries and 15 columns with no missing
    data. Here are the first few entries:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Step 3: Statistical Summaries'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s calculate summary statistics for the numerical data. You should see a
    summary of your data, including stats on the mean, standard deviation, and more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 4: Categorical Analysis'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll analyze the categorical variables using counts and visualizations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 5: Rating Distribution'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll create histograms or bar charts to visualize the distribution of star
    ratings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 6: Temporal Trends'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll examine trends over time from the review dates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 7: Review Text Analysis'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll analyze the length and sentiment of review texts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 8: Correlation Study'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll assess correlations between numerical variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start implementing each of these steps in Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Detailed Analysis of the Amazon Product Review Dataset
  prefs: []
  type: TYPE_NORMAL
- en: We have performed a detailed analysis as outlined. Below are the key findings
    and visualizations for each step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Statistical Summaries'
  prefs: []
  type: TYPE_NORMAL
- en: 'We calculated summary statistics for the numerical data. Here are some key
    statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Star Rating:** Mean = 0.796, Standard Deviation = 0.403, Min = 0, and Max
    = 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Helpful Votes:** Mean = 0.764, Standard Deviation = 2.843, Min = 0, and Max
    = 36'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Total Votes:** Mean = 1.068, Standard Deviation = 3.698, Min = 0, and Max
    = 47'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 4: Categorical Analysis'
  prefs: []
  type: TYPE_NORMAL
- en: 'The top categories by review count are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Grocery**: 100 reviews'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Digital_Ebook_Purchase**: 100 reviews'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Jewelry**: 100 reviews'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PC**: 100 reviews'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Books**: 100 reviews'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 5: Rating Distribution'
  prefs: []
  type: TYPE_NORMAL
- en: 'We visualized the distribution of the star ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated](img/B21232_11_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.5: Distribution of the star ratings'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 6: Temporal Trends'
  prefs: []
  type: TYPE_NORMAL
- en: 'We examined the number of reviews per month:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph with a line  Description automatically generated](img/B21232_11_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.6: Number of reviews per month'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 7: Review Text Analysis'
  prefs: []
  type: TYPE_NORMAL
- en: 'We analyzed the length and sentiment of the review texts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Distribution of the Review Lengths:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![A graph with numbers and lines  Description automatically generated](img/B21232_11_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.7: Distribution of the review lengths'
  prefs: []
  type: TYPE_NORMAL
- en: '**Distribution of the Sentiments:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![A yellow and orange rectangles  Description automatically generated](img/B21232_11_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.8: Distribution of the sentiments'
  prefs: []
  type: TYPE_NORMAL
- en: '**Positive Reviews**: 398'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Negative Reviews**: 102'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Step 8: Correlation Study'
  prefs: []
  type: TYPE_NORMAL
- en: 'We assessed the correlations between the numerical variables and visualized
    the correlation matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a graph  Description automatically generated](img/B21232_11_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.9: Correlation matrix'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs: []
  type: TYPE_NORMAL
- en: This analysis provided valuable insights into the dataset, including the distribution
    of star ratings, trends over time, and the sentiment of reviews. We also explored
    correlations between numerical variables. These insights can help in understanding
    customer feedback and improving product offerings.
  prefs: []
  type: TYPE_NORMAL
- en: If you need any further analysis or have specific questions, feel free to ask!
  prefs: []
  type: TYPE_NORMAL
- en: '**[End of response]**'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, GPT-4o has successfully performed data exploration by just uploading
    the CSV and providing the steps or actions to perform.
  prefs: []
  type: TYPE_NORMAL
- en: Assignment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Investigate how different products or categories perform in terms of ratings,
    helpful votes, and review length.
  prefs: []
  type: TYPE_NORMAL
- en: Challenge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Use natural language processing (NLP) techniques to analyze the content of the
    reviews. Extract common themes, keywords, and phrases that are frequently mentioned.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we delved into comprehensive data analysis using Python and
    pandas, leveraging the Amazon product review dataset. The journey began with data
    loading and inspection, ensuring the dataset was properly formatted and free of
    missing values. You were guided through each step with detailed explanations and
    code samples suitable for Jupyter Notebooks aimed at empowering data analysts
    to uncover actionable insights effectively.
  prefs: []
  type: TYPE_NORMAL
- en: We started by calculating statistical summaries for numerical data, revealing
    that the dataset predominantly consisted of positive reviews. Categorical analysis
    followed, where we explored distributions across different marketplaces, product
    categories, verified purchases, and sentiments. Visualizations, including histograms
    and bar charts, provided clear representations of star rating distributions, emphasizing
    the predominance of positive feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Temporal trends analysis uncovered a concentrated spread of reviews, primarily
    in October 2013 and August 2015, offering insights into review activity over time.
    We then conducted review text analysis, calculating review lengths and assessing
    sentiment counts to understand the dataset’s content more deeply. Finally, a correlation
    study examined relationships between star ratings and review engagement metrics,
    like helpful and total votes, offering insights into how these factors interact
    within the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn how to use ChatGPT to build a classification
    model using the same dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/aicode](https://packt.link/aicode)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code510410532445718281.png)'
  prefs: []
  type: TYPE_IMG
