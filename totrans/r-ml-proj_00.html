<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Preface</h1>
                </header>
            
            <article>
                
<p class="mce-root">R is one of the most popular languages when it comes to performing computational statistics (statistical computing) easily and exploring the mathematical side of machine learning. With this book, you will leverage the R ecosystem to build efficient machine learning applications that carry out intelligent tasks within your organization.</p>
<p class="mce-root">This book will help you test your knowledge and skills, guiding you on how to build easy through to complex machine learning projects. You will first learn how to build powerful machine learning models with ensembles to predict employee attrition. Next, you’ll implement a joke recommendation engine to perform sentiment analysis on Amazon reviews. You’ll also explore different clustering techniques to segment customers using wholesale data. In addition to this, the book will get you acquainted with credit card fraud detection using autoencoders, and reinforcement learning to make predictions and win on a casino slot machine.</p>
<p class="mce-root">By the end of the book, you will be equipped to confidently perform complex tasks to build research and commercial projects for automated operations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Who this book is for</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span class="calibre4">This book is for data analysts, data scientists, and ML developers who wish to master the concepts of ML using R by building real-world projects. Each project will help you test your expertise to implement the working mechanisms of ML algorithms and techniques. A basic understanding of ML and a working knowledge of R programming is a must.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What this book covers</h1>
                </header>
            
            <article>
                
<p class="mce-root"><a href="d8e2df34-05df-451e-88ce-62fdf17184d4.xhtml" class="calibre8">Chapter 1</a>, <em class="calibre15">Exploring the Machine Learning Landscape</em><span class="calibre4">, </span><span class="calibre4">will briefly review the various ML concepts that a practitioner must know. In this chapter, we will cover topics such as supervised learning, reinforcement learning, unsupervised learning, and real-world ML uses cases.</span></p>
<p class="mce-root"><a href="664c4f7e-187f-4fa0-b796-af7db785bb08.xhtml" class="calibre8">Chapter 2</a>, <em class="calibre15">Predicting Employee Attrition Using Ensemble Models</em><span class="calibre4">, covers the </span><span class="calibre4">creation of powerful ML models through ensemble learning. </span><span class="calibre4">The project covered in this chapter is from the human resources domain. Retention of talented employees is a key challenge faced by corporations. If we were able to predict the attrition of an employee well in advance, it is possible that the human resources or management team could do something to save the potential attrition from becoming real. It just so happens that it is possible to predict employee attrition through the application of ML. This chapter makes use of an IBM-curated public dataset that provides a pseudo employee attrition population and characteristics.</span> <span class="calibre4">We start the chapter with an introduction to the problem at hand and then attempt to explore the dataset with <strong class="calibre3">exploratory data analysis</strong> (<strong class="calibre3">EDA</strong>). The next step is the preprocessing phase, which includes the creation of new features using prior domain experience. Once the dataset is fully prepared, models will be created using multiple ensemble techniques, such as bagging, boosting , stacking, and randomization. Lastly, we will deploy the finally selected model for production. We will also learn about the concepts underlying the various ensemble techniques used to create the models.</span></p>
<p class="mce-root"><a href="9f39b0b1-736a-4b0d-9ca9-276096fe2ada.xhtml" class="calibre8">Chapter 3</a>, <em class="calibre15">Implementing a Joke Recommendation Engine</em><span class="calibre4">, introduces r</span><span class="calibre4">ecommendation engines, which are designed to predict the ratings that a user would give to content such as movies and music. Based on what a user has previously liked or seen and using other profiling attributes, a recommendation engine suggests new content that the user might like. Such engines have gained a lot of significance in recent years. We explore the exciting area of recommendation systems by working on a joke recommendation engine project. </span><span class="calibre4">In this chapter, we start by understanding the concepts and types of collaborative filtering algorithms. We will then build a recommendation engine to provide personalized joke recommendations using collaborative filtering approaches such as user-based collaborative filters and item-based collaborative filters. The dataset used for this project is a open dataset called the Jester jokes dataset. Apart from this, we will be exploring various libraries available in R that can be used to build recommendation systems, and we will be comparing the performances obtained from these approaches. </span><span class="calibre4">Additionally, we leverage the market basket analysis technique, a pretty popular technique in the marketing domain, to discern relationships between various jokes.</span></p>
<div class="title-page-name">
<p class="mce-root"><a href="dd2c7d12-7674-49e3-8965-af815f5c6f07.xhtml" class="calibre8">Chapter 4</a><span class="calibre4">,</span> <em class="calibre15">Sentiment Analysis of Amazon Reviews with NLP</em><span class="calibre4">, covers s</span><span class="calibre4">entiment analysis, which entails finding the sentiment of a sentence and labeling it as positive, negative, or neutral. This chapter introduces sentiment analysis and covers the various techniques that can be used to analyze text. We will understand text-mining concepts and the various ways that text is labeled based on the tone.</span></p>
</div>
<div class="title-page-name">
<p class="mce-root">We will apply sentiment analysis to Amazon product review data. This dataset contains millions of Amazon customer reviews and star ratings. It is a classification task where we will be categorizing each review as positive, negative, or neutral depending on the tone. Apart from using various popular R text-mining libraries to preprocess the reviews to be classified, we will also be leveraging a wide range of text representations, such as bag of words, word2vec, fastText, and Glove. Each of the text representations is then used as input for ML algorithms to perform classification. In the course of implementing each of these techniques, we will also learn about the concepts behind these techniques and also explore other instances where we could successfully apply them.</p>
</div>
<p class="mce-root"><a href="43de56cf-5bfa-44c0-be57-b20df236cc95.xhtml" class="calibre8">Chapter 5</a>, <em class="calibre15">Customer Segmentation Using Wholesale Data</em><span class="calibre4">, covers the s</span><span class="calibre4">egmentation, grouping, or clustering of customers, which can be achieved through unsupervised learning. We explore the various aspects of customer grouping in this chapter. </span><span class="calibre4">Customer segmentation is an important tool used by product sellers to understand their customers and gather information. Customers can be segmented based on different criteria, such as age and spending patterns. </span><span class="calibre4">In this chapter, we learn the various techniques of customer segmentation. For the project, we use a dataset containing wholesale transactions. This dataset is available in the UCI Machine Learning Repository. </span><span class="calibre4">We will be applying advanced clustering techniques, such as k-means, DIANA, and AGNES. At times, we will not know the number of groups that exist in the dataset at hand. We will explore the ML techniques for dealing with such ambiguity and have ML </span><span class="calibre4">find out the number of groups possible based on the underlying characteristics of the input data. Evaluating the output of the clustering algorithms is an area that is often challenging to practitioners. We also explore this area so as to have a well-rounded understanding of applying clustering algorithms to real-world problems.</span></p>
<p class="mce-root"><a href="018d53f7-b892-44e8-b45f-4d9041f9d65b.xhtml" class="calibre8">Chapter 6</a>, <em class="calibre15">Image Recognition Using Deep Neural Networks</em><span class="calibre4">, covers <strong class="calibre3">c</strong></span><span class="calibre4"><strong class="calibre3">onvolutional neural networks</strong> (<strong class="calibre3">CNNs</strong>), which are a type of deep neural network and are popular in computer vision applications. </span><span class="calibre4">In this chapter, we learn about the fundamental concepts underlying CNNs. We explore why CNNs work so well with computer vision problems such as object detection. We discuss the aspects of transfer learning and how it works in tandem with CNNs to solve computer vision problems. </span><span class="calibre4">As elsewhere in the book, we'll be going by the philosophy of learning by doing. We will learn about all of these concepts by applying a CNN in the building of a multi-class classification model on a popular open dataset called MNIST. The objective of the project is to classify given images of handwritten digits. The project explores the methodology for creating features from raw images. We will learn about the various preprocessing techniques that can be applied to the image data in order use the data with deep learning models.</span></p>
<p class="mce-root"><a href="002b0fa6-1419-42a8-bdb0-dd4bc422489a.xhtml" class="calibre8">Chapter 7</a>, <em class="calibre15">Credit Card Fraud Detection Using Autoencoders</em><span class="calibre4">, covers a</span><span class="calibre4">utoencoders, which are yet another type of unsupervised deep learning network. We start the chapter by understanding autoencoders and how they are different from the other deep learning networks, such as <strong class="calibre3">recurrent neural networks</strong> (<strong class="calibre3">RNNs</strong>)and CNNs. We will learn about autoencoders by implementing a project that identifies credit card fraud. </span><span class="calibre4">Credit card companies are constantly seeking ways to detect credit card fraud. Fraud detection is a key aspect for banks to protect their revenues. It can be achieved through the application of ML in the finance domain for the specific fraud detection problem. </span><span class="calibre4">A fraud is usually an anomalous event that requires immediate action. In this chapter, we will use an autoencoder to detect fraud. Autoencoders are neural networks that contain a bottleneck layer whose dimensionality is smaller than the input data. In this chapter, we will become familiar with dimensionality reduction and how it can be used to identify credit card fraud detection. For the project, we will be using the H2O deep learning framework in tandem with R. </span><span class="calibre4">As far as the dataset is concerned, we use an open dataset that contains credit card transactions of European card holders from September 2013. There are a total of 284,807 transactions, out of which 492 are fraudulent.</span></p>
<p class="mce-root"><a href="265e576c-694a-476f-be7a-72281b2fc662.xhtml" class="calibre8">Chapter 8</a>, <em class="calibre15">Automatic Prose Generation with Recurrent Neural Networks</em>, introduces some <span class="calibre4"><strong class="calibre3">deep neural networks</strong> (<strong class="calibre3">DNNs</strong>) that have recently received a lot of attention. This is due to their success in obtaining great results in various areas of ML, from face recognition and object detection to music generation and neural art. </span><span class="calibre4">This chapter introduces the concepts necessary for understanding deep learning. We discuss the nuts and bolts of neural networks, such as neurons, hidden layers, various activation functions, techniques for dealing with problems faced in neural networks, and using optimization algorithms to get weights in neural networks. We will also implement a neural network from scratch to demonstrate these concepts. The content of this chapter will help us get foundational knowledge on neural networks. </span><span class="calibre4">Then, we will learn how to apply an RNN by doing a project. It has always been thought that creative tasks such as authoring stories, writing poems, and painting pictures can only be achieved by humans. This is no longer true, thanks to deep learning! Technology can now accomplish creative tasks. We will create an application based on <strong class="calibre3">long short-term memory</strong> (<strong class="calibre3">LSTM</strong>) network, a variant of RNNs that generates text automatically. To accomplish this task, we make use of the MXNet framework, which extends its support for the R language to perform deep learning.<span class="calibre4"><span class="calibre4"> </span></span></span><span class="calibre4">In the course of implementing this project, we will also learn more about the concepts surrounding RNNs and LSTMs.</span></p>
<p class="mce-root"><a href="4b80233e-4fbe-4d90-ba32-5053930433c1.xhtml" class="calibre8">Chapter 9</a>, <em class="calibre15">Winning the Casino Slot Machines with Reinforcement Learning</em><span class="calibre4">, begins with an explanation of RL. We discuss the various concepts of RL, including strategies for solving what is called as the multi-arm bandit problem. We implement a project that uses UCB and Thompson sampling techniques in order to solve the multi-arm bandit problem.</span></p>
<p class="mce-root"><a href="d17f7a4d-ea3f-4d43-bc59-0cf260a8ac49.xhtml" class="calibre8">Appendix</a>, <em class="calibre15">The Road Ahead</em>, briefly discuss the advancements in the ML world and the need to stay on top of them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">To get the most out of this book</h1>
                </header>
            
            <article>
                
<div class="title-page-name">
<p class="mce-root">The projects covered in this book are intended to expose you to practical knowledge on the implementation of various ML techniques to real-world problems. It is expected that you have a good working knowledge of R and some basic understanding of ML. Basic knowledge of ML and R is a must prior to starting this project.</p>
<p class="mce-root">It should also be noted that the code for the projects is implemented using R version 3.5.2 (2018-12-20), nicknamed Eggshell Igloo. The project code has been successfully tested on Linux Mint 18.3 Sylvia. There is no reason to believe that the code does not work on other platforms, such as Windows; however, this is not something that has been tested by the author.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the example code files</h1>
                </header>
            
            <article>
                
<p class="mce-root">You can download the example code files for this book from your account at <a href="http://www.packt.com" target="_blank" class="calibre8">www.packt.com</a>. If you purchased this book elsewhere, you can visit <a href="http://www.packt.com/support" target="_blank" class="calibre8">www.packt.com/support</a> and register to have the files emailed directly to you.</p>
<p class="mce-root">You can download the code files by following these steps:</p>
<ol class="calibre12">
<li class="calibre10">Log in or register at <a href="http://www.packt.com" target="_blank" class="calibre8">www.packt.com</a>.</li>
<li class="calibre10">Select the <span>SUPPORT</span> tab.</li>
<li class="calibre10">Click on <span>Code Downloads &amp; Errata</span>.</li>
<li class="calibre10">Enter the name of the book in the <span>Search</span> box and follow the onscreen instructions.</li>
</ol>
<p class="mce-root">Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p>
<ul class="calibre9">
<li class="calibre10">WinRAR/7-Zip for Windows</li>
<li class="calibre10">Zipeg/iZip/UnRarX for Mac</li>
<li class="calibre10">7-Zip/PeaZip for Linux</li>
</ul>
<p class="mce-root"><span class="calibre4">The code bundle for the book is also hosted on GitHub at</span><span class="calibre4"> </span><a href="https://github.com/PacktPublishing/R-Machine-Learning-Projects" class="calibre8">https://github.com/PacktPublishing/R-Machine-Learning-Projects</a><span class="calibre4">. </span><span class="calibre4">In case there's an update to the code, it will be updated on the existing GitHub repository.</span></p>
<p class="mce-root"><span class="calibre4">We also have other code bundles from our rich catalog of books and videos available at</span><span class="calibre4"> </span><strong class="calibre3"><span class="calibre4"><a href="https://github.com/PacktPublishing/" target="_blank" class="calibre8">https://github.com/PacktPublishing/</a></span></strong><span class="calibre4">. Check them out!</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Download the color images</h1>
                </header>
            
            <article>
                
<p class="mce-root">We also provide a PDF file that has color images of the screenshots/diagrams used in this book. You can download it here: <a href="http://www.packtpub.com/sites/default/files/downloads/Bookname_ColorImages.pdf" target="_blank" class="calibre8">http://www.packtpub.com/sites/default/files/downloads/<span>9781789807943</span>_ColorImages.pdf</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conventions used</h1>
                </header>
            
            <article>
                
<p class="mce-root">There are a number of text conventions used throughout this book.</p>
<p class="mce-root"><kbd class="calibre11">CodeInText</kbd>: <span class="calibre4">Indicates c</span>ode words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. <span class="calibre4">Here is an example:</span> "<span class="calibre4">The </span><kbd class="calibre11">rsample</kbd><span class="calibre4"> library incorporates this dataset, and we can make use of this dataset directly from the library.</span>"</p>
<p class="mce-root">A block of code is set as follows:</p>
<pre class="calibre16">setwd("~/Desktop/chapter 2") <br class="title-page-name"/>library(rsample)<br class="title-page-name"/>data(attrition) <br class="title-page-name"/>str(attrition) <br class="title-page-name"/>mydata&lt;-attrition </pre>
<p class="mce-root">When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p>
<pre class="calibre16">[default]<br class="title-page-name"/>exten =&gt; s,1,Dial(Zap/1|30)<br class="title-page-name"/>exten =&gt; s,2,Voicemail(u100)<br class="title-page-name"/><strong class="calibre1">exten =&gt; s,102,Voicemail(b100)</strong><br class="title-page-name"/>exten =&gt; i,1,Voicemail(s0)</pre>
<p class="mce-root"><strong class="calibre3">Bold</strong>: Indicates a new term, an important word, or w<span class="calibre4">ords that you see onscreen. For example, words in menus or dialog boxes appear in the text like this. Here is an example: "You may recollect the <span class="calibre4">Customers Who Bought This Item Also Bought This</span> heading on Amazon (or any e-commerce site) where recommendations are shown.</span><span class="calibre4">"</span></p>
<div class="packtinfobox">Warnings or important notes appear like this.</div>
<div class="packttip">Tips and tricks appear like this.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Get in touch</h1>
                </header>
            
            <article>
                
<p class="mce-root">Feedback from our readers is always welcome.</p>
<p class="mce-root"><strong class="calibre3">General feedback</strong>: If you have questions about any aspect of this book, <span class="calibre4">mention the book title in the subject of your message and</span> email us at <kbd class="calibre11"><span>customercare@packtpub.com</span></kbd>.</p>
<p class="mce-root"><strong class="calibre3">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packt.com/submit-errata" target="_blank" class="calibre8">www.packt.com/submit-errata</a>, selecting your book, clicking on the Errata Submission Form link, and entering the details.</p>
<p class="mce-root"><strong class="calibre3">Piracy</strong>: If you come across any illegal copies of our works in any form on the Internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <kbd class="calibre11">copyright@packt.com</kbd> with a link to the material.</p>
<p class="mce-root"><strong class="calibre3">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please visit <a href="http://authors.packtpub.com/" target="_blank" class="calibre8">authors.packtpub.com</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reviews</h1>
                </header>
            
            <article>
                
<p class="mce-root">Please leave a review. Once you have read and used this book, why not leave a review on the site that you purchased it from? Potential readers can then see and use your unbiased opinion to make purchase decisions, we at Packt can understand what you think about our products, and our authors can see your feedback on their book. Thank you!</p>
<p class="mce-root">For more information about Packt, please visit <a href="http://www.packt.com/" target="_blank" class="calibre8">packt.com</a>.</p>


            </article>

            
        </section>
    </body></html>