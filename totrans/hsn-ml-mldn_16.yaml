- en: Using TensorFlow with ML.NET
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will be using a pre-trained TensorFlow model, specifically
    the Inception model, and we’ll integrate the model into a **Windows Presentation
    Foundation** (**WPF**) application. We will be taking the pre-trained model and
    applying transfer learning, by adding some pictures of food and bodies of water.
    After the transfer learning has been performed, we then allow the user to select
    their own images. By the end of the chapter, you should have a firm grasp of what
    it takes to integrate a TensorFlow model into your ML.NET application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down Google's Inception model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the image classification desktop application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring additional production application enhancements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breaking down Google's Inception model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google's Inception model ([https://github.com/google/inception](https://github.com/google/inception))
    has been trained on millions of images to help with one of the growing questions
    in our society—what is in my image? The type of applications wanting to answer
    this question range from matching faces, automatically detecting weapons or unwanted
    objects, sports branding in game pictures (such as the brand of sneakers), and
    image archivers that provide users with the support they need to search without
    manual tags, to name just a few.
  prefs: []
  type: TYPE_NORMAL
- en: This type of question is typically answered with **object recognition**. An
    application of object recognition that you might already be familiar with is **optical**
    **character** **recognition** (**OCR**). OCR is when an image of characters can
    be interpreted as text, such as what is found in Microsoft's OneNote Handwriting
    to Text feature, or in a toll booth that reads license plates. The particular
    application of object recognition that we will be looking into specifically is
    called **image classification**.
  prefs: []
  type: TYPE_NORMAL
- en: The Inception model helps with this problem by using deep learning to classify
    images. The model was trained in a supervised approach on millions of images,
    with the output being a neural network. The advantage of this approach is that
    the pre-built model can be enhanced with a smaller subset of images, which is
    what we will be doing in the next section of this chapter. This approach of adding
    additional data and labels is called **transfer** **learning**. This approach
    can also be helpful when creating customer-specific models.
  prefs: []
  type: TYPE_NORMAL
- en: Think of it like creating a branch from your master branch in GitHub; you might
    want to just add one class or modify one element without having to re-create the
    entire code base. In regards to models, take for instance, an image classifier
    for automobiles. Let us assume that you obtain millions of images covering US
    and foreign cars, trucks, vans, and more. A new customer comes to you requesting
    you to create a model to help monitor vehicles entering a government facility.
    The previous model should not be thrown away and won't need to be fully retrained,
    simply adding more commercial (or maybe military) vehicles with labels would be
    needed.
  prefs: []
  type: TYPE_NORMAL
- en: For a larger and more in-depth deep dive into Google's image classification,
    a good resource is their developer documentation, which can be found from [https://developers.google.com/machine-learning/practica/image-classification/](https://developers.google.com/machine-learning/practica/image-classification/).
  prefs: []
  type: TYPE_NORMAL
- en: Creating the WPF image classification application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, the application that we will be creating is an image classification
    application, specifically allowing the user to select an image and determine whether
    it is either food or water. This is achieved through the aforementioned and included,
    pre-trained TensorFlow Inception model. The first time that the application is
    run, the ML.NET version of the model is trained with the images and the `tags.tsv`
    file (to be reviewed in the next section).
  prefs: []
  type: TYPE_NORMAL
- en: As with previous chapters, the completed project code, sample dataset, and project
    files can be downloaded here: [https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter12](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter12)[.](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter10)
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the project architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will dive into a WPF desktop application. As mentioned in
    the first section of this chapter, we will be using the WPF framework to create
    our application. You might be asking, why not a UWP application such as the browser
    application that we created in [Chapter 10](9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml),
    *Using ML.NET with UWP*? The reasoning, at least at the time of writing, is that
    TensorFlow support, specifically for image classification, is not fully supported
    in a UWP application. Perhaps, in future versions of ML.NET, this will be added.
    For other non-image-based applications, you may be able to use TensorFlow in a
    UWP application.
  prefs: []
  type: TYPE_NORMAL
- en: Those who have done WPF development previously, and are looking closely, will
    notice that the project utilizes .NET Core 3.1\. In .NET Core 3.0, Microsoft added
    support for WPF and WinForms, therefore, you are no longer tied to the Windows-only
    .NET Framework for GUI development. Instead, this support is added through the
    `Microsoft.WindowsDesktop.App.WPF` NuGet package.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we will be using the `Microsoft.ML` (1.3.1) NuGet package—in
    addition to several additional NuGet packages—to be able to utilize TensorFlow
    within our .NET application. These include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Microsoft.ML.ImageAnalytics` (1.3.1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Microsoft.ML.TensorFlow` (1.3.1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SciSharp.TensorFlow.Redist` (1.14.0)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the time you are reading this, there may very well be newer versions of the
    packages and they should work, however, the versions that were noted above are
    the ones that we are going to use in this deep dive, and what is available in
    the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, you will find the Visual Studio Solution Explorer
    view of the solution. Due to the TensorFlow support being much more particular
    about project types and CPU targets, we have gone back to a single project, as
    opposed to the three-project architecture that was used in the previous several
    chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/26d6470c-1bff-4a86-b49e-2c37a72775a9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `tags.tsv` file (found in the `assets\images` folder in the code repository)
    contains eight rows, which map the included images to the preclassification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If you want to experiment with your own classification, delete the included
    images, copy your images, and update the `tags.tsv` file with the label. I should
    note, all of the images that are included were taken by me on various vacations
    to California—feel free to use them as you wish.
  prefs: []
  type: TYPE_NORMAL
- en: The files in the `assets/inception` folder contain all of the Google pre-trained
    files (and license file).
  prefs: []
  type: TYPE_NORMAL
- en: Diving into the WPF image classification application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in the opening section, our desktop application is a WPF application.
    For the scope of this example, as found in [Chapter 10](9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml),
    *Using ML.NET with UWP*, we are using standard approaches for handling the application
    architecture by following the **Model-View-ViewModel** (**MVVM**) design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'The files that we will be diving into in this section are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MainWindowViewModel`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MainWindow.xaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MainWindow.xaml.cs`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BaseML`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ImageDataInputItem`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ImageDataPredictionItem`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ImageClassificationPredictor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rest of the files inside the WPF project were untouched from the default
    Visual Studio .NET Core 3.1 WPF application template; for example, the `App.xaml`
    and `AssemblyInfo.cs` files.
  prefs: []
  type: TYPE_NORMAL
- en: The MainWindowViewModel class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The purpose of the `MainWindowViewModel` class is to contain our business logic
    and control the view, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we do is instantiate our previously discussed `ImageClassificationPredictor` class,
    so that it can be used to run predictions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The next block of code handles the power of MVVM for the classification string,
    and also stores the selected image. For each of these properties, we call `OnPropertyChanged`
    upon a change in values, which triggers the binding of the View to refresh for
    any field that is bound to these properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the `Initialize` method, which calls the predictor''s `Initialize`
    method. The method will return a tuple, which indicates whether the model can''t
    be loaded or whether it is not found, along with the exception (if thrown):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we handle what happens when the user clicks the Select Image button.
    This method opens a dialog box prompting the user to select an image. If the user
    cancels the dialog, the method returns. Otherwise, we call the two helper methods
    to load the image into memory and classify the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `LoadImageBytes` method takes the filename and loads the image into our
    MVVM-based `ImageSource` property so, after selection, the image control is automatically
    updated to a view of the selected image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'And lastly, the `Classify` method takes the path and passes it into the `Predictor`
    class. Upon returning the prediction, the classification and confidence are built
    into our MVVM `ImageClassification` property, therefore, the UI is updated automatically:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The last element of the `MainWindowViewModel` class is the same `OnPropertyChanged`
    method that we defined in [Chapter 10](9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml),
    *Using ML.NET with UWP*, which allows the MVVM magic to happen. With our `ViewModel`
    class defined, let us move on to the `MainWindow` XAML file.
  prefs: []
  type: TYPE_NORMAL
- en: The MainWindow.xaml class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in the *Breaking down UWP architecture *section of [Chapter 10](9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml),* Using
    ML.NET with UWP*, when describing the development, XAML markup is used to define
    your user interface. For the scope of this application, our UI is relatively simple:  `Button`,
    `Image Control`, and `TextBlock`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will look at the code now:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing that we define is our grid. In XAML, a grid is a container
    similar to a `<div>` in web development. We then define our rows. Similar to Bootstrap
    (but easier to understand in my opinion), is the pre-definition of the height
    of each row. Setting a row to `Auto` will auto-size the height to the content''s
    height, while an asterisk translates to using all remaining height based on the
    main container''s height:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We first define our `Button` object, which will trigger the aforementioned
    `SelectFile` method in our `ViewModel` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We then define our `Image` control, which is bound to our previously reviewed
    `SelectedImageSource` property that is found in our `ViewModel` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We then add the `TextBlock` control that will display our classification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: With the XAML aspect of our View defined, let us now dive into the code behind
    of the `MainWindow` class.
  prefs: []
  type: TYPE_NORMAL
- en: The MainWindow.xaml.cs file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `MainWindow.xaml.cs` file contains the code behind the XAML view, which
    is discussed here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing that we define is a wrapper property around the `DataContext`
    property, which is built into the base `Window` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the constructor for `MainWindow`, in order to initialize the
    `DataContext` property to our `MainWindowViewModel` object. If the initialization
    fails, we do not want the application to continue. In addition, we need to let
    the user know why it failed, using a `MessageBox` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we call the ViewModel''s `SelectFile` method to handle the image selection
    and classification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: With the code behind of the `MainWindow` class behind us, that concludes the
    WPF component. Let us now focus on the machine learning part of the example.
  prefs: []
  type: TYPE_NORMAL
- en: The BaseML class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `BaseML` class, as used in most of the previous examples, exposes a base
    class for our ML.NET classes. In the case of this example, we actually streamlined
    the class due to the nature of using a pre-trained model. The class now simply
    initializes the `MLContext` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: With the streamlined `BaseML` class reviewed, let us dive into the `ImageDataInputItem`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: The ImageDataInputItem class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `ImageDataInputItem` class contains our class to pass into the model; the
    essential property is the `ImagePath` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: While smaller than most of our input classes, the Inception model only requires
    the two properties. Now, let us dive into the output class that is called `ImageDataPredictionItem`.
  prefs: []
  type: TYPE_NORMAL
- en: The ImageDataPredictionItem class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `ImageDataPredictionItem` class contains the prediction response, including
    the confidence of the predicted value string (to contain `Water` or `Food` in
    the case of the included images):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Much like the input class, the output class has only two properties, similar
    to previous examples. With the input and output classes behind us, let us dive
    into the `ImageClassificationPredictor` class, which uses these classes for transfer
    learning and predictions.
  prefs: []
  type: TYPE_NORMAL
- en: The ImageClassificationPredictor class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `ImageClassificationPredictor` class contains all of the code that is needed
    to load and predict against the Inception TensorFlow model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to define several helper variables to access the images and
    `.tsv` files:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the settings that the pre-trained Inception model needs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create our `Predict` method and overload that simply takes the image
    file path. Like in previous examples, we create `PredictionEngine` with a call
    to our `MLContext` object, passing in our input class (`ImageDataInputItem`) and
    our output class (`ImageDataPredictionItem`), and then calling the `Predict` method
    to get our model prediction:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '4\. Finally, we initialize and extend our pre-trained model with our own samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'For the full code, please refer to the following GitHub repository link: [https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/blob/master/chapter12/chapter12.wpf/ML/ImageClassificationPredictor.cs](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/blob/master/chapter12/chapter12.wpf/ML/ImageClassificationPredictor.cs).
    With the `Initialize` method completed, that concludes the code deep dive. Let
    us now run the application!'
  prefs: []
  type: TYPE_NORMAL
- en: Running the image classification application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we are using a pre-trained model, we can just run the application from
    Visual Studio. Upon running the application, you will be presented with a mostly
    empty window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6f1449c0-2b5e-4219-a885-954599f1646e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Clicking on the Select Image File button and then selecting an image file will
    trigger the model to run. In my case, I selected a picture from a recent vacation
    to Germany, which came back with a 98.84% confidence score:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4a2c3d00-de73-40ec-8779-590ab092c4c1.png)'
  prefs: []
  type: TYPE_IMG
- en: Feel free to try various files on your machine to see the confidence score and
    classification—if you start noticing issues, add more samples to the images folder
    and `tags.tsv` file, as noted in the earlier section. Be sure to delete the `chapter12.mdl`
    file prior to making these changes.
  prefs: []
  type: TYPE_NORMAL
- en: Additional ideas for improvements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have completed our deep dive, there are a couple of additional elements
    that could possibly further enhance the application. A few ideas are discussed
    here.
  prefs: []
  type: TYPE_NORMAL
- en: Self-training based on the end user's input
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the advantages, as noted in the opening section of this chapter, is the
    ability to utilize transfer learning in dynamic applications. Unlike previous
    example applications that have been reviewed in this book, this application could
    actually allow the end user to select a series (or folder) of images, and with
    a few code changes, build the new `.tsv` file and train a new model. For a web
    application or commercial product, this would provide a high value and would also
    reduce the burden on you to, for instance, obtain images of every type—a daunting,
    and more than likely futile, goal.
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in the *Logging* section of [Chapter 10](9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml),
    *Using ML.NET with UWP*, having a desktop application has its pros and cons. The
    biggest con necessitating the need for logging is that your desktop application
    could be installed on any number of configurations of Windows 7 to Windows 10,
    with an almost unlimited number of permutations. As mentioned previously, logging
    by utilizing NLog ([https://nlog-project.org/](https://nlog-project.org/)) or
    a similar open source project is highly recommended, coupled with a remote logging
    solution such as Loggly, so that you can get error data from your user's machines.
    Given the GDPR and recent CCPA, we need to ensure that the data that is leaving
    the end user's machines is conveyed and that these logs do not include personal
    data (or actual images uploaded to a remote server via the logging mechanism).
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing a database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to the performance optimization suggestion in [Chapter 10](9c105516-7e4f-4f99-b70f-8b0d6165d8c5.xhtml),
    *Using ML.NET with UWP*, if a user selects the same image more than once, especially
    if this application was being used in a kiosk or converted to a web application,
    the performance advantages of storing the classification could be fairly significant.
    A quick and easy method for achieving this could be to perform a SHA256 of the
    image, and check that hash against a database. Depending on the number of users
    and if they are going to be concurrent, I would suggest one of two options:'
  prefs: []
  type: TYPE_NORMAL
- en: If the users are going one at a time and the application is going to remain
    a WPF application, using the previously mentioned lightweight database—LiteDB
    ([http://www.litedb.org/](http://www.litedb.org/))—would be recommended.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are launching a large web application using a production, then MongoDB
    or a horizontally scalable database, such as Microsoft's CosmosDB would be recommended
    in order to ensure that the database lookups wouldn't be slower than simply re-performing
    the model prediction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the course of this chapter, we have deep-dived into what goes into creating
    a WPF application using a pre-trained TensorFlow model. We also reviewed and looked
    closely into Google's image classification Inception model. In addition, we learned
    how to take that model and integrate it in order to perform image classification
    on user-selected images. Lastly, we also discussed some ways to further enhance
    the example application.
  prefs: []
  type: TYPE_NORMAL
- en: In the next and last chapter, we will focus on using a pre-trained ONNX model
    in a WPF application for object detection.
  prefs: []
  type: TYPE_NORMAL
