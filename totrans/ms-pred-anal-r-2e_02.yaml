- en: Chapter 2. Tidying Data and Measuring Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章.整理数据与衡量性能
- en: In this chapter, we will cover the topics of tidying your data in preparation
    for predictive modeling, performance metrics, cross-validation, and learning curves.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖整理数据以准备预测建模、性能指标、交叉验证和学习曲线等主题。
- en: 'In statistics, it is an accepted concept that there are two types of data,
    which are:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，有一个公认的概念，即有两种类型的数据，它们是：
- en: Untidy
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杂乱
- en: Tidy
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整洁
- en: Untidy data is considered to be raw or messy; tidy data is data that has gone
    through a quality assurance process and is ready to be used.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 杂乱的数据被认为是原始的或混乱的；整洁的数据是经过质量保证流程并准备好使用的。
- en: Getting started
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始
- en: 'Before we get started with discussing the process of tidying data, it would
    be very prudent to point out that whatever you do to tidy your data, you should
    be sure to:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始讨论整理数据的过程之前，指出以下几点是非常谨慎的：无论你如何整理数据，你都应该确保：
- en: Create and save your scripts so that you can use them again for new or similar
    data sources. This is referred to as **reusability**. Why spend time recreating
    the same code, rules, or logic if you don't have to? This applies to *new data*
    within the *same project* (that the scripts were developed for) or new projects
    you may be involved with in the future.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建并保存您的脚本，以便您可以在新的或类似的数据源中再次使用它们。这被称为**可重用性**。为什么要在不需要的情况下花费时间重新创建相同的代码、规则或逻辑？这适用于*同一项目*中的*新数据*（脚本是为该项目开发的）或您未来可能参与的新的项目。
- en: Tidy your data as "far upstream" as possible, perhaps even at the original source.
    In other words, save and maintain the original data, but use programmatic scripts
    to clean it, fix mistakes, and save that *cleaned* dataset for further analysis.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽可能“上游”地整理数据，也许甚至在原始来源处。换句话说，保存并维护原始数据，但使用程序脚本进行清理、修复错误，并保存该*清理后的*数据集以供进一步分析。
- en: Tidying data
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整理数据
- en: It is worth clarifying what the idea of *tidying data* means. Tidying data is
    the process of *reorganizing* (or perhaps just *organizing*) data, as well as
    addressing perceived issues or concerns someone has identified within your data.
    Issues affect the quality of data. Data quality, of course, is relative to the
    proposed purpose of use (of the data).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 值得明确的是，*整理数据*的概念。整理数据是重新组织（或可能只是组织）数据的过程，以及解决在您的数据中识别出的任何问题或担忧。问题会影响数据的质量。当然，数据质量是相对于拟议的用途（数据）而言的。
- en: Categorizing data quality
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据质量分类
- en: 'It is perhaps an accepted notion that issues with data quality may be categorized
    into one of the following areas:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 或许有一个公认的观点，即数据质量问题可以归类到以下一个领域：
- en: Accuracy
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确性
- en: Completeness
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整性
- en: Update status
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新状态
- en: Relevance
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关性
- en: Consistency (across sources)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一致性（跨来源）
- en: Reliability
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可靠性
- en: Appropriateness
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适当性
- en: Accessibility
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可访问性
- en: The quality or level of quality of your data can be affected by the way it is
    entered, stored, and managed. The process of addressing data quality (referred
    to most often as **data quality assurance** (**DQA**)) requires a routine and
    regular review and evaluation of the data and performing ongoing processes termed
    *profiling* and *scrubbing* (this is vital even if the data is stored in multiple
    disparate systems, making these processes difficult).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据的质量或质量水平可能受到其输入、存储和管理方式的影响。解决数据质量（通常称为**数据质量保证**（**DQA**））的过程需要定期和常规地审查和评估数据，并执行称为*配置文件*和*清理*的持续过程（即使数据存储在多个不同的系统中，这些过程也很困难）。
- en: Here, tidying the data will be much more project centric in that we're probably
    not concerned with creating a formal DQA process, but are only concerned with
    making certain that the data is correct for your particular predictive project.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，整理数据将更加以项目为中心，因为我们可能不关心创建正式的DQA流程，而只是确保数据对您的特定预测项目是正确的。
- en: In statistics, data unobserved or not yet reviewed by the data scientist is
    considered *raw* and cannot be reliably used in predictive projects. The process
    of tidying the data will usually involve several steps. Taking the extra time
    to break out the work is strongly recommended (rather than haphazardly addressing
    multiple data issues together).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，数据科学家尚未观察到的数据或尚未审查的数据被认为是*原始的*，不能在预测项目中可靠地使用。整理数据的过程通常涉及几个步骤。强烈建议花额外的时间将工作分解出来（而不是随意地一起解决多个数据问题）。
- en: The first step
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步
- en: 'The first step requires bringing the data to what may be called *mechanical*
    correctness. In this first step, you focus on things such as:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步需要将数据带到可能被称为**机械**正确性的状态。在这一步中，你关注的是如下事项：
- en: '**File format and organization**: Field order, column headers, number of records,
    and so on'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文件格式和组织**：字段顺序、列标题、记录数量等'
- en: '**Record data typing** (such as numeric values stored as strings)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记录数据类型**（例如，将数值存储为字符串）'
- en: '**Date and time processing** (typically reformatting values into standard formats
    or consistent formats)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日期和时间处理**（通常将值重新格式化为标准格式或一致格式）'
- en: '**Miss-content**: Wrong category labels, unknown or unexpected character encoding,
    and so on'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺失内容**：错误的类别标签、未知或意外的字符编码等'
- en: The next step
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步
- en: The second step is to address the *statistical soundness* of the data. Here
    we correct issues that may be *mechanically correct* but will most likely (depending
    upon the subject matter) impact a statistical outcome.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是解决数据的**统计可靠性**。在这里，我们纠正那些可能是**机械上正确**但很可能会（根据主题内容）影响统计结果的问题。
- en: 'These issues may include:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题可能包括：
- en: '**Positive/negative mismatch**: Age variables may be reported as negative'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正负不匹配**：年龄变量可能报告为负数'
- en: '**Invalid (based on accepted logic) data**: An under-aged person may be registered
    to possess a driver''s license'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无效（基于接受逻辑）数据**：一个未成年的人可能被登记为拥有驾照'
- en: '**Missing data**: Key data values may just be missing from the data source'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺失数据**：关键数据值可能只是从数据源中缺失'
- en: The final step
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最后一步
- en: Finally, the last step (before actually attempting to use the data) may be the
    *re-formatting* step. In this step, the data scientist will determine the form
    that the data must be in in order to most efficiently process it, based upon the
    intended use or objective.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在实际上使用数据之前，最后一步可能是**重新格式化**步骤。在这一步中，数据科学家将根据预期的用途或目标，确定数据必须采取的形式，以便最有效地处理它。
- en: 'For example, one might decide to:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个人可能会决定：
- en: '**Reorder or repeat** columns; that is to say, some final processing may require
    redundant or repeated data be generated within a file source to be correctly or
    more easily processed'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重新排序或重复**列；也就是说，某些最终处理可能需要在文件源中生成冗余或重复的数据，以便正确或更易于处理'
- en: '**Drop** columns and/or records (based upon specific criteria)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除**列和/或记录（基于特定标准）'
- en: '**Set decimal places**'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设置小数位数**'
- en: '**Pivot** data'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据透视**数据'
- en: '**Truncate or rename** values'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**截断或重命名**值'
- en: And so on
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等等
- en: There are a variety of somewhat routine methods for using R to resolve the aforementioned
    data errors.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 R 解决上述数据错误有多种相对常规的方法。
- en: 'For example:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '**Changing a data type**: Also referred to as "data type conversion," one can
    utilize the R `is` functions to test for an object''s data type and the `as` functions
    for an explicit conversion. A simplest example is shown here:![The final step](img/00018.jpeg)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更改数据类型**：也称为“数据类型转换”，可以使用 R 的 `is` 函数来测试对象的数据类型，以及 `as` 函数来进行显式转换。以下是一个最简单的例子：![最后一步](img/00018.jpeg)'
- en: '**Date and time**: There are multiple ways to manage date information with
    R. In fact, we can extend the preceding example and mention the `as.Date` function.
    Typically, date values are important to a statistical model and therefore it is
    important to take the time to understand the format of a model''s date fields
    and ensure that they are properly dealt with. Mostly, dates and times will appear
    in raw data format as strings, which can be converted and formatted as required.
    In the following code, the string fields containing a `saledate` and a `returndate`
    are converted to date type values and used with a common time function, `difftime`:![The
    final step](img/00019.jpeg)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日期和时间**：使用 R 管理日期信息有多种方式。实际上，我们可以扩展前面的例子，并提到 `as.Date` 函数。通常，日期值对统计模型很重要，因此花时间了解模型日期字段的格式并确保它们得到适当处理是很重要的。大多数情况下，日期和时间将以原始数据格式作为字符串出现，可以按需转换和格式化。在下面的代码中，包含
    `saledate` 和 `returndate` 的字符串字段被转换为日期类型值，并使用一个常见的时间函数 `difftime`：![最后一步](img/00019.jpeg)'
- en: 'Category labels are critical to statistical modeling as well as data visualization.
    An example of using labels with a sample of categorized data might be assigning
    a label to a participant in a study, perhaps by *level of education*: 1 = Doctoral,
    2 = Masters, 3 = Bachelors, 4 = Associates, 5 = Nondegree, 6 = Some College, 7
    = High School, or 8 = None:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别标签对于统计建模以及数据可视化至关重要。使用标签对分类数据的样本进行标记的一个例子可能是为研究中的参与者分配一个标签，例如通过**教育水平**：1
    = 博士，2 = 硕士，3 = 学士，4 = 专科，5 = 非学位，6 = 一些大学，7 = 高中，或 8 = 无：
- en: '[PRE0]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Assigning labels to data not only helps with readability, but allows a machine
    learning algorithm to learn from the sample, and apply the same labels to other,
    unlabeled data.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为数据分配标签不仅有助于可读性，而且允许机器学习算法从样本中学习，并将相同的标签应用于其他未标记的数据。
- en: '**Missing data parameters**: many times missing data can be excluded from a
    calculation simply by setting an appropriate parameter value. For example, the
    R functions `var`, `cov`, and `cor` compute variance, covariance or correlation
    of variables. These functions have the option to set `na.rm` to TRUE. Doing this
    tells R to exclude any and all records or cases with missing values.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺失数据参数**：很多时候，只需设置适当的参数值，就可以将缺失数据从计算中排除。例如，R 函数 `var`、`cov` 和 `cor` 用于计算变量的方差、协方差或相关系数。这些函数有设置
    `na.rm` 为 TRUE 的选项。这样做会告诉 R 排除任何带有缺失值的记录或案例。'
- en: Various other *data tidying* nuisances can exist within your data, such as incorrectly
    signed numeric data (that is, a negative value for data such as a participant's
    age), invalid data values based upon accepted scenario logic (for example, participant's
    age versus level of education, in that it isn't feasible that a 10-year-old would
    have earned a Master's degree), data values simply missing (is a participant's
    lack of response an indication of a not applicable question or an error?), and
    more. Thankfully, there are at least several approaches to these data scenarios
    with R.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您的数据中可能存在各种其他*数据整理*的烦恼，例如错误标记的数值数据（即，对于如参与者年龄之类的数据，为负值），基于接受场景逻辑的数据值无效（例如，参与者的年龄与教育水平相比，一个10岁的孩子获得硕士学位是不可能的），数据值简单缺失（参与者未作回应是否表示该问题不适用或存在错误？），等等。幸运的是，至少有几种方法可以处理这些数据场景，使用
    R 语言。
- en: Performance metrics
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能指标
- en: In the previous chapter, where we talked about the predictive modeling process,
    we delved into the importance of assessing a trained model's performance using
    training and test datasets. In this section, we will look at specific measures
    of performance that we will frequently encounter when describing the predictive
    accuracy of different models. It turns out that depending on the class of the
    problem, we will need to use slightly different ways of assessing (the model's)
    performance. As we focus on supervised models in this book, we will look at how
    to assess regression models and classification models. For classification models,
    we will also discuss some additional metrics used for the binary classification
    task, which is a very important and frequently encountered type of problem.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了预测建模过程，我们深入探讨了使用训练集和测试集来评估训练模型性能的重要性。在本节中，我们将探讨在描述不同模型的预测准确性时经常遇到的具体性能指标。结果是，根据问题的类别，我们需要使用稍微不同的方式来评估（模型的）性能。由于本书专注于监督模型，我们将探讨如何评估回归模型和分类模型。对于分类模型，我们还将讨论一些用于二元分类任务的额外指标，这是一种非常重要且经常遇到的问题类型。
- en: Note
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Note: In statistics, the term performance is usually interchangeable with accuracy.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在统计学中，性能一词通常与准确性可以互换使用。
- en: Assessing regression models
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估回归模型
- en: In a regression scenario, let's recall that through our model we are building
    a function that is an estimate of a theoretical underlying target function *f*.
    The model's inputs are the values of our chosen input features. If we apply this
    function to every observation, *x[i]*, in our training data, which is labeled
    with the true value of the function, *y[i]*, we will obtain a set of pairs. To
    make sure we are clear on this last point, the first entry is the actual value
    of the output variable in our training data for the *i^(th)* observation, and
    the second entry is the predicted value for this particular observation produced
    by using our model on the feature values for this observation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归场景中，让我们回顾一下，通过我们的模型，我们正在构建一个估计理论上的目标函数 *f* 的函数。模型的输入是我们选择的输入特征值。如果我们将这个函数应用于我们的训练数据中的每一个观测值，*x[i]*，这些数据被标记为函数的真实值，*y[i]*，我们将获得一组配对。为了确保我们清楚这一点，第一个条目是我们训练数据中第
    *i* 个观测值的输出变量的实际值，第二个条目是使用我们的模型对这一观测值的特征值进行预测得到的值。
- en: 'If our model has fit the data well, both values will be very close to each
    other in the training set. If this is also true for our test set, then we consider
    that our model is likely to perform well for future unseen observations. To quantify
    the notion that the predicted and correct values are close to each other for all
    the observations in a dataset, we define a measure known as the **Mean Square
    Error** (**MSE**), as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的模型很好地拟合了数据，这两个值在训练集中将非常接近。如果这在我们的测试集中也是真的，那么我们认为我们的模型很可能会在未来的未见观测值上表现良好。为了量化预测值和正确值对所有观测值在数据集中都接近这一概念，我们定义了一个称为
    **均方误差** (**MSE**) 的度量，如下所示：
- en: '![Assessing regression models](img/00020.jpeg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![评估回归模型](img/00020.jpeg)'
- en: Here, *n* is the total number of observations in the dataset. Consequently,
    this equation tells us to first compute the squared difference between an output
    value and its predicted value for every observation, *i*, in the test set, and
    then take the average of all these values by summing them up and dividing by the
    number of observations. Thus, it should be clear why this measure is called the
    mean square error. The lower this number, the lower the average error between
    the actual value of the output variable in our observations and what we predict
    and, therefore, the more accurate our model. We sometimes make reference to the
    **Root Mean Square Error** (**RMSE**), which is just the square root of the MSE
    and the **Sum of Squared Error** (**SSE**), which is similar to the MSE but without
    the normalization which results from dividing by the number of training examples,
    *n*. These quantities, when computed on the training dataset, are valuable in
    the sense that a low number will indicate that we have trained a model sufficiently
    well. We know that we aren't expecting this to be zero in general, and we also
    cannot decide between models on the basis of these quantities because of the problem
    of overfitting.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*n* 是数据集中观测值的总数。因此，这个方程告诉我们首先计算测试集中每个观测值 *i* 的输出值与其预测值之间的平方差，然后将这些值的总和除以观测值的数量来取平均值。因此，应该清楚为什么这个度量被称为均方误差。这个数字越低，实际输出变量的值与我们的预测值之间的平均误差就越低，因此我们的模型就越准确。我们有时会提到
    **均方根误差** (**RMSE**)，它只是 MSE 的平方根，以及 **平方和误差** (**SSE**)，它与 MSE 类似，但没有除以训练示例数量
    *n* 导致的归一化。这些量在训练数据集上计算时是有价值的，因为低数值表示我们已经很好地训练了模型。我们知道通常我们不期望这个值为零，而且由于过度拟合的问题，我们不能根据这些量来决定模型之间的优劣。
- en: The key place to compute these measures is on the test data. In a majority of
    cases, a model's training data MSE (or equally, RMSE or SSE) will be lower than
    the corresponding measure computed on the test data. A model *m[1]* that overfits
    the data compared to another model *m[2]* can often be identified as such when
    the *m[1]* model produces a lower training MSE but higher test MSE than model
    *m[2]*.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 计算这些度量的关键地方是在测试数据上。在大多数情况下，一个模型的训练数据 MSE（或者同样，RMSE 或 SSE）将低于在测试数据上计算的相应度量。一个与另一个模型
    *m[2]* 相比过度拟合数据的模型 *m[1]*，通常可以通过 *m[1]* 模型产生比模型 *m[2]* 更低的训练 MSE 但更高的测试 MSE 来识别。
- en: Assessing classification models
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估分类模型
- en: In regression models, the degree to which our predicted function incorrectly
    approximates an output, *y[i]*, for a particular observation, *x[i]*, is taken
    into account by the MSE. Specifically, large errors are squared, so a very large
    deviation on one data point can have a more significant impact than a few small
    deviations across more than one data point. It is precisely because we are dealing
    with a numerical output in regression that we can measure not only for which observations
    we aren't doing a good job at predicting, but also how far off we are.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归模型中，我们的预测函数对特定观察值 *x[i]* 的输出 *y[i]* 的近似程度，是通过均方误差（MSE）来考虑的。具体来说，大的误差会被平方，因此一个数据点的非常大的偏差可能比多个数据点的几个小偏差有更大的影响。正是因为我们在回归中处理的是数值输出，所以我们不仅可以测量哪些观察值在预测上做得不好，还可以测量我们偏离的程度有多远。
- en: 'For models that perform classification, we can again define an error rate,
    but here we can only talk about the number of misclassifications that were made
    by our model. Specifically, we have an error rate given by:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于执行分类的模型，我们同样可以定义一个错误率，但在这里我们只能谈论我们的模型所做的错误分类的数量。具体来说，我们有一个由以下公式给出的错误率：
- en: '![Assessing classification models](img/00021.jpeg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![评估分类模型](img/00021.jpeg)'
- en: This measure uses the `indicator` function to return the value of 1 when the
    predicted class is not the same as the labeled class. Thus, the error rate is
    computed by counting the number of times the class of the output variable is incorrectly
    predicted, and dividing this count by the number of observations in the dataset.
    In this way, we can see that the error rate is actually the percentage of misclassified
    observations made by our model. It should be noted that this measure treats all
    types of misclassifications as equal. If the cost of some misclassifications is
    higher than others, then this measure can be adjusted by adding in weights that
    multiply each misclassification by an amount proportional to its cost.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个度量使用 `indicator` 函数，当预测的类别与标记的类别不同时返回值为 1。因此，错误率是通过计算输出变量类别被错误预测的次数，并将这个计数除以数据集中的观察值数量来计算的。这样，我们可以看到错误率实际上是我们模型做出的错误分类观察值的百分比。需要注意的是，这个度量将所有类型的错误分类视为相等。如果某些错误分类的成本高于其他错误分类，那么可以通过添加权重来调整这个度量，这些权重将每个错误分类乘以与其成本成比例的量。
- en: If we want to diagnose the greatest source of error in a regression problem,
    we tend to look at the points for which we have the largest error between our
    predicted value and the actual value. When doing classifications, it is often
    very useful to compute what is known as the confusion matrix. This is a matrix
    that shows all pairwise misclassifications that were made on our data. We shall
    now return to our iris species classification problem. In a previous section,
    we trained three kNN models. We'll now see how we can assess their performance.
    Like many classification models, kNN can return predictions either as final class
    labels or via a set of scores pertaining to each possible output class. Sometimes,
    as is the case here, these scores are actually probabilities that the model has
    assigned to every possible output. Regardless of whether the scores are actual
    probabilities, we can decide on which output label to pick on the basis of these
    scores, typically by simply choosing the label with the highest score.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要诊断回归问题中最大的错误来源，我们通常会查看预测值与实际值之间误差最大的点。在进行分类时，计算所谓的混淆矩阵通常非常有用。这是一个显示我们在数据上所做的所有成对错误分类的矩阵。现在，我们将回到我们的鸢尾花物种分类问题。在前一节中，我们训练了三个
    kNN 模型。现在，我们将看到我们如何评估它们的性能。像许多分类模型一样，kNN 可以返回最终类别标签或与每个可能的输出类别相关的分数集。有时，就像这里的情况一样，这些分数实际上是模型分配给每个可能输出的概率。无论分数是否是实际概率，我们都可以根据这些分数来决定选择哪个输出标签，通常是通过简单地选择得分最高的标签。
- en: 'In R, the most common function to make model predictions is the `predict()`
    function, which we will use with our kNN models:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 语言中，最常用的进行模型预测的函数是 `predict()` 函数，我们将使用它来与我们的 kNN 模型一起使用：
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the kNN model, we can assign output scores as direct probabilities by computing
    the ratio of the nearest neighbors that belong to each output label. In the three
    test examples shown, the virginica species has unit probabilities in two of them,
    but only 60 percent probability for the remaining example. The other 40 percent
    belong to the versicolor species, so it seems that in the latter case, three out
    of five nearest neighbors were of the virginica species, whereas the other two
    were of the versicolor species. It is clear that we should be more confident about
    the two former classifications than the latter.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在 kNN 模型中，我们可以通过计算属于每个输出标签的最近邻的比例来直接将输出分数作为概率。在所展示的三个测试示例中，virginica 物种在其中的两个示例中具有单位概率，但在剩余的示例中只有
    60% 的概率。其余的 40% 归属于 versicolor 物种，因此似乎在后者的情况下，五个最近邻中有三个属于 virginica 物种，而另外两个属于
    versicolor 物种。很明显，我们应该对前两种分类比后一种分类更有信心。
- en: 'We''ll now compute class predictions for the three models on the test data:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将计算三个模型在测试数据上的类别预测：
- en: '[PRE2]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can use the `postResample()` function from the `caret` package to display
    test set accuracy metrics for our models:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `caret` 包中的 `postResample()` 函数来显示我们模型的测试集准确度指标：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here, accuracy is one minus the error rate and is thus the percentage of correctly
    classified observations. We can see that all the models perform very closely in
    terms of accuracy, with the model that uses a Z-score normalization prevailing.
    This difference is not significant given the small size of the test set.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，准确度是误差率的倒数，因此是正确分类观察值的百分比。我们可以看到，所有模型在准确度方面表现非常接近，使用 Z 分数归一化的模型占主导地位。考虑到测试集的大小很小，这种差异并不显著。
- en: 'This is defined as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这被定义为如下：
- en: '![Assessing classification models](img/00022.jpeg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![评估分类模型](img/00022.jpeg)'
- en: The Kappa statistic is designed to counterbalance the effect of random chance
    and takes values in the interval, [-1,1], where 1 indicates perfect accuracy,
    -1 indicates perfect inaccuracy, and 0 occurs when the accuracy is exactly what
    would be obtained by a random guesser. Note that a random guesser for a classification
    model guesses the most frequent class. In the case of our iris classification
    model, the three species are equally represented in the data, and so the expected
    accuracy is one-third. The reader is encouraged to check that by using this value
    for the expected accuracy; we can obtain the observed values of the Kappa statistic
    from the accuracy values.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Kappa 统计量旨在抵消随机因素的影响，其值在 [-1,1] 的区间内，其中 1 表示完美准确，-1 表示完美不准确，当准确度正好是随机猜测者所能获得的准确度时，出现
    0。请注意，对于分类模型，随机猜测者猜测最频繁的类别。在我们的鸢尾花分类模型中，三种物种在数据中均匀分布，因此预期的准确度是三分之一。鼓励读者检查一下，通过使用这个值作为预期的准确度，我们可以从准确度值中获得
    Kappa 统计量的观察值。
- en: We can also examine the specific misclassifications that our model makes, using
    a confusion matrix.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过混淆矩阵来检查我们的模型所犯的具体错误分类。
- en: 'This can be simply constructed by cross-tabulating the predictions with the
    correct output labels:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过将预测与正确的输出标签进行交叉表来简单地构建：
- en: '[PRE4]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `caret` package also has the very useful `confusionMatrix()` function, which
    automatically computes this table as well as several other performance metrics,
    the explanation of which can be found at [http://topepo.github.io/caret/other.html](http://topepo.github.io/caret/other.html).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`caret` 包还包含一个非常有用的 `confusionMatrix()` 函数，该函数会自动计算这个表格以及其他几个性能指标，其解释可以在 [http://topepo.github.io/caret/other.html](http://topepo.github.io/caret/other.html)
    找到。'
- en: In the preceding confusion matrix, we can see that the total number of correctly
    classified observations is 28, which is the sum of the numbers `10`, `9`, and
    `9` on the leading diagonal. The table in the output shows us that the setosa
    species seems to be easier to predict with our model, as it is never confused
    with other species. The `versicolor` and `virginica` species, however, can be
    confused with each other, and the model has misclassified one instance of each.
    We can therefore surmise that computing the confusion matrix serves as a useful
    exercise. Spotting class pairs that are frequently confused will guide us to improve
    our model, for example, by looking for features that might help distinguish these
    classes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在先前的混淆矩阵中，我们可以看到正确分类的总观测数是28，这是主对角线上数字`10`、`9`和`9`的总和。输出表显示，setosa物种似乎更容易用我们的模型预测，因为它从未与其他物种混淆。然而，`versicolor`和`virginica`物种可能会相互混淆，并且模型错误地将每种物种的一个实例分类。因此，我们可以推断出计算混淆矩阵是一项有用的练习。识别经常混淆的类别对将指导我们改进模型，例如，通过寻找可能有助于区分这些类别的特征。
- en: Assessing binary classification models
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估二元分类模型
- en: 'A special case of classification known as a binary classification occurs when
    we have two classes. Here are some typical binary classification scenarios:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一种称为二元分类的特殊分类情况发生在我们有两个类别时。以下是一些典型的二元分类场景：
- en: We want to classify incoming emails as spam or not spam using the email's content
    and header
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想根据电子邮件的内容和标题将收到的电子邮件分类为垃圾邮件或非垃圾邮件
- en: We want to classify a patient as having a disease or not using their symptoms
    and medical history
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想根据患者的症状和病史将患者分类为患有疾病或未患病
- en: We want to classify a document from a large database of documents as being relevant
    to a search query, based on the words in the query and the words in the document
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想根据查询中的单词和文档中的单词将来自大型文档数据库的文档分类为与查询相关的文档
- en: We want to classify a product from an assembly line as faulty or not
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想将装配线上的产品分类为有缺陷或无缺陷
- en: We want to predict whether a customer applying for credit at a bank will default
    on their payments, based on their credit score and financial situation
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想根据客户的信用评分和财务状况预测申请银行信贷的客户是否会违约
- en: 'In a binary classification task, we usually refer to our two classes as the
    positive class and the negative class. By convention, the positive class corresponds
    to a special case that our model is trying to predict, and is often rarer than
    the negative class. From the preceding examples, we would use the positive class
    label for our spam emails, faulty assembly line products, defaulting customers,
    and so on. Now consider an example in the medical diagnosis domain, where we are
    trying to train a model to diagnose a disease that we know is only present in
    1 in 10,000 of the population. We would assign the positive class to patients
    that have this disease. Notice that in such a scenario, the error rate alone is
    not an adequate measure of a model. For example, we can design the simplest of
    classifiers that will have an error rate of only 0.01 percent by predicting that
    every patient will be healthy, but such a classifier would be useless. We can
    come up with more useful metrics by examining the confusion matrix. Suppose that
    we had built a model to diagnose our rare disease and on a test sample of 100,000
    patients, we obtained the following confusion matrix:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在二元分类任务中，我们通常将我们的两个类别称为正类和负类。按照惯例，正类对应于我们的模型试图预测的特殊情况，并且通常比负类更罕见。从前面的例子中，我们会用正类标签来标记垃圾邮件、有缺陷的装配线产品、违约客户等等。现在考虑一个医学诊断领域的例子，我们试图训练一个模型来诊断一种我们知道在人口中只有1/10000的人会患上的疾病。我们会将正类分配给患有这种疾病的病人。请注意，在这种情况下，错误率本身并不是衡量模型的一个充分指标。例如，我们可以设计一个最简单的分类器，其错误率仅为0.01%，通过预测每个病人都将健康，但这样的分类器将毫无用处。我们可以通过检查混淆矩阵来得出更有用的指标。假设我们构建了一个用于诊断罕见疾病的模型，并在100,000个病人的测试样本上获得了以下混淆矩阵：
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The binary classification problem is so common that the cells of the binary
    confusion matrix have their own names. On the leading diagonal, which contains
    the correctly classified entries, we refer to the elements as the true negatives
    and true positives. In our case, we had 99900 true negatives and 13 true positives.
    When we misclassify an observation as belonging to the positive class when it
    actually belongs to the negative class, then we have a false positive, also known
    as a Type I error. A false negative or Type II error occurs when we misclassify
    a positive observation as belonging to the negative class. In our case, our model
    had 78 false positives and 9 false negatives.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 二元分类问题如此普遍，以至于二元混淆矩阵的单元格有自己的名称。在主对角线上，它包含正确分类的条目，我们称这些元素为真正的负例和真正的正例。在我们的案例中，我们有99900个真正的负例和13个真正的正例。当我们错误地将一个观察值分类为正类，而实际上它属于负类时，我们就有了一个假阳性，也称为I型错误。当我们错误地将一个正类观察值分类为负类时，就发生了假阴性或II型错误。在我们的案例中，我们的模型有78个假阳性和9个假阴性。
- en: 'We''ll now introduce two very important measures in the context of binary classification,
    which are precision and recall. Precision is defined as the ratio of the number
    of correctly predicted instances of the positive class to the total number of
    predicted instances of the positive class. Using the labels from the preceding
    binary confusion matrix, precision is given by:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将介绍在二元分类背景下两个非常重要的度量指标，即精确度和召回率。精确度定义为正确预测的正类实例数与预测的正类实例总数的比率。使用前一个二元混淆矩阵的标签，精确度可以表示为：
- en: '![Assessing binary classification models](img/00023.jpeg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![评估二元分类模型](img/00023.jpeg)'
- en: 'Precision, thus, essentially measures how accurate we are in making predictions
    for the positive class. By definition, we can achieve 100 percent precision by
    never making any predictions for the positive class, as this way we are guaranteed
    to never make any mistakes. Recall, by contrast, is defined as the number of correct
    predictions for the positive class over all the members of the positive class
    in our dataset. Once again, using the labels from the binary confusion matrix,
    we can see the definition of recall as:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，精确度本质上衡量了我们预测正类时的准确性。根据定义，我们可以通过从不为正类做出任何预测来达到100%的精确度，因为这样我们保证不会犯任何错误。相比之下，召回率定义为在数据集中所有正类成员中正确预测的正类数量。再次使用二元混淆矩阵的标签，我们可以看到召回率的定义如下：
- en: '![Assessing binary classification models](img/00024.jpeg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![评估二元分类模型](img/00024.jpeg)'
- en: 'Recall measures our ability to identify all the positive class members from
    our dataset. We can easily achieve maximum recall by always predicting the positive
    class for all our data points. We will make a lot of mistakes, but we will never
    have any false negatives. Notice that precision and recall form a tradeoff in
    our model''s performance. At one end, if we don''t predict the positive class
    for any of our data points, we will have zero recall but maximum precision. At
    the other end, if all our data points are predicted as belonging to the positive
    class (which, remember, is usually a rare class), we will have maximum recall
    but extremely low precision. Put differently, trying to reduce the Type I error
    leads to increasing the Type II error and vice versa. This inverse relationship
    is often plotted for a particular problem on a precision-recall curve. By using
    an appropriate threshold parameter, we can often tune the performance of our model
    in such a way that we achieve a specific point on this precision-recall curve
    that is appropriate for our circumstances. For example, in some problem domains,
    we tend to be biased toward having a higher recall than a higher precision, because
    of the high cost of misclassifying an observation from the positive class into
    the negative class. As we often want to describe the performance of a model using
    a single number, we define a measure known as the F1 score, which combines precision
    and recall. Specifically, the F1 score is defined as the harmonic mean between
    precision and recall:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率衡量我们识别数据集中所有正类成员的能力。我们可以通过总是预测所有数据点的正类来轻松实现最大召回率。我们将会犯很多错误，但我们将不会有任何假阴性。请注意，精确度和召回率在我们的模型性能中形成了一种权衡。在一端，如果我们不对我们的任何数据点预测正类，我们将有零召回率但最大精确度。在另一端，如果所有我们的数据点都被预测为属于正类（记住，这通常是一个罕见的类别），我们将有最大召回率但极低的精确度。换句话说，试图减少I型错误会导致增加II型错误，反之亦然。这种反向关系通常在特定问题的精确度-召回率曲线上绘制。通过使用适当的阈值参数，我们通常可以调整我们模型的性能，以便在精确度-召回率曲线上达到一个适合我们情况的特定点。例如，在某些问题域中，我们倾向于倾向于有比高精确度更高的召回率，因为将正类观察误分类为负类的成本很高。因为我们经常想用一个单一的数字来描述模型的性能，所以我们定义了一个称为F1分数的度量，它结合了精确度和召回率。具体来说，F1分数定义为精确度和召回率的调和平均数：
- en: '![Assessing binary classification models](img/00025.jpeg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![评估二分类模型](img/00025.jpeg)'
- en: The reader should verify that in our example confusion matrix, precision is
    14.3 percent, recall is 59.1 percent, and the F1 score is 0.23.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 读者应验证，在我们的示例混淆矩阵中，精确度为14.3%，召回率为59.1%，F1分数为0.23。
- en: Cross-validation
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证
- en: Cross-validation (which you may hear some data scientists refer to as *rotation
    estimation*, or simply a general technique for assessing models), is another method
    for assessing a model's performance (or its accuracy).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证（你可能听到一些数据科学家将其称为*旋转估计*，或简单地作为一种评估模型的一般技术），是评估模型性能（或其准确性）的另一种方法。
- en: Mainly used with predictive modeling to estimate how accurately a model might
    perform in practice, one might see cross-validation used to check how a model
    will potentially generalize; in other words, how the model will apply what it
    infers from samples, to an entire population (or dataset).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 主要用于预测建模来估计模型在实际应用中可能表现出的准确性，人们可能会看到交叉验证被用来检查模型潜在的泛化能力；换句话说，模型将如何将其从样本中推断出的信息应用到整个群体（或数据集）中。
- en: With cross-validation, you identify a (known) dataset as your validation dataset
    on which training is run, along with a dataset of unknown data (or first seen
    data) against which the model will be tested (this is known as your testing dataset).
    The objective is to ensure that problems such as overfitting (allowing non-inclusive
    information to influence results) are controlled, as well as provide an insight
    on how the model will generalize a real problem or on a real data file.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 使用交叉验证，你将一个（已知）数据集作为你的验证数据集，在该数据集上运行训练，以及一个未知数据集（或首次看到的数据集），模型将对其进行测试（这被称为你的测试数据集）。目标是确保像过度拟合（允许非包容性信息影响结果）等问题得到控制，以及提供有关模型如何泛化实际问题或真实数据文件的见解。
- en: 'This process will consist of separating data into samples of similar subsets,
    performing the analysis on one subset (called the training set), and validating
    the analysis on the other subset (called the validation set or testing set):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程将包括将数据分为相似子集的样本，在一个子集（称为训练集）上执行分析，并在另一个子集（称为验证集或测试集）上验证分析：
- en: Separation → Analysis → Validation
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 分离 → 分析 → 验证
- en: To reduce variability, multiple iterations (also called folds or rounds) of
    cross-validation are performed using different partitions, and the validation
    results are averaged over the rounds. Typically, a data scientist will use a model's
    stability to determine the actual number of rounds of cross-validation that should
    be performed.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少变异性，使用不同的分区进行多次迭代（也称为折或轮）的交叉验证，并将验证结果在轮次中平均。通常，数据科学家会使用模型的不变性来确定应该执行的实际交叉验证轮次数量。
- en: Again, the cross-validation method can perhaps be better understood by thinking
    about selecting a subset of data and manually calculating the results. Once you
    know the correct results, they can be compared to the model-produced results (using
    a separate subset of data). This is one round. Multiple rounds would be performed
    and the compared results averaged and reviewed, eventually providing a fair estimate
    of a model's prediction performance.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，通过思考选择数据子集并手动计算结果，可以更好地理解交叉验证方法。一旦你知道正确的结果，它们可以与模型产生的结果（使用另一个数据子集）进行比较。这是一轮。将执行多轮，比较结果平均并审查，最终提供一个公平的模型预测性能估计。
- en: Suppose a university provides data on its student body over time. The students
    are described as having various characteristics, such as having a High School
    GPA greater or less than 3.0, if they have a family member that graduated from
    the school, if the student was active in non-program activities, was a resident
    (lived on campus), was a student athlete, and so on. Our predictive model wants
    to predict what characteristics students who graduate early have.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一所大学提供其学生群体随时间变化的数据。学生被描述为具有各种特征，例如高中GPA是否大于或小于3.0，是否有家庭成员从该校毕业，学生是否在非编程活动中活跃，是否是居民（住在校园内），是否是学生运动员等等。我们的预测模型想要预测提前毕业的学生具有哪些特征。
- en: 'The following table is a representation of the results of using a five-round
    cross-validation process to predict our model''s expected accuracy:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 下表展示了使用五轮交叉验证过程预测模型预期准确性的结果表示：
- en: '![Cross-validation](img/00026.jpeg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![交叉验证](img/00026.jpeg)'
- en: Given the preceding figures, I'd say our predictive model is expected to be
    very accurate!
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的图表，我认为我们的预测模型预计将非常准确！
- en: In summary, cross-validation combines (averages) measures of fit (prediction
    error) to derive a more accurate estimate of model prediction performance. This
    method is typically used in cases where there is not enough data available to
    test without losing significant modeling or testing quality.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，交叉验证通过（平均）拟合度（预测误差）的度量来推导出模型预测性能的更准确估计。这种方法通常用于数据不足以进行测试而不失去显著建模或测试质量的情况下。
- en: Learning curves
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习曲线
- en: Another method of assessing a model's performance is by evaluating the model's
    growth of learning or the model's ability to improve learning (obtain a better
    score) with additional experience (for example, more rounds of cross-validation).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型性能的另一种方法是通过评估模型的学习增长或模型通过额外经验（例如，更多轮次的交叉验证）提高学习（获得更好的分数）的能力。
- en: Note
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Learning is the act of acquiring new, or modifying and reinforcing existing,
    knowledge.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 学习是获取新知识或修改和加强现有知识的行为。
- en: The information indicating a model's result or score with a data file population
    can be combined with other scores to show a line or curve, which is known as a
    model's learning curve.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 表示模型结果或分数与数据文件群体信息的数据可以与其他分数结合，以显示一条线或曲线，这被称为模型的学习曲线。
- en: A learning curve is a graphical representation of the growth of learning (the
    scores shown in a vertical axis) with practice (the individual data files or rounds
    shown in the horizontal axis).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线是学习增长（垂直轴上显示的分数）与练习（水平轴上显示的个体数据文件或轮次）之间关系的图形表示。
- en: 'This can also be conceptualized as:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可以被概念化为：
- en: The same task repeated in a series
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复相同的任务
- en: A body of knowledge learned over time
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随时间学习到的知识体系
- en: 'The following figure illustrates a hypothetical learning curve, showing the
    improved learning of a predictive model using resultant scores by cross-validation
    round:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个假设的学习曲线，显示了通过交叉验证轮次得到的分数来提高预测模型学习的情况：
- en: '![Learning curves](img/00027.jpeg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![学习曲线](img/00027.jpeg)'
- en: 'Source link: [https://en.wikipedia.org/wiki/File:Alanf777_Lcd_fig01.png](https://en.wikipedia.org/wiki/File:Alanf777_Lcd_fig01.png)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 来源链接：[https://en.wikipedia.org/wiki/File:Alanf777_Lcd_fig01.png](https://en.wikipedia.org/wiki/File:Alanf777_Lcd_fig01.png)
- en: Tip
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: It's funny; one might know that the familiar expression *it's a steep learning
    curve* is intended to describe an activity that is tough to learn, but in statistics,
    a learning curve with a steep start would actually represent a rapidly improving
    progress.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 很有趣；一个人可能知道熟悉的表达“it's a steep learning curve”是用来描述一个难以学习的活动，但在统计学中，一个陡峭的学习曲线实际上代表的是快速进步。
- en: Learning curves relating model performance to experience are commonly found
    to be used when performing model assessments.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型性能与经验相关的学习曲线通常在执行模型评估时被发现被使用。
- en: As we have mentioned earlier in this section, performance (or the scores) is
    meant to be the accuracy of a model while experience (or round) may be the number
    of training examples, datasets, or iterations used in optimizing the model parameters.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在此节之前所提到的，性能（或分数）是指模型的准确度，而经验（或轮次）可能是指用于优化模型参数的训练样本数、数据集或迭代次数。
- en: Plot and ping
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绘图和ping
- en: Using two generic R functions, we can demonstrate a simple learning curve visualization.
    Ping will open an image file which will hold our learning curve visualization
    so we can easily include it in a document later, and plot will draw our graphic.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 使用两个通用的R函数，我们可以展示一个简单的学习曲线可视化。ping将打开一个包含我们的学习曲线可视化的图像文件，这样我们就可以轻松地将其包含在文档中，而plot将绘制我们的图形。
- en: 'The following are our example R code statements:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们示例R代码语句：
- en: '[PRE6]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The preceding statements create the following graphic as a file:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的陈述创建了一个以下图形的文件：
- en: '![Plot and ping](img/00028.jpeg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![绘图和ping](img/00028.jpeg)'
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored the fundamental ideas surrounding issues and concerns
    with data quality and how to categorize quality issues by their type, as well
    as presented ideas for tidying up your data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了围绕数据质量问题及其类型分类的基本思想，以及整理数据的建议。
- en: In order to compare the performance of the different models that one may create,
    we went on to establish some fundamental notions of model performance, such as
    the **mean squared error** (**MSE**) for regression and the classification error
    rate for classification.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较一个人可能创建的不同模型的性能，我们进一步建立了一些关于模型性能的基本概念，例如回归的**均方误差**（**MSE**）和分类的错误率。
- en: We also introduced cross-validation as a generic assessment technique to be
    used in cases where there is a limited amount of data available.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还介绍了交叉验证作为一种通用的评估技术，用于数据量有限的情况。
- en: Finally, learning curves were discussed as a way to judge the ability of a model
    to improve its scores or ability to learn.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，学习曲线被讨论为判断模型提高分数或学习能力的一种方式。
- en: With a firm grounding in the basics of the predictive modeling process, we will
    look at linear regression in the next chapter.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在对预测建模过程的基本原理有了坚实的了解之后，我们将在下一章中探讨线性回归。
