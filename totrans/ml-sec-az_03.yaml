- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Planning for Regulatory Compliance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working with **artificial intelligence** (**AI**) systems, there are a
    couple of things that come to mind when we talk about compliance. The first is
    the process of adhering to laws, regulations, and standards that are usually set
    by governments, industry associations, or any other regulatory authorities, and
    the second is ethical considerations.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to develop **machine learning** (**ML**)
    models ethically and responsibly by using the six Responsible AI principles according
    to Microsoft and how to translate them into a responsible development strategy
    using Responsible AI tools. Then, we will do an overview of the industry-recognized
    regulatory compliance standards for Azure Machine Learning and how to enforce
    them by using Azure Policy. These standards are not only Microsoft benchmarks
    but also globally accepted frameworks such as the **National Institute of Standards
    and Technology Risk Management Framework** (**NIST RMF**).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Responsible AI development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regulatory compliance in Azure Policy for Azure Machine Learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compliance auditing and reporting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compliance automation in Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of the chapter, you will not only become familiar with the regulatory
    and security compliance standards, but you will learn how to handle auditing,
    reporting, and automation.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Responsible AI development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As AI systems gain popularity and are used by many people around the world,
    it raises the question of how ethically these systems perform. This is evident,
    for example, by the public release of OpenAI’s ChatGPT model. Everyone or almost
    everyone has used it so far, and it has had some interesting reactions. Many have
    been impressed, excited, and even loved this new product that can help them be
    more productive in their work and in their everyday lives. Others have been concerned
    or even scared of the prospects of this powerful model and how it can very easily
    mimic human behavior.
  prefs: []
  type: TYPE_NORMAL
- en: The focus of technology has always been to solve problems. We are amid a new
    technological revolution, and AI has the capability to improve people’s lives
    very quickly; however, that does not mean that there are no dangers involved.
    Every individual organization that uses and creates advanced AI systems will need
    to create a governance system for ethical and Responsible AI development.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will explore the Responsible AI principles and
    learn how to apply them to our organization.
  prefs: []
  type: TYPE_NORMAL
- en: Responsible AI principles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this book, we will follow Microsoft’s approach to **Responsible AI**, which
    is based on six ethical principles—fairness, reliability and safety, privacy and
    security, inclusiveness, transparency, and accountability.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will translate these six principles into more specific governance policies,
    and in the following section, we will discover the tools we can use to maintain
    governance and compliance in our systems. Here is a depiction of these principles:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – Responsible AI principles](img/B21076_03_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – Responsible AI principles
  prefs: []
  type: TYPE_NORMAL
- en: Let us discuss each of these in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Fairness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI-enabled systems and applications should treat all people fairly. Any system
    in development or production should avoid unfair bias and promote equal treatment
    and opportunities for all people who use it. This includes unbiased decision-making.
    We need to ensure that AI systems do not discriminate against individuals or groups
    based on attributes such as race, gender, age, or disability. So, when collecting
    data, we need to ensure we have a wide range of values for each category and that
    sensitive labels do not affect the predictions. When, for example, we need to
    include sensitive data in the dataset for the predictions, we should also be careful
    not to perpetuate existing inequalities or unintended correlations in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Mitigations include techniques for every step of the ML process but mostly in
    data preprocessing. For example, if we are training an application to approve
    a loan, we need to exclude all sensitive features, if possible, as demographic
    data can perpetuate biases. There are fairness libraries available to identify
    and prevent biases, such as the Fairlearn library we will see in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Reliability and safety
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI systems should not only be reliable and safe for their users but also throughout
    the development process. This principle focuses on ensuring that AI systems are
    dependable, perform as intended, and mitigate potential risks. Safety and reliability
    have to do with many aspects of a system and its processes.
  prefs: []
  type: TYPE_NORMAL
- en: A system must have reliable performance and deliver reliable and accurate predictions.
    We should strive to minimize errors, inconsistencies, or unexpected behaviors.
    Service disruptions, no matter how big or small, can affect other systems as well.
    ML models are usually part of other processes, so a model that analyzes and makes
    predictions to detect cybersecurity threats should have safeguards in place so
    that it does not fail.
  prefs: []
  type: TYPE_NORMAL
- en: We should always address risks that could lead to negative consequences for
    individuals or society. The extent to which we will ensure the safety of the system
    heavily depends on the system’s purpose. For instance, it is acceptable for an
    entertainment application that employs automated generation to produce subpar
    images without causing any harm, but the same standard does not apply to critical
    systems such as a self-driving vehicle or a surgery robotic arm. Finally, for
    a system to be reliable and safe it needs to be up to date and continuously monitored
    to ensure that it maintains or improves the standards it was built on. This means
    that there should be human interaction in the production process, or if the system
    learns from feedback, there should be an approval process in place.
  prefs: []
  type: TYPE_NORMAL
- en: Privacy and security
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Any AI system or ML-enabled application is no different than any other application
    that is based on data. Privacy and security are even more important as there are
    attack techniques that will make the trained model reveal the data used to train
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Before we even start, we need to consider data regulations so that we can decide
    where to store the data. When working with Azure, you need to be aware of the
    data center regions around the world to ensure your data is protected by the proper
    regulations and abides by any compliance requirements you have. When you are creating
    your Azure Machine Learning environment, you can choose your preferred region.
  prefs: []
  type: TYPE_NORMAL
- en: The second part is securing the data and the system. We will see the best practices
    to implement for the security and privacy of our workloads that are hosted in
    Azure extensively throughout this book. Always remember when securing your ML
    model and its data and algorithms that you must also ensure related systems are
    also secure, to prevent adversaries from using lateral access techniques to gain
    access to your resources.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest issue besides security is also privacy, especially in sectors such
    as finance or healthcare. As ML is based on data, we need to use the absolute
    minimum of **personally identifiable information** (**PII**) in our models. There
    are several techniques we can use to anonymize our data and libraries to help
    minimize identification, even from aggregated results such as the SmartNoise SDK
    we will see in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Inclusiveness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An AI system should be inclusive and promote equal access, participation, and
    benefits for all individuals and communities. During the development stage, it
    is particularly important to have diverse perspectives and experiences. When you
    include a wide range of stakeholders and experts from diverse backgrounds and
    demographics, you ensure that AI systems reflect the needs and values of diverse
    communities.
  prefs: []
  type: TYPE_NORMAL
- en: Accessibility is also a great consideration, and I am not talking about disabilities
    only. Of course, we need to incorporate features that accommodate various accessibility
    needs, such as support for screen readers, keyboard navigation, and other assistive
    technologies. Additionally, we need to consider the **user experience** (**UX**)
    and usability. If your target audience includes salespeople who are on the move
    all day, adding voice capabilities is also important for inclusiveness.
  prefs: []
  type: TYPE_NORMAL
- en: By using a user-centric approach in AI development, actively seeking feedback,
    and collaborating with a diverse group with a focus on understanding and addressing
    needs, you can be confident that you are contributing positively to social, economic,
    and cultural inclusion.
  prefs: []
  type: TYPE_NORMAL
- en: Transparency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Every AI system should be understandable in every aspect. That does not mean
    sharing all information about how it was created publicly because, as we saw in
    the previous chapter, this is potentially dangerous, and an adversary can use
    that information to compromise the system. However, it should be clear to the
    user how the system works, its limitations, and potential implications for individuals
    and society.
  prefs: []
  type: TYPE_NORMAL
- en: '**Explainability** is a major part of AI and ML. ML models, especially ones
    that provide predictions that involve complex decision-making, should provide
    insights into which features affect the predictions and to what degree. There
    are a lot of libraries available, and we will see some implementations in the
    next chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: The use of AI disclosure is also vital. Most of the time, models are deployed
    as part of another system of process. Users need to be aware of when the system
    uses AI automation and when the process is handled by a human to avoid any confusion.
    Clear communication of system capabilities and limitations helps manage user expectations
    and avoid potential misunderstandings.
  prefs: []
  type: TYPE_NORMAL
- en: Accountability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Accountability complements the other five principles and is a fundamental aspect
    of any system. It must be clear what the roles and responsibilities are of everyone
    that is involved in the ML process. This includes assigning accountability for
    the development, deployment, and continuous monitoring of ML models and related
    services. We need to be adaptable as AI systems continuously learn from feedback,
    and we need to be ready to acknowledge and address any incidents that result from
    our model’s predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Complying with applicable laws, regulations, and ethical guidelines in the development
    and use of AI systems is also important as the organization that developed the
    technology is usually accountable for any issues. Following compliance and legal
    requirements will help us minimize any potential future issues. This is not a
    one-time check; there needs to be continuous monitoring and evaluation of our
    AI systems to assess their performance and identify areas for improvement. Additionally,
    there are very few regulations for AI and data at this moment, so we need to keep
    up with any updates, which is a challenge as such regulations might be location-
    or industry-specific. We will talk about compliance a little more extensively
    later in this chapter and how to use Azure’s tools to ensure your development
    process is protected and compliance is assured.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'All principles, guidelines, and related documents can be found in the official
    Microsoft *Responsible AI* portal here: [https://www.microsoft.com/ai/responsible-ai](https://www.microsoft.com/ai/responsible-ai).'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Responsible AI in your organization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All the preceding points are easy in theory, but how do you start building a
    solid strategy? Let us review the first steps you need to take, as Responsible
    AI can be implemented in multiple stages.
  prefs: []
  type: TYPE_NORMAL
- en: First, you will start with an assessment. Where are you in your Responsible
    AI journey, and what do you need to improve? The second part is responsible development,
    and this stage depends on what your system’s goals are. There are different guidelines
    and tools here to ensure fairness and performance in all the stages of the ML
    life cycle. Our job does not end there; we need to ensure responsible deployment
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will briefly outline the tools and guidelines available.
    We will explore the implementation and best practices of each tool in the next
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: The Human-AI eXperience Toolkit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The **Human-AI eXperience (HAX) Toolkit** is a set of resources and hands-on
    tools to support organizations in the responsible development and deployment of
    AI systems. It contains multiple tools and guidelines that we can use to bring
    together UX, AI, project management, and engineering teams and maintain responsible
    and ethical AI development across all stages of the ML process.
  prefs: []
  type: TYPE_NORMAL
- en: The first step in using the HAX Toolkit is to familiarize yourself with the
    guidelines for human-AI interaction. They outline how an AI system should behave
    and interact with its users.
  prefs: []
  type: TYPE_NORMAL
- en: HAX Toolkit
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the HAX Toolkit’s latest documents and guidelines here: [https://www.microsoft.com/en-us/haxtoolkit/](https://www.microsoft.com/en-us/haxtoolkit/).'
  prefs: []
  type: TYPE_NORMAL
- en: Then, you can use the HAX Workbook, which is an Excel sheet with multiple questions
    that will help you prioritize work items and see which guidelines you need to
    implement based on your individual scenario. Especially if you are working with
    **natural language processing** (**NLP**), you can utilize the HAX Playbook. This
    will help you identify possible system failures and how you can prevent them or
    recover from them.
  prefs: []
  type: TYPE_NORMAL
- en: If all this sounds very theoretical, in the next section, we will see an example
    of how we can use the HAX Workbook to develop our strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the HAX Design Library
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The first thing we need to do is get familiar with the HAX Design Library.
    You can find all the complete material here: [https://www.microsoft.com/en-us/haxtoolkit/library/](https://www.microsoft.com/en-us/haxtoolkit/library/).
    Here you can find 18 guidelines based on the responsible AI principles for human-AI
    interaction. These guidelines come with design patterns to apply and examples
    by industry.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the 18 guidelines at a glance:'
  prefs: []
  type: TYPE_NORMAL
- en: '**G1: Make clear what the system** **can do.**Helps the user gain an understanding
    of what the system’s benefits or limitations are.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G2: Make clear how well the system can do what it** **can do.**     In this guideline, we ensure that the user is aware of the system’s error frequency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G3: Time services based** **on context.**     This plans when to take action depending on the user’s task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G4: Show contextually** **relevant information.**Shows the user information
    based on their current task or scenario.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G5: Match relevant** **social norms.**     Here, the experiences should match the user’s social and cultural environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G6: Mitigate** **social biases.**     Ensure the system treats all sensitive groups fairly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G7: Support** **efficient invocation.**The system should be available easily
    when needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G8: Support** **efficient dismissal.**     Ensure there is a capability to ignore the system’s services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G9: Support** **efficient correction.**     Ensure there is a capability to recover from errors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G10: Scope services when** **in doubt.**     Gracefully clarify ambiguous commands.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G11: Make clear why the system did what** **it did.**     Ensure that the system’s results can be explained.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G12: Remember** **recent interactions.**     Maintain a short history of previous actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G13: Learn from** **user behavior.**Adjust to the user actions if needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G14: Update and** **adapt cautiously.**     Limit disruption during maintenance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G15: Encourage** **granular feedback.**     Enable the user to provide feedback.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G16: Convey the consequences of** **user actions.**     Make clear how user actions impact the system’s functionality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G17: Provide** **global controls.**     Ensure that the user can customize the system’s behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**G18: Notify users** **about changes.**Keep the users informed about new features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After familiarizing ourselves with the above guidelines we need to see how we
    can use them to develop a Responsible AI strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Let us see how to prioritize and track the implementation of each guideline.
  prefs: []
  type: TYPE_NORMAL
- en: Using the HAX Workbook to develop a Responsible AI strategy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To get started, download the HAX Workbook from [https://www.microsoft.com/en-us/haxtoolkit/workbook](https://www.microsoft.com/en-us/haxtoolkit/workbook).
    We will fill in the first row together based on the scenario presented in [*Chapter
    1*](B21076_01.xhtml#_idTextAnchor015) with the diabetes prediction model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the workbook, the first row presents this guideline: *Make clear what the
    system* *can do.*'
  prefs: []
  type: TYPE_NORMAL
- en: Clarification
  prefs: []
  type: TYPE_NORMAL
- en: Usually, you would fill in all rows in a step before you move on to the next
    step. However, just as an example, we will go through the first guideline only.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us proceed to fill in the first row of the workbook, as demonstrated in
    the following steps. You can see how the result looks in the screenshots accompanying
    each step:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Select relevant guidelines**: In our case, the first guideline, *Make clear
    what the system can do*, is critical, as the predictions involve medical data
    and might influence the diagnosis and the treatment of the patient, so it should
    be clear to the doctor that the results are an estimation and they need to verify
    their validity before delivering a diagnosis and treatment to the patient. In
    the following screenshot, you can see the first step of the guideline together
    with an **EXAMPLES** column of how you are supposed to fill in the rest of the
    cells. As this guideline for us is critical, we choose **Yes** under **STEP 1**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Step 1: Select relevant guidelines](img/B21076_03_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2 – Step 1: Select relevant guidelines'
  prefs: []
  type: TYPE_NORMAL
- en: '**Imagine impact of relevant guidelines**: In this step, you will go through
    all guidelines that you have set as relevant and imagine the impact of implementing
    or not implementing this guideline on your users. In our case, it is very important
    as the ML model is designed to accelerate, not replace, the diagnostic process.
    The doctor should be aware that the prediction is an estimation, and they should
    verify the results. If the doctor does not verify the results, they might prescribe
    the wrong treatment, which can have dangerous consequences for the patient’s health:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Step 2: Imagine impact of relevant guidelines](img/B21076_03_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.3 – Step 2: Imagine impact of relevant guidelines'
  prefs: []
  type: TYPE_NORMAL
- en: '**Draft implementation requirements**: In this step, we outline what we need
    to do to implement this guideline. In this case, we have identified three tasks
    that do not require a big commitment; these are visible in the next screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Step 3: Draft implementation requirements](img/B21076_03_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.4 – Step 3: Draft implementation requirements'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prioritize**: Prioritization is up to you. How urgent is the implementation
    of this guideline? Since we are working with a system in healthcare, making clear
    what the system can do is crucial:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.5 – Step 4: Prioritize](img/B21076_03_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5 – Step 4: Prioritize'
  prefs: []
  type: TYPE_NORMAL
- en: '**Track**: You can use the document or your own project management tools to
    assess the responsible development features you have prioritized using this document:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.6 – Step 5: Track](img/B21076_03_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.6 – Step 5: Track'
  prefs: []
  type: TYPE_NORMAL
- en: This process (*steps 1* through *5*) is then to be repeated for all guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: After this exercise, you will have a good idea of how to approach ethical AI
    development. Even if you are not sure how to fill in the document, in the **EXAMPLES**
    column, you will find an explanation of how each guideline can be implemented
    in a system, which is especially helpful.
  prefs: []
  type: TYPE_NORMAL
- en: However, applications need to be tested to ensure we have covered all our bases.
    When it comes to human-AI interaction there are specific things we need to look
    out for.
  prefs: []
  type: TYPE_NORMAL
- en: So, let us take a look at how the HAX Playbook can help us with this.
  prefs: []
  type: TYPE_NORMAL
- en: Discovering the HAX Playbook
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you are working with NLP, then you should really utilize the HAX Playbook.
    It is an interactive tool that is based on the scenario you present, it provides
    common interaction scenarios for you to test to ensure that in your application
    you have considered the most basic issues that arise, and plan for remediation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The playbook can be found here: [https://microsoft.github.io/HAXPlaybook/](https://microsoft.github.io/HAXPlaybook/)
    or if you want to tweak the survey it creates, you can build the source code from
    here: [https://github.com/microsoft/HAXPlaybook](https://github.com/microsoft/HAXPlaybook).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the playbook, open the site and on the page and choose the AI features
    your application supports on the left. As soon as you click on something the playbook
    presents what the common usage is and the common errors and issues that can arise
    on the right, as seen in the next screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – The HAX Playbook](img/B21076_03_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 – The HAX Playbook
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you choose **Conversational AI** on the left and **Text** input,
    the playbook will suggest that a common error is the wrong spelling in the text.
    The more options you choose the more scenarios will be presented. These scenarios
    can also be exported in various formats for later usage.
  prefs: []
  type: TYPE_NORMAL
- en: After we have completed the human-AI user experience, let us ensure that our
    system is inclusive using the next methodology.
  prefs: []
  type: TYPE_NORMAL
- en: The Inclusive Design methodology
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the Responsible AI principles is inclusiveness, as we mentioned before.
    If you have no idea where to get started, you can use the Microsoft Inclusive
    Design principles, which is a methodology to ensure everyone is included and enabled
    in a digital environment.
  prefs: []
  type: TYPE_NORMAL
- en: Inclusive Design
  prefs: []
  type: TYPE_NORMAL
- en: 'Find Inclusive Design documents and guidelines here: [https://inclusive.microsoft.design/](https://inclusive.microsoft.design/).'
  prefs: []
  type: TYPE_NORMAL
- en: The Inclusive Design principles are simple. First, we need to recognize exclusion
    and acknowledge bias. Second, we need to learn through diversity by bringing in
    fresh and diverse perspectives. Finally, when you provide content to accommodate
    people with physical or mental impairments, it creates experiences that benefit
    everyone. After you have a good understanding of how to approach responsible design,
    you can proceed to work with many tools and libraries. In this book, we will see
    many implementations and tools that help us integrate Responsible AI features
    into our systems.
  prefs: []
  type: TYPE_NORMAL
- en: After Responsible AI development, we need to learn how to ensure regulatory
    compliance.
  prefs: []
  type: TYPE_NORMAL
- en: Regulatory compliance in Azure Policy for Azure Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regulatory compliance is the process of adhering to laws, regulations, and standards
    that are usually set by governments, industry associations, or any other regulatory
    authorities. Part of regulatory compliance means that an organization operates
    within specific legal or regulatory frameworks that apply to the industry and
    or its geographical location. Regulatory compliance is essential to maintain ethical
    practices, protect organizations and customers, and mitigate risks. It includes
    laws and regulations, policies and procedures, risk assessment and management,
    reporting and documentation, and, finally, monitoring and auditing. Building a
    culture of compliance within an organization can be difficult, but it is essential.
    This can include employee training and ensuring that compliance is a priority.
    However, sometimes, the implementation of security controls might be required
    in order to ensure that all those processes and practices are enforced.
  prefs: []
  type: TYPE_NORMAL
- en: If your organization needs to demonstrate compliance with legal or regulatory
    standards, Microsoft and the Azure platform are fully compliant with multiple
    global, regional, and industry standards. You can find all the information in
    the Azure compliance documentation. However, the fact that the platform is compliant
    does not automatically mean that the way you implement and use the services is
    also compliant. You might need to implement or configure those controls properly
    to comply with regulations that have nothing to do with the service but, for example,
    with the data. Here, we will explore all the regulatory compliance controls that
    apply to Azure Machine Learning that we are going to see how to implement in the
    following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Each control is tied to one or more **Azure Policy** definitions. Azure Policy
    is a service in Azure that you use to create, assign, and manage policies that
    enforce and govern your organization’s compliance and security requirements across
    Azure resources. These policies can be used to enforce various configurations
    and constraints on resources, such as resource types, regions, tagging, access
    controls, and more. You can use Azure Policy to bring your resources to compliance
    through remediation for existing resources and automatic remediation for new resources.
    You can group several business rules together to form a policy initiative. You
    can also define and implement a set of rules, called **policy definitions**, which
    define the desired state for your Azure resources. The policy definition or initiative
    can be assigned to any scope of resources that Azure supports, such as management
    groups, subscriptions, resource groups, or individual resources. Azure Policy
    evaluates resources against the defined policies and provides compliance results,
    allowing you to monitor and enforce the desired configurations in a central blade.
  prefs: []
  type: TYPE_NORMAL
- en: 'Policy assignment is quite simple. Let us see how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Azure portal at [http://portal.azure.com/](http://portal.azure.com/)
    and type `policy` in the search box, as seen in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.8 – Opening Azure Policy](img/B21076_03_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 – Opening Azure Policy
  prefs: []
  type: TYPE_NORMAL
- en: 'You will find yourself in the **Overview** blade. Here, you can see a summary
    of your policies and the compliance of your resources:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.9 – The Azure Policy Overview blade](img/B21076_03_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 – The Azure Policy Overview blade
  prefs: []
  type: TYPE_NORMAL
- en: 'To assign a new policy, head to the **Authoring** menu on the left and click
    **Assignments**. In this menu, you can assign a policy to your resources:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.10 – Policy assignments](img/B21076_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 – Policy assignments
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the **Assign policy** button and fill in the information as outlined
    in the next screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.11 – Assign policy basics](img/B21076_03_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 – Assign policy basics
  prefs: []
  type: TYPE_NORMAL
- en: '**Scope** is the space where the policy is applied. You can set the scope as
    the management group, a subscription, or the resource group your resources exist
    in. I chose my subscription. If you want to exclude specific resources, you can
    set an exclusion here. Then, you can choose a policy definition. There are more
    than 1,000 in the portal; you can find more on GitHub or you can create your own.
    I chose a simple one that makes a tag required for all resources. If there is
    remediation available, you can set this up on the **Remediation** tab. The one
    I chose does not have a remediation for previously created resources.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you don’t want to put more than the required settings, that is it! The assignment
    might take up to 15 minutes to become enabled, and then it is enforced at the
    scope you have set for all new resources.
  prefs: []
  type: TYPE_NORMAL
- en: For Azure Machine Learning there are several policies you can implement to ensure
    your resources are compliant. The two I would at least recommend enabling are
    the *Azure Machine Learning compute instances should be recreated to get the latest
    software updates*, so that your compute instances are always updated and secure
    with the latest operating system version and that compute should have idle shutdown
    enabled to prevent unwanted costs using the policy *Azure Machine Learning Compute
    Instance should have an idle shutdown*. The others are a little bit more scenario-specific
    and you can find the complete list in the following link.
  prefs: []
  type: TYPE_NORMAL
- en: Built-in policies for Azure Machine Learning
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the built-in policies for Azure Machine Learning in this table:
    [https://learn.microsoft.com/en-us/azure/governance/policy/samples/built-in-policies#machine-learning](https://learn.microsoft.com/en-us/azure/governance/policy/samples/built-in-policies#machine-learning)'
  prefs: []
  type: TYPE_NORMAL
- en: The fact that the preceding policies apply to Azure Machine Learning specifically
    does not mean that these are the only ones we can use to adhere to a compliance
    framework. As Azure Machine Learning uses multiple associated services to work,
    it is worth looking into policies for Azure Container registries, Azure Kubernetes
    services, databases in Azure we use, and so on. If the policy does not cover what
    we want to do, we can create a custom one or find more on GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: The Azure Policy service integrates with **Azure Resource Manager** (**ARM**),
    the **Azure portal**, **Azure DevOps**, and other Azure services, enabling you
    to enforce policies during resource creation, deployment, and ongoing management.
    Additionally, Azure Policy can be leveraged based on condition by using the **Azure
    Active Directory Conditional Access** features. In this section, we will explore
    industry standards and policies that apply to Azure ML specifically and use them
    to create a security baseline.
  prefs: []
  type: TYPE_NORMAL
- en: Azure compliance documentation
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find details and reports for all Azure compliance offerings here: [https://learn.microsoft.com/azure/compliance/](https://learn.microsoft.com/azure/compliance/).'
  prefs: []
  type: TYPE_NORMAL
- en: Azure Security Benchmark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Azure Security Benchmark** (**ASB**) is a set of recommendations based
    on industry standards that guide you on how you can secure your cloud solutions
    on Azure. The ASB contains policies and recommendations across all Azure services.
    That includes security and compliance standards. If you want to see each service
    and how you can apply the ASB recommendations, you can find ASB mapping files
    in the documentation. For Azure ML, we will take into consideration the network
    security and data protection controls.
  prefs: []
  type: TYPE_NORMAL
- en: Federal Risk and Authorization Management Program
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Federal Risk and Authorization Management Program** (**FedRAMP**) is the
    federal government’s approach to cloud service offerings suggested by the United
    States government. If your organization or your customer is located in the United
    States, you should really take into account those regulations to be compliant
    with relevant laws. The fact that this is suggested by the United States government
    does not mean that you cannot use it to secure Azure Machine Learning workloads
    in other locations.
  prefs: []
  type: TYPE_NORMAL
- en: 'FedRAMP in Azure includes two levels of protection: FedRAMP High and FedRAMP
    Moderate. The high impact level is usually for systems such as law enforcement,
    emergency services, healthcare, or finance, where the integrity, confidentiality,
    and security of systems will have catastrophic effects on the operations of the
    organization. The moderate impact level accounts for most cloud systems, which
    can have serious effects, but they’re not in an industry where data and operations
    are extremely sensitive. For Azure Machine Learning, we will use the **Access
    Control** and **System & Communications Protection** controls. Although those
    controls exist because of this approach, they are valid and can help you secure
    your workloads in any location or type. Throughout this book, we are going to
    include the best practices from multiple industry standards, including FedRAMP.'
  prefs: []
  type: TYPE_NORMAL
- en: New Zealand Information Security Manual (restricted)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **New Zealand Information Security Manual** (**NZISM**) is the New Zealand
    government’s guidelines for information assurance and system security. Although
    the NZISM is intended for use by New Zealand government agencies and organizations,
    it contains multiple controls that are especially important for Azure Machine
    Learning as they apply to Azure infrastructure and cryptography.
  prefs: []
  type: TYPE_NORMAL
- en: NIST SP 800-53 Rev. 5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NIST has proposed several controls, especially about security, ranging from
    low-impact, moderate-impact, high-impact, and privacy controls. The *NIST SP 800-53*
    database contains control assessment procedures and baselines for security and
    privacy controls for information systems and organizations. You can find all the
    information under the NIST RMF. With this compliance standard, we will acquire
    the knowledge to implement controls in Azure ML pertaining to access control,
    system protection, and communication security.
  prefs: []
  type: TYPE_NORMAL
- en: Reserve Bank of India IT Framework for Banks v2016
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some controls created under the Azure policy compliance for the **Reserve Bank
    of India IT Framework for Banks** can also be used to secure Azure Machine Learning
    workloads. Although this standard is about a very specific domain, it contains
    controls about metrics, advanced real-time threat defense and management, patch/vulnerability
    and change management, and anti-phishing controls that are especially useful for
    Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: All the preceding compliance standards and their policies are built in with
    the Azure platform, so it is easy to leverage them to create our security baseline,
    and you will see that many of those policies can overlap as they are part of many
    different approaches and standards. Of course, if you want, you can always create
    your own policies that apply to your individual industry or organizational procedures
    on top of those, but in this book, we will focus on constructing a solid basis
    for you to build on.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance auditing and reporting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just by using the Azure Policy service, you have access to the **Compliance**
    and **Remediation** blades, which you can use to monitor your compliance status
    for free for Azure resources. All you need is an active Azure subscription. Be
    careful, as there might be costs associated if you enable Azure Policy to an Arc
    resource. In that case, you can visit the Azure pricing calculator to see associated
    costs.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance auditing is the process of evaluating an organization’s adherence
    to relevant laws, regulations, policies, and industry standards. It usually involves
    a complete inspection of an organization’s practices, procedures, and controls
    to ensure they align with the established requirements. Compliance audits can
    be conducted by internal or external auditors, who must be independent of the
    processes being audited. Internal audits and compliance audits seem to have similar
    steps; however, they are very different, as compliance audits focus on whether
    the organization is compliant with all relevant laws, rules, and regulations and
    not financial or operational systems.
  prefs: []
  type: TYPE_NORMAL
- en: The auditing process involves many steps. The first is setting the scope. The
    audit scope defines the specific regulations, laws, standards, or policies that
    need to be assessed and are specific to the company location or industry. Then,
    there is the compliance assessment, where we assess where we are by analyzing
    processes, controls, and reports to determine if the organization is following
    the prescribed procedures. If the auditor identifies areas of non-compliance and
    potential risks that could impact the organization’s operations or reputation,
    they evaluate the severity and likelihood of these risks and then prioritize recommendations
    based on their assessment. These recommendations may include implementing new
    controls, revising policies and procedures, conducting employee training, or enhancing
    monitoring processes. At the end of the audit, a report is created with all the
    results to be shared with the appropriate stakeholders. Organizations are responsible
    for addressing and correcting the issues, sometimes within the auditing period,
    and ensuring that they monitor compliance so that they remediate issues in the
    future.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance auditing plays a crucial role in helping organizations maintain legal
    and regulatory compliance, mitigate risks, and demonstrate accountability to stakeholders.
    It assists in identifying and addressing areas of non-compliance before they lead
    to legal violations, financial losses, or reputational damage.
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish this in Azure together with Azure Policy, we have several tools
    available with which we can monitor and extract reports to demonstrate compliance
    with our services. Let us see some of them and how to use them for reporting.
  prefs: []
  type: TYPE_NORMAL
- en: Azure portal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can start by opening the Azure Policy service in the Azure portal. You
    don’t need to create a new resource for this; it is already part of your subscription.
    All you need to do is open the portal and search in the top box for `policy`,
    as we saw previously in this chapter. As soon as you open the **Policy** menu,
    you will see something similar to the next screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.12 – Azure Policy Overview blade in the Azure portal](img/B21076_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 – Azure Policy Overview blade in the Azure portal
  prefs: []
  type: TYPE_NORMAL
- en: Either from the **Overview** blade or the **Compliance** blade, you can see
    which policies you currently have assigned and which resources in your subscription
    are compliant or not. These are both in table form, and you can also see several
    graphs, as shown in the previous screenshot, to give you a quick look at the compliance
    percentage of your resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a great report as it gives you a summary of the information straight
    away. By clicking on a policy or an initiative assignment, you can see more information
    about the policy, view non-compliant resources, and create remediation tasks or
    exceptions, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.13 – Azure Policy assignment details using the portal](img/B21076_03_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.13 – Azure Policy assignment details using the portal
  prefs: []
  type: TYPE_NORMAL
- en: Note on the top how many options you have without leaving the reporting page.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Resource Graph Explorer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Azure Resource Graph Explorer** is a powerful service that gives you the
    ability to explore, query, and analyze your Azure resources and their properties
    quickly and efficiently. It’s a very scalable way to retrieve information and
    get insights. You can create Azure Resource Graph Explorer queries with **Kusto
    Query Language** (**KQL**) to get information about the policies in your environment.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us see how we can run a simple query and extract reports:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started, open Azure Resource Graph Explorer by typing the name in the
    top search bar, shown as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.14 – Opening Azure Resource Graph Explorer](img/B21076_03_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.14 – Opening Azure Resource Graph Explorer
  prefs: []
  type: TYPE_NORMAL
- en: 'At the bottom of the page, under `policy`, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.15 – Searching the query templates for policy-related queries](img/B21076_03_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.15 – Searching the query templates for policy-related queries
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the leftmost query. You will get the active policy assignments for your
    subscription:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.16 – Running a query in Azure Resource Graph Explorer](img/B21076_03_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.16 – Running a query in Azure Resource Graph Explorer
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can use KQL to tailor the results and the columns to the information
    you want, export the data as a `.csv` file, or pin the table to an Azure dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: KQL reference
  prefs: []
  type: TYPE_NORMAL
- en: 'If this is the first time you’ve heard about KQL, you can get started with
    KQL queries here as we will need it in the following chapters as well: [https://learn.microsoft.com/en-us/azure/data-explorer/kql-quick-reference](https://learn.microsoft.com/en-us/azure/data-explorer/kql-quick-reference).'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, there are other ways to access the compliance information generated
    by your policy and initiative assignments. We can use command-line scripting,
    the **Azure REST API**, and **Azure Monitor Logs**. Policy evaluation and enforcement
    reporting is real-time. As soon as each policy is enabled in your Azure subscription,
    any resource that is to be created is evaluated before the process is allowed
    to proceed.
  prefs: []
  type: TYPE_NORMAL
- en: You can integrate Azure Policy assignments with other services as well, such
    as Event Grid, or create alerts so that you get notified about your resources.
    Azure Policy works great with Azure Defender for Cloud, whereby you can actually
    see the compliance state of your resources based on the industry compliance standards
    we outlined here. However, we will talk more about those dashboards and tools
    later in this book when we tackle all the logging and monitoring techniques in
    Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Understandably, handling everything manually can create some administrative
    overhead. In the next section, we will explore how to automate some of those processes.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance automation in Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in the previous section, following the built-in compliance standards
    and enforcing policies in our resources is relatively easy. However, it is rare
    that we have only one resource or one subscription to apply those policies to.
    Usually, we will go through creating development environments and then deploying
    them again as production environments, and sometimes, we even maintain both with
    similar policies and enforcement rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recreating a development environment in Azure is easy as there are several
    ways to replicate resources between resource groups or subscriptions by using,
    for example, ARM templates and command-line scripts. However, ARM templates are
    only used to describe one or multiple related resources. Role assignments from
    **role-based access control** (**RBAC**) and policies must be recreated and reassigned
    to each subscription, resource group, or resource. In this case, we have another
    service that helps us recreate environments in Azure: **Azure Blueprints** and
    **Infrastructure as** **Code** (**IaC**).'
  prefs: []
  type: TYPE_NORMAL
- en: Let us discuss both in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Blueprints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While **ARM templates** in Azure Policy need to be deployed or assigned every
    time you need something implemented, the Azure Blueprints service leverages role
    assignments, policy assignments, ARM templates, and resource groups to replicate
    or recreate a complete environment, preserving resources and governance. Pretty
    much everything you accomplish with Azure blueprints you can also accomplish with
    Azure ARM templates. The difference is that ARM templates deploy one or more resources.
    Azure blueprints preserve the relationship between what should be deployed, the
    template and the blueprint assignment, policies, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'How that works is by creating a blueprint definition. A blueprint definition
    is composed of artifacts—specifically, resource groups, ARM templates, policy
    assignments, and role assignments that target a subscription or management group.
    Artifacts can also be parametric. To create a blueprint, you only need to follow
    two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to assign **Blueprint name** and **Definition location** values,
    which would be the subscription you want this blueprint applied to. This is shown
    in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.17 – Creating blueprint basic details](img/B21076_03_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.17 – Creating blueprint basic details
  prefs: []
  type: TYPE_NORMAL
- en: 'You need to declare artifacts and their parameters. Artifacts are resource
    groups, resource templates, RBAC assignments, and policies. Refer to the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.18 – Adding artifacts](img/B21076_03_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.18 – Adding artifacts
  prefs: []
  type: TYPE_NORMAL
- en: While you are working with a blueprint, its mode is set to **Draft**. When you
    are ready to apply it, you need to publish the blueprint, and it is set as **Published**.
    Each blueprint you publish has a version number. We use the version to differentiate
    it from future changes to the same blueprint. If you want to make a change to
    a blueprint, the only thing you need to do is create a new version with any changes
    you would like and then apply it to the same subscription or management group.
  prefs: []
  type: TYPE_NORMAL
- en: IaC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The portal and the command-line tools are not the only way to deploy services
    in Azure. We can also leverage IaC as well as **DevOps** practices to ensure alignment
    of your environments, roles, and policies across subscriptions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Governance** through IaC on Azure refers to the practice of managing and
    governing Azure resources and configurations using code-based declarative templates.
    Azure provides tools and services that enable you to implement IaC for efficient
    and consistent management of its cloud infrastructure.'
  prefs: []
  type: TYPE_NORMAL
- en: You can integrate IaC with version control and collaboration features, and you
    can also leverage continuous deployment and automation by integrating IaC with
    CI/CD pipelines. By integrating DevOps, you can automate the deployment, testing,
    and validation of any infrastructure changes.
  prefs: []
  type: TYPE_NORMAL
- en: Azure provides monitoring and auditing capabilities that can be leveraged with
    IaC. You can leverage and analyze logs and telemetry data so that you can monitor,
    and audit changes made to your infrastructure. This ensures compliance and governance
    in Azure. We will see how to leverage IaC and DevOps in ML (or, as we call it,
    **MLOps**) later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to develop AI systems responsibly and how to
    develop an ethical approach using Responsible AI tools. We became familiar with
    the industry security standards and learned how to enforce them using the Azure
    Policy service. Reporting and automation for regulatory compliance were never
    easier as there are a lot of tools we can use to help us view and maintain the
    compliance status of our services. For reporting and auditing, we have the **Compliance**
    and **Remediation** blades in Azure Policy, Azure Resource Graph Explorer, and
    command-line tools. To automate environment creation, we can leverage the Azure
    Blueprints service and IaC.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a strategy and some knowledge of multiple security standards
    available out of the box, let us see how we can implement all those controls and
    guardrails in our Azure environment. As always when it comes to ML, we will start
    with the data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explain data governance and how to securely store,
    transmit, back up, and restore data used in our ML projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 2: Securing Your Data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning is based on data, so it is our priority to secure them. In
    this part, you will learn how to develop a data governance program and then how
    to secure data during storage and transfer. You will also learn how to work with
    backup and recovery services and how to identify and protect sensitive information
    and interpret ML models. Finally, you will explore best practices that use federated
    learning and secure multi-party computation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B21076_04.xhtml#_idTextAnchor096)*, Data Protection and Governance*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B21076_05.xhtml#_idTextAnchor115)*, Data Privacy and Responsible
    AI Best Practices*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
