- en: Chapter 4. Counting the Pixels with Histograms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Computing the image histogram
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying look-up tables to modify the image appearance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equalizing the image histogram
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backprojecting a histogram to detect the specific image content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the mean shift algorithm to find an object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieving similar images using the histogram comparison
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Counting pixels with integral images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An image is composed of pixels of different values (colors). The distribution
    of pixel values across an image constitutes an important characteristic of that
    image. This chapter introduces the concept of image histograms. You will learn
    how to compute a histogram and how to use it to modify an image's appearance.
    Histograms can also be used to characterize an image's content and detect specific
    objects or textures in an image. Some of these techniques will be presented in
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Computing the image histogram
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An image is made of pixels, and each of them have different values. For example,
    in a 1-channel gray-level image, each pixel has a value between 0 (black) and
    255 (white). Depending on the picture content, you will find different amounts
    of each gray shade laid out inside the image.
  prefs: []
  type: TYPE_NORMAL
- en: A **histogram** is a simple table that gives you the number of pixels that have
    a given value in an image (or sometimes, a set of images). The histogram of a
    gray-level image will, therefore, have 256 entries (or **bins**). Bin 0 gives
    you the number of pixels that have the value 0, bin 1 gives you the number of
    pixels that have the value 1, and so on. Obviously, if you sum all of the entries
    of a histogram, you should get the total number of pixels. Histograms can also
    be normalized such that the sum of the bins equals 1\. In this case, each bin
    gives you the percentage of pixels that have this specific value in the image.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first three recipes of this chapter will use the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting started](img/00029.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Computing a histogram with OpenCV can be easily done by using the `cv::calcHist`
    function. This is a general function that can compute the histogram of multiple
    channel images of any pixel value type and range. Here, we will make this simpler
    to use by specializing a class for the case of 1-channel gray-level images. For
    other types of images, you can always directly use the `cv::calcHist` function,
    which offers you all the flexibility required. The next section will explain each
    of its parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, our specialized class looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'With the defined member variables, computing a gray-level histogram can then
    be accomplished using the following method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, your program simply needs to open an image, create a `Histogram1D` instance,
    and call the `getHistogram` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The `histo` object here is a simple one-dimensional array with `256` entries.
    Therefore, you can read each bin by simply looping over this array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'With the image shown at the start of this chapter, some of the displayed values
    would read as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'It is obviously difficult to extract any intuitive meaning from this sequence
    of values. For this reason, it is often convenient to display a histogram as a
    function, for example, using bar graphs. The following methods create such a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `getImageOfHistogram` method, you can obtain an image of the histogram
    function in the form of a bar graph that is drawn using lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00030.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'From the preceding histogram, it can be seen that the image exhibits a large
    peak of mid-gray level values and a good quantity of darker pixels. Coincidentally,
    these two groups mostly correspond to, respectively, the background and foreground
    of the image. This can be verified by thresholding the image at the transition
    between these two groups. A convenient OpenCV function can be used for this, namely
    the `cv::threshold` function that was introduced in the previous chapter. Here,
    to create our binary image, we threshold the image at the minimum value just before
    it increases toward the high peak of the histogram (gray value `60`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting binary image clearly shows you the background/foreground segmentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00031.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `cv::calcHist` function has many parameters to permit its use in many contexts,
    which are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Most of the time, your histogram will be one of a single 1-channel or 3-channel
    image. However, the function allows you to specify a multiple-channel image distributed
    over several images. This is why an array of images is input into this function.
    The sixth parameter, `dims`, specifies the dimensionality of the histogram, for
    example, 1 for a 1D histogram. Even if you are analyzing a multichannel image,
    you do not have to use all its channels in the computation of the histogram. The
    channels to be considered are listed in the `channel` array that has the specified
    dimensionality. In our class implementation, this single channel is the channel
    0 by default. The histogram itself is described by the number of bins in each
    dimension (this is the `histSize` array of integers) and by the minimum (inclusive)
    and maximum (exclusive) values in each dimension (given by the `ranges` array
    of 2-element arrays). It is also possible to define a non-uniform histogram; in
    which case, you need to specify the limits of each bin.
  prefs: []
  type: TYPE_NORMAL
- en: As with many OpenCV functions, a mask can be specified, indicating which pixels
    you want to include in the count (all pixels for which the mask value is 0 are
    then ignored). Two additional optional parameters can be specified, both of which
    are Boolean values. The first one indicates whether the histogram is uniform or
    not (uniform is the default). The second allows you to accumulate the result of
    several histogram computations. If this last parameter is true, then the pixel
    count of the image will be added to the current values found in the input histogram.
    This is useful when you want to compute the histogram of a group of images.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting histogram is stored in a `cv::Mat` instance. Indeed, the `cv::Mat`
    class can be used to manipulate general N-dimensional matrices. Recall from [Chapter
    2](part0019_split_000.html#page "Chapter 2. Manipulating Pixels"), *Manipulating
    Pixels*, that this class has defined the `at` method for matrices of dimension
    1, 2, and 3\. This is why we were able to write the following code when accessing
    each bin of the 1D histogram in the `getHistogramImage` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note that the values in the histogram are stored as `float` values.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Histogram1D` class presented in this recipe has simplified the `cv::calcHist`
    function by restricting it to a 1D histogram. This is useful for gray-level images,
    but what about color images?
  prefs: []
  type: TYPE_NORMAL
- en: Computing histograms of color images
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using the same `cv::calcHist` function, we can compute histograms of multichannel
    images. For example, a class that computes histograms of color BGR images can
    be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the histogram will be three-dimensional. Therefore, we need to
    specify a range for each of the three dimensions. In the case of our BGR image,
    the three channels have the same `[0,255]` range. With the arguments thus prepared,
    the color histogram is computed by the following method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'A three-dimensional `cv::Mat` instance is returned. When a histogram of `256`
    bins is selected, this matrix has `(256)^3` elements, which represents more than
    16 million entries. In many applications, it would be better to reduce the number
    of bins in the computation of the histogram. It is also possible to use the `cv::SparseMat`
    data structure that is designed to represent large sparse matrices (that is, matrices
    with very few nonzero elements) without consuming too much memory. The `cv::calcHist`
    function has a version that returns one such matrix. It is, therefore, simple
    to modify the previous method in order to use `cv::SparseMatrix`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Obviously, it is also possible to illustrate the color distribution in an image
    by showing the individual R, G, and B histograms.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Backprojecting a histogram to detect specific image content* recipe later
    in this chapter makes use of color histograms in order to detect specific image
    content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying look-up tables to modify the image appearance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image histograms capture the way a scene is rendered using the available pixel
    intensity values. By analyzing the distribution of the pixel values over an image,
    it is possible to use this information to modify and possibly improve an image.
    This recipe explains how we can use a simple mapping function, represented by
    a look-up table, to modify the pixel values of an image. As we will see, look-up
    tables are often defined from histogram distributions.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A **look-up table** is a simple one-to-one (or many-to-one) function that defines
    how pixel values are transformed into new values. It is a 1D array with, in the
    case of regular gray-level images, 256 entries. Entry `i` of the table gives you
    the new intensity value of the corresponding gray level, which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cv::LUT` function in OpenCV applies a look-up table to an image in order
    to produce a new image. We can add this function to our `Histogram1D` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When a look-up table is applied on an image, it results in a new image where
    the pixel intensity values have been modified as prescribed by the look-up table.
    A simple transformation could be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This transformation simply inverts the pixel intensities, that is, intensity
    `0` becomes `255`, `1` becomes `254`, and so on. Applying such a look-up table
    on an image will produce the negative of the original image. On the image of the
    previous recipe, the result is seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00032.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look-up tables are useful for any application in which all pixel intensities
    are given a new intensity value. The transformation, however, has to be global,
    that is, all pixels of each intensity value must undergo the same transformation.
  prefs: []
  type: TYPE_NORMAL
- en: Stretching a histogram to improve the image contrast
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is possible to improve an image's contrast by defining a look-up table that
    modifies the original image's histogram. For example, if you observe the histogram
    of the previous image shown in the first recipe, it is easy to notice that the
    full range of possible intensity values is not used (in particular, for this image,
    the brighter intensity values have not been used). We can, therefore, stretch
    the histogram in order to produce an image with an expanded contrast. To do so,
    the procedure uses a percentile threshold that defines the percentage of pixels
    that should be black and white in the stretched image.
  prefs: []
  type: TYPE_NORMAL
- en: 'We must, therefore, find the lowest (`imin`) and the highest (`imax`) intensity
    values such that we have the required minimum number of pixels below or above
    the specified percentile. The intensity values can then be remapped such that
    the `imin` value is repositioned at intensity `0` and the `imax` value is assigned
    the value of `255`. The in-between `i` intensities are simply linearly remapped
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Consequently, the complete image stretch method would look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Note the call to our `applyLookUp` method once this method has been computed.
    Also, in practice, it could be advantageous to not only ignore bins with the `0`
    value, but also entries with negligible count, for example, less than a given
    value (defined here as `minValue`). The method is called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting stretched image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stretching a histogram to improve the image contrast](img/00033.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The expanded histogram then looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stretching a histogram to improve the image contrast](img/00034.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Applying a look-up table on color images
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In [Chapter 2](part0019_split_000.html#page "Chapter 2. Manipulating Pixels"),
    *Manipulating Pixels*, we defined a color-reduction function that modifies the
    BGR values of an image in order to reduce the number of possible colors. We did
    this by looping through the image''s pixels and applying the color-reduction function
    on each of them. In fact, it would be much more efficient to precompute all color
    reductions and then modify each pixel by using a look-up table. This is indeed
    very easy to accomplish from what we learned in this recipe. The new color-reduction
    function would then be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The color-reduction scheme is correctly applied here because when a one-dimensional
    look-up table is applied to a multichannel image, then the same table is individually
    applied to all channels. When a look-up table has more than one dimension, then
    it must be applied to an image with the same number of channels.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next recipe shows you another way to improve the image contrast
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equalizing the image histogram
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, we showed you how the contrast of an image can be improved
    by stretching a histogram so that it occupies the full range of the available
    intensity values. This strategy indeed constitutes an easy fix that can effectively
    improve an image. However, in many cases, the visual deficiency of an image is
    not that it uses a too-narrow range of intensities. Rather, it is that some intensity
    values are used more frequently than others. The histogram shown in the first
    recipe of this chapter is a good example of this phenomenon. The middle-gray intensities
    are indeed heavily represented, while darker and brighter pixel values are rather
    rare. In fact, you would think that a good-quality image should make equal use
    of all available pixel intensities. This is the idea behind the concept of **histogram
    equalization**, that is, making the image histogram as flat as possible.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'OpenCV offers an easy-to-use function that performs histogram equalization.
    It is called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'After applying it on our image, the following screenshot is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00035.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This equalized image has the following histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00036.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Of course, the histogram cannot be perfectly flat because the look-up table
    is a global many-to-one transformation. However, it can be seen that the general
    distribution of the histogram is now more uniform than the original one.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In a perfectly uniform histogram, all bins would have an equal number of pixels.
    This implies that 50 percent of the pixels should have an intensity lower than
    `128`, 25 percent should have an intensity lower than `64`, and so on. This observation
    can be expressed using the rule that in a uniform histogram, *p%* of the pixels
    must have an intensity value lower than or equal to *255*p%*. The rule used to
    equalize a histogram is that the mapping of intensity `i` should be at the intensity
    that corresponds to the percentage of pixels that have an intensity value below
    `i`. Therefore, the required look-up table can be built from the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here, `p[i]` is the number of pixels that have an intensity lower than or equal
    to `i`. The `p[i]` function is often referred to as a **cumulative histogram**,
    that is, it is a histogram that contains the count of pixels lower than or equal
    to a given intensity instead of containing the count of pixels that have a specific
    intensity value. Recall that `image.total()` returns the number of pixels in an
    image, so `p[i]/image.total()` is a percentage of pixels.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, the histogram equalization greatly improves the image's appearance.
    However, depending on the visual content, the quality of the result can vary from
    image to image.
  prefs: []
  type: TYPE_NORMAL
- en: Backprojecting a histogram to detect specific image content
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A histogram is an important characteristic of an image's content. If you look
    at an image area that shows a particular texture or a particular object, then
    the histogram of this area can be seen as a function that gives the probability
    that a given pixel belongs to this specific texture or object. In this recipe,
    you will learn how the concept of **histogram backprojection** can be advantageously
    used to detect specific image content.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Suppose you have an image and you wish to detect specific content inside it
    (for example, in the following image, the clouds in the sky). The first thing
    to do is to select a region of interest that contains a sample of what you are
    looking for. This region is the one inside the rectangle drawn on the following
    test image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00037.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In our program, the region of interest is obtained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'You then extract the histogram of this ROI. This is easily accomplished using
    the `Histogram1D` class defined in the first recipe of this chapter as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'By normalizing this histogram, we obtain a function that gives us the probability
    that a pixel of a given intensity value belongs to the defined area as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Backprojecting a histogram consists of replacing each pixel value in an input
    image with its corresponding probability value read in the normalized histogram.
    An OpenCV function performs this task as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is the following probability map, with probabilities belonging to
    the reference area ranging from bright (low probability) to dark (high probability):'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00038.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'If we apply a threshold on this image, we obtain the most probable "cloud"
    pixels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00039.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The preceding result is disappointing because, in addition to the clouds, other
    areas have been wrongly detected as well. It is important to understand that the
    probability function has been extracted from a simple gray-level histogram. Many
    other pixels in the image share the same intensities as the cloud pixels, and
    pixels of the same intensity are replaced with the same probability value when
    backprojecting the histogram. One solution to improve the detection result would
    be to use the color information. However, in order to do this, we need to modify
    the call to `cv::calBackProject`.
  prefs: []
  type: TYPE_NORMAL
- en: The `cv::calBackProject` function is similar to the `cv::calcHist` function.
    The first parameter specifies the input image. You then need to list the channel
    numbers you wish to use. The histogram that is passed to the function is, this
    time, an input parameter; its dimension should match the one of the channel list
    array. As with `cv::calcHist`, the `ranges` parameter specifies the bin boundaries
    of the input histogram in the form of an array of float arrays, each specifying
    the range (minimum and maximum values) of each channel. The resulting output is
    an image, which is the computed probability map. Since each pixel is replaced
    by the value found in the histogram at the corresponding bin position, the resulting
    image has values between `0.0` and `1.0` (assuming a normalized histogram has
    been provided as input). A last parameter allows you to optionally rescale these
    values by multiplying them by a given factor.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's now see how we can use the color information in the histogram backprojection
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Backprojecting color histograms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Multidimensional histograms can also be backprojected onto an image. Let''s
    define a class that encapsulates the backprojection process. We first define the
    required attributes and initialize the data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define a threshold parameter that will be used to create the binary
    map that shows the detection result. If this parameter is set to a negative value,
    the raw probability map will be returned. Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The input histogram is normalized (this is, however, not required) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'To backproject the histogram, you simply need to specify the image, the range
    (we assumed here that all channels have the same range), and the list of channels
    used. Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now use a BGR histogram on the color version of the image we used previously
    (see the book''s website to see this image in color). This time, we will try to
    detect the blue sky area. We will first load the color image, define the region
    of interest, and compute the 3D histogram on a reduced color space as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you compute the histogram and use the `find` method to detect the sky
    portion of the image as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the detection on the color version of the image in the previous
    section is seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Backprojecting color histograms](img/00040.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The BGR color space is generally not the best one to identify color objects
    in an image. Here, to make it more reliable, we reduced the number of colors before
    computing the histogram (remember that the original BGR space counts more than
    16 million colors). The histogram extracted represents the typical color distribution
    for a sky area. Try to backproject it on another image. It should also detect
    the sky portion. Note that using a histogram built from multiple sky images should
    increase the accuracy of this detection.
  prefs: []
  type: TYPE_NORMAL
- en: Note that in this case, computing a sparse histogram would have been better
    in terms of memory usage. You should be able to redo this exercise using `cv::SparseMat`
    this time. Also, if you are looking for a bright-colored object, using the hue
    channel of the HSV color space would probably be more efficient. In other cases,
    the use of the chromaticity components of a perceptually uniform space (such as
    *L*a*b**) might constitute a better choice.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next recipe uses the HSV color space to detect an object in an image. This
    is one of the many alternative solutions you can use in the detection of some
    image content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the mean shift algorithm to find an object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The result of a histogram backprojection is a probability map that expresses
    the probability that a given piece of image content is found at a specific image
    location. Suppose we now know the approximate location of an object in an image;
    the probability map can be used to find the exact location of the object. The
    most probable location will be the one that maximizes this probability inside
    a given window. Therefore, if we start from an initial location and iteratively
    move around, it should be possible to find the exact object location. This is
    what is accomplished by the **mean shift algorithm**.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Suppose we have identified an object of interest—here, a baboon''s face—as
    shown in the following screenshot (refer to the book''s graphics PDF to view this
    image in color):'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00041.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This time, we will describe this object by using the hue channel of the HSV
    color space. This means that we need to convert the image into an HSV one and
    then extract the hue channel and compute the 1D hue histogram of the defined ROI.
    Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'As can be seen, the hue histogram is obtained using a convenient method that
    we have added to our `ColorHistogram` class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting histogram is then passed to our `ContentFinder` class instance
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now open a second image where we want to locate the new baboon''s face
    position. This image needs to be converted to the HSV space first, and then we
    backproject the histogram of the first image. Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, from an initial rectangular area (that is, the position of the baboon''s
    face in the initial image), the `cv::meanShift` algorithm of OpenCV will update
    the `rect` object at the new baboon''s face location. Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The initial (red) and new (green) face locations are displayed in the following
    screenshot (refer to the book''s graphics PDF to view this image in color):'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00042.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this example, we used the hue component of the HSV color space in order to
    characterize the object we were looking for. We made this choice because the baboon's
    face has a very distinctive pink color; consequently, the pixels' hue should make
    the face easily identifiable. The first step, therefore, is to convert the image
    to the HSV color space. The hue component is the first channel of the resulting
    image when the `CV_BGR2HSV` flag is used. This is an 8-bit component that varies
    from `0` to `180` (with `cv::cvtColor`, the converted image is of the same type
    as the source image). In order to extract the hue image, the 3-channel HSV image
    is split into three 1-channel images using the `cv::split` function. The three
    images are put into a `std::vector` instance, and the hue image is the first entry
    of the vector (that is, at index `0`).
  prefs: []
  type: TYPE_NORMAL
- en: When using the hue component of a color, it is always important to take its
    saturation into account (which is the second entry of the vector). Indeed, when
    the saturation of a color is low, the hue information becomes unstable and unreliable.
    This is due to the fact that for low-saturated color, the B, G, and R components
    are almost equal. This makes it difficult to determine the exact color that is
    represented. Consequently, we decided to ignore the hue component of colors with
    low saturation. That is, they are not counted in the histogram (using the `minSat`
    parameter that masks out pixels with saturation below this threshold in the `getHueHistogram`
    method).
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean shift algorithm is an iterative procedure that locates the local maxima
    of a probability function. It does this by finding the centroid, or weighted mean,
    of the data point inside a predefined window. The algorithm then moves the window
    center to the centroid location and repeats the procedure until the window center
    converges to a stable point. The OpenCV implementation defines two stopping criteria:
    a maximum number of iterations and a window center displacement value below which
    the position is considered to have converged to a stable point. These two criteria
    are stored in a `cv::TermCriteria` instance. The `cv::meanShift` function returns
    the number of iterations that have been performed. Obviously, the quality of the
    result depends on the quality of the probability map provided on the given initial
    position. Note that here, we used a histogram of colors to represent an image''s
    appearance; it is also possible to use histograms of other features to represent
    the object (for example, a histogram of edge orientation).'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The mean shift algorithm has been largely used for visual tracking. [Chapter
    11](part0072_split_000.html#page "Chapter 11. Processing Video Sequences"), *Processing
    Video Sequences*, will explore the problem of object tracking in more detail
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The mean shift algorithm has been introduced in the article *Mean Shift: A
    robust approach toward feature space analysis* by *D. Comaniciu and P. Meer* in
    *IEEE transactions on Pattern Analysis and Machine Intelligence, volume 24, number
    5, May 2002*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenCV also offers an implementation of the CamShift algorithm, which is an
    improved version of the mean shift algorithm in which the size and the orientation
    of the window can change.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieving similar images using the histogram comparison
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Content-based image retrieval is an important problem in computer vision. It
    consists of finding a set of images that present content that is similar to a
    given query image. Since we have learned that histograms constitute an effective
    way to characterize an image's content, it makes sense to think that they can
    be used to solve the content-based retrieval problem.
  prefs: []
  type: TYPE_NORMAL
- en: The key here is to be able to measure the similarity between two images by simply
    comparing their histograms. A measurement function that will estimate how different,
    or how similar, two histograms are will need to be defined. Various such measures
    have been proposed in the past, and OpenCV proposes a few of them in its implementation
    of the `cv::compareHist` function.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to compare a reference image with a collection of images and find
    the ones that are the most similar to this query image, we created an `ImageComparator`
    class. This class contains a reference to a query image and an input image, together
    with their histograms. In addition, since we will perform the comparison using
    color histograms, the `ColorHistogram` class is used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'To get a reliable similarity measure, the histogram should be computed over
    a reduced number of bins. Therefore, the class allows you to specify the number
    of bins to be used in each BGR channel. Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The query image is specified using an appropriate setter that also computes
    the reference histogram as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, a `compare` method compares the reference image with a given input
    image. The following method returns a score that indicates how similar the two
    images are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding class can be used to retrieve images that are similar to a given
    query image. The following code is initially provided to the class instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the query image we used is the color version of the beach image shown
    in the *Backprojecting a histogram to detect specific image content* recipe earlier
    in the chapter. This image was compared to the following series of images. The
    images are shown in order from the most similar to the least similar, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00043.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most histogram comparison measures are based on bin-by-bin comparisons. This
    is why it is important to work with a reduced number of histogram bins when measuring
    the similarity of two color histograms. The call to `cv::compareHist` is straightforward.
    You just input the two histograms and the function returns the measured distance.
    The specific measurement method you want to use is specified using a flag. In
    the `ImageComparator` class, the intersection method is used (with the `CV_COMP_INTERSECT`
    flag). This method simply compares, for each bin, the two values in each histogram
    and keeps the minimum one. The similarity measure, then, is the sum of these minimum
    values. Consequently, two images that have histograms with no colors in common
    would get an intersection value of `0`, while two identical histograms would get
    a value that is equal to the total number of pixels.
  prefs: []
  type: TYPE_NORMAL
- en: The other available methods are the Chi-Square measure (the `CV_COMP_CHISQR`
    flag) that sums the normalized square difference between the bins, the correlation
    method (the `CV_COMP_CORREL` flag) that is based on the normalized cross-correlation
    operator used in signal processing to measure the similarity between two signals,
    and the Bhattacharyya measure (the `CV_COMP_BHATTACHARYYA` flag) that is used
    in statistics to estimate the similarity between two probabilistic distributions.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The OpenCV documentation provides a description of the exact formulas used in
    the different histogram comparison measures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Earth Mover Distance is another popular histogram comparison method. It is implemented
    in OpenCV as the `cv::EMD` function. The main advantage of this method is that
    it takes into account the values found in adjacent bins to evaluate the similarity
    of two histograms. It is described in the article *The Earth Mover's Distance
    as a Metric for Image Retrieval* by *Y. Rubner, C. Tomasi, and L. J. Guibas in
    Int. Journal of Computer Vision, Volume 40, Number 2., 2000, pp. 99-121*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Counting pixels with integral images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous recipes, we learned that a histogram is computed by going through
    all the pixels of an image and cumulating a count of how often each intensity
    value occurs in this image. We have also seen that sometimes, we are only interested
    in computing our histogram in a certain area of the image. In fact, having to
    cumulate a sum of pixels inside an image''s subregion is a common task in many
    computer vision algorithms. Now, suppose you have to compute several such histograms
    over multiple regions of interest inside your image. All these computations could
    rapidly become very costly. In such a situation, there is a tool that can drastically
    improve the efficiency of counting pixels over image subregions: the **integral
    image**.'
  prefs: []
  type: TYPE_NORMAL
- en: Integral images have been introduced as an efficient way of summing pixels in
    image regions of interest. They are widely used in applications that involve,
    for example, computations over sliding windows at multiple scales.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe will explain the principle behind integral images. Our objective
    here is to show how pixels can be summed over a rectangle region by using only
    three arithmetic operations. Once we have learned this concept, the *There's more...*
    section of this recipe will show you two examples where integral images can be
    advantageously used.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This recipe will play with the following picture, in which a region of interest
    showing a girl on her bike is identified:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00044.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Integral images are useful when you need to sum pixels over several image areas.
    Normally, if you wish to get the sum of all pixels over a region of interest,
    you would write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The `cv::sum` function simply loops over all the pixels of the region and accumulates
    the sum. Using an integral image, this can be achieved using only three additive
    operations. However, first you need to compute the integral image as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'As will be explained in the next section, the same result can be obtained using
    this simple arithmetic expression on the computed integral image as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Both approaches give you the same result. However, computing the integral image
    is costly, since you have to loop over all the image pixels. The key is that once
    this initial computation is done, you will need to add only four pixels to get
    a sum over a region of interest no matter what the size of this region is. Integral
    images then become advantageous to use when multiple such pixel sums have to be
    computed over multiple regions of different sizes.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous section, you were introduced to the concept of integral images
    through a brief demonstration of the *magic* behind them, that is, how they can
    be used to cheaply compute the sum of pixels inside rectangular regions. To understand
    how they work, let''s now define what an integral image is. An integral image
    is obtained by replacing each pixel with the value of the sum of all the pixels
    located inside the upper-left quadrant delimitated by this pixel. The integral
    image can be computed by scanning the image once, as the integral value of a current
    pixel is given by the integral value of the previously discussed pixel plus the
    value of the cumulative sum of the current line. The integral image is therefore
    a new image containing pixel sums. To avoid overflows, this image is usually an
    image of `int` values (`CV_32S`) or float values (`CV_32F`). For example, in the
    following figure, pixel **A** in this integral image would contain the sum of
    the pixels contained inside the upper-left corner area, which is identified with
    a double-hatched pattern. Refer to the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00045.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the integral image has been computed, any summation over a rectangular
    region can be easily obtained through four pixel accesses, and here is why. Considering
    the preceding figure again, we can see that the sum of the pixels inside the region
    delimitated by the pixels **A**, **B**, **C**, and **D** can be obtained by reading
    the integral value at pixel **D**, from which you subtract the values of the pixels
    over **B** and to the left-hand side of **C**. However, by doing so, you have
    subtracted twice the sum of pixels located in the upper-left corner of **A**;
    this is why you have to re-add the integral sum at **A**. Formally, then, the
    sum of pixels inside **A**, **B**, **C**, and **D** is given by *A-B-C+D*. If
    we use the `cv::Mat` method to access pixel values, this formula translates to
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The complexity of this computation is, therefore, constant, no matter what the
    size of the region of interest is. Note that for simplicity, we used the `at`
    method of the `cv::Mat` class, which is not the most efficient way to access pixel
    values (see [Chapter 2](part0019_split_000.html#page "Chapter 2. Manipulating
    Pixels"), *Manipulating Pixels*). This aspect will be discussed in the *There's
    more...* section of this recipe, which presents two applications that benefit
    from the efficiency of the integral image concept.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Integral images are used whenever multiple pixel summations must be performed.
    In this section, we will illustrate the use of integral images by introducing
    the concept of adaptive thresholding. Integral images are also useful for the
    efficient computation of histograms over multiple windows. This is also explained
    in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive thresholding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Applying a threshold on an image in order to create a binary image could be
    a good way to extract the meaningful elements of an image. Suppose that you have
    the following image of a book:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adaptive thresholding](img/00046.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since you are interested in analyzing the text in this image, you apply a threshold
    to this image as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'You obtain the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adaptive thresholding](img/00047.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In fact, no matter what value you choose for the threshold, in some parts of
    the image, you get missing text, whereas in other parts, the text disappears under
    the shadow. To overcome this problem, one possible solution consists of using
    a local threshold that is computed from each pixel's neighborhood. This strategy
    is called **adaptive thresholding**, and it consists of comparing each pixel with
    the mean value of the neighboring pixels. Pixels that clearly differ from their
    local mean will then be considered as outliers and will be cut off by the thresholding
    process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adaptive thresholding, therefore, requires the computation of a local mean
    around every pixel. This requires multiple image window summations that can be
    computed efficiently through the integral image. Consequently, the first step
    is to compute the following integral image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can go through all the pixels and compute the mean over a square neighborhood.
    We could use our `IntegralImage` class to do so, but this one uses the inefficient
    `at` method for pixel access. This time, let''s get efficient by looping over
    the image using the pointers as we learned in [Chapter 2](part0019_split_000.html#page
    "Chapter 2. Manipulating Pixels"), *Manipulating Pixels*. This loop looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, a neighborhood of size 21 x 21 is used. To compute each mean,
    we need to access the four integral pixels that delimitate the square neighborhood:
    two located on the line pointed by `idata1` and two on the line pointed by `idata2`.
    The current pixel is compared to the computed mean, from which we subtract a threshold
    value (here, set to `10`); this is to make sure that rejected pixels clearly differ
    from their local mean. The following binary image is then obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adaptive thresholding](img/00048.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Clearly, this is a much better result than the one we got using a fixed threshold.
    Adaptive thresholding is a common image-processing technique. As such, it is also
    implemented in OpenCV as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This function call produces exactly the same result as the one we obtained using
    our integral image. In addition, instead of using the local mean for thresholding,
    this function allows you to use a Gaussian weighted sum (the method flag would
    be `ADAPTIVE_THRESH_GAUSSIAN_C`) in this case. It is interesting to note that
    our implementation is slightly faster than the `cv::adaptiveThreshold` call.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it is worth mentioning that we can also write an adaptive thresholding
    procedure by using the OpenCV image operators. This would be done as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Image filtering will be covered in [Chapter 6](part0047_split_000.html#page
    "Chapter 6. Filtering the Images"), *Filtering the Images*.
  prefs: []
  type: TYPE_NORMAL
- en: Visual tracking using histograms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we learned in the previous recipes, a histogram constitutes a reliable global
    representation of an object's appearance. In this recipe, we will demonstrate
    the usefulness of integral images by showing you how we can locate an object in
    an image by searching for an image area that presents a histogram similar to a
    target object. We accomplished this in the *Using the mean shift algorithm to
    find an object* recipe by using the concepts of histogram backprojection and local
    search through mean shift. This time, we will find our object by performing an
    explicit search for regions of similar histograms over the full image.
  prefs: []
  type: TYPE_NORMAL
- en: In the special case where an integral image is used on a binary image made of
    `0` and `1` values, the integral sum gives you the number of pixels that have
    a value of 1 inside the specified region. We will exploit this fact in this recipe
    to compute the histogram of a gray-level image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `cv::integral` function also works for multichannel images. You can take
    advantage of this fact to compute histograms of image subregions using integral
    images. You simply need to convert your image into a multichannel image made of
    binary planes; each of these planes is associated to a bin of your histogram and
    shows you which pixels have a value that falls into this bin. The following function
    creates such multiplane images from a gray-level one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The integral image computations can also be encapsulated into one convenient
    template class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We now want to find where the girl on the bicycle, whom we identified in the
    previous image, is in a subsequent image. Let''s first compute the histogram of
    the girl in the original image. We can accomplish this using the `Histogram1D`
    class we built in a previous recipe of this chapter. Here, we produce a 16-bin
    histogram as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The preceding histogram will be used as a referential representation to locate
    the target object (the girl on her bike) in a subsequent image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that the only information we have is that the girl is moving more or
    less horizontally over the image. Since we will have many histograms to compute
    at various locations, we compute the integral image as a preliminary step. Refer
    to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'To perform the search, we loop over a range of possible locations and compare
    the current histogram with the referential one. Our goal is to find the location
    with the most similar histogram. Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The location with the most similar histogram is then identified as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visual tracking using histograms](img/00049.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The white rectangle represents the search area. Histograms of all windows that
    fit inside this area have been computed. We kept the window size constant, but
    it could have been a good strategy to also search for slightly smaller or larger
    windows in order to take into account the eventual changes in scale. Note that
    in order to limit the complexity of this computation, the number of bins in the
    histograms to be computed should be kept low. In our example, we reduced this
    to `16` bins. Consequently, plane `0` of this multiplane image contains a binary
    image that shows you all pixels that have a value between `0` and `15`, while
    plane `1` shows you pixels with values between `16` and `31`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The search for an object consisted of computing the histograms of all windows
    of the given size over a predetermined range of pixels. This represents the computation
    of `3200` different histograms that have been efficiently computed from our integral
    image. All the histograms returned by our `IntegralImage` class are contained
    in a `cv::Vec` object (because of the use of the `at` method). We then use the
    `cv::compareHist` function to identify the most similar histogram (remember that
    this function, like most OpenCV functions, can accept either the `cv::Mat` or
    `cv::Vec` object through the convenient `cv::InputArray` generic parameter type).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Chapter 8](part0058_split_000.html#page "Chapter 8. Detecting Interest Points"),
    *Detecting Interest Points*, will present the `SURF` operator that also relies
    on the use of integral images'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The article *Robust Fragments-based Tracking using the Integral Histogram* by
    *A. Adam, E. Rivlin, and I. Shimshoni in the proceedings of the Int. Conference
    on Computer Vision and Pattern Recognition, 2006, pp. 798-805*, describes an interesting
    approach that uses integral images to track objects in an image sequence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
