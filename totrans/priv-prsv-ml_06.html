<html><head></head><body>
<div id="_idContainer055" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-71"><a id="_idTextAnchor079" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1.1">4</span></h1>
<h1 id="_idParaDest-72" class="calibre5"><a id="_idTextAnchor080" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.2.1">Overview of Differential Privacy Algorithms and Applications of Differential Privacy</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.3.1">The concept of differential privacy holds great significance in the realm of data privacy and its importance continues to grow as more and more data is collected and analyzed. </span><span class="kobospan" id="kobo.3.2">Differential privacy algorithms offer a means to safeguard individual privacy while still allowing for valuable insights to be derived from </span><span><span class="kobospan" id="kobo.4.1">this data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.5.1">In this chapter, we will gain an overview of differential privacy algorithms, along with a comprehension of crucial concepts such as sensitivity and clipping in the context of differential privacy. </span><span class="kobospan" id="kobo.5.2">Additionally, we will explore how aggregates are generated through the use of differential privacy, including in </span><span><span class="kobospan" id="kobo.6.1">real-world applications.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.7.1">The following main topics will be covered in </span><span><span class="kobospan" id="kobo.8.1">this chapter:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.9.1">Differential </span><span><span class="kobospan" id="kobo.10.1">privacy algorithms:</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.11.1">The Laplace algorithm for </span><span><span class="kobospan" id="kobo.12.1">differential privacy</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.13.1">The Gaussian algorithm for </span><span><span class="kobospan" id="kobo.14.1">differential privacy</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.15.1">Generating aggregates using </span><span><span class="kobospan" id="kobo.16.1">differential privacy</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.17.1">Sensitivity and its role in aggregate generation algorithms using </span><span><span class="kobospan" id="kobo.18.1">differential privacy:</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.19.1">Queries using differential privacy: Count, sum, and mean Count, sum, </span><span><span class="kobospan" id="kobo.20.1">and mean</span></span></li></ul></li>
<li class="calibre11"><span><span class="kobospan" id="kobo.21.1">Clipping:</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.22.1">Understanding its significance within the realm of differential privacy </span><span><span class="kobospan" id="kobo.23.1">and examples</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.24.1">Overview of real-world applications that make use of </span><span><span class="kobospan" id="kobo.25.1">differential privacy</span></span></li>
</ul>
<h1 id="_idParaDest-73" class="calibre5"><a id="_idTextAnchor081" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.26.1">Differential privacy algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.27.1">Differential privacy is a fundamental concept that’s designed to safeguard individual privacy while enabling the statistical analysis of sensitive data. </span><span class="kobospan" id="kobo.27.2">It establishes a mathematical framework that guarantees the preservation of individual privacy during data analysis and sharing processes. </span><span class="kobospan" id="kobo.27.3">Differential privacy algorithms play a vital role by introducing random noise into the data, making it challenging to identify </span><span><span class="kobospan" id="kobo.28.1">specific records.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.29.1">In the preceding chapter, we learned that the core idea behind differential privacy is to introduce random noise into the data analysis process. </span><span class="kobospan" id="kobo.29.2">This noise makes it difficult for an attacker to determine whether a particular individual’s data was included in the analysis, thus preserving privacy. </span><span class="kobospan" id="kobo.29.3">The fundamental concept is that the inclusion or exclusion of any individual’s data should not significantly impact the results of </span><span><span class="kobospan" id="kobo.30.1">the analysis:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer045">
<span class="kobospan" id="kobo.31.1"><img alt="Figure 4.1 – Illustrating the primary concept of differential privacy" src="image/B16573_04_01.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.32.1">Figure 4.1 – Illustrating the primary concept of differential privacy</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.33.1">Differential privacy can be defined mathematically. </span><span class="kobospan" id="kobo.33.2">For two datasets, </span><em class="italic"><span class="kobospan" id="kobo.34.1">D1</span></em><span class="kobospan" id="kobo.35.1"> and </span><em class="italic"><span class="kobospan" id="kobo.36.1">D2</span></em><span class="kobospan" id="kobo.37.1">, which differ by a single record, the probability that the randomized algorithm or mechanism, </span><em class="italic"><span class="kobospan" id="kobo.38.1">L</span></em><span class="kobospan" id="kobo.39.1"> (such as count, sum, average, and so on), applied to </span><em class="italic"><span class="kobospan" id="kobo.40.1">D1</span></em><span class="kobospan" id="kobo.41.1"> yields a result in subset </span><em class="italic"><span class="kobospan" id="kobo.42.1">S</span></em><span class="kobospan" id="kobo.43.1"> is bounded by the exponential of epsilon (</span><em class="italic"><span class="kobospan" id="kobo.44.1">ε</span></em><span class="kobospan" id="kobo.45.1">) multiplied by the probability that </span><em class="italic"><span class="kobospan" id="kobo.46.1">L</span></em><span class="kobospan" id="kobo.47.1"> applied to </span><em class="italic"><span class="kobospan" id="kobo.48.1">D2</span></em><span class="kobospan" id="kobo.49.1"> yields a result in S, plus a delta (</span><span><em class="italic"><span class="kobospan" id="kobo.50.1">δ</span></em></span><span><span class="kobospan" id="kobo.51.1">) term.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.52.1">Mathematically, this is given </span><span><span class="kobospan" id="kobo.53.1">as follows:</span></span></p>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.54.1">P(L[D1] ∈ S) ≤ exp(ε) * P(L[D2] ∈ S) + δ</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.55.1">In this equation, the </span><span><span class="kobospan" id="kobo.56.1">following applies:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.57.1">P</span></em> <span><span class="kobospan" id="kobo.58.1">denotes probability.</span></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.59.1">D1</span></em><span class="kobospan" id="kobo.60.1"> and </span><em class="italic"><span class="kobospan" id="kobo.61.1">D2</span></em><span class="kobospan" id="kobo.62.1"> represent the two datasets that differ by a </span><span><span class="kobospan" id="kobo.63.1">single record.</span></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.64.1">S</span></em><span class="kobospan" id="kobo.65.1"> encompasses all subsets of the randomized algorithm or </span><span><span class="kobospan" id="kobo.66.1">mechanism, </span></span><span><em class="italic"><span class="kobospan" id="kobo.67.1">L</span></em></span><span><span class="kobospan" id="kobo.68.1">.</span></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.69.1">ε</span></em><span class="kobospan" id="kobo.70.1"> (epsilon) is a positive real number that controls the privacy loss and is referred to as the privacy budget. </span><span class="kobospan" id="kobo.70.2">It determines the extent to which the algorithm can differ between the two databases and quantifies the privacy loss incurred when the algorithm is applied to the database. </span><span class="kobospan" id="kobo.70.3">If ε is zero, the queries will yield similar answers, which compromises privacy to a </span><span><span class="kobospan" id="kobo.71.1">lesser extent.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.72.1">To ensure differential privacy, random noise (in the form of a random number) is added to the results. </span><span class="kobospan" id="kobo.72.2">This noise prevents adversaries from determining whether the returned results are genuine or have noise</span><a id="_idIndexMarker321" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.73.1"> added, and if so, the magnitude of the added noise. </span><span class="kobospan" id="kobo.73.2">The added noise guarantees that the data cannot be utilized to identify individuals while still allowing useful statistical properties to </span><span><span class="kobospan" id="kobo.74.1">be calculated.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.75.1">The choice of the random number distribution depends on how to select the right random number. </span><span class="kobospan" id="kobo.75.2">Next, we’ll explore two well-known distributions, the Laplace distribution and the Gaussian distribution, to assess their suitability for the privacy parameter, ε, and to guarantee </span><span><span class="kobospan" id="kobo.76.1">differential privacy.</span></span></p>
<h2 id="_idParaDest-74" class="calibre7"><a id="_idTextAnchor082" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.77.1">Laplace distribution</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.78.1">The Laplace distribution, also referred to as the double exponential distribution, is a continuous probability</span><a id="_idIndexMarker322" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.79.1"> distribution named after the renowned mathematician Pierre-Simon Laplace. </span><span class="kobospan" id="kobo.79.2">It arises from</span><a id="_idIndexMarker323" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.80.1"> merging two exponential distributions, one positive and </span><span><span class="kobospan" id="kobo.81.1">one negative.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.82.1">To better comprehend the Laplace distribution, let’s understand the exponential distribution. </span><span class="kobospan" id="kobo.82.2">The exponential distribution is defined by </span><span><span class="kobospan" id="kobo.83.1">this function:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.84.1">f</span><span><span class="kobospan" id="kobo.85.1">(</span></span><span><span class="kobospan" id="kobo.86.1">x</span></span><span><span class="kobospan" id="kobo.87.1">)</span></span><span> </span><span><span class="kobospan" id="kobo.88.1">=</span></span><span> </span><span><span><span class="kobospan" id="kobo.89.1">e</span></span></span><span> </span><span><span class="superscript"><span class="kobospan1" id="kobo.90.1">-x</span></span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.91.1">When x equals 0, f(x) is equal to 1, and as x increases, f(x) gradually </span><span><span class="kobospan" id="kobo.92.1">approaches 0.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.93.1">To observe this behavior, you can try a simple Python program to analyze the </span><span><span class="kobospan" id="kobo.94.1">exponential distribution.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.95.1">Try out a simple Python program and test </span><span><span class="kobospan" id="kobo.96.1">this behavior:</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.97.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.98.1">code: Exponential_Laplace_Guassian_Clipping.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.99.1">
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
x = np.arange(0,10, 0.25)
# define f(x) = e power (-x)
plt.plot(x, np.exp(-x));
plt.xlabel("x")
plt.ylabel("f(x)")</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.100.1">Here’s </span><span><span class="kobospan" id="kobo.101.1">the</span></span><span><a id="_idIndexMarker324" class="pcalibre1 calibre6 pcalibre"/></span><span><span class="kobospan" id="kobo.102.1"> output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer046">
<span class="kobospan" id="kobo.103.1"><img alt="Figure 4.2 – Exponential distribution" src="image/B16573_04_02.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.104.1">Figure 4.2 – Exponential distribution</span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.105.1">Laplace distribution – mathematical definition</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.106.1">Laplace distribution’s probabilistic</span><a id="_idIndexMarker325" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.107.1"> density function is defined </span><span><span class="kobospan" id="kobo.108.1">as follows:</span></span></p>
<p class="calibre3"> </p>
<div class="calibre2">
<div class="img---figure" id="_idContainer047">
<span class="kobospan" id="kobo.109.1"><img alt="" role="presentation" src="image/B16573_04_Formula_01.jpg" class="calibre4"/></span>
</div>
</div>
<p class="calibre3"><span class="kobospan" id="kobo.110.1">Here, x is a random variable, μ is the location parameter that determines the center of the distribution, and b &gt; 0 is the scale parameter that controls the spread or variability of </span><span><span class="kobospan" id="kobo.111.1">the distribution.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.112.1">The Laplace distribution has several important properties. </span><span class="kobospan" id="kobo.112.2">It is symmetric around its mean (μ), with a peak at μ. </span><span class="kobospan" id="kobo.112.3">The tails of the distribution are heavy, meaning that it has a higher probability of observing extreme values compared to a Gaussian (normal) distribution. </span><span class="kobospan" id="kobo.112.4">This property </span><a id="_idIndexMarker326" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.113.1">makes the Laplace distribution suitable for modeling data with outliers or heavy-tailed behavior. </span><span class="kobospan" id="kobo.113.2">The Laplace distribution finds applications in various fields, including statistics, signal processing, image processing, and machine learning. </span><span class="kobospan" id="kobo.113.3">It is particularly useful in scenarios where robustness to outliers is desired or when modeling data with a Laplacian </span><span><span class="kobospan" id="kobo.114.1">noise assumption.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.115.1">If </span><span><span class="kobospan" id="kobo.116.1">μ</span></span><span class="kobospan" id="kobo.117.1"> equals 0 and b equals 1, then the equation is </span><span><span class="kobospan" id="kobo.118.1">as follows:</span></span></p>
<p class="calibre3"><span><span class="kobospan" id="kobo.119.1">𝔣</span></span><span><span class="kobospan" id="kobo.120.1">(</span></span><span><span class="kobospan" id="kobo.121.1">x</span></span><span><span class="kobospan" id="kobo.122.1">)</span></span><span> </span><span><span class="kobospan" id="kobo.123.1">=</span></span><span> </span><span><span class="kobospan" id="kobo.124.1">1</span></span><span><span class="kobospan" id="kobo.125.1"> </span></span><span><span class="kobospan" id="kobo.126.1">_</span></span><span><span class="kobospan" id="kobo.127.1"> </span></span><span><span><span class="kobospan" id="kobo.128.1">2</span></span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.129.1"> e-x</span></strong></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.130.1">This is nothing but half of the exponential distribution. </span><span class="kobospan" id="kobo.130.2">Let’s implement Laplace in simple Python code and understand </span><span><span class="kobospan" id="kobo.131.1">it further:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.132.1">
def laplace_dist(x, μ, b):
    return 1 / (2 * b) * np.exp(-np.abs(x - μ) / b)
def plot_laplace_dist(x, μ, b):
    plt.plot(x, laplace_dist(x, μ, b),
    label="μ={}, b={}".format(μ, b))
x = np.arange(-10, 10, 0.1)
plot_laplace_dist(x, -2, 4)
plt.axvline(x=-2, linestyle='dotted', linewidth=3, label='mean')
plot_laplace_dist(x, 4, 8)
plt.axvline(x=4, color='orange', linestyle='dotted', linewidth=3, label='mean')
plt.legend();</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.133.1">Here’s </span><span><span class="kobospan" id="kobo.134.1">the output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer048">
<span class="kobospan" id="kobo.135.1"><img alt="Figure 4.3 – Laplace distribution with different means and scaling parameters" src="image/B16573_04_03.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.136.1">Figure 4.3 – Laplace distribution with different means and scaling parameters</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.137.1">From this graph, we </span><a id="_idIndexMarker327" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.138.1">can see that as the scaling parameter (b) increases in the Laplace distribution, the tails contribute a greater proportion compared to the central point. </span><span class="kobospan" id="kobo.138.2">This characteristic can be leveraged to enhance privacy by utilizing larger </span><span><span class="kobospan" id="kobo.139.1">scaling parameters.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.140.1">By increasing the scaling parameter, the Laplace distribution’s tails become heavier, resulting in a higher likelihood of extreme values occurring. </span><span class="kobospan" id="kobo.140.2">This increased variability makes it more challenging for adversaries to extract sensitive information or identify individual data points accurately. </span><span class="kobospan" id="kobo.140.3">Therefore, larger scaling parameters can be employed as a privacy-enhancing measure as they contribute to a broader spread of the distribution and provide a greater level of </span><span><span class="kobospan" id="kobo.141.1">privacy protection.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.142.1">Why is the Laplace distribution one of the algorithms of choice for </span><span><span class="kobospan" id="kobo.143.1">differential privacy?</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.144.1">Take a look at the following example, which shows that Laplace distribution is one of the right algorithms to implement for </span><span><span class="kobospan" id="kobo.145.1">differential privacy:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.146.1">
ε = 0.5
x = np.arange(90.2, 110, 0.20)
query_result=np.average(x)
dist1 = laplace_dist(x, query_result, 1 / ε)
dist2 = laplace_dist(x, query_result + 1, 1 / ε)
plt.plot(x, dist1, label="distribution 1")
plt.plot(x, dist2, label="distribution 2")
plt.axvline(x=query_result, c="black", linestyle='dotted', label="query result")
plt.legend()</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.147.1">Here, we have taken a simple dataset that consists of numbers from 90 to 110 in increments of 0.2. </span><span class="kobospan" id="kobo.147.2">The average of these numbers is close to 100, which is the query result – that is, the query finds the average of </span><span><span class="kobospan" id="kobo.148.1">these numbers.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.149.1">We find the Laplace </span><a id="_idIndexMarker328" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.150.1">distribution for this dataset with the mean as the query result and the scaling factor (b) set to 2, which is </span><strong class="bold"><span class="kobospan" id="kobo.151.1">1 / ε</span></strong><span class="kobospan" id="kobo.152.1"> in </span><span><span class="kobospan" id="kobo.153.1">this case:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer049">
<span class="kobospan" id="kobo.154.1"><img alt="Figure 4.4 – Distributions using Laplace" src="image/B16573_04_04.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.155.1">Figure 4.4 – Distributions using Laplace</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.156.1">The query result can come from any of these possible distributions. </span><span class="kobospan" id="kobo.156.2">As per the differential privacy formula (DP), query results from one distribution should be less than or equal to e</span><span class="superscript"><span class="kobospan1" id="kobo.157.1">ε  </span></span><span class="kobospan" id="kobo.158.1">times the second distribution when they </span><span><span class="kobospan" id="kobo.159.1">are compared.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.160.1">In this particular instance, the resultant value of 100 from the query is derived from distribution 1. </span><span class="kobospan" id="kobo.160.2">However, it’s not possible to definitively exclude the possibility that it originates from the </span><a id="_idIndexMarker329" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.161.1">second distribution, particularly if the probability of the outcome is less than or equal to e</span><span class="superscript"><span class="kobospan1" id="kobo.162.1">ε  </span></span><span><span class="kobospan" id="kobo.163.1">times:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.164.1">
p1 = laplace_dist(query_result, query_result, 1 / ε)
p2 = laplace_dist(query_result, query_result+1, 1 / ε)
print(p1,p2)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.165.1">The result is </span><span><em class="italic"><span class="kobospan" id="kobo.166.1">0.25 0.15163266492815836</span></em></span><span><span class="kobospan" id="kobo.167.1">.</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.168.1">
p1, p2 * np.exp(ε)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.169.1">The result is 0.25   </span><span><span class="kobospan" id="kobo.170.1">0.25.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.171.1">This proves that the Laplace distribution can be used as one of the mechanisms for differential privacy and that the b scaling parameter can be set to 1/ε, which is the </span><span><span class="kobospan" id="kobo.172.1">privacy budget.</span></span></p>
<h2 id="_idParaDest-75" class="calibre7"><a id="_idTextAnchor083" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.173.1">Gaussian distribution</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.174.1">The Gaussian distribution, also </span><a id="_idIndexMarker330" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.175.1">known as normal distribution, is a continuous probability distribution that is widely used in statistical analysis to model real-world phenomena. </span><span class="kobospan" id="kobo.175.2">It is characterized by its </span><a id="_idIndexMarker331" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.176.1">bell-shaped curve, which is symmetrical around the </span><span><span class="kobospan" id="kobo.177.1">mean value.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.178.1">Gaussian distribution – mathematical definition</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.179.1">Gaussian distribution is also called normal distribution </span><a id="_idIndexMarker332" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.180.1">and it is a continuous </span><span><span class="kobospan" id="kobo.181.1">probability distribution.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.182.1">The formula for Gaussian distribution is defined </span><span><span class="kobospan" id="kobo.183.1">as follows:</span></span></p>
<p class="calibre3"> </p>
<div class="calibre2">
<div class="img---figure" id="_idContainer050">
<span class="kobospan" id="kobo.184.1"><img alt="" role="presentation" src="image/B16573_04_Formula_02.jpg" class="calibre4"/></span>
</div>
</div>
<p class="calibre3"><span class="kobospan" id="kobo.185.1">Here, </span><span><span class="kobospan" id="kobo.186.1">x</span></span><span class="kobospan" id="kobo.187.1"> is the random variable in the Gaussian distribution; </span><span><span class="kobospan" id="kobo.188.1">μ</span></span><span class="kobospan" id="kobo.189.1"> is the location parameter, as in, it will be the mean </span><a id="_idIndexMarker333" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.190.1">of the data; </span><span><span class="kobospan" id="kobo.191.1">σ</span></span><span class="kobospan" id="kobo.192.1"> is the standard deviation; and </span><span><span class="kobospan" id="kobo.193.1">σ</span></span><span><span class="kobospan" id="kobo.194.1">2</span></span><span class="kobospan" id="kobo.195.1"> is the variance of </span><span><span class="kobospan" id="kobo.196.1">the data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.197.1">The following code is an implementation of a </span><span><span class="kobospan" id="kobo.198.1">Gaussian function:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.199.1">
def guissan_dist(x, μ, σ):
    return (1/(σ * np.sqrt(2 * np.pi)) * np.exp(-(x - μ)**2 / (2 * σ**2)))
def plot_guissan(x, μ, σ ):
    plt.plot(x, guissan_dist(x, μ, σ),
    label="μ={}, σ ={}".format(μ, σ ))
x = np.arange(-10, 10, 0.1)
stdv=np.std(x)
plot_guissan(x, -2, stdv)
plot_laplace_dist(x,-2,4)
plt.legend()</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.200.1">Let’s generate plots for both the Gaussian distribution and the Laplace distribution using the random dataset</span><a id="_idIndexMarker334" class="pcalibre1 calibre6 pcalibre"/> <span><span class="kobospan" id="kobo.201.1">we’ve created:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer051">
<span class="kobospan" id="kobo.202.1"><img alt="Figure 4.5 – Gaussian distribution with different means and standard deviation" src="image/B16573_04_05.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.203.1">Figure 4.5 – Gaussian distribution with different means and standard deviation</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.204.1">Based on this graph, we can see that the Laplace distribution has a sharper peak compared to the </span><span><span class="kobospan" id="kobo.205.1">Gaussian distribution.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.206.1">Now, let’s determine if the Gaussian mechanism complies with ε </span><span><span class="kobospan" id="kobo.207.1">differential privacy:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.208.1">
query_result=100
p1 = guissan_dist(query_result, query_result, 1 / ε)
p2 = guissan_dist(query_result, query_result+1, 1 / ε)
print(p1,p2)
0.19947114020071635 0.17603266338214976
p1, p2 * np.exp(ε)
0.19947114020071635, 0.29022879645614585</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.209.1">The Gaussian mechanism does not satisfy ε differential privacy. </span><span class="kobospan" id="kobo.209.2">Let’s check whether it satisfies (ε, δ) differential </span><a id="_idIndexMarker335" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.210.1">privacy by adding a δ value in </span><span><span class="kobospan" id="kobo.211.1">this case:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.212.1">
p1, p2 * np.exp(ε)-0.09075
0.19947114020071635, 0.19947879645614586</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.213.1">This shows that the Gaussian mechanism supports (ε, δ) differential privacy, which is sometimes called approximate differential privacy due to the addition of </span><span><span class="kobospan" id="kobo.214.1">delta (δ).</span></span></p>
<h2 id="_idParaDest-76" class="calibre7"><a id="_idTextAnchor084" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.215.1">Comparison of noise-adding algorithms to apply differential privacy</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.216.1">The following table provides</span><a id="_idIndexMarker336" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.217.1"> a high-level comparison of three </span><span><span class="kobospan" id="kobo.218.1">noise-adding mechanisms:</span></span></p>
<table class="no-table-style" id="table001-4">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.219.1">Exponential Mechanism</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.220.1">Laplace Mechanism</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.221.1">Gaussian Mechanism</span></strong></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.222.1">Usage</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.223.1">Mostly used to select a specific record or choose the best element, specifically with non-numeric or </span><span><span class="kobospan" id="kobo.224.1">categorical data</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.225.1">Widely used in numerical aggregates due to its balance between privacy and utility and its ease </span><span><span class="kobospan" id="kobo.226.1">of implementation</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.227.1">Used when dealing with a smaller scale of data and where differential privacy needs to be </span><span><span class="kobospan" id="kobo.228.1">applied repeatedly</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.229.1">Noise type</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.230.1">Exponential noise</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.231.1">Laplace (double </span><span><span class="kobospan" id="kobo.232.1">exponential) noise</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.233.1">Gaussian noise</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.234.1">Privacy</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.235.1">High privacy level </span><a id="_idIndexMarker337" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.236.1">due to the exponential distribution of </span><span><span class="kobospan" id="kobo.237.1">output probabilities</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.238.1">Random noise might significantly change outcomes, compromising </span><span><span class="kobospan" id="kobo.239.1">data utility</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.240.1">Achieves either delta privacy or epsilon-delta privacy, which is a trade-off for </span><span><span class="kobospan" id="kobo.241.1">better utility</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.242.1">Implementation</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.243.1">Complex to implement due to the nature of </span><span><span class="kobospan" id="kobo.244.1">exponential distribution</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.245.1">Relatively easy to implement due to the feature of the </span><span><span class="kobospan" id="kobo.246.1">Laplace distribution</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.247.1">Complex to implement but generally suitable when data sensitivity </span><span><span class="kobospan" id="kobo.248.1">is low</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.249.1">Adaptability</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.250.1">Mainly used for </span><span><span class="kobospan" id="kobo.251.1">categorical data</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.252.1">Used mostly with </span><span><span class="kobospan" id="kobo.253.1">numerical data</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.254.1">Suitable for low-sensitivity and </span><span><span class="kobospan" id="kobo.255.1">multi-query data</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.256.1">Table 4.1 - High-level comparison of three noise-adding mechanisms</span></p>
<h2 id="_idParaDest-77" class="calibre7"><a id="_idTextAnchor085" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.257.1">Generating aggregates using differential privacy</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.258.1">Differential privacy is a technique that’s used to protect the privacy of individuals when they’re collecting and sharing data. </span><span class="kobospan" id="kobo.258.2">One of the ways that differential privacy can be used is in the generation of aggregates, which are statistical summaries of data that can provide useful insights </span><a id="_idIndexMarker338" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.259.1">while also protecting the privacy </span><span><span class="kobospan" id="kobo.260.1">of individuals.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.261.1">Once the noise has been added to the data, statistical aggregates can be calculated and released without compromising individual privacy. </span><span class="kobospan" id="kobo.261.2">Examples of statistical aggregates that can be generated using differential privacy include means, medians, and histograms. </span><span class="kobospan" id="kobo.261.3">One of the challenges of using differential privacy to generate aggregates is balancing privacy and accuracy. </span><span class="kobospan" id="kobo.261.4">The amount of noise that is added to the data will affect the accuracy of the statistical aggregates that are generated. </span><span class="kobospan" id="kobo.261.5">Therefore, there is often a trade-off between the amount of privacy protection and the accuracy of the results.  </span><span class="kobospan" id="kobo.261.6">Overall, the use of differential privacy to generate aggregates is a powerful tool for protecting individual privacy while still allowing useful statistical properties to be calculated. </span><span class="kobospan" id="kobo.261.7">However, it </span><a id="_idIndexMarker339" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.262.1">requires careful consideration of the specific use case and the trade-offs between privacy </span><span><span class="kobospan" id="kobo.263.1">and accuracy.</span></span></p>
<h1 id="_idParaDest-78" class="calibre5"><a id="_idTextAnchor086" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.264.1">Sensitivity</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.265.1">Sensitivity plays a crucial role in the realm of differential privacy. </span><span class="kobospan" id="kobo.265.2">It refers to the maximum amount by which the output of a function or computation can change when a single individual’s data point is added or removed from a dataset. </span><span class="kobospan" id="kobo.265.3">Sensitivity provides a measure of the privacy risk associated with performing computations on </span><span><span class="kobospan" id="kobo.266.1">sensitive data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.267.1">Let’s look at an example </span><a id="_idIndexMarker340" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.268.1">of a real-life scenario that illustrates the need to measure the impact of changing a dataset using </span><span><span class="kobospan" id="kobo.269.1">sensitivity analysis.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.270.1">Scenario – financial risk assessment model</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.271.1">Suppose a financial institution develops a machine learning model to assess the credit risk of loan applicants. </span><span class="kobospan" id="kobo.271.2">The model takes </span><a id="_idIndexMarker341" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.272.1">various features, such as income, credit history, employment status, and outstanding debt, into account to predict the likelihood of loan default. </span><span class="kobospan" id="kobo.272.2">The institution wants to ensure that the model is robust and not overly sensitive to the presence or absence of any individual in the dataset. </span><span class="kobospan" id="kobo.272.3">In this case, sensitivity analysis can be employed to evaluate the impact of changing the dataset, specifically by removing or modifying the data of certain individuals. </span><span class="kobospan" id="kobo.272.4">The institution wants to determine whether the exclusion or modification of data for specific individuals significantly alters the model’s predictions or introduces bias, and measure the privacy risk associated with </span><span><span class="kobospan" id="kobo.273.1">this change.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.274.1">Let’s break this down in </span><span><span class="kobospan" id="kobo.275.1">mathematical terms.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.276.1">For example, if we have a function, f, that takes a dataset, D, as input and returns a numerical output, then the</span><a id="_idIndexMarker342" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.277.1"> sensitivity of f is defined as the maximum absolute difference between the outputs of f on two datasets, D and D’, that differ by the presence or absence of a single individual’s </span><span><span class="kobospan" id="kobo.278.1">data point.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.279.1">So, here, the sensitivity of f is sensitivity(f) = max_{D, D’} ||f(D) - </span><span><span class="kobospan" id="kobo.280.1">f(D’)||.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.281.1">The sensitivity of a function is a fundamental concept in differential privacy because it determines the amount of noise that needs to be added to the output of the function to guarantee privacy. </span><span class="kobospan" id="kobo.281.2">Naturally, functions with higher sensitivity are more prone to leaking information about individuals in the dataset and therefore require more noise to be added to their outputs to </span><span><span class="kobospan" id="kobo.282.1">maintain privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.283.1">To understand sensitivity, let’s consider the </span><span><span class="kobospan" id="kobo.284.1">following dataset:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.285.1">X = [ </span><span><span class="kobospan" id="kobo.286.1">0, 1,2,3,4,5,6,7,8,9,10,11,…..N]</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.287.1">Two functions/queries are defined in this dataset: </span><span><span class="kobospan" id="kobo.288.1">𝔣</span></span><span><span class="kobospan" id="kobo.289.1">1</span></span><span><span class="kobospan" id="kobo.290.1">(</span></span><span><span class="kobospan" id="kobo.291.1">x</span></span><span><span class="kobospan" id="kobo.292.1">)</span></span><span> </span><span class="kobospan" id="kobo.293.1">= x  </span><strong class="source-inline"><span class="kobospan" id="kobo.294.1">and </span></strong><span class="kobospan" id="kobo.295.1">f2(x)  = </span><span><span class="kobospan" id="kobo.296.1">x</span></span><span><span class="superscript"><span class="kobospan1" id="kobo.297.1">3</span></span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.298.1">.</span></strong></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.299.1">Let’s define another function/query that calculates the </span><span><span class="kobospan" id="kobo.300.1">following difference:</span></span></p>
<p class="calibre3"><strong class="source-inline"> </strong><span><span class="kobospan" id="kobo.301.1">∆</span></span><span> </span><span><span class="kobospan" id="kobo.302.1">f</span></span><span><span class="kobospan" id="kobo.303.1">(</span></span><span><span class="kobospan" id="kobo.304.1">x</span></span><span><span class="kobospan" id="kobo.305.1">a</span></span><span><span class="kobospan" id="kobo.306.1">,</span></span><span> </span><span><span class="kobospan" id="kobo.307.1">x</span></span><span><span class="kobospan" id="kobo.308.1">b</span></span><span><span class="kobospan" id="kobo.309.1">)</span></span><span> </span><span><span class="kobospan" id="kobo.310.1">=</span></span><span> </span><span><span class="kobospan" id="kobo.311.1">|</span></span><span> </span><span><span class="kobospan" id="kobo.312.1">f</span></span><span><span class="kobospan" id="kobo.313.1">(</span></span><span><span class="kobospan" id="kobo.314.1">x</span></span><span><span class="kobospan" id="kobo.315.1">a</span></span><span><span class="kobospan" id="kobo.316.1">)</span></span><span> </span><span><span class="kobospan" id="kobo.317.1">−</span></span><span> </span><span><span><span class="kobospan" id="kobo.318.1">f</span></span></span><span><span><span class="kobospan" id="kobo.319.1">(</span></span></span><span><span><span class="kobospan" id="kobo.320.1">x</span></span></span><span><span><span class="kobospan" id="kobo.321.1">b</span></span></span><span><span><span class="kobospan" id="kobo.322.1">)</span></span></span><span><span> </span></span><span><span><span class="kobospan" id="kobo.323.1">|</span></span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.324.1">Let’s calculate f1, f2, </span><span><span class="kobospan" id="kobo.325.1">∆</span></span><span> </span><span><span class="kobospan" id="kobo.326.1">f</span></span><span><span class="kobospan" id="kobo.327.1">1</span></span><span><span class="kobospan" id="kobo.328.1">,</span></span><span> </span><span><span class="kobospan" id="kobo.329.1">∆</span></span><span> </span><span><span class="kobospan" id="kobo.330.1">f</span></span><span><span class="kobospan" id="kobo.331.1">2</span></span><span class="kobospan" id="kobo.332.1"> and observe </span><span><span class="kobospan" id="kobo.333.1">the data:</span></span></p>
<table class="no-table-style" id="table002-3">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.334.1">X</span></span><span lang="ar-SA" xml:lang="ar-SA"><span class="kobospan" id="kobo.335.1"></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.336.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.337.1">0</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.338.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.339.1">1</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.340.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.341.1">2</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.342.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.343.1">3</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.344.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.345.1">4</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.346.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.347.1">5</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.348.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.349.1">6</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.350.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.351.1">7</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.352.1">….</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.353.1">0</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.354.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.355.1">2</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.356.1">3</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.357.1">4</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.358.1">5</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.359.1">6</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.360.1">7</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.361.1">…</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.362.1">f</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.363.1">1</span></span></span><span><span class="kobospan" id="kobo.364.1">(x</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.365.1">i</span></span></span><span><span class="kobospan" id="kobo.366.1">)=x</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.367.1">0</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.368.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.369.1">2</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.370.1">3</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.371.1">4</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.372.1">5</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.373.1">6</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.374.1">7</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.375.1">…</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.376.1">f</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.377.1">2</span></span></span><span><span class="kobospan" id="kobo.378.1">(x</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.379.1">i</span></span></span><span><span class="kobospan" id="kobo.380.1">)=x3</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.381.1">0</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.382.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.383.1">8</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.384.1">27</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.385.1">64</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.386.1">125</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.387.1">216</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.388.1">343</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.389.1">…</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.390.1">∆</span></span><span><span class="kobospan" id="kobo.391.1">f</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.392.1">1</span></span></span><span><span class="kobospan" id="kobo.393.1">(xi, x</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.394.1">i+1</span></span></span><span><span class="kobospan" id="kobo.395.1">)</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.396.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.397.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.398.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.399.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.400.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.401.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.402.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.403.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.404.1">….</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.405.1">∆</span></span><span><span class="kobospan" id="kobo.406.1">f</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.407.1">2</span></span></span><span><span class="kobospan" id="kobo.408.1">(xi, x</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.409.1">i+1</span></span></span><span><span class="kobospan" id="kobo.410.1">)</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.411.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.412.1">7</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.413.1">21</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.414.1">37</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.415.1">61</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.416.1">91</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.417.1">127</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.418.1">…</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.419.1">...</span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.420.1">Table 4.2 - Sensitivity analysis of functions/queries on datasets</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.421.1">Sensitivity refers to the</span><a id="_idIndexMarker343" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.422.1"> impact a change in the underlying dataset can have on the result of </span><span><span class="kobospan" id="kobo.423.1">a query.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.424.1">Let xA, xB be any dataset from all possible datasets of X differing by at most </span><span><span class="kobospan" id="kobo.425.1">one element.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.426.1">So, the sensitivity is calculated with the </span><span><span class="kobospan" id="kobo.427.1">following equation:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.428.1">Sensitivity = max </span><span><span class="kobospan" id="kobo.429.1">|</span></span><span> </span><span><span class="kobospan" id="kobo.430.1">f</span></span><span><span class="kobospan" id="kobo.431.1">(</span></span><span><span class="kobospan" id="kobo.432.1">x</span></span><span><span class="kobospan" id="kobo.433.1">a</span></span><span><span class="kobospan" id="kobo.434.1">)</span></span><span> </span><span><span class="kobospan" id="kobo.435.1">−</span></span><span> </span><span><span class="kobospan" id="kobo.436.1">f</span></span><span><span class="kobospan" id="kobo.437.1">(</span></span><span><span class="kobospan" id="kobo.438.1">x</span></span><span><span class="kobospan" id="kobo.439.1">b</span></span><span><span class="kobospan" id="kobo.440.1">)</span></span><span> </span><span><span class="kobospan" id="kobo.441.1">|</span></span><span class="kobospan" id="kobo.442.1">|, where Xa,Xb </span><span><span class="kobospan" id="kobo.443.1">⊆</span></span><span> </span><span><span class="kobospan" id="kobo.444.1">X</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.445.1">Based on this definition, it is very clear that the sensitivity for f1(x) = x is 1 because the maximum difference is constant. </span><span class="kobospan" id="kobo.445.2">With the second query, f2(x)=x</span><span class="superscript"><span class="kobospan1" id="kobo.446.1">3</span></span><span class="kobospan" id="kobo.447.1">, the difference is not constant and it is unbounded, growing based on the number of data elements in the dataset. </span><span class="kobospan" id="kobo.447.2">To calculate the sensitivity of the second function/query, we need to specify the lower bounds and upper bounds – for example, from x</span><span class="subscript"><span class="kobospan1" id="kobo.448.1">5 </span></span><span class="kobospan" id="kobo.449.1">to x</span><span class="subscript"><span class="kobospan1" id="kobo.450.1">10</span></span><span class="kobospan" id="kobo.451.1">,</span><span class="subscript"> </span><span class="kobospan" id="kobo.452.1">x</span><span class="subscript"><span class="kobospan1" id="kobo.453.1">0</span></span><span class="kobospan" id="kobo.454.1"> to x</span><span class="subscript"><span class="kobospan1" id="kobo.455.1">5</span></span><span class="kobospan" id="kobo.456.1">, and </span><span><span class="kobospan" id="kobo.457.1">so on.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.458.1">Let’s define another query that is bounded within the input values of 5 to 10 or 0 to 5 using the </span><span><span class="kobospan" id="kobo.459.1">same function:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.460.1"> f3(x)  = x</span><span class="superscript"><span class="kobospan1" id="kobo.461.1">3</span></span><span class="kobospan" id="kobo.462.1">, where  </span><span><span class="kobospan" id="kobo.463.1">0&lt;=x&lt;=5</span></span></p>
<p class="calibre3"><span><span class="kobospan" id="kobo.464.1">∆</span></span><span> </span><span><span class="kobospan" id="kobo.465.1">f</span></span><span><span class="kobospan" id="kobo.466.1">(</span></span><span><span class="kobospan" id="kobo.467.1">x</span></span><span><span class="kobospan" id="kobo.468.1">a</span></span><span><span class="kobospan" id="kobo.469.1">,</span></span><span> </span><span><span class="kobospan" id="kobo.470.1">x</span></span><span><span class="kobospan" id="kobo.471.1">b</span></span><span><span class="kobospan" id="kobo.472.1">)</span></span><span> </span><span><span class="kobospan" id="kobo.473.1">=</span></span><span> </span><span><span class="kobospan" id="kobo.474.1">|</span></span><span> </span><span><span class="kobospan" id="kobo.475.1">f</span></span><span><span class="kobospan" id="kobo.476.1">(</span></span><span><span class="kobospan" id="kobo.477.1">x</span></span><span><span class="kobospan" id="kobo.478.1">a</span></span><span><span class="kobospan" id="kobo.479.1">)</span></span><span> </span><span><span class="kobospan" id="kobo.480.1">−</span></span><span> </span><span><span><span class="kobospan" id="kobo.481.1">f</span></span></span><span><span><span class="kobospan" id="kobo.482.1">(</span></span></span><span><span><span class="kobospan" id="kobo.483.1">x</span></span></span><span><span><span class="kobospan" id="kobo.484.1">b</span></span></span><span><span><span class="kobospan" id="kobo.485.1">)</span></span></span><span><span> </span></span><span><span><span class="kobospan" id="kobo.486.1">|</span></span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.487.1">Here’s </span><span><span class="kobospan" id="kobo.488.1">the table:</span></span></p>
<table class="no-table-style" id="table003-3">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span lang="ar-SA" xml:lang="ar-SA"> </span><span><span class="kobospan" id="kobo.489.1">X</span></span><span lang="ar-SA" xml:lang="ar-SA"><span class="kobospan" id="kobo.490.1"></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.491.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.492.1">0</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.493.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.494.1">1</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.495.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.496.1">2</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.497.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.498.1">3</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.499.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.500.1">4</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.501.1">X</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.502.1">5</span></span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.503.1">0</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.504.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.505.1">2</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.506.1">3</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.507.1">4</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.508.1">5</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.509.1">fx(x</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.510.1">i</span></span></span><span><span class="kobospan" id="kobo.511.1">)=x</span></span><span><span class="superscript"><span class="kobospan1" id="kobo.512.1">3</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.513.1">0</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.514.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.515.1">8</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.516.1">27</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.517.1">64</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.518.1">125</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.519.1">∆</span></span><span><span class="kobospan" id="kobo.520.1">f</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.521.1">2</span></span></span><span><span class="kobospan" id="kobo.522.1">(xi, x</span></span><span><span class="subscript"><span class="kobospan1" id="kobo.523.1">i+1</span></span></span><span><span class="kobospan" id="kobo.524.1">)</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.525.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.526.1">7</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.527.1">21</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.528.1">37</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.529.1">61</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.530.1">91</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.531.1">Table 4.3 - Sensitivity analysis of query bounded within input values</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.532.1">In this case, the </span><a id="_idIndexMarker344" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.533.1">sensitivity will be max | 1+7+21+37+61+91 | = </span><span><span class="kobospan" id="kobo.534.1">216:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.535.1">
def f(x):
    return x ** 3
def sensitivity(f, xa, xb):
    sensitivity = abs(f(xa) - f(xb))
    return sensitivity
# Sensitivity calculation for the input range 0 to 6 and summing the sensitivities
total_sensitivity = 0
for x in range(6):
    xa = x
    xb = x + 1
    sensitivity_value = sensitivity(f, xa, xb)
    print(sensitivity_value)
    total_sensitivity += sensitivity_value
print("Total Sensitivity within the range 0 to 6:", total_sensitivity)</span></pre>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.536.1">Output:</span></em></span></p>
<pre class="console"><span class="kobospan1" id="kobo.537.1">
1
7
19
37
61
91
Total sensitivity within the range 0 to 6: 216</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.538.1">The sensitivity of queries can be further classified into global sensitivity and local sensitivity, depending </span><a id="_idIndexMarker345" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.539.1">on whether the sensitivity is calculated using universal datasets or </span><span><span class="kobospan" id="kobo.540.1">local datasets.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.541.1">Global sensitivity</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.542.1">Global sensitivity refers to the maximum</span><a id="_idIndexMarker346" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.543.1"> possible change in query results when considering all possible datasets. </span><span class="kobospan" id="kobo.543.2">It is calculated based on the entire population or a universal dataset. </span><span class="kobospan" id="kobo.543.3">Global sensitivity provides an upper bound on the potential privacy risk and captures the </span><span><span class="kobospan" id="kobo.544.1">worst-case scenario.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.545.1">Local sensitivity</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.546.1">Local sensitivity, on the other hand, focuses</span><a id="_idIndexMarker347" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.547.1"> on the sensitivity of a query based on a specific local dataset. </span><span class="kobospan" id="kobo.547.2">It measures the maximum change in query results when a single data point is added or removed from this local dataset. </span><span class="kobospan" id="kobo.547.3">Local sensitivity provides a more fine-grained and context-specific measure of </span><span><span class="kobospan" id="kobo.548.1">privacy risk.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.549.1">Based on this, we can formulate </span><span><span class="kobospan" id="kobo.550.1">the following:</span></span></p>
<table class="no-table-style" id="table004-3">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.551.1">Query/Function</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.552.1">Global Sensitivity</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.553.1">Comments</span></strong></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.554.1">𝑓(𝑥) = 𝑥</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.555.1">1</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.556.1">Changing 𝑥 by 1 will result in</span><span lang="ar-SA" xml:lang="ar-SA"> </span><span class="kobospan" id="kobo.557.1">changes of 𝑓(𝑥) </span><span><span class="kobospan" id="kobo.558.1">by 1</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.559.1">𝑓(𝑥) = </span><span><span class="kobospan" id="kobo.560.1">𝑥</span></span><span><span class="superscript"> </span></span><span><span class="superscript"><span class="kobospan1" id="kobo.561.1">2</span></span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.562.1">Unbounded</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.563.1">A change in 𝑓(𝑥) depends on the value </span><span><span class="kobospan" id="kobo.564.1">of </span></span><span><span class="kobospan" id="kobo.565.1">𝑥</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.566.1">𝑓(𝑥) = 𝑥 + 𝑥</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.567.1">2</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.568.1">Changing 𝑥 by 1 changes 𝑓(𝑥) </span><span><span class="kobospan" id="kobo.569.1">by 2</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.570.1">𝑓( 𝑥) = 5 ∗ 𝑥</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.571.1">5</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.572.1">Changing 𝑥 by 1 changes 𝑓(𝑥) </span><span><span class="kobospan" id="kobo.573.1">by 5</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.574.1">Table 4.4 - Local sensitivity analysis of query results</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.575.1">Differential privacy is achieved by adding noise to the query result so that privacy </span><span><span class="kobospan" id="kobo.576.1">is guaranteed.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.577.1">The amount of noise that needs to be</span><a id="_idIndexMarker348" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.578.1"> added in differential privacy depends on four </span><span><span class="kobospan" id="kobo.579.1">key parameters:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.580.1">The privacy parameter (ε)</span></strong><span class="kobospan" id="kobo.581.1">: The privacy parameter, ε, controls the level of privacy protection provided by differential </span><a id="_idIndexMarker349" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.582.1">privacy. </span><span class="kobospan" id="kobo.582.2">A smaller value of ε implies stronger privacy guarantees but may result in higher noise being added to the </span><span><span class="kobospan" id="kobo.583.1">query result.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.584.1">The privacy budget (Δε)</span></strong><span class="kobospan" id="kobo.585.1">: The privacy</span><a id="_idIndexMarker350" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.586.1"> budget represents the total amount of privacy that can be expended over multiple queries or operations. </span><span class="kobospan" id="kobo.586.2">It is typically divided equally between the individual queries to ensure that the overall privacy guarantees </span><span><span class="kobospan" id="kobo.587.1">are maintained.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.588.1">Sensitivity (Δf)</span></strong><span class="kobospan" id="kobo.589.1">: Sensitivity refers to the </span><a id="_idIndexMarker351" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.590.1">maximum amount by which the query result can change when a single data point is added or removed. </span><span class="kobospan" id="kobo.590.2">It quantifies the impact of individual data on the query result and helps determine the amount of noise to </span><span><span class="kobospan" id="kobo.591.1">be added.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.592.1">Data size (N)</span></strong><span class="kobospan" id="kobo.593.1">: The size of the dataset being analyzed also influences the amount of noise added in differential </span><a id="_idIndexMarker352" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.594.1">privacy. </span><span class="kobospan" id="kobo.594.2">Larger datasets generally allow for less noise to be added, resulting in improved accuracy, while smaller datasets may require more noise to </span><span><span class="kobospan" id="kobo.595.1">preserve privacy.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.596.1">By carefully choosing appropriate values for these parameters and considering the trade-off between privacy </span><a id="_idIndexMarker353" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.597.1">and accuracy, the noise can be tailored to provide effective privacy protection while still yielding useful and reliable </span><span><span class="kobospan" id="kobo.598.1">query results:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer052">
<span class="kobospan" id="kobo.599.1"><img alt="Figure 4.6 – Parameters that influence the addition of noise" src="image/B16573_04_06.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.600.1">Figure 4.6 – Parameters that influence the addition of noise</span></p>
<h1 id="_idParaDest-79" class="calibre5"><a id="_idTextAnchor087" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.601.1">Queries that use differential privacy</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.602.1">Queries that use differential privacy allow analysts and data scientists to retrieve aggregated information from a</span><a id="_idIndexMarker354" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.603.1"> dataset while ensuring that the privacy of individual data points is protected. </span><span class="kobospan" id="kobo.603.2">These queries are designed to add a controlled amount of noise to the query results, making it difficult to discern the contribution of any particular individual in </span><span><span class="kobospan" id="kobo.604.1">the dataset.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.605.1">Various types of queries can be performed using differential privacy. </span><span class="kobospan" id="kobo.605.2">Some commonly used ones include </span><span><span class="kobospan" id="kobo.606.1">the following:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.607.1">Count queries</span></strong><span class="kobospan" id="kobo.608.1">: These queries </span><a id="_idIndexMarker355" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.609.1">aim to determine the number of records that satisfy certain conditions in a dataset while preserving privacy. </span><span class="kobospan" id="kobo.609.2">The query result is perturbed by adding noise to the true count, ensuring that individual contributions cannot be </span><a id="_idIndexMarker356" class="pcalibre1 calibre6 pcalibre"/><span><span class="kobospan" id="kobo.610.1">accurately determined.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.611.1">Sum queries</span></strong><span class="kobospan" id="kobo.612.1">: Sum queries involve calculating</span><a id="_idIndexMarker357" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.613.1"> the sum of specific values in a dataset while maintaining privacy – for example, computing the total income of a group of individuals while protecting the confidentiality of individual </span><span><span class="kobospan" id="kobo.614.1">income values.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.615.1">Average queries</span></strong><span class="kobospan" id="kobo.616.1">: Average queries</span><a id="_idIndexMarker358" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.617.1"> compute the average value of a specific attribute in a dataset while ensuring privacy. </span><span class="kobospan" id="kobo.617.2">Noise is added to the computed average to protect individual </span><span><span class="kobospan" id="kobo.618.1">data points.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.619.1">Top-K queries</span></strong><span class="kobospan" id="kobo.620.1">: Top-K queries aim</span><a id="_idIndexMarker359" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.621.1"> to identify the K largest values or records in a dataset while preserving privacy. </span><span class="kobospan" id="kobo.621.2">Noise is added to the query result to hide the specific contributions </span><span><span class="kobospan" id="kobo.622.1">of individuals.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.623.1">Range queries</span></strong><span class="kobospan" id="kobo.624.1">: Range queries involve</span><a id="_idIndexMarker360" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.625.1"> retrieving records or values within a specific range from a dataset while maintaining privacy. </span><span class="kobospan" id="kobo.625.2">Noise is added to the query result to prevent individual data points that have been identified falling within </span><span><span class="kobospan" id="kobo.626.1">the range.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.627.1">To achieve differential privacy, various mechanisms are used to add noise to the query results. </span><span class="kobospan" id="kobo.627.2">These mechanisms include the Laplace mechanism, the Gaussian mechanism, and randomized response, among others. </span><span class="kobospan" id="kobo.627.3">The choice of mechanism depends on the specific requirements of the query and the desired </span><span><span class="kobospan" id="kobo.628.1">privacy guarantees.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.629.1">It is important to note that the level of privacy protection provided by differential privacy is quantifiable through a privacy </span><a id="_idIndexMarker361" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.630.1">parameter called epsilon (ε). </span><span class="kobospan" id="kobo.630.2">A smaller value of ε provides stronger privacy guarantees but may introduce more noise into the query results, potentially reducing </span><span><span class="kobospan" id="kobo.631.1">their accuracy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.632.1">Queries that use differential privacy offer a balance between data utility and privacy protection. </span><span class="kobospan" id="kobo.632.2">They allow for meaningful analysis and insights to be derived from sensitive datasets while safeguarding the confidentiality of individuals’ information. </span><span class="kobospan" id="kobo.632.3">By incorporating differential privacy techniques into data analysis processes, organizations can ensure compliance with privacy regulations and build trust with their users </span><span><span class="kobospan" id="kobo.633.1">or customers.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.634.1">Let’s deep dive into these queries</span><a id="_idIndexMarker362" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.635.1"> one by one with the </span><span><span class="kobospan" id="kobo.636.1">following dataset:</span></span></p>
<table class="no-table-style" id="table005-2">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.637.1">Name</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.638.1">Age</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.639.1">Salary</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.640.1">Gender</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.641.1">Title</span></strong></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.642.1">A</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.643.1">32</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.644.1">200K</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.645.1">M</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.646.1">Staff Engineer</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.647.1">B</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.648.1">44</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.649.1">300K</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.650.1">F</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.651.1">Manager</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.652.1">C</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.653.1">55</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.654.1">400K</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.655.1">F</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.656.1">Director</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.657.1">D</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.658.1">66</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.659.1">500K</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.660.1">M</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.661.1">VP</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.662.1">Table 4.6 - Differential privacy queries analysis with the provided dataset</span></p>
<h4 class="calibre17"><span class="kobospan" id="kobo.663.1">Count queries using differential privacy</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.664.1">Analyze the results of the following </span><a id="_idIndexMarker363" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.665.1">queries and figure </span><a id="_idIndexMarker364" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.666.1">out how </span><span><span class="kobospan" id="kobo.667.1">sensitivity operates:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.668.1">How many total employees are there in this dataset? </span><span class="kobospan" id="kobo.668.2">The answer </span><span><span class="kobospan" id="kobo.669.1">is 4.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.670.1">How many people have below 300K salary? </span><span class="kobospan" id="kobo.670.2">The answer </span><span><span class="kobospan" id="kobo.671.1">is 1.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.672.1">How many male employees are working? </span><span class="kobospan" id="kobo.672.2">The answer </span><span><span class="kobospan" id="kobo.673.1">is 2.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.674.1">To ensure the answer includes noise and guarantees differential privacy, it is essential to determine the sensitivity of count queries and the appropriate value to use </span><span><span class="kobospan" id="kobo.675.1">for sensitivity.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.676.1">Count queries have a sensitivity of 1, meaning that if one record is added, the query result will increase by 1, or if one row is removed, the query result will decrease by 1. </span><span class="kobospan" id="kobo.676.2">By understanding the sensitivity of count queries, we can accurately incorporate noise while </span><span><span class="kobospan" id="kobo.677.1">preserving privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.678.1">We will utilize the NumPy library to generate differentially private results for the sample </span><span><span class="kobospan" id="kobo.679.1">count queries.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.680.1">NumPy provides Laplace noise </span><a id="_idIndexMarker365" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.681.1">generation based on the given sensitivity, mean, and </span><span><span class="kobospan" id="kobo.682.1">epsilon </span></span><span><a id="_idIndexMarker366" class="pcalibre1 calibre6 pcalibre"/></span><span><span class="kobospan" id="kobo.683.1">values:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.684.1">
import numpy as np
Total_employees = 4
sensitivity = 1
print("sensitivity:",sensitivity )
# epsilon =privacy loss or budget
epsilon= 0.8
noise = np.random.laplace(loc=0, scale=sensitivity/epsilon)
print("noise:",noise)
count_employee_dp = Total_employees + noise
print ("count with DP:", count_employee_dp)</span></pre>
<p class="calibre3"><span><span class="kobospan" id="kobo.685.1">Ouput:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.686.1">
sensitivity: 1
noise: 2.247932787995729
count with DP: 6.24793278799573</span></pre>
<h4 class="calibre17"><span class="kobospan" id="kobo.687.1">Sum queries using differential privacy</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.688.1">Let’s analyze the following queries and </span><a id="_idIndexMarker367" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.689.1">understand how sensitivity works</span><a id="_idIndexMarker368" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.690.1"> in </span><span><span class="kobospan" id="kobo.691.1">this case:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.692.1">What is the total salaries of all employees in this dataset? </span><span class="kobospan" id="kobo.692.2">The total sum of salaries is reported as 1,400K ( without applying </span><span><span class="kobospan" id="kobo.693.1">differential privacy).</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.694.1">What is the total age of employees? </span><span class="kobospan" id="kobo.694.2">The total sum of ages is reported as 197 (without applying </span><span><span class="kobospan" id="kobo.695.1">differential privacy).</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.696.1">To ensure the answers include the noise that was added by guaranteed differential privacy, it is important to determine the sensitivity for the sum queries and identify the appropriate value to use </span><span><span class="kobospan" id="kobo.697.1">for sensitivity.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.698.1">Unlike count queries, sensitivity for sum queries is not straightforward because the addition of a new row will increase the output by the </span><span><span class="kobospan" id="kobo.699.1">added value.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.700.1">Therefore, sensitivity in this case is unbounded since it depends on the data of the record </span><span><span class="kobospan" id="kobo.701.1">being added.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.702.1">For the query regarding the age of a person, we can estimate the upper bound by considering the historical maximum age to which a person has lived, which is around 126. </span><span class="kobospan" id="kobo.702.2">Thus, we can assume an upper bound of 126 for </span><span><span class="kobospan" id="kobo.703.1">this query.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.704.1">However, determining the</span><a id="_idIndexMarker369" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.705.1"> real upper bound for the salary query is challenging. </span><span class="kobospan" id="kobo.705.2">It could be 1M, 10M, 100M, or even higher. </span><span class="kobospan" id="kobo.705.3">As a result, in sum queries, the sensitivity depends on the lower and upper bounds provided to </span><span><span class="kobospan" id="kobo.706.1">the queries.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.707.1">To automatically calculate</span><a id="_idIndexMarker370" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.708.1"> the lower and upper bounds, a technique called clipping can be employed, which we will explore in the </span><span><span class="kobospan" id="kobo.709.1">next section:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.710.1">
Total_salary = 1400
Lower_bound=100
Upper_bound=9999
sensitivity = Upper_bound - Lower_bound
print("sensitivity:",sensitivity )
# epsilon =privacy loss or budget
epsilon= 0.9
noise = np.random.laplace(loc=0, scale=sensitivity/epsilon)
print("noise:",noise)
Total_salary_dp = Total_salary + noise
print ("total salary with DP:",Total_salary_dp)</span></pre>
<p class="calibre3"><span><span class="kobospan" id="kobo.711.1">Output:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.712.1">
sensitivity: 9899
noise: 4724.329480136737
total salary with DP: 6124.329480136737</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.713.1">Guaranteeing accuracy and privacy in the results of differential privacy are heavily influenced by their sensitivity, which</span><a id="_idIndexMarker371" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.714.1"> is determined</span><a id="_idIndexMarker372" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.715.1"> by the lower and upper bounds specified for </span><span><span class="kobospan" id="kobo.716.1">sum queries.</span></span></p>
<h4 class="calibre17"><span class="kobospan" id="kobo.717.1">Average queries using differential privacy</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.718.1">Analyze the following queries and figure out how</span><a id="_idIndexMarker373" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.719.1"> sensitivity works in </span><span><span class="kobospan" id="kobo.720.1">this case:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.721.1">What is the average salary? </span><span class="kobospan" id="kobo.721.2">The answer is </span><span><span class="kobospan" id="kobo.722.1">350 K.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.723.1">What is the average age? </span><span class="kobospan" id="kobo.723.2">The answer </span><span><span class="kobospan" id="kobo.724.1">is 49.26.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.725.1">To ensure that the answers for average queries include the noise added by guaranteed differential privacy, it is important</span><a id="_idIndexMarker374" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.726.1"> to determine the sensitivity for these queries and identify the appropriate value to use for the sensitivity parameter in the differential </span><span><span class="kobospan" id="kobo.727.1">privacy algorithm.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.728.1">One approach to considering average queries is to treat them as two separate queries: a summation query and a count query. </span><span class="kobospan" id="kobo.728.2">The sensitivity of count queries can be calculated using known methods; the sensitivity of sum queries can be </span><span><span class="kobospan" id="kobo.729.1">determined similarly.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.730.1">By understanding the sensitivity of both the count and sum queries, we can then provide the differentially private result for average queries. </span><span class="kobospan" id="kobo.730.2">This involves incorporating noise in a way that preserves privacy while ensuring the accuracy of the </span><span><span class="kobospan" id="kobo.731.1">average calculation:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.732.1">
Average_salary = 350
Total_salary_dp = 6124.329480136737
count_dp = 6.24793278799573
dp_average = (Total_salary_dp)/count_dp
dp_average
980.2169274137402</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.733.1">The noisy average salary with differential privacy will be distorted due to the added noise, while the average salary without differential privacy </span><span><span class="kobospan" id="kobo.734.1">remains unchanged.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.735.1">Now, let’s implement the same use case using differential privacy techniques such as sensitivity, clipping, and noise. </span><span class="kobospan" id="kobo.735.2">We’ll use the Laplace mechanism to inject noise into the </span><span><span class="kobospan" id="kobo.736.1">average calculation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.737.1">While the current discussion </span><a id="_idIndexMarker375" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.738.1">aims to provide an understanding of the base concepts, it’s important to note that production-grade frameworks</span><a id="_idIndexMarker376" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.739.1"> that implement differential privacy take into account various intricacies in more detail. </span><span class="kobospan" id="kobo.739.2">These frameworks address factors such as handling overflows of numbers during calculations and employing appropriate algorithms to ensure accurate and privacy-preserving computations. </span><span class="kobospan" id="kobo.739.3">These frameworks prioritize robustness and reliability to meet the demands of </span><span><span class="kobospan" id="kobo.740.1">real-world scenarios.</span></span></p>
<h1 id="_idParaDest-80" class="calibre5"><a id="_idTextAnchor088" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.741.1">Clipping</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.742.1">As discussed earlier, unbounded queries have an infinite sensitivity value, which cannot be directly utilized to provide results with differential privacy. </span><span class="kobospan" id="kobo.742.2">One approach to addressing this issue is to transform unbounded queries into bounded ones by specifying their lower and </span><span><span class="kobospan" id="kobo.743.1">upper bounds.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.744.1">In differential privacy, clipping is a </span><a id="_idIndexMarker377" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.745.1">technique that’s used to bind the sensitivity of a function by constraining its output within a specific range. </span><span class="kobospan" id="kobo.745.2">The fundamental concept is to clip or limit the output of a function to fall into a predetermined range, such as [-c, c], where c is a positive constant. </span><span class="kobospan" id="kobo.745.3">Afterward, noise is introduced to the clipped output to ensure </span><span><span class="kobospan" id="kobo.746.1">privacy guarantees.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.747.1">The clipping procedure involves </span><span><span class="kobospan" id="kobo.748.1">two steps:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.749.1">Scaling the function’s output</span></strong><span class="kobospan" id="kobo.750.1">: The output of the function is scaled by dividing it by a scaling factor, denoted as s. </span><span class="kobospan" id="kobo.750.2">This scaling ensures that the absolute value of the scaled</span><a id="_idIndexMarker378" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.751.1"> output is less than or equal to the clipping </span><span><span class="kobospan" id="kobo.752.1">threshold, c</span></span><span><span class="kobospan" id="kobo.753.1">.</span></span><p class="calibre3"><span class="kobospan" id="kobo.754.1">Mathematically, this can be represented as f’(D) = f(D) / s, where |f’(D)| &lt;= </span><span><span class="kobospan" id="kobo.755.1">c.</span></span></p></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.756.1">Adding noise</span></strong><span class="kobospan" id="kobo.757.1">: Once the output has been clipped, noise is incorporated to uphold differential privacy. </span><span class="kobospan" id="kobo.757.2">This noise can</span><a id="_idIndexMarker379" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.758.1"> be generated from a Laplace or Gaussian distribution, with appropriate parameters depending on the desired level </span><span><span class="kobospan" id="kobo.759.1">of privacy.</span></span></li>
</ol>
<p class="calibre3"><span class="kobospan" id="kobo.760.1">The clipping technique serves to restrict the influence of individual data points on the function’s output and facilitates the addition of sufficient noise to preserve privacy effectively. </span><span class="kobospan" id="kobo.760.2">By bounding the sensitivity using clipping, differential privacy mechanisms can maintain data confidentiality while providing </span><span><span class="kobospan" id="kobo.761.1">accurate results.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.762.1">Let’s revisit the simple dataset that we </span><span><span class="kobospan" id="kobo.763.1">used earlier:</span></span></p>
<table class="no-table-style" id="table006-2">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.764.1">Name</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.765.1">Age</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.766.1">Salary</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.767.1">Gender</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.768.1">Title</span></strong></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.769.1">A</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.770.1">32</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.771.1">200K</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.772.1">M</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.773.1">Staff Engineer</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.774.1">B</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.775.1">44</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.776.1">300K</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.777.1">F</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.778.1">Manager</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.779.1">C</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.780.1">55</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.781.1">400K</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.782.1">F</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.783.1">Director</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.784.1">D</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.785.1">66</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.786.1">500K</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.787.1">M</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.788.1">VP</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.789.1">Table 4.7 - Sensitivity bounding analysis using clipping technique</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.790.1">Given the actual query, “How much is the total salary of all employees in this dataset?” </span><span class="kobospan" id="kobo.790.2">and the actual answer, which is 1,400K, providing the total salary with differential privacy requires the addition of noise using a noise mechanism such as a Laplace or Gaussian mechanism. </span><span class="kobospan" id="kobo.790.3">This noise mechanism relies on the sensitivity of </span><span><span class="kobospan" id="kobo.791.1">the query.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.792.1">To proceed, we must establish the lower and upper bounds as arbitrary fixed values. </span><span class="kobospan" id="kobo.792.2">By calculating the difference between the lower and upper bounds, we obtain the sensitivity of the query. </span><span class="kobospan" id="kobo.792.3">However, to delve deeper into this process, we will apply the clip function to the </span><span><span class="kobospan" id="kobo.793.1">input data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.794.1">By applying the clip function, we constrain the input data within a specific range, which aids in managing the sensitivity of the query. </span><span class="kobospan" id="kobo.794.2">This technique helps limit the influence of individual data points and facilitates the addition of noise in a controlled manner. </span><span class="kobospan" id="kobo.794.3">By employing clipping, we can strike a</span><a id="_idIndexMarker380" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.795.1"> balance between data privacy and utility, ensuring accurate results while preserving the confidentiality of </span><span><span class="kobospan" id="kobo.796.1">sensitive information.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.797.1">Let’s play with the clip function on a dataset and understand </span><span><span class="kobospan" id="kobo.798.1">this further.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.799.1">Clipping example 1</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.800.1">Let’s consider the following example </span><a id="_idIndexMarker381" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.801.1">use case: a social media platform wants to determine the average number of likes per user for a given post. </span><span class="kobospan" id="kobo.801.2">The platform wants to protect the privacy of its users while still obtaining an </span><span><span class="kobospan" id="kobo.802.1">accurate estimate.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.803.1">Here’s an implementation in Python without </span><span><span class="kobospan" id="kobo.804.1">differential privacy:</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.805.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.806.1">code: DP_End_to_End.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.807.1">
import random
# Generate a list of simulated likes per user
likes_per_user = [random.randint(0, 100) for _ in range(1000)]
print(likes_per_user)
# Calculate the average number of likes per user
average_likes = sum(likes_per_user) / len(likes_per_user)
print("Average likes per user (without differential
privacy):", average_likes)</span></pre>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.808.1">Average likes per user (without differential </span></em><span><em class="italic"><span class="kobospan" id="kobo.809.1">privacy): 51.146</span></em></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.810.1">Now, let’s implement the same use case using differential privacy techniques such as sensitivity, clipping, and noise. </span><span class="kobospan" id="kobo.810.2">We’ll use the</span><a id="_idIndexMarker382" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.811.1"> Laplace mechanism to inject noise into the </span><span><span class="kobospan" id="kobo.812.1">average calculation:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.813.1">
import random
import numpy as np
# Generate a list of simulated likes per user
likes_per_user = [random.randint(0, 100) for _ in range(1000)]
average_likes = sum(likes_per_user) / len(likes_per_user)
print("Average likes per user (without differential
privacy):", average_likes)
# Set the sensitivity
sensitivity = 1
# Clip the likes per user to a specified range
clipped_likes_per_user = np.clip(likes_per_user, 0, 100)
# Calculate the average number of likes per user
clipped_average_likes = np.mean(clipped_likes_per_user)
# Define the privacy budget and epsilon value
privacy_budget = 1.0
epsilon = 0.1
# Calculate the scale parameter for the Laplace distribution
scale = sensitivity / (privacy_budget * epsilon)
# Inject noise using the Laplace mechanism
noisy_average_likes = clipped_average_likes + np.random.laplace(0, scale)
print("Average likes per user (with differential privacy):", noisy_average_likes)
Average likes per user (without differential privacy): 51.252
Average likes per user (with differential privacy): 41.61714462702061</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.814.1">In this example, we set the</span><a id="_idIndexMarker383" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.815.1"> sensitivity to 1 since the average calculation has a sensitivity of 1 (changing one user’s likes can affect the average by, at most, 1). </span><span class="kobospan" id="kobo.815.2">Then, we clipped the likes per user to ensure they fall within a specific range (in this case, 0 </span><span><span class="kobospan" id="kobo.816.1">to 100).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.817.1">Next, we calculated the clipped average likes and defined the privacy budget and epsilon value. </span><span class="kobospan" id="kobo.817.2">The privacy budget represents the total amount of privacy protection available and the epsilon value controls the level </span><span><span class="kobospan" id="kobo.818.1">of privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.819.1">Finally, we calculated the scale parameter for the Laplace distribution based on the sensitivity, privacy budget, and epsilon. </span><span class="kobospan" id="kobo.819.2">We added noise to the clipped average likes using the Laplace mechanism, considering the </span><span><span class="kobospan" id="kobo.820.1">scale parameter.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.821.1">The resulting noisy_average_likes value provides an estimate of the average number of likes per user while incorporating differential privacy techniques to protect </span><span><span class="kobospan" id="kobo.822.1">users’ privacy.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.823.1">Clipping example 2</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.824.1">The following is another </span><a id="_idIndexMarker384" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.825.1">example </span><span><span class="kobospan" id="kobo.826.1">of clipping:</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.827.1">Source code : </span></em><span><em class="italic"><span class="kobospan" id="kobo.828.1">DP_End_to_End.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.829.1">
import pandas as pd
data = {'age': [32, 44, 55, 66],
  'salary': [200, 300, 400, 500]}
df = pd.DataFrame(data)
df['salary'].clip(lower=0, upper=999)</span></pre>
<p class="calibre3"><span><span class="kobospan" id="kobo.830.1">Output:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.831.1">
0    200
1    300
2    400
3    500
Name: salary, dtype: int64</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.832.1">In this case, if we apply the </span><strong class="source-inline"><span class="kobospan" id="kobo.833.1">clip</span></strong><span class="kobospan" id="kobo.834.1"> function provided by </span><strong class="source-inline"><span class="kobospan" id="kobo.835.1">Pandas</span></strong><span class="kobospan" id="kobo.836.1"> with a range of 0 and 9,999, then the salaries</span><a id="_idIndexMarker385" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.837.1"> don’t change because of the lower and upper bound values in the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.838.1">clip</span></strong></span><span><span class="kobospan" id="kobo.839.1"> function.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.840.1">Clipping example 3</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.841.1">The following is another example </span><span><span class="kobospan" id="kobo.842.1">of clipping:</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.843.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.844.1">code: DP_End_to_End.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.845.1">
import pandas as pd
data = {'age': [32, 44, 55, 66], 'salary': [200, 300, 400, 500]}
df = pd.DataFrame(data)
df['salary'].clip(lower=250, upper=400)</span></pre>
<p class="calibre3"><span><span class="kobospan" id="kobo.846.1">Output:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.847.1">
0    250
1    300
2    400
3    400
Name: salary, dtype: int64</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.848.1">In this case, when we set the upper bound to 400 and the lower bound to 250, the clip function changed salaries above 400 to 400 and below 250 to 250 (for example, 200 becomes 250 and 500 </span><span><span class="kobospan" id="kobo.849.1">becomes 400).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.850.1">pandas’ </span><strong class="source-inline"><span class="kobospan" id="kobo.851.1">clip</span></strong><span class="kobospan" id="kobo.852.1"> function </span><a id="_idIndexMarker386" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.853.1">will enforce that the input data is within the specified clipping bounds. </span><span class="kobospan" id="kobo.853.2">If one of the values is too small, it will be converted into the lower clipping bound, and if a value is too large, it will be converted into the upper </span><span><span class="kobospan" id="kobo.854.1">clipping bound.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.855.1">The following schema illustrates </span><span><span class="kobospan" id="kobo.856.1">this operation:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.857.1">Clip (250, 200, 300, 400, </span><span><span class="kobospan" id="kobo.858.1">500, </span></span><span><strong class="bold"><span class="kobospan" id="kobo.859.1">400</span></strong></span><span><span class="kobospan" id="kobo.860.1">)</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer053">
<span class="kobospan" id="kobo.861.1"><img alt="Figure 4.7 – Illustrating clipping functionality" src="image/B16573_04_07.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.862.1">Figure 4.7 – Illustrating clipping functionality</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.863.1">Since it is a toy dataset, we can look at the data and come up with proper lower and upper bounds for clipping </span><span><span class="kobospan" id="kobo.864.1">the data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.865.1">Let’s add noise to the clipped inputs’ sum with sensitivity (the clipped range difference) </span><span><span class="kobospan" id="kobo.866.1">and epsilon:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.867.1">
def laplace_mech(v, sensitivity, epsilon):
    return v + np.random.laplace(loc=0, scale=sensitivity/epsilon)
epsilon = 0.9
sensitivity=400-100
print(laplace_mech(df['salary'].clip(lower=100, upper=400).sum(),sensitivity,epsilon))
print(laplace_mech(df['salary'].sum(),sensitivity,epsilon))</span></pre>
<p class="calibre3"><span><span class="kobospan" id="kobo.868.1">Output:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.869.1">
1693.8114539575836.  (With clipped)
1793.7575175454226.  (without clipping)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.870.1">By employing appropriate lower and upper bounds, the results that were obtained using differential privacy are closer to the actual values, resulting in increased accuracy compared to using random bounds. </span><span class="kobospan" id="kobo.870.2">In this example, the actual total salary is 1,400K, but with added noise, the returned value </span><span><span class="kobospan" id="kobo.871.1">is 1,693K.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.872.1">However, one potential drawback of using specific lower and upper bounds is that they may inadvertently reveal the actual salaries of individuals present in the dataset, thereby </span><span><span class="kobospan" id="kobo.873.1">compromising privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.874.1">An alternative approach is to initialize the lower bound with a value of zero or a suitably low value and gradually increase the upper bound. </span><span class="kobospan" id="kobo.874.2">The process involves observing the query result and monitoring when it stops changing or becomes stable. </span><span class="kobospan" id="kobo.874.3">At this point, the value of the upper bound is stopped, ensuring that the query result does not reveal sensitive information and </span><span><span class="kobospan" id="kobo.875.1">preserving privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.876.1">This iterative approach allows for a balance between accuracy and privacy as it dynamically determines the bounds based on the characteristics of the data. </span><span class="kobospan" id="kobo.876.2">It helps prevent the disclosure of specific salary information while still providing reasonably accurate results within the scope of </span><span><span class="kobospan" id="kobo.877.1">differential privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.878.1">Let’s explore this approach with the </span><span><span class="kobospan" id="kobo.879.1">toy dataset:</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.880.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.881.1">code: DP_End_to_End.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.882.1">
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('seaborn-whitegrid')
data = {'age': [32, 44, 55,66], 'salary': [200, 300, 400, 500]}
df = pd.DataFrame(data)
def laplace_mech(queryresult, sensitivity, epsilon):
    return queryresult + np.random.laplace(loc=0, scale=sensitivity/epsilon)
epsilon = 0.5
plt.plot([laplace_mech(df['salary'].clip(lower=0, upper=i).sum(), i, epsilon) for i in range(100,800,100)])
plt.xlabel('Clipping ranges for salary')
plt.ylabel('Total salary');</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.883.1">Here’s </span><span><span class="kobospan" id="kobo.884.1">the </span></span><span><a id="_idIndexMarker387" class="pcalibre1 calibre6 pcalibre"/></span><span><span class="kobospan" id="kobo.885.1">output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer054">
<span class="kobospan" id="kobo.886.1"><img alt="Figure 4.8 –Total Salary vs Clipping ranges for Salary" src="image/B16573_04_08.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.887.1">Figure 4.8 –Total Salary vs Clipping ranges for Salary</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.888.1">Given the small size of the dataset, it’s relatively straightforward to identify the optimal clipping value for the query </span><a id="_idIndexMarker388" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.889.1">results – in this scenario, the sum of the salaries doesn’t increase beyond 500. </span><span class="kobospan" id="kobo.889.2">However, with larger datasets, the noise can sometimes become too dominant to analyze for all different sensitivity or </span><span><span class="kobospan" id="kobo.890.1">clipping values.</span></span></p>
<h1 id="_idParaDest-81" class="calibre5"><a id="_idTextAnchor089" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.891.1">Overview of real-life applications of differential privacy</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.892.1">In this section, we will go through a</span><a id="_idIndexMarker389" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.893.1"> high-level summary of a few real-world applications that make use of </span><span><span class="kobospan" id="kobo.894.1">differential privacy.</span></span></p>
<h2 id="_idParaDest-82" class="calibre7"><a id="_idTextAnchor090" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.895.1">Differential privacy usage at Uber</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.896.1">Uber Technologies, Inc. </span><span class="kobospan" id="kobo.896.2">provides</span><a id="_idIndexMarker390" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.897.1"> mobility as a service – that is, ride-hailing services. </span><span class="kobospan" id="kobo.897.2">It has to protect the privacy of the customers who make use of its services but at the same time analyze its data to provide a better service. </span><span class="kobospan" id="kobo.897.3">It has developed an open source framework to achieve differential privacy with SQL queries, which it made to analyze and derive insights. </span><span class="kobospan" id="kobo.897.4">All SQL queries are transformed using Uber’s differential privacy framework, which executes SQL queries</span><a id="_idIndexMarker391" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.898.1"> and provides the query results with differential </span><span><span class="kobospan" id="kobo.899.1">privacy guaranteed.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.900.1">It can be found on GitHub </span><span><span class="kobospan" id="kobo.901.1">at </span></span><a href="https://github.com/uber-archive/sql-differential-privacy" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.902.1">https://github.com/uber-archive/sql-differential-privacy</span></span></a><span><span class="kobospan" id="kobo.903.1">.</span></span></p>
<h2 id="_idParaDest-83" class="calibre7"><a id="_idTextAnchor091" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.904.1">Differential privacy usage at Apple</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.905.1">Apple, Inc. </span><span class="kobospan" id="kobo.905.2">has incorporated local </span><a id="_idIndexMarker392" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.906.1">differential privacy on a large scale in its products with the aim of understanding and enhancing the user experience. </span><span class="kobospan" id="kobo.906.2">They’ve employed a private count mean sketch algorithm, which utilizes count, mean, sketch, and a privacy budget (epsilon). </span><span class="kobospan" id="kobo.906.3">For each key feature, they’ve established a privacy budget and the maximum number of records (differentially private records) that can be transmitted to a remote server after sensitive features such as IP addresses have </span><span><span class="kobospan" id="kobo.907.1">been removed:</span></span></p>
<table class="no-table-style" id="table007-2">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.908.1">Key Feature</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.909.1">Epsilon (</span></strong></span><span><span><span class="kobospan" id="kobo.910.1">𝜺</span></span></span><span><strong class="bold"><span class="kobospan" id="kobo.911.1">)</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.912.1">Number of Records per Day for </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.913.1">Each Device</span></strong></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.914.1">Emoji suggestions</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.915.1">4</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.916.1">1</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.917.1">Lookup hints</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.918.1">4</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.919.1">2</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.920.1">QuickType</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.921.1">8</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.922.1">2</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.923.1">….</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.924.1">Table 4.8 - Implementation of local differential privacy by Apple, Inc.</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.925.1">It injects noise after encoding the input vector using a hash function and flips each vector element with a probability of</span><span> </span><span class="kobospan" id="kobo.926.1">1/(1 + 𝑒 </span><span class="superscript"><span class="kobospan1" id="kobo.927.1">𝜀</span></span><span class="superscript"><span class="kobospan1" id="kobo.928.1">/2</span></span><span class="kobospan" id="kobo.929.1">), where </span><span><span class="kobospan" id="kobo.930.1">ε</span></span><span class="kobospan" id="kobo.931.1"> is the </span><span><span class="kobospan" id="kobo.932.1">privacy budget.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.933.1">More details about this algorithm can be found </span><span><span class="kobospan" id="kobo.934.1">at </span></span><a href="https://machinelearning.apple.com/research/learning-with-privacy-at-scale" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.935.1">https://machinelearning.apple.com/research/learning-with-privacy-at-scale</span></span></a><span><span class="kobospan" id="kobo.936.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.937.1">Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, Xiaofeng Wang, et al. </span><span class="kobospan" id="kobo.937.2">have undertaken a detailed analysis of Apple’s differential privacy implementation by debugging the client-side code and published a research article in Arxiv. </span><span class="kobospan" id="kobo.937.3">I strongly recommend that you read this paper to understand Apple’s implementation better and the additional details that </span><a id="_idIndexMarker393" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.938.1">were considered: </span><em class="italic"><span class="kobospan" id="kobo.939.1">Privacy Loss in Apple’s Implementation of Differential Privacy on MacOS </span></em><span><em class="italic"><span class="kobospan" id="kobo.940.1">10.12</span></em></span><span><span class="kobospan" id="kobo.941.1"> (</span></span><a href="https://arxiv.org/abs/1709.02753" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.942.1">https://arxiv.org/abs/1709.02753</span></span></a><span><span class="kobospan" id="kobo.943.1">).</span></span></p>
<h2 id="_idParaDest-84" class="calibre7"><a id="_idTextAnchor092" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.944.1">Differential privacy usage in the US Census</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.945.1">The US Census Bureau used differential </span><a id="_idIndexMarker394" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.946.1">privacy to apply noise to the 2020 census data to protect respondents’ confidentiality in the collected and shared </span><span><span class="kobospan" id="kobo.947.1">census data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.948.1">More details can be found </span><span><span class="kobospan" id="kobo.949.1">at </span></span><a href="https://www.census.gov/data/academy/webinars/2021/disclosure-avoidance-series/differential-privacy-101.html" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.950.1">https://www.census.gov/data/academy/webinars/2021/disclosure-avoidance-series/differential-privacy-101.html</span></span></a><span><span class="kobospan" id="kobo.951.1">.</span></span></p>
<h2 id="_idParaDest-85" class="calibre7"><a id="_idTextAnchor093" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.952.1">Differential privacy at Google</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.953.1">Google uses differential privacy in its Chrome</span><a id="_idIndexMarker395" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.954.1"> browser to find out about frequently visited pages; Google Maps and Google Assistant also have this functionality. </span><span class="kobospan" id="kobo.954.2">The differential privacy system that it has developed is called </span><strong class="bold"><span class="kobospan" id="kobo.955.1">Randomized Aggregatable Privacy-Preserving Ordinal Response</span></strong><span class="kobospan" id="kobo.956.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.957.1">RAPPOR</span></strong><span class="kobospan" id="kobo.958.1">) and provides an epsilon value of 2 as the lower limit and 8 to 9 as the </span><a id="_idIndexMarker396" class="pcalibre1 calibre6 pcalibre"/><span><span class="kobospan" id="kobo.959.1">upper limit.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.960.1">Google has open sourced the implementation of RAPPOR. </span><span class="kobospan" id="kobo.960.2">You can learn more about this </span><span><span class="kobospan" id="kobo.961.1">at </span></span><a href="https://github.com/google/rappor" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.962.1">https://github.com/google/rappor</span></span></a><span><span class="kobospan" id="kobo.963.1">.</span></span></p>
<h1 id="_idParaDest-86" class="calibre5"><a id="_idTextAnchor094" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.964.1">Summary</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.965.1">In this chapter, we covered the concept of differential privacy and explored how the Laplace and Gaussian mechanisms can generate noise to ensure privacy while generating aggregate query results. </span><span class="kobospan" id="kobo.965.2">We discussed the significance of parameters such as epsilon, delta, and sensitivity, and how they are used to calculate noise using Laplace or Gaussian distributions. </span><span class="kobospan" id="kobo.965.3">Additionally, we learned about the process of determining upper and lower bounds using the clipping technique. </span><span class="kobospan" id="kobo.965.4">Finally, we provided a summary of how differential privacy is used in real-world applications at Apple and Uber and by the US </span><span><span class="kobospan" id="kobo.966.1">Census Bureau.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.967.1">In the next chapter, we will delve into open source frameworks for differential privacy. </span><span class="kobospan" id="kobo.967.2">We will explore how to develop applications using these frameworks and dive into the realm of machine learning with differential privacy in detail. </span><span class="kobospan" id="kobo.967.3">This will provide a comprehensive understanding of how to implement differential privacy in practical scenarios and how to leverage its benefits in the context of machine </span><span><span class="kobospan" id="kobo.968.1">learning applications.</span></span></p>
</div>
</body></html>