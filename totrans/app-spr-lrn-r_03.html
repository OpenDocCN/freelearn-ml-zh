<html><head></head><body>
		<div id="_idContainer055" class="Content">
			<h1 id="_idParaDest-118"><em class="italics"><a id="_idTextAnchor119"/>Chapter 3:</em></h1>
		</div>
		<div id="_idContainer056" class="Content">
			<h1 id="_idParaDest-119"><a id="_idTextAnchor120"/>Introduction to Supervised Learning</h1>
		</div>
		<div id="_idContainer057" class="Content">
			<h2>Learning Objectives</h2>
			<p>By the end of this chapter, you will be able to:</p>
			<ul>
				<li class="bullets">Explain supervised learning and machine learning workflow</li>
				<li class="bullets">Use and explore the Beijing PM2.5 dataset</li>
				<li class="bullets">Explain the difference between continuous and categorical dependent variables</li>
				<li class="bullets">Implement the basic regression and classification algorithms in R</li>
				<li class="bullets">Identify the key differences between supervised learning and other types of machine learning</li>
				<li class="bullets">Work with the evaluation metrics of supervised learning algorithms</li>
				<li class="bullets">Perform model diagnostics for avoiding biased coefficient estimates and large standard errors</li>
			</ul>
			<p>In this chapter, we will introduce supervised learning and demonstrate the workflow of building machine learning models with real-world examples.</p>
		</div>
		<div id="_idContainer102" class="Content">
			<h2 id="_idParaDest-120"><a id="_idTextAnchor121"/>Introduction</h2>
			<p>In the previous chapters, we explored some of packages of R, such as the <strong class="inline">dplyr</strong>, <strong class="inline">plyr</strong>, <strong class="inline">lubridate</strong>, and <strong class="inline">ggplot2</strong>, where we discussed the basics of storing and processing data in R. Later, the same ideas were used in Exploratory Data Analysis (EDA) to understand the ways to break data into smaller parts, extract insights from data, and explore other ways to understand the data better, before venturing into advanced modeling techniques.</p>
			<p>In this chapter, we will take one step further toward introducing machine learning ideas. While broadly laying the foundation for thinking about various algorithms in machine learning, we will discuss supervised learning at length.</p>
			<p>Supervised learning is based on data that is well labeled by domain experts. For classifying cats and dogs from images, an algorithm first needs to see the images labeled as cats and dogs and then learn the features based on the label. Most enterprises with a good volume of historical data are the biggest beneficiaries of the wealth of knowledge they can extract from such data. If the data is clean and annotated well, supervised learning can result in a high accuracy of prediction, unlike other machine learning algorithms, which generally produce large errors in the beginning. In the absence of the right labels, it becomes difficult to derive any meaning out of data, other than just being able to do exploratory analysis and clustering.</p>
			<p>The standard component in solving real-world problems like predicting loan default (yes/no), failure of manufacturing machines in factories (yes/no), object detection in driverless cars (road, car, signal), predicting stock market prices (numeric) is a set of inputs (features) and a given output (label), which is usually obtained from historical data. When we predict the quantitative output, we call it <strong class="bold">regression</strong>, and when we predict the qualitative output, we call it <strong class="bold">classification</strong>.</p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor122"/>Summary of the Beijing PM2.5 Dataset</h2>
			<p>In the urban and rural parts of many nations, the primary pollutant, fine particulate matter, is the cause of many health risks in humans and also affects climate change. In particular, PM2.5, defined as an airborne particle with an aerodynamic diameter of less than 2.5 µm, is the major category of atmospheric particulate matter. Various studies have linked PM2.5 with serious health problems such as heart attack and lung morbidity. The table in this section shows the types of atmospheric particulate matter and their size distribution in micrometers.</p>
			<p>In this and the remaining chapters, we will use the dataset published by the authors of the research paper, <em class="italics">Assessing Beijing's PM2.5 pollution: severity, weather impact, APEC and winter heating</em>, where they use hourly PM2.5 readings taken at the US Embassy in Beijing located at 116.47 E, 39.95 N in conjunction with hourly meteorological measurements at <strong class="bold">Beijing Capital International Airport</strong> (<strong class="bold">BCIA</strong>), obtained from weather.nocrew.org. Their study claims to be the first to combine PM2.5 and meteorological data for an extended period in China's PM2.5 pollution. The following table describes the attributes in the dataset:</p>
			<div>
				<div id="_idContainer058" class="IMG---Figure">
					<img src="image/C12624_03_01.jpg" alt="Figure 3.1: Attributes in Beijing's PM2.5 dataset.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.1: Attributes in Beijing's PM2.5 dataset.</h6>
			<h3 id="_idParaDest-122"><a id="_idTextAnchor123"/>Exercise 40: Exploring the Data</h3>
			<p>In this exercise, we will learn the structure of the data with sample values for each attribute and use the <strong class="inline">summary</strong> function. We will see the five number summary statistics for numeric variables.</p>
			<p>Perform the following steps to complete this exercise:</p>
			<ol>
				<li>First, use the following command to read the Beijing PM2.5 dataset into the PM25 DataFrame object:<p class="snippet">PM25 &lt;- read.csv("https://raw.githubusercontent.com/TrainingByPackt/Applied-Supervised-Learning-with-R/master/Lesson03/PRSA_data_2010.1.1-2014.12.31.csv")</p></li>
				<li>Next, print the structure of data with sample values using the <strong class="inline">str</strong> command:<p class="snippet">str(PM25)</p><p>The output of the previous command is as follows:</p><p class="snippet">'data.frame':	43824 obs. of  13 variables:</p><p class="snippet"> $ No   : int  1 2 3 4 5 6 7 8 9 10 ...</p><p class="snippet"> $ year : int  2010 2010 2010 2010 2010 2010 2010 2010 2010 2010 ...</p><p class="snippet"> $ month: int  1 1 1 1 1 1 1 1 1 1 ...</p><p class="snippet"> $ day  : int  1 1 1 1 1 1 1 1 1 1 ...</p><p class="snippet"> $ hour : int  0 1 2 3 4 5 6 7 8 9 ...</p><p class="snippet"> $ pm2.5: int  NA NA NA NA NA NA NA NA NA NA ...</p><p class="snippet"> $ DEWP : int  -21 -21 -21 -21 -20 -19 -19 -19 -19 -20 ...</p><p class="snippet"> $ TEMP : num  -11 -12 -11 -14 -12 -10 -9 -9 -9 -8 ...</p><p class="snippet"> $ PRES : num  1021 1020 1019 1019 1018 ...</p><p class="snippet"> $ cbwd : Factor w/ 4 levels "cv","NE","NW",..: 3 3 3 3 3 3 3 3 3 3 ...</p><p class="snippet"> $ Iws  : num  1.79 4.92 6.71 9.84 12.97 ...</p><p class="snippet"> $ Is   : int  0 0 0 0 0 0 0 0 0 0 ...</p><p class="snippet"> $ Ir   : int  0 0 0 0 0 0 0 0 0 0 ...</p><h4>Note</h4><p class="callout">Observe that the dataset contains <strong class="inline">43824</strong> observations and 13 attributes. Observe that the dataset contains data from 2010 to 2014. The values of pm2.5, temperature, pressure, combined wind direction, cumulated wind speed, cumulated hours of snow, and cumulated hours of rain are aggregated at every hour of the day.</p></li>
				<li>Now, let's show the summary statistics of the dataset:<p class="snippet">summary(PM25)</p><p>The output is as follows:</p><p class="snippet">       No             year          month             day             hour           pm2.5       </p><p class="snippet"> Min.   :    1   Min.   :2010   Min.   : 1.000   Min.   : 1.00   Min.   : 0.00   Min.   :  0.00  </p><p class="snippet"> 1st Qu.:10957   1st Qu.:2011   1st Qu.: 4.000   1st Qu.: 8.00   1st Qu.: 5.75   1st Qu.: 29.00  </p><p class="snippet"> Median :21912   Median :2012   Median : 7.000   Median :16.00   Median :11.50   Median : 72.00  </p><p class="snippet"> Mean   :21912   Mean   :2012   Mean   : 6.524   Mean   :15.73   Mean   :11.50   Mean   : 98.61  </p><p class="snippet"> 3rd Qu.:32868   3rd Qu.:2013   3rd Qu.:10.000   3rd Qu.:23.00   3rd Qu.:17.25   3rd Qu.:137.00  </p><p class="snippet"> Max.   :43824   Max.   :2014   Max.   :12.000   Max.   :31.00   Max.   :23.00   Max.   :994.00  </p><p class="snippet">                                                                                 NA's   :2067    </p><p class="snippet">      DEWP              TEMP             PRES      cbwd            Iws               Is          </p><p class="snippet"> Min.   :-40.000   Min.   :-19.00   Min.   : 991   cv: 9387   Min.   :  0.45   Min.   : 0.00000  </p><p class="snippet"> 1st Qu.:-10.000   1st Qu.:  2.00   1st Qu.:1008   NE: 4997   1st Qu.:  1.79   1st Qu.: 0.00000  </p><p class="snippet"> Median :  2.000   Median : 14.00   Median :1016   NW:14150   Median :  5.37   Median : 0.00000  </p><p class="snippet"> Mean   :  1.817   Mean   : 12.45   Mean   :1016   SE:15290   Mean   : 23.89   Mean   : 0.05273  </p><p class="snippet"> 3rd Qu.: 15.000   3rd Qu.: 23.00   3rd Qu.:1025              3rd Qu.: 21.91   3rd Qu.: 0.00000  </p><p class="snippet"> Max.   : 28.000   Max.   : 42.00   Max.   :1046              Max.   :585.60   Max.   :27.00000  </p><p class="snippet">                  </p><p class="snippet">       Ir         </p><p class="snippet"> Min.   : 0.0000  </p><p class="snippet"> 1st Qu.: 0.0000  </p><p class="snippet"> Median : 0.0000  </p><p class="snippet"> Mean   : 0.1949  </p><p class="snippet"> 3rd Qu.: 0.0000  </p><p class="snippet"> Max.   :36.0000</p></li>
			</ol>
			<p>The following image is a graphical representation of the size distribution (in micrometers) of atmospheric particulate matter:</p>
			<div>
				<div id="_idContainer059" class="IMG---Figure">
					<img src="image/C12624_03_02.jpg" alt="Figure 3.2: Types and size distribution (in micrometers) of atmospheric particulate matter.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.2: Types and size distribution (in micrometers) of atmospheric particulate matter.</h6>
			<h6>Source: https://en.wikipedia.org/wiki/File:Airborne-particulate-size-chart.svg</h6>
			<h4>Note</h4>
			<p class="callout">The authors of the article "The impact of PM2.5 on the human respiratory system" published in the <strong class="bold">Journal of Thoracic Disease</strong> (<strong class="bold">JTD</strong>) discuss the association of air pollution with respiratory system diseases. They offer a comprehensive data-driven approach for explaining the factors causing such respiratory diseases. Special attention is given to Beijing, where the adverse effect of rising PM2.5 has been studied extensively by researchers and has become a mainstream discussion point in the various climate change forums around the world. One can find more detail in the article at https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4740125/.</p>
			<h2 id="_idParaDest-123"><a id="_idTextAnchor124"/>Regression and Classification Problems</h2>
			<p>We see classification and regression problems all around us in our daily life. The chances of rain from https://weather.com, our emails getting filtered into the spam mailbox and inbox, our personal and home loans getting accepted or rejected, deciding to pick our next holiday destination, exploring the options for buying a new house, investment decisions to gain short- and long-term benefits, purchasing the next book from Amazon; the list goes on and on. The world around us today is increasingly being run by algorithms that help us with our choices (which is not always a good thing).</p>
			<p>As discussed in <em class="italics">Chapter 2</em>, <em class="italics">Exploratory Analysis of Data</em>, we will use the <strong class="bold">Minto Pyramid</strong> principle called <strong class="bold">Situation–Complication–Question</strong> (<strong class="bold">SCQ</strong>) to define our problem statement. The following table shows the SCQ approach for Beijing's PM2.5 problem:</p>
			<div>
				<div id="_idContainer060" class="IMG---Figure">
					<img src="image/C12624_03_03.jpg" alt="Figure 3.3: Applying SCQ on Beijing's PM2.5 problem.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.3: Applying SCQ on Beijing's PM2.5 problem.</h6>
			<p>Now, in the SCQ construct described in the previous table, we can do a simple correlation analysis to establish the factors affecting the PM2.5 levels or create a predictive problem (prediction means finding an approximate function that maps from input variables to an output) that estimates the PM2.5 levels using all the factors. For the clarity of terminology, we will refer to factors as input variables. Then, PM2.5 becomes the dependent variable (often referred to as output variable). The dependent variable could be either categorical or continuous. </p>
			<p>For example, in the email classification into <strong class="bold">SPAM</strong>/<strong class="bold">NOT SPAM</strong> problem, the dependent variable is categorical. The following table highlights some critical differences between regression and classification problems:</p>
			<div>
				<div id="_idContainer061" class="IMG---Figure">
					<img src="image/C12624_03_04.jpg" alt="Figure 3.4: Difference between regression and classification problems.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.4: Difference between regression and classification problems.</h6>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor125"/>Machine Learning Workflow</h2>
			<p>In order to demonstrate the end-to-end process of building a predictive model (machine learning or supervised learning), we have created an easy-to-comprehend workflow. The first step is to design the problem, then source and prepare the data, which leads to coding the model for training and evaluation, and, finally, deploying the model. In the scope of this chapter, we will keep the model explanation to a bare minimum, as it will be covered again in detail in chapters 4 and 5.</p>
			<p>The following figure describes the workflow required to build a predictive model starting from preparing the data to deploying the model:</p>
			<div>
				<div id="_idContainer062" class="IMG---Figure">
					<img src="image/C12624_03_05.jpg" alt="Figure 3.5: Machine learning workflow.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.5: Machine learning workflow.</h6>
			<h3 id="_idParaDest-125"><a id="_idTextAnchor126"/>Design the Problem</h3>
			<p>Once we identify the domain of work, brainstorming on the designing of the problem is carried out. The idea is to first define the problem as a regression or classification problem. Once that is done, we choose the right target variable, along with identifying the features. The target variable is important because it decides how the training will take place. A supervised learning algorithm keeps the target variable at the center, while it tries to find a pattern from the given set of features.</p>
			<h3 id="_idParaDest-126"><a id="_idTextAnchor127"/>Source and Prepare Data</h3>
			<p>Data gathering and preparation is a painstaking job, mainly when the data sources are diverse and many. With each data source, the challenges are different and hence the time taken to process it varies. Data sources with tabular data are the easiest to process provided they do not contain a lot of garbage information, whereas textual data is the hardest to clean because of its free-flowing nature.</p>
			<h3 id="_idParaDest-127"><a id="_idTextAnchor128"/>Code the Model</h3>
			<p>Once the data is prepared and ready, we take up the task of choosing the right model. Most often, the experts first go with one baseline model to gauge the predictability power of the algorithm using input features and the target variable. Then, one can either directly try the state-of-the-art algorithms or decide to go with a trial-and-error method (of trying to use all the possible models). One must understand that there is no right or wrong model, and everything depends on the data. In coding, the data is randomly divided into training and testing. The code is written to train the model on the training dataset, and evaluation happens on the testing data. This ensures that the model does not underperform when it is deployed in the real world.</p>
			<h3 id="_idParaDest-128"><a id="_idTextAnchor129"/>Train and Evaluate</h3>
			<p>Model evaluation is the important part of the model, where its usability in practice is decided. Based on a given set of model evaluation metrics, we need to decide, after all the trial and error, the best model. In each iteration, metrics such as the R-squared value, accuracy, precision, and F-score are computed. Usually, the entire data is divided into training and testing data (with a third split for validation set also often included). The model is trained on the training data and tested on the testing data. This separation ensures that the model is not doing any rote learning. In more technical terms, the model is not overfitting (more on this in the <em class="italics">Evaluation Metrics</em> section in this chapter). Usually, at this stage of the workflow, one could decide to go back and include more variables, train the model, and redeploy. The process is repeated until the accuracy (or the other metrics of importance) of the model reaches a plateau.</p>
			<p>We use a random number generator function like <strong class="inline">sample()</strong> in R for splitting the data randomly into different parts as done in the next exercise 2, step 2.</p>
			<h3 id="_idParaDest-129"><a id="_idTextAnchor130"/>Exercise 41: Creating a Train-and-Test Dataset Randomly Generated by the Beijing PM2.5 Dataset</h3>
			<p>In this exercise, we will create a randomly generated train-and-test dataset from the Beijing PM2.5 dataset. We will reuse the <strong class="inline">PM25</strong> object created in the earlier exercise.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">Create a <strong class="inline">num_index</strong> variable and set it to a value equal to the number of observations in the Beijing's PM2.5 dataset:<p class="snippet">num_index &lt;- nrow(PM25)</p></li>
				<li>Using the <strong class="inline">sample()</strong> function, randomly select 70% of the <strong class="inline">num_index</strong> values, and store them in <strong class="inline">train_index</strong>:<p class="snippet">train_index &lt;- sample(1:num_index, 0.7*nrow(PM25))</p></li>
				<li>Use <strong class="inline">train_index</strong> to select a random subset of rows from the Beijing PM2.5 dataset and store them in a DataFrame named <strong class="inline">PM25_Train</strong>:<p class="snippet">PM25_Train &lt;- PM25[train_index,]</p></li>
				<li>Store the remaining observation into a DataFrame named <strong class="inline">PM25_Test</strong>:<p class="snippet">PM25_Test &lt;- PM25[-train_index,]</p></li>
			</ol>
			<p>The exercise shows a simple example for creating the train-and-test set. A randomly selected set for training and testing ensures that the model has no bias and learns well from all the possible examples before being used in the real world on unseen data.</p>
			<h3 id="_idParaDest-130"><a id="_idTextAnchor131"/>Deploy the Model</h3>
			<p>Once the best model is selected, the next step is to enable the model output to be used by a business application. The model is hosted as a <strong class="bold">REpresentational State Transfer</strong> (<strong class="bold">REST</strong>) API. These APIs are a way to host a web application as an endpoint that listens to any request for a model call and usually returns a JSON object as a response.</p>
			<p>Deployment of the model is becoming an essential part of all machine learning projects in the industry. A model that is not deployable is no good for a company, and perhaps, merely serves the purpose of R&amp;D. An increasing number of professionals are specializing in model deployment, which is sometimes a tedious and complicated process. In order to give the model deployment its due importance, we have given it a dedicated chapter, that is <em class="italics">Chapter 8</em>, <em class="italics">Model Deployment</em>.</p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor132"/>Regression</h2>
			<p>Now that we have seen the machine learning workflow, we will take two widely used types of machine learning algorithms: regression and classification; both employ supervised learning to train the models. The entire theme of this book revolves around these two types of algorithms. The Beijing PM2.5 dataset will be used extensively in demonstrating both these types. The dataset will help in understanding how one can convert a regression problem into a classification problem and vice versa.</p>
			<h3 id="_idParaDest-132"><a id="_idTextAnchor133"/>Simple and Multiple Linear Regression</h3>
			<p>Regression is one of the most useful and essential tools in analytics and econometrics (the branch of economics concerned with the use of mathematical methods, especially statistics, in describing economic systems). In many ways, modern machine learning has its roots in statistics, and one can attribute that mostly to Sir Francis Galton's work. Galton was an English Victorian-era statistician and polymath with deep interest and expertise in fields such as genetics, psychology, and anthropology. He was the first to apply statistical methods to study human behavior and intelligence. Notably, his publication, <em class="italics">Regression Towards Mediocrity in Hereditary Stature</em>, had many insightful findings based on regression.</p>
			<p>In this section, we will briefly analyze the various factors that affect the PM2.5 levels using the Beijing dataset. In particular, the effect of variables such as dew point, temperature, wind speed, and pressure on PM2.5 will be explored.</p>
			<h3 id="_idParaDest-133"><a id="_idTextAnchor134"/>Assumptions in Linear Regression Models</h3>
			<p>As regression borrows many of its concepts from applied statistics to model the data, it comes with many assumptions. One should not apply regression algorithms to any dataset or problem. Let's examine the assumptions for linear regression before we build any model.</p>
			<p>The following table shows the assumptions and how we can statistically test whether the linear regression model follows the assumption or not. The table also shows some corrective actions if the assumption is violated. We will take up an elaborate discussion on these assumptions and perform diagnostic analysis to identify the violation in much detail in <em class="italics">Chapter 4</em>, <em class="italics">Regression.</em></p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/C12624_03_06.jpg" alt="Figure 3.6: Various assumptions in a linear regression model (Part 1).&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.6: Various assumptions in a linear regression model (Part 1).</h6>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/C12624_03_07.jpg" alt="Figure 3.7: Various assumptions in a linear regression model (Part 2).&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.7: Various assumptions in a linear regression model (Part 2).</h6>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor135"/>Exploratory Data Analysis (EDA)</h2>
			<p>Building regression models requires an in-depth analysis of the patterns and relationship between target and input variables. The Beijing dataset provides a magnitude of different environmental factors that may affect the PM2.5 levels in the atmosphere.</p>
			<h3 id="_idParaDest-135"><a id="_idTextAnchor136"/>Exercise 42: Exploring the Time Series Views of PM2.5, DEWP, TEMP, and PRES variables of the Beijing PM2.5 Dataset</h3>
			<p>In this exercise, we will visualize the <strong class="inline">pm2.5</strong>, <strong class="inline">DEWP</strong>, <strong class="inline">TEMP</strong>, and <strong class="inline">PRES</strong> variables in a time series plot and observe any patterns that may emerge over the years in these variables.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Import all the required libraries in the system:<p class="snippet">library(dplyr)</p><p class="snippet">library(lubridate)</p><p class="snippet">library(tidyr)</p><p class="snippet">library(grid)</p><p class="snippet">library(ggplot2)</p></li>
				<li>Next, transform year, month, and hour into datetime using the <strong class="inline">lubridate</strong> package function named <strong class="inline">ymd_h</strong>:<p class="snippet">PM25$datetime &lt;- with(PM25, ymd_h(sprintf('%04d%02d%02d%02d', year, month, day,hour)))</p></li>
				<li>Plot the PM2.5, TEMP, DEWP, and PRES for all the years using the following command:<p class="snippet">plot_pm25 &lt;- PM25 %&gt;%</p><p class="snippet">  select(datetime, pm2.5) %&gt;%</p><p class="snippet">  na.omit() %&gt;%</p><p class="snippet">  ggplot() + </p><p class="snippet">  geom_point(aes(x = datetime, y = pm2.5), size = 0.5, alpha = 0.75) +</p><p class="snippet">  ylab("PM2.5")</p><p class="snippet">plot_TEMP &lt;- PM25 %&gt;%</p><p class="snippet">  select(datetime, TEMP) %&gt;%</p><p class="snippet">  na.omit() %&gt;%</p><p class="snippet">  ggplot() + </p><p class="snippet">  geom_point(aes(x = datetime, y = TEMP), size = 0.5, alpha = 0.75) +</p><p class="snippet">  ylab("TEMP")</p><p class="snippet">plot_DEWP &lt;- PM25 %&gt;%</p><p class="snippet">  select(datetime, DEWP) %&gt;%</p><p class="snippet">  na.omit() %&gt;%</p><p class="snippet">  ggplot() + </p><p class="snippet">  geom_point(aes(x = datetime, y = DEWP), size = 0.5, alpha = 0.75) +</p><p class="snippet">  ylab("DEWP")</p><p class="snippet">plot_PRES &lt;- PM25 %&gt;%</p><p class="snippet">  select(datetime, PRES) %&gt;%</p><p class="snippet">  na.omit() %&gt;%</p><p class="snippet">  ggplot() + </p><p class="snippet">  geom_point(aes(x = datetime, y = PRES), size = 0.5, alpha = 0.75) +</p><p class="snippet">  ylab("PRES")</p></li>
				<li>Now, use the following command to plot the graphs:<p class="snippet">grid.newpage()</p><p class="snippet">grid.draw(rbind(ggplotGrob(plot_pm25), ggplotGrob(plot_TEMP),ggplotGrob(plot_DEWP),ggplotGrob(plot_PRES), size = "last"))</p><p>The plot is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/C12624_03_08.jpg" alt="Figure 3.8: Scatterplot showing the trend and seasonality of environmental factors like temperature, dew point, and pressure, along with PM2.5 levels in Beijing from 2010 to 2014 end.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.8: Scatterplot showing the trend and seasonality of environmental factors like temperature, dew point, and pressure, along with PM2.5 levels in Beijing from 2010 to 2014 end.</h6>
			<p>In this exercise, we first show a time series view of the <strong class="inline">PM2.5</strong>, <strong class="inline">DEWP</strong>, <strong class="inline">TEMP</strong>, and <strong class="inline">PRES</strong> variables from the dataset and observe the pattern. As shown in <em class="italics">Figure 3.8</em>, a distinct seasonality is observed <strong class="bold">year on year</strong> (<strong class="bold">YoY</strong>). While <strong class="inline">DEWP</strong>, <strong class="inline">TEMP</strong>, and <strong class="inline">PRES</strong> show seasonality (the same pattern repeating every 12 months), PM2.5 seems to have a random pattern. This is an early indication that it's highly unlikely that we will see any effect of the three variables on PM2.5. However, let's probe further to ascertain this hypothesis using a correlation plot and observe if there exits any relationship between the variables.</p>
			<h3 id="_idParaDest-136"><a id="_idTextAnchor137"/>Exercise 43: Undertaking Correlation Analysis</h3>
			<p>In this exercise, we will undertake a correlation analysis to study the strength of the relationship between the various factors.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Import the <strong class="inline">corrplot</strong> package into the system using the following command:<p class="snippet">library(corrplot)</p></li>
				<li>Now, create a new object and store the required values from <strong class="inline">PM25</strong> into it:<p class="snippet">corr &lt;- cor(PM25[!is.na(PM25$pm2.5),c("pm2.5","DEWP","TEMP","PRES","Iws","Is","Ir")])</p></li>
				<li>Use the <strong class="inline">corrplot</strong> package to display the graphical representation of a correlation matrix:<p class="snippet">corrplot(corr)</p><p>The plot is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/C12624_03_09.jpg" alt="Figure 3.9: Correlation between all the pairs of variables in the Beijing dataset.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.9: Correlation between all the pairs of variables in the Beijing dataset.</h6>
			<p>First, we compute the correlation between all the variables. The resulting correlation plot shows that there appear to be no strong correlations between PM2.5 and the other variables. However, <strong class="inline">PM2.5</strong> and <strong class="inline">DEWP</strong>, <strong class="inline">TEMP</strong>, and <strong class="inline">Iws</strong> show some mild correlation, which indicates some relationship. This should not come as a surprise, because we saw in <em class="italics">Figure 3.8</em>, that while three variables follow a seasonality trend, PM2.5 seems more random. Note here that we have not done any processing or transformation to the dataset; these findings come directly from our first level of analysis. We will go into much detail later, in <em class="italics">Chapter 4</em>, <em class="italics">Regression</em>. Now, let's also visualize the relationship between the variables using a scatterplot.</p>
			<h3 id="_idParaDest-137"><a id="_idTextAnchor138"/>Exercise 44: Drawing a Scatterplot to Explore the Relationship between PM2.5 Levels and Other Factors</h3>
			<p>In this exercise, we will use a scatterplot to explore the relationship between <strong class="inline">pm2.5</strong> levels and other factors. We will like to see whether there emerge any interesting patterns or relationships. A scatterplot is a simple and effective visualization for exploratory analysis on the relationships between variables.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Import the <strong class="inline">ggplot2</strong> package into your system:<p class="snippet">library(ggplot2)</p></li>
				<li>Plot the scatterplot between <strong class="inline">DEWP</strong> and <strong class="inline">PM2.5</strong>, with the <strong class="inline">month</strong> variable used for color:<p class="snippet">ggplot(data = PM25, aes(x = DEWP, y = pm2.5, color = month)) +  geom_point() +  geom_smooth(method='auto',formula=y~x, colour = "red", size =1.5)</p><p>The scatterplot is as follows:</p><div id="_idContainer067" class="IMG---Figure"><img src="image/C12624_03_10.jpg" alt="Figure 3.10: Scatterplot showing the relationship between DEWP and PM2.5 levels.&#13;&#10;"/></div><h6>Figure 3.10: Scatterplot showing the relationship between DEWP and PM2.5 levels.</h6></li>
				<li>Plot the scatterplot between <strong class="inline">TEMP</strong> and <strong class="inline">PM2.5</strong>, with the <strong class="inline">month</strong> variable used for color:<p class="snippet">ggplot(data = PM25, aes(x = TEMP, y = pm2.5, color = month)) +  geom_point() +  geom_smooth(method='auto',formula=y~x, colour = "red", size =1.5)</p><p>The scatterplot is as follows:</p><div id="_idContainer068" class="IMG---Figure"><img src="image/C12624_03_11.jpg" alt="Figure 3.11: Scatterplot showing the relationship between TEMP and PM2.5 levels.&#13;&#10;"/></div><h6>Figure 3.11: Scatterplot showing the relationship between TEMP and PM2.5 levels.</h6></li>
				<li>Create a scatterplot between <strong class="inline">DEWP</strong> and <strong class="inline">PM2.5</strong>, with an hour of the day used for color and separate views for months of the year:<p class="snippet">ggplot(data = PM25, aes(x = DEWP, y = pm2.5, color = hour)) +  geom_point() +  geom_smooth(method='auto',formula=y~x, colour = "red", size =1) +  facet_wrap(~ month, nrow = 4)</p><p>The scatterplot is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/C12624_03_12.jpg" alt="Figure 3.12: Scatterplot showing the relationship between DEWP and PM2.5 split by month of the year.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.12: Scatterplot showing the relationship between DEWP and PM2.5 split by month of the year.</h6>
			<p>In order to gauge some relationship between variables, we used a scatterplot between <strong class="inline">PM2.5</strong> and <strong class="inline">DEWP</strong> with a line of fit. Observe that in the code, we have passed an argument to <strong class="inline">geom_smooth()</strong>, that is, <strong class="inline">method = "auto"</strong>, which automatically decides, based on the data, which model to use to fit a line. As shown in <em class="italics">Figure 3.10</em>, the line is not linear. The <strong class="inline">geom_smooth</strong> method chooses <strong class="bold">generalized additive model</strong> (<strong class="bold">GAM</strong>). This indicates that the linear relationship assumption of the linear regression model is being violated. A similar pattern is seen with the <strong class="inline">TEMP</strong> and <strong class="inline">PM2.5</strong> plot, as shown in <em class="italics">Figure 3.11</em>. However, we could go one step further and split the scatterplot month-wise, as shown in <em class="italics">Figure 3.12</em>. This shows that a linear relationship exists, but it is highly season-dependent. For example, in April (represented by the integer <strong class="inline">4</strong>), the <strong class="inline">DEWP</strong> and <strong class="inline">PM2.5</strong> have a near-to-perfect straight line fit. We will extend this discussion into further details in <em class="italics">Chapter 4</em>, <em class="italics">Regression</em>.</p>
			<p>So, we have seen some violation of assumption and the lack of a strong correlation between the environmental factors and PM2.5. However, there seems to be some scope for further scrutiny. In this introductory chapter on supervised learning, we will only focus on the approach based on our machine learning workflow.</p>
			<h4>Note</h4>
			<p class="callout">To know more about GAM, review this document: https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch13.pdf.</p>
			<h3 id="_idParaDest-138"><a id="_idTextAnchor139"/>Activity 5: Draw a Scatterplot between PRES and PM2.5 Split by Months</h3>
			<p>In this activity, we will create a scatterplot between <strong class="inline">DWEP</strong> and <strong class="inline">PM2.5</strong>. Through this activity, we will learn to use the <strong class="inline">facet_wrap()</strong> function to create a layer on top of <strong class="inline">ggplot()</strong> for splitting the visualization of scatterplot into each month, thus helping to observe any seasonality pattern.</p>
			<p>Perform the following steps to complete the activity:</p>
			<ol>
				<li value="1">In <strong class="inline">ggplot</strong>, assign the component of the <strong class="inline">a()</strong> method with the <strong class="inline">PRES</strong> variable.</li>
				<li>In the next layer of the <strong class="inline">geom_smooth()</strong> method, set <strong class="inline">colour = "blue"</strong> to differentiate.</li>
				<li>Finally, in the <strong class="inline">facet_wrap()</strong> layer, use the <strong class="inline">month</strong> variable to draw a separate segregation for each month.<p>The plot is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/C12624_03_13.jpg" alt="Figure 3.13: Scatterplot showing the relationship between PRES and PM2.5.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.13: Scatterplot showing the relationship between PRES and PM2.5.</h6>
			<h4>Note</h4>
			<p class="callout">The solution for this activity can be found on page 445.</p>
			<h3 id="_idParaDest-139"><a id="_idTextAnchor140"/>Model Building</h3>
			<p>We have briefly explored the relationship between <strong class="inline">PM2.5</strong> and a few factors such as <strong class="inline">TEMP</strong> and <strong class="inline">DEWP</strong>. The same analysis could be followed for other variables such as <strong class="inline">PRES</strong>, <strong class="inline">Iwd</strong>, and more. In this section, let's create a linear model. (We never hesitate to run a model even if we know the choice of model isn't the best. A trial-and-error approach in machine learning is always the best way to establish facts.)</p>
			<p>In general, a linear regression models the linear relationship between an input variable (independent variable) and a target variable (dependent variable or explanatory variable). If we have one explanatory variable, it is called <strong class="bold">simple linear regression</strong>, and where there is more than one explanatory variable, it's called <strong class="bold">multiple linear regression</strong>. The following equation is the mathematical representation of linear regression or a linear predictor function with <em class="italics">p</em> explanatory variables and <em class="italics">n</em> observations:</p>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/C12624_03_20.jpg" alt=""/>
				</div>
			</div>
			<p>Here, each <img src="image/C12624_03_21.png" alt="A picture containing furniture, table, seat, stool&#10;&#10;Description automatically generated"/> is a vector of column values (explanatory variable) for <img src="image/C12624_03_22.png" alt=""/>, and <img src="image/C12624_03_23.png" alt="A picture containing furniture&#10;&#10;Description automatically generated"/> is the unknown parameter or coefficient. <img src="image/C12624_03_24.png" alt="A picture containing furniture, seat&#10;&#10;Description automatically generated"/> makes this equation suitable for simple linear regression. There are many algorithms to fit this function onto the data. The most popular one is <strong class="bold">ordinary least square</strong> (<strong class="bold">OLS</strong>). We will discuss OLS in detail in our next chapter on regression.</p>
			<p>Another way to think of <img src="image/C12624_03_25.png" alt="A picture containing furniture&#10;&#10;Description automatically generated"/> is that it's a linear predictor function that fits the observations in the <img src="image/C12624_03_26.png" alt=""/>—dimension space as closely as possible, minimizing the residual sum of squares (the difference in the actual value of the target value from the predicted value).</p>
			<p>In the following exercise, we will skip the split of the dataset into train and test, as we are still in the exploration stage and have not decided to formally approach the modeling exercise. (We will touch on that in the next chapter.) We will use the <strong class="inline">lm()</strong> method in R for building a linear model. Again, more details on that in the next chapter. At this point, it is suffice to note that <strong class="inline">lm()</strong> fits a target variable to a straight line using either one or more input variables. In a simple linear regression, we use only one variable to fit the line, and in multiple linear regression, we can use more than one variable.</p>
			<h3 id="_idParaDest-140"><a id="_idTextAnchor141"/>Exercise 45: Exploring Simple and Multiple Regression Models</h3>
			<p>In this exercise, we will explore simple and multiple regression models.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Import the required libraries and packages into R-Studio.</li>
				<li>Next, create a DataFrame object named <strong class="inline">simple_PM25_linear_model</strong> and use the <strong class="inline">lm()</strong> method to build a linear model:<p class="snippet">simple_PM25_linear_model &lt;- lm(pm2.5 ~ DEWP, data = PM25)</p></li>
				<li>Print the summary of the object using the summary method, as illustrated here:<p class="snippet">summary(simple_PM25_linear_model)</p><p>The output is as follows:</p><p class="snippet">Call:</p><p class="snippet">lm(formula = pm2.5 ~ DEWP, data = PM25)</p><p class="snippet">Residuals:</p><p class="snippet">    Min      1Q  Median      3Q     Max </p><p class="snippet">-115.47  -61.26  -28.75   33.83  923.54 </p><p class="snippet">Coefficients:</p><p class="snippet">            Estimate Std. Error t value Pr(&gt;|t|)    </p><p class="snippet">(Intercept) 96.69984    0.44705  216.31   &lt;2e-16 ***</p><p class="snippet">DEWP         1.09325    0.03075   35.55   &lt;2e-16 ***</p><p class="snippet">---</p><p class="snippet">Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</p><p class="snippet">Residual standard error: 90.69 on 41755 degrees of freedom</p><p class="snippet">  (2067 observations deleted due to missingness)</p><p class="snippet">Multiple R-squared:  0.02939,	Adjusted R-squared:  0.02936 </p><p class="snippet">F-statistic:  1264 on 1 and 41755 DF,  p-value: &lt; 2.2e-16</p></li>
				<li>Next, create another DataFrame object and use the <strong class="inline">lm()</strong> method to build a linear model:<p class="snippet">multiple_PM25_linear_model &lt;- lm(pm2.5 ~ DEWP+TEMP+Iws, data = PM25)</p></li>
				<li>Print the summary of the model object using the <strong class="inline">summary</strong> function:<p class="snippet">summary(multiple_PM25_linear_model)</p><p>The output is as follows:</p><p class="snippet">A)</p><p class="snippet">______________________________________________________________</p><p class="snippet">Call:</p><p class="snippet">lm(formula = pm2.5 ~ DEWP + TEMP + Iws, data = PM25)</p><p class="snippet">Residuals:</p><p class="snippet">    Min      1Q  Median      3Q     Max </p><p class="snippet">-149.02  -53.74  -16.61   34.14  877.82 </p><p class="snippet">______________________________________________________________</p><p class="snippet">B)</p><p class="snippet">______________________________________________________________</p><p class="snippet">Coefficients:</p><p class="snippet">              Estimate Std. Error t value Pr(&gt;|t|)    </p><p class="snippet">(Intercept) 161.151207   0.768727  209.63   &lt;2e-16 ***</p><p class="snippet">DEWP          4.384196   0.051159   85.70   &lt;2e-16 ***</p><p class="snippet">TEMP         -5.133511   0.058646  -87.53   &lt;2e-16 ***</p><p class="snippet">Iws          -0.274337   0.008532  -32.15   &lt;2e-16 ***</p><p class="snippet">---</p><p class="snippet">Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</p><p class="snippet">______________________________________________________________</p><p class="snippet">C)</p><p class="snippet">______________________________________________________________</p><p class="snippet">Residual standard error: 81.51 on 41753 degrees of freedom</p><p class="snippet">  (2067 observations deleted due to missingness)</p><p class="snippet">Multiple R-squared:  0.216,	Adjusted R-squared:  0.2159 </p><p class="snippet">F-statistic:  3834 on 3 and 41753 DF,  p-value: &lt; 2.2e-16</p><p class="snippet">______________________________________________________________</p></li>
			</ol>
			<h3 id="_idParaDest-141"><a id="_idTextAnchor142"/>Model Interpretation</h3>
			<p>Now, based on the previous output of both the simple and multiple linear regression models, let's try to understand what each part of the output means. At this juncture of the book, it's sufficient to know what each part means; we will discuss the results in <em class="italics">Chapter 4</em>, <em class="italics">Regression</em>.</p>
			<ul>
				<li>Part <strong class="bold">A</strong>:<p>This part shows the call to the <strong class="inline">lm()</strong> method with the dependent and independent variables, represented like a formula using the <strong class="inline">~</strong> symbol. This resembles our linear predictor function. In a simple regression model, there is only one variable—<strong class="inline">DEWP</strong>—and in a multiple model, there are <strong class="inline">DEWP</strong>, <strong class="inline">TEMP</strong>, and <strong class="inline">Iws</strong>. You also see the five summary statistics of residuals (min, first quartile, median, third quartile, and max). This indicates how far the predicted values are from the actual value.</p></li>
				<li>Part <strong class="bold">B</strong>:<p>This part is where the core of the model output is shown. The estimates of the parameters are based on the OLS method. If we substitute the values of these estimates and <strong class="inline">X_j</strong> into our prediction equation, we will get the predictions. The column named <strong class="inline">Std</strong>. Error is the standard error of the estimate. t-value is obtained by taking the ratio of <strong class="inline">Estimate</strong> and <strong class="inline">Std</strong>. Error, and p-value highlights the statistical significance of the estimate. The visual clues, that is, the <strong class="inline">*</strong> and . symbols are based on the p-value. A value less than 0.001 gets a three star versus a value between 0.1 and 0.05, which gets a <strong class="inline">.</strong> (dot). Three stars means the best case and that the estimates corresponding to the independent variable are significant and useful in predicting (or explaining) the dependent variable. In other words, p-value helps in determining the significance of a regression model over a null model (just the mean of the dependent variable).</p></li>
				<li>Part <strong class="bold">C</strong>:<p>This part is the one that shows the efficacy of the model. The most important values to observe are the R-squared and adjusted R-squared values, which are statistical measures that signify the percentage of variation for a dependent variable that's explained by independent variable(s) in a regression model.</p></li>
			</ul>
			<p>Go through the section on evaluation metrics in this chapter to see the interpretation on how well the model has done on R-squared and adjusted R-squared metrics.</p>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor143"/>Classification</h2>
			<p>Similar to the regression algorithm, classification also learns from the dependent or target variables and uses all the predictor or independent variables to find the right pattern. The major difference comes from the idea that in classification, the target variable is categorical, whereas in regression, it is numeric. In this section, we will introduce logistic regression to demonstrate the concept using the Beijing PM2.5 dataset.</p>
			<h3 id="_idParaDest-143"><a id="_idTextAnchor144"/>Logistic Regression</h3>
			<p><strong class="bold">Logistic regression</strong> is the most favorable white-box model used for binary classification. White-box models are defined as models providing visibility into the entire reasoning done for the prediction. For each prediction made, we can leverage the model's mathematical equation and decode the reasons for the prediction made. There are also a set of classification models that are entirely black-box, that is, by no means can we understand the reasoning for the prediction leveraged by the model. In situations where we want to focus only on the end outcome, we should prefer black-box models as they are more powerful.</p>
			<h3 id="_idParaDest-144"><a id="_idTextAnchor145"/>A Brief Introduction</h3>
			<p>Though the name ends with <strong class="bold">regression</strong>, logistic regression is a technique used to predict binary categorical outcomes and is hence a good choice for classification problems. As discussed in the previous section, we need a different approach to model for a categorical outcome. This can be done by transforming the outcome into the log of the odds ratio or the probability of the event to happen.</p>
			<p>Let's distill this approach into simpler constructs. Assume that the probability of success for an event is 0.7. Then, the probability of failure for the same event would be defined as <em class="italics">1 – 0.7 = 0.3</em>. The odds of success are defined as the ratio of the probability of success to the probability of failure. The odds of success would then be <em class="italics">0.7/0.3 = 2.33</em>, that is, the odds of success are 2 to 1. If the probability of success is 0.5, that is, a 50-50 chance, the odds of success are 1 to 1. The logistic regression model can be mathematically represented as follows:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/C12624_03_27.jpg" alt=""/>
				</div>
			</div>
			<p>Here, <img src="image/C12624_03_28.png" alt="A drawing of a person&#10;&#10;Description automatically generated"/> is the log of the odds ratio, which is also called the <strong class="bold">logit</strong> function. Solving the math further, we can deduce the probability of the outcome as shown:</p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/C12624_03_29.jpg" alt=""/>
				</div>
			</div>
			<p>Discussing the mathematical background and derivation of the equations is beyond the scope of this chapter. However, to summarize, the logit function, which is the link function (or logic function), helps logistic regression reframe the problem (predicted outcome) intuitively as the log of the odds ratio. This, when solved, helps us to predict the probability of a binary dependent variable.</p>
			<h3 id="_idParaDest-145"><a id="_idTextAnchor146"/>Mechanics of Logistic Regression</h3>
			<p>Just like linear regression, where the beta coefficients for the variables are estimated using the OLS method, the logistic regression model leverages the <strong class="bold">maximum likelihood estimation</strong> (<strong class="bold">MLE</strong>) method. The MLE function estimates the best set of values of the model parameters or beta coefficients such that it maximizes the likelihood function, that is, the probability estimates. It can also be defined as the <em class="italics">agreement</em> of the selected model with the observed data). When the best set of parameter values is estimated, plugging these values/beta coefficients into the model equation, as defined earlier, helps in estimating the probability of the outcome for a given sample. Akin to OLS, MLE is an iterative process.</p>
			<h3 id="_idParaDest-146"><a id="_idTextAnchor147"/>Model Building</h3>
			<p>Like linear regression for building a logistic regression model in R, we have the <strong class="inline">glm()</strong> generalized linear model method to fit the data and logit function to score the observation.</p>
			<p>The syntax of using the glm() function is as follows:</p>
			<p class="snippet">glm(Y ~ X1 + X2 + X3, data = &lt;train_data&gt;,family=binomial(link='logit'))</p>
			<p>Here, Y is our dependent variable and X1, X2 and X3 are the independent variables. The argument data will take the training dataset. The family argument is set to binomial(link='logit'), which fits a logistic regression model.</p>
			<h3 id="_idParaDest-147"><a id="_idTextAnchor148"/>Exercise 46: Storing the Rolling 3-Hour Average in the Beijing PM2.5 Dataset</h3>
			<p>In this exercise, we will create a new variable that stores the rolling 3-hour average of the PM2.5 variable in the Beijing PM2.5 dataset. The rolling average will smoothen any noise from a reading of PM2.5.</p>
			<p>Let's use the <strong class="inline">rollapply</strong> method from the <strong class="inline">zoo</strong> package to complete the exercise:</p>
			<ol>
				<li value="1">Combine the <strong class="inline">year</strong>, <strong class="inline">month</strong>, <strong class="inline">day</strong>, and <strong class="inline">hour</strong> into a new variable called <strong class="inline">datetime</strong>:<p class="snippet">PM25$datetime &lt;- with(PM25, ymd_h(sprintf('%04d%02d%02d%02d', year, month, day,hour)))</p></li>
				<li>Remove the NAs and look at the top 6 values of the <strong class="inline">pm2.5</strong> variable in the PM2.5 dataset:<p class="snippet">PM25_subset &lt;- na.omit(PM25[,c("datetime","pm2.5")])</p><p class="snippet">head(PM25_subset$pm2.5)</p><p>The output is as follows:</p><p class="snippet">[1] 129 148 159 181 138 109</p></li>
				<li>Store the <strong class="inline">PM25_subset</strong> into a <strong class="inline">zoo</strong> object of ordered observation with datetime as its index, and print the top 6 values:<p class="snippet">zoo(PM25_subset$pm2.5,PM25_subset$datetime)</p><p>The output is as follows:</p><p class="snippet">2010-01-02 00:00:00 2010-01-02 01:00:00 2010-01-02 02:00:00 </p><p class="snippet">                129                 148                 159 </p><p class="snippet">2010-01-02 03:00:00 2010-01-02 04:00:00 2010-01-02 05:00:00 </p><p class="snippet">                181                 138                 109 </p></li>
				<li>Use the <strong class="inline">rollapply</strong> function to create a 3-hour rolling average of the <strong class="inline">pm2.5</strong> variable, and print the top 6 values:<p class="snippet">PM25_three_hour_pm25_avg &lt;- rollapply(zoo(PM25_subset$pm2.5,PM25_subset$datetime), 3, mean)</p><p>The output is as follows:</p><p class="snippet">2010-01-02 01:00:00 2010-01-02 02:00:00 2010-01-02 03:00:00 </p><p class="snippet">           145.3333            162.6667            159.3333 </p><p class="snippet">2010-01-02 04:00:00 2010-01-02 05:00:00 2010-01-02 06:00:00 </p><p class="snippet">           142.6667            117.3333            112.6667 </p></li>
			</ol>
			<p>Observe that the <strong class="inline">145.33</strong> value is the average of three hours of the <strong class="inline">pm2.5</strong> variable, as shown in step 3 (<strong class="inline">129</strong>, <strong class="inline">148</strong>, and <strong class="inline">159</strong>).</p>
			<h3 id="_idParaDest-148"><a id="_idTextAnchor149"/>Activity 6: Transforming Variables and Deriving New Variables to Build a Model</h3>
			<p>In this activity, we will perform a series of transformations and derive new variables before building the model. We need to convert the <strong class="inline">pm2.5</strong> variable into a categorical variable to apply a logistic regression model.</p>
			<p>The following steps need to be performed before we can build a logistic regression classification model:</p>
			<ol>
				<li value="1">Combine the year, month, day, and hour into a new variable called <strong class="inline">datetime</strong>.</li>
				<li>Using the datetime variable, calculate the average of the <strong class="inline">pm2.5</strong> values with a 3-hour window. Name this new variable <strong class="inline">PM25_three_hour_pm25_avg</strong>.</li>
				<li>Create a binary variable called <strong class="inline">pollution_level</strong>. It gets a value <strong class="inline">1</strong> if <strong class="inline">PM25_three_hour_pm25_avg</strong> is greater than <strong class="inline">35</strong>, else <strong class="inline">0</strong>.</li>
				<li>Using <strong class="inline">pollution_level</strong> as the dependent variable, build a logistic regression model.</li>
				<li>Print the summary of the model.<p>The final output is as follows:</p><p class="snippet">Call:</p><p class="snippet">glm(formula = pollution_level ~ DEWP + TEMP + Iws, family = binomial(link = "logit"), </p><p class="snippet">    data = PM25_for_class)</p><p class="snippet">Deviance Residuals: </p><p class="snippet">    Min       1Q   Median       3Q      Max  </p><p class="snippet">-2.4699  -0.5212   0.4569   0.6508   3.5824  </p><p class="snippet">Coefficients:</p><p class="snippet">              Estimate Std. Error z value Pr(&gt;|z|)    </p><p class="snippet">(Intercept)  2.5240276  0.0273353   92.34   &lt;2e-16 ***</p><p class="snippet">DEWP         0.1231959  0.0016856   73.09   &lt;2e-16 ***</p><p class="snippet">TEMP        -0.1028211  0.0018447  -55.74   &lt;2e-16 ***</p><p class="snippet">Iws         -0.0127037  0.0003535  -35.94   &lt;2e-16 ***</p><p class="snippet">---</p><p class="snippet">Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</p><p class="snippet">(Dispersion parameter for binomial family taken to be 1)</p><p class="snippet">    Null deviance: 49475  on 41754  degrees of freedom</p><p class="snippet">Residual deviance: 37821  on 41751  degrees of freedom</p><p class="snippet">AIC: 37829</p><p class="snippet">Number of Fisher Scoring iterations: 5</p><h4>Note</h4><p class="callout">The solution for this activity can be found on page 446.</p></li>
			</ol>
			<h3 id="_idParaDest-149"><a id="_idTextAnchor150"/>Interpreting a Model</h3>
			<p>A large part of the <strong class="inline">glm()</strong> output looks similar to the <strong class="inline">lm()</strong> method but with a few new values, such as the following:</p>
			<ul>
				<li><strong class="bold">Null deviance</strong></li>
				<li><strong class="bold">Residual deviance</strong></li>
				<li><strong class="bold">Akaike Information Criterion</strong> (<strong class="bold">AIC</strong>)</li>
				<li><strong class="bold">Fisher scoring</strong></li>
			</ul>
			<p>In order to avoid scoring, all the above measures will be described in detail in <em class="italics">Chapter 5</em>, <em class="italics">Classification</em>.</p>
			<p>Refer to0 the next section on <em class="italics">Evaluation Metrics</em> (the <em class="italics">Confusion Matrix Based Metrics</em> section) in this chapter to find an interpretation of how well the model has done on R-squared and adjusted R-squared metrics.</p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor151"/>Evaluation Metrics</h2>
			<p>In this section, we will go through all the evaluation measures for assessing the quality of the machine learning model predictions. Based on the dependent variable, we have several choices for the evaluation measures. In the train and evaluate step of our Machine Learning Workflow, we mentioned that until we get the desired results, we keep iterating the training model by adding new variables or changing the parameters. In each iteration, we try to optimize for any one or two evaluation metrics. The following table summarizes the various types of metrics used for regression, classification, and recommender systems. Given the scope of this book, we will delve into more details on regression and classification algorithms:</p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/C12624_03_14.jpg" alt="Figure 3.14: Metrics for various types of machine learning algorithms.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.14: Metrics for various types of machine learning algorithms.</h6>
			<h3 id="_idParaDest-151"><a id="_idTextAnchor152"/>Mean Absolute Error (MAE)</h3>
			<p>Absolute error is direction-agnostic, which means that it is does not matter whether the predicted value of the dependent variable by the model on the test dataset is less than or greater than the actual value. So, in our example of the Beijing PM2.5 dataset, MAE will give us the average absolute error (difference in the predicted and actual values of the dependent variable) in PM2.5 prediction indifferent to the direction of error (positive or negative):</p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/C12624_03_30.jpg" alt=""/>
				</div>
			</div>
			<p>Here, <img src="image/C12624_03_31.png" alt=""/> is the value of the ith observation of the dependent variable, and <img src="image/C12624_03_32.png" alt=""/> is the predicted or expected value.</p>
			<h3 id="_idParaDest-152"><a id="_idTextAnchor153"/>Root Mean Squared Error (RMSE)</h3>
			<p>Similar to MAE, root mean square error also computes the average prediction error. However, it is based on a quadratic scoring, where the square root of the average squared error is computed. Moreover, unlike MAE, which takes the absolute difference between the predicted and actual values, RMSE takes the square, which adds more weight to the high error values before taking the square root:</p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/C12624_03_33.jpg" alt=""/>
				</div>
			</div>
			<p>Here, <img src="image/C12624_03_34.png" alt=""/> represents the difference between the actual and estimated values of the dependent variable for the ith observation.</p>
			<h3 id="_idParaDest-153"><a id="_idTextAnchor154"/>R-squared</h3>
			<p>R-squared measures the percentage (value between 0 and 1 or from 0% to 100%) of the variance in the response variable explained by the linear model. In other words, it measures the variance explained by the input features. 0% R-squared means the model's input feature explains nothing about the response variable. Closer to 100% means that the model is a good predictor of the response variable. For example, if we want to predict the price of a house in a locality, features such as the number of bedrooms, area in sq. ft, and proximity to a school and market decides the value of a property. However, R-squared alone cannot be used for assessing the goodness of the model. Various diagnostic checks on residual, normality, and heteroscedasticity are also required. We will discuss this in detail in <em class="italics">Chapter 4</em>, <em class="italics">Regression</em>.</p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/C12624_03_35.jpg" alt=""/>
				</div>
			</div>
			<p>Here, <img src="image/C12624_03_36.png" alt=""/> is the sum of the square difference between the actual and estimated values of the dependent variable, while <img src="image/C12624_03_37.png" alt=""/> represents the sum of the square difference between the actual and mean of the dependent variable.</p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/C12624_03_38.jpg" alt=""/>
				</div>
			</div>
			<h3 id="_idParaDest-154"><a id="_idTextAnchor155"/>Adjusted R-square</h3>
			<p>When we add new variables in the regression model, the R-squared value of the model improves as the contribution of the newer variables in explaining the variation of the dependent variable increases. (A counter-argument arises if the newer variables are poorly designed and are not relevant for explaining the dependent variable.) So, for the evaluation metric to be agnostic to the number of variables, we penalize the R-squared value by incorporating <em class="italics">n</em> and <em class="italics">q</em> (number of observations and number of variables, respectively) in the calculation. This is called adjusted R-squared, adjusted for both the number of observations and variables. It is a good practice to look at the adjusted R-squared when dealing with multiple linear regression.</p>
			<p><strong class="bold">MSE</strong> (<strong class="bold">mean squared error</strong>):</p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/C12624_03_39.jpg" alt=""/>
				</div>
			</div>
			<p>Here, <em class="italics">n</em> is the number of observations, and <em class="italics">q</em> is the number of coefficients in the model.</p>
			<p><strong class="bold">MST</strong> (<strong class="bold">mean squared total</strong>):</p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/C12624_03_40.jpg" alt=""/>
				</div>
			</div>
			<h3 id="_idParaDest-155"><a id="_idTextAnchor156"/>Mean Reciprocal Rank (MRR)</h3>
			<p>MRR is popularly used to evaluate algorithms in search engines, recommender algorithms, and many other information retrieval algorithms in the digital space. MRR is easy to interpret. In general, it could be used to evaluate algorithms that produce a list of responses for an input. Examples are the search results you see in Google for your query and the product recommendations you see on Amazon. The following table shows an example of computing the reciprocal rank. MRR ranges from 0 to 1; a value closer to 1 indicates that the algorithm is giving relevant results at the top of the list.</p>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="image/C12624_03_41.jpg" alt=""/>
				</div>
			</div>
			<div>
				<div id="_idContainer094" class="IMG---Figure">
					<img src="image/C12624_03_15.jpg" alt="Figure 3.15: Example of computing reciprocal rank.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.15: Example of computing reciprocal rank.</h6>
			<h3 id="_idParaDest-156"><a id="_idTextAnchor157"/>Exercise 47: Finding Evaluation Metrics</h3>
			<p>In this exercise, we will find the MAE, RMSE, R-squared, Adjusted R-squared, and MRR.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">Import the required libraries and packages.</li>
				<li>Create a variable named <strong class="inline">y_predicted</strong> and assign the value from the <strong class="inline">multiple_PM25_linear_model</strong>:<p class="snippet">y_predicted &lt;- predict(multiple_PM25_linear_model, data = PM25)</p></li>
				<li>Use the following command to assign values from the <strong class="inline">PM25</strong> dataset:<p class="snippet">y_actual &lt;- PM25[!is.na(PM25$pm2.5),"pm2.5"]</p></li>
				<li>Find the MAE using the mean function:<p class="snippet">MAE &lt;- mean(abs(y_actual - y_predicted))</p><p>The output is as follows:</p><p class="snippet">## [1] 59.82112</p></li>
				<li>Next, calculate the RMSE:<p class="snippet">RMSE &lt;- sqrt(mean((y_actual - y_predicted)^2))</p><p>The output is as follows:</p><p class="snippet">## [1] 82.09164</p></li>
				<li>Now, calculate the R-squared value using the following command:<p class="snippet">model_summary &lt;- summary(multiple_PM25_linear_model)</p><p class="snippet">model_summary$r.squared</p><p>The output is as follows:</p><p class="snippet">## [1] 0.216</p></li>
				<li>Next, find the adjusted R-squared using the following command:<p class="snippet">model_summary$adj.r.squared</p><p>The output is as follows:</p><p class="snippet">## [1] 0.2159</p></li>
				<li>Finally, use the following command to find the MRR:<p class="snippet">Query_RR_Vector &lt;- c(1/3,1/4,1)</p><p class="snippet">MRR &lt;- sum(Query_RR_Vector)/length(Query_RR_Vector)</p><p>The output is as follows:</p><p class="snippet">## [1] 0.5277778</p></li>
			</ol>
			<p>Observe that MAE gives a value of <strong class="inline">59.82</strong> and RMSE is <strong class="inline">82.09,</strong> which shows a high variance in the errors. In other words, the observations have a high error (which increases the variance of the frequency distribution of error magnitudes) in prediction; MAE fails to identify the error, whereas RMSE amplifies it well. If the MAE and RMSE are almost equal, we could infer that the variance in the frequency distribution of error magnitudes is low and that the model is doing well with all the observations.</p>
			<h3 id="_idParaDest-157"><a id="_idTextAnchor158"/>Confusion Matrix-Based Metrics</h3>
			<p>Confusion matrix-based metrics are used in classification algorithms. There are a series of metrics one could derive from the confusion matrix (also called the <strong class="bold">contingency table</strong>). The following table computes the frequency of various cases as shown. The terms <strong class="bold">Positive</strong> and <strong class="bold">Negative</strong> are just conventions for calling out classes <strong class="inline">A</strong> and <strong class="inline">B</strong>. Otherwise, there is nothing negative or positive about the target variable. The contingency table could also be NxN, where <em class="italics">N</em> is the number of classes or categories in the response variable. For example, if we want to classify the 26 handwritten characters of the English alphabet in a given image, we need a 26x26 matrix:</p>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="image/C12624_03_16.jpg" alt="Figure 3.16: Elements of the confusion matrix.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.16: Elements of the confusion matrix.</h6>
			<p>If we arrange the <strong class="bold">TP</strong>, <strong class="bold">TN</strong>, <strong class="bold">FP</strong>, and <strong class="bold">FN</strong> in a 2x2 contingency matrix, we obtain the confusion matrix, as shown in the following table:</p>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="image/C12624_03_17.jpg" alt="Figure 3.17: Confusion matrix.&#13;&#10;"/>
				</div>
			</div>
			<h6>Figure 3.17: Confusion matrix.</h6>
			<h3 id="_idParaDest-158"><a id="_idTextAnchor159"/>Accuracy</h3>
			<p>Accuracy measures the correct overall classifications by the model for both positive and negative examples. The sum of the diagonal elements in the matrix (TP and TN) divided by the total number of positive and negative observations gives the accuracy. Accuracy is not always a reliable metric in real-world scenarios. Consider that we would like to distinguish cancer CT scans from benign CT scans. Clearly, we may have many negative scans and few positive scans. This leads to what we call the <strong class="bold">unbalanced dataset</strong>. If the model mostly predicts benign scans accurately but produces a significant error in predicting cancer CT scans, the accuracy may still be high, but the model is not so useful.</p>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/C12624_03_42.jpg" alt=""/>
				</div>
			</div>
			<h3 id="_idParaDest-159"><a id="_idTextAnchor160"/>Sensitivity</h3>
			<p>In order to tackle the issue we discussed with <em class="italics">accuracy</em>, we could use a combination of sensitivity, also known as recall, hit rate, or <strong class="bold">true positive rate</strong> (<strong class="bold">TPR</strong>), and specificity (discussed in the next section). Sensitivity gives the predictive power of the model with respect to the positive cases (detecting cancer in a CT scan). We obtain sensitivity from the ratio of all <strong class="bold">true positive</strong> (<strong class="bold">TP</strong>) cases to the number of <strong class="bold">positive</strong> (<strong class="bold">P</strong>) cases.</p>
			<div>
				<div id="_idContainer098" class="IMG---Figure">
					<img src="image/C12624_03_43.jpg" alt=""/>
				</div>
			</div>
			<h3 id="_idParaDest-160"><a id="_idTextAnchor161"/>Specificity</h3>
			<p>Specificity provides the quantitative assessment of correct predictions of negative examples (for example, detecting benign CT scans). We obtain sensitivity from the ratio of a number of true negative cases to the number of negative cases.</p>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="image/C12624_03_44.jpg" alt=""/>
				</div>
			</div>
			<p>High sensitivity and specificity values signify a superior model. In most cases, we try to balance the two metrics to get the best model.</p>
			<h3 id="_idParaDest-161"><a id="_idTextAnchor162"/>F1 Score</h3>
			<p>F1 score combines precision and sensitivity by taking the harmonic mean (appropriate for taking averages of two or more rates) of both, as described by the following formulas. <strong class="bold">Positive predictive value</strong> (<strong class="bold">PPV</strong> or precision) measures the number of true predictions over the sum of a number of true and false positives, that is, how many of all the predictions of positive cases were correct.</p>
			<div>
				<div id="_idContainer100" class="IMG---Figure">
					<img src="image/C12624_03_45.jpg" alt=""/>
				</div>
			</div>
			<p>F1 score is more robust than accuracy but still suffers in the case of unbalanced classes.</p>
			<p>There is no good or bad metric for evaluating the goodness of a classification model. Machine learning practitioners usually look at a combination of many metrics to conclude the goodness of a model. That is why it becomes important to know how to interpret each of the above discussed metrics.</p>
			<h3 id="_idParaDest-162"><a id="_idTextAnchor163"/>Exercise 48: Working with Model Evaluation on Training Data</h3>
			<p>In this exercise, we will work with model evaluation on training data using the <strong class="inline">confusionMatrix</strong> function from the <strong class="inline">caret</strong> package. The function prints metrics such as accuracy, sensitivity, specificity, and many more.</p>
			<p>Perform the following steps to complete the exercise:</p>
			<ol>
				<li value="1">Import the required libraries and packages into the system.</li>
				<li>Create a variable name <strong class="inline">predicated</strong> and assign the value, as illustrated here:<p class="snippet">predicted &lt;- ifelse(PM25_logit_model$fitted.values&gt;0.5, 1,0)</p></li>
				<li>Next, create another variable named <strong class="inline">actual</strong>, as illustrated here:<p class="snippet">actual &lt;- PM25_for_class$pollution_level</p></li>
				<li>Import the caret library:<p class="snippet">library(caret)</p></li>
				<li>Finally, use the <strong class="inline">confusionMatrix</strong> method to describe the performance of the classification model:<p class="snippet">confusionMatrix(predicted, actual)</p><p>The output is as follows:</p><p class="snippet">## Confusion Matrix and Statistics</p><p class="snippet">## </p><p class="snippet">##           Reference</p><p class="snippet">## Prediction     0     1</p><p class="snippet">##          0  5437  2097</p><p class="snippet">##          1  6232 27989</p><p class="snippet">##                                           </p><p class="snippet">##                Accuracy : 0.8005          </p><p class="snippet">##                  95% CI : (0.7967, 0.8044)</p><p class="snippet">##     No Information Rate : 0.7205          </p><p class="snippet">##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       </p><p class="snippet">##                                           </p><p class="snippet">##                   Kappa : 0.4444          </p><p class="snippet">##  Mcnemar's Test P-Value : &lt; 2.2e-16       </p><p class="snippet">##                                           </p><p class="snippet">##             Sensitivity : 0.4659          </p><p class="snippet">##             Specificity : 0.9303          </p><p class="snippet">##          Pos Pred Value : 0.7217          </p><p class="snippet">##          Neg Pred Value : 0.8179          </p><p class="snippet">##              Prevalence : 0.2795          </p><p class="snippet">##          Detection Rate : 0.1302          </p><p class="snippet">##    Detection Prevalence : 0.1804          </p><p class="snippet">##       Balanced Accuracy : 0.6981          </p><p class="snippet">##                                           </p><p class="snippet">##        'Positive' Class : 0               </p></li>
			</ol>
			<p>Many of the metrics shown in the results of the <strong class="inline">confusionMatric()</strong> output are described in this section. However, here's a quick summary before you read the details. The accuracy of this logistic regression model is 80%, which is good as per the standard. This indicates that we can predict the normal and above normal PM2.5 values using other environmental factors with 80% accuracy. However, note that the accuracy is on the entire training dataset. We have not split the data into two parts for checking the overfitting scenarios, a condition in which the model performs really good when tested on training data but shows inferior results on testing (or unseen) data.</p>
			<p>Sensitivity and specificity are 46% and 93%, respectively. This means the model is doing good for negative cases (1-Above normal PM2.5). Generally, there must be a tradeoff between these two metrics. However, in this case, the priority for the model is to be able to predict as many <strong class="bold">Above Normal</strong> states as possible. Hence, high specificity is desirable once we have the confusion matrix; it's possible to calculate all the metrics from it.</p>
			<h3 id="_idParaDest-163"><a id="_idTextAnchor164"/>Receiver Operating Characteristic (ROC) Curve</h3>
			<p>In the context of classification models, the output of a prediction is obtained as a quantitative estimate, usually a probability measure. In a binary logistic regression, the usual choice of the threshold to classify one observation from the other (for example, spam versus non-spam) is 0.5. This means that if the probability is greater than 0.5, classify it as spam and if not, non-spam. Now, depending on the threshold, you will get different values of TP, TN, FP, and FN in the confusion matrix we discussed earlier. While it is a standard practice to look at the confusion matrix at a given threshold (usually 0.5), it might not give us the complete view of whether the model will perform well in the real world, which is why the choice of threshold is essential.</p>
			<p>The ROC curve is an elegant visualization showing the variation between the true positive rate (often referenced by sensitivity) and the true negative rate (often referenced by specificity) at every possible threshold. It helps us identify the right threshold for classification. Also, the area under the ROC curve (referred to as AUC), which varies between 0 and 1, tells us how good the model is. Closer to 1 means that the model is successfully able to classify between positive and negative classes for most of the observation.</p>
			<p>Using the ROCR package in R, we will obtain the ROC curve for the PM2.5 prediction using logistic regression. Also, we will observe the AUC in the next exercise.</p>
			<h3 id="_idParaDest-164"><a id="_idTextAnchor165"/>Exercise 49: Creating an ROC Curve</h3>
			<p>In this exercise, we will use the ROCR package to obtain the ROC curve.</p>
			<p>Perform the following steps:</p>
			<ol>
				<li value="1">Import the ROCR package into the system using the following command:<p class="snippet">library(ROCR)</p></li>
				<li>Next, define the pred1 and pref1 objects:<p class="snippet">pred1 &lt;- prediction(predict(PM25_logit_model), PM25_for_class$pollution_level)</p><p class="snippet">perf1 &lt;- performance(pred1,"tpr","fpr")</p></li>
				<li>Next, find the AUC using the following command:<p class="snippet">auc &lt;- performance(pred1,"auc")</p><p class="snippet">as.numeric(auc@y.values)</p><p>The output is as follows:</p><p class="snippet">## [1] 0.8077673</p></li>
				<li>Plot the graph using the plot command:<p class="snippet">plot(perf1)</p><div id="_idContainer101" class="IMG---Figure"><img src="image/C12624_03_18.jpg" alt="Figure 3.18: ROC curve between true positive rate (sensitivity) and false positive rate (specificity).&#13;&#10;"/></div></li>
			</ol>
			<h6>Figure 3.18: ROC curve between true positive rate (sensitivity) and false positive rate (specificity).</h6>
			<h2 id="_idParaDest-165"><a id="_idTextAnchor166"/>Summary</h2>
			<p>In this chapter, we started out with laying the process for building a machine learning workflow, starting from designing the problem and moving to deploying the model. We briefly discussed simple and multiple and logistic regressions along with all the evaluation metrics needed to interpret and judge the performance of the model. These two algorithms demonstrate the supervised learning for regression and classification problems, respectively.</p>
			<p>Throughout the chapter, we used the Beijing PM2.5 dataset to build the models. In the process, we also converted a regression problem to a classification problem by simply re-engineering the dependent variable. Such re-engineering is often taken up on real-world problems to suit a particular use case.</p>
			<p>In the next chapter, we will delve into the details of regression algorithms and will elaborate the various types of regression algorithms beyond linear regression and discuss when to use which one.</p>
		</div>
	</body></html>