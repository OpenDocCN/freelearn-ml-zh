- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applying Machine Learning in Your Data Warehouse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Machine Learning** (**ML**) is a routine and necessary part of organizations
    in today’s modern business world. The origins of ML date back to the 1940s when
    logician Walter Pitts and neuroscientist Warren McCulloch tried to create a neural
    network that could map out human thought processes.'
  prefs: []
  type: TYPE_NORMAL
- en: Organizations can use their data along with ML algorithms to build a mathematical
    model to make faster, better-informed decisions, and the value of data to organizations
    today cannot be understated. Data volumes will continue to grow rapidly and organizations
    that can most effectively manage their data for predictive analytics and identify
    trends will have a competitive advantage, lower costs, and increased revenue.
    But to truly unlock this capability, you must bring ML closer to the data, provide
    self-service tools that do not require a deep data science background and eliminate
    unnecessary data movement in order to speed up the time it takes to operationalize
    ML models into your pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will introduce you to ML and discuss common use cases to apply
    ML in your data warehouse. You will begin to see the *art of the possible* and
    imagine how you can achieve business outcomes faster and more easily through the
    use of Amazon Redshift ML. We will guide you through the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the basics of ML algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traditional steps to implement ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overcoming the challenges of implementing ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the benefits of ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the basics of ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will go into more detail about machine learning so that
    you have a general understanding of the following areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised versus unsupervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start by looking at supervised and unsupervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing supervised and unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **supervised learning algorithm** is *supervised* by data that contains the
    known outcome you want to predict. The ML model learns from this known outcome
    in the data and then uses that learning to predict the outcome of new data.
  prefs: []
  type: TYPE_NORMAL
- en: This known outcome in the data is also referred to as the label or target. For
    example, if you have a dataset containing home sales information, the sales price
    would typically be the *target*.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning can be further broken down into **classification** or **regression**
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: With **unsupervised learning** the ML model must learn from the data outcome
    by grouping data based on similarities, differences, and other patterns without
    any guidance or known outcome.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use unsupervised algorithms to find patterns in the data. For example,
    you can use unsupervised learning to perform customer segmentation to be more
    effective in targeting groups of customers. Other use cases include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting abnormal sensor readings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Document tagging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the rich data that data warehouses contain, you can easily get started
    training models using both supervised and unsupervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dig into more details on classification and regression problem types.
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Classification problems are tasks to predict class labels, which can be either
    binary classification or multi-class classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Binary classification** – The outcome can be in one of two possible classes,
    for example, to predict whether a customer will churn, whether an email is spam,
    or whether a patient is likely to be hospitalized after being infected by COVID-19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-class classification** – The outcome can be in one of three or more
    possible classes – for example, predict a plant species or which category a news
    article belongs to. Other mutli-class classification use cases include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sales forecasting
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Intelligent call routing
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Advertisement optimization
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regression problems are used when you have a target of continuous values and
    want to predict a value based on the input variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regression problems are tasks predicting a continuous numeric value:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear regression**: With linear regression, we predict a numerical outcome
    such as how much a customer will spend or the predicted revenue for an upcoming
    concert or sporting event. See [*Chapter 7*](B19071_07.xhtml#_idTextAnchor111),
    *Building Regression Models*, for more details.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logistic regression**: Logistic regression is another option to solve a binary
    classification problem. We will show some examples of this technique in [*Chapter
    6*](B19071_06.xhtml#_idTextAnchor083), *Building* *Classification Models*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Regression use case examples include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Price and revenue prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer lifetime value prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting whether a customer is going to default on a loan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we will cover the steps to implement ML.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional steps to implement ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, you will get a better understanding of the critical steps
    needed to produce an optimal ML model:'
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning model evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A typical step in ML is to convert the raw data for input to train your model
    so that data scientists and data analysts can apply machine learning algorithms
    to the data. You may also hear the terms **data wrangling** or **feature engineering**.
  prefs: []
  type: TYPE_NORMAL
- en: This step is necessary since machine learning algorithms require inputs to be
    numbered. For example, you may need outliers or anomalies removed from your data.
    Also, you may need to fill in missing data values such as missing records for
    holidays. This helps to increase the accuracy of your model.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, it is important to ensure your training datasets are unbiased.
    Machine learning models learn from data and it is important that your training
    dataset has sufficient representation of demographic groups.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of data preparation steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Determining the inputs needed for your model** – This is the process of identifying
    the attributes that most influence the ML model outcome.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cleaning the data** – Correcting data quality errors, eliminating duplicate
    rows and anomalous data. You need to investigate the data and look for unusual
    values – this requires knowledge of the domain and how business logic is applied.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transforming the input features** – Machine models require inputs to be numeric.
    For example, you will use a technique called one-hot encoding when you have data
    that is not ordinal – such as country or gender data. This will convert the categorical
    value into a binary value, which creates better classifiers and therefore better
    models. But as you will see later, when you use the Auto ML feature of Redshift
    ML, this will have been taken care of for you.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_class`) for multi-class classification and the number of rounds (`num_rounds`)
    in an XGBoost model. Note that Amazon Redshift ML automatically tunes your model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Testing dataset** – This is the remaining 10% of your data used to evaluate
    the model performance after training and tuning the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traditionally, data preparation is a very time-consuming step and one of the
    reasons machine learning can be complex. As you will see later, Amazon Redshift
    ML automates many of the data preparation steps so you can focus on creating your
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating an ML model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After you have created your model, you need to calculate the model’s accuracy.
    When using Amazon Redshift ML, you will get a metric to quantify model accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some common methods used to determine model accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mean squared error** (**MSE**): MSE is the average of the squared differences
    between the predicted and actual values. It is used to measure the effectiveness
    of regression models. MSE values are always positive: the better a model is at
    predicting the actual values, the smaller the MSE value is. When the data contains
    outliers, they tend to dominate the MSE, which might cause subpar prediction performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accuracy**: The ratio of the number of correctly classified items to the
    total number of (correctly and incorrectly) classified items. It is used for binary
    and multi-class classification. It measures how close the predicted class values
    are to the actual values. Accuracy values vary between zero and one: one indicates
    perfect accuracy and zero indicates perfect inaccuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F1 score**: The F1 score is the harmonic mean of the precision and recall.
    It is used for binary classification into classes traditionally referred to as
    positive and negative. Predictions are said to be true when they match their actual
    (correct) class and false when they do not. Precision is the ratio of the true
    positive predictions to all positive predictions (including the false positives)
    in a dataset and measures the quality of the prediction when it predicts the positive
    class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F1_Macro** – The F1 macro score applies F1 scoring to multi-class classification.
    In this context, you have multiple classes to predict. You just calculate the
    precision and recall for each class, as you did for the positive class in binary
    classification. F1 macro scores vary between zero and one: one indicates the best
    possible performance and zero the worst.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Area under the curve** (**AUC**): The AUC metric is used to compare and evaluate
    binary classification by algorithms such as logistic regression that return probabilities.
    A threshold is needed to map the probabilities into classifications. The relevant
    curve is the receiver operating characteristic curve that plots the **true positive
    rate** (**TPR**) of predictions (or recall) against the **false positive rate**
    (**FPR**) as a function of the threshold value, above which a prediction is considered
    positive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now let’s take a look at a couple of these evaluation techniques in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Regression model evaluation example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A regression model’s accuracy is measured by the **Mean Square Error** (**MSE**)
    and **Root Mean Square Error** (**RMSE**). The MSE is the average squared difference
    between the predicted values and the actual values in a model’s dataset and is
    also known as *ground truth*. You can square the differences between the actual
    and predicted answers and then get the average to calculate the MSE. The square
    root of the MSE computes the RMSE. Low MSE and RMSE scores indicate a good model.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example of a simple way to calculate the MSE and RMSE so that you
    can compare them to the MSE score your model generated. Let’s assume we have a
    regression model predicting the number of hotel bookings by a customer for the
    next month.
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the MSE and RMSE as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You will calculate the MSE and RMSE for a regression model in one of the exercises
    in [*Chapter 7*](B19071_07.xhtml#_idTextAnchor111).
  prefs: []
  type: TYPE_NORMAL
- en: A classification model can be evaluated based on accuracy. The accuracy method
    is fairly straightforward, where it can be measured by taking the percentage of
    the total number of predictions compared to the total number of correct predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Binary classification evaluation example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A confusion matrix is useful for understanding the performance of classification
    models and is a recommended way to evaluate a classification model. We present
    the following details for your reference if you want to know more about this topic.
    We also have a detailed example in [*Chapter 10*](B19071_10.xhtml#_idTextAnchor178).
  prefs: []
  type: TYPE_NORMAL
- en: 'A confusion matrix is in a tabular format and contains four cells – **Actual
    Values** make up the *x* axis and **Predicted Values** make up the *y* axis, and
    the cells denote **True Positive**, **False Positive**, **False Negative**, and
    **True Negative**. This is good to measure precision, recall, and the **area under
    the curve** (**AUC**). *Figure 3**.1* shows a simple confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Actual Values** |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | True Positive | False Positive |'
  prefs: []
  type: TYPE_TB
- en: '| **Predicted Values** | False Negative | True Negative |'
  prefs: []
  type: TYPE_TB
- en: Figure 3.1 – Simple confusion matrix
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 3**.2*, we have 100 records in our dataset for our binary classification
    model where we are trying to predict customer churn:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Actual Values |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | 10 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Predicted Values | 6 | 80 |'
  prefs: []
  type: TYPE_TB
- en: Figure 3.2 – Confusion matrix
  prefs: []
  type: TYPE_NORMAL
- en: 'We can interpret the quality of our predictions from the model as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Correctly predicted 10 customers would churn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correctly predicted 80 customers would not churn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorrectly predicted 4 customers would churn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorrectly predicted 6 customers would not churn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The F1 score is one of the most important evaluation metrics as it considers
    the precision and recall rate of the model. For example, an F1 score of *.92*
    means that the model correctly predicted 92% of the time. This method makes sure
    predictions on both classes are good and *not* biased only toward one class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using our confusion matrix example from *Figure 3**.2*, we can calculate precision:'
  prefs: []
  type: TYPE_NORMAL
- en: Precision =  10 _ 10 + 4
  prefs: []
  type: TYPE_NORMAL
- en: 'This could also be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Precision =  True Positives  _______________________   (True Positives + False
    Positives)
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also calculate recall in a similar way:'
  prefs: []
  type: TYPE_NORMAL
- en: Recall =  10 _ 10 + 6
  prefs: []
  type: TYPE_NORMAL
- en: 'This could also be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Recall =  True Positives  _______________________   (True Positives + False
    Negatives)
  prefs: []
  type: TYPE_NORMAL
- en: 'The F1 score combines precision and recall – it can be calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 2 × ( precision × recall  ____________  precision + recall )
  prefs: []
  type: TYPE_NORMAL
- en: We have shown you the common techniques for evaluating ML models. As we progress
    through the book, you will see examples of these techniques that you can apply
    to your ML evaluation processes.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have learned the basics of ML, we will discuss some common challenges
    of implementing ML and how to overcome those.
  prefs: []
  type: TYPE_NORMAL
- en: Overcoming the challenges of implementing ML today
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data growth is both an opportunity and a challenge, and organizations are looking
    to extract more value from their data. Line-of-business users, data analysts,
    and developers are being called upon to use this data to deliver business outcomes.
    These users need easy-to-use tools and don’t typically have the skill set of a
    typical data scientist nor the luxury of time to learn these skills plus being
    experts in data management. Central IT departments are overwhelmed with analytics
    and data requirements and are looking for solutions to enable users with self-service
    tools delivered on top of powerful systems that are easy to use. Following are
    some of the main challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: Data is more diverse and growing rapidly. We have moved from analyzing terabytes
    to petabytes and exabytes of data. This data typically is spread across many different
    data stores across organizations. This means data has to be exported and then
    landed on another platform to train ML models. Amazon Redshift ML gives you the
    ability to train models using the data in place without having to move it around.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lack of expertise in data management impacts the ability to effectively scale
    to keep up with volumes of data and an increase in usage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lack of agility to react quickly to events and customer escalations due to
    data silos and the time required to train a model and make it available for use
    in making predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lack of qualified data scientists to meet today’s demands for machine learning.
    Demands are driven by the need to improve customer experiences, predict future
    revenues, detect fraud, and provide better patient care, just to name a few.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider the following workflow for creating an ML model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Typical machine learning workflow](img/B19071_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – Typical machine learning workflow
  prefs: []
  type: TYPE_NORMAL
- en: 'Following are the steps to create an ML model, as shown in *Figure 3**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we start off with data preparation. This can be a very time-consuming
    process and data may come from many different sources. This data must be cleansed,
    wrangled, and split into training and test datasets. It then needs to be exported
    and then loaded into the environment for training.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then you must know which ML algorithm you should use or you need to train your
    model on. This requires a data scientist who is skilled in tools such as R or
    Python and has experience in knowing which algorithm is best for a particular
    problem. As you will see in a later chapter, Amazon Redshift ML can automatically
    determine the algorithm for you.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then you will iterate many times through training, tuning, and validating the
    model until you find the best model for your use case.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, after you deploy the model, you need to continuously monitor the quality
    of the model and manage the environment including scaling hardware and applying
    patches and upgrades as needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In order to reduce the time required to build data pipelines for machine learning,
    we must bring machine learning closer to the data and reduce unnecessary data
    movement. You can use a data architecture, as we talked about in [*Chapter 1*](B19071_01.xhtml#_idTextAnchor015),
    *Introduction to Redshift Serverless*, with the data warehouse at the center.
    This also includes your data lake and other operational data stores, which, taken
    together, provide a unified view of all your data that is organized and easily
    available in a secure manner.
  prefs: []
  type: TYPE_NORMAL
- en: You can build upon the analytic stack that you have built out and enable your
    data analysts to build and train their own models. All data warehouse users can
    leverage the power of ML with no data science experience. DW users can create,
    train, and deploy ML models with familiar SQL commands. Then, using SQL, they
    can use those models to analyze the data accessible from Amazon Redshift. You
    can also leverage your existing models in Amazon SageMaker and run inferences
    on data stores in Amazon Redshift. Data scientists can leverage Redshift ML to
    iterate faster by baselining models directly through Redshift. BI professionals
    can now run inference queries directly through tools such as Amazon QuickSight.
  prefs: []
  type: TYPE_NORMAL
- en: Once you implement ML in your organization, you will begin to reap many benefits,
    which we will explore further in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the benefits of ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are three main areas where businesses can see the benefits of ML:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increased revenue** – With ML, you can leverage your data to quickly test
    new ideas in order to improve customer experiences. For example, using unsupervised
    learning, you can segment your customers and discover previously unknown purchase
    patterns, which can drive new focused campaigns for specific product or subscription
    offerings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Better operational and financial efficiency** – ML increases automation and
    agility within your business so that you can respond to changing market conditions
    faster. One example is forecasting product demand more accurately. By being able
    to better manage inventory, organizations can see huge cost savings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased agility to respond to business risks** – With ML, you can make
    decisions quicker than ever before. Using ML to detect anomalies, you can quickly
    take action when your supply chain, product quality, and other areas of your business
    face risks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application of ML in a data warehouse
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s look at a few use cases at a high level to illustrate some of these benefits.
    Subsequent chapters will dive into the details:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Improving customer experience**: ML can be used to reduce customer frustration
    with long wait times. Chatbots can answer many customer questions quickly, and
    in some cases, all of their questions:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Personalization**: ML can be used to better understand the behaviors and
    purchase history of customers to make more relevant offerings to customers based
    on their interests.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sentiment analysis**: ML can be used to understand customer sentiment from
    social media platforms. This analysis can then be used for marketing campaigns
    and customer retention efforts.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predicting equipment maintenance**: Consider any company with a fleet of
    vehicles or equipment. This could be a package delivery company or a service provider
    company that must be maintained appropriately. Without ML, it is likely that either
    equipment will be repaired too soon or too frequently, which leads to higher costs,
    or equipment will be repaired too late, which leads to equipment being out of
    service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use ML to predict the optimal time when each vehicle or piece of equipment
    needs to have maintenance to maximize operational efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: '**Financial analysis**: Banks and investment companies use ML for automation,
    risk analysis, portfolio allocation, and much more:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Calculating credit scores** – ML can quickly calculate credit scores and
    approve loans, which reduces risk.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fraud detection** – ML can quickly scan large datasets to detect anomalies
    and flag transactions and automatically decline or approve a transaction. Depending
    on the nature of a transaction, the system can automatically decline a withdrawal
    or purchase until a human makes a decision.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sports industry**: Auto racing teams can use a model to predict the best
    strategies for success and the most effective pit strategy:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build stronger team rosters by predicting future performance
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Improve player safety by predicting future injuries
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Health care industry**: Early detection of health conditions by combining
    ML with historical patient and treatment history and predicting the treatments
    with the highest probability of success.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just some of the benefits of ML. The possibilities are endless and
    advances are continually being made. As we go through subsequent chapters, you’ll
    see some use cases in action that you can try out on your own and start building
    up your ML skill set.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we walked you through how to apply machine learning to a data
    warehouse and explained the basics of ML. We also discussed how to overcome the
    challenges of implementing ML so that you can reap the benefits of ML in your
    organization.
  prefs: []
  type: TYPE_NORMAL
- en: These benefits contribute to increased revenue, better operational efficiencies,
    and better responses to changing business conditions. After this chapter, you
    now have a foundational understanding of the use cases and types of models you
    can deploy in your data warehouse.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will introduce you to Amazon Redshift ML and how you
    can start achieving business outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Part 2:Getting Started with Redshift ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Part 2* begins with an overview of Amazon Redshift ML, then dives into how
    to create various machine learning models using Amazon Redshift ML.'
  prefs: []
  type: TYPE_NORMAL
- en: By the end of *Part 2*, you will have an understanding of how to create a model
    by simply running a SQL command, the difference between supervised and unsupervised
    learning, and how to solve classification, regression, and clustering problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B19071_04.xhtml#_idTextAnchor057), *Leveraging Amazon Redshift
    Machine Learning*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B19071_05.xhtml#_idTextAnchor068), *Building Your First Machine
    Learning Model*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B19071_06.xhtml#_idTextAnchor083), *Building Classification Models*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B19071_07.xhtml#_idTextAnchor111), *Building Regression Models*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B19071_08.xhtml#_idTextAnchor139), *Building Unsupervised Models
    with K-Means Clustering*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
