- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Versioning and Reproducible Machine Learning Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reproducibility is an important topic to help machine learning developers go
    back to different stages of the machine learning life cycle and identify opportunities
    for model improvement. Having access to different versions of the data and models
    generated through the machine learning life cycles could help us in improving
    the reproducibility of our projects.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn about the meaning and importance of reproducibility
    in machine learning modeling. You will learn about tools for incorporating data
    versioning in machine learning pipelines to help you attain more effective collaboration
    in your projects and achieve reproducibility in your models. You will also learn
    about different aspects of model versioning and tools for incorporating it into
    your pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Reproducibility in machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data versioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model versioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll have learned how to use data and model versioning
    for your modeling projects in Python to achieve reproducibility.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the requirements for this chapter and will help you better
    understand the concepts, use them in your projects, and practice with the provided
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Python library requirements:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas` >= 1.4.4'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn` >= 1.2.2'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DVC` >= 1.10.0'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should also have basic knowledge of the machine learning life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find the code files for this chapter on GitHub at [https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter10](https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter10).
  prefs: []
  type: TYPE_NORMAL
- en: Reproducibility in machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Lack of *reproducibility* in your machine learning projects could be a waste
    of resources and decrease the credibility of your models and findings in your
    research projects. *Reproducibility* is not the only term used in this context;
    there are also two other key terms: *repeatability* and *replicability*. We don’t
    want to get into the details of these differences. Instead, we want to have a
    definition of reproducibility to use in this book. We define reproducibility in
    machine learning as the ability of different individuals or teams of scientists
    and developers to achieve the same results using the same dataset, methodology,
    and development environment as reported in an original report or study. We can
    ensure reproducibility through the proper sharing of code, data, model parameters
    and hyperparameters, and other relevant information, which allows others to validate
    and build upon our findings. Let’s better understand the importance of reproducibility
    by going through two examples.'
  prefs: []
  type: TYPE_NORMAL
- en: Scientists from a biotechnology company tried to reproduce the findings of 53
    cancer studies (Begley et al., 2012). But they were only able to reproduce the
    results of 6 out of the 53 studies. These were not necessarily in the context
    of reproducibility in machine learning, but it highlights the importance of reproducibility
    in scientific research and the potential consequences of basing decisions or further
    research and development on irreproducible findings.
  prefs: []
  type: TYPE_NORMAL
- en: Another example of highlighting the importance of reproducibility in the context
    of data analysis and data-driven discovery is what is known as the *Reinhart-Rogoff
    Excel Error* (Reinhart, C., and Rogoff, K., 2010). In 2010, the economists Carmen
    Reinhart and Kenneth Rogoff published a paper suggesting a negative correlation
    between high public debt and economic growth. This paper influenced economic policies
    worldwide. However, in 2013, other researchers discovered an error in their Excel
    calculations, which significantly impacted the results. But later, it was argued
    that the error was not the driver behind the conclusions (Maziarz, 2017). Here,
    we don’t want to focus on their findings but want to emphasize that the reproducibility
    of the analysis could eliminate any further argument regardless of whether or
    not there was an error or not in the original analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following three concepts can help you achieve reproducibility in your machine
    learning modeling projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code versioning**: Having access to the version of the code used in any given
    stage of a machine learning life cycle is fundamentally important to repeat an
    analysis or training and evaluation processes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data versioning**: To achieve reproducibility, we need to have access to
    the version of the data that’s used in any given stage of the machine learning
    life cycle, such as training and testing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model versioning**: Having a version of your model with frozen parameters
    and no randomness in initializing, evaluating, or other processes in modeling,
    helps you eliminate risks of irreproducibility'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We briefly talked about code versioning in [*Chapter 1*](B16369_01.xhtml#_idTextAnchor015),
    *Beyond Code Debugging*. Here, we will focus on data and model versioning to help
    you in designing reproducible machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Data versioning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have different stages in the machine learning life cycle, from data collection
    and selection to data wrangling and transformation, in which the data gets prepared
    step by step for model training and evaluation. Data versioning helps us maintain
    data integrity and reproducibility throughout these processes. Data versioning
    is the process of tracking and managing changes in datasets. It involves keeping
    a record of different versions or iterations of the data, allowing us to access
    and compare previous states or recover earlier versions when needed. We can reduce
    the risk of data loss or inconsistencies by ensuring that changes are properly
    documented and versioned.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are data versioning tools that can help us in managing and tracking changes
    in the data we want to use for machine learning modeling or processes to assess
    the reliability and fairness of our models. Here are some popular data-versioning
    tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**MLflow**: We introduced MLflow for experiment tracking and model monitoring
    in previous chapters, but you can also use it for data versioning ([https://mlflow.org/](https://mlflow.org/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Version Control** (**DVC**): This is an open source version control
    system for managing data, code, and ML models. It is designed to handle large
    datasets and integrates with Git ([https://dvc.org/](https://dvc.org/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pachyderm**: This is a data-versioning platform that provides reproducibility,
    provenance, and scalability in machine learning workflows ([https://www.pachyderm.com/](https://www.pachyderm.com/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Delta Lake**: This is an open source storage layer for Apache Spark and big
    data workloads that provides data versioning ([https://delta.io/](https://delta.io/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Git Large File Storage** (**Git-LFS**): This is an extension of Git that
    allows the versioning of large files, such as data files or models, alongside
    code ([https://git-lfs.github.com/](https://git-lfs.github.com/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these tools provides you with different data-versioning capabilities.
    You can choose the one that meets your needs considering the size of the data,
    the nature of the project, and the desired level of integration with other tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of using DVC with Python for data versioning. After installing
    DVC, you can initialize it by writing the following command in the Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create a `.dvc` directory and set up the necessary configuration.
    Now, let’s create a small DataFrame and save it as a CSV file in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can add the `dataset.csv` file to DVC and commit the changes, similar
    to committing code changes using Git:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates a `data.csv.dvc` file that tracks the dataset’s version, and it
    adds `data.csv` to `.gitignore` so that Git doesn’t track the actual data file.
    Now, we can modify the dataset as follows and save it with the same name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also commit the changes and save it as a different version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have two versions of the `dataset.csv` file, we can switch to the
    previous version or the latest version of the datasets when needed by using the
    following commands in the Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: But if you have many versions of the same file or data, you can use other simple
    commands available as part of DVC.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to versioning our data, we need to track and manage different versions
    of our models throughout the development life cycle. We will cover this next.
  prefs: []
  type: TYPE_NORMAL
- en: Model versioning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A model that goes to production is the eventual result of a series of experimentation
    and model modifications with different versions of training and test data, and
    different machine learning methods and their corresponding hyperparameters. Model
    versioning helps us ensure that changes that are made to models are traceable,
    helping to establish reproducibility in our machine learning projects. It ensures
    that every version of a model can be easily reproduced by providing a complete
    snapshot of the model’s parameters, hyperparameters, and training data at a given
    point in time. It allows us to easily roll back to a previous version in case
    of issues with a newly deployed model or to recover an older version that may
    have been unintentionally modified or deleted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go through a very simple example to better understand the need for model
    versioning. *Figure 10**.1* shows the performance of a random forest model with
    five estimators, or decision trees, and the different maximum depths allowed for
    these decision trees. If we simply change the random states that are used to split
    the data into train and test sets, using `train_test_split()` from `scikit-learn`,
    and perform model initialization for a `RandomForestClassifier()` model, we get
    different log-loss values and dependencies on the maximum depth of the trees in
    the random forest model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Log-loss in training and validation sets separated from the
    breast cancer dataset using different random states for modeling and data split](img/B16369_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Log-loss in training and validation sets separated from the breast
    cancer dataset using different random states for modeling and data split
  prefs: []
  type: TYPE_NORMAL
- en: This was a small example to show how such simple changes, which can happen if
    our models are not versioned, can have drastic effects on our machine learning
    modeling. When we use experiment tracking tools such as MLflow, we have access
    to all the tracked information for a selected model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To version our model, we need to make sure of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We have access to a saved version of the parameters of the corresponding model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other necessary information such as model hyperparameters are documented or
    saved for model retraining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code that needs to be used with the model parameters for inference or even
    retraining and testing is versioned
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processes with randomization, such as model initialization and data split for
    training and testing, have specified random states, or seeds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are different ways of storing your models and their related documentation.
    For example, you can store your model using serialization libraries such as `pickle`
    alone or in combination with DVC ([https://dvc.org/doc/api-reference/open](https://dvc.org/doc/api-reference/open)),
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: For this, you need to specify a local path on which to save the model using
    `pickle.dump` and a remote path for model versioning using DVC.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about the meaning and importance of reproducibility
    in machine learning modeling. You also learned about data and model versioning,
    which help us to develop more reliable and reproducible models and data analysis
    results. Next, you learned about the different tools and Python libraries you
    can use to version your data and models. With the concepts and practices introduced
    in this chapter, you are ready to ensure reproducibility in your machine learning
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn about techniques you can use to avoid and
    eliminate data drift and concept drift, which constitute two differences between
    the behavior of models before and after deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are three examples of tools that you can use for data versioning?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you generate different versions of the same data, such as by using DVC,
    do you need to save it with different names?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can you provide an example where you would use the same method and training
    and evaluation data but get different training and evaluation performance?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reinhart, C., & Rogoff, K. (2010b). *Debt and growth revisited*. VOX. CEPRs
    Policy Portal. Retrieved September 18, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinhart, C., & Rogoff, K. (2010a). *Growth in a time of debt*. American Economic
    Review, 100, 573–578.10.1257/aer.100.2.573.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Maziarz, Mariusz. *The Reinhart-Rogoff controversy as an instance of the ‘emerging
    contrary result’ phenomenon*. Journal of Economic Methodology 24.3 (2017): 213-225.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Begley, C. G., & Ellis, L. M. (2012). *Drug development: Raise standards for
    preclinical cancer research*. Nature, 483(7391), 531-533.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Association for Computing Machinery (2016). *Artifact Review and Badging*. Available
    online at [https://www.acm.org/publications/policies/artifact-review-badging](https://www.acm.org/publications/policies/artifact-review-badging)
    (Accessed November 24, 2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Plesser, Hans E. *Reproducibility vs. replicability: a brief history of a confused
    terminology*. Frontiers in neuroinformatics 11 (2018): 76.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pineau, J., Vincent, M., Larochelle, H., & Bengio, Y. (2020). *Improving reproducibility
    in machine learning research (A report from the NeurIPS 2019 reproducibility program)*.
    arXiv preprint arXiv:2003.12206.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raff, E., Lemire, D., & Nicholas, C. (2019). *A new measure of algorithmic stability
    for machine learning*. Journal of Machine Learning Research, 20(168), 1-32.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gundersen, O. E., & Kjensmo, S. (2018). *State of the art: Reproducibility
    in artificial intelligence*. In Thirty-Second AAAI Conference on Artificial Intelligence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jo, T., & Bengio, Y. (2017). *Measuring the tendency of CNNs to Learn Surface
    Statistical Regularities*. arXiv preprint arXiv:1711.11561.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Haibe-Kains, B., Adam, G. A., Hosny, A., Khodakarami, F., & Waldron, L. (2020).
    *Transparency and reproducibility in artificial intelligence*. Nature, 586(7829),
    E14-E16.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
