- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Labeling Data for Classification
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为分类任务标记数据
- en: In this chapter, we are going to learn how to label tabular data by applying
    business rules programmatically with Python libraries. In real-world use cases
    , not all of our data will have labels. But we need to prepare labeled data for
    training the **machine learning models** and **fine-tuning** the **foundation
    models**. The manual labeling of large sets of data or documents is cumbersome
    and expensive. In case of manual labeling, individual labels are created one by
    one. Also, occasionally, sharing private data with a crowd-sourcing team outside
    the organization is not secure.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何通过使用Python库以编程方式应用业务规则来标记表格数据。在实际应用案例中，并非所有我们的数据都会有标签。但我们需要为训练**机器学习模型**和**微调****基础模型**准备标记数据。手动标记大量数据或文档既繁琐又昂贵。在手动标记的情况下，标签是逐个创建的。此外，偶尔与组织外部的众包团队共享私有数据也不安全。
- en: So, programmatically labeling data is required to automate data labeling and
    quickly label a large-scale dataset. In case of programmatic labeling, there are
    mainly three approaches. In the first approach, users create **labeling functions**
    and apply to vast amounts of unlabeled data to auto label large training datasets.
    In the second approach, users apply **semi-supervised learning** to create **Pseudo-Labels**.
    **K-means clustering** is another way to group similar dataset and label those
    clusters. We will deep dive into all these three methods in this chapter and label
    the example tabular dataset. We will also discover how to utilize **large language
    models** (**LLMs**) for predicting labels in tabular data classification tasks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，需要通过编程方式对数据进行标记，以实现数据标记的自动化并快速标记大规模数据集。在编程标记的情况下，主要有三种方法。在第一种方法中，用户创建**标记函数**并将其应用于大量未标记的数据以自动标记大型训练数据集。在第二种方法中，用户应用**半监督学习**来创建**伪标签**。**K-means聚类**是另一种将相似数据集分组并标记这些聚类的途径。在本章中，我们将深入探讨这三种方法，并对示例表格数据集进行标记。我们还将发现如何利用**大型语言模型**（**LLMs**）在表格数据分类任务中预测标签。
- en: By the end of this chapter, you will be able to create labeling functions and
    a label model, and finally, you will be able to predict labels using that label
    model.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将能够创建标记函数和标记模型，并最终能够使用该标记模型预测标签。
- en: 'In this chapter, we are going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Predicting labels with LLMs for tabular data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LLMs预测表格数据的标签
- en: Labeling data using a rule-based generative model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于规则的生成模型进行数据标记
- en: Labeling data using semi-supervised learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用半监督学习进行数据标记
- en: Labeling data using K-means clustering
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用K-means聚类进行数据标记
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We need to install the Snorkel library using the following command:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要使用以下命令安装Snorkel库：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can download the dataset and Python notebook from the following link:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从以下链接下载数据集和Python笔记本：
- en: '[https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/code/Ch02](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/code/Ch02)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/code/Ch02](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/code/Ch02)'
- en: OpenAI setup requirements are same as mentioned in [*Chapter 1*](B18944_01.xhtml#_idTextAnchor015).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的设置要求与[第1章](B18944_01.xhtml#_idTextAnchor015)中提到的相同。
- en: Predicting labels with LLMs for tabular data
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LLMs预测表格数据的标签
- en: We will explore the process of predicting labels for tabular data classification
    tasks using **large language models** (**LLMs**) and few-shot learning.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨使用**大型语言模型**（**LLMs**）和少样本学习预测表格数据分类任务标签的过程。
- en: In the case of few-shot learning, we provide a few training data examples in
    the form of text along with a prompt for the model. The model adapts to the context
    and responds to new questions from the user.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在少样本学习的情况下，我们以文本形式提供一些训练数据示例，并附上对模型的提示。模型适应上下文并响应用户的新问题。
- en: First, let’s examine how to predict labels using LLMs for tabular data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看如何使用LLMs预测表格数据的标签。
- en: For tabular data, the initial step involves converting the data into serialized
    text data using LangChain’s templates. LangChain templates allow converting rows
    of data into fluent sentences or paragraphs by mapping columns to text snippets
    with variables that are filled based on cell values. Once we have the text data,
    we can utilize it as few-shot examples, comprising pairs of questions along with
    their corresponding labels (answers). Subsequently, we will send this few-shot
    data to the model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于表格数据，第一步是将数据转换为使用LangChain模板的序列化文本数据。LangChain模板允许通过将列映射到带有变量的文本片段来将数据行转换为流畅的句子或段落，这些变量根据单元格值填充。一旦我们有了文本数据，我们就可以将其作为包含问题及其对应标签（答案）对的少样本示例使用。随后，我们将这些少样本数据发送给模型。
- en: "![Figure 2.1 – LLM Few-shot example for \uFEFFpredicting labels](img/B18944_02_001.jpg)"
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1 – LLM几个示例用于预测标签](img/B18944_02_001.jpg)'
- en: Figure 2.1 – LLM Few-shot example for predicting labels
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – LLM几个示例用于预测标签
- en: Now we will use the LangChain template to translate the tabular data to natural
    language text.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用LangChain模板将表格数据转换为自然语言文本。
- en: '| **Patient ID** | **Age** | **Blood pressure** | **Diabetes** | **Death_event**
    |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| **患者ID** | **年龄** | **血压** | **糖尿病** | **死亡事件** |'
- en: '| 1 | 70 | high | yes | yes |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 70 | 高 | 是 | 是 |'
- en: '| 2 | 45 | high | no | no |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 45 | 高 | 否 | 否 |'
- en: '| 3 | 50 | normal | yes | ? |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 50 | 正常 | 是 | ? |'
- en: Table 2.1 – Few-shot example data in tabular format
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.1 – 几个示例数据表格格式
- en: 'The following is the text after converting the cell values to text using templates:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将单元格值转换为文本后得到的文本：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Similarly, we can convert the second row to text and send it as a few-shot example
    with a prompt to the LLM using `ChatCompletion` API.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以将第二行转换为文本，并使用`ChatCompletion` API将其作为几个示例与提示一起发送给LLM。
- en: 'These few shot examples are sent along with a prompt to the LLM and then the
    LLM responds with the predicted label, `Yes` or `No`, for new text:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些几个示例与一个提示一起发送给LLM，然后LLM对新文本预测标签，回答“是”或“否”：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We have seen how to leverage few-shot learning for predicting labels for tabular
    data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何利用少样本学习来预测表格数据的标签。
- en: The serialized data and the few-shot learning examples are used to provide context
    to the LLM model so that it can understand the meaning of the data and learn how
    to classify new tabular datasets. The LLM model generates a response based on
    the input.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化数据和少样本学习示例被用来为LLM模型提供上下文，以便它能够理解数据的含义并学习如何分类新的表格数据集。LLM模型根据输入生成响应。
- en: Now, let’s explore a second example of predicting labels using few-shot learning
    and LLMs for text data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探索第二个示例，使用少样本学习和LLM预测文本数据的标签。
- en: As mentioned earlier, in the case of few-shot learning, a small set of training
    data examples is provided along with the prompt to the LLM.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在少样本学习的情况下，提供一小组训练数据示例，并附上提示给LLM。
- en: The following code illustrates few-shot learning for predicting labels using
    prompts and LLMs. In this example, a system role is defined to guide the model
    in understanding the context and desired sentiment labels.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了使用提示和LLM进行标签预测的少样本学习示例。在这个例子中，定义了一个系统角色来引导模型理解上下文和期望的情感标签。
- en: The user provides a new message expressing sentiments about a new house. The
    code then calls the `ChatCompletion` API to generate a response using the specified
    GPT model deployment. The system and user messages are structured to guide the
    model’s understanding of the sentiment. The sentiment analysis output is obtained
    from the API response and printed.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 用户提供了一条表达对新房子情感的新消息。然后代码调用`ChatCompletion` API，使用指定的GPT模型部署生成响应。系统和用户消息被结构化以引导模型理解情感。从API响应中获取情感分析输出并打印。
- en: 'This approach enables the model to learn from examples provided in the system
    role and user messages, allowing it to predict sentiment labels for the user’s
    input:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法使模型能够从系统角色和用户消息中提供的示例中学习，从而能够预测用户输入的情感标签：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Send a completion call to generate the sentiment analysis
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发送完成调用以生成情感分析
- en: response = openai.ChatCompletion.create(
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: response = openai.ChatCompletion.create(
- en: engine = "",
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: engine = "",
- en: messages = [
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: messages = [
- en: '"role": "system", "content": system_role,'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '"role": "system", "content": system_role,'
- en: '"role": "user", "content": user_message,'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '"role": "user", "content": user_message,'
- en: ']'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ']'
- en: )
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: Print the sentiment analysis output
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 打印情感分析输出
- en: print(response['choices'][0]['message']['content'])
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: print(response['choices'][0]['message']['content'])
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: loading the data set
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据集
- en: '#df = pd.read_csv("<YourPath>/adult_income.csv", encoding=''latin-1)'''
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '#df = pd.read_csv("<YourPath>/adult_income.csv", encoding=''latin-1)'''
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: df.head()
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: df.head()
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: x = df.iloc[:,:-1]
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: x = df.iloc[:,:-1]
- en: y = df["income"]
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: y = df["income"]
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: from snorkel.labeling import labeling_function
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: from snorkel.labeling import labeling_function
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '@labeling_function()'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '@labeling_function()'
- en: 'def age(record):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 'def age(record):'
- en: 'if record[''age''] < 28 and record[''age''] > 58:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 'if record[''age''] < 28 and record[''age''] > 58:'
- en: return income_low
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: return "收入低"
- en: 'elif record[''age''] >28 and record[''age'']< 58:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 'elif record[''age''] >28 and record[''age'']< 58:'
- en: return income_high
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: return "收入高"
- en: 'else:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: return ABSTAIN
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: return "弃权"
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '@labeling_function()'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '@labeling_function()'
- en: 'def education(record):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 'def education(record):'
- en: 'if record[''education''] == "Bachelors" or record[''education''] == "Masters":'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 'if record[''education''] == "Bachelors" or record[''education''] == "Masters":'
- en: return income_high
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: return "收入高"
- en: 'else:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: return income_low
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: return "收入低"
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '@labeling_function()'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '@labeling_function()'
- en: 'def hours_per_week(record):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 'def hours_per_week(record):'
- en: 'if record[''hours.per.week''] > 40 or record[''hours.per.week''] < 60:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 'if record[''hours.per.week''] > 40 or record[''hours.per.week''] < 60:'
- en: return income_high
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: return "收入高"
- en: 'else:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: return income_low
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: return "收入低"
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '@labeling_function()'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '@labeling_function()'
- en: 'def work_class(record):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 'def work_class(record):'
- en: 'if record[''workclass''] == "Self-emp-inc" or record[''workclass''] == "Federal-gov":'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 'if record[''workclass''] == "Self-emp-inc" or record[''workclass''] == "Federal-gov":'
- en: return income_high
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: return "收入高"
- en: 'else:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 'else:'
- en: return income_low
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: return "收入低"
- en: '[PRE12]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: lfs = [age,education,hours_per_week,work_class]
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: lfs = [age,education,hours_per_week,work_class]
- en: from snorkel.labeling import PandasLFApplier
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: from snorkel.labeling import PandasLFApplier
- en: applier = PandasLFApplier(lfs=lfs)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: applier = PandasLFApplier(lfs=lfs)
- en: L_train = applier.apply(df=x)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: L_train = applier.apply(df=x)
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: From snorkel.labeling.model.label_model import LabelModel
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: From snorkel.labeling.model.label_model import LabelModel
- en: label_model = LabelModel(verbose=False)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: label_model = LabelModel(verbose=False)
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: label_model.fit(L_train=L_train, n_epochs=1000, seed=100)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: label_model.fit(L_train=L_train, n_epochs=1000, seed=100)
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: X['Labels'] = label_model.predict(L=L_train)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: X['Labels'] = label_model.predict(L=L_train)
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: pip install composeml
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: pip install composeml
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: import composeml as cp
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: import composeml as cp
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: from demo.next_purchase import load_sample
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: from demo.next_purchase import load_sample
- en: df = load_sample()
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: df = load_sample()
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'def amount_spent(df):'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 'def amount_spent(df):'
- en: total = df['amount'].sum()
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: total = df['amount'].sum()
- en: return total
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: return total
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: label_maker = cp.LabelMaker(
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: label_maker = cp.LabelMaker(
- en: target_dataframe_name="customer_id",
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: target_dataframe_name="customer_id",
- en: time_index="transaction_time",
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: time_index="交易时间",
- en: labeling_function=amount_spent,
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: labeling_function=amount_spent,
- en: window_size="5d",
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: window_size="5d",
- en: )
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: labels = label_maker.search(
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: labels = label_maker.search(
- en: df.sort_values('transaction_time'),
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: df.sort_values('transaction_time'),
- en: num_examples_per_instance=-1,
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: num_examples_per_instance=-1,
- en: gap=1,
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: gap=1,
- en: verbose=True,
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: verbose=True,
- en: )
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: labels.head()
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: labels.head()
- en: '[PRE22]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: labels = labels.threshold(300)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: labels = labels.threshold(300)
- en: labels.head()
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: labels.head()
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: import pandas as pd
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: import pandas as pd
- en: import numpy as np
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: import numpy as np
- en: from sklearn.model_selection import train_test_split
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.model_selection import train_test_split
- en: from sklearn.ensemble import RandomForestClassifier
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.ensemble import RandomForestClassifier
- en: '[PRE24]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: data = pd.read_csv("<your_path>/heart_failure_dataset.csv ", encoding='latin-1')
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: data = pd.read_csv("<your_path>/heart_failure_dataset.csv ", encoding='latin-1')
- en: 'y = training.DEATH_EVENT #Output for each example'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 'y = training.DEATH_EVENT #每个示例的输出'
- en: x = training.drop('DEATH_EVENT', axis=1)  #Input
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: x = training.drop('DEATH_EVENT', axis=1)  #输入
- en: '[PRE25]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: x_train,x_test,y_train,_ = train_test_split(x,y,test_size=.7)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: x_train,x_test,y_train,_ = train_test_split(x,y,test_size=.7)
- en: x_train.shape,y_train.shape,x_test.shape
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: x_train.shape,y_train.shape,x_test.shape
- en: '[PRE26]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: pseudomodel =  RandomForestClassifier(n_estimators = 10, criterion = 'entropy',
    random_state = 0)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: pseudomodel = RandomForestClassifier(n_estimators = 10, criterion = 'entropy',
    random_state = 0)
- en: '[PRE27]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: pseudomodel.fit(x_train,y_train)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: pseudomodel.fit(x_train,y_train)
- en: '[PRE28]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: pseudomodel.score(x_train,y_train)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: pseudomodel.score(x_train,y_train)
- en: '0.95'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '0.95'
- en: '[PRE29]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: y_new =  pseudomodel.predict(x_test)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: y_new = pseudomodel.predict(x_test)
- en: y_new.shape
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: y_new.shape
- en: '[PRE30]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Take a subset of the test set with pseudo-labels and append it onto
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从测试集中取一个子集，并附加到
- en: the training set
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: the training set
- en: from sklearn.utils import shuffle
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: from sklearn.utils import shuffle
- en: sampled_pseudo_data = pseudo_data.sample(n=150)
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: sampled_pseudo_data = pseudo_data.sample(n=150)
- en: temp_train = pd.concat([x, y], axis=1)
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: temp_train = pd.concat([x, y], axis=1)
- en: augemented_train = pd.concat([sampled_pseudo_data, temp_train])
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: augmented_train = pd.concat([sampled_pseudo_data, temp_train])
- en: shuffle(augemented_train)
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: shuffle(augmented_train)
- en: x = augemented_train.drop('DEATH_EVENT', axis=1)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: x = augmented_train.drop('DEATH_EVENT', axis=1)
- en: y = augemented_train.DEATH_EVENT
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: y = augmented_train.DEATH_EVENT
- en: x_train_final, x_test_final, y_train_final, y_test_final = train_test_split(x,
    y, test_size=0.3, random_state=42)
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: x_train_final, x_test_final, y_train_final, y_test_final = train_test_split(x,
    y, test_size=0.3, random_state=42)
- en: '[PRE31]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: finalmodel =  RandomForestClassifier(n_estimators = 10, criterion = 'entropy',
    random_state = 0)
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: finalmodel = RandomForestClassifier(n_estimators = 10, criterion = 'entropy',
    random_state = 0)
- en: '#this model is with augmented data'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '#此模型使用增强数据'
- en: finalmodel.fit(x_train_final,y_train_final)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: finalmodel.fit(x_train_final,y_train_final)
- en: finalmodel.score(x_train_final,y_train_final)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: finalmodel.score(x_train_final,y_train_final)
- en: '[PRE32]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Select features for clustering
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择聚类特征
- en: selected_features = ['hoursperweek', 'education-num']
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: selected_features = ['hoursperweek', 'education-num']
- en: '[PRE33]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: n_clusters = random.randint(2,4)
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: n_clusters = random.randint(2,4)
- en: '[PRE34]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: kmeans = KMeans(n_clusters=n_clusters, init='random', random_state=0)
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: kmeans = KMeans(n_clusters=n_clusters, init='random', random_state=0)
- en: kmeans.fit(X_scaled)
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: kmeans.fit(X_scaled)
- en: '[PRE35]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'while True:'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'while True:'
- en: '# Assign data points to clusters'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '# 将数据点分配到聚类中'
- en: cluster_labels = kmeans.predict(X_scaled)
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: cluster_labels = kmeans.predict(X_scaled)
- en: '# Calculate new centroids'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '# 计算新的质心'
- en: new_centroids = np.array([X_scaled[cluster_labels == i].mean(axis=0) for i in
    range(n_clusters)])
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: new_centroids = np.array([X_scaled[cluster_labels == i].mean(axis=0) for i in
    range(n_clusters)])
- en: '[PRE36]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '# Check for convergence by comparing old and new centroids'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '# 通过比较新旧质心来检查收敛性'
- en: 'if np.allclose(kmeans.cluster_centers_, new_centroids):'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if np.allclose(kmeans.cluster_centers_, new_centroids):'
- en: break
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: break
- en: '[PRE37]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '# Update centroids'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '# 更新质心'
- en: kmeans.cluster_centers_ = new_centroids
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: kmeans.cluster_centers_ = new_centroids
- en: '# Update inertia'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '# 更新惯性'
- en: inertia = kmeans.inertia_
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: inertia = kmeans.inertia_
- en: '[PRE38]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: intercluster_distances = pairwise_distances(kmeans.cluster_centers_)
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: intercluster_distances = pairwise_distances(kmeans.cluster_centers_)
- en: intracluster_distances = np.array([np.max(pdist(X_scaled[cluster_labels == i]))
    for i in range(n_clusters)])
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: intracluster_distances = np.array([np.max(pdist(X_scaled[cluster_labels == i]))
    for i in range(n_clusters)])
- en: '[PRE39]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: min_intercluster_distances = min(np.min(intercluster_distances[~np.eye(n_clusters,
    dtype=bool)]), min_intercluster_distances)
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: min_intercluster_distances = min(np.min(intercluster_distances[~np.eye(n_clusters,
    dtype=bool)]), min_intercluster_distances)
- en: max_intracluster_distances = max(np.max(intracluster_distances), max_intracluster_distances)
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: max_intracluster_distances = max(np.max(intracluster_distances), max_intracluster_distances)
- en: '[PRE40]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Print the results
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 打印结果
- en: 'print(f"Number of clusters: {n_clusters}")'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'print(f"聚类数量: {n_clusters}")'
- en: 'print(f"Inertia: {inertia}")'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'print(f"惯性: {inertia}")'
- en: 'print(f"Dunn''s Index: {dunn_index}")'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'print(f"Dunn指数: {dunn_index}")'
- en: '[PRE41]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Add the cluster labels as a new column to the original dataset
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将聚类标签作为新列添加到原始数据集中
- en: X['cluster_label'] = kmeans.labels_
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: X['cluster_label'] = kmeans.labels_
- en: Print the dataset with cluster labels
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 打印带有聚类标签的数据集
- en: X.head()
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: X.head()
- en: '[PRE42]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
