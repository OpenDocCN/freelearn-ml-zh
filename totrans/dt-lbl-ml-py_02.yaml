- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Labeling Data for Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we are going to learn how to label tabular data by applying
    business rules programmatically with Python libraries. In real-world use cases
    , not all of our data will have labels. But we need to prepare labeled data for
    training the **machine learning models** and **fine-tuning** the **foundation
    models**. The manual labeling of large sets of data or documents is cumbersome
    and expensive. In case of manual labeling, individual labels are created one by
    one. Also, occasionally, sharing private data with a crowd-sourcing team outside
    the organization is not secure.
  prefs: []
  type: TYPE_NORMAL
- en: So, programmatically labeling data is required to automate data labeling and
    quickly label a large-scale dataset. In case of programmatic labeling, there are
    mainly three approaches. In the first approach, users create **labeling functions**
    and apply to vast amounts of unlabeled data to auto label large training datasets.
    In the second approach, users apply **semi-supervised learning** to create **Pseudo-Labels**.
    **K-means clustering** is another way to group similar dataset and label those
    clusters. We will deep dive into all these three methods in this chapter and label
    the example tabular dataset. We will also discover how to utilize **large language
    models** (**LLMs**) for predicting labels in tabular data classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to create labeling functions and
    a label model, and finally, you will be able to predict labels using that label
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Predicting labels with LLMs for tabular data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labeling data using a rule-based generative model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labeling data using semi-supervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labeling data using K-means clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We need to install the Snorkel library using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You can download the dataset and Python notebook from the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/code/Ch02](https://github.com/PacktPublishing/Data-Labeling-in-Machine-Learning-with-Python/code/Ch02)'
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI setup requirements are same as mentioned in [*Chapter 1*](B18944_01.xhtml#_idTextAnchor015).
  prefs: []
  type: TYPE_NORMAL
- en: Predicting labels with LLMs for tabular data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will explore the process of predicting labels for tabular data classification
    tasks using **large language models** (**LLMs**) and few-shot learning.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of few-shot learning, we provide a few training data examples in
    the form of text along with a prompt for the model. The model adapts to the context
    and responds to new questions from the user.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s examine how to predict labels using LLMs for tabular data.
  prefs: []
  type: TYPE_NORMAL
- en: For tabular data, the initial step involves converting the data into serialized
    text data using LangChain’s templates. LangChain templates allow converting rows
    of data into fluent sentences or paragraphs by mapping columns to text snippets
    with variables that are filled based on cell values. Once we have the text data,
    we can utilize it as few-shot examples, comprising pairs of questions along with
    their corresponding labels (answers). Subsequently, we will send this few-shot
    data to the model.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 2.1 – LLM Few-shot example for \uFEFFpredicting labels](img/B18944_02_001.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – LLM Few-shot example for predicting labels
  prefs: []
  type: TYPE_NORMAL
- en: Now we will use the LangChain template to translate the tabular data to natural
    language text.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Patient ID** | **Age** | **Blood pressure** | **Diabetes** | **Death_event**
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 70 | high | yes | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 45 | high | no | no |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 50 | normal | yes | ? |'
  prefs: []
  type: TYPE_TB
- en: Table 2.1 – Few-shot example data in tabular format
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the text after converting the cell values to text using templates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Similarly, we can convert the second row to text and send it as a few-shot example
    with a prompt to the LLM using `ChatCompletion` API.
  prefs: []
  type: TYPE_NORMAL
- en: 'These few shot examples are sent along with a prompt to the LLM and then the
    LLM responds with the predicted label, `Yes` or `No`, for new text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We have seen how to leverage few-shot learning for predicting labels for tabular
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The serialized data and the few-shot learning examples are used to provide context
    to the LLM model so that it can understand the meaning of the data and learn how
    to classify new tabular datasets. The LLM model generates a response based on
    the input.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s explore a second example of predicting labels using few-shot learning
    and LLMs for text data.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, in the case of few-shot learning, a small set of training
    data examples is provided along with the prompt to the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: The following code illustrates few-shot learning for predicting labels using
    prompts and LLMs. In this example, a system role is defined to guide the model
    in understanding the context and desired sentiment labels.
  prefs: []
  type: TYPE_NORMAL
- en: The user provides a new message expressing sentiments about a new house. The
    code then calls the `ChatCompletion` API to generate a response using the specified
    GPT model deployment. The system and user messages are structured to guide the
    model’s understanding of the sentiment. The sentiment analysis output is obtained
    from the API response and printed.
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach enables the model to learn from examples provided in the system
    role and user messages, allowing it to predict sentiment labels for the user’s
    input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Send a completion call to generate the sentiment analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: response = openai.ChatCompletion.create(
  prefs: []
  type: TYPE_NORMAL
- en: engine = "",
  prefs: []
  type: TYPE_NORMAL
- en: messages = [
  prefs: []
  type: TYPE_NORMAL
- en: '"role": "system", "content": system_role,'
  prefs: []
  type: TYPE_NORMAL
- en: '"role": "user", "content": user_message,'
  prefs: []
  type: TYPE_NORMAL
- en: ']'
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: Print the sentiment analysis output
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: print(response['choices'][0]['message']['content'])
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: loading the data set
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '#df = pd.read_csv("<YourPath>/adult_income.csv", encoding=''latin-1)'''
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: df.head()
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: x = df.iloc[:,:-1]
  prefs: []
  type: TYPE_NORMAL
- en: y = df["income"]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: from snorkel.labeling import labeling_function
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '@labeling_function()'
  prefs: []
  type: TYPE_NORMAL
- en: 'def age(record):'
  prefs: []
  type: TYPE_NORMAL
- en: 'if record[''age''] < 28 and record[''age''] > 58:'
  prefs: []
  type: TYPE_NORMAL
- en: return income_low
  prefs: []
  type: TYPE_NORMAL
- en: 'elif record[''age''] >28 and record[''age'']< 58:'
  prefs: []
  type: TYPE_NORMAL
- en: return income_high
  prefs: []
  type: TYPE_NORMAL
- en: 'else:'
  prefs: []
  type: TYPE_NORMAL
- en: return ABSTAIN
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '@labeling_function()'
  prefs: []
  type: TYPE_NORMAL
- en: 'def education(record):'
  prefs: []
  type: TYPE_NORMAL
- en: 'if record[''education''] == "Bachelors" or record[''education''] == "Masters":'
  prefs: []
  type: TYPE_NORMAL
- en: return income_high
  prefs: []
  type: TYPE_NORMAL
- en: 'else:'
  prefs: []
  type: TYPE_NORMAL
- en: return income_low
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '@labeling_function()'
  prefs: []
  type: TYPE_NORMAL
- en: 'def hours_per_week(record):'
  prefs: []
  type: TYPE_NORMAL
- en: 'if record[''hours.per.week''] > 40 or record[''hours.per.week''] < 60:'
  prefs: []
  type: TYPE_NORMAL
- en: return income_high
  prefs: []
  type: TYPE_NORMAL
- en: 'else:'
  prefs: []
  type: TYPE_NORMAL
- en: return income_low
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '@labeling_function()'
  prefs: []
  type: TYPE_NORMAL
- en: 'def work_class(record):'
  prefs: []
  type: TYPE_NORMAL
- en: 'if record[''workclass''] == "Self-emp-inc" or record[''workclass''] == "Federal-gov":'
  prefs: []
  type: TYPE_NORMAL
- en: return income_high
  prefs: []
  type: TYPE_NORMAL
- en: 'else:'
  prefs: []
  type: TYPE_NORMAL
- en: return income_low
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: lfs = [age,education,hours_per_week,work_class]
  prefs: []
  type: TYPE_NORMAL
- en: from snorkel.labeling import PandasLFApplier
  prefs: []
  type: TYPE_NORMAL
- en: applier = PandasLFApplier(lfs=lfs)
  prefs: []
  type: TYPE_NORMAL
- en: L_train = applier.apply(df=x)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: From snorkel.labeling.model.label_model import LabelModel
  prefs: []
  type: TYPE_NORMAL
- en: label_model = LabelModel(verbose=False)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: label_model.fit(L_train=L_train, n_epochs=1000, seed=100)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: X['Labels'] = label_model.predict(L=L_train)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: pip install composeml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: import composeml as cp
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: from demo.next_purchase import load_sample
  prefs: []
  type: TYPE_NORMAL
- en: df = load_sample()
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'def amount_spent(df):'
  prefs: []
  type: TYPE_NORMAL
- en: total = df['amount'].sum()
  prefs: []
  type: TYPE_NORMAL
- en: return total
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: label_maker = cp.LabelMaker(
  prefs: []
  type: TYPE_NORMAL
- en: target_dataframe_name="customer_id",
  prefs: []
  type: TYPE_NORMAL
- en: time_index="transaction_time",
  prefs: []
  type: TYPE_NORMAL
- en: labeling_function=amount_spent,
  prefs: []
  type: TYPE_NORMAL
- en: window_size="5d",
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: labels = label_maker.search(
  prefs: []
  type: TYPE_NORMAL
- en: df.sort_values('transaction_time'),
  prefs: []
  type: TYPE_NORMAL
- en: num_examples_per_instance=-1,
  prefs: []
  type: TYPE_NORMAL
- en: gap=1,
  prefs: []
  type: TYPE_NORMAL
- en: verbose=True,
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: labels.head()
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: labels = labels.threshold(300)
  prefs: []
  type: TYPE_NORMAL
- en: labels.head()
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: import pandas as pd
  prefs: []
  type: TYPE_NORMAL
- en: import numpy as np
  prefs: []
  type: TYPE_NORMAL
- en: from sklearn.model_selection import train_test_split
  prefs: []
  type: TYPE_NORMAL
- en: from sklearn.ensemble import RandomForestClassifier
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: data = pd.read_csv("<your_path>/heart_failure_dataset.csv ", encoding='latin-1')
  prefs: []
  type: TYPE_NORMAL
- en: 'y = training.DEATH_EVENT #Output for each example'
  prefs: []
  type: TYPE_NORMAL
- en: x = training.drop('DEATH_EVENT', axis=1)  #Input
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: x_train,x_test,y_train,_ = train_test_split(x,y,test_size=.7)
  prefs: []
  type: TYPE_NORMAL
- en: x_train.shape,y_train.shape,x_test.shape
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: pseudomodel =  RandomForestClassifier(n_estimators = 10, criterion = 'entropy',
    random_state = 0)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: pseudomodel.fit(x_train,y_train)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: pseudomodel.score(x_train,y_train)
  prefs: []
  type: TYPE_NORMAL
- en: '0.95'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: y_new =  pseudomodel.predict(x_test)
  prefs: []
  type: TYPE_NORMAL
- en: y_new.shape
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Take a subset of the test set with pseudo-labels and append it onto
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: the training set
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: from sklearn.utils import shuffle
  prefs: []
  type: TYPE_NORMAL
- en: sampled_pseudo_data = pseudo_data.sample(n=150)
  prefs: []
  type: TYPE_NORMAL
- en: temp_train = pd.concat([x, y], axis=1)
  prefs: []
  type: TYPE_NORMAL
- en: augemented_train = pd.concat([sampled_pseudo_data, temp_train])
  prefs: []
  type: TYPE_NORMAL
- en: shuffle(augemented_train)
  prefs: []
  type: TYPE_NORMAL
- en: x = augemented_train.drop('DEATH_EVENT', axis=1)
  prefs: []
  type: TYPE_NORMAL
- en: y = augemented_train.DEATH_EVENT
  prefs: []
  type: TYPE_NORMAL
- en: x_train_final, x_test_final, y_train_final, y_test_final = train_test_split(x,
    y, test_size=0.3, random_state=42)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: finalmodel =  RandomForestClassifier(n_estimators = 10, criterion = 'entropy',
    random_state = 0)
  prefs: []
  type: TYPE_NORMAL
- en: '#this model is with augmented data'
  prefs: []
  type: TYPE_NORMAL
- en: finalmodel.fit(x_train_final,y_train_final)
  prefs: []
  type: TYPE_NORMAL
- en: finalmodel.score(x_train_final,y_train_final)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Select features for clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: selected_features = ['hoursperweek', 'education-num']
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: n_clusters = random.randint(2,4)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: kmeans = KMeans(n_clusters=n_clusters, init='random', random_state=0)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: kmeans.fit(X_scaled)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'while True:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '# Assign data points to clusters'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: cluster_labels = kmeans.predict(X_scaled)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '# Calculate new centroids'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: new_centroids = np.array([X_scaled[cluster_labels == i].mean(axis=0) for i in
    range(n_clusters)])
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '# Check for convergence by comparing old and new centroids'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'if np.allclose(kmeans.cluster_centers_, new_centroids):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: break
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '# Update centroids'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: kmeans.cluster_centers_ = new_centroids
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '# Update inertia'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: inertia = kmeans.inertia_
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: intercluster_distances = pairwise_distances(kmeans.cluster_centers_)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: intracluster_distances = np.array([np.max(pdist(X_scaled[cluster_labels == i]))
    for i in range(n_clusters)])
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: min_intercluster_distances = min(np.min(intercluster_distances[~np.eye(n_clusters,
    dtype=bool)]), min_intercluster_distances)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: max_intracluster_distances = max(np.max(intracluster_distances), max_intracluster_distances)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Print the results
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
- en: 'print(f"Number of clusters: {n_clusters}")'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'print(f"Inertia: {inertia}")'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'print(f"Dunn''s Index: {dunn_index}")'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Add the cluster labels as a new column to the original dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: X['cluster_label'] = kmeans.labels_
  prefs: []
  type: TYPE_NORMAL
- en: Print the dataset with cluster labels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: X.head()
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
