- en: '*Chapter 5*: Advanced Model Building – Part I'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*：高级模型构建 – 第一部分'
- en: In this chapter, we begin the transition from basic to advanced model building
    through the introduction of the nuanced issues and choices that a data scientist
    considers when building enterprise-grade models. We will discuss data splitting
    options, compare modeling algorithms, present a two-stage grid-search strategy
    for hyperparameter optimization, introduce H2O AutoML for automatically fitting
    multiple algorithms to data, and further investigate feature engineering tactics
    to extract as much information as possible from the data. We will introduce H2O
    Flow, a menu-based UI that is included with H2O, which is useful for monitoring
    the health of the H2O cluster and enables interactive data and model investigations.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过介绍数据科学家在构建企业级模型时考虑的细微问题和选择，开始从基本模型构建过渡到高级模型构建。我们将讨论数据分割选项，比较建模算法，提出超参数优化的两阶段网格搜索策略，介绍H2O
    AutoML，以自动将多个算法拟合到数据中，并进一步研究特征工程策略，以尽可能从数据中提取信息。我们将介绍H2O Flow，这是H2O附带的一个基于菜单的UI，它有助于监控H2O集群的健康状况，并允许进行交互式数据和模型调查。
- en: Throughout the entire process, we will illustrate these advanced model-building
    concepts using the Lending Club problem that was introduced in [*Chapter 3*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042),
    *Fundamental Workflow – Data to Deployable Model*. By the end of this chapter,
    you will be able to build an enterprise-scale, optimized predictive model using
    one or more supervised learning algorithms available within H2O. After that, all
    that is left is to review the model and deploy it into production.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个过程中，我们将使用在[*第三章*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042)中引入的Lending
    Club问题来阐述这些高级模型构建概念，*基本工作流程 – 从数据到可部署模型*。到本章结束时，你将能够使用H2O中可用的一个或多个监督学习算法构建一个企业级、优化的预测模型。之后，剩下的就是审查模型并将其部署到生产环境中。
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主要主题：
- en: Splitting data for validation or cross-validation and testing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分割用于验证或交叉验证和测试
- en: Algorithm considerations
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法考虑因素
- en: Model optimization with grid search
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用网格搜索进行模型优化
- en: H2O AutoML
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H2O AutoML
- en: Feature engineering options
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程选项
- en: Leveraging H2O Flow to enhance your IDE workflow
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用H2O Flow增强你的IDE工作流程
- en: Putting it all together – algorithms, feature engineering, grid search, and
    AutoML
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有内容整合在一起 – 算法、特征工程、网格搜索和AutoML
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: We are introducing the code and datasets in this chapter for the first time.
    At this point, if you have not set up your H2O environment, please refer to [*Appendix*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268)
    *– Alternative Methods to Launch H2O Clusters,* to do so.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中首次介绍代码和数据集。到目前为止，如果你还没有设置你的H2O环境，请参阅[*附录*](B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268)
    *– 启动H2O集群的替代方法*，以进行设置。
- en: Splitting data for validation or cross-validation and testing
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据分割用于验证或交叉验证和测试
- en: 'Splitting data into training, validation, and test sets is the accepted standard
    for model building when the size of the data is sufficiently large. The idea behind
    validation is simple: most algorithms naturally overfit on training data. Here,
    overfitting means that some of what is being modeled are actual idiosyncrasies
    of that specific dataset (for instance, noise) rather than representative of the
    population as a whole. So, how do you correct this? Well, you can do it by creating
    a holdout sample, called a validation set, which is scored against during the
    model-building process to determine whether what is being modeled is a signal
    or noise. This enables things such as hyperparameter tuning, model regularization,
    early stopping, and more.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据量足够大时，将数据分割为训练集、验证集和测试集是模型构建的公认标准。验证背后的思想很简单：大多数算法在训练数据上自然会出现过度拟合。在这里，过度拟合意味着正在建模的一些内容是该特定数据集的实际独特性（例如，噪声），而不是整个群体的代表性。那么，如何纠正这一点呢？嗯，你可以通过创建一个保留样本，称为验证集，在模型构建过程中对其进行评分，以确定正在建模的是信号还是噪声。这使超参数调整、模型正则化、早期停止等功能成为可能。
- en: The test dataset is an additional holdout that is used at the end of model building
    to determine true model performance. Having holdout test data is critical for
    any model build. In fact, it is so critical that you should neither trust nor
    deploy a model that has not been measured against a test dataset.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据集是在模型构建结束时使用的额外保留数据，用于确定模型的真正性能。对于任何模型构建来说，拥有保留测试数据都是至关重要的。事实上，它如此重要，以至于你不应该信任或部署没有与测试数据集进行比较的模型。
- en: 'An alternative to the train-validate-test split is to use a train-test split
    with k-fold cross-validation on the training data. Here is how that works:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 训练-验证-测试划分的替代方案是在训练数据上使用带有 k 折交叉验证的训练-测试划分。以下是它是如何工作的：
- en: Split the training data into k-folds, where, in our example, k is 5\.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练数据划分为 k 折，在我们的例子中，k 是 5。
- en: Fit a model with one of the folds playing the role of validation data and the
    other four folds being combined into training data.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用其中一个折作为验证数据，其他四个折合并为训练数据来拟合一个模型。
- en: Repeat this so that each fold is used as validation once.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复此过程，以便每个折都作为验证数据使用一次。
- en: This yields five models, each validated on a different subset of the data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这样可以得到五个模型，每个模型都在数据的不同子集上进行了验证。
- en: 'The following diagram illustrates this concept nicely:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表很好地说明了这个概念：
- en: '![Figure 5.1 – Illustration of 5-fold cross-validation'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.1 – 5 折交叉验证的示意图'
- en: '](img/Figure_5.1_B16721.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.1_B16721.jpg]'
- en: Figure 5.1 – Illustration of 5-fold cross-validation
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – 5 折交叉验证的示意图
- en: The k-fold cross-validation approach was originally developed for small data
    to allow the model to see more data in training. This comes at the cost of higher
    computational expenses. For many data scientists, k-fold cross-validation is used
    regardless of the data size.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: k 折交叉验证方法最初是为小数据集开发的，以便模型在训练中看到更多的数据。这以更高的计算成本为代价。对于许多数据科学家来说，无论数据集的大小如何，都会使用
    k 折交叉验证。
- en: Model Overfitting and Data Splitting
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 模型过拟合和数据划分
- en: The concept of model overfitting is critical. By definition, overfit models
    do not generalize well. If you are using a train-validate-test approach and building
    many models on the same validation set, it is likely that the leading model is
    overfit on the validation data. This likelihood increases as the number of models
    increases. Measuring the leading models against a holdout test set is the best
    indication of actual performance after deployment.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 模型过拟合的概念至关重要。根据定义，过拟合的模型泛化能力较差。如果你使用的是训练-验证-测试方法，并在同一个验证集上构建了许多模型，那么领先的模型很可能会在验证数据上过拟合。随着模型数量的增加，这种可能性会增大。将领先模型与保留测试集进行比较是衡量部署后实际性能的最佳指标。
- en: We can minimize any overfit-to-validation issues by ensuring each model is built
    on its own randomly selected train-validate partition. This could occur naturally
    in k-fold cross-validation if each model is built on a different partitioning
    of data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过确保每个模型都是基于其自己的随机选择的训练-验证分区来最小化任何过拟合到验证的问题。在 k 折交叉验证中，如果每个模型都是基于数据的不同分区构建的，这可能会自然发生。
- en: An interesting thing happens with data science competitions that have multiple
    entries (in the hundreds or thousands) that are tested against a blind holdout
    test dataset. It has been shown that leading models commonly overfit on the test
    data. So, what should you do in such a situation? The obvious answer is to have
    an additional holdout set, such as a meta-test set, that can be used to fairly
    evaluate how well these models would generalize after deployment.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学竞赛中，如果有多个参赛作品（数百或数千）与盲法保留测试数据集进行测试，会发生一些有趣的事情。已经证明，领先的模型通常会在测试数据上过拟合。那么在这种情况下，你应该怎么做呢？显然的答案是拥有一个额外的保留集，比如元测试集，这样就可以公平地评估这些模型在部署后如何泛化。
- en: In the next section, we will demonstrate both approaches using the Lending Club
    dataset. The following code begins in the *Model training* section of [*Chapter
    3*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042), *Fundamental Workflow – Data
    to Deployable Model*, specifically in *step 3* of *Fundamental Workflow*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将使用 Lending Club 数据集演示这两种方法。以下代码从 [*第 3 章*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042)
    的 *模型训练* 部分 *Fundamental Workflow – 数据到可部署模型* 开始，具体在 *基本工作流程* 的 *步骤 3* 中。
- en: Train, validate, and test set splits
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练、验证和测试集划分
- en: 'We split the data into three parts: 60% for training, 20% for validation, and
    20% for final testing, as shown in the following code block:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据分为三个部分：60% 用于训练，20% 用于验证，20% 用于最终测试，如下面的代码块所示：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The preceding code is straightforward. Optionally, we set `seed` for the reproducibility
    of the data splits. The `ratios` parameter only requires the training and validation
    proportions, and the test split is obtained by subtraction from one. The `destination_frames`
    option allows us to name the resulting data objects, which is not required but
    will make their identification in H2O Flow easier.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码很简单。可选地，我们设置`seed`以确保数据拆分的可重复性。`ratios`参数只需要训练和验证的比例，测试拆分通过从1中减去获得。`destination_frames`选项允许我们命名结果数据对象，这不是必需的，但会使在H2O
    Flow中识别它们更容易。
- en: Train and test splits for k-fold cross-validation
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: k折交叉验证的训练和测试拆分
- en: 'We could also split the data into two parts: 80% for training and 20% for testing.
    This can be done using a k-fold cross-validation approach, as the following code
    demonstrates:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将数据分成两部分：80%用于训练，20%用于测试。这可以通过k折交叉验证方法完成，如下面的代码所示：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: How to Set a Seed
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如何设置种子
- en: Random numbers in current computing are not random at all, but deterministic.
    **Pseudo**-**random number generators** (**PRNGs**) are complicated mathematical
    functions that return a fixed sequence of values given a specific seed. If the
    seed is omitted, the computer will set the seed automatically – typically, from
    the system clock. This seed value is often reported in logs. Setting the seed
    in code allows the analysis to be explicitly reproducible.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当前计算中的随机数根本不是随机的，而是确定的。**伪随机数生成器**（**PRNGs**）是复杂的数学函数，给定一个特定的种子会返回一个固定的值序列。如果省略了种子，计算机将自动设置种子——通常是从系统时钟中获取。这个种子值通常会在日志中报告。在代码中设置种子允许分析具有明确的可重复性。
- en: Next, we will turn our attention to choosing a modeling algorithm.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将关注选择建模算法。
- en: Algorithm considerations
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法考虑
- en: In this section, we will address the question of how a data scientist should
    decide which of the many machine learning and statistical algorithms should be
    chosen to solve a particular problem. We assume some prior familiarity with statistical
    and machine learning models such as logistic regression, decision trees, random
    forests, and gradient boosting models.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨数据科学家应该如何决定选择众多机器学习和统计算法中的哪一个来解决特定问题。我们假设读者对统计和机器学习模型如逻辑回归、决策树、随机森林和梯度提升模型有一定的了解。
- en: As outlined in [*Chapter 4*](B16721_04_Final_SK_ePub.xhtml#_idTextAnchor064),
    *H2O Model Building at Scale – Capability Articulation* H2O provides multiple
    supervised and unsupervised learning algorithms that can be used to build models.
    For example, in the case of a binary classification problem, a data scientist
    could choose a parametric GLM model (logistic regression); semiparametric GAM;
    nonparametric tree-based approaches such as **Random Forest**, **GBM**, **XGBoost**,
    or **RuleFit**; models from the machine learning community such as **Support Vector
    Machines** (**SVMs**) or **Deep Learning Neural Networks**; or the simple **Naïve
    Bayes Classifier**. To complicate things even further, any subset of these algorithms
    could be combined into one predictive model using **Stacked Ensembles** (which
    is a method for combining multiple highly predictive models into a single model;
    we will discuss this in the *H2O AutoML* section). So, what is a data scientist
    to do?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第4章](B16721_04_Final_SK_ePub.xhtml#_idTextAnchor064)中概述的，“H2O大规模模型构建 – 能力阐述”H2O提供了多种监督学习和无监督学习算法，可用于构建模型。例如，在二元分类问题的情况下，数据科学家可以选择参数化的GLM模型（逻辑回归）；半参数化的GAM；非参数的基于树的算法，如**随机森林**、**GBM**、**XGBoost**或**RuleFit**；来自机器学习社区的模型，如**支持向量机**（**SVMs**）或**深度学习神经网络**；或者简单的**朴素贝叶斯分类器**。更复杂的是，这些算法的任何子集都可以通过**堆叠集成**（这是一种将多个高度预测模型组合成一个模型的方法；我们将在*H2O
    AutoML*部分讨论此方法）组合成一个预测模型。那么，数据科学家该怎么办呢？
- en: A Note on RuleFit
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 关于RuleFit的说明
- en: The RuleFit algorithm is actually a penalized linear model. Here, we list it
    with tree-based models because the rules are extracted from a large population
    of randomly created decision trees. Rule selection and model regularization occur
    via LASSO. The intent is to combine the interpretability of linear models and
    explicit rules with the flexibility and predictive power of tree-based methods.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: RuleFit算法实际上是一个惩罚线性模型。在这里，我们将其与基于树的模型并列，因为规则是从大量随机创建的决策树中提取出来的。规则选择和模型正则化通过LASSO进行。目的是结合线性模型的可解释性和显式规则与基于树的方法的灵活性和预测能力。
- en: If the only criterion for model selection is pure predictive power, a data scientist
    could simply try everything and pick the model that performs best on a test dataset.
    Let's call this the *Kaggle solution*, named after the popular Kaggle data science
    competitions. Kaggle competitions result in algorithms and modeling approaches
    being pressure tested over multiple problems and datasets. Insights discovered
    during these competitions have found their way into real-world data science practices.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型选择的唯一标准是纯粹的预测能力，那么数据科学家可以简单地尝试所有方法，并选择在测试数据集上表现最好的模型。我们可以称之为*Kaggle解决方案*，这个名字来源于流行的Kaggle数据科学竞赛。Kaggle竞赛导致算法和建模方法在多个问题和数据集上进行了压力测试。在这些竞赛中发现的见解已经融入到现实世界的数据科学实践中。
- en: However, in an enterprise setting, it is rare for predictive power to be the
    only consideration for algorithm selection. Model transparency could be another.
    As an oversimplification, parametric models that are inherently interpretable
    (GLM) might be less predictive than nonparametric models. Nonparametric models
    such as random forest, GBM, XGBoost, and deep learning neural networks are black
    boxes that are difficult to interpret but frequently produce superior predictions.
    (Note that the GAM and RuleFit algorithms combine model transparency with predictions
    that often rival black-box methods.)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在企业环境中，预测能力通常是算法选择的唯一考虑因素的情况很少见。模型透明度可能是一个考虑因素。作为一个过度简化的例子，本质上可解释的参数模型（GLM）可能不如非参数模型具有预测性。随机森林、GBM、XGBoost和深度学习神经网络等非参数模型是难以解释的黑盒，但通常会产生更优越的预测。（注意，GAM和RuleFit算法结合了模型透明度和通常与黑盒方法相媲美的预测。）
- en: In addition to pure modeling criteria, there are business and implementation
    considerations that come into play in modeling and deployment decisions. We will
    cover these, in more detail, in the later chapters.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 除了纯粹的建模标准，在建模和部署决策中还有商业和实施方面的考虑。我们将在后面的章节中更详细地介绍这些内容。
- en: 'In the remaining part of this section, we will give a high-level overview of
    decision trees, random forest, and gradient boosting models. We will illustrate
    the Lending Club data while concentrating on two specific boosting implementations:
    H2O GBM and XGBoost.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的剩余部分，我们将对决策树、随机森林和梯度提升模型进行高级概述。我们将以Lending Club数据为例，专注于两种特定的提升实现：H2O GBM和XGBoost。
- en: Algorithm Popularity in the Industry
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 行业中的算法流行度
- en: Our collective experience of working with scores of customers spanning multiple
    industries leads to the following general observations. First, classification
    problems are more prevalent than regression problems by a wide margin. Second,
    when choosing an algorithm, the gold standard for interpretable classification
    problems remains logistic regression (GLM). The most frequent nonparametric algorithm
    choice is some form of gradient boosting, currently the GBM, XGBoost, or LightGBM
    implementations. The popularity of gradient boosting has been helped by its frequent
    appearance (either alone or in an ensemble) high up on the Kaggle leaderboards.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们与多个行业的大量客户合作的经验导致以下一般观察。首先，分类问题比回归问题更为普遍。其次，在选择算法时，可解释分类问题的黄金标准仍然是逻辑回归（GLM）。最常见的选择是非参数算法，通常是某种形式的梯度提升，目前是GBM、XGBoost或LightGBM实现。梯度提升的流行得益于它在Kaggle排行榜上频繁的出现（无论是单独出现还是作为集成的一部分）。
- en: An introduction to decision trees
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决策树的介绍
- en: At the heart of every random forest or GBM implementation is the concept of
    a decision tree. A decision tree can be used for either *classification*, where
    observations are assigned to discrete groups, or *regression*, where observations
    are a numerical outcome.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 每个随机森林或GBM实现的核心是决策树的概念。决策树可以用于*分类*，其中观察被分配到离散的组中，或者用于*回归*，其中观察是数值结果。
- en: 'Observation assignment is made through *conditional control statements* that
    form a tree-like structure. The general decision tree algorithm can be described
    as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过*条件控制语句*进行观察分配，这些语句形成一个树状结构。一般的决策树算法可以描述如下：
- en: Search through all the candidate predictors, identifying the variable split
    that yields the greatest predictive power.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在所有候选预测变量中搜索，以确定产生最大预测能力的变量分割。
- en: For each newly created branch, repeat the variable splitting process from *step
    1*.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个新创建的分支，重复从*步骤1*开始的变量分割过程。
- en: Continue until the stopping criteria are met.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续进行，直到满足停止标准。
- en: The functions used for splitting include information entropy and the Gini coefficient.
    Let's illustrate them using entropy. In information theory, the entropy of a random
    variable is the average level of uncertainty in the variable's outcomes. A pure
    or homogeneous classification tree node will have an entropy of zero. At each
    candidate split, we calculate the entropy and choose the split with the lowest
    entropy.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 用于分割的函数包括信息熵和基尼系数。让我们使用熵来阐述它们。在信息论中，随机变量的熵是该变量结果的平均不确定性水平。一个纯或同质的分类树节点将具有零熵。在每个候选分割点，我们计算熵并选择具有最低熵的分割。
- en: 'Conceptually, we could continue splitting until all nodes are pure, but that
    would yield an extremely overfit tree. Instead, we utilize stopping criteria such
    as the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，我们可以继续分割，直到所有节点都是纯的，但那样会产生一个过度拟合的树。相反，我们利用以下停止标准：
- en: The minimum number of observations that is needed at each node after splitting
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每次分割后，每个节点所需的观察数的最小值
- en: The reduction in entropy is not enough based on a selected cutoff value
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于所选截止值的熵减少不足
- en: The maximum depth of the tree
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 树的最大深度
- en: To illustrate, let's suppose we are building a decision tree to model the probability
    of surviving the sinking of the Titanic in 1912\. Our data includes name, gender,
    age, the class of passage booked, the price of the tickets, the location of the
    cabin or berth, the city where the passenger boarded, any traveling companions,
    and more. The resulting decision tree can be found in the diagram that follows.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，让我们假设我们正在构建一个决策树来模拟1912年泰坦尼克号沉没的生存概率。我们的数据包括姓名、性别、年龄、预订舱位的等级、票价、船舱或卧铺的位置、乘客登船的城市、任何旅行伴侣等等。结果决策树可以在下面的图中找到。
- en: 'The first split increases the predictive power the most (by reducing entropy
    the most):'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次分割最大限度地增加了预测能力（通过最大限度地减少熵）：
- en: Is the subject Male? If yes, the next split is created by the `Age < 18` rule.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主题是男性吗？如果是，则通过`年龄 < 18`规则创建下一个分割。
- en: For males older than 18, the survival probability for this terminal or *leaf*
    node is 17%.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于18岁以上的男性，此终端或*叶*节点的生存概率为17%。
- en: 'For males under 18, one more split is needed: `3rd Class`.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于18岁以下的男性，还需要一个额外的分割：`3级`。
- en: For males in the 3rd class who are under 18, the survival probability is 14%.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于3级且年龄低于18岁的男性，生存概率为14%。
- en: For males in the 1st and 2nd classes who are under 18, the survival probability
    is 44%.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于1级和2级且年龄低于18岁的男性，生存概率为44%。
- en: The tree on the `Male=Yes` branch stops splitting at these leaf nodes because
    one or more stopping criteria have been met.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 树在`Male=Yes`分支上的这些叶节点停止分割，因为这些节点满足了一个或多个停止标准。
- en: 'A similar process for the `Male=No` branch proceeds. Note that according to
    this model, non-`3rd Class` females have a survival probability of 95%. For `3rd
    Class` female passengers, survival probabilities depend on where they boarded,
    resulting in either a 38% or 70% survival probability leaf node. The decision
    tree model supports the *women and children first* ethos for emergencies at sea:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`Male=No`分支也进行类似的过程。请注意，根据此模型，非`3级`女性的生存概率为95%。对于`3级`女性乘客，生存概率取决于他们登船的位置，导致38%或70%的生存概率叶节点。决策树模型支持海难时的*妇女和儿童优先*的道德观：
- en: '![Figure 5.2 – A decision tree modeling the survival probabilities on the Titanic'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.2 – 一个模拟泰坦尼克号生存概率的决策树'
- en: '](img/Figure_5.2_B16721.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.2 – 一个模拟泰坦尼克号生存概率的决策树'
- en: Figure 5.2 – A decision tree modeling the survival probabilities on the Titanic
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – 一个模拟泰坦尼克号生存概率的决策树
- en: Decision trees have some clear advantages. Their layout is simple to comprehend,
    and their interpretation, as we have just demonstrated, is straightforward. The
    algorithm trains and scores quickly. Decision trees are robust when it comes to
    nonlinear relationships, feature distributions, correlated features, and missing
    values. On the other hand, they do not model linear relationships efficiently.
    They have high variance, meaning, in part, that trees are easily overfitted. Perhaps
    their greatest drawback is that individual decision trees don't predict particularly
    well, which is an issue that was first raised by the original developers of the
    decision tree methodology.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树有一些明显的优势。它们的布局简单易懂，并且正如我们刚才所展示的，它们的解释是直接的。算法训练和评分速度快。决策树在处理非线性关系、特征分布、相关特征和缺失值时具有鲁棒性。另一方面，它们在建模线性关系方面效率不高。它们具有高方差，这意味着部分原因是树容易过拟合。也许它们最大的缺点是单个决策树的预测能力特别差，这是决策树方法论原始开发者首先提出的问题。
- en: To remedy the poor predictive properties of decision trees, algorithms based
    on ensembles of individual trees have been developed. In general, the objective
    of ensemble methods is to create a *strong learner* by combining information across
    multiple *weak learners* (in our case, decision trees). The adaptation of two
    ensemble methods, bagging and boosting, to trees has resulted in random forest
    and gradient boosting algorithms, respectively. We will review each of these ensemble
    methods and their implementations in H2O next.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了纠正决策树预测性能不佳的问题，已经开发出基于单个树集成的方法。一般来说，集成方法的目的是通过结合多个*弱学习器*（在我们的情况下，是决策树）的信息来创建一个*强学习器*。将Bagging和Boosting两种集成方法应用于树，分别产生了随机森林和梯度提升算法。接下来，我们将回顾这些集成方法及其在H2O中的实现。
- en: Random forests
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机森林
- en: '**Bagging** (which is short for *bootstrap aggregating*) is an ensemble method
    that fits models to bootstrapped samples of the data and averages across them.
    **Bootstrapping** is a resampling method that samples from the data rows with
    replacement. This creates randomness in the row (or observation) space. Random
    forest is a bagging method for decision trees that adds randomness to the column
    (or variable) space.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**Bagging**（即*自助聚合*）是一种集成方法，它将模型拟合到数据的自助样本，并对它们进行平均。**自助法**是一种重采样方法，它从数据行中进行有放回的抽样。这会在行（或观察）空间中产生随机性。随机森林是决策树的一种Bagging方法，它向列（或变量）空间添加随机性。'
- en: 'The random forest algorithm can be described as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林算法可以描述如下：
- en: Build a deep tree based on randomly selected rows of the data.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于随机选择的数据行构建一个深度树。
- en: At each split, only evaluate a random subset of variables to split on.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每次分割时，仅评估一个随机子集的变量进行分割。
- en: Repeat this many times, creating a *forest* as a collection of all the trees.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复此操作多次，创建一个由所有树组成的*森林*。
- en: Get the average across all trees in the forest.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取森林中所有树的平均值。
- en: H2O includes two implementations of random forest, **Distributed Random Forest**
    (**DRF**) and **Extremely Randomized Trees** (**XRT**). In the following sections,
    we will summarize these algorithms.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: H2O包括两种随机森林实现，**分布式随机森林**（**DRF**）和**极端随机树**（**XRT**）。在接下来的章节中，我们将总结这些算法。
- en: Distributed Random Forest (DRF)
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分布式随机森林（DRF）
- en: 'DRF is the default random forest implementation in H2O. The highlights of this
    algorithm are listed as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: DRF是H2O中的默认随机森林实现。该算法的亮点如下：
- en: Each tree in a DRF is built in parallel.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DRF中的每一棵树都是并行构建的。
- en: The splitting rule is created by choosing the most discriminative threshold
    among a random subset of candidate features.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过选择候选特征随机子集中最具判别性的阈值来创建分割规则。
- en: Extremely Randomized Trees (XRT)
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 极端随机树（XRT）
- en: 'The XRT algorithm adds additional randomness to the splitting-rule process.
    This has the effect of reducing model variance at the cost of (slightly) increased
    bias. XRT is enabled by setting `histogram_type="Random"`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: XRT算法在分割规则过程中增加了额外的随机性。这以（略微）增加偏差为代价降低了模型方差。通过设置`histogram_type="Random"`来启用XRT：
- en: Each tree in an XRT is built in parallel.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XRT中的每一棵树都是并行构建的。
- en: Rather than finding the most discriminative threshold, this algorithm will create
    thresholds at random for each candidate variable. The best of this set is picked
    as the splitting rule.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 而不是寻找最具判别性的阈值，此算法将为每个候选变量随机创建阈值。从这个集合中选取最佳者作为分割规则。
- en: The hyperparameters for both random forest implementations are shared.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 两种随机森林实现的超参数是共享的。
- en: Random forest hyperparameters
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随机森林超参数
- en: 'The random forest methods in H2O require the following hyperparameters:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: H2O 中的随机森林方法需要以下超参数：
- en: The number of trees to be built, `ntrees` (this defaults to 50).
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要构建的树的数量，`ntrees`（默认值为 50）。
- en: The maximum tree depth, `max_depth` (this defaults to 20). Note that too large
    a value can result in overfitting.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大树深度，`max_depth`（默认值为 20）。请注意，过大的值可能导致过拟合。
- en: The minimum number of observations per leaf, `min_rows` (this defaults to 1).
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个叶子节点所需的最小观测数，`min_rows`（默认值为 1）。
- en: Additional hyperparameters are available for tuning the random forest model.
    You can find them at [https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html).
    A grid search can aid the process of hyperparameter selection and model optimization.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林模型提供了额外的超参数以供调整。您可以在[https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html)找到它们。网格搜索可以协助超参数选择和模型优化过程。
- en: Gradient boosting
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度提升
- en: Boosting is an ensemble method that combines models sequentially, with each
    new model built on the residuals of the previous model. Boosted trees are based
    on a sequence of relatively shallow decision trees.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 提升是一种结合模型序列的集成方法，每个新模型都是基于前一个模型的残差构建的。提升树基于一系列相对浅的决策树。
- en: 'The boosted trees algorithm can be described as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 提升树算法可以描述如下：
- en: Start by building a shallow decision tree.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先构建一个浅决策树。
- en: Fit a shallow decision tree to the residuals of the previous tree.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将浅决策树拟合到前一棵树的残差。
- en: Multiply the residual tree by a shrinkage parameter (or the learning rate).
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将残差树乘以收缩参数（或学习率）。
- en: Repeat *steps 2* and *3* until the stopping criteria are met.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复 *步骤 2* 和 *步骤 3*，直到满足停止标准。
- en: 'Building on the residuals makes the algorithm concentrate on areas where the
    model is not predicting well. The process is illustrated in the following diagram:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在残差上构建有助于算法专注于模型预测不佳的区域。这个过程在以下图中展示：
- en: '![Figure 5.3 – The H2O GBM algorithm'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.3 – The H2O GBM algorithm](img/Figure_5.3_B16721.jpg)'
- en: '](img/Figure_5.3_B16721.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.3_B16721.jpg](img/Figure_5.3_B16721.jpg)'
- en: Figure 5.3 – The H2O GBM algorithm
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – H2O GBM 算法
- en: 'The GBM approach results in highly predictive models, but care must be taken
    to avoid overfitting. H2O includes two versions of gradient boosting: H2O GBM
    and XGBoost. In the following sections, we will summarize these algorithms.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: GBM 方法导致高度预测性的模型，但必须小心避免过拟合。H2O 包含两种梯度提升版本：H2O GBM 和 XGBoost。在接下来的章节中，我们将总结这些算法。
- en: H2O GBM
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: H2O GBM
- en: 'The H2O GBM implementation follows the original algorithm, as described in
    the book, *The Elements of Statistical Learning by* *Jerome H. Friedman, Robert
    Tibshirani, and Trevor Hastie*, with modifications to improve performance on large
    and complex data. We can summarize this as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: H2O GBM 实现遵循书中描述的原算法，即由 *Jerome H. Friedman, Robert Tibshirani, 和 Trevor Hastie*
    所著的 *《统计学习的要素*》，并对大型和复杂数据的性能进行了改进。我们可以这样总结：
- en: Each tree in a GBM is built in parallel.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GBM 中的每一棵树都是并行构建的。
- en: Categorical variables can be split into groups instead of just using Boolean
    splits.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类别变量可以分成组，而不仅仅是使用布尔分割。
- en: Shared histograms are used to calculate cut points.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用共享直方图来计算分割点。
- en: H2O uses a greedy search of histogram bins, optimizing the improvement in squared
    error.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H2O 使用贪婪搜索直方图区间，优化平方误差的改进。
- en: One important advantage of this implementation is that H2O GBM naturally handles
    high-cardinality categorical variables (that is, categorical variables with a
    lot of categories).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 此实现的一个重要优点是 H2O GBM 自然处理高基数类别变量（即具有很多类别的类别变量）。
- en: XGBoost
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: XGBoost
- en: XGBoost is very similar to classic GBM, with the main difference being the inclusion
    of a penalty term for the number of variables. Mathematically, this means it contains
    regularization terms in the cost function. Trees are grown in *breadth* rather
    than *depth*.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 与经典 GBM 非常相似，主要区别在于包含变量数量的惩罚项。从数学上讲，这意味着它在成本函数中包含正则化项。树是在 *宽度* 而不是 *深度*
    上生长的。
- en: Another popular GBM approach is LightGBM. The LightGBM algorithm builds trees
    as deep as necessary by repeatedly splitting the one leaf that gives the biggest
    gain. Unlike XGBoost, trees are grown in *depth* rather than *breadth*. In theory,
    LightGBM is optimized for sparse data. While H2O does not implement LightGBM directly,
    it provides a method for emulating the LightGBM approach using a set of options
    within XGBoost (such as setting `tree_method="hist"` and `grow_policy="lossguide"`).
    For more details, please refer to [https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/xgboost.html](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/xgboost.html).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种流行的GBM方法是LightGBM。LightGBM算法通过重复分割提供最大增益的单个叶子节点来构建必要的深度。与XGBoost不同，树是在*深度*而不是*宽度*上生长的。理论上，LightGBM针对稀疏数据进行了优化。虽然H2O没有直接实现LightGBM，但它提供了一种使用XGBoost（如设置`tree_method="hist"`和`grow_policy="lossguide"`）选项来模拟LightGBM方法的方法。更多详情请参阅[https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/xgboost.html](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/xgboost.html)。
- en: Boosting hyperparameters
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升超参数
- en: 'All boosting methods in H2O require the following hyperparameters:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: H2O中的所有提升方法都需要以下超参数：
- en: The number of trees to be built, `ntrees` (the default is 50).
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要构建的树的数量，`ntrees`（默认为50）。
- en: The maximum tree depth, `max_depth` (the default is 6).
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大树深度，`max_depth`（默认为6）。
- en: The shrinkage parameter or learning rate, `learn_rate` (the default is 0.3).
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收缩参数或学习率，`learn_rate`（默认为0.3）。
- en: Simply adding trees to boosting approaches without further restrictions can
    lead to overfitting. A grid search can aid in the process of hyperparameter tuning.
    Additional hyperparameters for boosting will be introduced in the *Model optimization
    with grid search* section.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地将树木添加到提升方法中而不进行进一步限制可能导致过拟合。网格搜索可以在超参数调整过程中提供帮助。在*使用网格搜索进行模型优化*部分将介绍用于提升的额外超参数。
- en: Baseline model training
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基线模型训练
- en: Returning to the Lending Club data, now we are ready to build baseline models
    for each algorithm we are considering. By baseline, we mean models that have been
    fitted with settings at reasonable or default values. This will be the starting
    point in model optimization.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 回到Lending Club数据，我们现在准备为考虑的每个算法构建基线模型。这里的基线是指使用合理或默认值设置拟合的模型。这将是模型优化的起点。
- en: 'As discussed in [*Chapter 3*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042),
    *Fundamental Workflow – Data to Deployable Model*, we start with the `bad_loan`
    response and the same set of predictors for all models:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如[*第3章*](B16721_03_Final_SK_ePub.xhtml#_idTextAnchor042)中所述，*基本工作流程 - 从数据到可部署模型*，我们以`bad_loan`响应和所有模型的相同预测集开始：
- en: '[PRE10]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In the preceding code, we remove the `bad_loan` response variable and the `issue_d`
    raw date variable from the predictors. Recall that `issue_d` was used to create
    two features, `issue_d_month` and `issue_d_year`, which are included in the predictors.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们从预测集中移除了`bad_loan`响应变量和`issue_d`原始日期变量。回想一下，`issue_d`被用来创建两个特征，`issue_d_month`和`issue_d_year`，这些特征包含在预测集中。
- en: Next, we fit a baseline H2O GBM model using a train-validate-test split, followed
    by a baseline XGBoost model using 5-fold cross-validation.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用训练-验证-测试拆分拟合一个基线H2O GBM模型，然后使用5折交叉验证拟合一个基线XGBoost模型。
- en: Baseline GBM train-validate-test model
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基线GBM训练-验证-测试模型
- en: 'The first model we fit is a default H2O GBM, trained on the 60%–20% training-validation
    split with the following default settings:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先拟合的是默认的H2O GBM模型，它在60%–20%的训练-验证拆分上训练，以下为默认设置：
- en: '[PRE13]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here, the `model_id` parameter in the `gbm.train` command is optional and used
    to label the model object for identification in H2O Flow.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`gbm.train`命令中的`model_id`参数是可选的，用于在H2O Flow中标识模型对象。
- en: 'We will investigate model diagnostics and explainability, in greater depth,
    in [*Chapter 7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127), *Understanding
    ML Models*. Here, we are only using a couple of those commands to aid in comparing
    the gradient boosting algorithms. To begin with, we visualize the performance
    of the baseline GBM model across all splits using the `model_performance` method:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第7章*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127)中更深入地研究模型诊断和可解释性，*理解机器学习模型*。在这里，我们只使用其中的一些命令来帮助比较梯度提升算法。首先，我们使用`model_performance`方法可视化基线GBM模型在所有拆分上的性能：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The `%matplotlib` command allows figures to be displayed in a Jupyter notebook.
    This is only required once and is not needed outside of Jupyter. The first ROC
    curve is for the train split:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`%matplotlib` 命令允许在 Jupyter 笔记本中显示图形。这只需要执行一次，并且在不使用 Jupyter 的情况下不需要。'
- en: '![Figure 5.4 – The ROC curve for the GBM train split'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.4 – GBM 训练分割的 ROC 曲线'
- en: '](img/Figure_5.4_B16721.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.4_B16721.jpg)'
- en: Figure 5.4 – The ROC curve for the GBM train split
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 – GBM 训练分割的 ROC 曲线
- en: 'The second ROC curve for the validation split uses similar code:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 验证分割的第二个 ROC 曲线使用类似的代码：
- en: '[PRE22]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This will produce the following output:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 5.5 – The ROC curve for the GBM validation split'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.5 – GBM 验证分割的 ROC 曲线'
- en: '](img/Figure_5.5_B16721.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.5_B16721.jpg)'
- en: Figure 5.5 – The ROC curve for the GBM validation split
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 – GBM 验证分割的 ROC 曲线
- en: 'The ROC curve for the test split uses similar code:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 测试分割的 ROC 曲线使用类似的代码：
- en: '[PRE23]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This will produce the following output:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 5.6 – The ROC curve for the GBM test split'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.6 – GBM 测试分割的 ROC 曲线'
- en: '](img/Figure_5.6_B16721.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.6_B16721.jpg)'
- en: Figure 5.6 – The ROC curve for the GBM test split
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 – GBM 测试分割的 ROC 曲线
- en: 'To extract the AUC for these splits, we enter the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 要提取这些分割的 AUC，我们输入以下内容：
- en: '[PRE24]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The code block and results, as produced in the Jupyter notebook, are shown
    here:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块和结果，如 Jupyter 笔记本中产生的，在此处显示：
- en: '![Figure 5.7 – The GBM model performance results from the Jupyter notebook'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.7 – 来自 Jupyter 笔记本的 GBM 模型性能结果'
- en: '](img/Figure_5.7_B16721.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.7_B16721.jpg)'
- en: Figure 5.7 – The GBM model performance results from the Jupyter notebook
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 – 来自 Jupyter 笔记本的 GBM 模型性能结果
- en: 'Additionally, the train and validation performance values are stored in the
    model object:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，训练和验证性能值存储在模型对象中：
- en: '[PRE27]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This will return a dictionary, as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个字典，如下所示：
- en: '![Figure 5.8 – AUC from the GBM model object in the Jupyter notebook'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.8 – 来自 Jupyter 笔记本的 GBM 模型对象的 AUC'
- en: '](img/Figure_5.8_B16721.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.8_B16721.jpg)'
- en: Figure 5.8 – AUC from the GBM model object in the Jupyter notebook
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 – 来自 Jupyter 笔记本的 GBM 模型对象的 AUC
- en: These results show that the baseline GBM model is overfitting on the training
    data. This is not a surprise.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，基线 GBM 模型在训练数据上过度拟合。这并不令人惊讶。
- en: Let's take a quick look at model interpretation, which we will cover in more
    depth in [*Chapter 7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127), *Understanding
    ML Models*. The variable importance plot ranks variables in terms of relative
    importance in predicting bad loans. Relative importance for a variable is determined
    by checking whether that variable was used to split on and calculating the decrease
    in squared error across all trees.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速看一下模型解释，我们将在[*第7章*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127)中更深入地探讨，*理解机器学习模型*。变量重要性图按相对重要性对变量进行排序，以预测不良贷款。一个变量的相对重要性是通过检查该变量是否用于分割，并计算所有树上的平方误差的减少来确定的。
- en: 'Here is the code to produce a variable importance plot:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码用于生成变量重要性图：
- en: '[PRE28]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The generated plot is as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表如下：
- en: '![Figure 5.9 – The baseline GBM variable importance plot'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.9 – 基线 GBM 变量重要性图'
- en: '](img/Figure_5.9_B16721.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.9_B16721.jpg)'
- en: Figure 5.9 – The baseline GBM variable importance plot
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9 – 基线 GBM 变量重要性图
- en: The resulting variable importance plot, as shown in *Figure 5.9*, shows that
    the address state, which is a high-cardinality categorical variable with 50 levels
    corresponding to the states in the United States, is by far the most important
    variable.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图5.9*所示的结果变量重要性图显示，地址州，这是一个具有50个级别的高基数分类变量，对应于美国的各州，是迄今为止最重要的变量。
- en: Baseline XGBoost cross-validated model
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基线 XGBoost 交叉验证模型
- en: 'Let''s build our baseline XGBoost model using 5-fold cross-validation and the
    train-test split:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用5折交叉验证和训练-测试分割来构建我们的基线 XGBoost 模型：
- en: '[PRE29]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In the preceding code, `nfolds` sets the number of folds, `seed` is optional
    and included here for instructional purposes, and `model_id` is an optional identifier
    for use in H2O Flow.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`nfolds` 设置折叠数，`seed` 是可选的，这里包含它是为了教学目的，而 `model_id` 是 H2O Flow 中使用的可选标识符。
- en: 'We can get AUC for the train and cross-validation sets directly from the model
    object:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接从模型对象中获取训练和交叉验证集的 AUC：
- en: '[PRE35]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This yields the following result:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下结果：
- en: '![Figure 5.10 – The XGBoost model train and cross-validation performance results'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.10 – XGBoost 模型训练和交叉验证性能结果'
- en: '](img/Figure_5.10_B16721.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.10_B16721.jpg)'
- en: Figure 5.10 – The XGBoost model train and cross-validation performance results
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.10 – XGBoost模型训练和交叉验证性能结果
- en: 'The test set AUC requires that we include the test data to be scored against:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集AUC要求我们包括要评分的测试数据：
- en: '[PRE36]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This results in the following output:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 5.11 – The XGBoost model test performance results from the Jupyter
    notebook'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.11 – The XGBoost model test performance results from the Jupyter
    notebook'
- en: '](img/Figure_5.11_B16721.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.11_B16721.jpg](img/Figure_5.11_B16721.jpg)'
- en: Figure 5.11 – The XGBoost model test performance results from the Jupyter notebook
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11 – The XGBoost模型测试性能结果来自Jupyter笔记本
- en: 'We can easily combine these results into a single dictionary using a little
    Python code:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以很容易地使用一点Python代码将这些结果合并到一个字典中：
- en: '[PRE37]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This Python code block produces the following:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这个Python代码块生成了以下结果：
- en: '![Figure 5.12 – XGBoost model performance as a dictionary'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.12 – XGBoost模型性能作为字典'
- en: '](img/Figure_5.12_B16721.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.12_B16721.jpg](img/Figure_5.12_B16721.jpg)'
- en: Figure 5.12 – XGBoost model performance as a dictionary
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.12 – XGBoost模型性能作为字典
- en: 'Again, the AUC values confirm that the baseline model is overfit on the training
    data and is far too optimistic. The fact that the cross-validation and test AUC
    values are in the same ballpark is comforting, as it means the cross-validation
    procedure is more accurately reflecting what you might see in the out-of-sample
    test data. This is an important check and might not always be the case, especially
    when the training and test splits cover different time periods. Next, let''s consider
    a variable importance plot for the baseline XGBoost model:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，AUC值证实了基线模型在训练数据上过拟合，并且过于乐观。交叉验证和测试AUC值处于同一水平，这令人欣慰，因为它意味着交叉验证过程更准确地反映了你可能在样本外测试数据中看到的情况。这是一个重要的检查，并不总是如此，尤其是在训练和测试分割覆盖不同的时间段时。接下来，让我们考虑基线XGBoost模型的变量重要性图：
- en: '[PRE40]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The results are as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 5.13 – A baseline XGBoost variable importance plot'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.13 – A baseline XGBoost variable importance plot'
- en: '](img/Figure_5.13_B16721.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.13_B16721.jpg](img/Figure_5.13_B16721.jpg)'
- en: Figure 5.13 – A baseline XGBoost variable importance plot
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13 – 基线XGBoost变量重要性图
- en: A comparison of the variable importance plots for the GBM and XGBoost baseline
    models demonstrates some of the differences between these two boosting algorithms.
    Additionally, it introduces us to a more nuanced discussion of how to choose an
    algorithm given the multiple options under consideration.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: GBM和XGBoost基线模型的变量重要性图比较展示了这两种提升算法之间的差异。此外，它还引出了在考虑多个选项时如何选择算法的更深入讨论。
- en: Notice that the most important variable in the H2O GBM model is `addr_state`,
    a high-cardinality categorical variable (with approximately 50 levels corresponding
    to the states in the United States). XGBoost defaults to the one-hot encoding
    of categorical variable levels. One-hot encoding represents each level of a categorical
    variable with a numeric variable containing 1 for the rows in that level and 0
    otherwise. The one-hot encoding of a categorical variable with 50 levels such
    as `addr_state` results in 50 new, relatively sparse variables corresponding to
    each state. In the XGBoost variable importance plot, states appear individually
    and far lower in importance, such as `addr_state_FL`, `addr_state_CA`, and `addr_state_NV`
    in the previous plot.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在H2O GBM模型中最重要的变量是`addr_state`，这是一个高基数分类变量（大约有50个级别，对应于美国的各个州）。XGBoost默认将分类变量级别进行独热编码。独热编码将分类变量的每个级别用一个包含1的数值变量表示，该变量对应于该级别的行，否则为0。例如，`addr_state`这样的50个级别的分类变量的独热编码会产生50个新的、相对稀疏的变量，对应于每个州。在XGBoost变量重要性图中，各州单独出现，重要性远低于其他变量，如前图中`addr_state_FL`、`addr_state_CA`和`addr_state_NV`所示。
- en: A data scientist could always address this issue with feature engineering approaches
    such as target encoding. Target encoding, which we will revisit in more detail
    later, is a method for replacing levels of categorical variables with representative
    numeric values. If target encoding is implemented, then the choice between XGBoost
    and H2O GBM might come down to pure performance. On the other hand, if target
    encoding is not an option, then H2O GBM should be the boosting algorithm choice.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家可以通过特征工程方法，如目标编码来解决这个问题。目标编码，我们将在稍后更详细地回顾，是一种用代表性的数值值替换分类变量级别的的方法。如果实现了目标编码，那么XGBoost和H2O
    GBM之间的选择可能就取决于纯性能。另一方面，如果目标编码不是一个选项，那么H2O GBM应该是提升算法的选择。
- en: In other words, XGBoost requires target encoding, while H2O GBM gives the data
    scientist the option of modeling the high-cardinality categorical variables directly
    or by using a target-encoded version of those variables. This is a nice illustration
    of the interaction between algorithms, feature engineering choices, and potentially
    other factors such as business, compliance, or regulatory considerations.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，XGBoost 需要目标编码，而 H2O GBM 则给数据科学家提供了直接对高基数分类变量建模或使用这些变量的目标编码版本的选项。这是算法、特征工程选择以及可能的其他因素（如业务、合规性或监管考虑）之间相互作用的良好示例。
- en: Next, we will turn our attention to improving our baseline models by using grid
    search to find the hyperparameter settings for model optimization.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将关注通过使用网格搜索来找到模型优化的超参数设置，以改进我们的基线模型。
- en: Model optimization with grid search
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用网格搜索进行模型优化
- en: Choosing an algorithm for building a predictive model is not enough. Many algorithms
    have hyperparameters whose values have a direct impact on the predictive power
    of the model. So, how do you choose values for your hyperparameters?
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个算法来构建预测模型是不够的。许多算法都有超参数，其值对模型的预测能力有直接影响。那么，你该如何选择超参数的值呢？
- en: A brute-force method would create a grid of all possible values and search over
    them. This approach is computationally expensive, takes an inordinate amount of
    time, and ultimately, yields results that are not much better than what we could
    achieve by other means. We have outlined a strategy for grid search that has proved
    effective in building optimized models while running in a reasonable amount of
    time.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 暴力方法会创建一个包含所有可能值的网格，并对其进行搜索。这种方法计算成本高昂，耗时过长，最终得到的结果与我们通过其他方式所能达到的结果相差无几。我们已经概述了一种网格搜索策略，该策略在构建优化模型的同时，在合理的时间内运行。
- en: The general strategy entails, first, tuning a few key parameters using a **Cartesian**
    grid search. These key parameters are those we expect to have the biggest impact
    on the results. Then, we fine-tune other parameters using a random grid search.
    This two-stage approach allows us to hone in on the computationally expensive
    parameters first.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 一般策略包括首先使用笛卡尔网格搜索调整几个关键参数。这些关键参数是我们预期将对结果影响最大的参数。然后，我们使用随机网格搜索微调其他参数。这种两阶段方法使我们能够首先专注于计算成本较高的参数。
- en: 'From our experience with gradient boosting methods across many datasets from
    many domains, our strategy follows these principles:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们在多个领域的大量数据集上使用梯度提升方法的经验来看，我们的策略遵循以下原则：
- en: The optimal value for maximum allowed tree depth (`max_depth`) is heavily data-
    and problem-specific. Deeper trees, especially at depths greater than 10, can
    take significantly longer to train. In the interest of time, it is a good idea
    to, first, narrow the approximate depth down to a small range of values.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最大允许树深度（`max_depth`）的最佳值高度依赖于数据和问题。深度更大的树，尤其是在深度大于10的情况下，训练时间会显著增加。为了节省时间，首先将大致深度缩小到一个小范围值是一个好主意。
- en: We increase the number of trees (`ntrees`) until the validation set error starts
    increasing.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们增加树的数量（`ntrees`），直到验证集错误开始增加。
- en: Very low learning rates (`learn_rate`) are universally recommended. This generally
    yields better accuracy but requires more trees and additional computation time.
    A clever alternative is to start with a relatively high learning rate (say 0.05
    or 0.02) and iteratively shrink it by using `learn_rate_annealing`. For example,
    setting `learn_rate=0.02` and `learn_rate_annealing=0.995` speeds up convergence
    significantly without sacrificing much accuracy. This is very useful for hyperparameter
    searches. For even faster scans, values of 0.05 and 0.99 can be tried instead.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 极低的学习率（`learn_rate`）普遍推荐。这通常会产生更好的精度，但需要更多的树和额外的计算时间。一个巧妙的替代方案是从相对较高的学习率（例如0.05或0.02）开始，并通过使用`learn_rate_annealing`迭代地缩小它。例如，将`learn_rate=0.02`和`learn_rate_annealing=0.995`设置可以显著加快收敛速度，同时不会牺牲太多精度。这对于超参数搜索非常有用。为了更快地扫描，可以尝试0.05和0.99的值。
- en: Sampling rows and columns using `sample_rate` and `col_sample_rate`, respectively,
    reduces the validation and test set error rates and improves generalization. A
    good starting point for most datasets is between 70% and 80% sampling on both
    rows and columns (rates of between 0.7 and 0.8). Optionally, the column sampling
    rate per tree parameter (`col_sample_rate_per_tree`) can be set. It is multiplicative
    with `col_sample_rate`. For example, setting both parameters to 0.9 results in
    an overall 81% of columns being considered for the split.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `sample_rate` 和 `col_sample_rate` 分别采样行和列，可以降低验证集和测试集的错误率，并提高泛化能力。对于大多数数据集来说，行和列的采样率（介于
    0.7 和 0.8 之间）在 70% 到 80% 之间是一个好的起点。可选地，可以设置每个树的列采样率参数（`col_sample_rate_per_tree`）。它与
    `col_sample_rate` 是乘法关系。例如，将这两个参数都设置为 0.9，则总共考虑 81% 的列进行分割。
- en: Early stopping using `stopping_rounds`, `stopping_metric`, and `stopping_tolerance`
    can make grid search more efficient. For our needs, we can use 5, AUC, and 1e-4
    as good starting points. This means that if the validation AUC doesn't improve
    by more than 0.0001 after 5 iterations, the computation will end.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `stopping_rounds`、`stopping_metric` 和 `stopping_tolerance` 进行早期停止可以使网格搜索更高效。针对我们的需求，可以使用
    5、AUC 和 1e-4 作为良好的起点。这意味着如果在 5 次迭代后验证集 AUC 没有超过 0.0001 的提升，计算将结束。
- en: To improve the predictive accuracy of highly imbalanced classification datasets,
    the `sample_rate_per_class` parameter can be set. This implements stratified row
    sampling based on the specific response class. The parameter values are entered
    as an array of ratios, one per response class, in lexicographic order.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了提高高度不平衡的分类数据集的预测准确性，可以设置 `sample_rate_per_class` 参数。这实现了基于特定响应类的分层行采样。参数值以字典序排列的比率数组形式输入，每个响应类一个。
- en: Most of the other options only have a relatively small impact on model performance.
    That said, they might be worth tuning with a random hyperparameter search.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大多数其他选项对模型性能的影响相对较小。尽管如此，它们可能值得通过随机超参数搜索进行调整。
- en: Next, we will build an optimized H2O GBM model for the Lending Club data and
    compare the results with the baseline model.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将为 Lending Club 数据构建一个优化的 H2O GBM 模型，并将结果与基线模型进行比较。
- en: Step 1 – a Cartesian grid search to focus on the best tree depth
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 1 步 – 一个笛卡尔网格搜索来关注最佳树深度
- en: The optimal `max_depth` parameter value is very specific to the use case and
    data being modeled. Additionally, it has a profound impact on the model training
    time. In other words, large tree-depth values require significantly more computation
    than smaller values. First, we will focus on good candidate `max_depth` values
    using a quick Cartesian grid search.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳 `max_depth` 参数值非常具体于使用案例和建模的数据。此外，它对模型训练时间有深远的影响。换句话说，较大的树深度值需要比较小的值显著更多的计算。首先，我们将使用快速笛卡尔网格搜索来关注好的候选
    `max_depth` 值。
- en: 'Here, we use early stopping in conjunction with learning rate annealing to
    speed up convergence and efficiently tune the `max_depth` parameter:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们结合使用早期停止和学习率退火来加速收敛并有效地调整 `max_depth` 参数：
- en: 'We start by defining the hyperparameters:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先定义超参数：
- en: '[PRE41]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We follow our strategy by defining an excessive number of trees with early
    stopping enabled. We use learning rate annealing, as shown in the following code
    block, to shrink the `learn_rate` and sample 80% of the rows and columns. Also,
    we score every 10 trees in order to make the early stopping reproducible. For
    model builds with large amounts of data, we might want to score every 100 or 1,000
    trees:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过定义大量启用早期停止的树来遵循我们的策略。我们使用学习率退火，如以下代码块所示，来缩小 `learn_rate` 并采样 80% 的行和列。我们还每
    10 棵树评分一次，以便使早期停止可重复。对于大量数据的模型构建，我们可能希望每 100 或 1,000 棵树评分一次：
- en: '[PRE42]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Setting the score_tree_interval Parameter
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 设置 `score_tree_interval` 参数
- en: Scoring trees during a model grid search is essentially a waste of compute resources,
    as it requires more time to arrive at an optimum solution. However, it is required
    to make the early stopping process reproducible. We want to set the value high
    enough to ensure reproducibility but also not waste compute cycles. This is, largely,
    data- and problem-specific. The value of 10 that we used earlier is perhaps too
    aggressive even for this problem; 100 might have been more appropriate.
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在模型网格搜索期间评分树基本上是浪费计算资源，因为它需要更多的时间才能达到最佳解决方案。然而，它是使早期停止过程可重复所必需的。我们希望设置一个足够高的值以确保可重复性，但又不浪费计算周期。这在很大程度上是数据和相关问题的特定。我们之前使用的
    10 的值可能对这个问题来说过于激进；100 可能更合适。
- en: 'Now we define the grid and set the search criteria to Cartesian:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们定义网格并设置搜索标准为笛卡尔：
- en: '[PRE43]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Then, we fit the grid, as shown in the following code block:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们拟合网格，如下面的代码块所示：
- en: '[PRE44]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'To display the grid search results based on descending values of AUC, we use
    the following code:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要根据AUC的降序值显示网格搜索结果，我们使用以下代码：
- en: '[PRE45]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This results in the following:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了以下结果：
- en: '![Figure 5.14 – Tuning the maximum tree depth parameter value'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.14 – 调整最大树深度参数值'
- en: '](img/Figure_5.14_B16721.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.14_B16721.jpg](img/Figure_5.14_B16721.jpg)'
- en: Figure 5.14 – Tuning the maximum tree depth parameter value
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14 – 调整最大树深度参数值
- en: For this data and the H2O GBM algorithm, the `max_depth` values of 2 to 6 appear
    to give the best results. Next, we will search in the range of 2 to 6 and tune
    any additional parameters.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个数据和H2O GBM算法，`max_depth`的值为2到6似乎给出了最佳结果。接下来，我们将在2到6的范围内进行搜索并调整任何其他参数。
- en: Step 2 – a random grid search to tune other parameters
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步 – 随机网格搜索以调整其他参数
- en: 'Now that we have focused on a good range for the maximum tree depth, we can
    set up our tuning hyperparameters as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经关注了最大树深度的良好范围，我们可以设置以下调整超参数：
- en: '[PRE46]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The `min_split_improvement` parameter attempts to reduce overfitting in the
    GBM and XGBoost models by demanding that each split does not lead to worse error
    measures. We will try four different settings of that parameter.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_split_improvement`参数试图通过要求每个分割不会导致更差的误差度量来减少GBM和XGBoost模型中的过拟合。我们将尝试该参数的四种不同设置。'
- en: 'In the following search criteria, we limit our runtime to 5 minutes for illustrative
    purposes. Additionally, we limit the number of models built to 10\. Depending
    on your use case, you might want to increase the runtime substantially or just
    exclude these options altogether:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下搜索标准中，我们为了说明目的将运行时间限制为5分钟。此外，我们将构建的模型数量限制为10个。根据您的用例，您可能希望显著增加运行时间或完全排除这些选项：
- en: '[PRE52]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Also, we set up our final grid parameters:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们设置了最终的网格参数：
- en: '[PRE60]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'And we fit our final grid, as shown in the following code block:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们拟合最终的网格，如下面的代码块所示：
- en: '[PRE67]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Further Documentation
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 更多文档
- en: There are several additional hyperparameters available that are listed in the
    H2O documentation at [http://docs.h2o.ai/h2o/latest-stable/h2o-docs/parameters.html](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/parameters.html).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个额外的超参数可用，在H2O文档[http://docs.h2o.ai/h2o/latest-stable/h2o-docs/parameters.html](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/parameters.html)中列出。
- en: Further details on grid search can be found at [http://docs.h2o.ai/h2o/latest-stable/h2o-docs/grid-search.html#grid-search-in-python](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/grid-search.html#grid-search-in-python).
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 关于网格搜索的更多详细信息，请参阅[http://docs.h2o.ai/h2o/latest-stable/h2o-docs/grid-search.html#grid-search-in-python](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/grid-search.html#grid-search-in-python)。
- en: 'Now we train the model. Note that the `max_runtime_secs` setting, as follows,
    overrides the value set in `search_criteria_tune`:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们训练模型。请注意，以下`max_runtime_secs`设置覆盖了在`search_criteria_tune`中设置的值：
- en: '[PRE72]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'After 3 minutes or less, we look at the results of our grid search sorted by
    `AUC`:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在3分钟或更短的时间内，我们查看按`AUC`排序的网格搜索结果：
- en: '[PRE79]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'The output is as follows:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.15 – The grid search results for GBM model optimization'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.15 – GBM模型优化的网格搜索结果'
- en: '](img/Figure_5.15_B16721.jpg)'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.15_B16721.jpg](img/Figure_5.15_B16721.jpg)'
- en: Figure 5.15 – The grid search results for GBM model optimization
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15 – GBM模型优化网格搜索结果
- en: Optimization Strategy Results
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 优化策略结果
- en: This exercise shows the importance of hyperparameter tuning. Although we constrained
    this optimization by only searching for 3 minutes and producing 10 models, 9 out
    of 10 outperformed the baseline GBM model with default values.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习展示了超参数调整的重要性。尽管我们通过仅搜索3分钟并生成10个模型来限制了这个优化，但其中9个模型的表现优于具有默认值的基线GBM模型。
- en: 'We can easily select the best model based on the previous leaderboard and extract
    its AUC performance values:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以很容易地根据之前的排行榜选择最佳模型，并提取其AUC性能值：
- en: '[PRE82]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'This Python code block produces the following:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 以下Python代码块生成了以下结果：
- en: '![Figure 5.16 – The performance of the best optimized GBM model from the grid
    search'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.16 – 网格搜索中最佳优化GBM模型的表现'
- en: '](img/Figure_5.16_B16721.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.16_B16721.jpg](img/Figure_5.16_B16721.jpg)'
- en: Figure 5.16 – The performance of the best optimized GBM model from the grid
    search
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16 – 网格搜索中最佳优化GBM模型的表现
- en: Our grid search strategy is a tremendous way to fine-tune the hyperparameters
    of a machine learning model. Next, we will explore AutoML in H2O.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的网格搜索策略是微调机器学习模型超参数的绝佳方式。接下来，我们将探讨H2O中的AutoML。
- en: H2O AutoML
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: H2O AutoML
- en: The most efficient method of model building and tuning utilizes H2O AutoML.
    AutoML builds models from multiple algorithms while implementing appropriate grid
    search and model optimization based on the model type. The user can specify constraints
    such as compute time limits or limits on the number of models created.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 构建和调整模型的最有效方法是使用H2O AutoML。AutoML从多个算法中构建模型，同时根据模型类型实施适当的网格搜索和模型优化。用户可以指定约束条件，例如计算时间限制或创建模型数量的限制。
- en: 'Some features of AutoML include the following:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML的一些功能包括以下内容：
- en: AutoML trains a random grid of GLMs, GBMs, and DNNs using a carefully chosen
    hyperparameter space.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML使用精心选择的超参数空间训练GLM、GBM和DNN的随机网格。
- en: Individual models are tuned using a validation set or with cross-validation.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用验证集或交叉验证对单个模型进行调整。
- en: 'Two stacked ensemble models are trained by default: *All Models* and a lightweight
    *Best of Family* ensemble.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认训练两个堆叠集成模型：*所有模型*和轻量级的*家族最佳*集成。
- en: AutoML returns a sorted leaderboard of all models.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML返回所有模型的排序排行榜。
- en: Any model can be easily promoted to production.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何模型都可以轻松推广到生产环境中。
- en: '**Stacked ensembles** are highly predictive models that usually appear at the
    top of leaderboards. Similar to the other ensemble approaches that we introduced
    earlier (such as bagging and boosting), we stack works by combining information
    from multiple predictive models into one. Unlike bagging and boosting, which rely
    on weak learners as the component models, stacking works by optimally combining
    a diverse set of strongly predictive models. The *All Models* stacked ensemble
    is created by combining the entire list of models investigated in an AutoML run.
    The *Best of Family* ensemble contains, at most, six component models. Its performance
    is usually comparable to the All Models ensemble, but being less complex, it is
    typically better suited for production. (For more information on stacked ensembles,
    see [https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/stacked-ensembles.html](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/stacked-ensembles.html)).'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '**堆叠集成**是高度预测性的模型，通常出现在排行榜的顶部。类似于我们之前介绍的其他集成方法（如bagging和boosting），堆叠通过将多个预测模型的信息组合在一起来工作。与依赖于弱学习者的组件模型不同，堆叠通过最优地组合一组多样化的强预测模型来工作。*所有模型*堆叠集成是通过结合AutoML运行中调查的整个模型列表创建的。*家族最佳*集成最多包含六个组件模型。其性能通常与所有模型集成相当，但由于其复杂性较低，通常更适合生产。（有关堆叠集成的更多信息，请参阅[https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/stacked-ensembles.html](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/stacked-ensembles.html)）。'
- en: 'Training models using AutoML is relatively straightforward:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AutoML训练模型相对简单：
- en: '[PRE86]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The AutoML Runtime Parameter Choices
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML运行时参数选择
- en: Our values for the `max_runtime_secs_per_model` and `max_models` parameters
    allow us to quickly screen multiple model types while restricting overall runtime.
    This is neither optimal nor recommended and is used in tutorial or classroom settings
    to demonstrate AutoML. Instead, you can set the overall `max_runtime_secs` parameter
    to an explicit value. The default is 3,600 (that is, 1 hour).
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为`max_runtime_secs_per_model`和`max_models`参数设定的值使我们能够快速筛选多种模型类型，同时限制总体运行时间。这既不是最优的，也不是推荐的，通常在教程或课堂设置中使用以演示AutoML。相反，您可以将总体`max_runtime_secs`参数设置为显式值。默认值为3,600（即1小时）。
- en: 'H2O AutoML trains the following algorithms (in order):'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: H2O AutoML按以下顺序训练以下算法：
- en: Three XGBoost GBMs
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个XGBoost GBM
- en: A grid of GLMs
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组GLM网格
- en: A DRF
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个DRF
- en: Five H2O GBMs
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 五个H2O GBM
- en: A deep neural net
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个深度神经网络
- en: An extremely randomized forest
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个极端随机森林
- en: Random grids of XGBoost GBMs, H2O GBMs, and deep neural nets
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机网格的XGBoost GBM、H2O GBM和深度神经网络
- en: Two stacked ensemble models
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个堆叠集成模型
- en: If there is not enough time to complete all of these algorithms, some can be
    omitted from the leaderboard.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有足够的时间完成所有这些算法，一些算法可以从不包含在排行榜中。
- en: The AutoML leaderboard
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoML排行榜
- en: The AutoML object contains a leaderboard of models along with their cross-validated
    model performance. You can create a leaderboard for a specific dataset by specifying
    the `leaderboard_frame` argument.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML对象包含一个包含模型及其交叉验证模型性能的排行榜。您可以通过指定`leaderboard_frame`参数为特定数据集创建排行榜。
- en: 'The models are ranked by a metric whose default is based on the problem type:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是根据一个默认基于问题类型的指标进行排名的：
- en: For regression, this is deviance.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于回归，这是偏差。
- en: For binary classification, AUC is the default metric.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于二元分类，AUC是默认指标。
- en: For multiclass classification, we use the mean per-class error.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于多类分类，我们使用每类的平均误差。
- en: Additional metrics such as Logloss are provided for convenience.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了方便起见，还提供了额外的指标，如Logloss。
- en: 'Next, we print out the leaderboard:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们打印出排行榜：
- en: '[PRE94]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '![Figure 5.17 – The AutoML leaderboard'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.17 – AutoML排行榜'
- en: '](img/Figure_5.17_B16721.jpg)'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.17_B16721.jpg)'
- en: Figure 5.17 – The AutoML leaderboard
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.17 – AutoML排行榜
- en: As expected, the stacked ensemble models outperform all the individual models
    on the leaderboard. Any of these models can be selected for further investigation
    and potential deployment. Next, we will show you how to select the top model.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，堆叠集成模型在排行榜上的所有单个模型中表现最佳。这些模型中的任何一个都可以被选中进行进一步调查和潜在部署。接下来，我们将向您展示如何选择顶级模型。
- en: Examining the top model
  id: totrans-375
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检查顶级模型
- en: 'The `aml.leader` object contains the best model from the leaderboard, including
    details for both training and cross-validated data. We use the following code
    to print the AUC values for training, cross-validation, and testing data for the
    best model:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '`aml.leader`对象包含排行榜中的最佳模型，包括训练和交叉验证数据的详细信息。我们使用以下代码打印最佳模型的训练、交叉验证和测试数据的AUC值：'
- en: '[PRE95]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The resulting values are as follows:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 结果值如下：
- en: '![Figure 5.18 – The performance of the best model from the AutoML leaderboard'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.18 – AutoML排行榜中最佳模型的性能'
- en: '](img/Figure_5.18_B16721.jpg)'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.18_B16721.jpg)'
- en: Figure 5.18 – The performance of the best model from the AutoML leaderboard
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.18 – AutoML排行榜中最佳模型的性能
- en: Examining a selected model
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检查所选模型
- en: In practice, the leading model might not be the one you end up putting into
    production. As alluded to earlier, other considerations such as the modeling type,
    regulatory or compliance requirements, internal business preferences, and the
    likelihood of model approval could play a role in determining which model to use.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，领先的模型可能不是你最终投入生产的模型。如前所述，其他考虑因素，如建模类型、监管或合规要求、内部业务偏好以及模型批准的可能性，可能在确定使用哪个模型时发挥作用。
- en: Other Reasons to Use a Leaderboard
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 使用排行榜的其他原因
- en: The most obvious reason for using AutoML and exploring its leaderboard is to
    find the top model and put that into production. As mentioned earlier, that might
    not be allowed. Let's consider a scenario where I am only able to put a GLM into
    production. So, why bother fitting other models using AutoML? One answer is that
    the best model gives me a practical ceiling that I can also report. *GLM has an
    AUC of 0.69905, while the best possible model yielded 0.71336*.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AutoML和探索其排行榜的最明显原因是为了找到顶级模型并将其投入生产。如前所述，这可能不被允许。让我们考虑一个场景，即我只能将GLM投入生产。那么，为什么还要使用AutoML拟合其他模型呢？一个答案是，最佳模型给了我一个我可以报告的实际上限。*GLM的AUC为0.69905，而最佳可能模型的AUC为0.71336*。
- en: In a business context, I should always be able to translate performance differences
    into terms of cost reduction or increased profit. In other words, the AUC difference
    translated into dollars and cents is "the cost of doing business" or "how much
    money is being left on the table" by using the selected model instead of the best.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在商业环境中，我应该始终能够将性能差异转化为成本降低或利润增加的术语。换句话说，将AUC差异转化为美元和美分是“业务成本”或“使用所选模型而不是最佳模型所留下的钱”。
- en: 'Here, we demonstrate how to select any model from the leaderboard. The top
    individual (non-ensemble) model is in third position. We select this model with
    the following code and examine its performance in terms of AUC:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们演示如何从排行榜中选择任何模型。顶级单个（非集成）模型位于第三位。我们使用以下代码选择此模型，并检查其AUC性能：
- en: '[PRE99]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'This results in the following:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下结果：
- en: '![Figure 5.19 – The performance of the selected model from the AutoML leaderboard'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.19 – AutoML排行榜中选定模型的性能'
- en: '](img/Figure_5.19_B16721.jpg)'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.19_B16721.jpg)'
- en: Figure 5.19 – The performance of the selected model from the AutoML leaderboard
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.19 – AutoML排行榜中选定模型的性能
- en: Once a model object has been selected via AutoML, all the model diagnostics
    and explainability procedures, which we will cover in [*Chapter 7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127),
    *Understanding ML Models*, will be available.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦通过AutoML选择了模型对象，所有模型诊断和可解释性流程，我们将在[*第7章*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127)“理解机器学习模型”中介绍，都将可用。
- en: Feature engineering options
  id: totrans-400
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程选项
- en: In this section, we will demonstrate how feature engineering can lead to better
    predictive models. Second only to data cleaning, typically, feature engineering
    is the most time-consuming of all tasks involved in the modeling process. It can
    also be the "secret sauce" that makes for a great predictive model.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将演示特征工程如何导致更好的预测模型。通常，特征工程仅次于数据清洗，是建模过程中所有任务中最耗时的。它也可以是使预测模型出色的“秘密配方”。
- en: So, what does feature engineering mean? Put simply, it is how to extract information
    from raw data into a form that is both usable by the modeling algorithm and interpretable
    for the problem at hand. For example, a date or date-time object might be represented
    in data as a string or a number (for example, Unix time is the number of seconds
    since 00:00:00 UTC on January 1, 1970). Presented with such features, an algorithm
    is liable to treat dates as levels of a categorical variable or a continuous numeric
    value. Neither of these forms is very helpful. However, embedded in this raw data
    is information about not only the day, the month, and the year, but the day of
    the week, the weekend or weekday, seasons, holidays, and more. If the object contains
    time, then you could also produce the hour of the day, the time of day (for example,
    morning, afternoon, evening, or night), and more.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，特征工程是什么意思呢？简单来说，它是指如何从原始数据中提取信息，使其既能被建模算法使用，又能对当前问题进行解释。例如，日期或日期时间对象在数据中可能以字符串或数字（例如，Unix时间是从1970年1月1日00:00:00
    UTC以来的秒数）的形式表示。面对这样的特征，算法可能会将日期视为分类变量的级别或连续数值。这两种形式都不太有用。然而，这些原始数据中不仅包含了关于日、月、年的信息，还包括了星期几、周末或工作日、季节、节假日等等。如果对象包含时间，那么还可以产生一天中的小时数、一天中的时间（例如，上午、下午、傍晚或夜间）等等。
- en: Which features to create depends largely on the use case. Even in the best of
    circumstances, most engineered features may not be selected by a model algorithm.
    Subject-matter expertise and an understanding of the context of the problem play
    a major role in engineering good features. For example, the debt-to-income ratio
    used in lending divides how much a customer owes per month by their monthly income.
    This engineered feature has proven so predictive in risk modeling that it has
    been given its own name and abbreviation, DTI.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建哪些特征在很大程度上取决于用例。即使在最佳情况下，大多数工程特征也可能不会被模型算法选中。专业知识和对问题背景的理解在构建良好特征中起着重要作用。例如，在贷款中使用的债务收入比将客户每月欠款除以他们的月收入。这个工程特征在风险建模中已被证明具有很高的预测性，以至于它已经得到了自己的名称和缩写，DTI。
- en: Subject-Matter Expertise and Feature Engineering
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 专业知识与特征工程
- en: One of our colleagues, an accomplished data scientist, multiple Kaggle grandmaster,
    and a Ph.D., once commented that he did not enjoy FinTech data science competitions
    because "there is more Fin than Tech in them." By this, he meant, at least in
    part, that those problems put a premium on subject-matter insights that he had
    no experience of.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的一位同事，一位杰出的数据科学家、多次Kaggle大师，以及一位博士，曾评论说，他不喜欢参加FinTech数据科学竞赛，因为“其中Fin比Tech多。”通过这句话，他至少部分地意思是，那些问题高度重视他缺乏经验的领域专业知识。
- en: Another great example of feature engineering is **natural language processing**
    (**NLP**) in the context of predictive modeling. NLP attempts to represent words,
    word meanings, and sentences as numeric values that can be incorporated naturally
    into machine learning algorithms. TF-IDF and word embeddings (word2vec) are two
    such approaches. We will cover these in more detail in the *Modeling in Sparkling
    Water* section of [*Chapter 6*](B16721_06_Final_SK_ePub.xhtml#_idTextAnchor106),
    *Advanced Model Building – Part II*, and in the detailed Lending Club analysis
    within [*Chapter 8*](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137), *Putting
    It All Together*.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个特征工程的好例子是在预测建模的上下文中进行自然语言处理（**NLP**）。NLP试图将单词、单词含义和句子表示为可以自然地纳入机器学习算法的数值。TF-IDF和词嵌入（word2vec）是两种这样的方法。我们将在[*第6章*](B16721_06_Final_SK_ePub.xhtml#_idTextAnchor106)的*Sparkling
    Water建模*部分、*高级模型构建 – 第二部分*和[*第8章*](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137)的详细Lending
    Club分析中进行更详细的介绍，*整合一切*。
- en: In the remainder of this section, we will investigate target encoding in depth.
    Target encoding is one of the most common and impactful feature engineering options
    available. We will illustrate its use in the **Lending Club model**. In [*Chapter
    8*](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137), *Putting It All Together*,
    we will implement additional feature engineering recipes to improve the predictive
    model.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的剩余部分，我们将深入探讨目标编码。目标编码是可用的最常见和最有影响力的特征工程选项之一。我们将通过在**Lending Club模型**中展示其使用来阐述。在[*第8章*](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137)的*整合一切*中，我们将实现额外的特征工程配方来提高预测模型。
- en: Target encoding
  id: totrans-408
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标编码
- en: 'Target encoding replaces categorical levels with a numeric value representing
    some function of the target variable, such as the mean. The following diagram
    illustrates mean target encoding:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 目标编码将分类级别替换为表示目标变量某些函数的数值，例如平均值。以下图表说明了平均目标编码：
- en: '![Figure 5.20 – Mean target encoding'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 5.20 – 平均目标编码'
- en: '](img/Figure_5.20_B16721.jpg)'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.20_B16721.jpg]'
- en: Figure 5.20 – Mean target encoding
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.20 – 平均目标编码
- en: 'The approach is simple: replace the categorical feature levels (**A**, **B**,
    and **C**) with their respective means (**0.75**, **0.66**, and **1.00**).'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法很简单：将分类特征级别（**A**、**B**和**C**）替换为其相应的平均值（**0.75**、**0.66**和**1.00**）。
- en: Target encoding is a clever idea and, in spirit, is analogous to the random
    effects found in statistical random and mixed effect models. In fact, for certain
    simple cases, you can prove that mean target encoding actually yields the empirical
    Bayes estimates of the random effects. What this means is that the intent behind
    target encoding is based on sound principles.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 目标编码是一个巧妙的想法，在精神上与统计随机和混合效应模型中发现的随机效应类似。实际上，对于某些简单的情况，你可以证明平均目标编码实际上产生了随机效应的经验贝叶斯估计。这意味着目标编码背后的意图是基于正确的原则。
- en: However, target encoding uses a function of the target as an input to predict
    the target. This is the very definition of data leakage. Data leakage leads to
    overly optimistic models that do not generalize well and are, at best, misleading
    in practice. H2O implements target encoding using carefully constructed cross-validation
    procedures. Essentially, this eliminates data leakage by calculating the target-encoded
    value for each row based on other folds of the data.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，目标编码使用目标的函数作为预测目标的输入。这正是数据泄露的定义。数据泄露会导致过度乐观的模型，这些模型泛化能力差，在实践中至多只是误导。H2O通过精心构建的交叉验证程序实现目标编码。本质上，这是通过基于其他数据折叠计算每行的目标编码值来消除数据泄露。
- en: Random Effects
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 随机效应
- en: The mathematical structure underlying the estimation of random effects in statistical
    models does not suffer from data leakage concerns in the same way that target
    encoding does. This is because the information in the target variable is partitioned,
    and the portion used to estimate the random effects is separate from the portion
    used to estimate the other model parameters.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 统计模型中随机效应估计的数学结构不会像目标编码那样受到数据泄露问题的困扰。这是因为目标变量中的信息被分割，用于估计随机效应的部分与用于估计其他模型参数的部分是分开的。
- en: 'We use the **H2O-3 Target Encoding Estimator** to replace categorical values
    with a mean of the target variable. We tune target encoding via the following:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用**H2O-3目标编码估计器**将分类值替换为目标变量的平均值。我们通过以下方式调整目标编码：
- en: Setting `data_leakage_handling` to `k-fold` controls data leakage.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`data_leakage_handling`设置为`k-fold`可以控制数据泄露。
- en: Adding random `noise` to the target average helps to prevent overfitting.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向目标平均值添加随机`noise`有助于防止过拟合。
- en: We adjust for categories with small group sizes through `blending`.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过`blending`调整小群体大小的类别。
- en: Any categorical levels with fewer observations will result in an unreliable
    (high variance) target-encoded mean. A blended average consisting of a weighted
    average of the group's target value and the global target value can improve this
    estimate. By setting `blending=True`, the target mean will be weighted based on
    the sample size of the categorical level.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 任何观测值较少的分类层级将导致目标编码的平均值不可靠（高方差）。由组的目标值和全局目标值的加权平均值组成的混合平均可以改善这个估计。通过设置`blending=True`，目标平均值将根据分类层级的样本大小进行加权。
- en: When blending is enabled, the `smoothing` parameter controls the rate of transition
    between the level's posterior probability and the prior probability (with a default
    value of 20). The `inflection_point` parameter represents half of the sample size
    for which we completely trust the estimate. The default value is 10.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 当启用混合时，`smoothing`参数控制层级后验概率与先验概率（默认值为20）之间的过渡速率。`inflection_point`参数代表我们完全信任估计的样本大小的一半。默认值是10。
- en: Target encoding the Lending Club data
  id: totrans-424
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对Lending Club数据进行目标编码
- en: 'To determine whether a categorical variable would benefit from target encoding,
    first, create a table for the variable, which has been sorted from most frequent
    to least frequent. To do this efficiently, we will define a Python function:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定一个分类变量是否可以从目标编码中受益，首先，为该变量创建一个从最频繁到最不频繁排序的表格。为此，我们将定义一个Python函数：
- en: '[PRE103]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: Note that the preceding code requires the Python pandas package to be available
    since the `as_data_frame` call outputs the table in a pandas format.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，前面的代码需要Python pandas包可用，因为`as_data_frame`调用以pandas格式输出表格。
- en: 'First, consider the `purpose` variable, which records the purpose of the loan:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，考虑记录贷款目的的`purpose`变量：
- en: '[PRE109]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'This returns the following:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回以下内容：
- en: '![Figure 5.21 – Levels of the purpose variable'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.21 – purpose变量的层级'
- en: '](img/Figure_5.21_B16721.jpg)'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/Figure_5.21_B16721.jpg]'
- en: Figure 5.21 – Levels of the purpose variable
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.21 – purpose变量的层级
- en: Note the high concentration of loans for debt consolidation (46%) and the sizable
    numbers for both credit cards (13%) and other (11%), with the remaining 30% captured
    among 11 other loan purposes. One option for this data would be to collapse the
    categories into fewer levels and leave the `purpose` variable as a categorical
    variable. This might make sense if the categories could be collapsed in a coherent
    manner. A better option uses mean target encoding to represent all levels without
    overfitting those with small percentages in the tail. Blending will also be enabled
    here, although the amount of smoothing it provides might not be impactful. The
    `renewable_energy` category has 75 observations, which, in most cases, is sufficient
    to reliably estimate a mean even though the percentage is very small.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 注意债务重组贷款（46%）的高度集中，以及信用卡（13%）和其他（11%）的相当数量，剩余的30%分布在11个其他贷款用途中。对于这些数据的一个选项是将类别合并成更少的层级，并将`purpose`变量保留为分类变量。如果类别可以以连贯的方式合并，这可能是有意义的。更好的选项是使用平均目标编码来表示所有层级，而不会过度拟合尾部的小百分比。在这里也将启用混合，尽管它提供的平滑量可能不会产生重大影响。`renewable_energy`类别有75个观测值，在大多数情况下，即使百分比非常小，这也足以可靠地估计平均值。
- en: 'A second variable to consider is `addr_state`:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑的第二个变量是`addr_state`：
- en: '[PRE110]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'The first few rows are listed as follows:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 前几行如下所示：
- en: '![Figure 5.22 – The top ten states by count'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.22 – 按计数排名前十的州'
- en: '](img/Figure_5.22_B16721.jpg)'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.22_B16721.jpg)'
- en: Figure 5.22 – The top ten states by count
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.22 – 按计数排名前十的州
- en: 'And the last few rows are listed as follows:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 最后几行如下所示：
- en: '![Figure 5.23 – The last seven states by count'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.23 – 按计数排名最后七个州'
- en: '](img/Figure_5.23_B16721.jpg)'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.23 – 按计数排名最后七个州'
- en: Figure 5.23 – The last seven states by count
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.23 – 按计数排名最后七个州
- en: 'High-cardinality categorical variables such as `addr_state` are prime candidates
    for target encoding. The distribution of records is also highly skewed, with the
    top 4 levels accounting for, approximately, 40% of the data. Blending will be
    especially important because the raw counts for states in the tail are extremely
    small:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 高基数分类变量，如`addr_state`，是目标编码的理想候选者。记录的分布也非常倾斜，前四个层级大约占40%的数据。混合在这里特别重要，因为尾部州的原始计数非常小：
- en: 'Start by importing the target encoding estimator and specifying the columns
    to encode:'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先导入目标编码估计器并指定要编码的列：
- en: '[PRE111]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'The `k_fold` strategy requires a fold column, which is created as follows:'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`k_fold`策略需要一个折叠列，它如下创建：'
- en: '[PRE112]'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Train a target encoding model by setting the parameters:'
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过设置以下参数来训练目标编码模型：
- en: '[PRE113]'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Here is the training:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是训练过程：
- en: '[PRE114]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'Now, create a new target-encoded train and test set, explicitly setting the
    noise level on the test set to `0`:'
  id: totrans-459
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个新的目标编码训练集和测试集，明确地将测试集的噪声水平设置为`0`：
- en: '[PRE115]'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'Next, check the results of target encoding by looking at histograms of the
    target-encoded variables:'
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过查看目标编码变量的直方图来检查目标编码的结果：
- en: '[PRE116]'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'This yields the following plot:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下图表：
- en: '![Figure 5.24 – The target-encoded loan purpose variable'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.24 – 目标编码的贷款用途变量'
- en: '](img/Figure_5.24_B16721.jpg)'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.24_B16721.jpg)'
- en: Figure 5.24 – The target-encoded loan purpose variable
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.24 – 目标编码的贷款用途变量
- en: 'The following code produces a histogram for the `addr_state_te` variable:'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码为`addr_state_te`变量生成直方图：
- en: '[PRE117]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'The output is as follows:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.25 – The target-encoded address state variable'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.25 – 目标编码的地址状态变量'
- en: '](img/Figure_5.25_B16721.jpg)'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.25_B16721.jpg)'
- en: Figure 5.25 – The target-encoded address state variable
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.25 – 目标编码的地址状态变量
- en: 'Add the target-encoded variables to the predictor list:'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将目标编码变量添加到预测器列表中：
- en: '[PRE118]'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'Then, remove the source columns, using a list comprehension for efficiency:'
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用列表推导式以提高效率来删除源列：
- en: '[PRE119]'
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'As we create other features, our predictor list will change. In order to keep
    track of these steps, it is wise to update a copy of the `predictors` list rather
    than the original:'
  id: totrans-477
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建其他特征时，我们的预测器列表将发生变化。为了跟踪这些步骤，更新`predictors`列表的副本而不是原始列表是明智的：
- en: '[PRE120]'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'Additionally, we rename our datasets using the target-encoded values for convenience:'
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，为了方便，我们使用目标编码的值来重命名我们的数据集：
- en: '[PRE121]'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: How Much Should You Tune the Target Encoding Model?
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该调整目标编码模型多少？
- en: 'Note that we used the same target encoding parameters for transforming two
    different variables. So, why not encode variables individually with custom parameter
    settings for each? In our situation, we did not need to. The only parameter values
    to vary are those that determine the amount of blending: `inflection_point` and
    `smoothing`. For the `purpose` variable, blending is not really needed because
    sample sizes are large enough to yield accurate means. On the other hand, the
    `addr_state` variable would greatly benefit from blending. Therefore, we set the
    parameters to values that are reasonable for `addr_state`. These will, essentially,
    be ignored by `purpose`.'
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，我们使用了相同的目标编码参数来转换两个不同的变量。那么，为什么不为每个变量单独编码并使用自定义参数设置呢？在我们的情况下，我们并不需要这样做。唯一需要变化的参数值是那些确定混合量的值：`inflection_point`和`smoothing`。对于`purpose`变量，混合实际上并不需要，因为样本量足够大，可以产生准确的中值。另一方面，`addr_state`变量将极大地受益于混合。因此，我们将参数设置为对`addr_state`合理的值。这些值基本上会被`purpose`忽略。
- en: In situations where the outputs of one model are inputs for another, always
    bear in mind that what matters is the effect that varying parameter settings in
    the input model have on the final model's predictions.
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在一种模型输出是另一个模型输入的情况下，始终牢记，重要的是输入模型中参数设置变化对最终模型预测的影响。
- en: 'Let''s refit our model with these new features using AutoML and print the leaderboard:'
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用AutoML用这些新特征重新拟合我们的模型并打印排行榜：
- en: '[PRE122]'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'This results in the following output:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了以下输出：
- en: '![Figure 5.26 – The AutoML leaderboard after target encoding'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.26 – 目标编码后的AutoML排行榜'
- en: '](img/Figure_5.26_B16721.jpg)'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.26_B16721.jpg)'
- en: Figure 5.26 – The AutoML leaderboard after target encoding
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.26 – 目标编码后的AutoML排行榜
- en: The best individual (non-ensemble) model is a GBM, whose performance (**0.704491**)
    is only slightly better than the best GBM (**0.703838**) prior to target encoding.
    People often ask, is this tiny performance gain worth the effort of target encoding?
    That question misses the point entirely. Recall that H2O GBM naturally handles
    high-cardinality categorical variables well, so the fact that performance is equivalent
    should come as no surprise.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳个体（非集成）模型是GBM，其性能（**0.704491**）仅略优于目标编码前的最佳GBM（**0.703838**）。人们经常问，这个微小的性能提升是否值得目标编码的努力？这个问题完全忽略了重点。回想一下，H2O
    GBM自然能很好地处理高基数分类变量，所以性能相当的事实并不令人惊讶。
- en: 'What is the right question to ask? Let''s look at variable importance and compare
    the variables before and after target encoding:'
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应该问什么正确的问题？让我们看看变量重要性，并比较目标编码前后的变量：
- en: '[PRE123]'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: 'Before target encoding, the high-cardinality variables are among the most important:'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标编码之前，高基数变量是最重要的：
- en: '![Figure 5.27 – Variable importance for the H2O GBM model before target encoding'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.27 – 目标编码前的H2O GBM模型变量重要性'
- en: '](img/Figure_5.27_B16721.jpg)'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.27_B16721.jpg)'
- en: Figure 5.27 – Variable importance for the H2O GBM model before target encoding
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.27 – 目标编码前的H2O GBM模型变量重要性
- en: 'After target encoding, the importance of these categorical variables has changed:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标编码之后，这些分类变量的重要性发生了变化：
- en: '![Figure 5.28 – Variable importance for the H2O GBM model after target encoding'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.28 – 目标编码后的H2O GBM模型变量重要性'
- en: '](img/Figure_5.28_B16721.jpg)'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.28_B16721.jpg)'
- en: Figure 5.28 – Variable importance for the H2O GBM model after target encoding
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.28 – 目标编码后的H2O GBM模型变量重要性
- en: The effect of target encoding for the GBM model has less to do with overall
    model performance than with the impact and interpretation of those variables.
    Target encoding `purpose` has only slightly changed its importance, from *third*
    place to *fifth* place. Target encoding `addr_state` has decreased its impact
    substantially, from *first* place to *seventh* place. This impact difference also
    leads to an interpretability difference. The former model primarily splits on
    state, in essence implying a different loan default model per state (with implications
    that might have to be explained to a regulator). In the latter model, the effect
    of the state is adjusted in a very similar manner to random effects in a statistical
    model.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 目标编码对GBM模型的影响与整体模型性能的关系不大，而与这些变量的影响和解释有关。目标编码`purpose`的重要性略有变化，从第三位上升到第五位。目标编码`addr_state`的影响大幅下降，从第一位下降到第七位。这种影响差异也导致了可解释性的差异。前一个模型主要按州进行分割，本质上意味着每个州都有一个不同的贷款违约模型（可能需要向监管机构解释的后果）。在后一个模型中，州的影响以非常类似于统计模型中随机效应的方式进行调整。
- en: The data scientist has the option of choosing which scenario makes the most
    sense for their situation. An additional benefit of target encoding `addr_state`
    is the blending feature, which, in production, will generalize better for states
    with low counts.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家可以选择对他们情况最有意义的场景。目标编码`addr_state`的另一个好处是混合功能，在生产中，它将更好地泛化低计数州的变量。
- en: 'Select the best XGBoost target-encoded model from the leaderboard:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 从排行榜中选择最佳的XGBoost目标编码模型：
- en: '[PRE124]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-505
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: 'This yields the following plot:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下图表：
- en: '![Figure 5.29 – The XGBoost model variable importance plot after target encoding'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.29 – 目标编码后的XGBoost模型变量重要性图'
- en: '](img/Figure_5.29_B16721.jpg)'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.29_B16721.jpg)'
- en: Figure 5.29 – The XGBoost model variable importance plot after target encoding
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.29 – 目标编码后的XGBoost模型变量重要性图
- en: Both `purpose` and `address_state` have entered the top 10 in positions almost
    identical to the GBM model. Target encoding categorical variables is more important
    in XGBoost models than in GBM models. Other considerations being equal, some feature
    engineering steps may be influenced by the algorithm chosen.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '`purpose`和`address_state`几乎以与GBM模型相同的位置进入了前10名。在XGBoost模型中，对目标编码分类变量的重要性比在GBM模型中更重要。在其他条件相同的情况下，一些特征工程步骤可能会受到所选算法的影响。'
- en: Other feature engineering options
  id: totrans-511
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他特征工程选项
- en: 'There are multiple ways in which to categorize feature engineering options,
    and there are almost an infinite number of approaches you could take, depending
    on the problem. For some high-level categorizations, we can think of the following
    rough hierarchy:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程选项的分类方法有多种，根据问题的不同，你可以采取几乎无限的方法。对于一些高级分类，我们可以考虑以下大致层次结构：
- en: 'Algebraic transformers:'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代数转换器：
- en: Add, subtract, multiply, or divide numeric columns to create new interaction
    features.
  id: totrans-514
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过添加、减去、乘以或除以数值列来创建新的交互特征。
- en: Use simple mathematical functions such as log, exp, power, roots, and trigonometric
    functions
  id: totrans-515
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用简单的数学函数，如对数、指数、幂、根和三角函数
- en: 'Cluster-based transformers: Use k-means or other unsupervised algorithms to
    create clusters. Then, do the following:'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于聚类的转换器：使用k-means或其他无监督算法创建聚类。然后，执行以下操作：
- en: Measure the distance of a numeric observation to a specified cluster.
  id: totrans-517
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量数值观测值到指定聚类的距离。
- en: Consider each cluster as a level of a categorical variable and target encode
    to clusters.
  id: totrans-518
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个集群视为分类变量的一个级别，并对集群进行目标编码。
- en: 'Numeric to categorical transformations: Often, binning into deciles or using
    histograms and then taking the mean within each bin produces good predictive features.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值到分类变换：通常，将数据分箱到十分位或使用直方图，然后在每个箱内取平均值可以产生好的预测特征。
- en: 'Categorical to numeric transformations:'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类到数值变换：
- en: One-hot or indicator value encoding.
  id: totrans-521
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单热或指示值编码。
- en: Target encoding.
  id: totrans-522
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标编码。
- en: 'Numeric summary encoding: This is similar to target encoding except you are
    summarizing one of the numeric predictor columns rather than the target variable;
    for example, the mean temperature per state.'
  id: totrans-523
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数值摘要编码：这与目标编码类似，但你是在总结一个数值预测列而不是目标变量；例如，每个州的平均温度。
- en: '**Weight of evidence**: This is only used for binary classification problems.
    The weight of evidence is the natural log of the ratio of successes over failures
    (good over bad and ones over zeros):'
  id: totrans-524
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**证据权重**：这仅用于二元分类问题。证据权重是成功与失败（好与坏、一与零）比率的自然对数：'
- en: '![](img/B16721_05_001.jpg)'
  id: totrans-525
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16721_05_001.jpg)'
- en: 'Dimension reduction transformations: Truncated eigenvalue or singular value
    decomposition.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维度缩减变换：截断特征值或奇异值分解。
- en: As a data scientist, you can combine multiples of these components into a reasonable
    feature for a particular problem at hand. We will revisit some of these recipes
    in our complete analysis of the Lending Club data, which can be found in [*Chapter
    8*](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137), *Putting It All Together*.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，你可以将这些组件的多个组合用于特定问题的合理特征。我们将在对Lending Club数据的完整分析中重新审视一些这些配方，这些配方可以在[*第8章*](B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137)，“整合一切”中找到。
- en: Leveraging H2O Flow to enhance your IDE workflow
  id: totrans-528
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用H2O Flow增强你的IDE工作流程
- en: 'H2O Flow is a web-based UI available wherever an H2O cluster is running. Flow
    is interactive, allowing users to do everything including import data, build models,
    investigate models, and put models into production. While incredibly easy to use,
    our experience is that most data scientists (authors included) prefer coding in
    Python or R to menu-driven interactive interfaces. This section is written for
    those data scientists: why use Flow when I am a coder?'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: H2O Flow是一个基于Web的UI，在H2O集群运行的地方都可以使用。Flow是交互式的，允许用户执行所有操作，包括导入数据、构建模型、调查模型以及将模型投入生产。虽然使用起来非常简单，但我们的经验是，大多数数据科学家（包括作者）更喜欢使用Python或R进行编码，而不是菜单驱动的交互式界面。本节是为这些数据科学家编写的：为什么我作为程序员还要使用Flow？
- en: 'There are two main reasons:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个主要原因：
- en: '**Monitoring** the state of the H2O cluster and the jobs that are being run'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**H2O集群的状态和正在运行的作业'
- en: '**Interactive investigation** of the data, models, model diagnostics, and more
    where interactivity is an asset rather than an annoyance'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交互式调查**数据、模型、模型诊断等，其中交互性是资产而非烦恼。'
- en: Connecting to Flow
  id: totrans-533
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连接到Flow
- en: 'By default, Flow is started on port 54321 of the H2O server as the cluster
    is launched (this port is configurable at startup). Enter `Error! Hyperlink reference
    not valid.` into your browser to open Flow. The Flow UI is straightforward and
    self-explanatory, with helpful instructions and videos:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，当集群启动时，Flow在H2O服务器的54321端口启动（此端口在启动时可配置）。在浏览器中输入`Error! Hyperlink reference
    not valid.`以打开Flow。Flow UI简单直观，有有用的说明和视频：
- en: '![Figure 5.30 – The H2O Flow UI'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.30 – H2O Flow UI'
- en: '](img/Figure_5.30_B16721.jpg)'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.30_B16721.jpg)'
- en: Figure 5.30 – The H2O Flow UI
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.30 – H2O Flow UI
- en: First, let's consider Flow's monitoring capabilities.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们考虑Flow的监控能力。
- en: Monitoring with Flow
  id: totrans-539
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Flow进行监控
- en: Under the **Admin** menu in Flow, the top three options are **Jobs**, **Cluster
    Status**, and **Water Meter**. These are central to the monitoring capabilities
    of Flow, and we will review each of them individually.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 在Flow的**管理员**菜单下，前三项选项是**作业**、**集群状态**和**水表**。这些都是Flow监控能力的核心，我们将逐一回顾它们。
- en: 'The Flow **Admin** menu is shown here:'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示了Flow的**管理员**菜单：
- en: '![Figure 5.31 – The monitoring options using the Flow Admin menu'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.31 – 使用Flow管理员菜单进行监控选项'
- en: '](img/Figure_5.31_B16721.jpg)'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.31_B16721.jpg)'
- en: Figure 5.31 – The monitoring options using the Flow Admin menu
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.31 – 使用Flow管理员菜单进行监控选项
- en: We start by monitoring jobs.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从监控作业开始。
- en: Monitoring jobs
  id: totrans-546
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控作业
- en: 'The `getJobs` in the Flow command line:'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: Flow命令行中的`getJobs`：
- en: '![Figure 5.32 – Listing the job options using the Flow Admin menu'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.32 – 使用Flow管理员菜单列出作业选项'
- en: '](img/Figure_5.32_B16721.jpg)'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.32 – Listing the job options using the Flow Admin menu
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
- en: We continue by monitoring health.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring H2O cluster health
  id: totrans-552
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `getCloud` command. This monitors the health of the cluster and is one
    of the first places to check whether H2O does not appear to be working correctly:'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.33 – Monitoring the cluster status using the Flow Admin menu'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.33_B16721.jpg)'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.33 – Monitoring the cluster status using the Flow Admin menu
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will monitor CPU usage.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring CPU usage live
  id: totrans-558
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The **Water Meter** tool is a useful monitor of CPU usage. It shows a bar per
    CPU with colors corresponding to the activity status of each CPU. Rather than
    watching a black progress bar grow across the cell of a Jupyter notebook, the
    Water Meter is much more informative. Also, it illustrates, in real time, how
    well a particular computation is distributed among the available compute resources:'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.34 – The H2O Flow Water Meter'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.34_B16721.jpg)'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.34 – The H2O Flow Water Meter
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
- en: We can also monitor grid search.
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring grid search
  id: totrans-564
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: H2O Flow allows you to interactively monitor individual model builds, but it
    is especially useful when executing multiple jobs like a grid search or AutoML
    creates. These can be monitored live upon launch and reviewed during runtime and
    after completion.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step in our grid search strategy was to evaluate model depth. While
    the model is running, we can open Flow and list jobs. The job named `gbm_depth_grid`
    is running. Clicking on the name opens the running job, allowing us to view more
    details or cancel the job. These actions are not readily available from within
    Python:'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.35 – Grid search job monitoring within Flow'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.35_B16721.jpg)'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.35 – Grid search job monitoring within Flow
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
- en: 'Selecting the **View** button at any time opens the grid:'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.36 – Grid search results within Flow'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.36_B16721.jpg)'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.36 – Grid search results within Flow
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
- en: The subsequent selection of any of the individual grid models opens an interactive
    model view, which we will discuss in more detail in the next section and in [*Chapter
    7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127), *Understanding ML Models*.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring AutoML
  id: totrans-575
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Monitoring AutoML jobs is similar. First, search for the AutoML build job in
    the job listings and select the model''s name link:'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.37 – Selecting the AutoML build job'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.37_B16721.jpg)'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.37 – Selecting the AutoML build job
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the AutoML build is in process, you can monitor the progress live or click
    on **View** to watch the leaderboard as the models are built:'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.38 – Viewing the AutoML build job'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.38_B16721.jpg)'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.38 – Viewing the AutoML build job
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: Flow is Great for Monitoring Leaderboards'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: The interactive leaderboard is a great way to monitor AutoML jobs in real time.
    This is especially true for AutoML runs that are not constrained to finish quickly
    but plan to run for multiple hours as models are built. Again, all that is available
    in Python is a progress bar that can seem very slow if you cannot see the actual
    work on the server (Figure 5.39).
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 交互式排行榜是实时监控AutoML作业的好方法。这对于那些不急于完成但计划运行数小时以构建模型的AutoML运行尤其如此。再次强调，Python中可用的只是进度条，如果你看不到服务器上的实际工作，进度条可能会显得非常慢（图5.39）。
- en: '![Figure 5.39 – The AutoML leaderboard in Flow'
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.39 – 流中的AutoML排行榜'
- en: '](img/Figure_5.39_B16721.jpg)'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.39_B16721.jpg)'
- en: Figure 5.39 – The AutoML leaderboard in Flow
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.39 – 流中的AutoML排行榜
- en: The selection of any individual AutoML model opens an interactive model view.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 选择任何单个AutoML模型将打开一个交互式模型视图。
- en: Interactive investigations with Flow
  id: totrans-590
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流的交互式调查
- en: As we mentioned earlier, interactivity in Flow is quite useful for the live
    monitoring of running jobs. In addition, Flow makes exploring data before modeling
    and evaluating candidate models after model build more convenient than coding
    in Python. The only potential downside to menu-driven exploration is when reproducibility
    is at a premium and documentation of the whole modeling process is required. We
    will explore this topic in more detail when we discuss H2O AutoDoc capabilities
    in [*Chapter 7*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127), *Understanding
    ML Models*.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，流中的交互性对于实时监控运行中的作业非常有用。此外，流使得在建模之前探索数据和在模型构建后评估候选模型比在Python中编码更方便。唯一可能的缺点是在可重复性和整个建模过程的文档化非常重要时，通过菜单驱动的探索。我们将在讨论H2O
    AutoDoc功能时更详细地探讨这个话题，见[*第7章*](B16721_07_Final_SK_ePub.xhtml#_idTextAnchor127)，*理解机器学习模型*。
- en: Interactive data exploration in Flow
  id: totrans-592
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流中的交互式数据探索
- en: 'Perform the following steps:'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤：
- en: 'In the **Data** menu, select **List All Frames**:'
  id: totrans-594
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**数据**菜单中，选择**列出所有框架**：
- en: '![Figure 5.40 – Listing data frames in Flow'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.40 – 流中列出数据框'
- en: '](img/Figure_5.40_B16721.jpg)'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.40_B16721.jpg)'
- en: Figure 5.40 – Listing data frames in Flow
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.40 – 流中列出数据框
- en: 'Click on the **LendingClubClean.hex** link to pull up the data summary:'
  id: totrans-598
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**LendingClubClean.hex**链接以拉起数据摘要：
- en: '![Figure 5.41 – The Lending Club data in Flow'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.41 – 流中的Lending Club数据'
- en: '](img/Figure_5.41_B16721.jpg)'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.41_B16721.jpg)'
- en: Figure 5.41 – The Lending Club data in Flow
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.41 – 流中的Lending Club数据
- en: 'Clicking on the `purpose` column link produces a summary plot:'
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 点击`目的`列的链接会生成一个摘要图：
- en: '![Figure 5.42 – The loan purpose data column in Flow'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.42 – 流中贷款目的数据列'
- en: '](img/Figure_5.42_B16721.jpg)'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.42_B16721.jpg)'
- en: Figure 5.42 – The loan purpose data column in Flow
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.42 – 流中贷款目的数据列
- en: 'Next, clicking on `Inspect` and then `domain` will yield a summary table similar
    to the one that we created in Python:'
  id: totrans-606
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，点击`检查`然后`域`将生成一个类似于我们在Python中创建的摘要表：
- en: '![Figure 5.43 – A table of the loan purpose data in Flow'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.43 – 流中贷款目的数据表'
- en: '](img/Figure_5.43_B16721.jpg)'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.43_B16721.jpg)'
- en: Figure 5.43 – A table of the loan purpose data in Flow
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.43 – 流中贷款目的数据表
- en: Model exploration in Flow
  id: totrans-610
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流中的模型探索
- en: 'Selecting any model in Flow, whether through the **List All Models** option
    in the **Model** menu item, from a grid search, or the AutoML leaderboard, yields
    a model summary:'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 在流中选择任何模型，无论是通过**模型**菜单项中的**列出所有模型**选项，还是从网格搜索或AutoML排行榜，都会得到一个模型摘要：
- en: '![Figure 5.44 – A GBM model summary from AutoML in Flow'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.44 – 流中AutoML的GBM模型摘要'
- en: '](img/Figure_5.44_B16721.jpg)'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.44_B16721.jpg)'
- en: Figure 5.44 – A GBM model summary from AutoML in Flow
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.44 – 流中AutoML的GBM模型摘要
- en: 'The layout of the model summary makes it very easy to explore. ROC curves and
    AUC values for training and validation sets are displayed by default. Variable
    importance plots are also readily available:'
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 模型摘要的布局使其非常容易探索。默认情况下显示训练集和验证集的ROC曲线和AUC值。变量重要性图也易于获取：
- en: '![Figure 5.45 – GBM variable importance in Flow'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.45 – 流中的GBM变量重要性'
- en: '](img/Figure_5.45_B16721.jpg)'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_5.45_B16721.jpg)'
- en: Figure 5.45 – GBM variable importance in Flow
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.45 – 流中的GBM变量重要性
- en: Generally, getting results immediately through the model summary is more convenient
    than doing the equivalent from the Python client.
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，通过模型摘要立即获取结果比从Python客户端执行等效操作更方便。
- en: Best Practices in Flow
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 流的最佳实践
- en: If you are coding in Python, we strongly suggest using Flow solely as a monitoring
    platform and read-only tool. That is the approach we use in our own work. Code
    should contain all the steps that import data, create features, fit models, deploy
    models, and more. This allows you to repeat any analysis and is a prerequisite
    for reproducibility. Code is often less convenient for investigative and interactive
    steps. Reserve those for Flow.
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用Python进行编码，我们强烈建议仅将Flow用作监控平台和只读工具。这是我们自己的工作所采用的方法。代码应包含所有导入数据、创建特征、拟合模型、部署模型等步骤。这允许你重复任何分析，并且是可重复性的先决条件。代码在调查和交互式步骤中通常不太方便。将这些步骤留给Flow。
- en: Putting it all together – algorithms, feature engineering, grid search, and
    AutoML
  id: totrans-622
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将所有这些放在一起——算法、特征工程、网格搜索和AutoML
- en: The H2O AutoML implementation is simple yet powerful, so why would we ever need
    grid search? In fact, for a lot of real-world enterprise use cases, any of the
    top candidates in an AutoML leaderboard would be great models to put into production.
    This is especially true of the stacked ensemble models produced by AutoML.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: H2O AutoML实现简单而强大，那么我们为什么还需要网格搜索呢？实际上，对于许多现实世界的企业用例，AutoML排行榜上的任何顶级候选模型都可以是投入生产的优秀模型。这尤其适用于AutoML产生的堆叠集成模型。
- en: However, our coverage of grid search was not just to satisfy intellectual curiosity.
    A more involved process, which we will outline next, uses AutoML followed by a
    customized grid search to discover and fine-tune model performance.
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们对网格搜索的覆盖并不仅仅是为了满足知识上的好奇心。接下来我们将概述的一个更复杂的过程，它使用AutoML，然后是定制的网格搜索来发现和微调模型性能。
- en: An enhanced AutoML procedure
  id: totrans-625
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强的AutoML程序
- en: 'Here are the steps:'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是步骤：
- en: Start by running AutoML on your data to create a baseline leaderboard. You can
    investigate leading models, gain an understanding of the runtimes required to
    fit algorithms to your data, and more, which may inform future AutoML parameter
    choices and expectations.
  id: totrans-627
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，在你的数据上运行AutoML以创建一个基准排行榜。你可以调查领先模型，了解拟合算法到你的数据所需的运行时间，等等，这些都可能为未来的AutoML参数选择和预期提供信息。
- en: The second stage is feature engineering. While developing new features, repeat
    AutoML runs as desired to check the impact of engineering and see what other insights
    might be gained from diagnostics.
  id: totrans-628
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二阶段是特征工程。在开发新特征的同时，根据需要重复AutoML运行，以检查工程的影响，并查看从诊断中可能获得的其他见解。
- en: After completion of the feature engineering stage, use AutoML to create a final
    leaderboard.
  id: totrans-629
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在完成特征工程阶段后，使用AutoML创建一个最终的排行榜。
- en: Choose a model from the leaderboard as a candidate for production. If you select
    an ensemble model, you are done. There is very little you can do to improve upon
    the performance of a stacked ensemble.
  id: totrans-630
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从排行榜中选择一个模型作为生产候选。如果你选择了一个集成模型，那么你就完成了。对于堆叠集成模型的表现，你几乎没有什么可以改进的。
- en: If you choose an individual model, say a GBM or DRF, use the parameters of that
    model as a guide for further grid searching, employing the general strategy outlined
    in this chapter. It is possible to further fine-tune a candidate model using additional
    grid search.
  id: totrans-631
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你选择一个单独的模型，比如GBM或DRF，那么使用该模型的参数作为进一步网格搜索的指南，采用本章概述的一般策略。使用额外的网格搜索进一步微调候选模型是可能的。
- en: This enhanced AutoML procedure might be overkill for a lot of problems. If you
    are in a business that has a practice of quickly building and deploying models,
    especially one that updates or replaces models frequently, then this approach
    might literally be more effort than it is worth. The advantages of a model built
    on recent data often outweigh the gains made by using these extra modeling steps.
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 这种增强的AutoML程序对于许多问题来说可能过于复杂。如果你所在的企业有快速构建和部署模型的实践，尤其是经常更新或替换模型的，那么这种方法可能实际上付出的努力超过了它的价值。基于最近数据的模型构建的优势往往超过了使用这些额外建模步骤所获得的收益。
- en: However, if you are in an industry where the model review and due diligence
    process is long and involved, where the models that are put into production tend
    to stay in production for a long time, or you are working on a model that is high
    risk in any way (for example, one that directly impacts peoples' lives rather
    than just what ad they will see on a website), then this more involved procedure
    might well be worth the extra effort. We have used it successfully in multiple
    real-world use cases.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你所在的行业模型审查和尽职调查过程漫长且复杂，或者投入生产的模型往往长时间留在生产中，或者你正在处理一个风险很高的模型（例如，直接影响人们生活的模型，而不仅仅是网站上他们会看到的广告），那么这个更复杂的程序可能确实值得额外的努力。我们已经在多个实际案例中成功使用了它。
- en: Summary
  id: totrans-634
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have considered different options for splitting data, explored,
    in some depth, powerful and popular algorithms such as gradient boosting and random
    forest, learned how to optimize model hyperparameters using a two-stage grid search
    strategy, utilized AutoML to efficiently fit multiple models, and further investigated
    options for feature engineering, including a deep dive into target encoding. Additionally,
    we saw how Flow can be used to monitor the H2O system and investigate data and
    models interactively. You now have most of the tools required to build effective
    enterprise-scale predictive models using the H2O platform.
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们考虑了不同的数据拆分选项，深入探讨了梯度提升和随机森林等强大且流行的算法，学习了如何使用两阶段网格搜索策略优化模型超参数，利用AutoML高效地拟合多个模型，并进一步研究了特征工程选项，包括对目标编码的深入研究。此外，我们还看到了如何使用Flow来监控H2O系统并交互式地调查数据和模型。你现在拥有了使用H2O平台构建有效企业级预测模型所需的大部分工具。
- en: 'However, we are not finished with our advanced modeling topics. In [*Chapter
    6*](B16721_06_Final_SK_ePub.xhtml#_idTextAnchor106), *Advanced Model Building
    – Part II*, we will discuss best practices for data acquisition, look in more
    depth at checkpointing and refitting models, and show you how to ensure reproducibility.
    Additionally, we will thoroughly consider two more hands-on examples: the first
    demonstrating Sparkling Water pipelines for efficiently integrating Spark capabilities
    with H2O modeling, and the second introducing isolation forests, an unsupervised
    learning algorithm for anomaly detection in H2O.'
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们还没有结束对高级建模主题的探讨。在[*第6章*](B16721_06_Final_SK_ePub.xhtml#_idTextAnchor106)，“高级模型构建
    – 第二部分”，我们将讨论数据获取的最佳实践，更深入地探讨模型检查点和重新拟合，并展示如何确保可重复性。此外，我们还将详细考虑两个更实用的示例：第一个展示了Sparkling
    Water管道如何高效地将Spark功能与H2O建模集成，第二个介绍了隔离森林，这是一种用于H2O中异常检测的无监督学习算法。
