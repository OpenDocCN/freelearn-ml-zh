["```py\nimport numpy as np\ndistribution = list(range(1,4))\nminus_distribution = [-x for x in distribution]\nlog_distribution = [x for x in map(np.log2,distribution)]\nentropy_value = np.dot(minus_distribution, log_distribution)\n```", "```py\ndef entropy(distribution):\n    minus_distribution = [-x for x in distribution]\n    log_distribution = [x for x in map(np.log2, distribution)]\n    return np.dot(minus_distribution, log_distribution)\n```", "```py\n    H_employed = entropy([4/7, 3/7])\n    ```", "```py\n    H_income = entropy([1/7, 2/7, 1/7, 2/7, 1/7])\n    ```", "```py\n    H_loanType = entropy([3/7, 2/7, 2/7])\n    ```", "```py\n    H_LoanAmount = entropy([1/7, 1/7, 3/7, 1/7, 1/7])\n    ```", "```py\n    H_incomeMoreThan75K = entropy([4/7, 3/7])\n    ```", "```py\n    H_loanMoreThan15K = entropy([6/7, 1/7])\n    ```", "```py\nH_label = entropy([5/7, 2/7])\n0.863120568566631\n```", "```py\nH_group1 = entropy([1]) #0\nH_group2 = entropy([5/6, 1/6]) #0.65\n```", "```py\nH_group1 * 1/7 + H_group2 * 6/7 #0.55\nInformation_gain = 0.8631 â€“ 0.5572 #0.30\n```", "```py\nfeatures_train, features_test, label_train, label_test =\n    model_selection.train_test_split(\n        features,\n        label,\n        test_size=0.1\n    )\n```", "```py\nfrom sklearn.tree import DecisionTreeClassifier\ndecision_tree = DecisionTreeClassifier(max_depth=6)\ndecision_tree.fit( features_train, label_train )\n```", "```py\ndecision_tree.predict(features_test)\n```", "```py\ndecision_tree.score(features_test, label_test)\n```", "```py\n# testLabel denotes the test label\npredicted_label = decision_tree.predict(testFeature)\n```", "```py\n# Classifier 1\nTestLabels1 = [True, True, False, True, True]\nPredictedLabels1 = [True, False, False, False, False]\n# Classifier 2\nTestLabels2 = [True, True, False, True, True]\nPredictedLabels = [True, True, True, True, True]\n```", "```py\n    TruePositives1 = 1 # both the predicted and test labels are true\n    FalsePositives1 = 0 # predicted label is true, test label is false\n    FalseNegatives1 = 3 # predicted label is false, test label is true\n    Precision1 = TruePositives1 / (TruePositives1 + FalsePositives1)\n    Precision1 # 1/1 = 1\n    Recall1 = TruePositives1 / (TruePositives1 + FalseNegatives1)\n    Recall1 #1/4 = 0.25\n    ```", "```py\n    TruePositives2 = 4\n    FalsePositives2 = 1\n    FalseNegatives2 = 0\n    Precision2 = TruePositives2 / (TruePositives2 + FalsePositives2) Precision2 #4/5 = 0.8\n    Recall2 = TruePositives2 / (TruePositives2 + FalseNegatives2)\n    Recall2 # 4/4 = 1\n    ```", "```py\n    2*Precision*Recall / (Precision + Recall)\n    ```", "```py\n    2 * 1 * 0.25 / (1 + 0.25) # 0.4\n    ```", "```py\n    2 * 0.8 * 1 / (0.8 + 1) # 0.888888888888889\n    ```", "```py\nfrom sklearn.metrics import classification_report\nprint(\n    classification_report(\n        label_test,\n        decision_tree.predict(features_test)\n    )\n)\n```", "```py\n             precision    recall f1-score support\n          0     0.97     0.97     0.97        36\n          1     1.00     1.00     1.00         5\n          2     1.00     0.99     1.00     127\n          3     0.83     1.00     0.91         5\navg / total     0.99     0.99     0.99     173\n```", "```py\nlabelEncoders['Class'].inverse_transform([0, 1, 2, 3])\narray(['acc', 'good', 'unacc', 'vgood'])\n```", "```py\nfrom sklearn.metrics import recall_score, precision_score, f1_score\nlabel_predicted = decision_tree.predict(features_test)\n```", "```py\nprecision_score(label_test, label_predicted, average=None)\n```", "```py\n array([0.97222222, 1\\.        , 1\\.        , 0.83333333])\n```", "```py\nprecision_score(label_test, label_predicted, average='weighted')\n```", "```py\nrecall_score(label_test, label_predicted, average=None)\n```", "```py\n array([0.97222222, 1\\.        , 0.99212598, 1\\.        ])\n```", "```py\nrecall_score(label_test, label_predicted, average='weighted')\n```", "```py\nf1_score(label_test, label_predicted, average=None)\n```", "```py\n array([0.97222222, 1\\.        , 0.99604743, 0.90909091])\n```", "```py\nf1_score(label_test, label_predicted, average='weighted')\n```", "```py\nfrom sklearn.metrics import accuracy_score\naccuracy_score(label_test, label_predicted )\n```", "```py\ndecisionTree.score(features_test, label_test)\n```", "```py\n# Classifier 1\nTestLabels1 = [True, True, False, True, True]\nPredictedLabels1 = [True, False, False, False, False]\n# Classifier 2\nTestLabels2 = [True, True, False, True, True]\nPredictedLabels = [True, True, True, True, True]\n```", "```py\n           True False\n    True     1     0\n    False     3     1\n    ```", "```py\n           True False\n    True     4     1\n    False     0     0\n    ```", "```py\n                    True            False\n    True    TruePositives FalsePositives\n    False FalseNegatives TrueNegatives    \n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    confusion_matrix(label_test, label_predicted)\n    array([[ 25, 0, 11, 0],\n         [ 5, 0, 0, 0],\n         [ 0, 0, 127, 0],\n           [ 5, 0, 0, 0]])\n    ```", "```py\n    import pandas\n    pandas.crosstab(label_test, label_predicted)\n    col_0 0    2\n    row_0        \n    0     25 11\n    1     5    0\n    2     0 127\n    3     5    0\n    ```", "```py\nfrom sklearn.metrics import accuracy_score\naccuracy_score(label_test, label_predicted)\n```", "```py\n0.8786127167630058\n```", "```py\nfrom sklearn import model_selection\nfeatures_train, features_test, label_train, label_test =\n    model_selection.train_test_split(\n        features,\n        label,\n        test_size=0.1\n    )\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest_classifier = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=6\n)\nrandomForestClassifier.fit(features_train, label_train)\nlabels_predicted = random_forest_classifier.predict(features_test)\n```", "```py\nrandom_forest_classifier.feature_importances_\n```", "```py\narray([0.12794765, 0.1022992 , 0.02165415, 0.35186759, 0.05486389,\n       0.34136752])\n```", "```py\nfrom sklearn.ensemble import ExtraTreesClassifier\nextra_trees_classifier = ExtraTreesClassifier(\n    n_estimators=100,\n    max_depth=6\n)\nextra_trees_classifier.fit(features_train, label_train)\nlabels_predicted = extra_trees_classifier.predict(features_test)&#9;\n```"]