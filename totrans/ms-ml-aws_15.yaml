- en: Using AWS Rekognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have studied deep learning algorithms and how to implement them using SageMaker
    in [Chapter 7](c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml), *Implementing Deep
    Learning Algorithms*, and [Chapter 9](37b99b21-96c2-4857-b8e0-686179d109cf.xhtml), *Image
    Classification and Detection with SageMaker*. You must have realized that training
    a good **Convolutional Neural Network** (**CNN**) takes a lot of expertise and
    resources. Moreover, it also requires a large number of labeled images with objects.
    Amazon has an out-of-box solution for image recognition, called **Amazon Rekognition**,
    that offers various tools for image recognition using pretrained image recognition
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Amazon Rekognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing object and scene detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing facial analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing Amazon Rekognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building image recognition models using deep learning is very challenging. Firstly,
    you need a large, labeled dataset in order to train the deep learning model to
    perform specific tasks. Secondly, you need knowledge of how to design a network
    and tune the parameters to get the best accuracy. Finally, training such deep
    learning models at scale requires expensive GPU-based clusters to train these
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Rekognition ([https://aws.amazon.com/rekognition/](https://aws.amazon.com/rekognition/))
    is a tool offered by AWS featuring image recognition models that are already pretrained
    for use in your applications. Amazon Rekognition models are based on an analysis
    of billions of videos and images. Similar to how **Amazon Comprehend** offers
    NLP models as a service, Rekognition offers various image recognition models that
    can perform specific tasks. The advantage of using Amazon Rekognition is that
    you can simply use dashboards and APIs to perform image recognition tasks at high
    accuracy, without the high-level expertise required to train such machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Rekognition only offers a limited number of models that perform specific
    tasks. In this section, we'll look at the various tools available in the Amazon
    Rekognition dashboard. We'll also look at how we can access these features using
    AWS APIs in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing object and scene detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Object and scene detection algorithms can recognize various objects in the image
    and assign confidence to each prediction. This algorithm uses a hierarchy of labels
    to label objects and returns all the nodes of the leaf when it detects an object.
    Object detection is a classic application of image recognition. It allows us to
    identify what is inside an image and label it. For example, consider a newsroom
    where photographers are submitting hundreds of images and videos every day. You
    need people to label such images so that if you wish to access an image of a celebrity
    who was pictured during a car crash, these image libraries can be searchable.
  prefs: []
  type: TYPE_NORMAL
- en: Object detection allows you to automatically label these images so that they
    can be stored, organized, and retrieved efficiently. One of the key features of
    an object detection algorithm is that they have to be comprehensive and should
    be able to detect a large array of objects. Moreover, such algorithms also detect
    the edges of the object and should be able to return the bounding box for an object.
    Amazon Rekognition performs both these tasks effectively.
  prefs: []
  type: TYPE_NORMAL
- en: You can access the Amazon Rekognition dashboard using the AWS Console. Just
    search for Rekognition in the search bar and you will be able to access the demo
    for Amazon Rekognition. The demo shows you how the tools work, but you would need
    to use the API if you want to analyze multiple images.
  prefs: []
  type: TYPE_NORMAL
- en: Once, you are on the demo screen, select Object and Scene detection to access
    a demo where you can select a single image and detect the images in the object.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the purpose of this demo, I have used a screenshot of the Chicago river
    with ferry boats on the river:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d75ffa44-7ade-4576-85d5-e96b4420801a.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see from the preceding screenshot, the object detection tool returns
    a ranked list of objects in the image along with the confidence of detection.
    As we mentioned previously, since the tool uses a hierarchy of categories, it
    may detect similar categories at the top. For example, it was able to detect the
    boat in the image. However, it also returned Vehicle and Transportation categories
    with the same confidence score. We can also see that the demo shows bounding boxes
    for each of the objects that it detected in the image.
  prefs: []
  type: TYPE_NORMAL
- en: However, using this tool to perform object detection may be tedious as it only
    handles one image at a time. So, we can also use an API to access the Amazon Rekognition
    tool. You need to upload your images to a folder in S3 bucket in order to use
    object detection on them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Python code can be used to perform the same operation on the
    image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The image has to be in the S3 bucket and you have to specify the bucket name
    and image name as a parameter of the request function. The response is long, so
    we only show the format of the first prediction in the response JSON:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can observe from the response, we found three instances of the **`Boat` **object
    in the image. The response provides the bounding box for each of the objects found
    in the image. Moreover, you can observe that the boat in the far right is small,
    so the confidence in detecting it is much lower than the other two boats in the
    image. The response also returned the parents of the object in the hierarchy.
    So, if you have hundreds of images to categorize, you can add them all to an S3
    bucket and use this code to iterate through them and detect labels for those objects.
    Because of tools such as Amazon Rekognition, data scientists now have access to
    world-class deep learning models that they can apply in the tools that they are
    building. However, such an object detection algorithm only works for a limited
    number of objects. For example, we tried the algorithm on x-ray images of cancer
    in this tool and it was not able to return any results. If you are working on
    a very specialized product where you are trying to detect medical images of tumors
    or images from a space telescope, you would need to train your own models based
    on a large number of labeled images.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing facial analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon Rekognition also offers a powerful tool for performing facial analysis
    on images. It can predict interesting attributes such as age and gender based
    on looking at the image. It can also detect features such as a smile or whether
    the person is wearing glasses from this model. Such models would be trained by
    analyzing a lot of labeled facial images and training an image recognition model
    to recognize these features. The CNN models that we studied in [Chapter 7](c832a5c1-d877-4c90-bfb5-e3a0fe99d19a.xhtml),
    *Implementing Deep Learning Algorithms*, would be a good fit for such applications
    as it can automatically generate feature maps using local receptive fields methodology
    from the image and detect boxes that would contain evidence of these facial features.
  prefs: []
  type: TYPE_NORMAL
- en: The facial analysis demo can be accessed in the same way as the object detection
    demo. In order to test the model, we picked the picture of Mona Lisa by Leonardo
    Da Vinci. One of the long-standing mysteries about the image is whether the lady
    in the image is smiling or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see how the facial analysis demo provides
    features of the face from the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/23e3776b-36a6-499c-98fa-e0f75919e4ae.png)'
  prefs: []
  type: TYPE_IMG
- en: The facial analysis model does predict that there is a face in the image and
    creates a correct box around it. It correctly predicted that the image is female
    and predicts an age range for that person. It predicted that the person in the
    image is not smiling. It also correctly predicted that the person is not wearing
    any glasses.
  prefs: []
  type: TYPE_NORMAL
- en: You can also access this same information using an API call.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the following Python code, you can perform the same task of facial analysis
    as in the preceding demo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You have to store your image on an S3 bucket and provide the bucket and image
    name to the API call. You can also specify what attributes you need to be returned,
    or specify `All` in case you need all the attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The response of this call is in JSON format and looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We have edited this response to maintain brevity. However, you can observe that
    you can see information about `Age`, `Gender`, and `Smile` as we saw in the demo.
    However, it also identifies emotions on the face such as sadness and calm. It
    also locates landmarks on the face such as the eyes, nose, and lips.
  prefs: []
  type: TYPE_NORMAL
- en: Such tools are used in current smartphones where a smile can trigger a photo.
    It is used in consumer surveys in restaurants to gauge the demographics of people
    in the restaurant and whether they are happy with the service.
  prefs: []
  type: TYPE_NORMAL
- en: Other Rekognition services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon Rekognition also offers other image recognition services. You can use
    the API as in the examples in this chapter to access these services. We will list
    some of the services and their applications here.
  prefs: []
  type: TYPE_NORMAL
- en: Image moderation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use Rekognition to monitor images and check whether the content is suggestive
    or unsafe. Such techniques are used to moderate live video services, such as Twitch
    or Facebook Live, where **Artificial Intelligence** (**AI**) can automatically
    detect unsafe content. As services such as YouTube or Instagram see an unimaginable
    amount of data being uploaded on them every day, using such AI techniques can
    help to lower the cost of moderating the platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows how the image moderation tool can detect suggestive
    themes in the image and automatically label them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4cb081b8-a312-4e7a-90d7-dc6cfcdbb7b5.png)'
  prefs: []
  type: TYPE_IMG
- en: Celebrity recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recognition can also be used to detect celebrities in pictures or videos automatically.
    This can be done by an image recognition model learning from labeled images and
    videos. Deep learning algorithms can automatically extract facial features and
    then compare them to predict who the celebrity may be. For example, many of the
    movies and TV shows on services such as Amazon Prime can show the names of actors
    on the screen using this technique. Manually labeling these scenes with the names
    of actors may be a very tedious task; however, deep learning algorithms can do
    this automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, Amazon Rekognition detects an image of Jeff Bezos
    and labels it correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b99b830-cdb2-410e-8cf0-9f009f3c3536.png)'
  prefs: []
  type: TYPE_IMG
- en: Face comparison
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Celebrity recognition technology can be further extended to do facial comparisons
    and detect faces that are similar. For example, your Facebook account automatically
    matches the faces in an image you upload with your friends and tags the images
    automatically. They use such image recognition algorithms to train models for
    each face and run those models on your uploaded images to detect whether your
    friends are in that picture. Amazon Rekognition also offers a feature called **face
    comparison** that compares faces between two images and detects whether the same
    people appear in both pictures.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can observe that the face comparison algorithm
    can automatically match the faces in two images and detect which faces are similar
    to each other:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c306bb9d-5e78-4949-8151-8dcbe8e1c4f4.png)'
  prefs: []
  type: TYPE_IMG
- en: Amazon Rekognition also offers another tool that can detect text in a picture.
    This model is similar to what we built in [Chapter 8](a05fc52e-bb4c-4200-b0c5-154dccaad739.xhtml), *Implementing
    Deep Learning with TensorFlow on AWS*, where our model was able to detect numbers.
    This tool is also very useful for reading text in the real world. Applications
    such as Google Translate can analyze camera images and can translate them to your
    native language. Self-driving cars can also use this technology to read road signs
    and react accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows how Amazon Rekognition can detect text inside
    an image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1002b21c-e520-47b4-b1ea-677ecda4dcd4.png)'
  prefs: []
  type: TYPE_IMG
- en: Recognition does not do an accurate job with this image, but is able to box
    and recreate the text in this image.
  prefs: []
  type: TYPE_NORMAL
- en: We have not given code examples for these services in this section. The API
    calls are similar to what we discussed in the first two tools presented in this
    section. We encourage you to try the API calls for these services and test how
    they work.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon Rekognition allows data scientists to access high-quality image recognition
    algorithms using API calls. One of the biggest obstacles in using deep learning
    is generating large datasets and running expensive GPU-based clusters to train
    the models. AWS Rekognition makes it easier for users to access these features
    without the prerequisite expertise required to train such models. The application
    developers can concentrate on building functionality without having to spend a
    lot of time on deep learning tasks. In this chapter, we studied various tools
    that are available in Amazon Rekognition and also learned how to make API calls
    and read the response JSON. Moreover, we also studied various applications where
    these tools can be useful.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will demonstrate how you can build automated chat bots
    using a service called Amazon Lex.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Create an app using Python where you can pass a photo of a group and detect
    what the mood of the room was at that time. Provide details on what your code
    detected based on the facial analysis tools and how you summarized the results
    to find the mood in the photo.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a tool that would recognize the actors in a movie clip. Provide the time
    at which the actors appeared on the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
