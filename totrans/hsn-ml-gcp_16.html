<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Generative Neural Networks</h1>
                </header>
            
            <article>
                
<p class="mce-root"><span>In recent times, neural networks have been used as generative models: algorithms able to replicate the distribution of data in input to then be able to generate new values starting from that distribution. Usually, an image dataset is analyzed, and we try to learn the distribution associated with the pixels of the images to produce shapes</span> <span>similar </span><span>to the original ones. Much work is ongoing to get neural networks to create novels, articles, art, and music.</span><br/></p>
<p><strong>Artificial intelligence</strong> (<strong>AI</strong>) researchers are interested in generative models because they represent a springboard towards the construction of AI systems able to use raw data from the world and automatically extract knowledge. These models seem to be a way to train computers to understand the concepts without the need for researchers to teach such concepts a priori. It would be a big step forward compared to current systems, which are only able to learn from training data accurately labeled by competent human beings.</p>
<p>In this chapter, we will touch one of the most exciting research avenues on generating models with neural networks. First, we will get an introduction to unsupervised learning algorithms; then an <span>overview of </span>generative models will be proposed. We will also discover the most common generative models and show how to implement a few examples. Finally, we will introduce the reader to the Nsynth dataset and the Google Magenta project.</p>
<p>The topics covered are:</p>
<ul>
<li>Unsupervised learning</li>
<li>Generative model introduction</li>
<li>Restricted Boltzmann machine</li>
<li>Deep Boltzmann machines</li>
<li>Autoencoder</li>
<li>Variational autoencoder</li>
<li>Generative adversarial network</li>
<li>Adversarial autoencoder</li>
</ul>
<p>At the end of the chapter, the reader will learn how to extract the content generated within the neural net with different types of content.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unsupervised learning</h1>
                </header>
            
            <article>
                
<p>Unsupervised learning is a machine learning technique that, starting from a series of inputs (system experience), is able to reclassify and organize on the basis of common characteristics to try to make predictions on subsequent inputs. Unlike supervised learning, only unlabeled examples are provided to the learner during the learning process, as the classes are not known a priori but must be learned automatically.</p>
<p>The following diagram shows three groups labeled from raw data:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/cd2095b9-045f-48fc-86e2-e6df1f973034.png" style=""/></div>
<div>
<p>From this diagram, it is possible to notice that the system has identified three groups on the basis of a similarity, which in this case is due to proximity. In general, unsupervised learning tries to identify the internal structure of data to reproduce it.</p>
<p>Typical examples of these algorithms are search engines. These programs, given one or more keywords, are able to create a list of links that lead to pages that the search algorithm considers relevant to the research carried out. The validity of these algorithms depends on the usefulness of the information that they can extract from the database.</p>
<p>Unsupervised learning techniques work by comparing data and looking for similarities or differences. As is known, machine learning algorithms try to imitate the functioning of an animal's nervous system. For this purpose, we can hypothesize that neural processes are guided by mechanisms that optimize the unknown objective they pursue. Each process evolves from an initial situation associated with a stimulus to a terminal in which there is an answer, which is the result of the process itself. It is intuitive that, in this evolution, there is a transfer of information. In fact, the stimulus provides the information necessary to obtain the desired response. Therefore, it is important that this information is transmitted as faithfully as possible until the process is completed. A reasonable criterion for interpreting the processes that take place in the nervous system is, therefore, to consider them as transfers of information with maximum preservation of the same.</p>
<p>Unsupervised learning algorithms are based on these concepts. It is a question of using learning theory techniques to measure the loss of information that has occurred in the transfer. The process under consideration is considered as the transmission of a signal through a noisy channel, using well-known techniques developed in the field of communications. It is possible, however, to follow a different approach based on a geometric representation of the process. In fact, both the stimulus and the response are characterized by an appropriate number of components, which in a space correspond to a point. Thus, the process can be interpreted as a geometric transformation of the input space to the output space. The exit space has a smaller size than the input space, as the stimulus contains the information necessary to activate many simultaneous processes. Compared to only one, it is redundant. This means that there is always a redundancy reduction operation in the transformation under consideration.</p>
<p>In the entry and exit space, typical regions are formed, with which <span>the information</span><span> is associated. The natural mechanism that controls the transfer of information must therefore identify, <span>in some way, </span>these important regions for the process under consideration, and make sure that they correspond in the transformation. Thus, a data grouping operation is present in the process in question; this operation can be identified with the acquisition of experience. The two previous operations of grouping and reduction of redundancy are typical of optimal signal processing, and there is biological evidence of their existence in the functioning of the nervous system. It is interesting to note that these two operations are automatically achieved in the case of non-supervised learning based on experimental principles, such as competitive learning.</span></p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generative models</h1>
                </header>
            
            <article>
                
<p>A generative model aims to generate all the values of a phenomenon, both those that can be observed (input) and those that can be calculated from the ones observed (target). We try to understand how such a model can succeed in this goal by proposing a first distinction between generative and discriminative models.</p>
<p>Often, in machine learning, we need to predict the value of a target vector <em>y</em> given the value of an input <em>x</em> vector. From a probabilistic perspective, the goal is to find the conditional probability distribution <em>p(y|x)</em>.</p>
<div class="packt_tip">
<p>The conditional probability of an event <em>y</em> with respect to an event <em>x</em> is the probability that <em>y</em> occurs, knowing that <em>x</em> is verified. This probability, indicated by <em>p(y|x)</em>, expresses a correction of expectations for <em>y</em>, dictated by the observation of <em>x</em>.</p>
</div>
<p>The most common approach to this problem is to represent the conditional distribution using a parametric model, and then determine the parameters using a training set consisting of pairs (<em>xn</em>, <em>yn</em>) that contain both the values ​​of the input variables and the relative vectors of corresponding outputs. The resulting conditional distribution can be used to make predictions of the target (<em>y</em>) for new input values ​​(<em>x</em>). This is known as a <strong>discriminatory approach</strong>, since the conditional distribution discriminates directly between the different values ​​of <em>y</em>.</p>
<p>As an alternative to this approach, we can look for the joint probability distribution <em>p(x∩ y)</em>, and then use this joint distribution to evaluate the conditional probability <em>p(y | x)</em> in order to make predictions of <em>y</em> for new values ​​of <em>x</em>. This is known as <strong>generative approach</strong>, because by sampling from the joint distribution, it is possible to generate synthetic examples of the vector of characteristics <em>x</em>.</p>
<div class="packt_tip">
<p>The joint probability distribution <em>p(x, y)</em> is a probability distribution that gives the probability that each of <em>x</em>, <em>y</em> vectors falls in any particular range or discrete set of values specified for that variable.</p>
</div>
<p>A generative approach, regardless of the type of data and the theoretical model used, is divided into two basic steps:</p>
<ol>
<li>The first step involves the construction of the generative model. The input data is processed with the aim of deducing their distribution. To do this, input data can simply be reorganized into a different structure, or it can represent new information extracted from input data from specific algorithms. The result of the construction of the generative model is the presentation of data according to the distribution to which it has been approximated.</li>
<li>Once the generative model has been built on the input data, this allows sampling, which leads to the formation of new data that shares the same distribution with the input data.</li>
</ol>
<p>The construction of a generative model allows highlighting features and properties implicitly present in the initial data. The individual approaches are then distinguished by the type of processing performed on the data to explain these characteristics, and consequently for the type of variables on which an approximate data distribution is obtained.</p>
<p>Why are AI researchers so excited about generative models? Let's take a simple example: suppose we provide the system with a series of images of cats. Suppose then, that after seeing these images, the computer is able to generate new photos of cats in a completely independent manner. If the computer were able to do it and the images that were produced had the right number of legs, tails, ears, and so on, it would be easy to prove that the computer knows which parts make up the cat, even if no one has ever explained cat anatomy to it. So, in a sense, a good generative model is proof of the basic knowledge of concepts by computers.</p>
<p>This is why researchers are so enthusiastic about building generative models. These models seem to be a way to train computers to understand concepts without the need for researchers to teach them a priori concepts.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Restricted Boltzmann machine</h1>
                </header>
            
            <article>
                
<p>A Boltzmann machine is a probabilistic graphic model that can be interpreted as a stochastic neural network. Boltzmann machines were first introduced in 1985 by Geoffrey Hinton and Terry Sejnowski. <strong>Stochastic</strong> is due to the behavior of the neurons; within them, in the activation function, they will have a probabilistic value that will influence the activation of the neuron.</p>
<p>In practice, a Boltzmann machine is a model (including a certain number of parameters) that, when applied to a data distribution, is able to provide a representation. This model can be used to extract important aspects of an unknown distribution (target distribution) starting only from a sample of the latter. The data samples referred to by a Boltzmann Machine are also called <strong>training data</strong>. The following diagram shows a Boltzmann machine's architecture:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/8e44f820-27f1-481c-88ad-ebe5c3822a5f.png" style=""/></div>
<p>Training a Boltzmann machine means adapting its parameters so that the probability distribution represented by it interpolates the training data as best as possible. The training of a Boltzmann machine is a rather demanding work from a computational point of view. However, this problem can be made easier by imposing restrictions on the topology of the network on which you are working; this defines <strong>Restricted Boltzmann machines</strong> (<strong>RBM</strong>).</p>
<p>In Boltzmann machines, there are two types of units:</p>
<ul>
<li>Visible units (or neurons since, as we said, a Boltzmann machine can be interpreted as a neural network)</li>
<li>Hidden units (or neurons)</li>
</ul>
<p>Even in RBMs, there are both of these types of units and we can imagine them as arranged on two levels:</p>
<ul>
<li>Visible units are the components of an observation (for example, if our data consists of images, we can associate a visible unit with each pixel)</li>
<li>Hidden units instead give us a model of the dependencies that exist between the components of our observation (for example, the dependency relationships that exist between the pixels of an image)</li>
</ul>
<p>Hidden units can therefore be seen as detectors of data characteristics. In the RBM graph, every neuron is connected to all the neurons of the other level, while there are no connections between neurons of the same level; it is precisely this restriction that gives the RBM its name, as shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b5015ef9-9fd2-4a71-9c23-0cb45759b829.png" style=""/></div>
<p>After successful training, an RBM provides a very good representation of the distribution that underlies training data. It is a generative model that allows sampling new data starting from the learned distribution; for example, new image structures can be generated starting from studied images. Having a generative model makes useful applications possible. For example, you can think of integrating some visible units corresponding to a partial observation (that is, you fix the values of the observed variables and consider them constant) and then produce the remaining ones visible units to complete the observation; in the image analysis example, this can be useful for an image completion task.</p>
<p>As generative models, RBMs can also be used as classifiers. Consider an application of this type:</p>
<ul>
<li>RBM is trained to learn the joint probability distribution of the input data (explanatory variables) and the corresponding labels (response/output variables), both represented in the graph of the network, from the visible units of the RBM.</li>
<li>Subsequently, a new input pattern, this time without labels, can be linked to the visible variables. The corresponding labels can be predicted by sampling directly from the Boltzmann machine.</li>
</ul>
<p>The Boltzmann machine is able to complete partial patterns of data on visible units. If we divide the visible units into units of input and output, given the input pattern, the Boltzmann machine completes it by producing the outputs (classification). Otherwise, it works as associative memory, returning the most similar pattern among those learned to the (partial) data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Boltzmann machine architecture</h1>
                </header>
            
            <article>
                
<p>Boltzmann machine architecture is based on input, output, and hidden nodes. The connection weights are symmetrical:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/6acae0d1-92b9-42d1-978d-72cb6705d75f.png" style="width:13.50em;height:1.75em;"/></div>
<p>Based on this assumption, Boltzmann machines are highly recurrent, and this recurrence eliminates any basic difference between input and output nodes, which can be considered as input or output when needed. The Boltzmann machine is a network of units with an <strong>energy</strong> defined for the overall network. Its units produce binary results ((1,0) values). Outputs are computed probabilistically, and depend upon the temperature variable <em>T</em>.</p>
<p>The consensus function of the Boltzmann machine is given by the following formula:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/14f55f75-1a92-4109-9e2f-16d8b98a6736.png" style="width:9.67em;height:4.75em;"/></div>
<p>In the previous formula, the terms are defined as follows:</p>
<ul>
<li><em>S<sub>i</sub></em> is the state of unit <em>i(1,0)</em></li>
<li><em>w<sub>ij</sub></em> is the connection strength between unit <em>j</em> and unit <em>i</em></li>
<li><em>u<sub>j</sub></em> is the output of unit <em>j</em></li>
</ul>
<p>The calculation proceeds within the machine in a stochastic manner so that the consent is increased. Thus, if <em>w<sub>ij</sub></em> is positive, there is a tendency to have units <em>i</em> and <em>j</em> both activated or both deactivated, while if the weight is negative, there is a tendency to have them with different activations (one activated and the other not). When a weight is positive, it is called <strong>excitatory</strong>; otherwise, it is called <strong>inhibitory</strong>.</p>
<p>Each binary unit makes a stochastic decision to be either 1 (with probability <em>p<sub>i</sub></em>) or 0 (with probability <em>1- p<sub>i</sub></em>). This probability is given by the following formula:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/3d3077fe-3819-4235-b6cc-1247b5eab5f7.png" style="width:10.75em;height:3.67em;"/></div>
<p class="NormalPACKT"><span>At the equilibrium state of the network, the likelihood is defined as the exponentiated negative energy, known as the <strong>Boltzmann distribution</strong>. You can imagine that by administering energy, you can get the system out of the local minima. This must be done slowly, because a violent shock can drive the system away from the global minimum. The best method is to give energy and then slowly reduce it. This concept is used in metallurgy, where an ordered state of the metal is obtained first by melting, and then slowly the temperature is reduced. The reduction in temperature as the process is under way is called <strong>simulated annealing</strong>.</span></p>
<p class="NormalPACKT"><span>This method can be reproduced by adding a probabilistic update rule to the Hopfield network (refer to <a href="0fa9cfb2-9e84-4f95-b287-c28f1805cc97.xhtml" target="_blank">Chapter 13</a>, <em>Beyond Feedforward Networks – CNN and RNN</em>); the network that reproduces it is called <strong>Boltzmann machine</strong>. There will be a parameter that varies: the temperature. So at high <em>T</em>, the probability of jumping to a higher energy is much greater than at low temperatures.</span></p>
<p class="NormalPACKT"><span>When the temperature drops, the probability of assuming the correct minimum energy status approaches 1, and the network reaches the thermal equilibrium. Each unit of the network makes an energy leap given by the following formula:</span></p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/bdcee90a-5723-4c44-b7d3-fffdd91cdc9c.png" style="width:10.83em;height:1.83em;"/></div>
<p class="NormalPACKT"><span>The system changes to a state of lower energy according to the following probabilistic rule (transition function):</span></p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/d3a92cb1-11e1-4512-98d1-fe158d8c23f5.png" style="width:11.33em;height:3.42em;"/></div>
<p class="NormalPACKT"><span>It is seen that the probability of transition to a higher energy state is greater at high <em>T</em> than at low <em>T</em>. The network can assume a configuration of stable states according to the following Boltzmann distribution:</span></p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/5ba15569-d320-436d-a1b8-13c948c30e70.png" style="width:7.00em;height:2.08em;"/></div>
<p>That is, it depends on the energy of the state and temperature of the system. Lower energy states are more likely; in fact if <em>E<sub>a</sub> &lt; E<sub>b</sub></em>, then <em>P<sub>a</sub>/P<sub>b</sub> &gt; 1</em>, because of which <em>P<sub>a</sub>&gt;P<sub>b</sub></em>. So the system tends toward a state of minimum energy.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Boltzmann machine disadvantages</h1>
                </header>
            
            <article>
                
<p>Numerous problems have emerged in the use of algorithms based on Boltzmann machines. The following are some of the problems encountered:</p>
<ul>
<li>Weight adjustment</li>
<li>The time needed to collect statistics in order to calculate probabilities,</li>
<li>How many weights change at a time</li>
<li>How to adjust the temperature during simulated annealing</li>
<li>How to decide when the network has reached the equilibrium temperature.</li>
</ul>
<p>The main disadvantage is that Boltzmann learning is significantly slower than backpropagation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep Boltzmann machines</h1>
                </header>
            
            <article>
                
<p>Another type of Boltzmann Machine is <strong>Deep Boltzmann machine</strong> (<strong>DBM</strong>). This is a neural network similar to RBM, but instead of having only one layer of hidden nodes, DBMs have many. Each layer of neurons is connected only to those adjacent (the one immediately preceding and immediately following); here <span>also, </span>the neurons of the same layer are not interconnected. This structure allows the emergence of particular statistics from each layer that can capture new data features. The following diagram shows a DBM model with one visible layer and two hidden layers:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/cec3294c-9538-4bc9-9c3d-cbcd6597215e.png" style=""/></div>
<p class="NormalPACKT"><span>As we can see, connections are only between units in neighboring layers. Like RBMs and DBMs contain only binary units.</span></p>
<p class="NormalPACKT"><span>The DBMs model assigns the following probability to a visible vector <em>v</em>:</span></p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/246b4b27-7a6d-4e45-aefe-fb19b9e2d4b6.png" style="width:23.25em;height:4.50em;"/></div>
<p>In the previous formula, the terms are defined as follows:</p>
<ul>
<li><em>v</em> is the visible vector</li>
<li><em>θ = (W(1),W(2))</em> are the model parameters, representing visible-to-hidden and hidden-to-hidden symmetric interaction terms</li>
<li><em>h<sup>(1)</sup></em> and <em>h<sup>(2)</sup></em> are hidden stochastic binary variables</li>
<li><em>Z(θ)</em> is the partition function</li>
</ul>
<p>DBMs are particularly useful in the case of the recognition of objects or words. This is due to the great ability to learn complex and abstract internal representations using little labeled input data, instead of exploiting a large amount of unlabeled input data. However, unlike deep convolutional neural networks, DBMs adopt the inference and training procedure in both directions to better detect representations of input structures.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Autoencoder</h1>
                </header>
            
            <article>
                
<p>An autoencoder is a neural network whose purpose is to code its input into small dimensions and the result obtained, to be able to reconstruct the input itself. Autoencoders are made up of the union of the following two subnets:</p>
<ul>
<li>Encoder, which calculates the function:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><em>z = ϕ(x)</em></div>
<p>Given an input <em>x</em>, the encoder encodes it in a variable <em>z</em>, also called <strong>latent variable</strong>. <em>z</em> usually has much smaller dimensions than <em>x</em>.</p>
<ul>
<li>Decoder, which calculates the following function:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><em>x' = ψ(z)</em></div>
<p>Since <em>z</em> is the code of <em>x</em> produced by the encoder, the decoder must decode it so that <em>x'</em> is similar to <em>x</em>.</p>
<p>The training of autoencoders is intended to minimize the mean square error between the input and the result.</p>
<div class="mce-root packt_tip"><strong>Mean Squared Error</strong> (<strong>MSE</strong>) is the average squared difference between the outputs and targets. Lower values are indicative of better results. Zero means no error.</div>
<p>For n observations, <em>MSE</em> is given by the following formula:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/9c0e222d-4550-4c01-ba34-712bc3d26588.png" style="width:13.33em;height:4.00em;"/></div>
<p>Finally, we can summarize that the encoder encodes the input in a compressed representation and the decoder returns from it a reconstruction of the input, as shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-730 image-border" src="assets/b4d01427-e444-48e4-9ff6-19e7f4da2887.png" style=""/></div>
<p>Let’s define the following terms:</p>
<ul>
<li><em>W</em>: input → hidden weights</li>
<li><em>V</em>: hidden → output weights</li>
</ul>
<p>The previous formulas become:</p>
<div class="CDPAlignCenter CDPAlign"><em>z = ϕ(W* x)</em></div>
<p>And they also become:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><em>x' = ψ(V*W1* x)</em></div>
<p>Finally, the training of autoencoders is intended to minimize the following quantity:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/599757b5-83ce-4735-9e7d-76dd298d25f6.png" style="width:11.58em;height:3.33em;"/></div>
<p>The purpose of autoencoders is not simply to perform a sort of compression of the input or to look for an approximation of the identity function. There are techniques that allow, starting from a hidden layer of reduced dimensions, to direct the model to give greater importance to some data properties, thus giving rise to different representations based on the same data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Variational autoencoder</h1>
                </header>
            
            <article>
                
<p><strong>Variational autoencoder</strong> (<strong>VAE</strong>) are inspired by the concept of Autoencoder: a model consisting of two neural networks called <strong>encoders</strong> and <strong>decoders</strong>. As we have seen, the encoder network tries to code its input in a compressed form, while the network decoder tries to reconstruct the initial input, starting from the code returned by the encoder.</p>
<p>However, the functioning of the VAE is very different than that of simple autoencoders. VAEs allow <span>not only </span>coding/decoding of input but also generating new data. To do this, they treat both the code <em>z</em> and the reconstruction/generation <em>x'</em> as if they belonged to a certain probability distribution. In particular, the VAEs are the result of the combination of deep learning and Bayesian inference, in the sense that they consist of a neural network trained with the backpropagation algorithm modified with a technique called <strong>re-parameterization</strong>. While deep learning has proven to be very effective in the approximation of complex functions, the Bayesian statistics allow managing the uncertainty derived from a random generation in the form of probabilities.</p>
<p>The VAE uses the same structure to generate new images, similar to those belonging to the training set. In this case, the encoder does not directly produce a code for a given input but calculates the mean and variance of a normal distribution. A value is taken from this distribution and it is decoded by the decoder. The training consists of modifying the encoder and decoder parameters so that the result of the decoded so carried out is as similar as possible to the starting image. At the end of the training, we have that starting from the normal distribution with mean and variance produced by the encoder; the decoder will be able to produce images similar to those belonging to the training set.</p>
<p>Let's define the following terms:</p>
<ul>
<li><em>X</em>: Input data vector</li>
<li><em>z</em>: Latent variable</li>
<li><em>P(X)</em> : Probability distribution of the data</li>
<li><em>P(z)</em>: Probability distribution of the latent variable</li>
<li><em>P(X|z)</em>: Posterior probability, that is, the distribution of generating data given the latent variable</li>
</ul>
<div class="packt_tip">
<p>The posterior probability <em>P(X|z)</em> is the probability of the condition <em>X</em> given the evidence <em>z</em>.</p>
</div>
<p>Our goal is to generate data according to the characteristics contained in the latent variable, so we want to find <em>P(X)</em>. For this purpose, we can use the law of total probability according to the following formula:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/8b70972e-9595-4b55-9d90-53a6db072c2a.png" style="width:12.33em;height:2.67em;"/></div>
<p class="NormalPACKT"><span>To understand how we arrived at this formulation, we reason by step. Our first task in </span><span>defining</span><span> the </span><span>model is to infer good values of the latent variables starting from the observed data, or to calculate the posterior <em>p(z|X)</em>. To do this, we can use the Bayes theorem:</span></p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/4d46bbe0-263d-468d-add4-a5eb6764734d.png" style="width:11.25em;height:2.92em;"/></div>
<p class="NormalPACKT"><span>In the previous formula, the <em>P(X)</em> term </span><span>appears.</span><span> In the context of Bayesian statistics, it may also be referred to as the evidence or model evidence. The evidence can be calculated by marginalizing out the latent variables. This brings us to the starting formula:</span></p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/e0fe3410-7faa-4200-a3e5-2578aa13fff0.png" style="width:13.50em;height:2.92em;"/></div>
<p>The computational estimate of this integral requires an exponential time as it must be evaluated on all the configurations of latent variables. To reduce the computational cost, we are forced to approximate the estimate of the posterior probability.</p>
<p>In VAE, as the name suggests, we deduce <em>p(z | X)</em> using a method called <strong>variational inference</strong> (<strong>VI</strong>). VI is one of the most used methods in Bayesian inference. This technique considers inference as an optimization problem. In doing this, we use a simpler distribution that is easy to evaluate (for example, Gaussian) and minimize the difference between these two distributions using the <strong>Kullback-Leibler divergence metric</strong>.</p>
<div class="packt_tip">
<p>Kullback-Leibler divergence metric is a non-symmetric measure of the difference between two probability distributions <em>P</em> and <em>Q</em>. Specially, the Kullback-Leibler divergence of <em>Q</em> from <em>P</em>, denoted by <strong>DKL</strong> <em>(P ||Q)</em>, is the measurement of the information lost when <em>Q</em> is used to approximate <em>P</em>.</p>
</div>
<p>For discrete probability distributions <em>P</em> and <em>Q</em>, the Kullback-Leibler divergence from <em>Q</em> to <em>P</em> is defined as follows:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/57583f96-c918-48a5-9f01-1f29c375b290.png" style="width:14.83em;height:2.92em;"/></div>
<p>Analyzing the formula makes it evident that the divergence of Kullback-Leibler is the expectation of the logarithmic difference between the probabilities <em>P</em> and <em>Q</em>, where the expectation is taken using the probability <em>P</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Generative adversarial network</h1>
                </header>
            
            <article>
                
<p><strong>Generative adversarial network</strong> (<strong>GAN</strong>) is a generative model consisting of two networks that are jointly trained, called <strong>generator</strong> and <strong>discriminator</strong>.</p>
<p>The dynamics between these two networks are like those between a forger and an investigator. The forger tries to produce faithful imitations of authentic works of art, while the investigator tries to distinguish the fakes from the originals. In this analogy, the forger represents the generator and the investigator represents the discriminator. The generator accepts input values ​​belonging to a fixed distribution and tries to produce images similar to those of the dataset. The discriminator tries to distinguish the data created by the generator from those belonging to the dataset. These two networks are jointly coached:</p>
<ul>
<li>The discriminator tries to return output = 1 if the input belongs to the dataset and returns 0 if its input was generated by the generator</li>
<li>The generator instead tries to maximize the possibility that the discriminator will make mistakes</li>
</ul>
<p>The generator acquires a random input noise and tries to create a sample of data, while the discriminator takes input <span>from </span>either real-world examples or the generator, as shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/bc17de32-bdec-4266-9b6a-3cd00a7a346a.png" style=""/></div>
<p class="NormalPACKT"><span>For simplicity, the two opposing networks are of the multilayer perceptron type; however, the same structure can be modeled with deep networks. For example, to generate new images, instead of sampling data from a complex distribution, the approach used in these networks is to start from values belonging to a simple distribution or from random values. Subsequently, they are mapped through a second distribution that will be learned during the training.</span></p>
<p class="NormalPACKT"><span>In such a system, training leads to constant competition between generator and discriminator. Under these conditions, the optimization process can be carried out independently on both sides. Naming <em>G(z)</em> the generator and <em>D(x)</em> the discriminator, the training of the model aims to maximize the probability of the discriminator to assign 1 to values coming from the training set, instead of 0 to those produced by the generator. On the other hand, we want to teach the generator to minimize the following quantity:</span></p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/6001f561-7c54-47ba-bee9-755125f7f352.png" style="width:8.92em;height:1.42em;"/></div>
<p class="NormalPACKT"><span>The training is then performed by applying the gradient descent technique to the following expression:</span></p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/f02edaee-d830-4920-a698-7b99d1410767.png" style="width:43.75em;height:2.42em;"/></div>
<p>This method originates from game theory, in particular from the method called <strong>two-player minimax game</strong>. The algorithms of this type adopt the strategy of minimizing the maximum possible loss resulting from the choice of a player. It can happen that, in the training process, the discriminator is not able to classify examples generated by real ones.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adversarial autoencoder </h1>
                </header>
            
            <article>
                
<p><strong>Adversarial autoencode</strong>r (<strong>AAE</strong>) is a generative model produced by the union of VAE and GAN. To explain the model, we start by defining the following terms:</p>
<ul>
<li><em>x</em>: Autoencoder input</li>
<li>z: Code produced from <em>x</em>,</li>
<li><em>p(z)</em>: The distribution we want to impose</li>
<li><em>q(z|x)</em>: Distribution learned from the encoder</li>
<li><em>p(x|z)</em>: Distribution learned from the decoder</li>
<li><em>pdata</em>: Distribution of the data</li>
<li><em>p(x)</em>: Distribution of the model</li>
</ul>
<p>We consider the function <em>q(z|x)</em> as a posterior distribution of <em>q(z)</em>, which is defined as follows:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/09520493-7e28-4d45-86c5-e5a66cde4a86.png" style="width:14.17em;height:3.00em;"/></div>
<p class="NormalPACKT"><span>We try to impose the equality <em>q(z)=p(z)</em> on the model. The difference with a VAE is due to the fact that what drives <em>q (z)</em> towards <em>p(z)</em> is an adversarial network. The encoder of the VAE is considered the generator of a GAN for which a discriminator can be used. This tries to distinguish data belonging to <em>q(z)</em> from that coming from <em>p(z)</em>. The following diagram shows an AAE architecture:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e48353cc-d8e6-4f7b-b6de-566fa7919e91.png" style=""/></div>
<div>
<p>The trainings of the adversarial network and of the autoencoder take place jointly, using stochastic gradient descent.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Feature extraction using RBM</h1>
                </header>
            
            <article>
                
<div>
<p>Recently, several types of <strong>artificial neural networks</strong> (<strong>ANNs</strong>) have been applied to classify a specific dataset. However, most of these models use only a limited number of features as input, in which case there may not be enough information to make the prediction due to the complexity of the starting dataset. If you have more features, the run time of training would be increased and generalization performance would deteriorate due to the curse of dimesionality. In these cases, a tool to extract the characteristics would be particularly useful. RBM is a machine learning tool with a strong representation power, which is often used as a feature extractor in a wide variety of classification problems.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Breast cancer dataset</h1>
                </header>
            
            <article>
                
<div>
<p>The breast is made up of a set of glands and adipose tissue, and is located between the skin and the chest wall. In fact, it is not a single gland but a set of glandular structures, called <strong>lobules</strong>, joined together to form a lobe. In a breast, there are 15 to 20 lobes. The milk reaches the nipple from the lobules through small tubes called <strong>milk ducts</strong>.</p>
<p>Breast cancer is a potentially serious disease if it is not detected and treated. It is caused by uncontrolled multiplication of some cells in the mammary gland that are transformed into malignant cells. This means that they have the ability to detach themselves from the tissue that has generated them to invade the surrounding tissues and eventually other organs of the body. In theory, cancers can be formed from all types of breast tissues, but the most common ones are from glandular cells or from those forming the walls of the ducts.</p>
<p>The objective of this example is to identify each of a number of benign or malignant classes. To do this, we will use the data contained in the dataset named BreastCancer (Wisconsin Breast Cancer database). This data has been taken from the UCI Repository of machine learning databases as DNA samples arrive periodically, as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronological grouping of the data. This grouping information appears immediately, having been removed from the data itself. Each variable, except for the first, was converted into 11 primitive numerical attributes with values ranging from zero through ten.</p>
<div class="packt_infobox">
<p>To get the data, we draw on the large collection of data available in the UCI Machine Learning Repository at the following link: <a href="http://archive.ics.uci.edu/ml" target="_blank">http://archive.ics.uci.edu/ml</a>.</p>
</div>
<p>To load the dataset, we will use the <kbd>sklearn.datasets</kbd> module. It includes utilities to load datasets, including methods to load and fetch popular reference datasets. It also features some artificial data generators.</p>
<p>The breast cancer dataset is a classic and very easy binary classification dataset. The following table has some information about the dataset:</p>
<div>
<table>
<tbody>
<tr>
<td>
<p>Classes</p>
</td>
<td>
<p>2</p>
</td>
</tr>
<tr>
<td>
<p>Samples per class</p>
</td>
<td>
<p>212(M), 357(B)</p>
</td>
</tr>
<tr>
<td>
<p>Samples total</p>
</td>
<td>
<p>569</p>
</td>
</tr>
<tr>
<td>
<p>Dimensionality</p>
</td>
<td>
<p>30</p>
</td>
</tr>
<tr>
<td>
<p>Features</p>
</td>
<td>
<p>real and positive</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data preparation</h1>
                </header>
            
            <article>
                
<p>After introducing the breast cancer dataset, we can analyze the code that will allow us to classify the input data line by line. In the first part of the code, we import the libraries we will use later:</p>
<pre>from sklearn import linear_model, datasets, preprocessing<br/>from sklearn.cross_validation import train_test_split<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.neural_network import BernoulliRBM<br/>from pandas_ml import ConfusionMatrix<br/>import numpy as np<br/>import pandas as pd</pre>
<p>For now, let's limit ourselves to import; we will deepen them at the time of use. To start, we have to import the dataset; we will do so using the <kbd>sklearn.datasets</kbd> package:</p>
<pre>BC = datasets.load_breast_cancer()</pre>
<p>This command loads and returns the breast cancer <kbd>wisconsin</kbd> dataset. The <kbd>sklearn.datasets</kbd> package embeds some small toy datasets. To evaluate the impact of the scale of the dataset (<kbd>n_samples</kbd> and <kbd>n_features</kbd>) while controlling the statistical properties of the data (typically the correlation and informativeness of the features), it is also possible to generate synthetic data. This package also features helpers to fetch larger datasets commonly used by the machine learning community to benchmark algorithm on data that comes from the real world. A dataset is a dictionary-like object that holds all the data and some metadata about the data. This data is stored in the data member, which is a <kbd>n_samples</kbd> and <kbd>n_features</kbd> array. In the case of a supervised problem, one or more response variables are stored in the target member.</p>
<p>Data is returned in a <kbd>Bunch</kbd> object, a dictionary-like object that contains the following attributes:</p>
<ul>
<li><kbd>data</kbd>: The data to learn</li>
<li><kbd>target</kbd>: The classification labels</li>
<li><kbd>target_names</kbd>: The meaning of the labels</li>
<li><kbd>feature_names</kbd>: The meaning of the features</li>
<li><kbd>DESCR</kbd>: The full description of the dataset</li>
</ul>
<p>To confirm the content of the data, let's extract the dimensions:</p>
<pre>print(BC.data.shape)<br/>print(BC.target.shape)</pre>
<p>The results are listed as follows:</p>
<pre>(569, 30)<br/>(569,)</pre>
<p>To better understand the operations, we divide these data into <kbd>X</kbd> (predictors) and <kbd>Y</kbd> (target):</p>
<pre>X = BC.data<br/>Y = BC.target</pre>
<p>At this point, we extract a series of statistics from the predictors using the tools that make available to us the <kbd>pandas</kbd> library.</p>
<div class="packt_tip">
<p><kbd>pandas</kbd> is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.</p>
</div>
<p>To use this function, we have to convert the input data from <kbd>numpy.darray</kbd> to <kbd>pandas</kbd> dataframe:</p>
<pre>Xdata=pd.DataFrame(X)<br/>print(Xdata.describe())</pre>
<p>The results are shown as follows:</p>
<pre>               0           1           2            3           4   \<br/>count  569.000000  569.000000  569.000000   569.000000  569.000000<br/>mean    14.127292   19.289649   91.969033   654.889104    0.096360<br/>std      3.524049    4.301036   24.298981   351.914129    0.014064<br/>min      6.981000    9.710000   43.790000   143.500000    0.052630<br/>25%     11.700000   16.170000   75.170000   420.300000    0.086370<br/>50%     13.370000   18.840000   86.240000   551.100000    0.095870<br/>75%     15.780000   21.800000  104.100000   782.700000    0.105300<br/>max     28.110000   39.280000  188.500000  2501.000000    0.163400</pre>
<p>Due to space constraints, we have reported only the results for the first five predictors. As we can see, the variables have different ranges. When the predictors have different ranges, the impact on response variables by the feature having a greater numeric range could be more than the one having a less numeric range, and this could, in turn, impact the prediction accuracy. Our goal is to improve predictive accuracy and not allow a particular feature to impact the prediction due to a large numeric value range. Thus, we may need to scale values under different features such that they fall under a common range. Through this statistical procedure, it is possible to compare identical variables belonging to different distributions and also different variables or variables expressed in different units.</p>
<div class="packt_tip">
<p>Remember, it is good practice to rescale the data before training a machine learning algorithm. With rescaling, data units are eliminated, allowing you to easily compare data from different locations.</p>
</div>
<p>In this case, we will use the min-max method (usually called <strong>feature scaling</strong>) to get all the scaled data in the range (0, 1). The formula to achieve this is:</p>
<div class="CenterAlign"><img class="fm-editor-equation" src="assets/4d0fa157-043f-480a-8c67-3356ced2ab01.png" style="width:13.00em;height:3.08em;"/></div>
<p>The following command performs a feature scaling:</p>
<pre>X = (X - np.min(X, 0)) / (np.max(X, 0) - np.min(X, 0))</pre>
<p><kbd>numpy.min()</kbd> and <kbd>numpy.max()</kbd> are used to calculate the minimum and maximum values of each database column.</p>
<p>Let's now split the data for the training and the test models. Training and testing the model forms the basis for further usage of the model for prediction in predictive analytics. Given a dataset of 100 rows of data, which includes the predictor and response variables, we split the dataset into a convenient ratio (say 80:20), and allocate 80 rows for training and 20 rows for testing. The rows are selected at random to reduce bias. Once the training data is available, the data is fed to the machine learning algorithm to get the massive universal function in place. To split the dataset, we will use the <kbd>sklearn.model_selection.train_test_split()</kbd> function:</p>
<pre>X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)</pre>
<p>The <kbd>train_test_split()</kbd> function splits arrays or matrices into random train and test subsets. The first two arguments are <kbd>X</kbd> (predictors) and <kbd>Y</kbd> (target) numpy arrays. Allowed inputs are lists, <kbd>numpy</kbd> arrays, scipy-sparse matrices, or <kbd>pandas</kbd> dataframes. Then two options are added:</p>
<ul>
<li><kbd>test_size</kbd>: This should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split</li>
<li><kbd>random_state</kbd>: This is the seed used by the random number generator</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Model fitting</h1>
                </header>
            
            <article>
                
<p>We have previously said that RBM is often used as a feature in a wide variety of classification problems. It's time to see how to do it. The first thing to do is to use the <kbd>BernoulliRBM</kbd> function of the <kbd>sklearn.neural_network</kbd> module.</p>
<div class="packt_tip">
<p><kbd>sklearn</kbd> is a free machine learning library for the Python programming language. It features various classification, regression, and clustering algorithms, including support vector machines, random forests, gradient boosting, k-means, and DBSCAN. And it is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.</p>
</div>
<p>In the <kbd>sklearn</kbd> library, the <kbd>sklearn.neural_network</kbd> module includes models based on neural networks. In this module, the <kbd>BernoulliRBM</kbd> function fits a Bernoulli RBM. An RBM with binary visible units and binary hidden units is returned. The parameters are estimated using <strong>Stochastic Maximum Likelihood</strong> (<strong>SML</strong>), also known as <strong>Persistent Contrastive Divergence</strong> (<strong>PCD</strong>). First, we will set the architecture of the model:</p>
<pre>RbmModel = BernoulliRBM(random_state=0, verbose=True)</pre>
<p>Then, we will fit the model with the training data:</p>
<pre>FitRbmModel = RbmModel.fit_transform(X_train, Y_train)</pre>
<p>The <kbd>fit_transform</kbd> method fits the transformer to <kbd>X_train</kbd> and <kbd>Y_train</kbd> with optional parameter <kbd>fit_params</kbd>, and returns a transformed version of <kbd>X_train</kbd>. In this case, no optional parameters are used.</p>
<p>If you remember, our purpose is to use the <kbd>Rbm</kbd> model to extract the features that will then be used by the logistic regression model to classify the data. So, the first part has already been performed—we already have the features extracted in the <kbd>FitRbmModel</kbd> variable. The time has come to create the logistic regression model. To do this, we will use <kbd>LogisticRegression</kbd> function of the <kbd>sklearn.linear_model</kbd> module, as follows:</p>
<pre>LogModel = linear_model.LogisticRegression()</pre>
<p>We now set coefficients of the features in the decision function equal to the features extracted from the <kbd>rbm</kbd> model:</p>
<pre>LogModel.coef_ = FitRbmModel</pre>
<p>Now we can build the classifier. To do this, we will use the <kbd>Pipeline</kbd> function of the <kbd>sklearn.pipeline</kbd> module:</p>
<pre>Classifier = Pipeline(steps=[('RbmModel', RbmModel), ('LogModel', LogModel)])</pre>
<p>The purpose of the <kbd>pipeline</kbd> is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names, as in the previous code. A step's estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting to <kbd>None</kbd>. The classifier is now ready; we just have to train it:</p>
<pre>LogModel.fit(X_train, Y_train)<br/>Classifier.fit(X_train, Y_train)</pre>
<p>First, the logistic regression model is trained and then the classifier. We just have to make predictions. Recall that for doing this, we have an unused dataset available: <kbd>X_test</kbd> and <kbd>Y_test</kbd>. To check the performance of the classifier, we will compare the forecasts with the real data:</p>
<pre>print ("The RBM model:")<br/>print ("Predict: ", Classifier.predict(X_test))<br/>print ("Real:    ", Y_test)</pre>
<p>The following screenshot shows the results returned:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/45e4aa13-a412-47eb-b29b-72ce75cb5df6.png" style=""/></div>
<p>Finally, to better understand the model performance, we will calculate the confusion matrix. In a confusion matrix, our classification results are compared to real data. The strength of a confusion matrix is that it identifies the nature of the classification errors as well as their quantities. In this matrix, the diagonal cells show the number of cases that were correctly classified; all the other cells show the misclassified cases. To calculate the confusion matrix, we can use the <kbd>ConfusionMatrix()</kbd> function contained in pandas library as follows:</p>
<pre>CM = ConfusionMatrix(Y_test, Classifier.predict(X_test))<br/>CM.print_stats()</pre>
<p>In the following code, the results returned by the <kbd>ConfusionMatrix()</kbd> function <span>are shown</span>:</p>
<pre>population: 114<br/>P: 72<br/>N: 42<br/>PositiveTest: 87<br/>NegativeTest: 27<br/>TP: 71<br/>TN: 26<br/>FP: 16<br/>FN: 1<br/>TPR: 0.9861111111111112<br/>TNR: 0.6190476190476191<br/>PPV: 0.8160919540229885<br/>NPV: 0.9629629629629629<br/>FPR: 0.38095238095238093<br/>FDR: 0.1839080459770115<br/>FNR: 0.013888888888888888<br/>ACC: 0.8508771929824561<br/>F1_score: 0.8930817610062893<br/>MCC: 0.6866235389841608<br/>informedness: 0.6051587301587302<br/>markedness: 0.7790549169859515<br/>prevalence: 0.631578947368421<br/>LRP: 2.588541666666667<br/>LRN: 0.022435897435897433<br/>DOR: 115.37500000000003<br/>FOR: 0.037037037037037035</pre>
<p>Several bits of information are returned; in particular, we can notice that the accuracy of the model is 0.85.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Autoencoder with Keras</h1>
                </header>
            
            <article>
                
<p>As we said previously, an autoencoder is a neural network whose purpose is to code its input into small dimensions and the result obtained to be able to reconstruct the input itself. Autoencoders are made up of the union of the following two subnets: encoder and decoder. To these functions is added another; it's a loss function calculated as the distance between the amount of information loss between the compressed representation of the data and the decompressed representation. The encoder and the decoder will be differentiable with respect to the distance function, so the parameters of the encoding/decoding functions can be optimized to minimize the loss of reconstruction, using the gradient stochastic.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Load data</h1>
                </header>
            
            <article>
                
<p>This is a database of handwritten digits consisting of 60,000 28 x 28 grayscale images of the 10 digits, along with a test set of 10,000 images. This dataset is already available in the Keras library. The following diagram shows a sample of images of 0-8 from the MNIST dataset:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/fec99017-84f1-44c8-b493-7ae8745a8ed6.png" style=""/></div>
<p class="mce-root">As always, we will analyze the code line by line. In the first part of the code, we import the libraries we will use later:</p>
<pre>from keras.layers import Input, Dense<br/>from keras.models import Model</pre>
<p class="mce-root">This code imports the following function:</p>
<ul>
<li>The Input function is used to instantiate a Keras tensor. A Keras tensor is a tensor object from the underlying backend (Theano, TensorFlow, or CNTK). We augment it with certain attributes that allow us to build a Keras model just by knowing the inputs and outputs of the model.</li>
<li>The Dense function is used instantiate a regular densely connected NN layer.</li>
<li>The Model function is used to define the model. The model is the thing that you can summarize, fit, evaluate, and use to make predictions. Keras provides a <kbd>Model</kbd> class that you can use to create a model from your created layers. It only requires that you specify the input and output layers.</li>
</ul>
<p class="mce-root">To import the dataset, simply use this code:</p>
<pre class="mce-root">from keras.datasets import mnist<br/>(x_train, y_train), (x_test, y_test) = mnist.load_data()</pre>
<p class="mce-root">The following tuples are returned:</p>
<ul>
<li><kbd>x_train, x_test</kbd>: A <kbd>uint8</kbd> array of grayscale image data with shape (<kbd>num_samples</kbd>, 28, 28)</li>
<li><kbd>y_train, y_test</kbd>: A <kbd>uint8</kbd> array of digit labels (integers in range 0-9) with shape (<kbd>num_samples</kbd>)</li>
</ul>
<p class="mce-root">Now we have to normalize all values between 0 and 1. The Mnist images are stored in pixel format, where each pixel (totally 28 x 28) is stored as an 8-bit integer giving a range of possible values from 0 to 255. Typically, zero is taken to be black, and 255 is taken to be white. The values in between make up the different shades of gray. Now, to normalize all values between 0 and 1, simply divide each value by 255. So the pixel containing the value 255 will become 1 and the one containing 0 will remain as such; in between lie all the other values:</p>
<pre class="mce-root">x_train = x_train.astype('float32') / 255<br/>x_test = x_test.astype('float32') / 255</pre>
<p class="mce-root">By using the <kbd>astype()</kbd> function, we have converted the input data in <kbd>float32</kbd> (single precision float: sign bit, 8-bits exponent, 23 bits mantissa). As we said, each sample (image) consists of a 28 x 28 matrix. To reduce the dimensionality, we will flatten the 28 x 28 images into vectors of size 784:</p>
<pre class="mce-root">x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))<br/>x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))</pre>
<p class="mce-root">The <kbd>reshape()</kbd> function gives a new shape to an array without changing its data. The new shape should be compatible with the original shape. The first dimension of the new shape is the number of observations returned from the <kbd>len()</kbd> function (<kbd>len(x_train)</kbd> and <kbd>len(x_test)</kbd>). The second dimension represents the product of the last two dimensions of the starting data (28 x 28 = 784). To better understand this transformation, we print the shape of the starting dataset <span>first</span><span> </span><span>and then the shape of the transformed dataset:</span></p>
<pre class="mce-root">print (x_train.shape)<br/>print (x_test.shape)</pre>
<p class="mce-root">The following are the results before and after the dataset reshape:</p>
<pre class="mce-root">(60000, 28, 28)<br/>(10000, 28, 28)<br/>(60000, 784)<br/>(10000, 784)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Keras model overview</h1>
                </header>
            
            <article>
                
<p class="mce-root">There are two types of models available in Keras:</p>
<ul>
<li>Sequential model</li>
<li>Keras functional API</li>
</ul>
<p>Let us take a look at each one in detail in the following sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sequential model</h1>
                </header>
            
            <article>
                
<p class="mce-root">The <kbd>Sequential</kbd> model is a linear stack of layers. We can create a <kbd>Sequential</kbd> model by passing a list of layer instances to the constructor as follows:</p>
<pre class="mce-root">from keras.models import Sequential<br/>from keras.layers import Dense, Activation<br/>model = Sequential([<br/>    Dense(32, input_shape=(784,)),<br/>    Activation('relu'),<br/>    Dense(10),<br/>    Activation('softmax'),<br/>])</pre>
<p class="mce-root">We can also simply add layers via the <kbd>.add()</kbd> method:</p>
<pre class="mce-root">model = Sequential()<br/>model.add(Dense(32, input_dim=784))<br/>model.add(Activation('relu'))</pre>
<p class="mce-root">This type of model needs to know what input shape it should expect. For this reason, the first layer in a <kbd>Sequential</kbd> model needs to receive information about its input shape. There are several possible ways to do this:</p>
<ul>
<li>Pass an <kbd>input_shape</kbd> argument to the first layer</li>
<li>Specify of their input shape via the <kbd>input_dim</kbd> and <kbd>input_length</kbd> arguments </li>
<li>Pass a <kbd>batch_size</kbd> argument to a layer</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Keras functional API</h1>
                </header>
            
            <article>
                
<p class="mce-root">Another way to define a model is the Keras functional API. The Keras functional API is the way to go for defining complex models, such as multi-output models, directed acyclic graphs, or models with shared layers. For example, to define a densely connected network, simply type the following code:</p>
<pre class="mce-root">from keras.layers import Input, Dense<br/>from keras.models import Model<br/>inputs = Input(shape=(784,))<br/>x = Dense(64, activation='relu')(inputs)<br/>x = Dense(64, activation='relu')(x)<br/>predictions = Dense(10, activation='softmax')(x)<br/>model = Model(inputs=inputs, outputs=predictions)<br/>model.compile(optimizer='rmsprop',<br/>              loss='categorical_crossentropy',<br/>              metrics=['accuracy'])<br/>model.fit(data, labels) </pre>
<p class="mce-root">In the following section, we will dive deep into this type of model by applying it to our example.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Define model architecture</h1>
                </header>
            
            <article>
                
<p class="mce-root">Now we will build the model using the Keras functional API. As we saw before, first we have to define the input:</p>
<pre class="mce-root">InputModel = Input(shape=(784,))</pre>
<p class="mce-root">This returns a tensor that represents our input placeholder. Later, we will use this placeholder to define a <kbd>Model</kbd>. At this point, we can add layers to the architecture of our model:</p>
<pre class="mce-root">EncodedLayer = Dense(32, activation='relu')(InputModel)</pre>
<p class="mce-root">The Dense class is used to define a fully connected layer. We have specified the number of neurons in the layer as the first argument (32), the activation function using the activation argument (<kbd>relu</kbd>), and finally the input tensor (<kbd>InputModel</kbd>) of the layer.</p>
<div class="packt_tip">Remember that given an input <kbd>x</kbd>, the encoder encodes it in a variable <kbd>z</kbd>, also called <strong>latent variable</strong>. <kbd>z</kbd> usually has much smaller dimensions than <kbd>x</kbd>; in our case, we have passed from 784 to 32 with a compression factor of 24.5.</div>
<p class="mce-root">Now let's add the decoding layer:</p>
<pre class="mce-root">DecodedLayer = Dense(784, activation='sigmoid')(EncodedLayer)</pre>
<p class="mce-root">This layer is the lossy reconstruction of the input. For another time, we have used the Dense class with 784 neurons (dimensionality of the output space), the <kbd>sigmoid</kbd> activation function, and <kbd>EncodedLayer</kbd> output as input. Now we have to instantiate a model as follows:</p>
<pre class="mce-root">AutoencoderModel = Model(InputModel, DecodedLayer)</pre>
<p class="mce-root">This model will include all layers required in the computation of <kbd>DecodedLayer</kbd> (output) given <kbd>InputModel</kbd> (input). In the following are listed some useful attributes of Model class:</p>
<ul>
<li><kbd>model.layers</kbd> is a flattened list of layers comprising the model graph</li>
<li><kbd>model.inputs</kbd> is the list of input tensors</li>
<li><kbd>model.outputs</kbd> is the list of output tensors</li>
</ul>
<p class="mce-root">So, we have to configure the model for training. To do this, we will use the <kbd>compile</kbd> method as follows:</p>
<pre class="mce-root">AutoencoderModel.compile(optimizer='adadelta', loss='binary_crossentropy')</pre>
<p class="mce-root">This method configures the model for training. Only two arguments are used:</p>
<ul>
<li><kbd>optimizer</kbd>: String (name of optimizer) or optimizer instance.</li>
<li><kbd>loss</kbd>: String (name of objective function) or objective function. If the model has multiple outputs, you can use a different loss on each output by passing a dictionary or a list of losses. The loss value that will be minimized by the model will then be the sum of all individual losses.</li>
</ul>
<p class="mce-root">We have used adadelta optimizer. This method dynamically adapts over time, using only first-order information, and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of the learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities, and selection of hyperparameters.</p>
<p class="mce-root">Furthermore, we have used <kbd>binary_crossentropy</kbd> as a <kbd>loss</kbd> function. Loss functions are computationally feasible functions representing the price paid for inaccuracy of predictions in classification problems.</p>
<p class="mce-root">At this point, we can train the model:</p>
<pre class="mce-root">history = AutoencoderModel.fit(x_train, x_train,<br/>                batch_size=256,<br/>                epochs=100,<br/>                shuffle=True,<br/>                validation_data=(x_test, x_test))</pre>
<p class="mce-root">The fit method trains the model for a fixed number of epochs (iterations on a dataset). In the following, the arguments passed are explained to better understand the meaning:</p>
<ul>
<li><kbd>x</kbd>: A Numpy array of training data (if the model has a single input), or list of Numpy arrays (if the model has multiple inputs). If input layers in the model are named, you can also pass a dictionary mapping input names to Numpy arrays. <kbd>x</kbd> can be None (default) if feeding from framework-native tensors (for example,. TensorFlow data tensors).</li>
<li><kbd>y</kbd>: A Numpy array of target (label) data if the model has a single output, or a list of Numpy arrays if the model has multiple outputs. If output layers in the model are named, you can also pass a dictionary mapping output names to Numpy arrays. <kbd>y</kbd> can be <kbd>None</kbd> (default) if feeding from framework-native tensors (for example, TensorFlow data tensors).</li>
<li><kbd>batch_size</kbd>: <kbd>Integer</kbd> or <kbd>None</kbd>. This is the number of samples per gradient update. If unspecified, <kbd>batch_size</kbd> will default to <kbd>32</kbd>.</li>
<li><kbd>epochs</kbd>: An Integer. It is the number of epochs to train the model. An epoch is an iteration over the entire <kbd>x</kbd> and <kbd>y</kbd> data provided. Note that in conjunction with <kbd>initial_epoch</kbd>, <kbd>epochs</kbd> is to be understood as the final epoch. The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached.</li>
<li><kbd>shuffle</kbd>: A boolean to decide whether to shuffle the training data before each epoch or <kbd>str</kbd> (for <kbd>batch</kbd>). <kbd>batch</kbd> is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. It has no effect when <kbd>steps_per_epoch</kbd> is anything other than None.</li>
<li><kbd>validation_data</kbd>: A tuple (<kbd>x_val</kbd> and <kbd>y_val</kbd>) or tuple (<kbd>x_val</kbd>, <kbd>y_val</kbd>, and <kbd>val_sample_weights</kbd>) on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. <kbd>validation_data</kbd> will override <kbd>validation_split</kbd>.</li>
</ul>
<p class="mce-root">A <kbd>History</kbd> object is returned. Its <kbd>history.history</kbd> attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).</p>
<p class="mce-root">Our model is now ready, so we can use it to automatically rebuild the handwritten digits. To do this, we will use the <kbd>predict</kbd> method:</p>
<pre class="mce-root">DecodedDigits = AutoencoderModel.predict(x_test)</pre>
<p class="mce-root">This method generates output predictions for the input samples (<kbd>x_test</kbd>). Running this example, you should see a message for each of the 100 epochs, printing the loss and accuracy for each, followed by a final evaluation of the trained model on the training dataset. This is shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/8bf13071-a06e-4ec3-9d31-595c5063f0f2.png"/></div>
<p>To get an idea of how the <kbd>loss</kbd> function varies during the epochs, it can be useful create a plot of loss on the training and validation datasets over training epochs. To do this, we will use the <kbd>Matplotlib</kbd> library as follows:</p>
<pre>plt.plot(history.history['loss'])<br/>plt.plot(history.history['val_loss'])<br/>plt.title('Autoencoder Model loss')<br/>plt.ylabel('loss')<br/>plt.xlabel('epoch')<br/>plt.legend(['train', 'test'], loc='upper left')<br/>plt.show()</pre>
<p>A plot of loss on the training and validation datasets over training epochs is shown in the following graph:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ddd7f4d5-cff7-4b35-8021-5803be3c2b4b.png" style=""/></div>
<p>Our work is done; we just have to verify the results obtained. We can print on screen the starting handwriting digits and those reconstructed from our model. Of course, we will do it only for some of the 60,000 digits contained in the dataset; in fact, we will limit ourselves to display the first five. We will also use the <kbd>Matplotlib</kbd> library <span>in this case</span><span>:</span></p>
<pre>n=5<br/>plt.figure(figsize=(20, 4))<br/>for i in range(n):<br/>    ax = plt.subplot(2, n, i + 1)<br/>    plt.imshow(x_test[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)<br/>    ax = plt.subplot(2, n, i + 1 + n)<br/>    plt.imshow(DecodedDigits[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)<br/>plt.show()</pre>
<p>The results are shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/10667a27-bb86-4860-8a5c-3e006d6b793d.png" style=""/></div>
<div>
<p>As you can see, the result is very close to the original, meaning that the model works well.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Magenta</h1>
                </header>
            
            <article>
                
<div>
<p>On June 1, 2016, Google launched the Magenta project, a research project that aims to allow the creation of art and music in an autonomous way through the use of AI. Based on the TensorFlow platform, Magenta aims to publish code in open source mode on GitHub to allow developers to achieve increasingly striking and advanced results.</p>
<p>The project is a brainchild of the Google Brain team, a deep learning AI research team at Google. It combines open-ended machine learning research with system engineering and Google-scale computing resources.</p>
<p>The Magenta project has set itself two ambitious goals: to develop machine learning for art and music, and to build a community of people interested in this topic. Machine learning has long been used in different contexts, in particular for <span>speech </span>recognition and translation of languages. Magenta was created to concentrate activity on previously unexplored fields such as the generation of art in the broad sense. To do this, Magenta wanted to create a physical place, where all people united by the same interest (that is, generation of art) could exchange ideas and products. In other words, a community of artists, programmers, and researchers of machine learning.</p>
<p>For more information, refer to the official website of the project at the following URL: <a href="https://magenta.tensorflow.org/" target="_blank">https://magenta.tensorflow.org/</a>.</p>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The NSynth dataset</h1>
                </header>
            
            <article>
                
<p>From reading the previous chapters, we have now understood that, to correctly train a machine learning algorithm, it is necessary to have a dataset containing an important number of observations. Recently, the increased use of generative models has been applied to images thanks to the availability of high-quality image datasets, which therefore correspond to a significant data set. With this in mind, the Google Brain team has made NSynth available. It's a large-scale, high-quality set of musical notes that is an order of magnitude larger than comparable public datasets. The aim is to have a significant audio dataset in order to develop generative models with better performance.</p>
<p>The NSynth dataset was introduced by Jesse Engel et al. in the article named <em>Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders</em>.</p>
<p>NSynth is an audio dataset containing 305,979 musical notes, each with a unique tone, tone, and envelope. For 1,006 tools from commercial sample libraries, the Google Brain team generated 4 seconds of 16 kHz monophonic audio fragments, called <strong>notes</strong>, spanning each step of a standard MIDI piano or (21-108) and five different speeds (25, 50, 75, 100, and 127). The note was kept for the first 3 seconds and allowed to fall for the final <span>second</span><span>.</span></p>
<p>The Google Brain team also annotated each of the notes with three additional pieces of information based on a combination of human evaluation and heuristic algorithms:</p>
<ul>
<li><strong>Source</strong>: The method of sound production for the note's instrument. This can be one of acoustic or electronic for instruments that were recorded from acoustic or electronic instruments respectively, or synthetic for synthesized instruments.</li>
<li><strong>Family</strong>: The high-level family of which the note’s instrument is a member. Each instrument is a member of exactly one family.</li>
<li><strong>Qualities</strong>: Sonic qualities of the note. Each note is annotated with zero or more qualities.</li>
</ul>
<p>The NSynth dataset can be downloaded in two formats:</p>
<ul>
<li>TFRecord files of serialized TensorFlow example protocol buffers with one Example proto per note</li>
<li>JSON files containing non-audio features alongside 16-bit PCM WAV audio files</li>
</ul>
<p>The full dataset is split into three sets:</p>
<ul>
<li><strong>Train</strong>: A training set with 289,205 examples. Instruments do not overlap with valid or test.</li>
<li><strong>Valid</strong>: A validation set with 12,678 examples. Instruments do not overlap with train.</li>
<li><strong>Test</strong>: A test set with 4,096 examples. Instruments do not overlap with train.</li>
</ul>
<p>For more information and to download the dataset, refer to the official website of the project at the following URL: <a href="https://magenta.tensorflow.org/datasets/nsynth" target="_blank">https://magenta.tensorflow.org/datasets/nsynth</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we explored one of the most interesting research sites on modeling with neural networks. First we saw an introduction to unsupervised learning algorithms. Unsupervised learning is a machine learning technique that, starting from a series of inputs (system experience), will be able to reclassify and organize on the basis of common characteristics to try to make predictions on subsequent inputs. Unlike supervised learning, only unlabeled examples are provided to the learner during the learning process, as the classes are not known a priori but must be learned automatically.</p>
<p>So, we analyzed different types of generative models. A Boltzmann machine is a probabilistic graphic model that can be interpreted as a stochastic neural network. In practice, a Boltzmann machine is a model (including a certain number of parameters) that, when applied to a data distribution, is able to provide a representation. This model can be used to extract important aspects of an unknown distribution (target distribution) starting only from a sample of the latter.</p>
<p>An autoencoder is a neural network whose purpose is to code its input into small dimensions and the result obtained to be able to reconstruct the input itself. The purpose of autoencoders is not simply to perform a sort of compression of the input or look for an approximation of the identity function; but there are techniques that allow us <span>to direct the model </span>(starting from a hidden layer of reduced dimensions) to give greater importance to some data properties. Thus they give rise to different representations based on the same data.</p>
<p>GAN is a generative model consisting of two networks that are jointly trained, called <strong>generator</strong> and <strong>discriminator</strong>. The dynamics between these two networks is like a forger and an investigator. The forger tries to produce faithful imitations of authentic works of art while the investigator tries to distinguish the fakes from the originals.</p>
<p>Then, we showed how to implement some examples: feature extraction using RBM and autoencoder with Keras. Finally, we introduced the Nsynth dataset and the Google Magenta project.</p>


            </article>

            
        </section>
    </body></html>