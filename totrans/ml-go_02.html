<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Matrices, Probability, and Statistics</h1>
                </header>
            
            <article>
                
<p>Although we will take a mostly practical/applied approach to machine learning throughout this book, certain fundamental topics are essential to understand and properly apply machine learning. In particular, a fundamental understanding of probability and statistics will allow us to match certain algorithms with relevant problems, understand our data and results, and apply necessary transformations to our data. Matrices and a little linear algebra will then allow us to properly represent our data and implement optimizations, minimizations, and matrix-based transformations.</p>
<p>Do not worry too much if you are a little rusty in math or statistics. We will cover a few of the basics here and show you how to programmatically work with the relevant statistical measures and matrix techniques that will be utilized later in the book. That being said, this is not a book on statistics, probability, and linear algebra. To truly be proficient in machine learning, one should take time to learn these subjects on a deeper level.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Matrices and vectors</h1>
                </header>
            
            <article>
                
<p>If you spend much time learning and applying machine learning, you will see a bunch of references to matrices and vectors. In fact, many machine learning algorithms boil down to a series of iterative operations on matrices. What are matrices and vectors, and how do we represent them in our Go programs?</p>
<p>For the most part, we will utilize packages from <kbd>github.com/gonum</kbd> to form and work with matrices and vectors. This is a great series of Go packages focused on numerical computing, and they just keep getting better and better.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Vectors</h1>
                </header>
            
            <article>
                
<p>A vector is an ordered collection of numbers arranged in either a row (left to right) or column (up and down). Each of the numbers in a vector is called a component. This might be, for example, a collection of numbers that represents our company sales, or it might be a collection of numbers representing temperatures.</p>
<p>It's, of course, natural for us to use Go slices to represent these ordered collections of data, as follows:</p>
<pre>// Initialize a "vector" via a slice.<br/>var myvector []float64<br/><br/>// Add a couple of components to the vector.<br/>myvector = append(myvector, 11.0)<br/>myvector = append(myvector, 5.2)<br/><br/>// Output the results to stdout.<br/>fmt.Println(myvector)</pre>
<p>Slices are indeed ordered collections. However, they don't really represent the concept of rows or columns, and we would still need to work out various vector operations on top of slices. Thankfully, on the vector operation side, gonum provides <kbd>gonum.org/v1/gonum/floats</kbd> to operate on slices of <kbd>float64</kbd> values and <kbd>gonum.org/v1/gonum/mat</kbd>, which, along with matrices, provides a <kbd>Vector</kbd> type (with corresponding methods):</p>
<pre>// Create a new vector value.<br/>myvector := mat.NewVector(2, []float64{11.0, 5.2})</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Vector operations</h1>
                </header>
            
            <article>
                
<p>As mentioned here, working with vectors necessitates the use of certain vector-/matrix-specific operations and rules. For example, how do we multiply vectors together? How do we know if two vectors are similar? Both <kbd><span>gonum.org/v1/gonum/floats</span></kbd> <span>and <kbd>gonum.org/v1/gonum/mat</kbd></span> <span>provide built-in methods and functions for vector/slice operations, such as dot products, sorting, and distance. We won't cover all of the functionality here, as there is quite a bit, but we can get a general feel for how we might work with vectors. First, we can work with <kbd>gonum.org/v1/gonum/floats</kbd></span> in the following way<span>:</span></p>
<pre>// Initialize a couple of "vectors" represented as slices.<br/>vectorA := []float64{11.0, 5.2, -1.3}<br/>vectorB := []float64{-7.2, 4.2, 5.1}<br/><br/>// Compute the dot product of A and B<br/>// (https://en.wikipedia.org/wiki/Dot_product).<br/>dotProduct := floats.Dot(vectorA, vectorB)<br/>fmt.Printf("The dot product of A and B is: %0.2f\n", dotProduct)<br/><br/>// Scale each element of A by 1.5.<br/>floats.Scale(1.5, vectorA)<br/>fmt.Printf("Scaling A by 1.5 gives: %v\n", vectorA)<br/><br/>// Compute the norm/length of B.<br/>normB := floats.Norm(vectorB, 2)<br/>fmt.Printf("The norm/length of B is: %0.2f\n", normB)</pre>
<p>We can also do similar operations with <kbd><span>gonum.org/v1/gonum/mat</span></kbd><span>:</span></p>
<pre>// Initialize a couple of "vectors" represented as slices.<br/>vectorA := mat.NewVector(3, []float64{11.0, 5.2, -1.3})<br/>vectorB := mat.NewVector(3, []float64{-7.2, 4.2, 5.1})<br/><br/>// Compute the dot product of A and B<br/>// (https://en.wikipedia.org/wiki/Dot_product).<br/>dotProduct := mat.Dot(vectorA, vectorB)<br/>fmt.Printf("The dot product of A and B is: %0.2f\n", dotProduct)<br/><br/>// Scale each element of A by 1.5.<br/>vectorA.ScaleVec(1.5, vectorA)<br/>fmt.Printf("Scaling A by 1.5 gives: %v\n", vectorA)<br/><br/>// Compute the norm/length of B.<br/>normB := blas64.Nrm2(3, vectorB.RawVector())<br/>fmt.Printf("The norm/length of B is: %0.2f\n", normB)</pre>
<p>The semantics are similar in the two cases. If you are only working with vectors (not matrices), and/or you just need some lightweight and quick operations on slices of floats, then <kbd><span>gonum.org/v1/gonum/floats</span></kbd> <span>is likely a good choice. However, if you are working with both matrices and vectors, and/or want access to a wider range of vector/matrix functionality, you are likely better off with <kbd>gonum.org/v1/gonum/mat</kbd> (along with occasional references to <kbd>gonum.org/v1/gonum/blas/blas64</kbd>).</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Matrices</h1>
                </header>
            
            <article>
                
<p class="CDPAlignLeft CDPAlign">Matrices and linear algebra may seem complicated to many people, but simply put, matrices are just rectangular organizations of numbers, and linear algebra dictates the rules associated with their manipulation. For example, a matrix <em>A</em> with numbers arranged on a 4 x 3 rectangle may look like this:</p>
<div style="padding-left: 150px" class="mce-root CDPAlignLeft CDPAlign"><img height="76" width="187" src="assets/9c09508b-58b4-4c41-a8af-1ef689c8f4e1.png"/></div>
<p>The components of <em>A</em> (<em>a<sub>11</sub></em>, <em>a<sub>12</sub></em>, and so on) are the individual numbers that we are arranging into a matrix, and the subscripts indicate the location of the components within the matrix. The first index is the row index and the second index is the column index. More generally, <em>A</em> could have any shape/size with <em>M</em> rows and <em>N</em> columns:</p>
<div style="padding-left: 150px" class="mce-root CDPAlignLeft CDPAlign"><img height="99" width="207" src="assets/a3c91fdb-9642-46a9-b5e2-7b20f017b80e.png"/></div>
<p>To form a matrix like this with <kbd><span>gonum.org/v1/gonum/mat</span></kbd><span>, we need to create a slice of <kbd>float64</kbd> values that is a flat representation of all the matrix components. For instance, in our example, we want to form the following matrix:</span></p>
<div style="padding-left: 180px" class="mce-root CDPAlignLeft CDPAlign"><img height="52" width="150" src="assets/bb87521a-251b-4b5a-bd63-b35efd6d4df8.png"/></div>
<p><span>We would need to create a slice of <kbd>float64</kbd> values as follows:</span></p>
<pre>// Create a flat representation of our matrix.<br/>components := []float64{1.2, -5.7, -2.4, 7.3}</pre>
<p>Then, we can supply this, along with dimension information, to <span><kbd>gonum.org/v1/gonum/mat</kbd></span> <span>to form a new <kbd>mat.Dense</kbd> matrix value:<br/></span></p>
<pre>// Form our matrix (the first argument is the number of<br/>// rows and the second argument is the number of columns).<br/>a := mat.NewDense(2, 2, data)<br/><br/>// As a sanity check, output the matrix to standard out.<br/>fa := mat.Formatted(a, mat.Prefix(" "))<br/>fmt.Printf("mat = %v\n\n", fa)</pre>
<p>Note that we have also used the nice formatting logic in <kbd><span>gonum.org/v1/gonum/mat</span></kbd> to print the matrix as a sanity check. When you run this, you should see the following:</p>
<pre><strong>$ go build</strong><br/><strong>$ ./myprogram</strong><br/><strong>A = [ 1.2 -5.7]   </strong><br/><strong>    [-2.4  7.3]</strong></pre>
<p>We can then access and modify certain values within <em>A</em> via built-in methods:</p>
<pre>// Get a single value from the matrix.<br/>val := a.At(0, 1)<br/>fmt.Printf("The value of a at (0,1) is: %.2f\n\n", val)<br/><br/>// Get the values in a specific column.<br/>col := mat.Col(nil, 0, a)<br/>fmt.Printf("The values in the 1st column are: %v\n\n", col)<br/><br/>// Get the values in a kspecific row.<br/>row := mat.Row(nil, 1, a)<br/>fmt.Printf("The values in the 2nd row are: %v\n\n", row)<br/><br/>// Modify a single element.<br/>a.Set(0, 1, 11.2)<br/><br/>// Modify an entire row.<br/>a.SetRow(0, []float64{14.3, -4.2})<br/><br/>// Modify an entire column.<br/>a.SetCol(0, []float64{1.7, -0.3})</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Matrix operations</h1>
                </header>
            
            <article>
                
<p>As with vectors, matrices have their own set of rules for arithmetic, along with a whole set of special operations. Some of the arithmetic associated with matrices behaves in a similar way to what you might expect. However, you need to take special care when doing things such as multiplying matrices together or taking an inverse.</p>
<p>Conveniently, <kbd><span>gonum.org/v1/gonum/mat</span></kbd> <span>provides a nice API for this arithmetic and many other special operations. Here is an example showing a few operations, such as adding, multiplying, dividing, and so on:</span></p>
<pre>// Create two matrices of the same size, a and b.
a := mat.NewDense(3, 3, []float64{1, 2, 3, 0, 4, 5, 0, 0, 6})
b := mat.NewDense(3, 3, []float64{8, 9, 10, 1, 4, 2, 9, 0, 2})

// Create a third matrix of a different size.
c := mat.NewDense(3, 2, []float64{3, 2, 1, 4, 0, 8})

// Add a and b.
d := mat.NewDense(0, 0, nil)
d.Add(a, b)
fd := mat.Formatted(d, mat.Prefix("            "))
fmt.Printf("d = a + b = %0.4v\n\n", fd)

// Multiply a and c.
f := mat.NewDense(0, 0, nil)
f.Mul(a, c)
ff := mat.Formatted(f, mat.Prefix("          "))
fmt.Printf("f = a c = %0.4v\n\n", ff)

// Raising a matrix to a power.
g := mat.NewDense(0, 0, nil)
g.Pow(a, 5)
fg := mat.Formatted(g, mat.Prefix("          "))
fmt.Printf("g = a^5 = %0.4v\n\n", fg)

// Apply a function to each of the elements of a.
h := mat.NewDense(0, 0, nil)
sqrt := func(_, _ int, v float64) float64 { return math.Sqrt(v) }
h.Apply(sqrt, a)
fh := mat.Formatted(h, mat.Prefix("              "))
fmt.Printf("h = sqrt(a) = %0.4v\n\n", fh)</pre>
<p>In particular, note the <kbd>Apply()</kbd> method above. This functionality is extremely useful as it allow you to apply any function to the elements of a matrix. You can apply the same function to all elements or make the function dependent on the indices of the matrix elements. For example, you could you this method to perform element-wise multiplications, applications of user defined functions, or applications of functions from third party packages.</p>
<p>Then, for all the various things, such as determinants, eigenvalue/vector solvers, and inverses, <kbd><span>gonum.org/v1/gonum/mat</span></kbd> <span>has you covered. Again, I won't expand on all of the functionality, but here is a sample of some of the operations:</span></p>
<pre>// Create a new matrix a.<br/>a := mat.NewDense(3, 3, []float64{1, 2, 3, 0, 4, 5, 0, 0, 6}) <br/><br/>// Compute and output the transpose of the matrix.<br/>ft := mat.Formatted(a.T(), mat.Prefix(" "))<br/>fmt.Printf("a^T = %v\n\n", ft)<br/><br/>// Compute and output the determinant of a.<br/>deta := mat.Det(a)<br/>fmt.Printf("det(a) = %.2f\n\n", deta)<br/><br/>// Compute and output the inverse of a.<br/>aInverse := mat.NewDense(0, 0, nil)<br/>if err := aInverse.Inverse(a); err != nil {<br/>    log.Fatal(err)<br/>}<br/>fi := mat.Formatted(aInverse, mat.Prefix(" "))<br/>fmt.Printf("a^-1 = %v\n\n", fi)</pre>
<p>Note that in this example, we leverage Go's explicit error handling functionality when we need to ensure that we are maintaining integrity and readability. Matrices don't always have inverses. There are various situations like this that arise when working with matrices and large datasets, and we want to ensure that our application behaves as expected.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Statistics</h1>
                </header>
            
            <article>
                
<p>At the end of the day, the success of your machine learning application is going to come down to the quality of your data, your understanding of the data, and your evaluation/validation of the results. All three of these things require us to have an understanding of statistics.</p>
<p>The field of statistics helps us to gain an understanding of our data, and to quantify what our data and results look like. It also provides us with mechanisms to measure how well our application is performing and prevent certain machine learning pitfalls (such as overfitting).</p>
<p>As with linear algebra, we aren't able to give a complete introduction to statistics here, but there are many resources online and in print to learn introductory statistics. Here we will focus on a fundamental understanding of the basics, along with the practicalities of implementation in Go. We will introduce the idea of distributions, along with an introduction to quantifying and visualizing these distributions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Distributions</h1>
                </header>
            
            <article>
                
<p>A distribution is a representation of how often values appear within a dataset. Let's say, for instance, that one thing you are tracking as a data scientist is the daily sales of a certain product or service, and you have a long list (which you could represent as a vector or part of a matrix) of these daily sales numbers. These sales numbers are part of our dataset, and they include one day with sales of $121, another day with sales of $207, and so on.</p>
<p>There will be one sales number that is the lowest out of the one we have accumulated. There will also be one sales number that is the highest out of the one we have accumulated, and the rest of the sales numbers that are somewhere in between (at least if we assume no exact duplicates). The following image represents these low, high, and in-between values of sales along a line:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="232" width="1168" class="alignnone size-full wp-image-513 image-border" src="assets/15145fdc-66d2-468c-b2f8-2fe1fc9eabea.png"/></div>
<p>This is, thus, a distribution of sales, or at least one representation of the distribution of sales. Note that this distribution has areas where there are more numbers and areas where the numbers are a little sparse. Additionally, note that there seems to be a tendency for numbers to be near the center of the distribution.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Statistical measures</h1>
                </header>
            
            <article>
                
<p>To quantify what a distribution looks like, we will use various statistical measures. Generally, there are two types of these measures:</p>
<ol>
<li><strong>Central tendency measures</strong>: These measure where most of the values are located, or where the <em>center</em> of the distribution is located (for example, along the preceding linear representation).</li>
<li><strong>Spread or dispersion measures</strong>: These measure how the values of the distribution are spread across the distribution's range (from the lowest value to the highest value).</li>
</ol>
<p>There are various packages that allow you to quickly calculate and/or utilize these statistical measures. We will make use of <kbd><span>gonum.org/v1/gonum/stat</span></kbd> (you are probably starting to notice that we will be making heavy use of gonum) and <kbd>github.com/montanaflynn/stats</kbd>.</p>
<div class="packt_tip">Note, there is a one letter difference in the names of the <kbd><span>gonum.org/v1/gonum/stat</span></kbd> <span>and</span> <kbd>github.com/montanaflynn/stats</kbd> <span>packages. Keep this in mind as you review the examples in the following sections.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Measures of central tendency</h1>
                </header>
            
            <article>
                
<p>Measures of central tendency include the following:</p>
<ul>
<li><kbd>Mean</kbd>: This is what you might commonly refer to as an average. We calculate this by summing all of the numbers in the distribution and then dividing by the count of the numbers.</li>
<li><kbd>Median</kbd>: If we sort all of the numbers in our distribution from the lowest to highest, this is the number that separates the lowest half of the numbers from the highest half of the numbers.</li>
<li><kbd>Mode</kbd>: This is the most frequently occurring value in the distribution.</li>
</ul>
<p>Let's calculate these measures for the values in one column of the iris dataset previously introduced in <a href="4f556f8e-6876-48ca-9ac5-f897b733e23e.xhtml" target="_blank">Chapter 1</a>, <em>Gathering and Organizing Data</em>. As a reminder, this dataset included four columns of flower measurements, along with a column of the corresponding flower species. Thus, each of the measurement columns includes a bunch of values that represent a distribution of that measurement:</p>
<pre>// Open the CSV file.<br/>irisFile, err := os.Open("../data/iris.csv")<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/>defer irisFile.Close()<br/><br/>// Create a dataframe from the CSV file.<br/>irisDF := dataframe.ReadCSV(irisFile)<br/><br/>// Get the float values from the "sepal_length" column as<br/>// we will be looking at the measures for this variable.<br/>sepalLength := irisDF.Col("sepal_length").Float()<br/><br/>// Calculate the Mean of the variable.<br/>meanVal := stat.Mean(sepalLength, nil)<br/><br/>// Calculate the Mode of the variable.<br/>modeVal, modeCount := stat.Mode(sepalLength, nil)<br/><br/>// Calculate the Median of the variable.<br/>medianVal, err := stats.Median(sepalLength)<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/><br/>// Output the results to standard out.<br/>fmt.Printf("\nSepal Length Summary Statistics:\n")<br/>fmt.Printf("Mean value: %0.2f\n", meanVal)<br/>fmt.Printf("Mode value: %0.2f\n", modeVal)<br/>fmt.Printf("Mode count: %d\n", int(modeCount))<br/>fmt.Printf("Median value: %0.2f\n\n", medianVal)</pre>
<p>Running this program results in the following:</p>
<pre><strong>$ go build</strong><br/><strong>$ ./myprogram</strong><br/><br/><strong>Sepal Length Summary Statistics:</strong><br/><strong>Mean value: 5.84</strong><br/><strong>Mode value: 5.00</strong><br/><strong>Mode count: 10</strong><br/><strong>Median value: 5.80</strong></pre>
<p>You can see that the mean, mode, and median are all slightly different. However, note that the mean and median are very close for the values in the <kbd>sepal_length</kbd> column.</p>
<p>On the other hand, if we change <kbd>sepal_length</kbd> to <kbd>petal_length</kbd> in the preceding code, we will get the following results:</p>
<pre><strong>$ go build</strong><br/><strong>$ ./myprogram</strong><br/><br/><strong>Sepal Length Summary Statistics:</strong><br/><strong>Mean value: 3.76</strong><br/><strong>Mode value: 1.50</strong><br/><strong>Mode count: 14</strong><br/><strong>Median value: 4.35</strong></pre>
<p>For the <kbd>petal_length</kbd> values, the mean and median are not as close. We can already start to get some intuition about the data from this information. If the mean and median aren't close, this implies that high or low values are dragging the mean higher or lower, respectively--an influence that isn't as noticeable in the median. We call this a <strong>skewed</strong> <strong>distribution</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Measures of spread or dispersion</h1>
                </header>
            
            <article>
                
<p>Now that we have an idea about where most of our values are located (or the center of our distribution), let's try to quantify how the values of our distribution are spread around the center of our distribution. Some of the widely used measures that quantify this are as follows:</p>
<ul>
<li><strong>Maximum</strong>: The highest value of the distribution</li>
<li><strong>Minimum</strong>: The lowest value of the distribution</li>
<li><strong>Range</strong>: The difference between the maximum and minimum</li>
<li><strong>Variance</strong>: This measure is calculated by taking each of the values in the distribution, calculating each one's difference from the distribution's mean, squaring this difference, adding it to the other squared differences, and dividing by the number of values in the distribution</li>
<li><strong>Standard deviation</strong>: The square root of the variance</li>
<li><strong>Quantiles/quartiles</strong>: Similar to the median, these measures define cut-off points in the distribution where a certain number of lower values are below the measure and a certain number of higher values are above the measure</li>
</ul>
<p>Using <kbd><span>gonum.org/v1/gonum/stat</span></kbd><span>, the calculation of these measures looks as follows:</span></p>
<pre>// Open the CSV file.<br/>irisFile, err := os.Open("../data/iris.csv")<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/>defer irisFile.Close()<br/><br/>// Create a dataframe from the CSV file.<br/>irisDF := dataframe.ReadCSV(irisFile)<br/><br/>// Get the float values from the "sepal_length" column as<br/>// we will be looking at the measures for this variable.<br/>sepalLength := irisDF.Col("petal_length").Float()<br/><br/>// Calculate the Max of the variable.<br/>minVal := floats.Min(sepalLength)<br/><br/>// Calculate the Max of the variable.<br/>maxVal := floats.Max(sepalLength)<br/><br/>// Calculate the Median of the variable.<br/>rangeVal := maxVal - minVal<br/><br/>// Calculate the variance of the variable.<br/>varianceVal := stat.Variance(sepalLength, nil)<br/><br/>// Calculate the standard deviation of the variable.<br/>stdDevVal := stat.StdDev(sepalLength, nil)<br/><br/>// Sort the values.<br/>inds := make([]int, len(sepalLength))<br/>floats.Argsort(sepalLength, inds)<br/><br/>// Get the Quantiles.<br/>quant25 := stat.Quantile(0.25, stat.Empirical, sepalLength, nil)<br/>quant50 := stat.Quantile(0.50, stat.Empirical, sepalLength, nil)<br/>quant75 := stat.Quantile(0.75, stat.Empirical, sepalLength, nil)<br/><br/>// Output the results to standard out.<br/>fmt.Printf("\nSepal Length Summary Statistics:\n")<br/>fmt.Printf("Max value: %0.2f\n", maxVal)<br/>fmt.Printf("Min value: %0.2f\n", minVal)<br/>fmt.Printf("Range value: %0.2f\n", rangeVal)<br/>fmt.Printf("Variance value: %0.2f\n", varianceVal)<br/>fmt.Printf("Std Dev value: %0.2f\n", stdDevVal)<br/>fmt.Printf("25 Quantile: %0.2f\n", quant25)<br/>fmt.Printf("50 Quantile: %0.2f\n", quant50)<br/>fmt.Printf("75 Quantile: %0.2f\n\n", quant75)</pre>
<p>Running this program gives the following result:</p>
<pre><strong>$ go build</strong><br/><strong>$ ./myprogram</strong><br/><br/><strong>Sepal Length Summary Statistics:</strong><br/><strong>Max value: 6.90</strong><br/><strong>Min value: 1.00</strong><br/><strong>Range value: 5.90</strong><br/><strong>Variance value: 3.11</strong><br/><strong>Std Dev value: 1.76</strong><br/><strong>25 Quantile: 1.60</strong><br/><strong>50 Quantile: 4.30</strong><br/><strong>75 Quantile: 5.10</strong></pre>
<p>Okay, let's try to get through these numbers and see what they imply about the distribution of values in the <kbd>sepal_length</kbd> column. We can deduce the following.</p>
<p>First, the standard deviation is <kbd>1.76</kbd> and the whole range of values is <kbd>5.90</kbd>. As opposed to the variance, the standard deviation has the same units as the values themselves, and thus we can see that the values actually vary quite a bit within the range of values (the standard deviation value is about 30% of the total range of values).</p>
<p>Next, let's look at the quantiles. The 25% quantile represents a point in the distribution where 25% of the values in the distribution are below the measure and the other 75% are above. This is similar for the 50% and 75% quantiles. As the 25% quantile is much closer to the minimum than the distance between the 75% quantile and the maximum, we can deduce that the higher values in the distribution are likely more spread out than the lower values.</p>
<p>Of course, you can utilize any combination of these measures, along with the central tendency measures, to help you quantify how a distribution looks, and there are other statistical measures that can't be covered here.</p>
<div class="packt_tip">The point here is that you should be making use of measures like these to help you build mental models of your data. This will allow you to put results in context and sanity-check your work.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Visualizing distributions</h1>
                </header>
            
            <article>
                
<p>Even though it is important to quantify how a distribution looks, we should actually visualize the distribution to gain the most intuition. There are various types of plots and graphs that allow us to create a visual representation of a distribution of values. These help us form a mental model of the data and communicate information about our data to other members of our team, users of our applications, and so on.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Histograms</h1>
                </header>
            
            <article>
                
<p>The first type of these graphs or charts that help us understand our distributions is called a <strong>histogram</strong>. Actually, a histogram is really a certain way of organizing or counting your values, which can then be plotted in a histogram plot. To form a histogram, we first create a certain number of bins, carving out different areas of the total range of our values. For example, take the distribution of sales numbers that we discussed in the previous sections:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="121" width="565" class="alignnone size-full wp-image-514 image-border" src="assets/bad47dc3-012f-43af-a67f-fb75d8e3913a.png"/></div>
<p>Next, we count how many of our values are in each of these bins:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="115" width="586" class="alignnone size-full wp-image-515 image-border" src="assets/39fcec2e-af90-4cff-bf18-a6cb10ac9113.png"/></div>
<p class="CDPAlignLeft CDPAlign">These counts, along with the definition of the bins, form our histogram. We can then easily convert this to a plot of the counts, which provides a nice visual representation of our distribution:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="158" width="297" class="alignnone size-full wp-image-516 image-border" src="assets/0c7f0414-810c-45cb-bf42-1d29b2923a7a.png"/></div>
<p class="CDPAlignLeft CDPAlign">We can again use gonum to create a histogram from actual data and plot the histogram. The packages that gonum provides for this type of plotting, along with other types of plotting, can be found in <kbd>gonum.org/v1/plot</kbd>. As an example, let's create a histogram plot for each of the columns in the iris dataset.</p>
<p class="CDPAlignLeft CDPAlign">First, import the following from gonum:</p>
<pre class="CDPAlignLeft CDPAlign">import (<br/>    "gonum.org/v1/plot"<br/>    "gonum.org/v1/plot/plotter"<br/>    "gonum.org/v1/plot/vg"<br/>)</pre>
<p class="CDPAlignLeft CDPAlign">Then we will read in the iris dataset, create a dataframe, and look over the numerical columns generating the histogram plots:</p>
<pre class="CDPAlignLeft CDPAlign">// Open the CSV file.<br/>irisFile, err := os.Open("../data/iris.csv")<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/>defer irisFile.Close()<br/><br/>// Create a dataframe from the CSV file.<br/>irisDF := dataframe.ReadCSV(irisFile)<br/><br/>// Create a histogram for each of the feature columns in the dataset.<br/>for _, colName := range irisDF.Names() {<br/><br/>    // If the column is one of the feature columns, let's create<br/>    // a histogram of the values.<br/>    if colName != "species" {<br/><br/>        // Create a plotter.Values value and fill it with the<br/>        // values from the respective column of the dataframe.<br/>        v := make(plotter.Values, irisDF.Nrow())<br/>        for i, floatVal := range irisDF.Col(colName).Float() {<br/>            v[i] = floatVal<br/>        }<br/><br/>        // Make a plot and set its title.<br/>        p, err := plot.New()<br/>        if err != nil {<br/>            log.Fatal(err)<br/>        }<br/>        p.Title.Text = fmt.Sprintf("Histogram of a %s", colName)<br/><br/>        // Create a histogram of our values drawn<br/>        // from the standard normal.<br/>        h, err := plotter.NewHist(v, 16)<br/>        if err != nil {<br/>            log.Fatal(err)<br/>        }<br/><br/>        // Normalize the histogram.<br/>        h.Normalize(1)<br/><br/>        // Add the histogram to the plot.<br/>        p.Add(h)<br/> <br/>        // Save the plot to a PNG file.<br/>        if err := p.Save(4*vg.Inch, 4*vg.Inch, colName+"_hist.png"); err != nil {<br/>            log.Fatal(err)<br/>        }<br/>    }<br/>}</pre>
<p>Note that we have normalized our histograms (with <kbd>h.Normalize()</kbd>). This is typical because often you will want to compare different distributions with different counts of values. Normalizing the histogram allows us to compare the different distributions side by side.</p>
<p>The preceding code will generate four <kbd>*.png</kbd> files with the following histograms for the numerical columns in the iris dataset:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="499" width="510" class="alignnone size-full wp-image-517 image-border" src="assets/0ad2584e-4871-43cd-ae40-3f220b1b394c.png"/></div>
<p>Each of these distributions looks different from the others. The <kbd>sepal_width</kbd> distribution looks like a bell curve or normal/Gaussian distribution (which we will discuss later in the book). On the other hand, the petal distributions look like they have two different distinct clumps of values. We will make use of these observations later on when we are developing our machine learning workflows, but for now, just note how these visualizations are able to help us develop a mental model of our data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Box plots</h1>
                </header>
            
            <article>
                
<p>Histograms are by no means the only way to visually gain an understanding of our data. Another commonly used type of plot is called a <strong>box plot</strong>. This type of plot also gives us an idea about the grouping and spread of values in a distribution, but, as opposed to the histogram, the box plot has several marked features that help guide our eyes:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="360" width="557" class="alignnone size-full wp-image-518 image-border" src="assets/f966ccf5-2b63-4ec6-a01b-b7f5cc7b5fb6.png"/></div>
<p><span>Because</span> the borders of the boxes in the box plots are defined by the median, <strong>first quartile</strong> (25% quantile/percentile), and <strong>third quartile</strong>, the same number of distribution values that are contained in the two central boxes. If one box is bigger than the other, it means that the distribution is skewed.</p>
<p>The box plots also include two tails or whiskers. These give us a quick visual indication of the range of the distribution as compared to the area that includes most of the values (the middle 50%).</p>
<p>To solidify this type of plot, let's again create plots for the iris dataset. Similar to the histograms, we will use <kbd>gonum.org/v1/plot</kbd><span>. However, in this case, we will put all the box plots into the same <kbd>*.png</kbd>:</span></p>
<pre>// Open the CSV file.<br/>irisFile, err := os.Open("../data/iris.csv")<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/>defer irisFile.Close()<br/><br/>// Create a dataframe from the CSV file.<br/>irisDF := dataframe.ReadCSV(irisFile)<br/><br/>// Create the plot and set its title and axis label.<br/>p, err := plot.New()<br/>if err != nil {<br/>    log.Fatal(err)<br/>}<br/><br/>p.Title.Text = "Box plots"<br/>p.Y.Label.Text = "Values"<br/><br/>// Create the box for our data.<br/>w := vg.Points(50)<br/><br/>// Create a box plot for each of the feature columns in the dataset.<br/>for idx, colName := range irisDF.Names() {<br/><br/>    // If the column is one of the feature columns, let's create<br/>    // a histogram of the values.<br/>    if colName != "species" {<br/><br/>        // Create a plotter.Values value and fill it with the<br/>        // values from the respective column of the dataframe.<br/>        v := make(plotter.Values, irisDF.Nrow())<br/>        for i, floatVal := range irisDF.Col(colName).Float() {<br/>            v[i] = floatVal<br/>        }<br/><br/>        // Add the data to the plot.<br/>        b, err := plotter.NewBoxPlot(w, float64(idx), v)<br/>        if err != nil {<br/>            log.Fatal(err)<br/>        }<br/>        p.Add(b)<br/>    }<br/>}<br/><br/>// Set the X axis of the plot to nominal with<br/>// the given names for x=0, x=1, etc.<br/>p.NominalX("sepal_length", "sepal_width", "petal_length", "petal_width")<br/><br/>if err := p.Save(6*vg.Inch, 8*vg.Inch, "boxplots.png"); err != nil {<br/>    log.Fatal(err)<br/>}</pre>
<p>This will generate the following figure:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img height="469" width="351" class="alignnone size-full wp-image-519 image-border" src="assets/f089ea36-f5fb-4abf-91e2-d30e895c8f71.png"/></div>
<p class="CDPAlignLeft CDPAlign">As we observed in the histograms, the <kbd>sepal_length</kbd> column appears to be relatively symmetrical. On the other hand, <kbd>petal_length</kbd> appears to be much less symmetrical. Note also that gonum has included several outliers (marked as circles or dots) in the box plots. Many plotting packages include these. They indicate the values that are at least a certain distance away from the median of the distribution.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Probability</h1>
                </header>
            
            <article>
                
<p>At this point, we now understand a couple of ways to represent/manipulate our data (matrices and vectors), and we know how to gain and understanding about our data, and how to quantify how our data looks (statistics). However, sometimes when we are developing machine learning applications, we also want to know how likely it is that a prediction is correct or how significant certain results are, given a history of results. Probability can help us answer these <em>how likely</em> and <em>how significant</em> questions.</p>
<p>Generally, probability has to do with the likelihood of events or observations. For example, if we are going to flip a coin to make a decision, how likely is it that we would see heads (50%), how likely is it that we would see tails (50%), or even how likely is it that the coin is a fair coin? This might seem like a trivial example, but many similar questions come up when doing machine learning. In fact, some machine learning algorithms are built on probabilistic rules and theorems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random variables</h1>
                </header>
            
            <article>
                
<p>Let's say that we have an experiment, like our scenario of flipping the coin, which could have multiple outcomes (heads or tails). Now let's define a variable whose value could be one of these outcomes. This variable is referred to as a <strong>random variable</strong>.</p>
<p>In the case of the coin toss (at least if we are considering a fair coin), each of the outcomes of the random variable is equally likely. That is, we have a 50% chance of seeing a heads outcome and a 50% chance of seeing a tails outcome. Yet, the various values of the random variable need not be equally likely. If we are trying to predict whether it will rain or not, those outcomes will not be equally likely.</p>
<p>Random variables allow us to define these how likely and how significant sort of questions that we mentioned earlier. They can have a finite number of outcomes and/or could represent ranges of continuous variables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Probability measures</h1>
                </header>
            
            <article>
                
<p>So how likely is it that we observe a specific outcome of an experiment? Well, to quantify the answer to this question, we introduce <strong>probability measures</strong>, which are often referred to as probabilities. They are represented by a number between 0 and 1 and/or by a percentage between 0% and 100%.</p>
<p>In the case of flipping a fair coin, we have the following scenario:</p>
<ul>
<li>There is a 0.5 or 50% chance, or probability, of heads, where 0.5 or 50% is a probability measure</li>
<li>There is a 0.5 or 50% chance of tails</li>
</ul>
<p>Probability measures for a certain experiment must add up to 1 because when an event occurs, it has to correspond to one of the possible outcomes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Independent and conditional probability</h1>
                </header>
            
            <article>
                
<p>Two events (outcomes of experiments) are independent if the probability of one of the events in no way affects the probability of the other events. An example of independent events is the flipping of coins or the rolling of dice. On the other hand, dependent events are those events where the probability of one event influences the probability of another event. An example of dependent events is drawing cards from a deck of cards without replacement.</p>
<p>How can we quantify this second type of probability, which is commonly referred to as conditional probability? Symbolically, independent probabilities can be represented by <em>P(A)</em>, which is the probability of <em>A</em> (where <em>A</em> could represent flipping a coin, rolling a die, and so on). Then conditional probabilities are represented by <em>P(B|A)</em>, which is the probability of <em>A</em> given <em>B</em> (where <em>B</em> is another outcome).</p>
<p>To actually calculate a conditional probability, we can use the Bayes theorem/rule: <em>P(A|B) = P(B|A) P(A) / P(B)</em>. Sometimes you will see these terms defined as follows:</p>
<ul>
<li><em>P(A|B)</em>: The <em>posterior</em>, because it is something we know about <em>A</em> after observing <em>B</em></li>
<li><em>P(A)</em>: The <em>prior</em>, because it is data we have about <em>A</em> before observing <em>B</em></li>
<li><em>P(B|A)</em>: The <em>likelihood</em>, because it is a measure of the compatibility of <em>B</em> with <em>A</em></li>
<li><em>P(B)</em>: The <em>evidence</em>, because it measures the probability of <em>B</em>, which we already know is true</li>
</ul>
<p>This theorem is the basis for various techniques that will be discussed later in the book, such as the naive the Bayes technique for classification.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Hypothesis testing</h1>
                </header>
            
            <article>
                
<p>We can quantify <em>how likely</em> questions with probabilities and can even calculate conditional probabilities with Bayes theorem, but how can we quantify <em>how significant</em> questions that correspond to real-world observations? For example, we can quantify the probability of heads/tails with a fair coin, but how can we determine <em>how significant</em> it is when we flip a coin a bunch of times and observe 48% heads and 52% tails? Is this significant? Does it mean that we have an unfair coin?</p>
<p>These <em>how significant</em> questions can be answered using a process called hypothesis testing. This process generally includes the following steps:</p>
<ol>
<li>Formulate a <strong>null hypothesis</strong>, referred to as <em>H<sub>0</sub></em>, and an <strong>alternate hypothesis</strong>, referred to as <em>H<sub>a</sub></em>. <em>H<sub>0</sub></em> represents the scenario where what you observe (for example, 48% heads and 52% tails) is the result of pure chance, whereas <em>H<sub>a</sub></em> represents the scenario where some type of underlying effect is causing significant deviation from pure chance (for example, an unfair coin). The null hypothesis is always assumed to be true.</li>
<li>Determine a <strong>test statistic</strong> that you will use to determine the validity of <em>H<sub>0</sub>.</em></li>
<li>Determine a <strong>p-value</strong>, which indicates the probability of observing a test statistic at least as significant as your test statistic assuming that <em>H<sub>0</sub></em> is true. This p-value can be obtained from a probability distribution corresponding to the test statistic (often represented as a table or distribution function).</li>
<li>Compare your p-value with a predetermined threshold. If the p-value is less or equal to the predetermined threshold, <em>H<sub>0</sub></em> is ruled out in favor of <em>H<sub>a</sub></em>.</li>
</ol>
<p>This might seem rather abstract, but this process will intersect with your machine learning workflows at some point. For example, you may change one of your machine learning models that optimizes advertisements, and then you may want to quantify if an increase in sales is actually statistically significant. In another scenario, you may be analyzing logs representing possible fraudulent network traffic, and you might need to build a model that recognizes statistically significant deviations from expected network traffic.</p>
<div class="packt_infobox">Note that you may also see certain hypothesis tests referred to as A/B tests, and, although the process listed here is common, it is by no means the only methodology for hypothesis testing. There are methods for Bayesian A/B testing, bandit algorithms for optimization, and more, which won't be covered in detail in this book.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Test statistics</h1>
                </header>
            
            <article>
                
<p>There are many different test statistics that can be used in hypothesis testing. These include the Z-statistic, T-statistic, F-statistic, and chi-square statistic. You can, of course, implement these measures from scratch in Go without too much trouble. However, there are also some pre-existing implementations that you can use.</p>
<p>Returning to <kbd><span>gonum.org/v1/gonum/stat</span></kbd>, we can calculate a chi-square statistic as follows:</p>
<pre>// Define observed and expected values. Most<br/>// of the time these will come from your<br/>// data (website visits, etc.).<br/>observed := []float64{48, 52}<br/>expected := []float64{50, 50}<br/><br/>// Calculate the ChiSquare test statistic.<br/>chiSquare := stat.ChiSquare(observed, expected)</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Calculating p-values</h1>
                </header>
            
            <article>
                
<p>Let's say that we have the following scenario:</p>
<div class="packt_quote">A survey of local residents reveals that 60% of all residents get no regular exercise, 25% exercise sporadically, and 15% exercise regularly. After doing some fancy modeling and putting some community services in place, the survey was repeated with the same questions. The follow up survey was completed by 500 residents with the following results:<br/>
<br/>
No Regular Exercise: 260<br/>
Sporadic Exercise: 135<br/>
Regular Exercise: 105<br/>
Total: 500</div>
<p>Now, we want to determine if there is evidence for a statistically significant shift in the responses of the residents. Our null and alternate hypotheses are as follows:</p>
<ul>
<li><em>H<sub>0</sub></em>: The deviations from the previously observed percentages are due to pure chance</li>
<li><em>H<sub>a</sub></em>: The deviations are due to some underlying effect outside of pure chance (possibly our new community services)</li>
</ul>
<p>First, let's calculate our test statistic using the chi-square test statistic:</p>
<pre>// Define the observed frequencies.<br/>observed := []float64{<br/>    260.0, // This number is the number of observed with no regular exercise.<br/>    135.0, // This number is the number of observed with sporatic exercise.<br/>    105.0, // This number is the number of observed with regular exercise.<br/>} <br/>    <br/>// Define the total observed.<br/>totalObserved := 500.0<br/>    <br/>// Calculate the expected frequencies (again assuming the null Hypothesis).<br/>expected := []float64{<br/>    totalObserved * 0.60,<br/>    totalObserved * 0.25,<br/>    totalObserved * 0.15,<br/>}<br/><br/>// Calculate the ChiSquare test statistic.<br/>chiSquare := stat.ChiSquare(observed, expected)<br/><br/>// Output the test statistic to standard out.<br/>fmt.Printf("\nChi-square: %0.2f\n", chiSquare)</pre>
<p>This will give us the following value for chi-square:</p>
<pre><strong>$ go build</strong><br/><strong>$ ./myprogram</strong><br/><br/><strong>Chi-square: 18.13</strong></pre>
<p>Next, we need to calculate the p-value corresponding to this <kbd>Chi-square</kbd>. This requires us to know information about the <strong>chi-squared distribution</strong>, which defines the p-values for certain measures of chi-square and certain <strong>degrees of freedom</strong>. <kbd><span>github.com/gonum/stat</span></kbd> <span>also includes a representation of this chi-squared distribution from which we can calculate our <kbd>p-value</kbd>:</span></p>
<pre>// Create a Chi-squared distribution with K degrees of freedom.<br/>// In this case we have K=3-1=2, because the degrees of freedom<br/>// for a Chi-squared distribution is the number of possible<br/>// categories minus one.<br/>chiDist := distuv.ChiSquared{<br/>    K: 2.0,<br/>    Src: nil,<br/>}<br/><br/>// Calculate the p-value for our specific test statistic.<br/>pValue := chiDist.Prob(chiSquare)<br/><br/>// Output the p-value to standard out.<br/>fmt.Printf("p-value: %0.4f\n\n", pValue)</pre>
<p>This gives us the following result:</p>
<pre><strong>$ go build</strong><br/><strong>$ ./myprogram</strong><br/><br/><strong>Chi-square: 18.13</strong><br/><strong>p-value: 0.0001</strong></pre>
<p>So, there is a 0.01% probability that the results we see in the deviations in the second version of the survey are purely due to chance. If we, for example, are using a threshold of 5% (which is common), we would need to reject the null hypothesis and adopt our alternative hypothesis.</p>
<p> </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">References</h1>
                </header>
            
            <article>
                
<p>Vectors and matrices:</p>
<ul>
<li><kbd>gonum.org/v1/gonum/floats</kbd> docs: <a href="https://godoc.org/gonum.org/v1/gonum/floats">https://godoc.org/gonum.org/v1/gonum/floats</a></li>
<li><kbd>gonum.org/v1/gonum/mat</kbd> docs: <a href="https://godoc.org/gonum.org/v1/gonum/mat">https://godoc.org/gonum.org/v1/gonum/mat</a></li>
</ul>
<p>Statistics:</p>
<ul>
<li><span><kbd>gonum.org/v1/gonum/stat</kbd> docs: <a href="https://godoc.org/gonum.org/v1/gonum/stat">https://godoc.org/gonum.org/v1/gonum/stat</a></span></li>
<li><kbd>github.com/montanaflynn/stats</kbd> docs: <a href="https://godoc.org/github.com/montanaflynn/stats">https://godoc.org/github.com/montanaflynn/stats</a></li>
</ul>
<p>Visualization:</p>
<ul>
<li><kbd>gonum.org/v1/plot</kbd> docs: <a href="https://godoc.org/gonum.org/v1/plot">https://godoc.org/gonum.org/v1/plot</a></li>
<li><kbd>gonum.org/v1/plot</kbd> wiki with examples: <a href="https://github.com/gonum/plot/wiki/Example-plots">https://github.com/gonum/plot/wiki/Example-plots</a></li>
</ul>
<p>Probability:</p>
<ul>
<li><kbd>gonum.org/v1/gonum/stat/distuv</kbd> docs: <a href="https://godoc.org/gonum.org/v1/gonum/stat/distuv">https://godoc.org/gonum.org/v1/gonum/stat/distuv</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>This introduction to matrices, linear algebra, statistics, and probability in Go has given us a set of tools to understand, structure, and operate on data. This set of tools will be used throughout the book as we work on a diverse set of problems, and these tools could be used in a variety of contexts outside of machine learning. However, in the next chapter, we will discuss some ideas and techniques that will be extremely important in the machine learning context, specifically, evaluation and validation.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </body></html>