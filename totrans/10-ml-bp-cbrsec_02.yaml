- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On Cybersecurity and Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the dawn of the Information Age, cybersecurity has become a pressing issue
    in today’s society and a skill that is much sought after in industry. Businesses,
    governments, and individual users are all at risk of security attacks and breaches.
    The fundamental goal of cybersecurity is to keep users and their data safe. Cybersecurity
    is a multi-faceted problem, ranging from highly technical domains (cryptography
    and network attacks) to user-facing domains (detecting hate speech or fraudulent
    credit card transactions). It helps to prevent sensitive information from being
    corrupted, avoid financial fraud and losses, and safeguard users and their devices
    from harmful actors.
  prefs: []
  type: TYPE_NORMAL
- en: 'A large part of cybersecurity analytics, investigations, and detections are
    now driven by **machine learning** (**ML**)and “smart” systems. Applying data
    science and ML to the security space presents a unique set of challenges: the
    lack of sufficiently labeled data, limitations on powerful models due to the need
    for explainability, and the need for nearly perfect precision due to high-stakes
    scenarios. As we progress through the book, you will learn how to handle these
    critical tasks and apply your ML and data science skills to cybersecurity problems.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The basics of cybersecurity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning – cybersecurity versus other domains
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have built the foundation for further projects.
  prefs: []
  type: TYPE_NORMAL
- en: The basics of cybersecurity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book aims to marry two important fields of research: cybersecurity and
    ML. We will present a brief overview of cybersecurity, how it is defined, what
    the end goals are, and what problems arise.'
  prefs: []
  type: TYPE_NORMAL
- en: Traditional principles of cybersecurity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The fundamental aim of cybersecurity is to keep users and data safe. Traditionally,
    the goals of cybersecurity were three-fold: **confidentiality, integrity, and
    availability**, the **CIA** triad.'
  prefs: []
  type: TYPE_NORMAL
- en: Let us now examine each of these in depth.
  prefs: []
  type: TYPE_NORMAL
- en: Confidentiality
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The confidentiality goal aims to keep data secret from unauthorized parties.
    Only authorized entities should have access to data.
  prefs: []
  type: TYPE_NORMAL
- en: Confidentiality can be achieved by encrypting data. Encryption is a process
    where plain-text data is coded into a ciphertext using an encryption key. The
    ciphertext is not human-readable; a corresponding decryption key is needed to
    decode the data. Encryption of information being sent over networks prevents attackers
    from reading the contents, even if they intercept the communication. Encrypting
    data at rest ensures that adversaries will not be able to read your data, even
    if the physical data storage is compromised (for example, if an attacker breaks
    into an office and steals hard drives).
  prefs: []
  type: TYPE_NORMAL
- en: Another approach to ensuring confidentiality is access control. Controlling
    access to information is the first step in preventing unauthorized exposure or
    sharing of data (whether intentional or not). Access to data should be granted
    by following the principle of least privilege; an individual or application must
    have access to the minimum data that it requires to perform its function. For
    example, only the finance division in a company should have access to revenue
    and transaction information. Only system administrators should be able to view
    network and access logs.
  prefs: []
  type: TYPE_NORMAL
- en: ML can help in detecting abnormal access, suspicious behavior patterns, or traffic
    from malicious sources, thus ensuring that confidentiality is maintained. For
    example, suppose an administrator suddenly starts accessing confidential/privileged
    files outside of the regular pattern for themselves or administrators in general.
    An ML model may flag it as anomalous and set off alarms so that the administrator
    can be investigated.
  prefs: []
  type: TYPE_NORMAL
- en: Integrity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The integrity goal ensures that data is trustworthy and tamper-free. If the
    data can be tampered with, there is no guarantee of its authenticity and accuracy;
    such data cannot be trusted.
  prefs: []
  type: TYPE_NORMAL
- en: Integrity can be ensured using hashing and checksums. A **checksum** is a numerical
    value computed by applying a hash function to the data. Even if a single bit of
    the data were to change, the checksum would change. Digital signatures and certificates
    also facilitate integrity; once an email or code library has been digitally signed
    by a user, it cannot be changed; any change requires a new digital signature.
  prefs: []
  type: TYPE_NORMAL
- en: Attackers may wish to compromise the integrity of a system or service for their
    gain. For example, an attacker may intercept incoming requests to a banking server
    and change the destination account for any money transfer. Malicious browser extensions
    may redirect users to a site for gaming traffic and advertising statistics; the
    original destination URL entered by the user was tampered with. By analyzing the
    patterns in data coupled with other signals, ML models can detect integrity breaches.
  prefs: []
  type: TYPE_NORMAL
- en: Availability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first two goals ensure that data is kept secret, tamper-free, and safe from
    attackers. However, these guarantees are meaningless if authorized users cannot
    access the data as needed. The availability goal ensures that information is always
    available to legitimate users of a system.
  prefs: []
  type: TYPE_NORMAL
- en: Attackers may try to compromise availability by executing a **denial-of-service**
    (**DoS**) attack, where the target service is bombarded with incoming requests
    from unauthorized or dummy nodes. For example, an attacker may send millions of
    dummy queries to a database server. While the attacker may not be able to actually
    extract any useful information, the server is so overwhelmed that legitimate queries
    by authorized users are never executed. Alternatively, an attacker may also degrade
    availability by physically destroying data.
  prefs: []
  type: TYPE_NORMAL
- en: Availability can be guaranteed by implementing redundancy in data and services.
    Regular backup of data ensures that it is still available even if one copy is
    destroyed or tampered with. If multiple API endpoints to achieve the same functionality
    are present, legitimate users can switch to another endpoint, and availability
    will be preserved. Similar to confidentiality and integrity, pattern analysis
    and classification algorithms can help detect DoS attacks. An emerging paradigm,
    graph neural networks, can help detect coordinated bot attacks known as **distributed
    denial of** **service** (**DDoS**).
  prefs: []
  type: TYPE_NORMAL
- en: Modern cybersecurity – a multi-faceted issue
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The CIA triad focuses solely on cybersecurity for data. However, cybersecurity
    today extends far beyond just data and servers. Data stored in servers becomes
    information used by organizations, which is transformed into the applications
    that are ultimately used by humans. Cybersecurity encompasses all these aspects,
    and there are different problem areas in each aspect.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1**.1* shows how varied and multi-faceted the issue of cybersecurity
    is and the various elements it encompasses:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Various problem areas in cybersecurity](img/B19327_01_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 – Various problem areas in cybersecurity
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following sections, we will discuss some common security-related problems
    and research areas in four broad categories: data security, information security,
    application security, and user security.'
  prefs: []
  type: TYPE_NORMAL
- en: Data security
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data in its raw format is stored on hard drives in offices or in the cloud,
    which is eventually stored in physical machines in data centers. At the data level,
    the role of cybersecurity is to keep the data safe. Thus, the focus is on maintaining
    confidentiality, integrity, and availability (the three goals of the CIA triad)
    of the data. Cybersecurity problems at this level focus on novel cryptographic
    schemes, lightweight encryption algorithms, fault tolerance systems, and complying
    with regulations for data retention.
  prefs: []
  type: TYPE_NORMAL
- en: Information security
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data from data centers and the cloud is transformed into information, which
    is used by companies to build various services. At the information level, the
    role of cybersecurity is to ensure that the information is being accessed and
    handled correctly by employees. Problems at this level focus on network security
    administration, detecting policy violations and insider threats, and ensuring
    that there is no inadvertent leakage of private data.
  prefs: []
  type: TYPE_NORMAL
- en: Application security
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Information is transformed into a form suitable for consumers using a variety
    of services. An example of this is information about Facebook users being transformed
    into a list of top friend recommendations. At the application level, the role
    of cybersecurity is to ensure that the application cannot be compromised. Problems
    at this level focus on malware detection, supply chain attack detection, anomaly
    detection, detecting bot and automated accounts, and flagging phishing emails
    and malicious URLs.
  prefs: []
  type: TYPE_NORMAL
- en: User security
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, applications are used by human end users, and the role of cybersecurity
    here is to ensure the safety of these users. Problems at this level include detecting
    hate speech, content moderation, flagging fraudulent transactions, characterizing
    abusive behavior, and protecting users from digital crimes (identity theft, scams,
    and extortion). Note that this aspect goes beyond technical elements of cybersecurity
    and enters into the realm of humanities, law, and the social sciences.
  prefs: []
  type: TYPE_NORMAL
- en: We will now present a case study to explain more clearly how security problems
    arise at each level (data, information, application, and user).
  prefs: []
  type: TYPE_NORMAL
- en: A study on Twitter
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Figure 1**.1* shows the threat model in the four broad levels we described.
    Let us understand this concretely using the example of Twitter. Twitter is a social
    media networking platform where users can post short opinions, photos, and videos
    and interact with the posts of others.'
  prefs: []
  type: TYPE_NORMAL
- en: At the data level, all of the data (posts, login credentials, and so on) are
    stored in the raw form. An adversary may try to physically break into data centers
    or try to gain access to this data using malicious injection queries. At the information
    level, Twitter itself is using the data to run analytics and train its predictive
    models. An adversary may try to harvest employee credentials via a phishing email
    or poison models with corrupt data.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the application level, the analytics are being transformed into actionable
    insights consumable by end users: recommendation lists, news feeds, and top-ranking
    posts. An adversary may create bot accounts that spread misinformation or malicious
    extensions that redirect users outside of Twitter. Finally, at the user level,
    end users actually use the app to tweet. Here, an adversary may try to attack
    users with hate speech or abusive content.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we have discussed cybersecurity and looked at various cybersecurity
    problems that occur. We will now turn to a related but slightly different topic:
    privacy.'
  prefs: []
  type: TYPE_NORMAL
- en: Privacy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The terms security and privacy are often confused and used interchangeably.
    However, the goals of security and privacy are very different. While security
    aims to secure data and systems, privacy refers to individuals having full control
    over their data. When it comes to privacy, every individual should know the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What data is being collected (location, app usage, web tracking, and health
    metrics)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How long it will be retained for (deleted immediately or in a week/month/year)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who can access it (advertisers, research organizations, and governments)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How it can be deleted (how to make a request to the app)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security and privacy are interrelated. If an attacker hacks into a hospital
    or medical database (a breach of security), then they may have access to sensitive
    patient data (a breach of privacy). There are numerous laws around the world,
    such as the **General Data Protection Regulation** (**GDPR**) in Europe, that
    mandate strict security controls in order to ensure user privacy.
  prefs: []
  type: TYPE_NORMAL
- en: Because ML relies on a lot of collected data, there has been a push for privacy-preserving
    ML. We will be discussing some techniques for this in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: This completes our discussion of cybersecurity. We started by describing the
    traditional concepts of security, followed by various cybersecurity problems at
    multiple levels. We also presented a case study on Twitter that helps put these
    problems in context. Finally, we looked at privacy, a closely related topic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will turn to the second element in the book: ML.'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will present a brief overview of ML principles and techniques.
    The traditional computing paradigm defines an algorithm as having three elements:
    the input, an output, and a process that specifies how to derive the output from
    the input. For example, in a credit card detection system, a module to flag suspicious
    transactions may have transaction metadata (location, amount, type) as input and
    the flag (suspicious or not) as output. The process will define the rule to set
    the flag based on the input, as shown in *Figure 1**.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.2 – Traditional input-process-output model for fraud detection](img/B19327_01_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.2 – Traditional input-process-output model for fraud detection
  prefs: []
  type: TYPE_NORMAL
- en: ML is a drastic change to the input-process-output philosophy. The traditional
    approach defined computing as deriving the output by applying the process to the
    input. In ML, we are given the input and output, and the task is to derive the
    process that connects the two.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing our analogy of the credit card fraud detection system, we will now
    be provided with a dataset that has the input features and output flags. Our task
    is to learn how the flag can be computed based on the input. Once we learn the
    process, we can generalize it to new data that comes our way in the traditional
    input-process-output way. Most of the security-related problems we will deal with
    in this book are *classification* problems. Classification is a task in which
    data points are assigned discrete, categorical labels (fraud/non-fraud or low-risk/medium-risk/high-risk).
  prefs: []
  type: TYPE_NORMAL
- en: ML is not a one-step process. There are multiple steps involved, such as cleaning
    and preparing the data in the right form, training and tuning models, deploying
    them, and monitoring them. In the next section, we will look at the major steps
    involved in the workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning workflow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we will see some of the basic steps that go into end-to-end ML. It begins
    with preprocessing the data to make it fit for use by ML models and ends with
    monitoring and tuning the models.
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first step in any ML experiment is to process the data into a format suitable
    for ML. Real-world data is often not suitable to be used directly by a model due
    to two main reasons.
  prefs: []
  type: TYPE_NORMAL
- en: The first reason is variability in format. Data around us is in multiple formats,
    such as numbers, images, text, audio, and video. All of these need to be converted
    into numerical representations for a model to consume them. Preprocessing would
    convert images into matrices, text into word embeddings, and audio streams into
    time series. Some features of data are discrete; they represent categorical variables.
    For example, in a dataset about users, the `Country` field would take on string
    values such as `India`, `Canada`, `China`, and so on. Preprocessing converts such
    categorical variables into a numerical vector form that can be consumed by a model.
  prefs: []
  type: TYPE_NORMAL
- en: The second reason is noise in real-world data. Measurement inaccuracies, processing
    errors, and human errors can cause corrupt values to be recorded. For example,
    a data entry operator might enter your age as 233 instead of 23 by mistakenly
    pressing the *3* key twice. A web scraper collecting data may face network issues
    and fail to make a request; some fields in the data will then be missing.
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, preprocessing removes noise, handles missing data, and transforms
    data into a format suitable for consumption by an ML model.
  prefs: []
  type: TYPE_NORMAL
- en: The training phase
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After the data has been suitably preprocessed, we train a model to learn from
    the data. A model expresses the relationship between the preprocessed features
    and some target variables. For example, a model to detect phishing emails will
    produce as output a probability that an email is malicious based on the input
    features we define. A model that classifies malware as 1 of 10 malware families
    will output a 10-dimensional vector of probability distribution over the 10 classes.
    In the training phase, the model will learn the parameters of this relationship
    so that the error over the training data is minimized (that is, it is able to
    predict the labels for the training data as closely as possible). During the training
    phase, a subset of the data is reserved as validation data to examine the error
    of the trained model over unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: One of the problems that a model can face is overfitting; if a model learns
    parameters too specific to the training data, it cannot generalize well to newer
    data. This can be diagnosed by comparing the performance of the model on training
    and validation data; a model that overfits will show decreasing loss or error
    over the training data but a non-decreasing loss on validation data. The opposite
    problem to this also exists – the model can suffer from underfitting where it
    is simply not able to learn from the training data.
  prefs: []
  type: TYPE_NORMAL
- en: The inferencing phase
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once a model has been trained, we want to use it to make predictions for new,
    unseen data. There is no parameter learning in this phase; we simply plug in the
    features from the data and inspect the prediction made by the model. Inferencing
    often happens in real time. For example, every time you use your credit card,
    the parameters of your transaction (amount, location, and category) are used to
    run inferencing on a fraud detection model. If the model flags the transaction
    as suspicious, the transaction is declined.
  prefs: []
  type: TYPE_NORMAL
- en: The maintenance phase
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ML models need continuous monitoring and tuning so that their performance does
    not degrade. A model may become more error-prone in its predictions as time passes
    because it has been trained on older data. For example, a model to detect misinformation
    trained in 2019 would have never been exposed to fake news posts about the COVID-19
    pandemic. As a result, it never learned the characteristics of COVID-related fake
    news and may fail to recognize such articles as misinformation. To avoid this,
    a model has to be retrained on newer data at a regular cadence so that it learns
    from it.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, new features may become available that could help improve the
    performance of the model. We would then need to train the model with the new feature
    set and check the performance gains. There may be different slices of data in
    which different classification thresholds show higher accuracy. The model then
    has to be tuned to use a different threshold in each slice. Monitoring models
    is an ongoing process, and there are automated tools (called MLOps tools) that
    offer functionality for continuous monitoring, training, tuning, and alerting
    of models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will look at the fundamental ML paradigms: supervised and unsupervised
    learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ML has two major flavors: supervised and unsupervised. In **supervised learning**,
    we have access to labeled data. From the labeled data, we can learn the relation
    between the data and the labels. The most fundamental example of a supervised
    learning algorithm is **linear regression**.'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Linear regression assumes that the target variable can be expressed as a linear
    function of the features. We initially start with a linear equation with arbitrary
    coefficients, and we tune these coefficients as we learn from the data. At a high
    level and in the simplest form, linear regression works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Let *y* be the target variable and *x*1, *x*2, and *x*3 be the predictor features.
    Assuming a linear relationship, our model is *y = a*0 + a1x1 + a2x2 + a3x3\. Here,
    *a*0, *a*1, *a*2, and *a*3 are parameters initially set to random.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Consider the first data point from the training set. It will have its own set
    of predictors (*x*1, *x*2, and *x*3 ) and the target as ground truth (*y*). Calculate
    a predicted value of the target using the equation defined previously; call this
    predicted value *y’*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate a *loss* that indicates the error of the prediction. Typically, we
    use the **ordinary least squares** (**OLS**) error as the loss function. It is
    simply the square of the difference between the actual and predicted value of
    the target: L = (y − y ′ ) 2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The loss, *L*, tells us how far off our prediction is from the actual value.
    We use the loss to modify the parameters of our model. This part is the one where
    we *learn* from the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *steps 2*, *3*, and *4* over each data point from the training set, and
    update the parameters as you go. This completes one *epoch* of training.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat the preceding steps for multiple epochs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the end, your parameters will have been tuned to capture the linear relationship
    between the features and the target.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will now look at gradient descent, the algorithm that is the heart and soul
    of linear regression (and many other algorithms).
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The crucial step in the preceding instructions is *step 4*; this is the step
    where we update the parameters based on the loss. This is typically done using
    an algorithm called **gradient descent**. Let *θ* be the parameters of the model;
    we want to choose the optimal values for *θ* such that the loss is as small as
    possible. We calculate the gradient, which is the derivative of the loss with
    respect to the parameters. We update the parameter *θ* to its new value *θ’* based
    on the gradient as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: θ′= θ − η  δL _ δθ
  prefs: []
  type: TYPE_NORMAL
- en: 'The δL _ δθ  gradient represents the slope of the tangent to the loss curve
    at that particular value of *θ*. The sign of the gradient will tell us the direction
    in which we need to change θ in order to reach minima on the loss. We always move
    in the direction of descending gradient to minimize the loss. For a clearer understanding,
    carefully observe the loss curve plotted against the parameter in the following
    chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Traversing the loss curve using gradient descent](img/B19327_01_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.3 – Traversing the loss curve using gradient descent
  prefs: []
  type: TYPE_NORMAL
- en: Suppose because of our random selection, we select the *θ*1 parameter. When
    we calculate the gradient of the curve (the slope of the tangent to the curve
    at point A), it will be negative. Applying the previous equation of gradient descent,
    we will have to calculate the gradient and add it to *θ*1 to get the new value
    (say *θ*2).
  prefs: []
  type: TYPE_NORMAL
- en: We continue this process until we reach point E, where the gradient is very
    small (nearly 0); this is the minimum loss we can reach, and even if we were to
    continue the gradient descent process, the updates would be negligible (because
    of the very small and near-zero value of the gradient). Had we started at point
    H instead of A, the gradient we calculated would have been positive. In that case,
    according to the gradient descent equation, we would have had to decrease *θ*
    to reach the minimum loss. Gradient descent ensures that we always move down the
    curve to reach the minima.
  prefs: []
  type: TYPE_NORMAL
- en: An important element in the equation that we have not discussed so far is *η*.
    This parameter is called the **learning rate**. The gradient gives us the direction
    in which we want to change *θ*. The learning rate tells us by how much we want
    to change *θ*. A smaller value of *η* means that we are making very small changes
    and thus taking small steps to reach the minima; it may take a long time to find
    the optimal values. On the other hand, if we choose a very large value for the
    learning rate, we may miss the minima.
  prefs: []
  type: TYPE_NORMAL
- en: For example, because of a large learning rate, we might jump directly from point
    D to F without ever getting to E. At point F, the direction of the gradient changes,
    and we may jump in the opposite direction back to D. We will keep oscillating
    between these two points without reaching the minima.
  prefs: []
  type: TYPE_NORMAL
- en: In the linear regression algorithm discussed previously, we performed the gradient
    descent process for every data point in the training data. This is known as **stochastic
    gradient descent**. In another, more efficient version of the algorithm, we consider
    batches of data, aggregate the loss values, and apply gradient descent over the
    aggregated loss. This is known as **batch** **gradient descent**.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent is at the core of most modern ML algorithms. While we have
    described it in the context of linear regression, it is simply an optimization
    algorithm and is widely used in other models such as deep neural networks as well.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In supervised learning, we had ground truth data to learn the relationship between
    the features and labels. The goal of unsupervised learning is to discover patterns,
    trends, and relationships within data. Unsupervised learning allows us to make
    predictions and detect anomalies without having access to labels during training.
    Let us look at clustering, a popular unsupervised learning problem.
  prefs: []
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As the name suggests, clustering is the process of grouping data into clusters.
    It allows us to examine how the data points group together, what the common characteristics
    in those groups are, and what the hidden trends in the data are. There is no *learning*
    involved in clustering. An ideal clustering is when the intra-cluster similarity
    is high and inter-cluster similarity is low. This means that points within a cluster
    are very similar to one another and very different from points in other clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most fundamental clustering algorithm is called **K-means clustering**.
    It partitions the data points into *k* clusters, where *k* is a parameter that
    has to be preset. The general process of the K-means algorithm is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Select *K* points randomly from the training data. These points will be the
    centroids of our clusters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each point, calculate the distance to each of the centroids. The distance
    metric generally used is **Euclidean distance**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign each point to one of the *K* clusters based on the distance. A point
    will be assigned to the centroid that is closest to it (minimum distance).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each of the *K* centroids will now have a set of points associated with it;
    this forms a cluster. For each cluster, calculate the updated cluster centroids
    as a mean of all the points assigned to that cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Repeat *steps 2–4* until one of the following occurs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The cluster assignment in *step 3* does not change
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A fixed number of repetitions of the steps have passed
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The core concept behind this algorithm is to optimize the cluster assignment
    so that the distance of each point to the centroid of the cluster it belongs to
    is small; that is, clusters should be as tightly knit as possible.
  prefs: []
  type: TYPE_NORMAL
- en: We have looked at supervised and unsupervised learning. A third variant, semi-supervised
    learning, is the middle ground between the two.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the name suggests, semi-supervised learning is the middle ground between
    supervised and unsupervised learning. Often (and especially in the case of critical
    security applications), labels are not available or are very few in number. Manual
    labeling is expensive as it requires both time and expert knowledge. Therefore,
    we have to train a model from only these limited labels.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-supervised learning techniques are generally based on a self-training approach.
    First, we train a supervised model based on the small subset of labeled data.
    We then run inferencing on this model to obtain predicted labels on the unlabeled
    data. We use our original labels, and high-confidence predicted labels together
    to train the final model. This process can be repeated for a fixed number of iterations
    or until we reach a point where the model performance does not change significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach to semi-supervised learning is called **co-training**, where
    we jointly train two models with different views (feature sets) of the data. We
    begin by independently training two models based on different feature sets and
    available labels. We then apply the models to make predictions for the unlabeled
    data and obtain pseudo labels. We add the high-confidence labels from the first
    model to the training set of the second and vice versa. We repeat the process
    of training models and obtain pseudo labels for a fixed number of iterations or
    until we reach a point where the performance of both models does not change significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have covered the major paradigms in ML, we can turn to evaluate
    the performance of models.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have mentioned model performance in passing. In this section, we
    will define formal metrics for evaluating the performance of a model. As most
    of the problems we deal with will be classification-based, we will discuss metrics
    specific to classification only.
  prefs: []
  type: TYPE_NORMAL
- en: A confusion matrix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Classification involves predicting the label assigned to a particular data point.
    Consider the case of a fraud detection model. As can be seen in *Figure 1**.4*,
    if the actual and predicted label of a data point are both **Fraud**, then we
    call that example a **True Positive (TP)**. If both are **Non-Fraud**, we call
    it a **True Negative (TN)**. If the predicted label is **Fraud**, but the actual
    label (expected from ground truth) is **Non-Fraud**, then we call it a **False
    Positive (FP)**. Finally, if the predicted label is **Non-Fraud**, but the actual
    label (expected from ground truth) is **Fraud**, we call it a **False** **Negative
    (FN)**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the predicted and the actual label of data, we can construct what
    is called a **confusion matrix**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4 – Confusion matrix](img/B19327_01_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.4 – Confusion matrix
  prefs: []
  type: TYPE_NORMAL
- en: 'The confusion matrix provides a quick way to visually inspect the performance
    of the model. A good model will show the highest true positives and negatives,
    while the other two will have smaller values. The confusion matrix allows us to
    conveniently calculate metrics relevant to classification, namely the accuracy,
    precision, recall, and F-1 score. Let us learn more about these metrics as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy**: This is a measure of how accurate the model predictions are across
    both classes. Simply put, it is the number of examples for which the model is
    able to predict the labels correctly, that is, the proportion of true positives
    and negatives in the data. It can be calculated as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accuracy =  TP + TN ______________  TP + TN + FP + FN
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision**: This is a measure of the confidence of the model in the positive
    predictions. In simple terms, it is the proportion of the true positives in all
    the examples predicted as positive. Precision answers the question: Of all the
    examples predicted as fraud, how many of them are actually fraud? Precision can
    be calculated as the following formula:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precision =  TP _ TP + FP
  prefs: []
  type: TYPE_NORMAL
- en: '**Recall**: This is a measure of the completeness of the model in the positive
    class. Recall answers the question: Of all the examples that were fraud, how many
    could the model correctly detect as fraud? Recall can be calculated as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recall =  TP _ TP + FN
  prefs: []
  type: TYPE_NORMAL
- en: When a model has high precision, it means that most of the predicted fraud is
    actually fraud. When a model has a high recall, it means that out of all the fraud
    in the data, most of it is predicted by the model as fraud. Consider a model that
    predicts *everything* as fraud. This model has a high recall; as everything is
    marked as fraud, naturally, all the actual fraud is also being captured, but at
    the cost of a large number of false positives (low precision). Alternatively,
    consider a model that predicts *nothing* as fraud. This model has a high precision;
    as it marks nothing as fraud, there are no false positives, but at the cost of
    a large number of false negatives (low recall). This trade-off between precision
    and recall is a classic problem in ML.
  prefs: []
  type: TYPE_NORMAL
- en: '**F-1 Score**: This measure captures the degrees of both precision and recall.
    High precision comes at the cost of low recall and vice versa. The F-1 score is
    used to identify the model that has the highest precision and recall together.
    Mathematically, it is defined as the harmonic mean of the precision and recall,
    calculated as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: F1 Score =  2 ·Precision ·Recall   ______________  Precision + Recall
  prefs: []
  type: TYPE_NORMAL
- en: '**Receiver Operating Characteristic (ROC) curve**: We have seen that classification
    models assign a label to a data point. In reality, however, the models compute
    a probability that the data point belongs to a particular class. The probability
    is compared with a threshold to determine whether the example belongs to that
    class or not. Typically, a threshold of 0.5 is used. So, in our example of the
    fraud detection model, if the model outputs a value greater than 0.5, we will
    classify the data point as **Fraud**. A smaller value will lead to us classifying
    it as **Non-Fraud**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The threshold probability is a parameter, and we can tune this parameter to
    achieve high precision or recall. If you set a very low threshold, the bar to
    meet for an example to be fraudulent is very low; for example, at a threshold
    of 0.1, nearly all examples will be classified as fraud. This means that we will
    be catching all the fraud out there; we have a high recall.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, if you set a very high threshold, the bar to meet will be
    very high. Not all fraud will be caught, but you can be sure that whatever is
    marked as fraud is definitely fraud. In other words, you have high precision.
    This trade-off between precision and recall is captured in the ROC curve, as shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5 – ROC curve](img/B19327_01_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.5 – ROC curve
  prefs: []
  type: TYPE_NORMAL
- en: The ROC curve plots the **True Positive Rate** (**TPR**) against the **False
    Positive Rate** (**FPR**) for every value of the threshold from 0 to 1\. It allows
    us to observe the precision we have to tolerate to achieve a certain recall and
    vice versa. In the ROC plotted in the preceding diagram, points **A** and **B**
    indicate the true positive and negative rates that we have to tolerate at two
    different thresholds. The **Area under the ROC Curve** (**AUC**), represented
    by the shaded area, provides an overall measure of the performance of the model
    across all threshold values. The AUC can be interpreted as the probability that
    a model scores a random positive example (fraud) higher than a random negative
    one (non-fraud). When comparing multiple models, we choose the one with the highest
    value of the AUC.
  prefs: []
  type: TYPE_NORMAL
- en: We have looked at the fundamental concepts behind ML, the underlying workflow,
    and the evaluation approaches. We will now examine why the application of ML in
    cybersecurity is different from other fields and the novel challenges it poses.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning – cybersecurity versus other domains
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'ML today is applied to a wide variety of domains, some of which are detailed
    in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: In sales and marketing, to identify the segment of customers likely to buy a
    particular product
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In online advertising, for click prediction and to display ads accordingly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In climate and weather forecasting, to predict trends based on centuries of
    data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In recommendation systems, to find the best items (movies, songs, posts, and
    people) relevant to a user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While every sector imaginable applies ML today, the nuances of it being applied
    to cybersecurity are different from other fields. In the following subsections,
    we will see some of the reasons why it is much more challenging to apply ML to
    the cybersecurity domain than to other domains such as sales or advertising.
  prefs: []
  type: TYPE_NORMAL
- en: High stakes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Security problems often involve making crucial decisions that can impact money,
    resources, and even life. A fraud detection model that performs well has the potential
    to save millions of dollars in fraud. A botnet or malware detection model can
    save critical systems (such as in the military) or sensitive data (such as in
    healthcare) from being compromised. A model to flag abusive users on social media
    can potentially save someone’s life. Because the stakes are so high, the precision-recall
    trade-off becomes even more crucial.
  prefs: []
  type: TYPE_NORMAL
- en: In click fraud detection, we have to operate at high precision (or else we would
    end up marking genuine clicks as fraud), and this comes at the cost of poor recall.
    Similarly, in abuse detection, we must operate at high recall (we want all abusers
    to be caught), which comes at the cost of high false positives (low precision).
    In use cases such as click prediction or targeting, the worst thing that might
    happen because of a poor model is a few non-converting clicks or mistargeted advertisements.
    On the other hand, models for security must be thoroughly tuned and diligently
    monitored as the stakes are much higher than in other domains.
  prefs: []
  type: TYPE_NORMAL
- en: Lack of ground truth
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most well-studied ML methods are supervised in nature. This means that they
    depend on ground-truth labels to learn the model. In security problems, the ground
    truth is not always available, unlike in other domains. For example, in a task
    such as customer targeting or weather forecasting, historical information can
    tell us whether a customer actually purchased a product or whether it actually
    rained; this can be used as ground truth.
  prefs: []
  type: TYPE_NORMAL
- en: However, such obvious ground truth is not available in security problems such
    as fraud or botnet detection. We depend on expert annotation and manual investigations
    to label data, which is a resource-heavy task. In addition, the labels are based
    on human knowledge and heuristics (i.e., does this seem fraudulent?) and not on
    absolute truth such as the ones we described for customer targeting or weather
    prediction. Due to the lack of high-confidence labels, we often have to rely on
    unsupervised or semi-supervised techniques for security applications.
  prefs: []
  type: TYPE_NORMAL
- en: The need for user privacy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In recent years, there has been a push to maintain user privacy. As we have
    discussed previously, with increased privacy comes reduced utility. This proves
    to be particularly challenging in security tasks. The inability to track users
    across websites hampers our ability to detect click fraud. A lack of permissions
    to collect location information will definitely reduce the signals we have access
    to detect credit card fraud. All of these measures preserve user privacy by avoiding
    undue tracking and profiling; however, they also degrade the performance of security
    models, which are actually for the benefit of the user. The fewer signals available
    to us, the lower the fidelity in the prediction of our models.
  prefs: []
  type: TYPE_NORMAL
- en: The need for interpretability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most powerful ML models (neural networks, transformers, and graph-based learning
    models) operate as a black box. The predictions made by the model lack interpretability.
    Because these models learn higher-order features, it is not possible for a human
    to understand and explain why a particular example is classified the way it is.
  prefs: []
  type: TYPE_NORMAL
- en: In security applications, however, explainability is important. We need to justify
    each prediction, at least for the positive class. If a transaction is flagged
    as fraudulent, the bank or credit card company needs to understand what went into
    the prediction in order to ascertain the truth. If users are to be blocked or
    banned, the platform may need adequate justification, more convincing than a model
    prediction. Classical ML algorithms such as decision trees and logistic regression
    provide some interpretation based on tree structure and coefficients, respectively.
    This need for interpretability in models is an obstacle to using state-of-the-art
    deep learning methods in security.
  prefs: []
  type: TYPE_NORMAL
- en: Data drift
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The cybersecurity landscape is an ever-changing one, with new attack strategies
    coming up every day. The nature of attackers and attack vectors is constantly
    evolving. As a result, there is also a change in the features that the model expects
    if data at inference time is significantly different in nature from that which
    the model was trained on. For example, an entirely new variant of malware may
    not be detected by a model as no examples of this variant were in the training
    data. A fake news detection model trained in 2019 may not be able to recognize
    COVID-19-related misinformation as it was never trained on that data. This data
    drift makes it challenging to build models that have sustained performance in
    the wild.
  prefs: []
  type: TYPE_NORMAL
- en: These problems (lack of labels, data drift, and privacy issues) also arise in
    other applications of ML. However, in the case of systems for cybersecurity, the
    stakes are high, and the consequences of an incorrect prediction can be devastating.
    These issues, therefore, are more challenging to handle in cybersecurity.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This introductory chapter provided a brief overview of cybersecurity and ML.
    We studied the fundamental goals of traditional cybersecurity and how those goals
    have now evolved to capture other tasks such as fake news, deep fakes, click spam,
    and fraud. User privacy, a topic of growing importance in the world, was also
    introduced. On the ML side, we covered the basics from the ground up: beginning
    with how ML differs from traditional computing and moving on to the methods, approaches,
    and common terms used in ML. Finally, we also highlighted the key differences
    in ML for cybersecurity that make it so much more challenging than other fields.
    The coming chapters will focus on applying these concepts to designing and implementing
    ML models for security issues. In the next chapter, we will discuss how to detect
    anomalies and network attacks using ML.'
  prefs: []
  type: TYPE_NORMAL
