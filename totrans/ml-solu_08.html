<html><head></head><body><div id="sbo-rt-content"><div class="chapter" title="Chapter 8. Developing Chatbots"><div class="titlepage"><div><div><h1 class="title"><a id="ch08"/>Chapter 8. Developing Chatbots</h1></div></div></div><p>The year 2017 was all about chatbots, and that continues in 2018. Chatbots are not new at all. The concept of chatbots has been around since the 1970s. Sometimes, a chatbot application is also referred to as a question-answering system. This is a more specific technical term for a chatbot. Let's take a step into history. Lunar was the first rule-based question-answering system. Using this system, geologists could ask questions regarding the moon rock from the Apollo missions. In order to improvise the rule-based system that was used in the Apollo mission, we had to find out a way to encode pattern-based question and <a id="id891" class="indexterm"/>answers. For this purpose, <span class="strong"><strong>Artificial Intelligence Markup Language</strong></span> was used, also called <span class="strong"><strong>AIML</strong></span>. This helps the programmer code less lines of code in order to achieve the same result that we generated by using a hardcoded pattern-based system. With recent advances in the field<a id="id892" class="indexterm"/> of <span class="strong"><strong>Machine Learning</strong></span> (<span class="strong"><strong>ML</strong></span>), we can build a chatbot without hardcoded responses.</p><p>Chatbots are <a id="id893" class="indexterm"/>now used in apps because of the numerous benefits they have; for example, users don't need to install different varieties of apps on their mobile. If there is a chatbot that provides you the news, then you can ask for news that is on CNN or The Economic Times. Big tech giants such as Facebook, Hike, WeChat, Snapchat, Slack, and so on provide chatbots for better customer engagement. They achieve this by making a chatbot that one can guide their customers in order to perform some operations; it also provides useful information about the product and its platforms.</p><p>Chatbots <a id="id894" class="indexterm"/>provide different services. By using the Facebook chatbot platform you can order flowers and see the news as well. Doesn't it sound cool? Technically, these chatbots are the new apps of the current era. I have briefly discussed the benefits of the chatbot, but we will look at them in detail in this chapter.</p><p>In this chapter, we will be covering the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Introducing the problem statement</li><li class="listitem" style="list-style-type: disc">Understanding the datasets</li><li class="listitem" style="list-style-type: disc">Building the basic version of chatbots:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding rule-based systems</li><li class="listitem" style="list-style-type: disc">Understanding the approach </li><li class="listitem" style="list-style-type: disc">Understanding architecture </li></ul></div></li><li class="listitem" style="list-style-type: disc">Implementing the rule-based system of chatbots</li><li class="listitem" style="list-style-type: disc">Testing rule-based chatbots </li><li class="listitem" style="list-style-type: disc">Problem with the existing approach:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding key concepts for optimizing the approach</li></ul></div></li><li class="listitem" style="list-style-type: disc">Implementing the revised approach:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Data preparation</li><li class="listitem" style="list-style-type: disc">Implementing the sequence-to-sequence (seq2seq) model</li></ul></div></li><li class="listitem" style="list-style-type: disc">Testing the revised approach:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding the testing metrics</li><li class="listitem" style="list-style-type: disc">Testing the revised version of chatbots</li></ul></div></li><li class="listitem" style="list-style-type: disc">Problem with the revised approach:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding key concepts for solving the existing problems</li></ul></div></li><li class="listitem" style="list-style-type: disc">The best approach:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Implementing the best approach</li></ul></div></li><li class="listitem" style="list-style-type: disc">Summary</li></ul></div><div class="section" title="Introducing the problem statement"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec75"/>Introducing the problem statement </h1></div></div></div><p>In this chapter, our<a id="id895" class="indexterm"/> primary goal is to understand how to build a chatbot. Chatbots, or <span class="strong"><strong>question-answering systems</strong></span> (<span class="strong"><strong>QA systems</strong></span>), are really helpful. Let's consider a fun example. Suppose you are a student and you have five books to read. Reading and understanding five books may take time. What if you could feed the content of all these five books to the computer and ask only relevant questions? By doing this, students could learn the concepts and new information faster. As we all know, major internet product companies are arranging information so it is easy to access. Chatbots or QA systems will help us understand the meaning behind this information. This is the main reason why chatbots are the buzzword for the year 2017. Whatever application you can think of, you can make a chatbot for it. Many messaging platforms now host chatbots built by developers, including Facebook Messenger, Slack, WeChat, and so on. Chatbots are the new app because they already live inside the installed apps that you probably use a dozen times in a day. Chatbots developed using Facebook chatbot APIs are inside the Facebook Messenger app. You might use Messenger a dozen times a day. So, users don't need to install a separate app for a specific functionality. This will help companies engage their customers even better.</p><p>Before we proceed, I <a id="id896" class="indexterm"/>want to introduce a couple of important terms that can help us understand which kind of chatbot development we are targeting in this chapter. First of all, let's understand what the different approaches for developing a chatbot are: </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Retrieval-based approach</li><li class="listitem" style="list-style-type: disc">Generative-based approach</li></ul></div><div class="section" title="Retrieval-based approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec127"/>Retrieval-based approach</h2></div></div></div><p>In a<a id="id897" class="indexterm"/> retrieval-based approach, we need to define the set of predefined responses, and we will apply some kind of heuristics on predefined <a id="id898" class="indexterm"/>responses so that the chatbot can generate the best possible answers for the given questions. The answers are very dependent on the input question and the context of that input question.</p><p>Earlier, during the development of the retrieval-based model, we used only expression matching, which can help us get the appropriate answer, but using only expression matching won't help us here. So recently, researchers and programmers have started using expression matching along with advanced machine learning (ML) classifier techniques. Let's take an example to understand how the machine learning classifier will be useful in order to build retrieval-based chatbots.</p><p>Suppose Alice needs to send flowers to her friends on their birthdays. One of her friends, Emma, likes roses and another friend, Lucy, likes lilies. Alice uses a flower-ordering chatbot to book her order. She writes, <span class="emphasis"><em>I want to book one multicolor rose flower bouquet and one with lilies</em></span>. So, in this case, if we implement a basic ML classifier, the chatbot can easily identify that there are two different orders Alice is booking, and it is also able to interpret the quantity of each of them. The chatbot will also ask for the different addresses and so on. By using ML techniques, we can code more complex heuristics, which can help us to generate more appropriate chatbot answers. The Facebook messenger chatbot API is an example of this.</p><p>There is another interesting example that can be solved by using ML heuristics. Say, you ask a chatbot, <span class="emphasis"><em>what day is it today? Or</em></span>,<span class="emphasis"><em> today is what day?</em></span> If we have implemented advanced ML techniques, then it can recognize that both questions are worded differently but have the same intent. During the development of the chatbot, intent and context detection are more complex tasks, which can be implemented by ML techniques and using some heuristics.</p><p>Now let's move on to the harder approach, which is the generative-based approach.</p></div><div class="section" title="Generative-based approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec128"/>Generative-based approach</h2></div></div></div><p>In the <a id="id899" class="indexterm"/>generative-based approach, there aren't any predefined responses given to the chatbot. The chatbot generates the<a id="id900" class="indexterm"/> responses from scratch. In order to build the generative-based chatbot, we need to provide a lot of data and the machine will learn how to answer the questions asked by users just by seeing the data. In 2015, Google researchers Oriol Vinyals and Quoc V. Le proposed an approach called A <span class="emphasis"><em>Neural Conversational Network.</em></span> You can refer to the paper at: <a class="ulink" href="https://arxiv.org/pdf/1506.05869v2.pdf">https://arxiv.org/pdf/1506.05869v2.pdf</a>.</p><p>In this paper, researchers have used a Cornell movie dialog dataset. This dataset has been fed to the machines so that it can learn the basic English language. For this, they have used the <span class="strong"><strong>Sequence-to-sequence</strong></span> (<span class="strong"><strong>seq2seq</strong></span>) neural network architecture. After that, they used the IT support <a id="id901" class="indexterm"/>dataset so that the machines have domain knowledge. Once a machine is trained on that, they have tested the chatbot in the IT support department, this chatbot will be able to answer questions with great accuracy. In the upcoming section, we will build our own Neural Conversational Network. This approach is less time consuming and overcomes the challenges we face in the retrieval-based model, such as intent identification, context identification, and so on.</p><p>There are some other important terms that we need to discuss here. There are some important constraints that we need to think about before developing a chatbot. The first one is related to the conversation domain:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Open domain</li><li class="listitem" style="list-style-type: disc">Closed domain</li></ul></div></div><div class="section" title="Open domain"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec129"/>Open domain</h2></div></div></div><p>First, let's understand<a id="id902" class="indexterm"/> what an open domain is. Conversations are fuzzy and uncertain sometimes. Let me give you an example. Suppose you meet an old school friend that you haven't seen for many years. During the course of the <a id="id903" class="indexterm"/>conversation, you don't know which particular topic you both are going to talk about. In this situation, the conversation can go anywhere. So, the domain of the conversation is not fixed. You can talk about life, jobs, travelling, family, and so on. There is an infinite number of topics that you can talk about. This kind of conversation, where we can't restrict the areas we are talking about, is called an open domain. Developing an open domain chatbot is difficult because ideally, this kind of chatbot can answer every question from any kind of domain with human-level accuracy.</p><p>Currently, these kinds of chatbots are not made. When we are able to make this kind of chatbot, it will have to pass the Turing Test. Let me give you a glimpse of the Turing Test so that you can understand the explanation better. This experiment was created by the great computer scientist Alan Turing in 1950. In this experiment, a person, called a judge, asks a series<a id="id904" class="indexterm"/> of questions to a person and a machine. Now, the judge won't know which answer is from the human and which one is from the machine. But after seeing or hearing the answers, if the judge can't differentiate which answers are coming from the human and which answers are coming from the machine, then the machine passes the Turing Test, and we <a id="id905" class="indexterm"/>can say that the machine exhibited human-level intelligence because it behaves as intelligently as humans. So far, there is not a single chatbot that has passed the <a id="id906" class="indexterm"/>Turing Test with human-level accuracy. You can read more about the Turing Test by visiting <a class="ulink" href="https://en.wikipedia.org/wiki/Turing_test">https://en.wikipedia.org/wiki/Turing_test</a>. This segment of technology is growing rapidly, so the next five years could be exciting.</p><p>Google has been quite aggressive in making an open domain chatbot. It is building this product in the form of Google Assistance, but the accuracy levels and functionality in passing the Turing Test are still limited. Now let's understand the second type of domain.</p></div><div class="section" title="Closed domain"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec130"/>Closed domain</h2></div></div></div><p>A <a id="id907" class="indexterm"/>closed domain is the opposite of an open domain. For a <a id="id908" class="indexterm"/>closed domain, we need to restrict the conversation topics. Let's take an example: in the office, we sometimes have meetings. Before the meeting, the participants know the topics on which there's going to be a discussion. So during the meeting, we just focus on those topics. Here, we won't have an infinite number of topics and domains to talk about. This kind of conversation, where we have restricted the areas we can talk about, is called a closed domain.</p><p>If a financial institute such as a bank launches a chatbot for their customers, then the developed chatbot cannot answer questions such as <span class="emphasis"><em>can you tell me</em></span> <span class="emphasis"><em>what the weather in Singapore is today?</em></span> But it helps you check the procedure of applying for a credit card, and this is because a chatbot can understand questions related to a specific domain. A chatbot for a closed domain is definitely possible, and there are many companies that are building domain-specific chatbots as it is good for engaging with the customer base. So during the chapter, we will be focusing on the closed domain chatbot.</p><p>Let's try to understand the last constraint; the conversation length, which means the length of the answers we will be getting from the chatbot. Based on that, we need to understand the following terms:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Short conversation</li><li class="listitem" style="list-style-type: disc">Long conversation</li></ul></div></div><div class="section" title="Short conversation"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec131"/>Short conversation</h2></div></div></div><p>This type<a id="id909" class="indexterm"/> of chatbot can generate short answers. During the development of the chatbot, we need to ask ourselves whether we expect a short <a id="id910" class="indexterm"/>conversation or not. If we expect a short answer then you should be glad because this short conversation-based chatbot can be easily built. An example of a short conversation is <a id="id911" class="indexterm"/>as follows:</p><p>Human: Hi</p><p>Machine: Hello</p><p>Human: How are you?</p><p>Machine: I'm fine</p><p>This example indicates short conversations generated by a chatbot.</p></div><div class="section" title="Long conversation"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec132"/>Long conversation</h2></div></div></div><p>This type of chatbot <a id="id912" class="indexterm"/>can generate long answers. It<a id="id913" class="indexterm"/> is hard for a machine to learn long conversations, so building a chatbot that can generate long conversations is difficult. Let's look at an example of a long conversation:</p><p>Human: I want to tell you a story.</p><p>Machine: Please go on.</p><p>Human: Here you go. John went to the market. Daniel is travelling to India. Siri has an apple. Siri is in the kitchen. So my question is, where is Siri?</p><p>Machine: Based on your story, I think Siri is in the kitchen.</p><p>As you can see in this example, in order to generate the right answer, the machine should also store and process the given facts so that it can generate the right answer. Therefore, long conversation and reasoning-based chatbots are a bit hard to develop.</p><p>So far, you have learned a lot of terms. Now let's see how they're going to affect us when we develop a chatbot. Based on the approaches and domain type, we can build different types of chatbots.</p><div class="section" title="Open domain and generative-based approach"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec101"/>Open domain and generative-based approach</h3></div></div></div><p>We <a id="id914" class="indexterm"/>want to build a chatbot using the generative-based approach, which operates on the open domain. This means that the chatbot needs to learn how to answer the questions from any domain from scratch. The conversation can go in any direction here. This type of chatbot is an example of <span class="strong"><strong>Artificial General Intelligence</strong></span> (<span class="strong"><strong>AGI</strong></span>), and we are not quite there yet.</p><p>So, developing<a id="id915" class="indexterm"/> this type of chatbot is not a part of this chapter.</p></div><div class="section" title="Open domain and retrieval-based approach"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec102"/>Open domain and retrieval-based approach</h3></div></div></div><p>If we<a id="id916" class="indexterm"/> want to build a chatbot that can operate on an open domain using a retrieval-based approach, then as coders, we need to hardcode pretty much all the responses and possible questions as well as variations. This approach consumes a hell of a lot of time, so this type of chatbot is also not a part of this chapter.</p></div><div class="section" title="Closed domain and retrieval-based approach"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec103"/>Closed domain and retrieval-based approach</h3></div></div></div><p>We have<a id="id917" class="indexterm"/> understood that we can't operate on the open domain, but what about the closed domain? We can surely work on the closed domain as there is a finite number of questions that can be asked by a user to a chatbot and that a chatbot can answer. If we use the retrieval-based approach for a closed domain, then we can code questions that are relatively easy. We can integrate some NLP tools, such as a parser, <span class="strong"><strong>Name Entity Recognition</strong></span> (<span class="strong"><strong>NER</strong></span>), and so on in order to generate the most accurate answer.</p><p>Let's take an example. Suppose we want to build a chatbot that can give us real-time weather information for any location. If we build the chatbot using a retrieval-based approach, then the user will definitely get an accurate answer for questions such as <span class="emphasis"><em>What is the weather in Mumbai? What is the weather in California? Are there any chances of rainfall today?</em></span> The chatbot will give you answers to the first two questions really well, but during the third question, it will be confused because we don't provide a location for the chances of rainfall. If the chatbot has used some heuristics, then there will be a chance that you may get a response. Chatbot may ask you about the location for which you want to know the chances of rainfall, but mostly, this won't happen. The chatbot directly tells you the chances of rainfall in, say, California. In reality, I want to know the chances of rainfall in Mumbai. So, these kinds of context-related problems are common to the retrieval-based approach. We need to implement the generative-based approach to overcome context-related problems.</p></div><div class="section" title="Closed domain and generative-based approach"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec104"/>Closed domain and generative-based approach</h3></div></div></div><p>When <a id="id918" class="indexterm"/>we use the generative-based approach for the closed domain, the development of this kind of chatbot takes less coding time, and the quality of the answers improves as well. If we want our chatbot to understand long contexts and intents over a series of questions from the user, then the generative-based approach is the right choice. After training on large corpus and optimization, the chatbot can understand the context and intent of questions as well as be able to ask reasoning types of questions. This space of chatbot development is exciting and interesting for research and implementing new ideas.</p><p>Let's take<a id="id919" class="indexterm"/> an example. Suppose we have built a chatbot to apply for a home loan from a bank. When the user runs this chatbot, it may ask these questions: what is the status of my home loan application? Are there any documents remaining from my side that I should upload? Will I get approval in the next 2 days or not? Have you received my tax sheets and salary slips? The context of the last question is dependent on the second question. These kinds of questions and their answers can be easily generated with the generative-based approach.</p><p>Refer to the following figure, which will help us summarize all the preceding discussions:</p><div class="mediaobject"><img src="Images/B08394_08_01.jpg" alt="Closed domain and generative-based approach" width="1000" height="1000"/><div class="caption"><p> Figure 8.1: Pictorial representation of the approach to develop a chatbot</p></div></div><p>In this<a id="id920" class="indexterm"/> chapter, we will be building a chatbot that will be based on the closed domain and that uses retrieval-based and generative-based approaches.</p><p>Now let's look at the dataset that we will be using in this chapter.</p></div></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Understanding datasets"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec76"/>Understanding datasets</h1></div></div></div><p>In order<a id="id921" class="indexterm"/> to develop a chatbot, we are using two datasets. These <a id="id922" class="indexterm"/>datasets are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Cornell Movie-Dialogs dataset</li><li class="listitem" style="list-style-type: disc">bAbI dataset</li></ul></div><div class="section" title="Cornell Movie-Dialogs dataset"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec133"/>Cornell Movie-Dialogs dataset</h2></div></div></div><p>This dataset <a id="id923" class="indexterm"/>has been widely used<a id="id924" class="indexterm"/> for developing chatbots. You can download the Cornell Movie-Dialogs corpus from this link: <a class="ulink" href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html</a>. This<a id="id925" class="indexterm"/> corpus contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts.</p><p>This corpus has 220,579 conversational exchanges between 10,292 pairs of movie characters. It involves 9,035 characters from 617 movies. In total, it has 304,713 utterances. This dataset also contains movie metadata. There are the following types of metadata:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Movie-related metadata includes the following details:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Genre of the movie</li><li class="listitem" style="list-style-type: disc">Release year</li><li class="listitem" style="list-style-type: disc">IMDb rating</li></ul></div></li><li class="listitem" style="list-style-type: disc">Character-related metadata includes the following details:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Gender of 3,774 characters</li><li class="listitem" style="list-style-type: disc">Total number of characters in movies</li></ul></div></li></ul></div><p>When you download this dataset, you'll notice that there are two files we will be using throughout this chapter. The names of the files are <code class="literal">movie_conversations.txt</code> and <code class="literal">movie_lines.txt</code>. Let's look at the content details of each file.</p><div class="section" title="Content details of movie_conversations.txt"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec105"/>Content details of movie_conversations.txt</h3></div></div></div><p>This <a id="id926" class="indexterm"/>file contains <code class="literal">line_id</code> for the <code class="literal">movie_lines.txt</code> file. You can see the content of <code class="literal">movie_conversations.txt</code> in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_02.jpg" alt="Content details of movie_conversations.txt" width="608" height="113"/><div class="caption"><p>Figure 8.2: Sample content of the movie_conversations.txt file</p></div></div><p>As you can<a id="id927" class="indexterm"/> see in the preceding figure, this file contains line numbers, and the actual content of the conversation is present in <span class="emphasis"><em>movie_lines.txt</em></span>. <span class="emphasis"><em>+++$+++</em></span> acts as a separator. You must definitely be eager to know how to process this dataset; just bear with me for a while and we will cover this aspect in the upcoming sections.</p><p>Now let's look at the content of the next file.</p></div><div class="section" title="Content details of movie_lines.txt"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec106"/>Content details of movie_lines.txt</h3></div></div></div><p>This file <a id="id928" class="indexterm"/>contents the actual movie dialogs. You can see the sample content of <code class="literal">movie_lines.txt</code> in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_03.jpg" alt="Content details of movie_lines.txt" width="1000" height="170"/><div class="caption"><p>figure 8.3: Sample content of movie_lines.txt</p></div></div><p>As you can see in the preceding figure, each line has a unique conversation line ID. This <code class="literal">line_id</code> refers to the <code class="literal">movie_conversations.txt</code> file. This file contains the same line separator and the names of the characters involved in the conversation.</p><p>If you see the both files together, then it is might make more sense to you. In the <code class="literal">movie_conversations.txt</code> file, refer to the conversations on <span class="emphasis"><em>line_id 194, 195, 196</em></span>, and<span class="emphasis"><em> 197</em></span>. All these conversations can be found in <code class="literal">movie_lines.txt.</code> In the preceding image, you can see that <span class="emphasis"><em>line_id</em></span> <span class="emphasis"><em>194 </em></span>contains this question: <span class="emphasis"><em>Can we make this quick? Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad. Again.</em></span> On the other hand, <span class="emphasis"><em>line_id</em></span> <span class="emphasis"><em>195</em></span> contains the answer: <span class="emphasis"><em>Well, I thought we'd start with pronunciation, if that's okay with you.</em></span>
</p><p>We need to <a id="id929" class="indexterm"/>prepare the dataset in the form of a question-answer format before feeding it to the machine. We will implement the data preparation step before using it for training.</p><p>Now let's look at the bAbI dataset.</p></div></div><div class="section" title="The bAbI dataset"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec134"/>The bAbI dataset</h2></div></div></div><p>This <a id="id930" class="indexterm"/>dataset is built by Facebook AI Research (FAIR), where<a id="id931" class="indexterm"/> AI stands for artificial intelligence. This<a id="id932" class="indexterm"/> dataset belongs to the bAbI project. You can download the dataset from <a class="ulink" href="https://research.fb.com/downloads/babi/">https://research.fb.com/downloads/babi/</a>. It is a well-maintained dataset. The goal of the bAbI project is to try to build an automatic text understanding and reasoning system. This dataset consists of the following sub datasets:  </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The (20) QA bAbI tasks</li><li class="listitem" style="list-style-type: disc">The (6) dialog bAbI tasks</li><li class="listitem" style="list-style-type: disc">The Children's Book Test</li><li class="listitem" style="list-style-type: disc">The Movie Dialog dataset</li><li class="listitem" style="list-style-type: disc">The WikiMovies dataset</li><li class="listitem" style="list-style-type: disc">The Dialog-based Language Learning dataset</li><li class="listitem" style="list-style-type: disc">The SimpleQuestions dataset</li><li class="listitem" style="list-style-type: disc">HITL Dialogue Simulator</li></ul></div><p>We will be using only one subset here, which is the (20) QA bAbI tasks because it is the one that's most useful for building the chatbot.</p><div class="section" title="The (20) QA bAbI tasks"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec107"/>The (20) QA bAbI tasks</h3></div></div></div><p>Let's <a id="id933" class="indexterm"/>look at this subdataset in detail. Here, 20 different tasks have been performed using this (20) QA bAbI dataset. Let's see what these tasks are. These tasks give machines the capacity to perform some reasoning, and based on that, the machine can answer a question. You can refer to the task name given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_04.jpg" alt="The (20) QA bAbI tasks" width="275" height="681"/><div class="caption"><p>Figure 8.4: (20) QA bAbI task details</p><p>Image source:  http://www.thespermwhale.com/jaseweston/babi/abordes-ICLR.pdf</p></div></div><p>Facebook <a id="id934" class="indexterm"/>researchers Jason Weston, Antoine Bordes, Sumit Chopra, Alexander M. Rush, Bart van Merriënboer, Armand Joulin, and Tomas Mikolov published a paper in which they proposed an interesting AI-based QA system. You can refer to their research paper by visiting <a class="ulink" href="https://arxiv.org/abs/1502.05698">https://arxiv.org/abs/1502.05698</a>. In this chapter, we will be attempting to achieve the results for task T1, and we will regenerate its result.</p><p>This dataset contains the corpus in two languages, English and Hindi. There are two types of folders here: the folder with the name <span class="emphasis"><em>en </em></span>has 1,000 training examples, whereas <span class="emphasis"><em>en-10K</em></span> has 10,000 training examples. The format for each of the task datasets is given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_05.jpg" alt="The (20) QA bAbI tasks" width="446" height="226"/><div class="caption"><p>Figure 8.5: Format of Single supporting QA bAbI task</p></div></div><p>The supporting facts are called a story. Based on the story, the user can ask questions to the machine, and the machine should give the logically correct answer that can be derived from the provided supporting text. This is a hard task because in this case, the machine should remember the long context that it can use as and when needed. We will use this interesting dataset soon.</p><p>Now let's start building the chatbot baseline version.</p></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Building the basic version of a chatbot"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec77"/>Building the basic version of a chatbot</h1></div></div></div><p>In this<a id="id935" class="indexterm"/> section, we will be building the basic version of a chatbot. Getting data is not an issue for any company nowadays but getting a domain-specific conversational dataset is challenging.</p><p>There are <a id="id936" class="indexterm"/>so many companies out there whose goal is to make an innovative domain-specific chatbot, but their major challenge is getting the right data. If you are facing the same issue, then this basic approach can help you in that. This basic version of a chatbot is based on the closed domain and the retrieval-based approach, which uses the rule-based system. So, let's start understanding each aspect of the rule-based system.</p><div class="section" title="Why does the rule-based system work?"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec135"/>Why does the rule-based system work?</h2></div></div></div><p>As I mentioned <a id="id937" class="indexterm"/>earlier, a rule-based system is the way to implementing a retrieval-based approach. Now, you may wonder<a id="id938" class="indexterm"/> why we need a rule-based system. Considering that we are living in the era of Machine Learning (ML), doesn't it sound old? Let me share my personal experience with you. I closely collaborate with many start-ups. Some of them operate in the financial domain, some in the human resource domain, and some in the legal domain. In this era of chatbots, start-ups are really keen on developing domain-specific chatbots that can help users. Initially, they work on some general dataset so that the machine can learn the language and generate the logical casual answers for them, but they soon realize that they don't have enough domain-specific data to help them build a good chatbot. Let me give you an example.</p><p>I collaborated with a fintech start-up where we needed to build a chatbot. The specific requirement for the chatbot was that it should help customers who want to apply for a home loan as well as those who have already applied and need some assistance. Now, this fintech just started 1 and a half years ago. So they don't have large chat logs about the kind of queries customers may have. In short, the company doesn't have enough domain-specific data, such as what kind of queries a home loan applicant may ask and how to synchronize these customer queries to the loan procedure this fintech company follows. In this case, there are two main things that we need to focus on:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We need to build a minimum viable chatbot that can help customers with basic FAQs</li><li class="listitem" style="list-style-type: disc">With the help of this minimum viable chatbot, you can also come to learn what kind of questions people are asking, and based on these questions, the chatbot can be tweaked  </li></ul></div><p>In these kind of situations, where we don't have a domain-specific dataset, the rule-based or retrieval-based model will work for us. From the next section onward, we will explore the rule-based system and the approach of developing a basic chatbot and its architecture.</p></div><div class="section" title="Understanding the rule-based system"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec136"/>Understanding the rule-based system</h2></div></div></div><p>In this section, we <a id="id939" class="indexterm"/>will cover the rule-based system so that you don't feel left out when we start developing the retrieval-based chatbot. The <span class="strong"><strong>rule</strong></span>-<span class="strong"><strong>based</strong></span> (<span class="strong"><strong>RB</strong></span>) system is defined as follows: using available knowledge or <a id="id940" class="indexterm"/>rules, we develop a system that uses the rules, apply the available system rules on the corpus, and try to generate or infer the results. From the perspective of the chatbot, the RB system has all possible questions and answers and they're hardcoded. We can definitely use regular expressions and fuzzy logic to implement some kind of heuristics in order to make the RB system more accurate.</p><p>Refer to the following figure, which will give you an idea about the workflow of the chatbot using the retrieval-based approach:</p><div class="mediaobject"><img src="Images/B08394_08_06.jpg" alt="Understanding the rule-based system" width="1000" height="327"/><div class="caption"><p>Figure 8.6: Workflow of rule-based chatbot</p></div></div><p>Based on the preceding figure, you know that in an RB system we will manually hand-code all possible questions and answers as well as implement regular expressions and fuzzy logic, which will give the chatbot the ability to generate the appropriate answers. Based on business requirements, questions can be added and deleted from this system. Now let's discuss our approach, and based on this approach we will build a basic version of the chatbot.</p></div><div class="section" title="Understanding the approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec137"/>Understanding the approach </h2></div></div></div><p>In this section, we<a id="id941" class="indexterm"/> will look at the steps that will help us implement the basic version of the chatbot. Here, I'm building a chatbot for the finance domain, which will help users apply for home loans. We will code some questions so that you know how a rule-based chatbot can be developed. We need to perform the <a id="id942" class="indexterm"/>following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Listing down possible questions and answers.</li><li class="listitem">Deciding standard messages.</li><li class="listitem">Understanding the architecture.</li></ol></div></div><div class="section" title="Listing down possible questions and answers"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec138"/>Listing down possible questions and answers</h2></div></div></div><p>First of all, we need to list all the questions that we can think of on behalf of the users. Once we decide on the questions, then one by one we need to decide the answers to these questions. Suppose <a id="id943" class="indexterm"/>we ask the user to provide their full name, email ID, phone number, and loan amount so in case the user drops in between, the customer executive can call them back. After this, we ask the user what kind of assistance they require and then they can ask their questions. They may ask for the eligibility criteria, application status, document requirements, and so on. During the first iteration, you need to add the bare minimum questions that are frequently asked by users. Once we decide the questions and answers, it will be easy for us to code them.</p><p>Say, I include the following questions in this basic version of the financial domain chatbot:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Please let me know the eligibility criteria for getting a home loan</li><li class="listitem" style="list-style-type: disc">Please let me know what the status of my loan application is</li><li class="listitem" style="list-style-type: disc">Let me know the list of documents I need to submit</li></ul></div><p>The answers to <a id="id944" class="indexterm"/>each of these questions will be as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We need a minimum of 3 years of job experience, 3 years of IT returns, and a minimum income of more than 3.5 lakh INR</li><li class="listitem" style="list-style-type: disc">Your application is with our credit risk management team </li><li class="listitem" style="list-style-type: disc">You need to submit salary slips for the last 6 months, a proof of identity, 3 years of IT returns, and the lease documents for your house.</li></ul></div><p>We also need to decide some standard messages, which we will cover in the next section.</p></div><div class="section" title="Deciding standard messages"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec139"/>Deciding standard messages</h2></div></div></div><p>We need to decide the standard message, for example, a welcome message from the chatbot. If the user<a id="id945" class="indexterm"/> asks a question that the chatbot cannot answer, then what message should pop up? We also need to decide the message when the user ends the chat.</p><p>These standard messages help users understand what they can and cannot ask the chatbot. Now let's look at the architectural part of the basic version of the chatbot.</p></div><div class="section" title="Understanding the architecture"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec140"/>Understanding the architecture</h2></div></div></div><p>In this <a id="id946" class="indexterm"/>section, let's talk about architecture. When we are building a domain-specific rule-based chatbot, then we need to store whatever questions the users ask. We also need to build a chatbot that is fast and scalable. In this approach, we build the web services. The web service REST APIs will be easily integrated with the website and the frontend. We need a database that can store the conversations of the users. This conversation data will be helpful when we try to improvise the chatbot or use it for ML training. The libraries that I'm using are given as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Flask for implementing web services and REST APIs</li><li class="listitem" style="list-style-type: disc">MongoDB for storing the conversations. The reason behind choosing the NoSQL database is that conversations don't have a specific format. NoSQL is a good option to store schema-less data. We need to store the raw conversations, so NoSQL is a good option.</li></ul></div><p>You can refer to the following figure, which will help you understand the entire architecture and process:</p><p> </p><div class="mediaobject"><img src="Images/B08394_08_07.jpg" alt="Understanding the architecture" width="1000" height="508"/><div class="caption"><p>Figure 8.7: Architectural design for the basic version of a chatbot</p></div></div><p>
</p><p>Based on this<a id="id947" class="indexterm"/> architecture, you will find that the process flow of the basic version of a chatbot is quite simple. This flow involves seven simple steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The user will ask their questions to the chatbot.</li><li class="listitem">The rule-based engine of the chatbot will process the question. Here, the REST API has been called to generate the response.</li><li class="listitem">If the question that's asked is available to the RB system, then the user will get an appropriate answer.</li><li class="listitem">If the question that's asked is not available to the RB system, then the user will not get the answer but a standard error message.</li><li class="listitem">The conversation of the user will be stored in the MongoDB database. This response is in the JSON format.</li><li class="listitem">The same JSON response is sent by the REST API to the frontend. At the frontend, a JavaScript parses this response and pops up the appropriate answer.</li><li class="listitem">When the user gets their answer, they may end the chat or ask another question.</li></ol></div><p>Another major point that I want to highlight is that before storing the data to MongoDB, we need to finalize the attributes of the JSON response that will actually help us when we parse the JSON <a id="id948" class="indexterm"/>response using JavaScript. You can refer to the following screenshot, which will help you learn which kind of JSON schema I have decided on: </p><div class="mediaobject"><img src="Images/B08394_08_08.jpg" alt="Understanding the architecture" width="488" height="369"/><div class="caption"><p>Figure 8.8: Understanding the JSON response attribute</p></div></div><p>The usage of each of the JSON attributes is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">current_form_action:</code> This<a id="id949" class="indexterm"/> attribute indicates which REST API is currently being invoked.</li><li class="listitem" style="list-style-type: disc"><code class="literal">message_bot:</code> This<a id="id950" class="indexterm"/> field carries the answer from the bot.</li><li class="listitem" style="list-style-type: disc"><code class="literal">message_human:</code> This<a id="id951" class="indexterm"/> field carries the query of the user.</li><li class="listitem" style="list-style-type: disc"><code class="literal">next_field_type:</code> If we<a id="id952" class="indexterm"/> need to populate the textbox or button in the next question, this is useful for generating dynamic HTML components.</li><li class="listitem" style="list-style-type: disc"><code class="literal">next_form_action:</code> This <a id="id953" class="indexterm"/>attribute indicates which REST API we should invoke in the upcoming request.</li><li class="listitem" style="list-style-type: disc"><code class="literal">placeholder_text:</code> If <a id="id954" class="indexterm"/>you want to put watermark text in the textbox, then this attribute helps you with the HTML functionality.</li><li class="listitem" style="list-style-type: disc"><code class="literal">previous_field_type:</code> This<a id="id955" class="indexterm"/> attribute keeps track of what the last field type was.</li><li class="listitem" style="list-style-type: disc"><code class="literal">previous_form_action:</code> This <a id="id956" class="indexterm"/>attribute keeps track of what the last REST API we invoked was.</li><li class="listitem" style="list-style-type: disc"><code class="literal">suggestion_message:</code> Sometimes, we need a message to invoke a specific rule. This is the same as <a id="id957" class="indexterm"/>when you say, <span class="emphasis"><em>OK Google</em></span> and the Google home assistance is invoked. This attribute basically guides the user as to what they need to expect when asking their queries.</li></ul></div><p>Now let's start the implementation of the rule-based chatbot.</p></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Implementing the rule-based chatbot"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec78"/>Implementing the rule-based chatbot</h1></div></div></div><p>In this section, we <a id="id958" class="indexterm"/>will understand the implementation of the chatbot. This implementation is divided into two parts. You can find this code by visiting: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_Rule_Based">https://github.com/jalajthanaki/Chatbot_Rule_Based</a>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Implementing the conversation flow</li><li class="listitem" style="list-style-type: disc">Implementing RESTful APIs using flask</li></ul></div><div class="section" title="Implementing the conversation flow"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec141"/>Implementing the conversation flow</h2></div></div></div><p>In order to<a id="id959" class="indexterm"/> implement the conversation logic, we are writing a separate Python script, so that whenever we need to add or delete some logic it will be easy for us. Here, we create one Python package in which we put this conversation logic. The name of the file is <span class="emphasis"><em>conversationengine.py</em></span> and it uses JSON, BSON, and re as Python dependencies.</p><p>In this file, we have implemented each conversation in the form of a function. When the user opens the chatbot for the first time, a welcome message should pop up. You can refer to the code given in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_08_09.jpg" alt="Implementing the conversation flow" width="999" height="316"/><div class="caption"><p>Figure 8.9: Code snippet for the welcome message</p></div></div><p>Now the users need to type in <span class="strong"><strong>Hi</strong></span> in order to start a conversation. When the user types <span class="strong"><strong>hi</strong></span>, the <code class="literal">start_coversation_action</code> function will be invoked and the chatbot will ask for some information so that it can give the<a id="id960" class="indexterm"/> user a more accurate, personalized answer. First, it asks the user their name, and then it asks for their email ID and phone number. You can refer to the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_08_10.jpg" alt="Implementing the conversation flow" width="1000" height="701"/><div class="caption"><p>Figure 8.10: Code snippet for asking basic user information</p></div></div><p>In the same<a id="id961" class="indexterm"/> way, there are the <code class="literal">borrowers_name_asking</code>, <code class="literal">borrowers_email_id_asking</code>, and <code class="literal">mobilenumber_asking</code> functions, which ask the user to provide their name, email ID, and phone number. Apart from this, there are questions that can help users learn what the status of their loan application is. If the customer is new, then they can ask questions such as <span class="emphasis"><em>what kind of documents are needed in order to apply for a home loan? </em></span>You can find these status- and document-related questions inside the <code class="literal">other_cases</code> function. You can refer to the code for this function in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_08_11.jpg" alt="Implementing the conversation flow" width="1000" height="507"/><div class="caption"><p>Figure 8.11: Code snippet for question related to loan application status and documents needed for applying for a home loan</p></div></div><p>As you can<a id="id962" class="indexterm"/> see in the preceding figure<span class="emphasis"><em>,</em></span> we have used a regular expression here so that the chatbot can answer status- and document-related questions. This is coded purely using keyword-based logic.</p><p>Now let's look at how to build the web service with this function using flask.</p></div><div class="section" title="Implementing RESTful APIs using flask"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec142"/>Implementing RESTful APIs using flask</h2></div></div></div><p>So far, we<a id="id963" class="indexterm"/> have only coded the function that takes the user input query and invokes the appropriate function based on that query. For better maintenance and easy integration, we need to implement RESTful APIs using flask. In order to implement this, we use the <code class="literal">flask</code>, <code class="literal">json</code>, <code class="literal">os</code>, <code class="literal">uuid</code>, <code class="literal">datetime</code>, <code class="literal">pytz</code>, and <code class="literal">flsk_pymongo </code>libraries. Flask is an easy-to-use web framework. You can find the code snippet in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_12.jpg" alt="Implementing RESTful APIs using flask" width="1000" height="300"/><div class="caption"><p>Figure 8.12: Code snippet for making a RESTful API for the chatbot</p></div></div><p>As you<a id="id964" class="indexterm"/> can see in the preceding figure, each route calls a different method that is part of the <code class="literal">conversationengine.py</code> file we covered earlier. In order to run this flask engine, we need to use the flask <code class="literal">app.run ()</code> command. You can find all APIs and their functions by visiting: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_Rule_Based/blob/master/flaskengin.py">https://github.com/jalajthanaki/Chatbot_Rule_Based/blob/master/flaskengin.py</a>.</p><p>Now let's test this rule-based chatbot.</p></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Testing the rule-based chatbot"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec79"/>Testing the rule-based chatbot</h1></div></div></div><p>In this<a id="id965" class="indexterm"/> section, we will test the basic version of the chatbot. Let's begin with basic personal information that the chatbot asks for from the user. Here, I will generate the JSON response generated by the flask RESTful API. We need a JavaScript to parse this JSON response if we are integrating these APIs with the frontend. I won't explain the frontend integration part here, so let's analyze the JSON responses.</p><p>For the welcome message, refer to the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_08_13.jpg" alt="Testing the rule-based chatbot" width="449" height="266"/><div class="caption"><p>Figure 8.13: JSON response for the welcome message</p></div></div><p>The JSON<a id="id966" class="indexterm"/> response when the chatbot is asking for the name of a user is given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_14.jpg" alt="Testing the rule-based chatbot" width="476" height="258"/><div class="caption"><p>Figure 8.14: JSON response for asking the name of the user</p></div></div><p>If the user<a id="id967" class="indexterm"/> asks for the status of his application, then they will get the JSON response given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_15.jpg" alt="Testing the rule-based chatbot" width="488" height="276"/><div class="caption"><p>Figure 8.15: JSON response to get status-related information</p></div></div><p>If the user asks status-related questions with a blend of Hindi-English (Hinglish) and if they use the word <span class="emphasis"><em>status </em></span>in their query, then the chatbot will generate the response. You can see the response in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_16.jpg" alt="Testing the rule-based chatbot" width="510" height="270"/><div class="caption"><p>Figure 8.16: json response to get status-related information for the Hindi-English (Hinglish) language</p></div></div><p>If the user <a id="id968" class="indexterm"/>asks queries that are not coded, then it will generate the following json response:</p><div class="mediaobject"><img src="Images/B08394_08_17.jpg" alt="Testing the rule-based chatbot" width="644" height="269"/><div class="caption"><p>Figure 8.17: JSON response for an unknown question</p></div></div><p>After testing, we come to learn that queries that have been coded are working fine, but this basic version of a chatbot is not working properly for questions that we haven't coded. I want to point out some advantages after testing the rule-based chatbot. However, there are <a id="id969" class="indexterm"/>various disadvantages of this approach too, which we will discuss in an upcoming section.</p><div class="section" title="Advantages of the rule-based chatbot"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec143"/>Advantages of the rule-based chatbot</h2></div></div></div><p>You can<a id="id970" class="indexterm"/> refer to the following advantages of the rule-based chatbot:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Easy to code.</li><li class="listitem" style="list-style-type: disc">Needs less computation power.</li><li class="listitem" style="list-style-type: disc">Uses the pattern matching approach so if users use English and other languages in their conversation, they will still get an answer. This is because the chatbot identifies keywords that the user provides in their question. Suppose the user asks in English, <span class="emphasis"><em>can you provide me a list of documents that I need to submit?</em></span> And another user may ask a question in the Hindi language: <span class="emphasis"><em>Kya aap mujhe bata sakte hain mujhe kaun se documents submit karne hain? </em></span>For this question, the chatbot will generate the answer because it finds specific keywords from user queries, and if those keywords are present, then the chatbot generates an answer irrespective of the language.</li></ul></div><p>Now let's look at the problems related to this approach that we need to solve in order to improve the chatbot.</p></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Problems with the existing approach"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec80"/>Problems with the existing approach</h1></div></div></div><p>In this section, we will discuss the problems with the basic version of our chatbot. As we already know, for <a id="id971" class="indexterm"/>unseen queries this approach doesn't work, which means that the basic approach is not able to generalize the user's questions properly.</p><p>I have listed down some of the problems here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Time consuming because we need to hardcode each and every scenario, which is not feasible at all</li><li class="listitem" style="list-style-type: disc">It cannot work for unseen use cases</li><li class="listitem" style="list-style-type: disc">The user should process the rigid flow of conversation</li><li class="listitem" style="list-style-type: disc">It cannot understand the long context</li></ul></div><p>Most of these problems can be solved using the generative-based approach. Let's look at the key concepts that will help us improvise this approach.</p><div class="section" title="Understanding key concepts for optimizing the approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec144"/>Understanding key concepts for optimizing the approach</h2></div></div></div><p>In this section, we will <a id="id972" class="indexterm"/>be discussing the key concepts that can help us improvise the chatbot basic version. The problems that we have listed down previously can be solved by using <span class="strong"><strong>Deep Learning</strong></span> (<span class="strong"><strong>DL</strong></span>) techniques, which <a id="id973" class="indexterm"/>can help us build a more generalized chatbot in less time.</p><p>Before proceeding ahead, we need to decide which DL technique we will use for our revised approach. DL helps us achieve great results. Here, we need to use the End-to-End DL approach that makes no assumptions about data, the structure of the dialog, and use cases. This is what we want. In order to achieve this, we will be using <span class="strong"><strong>Recurrent Neural Nets</strong></span> (<span class="strong"><strong>RNN</strong></span>). Now <a id="id974" class="indexterm"/>you may ask why RNN is useful. Let me explain this by way of an example. Suppose we want to classify the temperature in the hot or cold category; to do that, we will be using a feed forward neural net to classify the temperature into hot or cold, but the conversation isn't a fixed size. A conversation is a sequence of words. We need to use a neural net that can help us process the sequences of words. RNN is best for processing these kinds of sequences. In RNN, we feed data back into the input while training it in a recurring loop.</p><p>In the revised approach, we are going to use the sequence-to-sequence (seq2seq) model from TensorFlow. So, let's discuss the sequence model for a bit.</p><div class="section" title="Understanding the seq2seq model"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec108"/>Understanding the seq2seq model</h3></div></div></div><p>The <a id="id975" class="indexterm"/>good part of using the seq2seq model is that we don't need to perform feature engineering. Like most of the DL techniques, it <a id="id976" class="indexterm"/>generates features by its own. We will discuss the seq2seq model briefly. The seq2seq model <a id="id977" class="indexterm"/>consists of two <span class="strong"><strong>Long Short Term Memory</strong></span> (<span class="strong"><strong>LSTM</strong></span>) recurrent neural networks. The first neural net is an <span class="emphasis"><em>encoder</em></span>. It<a id="id978" class="indexterm"/> processes the input. The second neural net is a <span class="emphasis"><em>decoder</em></span>. It <a id="id979" class="indexterm"/>generates the output. Usually, the DL algorithm needs a dimensionality of the inputs and outputs to be a fixed size, but here, we are accepting a sequence of words in a sentence and outputting a new sequence of words. So, we need a sequence model that can learn data with long range memory dependencies. The LSTM architecture is best suited for this. The encoder LSTM turns the input sentence of <a id="id980" class="indexterm"/>variable length into a fixed dimensional vector representation. We can think of this as a <span class="emphasis"><em>thought vector</em></span> or a <span class="emphasis"><em>context vector</em></span>. The reason we are using LSTM is that it can remember <a id="id981" class="indexterm"/>words from far back in the sequence; here, we are dealing with large sequence attention mechanisms of the seq2seq model, which helps the decoder selectively look at the parts of the sequence that are most relevant for more accuracy.</p><p>You can refer to the architecture of the seq2seq model in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_18.jpg" alt="Understanding the seq2seq model" width="1000" height="302"/><div class="caption"><p>Figure 8.18: Architecture of the seq2seq model</p><p>Image source:  <a class="ulink" href="http://suriyadeepan.github.io/img/seq2seq/seq2seq2.png">http://suriyadeepan.github.io/img/seq2seq/seq2seq2.png</a>
</p></div></div><p>When we<a id="id982" class="indexterm"/> provide a large enough dataset of questions and responses, it will recognize the closeness of the set of questions and represent them as a single thought vector. This representation helps the machine to understand the intent of the questions irrespective of the structure of the sentence so the machine can recognize the questions such as "what time it is?" and "what's the time?" have the same intent, so they will fall into a single thought vector. After training, we will have a huge set of not just synapse weights but thought vectors as well. After that, we need to use additional hyper parameters along with appropriate loss functions when we train the model. Once we train the model, we can chat with it.</p><p>If you want to know more details about the seq2seq model, then you should refer to a research paper published by Google researchers titled <span class="emphasis"><em>A Neural Conversational Model</em></span>. You can also refer to this paper at: <a class="ulink" href="https://arxiv.org/pdf/1506.05869v3.pdf">https://arxiv.org/pdf/1506.05869v3.pdf </a>and this amazing article if you want to learn more about LSTM at: <a class="ulink" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>.</p><p>Now let's implement the chatbot using the seq2seq model.</p></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Implementing the revised approach"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec81"/>Implementing the revised approach</h1></div></div></div><p>In this<a id="id983" class="indexterm"/> section, we will cover each part of the implementation. You can find the code by using this GitHub link: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_tensorflow">https://github.com/jalajthanaki/Chatbot_tensorflow</a>. Note that here, I'm using TensorFlow version 0.12.1. I perform training on a GeForce GTX 1060 6GB GPU for a few hours. In <a id="id984" class="indexterm"/>this implementation, we don't need to generate features because the seq2seq model generates its internal representation for sequences of words given in a sentence. Our implementation<a id="id985" class="indexterm"/> part has the following steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Data preparation</li><li class="listitem" style="list-style-type: disc">Implementing the seq2seq model </li></ul></div><p>Let's begin our coding.</p><div class="section" title="Data preparation"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec145"/>Data preparation</h2></div></div></div><p>During this<a id="id986" class="indexterm"/> implementation, we will be using the Cornell movie-dialogs dataset. First of all, we need to prepare data in a format that we can use for training. There is a Python script that is used to perform data preparation. You can find the script at: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_tensorflow/blob/master/data/prepare_data_script/data.py">https://github.com/jalajthanaki/Chatbot_tensorflow/blob/master/data/prepare_data_script/data.py</a>.</p><p>Data preparation can be subdivided into the following steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Generating question-answer pairs</li><li class="listitem" style="list-style-type: disc">Preprocessing the dataset</li><li class="listitem" style="list-style-type: disc">Splitting the dataset into the training dataset and the testing dataset</li><li class="listitem" style="list-style-type: disc">Building a vocabulary for the training and testing datasets</li></ul></div><div class="section" title="Generating question-answer pairs"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec109"/>Generating question-answer pairs</h3></div></div></div><p>In order to <a id="id987" class="indexterm"/>generate question-answer pairs from the Cornell movie-dialogs dataset, we are using the <code class="literal">movie_lines.txt</code> and <code class="literal">movie_conversations.txt </code>files. The <code class="literal">movie_lines.txt </code>files give us information about<span class="emphasis"><em> line_id</em></span>
<code class="literal"> </code>of each conversation along with the real conversation, whereas <code class="literal">movie_conversations.txt </code>has <span class="emphasis"><em>line_ids</em></span> only. In this situation, we need to generate the appropriate pair of conversations of question and answer from the dataset. For that, we will combine these two files. In Python script, there are some functions that help us combine these files. The details related to functions are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">get_id2line():</code> This<a id="id988" class="indexterm"/> function helps us spilt the data using the +++$+++ pattern. We perform splitting on the <code class="literal">movie_lines.txt</code> file. After splitting, with the help of this function, we create a dictionary in which we put <span class="emphasis"><em>line_id</em></span> as the key and the movie dialog as the value. So, <span class="emphasis"><em>key = line_id</em></span> and <span class="emphasis"><em>value = text</em></span></li><li class="listitem" style="list-style-type: disc"><code class="literal">get_conversations():</code> This<a id="id989" class="indexterm"/> function splits the data given in the <code class="literal">movie_conversations.txt </code>file. This will help us create a list. This list contains list of <span class="emphasis"><em>line_ids</em></span>.</li><li class="listitem" style="list-style-type: disc"><code class="literal">gather_dataset():</code> This function actually generates question-answer pairs. In this function, a simple logic is applied. We take the list of <span class="emphasis"><em>line_ids</em></span> and we know<a id="id990" class="indexterm"/> that the last element indicates the answer. So, we separate the questions and answers. With the help of the <code class="literal">get_id2line()</code> function, we search the questions and their corresponding answers. Here, we are using the value of the key to search questions and answers.</li></ul></div><p>You can refer<a id="id991" class="indexterm"/> to the following screenshot to see the actual coding: </p><div class="mediaobject"><img src="Images/B08394_08_19.jpg" alt="Generating question-answer pairs" width="1000" height="774"/><div class="caption"><p>Figure 8.19: Functions used for generating question-answer pairs</p></div></div><p>Now let's explore the data preprocessing section.</p></div><div class="section" title="Preprocessing the dataset"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec110"/>Preprocessing the dataset</h3></div></div></div><p>Some preprocessing and filtering <a id="id992" class="indexterm"/>steps are involved here. As a part of preprocessing, we perform the following steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We convert the conversation into lowercase using the inbuilt string function, <code class="literal">lower()</code>.</li><li class="listitem" style="list-style-type: disc">We also remove the junk characters and too short or too long conversations. For this, we use a list-based approach to remove junk characters and the <code class="literal">filter_data()</code> function to remove too short or too long conversations. When we apply the <code class="literal">filter_data()</code> function on our dataset, <span class="emphasis"><em>28%</em></span> of dataset is filtered.  </li><li class="listitem" style="list-style-type: disc">We also filter out conversations with so many unknowns. Here, <span class="emphasis"><em>2%</em></span> of the dataset has been affected. For this, we have used the <code class="literal">filter_unk()</code> method.</li><li class="listitem" style="list-style-type: disc">We also tokenize the sentences. In this process, we convert <span class="emphasis"><em>list of [line of text] </em></span>into<span class="emphasis"><em> list of [line of words]</em></span>. This tokenization is helpful because during training, the machine can process individual words of the sentence, and with the help of the word ID, data retrieval becomes much faster.</li></ul></div><p>You can refer to the code given in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_08_20.jpg" alt="Preprocessing the dataset" width="746" height="669"/><div class="caption"><p>Figure 8.20: Code snippet for preprocessing</p></div></div></div><div class="section" title="Splitting the dataset into the training dataset and the testing dataset"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec111"/>Splitting the dataset into the training dataset and the testing dataset</h3></div></div></div><p>After <a id="id993" class="indexterm"/>preprocessing, we will split the data into the training dataset and the testing dataset and for that, we will use the following functions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We can save the training and testing datasets using the <code class="literal">prepare_seq2seq_files()</code> function </li><li class="listitem" style="list-style-type: disc">You can access the <code class="literal">train.enc</code>, <code class="literal">train.dec</code>, <code class="literal">test.enc</code>, and <code class="literal">test.dec</code> data files directly from this GitHub link: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_tensorflow/tree/master/data">https://github.com/jalajthanaki/Chatbot_tensorflow/tree/master/data</a> </li></ul></div></div><div class="section" title="Building a vocabulary for the training and testing datasets"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec112"/>Building a vocabulary for the training and testing datasets</h3></div></div></div><p>Now it's time to<a id="id994" class="indexterm"/> generate the vocabulary from the dataset. For vocabulary generation, we will perform the following steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Using the <code class="literal">prepare_custom_data()</code> function of the <code class="literal">data_utils.py</code> file, we can generate the vocabulary that we will feed into the seq2seq model while training.</li><li class="listitem" style="list-style-type: disc">You can access the <code class="literal">data_uti</code><code class="literal">ls.py</code> file using this link: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_tensorflow/blob/master/data_utils.py">https://github.com/jalajthanaki/Chatbot_tensorflow/blob/master/data_utils.py</a></li><li class="listitem" style="list-style-type: disc">Note that vocabulary files are generated when we start training.</li><li class="listitem" style="list-style-type: disc">The filenames of vocabulary files are <code class="literal">train.enc.ids20000</code>, <code class="literal">train.dec.ids20000</code>, <code class="literal">test.enc.ids20000</code>, and <code class="literal">test.dec.id</code><code class="literal">s20000</code>. Here, 20000 indicates the size of the vocabulary we have provided.</li><li class="listitem" style="list-style-type: disc">You can access this file at: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_tensorflow/tree/master/data">https://github.com/jalajthanaki/Chatbot_tensorflow/tree/master/data</a></li></ul></div><p>You can see the code for the <code class="literal">prepare_custom_data()</code> function in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_08_21.jpg" alt="Building a vocabulary for the training and testing datasets" width="1000" height="338"/><div class="caption"><p>Figure 8.21: Code snippet for generating the vocabulary</p></div></div><p>Now let's actually implement the seq2seq model using TensorFlow.</p></div></div><div class="section" title="Implementing the seq2seq model"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec146"/>Implementing the seq2seq model</h2></div></div></div><p>In this section, we <a id="id995" class="indexterm"/>chatbot development:seq2seq model, building" will be performing the actual training using the seq2seq model. We will be using TensorFlow to implement the seq2seq model. Before getting into training, let's look into the hyper parameters configuration file, which you can access using this GitHub link: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_tensorflow/blob/master/seq2seq.ini">https://github.com/jalajthanaki/Chatbot_tensorflow/blob/master/seq2seq.ini</a>.</p><p>During<a id="id996" class="indexterm"/>chatbot development:seq2seq model, building"  training, our script uses these files and their parameters. The following parameters are in this configuration file:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">Mode</code>: This can be either train or test</li><li class="listitem" style="list-style-type: disc"><code class="literal">train_enc:</code> This contains the path of the training dataset for the encoder.</li><li class="listitem" style="list-style-type: disc"><code class="literal">train_dec:</code> This contains the path of the training dataset for the decoder.</li><li class="listitem" style="list-style-type: disc"><code class="literal">test_enc:</code> This contains the path of the testing dataset for the encoder.</li><li class="listitem" style="list-style-type: disc"><code class="literal">test_dec:</code> This contains the path of the testing dataset for the decoder.</li><li class="listitem" style="list-style-type: disc"><code class="literal">Working_directory:</code> This is the folder where we can store our checkpoints, vocabulary, and temporary data files</li><li class="listitem" style="list-style-type: disc"><code class="literal">enc_vocab_size:</code> This number defines the vocabulary size for the encoder. We set 20,000 as the vocabulary size.</li><li class="listitem" style="list-style-type: disc"><code class="literal">dec_vocab_size:</code> This number defines the vocabulary size for the decoder. We set 20,000 as the vocabulary size.</li><li class="listitem" style="list-style-type: disc"><code class="literal">num_layers:</code> This indicates the number of LSTM layers. Here, we set it as 3.</li><li class="listitem" style="list-style-type: disc"><code class="literal">layer_size:</code> This indicates the number of layers in the seq2seq model. We set it as 256.</li><li class="listitem" style="list-style-type: disc"><code class="literal">steps_per_checkpoint:</code> At a checkpoint, the model's parameters are saved, the model is evaluated, and results are printed.</li><li class="listitem" style="list-style-type: disc"><code class="literal">learning_rate:</code> This indicates how fast or how slow we train our model. We set the value to 0.5 for now.</li></ul></div><p>Most of the preceding parameters can be changed in order to get the best possible results. During training, we need to set the Mode as train and run the following command:</p><div class="informalexample"><pre class="programlisting">$ python execute.py</pre></div><p>Now it's time to understand what is inside the execute.py file. You can access this file using this GitHub link: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_tensorflow/blob/master/execute.py">https://github.com/jalajthanaki/Chatbot_tensorflow/blob/master/execute.py</a>.</p><p>In this script, we call the TensorFlow API. This script can be divided into the following parts:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Creating the model</li><li class="listitem" style="list-style-type: disc">Training the model</li></ul></div><div class="section" title="Creating the model"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec113"/>Creating the model</h3></div></div></div><p>We are <a id="id997" class="indexterm"/>using the <code class="literal">Seq2SeqModel() </code>function from TensorFlow here. This function reads the configuration file and uses the values defined in the configuration file. In order to store the train model, we use the <code class="literal">saver.restore()</code> function, and to get the status of the checkpoints we use the <code class="literal">get_checkpoint_state()</code> function. You can refer to the code snippet given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_22.jpg" alt="Creating the model" width="1000" height="280"/><div class="caption"><p>Figure 8.22: Code snippet for creating seq2seq model</p></div></div></div><div class="section" title="Training the model"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec114"/>Training the model</h3></div></div></div><p>We defined the <code class="literal">train()</code>method <a id="id998" class="indexterm"/>inside the <code class="literal">execute.py</code> file. This function initializes the TensorFlow session and begins training. You can refer to the code snippet given in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_08_23.jpg" alt="Training the model" width="1000" height="371"/><div class="caption"><p>Figure 8.23: Code snippet for training the model</p></div></div><p>Now it's <a id="id999" class="indexterm"/>time to train the model. When we execute the <code class="literal">python execute.py </code>command, you will see the output given in the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_08_24.jpg" alt="Training the model" width="1000" height="361"/><div class="caption"><p>Figure 8.24: Training of the seq2seq model using TensorFlow</p></div></div><p>Here, training has been performed on a GPU. I trained this model for 3 hours. I have trained this model for 15,000 checkpoints. You can refer to the following screesnhot:</p><div class="mediaobject"><img src="Images/B08394_08_25.jpg" alt="Training the model" width="801" height="579"/><div class="caption"><p>Figure 8.25: Output of the seq2seq training</p></div></div><p>On a CPU, training <a id="id1000" class="indexterm"/>will take a lot of time, so I have also uploaded pre-trained models for you to use. You can download them by using this GitHub link: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_tensorflow/tree/master/working_dir">https://github.com/jalajthanaki/Chatbot_tensorflow/tree/master/working_dir</a>.</p><p>Now it's time to understand the testing metrics that help us evaluate the trained model.</p></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Testing the revised approach"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec82"/>Testing the revised approach</h1></div></div></div><p>In this section, we <a id="id1001" class="indexterm"/>will perform testing of the revised approach. Before performing actual testing and seeing how good or bad the chatbot conversation is, we need to understand the basic testing metrics that we will be using for this approach and for the best approach. These testing metrics help us evaluate the model accuracy. Let's understand the testing metrics first, and then we will move on to the testing of the revised approach.</p><div class="section" title="Understanding the testing metrics"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec147"/>Understanding the testing metrics</h2></div></div></div><p>In this<a id="id1002" class="indexterm"/> section, we need to understand<a id="id1003" class="indexterm"/> the following testing metrics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Perplexity</li><li class="listitem" style="list-style-type: disc">Loss</li></ul></div><div class="section" title="Perplexity"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec115"/>Perplexity</h3></div></div></div><p>In the NLP domain, perplexity is<a id="id1004" class="indexterm"/> also referred to as per-word perplexity. Perplexity is a measurement of how well a trained model predicts the output for unseen data. It is also used to compare probability models. A low perplexity indicates that the probability distribution is good at predicting the sample. Even during training, you can see that for each checkpoint, perplexity is decreasing. Ideally, when there is no change in perplexity, we need to stop the training. During<a id="id1005" class="indexterm"/> the training of the seq2seq model, I stopped training after 3 hours, so when you train the model from your end you can wait till the perplexity stops decreasing further.</p><p>Perplexity is using the concept of entropy. If you want to know about perplexity, then you can refer to <a class="ulink" href="https://www.youtube.com/watch?v=BAN3NB_SNHY">https://www.youtube.com/watch?v=BAN3NB_SNHY</a>. Per-word perplexity is based on entropy. So, in order to understand entropy, you can refer to the following links:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="ulink" href="https://www.youtube.com/watch?v=Bd15qhUrKCI">https://www.youtube.com/watch?v=Bd15qhUrKCI</a></li><li class="listitem" style="list-style-type: disc"><a class="ulink" href="https://www.youtube.com/watch?v=K-rQ8KnmmH8">https://www.youtube.com/watch?v=K-rQ8KnmmH8</a></li><li class="listitem" style="list-style-type: disc"><a class="ulink" href="https://www.youtube.com/watch?v=ICKBWIkfeJ8&amp;list=PLAwxTw4SYaPkQXg8TkVdIvYv4HfLG7SiH">https://www.youtube.com/watch?v=ICKBWIkfeJ8&amp;list=PLAwxTw4SYaPkQXg8TkVdIvYv4HfLG7SiH</a></li></ul></div><p>Once you understand entropy, it will be easy for you to understand the equation of perplexity. Refer to the equation given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_26.jpg" alt="Perplexity" width="233" height="60"/><div class="caption"><p>Figure 8.26: Equation of perplexity</p><p>Image source:  https://www.tensorflow.org/tutorials/recurrent</p></div></div><p>Here, N is the number of samples and P is a probability function. We are calculating entropy using the natural logarithm function. Now let's look at another testing metric.</p></div><div class="section" title="Loss"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec116"/>Loss</h3></div></div></div><p>Training loss <a id="id1006" class="indexterm"/>indicates the direction in which the training progresses. Usually, when we start training, the value of loss is high and training accuracy is low, but during the training, the value of loss goes down and the training accuracy goes up. There are many error functions that are used in DL algorithms. Here, we<a id="id1007" class="indexterm"/> are using cross-entropy as a loss function. Cross-entropy and log loss are slightly different depending on the context, but in machine learning, when calculating error rates between 0 and 1, they are the same thing. You can refer to the equation given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_27.jpg" alt="Loss" width="704" height="604"/><div class="caption"><p>Figure 8.27: Equation for cross-entropy</p><p>Image source: http://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy</p></div></div><p>If you want to explore the cross-entropy loss function, then you can refer to: <a class="ulink" href="http://neuralnetworksanddeeplearning.com/chap3.html">http://neuralnetworksanddeeplearning.com/chap3.html</a>.</p><p>We haven't gone into great mathematical detail here because just by tracking the training process, you will get to know whether the value of loss is increasing or decreasing. If it is decreasing over the <a id="id1008" class="indexterm"/>period of training time, then the training is moving in the right direction. This is applicable to perplexity as well. Initially, the perplexity value is huge, but during training it gradually falls down and at some point it neither increases nor decreases. At that time, we need to stop the training. Now let's test the revised chatbot.</p></div></div><div class="section" title="Testing the revised version of the chatbot"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec148"/>Testing the revised version of the chatbot</h2></div></div></div><p>In this section, we <a id="id1009" class="indexterm"/>will be performing testing of the revised chatbot. I have trained it on a GPU for only 3 hours; now let's check how much our chatbot can tell us. For testing, we need to make a small change in the <code class="literal">seq2seq.ini</code> configuration file. We need to set <span class="emphasis"><em>value of mode as test</em></span> and then execute the <code class="literal">python execute.py</code> command.</p><p>After executing the given command, you will get the output given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_28.jpg" alt="Testing the revised version of the chatbot" width="1000" height="523"/><div class="caption"><p>Figure 8.28: Output of testing revised approach</p></div></div><p>If you train for a longer period of time, then you will get a more impressive result. I feel that DL algorithms help us if we want to build the chatbot using the generative-based approach. Now let's discuss how we can improvise this revised approach.</p></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Problems with the revised approach"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec83"/>Problems with the revised approach</h1></div></div></div><p>In this section, we <a id="id1010" class="indexterm"/>will be discussing what the problems with the revised approach are. Is there any way in which we can optimize the revised approach? So first of all, let's discuss the area of improvement so that during the upcoming approach, we can focus on that particular point.</p><p>Some of the points that I want to highlight are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">In the previous version of our chatbot there was a lack of reasoning, which means the chatbot couldn't answer the question by applying basic reasoning to it. This is what we need to improve.</li><li class="listitem" style="list-style-type: disc">Let me give you an example. Suppose I tell chatbot a story: <span class="emphasis"><em>John is in the kitchen. Daniel is in the bathroom</em></span>. After that, say, I ask the chatbot this question: <span class="emphasis"><em>Where is John?</em></span> The chatbot that we have built so far will not be able to answer this simple question. We as humans answer these kinds of questions well.</li><li class="listitem" style="list-style-type: disc">We try to implement this kind of functionality in our next approach so that we can enable some features of AI in the chatbot</li></ul></div><p>Let's look at the important concepts that can help us build the AI-enabled chatbot.</p><div class="section" title="Understanding key concepts to solve existing problems"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec149"/>Understanding key concepts to solve existing problems</h2></div></div></div><p>The <a id="id1011" class="indexterm"/>Facebook AI research group published a paper that proposed a Memory Network that can prove that the machine can also answer questions that are based on reasoning. You can certainly refer to this paper titled, Towards AI-Complete question answering: A set of prerequisite toy tasks. The link is: <a class="ulink" href="https://arxiv.org/pdf/1502.05698.pdf">https://arxiv.org/pdf/1502.05698.pdf</a>. You can also refer to this paper on the memory network at: <a class="ulink" href="https://arxiv.org/pdf/1410.3916.pdf">https://arxiv.org/pdf/1410.3916.pdf</a>.</p><p>Here, we will be using the bAbI dataset and train the model based on the improvised memory network. Once training is done, we will check whether our chatbot can answer questions based on using the simple reasoning ability or not. We will be recreating the result of the Facebook research paper. Before we move to the implementation part, we need to understand what memory networks are and how we can build a system that will use logic to answer questions. So, let's look at memory networks briefly.</p><div class="section" title="Memory networks"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec117"/>Memory networks</h3></div></div></div><p>In this section, we <a id="id1012" class="indexterm"/>will explore the memory network<a id="id1013" class="indexterm"/> so that we can understand what is actually happening behind the scenes when we implement it in the upcoming section.</p><p>Basically, in the LSTM network, memory is encoded by using hidden states and weights. These hidden states and weights are too small for extremely long sequences of data, be that a book or a movie. So, in a language translation application, multiple LSTM stats are used along with the attention mechanism in order to choose the appropriate work for translation<a id="id1014" class="indexterm"/> that fits the context. Facebook researchers have developed another strategy called a memory network that outperforms LSTMs for the question-answer system.</p><p>The basic<a id="id1015" class="indexterm"/> idea behind the memory network was to allow the neural network to use an external data structure as memory storage, and it learns where to retrieve the required memory from this external memory structure in a supervised way. You can refer to the architecture of the memory network given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_29.jpg" alt="Memory networks" width="1000" height="404"/><div class="caption"><p>Figure 8.29: Architecture of memory network</p></div></div><p>When it came to answering questions from the little data that was generated, the information was pretty easy to handle with the memory network, but in the real world, having the data handle long dependency relations is a challenging task. On Kaggle, there was a competition called The Allen AI Science Challenge in which the winner used a special variation of the memory network called a dynamic memory network (DMN), and that is what we are using to build our chatbot.</p><div class="section" title="Dynamic memory network (DMN)"><div class="titlepage"><div><div><h4 class="title"><a id="ch08lvl4sec51"/>Dynamic memory network (DMN)</h4></div></div></div><p>The <a id="id1016" class="indexterm"/>architecture of DMN is given in the<a id="id1017" class="indexterm"/> following figure:</p><div class="mediaobject"><img src="Images/B08394_08_30.jpg" alt="Dynamic memory network (DMN)" width="937" height="432"/><div class="caption"><p>Figure 8.30: Architecture of DMN</p><p>Image source:  https://yerevann.github.io/public/2016-02-06/dmn-high-level.png</p></div></div><p>The architecture of <a id="id1018" class="indexterm"/>DMN defines two types of memory, which are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Semantic memory: We <a id="id1019" class="indexterm"/>are using the pre-trained glove model that will generate vectors for input data. These vectors are the input to our DMN model and are used as semantic memory.</li><li class="listitem" style="list-style-type: disc">Episodic memory: This<a id="id1020" class="indexterm"/> memory contains other knowledge. The inspiration for this memory came from the hippocampus function of our brain. It's able to retrieve temporal states that are triggered by a response, such as an image or a sound. We will see the usage of this episodic memory in a bit.</li></ul></div><p>These are some important modules<a id="id1021" class="indexterm"/> that we need to understand:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Input module</li><li class="listitem" style="list-style-type: disc">Question module</li><li class="listitem" style="list-style-type: disc">Episodic memory module</li></ul></div><p>Before I start explaining the modules, please refer to the following figure for better understanding:</p><div class="mediaobject"><img src="Images/B08394_08_31.jpg" alt="Dynamic memory network (DMN)" width="1000" height="395"/><div class="caption"><p>Figure 8.31: Details on each DMN module</p><p>Image source:  https://yerevann.github.io/public/2016-02-06/dmn-details.png</p></div></div><div class="section" title="Input module"><div class="titlepage"><div><div><h5 class="title"><a id="ch08lvl5sec18"/>Input module</h5></div></div></div><p>The input module<a id="id1022" class="indexterm"/> is a GRU (Gated Recurrent Unit) that runs on a sequence of word vectors. A GRU cell is kind of like an LSTM cell, but it's more computationally efficient since it has only two gates and doesn't use a memory unit. The two gates control when the content is updated and when it's erased. There are only two tasks GRU is performing: one is <span class="emphasis"><em>Update </em></span>and the other is <span class="emphasis"><em>Reset</em></span>. You can refer to the following figure depicting LSTM and GRU:</p><div class="mediaobject"><img src="Images/B08394_08_32.jpg" alt="Input module" width="791" height="342"/><div class="caption"><p>Figure 8.32: Illustration of LSTM and GRU</p><p>Image source:  https://cdn-images-1.medium.com/max/1200/0*1udenjz1XCZ5cHU4</p></div></div><p>The hidden stats of the input module represent the input process in the form of a vector so far. It outputs hidden states after every sentence, and these outputs are called facts in the paper because they represent the essence of what is fed. You might want to know how the hidden state is calculated in GRU. For that, you can refer to the following equation:</p><p>Ht = GRU(Xt, ht-1)</p><p>Here, Ht is the <a id="id1023" class="indexterm"/>current timestep, ht-1 is the previous timestep, and Xt is the given word vector. The preceding equation is the simple format of the GRU hidden stat calculation. You can see more detailed and complex equations in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_33.jpg" alt="Input module" width="1000" height="293"/><div class="caption"><p>Figure 8.33: Equation for calculating the hidden state in GRU</p><p>Image source:  https://yerevann.github.io/public/2016-02-06/gru.png</p></div></div><p>In this equation, with the help of the given word vector and the previous timestep vector, we compute the current timestep vector. The update gave us a single layer neural network. We sum up the matrix multiplications and add bias terms to it. Then, the sigmoid squashes it to a list of values between 0 and 1, and that is our output vector. We do this twice with different sets of weights, and then we use the reset gate that will learn to ignore the past timesteps when necessary. For example, if the next sentence has nothing to do with those that came before it, the update gate is similar in that it can learn to ignore the current timestep entirely. Maybe the current sentence has nothing to do with the answer whereas previous ones did.</p></div><div class="section" title="Question module"><div class="titlepage"><div><div><h5 class="title"><a id="ch08lvl5sec19"/>Question module</h5></div></div></div><p>This <a id="id1024" class="indexterm"/>module processes the question word by word and outputs a vector using the same GRU as the input module and with the same weight. We need to code for input statements (input data) and for the question that we will ask. We can code them by implementing embedding layers for them. Now we need to create an episodic memory representation for both.</p></div><div class="section" title="Episodic memory"><div class="titlepage"><div><div><h5 class="title"><a id="ch08lvl5sec20"/>Episodic memory</h5></div></div></div><p>As I've described earlier, the concept of episodic memory derives from the hippocampus function of our brain. Both fact and question vectors extracted from the input and enter to the episodic <a id="id1025" class="indexterm"/>memory module. It is composed of two nested GRUs. The inner GRU generates what are called episodes. It does this by passing over the facts from the input module. When updating its inner state, it takes into account the output of an attention function on the current fact. The attention function gives a score between 0 and 1 to each fact and so the GRU ignores facts with low scores. During training, after each full pass on all the available facts, the inner GRU outputs an episode, which is then fed to the outer GRU. We need multiple episodes so that our model can learn what part of a sentence it should pay attention to. During the second pass, the GRU realizes that something else is also important in the sentence. With the help of multiple passes, we can gather increasingly relevant information.</p><p>This is a brief explanation of DMN. You can refer to this great article as well: <a class="ulink" href="https://yerevann.github.io/2016/02/05/implementing-dynamic-memory-networks/">https://yerevann.github.io/2016/02/05/implementing-dynamic-memory-networks/</a>.</p><p>Now let's look at the implementation for this.</p></div></div></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="The best approach"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec84"/>The best approach</h1></div></div></div><p>We have<a id="id1026" class="indexterm"/> covered the entire concept that can help us implement the DMN-based chatbot. In order to implement this approach, we will be using Keras with the TensorFlow backend. Without wasting any time, we will jump to the implementation section. You can refer to the code for this approach using this GitHub link: <a class="ulink" href="https://github.com/jalajthanaki/Chatbot_based_on_bAbI_dataset_using_Keras">https://github.com/jalajthanaki/Chatbot_based_on_bAbI_dataset_using_Keras</a>.</p><div class="section" title="Implementing the best approach"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec150"/>Implementing the best approach</h2></div></div></div><p>Here, we will train <a id="id1027" class="indexterm"/>our model on the given bAbI task 1 dataset. First of all, we need to parse the stories and build the vocabulary. You can refer to the code in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_34.jpg" alt="Implementing the best approach" width="888" height="846"/><div class="caption"><p>Figure 8.34: Code snippet for parsing stories and build vocabulary</p></div></div><p>We can <a id="id1028" class="indexterm"/>initialize our model and set its loss function as a categorical cross-entropy with stochastic gradient descent implementation using RMSprop in Keras. You can refer to the following screenshot:</p><div class="mediaobject"><img src="Images/B08394_08_35.jpg" alt="Implementing the best approach" width="653" height="363"/><div class="caption"><p>Figure 8.35: Code snippet for building the model</p></div></div><p>Before <a id="id1029" class="indexterm"/>training, we need to set a hyperparameter. With the help of the value of the hyperparameter script, we will decide whether to run the script in the training mode or the testing mode. You can see all the hyperparameters that we need to set during training in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_36.jpg" alt="Implementing the best approach" width="200" height="145"/><div class="caption"><p>Figure 8.36: Hyperparameter values for training</p></div></div><p>Here we have used three hyperparameters. We can experiment with them. Let's discuss them for a minute:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">train_epochs: This <a id="id1030" class="indexterm"/>parameter indicates the number of times the training examples complete a forward pass and backward pass in a neural network. One epoch means one forward pass and one backward pass of the training example. Here we are setting train_epochs 100 times. You can increase it but then the training time also increases.</li><li class="listitem" style="list-style-type: disc">batch_size: This <a id="id1031" class="indexterm"/>parameter indicates the number of training examples in one forward and backward pass. The higher batch size needs more memory so we have set this value to 32. If you have more memory available then you can increase the batch size. Please see the simple example given in the following information box.</li><li class="listitem" style="list-style-type: disc">lstm_size: This <a id="id1032" class="indexterm"/>parameter indicates the number of LSTM cells present in our neural network. You can decrease and increase the number of LSTM cells. In our case, less than 64 LSTM cells will not give us good output so I have set lstm_size to 64.</li></ul></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note11"/>Note</h3><p>If you have 1000 training examples and your batch size is 500 then it will take 2 iterations to complete 1 epoch.</p></div></div><p>I have trained this <a id="id1033" class="indexterm"/>model on a GPU. If you are not using a GPU then it may take a lot of time. You can start training by executing this command: <code class="literal">python main.py</code>. The output of the training is given in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_37.jpg" alt="Implementing the best approach" width="1000" height="221"/><div class="caption"><p>Figure 8.37: Code snippet for the training output</p></div></div><p>Once we train the model, we can load and test it. There are two testing modes available:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Random testing mode</li><li class="listitem" style="list-style-type: disc">User interactive testing mode</li></ul></div><div class="section" title="Random testing mode"><div class="titlepage"><div><div><h3 class="title"><a id="ch08lvl3sec118"/>Random testing mode</h3></div></div></div><p>In this <a id="id1034" class="indexterm"/>mode, the script itself will load a random story and give you its answer. You can see the value of the hyperparameters in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_38.jpg" alt="Random testing mode" width="201" height="147"/><div class="caption"><p>figure 8.38, Value of hyperparameters for random testing mode.</p></div></div><p>For testing, execute the <code class="literal">python main.py</code> command and you can see the testing results. These results have been shown in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_39.jpg" alt="Random testing mode" width="1000" height="35"/><div class="caption"><p>Figure 8.39: Result of a random testing mode</p></div></div><div class="section" title="User interactive testing mode"><div class="titlepage"><div><div><h4 class="title"><a id="ch08lvl4sec52"/>User interactive testing mode</h4></div></div></div><p>In this<a id="id1035" class="indexterm"/> mode, if the testing user can give their own story and ask their own question, the chatbot will generate the answer to that question. You just need to remember that before every word, you need to provide space. You can refer to the value of the hyperparameter for the user interactive testing mode in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_40.jpg" alt="User interactive testing mode" width="209" height="153"/><div class="caption"><p>Figure 8.40: Values of hyperparameters for the user interactive testing mode</p></div></div><p>For <a id="id1036" class="indexterm"/>testing, execute the <code class="literal">python main.py</code> command and you can see the testing results. These results are shown in the following figure:</p><div class="mediaobject"><img src="Images/B08394_08_41.jpg" alt="User interactive testing mode" width="1000" height="170"/><div class="caption"><p>Figure 8.41: Result of the user interactive testing mode</p></div></div><p>If you want to test all other tasks, then you can use this web application: <a class="ulink" href="https://ethancaballero.pythonanywhere.com/">https://ethancaballero.pythonanywhere.com/</a>.</p><p>This approach gives us up to 92 to 95% accuracy. This approach helps us build AI-enabled chatbots.</p></div></div></div></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Discussing the hybrid approach"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec85"/>Discussing the hybrid approach</h1></div></div></div><p>In a real-life scenario, in <a id="id1037" class="indexterm"/>order to build the chatbot we can also combine some of the techniques described here. As per the business needs we can use a hybrid approach.</p><p>Let's take an <a id="id1038" class="indexterm"/>example. Suppose you are building a chatbot for the finance domain. If a user asks for the available balance in his account then we just need a rule-based system, which can query the database and generate the account balance details for that user. If a user asks how he can transfer money from one account to the other account, the chatbot can help the user by generating step-by-step information on how to transfer money. Here, we will use the deep learning-based generative approach. We should have one system that includes a rule-based engine as well as a deep learning algorithm to generate the best possible output. In this system, a user's question first goes to the rule-based system. If that question's answer can be generated by the rule-based system, then the answer will be passed to the end user. If the answer is not generated by a rule-based system, then the question will pass further on to the deep learning algorithm and it will generate the answer. Finally, the end-user will see the response to his question.</p></div></div>



  
<div id="sbo-rt-content"><div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec86"/>Summary</h1></div></div></div><p>In this chapter, we referred to a different dataset in order to make a chatbot. You learned about the rule-based approach that can be used if you don't have any datasets. You also learned about the open and closed domains. After that, we used the retrieval-based approach in order to build the basic version of a chatbot. In the revised approach, we used TensorFlow. This revised approach is great for us because it saves time compared to the basic approach. We implemented Google's neural Conversational Model paper on the Cornell Movie-Dialogs dataset. For the best approach, we built a model that used the Facebook bAbI dataset and built the basic reasoning functionality that helped us generate good results for our chatbot. Although the training time for the revised and best approaches are really long, those who want to train the model on the cloud platform can choose to do so. So far, I like Amazon Web Services (AWS) and the Google Cloud platform. I also uploaded a pre-trained model to my GitHub repository so you could recreate the results. If you are a beginner and want to make a really good chatbot, then Google's API.AI is a good chatbot development platform. It is now known as Dialogflow and is available at: <a class="ulink" href="https://dialogflow.com/">https://dialogflow.com/</a>. You can also refer to the IBM Watson API at: <a class="ulink" href="https://www.ibm.com/watson/how-to-build-a-chatbot/">https://www.ibm.com/watson/how-to-build-a-chatbot/</a>. These APIs can help you a great deal in building a chatbot; plus it requires less coding knowledge.</p><p>In the next chapter, we will be building a computer vision-based application that will help us identify named objects present in images and videos. This application will detect objects in real time. The object-detection application is used to build self-driving cars, robots, and so on, so keep reading!</p></div></div>



  </body></html>