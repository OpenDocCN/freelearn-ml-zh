["```py\n\nimport pennylane as qml \n\nimport numpy as np \n\nimport torch \n\nimport torch.nn as nn \n\nseed = 1234 \n\nnp.random.seed(seed) \n\ntorch.manual_seed(seed)\n\n```", "```py\n\nphi = np.pi / 3 \n\ntheta = np.pi / 4 \n\ndelta = np.pi / 5\n\n```", "```py\n\ndef PrepareTrueState(): \n\n    qml.U3(theta, phi, delta, wires = 0)\n\n```", "```py\n\ndef GeneratorVF(weights): \n\n    qml.U3(weights[0], weights[1], weights[2], wires = 0) \n\ndef DiscriminatorVF(nqubits, weights, reps = 1): \n\n    par = 0 # Index for parameters. \n\n    for rep in range(reps): \n\n        for q in range(nqubits): \n\n            qml.RX(weights[par], wires = q) \n\n            par += 1 \n\n            qml.RY(weights[par], wires = q) \n\n            par += 1 \n\n            qml.RZ(weights[par], wires = q) \n\n            par += 1 \n\n        for i in range(nqubits - 1): \n\n            qml.CNOT(wires = [i, i + 1]) \n\n    for q in range(nqubits): \n\n        qml.RX(weights[par], wires = q) \n\n        par += 1 \n\n        qml.RY(weights[par], wires = q) \n\n        par += 1 \n\n        qml.RZ(weights[par], wires = q) \n\n        par += 1\n\n```", "```py\n\ndef Generator(weights): \n\n    GeneratorVF(weights) \n\ndef Discriminator(weights): \n\n    DiscriminatorVF(2, weights, reps = 3)\n\n```", "```py\n\nstate_0 = [[1], [0]] \n\nM = state_0 * np.conj(state_0).T\n\n```", "```py\n\ndev = qml.device(’default.qubit’, wires = 2) \n\n@qml.qnode(dev, interface=\"torch\", diff_method = \"backprop\") \n\ndef true_discriminator(weights_dis): \n\n    PrepareTrueState() \n\n    Discriminator(weights_dis) \n\n    return qml.expval(qml.Hermitian(M, wires = [0])) \n\n@qml.qnode(dev, interface=\"torch\", diff_method = \"backprop\") \n\ndef generator_discriminator(weights_gen, weights_dis): \n\n    Generator(weights_gen) \n\n    Discriminator(weights_dis) \n\n    return qml.expval(qml.Hermitian(M, wires = [0]))\n\n```", "```py\n\ndef discriminator_loss(weights_gen, weights_dis): \n\n    # Outcome of the discriminator with a generated state. \n\n    out_gen = generator_discriminator(weights_gen, weights_dis) \n\n    # Outcome of the discriminator with the true state. \n\n    out_true = true_discriminator(weights_dis) \n\n    return -(torch.log(1 - out_gen) + torch.log(out_true))/2\n\n```", "```py\n\ndef generator_loss(weights_gen, weights_dis): \n\n    out_gen = generator_discriminator(weights_gen, weights_dis) \n\n    return -torch.log(out_gen)\n\n```", "```py\n\nweights_gen = torch.rand(3, requires_grad = True) \n\nweights_dis = torch.rand((3 + 1) * 2 * 3, requires_grad = True)\n\n```", "```py\n\noptg = torch.optim.SGD([weights_gen], lr = 0.5) \n\noptd = torch.optim.SGD([weights_dis], lr = 0.5)\n\n```", "```py\n\ndis_losses = [] # Discriminator losses. \n\ngen_losses = [] # Generator losses. \n\nlog_weights = [] # Generator weights. \n\nncycles = 150 # Number of training cycles. \n\nfor i in range(ncycles): \n\n    # Train the discriminator. \n\n    optd.zero_grad() \n\n    lossd = discriminator_loss(weights_gen.detach(), weights_dis) \n\n    lossd.backward() \n\n    optd.step() \n\n    # Train the generator. \n\n    optg.zero_grad() \n\n    lossg = generator_loss(weights_gen, weights_dis.detach()) \n\n    lossg.backward() \n\n    optg.step() \n\n    # Log losses and weights. \n\n    lossd = float(lossd) \n\n    lossg = float(lossg) \n\n    dis_losses.append(lossd) \n\n    gen_losses.append(lossg) \n\n    log_weights.append(weights_gen.detach().clone().numpy()) \n\n    # Print the losses every fifteen cycles. \n\n    if (np.mod((i+1), 15) == 0): \n\n        print(\"Epoch\", i+1, end= \" \") \n\n        print(\"| Discriminator loss:\", round(lossd, 4), end = \" \") \n\n        print(\"| Generator loss:\", round(lossg, 4))\n\n```", "```py\n\nEpoch 15 | Discriminator loss: 0.6701 | Generator loss: 0.7065 \nEpoch 30 | Discriminator loss: 0.6987 | Generator loss: 0.6791 \nEpoch 45 | Discriminator loss: 0.6931 | Generator loss: 0.6992 \nEpoch 60 | Discriminator loss: 0.6931 | Generator loss: 0.6924 \nEpoch 75 | Discriminator loss: 0.6932 | Generator loss: 0.6927 \nEpoch 90 | Discriminator loss: 0.6931 | Generator loss: 0.6934 \nEpoch 105 | Discriminator loss: 0.6931 | Generator loss: 0.6931 \nEpoch 120 | Discriminator loss: 0.6931 | Generator loss: 0.6931 \nEpoch 135 | Discriminator loss: 0.6931 | Generator loss: 0.6932 \nEpoch 150 | Discriminator loss: 0.6931 | Generator loss: 0.6931\n\n```", "```py\n\nimport matplotlib.pyplot as plt \n\nepochs = np.array(range(len(gen_losses))) + 1 \n\nplt.plot(epochs, gen_losses, label = \"Generator loss\") \n\nplt.plot(epochs, dis_losses, label = \"Discriminator loss\") \n\nplt.xlabel(\"Epoch\") \n\nplt.legend()\n\n```", "```py\n\n@qml.qnode(dev, interface=\"torch\") \n\ndef generated_coordinates(weights_gen): \n\n    Generator(weights_gen) \n\n    return [qml.expval(qml.PauliX(0)), qml.expval(qml.PauliY(0)), \n\n    qml.expval(qml.PauliZ(0))] \n\n@qml.qnode(dev, interface=\"torch\") \n\ndef true_coordinates(): \n\n    PrepareTrueState() \n\n    return [qml.expval(qml.PauliX(0)), \n\n            qml.expval(qml.PauliY(0)), \n\n            qml.expval(qml.PauliZ(0))] \n\nprint(\"Bloch coordinates\") \n\nprint(\"Generated:\", generated_coordinates(weights_gen)) \n\nprint(\"True:\", true_coordinates())\n\n```", "```py\n\nBloch angles \nBloch coordinates \nGenerated: tensor([0.3536, 0.6124, 0.7071], dtype=torch.float64, \ngrad_fn=<MvBackward0>) \nTrue: tensor([0.3536, 0.6124, 0.7071], dtype=torch.float64)\n\n```", "```py\n\ntrue_coords = true_coordinates() \n\ndef plot_coordinates(cycle): \n\n    coords = generated_coordinates(log_weights[cycle - 1]) \n\n    plt.bar([\"X\", \"Y\", \"Z\"], true_coords, width = 1, \n\n        color = \"royalblue\", label = \"True coordinates\") \n\n    plt.bar([\"X\", \"Y\", \"Z\"], coords, width = 0.5, \n\n        color = \"black\", label = \"Generated coordinates\") \n\n    plt.title(f\"Training cycle {cycle}\") \n\n    plt.legend()\n\n```", "```py\n\nimport numpy as np \n\nfrom qiskit import * \n\nfrom qiskit.utils import algorithm_globals \n\nseed = 1234 \n\nnp.random.seed(seed) \n\nalgorithm_globals.random_seed = seed\n\n```", "```py\n\nN = 1000 \n\nn = 3 \n\np = 0.5 \n\nreal_data = np.random.binomial(n, p, N)\n\n```", "```py\n\nfrom qiskit_machine_learning.algorithms import QGAN \n\nfrom qiskit.utils import QuantumInstance \n\nncycles = 3000 # Number of training cycles. \n\nbsize = 100 # Batch size. \n\n# Quantum instance on which the QGAN will run. \n\nquantum_instance = QuantumInstance( \n\n    backend=Aer.get_backend(’statevector_simulator’)) \n\n# Create the QGAN object. \n\nqgan = QGAN(data = real_data, \n\n            num_qubits = [2], \n\n            batch_size = bsize, \n\n            num_epochs = ncycles, \n\n            bounds = [0,3], \n\n            seed = seed, \n\n            tol_rel_ent = 0.001)\n\n```", "```py\n\nresult = qgan.run(quantum_instance)\n\n```", "```py\n\nimport matplotlib.pyplot as plt \n\nplt.title(\"Loss function evolution\") \n\ncycles = np.array(range(len(qgan.g_loss))) + 1 \n\nplt.plot(cycles, qgan.g_loss, label = \"Generator\") \n\nplt.plot(cycles, qgan.d_loss, label = \"Discriminator\") \n\nplt.xlabel(\"Cycle\") \n\nplt.legend()\n\n```", "```py\n\nsamples_g, prob_g = qgan.generator.get_output(qgan.quantum_instance, \n\n                                             shots=10000) \n\nreal_distr = [] \n\nfor i in range(0,3+1): \n\n    proportion = np.count_nonzero(real_data == i) / N \n\n    real_distr.append(proportion) \n\nplt.bar(range(4), real_distr, width = 0.7, color = \"royalblue\", \n\n        label = \"Real distribution\") \n\nplt.bar(range(4), prob_g, width = 0.5, color = \"black\", \n\n        label = \"Generated distribution\")\n\n```", "```py\n\nplt.title(’Relative entropy evolution’) \n\nplt.plot(qgan.rel_entr) \n\nplt.show()\n\n```"]