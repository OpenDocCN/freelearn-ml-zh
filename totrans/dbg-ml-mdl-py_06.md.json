["```py\n# loading UCI adult income dataset# classification task to predict if people made over $50k in the 90s or not\nX,y = shap.datasets.adult()\n# split the data to train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size = 0.3, random_state=10)\n# initializing a XGboost model\nxgb_model = xgboost.XGBClassifier(random_state=42)\n# fitting the XGboost model with training data\nxgb_model.fit(X_train, y_train)\n# generating predictions for the test set\ny_pred = xgb_model.predict(X_test)\n# identifying misclassified datapoints in the test set\nmisclassified_index = np.where(y_test != y_pred)[0]\n# calculating roc-auc of predictions\nprint(\"ROC-AUC of predictions: {}\".format(\n    roc_auc_score(y_test, xgb_model.predict_proba(\n        X_test)[:, 1])))\nprint(\"First 5 misclassified test set datapoints:\n    {}\".format(misclassified_index[0:5]))\n```", "```py\n# generate the Tree explainerexplainer = shap.TreeExplainer(xgb_model)\n# extract SHAP values from the explainer object\nshap_values = explainer.shap_values(X_test)\n```", "```py\n# If interaction_index of \"auto\" is chosen then# the strongest interaction is used to color the dots.\nshap.dependence_plot(\"Education-Num\", shap_values, X_test)\n```", "```py\n# generate dependence plot for \"Age\" featureshap.dependence_plot(\"Age\", shap_values, X_test,\n    interaction_index=None)\n```", "```py\n# generate dependence plot for \"Age\" featureshap.dependence_plot(\"Age\",\n    shap_values[misclassified_index],\n    X_test.iloc[misclassified_index,:],\n    interaction_index=None)\n```", "```py\n# extracting expected valuesexpected_value = explainer.expected_value\n# generate waterfall plot for observation 12\nshap.plots._waterfall.waterfall_legacy(expected_value,\n    shap_values[12], features=X_test.iloc[12,:],\n    feature_names=X.columns, max_display=15, show=True)\n# generate waterfall plot for observation 24\nshap.plots._waterfall.waterfall_legacy(expected_value,\n    shap_values[24],features=X_test.iloc[24,:],\n    feature_names=X.columns,max_display=15, show=True)\n```", "```py\n# create a SHAP beeswarm plot (i.e. SHAP summary plot)shap.summary_plot(shap_values, X_test,plot_type=\"bar\")\n```", "```py\nxgb_model.fit(np.array(X_train), y_train) makes the model usable for the lime library:\n```", "```py\n# create explainerexplainer = lime.lime_tabular.LimeTabularExplainer(\n    np.array(X_train), feature_names=X_train.columns,\n    #X_train.to_numpy()\n    class_names=['Lower income','Higher income'],\n    verbose=True)\n# visualizing explanation by LIME\nprint('actual label of sample 12: {}'.format(y_test[12]))\nprint('prediction for sample 12: {}'.format(y_pred[12]))\nexp = explainer.explain_instance(\n    data_row = X_test.iloc[12],\n    predict_fn = xgb_model.predict_proba)\nexp.show_in_notebook(show_table=True)\n```", "```py\nsp_obj = submodular_pick.SubmodularPick(explainer,    np.array(X_train), xgb_model.predict_proba,\n    method='sample', sample_size=3, num_features=8,\n    num_exps_desired=5)\n# showing explanation for the picked instances for explanation if you are using Jupyter or Colab notebook\n[exp.show_in_notebook() for exp in sp_obj.explanations]\n```", "```py\n### This example is taken from https://github.com/interpretml/DiCE ###dataset = helpers.load_adult_income_dataset()\ntarget = dataset[\"income\"] # outcome variable\ntrain_dataset, test_dataset, _, _ = train_test_split(\n    dataset,target,test_size=0.2,random_state=0,\n    stratify=target)\n# Dataset for training an ML model\nd = dice_ml.Data(dataframe=train_dataset,\n    continuous_features=['age','hours_per_week'],\n    outcome_name='income')\n# Pre-trained ML model\nm = dice_ml.Model(\n    model_path=dice_ml.utils.helpers.get_adult_income_modelpath(),\n    backend='TF2', func=\"ohe-min-max\")\n# DiCE explanation instance\nexp = dice_ml.Dice(d,m)\n```", "```py\nquery_instance = test_dataset.drop(columns=\"income\")[0:1]dice_exp = exp.generate_counterfactuals(query_instance,\n    total_CFs=10, desired_class=\"opposite\",\n    random_seed = 42)\n# Visualize counterfactual explanation\ndice_exp.visualize_as_dataframe()\n```"]