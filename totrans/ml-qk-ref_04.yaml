- en: Training Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you hear the term **neural networks**, it gives you a sense that its a
    form of biological terminology pertaining to brains. And I have to tell you candidly
    that it's a no brainer to guess that and, in fact, we are treading along the right
    path by doing so. We will see how it is connected to that.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks have brought in a revolution in the data science world. Until
    2011, due to not having enough computation power, the people rooting for neural
    networks were not able to propagate it to the extent that they wanted. But, with
    the advent of cheaper computation solutions and more research in the area of neural
    networks, they have taken the data science and artificial world by storm. Neural
    networks are an algorithm that can be applied in both supervised and unsupervised
    learning. With deeper networks, they are able to provide solutions to unstructured
    data, such as images and text.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network initialization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overfitting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dropouts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stochastic gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recurrent neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let me explain first of all what neurons are and how they are structured. The
    following labelled diagram shows a typical neuron:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c407659-7770-4b8f-84ab-cc64be72d799.png)'
  prefs: []
  type: TYPE_IMG
- en: We define neuron as an electrically excitable cell that receives, processes,
    and transmits information through electric and chemical signals. A dendrite is
    a part of it that receives signals from other neurons. One thing that we need
    to pay attention to is that just a single neuron can't do anything and there are
    billions of neurons connected to each other, which enables the electro-chemical
    signal flow and, in turn, the information to flow through it. The information
    passes through an axon and a synapse, before being transmitted.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to a neural network, the structure doesn't change much. Let's
    have a look at it. In the middle, we have a neuron and this neuron gets signals
    from three other neurons, X1, X2, and X3\. All three neurons are connected by
    arrows that act like a synapse. These neurons, X1, X2, and X3, are called **input
    layer neurons**. After passing through the neuron, we get the output value. It's
    interesting to see that the human brain gets an input signal through all the sensors
    such as eyes, ear, touch, and nose and that all the synapses let these electro-chemical
    signals go, and output comes as vision, voice, sense of touch, and smell. A similar
    process is followed in the case of a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: How a neural network works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s say we have one set of input and output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input (X)** | **Output (Y)** |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 12 |'
  prefs: []
  type: TYPE_TB
- en: In the preceding table, input and output might look to have a linear relationship;
    however, that is not always the case. In addition, every time the model needs
    to initialize. Let's understand the meaning of initialization.
  prefs: []
  type: TYPE_NORMAL
- en: Model initialization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Going by the preceding table, the network is trying to find a relationship
    between input and output. For example, let''s assume the relationship that comes
    through is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y = W. X*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding equation, *Y* and *X* are known, and based on that *W* has
    to be found out. But, finding out the value of *W* in one iteration is rare. It
    has to be initialized first. Let''s say *W* is initialized with the value of *3*.
    And the equation turns out to be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Y= 3X*'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input (X)** | **Actual Output (Y)** |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 12 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 15 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 18 |'
  prefs: []
  type: TYPE_TB
- en: Now we have to assess the output and whether it is close to the desired output.
  prefs: []
  type: TYPE_NORMAL
- en: Loss function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, the model has been randomly initialized and with this we have been able
    to get an output. In order to assess if the actual output is close to the desired
    output, **loss function** is introduced. It enables the generalization of the
    model, and figures out how well the model is able to reach the desired output.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can have a look at the new table, which has got actual output as well as
    desired output:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input (X)** | **Actual Output (Y[a])** | **Desired Output (Y)** |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 6 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 9 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 12 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 15 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 18 | 12 |'
  prefs: []
  type: TYPE_TB
- en: 'If we have to put the loss function down, it has to be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Loss Function = Desired Output-Actual Output*'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, putting loss function this way would invite both kinds of values:
    negative and positive. In the case of a negative value for the loss function,
    it would mean that the network is overshooting as *Desired Output < Actual Output*
    and in the reverse scenario (*Desired Output > Actual Output*), the network would
    undershoot. In order to get rid of this kind of thing, we will go for having an
    absolute loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input(X)** | **Actual Output (Y[a])** | **Desired Output (Y)** | **Loss=Y-Y[a]**
    | **Absolute Loss** |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 6 | 4 | -2 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 9 | 6 | -3 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 12 | 8 | -4 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 15 | 10 | -5 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 18 | 12 | -6 | 6 |'
  prefs: []
  type: TYPE_TB
- en: Total Absolute Loss = 20
  prefs: []
  type: TYPE_NORMAL
- en: 'Having this approach of absolute loss will do no good to the model, as if we
    try to see the preceding table gingerly, the smallest loss is of 2 units and the
    maximum coming through is 6 units. One might get a feeling that the difference
    between maximum and minimum loss is not much (here, 4 units), but it can be huge
    for the model. Hence, a different route is taken altogether. Rather than taking
    absolute loss, we would go for the square of losses:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input(X)** | **Actual output (Y[a])** | **Desired output (Y)** | **Loss=Y-Y[a]**
    | **Square of Loss** |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 6 | 4 | -2 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 9 | 6 | -3 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 12 | 8 | -4 | 16 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 15 | 10 | -5 | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 18 | 12 | -6 | 36 |'
  prefs: []
  type: TYPE_TB
- en: Now, the more the loss, the more the penalization. It can easily make things
    evident where we have more losses.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have to figure out a way to minimize the total loss function and it can be
    achieved by changing the weight. It can be done by using a crude method like modifying
    the parameter *W* over a range of -500 to 500 with a step 0.001\. It will help
    us to find a point where the sum of squares of error becomes 0 or minimum.
  prefs: []
  type: TYPE_NORMAL
- en: But this approach will work out in this scenario because we don't have too many
    parameters here and computation won't be too challenging. However, when we have
    a number of parameters, the computation would take a hit.
  prefs: []
  type: TYPE_NORMAL
- en: Here, mathematics comes to our rescue in the form of differentiation (maxima
    and minima approach) in order to optimize the weights. The derivative of a function
    at a certain point gives the rate at which this function is changing its values.
    Here, we would take the derivative of loss function. What it will do is to assess
    an impact on total error by making a slight adjustment or change in weight. For
    example, if we try to make a change in weight which is *δW, W= W+ **δW*, we can
    find out how it is influencing loss function. Our end goal is to minimize the
    loss function through this.
  prefs: []
  type: TYPE_NORMAL
- en: 'We know that the minima will be arrived at *w=2*; hence, we are exploring different
    scenarios here:'
  prefs: []
  type: TYPE_NORMAL
- en: '*w<2* implies a positive loss function, negative derivative, meaning that an
    increase of weight will decrease the loss function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*w>2* implies positive loss function, but the derivative is positive, meaning
    that any more increase in the weight will increase the losses'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At *w=2*, loss=0 and the derivative is 0; minima is achieved:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/18242011-6eff-469d-8dde-610e9b8146b6.png)'
  prefs: []
  type: TYPE_IMG
- en: Computation in neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s look at a simple and shallow network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/74496ea6-7e1a-45ce-9483-1b594efecada.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: '**I1**: Input neuron 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I2**: Input neuron 2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**B1**: Bias 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**H1**: Neuron 1 in hidden layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**H2**: Neuron 2 in hidden layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**B2**: Bias 2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**O1**: Neuron at output layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final value comes at the output neuron **O1**. **O1** gets the input from
    **H1**, **H2**, and **B2**. Since **B2** is a bias neuron, the activation for
    it is always 1\. However, we need to calculate the activation for **H1** and **H2**.
    In order to calculate activation of **H1** and **H2**, activation for **I1**,
    **I2**, and **B1** would be required. It may look like **H1** and **H2** will
    have the same activation, since they have got the same input. But this is not
    the case here as weights of **H1** and **H2** are different. The connectors between
    two neurons represent weights.
  prefs: []
  type: TYPE_NORMAL
- en: Calculation of activation for H1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s have a look at the part of network involving just **H1**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a119d44b-03e2-48ea-aea5-a71f3ca56d56.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The hidden layer comes out as in the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d64d4cf1-b2c9-492f-b3d9-80f867ea7193.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Where:'
  prefs: []
  type: TYPE_NORMAL
- en: '*A*: Activation function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x[i]*: Input values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*w[i]*: Weight values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In our scenario, there are three input values, *n=3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '*x[1]* = *I1* = Input value 1 from first neuron'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x[2 ]*= *I2*= Input value 2 from second neuron'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x[3 ]*= *B1* = *1*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*w1 *= Weight from *I1* to *H1*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*w2 *= Weight from *I2* to *H1*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*w3 *= Weight from *B1* to *H1*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backward propagation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this step, we calculate the gradients of the loss function *f(y, y_hat)*
    with respect to *A*, *W*, and *b* called *dA*, *dW,* and *db*. Using these gradients,
    we update the values of the parameters from the last layer to the first.
  prefs: []
  type: TYPE_NORMAL
- en: Activation function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Activation function is typically introduced in the neural network in order to
    induce non-linearity. Without non-linearity, a neural network will have little
    chance to learn non-linearity. But you might question as to why why we need non-linearity
    in the first place. If we deem every relationship as a linear one, then the model
    won't be able to do justice to the actual relationship because having a linear
    relationship is a rarity. If applied linearity, the model's output won't be a
    generalized one.
  prefs: []
  type: TYPE_NORMAL
- en: Also, the main purpose of an activation function is to convert an input signal
    into an output. Let's say if we try to do away with an activation function, it
    will output a linear result. Linear function is a polynomial of the first degree
    and it's easy to solve but, again, it's not able to capture complex mapping between
    various features, which is very much required in the case of unstructured data.
  prefs: []
  type: TYPE_NORMAL
- en: Non-linear functions are those that have a degree more than one. Now we need
    a neural network model to learn and represent almost anything and any arbitrary
    complex function that maps inputs to outputs. Neural networks are also called **universal
    function approximators**. It means that they can compute and learn any function.
    Hence, activation function is an integral part of a neural network to make it
    learn complex functions.
  prefs: []
  type: TYPE_NORMAL
- en: Types of activation functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Sigmoid**: This type of activation function comes along as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/8bcb8153-74b3-4a24-b927-2967314bbf01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The value of this function ranges between *0* and *1*. It comes with a lot
    of issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Vanishing gradient
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Its output is not zero-centered
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It has slow convergence
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hyperbolic tangent function (tanh)**: The mathematical formula to represent
    it is this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/76547790-6185-4522-bddc-1e58280a80f8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The value of this function ranges between -1 and +1\. However, it still faces
    the vanishing gradient problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e924e24-2a35-4a8f-9072-4c49f9d7f9ad.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Rectified Linear Units (ReLU)**: Mathematically, we represent it in the following
    manner:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/141499a5-01e1-4e4a-97d7-21fa7000f8df.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/ce1a9375-30b1-4e09-9822-66bf365ed966.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Going by the preceding diagram, ReLU is linear for all positive values, and
    zero for all negative values. This means that the following are true:'
  prefs: []
  type: TYPE_NORMAL
- en: It's cheap to compute as there is no complicated math. The model can therefore
    take less time to train.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: It converges faster. Linearity means that the slope doesn't hit the plateau
    when *x* gets large. It doesn't have the vanishing gradient problem suffered by
    other activation functions such as sigmoid or tanh.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Network initialization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen that there are a number of stages in a neural network model.
    We already know that weight exists between two nodes (of two different layers).
    The weights undergo a linear transformation and, along with values from input
    nodes, it crosses through nonlinear activation function in order to yield the
    value of the next layer. It gets repeated for the next and subsequent layers and
    later on, with the help of backpropagation, optimal values of weights are found
    out.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a long time, weights used to get randomly initialized. Later on, it was
    realized that the way we initialize the network has a massive impact on the model.
    Let''s see how we initialize the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Zero initialization**: In this kind of initialization, all the initial weights
    are set to zero. Due to this, all the neurons of all the layers perform the same
    calculation, which results in producing the same output. It will make the whole
    deep network futile. Predictions coming out of this network would be as good as
    random. Intuitively speaking, it doesn''t perform symmetry breaking. Normally,
    during forward propagation of a neural network, each hidden node gets a signal
    and this signal is nothing but the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/7ed004a1-bbc9-4521-b36d-17faa6d57a86.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If a network is initialized with zero, then all the hidden nodes will get zero
    signal because all the inputs will be multiplied by zero. Hence, no matter what
    the input value is, if all weights are the same, all units in the hidden layer
    will be the same too. This is called **symmetry**, and it has to be broken in
    order to have more information capturing a good model. Hence, the weights are
    supposed to be randomly initialized or with different values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f0640572-0929-4ab6-8727-a72292178280.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Random initialization**: This kind of initialization helps in symmetry breaking. In
    this method, the weights are randomly initialized very close to zero. Every neuron
    doesn''t perform the same computation as the weight is not equal to zero:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/5d537d8c-7360-4499-a735-08e3745db251.png)'
  prefs: []
  type: TYPE_IMG
- en: '**He-et-al initialization**: This initialization depends on the size of the
    previous layer. It helps in attaining a global minimum of the cost function. The
    weights are random but differ in range depending on the size of the previous layer
    of neurons:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/4ea122bf-7683-472f-b158-b3ffef64ec96.png)'
  prefs: []
  type: TYPE_IMG
- en: Backpropagation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Backpropagation takes place once feed forward is completed. It stands for **backward
    propagation of errors**. In the case of neural networks, this step begins to compute
    the gradient of error function (loss function) with respect to the weights. One
    can wonder why the term **back** is associated with it. It's due to gradient computation
    that starts backwards through the network. In this, the gradient of the final
    layer of weights gets calculated first and the the weights of the first layer
    are calculated last.
  prefs: []
  type: TYPE_NORMAL
- en: 'Backpropagation needs three elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dataset**: A dataset that consists of pairs of input-output ![](img/4547391a-da1a-4ad7-b3dd-a8fc87618733.png) where ![](img/413b860f-3d7a-4eb6-b627-8ba6547d1c7a.png) is
    the input and ![](img/516eb17d-0d03-4582-8e5a-b81806b6e626.png) is the output
    that we are expecting. Hence, a set of such input-outputs of size *N* is taken
    and denoted as ![](img/69a7749c-d852-4e99-bff9-f07109e362a8.png).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Feed-forward network**: In this, the parameters are denoted as *θ*. The parameters,![](img/ca7375da-5da5-4a0b-a055-11c63e0c870b.png),
    the weight between node *j* in layer *l[k] *and node *i* in layer *l[k-1]*, and the
    bias ![](img/b91ce0ca-b2ff-4a9a-bc69-9b4193a865eb.png) for node *i* in layer *l[k-1]*.
    There are no connections between nodes in the same layer and layers are fully
    connected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Loss function**: *L(X,θ)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training a neural network with gradient descent requires the calculation of
    the gradient of the loss/error function *E(X,θ)* with respect to the weights ![](img/dadeb00b-55a2-421c-8bab-946c28b37d4d.png) and
    biases ![](img/1455e031-42d4-4c52-bf4f-5626cbc06bc2.png). Then, according to the
    learning rate *α*, each iteration of gradient descent updates the weights and
    biases collectively, denoted according to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c456d7b-2549-43ba-8427-cdeefb863b33.png)'
  prefs: []
  type: TYPE_IMG
- en: Here ![](img/64229546-bef0-4e41-8c0c-4f7ad5c38557.png) denotes the parameters
    of the neural network at iteration in gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already discussed overfitting in detail. However, let's have a recap
    of what we learned and what overfitting is in a neural network scenario.
  prefs: []
  type: TYPE_NORMAL
- en: By now, we are cognizant of the fact that, when a large number of parameters
    (in deep learning) are available at our disposal to map and explain an event,
    more often than not, the model built using these parameters will tend to have
    a good fit and try to showcase that it has the ability to describe the event properly.
    However, the real test of any model is always on unseen data, and we were able
    to assess how the model fares on such unseen data points. We expect our model
    to have an attribute of generalization and it will enable the model to score on
    test data (unseen) in alignment with the trained one. But, a number of times our
    model fails to generalize when it comes to the unseen data, as the model has not
    learned the insights and causal relationship of the event. In this scenario, one
    might be able to see the huge gulf of variance in training accuracy and test accuracy and,
    needless to say, it is not what we are seeking out of the model. This phenomenon
    is called **overfitting**.
  prefs: []
  type: TYPE_NORMAL
- en: In deep learning, there are millions of parameters you may encounter and in
    all likelihood, you might fall into the trap of overfitting. As we had defined
    overfitting in the first chapter, it happens when a model learns the detail and
    noise in the training data to the extent that it negatively impacts the performance
    of the model on new data.
  prefs: []
  type: TYPE_NORMAL
- en: Prevention of overfitting in NNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we already discussed in the earlier chapters, overfitting is a major issue
    that needs to be considered while building models as our work doesn't get over
    only at training phase. The litmus test for any model takes place on unseen data.
    Let's explore the techniques of handling overfitting issues in neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Vanishing gradient
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neural networks have been a revelation in extracting complex features out of
    the data. Be it images or texts, they are able to find the combinations that result
    in better predictions. The deeper the network, the higher the chances of picking
    those complex features. If we keep on adding more hidden layers, the learning
    speed of the added hidden layers get faster.
  prefs: []
  type: TYPE_NORMAL
- en: However, when we get down to backpropagation, which is moving backwards in the
    network to find out gradients of the loss with respect to weights, the gradient
    tends to get smaller and smaller as we head towards the first layer. It that initial
    layers of the deep network become slower learners and later layers tend to learn
    faster. This is called the **vanishing gradient problem**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Initial layers **in the network are important because they are responsible
    to *learn and detect the simple patterns* and are actually the **building blocks** of
    our network. Obviously, if they give improper and **inaccurate** results, then
    how can we expect the next layers and the complete network to perform effectively
    and produce accurate results? The following diagram shows the figure of a ball
    that rolls on a steeper slope:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a3ae1b6c-f32c-4cd9-887a-e201c1590813.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Just to make it a little simpler for us all, let''s say that there are two
    slopes: one being steeper and the other being less steep. Both slopes have got
    balls rolling down them and it is a no brainer that the ball will roll down the
    steeper slope faster than the one that is not as steep. Similar to that, if the
    gradient is large, the learning and training gets faster; otherwise, training
    gets too slow if the gradient is less steep.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From backpropagation intuition, we are aware of the fact that the optimization
    algorithms such as gradient descent slowly seeko attain the local optima by regulating
    weights such that the cost function''s output is decreased. The gradient descent
    algorithm updates the weights by the negative of the gradient multiplied by the
    learning rate (*α*) (which is small):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/440170ea-fc59-46bc-817e-dec702406d97.png)'
  prefs: []
  type: TYPE_IMG
- en: It says that we have to repeat until it attains convergence. However, there
    are two scenarios here. The first is that, if there are fewer iterations, then
    the accuracy of the result will take a hit; the second is that more iterations
    result in training taking too much time. This happens because weight does not
    change enough at each iteration as the gradient is small (and we know *α* is already
    very small). Hence, weight does not move to the lowest point in the assigned iterations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s talk about that activation function, which might have an impact on the
    vanishing gradient problem. Here, we talk about the sigmoid function, which is
    typically used as an activation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7657cf67-19e2-45f3-81b7-4084792ceb64.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/2857f1c6-3632-4d5a-acda-04b0ef32219a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It translates all input values into a range of values between *(0,1)*. If we
    have to find out the derivative of the sigmoid function then:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b5d457b0-01e6-4904-baa1-f1e0674a4969.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s plot it now:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df11e32f-2167-467a-bd05-36ce684c8313.png)'
  prefs: []
  type: TYPE_IMG
- en: It is quite evident that the derivative has got the maximum value as 0.25\.
    Hence, the range of values under which it would lie is *(0,1/4)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical neural network looks like the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1acf1c62-c478-4e81-9699-0e7c6f511a05.png)'
  prefs: []
  type: TYPE_IMG
- en: Once the weight parameters are initialized, the input gets multiplied by weights
    and gets passed on through an activation function and, finally, we get a cost
    function (**J**). Subsequently, backpropagation takes place to modify the weights
    through gradient descent in order to minimize **J**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to calculate the derivative with respect to first weight, we are using
    the chain rule. It will turn out to be like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3a106879-37e1-4614-a153-6ee334fb3b73.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we just try to study the derivatives in the middle of the preceding expression,
    we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4ff036d1-3594-41c1-ae0e-7cf946652c0a.png)'
  prefs: []
  type: TYPE_IMG
- en: Part 1—from the output to hidden2.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the output is the activation of the 2nd hidden unit, the expression turns
    out to be like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3941e87a-2dd0-453c-bfd3-e9799e41ebce.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/5ecc45d9-810a-4fc3-b0d4-eb19564c6eea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly for part 2, from hidden 2 to hidden 1, the expression turns out to
    be like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/adc5ddd6-823d-42ba-b0fe-361a56202f8e.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](img/773e3435-985d-4240-bb66-935d38d4f466.png)'
  prefs: []
  type: TYPE_IMG
- en: 'On putting everything together, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98f8ca56-7833-4e7e-b0e2-a145aa45817b.png)'
  prefs: []
  type: TYPE_IMG
- en: We know that the maximum value of the derivative of the sigmoid function is
    1/4 and the weights can typically take the values between -1 and 1 if weights
    have been initialized with standard deviation 1 and mean 0\. It will lead to the
    whole expression being smaller. If there is a deep network to be trained, then
    this expression will keep on getting even smaller and, as a result of that, the
    training time will become slow-paced.
  prefs: []
  type: TYPE_NORMAL
- en: Overcoming vanishing gradient
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From the preceding explanation of vanishing gradient, it comes out that the
    root cause of this problem is the sigmoid function being picked as an activation
    function. The similar problem has been detected when *tanh* is chosen as an activation
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to counter such a scenario, the ReLU function comes to the rescue:'
  prefs: []
  type: TYPE_NORMAL
- en: '*ReLU(x)= max(0,x)*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a7bd50b5-43f3-4021-96d0-4f8bad02d742.png)'
  prefs: []
  type: TYPE_IMG
- en: If the input is negative or less than zero, the function outputs as zero. In
    the second scenario, if the input is greater than zero, then the output will be
    equal to input.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take the derivative of this function and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 1**: *x<0*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a8afc1d4-1539-4c14-a667-536914439103.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Case 2**: *x>0*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/18ee3326-b6a5-42a1-8b59-34b0438ffd82.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we have to plot it, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7c495aa3-2edc-4e29-b2c3-469228c57c88.png)'
  prefs: []
  type: TYPE_IMG
- en: So, the derivative of ReLU is either 0 or 1\. The plot comes out to be like
    a step function. Now, we can see that we won't face the vanishing gradient problem
    as the value of the derivative doesn't lie between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: However, it's still not true. We might still face this problem when the input
    value happens to be negative and we know that derivative turns out to be zero
    in this scenario. Typically, it doesn't happen that the weighted sum ends up negative,
    and we can indeed initialize weights to be only positive and/or normalize input
    between 0 and 1, if we are concerned about the chance of an issue like this occurring.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is still a workaround for this kind of scenario. We have got another
    function called **Leaky ReLU**, which appears as the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '*RELU (x) = max (εx, x)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the value of ε is typically 0.2–0.3\. We could plot it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bad4eb21-876b-4479-a23a-eece3cf8b89b.png)'
  prefs: []
  type: TYPE_IMG
- en: Recurrent neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our thought process always has a sequence. We always understand things in an
    order. For example, if we watch a movie, we understand the next sequence by connecting
    it with the previous one. We retain the memory of the last sequence and get an
    understanding of the whole movie. We don't always go back to the first sequence
    in order to get it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Can a neural network act like this? Traditional ones typically cannot operate
    in this manner and that is a major shortcoming. This is where recurrent neural
    networks make a difference. It comes with a loop that allows information to flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bbf8d6b1-9c18-4882-aa18-6151eafb603f.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, a neural network takes an input as **X[t] **and throws an output in the
    form of **h[t ]**. A recurrent neural network is made up of multiple copies of
    the same network that pass on the message to the successor.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we were to go and unroll the preceding network, it would look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/29ac117d-d864-4bff-a992-4a6ede2b024e.png)'
  prefs: []
  type: TYPE_IMG
- en: This chain-like nature reveals that recurrent neural networks are intimately
    related to sequences and lists. They are the natural architecture of neural networks
    to use for such data. Since the network has got an internal memory, RNNs are able
    to remember the input they received which, in turn, enables them to come up with
    accurate and precise results and predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we have been talking about sequential data. But we need to have a proper
    understanding of this term, sequential data. This form of data is an order data
    where there exists a relationship between data at time *t* and the data at time
    *t-1*. An example of that kind of data can be financial data, time-series data,
    video, and so on. RNNs allow us to operate over sequences of vectors. For example,
    look at the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f5836407-530c-42b7-95b3-db16dfd08cb4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Each rectangle is represented as a vector, and arrows stand for functions.
    Input vectors are in red, output vectors are in blue, and green vectors hold the
    RNN''s state:'
  prefs: []
  type: TYPE_NORMAL
- en: Vanilla mode of processing can be done without including RNN, from a fixed-sized
    input to output
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequencing the output in a proper format
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequencing the input
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sequencing the input and output (for example, machine translation: an RNN which
    reads a sentence in English and then outputs a sentence in some other language,
    like German).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Syncing the sequenced input and output (for example, video classification where
    label each frame of the video)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations of RNNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recurrent neural networks function just right when it comes to short-term dependencies.
    What this means is that, if there is just a single statement to be dealt with,
    a neural network operates fine. For example, if there is a sentence, *India's
    capital is __*, in this scenario we would invariably get the correct result as
    this is a universal statement and there is nothing like a context here. This statement
    has no dependency on the previous sentence and here, there is no previous sentence
    either.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, the prediction would be *India's capital is New Delhi*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Afterall, the vanilla RNN''s does not understand the context behind an input.
    We will understand with an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Staying in India meant that I gravitated towards cricket. But, after 10 years,
    I moved to the US for work.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The popular game in India is ___*.'
  prefs: []
  type: TYPE_NORMAL
- en: One can see that there is a context in the first sentence and then it changes
    in the second one. However, prediction has to be done by the network on the basis
    of the first one. It is highly likely that the popular game in India is cricket,
    but context plays a role here and it has to be understood by the network. Simple
    RNN is a failure here.
  prefs: []
  type: TYPE_NORMAL
- en: That is where **Long Short-Term Memory** (**LSTM**) comes into the picture.
  prefs: []
  type: TYPE_NORMAL
- en: Use case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's work on a use case that will help us in understanding the network.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will work on a time series problem. We have got the Google stock price dataset.
    One being training and the other being test. We will now look at a use case to
    forecast the stock prices of Google:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by importing the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, import the training set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Feature scaling is done in the next step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create a data structure with 60 time steps and 1 output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, reshape the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, import the Keras libraries and packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We will initialize the RNN with the regressor function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, add the first LSTM layer and some dropout regularization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, add the second LSTM layer and some dropout regularization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the third LSTM layer and some dropout regularization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a fourth LSTM layer and some dropout regularization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, add the output layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will compile the RNN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We will fit the RNN to the training set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the real stock price of 2017 as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the predicted stock price of 2017 as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will visualize the results as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned about neural networks along with their working,
    and were introduced to backward propagation and the activation function. We studied
    network initialization and how can we initialize the different types of models.
    We learned about overfitting and dropouts in the neural network scenario.
  prefs: []
  type: TYPE_NORMAL
- en: We introduced the concept of RNN, and studied a use case regarding the Google
    stock price dataset. In the next chapter, we will study time series analysis.
  prefs: []
  type: TYPE_NORMAL
