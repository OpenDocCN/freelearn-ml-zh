<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Using Pretrained Models</h1>
                </header>
            
            <article>
                
<p>In the previous two chapters, you learned how to use supervised ML algorithms (<a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">Chapter 3</a>, <em>Supervised Learning</em>) and unsupervised ML algorithms (<a href="26788e93-3614-413f-bcde-5580516f9c5f.xhtml" target="_blank">Chapter 4</a>, <em>Unsupervised Learning</em>) to solve a wide range of problems. The solutions created models from scratch and consisted only of Go code. We did not use models that had already been trained, nor did we attempt to call Matlab, Python, or R code from Go. However, there are several situations in which this can be beneficial. In this chapter, we will present several strategies aimed at using pretrained models and creating polyglot ML applications <span>–</span> that is, where the main application logic is written in Go but where specialist techniques and models may have been written in other languages.</p>
<p>In this chapter, you will learn about the following topics:</p>
<ul>
<li>How to load a pretrained GoML model and use it to generate a prediction</li>
<li><span>When to consider using a pure-Go solution or polyglot solution</span></li>
<li>How to use the os/exec package to invoke ML models written in other languages</li>
<li>How to use HTTP to invoke ML models written in other languages, where they may reside on a different machine or even across the internet</li>
<li>How to run TensorFlow models using the TensorFlow API for Go</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to restore a saved GoML model</h1>
                </header>
            
            <article>
                
<p>Once you have put the hard work into creating a ML model, you may need to shut down your computer. What happens to your model when the computer is restarted? Unless you have persisted it to disk, it will disappear and you will need to start the training process again. Even if you have saved the model hyperparameters in a gophernotes notebook, the model itself will not have been saved. And if the training process is a long one, you may need to wait a long time before your model is ready to use again. </p>
<p>In the following example, we will explain how to restore the model we created in <a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">Chapter 3</a>, <em>Supervised Learning</em>, and persist it to the local filesystem in a <kbd>model.dat</kbd> file using its <kbd>PersistToFile</kbd> method, which is provided by the GoML API. We will restore it using its <kbd>RestoreFromFile</kbd> method. We will assume that all the other funcs we created in <a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank"/><a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">Chapter 3</a>, <em>Supervised Learning</em>, are available to us, such as converting an image into a slice of floats: </p>
<pre>// IsImageTrousers invokes the Saved model to predict if image at given index is, in fact, of trousers<br/>// For simplicity, this loads the model from disk on every request, whereas loading it once and caching it<br/>// would be preferable in a commercial application.<br/><br/>func IsImageTrousers(i int) (bool, error) {<br/>  model := linear.Logistic{}<br/>  if err := model.RestoreFromFile("model.dat"); err != nil {<br/>    return false, err<br/>  }<br/>  prediction, err := model.Predict(testImages[i])<br/>  return prediction &gt; 0.5, err<br/>}</pre>
<p>We can now use this code within gophernotes to generate a prediction and compare it to the ground truth in the <kbd>Label</kbd> column:</p>
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3">
<pre>// Prediction<br/><br/>IsImageTrousers(16)</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<p class="prompt output_prompt">Running the preceding code cell in gophernotes will produce the following output:</p>
<div class="output_text output_subarea output_execute_result">
<pre>true &lt;nil&gt;</pre></div>
</div>
</div>
</div>
<p>Let's check the output:</p>
<pre><span class="mi">// Ground truth<br/><br/>df.Col("Label").Elem(16).Int() == 1<br/></span></pre>
<p>We could also use the same validation techniques we introduced in <a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">Chapter 3</a>,<em> Supervised Learning</em>, to check that the quality of the output is as expected. This approach works very well when the model was written in Go and persisted to be reused at a later time. However, if the model was written in Python and not recoverable directly in Go (such is the case for <kbd>scikit-learn</kbd> models, for example), the only way to use it to make a prediction may be to engineer some communication between a Python model and a Go application. While this increases the overall complexity of the applications, it has significant advantages, as we will discuss in the following sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deciding when to adopt a polyglot approach</h1>
                </header>
            
            <article>
                
<p>As we have seen in the previous chapters, the Go ecosystem provides ample opportunities to solve machine learning problems natively. However, being obstinate in requiring the solution to remain pure-Go can lead to increased development time or even reduced training performance, as other, more specialized ML libraries can provide higher-level APIs or performance optimizations that have not been implemented in the corresponding Go libraries yet.</p>
<p>A good example of both is the Python ML library, Keras. The aim of this library is to provide a high-level API that allows the author to perform a wide range of ML tasks, such as data preprocessing, model training, model validation, and persistence. Its abstractions have concrete implementations in various backends, such as TensorFlow, which are known to be extremely performant. For these reasons, Keras is one of the most popular ML libraries in any language: its MIT-licensed GitHub repository has over 40,000 stars and a search on GitHub reveals that over 20,000 repositories match the search term keras, meaning that the name of the repository includes that word. A search of the code content reveals that over one million files on GitHub contain the search term keras. </p>
<p>However, to write the entire application in Python just to make use of one library fails to take advantage of the benefits offered by Go, which we enumerated in <a href="cefdc727-5b16-4942-8adb-a2d476e9d546.xhtml" target="_blank">Chapter 1</a>, <em>Introducing Machine Learning with Go</em>. If these factors are not important in the development of your application, then by all means create it in Python, but, in what follows, we will assume that you want the best of both worlds.</p>
<p>Therefore, two options present themselves: first, develop the application entirely in Go. Second, develop the ML model in Python and invoke this model from your Go code, which will contain the main application and business logic. Within a commercial setting where the goal is to produce a production-ready product, the advantages of both options are as follows:</p>
<p><strong>Pure-Go application</strong>:</p>
<ul>
<li>Easier to maintain over a polyglot solution</li>
<li>Less complexity in application component interactions, because there is no need to manage invocation of an external ML component</li>
<li>Easier to on-board team members</li>
<li>Less dependencies to update</li>
</ul>
<p>Existing libraries may offer the required functionality out of the box with sufficient performance, obviating any advantage gained from using specialized libraries in other languages.</p>
<p><strong>Polyglot application</strong>:</p>
<ul>
<li>Drastically reduce the amount of code for complex ML problems using high-level abstractions from specialist libraries in other languages</li>
<li>In some cases, performance advantages, as some GoML libraries are not designed for out-and-out speed (deep learning is a good example of this)</li>
<li>Can suit a multi-team approach better, as data science teams are more familiar with Python or R libraries</li>
<li>Leverage preexisting models—academic research papers typically publish Caffe or TensorFlow models with Python or Lua scripts to invoke them</li>
</ul>
<p>In conclusion, for ML applications where existing Go libraries offer what you need out of the box or with little modification, a native Go solution will reduce complexity in the application and enhance maintainability. However, if this is not the case, particularly for very complex problems such as deep learning and computer vision, combining Go with the latest tools from other languages is worth the added complexity.</p>
<p>In the examples that follow, we will invoke a variety of Python ML models from a Go application. Our reason for using Python specifically is that Python is preinstalled in most Linux distributions and is also the most popular language for ML<sup>[4][5]</sup>. The solutions we will describe can be applied to a model written in any programming language.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Example – invoking a Python model using os/exec</h1>
                </header>
            
            <article>
                
<p>To get started with polyglot ML applications, we will revisit the logistic regression example from <a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">Chapter 3</a>, <em>Supervised Learning</em>. We will assume that, instead of Go, the model was written in Python and that we wish to invoke it from our Go application. To do this, we will use command-line arguments to pass inputs to the model and read the model's prediction from <strong>standard output</strong> (<strong>STDOUT</strong>).</p>
<p>To exchange data between Python and Go, we will use strings formatted using <strong>JavaScript Object Notation</strong> (<strong>JSON</strong>). This choice is arbitrary of course<sup>[6]</sup>, and we could have chosen any one of the other formats for which the Go and Python standard libraries have support, such as XML, or invented our own. JSON has the advantage that it takes very little effort to use in both languages.</p>
<p>The process we will follow to communicate with the Python subprocess is as follows. Generally, there are three steps: serialization of the request, executing the subprocess, and deserialization of the response:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-192 image-border" src="assets/9c2271a0-d0ce-448b-bd00-dc17353a7b93.png" style="width:21.83em;height:26.58em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Fig.1: The process we use to communicate with a Python subprocess that runs a pretrained logistic regression model</div>
<p>We will start by loading the MNIST dataset and converting it into a dataframe. You can find the code for this in <a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml">Chapter 3</a>, <em>Supervised Learning</em>. This time, however, we will convert the image data into a slice of ints, with each int between 0 and 255 (the value of each pixel), rather than a slice of floats. This is to ensure alignment with the Python model:</p>
<pre>// ImageSeriesToInts converts the dataframe's column containing image data for multiple images to a slice of int slices, where each int is between 0 and 255, representing the value of the pixel.<br/><br/>func ImageSeriesToInts(df dataframe.DataFrame, col string) [][]int {<br/><br/>  s := df.Col(col)<br/><br/>  ret := make([][]int, s.Len(), s.Len())<br/><br/>  for i := 0; i &lt; s.Len(); i++ {<br/><br/>    b := []byte(s.Elem(i).String())<br/><br/>    ret[i] = NormalizeBytes(b)<br/><br/>  }<br/><br/>  return ret<br/><br/>}</pre>
<p>Next, we will introduce a function that will allow us to start the Python subprocess and wait for it to finish:</p>
<pre>// InvokeAndWait invokes a Python 3 script with the given arguments, waits for it to finish, and returns the concatenated output of its STDOUT and STERRR.<br/>func InvokeAndWait(args ...string) ([]byte, error) {<br/>  var (<br/>    output []byte<br/>    errOutput []byte<br/>    err error<br/>  )<br/>  cmd := exec.Command("python3", args...)<br/>  stdout, err := cmd.StdoutPipe()<br/>  if err != nil {<br/>    return nil, err<br/>  }<br/>  stderr, err := cmd.StderrPipe()<br/>  if err := cmd.Start(); err != nil {<br/>    return nil, err<br/>  }<br/>  if output, err = ioutil.ReadAll(stdout); err != nil {<br/>    return nil, err<br/>  }<br/>  if errOutput, err = ioutil.ReadAll(stderr); err != nil || len(errOutput) &gt; 0 {<br/><br/>    return nil, fmt.Errorf("Error running model: %s", string(errOutput))<br/>  }<br/>  return output, nil<br/>}</pre>
<p>Now, we are ready to assemble our prediction function, which will serialize the image data, pass it to the subprocess as an argument when it starts, wait for the subprocess to finish, and deserialize the response:</p>
<pre>// IsImageTrousers invokes the Python model to predict if image at given index is, in fact, of trousers<br/><br/>func IsImageTrousers(i int) (bool, error){<br/>    b, err := json.Marshal(testImages[i])<br/>    if err != nil {<br/>        panic(err)<br/>    }<br/>    b, err = InvokeAndWait("model.py", "predict", string(b))<br/>    if err != nil {<br/>        return false, err<br/>    } else {<br/>        var ret struct {<br/>            IsTrousers bool `json:"is_trousers"`<br/>        }<br/>        err := json.Unmarshal(b, &amp;ret)<br/>        if err != nil {<br/>            return false, err<br/>        }<br/>        return ret.IsTrousers, nil<br/>    }<br/>}</pre>
<p>We can now use this code within gophernotes to generate a prediction and compare it to the ground truth in the <kbd>Label</kbd> column:</p>
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3">
<pre>// Prediction<br/>IsImageTrousers(16)</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<p class="prompt output_prompt">Running this in a gophernotes cell provides the following output:</p>
<div class="output_text output_subarea output_execute_result">
<pre>true &lt;nil&gt;</pre></div>
</div>
</div>
</div>
<p>Let's check the output:</p>
<pre>// Ground truth<br/>df.Col("Label").Elem(16).Int() == 1</pre>
<p>As expected, this outputs <kbd>true</kbd>. We can repeat this for several different images to get some confidence that everything is working as it should. Both the Go and Python code use the <kbd>predict</kbd> argument to signify which action should be performed <span>– </span>we could also have a <kbd>test</kbd> action that checks that the image the Python code reconstructs from its arguments is the correct one, further increasing our confidence that the subprocess communication is correct. </p>
<div class="mce-root packt_infobox">Subprocess communication can be operating system-specific, particularly when output redirection is involved. One advantage of Go is that the pipe method we present here works equally well across operating systems, with no extra modification needed, whereas, in other languages such as Python, additional work is sometimes required. </div>
<p>While the code is succinct and easy to debug, the need to start a new Python process to handle every request can impact performance for applications with smaller, quicker models. Furthermore, it creates a fairly tight coupling between the Go application and its Python model. This could pose an issue in larger teams where a data science team creates a model and a software development team creates the rest of the application. It could also create issues where the model should be exposed to multiple applications, not just one <span>– </span>what should you do then? Have one copy of the model for each application? This could lead to maintainability issues. In the following example, we will look at one way to decouple the Go application from its Python model. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Example – invoking a Python model using HTTP</h1>
                </header>
            
            <article>
                
<p>What if the model resides on a different machine, we need to decouple the Go and model logic, or if there are multiple actions we may wish to perform, such as training a user-specific model based on user data, and later use this model to generate a prediction? In those cases, our previous solution using command-line arguments will become more complex as we add more arguments to distinguish between actions and return codes. This type of invocation is generally known as <strong>Remote Procedure Call</strong> (<strong>RPC</strong>), and solutions such as SOAP or JSON-RPC have been known to the industry for decades<sup>[7]</sup>. </p>
<p>In the following example, we will use a more universal and generic protocol: HTTP. Strictly speaking, HTTP is a data transfer protocol, and one that is often used as the plumbing for RPC protocols. However, with very little effort, we can create our own minimal RPC on top of HTTP by exposing a single endpoint that will accept POST requests. This has the advantage that no dependencies beyond the standard library in either Python or Go are required, and that debugging protocol errors are particularly straightforward. The downside is that it requires a bit more work to handle concerns such as serialization.</p>
<p>The request/response process we will follow is illustrated in the following diagram:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-193 image-border" src="assets/6df6714f-40d5-4529-89fe-b80f27b22285.png" style="width:55.92em;height:15.25em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Fig. 2: The request/reply process for a GoML application to communicate with a pretrained Python model using HTTP</div>
<p>Unlike the previous example, we assume that the Python HTTP server is already running. If you are following along with the companion repository, you can start the Python server with the <kbd>python3 model_http.py</kbd> command after installing its dependencies using <kbd>install-python-dependencies.sh</kbd>. This means that the Go code is particularly short:</p>
<pre>// Predict returns whether the ith image represents trousers or not based on the logistic regression model<br/><br/>func Predict(i int) (bool, error){<br/>    b, err := json.Marshal(testImages[i])<br/>    if err != nil {<br/>        return false, err<br/>    }<br/>    r := bytes.NewReader(b)<br/>    resp, err := http.Post("http://127.0.0.1:8001", "application/json", r)<br/>    if err != nil {<br/>        return false, err<br/>    }<br/>    body, err := ioutil.ReadAll(resp.Body)<br/>    if err != nil {<br/>        return false, err<br/>    }<br/>    resp.Body.Close()<br/>    var resp struct {<br/>        IsTrousers bool `json:"is_trousers"`<br/>    }<br/>    err := json.Unmarshal(body, &amp;resp)<br/>    return resp.IsTrousers, err <br/>}</pre>
<p>As we did previously, we can generate some predictions to ensure communication between Go and Python processes is working as expected:</p>
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3">
<pre>// Expected: true &lt;nil&gt;<br/><br/>Predict(16)</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<p class="prompt output_prompt">As expected, we get back the following:</p>
<div class="output_text output_subarea output_execute_result">
<pre>true &lt;nil&gt;</pre></div>
</div>
</div>
</div>
<p>We can continue this process for several other images to ensure that the response matches the ground truth value, as defined by the <kbd>df.Col("Label")</kbd> series. We could also create multiple HTTP endpoints on our Python HTTP server to allow testing of various kinds, further enhancing our confidence in interprocess communication.</p>
<div class="packt_tip">In the likely event that you ever need to debug communication with an HTTP server, a great tool is Postman, a free GUI tool that lets you create HTTP requests and inspect the responses. You can get Postman at:<br/>
 <a href="https://www.getpostman.com/">https://www.getpostman.com/</a>.</div>
<p>In the previous examples, we assumed that the model was created in a different programming language (Python) and could only be accessed from that language. However, there are a few popular deep learning libraries that have striven to become more polyglot and, therefore, provide means to create a model using one language and use it using another. In the following examples, we will look at two of these libraries.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Example – deep learning using the TensorFlow API for Go</h1>
                </header>
            
            <article>
                
<p>Deep learning is a subfield of machine learning that employs neural networks, usually with many layers, to solve complex problems such image or speech recognition. In this example, we will look at how to leverage TensorFlow, a popular deep learning framework, using its Go bindings.</p>
<p>TensorFlow is a highly optimized library that was created by Google to perform calculations on objects called tensors<sup>[8]</sup>. If a vector is a collection of scalar entries (numbers) and a matrix a collection of vectors, then a tensor can be thought of as a higher-dimensional matrix, of which scalars, vectors, and matrices are special cases. While this may seem a bit abstract, tensors are natural objects to use when describing neural networks, and this is why TensorFlow has become one of the most popular libraries—even <em>the</em> most popular, according to some commentators—for commercial and academic deep learning development<sup>[9][10]</sup>. </p>
<p>In 2011, the team at Google Brain built a proprietary deep learning system called DistBelief<sup>[11]</sup>. A number of prominent computer scientists such as Jeff Dean and Geoffrey Hinton worked on its backpropagation and other neural network-related algorithms, leading to an increased uptake of the framework across many projects at Google. In 2017, the second generation of this framework, now called TensorFlow, was released under an open source license<sup>[12]</sup>.</p>
<p>TensorFlow is at its core a low-level API, also known as a backend for deep learning computations. Practically speaking, a data scientist working a commercial problem does not usually need to interact directly with the TensorFlow API on a daily basis. Instead, a number of frontends, such as Keras, which we introduced previously, are available as higher-level abstractions over TensorFlow and offer the best of both the performance and ease-of-use worlds. On the other hand, academic research where new types of neural architectures are invented is often performed using the low-level API, because no abstractions exist for the new constructs yet. The objects you create in TensorFlow, called <strong>graphs</strong>, can be persisted and reused in other languages, thanks to recent efforts to make the framework more polyglot<sup>[13]</sup>. </p>
<p>In this example, we will explain how to install TensorFlow and how to use its Go API to load a pretrained TensorFlow model and use it to make a prediction.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing TensorFlow</h1>
                </header>
            
            <article>
                
<p>The TensorFlow experience is usually a slick one—that is, after you have managed to install it correctly. The TensorFlow team recognized that this was a difficult step, and that building TensorFlow from source usually took hours in the best case, and as a result they now provide several easy installation options. It is worth noting that, if you have a compatible GPU on your system, you should install a GPU option as this will usually accelerate the software significantly, something particularly noticeable in the training phase:</p>
<ul>
<li><strong>Install with pip</strong>: TensorFlow is aimed at Python programmers who will typically use <kbd>pip</kbd> to manage their packages. At the time of writing, this method has been tested with Ubuntu Linux 16.04 or later, macOS 10.12.6 (Sierra) or later (albeit with no GPU support), Raspbian 9.0 or later, and Windows 7 or later.</li>
<li><strong>Use a Docker image</strong>: This will work with a wide range of systems that support Docker. There are two images to choose from: a vanilla TensorFlow image and one that also includes Jupyter, allowing you to have the same experience as gophernotes but with Python only.</li>
<li><strong>Build from source</strong>: This is best option if you are using a non-standard configuration or want to exert specific control over part of the build process (perhaps take advantage of some optimization that will only work for your particular configuration).</li>
</ul>
<div class="packt_infobox">There is also a fourth option, which is to use Google Colaboratory to run TensorFlow-based code in Google's cloud, but we will not delve into this option, as it currently only works with Python.</div>
<p><span>In this example, we will use a Docker image. Docker can be seen as a solution for packaging and running multiple applications (called containers) on the same machine while keeping them from interfering with one another. If you are not already familiar with it, head to <a href="https://docs.docker.com/get-started/">https://docs.docker.com/get-started/</a> for a five-minute tutorial. </span></p>
<p><span>We will use the vanilla TensorFlow-on-Ubuntu image called <kbd>tensorflow/tensorflow</kbd>, which does not include Jupyter. We will need to install Go on top of this image so that we can run our code. Because our code will depend on TensorFlow bindings for Go, we will also install them according to the official instructions<sup>[14]</sup>. This will require us to install the TensorFlow C bindings, too. Our Dockerfile will thus look as follows. Some steps have been omitted for brevity – you can find the full Dockerfile in the companion repository for this book:</span></p>
<pre>FROM tensorflow/tensorflow<br/><br/>## Install gcc for cgo ##<br/>RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \<br/> curl \<br/> git \<br/> wget \<br/> g++ \<br/> gcc \<br/> libc6-dev \<br/> make \<br/> pkg-config \<br/> &amp;&amp; rm -rf /var/lib/apt/lists/*<br/><br/>## Install TensorFlow C library ##<br/>RUN curl -L \<br/> "https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-1.13.1.tar.gz" | \<br/> tar -C "/usr/local" -xz<br/>RUN ldconfig<br/><br/>## Install Go ##<br/>ENV GOLANG_VERSION 1.9.2<br/><br/>RUN wget -O go.tgz "https://golang.org/dl/go${GOLANG_VERSION}.${goRelArch}.tar.gz"; \<br/> echo "${goRelSha256} *go.tgz" | sha256sum -c -; \<br/> tar -C /usr/local -xzf go.tgz; \<br/> rm go.tgz; \<br/> \<br/> if [ "$goRelArch" = 'src' ]; then \<br/> echo &gt;&amp;2; \<br/> echo &gt;&amp;2 'error: UNIMPLEMENTED'; \<br/> echo &gt;&amp;2 'TODO install golang-any from jessie-backports for GOROOT_BOOTSTRAP (and uninstall after build)'; \<br/> echo &gt;&amp;2; \<br/> exit 1; \<br/> fi; \<br/> \<br/> export PATH="/usr/local/go/bin:$PATH"; \<br/> go version<br/><br/>ENV GOPATH /go<br/>ENV PATH $GOPATH/bin:/usr/local/go/bin:$PATH<br/><br/>RUN mkdir -p "$GOPATH/src" "$GOPATH/bin" &amp;&amp; chmod -R 777 "$GOPATH"<br/><br/>## Go get tensorflow go library ##<br/>RUN \<br/> go get github.com/tensorflow/tensorflow/tensorflow/go \<br/> github.com/tensorflow/tensorflow/tensorflow/go/op<br/><br/>## Set up the environment so we can just run our code ##<br/>RUN mkdir $GOPATH/src/model<br/><br/>WORKDIR $GOPATH/src/model<br/><br/>ADD . $GOPATH/src/model<br/><br/>CMD ["go", "run", "main.go"]</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Import the pretrained TensorFlow model</h1>
                </header>
            
            <article>
                
<p>In <a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">Chapter 3</a>, <em>Supervised Learning</em>, we explained how to create a deep learning model in pure Go using the go-deep library. While this worked as a toy example, it was quite slow to train and required a lot of superfluous code. It would have been much easier, and resulted in more performance code, to use one of the industry-leading deep learning libraries, but unfortunately they are written in other languages. Using the Python library Keras, we have created a deep learning model that will serve as a classifier in the same problem that we looked at previously: <em>Is the given image of a pair of trousers?</em> We will now write some Go code to import our pretrained model.</p>
<div class="packt_tip">What if only the weights of the model were saved, rather than the more complete SavedModel format? In that case, you can still import it using the <kbd>graph.Import</kbd> func, but, subsequently, more work is required to tell TensorFlow about all the operations and variables. There is an example in the TensorFlow API godocs that illustrates this process<sup>[15]</sup>. </div>
<p>What follows assumes that the model was saved in the<span> </span><kbd>SavedModel</kbd><span> </span>format and that we know the names of the input and output<span> </span><kbd>Ops</kbd>. If the model was created by someone else using Keras or another third-party library, this can sometimes be tricky. One option is to use the <kbd>SavedModel</kbd> command-line interface tool to inspect the model<sup>[16]</sup>. </p>
<div class="packt_tip">If the model was created in Keras and you have access to the Python code, just inspect its <kbd>input</kbd><span> </span>and<span> </span><kbd>output</kbd> properties to see the names of the corresponding tensors. They may have a <kbd>:0</kbd> appended to them, which you can ignore.</div>
<p>To restore a <kbd>SavedModel</kbd> in Go, simply use the<span> </span><kbd>LoadSavedModel</kbd><span> </span>func. This will return a Graph and Session object that you can then operate on, passing inputs and retrieving outputs:</p>
<pre>savedModel, err := tf.LoadSavedModel("./saved_model", []string{"serve"}, nil)<br/>if err != nil {<br/>  log.Fatalf("failed to load model: %v", err)<br/>}</pre>
<p>Note that the second argument, called the tag, is often set to serve by convention. We can now access the input and output operations:</p>
<pre>input := savedModel.Graph.Operation("input_input_1")<br/>output := savedModel.Graph.Operation("output_1/BiasAdd")</pre>
<p>If either the input or output is nil at this stage, this means that you do not have the correct names, so you will need to return to inspecting the model to find out what they should be. It can also be useful to look at<span> </span><kbd>savedModel.Graph.Operations</kbd>, which is a slice of<span> </span><kbd>Operation</kbd>, and filter the list of operations down by those containing the search string input in their<span> </span><kbd>Name()</kbd>. </p>
<p>We can now access the restored session and graph:</p>
<pre>session := savedModel.Session<br/>graph := savedModel.Graph<br/>defer session.Close()<br/>fmt.Println("Successfully imported model!")</pre>
<p>Now, we can run this code inside our TensorFlow Docker container and see the result. We will build the Docker image from its Dockerfile and run it:</p>
<pre>docker build -t tfgo . &amp;&amp; \<br/>docker run -it tfgo</pre>
<p>If everything goes well, we should see some output while the container is being built (this will run much faster the second time) with the following messages at the end:</p>
<pre>Successfully built 9658a6232ef8<br/>Successfully tagged tfgo:latest<br/>Successfully imported model!</pre>
<p>The first two lines tell us that our Docker image was successfully built, and the last line comes from our Go code and lets us know that the model import operation worked without resulting in any errors.</p>
<div class="packt_tip">Depending on how you installed Docker, you may need superuser privileges to run these commands, so just prefix them with <kbd>sudo</kbd> if required. </div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating inputs to the TensorFlow model</h1>
                </header>
            
            <article>
                
<p>Now that we are able to recreate the TensorFlow graph and session from a <kbd>SavedModel</kbd>, we will create a procedure that will accept an image from the MNIST fashion dataset as a slice of bytes and use these bytes to populate the inputs of the model we loaded previously. Then, we will be able to run the model to get an output prediction. </p>
<p><span>We must create a procedure that will accept an image from the MNIST fashion dataset and return a tensor of the correct shape. We know from Chapter 3, <em>Supervised Learning</em>, that the model will expect a slice of 784 floats, and an inspection of the model (using <kbd>model.summary</kbd> in Python, or the <kbd>SavedModel</kbd> CLI) will reveal that the inputs should be a 1 x 784 tensor of</span> <kbd>float32</kbd><span> values.</span></p>
<div class="packt_infobox">When constructing tensors by passing slices of slices as an argument to the <kbd>NewTensor</kbd> func, make sure that they are all the same length. For example, you can pass 3 slices containing 7 elements each, and this will create a (3,7) tensor, but not 3 slices containing 5, 6, and 7 elements, respectively—the second dimension must be the same for all slices. </div>
<p><span>We can construct a blank (zero) tensor with the right shape like so:</span></p>
<pre>func makeBlankInputTensor() (*tf.Tensor, error) {<br/>  t := make([][]float32, 1)<br/>  t[0] = make([]float32, 784)<br/>  tensor, err := tf.NewTensor(t)<br/>  return tensor, err<br/>}</pre>
<p>While this is not very useful on its own, it illustrates the use of the <kbd>NewTensor</kbd> func, which can infer the correct tensor shape and value type from the Go <kbd>interface{}</kbd> it is passed. Using the <kbd>ImageSeriesToFloats</kbd> func we introduced in <a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml">Chapter 3</a>, <em>Supervised Learning</em>, we can easily convert an image into a slice of <kbd>float32</kbd> and thus make the input tensor.  </p>
<p>We can run the model to get a prediction:</p>
<pre>tensor, err := makeTensorFromImage("/path/to/fashion/MNIST", 12)<br/>if err != nil {<br/>  log.Fatal(err)<br/>}<br/>prediction, err := session.Run(<br/>  map[tf.Output]*tf.Tensor{<br/>    graph.Operation(input.Name()).Output(0): tensor,<br/>  },<br/>  []tf.Output{<br/>    graph.Operation(output.Name()).Output(0),<br/>  },<br/>  nil)<br/>if err != nil {<br/>  log.Fatal(err)<br/>}<br/><br/>probability := prediction[0].Value().([][]float32)[0][0]<br/>if probability &gt; 0.5 {<br/>  fmt.Printf("It's a pair of trousers! Probability: %v\n", probability)<br/>} else {<br/>  fmt.Printf("It's NOT a pair of trousers! Probability: %v\n", probability)<br/>}</pre>
<p>For example, when running this with a blank tensor as the input, the last few lines of output are as follows:</p>
<pre>Successfully built b7318b44f92d<br/>Successfully tagged tfgo:latest<br/>Successfully imported model!<br/>It's NOT a pair of trousers! Probability: 0.04055497</pre>
<p>In the following chapter, we will explore the pattern of using Docker to deploy ML application workloads in more detail.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we compared Go-only and polyglot ML solutions from a practical point of view, contrasting their drawbacks and advantages. We then presented two generic solutions to develop polyglot ML solutions: the os/exec package and JSON-RPC. Finally, we looked at two highly-specialized libraries that come with their own RPC-based integration solutions: TensorFlow and Caffe. You have learned<span> h</span><span>ow to decide whether to use a Go-only or polyglot approach to ML in your application, h</span><span>ow to implement an RPC-based polyglot ML application, and h</span><span>ow to run TensorFlow models from Go.</span></p>
<p>In the next chapter, we will cover the last step of the ML development life cycle: taking an ML application written in Go to production.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further readings</h1>
                </header>
            
            <article>
                
<ol>
<li><em>Ke</em><em>ras GitHub repository</em>: <a href="https://github.com/keras-team/keras">https://github.com/keras-team/keras</a>. Retrieved April 30, 2019.</li>
<li><em>GitHub search for keras</em>: <a href="https://github.com/search?utf8=%E2%9C%93&amp;q=keras&amp;type=">https://github.com/search?utf8=%E2%9C%93&amp;amp;q=keras&amp;amp;type=</a>. Retrieved April 30, 2019.</li>
<li><em>GitHub content search for keras</em>: <a href="https://github.com/search?q=keras&amp;type=Code">https://github.com/search?q=keras&amp;amp;type=Code</a>. Retrieved April 30, 2019.</li>
<li><em>Python is Becoming the World's Most Popular Coding Language</em>, The Economist. July 26, 2018: <a href="https://www.economist.com/graphic-detail/2018/07/26/python-is-becoming-the-worlds-most-popular-coding-language">https://www.economist.com/graphic-detail/2018/07/26/python-is-becoming-the-worlds-most-popular-coding-language.</a> Retrieved April 30, 2019.</li>
<li><em>Using Python on Unix Platforms</em>: <a href="https://docs.python.org/2/using/unix.html">https://docs.python.org/2/using/unix.html</a>. Retrieved April 30, 2019.</li>
<li><em>JSON</em>: <a href="https://www.json.org/">https://www.json.org/</a>. Retrieved April 30, 2019.</li>
<li><em>Cover Pages <span>–</span> SOAP</em>: <a href="http://xml.coverpages.org/soap.html">http://xml.coverpages.org/soap.html</a>. Retrieved April 30, 2019.</li>
<li><em>TensorFlow Core</em>: <a href="https://www.tensorflow.org/overview/">https://www.tensorflow.org/overview/</a>. Retrieved April 30, 2019.</li>
<li><em>Deep Learning Framework Power Scores</em>: <a href="https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a">https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a</a>. Retrieved April 30, 2019. </li>
</ol>
<ol start="10">
<li><em>Ranking Popular Deep Learning Frameworks</em>: <a href="https://blog.thedataincubator.com/2017/10/ranking-popular-deep-learning-libraries-for-data-science/">https://blog.thedataincubator.com/2017/10/ranking-popular-deep-learning-libraries-for-data-science/</a>. Retrieved April 30, 2019.</li>
<li>Dean, Jeff et. al. <em>Large-Scale Machine Learning on Heterogeneous Distributed Systems</em>. Nov. 9, 2015. <a href="http://download.tensorflow.org/paper/whitepaper2015.pdf">http://download.tensorflow.org/paper/whitepaper2015.pdf</a>. Retrieved April 30, 2019. </li>
<li><em>TensorFlow</em> <kbd>RELEASE.md</kbd>: <a href="https://github.com/tensorflow/tensorflow/blob/07bb8ea2379bd459832b23951fb20ec47f3fdbd4/RELEASE.md">https://github.com/tensorflow/tensorflow/blob/07bb8ea2379bd459832b23951fb20ec47f3fdbd4/RELEASE.md</a>. Retrieved April 30, 2019.</li>
<li><em>TensorFlow in Other Languages</em>: <a href="https://www.tensorflow.org/guide/extend/bindings">https://www.tensorflow.org/guide/extend/bindings</a>. Retrieved April 30, 2019. </li>
<li><em>Installing TensorFlow for Go</em>: <a href="https://www.tensorflow.org/install/lang_go">https://www.tensorflow.org/install/lang_go </a>. Retrieved May 1, 2019. </li>
<li><em>TensorFlow—godocs</em>: <a href="https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go">https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go</a>. Retrieved May 3, 2019.</li>
<li><em>Save and Restore</em>: <a href="https://www.tensorflow.org/guide/saved_model#install_the_savedmodel_cli">https://www.tensorflow.org/guide/saved_model#install_the_savedmodel_cli</a>. Retrieved May 3, 2019.</li>
<li><em>Tag constants</em>: <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/tag_constants.py">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/tag_constants.py</a>. Retrieved May 22, 2019.</li>
</ol>


            </article>

            
        </section>
    </body></html>