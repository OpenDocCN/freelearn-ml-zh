["```py\n{\n  \"image\": {\n    object(Image)// Image which needs to be processed.\n  },\n  \"features\": [\n    {\n      object(Feature) //Google Vision Feature that needs to be invoked.\n    }\n  ],\n  \"imageContext\": {\n    object(ImageContext) //additional image context if required.\n  },\n}\n```", "```py\n{\n \"labelAnnotations\": [\n {\n object(EntityAnnotation)\n }\n ],\n \"error\": {\n object(Status)\n },\n}\n```", "```py\ndependencies {\n compile fileTree(include: ['*.jar'], dir: 'libs')\n testCompile 'junit:junit:4.12'\n compile 'com.android.support:appcompat-v7:27.0.2'\n compile 'com.android.support:design:27.0.2'\n compile 'com.google.api-client:google-api-client-android:1.23.0' exclude module: 'httpclient'\n compile 'com.google.http-client:google-http-client-gson:1.23.0' exclude module: 'httpclient'\n compile 'com.google.apis:google-api-services-vision:v1-rev369-1.23.0'\n}\n```", "```py\nVision.Builder builder = new Vision.Builder(httpTransport, jsonFactory, null); \n```", "```py\nVisionRequestInitializer requestInitializer = new VisionRequestInitializer(CLOUD_VISION_API_KEY)\nbuilder.setVisionRequestInitializer(requestInitializer);\n```", "```py\nVision vision = builder.build();\n\n```", "```py\nBatchAnnotateImagesRequest batchAnnotateImagesRequest = new BatchAnnotateImagesRequest();\n\nbatchAnnotateImagesRequest.setRequests(new ArrayList<AnnotateImageRequest>() {{ AnnotateImageRequest annotateImageRequest = new AnnotateImageRequest();\n // Add the image\n Image base64EncodedImage = new Image();\n // Convert the bitmap to a JPEG\n // Just in case it's a format that Android understands but Cloud Vision\n ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); bitmap.compress(Bitmap.CompressFormat.JPEG, 90, byteArrayOutputStream);\nbyte[] imageBytes = byteArrayOutputStream.toByteArray();\n// Base64 encode the JPEG\nbase64EncodedImage.encodeContent(imageBytes); annotateImageRequest.setImage(base64EncodedImage);\n// add the features we want\nannotateImageRequest.setFeatures(new ArrayList<Feature>() {{\nFeature labelDetection = new Feature(); labelDetection.setType(\"LABEL_DETECTION\"); labelDetection.setMaxResults(MAX_LABEL_RESULTS);\nadd(labelDetection);\n}});\n// Add the list of one thing to the request\nadd(annotateImageRequest);\n}});\nVision.Images.Annotate annotateRequest =  vision.images().annotate(batchAnnotateImagesRequest);\n```", "```py\n //Formatting the response as a string\n private static String convertResponseToString(BatchAnnotateImagesResponse response) {\n StringBuilder message = new StringBuilder(\"I found these things:\\n\\n\"); List<EntityAnnotation> labels = response.getResponses().get(0).getLabelAnnotations();\n if (labels != null) {\n for (EntityAnnotation label : labels) {\n message.append(String.format(Locale.US, \"%.3f: %s\", label.getScore(), label.getDescription()));\n message.append(\"\\n\");\n }\n } else {\n message.append(\"nothing\");\n }\n return message.toString();\n }\n\n```"]