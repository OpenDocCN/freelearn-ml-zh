["```py\npip3 install mlflow\n```", "```py\nmlflow ui\n```", "```py\n[2021-03-11 14:34:23 +0200] [43819] [INFO] Starting gunicorn 20.0.4\n[2021-03-11 14:34:23 +0200] [43819] [INFO] Listening at: http://127.0.0.1:5000 (43819)\n[2021-03-11 14:34:23 +0200] [43819] [INFO] Using worker: sync\n[2021-03-11 14:34:23 +0200] [43821] [INFO] Booting worker with pid: 43821\n```", "```py\npip3 install --upgrade azureml-sdk\n```", "```py\n    python3 -m pip install jupyterhub\n    ```", "```py\n    def swap(a,b):\n    \"\"\"Swaps the variables a and b. Returns the swapped variables\"\"\" \n    return b, a\n    ```", "```py\n    def function_with_types_in_docstring(param1, param2): \"\"\"Example function with types documented in the docstring.\n    `PEP 484`_ type annotations are supported. If attribute, parameter, and\n    return types are annotated according to `PEP 484`_, they do not need to be\n    included in the docstring:\n    Args:\n        param1 (int): The first parameter. \n        param2 (str): The second parameter.\n    Returns:\n         bool: The return value. True for success, False otherwise.\n                                  \"\"\"\n    ```", "```py\ngit clone https://xxxxxxxxx@dev.azure.com/xxxxx/Learn_MLOps/_git/Learn_MLOps\n```", "```py\njupyter lab\n```", "```py\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.pyplot import figure\nimport seaborn as sns\nfrom azureml.core import Workspace, Dataset\n#import dataset\ndf = pd.read_csv('Dataset/weather_dataset_raw.csv')\n```", "```py\ndf.describe()\n```", "```py\ndf.dtypes\n```", "```py\ndf['Timestamp'] = pd.to_datetime(df['Timestamp'])\n```", "```py\ndf.isnull().values.any()\n```", "```py\ndf['Weather_conditions'].fillna(method='ffill', inplace=True, axis=0)\n```", "```py\ndf['Weather_conditions'].value_counts()\n```", "```py\ndf['Weather_conditions'].replace({\"snow\": \"no_rain\",  \"clear\": \"no_rain\"}, inplace=True)\n```", "```py\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = df['Weather_conditions']\ny = le.fit_transform(y)\n```", "```py\ny = pd.DataFrame(data=y, columns=[\"Weather_condition\"])\ndf = pd.concat([df,y], axis=1)\ndf.drop(['Weather_conditions'], axis=1, inplace=True)\n```", "```py\ndf['Future_weather_condition'] = df.Current_weather_condition.shift(4, axis = 0) \ndf.dropna(inplace=True)\n```", "```py\ndf.corr(method=\"pearson\")\n# Visualizing using heatmap\ncorrMatrix = df.corr()\nsn.heatmap(corrMatrix, annot=True)\nplt.show()\n```", "```py\ntime = df['Timestamp]\ntemp = df['Temperature_C']\n# plot graph\nplt.plot(time, temp)\nplt.show()\n```", "```py\nsubscription_id = '---insert your subscription ID here----'\nresource_group = 'Learn_MLOps'\nworkspace_name = 'MLOps_WS' \nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n```", "```py\n# get the default datastore linked to upload prepared data\ndatastore = workspace.get_default_datastore()\n#upload the local file from src_dir to target_path in datastore\ndatastore.upload(src_dir='Dataset', target_path='data')\ndataset =  /\nDataset.Tablular.from_delimited_files(datastore.path('data/weather_dataset_processed.csv'))\n```", "```py\n# preview the first 3 rows of the dataset from the datastore\ndataset.take(3).to_pandas_dataframe()\n```", "```py\nweather_ds = dataset.register(workspace=workspace, name=weather_ds_portofTurku, description='processed weather data')\n```"]