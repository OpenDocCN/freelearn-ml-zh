<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer051">
<h1 class="chapter-number" id="_idParaDest-94"><a id="_idTextAnchor094"/>4</h1>
<h1 id="_idParaDest-95"><a id="_idTextAnchor095"/>Developing and Deploying ML Models</h1>
<p>In the previous chapter, we discussed the preparation stage for the ML process, including problem framing and data preparation. After we have framed the problem and have a clean dataset, it’s time to develop and deploy the ML model. In this chapter, we will discuss the model development process. We will start from model data input and hardware/software platform setup, then focus on the model development pipeline, including model training, validation, testing, and finally deploying to production. Our emphasis is on understanding the basic concepts and the thought processes behind them and strengthening the knowledge and skills by practicing. The following topics are covered in this chapter:</p>
<ul>
<li>Splitting the dataset</li>
<li>Building the platform</li>
<li>Training the model</li>
<li>Validating the model</li>
<li>Tuning the model</li>
<li>Testing and deploying the model</li>
<li>Practicing with scikit-learn</li>
</ul>
<p>In <a href="B18333_13.xhtml#_idTextAnchor209"><em class="italic">Appendix 3</em></a>, we provide practice examples of ML model development using the Python data science package scikit-learn.</p>
<h1 id="_idParaDest-96"><a id="_idTextAnchor096"/>Splitting the dataset</h1>
<p>Through the data preparation process, we have gained a dataset that is ready to be used for model <a id="_idIndexMarker205"/>development. To avoid model underfitting and overfitting, it is a best practice to split the dataset randomly yet proportionally, into independent subsets based on the model development process: a training dataset, a validation dataset, and a testing dataset:</p>
<ul>
<li><strong class="bold">Training dataset</strong>: The subset <a id="_idIndexMarker206"/>of data used to train the model. The model will learn from the training dataset.</li>
<li><strong class="bold">Validation dataset</strong>: The <a id="_idIndexMarker207"/>subset of data used to validate the trained model. Model hyperparameters will be tuned for optimization based on validation.</li>
<li><strong class="bold">Testing dataset</strong>: The subset <a id="_idIndexMarker208"/>of data used to evaluate a final model before its deployment to production.</li>
</ul>
<p>A common practice is to use 80 percent of the data for the training subset, 10 percent for validation, and 10 percent for testing. When you have a large amount of data, you can split it into 70 percent training, 15 percent validation, and 15 percent testing.</p>
<h1 id="_idParaDest-97"><a id="_idTextAnchor097"/>Preparing the platform</h1>
<p>While data input has a big impact on model quality, the hardware/software platform where we <a id="_idIndexMarker209"/>train/validate/test the model will also impact the model and the development process. Choosing the right platform is very important to the ML process.</p>
<p>While certainly, you can choose to use a desktop or laptop for ML model development, it is a recommended practice to use cloud platforms, thanks to the great advantages that cloud computing provides: self-provisioning, on-demand, resilience, and scalability, at a global scale. Many tools are provided in cloud computing to assist data scientists in data preparation and model development.</p>
<p>Among the cloud service providers, Google Cloud Platform provides great ML platforms to data scientists: flexible, resilient, and performant, from end to end. We will discuss more details of the Google Cloud ML platform in the third part of the book.</p>
<p>Now that we have prepared the datasets and ML platform, let’s dive right into the ML model <a id="_idIndexMarker210"/>development process, starting with model training.</p>
<h1 id="_idParaDest-98"><a id="_idTextAnchor098"/>Training the model </h1>
<p>Using the training data subset, on the platform, we train ML models to learn the relationships <a id="_idIndexMarker211"/>between the target and the features. ML model training is an iterative process: it starts from an assumed model with initial parameters and continues the learning process until it fits the training dataset. <em class="italic">Figure 4.1</em> shows a sample ML model training process, where we have selected a linear regression model (<em class="italic">z=wx+b</em>) and chosen the initial parameters (<em class="italic">w</em> and <em class="italic">b</em>). We calculate the model predict-error – the gap between the model output and the actual data label – this step is called forward propagation. If the <a id="_idIndexMarker212"/>error is not optimized (the accuracy is not within the specified range), we will <a id="_idIndexMarker213"/>need to move back and adjust the model’s parameters (<em class="italic">w</em> and <em class="italic">b</em>) – this step is called backward propagation. We will then go forward to recalculate the error again. This model training process repeats the steps of <em class="italic">forward propagation</em>, <em class="italic">backward propagation</em>, and <em class="italic">forward propagation</em> until we get a model that yields the predict-error within the expected range, that is, meeting the accuracy defined by the business objectives. The model training process is then complete.</p>
<div>
<div class="IMG---Figure" id="_idContainer030">
<img alt="Figure 4.1 – ML model training process " height="143" src="image/Figure_4.1.jpg" width="1097"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – ML model training process</p>
<p>As you may have noticed, we chose a linear model (<em class="italic">z=wx+b</em>) in the previous example. In real life, we often use domain knowledge and certain assumptions when selecting an ML model. It could be linear, polynomial, or even something that can only be expressed by neural networks. </p>
<p>Next, we will look at the sample ML problems framed in the previous chapter (<em class="italic">examples 1</em>, <em class="italic">2</em>, and <em class="italic">3</em>), discuss linear regression and binary classification, and then extend them to advanced models and algorithms.</p>
<h2 id="_idParaDest-99"><a id="_idTextAnchor099"/>Linear regression </h2>
<p>In <a href="B18333_03.xhtml#_idTextAnchor072"><em class="italic">Chapter 3</em></a><em class="italic">, Preparing for ML Development</em>, we talked about <em class="italic">example 1</em>: Zeellow needs to accurately <a id="_idIndexMarker214"/>predict house prices from their historical dataset. Since <a id="_idIndexMarker215"/>the inputs for the problem are labeled, it is a supervised learning problem, and since the output is a continuous value, it is a regression problem. </p>
<p>From a mathematical point of view, this is a typical problem of finding the function (relationship) between the target and the features, and the only things we have are the sample datasets. So, how do we figure out the function? Let’s inspect a simple dataset of <em class="italic">example 1</em>: the sale prices for 10 houses for a certain time period, at a certain location. The sample dataset is shown in <em class="italic">Table 4.2</em>.</p>
<div>
<div class="IMG---Figure" id="_idContainer031">
<img alt="Table 4.2 – Example 1 housing dataset " height="656" src="image/Figure_4.2.jpg" width="1631"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 4.2 – Example 1 housing dataset</p>
<p>There are multiple features related to the target (house price). We will start by examining the relationship between the house price and one feature of the house. Let us look at the house sale price (target, denoted by <em class="italic">y</em>) and the house square footage (feature, denoted by <em class="italic">x</em>), leading to the topic of one variable regression.</p>
<h3>One variable regression</h3>
<p>As you can <a id="_idIndexMarker216"/>see from <em class="italic">Table 4.2</em>, there are 10 rows from the sample training dataset, and we need to find a function <em class="italic">y=f(x)</em> that will best describe the relationship between target <em class="italic">y</em> and feature <em class="italic">x</em>. Naturally, we will use a diagram to visualize their relationship. If we put the 10 items in the dataset into a coordinate system, we get <em class="italic">Figure 4.3</em>. As you can see, there are 10 points distributed in the first quadrant and we need to make an assumption about the relationship between the house price (<em class="italic">y</em>) and the house square footage (<em class="italic">x</em>). Is it a linear function (as shown by lines l<span class="subscript">1</span> and l<span class="subscript">2</span>) or a quadratic function (curve shown as d1) that represents the relationship of <em class="italic">y </em>and <em class="italic">x</em>? Evidently, d1 does not work since intuitively we know that <em class="italic">y</em> will increase <a id="_idIndexMarker217"/>when <em class="italic">x</em> increases. Now, among line l<span class="subscript">1</span> and l<span class="subscript">2</span>, which one do we choose? This becomes a one-variable linear regression problem: find the best line <em class="italic">y=w*x+b*</em> (with parameters <em class="italic">w*</em> and <em class="italic">b*</em>) that best fits the training dataset.</p>
<div>
<div class="IMG---Figure" id="_idContainer032">
<img alt="Figure 4.3 – Linear regression " height="604" src="image/Figure_4.3.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – Linear regression</p>
<p>Our objective here is to find the function that best fits the existing data and will predict the best target value (closest to the actual value) for new data. How do you define a <em class="italic">best fit</em>? To answer this question, we came up with the mathematical concept of a <em class="italic">cost function</em> to measure a model’s performance: the difference or distance between the predicted values and the actual values.</p>
<p>There are several ways to measure the difference between predicted values and actual values. Denote (<em class="italic">x</em><span class="subscript">i</span>, <em class="italic">y</em><span class="subscript">i</span>) using the coordinate of the <em class="italic">i</em><span class="superscript">th</span> data point; that is, <em class="italic">y</em><span class="subscript">i</span> is the actual value for <em class="italic">x</em><span class="subscript">i</span>, and <img alt="" height="42" src="image/B18333_04_001.png" width="25"/> is the predicted value for <em class="italic">x</em><span class="subscript">i</span>. The cost function can then be defined as one of the following (here <em class="italic">N</em> is the number of samples, <em class="italic">N=10</em> for our <em class="italic">example 1</em>):</p>
<ul>
<li>The <strong class="bold">Mean Absolute Error</strong> (<strong class="bold">MAE</strong>) is the sum of the absolute differences between <a id="_idIndexMarker218"/>the prediction and true values:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer034">
<img alt="" height="115" src="image/B18333_04_002.jpg" width="341"/>
</div>
</div>
<ul>
<li>The <strong class="bold">Mean Squared Error</strong> (<strong class="bold">MSE</strong>) is the sum of the squared differences between <a id="_idIndexMarker219"/>the prediction and true values:<div class="IMG---Figure" id="_idContainer035"><img alt="" height="128" src="image/B18333_04_003.jpg" width="399"/></div></li>
</ul>
<p>While the MSE and MAE can be both used as cost functions, there are some differences between them: minimizing <a id="_idIndexMarker220"/>the MAE tends to decrease the gap at each point and can lead some to zeros (thus removing some features and making the model scarce). Minimizing the MSE will avoid big gaps but will not lead to zero gaps. </p>
<p>Now the problem becomes: how do we choose the right parameter (<em class="italic">w, b</em>) such that the MSE or MAE is minimized? We will use the MSE as the cost function, and our focus is to find the right parameters (<em class="italic">w, b</em>) so that the cost function MSE is minimized for the training dataset. To that end, we introduce the concept of <strong class="bold">gradient descent</strong>.</p>
<h3>Gradient descent </h3>
<p>From a mathematical <a id="_idIndexMarker221"/>point of view, if we simplify the MSE function with <a id="_idIndexMarker222"/>just one variable <em class="italic">w</em>, then the diagram will be something similar to <em class="italic">Figure 4.4.</em> Mathematically we can find the value <em class="italic">w*</em> that minimizes <em class="italic">f(w)</em> by using derivatives, since the derivative of <em class="italic">f(w)</em> is zero at <em class="italic">w*</em>. </p>
<p>From a computer programming point of view, we will need to use an algorithm called gradient descent to find the best point <em class="italic">w*</em>. With one variable, a gradient is the derivative of the cost function. Starting from an initial point (<em class="italic">w</em><span class="subscript">0</span>, <em class="italic">f</em><span class="subscript">0</span>), we want to find the next point at (<em class="italic">w</em><span class="subscript">1</span>, <em class="italic">f</em><span class="subscript">1</span>) where <em class="italic">f</em><span class="subscript">1 </span><em class="italic">= f(w</em><span class="subscript">1</span><em class="italic">)</em> is smaller than <em class="italic">f</em><span class="subscript">0</span><em class="italic">=f (w</em><span class="subscript">0</span><em class="italic">)</em>. Since the derivative of <em class="italic">f(w)</em> at <em class="italic">w</em><span class="subscript">0</span> is negative and we want to minimize <em class="italic">f</em>, the moving direction from <em class="italic">w</em><span class="subscript">0</span> to <em class="italic">w</em><span class="subscript">1</span> will be increasing, and the moving magnitude (also called step-size or learning rate) needs to be tweaked, such that it will neither be too small to cause many steps to reach <em class="italic">w*</em> nor be too big and cause divergence away from <em class="italic">w*</em>.</p>
<div>
<div class="IMG---Figure" id="_idContainer036">
<img alt="Figure 4.4 – Gradient descent " height="850" src="image/Figure_4.4.jpg" width="1197"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.4 – Gradient descent</p>
<p><em class="italic">Figure 4.4</em> also <a id="_idIndexMarker223"/>shows the steps for the gradient descent algorithm: moving <a id="_idIndexMarker224"/>from the initial point <em class="italic">(w</em><span class="subscript">0</span><em class="italic">, f</em><span class="subscript">0</span><em class="italic">)</em> to <em class="italic">(w</em><span class="subscript">1</span><em class="italic">, f</em><span class="subscript">1</span><em class="italic">)</em>, to <em class="italic">(w</em><span class="subscript">2</span><em class="italic">, f</em><span class="subscript">2</span><em class="italic">)</em>, till it reaches the optimized point <em class="italic">(w</em><span class="subscript">3</span><em class="italic">, f</em><span class="subscript">3</span><em class="italic">) = (w*, f*)</em>. Note that the starting point is important for non-convex cost functions where multiple minimum values existed for <em class="italic">w</em>, as shown in <em class="italic">Figure 4.5</em>. </p>
<div>
<div class="IMG---Figure" id="_idContainer037">
<img alt="Figure 4.5 – Non-convex cost functions " height="480" src="image/Figure_4.5.jpg" width="907"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.5 – Non-convex cost functions</p>
<p>The gradient descendent algorithm lets us find the minimum <em class="italic">f</em> value by repeatedly moving from <em class="italic">(w</em><span class="subscript">i</span><em class="italic">, f</em><span class="subscript">i</span><em class="italic">)</em> to <em class="italic">(w</em><span class="subscript">i</span><em class="italic">+1</em><em class="italic">, f</em><span class="subscript">i</span><em class="italic">+1</em><em class="italic">)</em>, in the direction as depicted by the gradient at the point <em class="italic">(w</em><span class="subscript">i</span><em class="italic">, f</em><span class="subscript">i</span><em class="italic">)</em>: if gradient <em class="italic">(w</em><span class="subscript">i</span><em class="italic">)</em> is negative, move toward the direction of increasing <em class="italic">w</em>; otherwise, move <a id="_idIndexMarker225"/>toward decreasing <em class="italic">w</em>. After certain moves, if we can find the <a id="_idIndexMarker226"/>minimum <em class="italic">f*</em> at point <em class="italic">(w* f*)</em>, we call the model converges at weight <em class="italic">w*</em>, and we have found the parameter <em class="italic">w*</em>. Otherwise, the model is non-convergent. After we find the converged <em class="italic">w*</em>, finding parameter <em class="italic">b*</em> is relatively easy, and we have found the best fit line: <em class="italic">f(x) = w*x + b*</em>, which can be used to predict the house price for new values of <em class="italic">x</em>.</p>
<h3>Extending to multiple features (variables)</h3>
<p>With the gradient descendent algorithm, we are able to find the best model that fits the sample dataset. We <a id="_idIndexMarker227"/>will use it to predict the sale price (target <em class="italic">y</em>) from new data. In real life, there are many features affecting a house’s sale price, such as its age, the number of bedrooms and bathrooms, and of course the house’s location. So, we need to extend our model to multiple features (variables).</p>
<p>When extending to multiple features, we use a vector <em class="italic">X=(x</em><span class="subscript">1</span><em class="italic">, x</em><span class="subscript">2</span><em class="italic">, x</em><span class="subscript">3</span><em class="italic">, …, x</em><span class="subscript">n</span><em class="italic">)</em><span class="superscript">T</span> to represent the multiple feature values <em class="italic">x</em><span class="subscript">1</span><em class="italic">, x</em><span class="subscript">2</span><em class="italic">, x</em><span class="subscript">3</span><em class="italic">, …, x</em><span class="subscript">n</span>, and the linear function will become this:</p>
<pre class="source-code">Y=WX+B</pre>
<p>where <em class="italic">W</em> is a matrix and <em class="italic">B</em> is a vector. </p>
<p>Then, the cost function can be written as follows: </p>
<pre class="source-code">F(W)=W<span class="superscript">T</span>AW/2 </pre>
<p>where <em class="italic">A</em> is a matrix constructed from the dataset.</p>
<p>Mathematically, we can find the value <em class="italic">W</em> that minimizes <em class="italic">F(W) </em>by using partial derivatives <a id="_idIndexMarker228"/>with multiple variables. Accordingly, we can also extend the gradient descendent algorithm from one dimension to multiple dimensions, to find a matrix <em class="italic">W</em> that best fits the datasets by minimizing the cost function <em class="italic">F(W)</em>.</p>
<h3>Extending to non-linear regression</h3>
<p>In previous <a id="_idIndexMarker229"/>discussions, we assumed the relationship of the sale price (target <em class="italic">y</em>) and the house square footage <em class="italic">x</em> is linear. In many real-life ML models, there always exist non-linear relationships, for example, a polynomial relationship (with one feature/variable <em class="italic">x</em> here):</p>
<pre class="source-code">y = w<span class="subscript">1</span>x + w<span class="subscript">2</span>x<span class="superscript">2</span> + w<span class="subscript">3</span>x<span class="superscript">3</span> + …. + w<span class="subscript">n</span>x<span class="superscript">n</span></pre>
<p>From linear to non-linear, the mathematical logic is the same – we need to find the model parameters <em class="italic">(w</em><span class="subscript">1</span><em class="italic">, w</em><span class="subscript">2</span><em class="italic">,... w</em><span class="subscript">n</span><em class="italic">)</em> by minimizing the cost function.</p>
<p>By extending from the linear one-variable solution to non-linear and multi-variables, the regression model solves the type of ML problems that predict continuous values. Due to the mathematical complexity of the problem, we will not discuss it further here. In the next section, we will look at another type of ML problem, <strong class="bold">classification</strong>, and we will start with the simplest case of binary classification.</p>
<h2 id="_idParaDest-100"><a id="_idTextAnchor100"/>Binary classification</h2>
<p>In the previous chapter, we also talked about another sample ML problem (<em class="italic">example 2</em>) – Zeellow Lender <a id="_idIndexMarker230"/>is trying to automate the decision process of <a id="_idIndexMarker231"/>approval or denial for new loan applications. Since the model output is <em class="italic">yes</em> or <em class="italic">no</em>, this is a binary classification problem. Another type of classification problem is multi-category classification. For example, given an image, we need to tell whether it is a dog, a cat, or a cow. </p>
<p>For classification problems, we always use the concept of <em class="italic">probability</em>. For <em class="italic">example 2</em>, the ML model will output <em class="italic">yes</em> or <em class="italic">no</em>, based on the customer’s loan default probabilities: if the default probability is higher than a threshold value, we will deny the application. For the image classification example, we will say how probable it is that the image is of a cat, a dog, or a cow. Let us start with the binary problem of <em class="italic">example 2</em>.</p>
<h3>Logistic regression</h3>
<p>From a mathematical <a id="_idIndexMarker232"/>point of view, <em class="italic">example 2</em> is a problem of finding the function (relationship) between the target (<em class="italic">yes</em>/<em class="italic">no</em>) and the application features, and the only thing we have are the sample datasets. So, how do we figure out the function? Let’s inspect a simple dataset we have with <em class="italic">example 2</em>: the loan application decisions for 10 applications for a certain time period at a certain location. The sample dataset is shown in <em class="italic">Table 4.6.</em></p>
<div>
<div class="IMG---Figure" id="_idContainer038">
<img alt="Table 4.6 – Example 2 loan dataset " height="735" src="image/Figure_4.6.jpg" width="1502"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 4.6 – Example 2 loan dataset</p>
<p>From <em class="italic">Table 4.6</em>, we can see that there are many features of an applicant that affect their loan application’s approval or denial. To simplify, we choose the applicant’s income <em class="italic">x</em> as the single feature/variable and use <em class="italic">z</em> as a linear function of <em class="italic">x</em>: </p>
<p><em class="italic">z = wx + b</em></p>
<p>Since the final output target is a yes (<em class="italic">1</em>) or no (<em class="italic">0</em>), we will need a function that maps the above <em class="italic">z</em> value <a id="_idIndexMarker233"/>to a probability <em class="italic">p</em> that has a value between <em class="italic">0</em> and <em class="italic">1</em>: the probability of approving the loan (target variable <em class="italic">y=1</em>). </p>
<p>From statistics, we have the following:</p>
<pre class="source-code">p=e<span class="superscript">z</span>/(1+e<span class="superscript">z</span>)=1/(1+e<span class="superscript">-z</span>)</pre>
<p>And this is the so-called <strong class="bold">sigmoid function</strong> <em class="italic">(Figure 4.7)</em>, which maps the probability of loan <a id="_idIndexMarker234"/>approval <em class="italic">p</em> with the value of <em class="italic">z</em>. </p>
<div>
<div class="IMG---Figure" id="_idContainer039">
<img alt="Figure 4.7 – Sigmoid function" height="431" src="image/Figure_4.7.jpg" width="626"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.7 – Sigmoid function</p>
<p>With the sigmoid function, the output transforms a real value <em class="italic">z</em> to a probability value <em class="italic">p</em>, which is between <em class="italic">0</em> and <em class="italic">1</em>. This brings in the concept of <em class="italic">logistic regression</em>, a classification algorithm used to predict the probability of a target value of yes (<em class="italic">1</em>). Simply put, logistic regression can be thought of as a linear regression with the output as the probability of target is <em class="italic">1</em>, ranging in (<em class="italic">0,1</em>).</p>
<h3>The threshold for binary classification</h3>
<p>As we see from the preceding binary classification model, logistic regression returns a probability <a id="_idIndexMarker235"/>value between <em class="italic">0</em> and <em class="italic">1</em>. To convert a probability value to a classification, we need to determine the threshold value – when the probability is above the threshold, the class is <em class="italic">1</em> (yes); otherwise, it is <em class="italic">0</em> (no). For <em class="italic">Example 2</em>, if you set the threshold as <em class="italic">0.9</em>, then you will approve the loan application when the probability is higher than 90%; otherwise, you will reject the application. But how do we define the threshold? The answer is related to the business case and a model measurement <a id="_idIndexMarker236"/>metric called a <strong class="bold">confusion matrix</strong>. We will discuss them more in the model validation section.</p>
<h3>Extending to multi-class classification</h3>
<p>We can extend <a id="_idIndexMarker237"/>binary classification problems to multi-class classification problems. There are different ways to go from binary to multi-class. Given a multi-classification model, we can decompose it into multiple binary classification problems. Please refer to the following link for more details:</p>
<p><a href="https://svivek.com/teaching/lectures/slides/multiclass/multiclass-full.pdf">https://svivek.com/teaching/lectures/slides/multiclass/multiclass-full.pdf</a></p>
<p>So far, we have discussed regression and classification problems and introduced the gradient descent algorithm. Now let’s look at some advanced algorithms.</p>
<h2 id="_idParaDest-101"><a id="_idTextAnchor101"/>Support vector machine</h2>
<p>One popular advanced ML algorithm is called <strong class="bold">support vector machine</strong>, or <strong class="bold">SVM</strong>. It is a model commonly <a id="_idIndexMarker238"/>used for classification problems. The idea <a id="_idIndexMarker239"/>of SVM is simple: the algorithm finds a line (two dimensions) or a hyperplane (three or more dimensions) that separates the data into different classes.</p>
<p>Let’s use a two-dimension separation problem to illustrate SVM. As shown in <em class="italic">Figure 4.8</em>, we are trying to find a line that separates the points into two groups: a group of circles and a group of squares. There are three lines separating the points. Out of the three lines, which one is the best choice? </p>
<div>
<div class="IMG---Figure" id="_idContainer040">
<img alt="Figure 4.8 – SVM illustration " height="439" src="image/Figure_4.8.jpg" width="751"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.8 – SVM illustration</p>
<p>Let’s take a closer <a id="_idIndexMarker240"/>look at the diagram. For each line, there are <a id="_idIndexMarker241"/>points that are closest to <a id="_idIndexMarker242"/>the line from both classes – we call these points <strong class="bold">support vectors</strong>, and we call the distance between the line and its support vectors the <strong class="bold">margin</strong>. The objective of SVM is to maximize the margin. Out of the three lines in <em class="italic">Figure 4.8</em>, you can see that line 1 is our choice since it has the greatest margin out of the three. </p>
<div>
<div class="IMG---Figure" id="_idContainer041">
<img alt="Figure 4.9 – Non-linear curve separating the data " height="420" src="image/Figure_4.9.jpg" width="647"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.9 – Non-linear curve separating the data</p>
<p>If we extend this two-dimensional problem to three dimensions, then a hyperplane for which the <a id="_idIndexMarker243"/>margin is maximum is the optimal <a id="_idIndexMarker244"/>hyperplane. Nevertheless, both are still linear models. However, in real life, the separation is often not linear. <em class="italic">Figure 4.9</em> shows an example where the separation is a circle (non-linear).</p>
<h2 id="_idParaDest-102"><a id="_idTextAnchor102"/>Decision tree and random forest</h2>
<p>For a classification ML problem with multiple features, the natural thing to think of doing would be to classify the feature values – do a binary classification at each feature. Another popular ML algorithm, the decision tree model, uses this logic to construct a decision tree, in which <a id="_idIndexMarker245"/>each internal node represents a test on a feature, each leaf <a id="_idIndexMarker246"/>node represents a class label, and the branches represent feature combinations that lead to the leaf nodes – the class labels. From root to leaf, the paths represent classification rules. Decision trees are constructed to split a dataset based on different conditions for each feature.</p>
<p>Decision tree is one of the <a id="_idIndexMarker247"/>most widely used methods for supervised learning. <em class="italic">Figure 4.10</em> illustrates a logic flow of a decision tree for <em class="italic">example 2</em> discussed earlier: the loan application decision process. The decision tree starts from the credit history:</p>
<ul>
<li>If the credit history (score) is good, it will check the applicant’s income and the loan amount – if the income is low and the loan amount is big, it will reject the application. Otherwise, the loan application will be approved.</li>
<li>If the credit history is bad, it will check the applicant’s income and loan amount – if the income is high and the loan amount is small, it will approve the application. Otherwise, the loan application will be rejected:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer042">
<img alt="Figure 4.10 – Decision tree for example 2 " height="853" src="image/Figure_4.10.jpg" width="1277"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.10 – Decision tree for example 2</p>
<p>With the decision tree model, you can predict results based on new feature data, such as a new <a id="_idIndexMarker248"/>application’s feature values. However, in a situation where the <a id="_idIndexMarker249"/>dataset size is large, then a decision tree can be complex and may lead to overfitting. To tackle the problem, we often use random forest, which consists of many decision trees. Random forest gets the predictions from <a id="_idIndexMarker250"/>these individual decision trees and does a final optimization by combining the <a id="_idIndexMarker251"/>decision tree prediction values with a voting or averaging process. Random forest is usually better than a single decision tree because it avoids overfitting using the averaging or voting mechanism.</p>
<p>In this section, we discussed various ML model training algorithms: from one-variable linear regressions <a id="_idIndexMarker252"/>to multi-variable non-linear regressions; from <a id="_idIndexMarker253"/>binary classifications to multi-class classifications; from <a id="_idIndexMarker254"/>support vector machine to decision trees and random forest. The result <a id="_idIndexMarker255"/>of ML training is a model that fits the training dataset well. Will such a model make good predictions on new production data? The answer is that we need to validate the model using the validation dataset before deploying the model to test and predict production data.</p>
<h1 id="_idParaDest-103"><a id="_idTextAnchor103"/>Validating the model </h1>
<p>After you train your model, you will need to determine whether it will perform well in predicting the target on future new data, and that is the validation process: you must validate the model performance on a labeled dataset that was not used in training – the validation dataset that was built during the dataset splitting phase.</p>
<h2 id="_idParaDest-104"><a id="_idTextAnchor104"/>Model validation</h2>
<p>Recall what we have discussed in <a href="B18333_03.xhtml#_idTextAnchor072"><em class="italic">Chapter 3</em></a>: in the ML problem framing phase, you define the business <a id="_idIndexMarker256"/>problem and craft a business metric to measure model success. Now, in this model validation phase, the model validation metric needs to be linked to that business metric as closely as possible. </p>
<p>Earlier in this chapter, we have defined the cost function, which is used to find the optimized model. The cost function is also used for ML model validation. For regression problems, the cost function (the gap between the model value and the actual value) is usually the MSE, which was discussed in the previous section. For binary classification, the cost function is usually expressed in a metric called a confusion matrix. Let’s take a closer look at the confusion matrix, as well as the impact of changing the classification threshold on the confusion matrix.</p>
<h2 id="_idParaDest-105"><a id="_idTextAnchor105"/>Confusion matrix</h2>
<p>A confusion matrix is used to <a id="_idIndexMarker257"/>measure a binary classification <a id="_idIndexMarker258"/>model’s predictions, as shown in <em class="italic">Figure 4.11.</em></p>
<div>
<div class="IMG---Figure" id="_idContainer043">
<img alt="Figure 4.11 – Confusion matrix " height="361" src="image/Figure_4.11.jpg" width="608"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.11 – Confusion matrix</p>
<p>Based on whether the model predicts the actual classes, there are four situations:</p>
<ul>
<li><strong class="bold">True Positive</strong> (<strong class="bold">TP</strong>) is where <a id="_idIndexMarker259"/>the model <em class="italic">correctly</em> predicts the <em class="italic">positive</em> class. </li>
<li><strong class="bold">True Negative</strong> (<strong class="bold">TN</strong>) is where <a id="_idIndexMarker260"/>the model <em class="italic">correctly</em> predicts the <em class="italic">negative</em> class.</li>
<li><strong class="bold">False Positive</strong> (<strong class="bold">FP</strong>) is where <a id="_idIndexMarker261"/>the model <em class="italic">incorrectly</em> predicts the <em class="italic">positive</em> class. </li>
<li><strong class="bold">False Negative</strong> (<strong class="bold">FN</strong>) is <a id="_idIndexMarker262"/>where the model <em class="italic">incorrectly</em> predicts the <em class="italic">negative</em> class. </li>
</ul>
<p>Let’s look at a computer vision ML problem: you trained two models for image recognition – to <a id="_idIndexMarker263"/>classify an image as being of a cat or not. You have run the <a id="_idIndexMarker264"/>two models on the validation dataset and compared the results with the labels, and <em class="italic">Figure 4.12</em> shows the confusion matrices for the two ML models. How do we measure which model performs better?</p>
<div>
<div class="IMG---Figure" id="_idContainer044">
<img alt="Figure 4.12 – Confusion matrices for two ML models " height="340" src="image/Figure_4.12.jpg" width="1195"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.12 – Confusion matrices for two ML models</p>
<p>To help us <a id="_idIndexMarker265"/>compare the classification model performances, we <a id="_idIndexMarker266"/>need to define more metrics:</p>
<ul>
<li><strong class="source-inline">Recall</strong> (<strong class="source-inline">sensitivity</strong>) measures the proportion of actual positives that were identified correctly:<p class="source-code">Recall =TP/(TP+FN)</p></li>
<li><strong class="source-inline">Specificity</strong> measures the proportion of actual negatives that were identified correctly:<p class="source-code">Specificity =TN/(FP+TN)</p></li>
</ul>
<p>Applying the preceding metrics to the two models, we have come up with the following table:</p>
<div>
<div class="IMG---Figure" id="_idContainer045">
<img alt="Table 4.13 – Recall and specificity for two ML models " height="245" src="image/Figure_4.13.jpg" width="1304"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 4.13 – Recall and specificity for two ML models</p>
<p>Depending on the business goal, these two models’ performance can be measured and interpreted <a id="_idIndexMarker267"/>from different points of view. If the goal is to identify as <a id="_idIndexMarker268"/>many cats as possible and the amount of false positives does not matter, then model two is better performed since it has a high recall metric. However, if your goal is to identify the not-cats, then model one may be a better choice since it has a high specificity metric.</p>
<p>You can use more metrics to help with your decision making. Next, we introduce the concepts of the receiver operating characteristic curve and the area under the curve.</p>
<h2 id="_idParaDest-106"><a id="_idTextAnchor106"/>ROC curve and AUC</h2>
<p>In previous <a id="_idIndexMarker269"/>chapters, we discussed the cutoff for converting a probability into <a id="_idIndexMarker270"/>a class. The threshold will impact the confusion matrix. </p>
<p>An <strong class="bold">Receiver Operating Characteristic</strong> (<strong class="bold">ROC</strong>) curve is <a id="_idIndexMarker271"/>a graph <a id="_idIndexMarker272"/>showing the <strong class="bold">True Positive Rate</strong> (<strong class="bold">TPR</strong>) and <strong class="bold">False Positive Rate</strong> (<strong class="bold">FPR</strong>), as two dimensions, under all threshold <a id="_idIndexMarker273"/>values.</p>
<p>The TPR is a synonym for recall and is therefore defined as follows:</p>
<pre class="source-code">TPR =TP/(TP+FN) (Of all the positive cases, the proportion of cases identified as positive)</pre>
<p>The FPR is defined as follows:</p>
<pre class="source-code">FPR =FP/(FP+TN) (Of all the native cases, the proportion of cases identified as positive)</pre>
<div>
<div class="IMG---Figure" id="_idContainer046">
<img alt="Figure 4.14 – ROC curves " height="742" src="image/Figure_4.14.jpg" width="931"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.14 – ROC curves</p>
<p>To build an ROC curve, you calculate the TPR (or recall) against the FPR for each threshold and <a id="_idIndexMarker274"/>plot it on a graph. <em class="italic">Figure 4.14 </em>shows a sample ROC. If we take a <a id="_idIndexMarker275"/>close look at the graph, we will see that the point at (<em class="italic">0,0</em>) represents zero true positives and zero false positives. The point at (<em class="italic">1,1</em>) means that all the positives are correctly identified but all the negatives also incorrectly <a id="_idIndexMarker276"/>identified. The dotted line from (<em class="italic">0,0</em>) to (<em class="italic">1,1</em>), called a <strong class="bold">random classifier</strong>, represents <em class="italic">TPR=FPR</em>. In the diagram, the ideal line is the <em class="italic">perfect classifier</em>, which represents <em class="italic">TPR=1</em> with no <em class="italic">false positives</em>:</p>
<div>
<div class="IMG---Figure" id="_idContainer047">
<img alt="Figure 4.15 – AUC: the area under the curve" height="543" src="image/Figure_4.15.jpg" width="647"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.15 – AUC: the area under the curve</p>
<p>Since the goal for <a id="_idIndexMarker277"/>a classification problem is a model that has a high <a id="_idIndexMarker278"/>TPR and a low FPR – as close as possible to the <em class="italic">perfect classifier</em> – we often use the <strong class="bold">Area Under the Curve</strong> (<strong class="bold">AUC</strong>)-ROC as a measurement of classification model performance: the greater the AUC-ROC, the better. A sample AUC-ROC is shown in <em class="italic">Figure 4.15</em>.</p>
<h2 id="_idParaDest-107"><a id="_idTextAnchor107"/>More classification metrics</h2>
<p>As you can see, with <a id="_idIndexMarker279"/>the four numbers from the confusion matrix, you can calculate a model’s recall and specificity, and here we introduce accuracy, precision, and F1-score:</p>
<ul>
<li><strong class="source-inline">Accuracy</strong> measures the proportion of correct predictions among the total number of cases:<p class="source-code">Accuracy=(TP+TN)/(TP+TN+FP+FN)</p></li>
<li><strong class="source-inline">Precision</strong> measures the proportion of positive identifications that are actually correct:<p class="source-code">Precision=TP/(TP+FP)</p></li>
<li><strong class="source-inline">F1-score</strong> combines precision and sensitivity and measures the overall performance:<p class="source-code">F1-score =2 X Precision X Recall/(Precision + Recall)</p></li>
</ul>
<p>So far, we have introduced many classification metrics – which one should you choose? It really depends on the business context and goals. For a classification model that identifies emails as spam or not spam, while precision is good to identify the spam, you also want to avoid <a id="_idIndexMarker280"/>labeling a legitimate email as spam. For a classification model that identifies whether a patient has a terminal illness or not, it is vitally important to identify the illness for a patient who actually has that illness. In this situation, sensitivity is a better metric than precision to use.</p>
<p>The F1 score combines precision and recall to give you one number that quantifies the overall performance. You might want to use the F1 score when you have a class imbalance but you want to preserve the equality between precision and sensitivity.</p>
<h1 id="_idParaDest-108"><a id="_idTextAnchor108"/>Tuning the model</h1>
<p>During the model validation process, we evaluate the model performances, and there are situations where the model does not fit the validation dataset. Let’s examine the different cases.</p>
<h2 id="_idParaDest-109"><a id="_idTextAnchor109"/>Overfitting and underfitting</h2>
<p>While underfitting describes the situation where prediction error is not minimized, overfitting is the case <a id="_idIndexMarker281"/>where the model fits the training dataset very well but does <a id="_idIndexMarker282"/>not fit the validation dataset. An overfitting model gets a very low cost function value during training but poorly predicts on new data. <em class="italic">Figure 4.16</em> depicts the situations for underfitting, robust, and overfitting.</p>
<div>
<div class="IMG---Figure" id="_idContainer048">
<img alt="Figure 4.16 – Model fittings " height="360" src="image/Figure_4.16.jpg" width="1106"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.16 – Model fittings</p>
<p>When we try to minimize the cost function and avoid underfitting, we need to make sure our model is <a id="_idIndexMarker283"/>generalized and not prone to overfitting. From our ML practice, we <a id="_idIndexMarker284"/>know that overfitting is often caused by making a model more complex than necessary. As you can see in <em class="italic">Figure 4.16</em>, overfitting makes a training model memorize data. The ML’s fundamental principle is making the model fit well on the data without losing generality. To avoid overfitting, we introduce regularization to decrease model complexity.</p>
<h2 id="_idParaDest-110"><a id="_idTextAnchor110"/>Regularization</h2>
<p>To avoid overfitting, we <a id="_idIndexMarker285"/>need to reduce model complexity. Model complexity can be thought of in two ways:</p>
<ul>
<li>Model complexity as a function of the <em class="italic">total number of features</em> with nonzero weights</li>
<li>Model complexity as a function of the <em class="italic">weights</em> of all the features in the model</li>
</ul>
<p>The idea of regularization is introduced to add a factor to penalize the model complexity and enhance model generalization. Corresponding to the preceding two complexities, we have two kinds of regularization/generalization:</p>
<ul>
<li>Quantify complexity with the <em class="italic">L2 regularization</em> formula, which defines the regularization term as the sum of the squares of all the feature weights – weights close to zero have little effect on model complexity, while outlier weights can have a huge impact. <em class="italic">Ridge regression</em> uses L2 regularization: the cost function is altered by adding a penalty equivalent to the square of the weights. Let <em class="italic">p</em> be the number of features, and the coefficient (weight) of the <em class="italic">i</em>th feature is <em class="italic">w</em><span class="subscript">i</span>; then, the cost function is written as follows:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer049">
<img alt="" height="133" src="image/B18333_04_004.jpg" width="532"/>
</div>
</div>
<ul>
<li>Quantify complexity with the <em class="italic">L1 regularization</em> formula, which defines the regularization term as the sum of the absolute of all the feature weights – weights close to zero <a id="_idIndexMarker286"/>have a large effect on model complexity, while outlier weights have less impact. Lasso regression uses L1 regularization: the cost function is altered by adding a penalty equivalent to the absolute of the weights:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer050">
<img alt="" height="132" src="image/B18333_04_005.jpg" width="546"/>
</div>
</div>
<p>How should you choose the parameter lambda for the preceding formulas? If the lambda value is too high, the model will be simple and carry a risk of underfitting the data. If the lambda value is too low, the model will be more complex, with the risk of overfitting your data and leading to generalization issues with new data. The ideal value of lambda produces a model that fits the training data and generalizes well to new data. One objective of model tuning is to balance the model complexity and generalization.</p>
<p>Other than regularization, we can use early stopping to avoid overfitting. Early stopping is a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. This means ending the training when the training results are good enough, and before the model fully reaches convergence. </p>
<h2 id="_idParaDest-111"><a id="_idTextAnchor111"/>Hyperparameter tuning</h2>
<p>Hyperparameter <a id="_idIndexMarker287"/>tuning is the process of finding the best <a id="_idIndexMarker288"/>version of a model by running many training jobs on your dataset. It uses the algorithm and ranges of hyperparameters that you specify, then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. </p>
<p>There are two basic types of hyperparameters. The first kind is model hyperparameters. They are directly linked to <a id="_idIndexMarker289"/>the model that is selected and thus have a direct impact on the performance of that model. They help define the model itself, for example, the number of layers in a neural network model and the activation functions that are used.</p>
<p>The second kind is algorithm hyperparameters. They do not affect the performance of the algorithm directly but <a id="_idIndexMarker290"/>affect the efficiency and the rate of model training. For example, the learning rate for a gradient descent algorithm may affect how quickly an ML model converges. </p>
<p>The process of tuning hyperparameters involves changing the hyperparameter values and attempting to find <a id="_idIndexMarker291"/>those that yield the best results. The common <a id="_idIndexMarker292"/>hyperparameters that are often tuned include the following:</p>
<ul>
<li><strong class="bold">The batch size</strong>: The number of samples that are processed during training, before the model is updated</li>
<li><strong class="bold">The number of training epochs</strong>: The number of times that we run through the full set of training data during model training</li>
<li><strong class="bold">The learning rate</strong>: The distance we travel when trying to find the optimal value for a parameter</li>
</ul>
<p>Through the ML model training, validation, and hyperparameter tuning, we have come up with a model that can be deployed for testing. </p>
<h1 id="_idParaDest-112"><a id="_idTextAnchor112"/>Testing and deploying the model </h1>
<p>To test and get <a id="_idIndexMarker293"/>performance metrics from your model, you must make <a id="_idIndexMarker294"/>inferences or predictions from the model—which typically requires deployment. The goal of the deployment phase is to provide a managed environment to host models for inference both securely and with low latency. You can deploy your model in one of two ways:</p>
<ul>
<li><strong class="bold">Single predictions</strong>: Deploy your model online with a permanent endpoint. For example, we can deploy the housing model (price prediction) with an online endpoint.</li>
<li><strong class="bold">Batch transform</strong>: Spin up your model and perform the predictions for the entire dataset that you provide. For example, with a <strong class="source-inline">.csv</strong> file or multiple sets of records to be sent at a time, the model will return a batch of predictions.</li>
</ul>
<p>After deploying a model into testing, you evaluate the model to see whether it meets the performance requirements and the business requirements, which is the ultimate goal for any ML <a id="_idIndexMarker295"/>problem. All the stakeholders will need to evaluate the ML solution’s benefits <a id="_idIndexMarker296"/>and approve the model’s deployment to production. Keep in mind that the most accurate model may not be the best solution to an ML problem.</p>
<p>After all the stakeholders approve the model, we then deploy the model to production. Otherwise, we need to go back to the process of model training, validation and tuning, re-testing, and re-evaluation.</p>
<p>After deploying a model to production, you still need to monitor the production data, since new data accumulates over time, and alternative or new outcomes can potentially be identified. Therefore, deploying a model is a continuous process, not a one-time exercise.</p>
<h1 id="_idParaDest-113"><a id="_idTextAnchor113"/>Practicing model development with scikit-learn </h1>
<p>Scikit-learn is one <a id="_idIndexMarker297"/>of the most useful libraries for ML in Python. The scikit-learn <a id="_idIndexMarker298"/>library contains a lot <a id="_idIndexMarker299"/>of tools for ML, including ones for classification and regression. </p>
<p>In <a href="B18333_13.xhtml#_idTextAnchor209"><em class="italic">Appendix 3</em></a> of the book, we have provided a step-by-step practice exercise for using scikit-learn to develop ML models. Practicing these steps is essential to master scikit-learn skills. Please refer to <a href="B18333_13.xhtml#_idTextAnchor209"><em class="italic">Appendix 3</em></a>, <em class="italic">Practicing with Scikit-Learn</em>, to learn and practice with examples of ML model training, validation, and testing using scikit-learn.</p>
<h1 id="_idParaDest-114"><a id="_idTextAnchor114"/>Summary</h1>
<p>In this chapter, we have discussed the basic concepts of the ML model development process: data splitting, platform setup, ML model training, validation, testing, and deployment. </p>
<p>Since the concept of AI emerged in the 1950s, there were no big breakthroughs until 2012, when <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>) was invented using neural networks. DL has greatly improved ML model performance and opened up a huge avenue for applying ML to many business use cases. In the next chapter, we will discuss neural networks and DL.</p>
<h1 id="_idParaDest-115"><a id="_idTextAnchor115"/>Further reading</h1>
<p>For further insights into the topics of the chapter, you can refer to the following:</p>
<ul>
<li><a href="https://scikit-learn.org/stable/tutorial/basic/tutorial.xhtml">https://scikit-learn.org/stable/tutorial/basic/tutorial.xhtml</a></li>
<li><a href="https://scikit-learn.org/stable/tutorial/index.xhtml">https://scikit-learn.org/stable/tutorial/index.xhtml</a></li>
<li><a href="B18333_13.xhtml#_idTextAnchor209"><em class="italic">Appendix 3</em></a><em class="italic">, Practicing with ScikitLearn</em></li>
</ul>
</div>
<div>
<div id="_idContainer052">
</div>
</div>
</div>
</body></html>