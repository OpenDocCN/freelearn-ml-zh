- en: '*Chapter 2*: Architectures for Streaming and Real-Time Machine Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Streaming architectures are an essential component of solutions for real-time
    machine learning and streaming analytics. Even if you have a model or other analytics
    tools that can treat data in real time, update, and respond straight away, this
    will be of no use if there is no architecture to support your solution.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: The first important consideration is making sure that your models and analytics
    can function on each data point; there needs to be an update function and/or a
    predict function that can update the solution on each new observation being received
    by the system.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important consideration for real-time and streaming architectures is
    data ingress: how to make sure that data can be received on an observation per
    observation basis, rather than the more traditional batch approach with daily
    database updates, for example.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Besides that, it will be important that you understand how to make different
    software systems communicate. For example, data has to flow very fast from your
    data generating process, maybe go through a data storage solution, a data quality
    tool, or a security layer, and then be received by your analytics program. The
    analytics program will do its work and send the result back to the source, or
    maybe forward the treated data points to a visualization solution, an alerting
    system, or similar.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will get an introduction to architectures for streaming
    and real-time machine learning. The central focus of this book will remain on
    the analytics and machine learning part of the pipeline. The goal of this chapter
    is to give you enough elements to imagine and implement rough working architectures,
    while some of the highly-specialized parts on performance, availability, and security
    will be left out.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Defining your analytics as a function
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Understanding microservices architecture
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Communicating between services through APIs
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Demystifying the HTTP protocol
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building a simple API on AWS
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Big data tools for real-time streaming
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calling a big data environment in real time
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can find all the code for this book on GitHub at the following link: [https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python](https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python).
    If you are not yet familiar with Git and GitHub, the easiest way to download the
    notebooks and code samples is the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Go to the link of the repository.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the green **Code** button.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Download ZIP**.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you download the ZIP file, you unzip it in your local environment, and
    you will be able to access the code through your preferred Python editor.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Python environment
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To follow along with this book, you can download the code in the repository
    and execute it using your preferred Python editor.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: If you are not yet familiar with Python environments, I would advise you to
    check out Anaconda ([https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)),
    which comes with the Jupyter Notebook and JupyterLab, which are both great for
    executing notebooks. It also comes with Spyder and VSCode for editing scripts
    and programs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: If you have difficulty installing Python or the associated programs on your
    machine, you can check out Google Colab ([https://colab.research.google.com/](https://colab.research.google.com/))
    or Kaggle Notebooks ([https://www.kaggle.com/code](https://www.kaggle.com/code)),
    which both allow you to run Python code in online notebooks for free, without
    any setup to do.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: The code in the book will generally use Colab and Kaggle Notebooks with Python
    version 3.7.13, and you can set up your own environment to mimic this.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Defining your analytics as a function
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to get started with architecture, let's build an idea from the ground
    up using the different building blocks that are necessary to make this a minimal
    working product.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: The first thing that you need to have for this is an understanding of the type
    of real-time analytics that you want to execute.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, let''s go with the same example as in the previous chapter: a real-time
    business rule that prints an alert when the temperature or acidity of our production
    line is out of the acceptable limits.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous chapter, this alert was coded as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Code block 2-1
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the previous chapter, you used an iteration over a DataFrame to test out
    this code. In reality, you will always need an idea of architecture so that you
    can make your code actually receive data in real time from a data generating process.
    This building block will be covered in this chapter.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following schematic drawing, you see a high-level architectural schema
    for our streaming solution:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – A high-level architectural schema for a streaming solution'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_02_01.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – A high-level architectural schema for a streaming solution
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: In this schematic drawing, you clearly see that writing code will give you some
    of the key components of your solution. However, you need to build an architecture
    around this to make the solution come to life. The darker pieces are still missing
    from the example implementation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: While the goal of this book is not to give a full in-depth course on architecture,
    you will discover some tools and building blocks here that will allow you to deliver
    an MVP real-time use case. To get your building blocks cleanly organized, you
    will need to choose an architectural structure for your solutions. Microservices
    are an architectural pattern that will allow you to build clean, small building
    blocks and have them communicate with each other.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Understanding microservices architecture
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concept of **microservices** is important to understand when working on
    architectures. Although there are other ways to architecture software projects,
    microservices are quite popular for a good reason. They help teams be flexible
    and effective, and help to keep software flexible and clearly structured.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理架构时理解**微服务**的概念非常重要。尽管有其他方法来架构软件项目，但微服务因其良好的原因而非常受欢迎。它们帮助团队保持灵活和高效，并有助于保持软件的灵活性和清晰结构。
- en: 'The idea behind microservices is in the name: software is represented as many
    small services that operate individually. When looking at the overall architecture,
    each of the microservices is inside a small, *black box* with clearly defined
    inputs and outputs. Processes are put in place to call the right black box at
    the right time.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务的理念体现在其名称中：软件被表示为许多独立操作的小服务。在查看整体架构时，每个微服务都在一个小小的、*黑盒*中，具有明确定义的输入和输出。会放置一些流程来在正确的时间调用正确的黑盒。
- en: Microservice architecture is loosely coupled. This means that there is no fixed
    communication between the different microservices. Instead, each microservice
    can be called, or not called, by any other services or code.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构是松散耦合的。这意味着不同微服务之间没有固定的通信。相反，每个微服务可以被任何其他服务或代码调用，也可以不被调用。
- en: If a change needs to be made to one of the microservices, the scope of the change
    is fairly local, thereby not affecting other microservices. As input and output
    are predefined, this also helps in keeping the foundational structure of the program
    in order, without it being fixed in any way.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要对某个微服务进行更改，更改的范围相对局部，因此不会影响其他微服务。由于输入和输出是预定义的，这也帮助保持程序的基础结构有序，而不会以任何方式固定。
- en: To allow different microservices to communicate, an often-chosen solution is
    to use **Application Programming Interfaces** (**APIs**). Let's deep dive into
    those now.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了允许不同的微服务进行通信，一个常用的解决方案是使用**应用程序编程接口**（**API**）。现在让我们深入了解这些内容。
- en: Communicating between services through APIs
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过API在服务之间进行通信
- en: A central component in microservice architectures is the use of APIs. An API
    is a part that allows you to connect two microservices (or other pieces of code)
    together.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构中的一个重要组成部分是API的使用。API是一个允许您将两个微服务（或其他代码片段）连接起来的部分。
- en: APIs are much like websites. Just like a website, an API is built behind a website-like
    link or an IP address. When you go to a website, the server of the website sends
    you the code that represents the website. Your internet browser then interprets
    this code and shows you a web page.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: API与网站非常相似。就像网站一样，API是在类似网站的链接或IP地址后面构建的。当您访问一个网站时，网站的服务器会向您发送代表网站的代码。然后您的互联网浏览器解释此代码并显示网页。
- en: When you call an API, the API will receive your request. The request triggers
    your code to be run on the server and generates a response that is sent back to
    you. If something goes wrong (maybe your request was not as expected or an error
    occurs), you may not receive any response, or receive an error code such as `request
    not authorized` or `internal server error`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当您调用API时，API将接收您的请求。请求触发服务器上您的代码运行，并生成一个发送回您的响应。如果出现问题（可能是您的请求不符合预期或发生错误），您可能不会收到任何响应，或者收到如“请求未授权”或“内部服务器错误”之类的错误代码。
- en: 'The following figure shows a flow chart that covers this. A computer or user
    sends an HTTP request, and the API server sends back the response according to
    the code that runs on the API server:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图显示了涵盖此内容的流程图。计算机或用户发送HTTP请求，API服务器根据在API服务器上运行的代码发送响应：
- en: '![Figure 2.2 – A high-level architectural schema for a streaming solution'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.2 – 流式解决方案的高级架构图'
- en: '](img/B18335_02_02.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18335_02_02.jpg)'
- en: Figure 2.2 – A high-level architectural schema for a streaming solution
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 流式解决方案的高级架构图
- en: You can call APIs with a lot of different tools. Sometimes, you can even use
    your internet browser, otherwise, tools such as cURL do the job on the command
    line. You can use tools such as Postman or Insomnia for calling APIs with a user
    interface. All the communication is covered in fixed rules and practices, which,
    together, are called the HTTP protocol, which we will explore in the next section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用许多不同的工具调用API。有时，您甚至可以使用您的互联网浏览器，否则，像cURL这样的工具可以在命令行上完成这项工作。您可以使用Postman或Insomnia等工具通过用户界面调用API。所有通信都遵循固定的规则和实践，这些规则和实践共同构成了HTTP协议，我们将在下一节中探讨。
- en: Demystifying the HTTP protocol
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 揭秘HTTP协议
- en: Interaction between services (or websites) uses the HTTP protocol. When working
    with APIs and building communicating microservices, it is important to understand
    the basics of the HTTP protocol.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: The most important thing to know is how to send and format requests and responses.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: The GET request
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The simplest HTTP request is the `GET` request. You use this when you need to
    get something from a server or a service. For example, when going to a website,
    your browser sends a `GET` request to the website's IP address to obtain the website's
    layout code.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'A `GET` request can simply be sent from Python using the following code:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Code block 2-2
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This code uses the `requests` library in Python to send a `GET` request to the
    Google home page. This is technically the same process as going to your internet
    browser and going to the Google home page. You'll obtain all the code that is
    needed for your web browser to show you the Google home page. Although many of
    you are very familiar with the look of the Google home page in your browser, it
    is much less recognizable in this code response. It is important to understand
    that it is actually exactly the same thing, just in a different format.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: The POST request
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `POST` request is another request that you'll encounter very often. It allows
    you to send some data with your request. This is often necessary, especially in
    analytics APIs, as the analytics are likely to happen on this data. By adding
    the data in the body of the `POST` request, you make sure that your analytics
    code received your data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'The syntax in Python will be something like the following code block. For now,
    this code doesn''t work as you have not built a server that is able to do something
    with this data. However, just keep in mind that the `POST` request allows you
    to send your data point to an API with the goal of obtaining a response:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Code block 2-3
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: JSON format for communication between systems
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most common format for interaction between services is the **JavaScript
    Object Notation** (**JSON**) format. It is a data type that very strongly resembles
    the dictionary format in Python. In effect, it is a key-value object that is surrounded
    by accolades.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of a JSON payload is as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Code block 2-4
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This data format is fairly easy to understand and very commonly used. It is,
    therefore, important to understand how it works. You'll see its use later on in
    the chapter as well.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: RESTful APIs
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While API development is out of scope for this book, it will be useful to have
    some pointers and best practices. The most used API structure is the **Representational
    State Transfer** (**REST**) API.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: The REST API works just like other APIs, but it follows a certain set of style
    rules that make it recognizable as a REST API, also called the RESTful API.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 'There are six guiding constraints in REST APIs:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Client-server architecture
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statelessness
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cacheability
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Layered system
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code on demand (optional)
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uniform interface
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you want to go further on this, some further reading resources are provided
    at the end of the chapter. Now that we have learned about the HTTP protocol, let's
    build an API on **Amazon Web Services** (**AWS**).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在这个主题上更进一步，本章末尾提供了一些额外的阅读资源。现在我们已经了解了 HTTP 协议，让我们在 **Amazon Web Services**（**AWS**）上构建一个
    API。
- en: Building a simple API on AWS
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 AWS 上构建简单的 API
- en: In order to do something practical, let's build a super simple API on AWS. This
    will allow you to understand how different services can communicate together.
    It can also serve as a good testing environment for putting the examples in the
    rest of the book to the test.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做一些实际的事情，让我们在 AWS 上构建一个非常简单的 API。这将帮助你理解不同的服务如何相互通信。它也可以作为测试本书中其他示例的良好测试环境。
- en: You will use the following components of the AWS framework.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用 AWS 框架的以下组件。
- en: API Gateway in AWS
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS 中的 API Gateway
- en: This is an AWS service that handles API requests for you. You specify the type
    of request that you expect to receive, and you specify the action that should
    be taken upon reception of a request. When building an API using API Gateway,
    this will automatically generate an IP address or link to which you can send your
    API requests.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个为你处理 API 请求的 AWS 服务。你指定你期望接收的请求类型，并指定在接收到请求时应采取的操作。当你使用 API Gateway 构建API时，这将自动生成一个IP地址或链接，你可以将你的API请求发送到那里。
- en: Lambda in AWS
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS 中的 Lambda
- en: Lambda is a serverless execution environment for code. This means that you can
    write Python code, plug it to the API Gateway, and not think about how to set
    up servers, firewalls, and all that. This is great for decoupling systems, and
    it is fast enough for many real-time systems.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 是一个无服务器代码执行环境。这意味着你可以编写 Python 代码，将其连接到 API Gateway，而无需考虑如何设置服务器、防火墙等。这对于解耦系统来说很棒，而且对于许多实时系统来说足够快。
- en: Data-generating process on a local machine
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本地机器上的数据生成过程
- en: As the last component, you will build a separate data-generating process in
    Python. You can execute this code in a notebook. Every time a new data point is
    generated, the code will call the API with the analytics service and reply with
    an alert if needed.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一个组件，你将在 Python 中构建一个独立的数据生成过程。你可以在笔记本中执行此代码。每次生成新的数据点时，代码将调用 API 并与分析服务通信，如果需要，则发送警报。
- en: 'A schematic overview of this architecture can be seen in the following figure:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了该架构的概览：
- en: '![Figure 2.3 – Detailed architecture schema for AWS'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.3 – AWS 的详细架构图'
- en: '](img/B18335_02_03.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18335_02_03.jpg)'
- en: Figure 2.3 – Detailed architecture schema for AWS
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – AWS 的详细架构图
- en: Implementing the example
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现示例
- en: In order to implement the example, we will use the following step-by-step instructions.
    If you have an AWS account, you can skip *Step 0*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现示例，我们将使用以下分步说明。如果你已经有了 AWS 账户，你可以跳过 *步骤 0*。
- en: Step 0 – Creating an account on AWS
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 0 – 在 AWS 上创建账户
- en: If you do not yet have an account on AWS, it is easy to create one. You will
    have to set it up with a credit card, but the services that we will use here all
    have a free tier. As long as you shut down the resources at the end of your test,
    you are unlikely to incur any fees. However, be careful, because mistakes happen,
    and if you use a lot of resources on AWS, you will end up paying.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有 AWS 账户，创建一个账户很容易。你需要用信用卡设置它，但我们在这里使用的所有服务都有免费层。只要你测试结束后关闭资源，你不太可能产生任何费用。然而，要小心，因为错误是会发生的，如果你在
    AWS 上使用大量资源，你最终可能会付费。
- en: To set up an account, you can simply follow the steps on [aws.amazon.com](http://aws.amazon.com).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置账户，你可以简单地遵循 [aws.amazon.com](http://aws.amazon.com) 上的步骤。
- en: Step 1 – Setting up a Lambda function
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 1 – 设置 Lambda 函数
- en: Upon receipt of the `POST` request, a Lambda function has to be called to execute
    our alert and send back the response.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在接收到 `POST` 请求后，必须调用 Lambda 函数来执行我们的警报并发送响应。
- en: 'Go to **Lambda** in the **Services** menu and click on **Create function**.
    You will see the following screen:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **服务** 菜单中选择 **Lambda** 并点击 **创建函数**。你将看到以下屏幕：
- en: '![Figure 2.4 – Creating a Lambda function'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.4 – 创建 Lambda 函数'
- en: '](img/B18335_02_04.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18335_02_04.jpg)'
- en: Figure 2.4 – Creating a Lambda function
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – 创建 Lambda 函数
- en: Make sure to select **Python** and to give the appropriate name to your function.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 确保选择 **Python** 并给你的函数起一个合适的名字。
- en: 'When you have finished creating the function, it is time to code it. You can
    use the following code for this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成函数的创建后，就是时候编写代码了。你可以使用以下代码：
- en: Code block 2-5
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块 2-5
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This code has two functions. The `super_simple_alert` function takes a `datapoint`
    and returns an answer (an alarm in string format). The `lambda_handler` function
    is the code that deals with the incoming API calls. The event contains the `datapoint`,
    so the event is passed to the `super_simple_alert` function in order to analyze
    whether an alert should be launched. This is stored in the `answer` variable.
    Finally, the `lambda_handler` function returns a Python dictionary with the status
    code `200` and a body that contains the answer.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'The window should now look as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – The Lambda function window'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_02_05.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.5 – The Lambda function window
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Set up API Gateway
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As a first step, let's set up API Gateway to receive a `POST` request. The `POST`
    request will contain a body in which there is JSON that has a value for temperature
    and pH, just like in the alerting example.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up API Gateway, you have to go to the **API Gateway** menu, which is
    accessible through the **Services** menu. The **Management** console looks as
    follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – The AWS Management console'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_02_06.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.6 – The AWS Management console
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: 'You should end up on the **API Gateway** menu, which looks as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – The API Gateway menu'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_02_07.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.7 – The API Gateway menu
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: When you are in the **API Gateway** menu, you can go to **Create API** to set
    up your first API.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside **Create API**, do the following steps:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Select **REST API**.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the **REST** protocol.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the API as a new API.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an API name, for example, `streamingAPI`.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will obtain an empty API configuration menu, as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Adding a method in API Gateway'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_02_08.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.8 – Adding a method in API Gateway
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to add a `POST` method, so go to `POST` method. The following menu
    will appear for setting up the `POST` method:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – The POST setup'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_02_09.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.9 – The POST setup
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Deploy the API
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Still in the API Gateway menu, click on `test` to deploy to. You can use the
    default setup for this stage, but it is important to take the URL that is on top
    here to be able to call your API from your data generation process. You will need
    to set the settings as shown in the following screenshot:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – More details for the API'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_02_010.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 – More details for the API
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – Calling your API from another Python environment
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, you can call your API from another Python environment, such as a notebook
    on your own computer, or from a Google Colab notebook.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following code to do that:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Code block 2-6
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'You will obtain the following answer:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Code block 2-7
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Now, you can imagine how a real-time data-generating process would simply call
    the API at each new data point and alerts would be generated right away!
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: More architectural considerations
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although this is a great first try at building an API, you should be aware that
    there is much more to think about when you want to build this in a reliable and
    secure way. There is a reason that data science and software engineering are different
    jobs, and it takes time to learn all the skills necessary to manage an API from
    A to Z. In general, this will not be asked of a data scientist.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the things that were not covered in this example are as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'Performance: scaling, load balancing, and latency'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DDoS attacks
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security and hacking
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Financial aspects of API invocation
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dependency on a cloud provider versus being cloud provider agnostic
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of the chapter, there are some resources for further reading, which
    you can check out.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Other AWS services and other services in general that have the same functionality
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The current example used API Gateway and a Lambda function to build an API.
    The advantages of this method are the easiness of access and setup, which makes
    it great as a method to present in this book. However, you should be aware that
    there are many other tools and technologies for building APIs.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: AWS is one of the most used cloud providers, and most things that can be done
    on AWS can be done on the other cloud providers' platforms as well. Examples of
    other big players are Google's GCP and Microsoft's Azure. Even on AWS, there are
    many alternatives.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: You can also build APIs in local environments. When doing this, you'll again
    have a large choice of tools and providers. Now that you have seen how to build
    an API using standard programming in Python and using a microservices approach,
    you will next see some alternatives using the big data environment. Big data environments
    generally have a steeper learning curve and may often be made for a specific use
    case, but they can be very powerful and absolutely necessary when working with
    high volume and velocity.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Big data tools for real time streaming
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many big data tools that do real-time streaming analytics. They can
    be great alternatives for *regular* real-time systems, especially when volumes
    are large and high speeds are required.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'As a reminder, the term **big data** is generally used to regroup tools that
    solve problems that are too complex to fit in memory The problems solved have
    three core characteristics: volume, variety, and velocity.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Big data tools are generally known for doing a lot of work in parallel computing.
    When writing non-optimized, regular Python code, the code will often pass data
    points one by one. Big data solutions solve this by treating data points in parallel
    on multiple servers. This approach makes big data tools faster whenever there
    is a lot of data, but slower when there is little data (due to the overhead of
    managing the different workers).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Big data tools are often relatively specific; they should only be used for use
    cases that have vast amounts of data. It does not make sense to start working
    on big data tools for every problem at hand.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'Numerous such solutions are made for working with streaming data. Let''s have
    a look at some commonly used tools:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为处理流式数据，已经制作了许多此类解决方案。让我们看看一些常用的工具：
- en: '**Spark Streaming**: Spark Streaming is an addition to Spark, one of the main
    tools for big data nowadays. Spark Streaming can be plugged into sources such
    as Kafka, Flume, and Amazon Kinesis, thereby making streaming data accessible
    in a Spark environment.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark Streaming**：Spark Streaming 是 Spark 的一个补充，Spark 是当今大数据的主要工具之一。Spark
    Streaming 可以连接到 Kafka、Flume 和 Amazon Kinesis 等源，从而使得流式数据在 Spark 环境中变得可访问。'
- en: '**Apache Kafka**: Kafka is an open source tool managed by Apache. It is a framework
    that is made for delivering real-time data feeds. It is used by many companies
    to deliver data pipelines and streaming analytics. Even some cloud providers have
    integrated Kafka into their solutions.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Kafka**：Kafka 是 Apache 管理的开源工具。它是一个用于提供实时数据流的框架。许多公司使用 Kafka 来提供数据管道和流式分析。甚至一些云服务提供商已经将
    Kafka 集成到他们的解决方案中。'
- en: '**Apache Flume**: Apache Flume is another open source tool managed by Apache,
    which also focuses on streaming data. Flume is specifically used for treating
    large amounts of log data in a big data environment.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Flume**：Apache Flume 是 Apache 管理的另一个开源工具，它也专注于流式数据。Flume 专门用于在大数据环境中处理大量日志数据。'
- en: '**Apache Beam**: Another tool in the Apache streaming family is Apache Beam.
    This tool can handle both batch and streaming data. It is best known for building
    ETL and data processing pipelines.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Beam**：Apache 流式家族中的另一个工具是 Apache Beam。这个工具可以处理批量和流式数据。它最出名的是构建 ETL
    和数据处理流程。'
- en: '**Apache Storm**: Apache Storm is a stream processing computation framework
    that allows doing distributed computation. It is used to process data streams
    with Hadoop in real time.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Storm**：Apache Storm 是一个流处理计算框架，允许进行分布式计算。它用于实时处理与 Hadoop 相关的数据流。'
- en: '**Apache NiFi**: Apache NiFi is a tool that focuses on ETL. It gives its users
    the possibility to automate and manage data flows between systems. It can work
    together with Kafka.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache NiFi**：Apache NiFi 是一个专注于 ETL 的工具。它为用户提供自动化和管理系统间数据流的可能性。它可以与 Kafka
    一起工作。'
- en: '**Google Cloud DataFlow**: Google Cloud DataFlow is a tool proposed by Google
    Cloud Platform. It is developed specifically for tackling streaming use cases.
    It allows users to execute Apache Beam pipelines in a fully managed service.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Cloud DataFlow**：Google Cloud DataFlow 是由 Google Cloud Platform 提出的一种工具。它专门针对流式使用案例进行开发。它允许用户在完全管理的服务中执行
    Apache Beam 流程。'
- en: '**Amazon Kinesis**: Amazon Kinesis is strongly based on open source Apache
    Kafka, which was discussed earlier. The advantage of using Kinesis over Kafka
    is that it comes with a lot of things that are managed for you, whereas if you
    use Kafka directly, you spend more effort on managing the service. Of course,
    in return, you must use the AWS platform to access it.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon Kinesis**：Amazon Kinesis 强烈基于前面讨论过的开源 Apache Kafka。使用 Kinesis 而不是
    Kafka 的优势在于，它为你提供了许多管理服务，而如果你直接使用 Kafka，则需要投入更多精力来管理服务。当然，作为回报，你必须使用 AWS 平台来访问它。'
- en: '**Azure Stream Analytics**: Azure Stream Analytics is the main streaming analytics
    service proposed on Microsoft''s cloud platform, Azure. It is a real-time analytics
    service that is based on Trill.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Stream Analytics**：Azure Stream Analytics 是微软云平台 Azure 上提出的主要流式分析服务。它是一个基于
    Trill 的实时分析服务。'
- en: '**IBM Streams**: IBM Streams is a streaming analytics tool that is proposed
    on the IBM cloud. Just like Kinesis, it is based on the open source Kafka project.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IBM Streams**：IBM Streams 是一种在 IBM 云上提出的流式分析工具。就像 Kinesis 一样，它基于开源 Kafka
    项目。'
- en: Calling a big data environment in real time
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时调用大数据环境
- en: If your real-time analytics service is managed by a big data or specific streaming
    tool, you cannot always follow the API method for connecting your real-time process
    to your analytics process.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的实时分析服务由大数据或特定流式工具管理，你并不总是可以遵循 API 方法将你的实时流程连接到你的分析流程。
- en: In most cases, you'll need to look into the documentation of the tool of your
    choice and make sure that you understand how to make the connections work. At
    this point, you are often going to need a specialized profile to work with you,
    as this level of architecture and data engineering is generally considered out
    of scope for most data scientists.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，你需要查阅你选择工具的文档，并确保你理解如何使连接工作。在这个阶段，你通常需要一位专业配置文件来与你合作，因为这种级别的架构和数据工程通常被认为超出了大多数数据科学家的范围。
- en: A general difference between the microservice system and the big data system
    is that in a microservice approach, we are generally considering that there must
    be a response coming from the API that is taken into account by the calling service.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: In big data environments, it is much more common for a service such as a website
    to send data to a big data environment but not need a response. You could imagine
    a website that writes out every interaction by a user to a fixed location as JSON
    files. The big data streaming tool is then plugged onto this data storage location
    to read in the data in a streaming fashion and converts this into an analysis,
    a visualization, or something else.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s build a minimal example that will show how to do this:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create a JSON file called `example.json`, in which you write only the
    following data:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code block 2-8
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'You can now write a very short piece of Spark Streaming code that reads this
    data in a streaming way:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: In short, this code starts by creating a `spark` session. Once the session is
    created, a schema is defined for the `example.json` file. As it has only one key
    (called `value`), the schema is quite short. The data type for the value is `string`.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: You then see that the data is imported using the `.readStream` method, which
    actually does a lot of the heavy lifting in streaming for you. If you'd like to
    go further with this example, you could write all kinds of analytical Spark functions
    using the `streamingDF` library and you will have streaming analytics using the
    well-known big data tool **PySpark**.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have started to discover the field of architecture. You
    have built your own API on AWS, and you have seen the basic foundation of communication
    between systems. You should now understand that data is key in communication between
    systems and that good communication between systems is essential for delivering
    value through analytics.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: This is especially true in the case of real-time and streaming analytics. The
    high speed and often large size of data can easily pose problems if architectural
    bottlenecks are not identified early enough in the project.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: There are other topics that you must remember to take into account, including
    security, availability, and compliance. Those topics are best left to someone
    who makes it their full-time responsibility to take care of such data architecture
    problems.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we'll go back to the core of this book, as you'll
    discover how to build analytics use cases on streaming data.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Microservices Architecture*: [https://cloud.google.com/learn/what-is-microservices-architecture](https://cloud.google.com/learn/what-is-microservices-architecture)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'API: [https://www.redhat.com/en/topics/api/what-are-application-programming-interfaces](https://www.redhat.com/en/topics/api/what-are-application-programming-interfaces)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'HTTP: [https://developer.mozilla.org/en-US/docs/Web/HTTP](https://developer.mozilla.org/en-US/docs/Web/HTTP)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Top 10 real-time data streaming tools*: [https://ipspecialist.net/top-10-real-time-data-streaming-tools/](https://ipspecialist.net/top-10-real-time-data-streaming-tools/)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spark Streaming: [https://spark.apache.org/docs/latest/streaming-programming-guide.html](https://spark.apache.org/docs/latest/streaming-programming-guide.html)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kafka: [https://kafka.apache.org/](https://kafka.apache.org/)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Flume: [https://flume.apache.org/](https://flume.apache.org/)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Beam: [https://beam.apache.org/](https://beam.apache.org/)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Storm: [https://storm.apache.org/](https://storm.apache.org/)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NiFi: [https://nifi.apache.org/](https://nifi.apache.org/)'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google Cloud Dataflow: [https://cloud.google.com/dataflow](https://cloud.google.com/dataflow)'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amazon Kinesis: [https://aws.amazon.com/kinesis/](https://aws.amazon.com/kinesis/)'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Azure Stream Analytics: [https://azure.microsoft.com/en-us/services/stream-analytics/](https://azure.microsoft.com/en-us/services/stream-analytics/)'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'IBM Streams: [https://www.ibm.com/docs/en/streams](https://www.ibm.com/docs/en/streams)'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Capturing Web Page Scroll Progress with Amazon Kinesis*, by AWS: [https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/kinesis-examples-capturing-page-scrolling.html](https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/kinesis-examples-capturing-page-scrolling.html)'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
