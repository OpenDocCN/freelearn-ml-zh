- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AutoML with LightGBM and FLAML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed two case studies that showed end-to-end
    examples of how to approach data science problems. Of the steps involved in the
    typical data science life cycle, often, the most time-consuming tasks are preparing
    the data, finding the correct models, and tuning the models.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter looks at the concept of automated machine learning. Automated machine
    learning systems seek to automate some or all parts of the machine learning life
    cycle. We will look at **FLAML**, a library that automates the process’s model
    selection and tuning steps using efficient hyperparameter optimization algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we will present a case study using FLAML and another open source tool
    called Featuretools. Practical usage of FLAML will be discussed and shown. We
    will also show FLAML’s zero-shot AutoML functionality, which bypasses tuning altogether.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main topics of this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to automatic machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FLAML for AutoML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Case study – using FLAML with LightGBM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The chapter includes examples and code excerpts showcasing using FLAML with
    LightGBM for AutoML use cases. Complete examples and instructions for setting
    up a suitable environment for this chapter are available at [https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-7](https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-7).
  prefs: []
  type: TYPE_NORMAL
- en: Automated machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Automated machine learning** (**AutoML**) is a burgeoning field that aims
    to automate complex aspects of ML workflows, allowing for more efficient and accessible
    deployment of ML models. The advent of AutoML reflects the increasing sophistication
    of artificial intelligence and ML technologies and their permeation into various
    industry and research sectors. It aims to alleviate some of the complex, time-consuming
    aspects of the data science process, allowing for broader usage and more accessible
    application of ML technologies.'
  prefs: []
  type: TYPE_NORMAL
- en: For software engineers well versed in ML and data science processes, the increasing
    complexity of ML models and the expanding universe of algorithms can pose a significant
    challenge. Building a robust, high-performing model requires substantial expertise,
    time, and computational resources to select suitable algorithms, tune hyperparameters,
    and conduct in-depth comparisons. AutoML has emerged as a solution to these challenges,
    aiming to automate these complex, frequently labor-intensive tasks.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML also serves to democratize the field of ML. By abstracting away some
    of the complexities of data engineering and model building and tuning, AutoML
    makes it possible for individuals and organizations with less experience in ML
    to leverage these powerful technologies. As a result, ML can be effective in a
    broader array of contexts, with more individuals and organizations capable of
    deploying ML solutions.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML systems are available at various levels of complexity. Although all AutoML
    systems aim to simplify the ML workflow, most systems and tools only focus on
    parts of the workflow. Commonly, steps such as data preprocessing, feature engineering,
    model selection, and hyperparameter tuning are automated. Such automation saves
    time and can improve the robustness and performance of ML models by systematically
    exploring a more comprehensive array of options that may be overlooked or unexplored
    due to human biases or time constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Automating feature engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed in [*Chapter 6*](B16690_06.xhtml#_idTextAnchor094), *Solving Real-World
    Data Science Problems with LightGBM*, data cleaning and feature engineering are
    critical parts of the ML workflow. They involve dealing with unusable data, handling
    missing values, and creating meaningful features that can be fed into the model.
    Manual feature engineering can be particularly challenging and time-consuming.
    AutoML systems aim to handle these tasks effectively, enabling automated feature
    extraction and transformation, leading to more robust models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data cleaning automation is typically achieved by following specific well-known
    techniques for dealing with problems such as outliers and missing values. In previous
    chapters, we applied some of these techniques manually: outliers can be tested
    statistically and capped or truncated. Missing values are typically imputed using
    descriptive statistics such as the mean or the mode. AutoML systems either use
    heuristic algorithms and tests to select the best techniques to clean the data
    or take multiple approaches and tests that work best by training models against
    the data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The methods for automating feature engineering are often similar: many possible
    transformations are applied to all existing features, and the usefulness of the
    generated features is tested after modeling. Examples of how transformations generate
    features can be found in the following case study.'
  prefs: []
  type: TYPE_NORMAL
- en: Another method for automating feature engineering is extracting features using
    rules based on the data type of the features. For example, the day, week, month,
    and year could be extracted from a date field. Or the number of characters, lemmas,
    stems, or embeddings of word or sentence features could be calculated.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you may notice, the application of feature engineering automation techniques
    relies on technical information about the features at hand, typically the data
    type, alongside correlation and relationships with other features. Importantly,
    there is no domain knowledge applied when creating new features. This highlights
    one of the shortcomings of AutoML: it cannot handle specific, domain-driven decisions
    that require human expertise. For example, consider a diabetes dataset with a
    feature for fasting blood sugar. A medical professional (domain expert) knows
    that an individual with a fasting blood sugar of 100 to 125 mg/dL is considered
    prediabetic, and any higher is considered diabetic. This continuous feature can
    be engineered to specific classes: normal, prediabetic, and diabetic, simplifying
    the data for modeling. A transformation like this is not possible to achieve with
    AutoML systems.'
  prefs: []
  type: TYPE_NORMAL
- en: Automating model selection and tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Areas where AutoML is particularly useful are model selection and hyperparameter
    tuning. Given the plethora of algorithms available, choosing the best one for
    a particular dataset and problem can be daunting. AutoML systems use various techniques,
    including Bayesian optimization and meta-learning, to select the best model. They
    also automate the tuning of hyperparameters to maximize model performance.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML systems can provide automated cross-validation, reducing the risk of
    overfitting and ensuring the model’s generalizability to unseen data. Once the
    optimal model is selected and trained, many AutoML tools can also help with deployment,
    making the model available for inference on new data.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the initial model deployment, some AutoML solutions also provide value
    in ongoing model monitoring and maintenance. As real-world data evolves, models
    may suffer from drift, and their performance can degrade. AutoML can help monitor
    model performance and retrain the model as needed, ensuring that your ML system
    remains effective in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: Risks of using AutoML systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned previously, AutoML systems typically use no domain knowledge to
    aid in feature engineering, model selection, or other automation. Instead, a brute-force
    or scattershot approach of try and see is used.
  prefs: []
  type: TYPE_NORMAL
- en: The “black box” nature of some AutoML systems can also make it challenging to
    interpret decisions made by the system, making it less suitable for applications
    that require high levels of explainability.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it’s still essential to have a data scientist or domain expert in
    the loop, working alongside the AutoML system, to identify and act on opportunities
    where domain knowledge can lead to better models. However, AutoML systems sometimes
    hinder the data scientist instead of enabling them by creating one extra layer
    between the scientist and the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve already seen one AutoML framework in action. Optuna, which we discussed
    in [*Chapter 5*](B16690_05.xhtml#_idTextAnchor083), *LightGBM Parameter Optimization
    with Optuna*, is an example of an AutoML framework focusing on hyperparameter
    tuning. In the next section, we discuss another AutoML framework: FLAML.'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing FLAML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**FLAML** (**Fast and Lightweight AutoML**) is a Python library developed by
    Microsoft Research *[1]*. It is designed to produce high-quality ML models with
    low computational cost automatically. The primary aim of FLAML is to minimize
    the resources required to tune hyperparameters and identify optimal ML models,
    making AutoML more accessible and cost-effective, particularly for users with
    budget constraints.'
  prefs: []
  type: TYPE_NORMAL
- en: FLAML offers several key features that set it apart. One of these is its efficiency.
    It provides a fast and lightweight solution for ML tasks, minimizing the time
    and computational resources needed. It achieves this without compromising the
    quality of the models it produces. FLAML also emphasizes its versatility across
    various ML algorithms and various application domains.
  prefs: []
  type: TYPE_NORMAL
- en: The core of FLAML’s efficiency lies in its novel, cost-effective search algorithms.
    These algorithms intelligently explore the hyperparameter space, initially focusing
    on “cheap” configurations. It gradually explores more “expensive” configurations
    as it gains more insights into the search space. This ensures a balanced exploration
    and exploitation, delivering optimized models within user-specified time and resource
    budgets.
  prefs: []
  type: TYPE_NORMAL
- en: FLAML also excels at the model selection process. It supports various ML algorithms,
    including XGBoost, LightGBM, CatBoost, RandomForest, and various linear models.
    The library can automatically choose the best algorithm for a given dataset and
    optimize its hyperparameters, providing users with an optimal model without extensive
    manual intervention.
  prefs: []
  type: TYPE_NORMAL
- en: FLAML provides a straightforward, intuitive API that integrates seamlessly with
    existing Python-based data science and ML workflows. Users specify the dataset,
    a time budget (in seconds), and the optimization task, and FLAML handles the rest.
    This user-friendliness and efficiency make it a practical choice for ML beginners
    and seasoned practitioners looking to expedite their workflows.
  prefs: []
  type: TYPE_NORMAL
- en: 'The novelty behind FLAML’s efficiency comes from its **hyperparameter optimization**
    (**HPO**) algorithms. FLAML provides two HPO algorithms: **Cost Frugal Optimization**
    and **BlendSearch**.'
  prefs: []
  type: TYPE_NORMAL
- en: Cost Frugal Optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Cost Frugal Optimization** (**CFO**) is a local search method that leverages
    random direct search to explore the hyperparameter space *[2]*. The CFO algorithm
    starts with a low-cost hyperparameter configuration (for LightGBM, a low-cost
    configuration would, for instance, have few boosted trees). It takes randomized
    steps for a fixed number of iterations in the hyperparameter space toward higher
    cost parameter regions.'
  prefs: []
  type: TYPE_NORMAL
- en: The CFO step size is adaptive, meaning the algorithm lowers the step size if
    there is no improvement for several iterations. Doing so means large step sizes
    aren’t taken in unpromising directions with high cost.
  prefs: []
  type: TYPE_NORMAL
- en: CFO also utilizes random restarts. As a local search algorithm, CFO can get
    stuck in local optima. If no progress is made and the step size is already small,
    the algorithm restarts at a random point.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, CFO quickly (with large step sizes) attempts to reach more promising
    regions in the search space, using as little of the optimization budget as possible
    (by starting in low-cost regions). CFO continues the search while the optimization
    budget allows, restarting in random areas if stagnation occurs. FLAML allows the
    user to set the optimization budget in seconds.
  prefs: []
  type: TYPE_NORMAL
- en: BlendSearch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: FLAML provides an alternative to the CFO algorithm in BlendSearch. BlendSearch
    differs from CFO by running both a global and local search process using a multithreaded
    approach *[3]*.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to CFO, BlendSearch starts with a low-cost configuration and proceeds
    with a local search. However, unlike CFO, BlendSearch does not wait for the local
    search to stagnate before exploring new regions. Instead, a global search algorithm
    (such as Bayesian optimization) continually suggests new starting points. Starting
    points are filtered based on their distance to existing points and prioritized
    in terms of cost.
  prefs: []
  type: TYPE_NORMAL
- en: Each iteration of BlendSearch then chooses whether to continue a local search
    or start at a new global search point based on the performance in the previous
    iteration. Like CFO, configurations proposed by the global search method are validated
    for viability.
  prefs: []
  type: TYPE_NORMAL
- en: As BlendSearch uses global optimization, BlendSearch is less prone to getting
    stuck in local minima. BlendSearch is recommended over CFO if the hyperparameter
    search space is highly complex. It’s often a good idea to try CFO first and only
    switch to BlendSearch if CFO is struggling.
  prefs: []
  type: TYPE_NORMAL
- en: FLAML limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite its advantages, FLAML also has its limitations. The library’s automated
    processes may not consistently outperform manual tuning by experts, particularly
    for complex, domain-specific tasks. Also, as with other AutoML solutions, the
    interpretability of the produced models can be challenging, especially when dealing
    with models such as boosted trees or neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: FLAML only performs the model selection and tuning part of the ML process. These
    are some of the most time-consuming parts of model development, but FLAML does
    not provide the functionality to perform feature engineering or data preparation.
  prefs: []
  type: TYPE_NORMAL
- en: The following section presents a case study of using FLAML with LightGBM, showcasing
    everyday use cases, different optimization algorithms, and FLAML’s zero-shot AutoML.
  prefs: []
  type: TYPE_NORMAL
- en: Case study – using FLAML with LightGBM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use the Wind Turbine dataset from the previous chapter for the case
    study. The dataset is cleaned as before, imputing missing values and capping outliers
    to appropriate ranges. However, we take a different approach to feature engineering.
    To further explore AutoML, we use an open source framework called Featuretools.
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Featuretools** ([https://featuretools.alteryx.com/en/stable/#](https://featuretools.alteryx.com/en/stable/#))
    is an open source framework for automated feature engineering. Specifically, Featuretools
    is well suited to transforming relational datasets and temporal data.'
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in the previous section, automated feature engineering tools typically
    use combinatorial transformations of features to generate new features for the
    dataset. Featuretools supports feature transformations through their **Deep Feature
    Synthesis** (**DFS**) process.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, consider a dataset of online customer web sessions. Typical
    features that could be useful in such a dataset are the total sessions a customer
    visited the site for, or the month a customer signed up. Using Featuretools and
    DFS, this can be achieved using the following code (courtesy of [https://featuretools.alteryx.com/](https://featuretools.alteryx.com/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Two transformations are being applied here: a transformation for “`month`”
    and an aggregation for “`count`”. With these transformations, the month would
    be automatically extracted from any dates present for a customer (such as the
    join date), and the count aggregations would be calculated for each customer (such
    as the number of sessions or transactions). Featuretools has a rich set of transformations
    and aggregations available. [A complete list is available at https://featuretools.alteryx.](https://featuretools.alteryx.com/en/stable/api_reference.xhtml)com/en/stable/api_reference.xhtml.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how we can use Featuretools to engineer the features for the Wind
    Turbine dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Using Featuretools with the Wind Turbine dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We must perform two feature engineering tasks for our dataset: engineer features
    for the datetime field and encode categorical features. To get started, we create
    an `EntitySet` for our data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`EntitySet` tells the Featuretools framework the entities and relationships
    we work with within the data. Customer is an example of an entity in the earlier
    example; for this case, it’s Wind Turbines. We then pass the data frame and the
    column to be used as an index.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We then apply `dfs` and `encode_features` to engineer the features for our
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code extracts the day, year, month, and weekday for each of our
    wind turbine measurements. The feature encoding then automatically one-hot encodes
    the categorical features for our dataset, including the new datefields.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an excerpt from the dataset column list showing some of the
    columns created by Featuretools:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Note the one-hot encoding of categorical features: each value is now split
    into a separate column. This includes columns for unknown values (for example,
    `YEAR(datetime) is unknown`), which illustrates another way of dealing with missing
    values in categorical features. Instead of imputing a value by using something
    such as the mode, we have a column that signals to the model (`true` or `false`)
    that the value is missing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The automated feature engineering has increased our column count from 22 columns
    to 66 columns. This illustrates another general caveat with automated feature
    engineering and AutoML: automation may lead to overcomplicated datasets. In [*Chapter
    6*](B16690_06.xhtml#_idTextAnchor094), *Solving Real-World Data Science Problems
    with LightGBM*, we could encode features selectively based on our understanding
    of the learning algorithm. LightGBM can automatically handle categorical features;
    therefore, one-hot encoding is superfluous if LightGBM is the only learning algorithm
    used.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the datefields could be handled numerically. By applying our knowledge
    of the problem and algorithm, we can reduce the dimensionality of the learning
    problem, thereby simplifying it. The ease of use of automated systems has to be
    balanced with the manual effort of expert feature engineering, which could save
    time later on.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is now ready for model development; we’ve completed the feature
    engineering for our dataset using only two lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: FLAML AutoML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now look at model selection and tuning. We will use FLAML to compare
    five different models: LightGBM, RandomForest, XGBoost, ExtraTrees, and a limited-depth
    version of XGBoost. We would also like to find optimal parameters for the best
    model. This entire process is possible in two lines of code with FLAML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code fits an optimal regression model within a time budget of
    60 seconds. FLAML automatically uses a holdout set to calculate validation results
    and then proceeds with optimization, using CFO as the tuner by default.
  prefs: []
  type: TYPE_NORMAL
- en: 'The AutoML class provides “task-oriented AutoML.” The user sets the learning
    task, and FLAML does the rest. Among others, the following tasks are supported:
    classification, regression, time-series forecasting and time-series classification,
    ranking, and NLP-related tasks such as summarization and word token classification.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The call to `fit` is customizable. For example, we could customize it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, we customize the hyperparameter search space by explicitly declaring the
    learning rate as a log-scaled uniform variable within a range. Other options for
    setting the search space for parameters are uniform sampling, random integer sampling,
    and choice-based sampling for categorical parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, we set the estimator list to focus on only three modeling algorithms:
    LightGBM, Random Forest, and XGBoost. Lastly, we can customize the HPO algorithm,
    and here, we set it to BlendSearch, which uses the multithreaded optimization
    approach discussed earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: A complete list of customizations is available at https://microsoft.github.io/FLAML/docs/reference/automl/automl/#automl-objects.
  prefs: []
  type: TYPE_NORMAL
- en: Once `fit` has been called, we can use the AutoML-trained model as we would
    any other. FLAML provides a scikit-learn-style API for prediction and probability-based
    prediction (for classification problems).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code creates predictions from the given data and calculates metrics
    and feature importance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also get the best hyperparameter configuration for the winning model
    and for each of the models trialed by calling the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: A final notable feature of FLAML is zero-shot AutoML, which bypasses the need
    for model tuning entirely.
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot AutoML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Zero-shot AutoML** is a FLAML feature where hyperparameter optimization is
    not performed. Instead, suitable hyperparameter configurations are determined
    offline by analyzing the performance of an algorithm on a wide variety of datasets.
    The process can be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before building a model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train models on many datasets using AutoML
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Store all datasets’ hyperparameter configurations, evaluation results, and metadata
    as a zero-shot solution
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When building a model for a new problem:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use FLAML to analyze the new dataset against the zero-shot solution results
    and determine suitable hyperparameters
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Train a model on the new dataset using the hyperparameters
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The first step is performed only once for a given model type (such as LightGBM).
    Thereafter, a new model can be built for any new problem without tuning. The solution
    is “zero-shot” because suitable parameters are used on the first fit for a new
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'FLAML’s zero-shot AutoML approach has many advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, no tuning is involved, sparing much computational effort and time
    when solving a new problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since no tuning is required, a validation dataset is not required either, and
    more of the data may be used for training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even less involvement is required by the user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, no code changes are required, as we’ll see next
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, creating the zero-shot solution for a model type is still arduous,
    requiring varied datasets and much computation to train many models. Fortunately,
    FLAML provides pretrained zero-shot solutions for many popular models, including
    LightGBM, XGBoost, and scikit-learn’s random forests.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use a zero-shot solution, replace the regular LightGBM import with the FLAML-wrapped
    version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Calling `fit` analyzes the data in `X`, selects suitable parameters, and trains
    the model using those parameters. Training is performed only once, and no tuning
    is done.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our case study of FLAML. As we have seen, FLAML provides an intuitive
    API for sophisticated model selection and tuning functionality, which could spare
    much effort when working on an ML problem.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In summary, this chapter discussed AutoML systems and their uses. Typical approaches
    to automating feature engineering, model selection, and tuning were discussed.
    We also mentioned the risks and caveats associated with using these systems.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter also introduced FLAML, a library for AutoML that provides tools
    for automating the model selection and tuning process. We also presented CFO and
    BlendSearch, two efficient hyperparameter optimization algorithms provided by
    FLAML.
  prefs: []
  type: TYPE_NORMAL
- en: The practicalities of applying FLAML were shown in the form of a case study.
    In addition to FLAML, we showcased an open source tool called Featuretools, which
    provides functionality to automate feature engineering. We showed how to develop
    optimized models in fixed-time budgets using FLAML. Finally, we provided examples
    of using FLAML’s zero-shot AutoML functionality, which analyzes datasets against
    configurations for known problems to determine suitable hyperparameters, eliminating
    the need for model tuning.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter discusses building ML pipelines around LightGBM models, focusing
    on exporting, packaging, and deploying LightGBM models for production.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| *[**1]* | *C. Wang, Q. Wu, M. Weimer, and E. Zhu, “FLAML: A Fast and Lightweight
    AutoML Library,” in* *MLSys, 2021.* |'
  prefs: []
  type: TYPE_TB
- en: '| *[**2]* | *Q. Wu, C. Wang and S. Huang, Frugal Optimization for Cost-related*
    *Hyperparameters, 2020.* |'
  prefs: []
  type: TYPE_TB
- en: '| *[**3]* | *C. Wang, Q. Wu, S. Huang, and A. Saied, “Economical Hyperparameter
    Optimization With Blended Search Strategy,” in* *ICLR, 2021.* |'
  prefs: []
  type: TYPE_TB
- en: 'Part 3: Production-ready Machine Learning with LightGBM'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Part 3, we will delve into the practical applications of ML solutions in
    production environments. We will uncover the intricacies of machine learning pipelines,
    ensuring systematic data processing and model building for consistent results.
    MLOps, a confluence of DevOps and ML, takes center stage, highlighting the importance
    of deploying and maintaining robust ML systems in real-world scenarios. Through
    hands-on examples, we will explore the deployment of ML pipelines on platforms
    (like Google Cloud, Amazon SageMaker, and the innovative PostgresML) emphasizing
    the unique advantages each offers. Lastly, distributed computing and GPU-based
    training will be explored, showcasing methods to expedite training processes and
    manage larger datasets efficiently. This concluding part will emphasize the seamless
    integration of ML into practical, production-ready solutions, equipping readers
    with the knowledge to bring their models to life in dynamic environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part will include the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B16690_08.xhtml#_idTextAnchor134)*, Machine Learning Pipelines
    and MLOps with LightGBM*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B16690_09.xhtml#_idTextAnchor146)*, LightGBM MLOps with AWS SageMaker*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B16690_10.xhtml#_idTextAnchor162)*, LightGBM* *M**odels with
    PostgresML*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B16690_11.xhtml#_idTextAnchor177)*, Distributed and GPU-based
    Learning with LightGBM*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
