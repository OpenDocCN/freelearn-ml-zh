<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer076">
<h1 class="chapter-number" id="_idParaDest-142"><a id="_idTextAnchor143"/>7</h1>
<h1 id="_idParaDest-143"><a id="_idTextAnchor144"/>Exploring Google Cloud Vertex AI</h1>
<p>In the last chapter, we discussed Google Cloud BQML, which is used to develop ML models from structured data, and Google’s TensorFlow and Keras frameworks, which provide a high-level API interface for ML model development. In this chapter, we will discuss Cloud Vertex AI, which is Google’s integrated cloud service suite for ML model development. We will examine the Vertex AI suite and all its products and services.</p>
<p><strong class="bold">Google Vertex AI</strong> is an integrated set of Google Cloud products, features, and a management interface that <a id="_idIndexMarker425"/>simplifies the management of ML services. It offers users a complete platform to build, train, and deploy ML applications in Google Cloud, from end to end. Vertex AI provides a single stop for data scientists to build machine learning applications.</p>
<p>In this chapter, we will discuss the following Vertex AI products and services:</p>
<ul>
<li>Vertex AI data labeling and datasets</li>
<li>Vertex AI Feature Store</li>
<li>Vertex AI Workbench and notebooks</li>
<li>Vertex AI training </li>
<li>Vertex AI models and predictions</li>
<li>Vertex AI Pipelines</li>
<li>Vertex AI metadata</li>
<li>Vertex AI experiments and TensorBoard</li>
</ul>
<p>Let’s start with data labeling and datasets in the Vertex AI suite.</p>
<h1 id="_idParaDest-144"><a id="_idTextAnchor145"/>Vertex AI data labeling and datasets</h1>
<p>Datasets play such a <a id="_idIndexMarker426"/>significant role in the machine learning process that the quality of datasets has a huge impact on the ML model performance. As we discussed in <a href="B18333_04.xhtml#_idTextAnchor094"><em class="italic">Chapter 4</em></a>, <em class="italic">Developing and Deploying ML Models</em>, data preparation is the <a id="_idIndexMarker427"/>first and most important step in any machine learning process. </p>
<p><strong class="bold">Vertex AI Data labeling</strong> is a Google Cloud service that lets end users work with human workers to review and label datasets uploaded by users. After the datasets are labeled, they <a id="_idIndexMarker428"/>can be used to train machine learning models. The human workers are employed by Google, and the users will need to provide the dataset, the labels, and instructions to the human workers for labeling.</p>
<p>End users can also upload labeled datasets directly. <strong class="bold">Vertex AI datasets</strong> are part of a Google Cloud service that <a id="_idIndexMarker429"/>provides users with the ability to upload data of varying types for the purpose of building, training, and validating machine <a id="_idIndexMarker430"/>learning models. Currently, Vertex AI supports four types of datasets (image, tabular, text, and videos):</p>
<ul>
<li><strong class="bold">Image datasets</strong>: You can <a id="_idIndexMarker431"/>create image datasets within Vertex AI, and use them to train models for image classification, image segmentation, and object detection. With Vertex AI, you can either upload the image datasets directly or use the images stored in Google Cloud Storage buckets.</li>
<li><strong class="bold">Tabular datasets</strong>: You can directly upload a CSV file from your local computer, use <a id="_idIndexMarker432"/>one from Google Cloud Storage, or select a table from the BigQuery service. Once the tabular dataset is generated, the data is available in Vertex AI datasets for model training.</li>
<li><strong class="bold">Video datasets</strong>: Vertex AI allows you to directly upload videos from your local computers or use <a id="_idIndexMarker433"/>videos from Google Cloud buckets. Once you have the video datasets, you can use them for video classifications or action recognitions.</li>
<li><strong class="bold">Text datasets</strong>: In Vertex AI, you create a text dataset, and import the CSVs from a Google <a id="_idIndexMarker434"/>Cloud Storage bucket into the dataset. Then, you can use the dataset for text document classification, custom text entity identification, sentiment analysis, and so on.</li>
</ul>
<p>Vertex AI datasets allow you <a id="_idIndexMarker435"/>to create and manage datasets directly within the Vertex AI suite, and the datasets uploaded through Vertex AI are automatically stored in the Cloud Storage bucket, which is created and managed by Vertex AI. </p>
<h1 id="_idParaDest-145"><a id="_idTextAnchor146"/>Vertex AI Feature Store</h1>
<p>In ML/DL model training, features are the attributes to build a model and make future inferences. Google <a id="_idIndexMarker436"/>Vertex AI Feature Store is a fully managed cloud service that provides a centralized repository to store, organize, and serve ML features. You can create and manage a <strong class="bold">Vertex AI Feature Store</strong> that contains all the model features and their values. With a central feature store, users in a Google Cloud organization can share and reuse these features for model training or serving tasks in different ML/DL projects to speed up machine learning application development and model deployment.</p>
<p>Vertex AI Feature Store enables users to manage features in ML models. A feature store can serve real-time, online predictions, or batch predictions for the new data. For example, after loading information about movie-watching habits, the Feature Store can serve to predict what movie a new user may watch based on their characteristics.</p>
<p>In traditional ML frameworks, you may have computed feature values and saved them in various locations including Cloud Storage buckets or BQ tables, and you may have separate solutions for storing and managing the feature values. With Vertex AI Feature Store, you are provided with a unified solution, consistent across the organization, to store and serve features that can be shared among different teams for different projects or use cases.</p>
<h1 id="_idParaDest-146"><a id="_idTextAnchor147"/>Vertex AI Workbench and notebooks </h1>
<p>The <strong class="bold">Vertex AI Workbench</strong> service provides a single development platform for the entire data <a id="_idIndexMarker437"/>science workflow; you can use it to launch Cloud VM instances/notebooks to query and explore data and to develop and train a model for deployment.</p>
<p>As we explained earlier in the <em class="italic">Preparing the platform </em>section, Jupyter Notebook is a widely used <a id="_idIndexMarker438"/>platform for ML model development. Vertex AI Workbench <a id="_idIndexMarker439"/>provides two Jupyter-Notebook-based options for your data scientists, managed notebooks and user-managed notebooks:</p>
<ul>
<li><strong class="bold">Managed notebooks</strong> are Google-managed, Jupyter-based, scalable, enterprise-ready <a id="_idIndexMarker440"/>compute instances that help you set up and work in an end-to-end ML production environment. </li>
<li><strong class="bold">User-managed notebooks</strong> are heavily customizable instances and are thus fitting for users who need a lot of control over their environment. With a user-managed <a id="_idIndexMarker441"/>notebook instance, you have a suite of deep learning packages pre-installed, including TensorFlow and PyTorch frameworks. </li>
</ul>
<p>Vertex AI Workbench provides <a id="_idIndexMarker442"/>flexible notebook options. It offers a great ML model training platform for data scientists to train and develop models.</p>
<h1 id="_idParaDest-147"><a id="_idTextAnchor148"/>Vertex AI Training</h1>
<p>In an ML model <a id="_idIndexMarker443"/>development process, training jobs are discrete tasks that generate ML models. In Vertex AI, you can choose different training methods based on the source of model and data; <strong class="bold">Vertex AI AutoML</strong>, which is managed by Google, uses Google’s model and <a id="_idIndexMarker444"/>your data to train, and the <strong class="bold">Vertex AI platform</strong>, with user-defined code <a id="_idIndexMarker445"/>or custom containers, utilizes your model and your data to perform model training. </p>
<h2 id="_idParaDest-148"><a id="_idTextAnchor149"/>Vertex AI AutoML</h2>
<p><strong class="bold">Vertex AI AutoML</strong> is a managed Google Cloud service that enables users to build models across <a id="_idIndexMarker446"/>a wide variety of use cases without writing any code. The objective is to enable ML model development for various levels of AI expertise. </p>
<p>The types of models supported <a id="_idIndexMarker447"/>by Vertex AutoML are shown in <em class="italic">Table 7.1</em>:</p>
<div>
<div class="IMG---Figure" id="_idContainer072">
<img alt="Table 7.1 – Vertex AI AutoML models " height="276" src="image/Figure_7.1.jpg" width="1299"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 7.1 – Vertex AI AutoML models</p>
<p>When creating an AutoML training pipeline job, you have the following options:</p>
<ul>
<li><strong class="bold">Dataset</strong>: Managed by Vertex AI and uploaded by a user</li>
<li><strong class="bold">Model type</strong>: Selected from the supported models (as described above)</li>
<li><strong class="bold">Data split</strong> (Optional): Split dataset between training, validation, and testing data using custom parameters</li>
<li><strong class="bold">Encryption</strong> (Optional): Option to select a <strong class="bold">customer-managed encryption key</strong> (<strong class="bold">CMEK</strong>) for <a id="_idIndexMarker448"/>in-process encryption</li>
</ul>
<p>Vertex AI AutoML helps you <a id="_idIndexMarker449"/>to build a code-free model based on your training data. With Vertex AI AutoML, you customize Google’s models using your own data.</p>
<h2 id="_idParaDest-149"><a id="_idTextAnchor150"/>The Vertex AI platform</h2>
<p>The <strong class="bold">Vertex AI platform</strong>, with custom containers, enables you to build your own models from <a id="_idIndexMarker450"/>scratch, with your own data. <strong class="bold">Custom containers</strong> are user-created Docker <a id="_idIndexMarker451"/>images that are selected while creating a pipeline. A typical workflow for a custom container environment <a id="_idIndexMarker452"/>is shown in <em class="italic">Figure 7.2</em>, and it has the following steps:</p>
<ol>
<li><strong class="bold">Code development</strong>: You can build an application in the programming language of your choice, locally or within a notebook, and dependencies can be sourced from any internet location by default.</li>
<li><strong class="bold">Build</strong>: You can build code into a packaged artifact or write a configuration to automatically package code and various dependencies into a container runtime artifact.</li>
<li><strong class="bold">Artifact storage</strong>: You can push newly built customized artifacts into Cloud Storage or a container registry.</li>
<li><strong class="bold">Start training pipeline</strong>: You can select a <em class="italic">custom container</em> when creating a training pipeline to build an ML model.</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer073">
<img alt="Figure 7.1 – Vertex AI platform custom container " height="445" src="image/Figure_7.2.jpg" width="1451"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – Vertex AI platform custom container</p>
<p>After the <a id="_idIndexMarker453"/>models are trained in Vertex AI, you can use either AutoML or custom containers, accessed/managed in Vertex AI Models, and be deployed in Vertex AI Endpoints for individual predictions or batch predictions.</p>
<h1 id="_idParaDest-150"><a id="_idTextAnchor151"/>Vertex AI Models and Predictions</h1>
<p><strong class="bold">Vertex AI Models</strong> provides <a id="_idIndexMarker454"/>a platform for managing ML models. With Vertex AI Models, you can develop and manage ML models in many ways:</p>
<ul>
<li><strong class="bold">Create model</strong>: Users can choose to create a new model and be redirected to the <strong class="bold">training Pipelines</strong> screen.</li>
<li><strong class="bold">Upload model</strong>: Users can upload a model that’s been trained elsewhere for use within their Vertex AI project.</li>
<li><strong class="bold">Deploy model</strong>: Users can deploy a selected model to an endpoint, making it available through a REST API.</li>
<li><strong class="bold">Export model</strong>: Users can export a trained model to a GCS bucket, where it can be stored or used in another project.</li>
</ul>
<p>After the models are trained, they can be exported or deployed publicly or privately to predict production cases. When you deploy a model to an endpoint resource for online predictions, or when you request batch predictions, you can always customize the VM types that the prediction service uses, and you can also configure prediction nodes to use GPUs. We will discuss model deployment in the next sections.</p>
<h2 id="_idParaDest-151"><a id="_idTextAnchor152"/>Vertex AI endpoint prediction</h2>
<p><strong class="bold">Vertex AI Endpoints</strong> allow users to create REST API endpoints based on Vertex AI models, to <a id="_idIndexMarker455"/>predict results for new data. With Vertex AI, a model can be deployed into either public endpoints or private endpoints:</p>
<ul>
<li><strong class="bold">Public endpoints</strong>: The <a id="_idIndexMarker456"/>model is deployed to an internet-routable, Google-managed endpoint hosted in a selected region.</li>
<li><strong class="bold">Private endpoints</strong>: The model is deployed to a Google-managed endpoint hosted in <a id="_idIndexMarker457"/>a selected region on a private IP address in a selected VPC.</li>
</ul>
<p>Vertex AI Endpoints are used to deploy trained models for online prediction. When creating a new endpoint, users can configure the following:</p>
<ul>
<li><strong class="bold">Endpoint Name</strong></li>
<li><strong class="bold">GCP Region</strong></li>
<li><strong class="bold">Private or Public Access</strong></li>
<li><strong class="bold">Encryption (Optional)</strong></li>
<li><strong class="bold">Model(s)</strong>: One or more models to be served by the new endpoint.</li>
</ul>
<p>Integrating with Vertex AI training and Vertex AI Models, Vertex AI Endpoints allow users to predict individual results interactively.</p>
<h2 id="_idParaDest-152"><a id="_idTextAnchor153"/>Vertex AI batch prediction</h2>
<p>Different from Vertex AI Endpoints, <strong class="bold">Vertex AI batch prediction</strong> jobs are discrete tasks that <a id="_idIndexMarker458"/>run batch sets of input data against a prediction model. As shown in <em class="italic">Figure 7.3</em>, it can input files in Google Cloud Storage, and outputs the results to a specified GCS location.</p>
<div>
<div class="IMG---Figure" id="_idContainer074">
<img alt="Figure 7.2 – Vertex AI batch prediction " height="586" src="image/Figure_7.3.jpg" width="1391"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – Vertex AI batch prediction</p>
<p>When creating <a id="_idIndexMarker459"/>a batch prediction job, you have the following options:</p>
<ul>
<li><strong class="bold">Region</strong>: Where the model is stored</li>
<li><strong class="bold">Model</strong>: Points to the ML model</li>
<li><strong class="bold">Input data</strong>: Cloud Storage bucket where input data is stored</li>
<li><strong class="bold">Output directory</strong>: Cloud Storage bucket to store predictions</li>
<li>Compute-related information including machine type and number of nodes</li>
</ul>
<p>As we can see from the preceding services, Vertex AI provides an ML development and management suite for you to create and manage datasets, create and manage notebooks to conduct model training, and develop and manage models for the endpoint of batch prediction. With Vertex AI, you can perform all the tasks in an ML workflow, from end to end. And that leads us to the Vertex AI Pipelines discussion: automating the ML workflow.</p>
<h1 id="_idParaDest-153"><a id="_idTextAnchor154"/>Vertex AI Pipelines</h1>
<p><strong class="bold">Vertex AI Pipelines</strong> allow <a id="_idIndexMarker460"/>you to automatically orchestrate your ML workflow <a id="_idIndexMarker461"/>in a serverless manner using <strong class="bold">TensorFlow Extended</strong> (<strong class="bold">TFX</strong>) or <strong class="bold">Kubeflow</strong>. Each Vertex AI pipeline job is generated from a configuration <a id="_idIndexMarker462"/>file that outlines a list of steps. A typical Vertex AI pipeline imports data into a dataset, trains a model using a <strong class="bold">training pipeline</strong>, and deploys the <a id="_idIndexMarker463"/>model to a new endpoint for prediction. Pipeline jobs are run using compute <a id="_idIndexMarker464"/>resources, with the following options:</p>
<ul>
<li>You can write custom <a id="_idIndexMarker465"/>configurations for pipeline jobs using the <strong class="bold">Kubeflow DSL</strong>.</li>
<li>You can create, run, and schedule pipeline jobs.</li>
<li>You can specify <strong class="bold">Service Account</strong> or use <strong class="bold">Compute Default Service Account</strong> if not specified.</li>
</ul>
<p>Google Vertex AI Pipelines orchestrates your ML workflow, based on your descriptions of the workflow as a pipeline. ML pipelines are portable and scalable ML workflows that are based on containers. ML pipelines are composed of a set of input parameters and a list of steps – each step is an instance of the pipeline.</p>
<h1 id="_idParaDest-154"><a id="_idTextAnchor155"/>Vertex AI Metadata</h1>
<p><strong class="bold">Vertex AI Metadata</strong> is a repository of metadata that is generated across a variety of Vertex AI components. When <a id="_idIndexMarker466"/>models are developed in the ML workflow pipelines, metadata is generated and stored, and you can consolidate this metadata into a single metadata store, which allows users to query and answer questions such as the following:</p>
<ul>
<li>Which version of a trained model has achieved a certain quality threshold?</li>
<li>Which pipeline runs/uses a certain dataset?</li>
</ul>
<p>Within a Vertex AI pipeline, users can also configure data objects that are written to the metadata store. And from there, users can create <em class="italic">Context</em> objects that organize these data objects into logical groupings and obtain more insights.</p>
<p>Using the Vertex AI metadata API, users can build schemas, organize data objects, or query data that’s been stored within Vertex AI metadata.</p>
<h1 id="_idParaDest-155"><a id="_idTextAnchor156"/>Vertex AI experiments and TensorBoard </h1>
<p><strong class="bold">TensorBoard</strong> is a Google open <a id="_idIndexMarker467"/>source project for machine learning experiment visualization. Vertex AI experiments are an implementation of TensorBoard. With <a id="_idIndexMarker468"/>Vertex AI experiments, users can create TensorBoard instances and upload TensorBoard logs generated from Vertex AI Models to run experiments – visual representations of a variety of metrics, such as loss function and accuracy over different model parameters at different running times. <em class="italic">Figure 7.4</em> shows a sample workflow for Vertex AI experiments and TensorBoard:</p>
<div>
<div class="IMG---Figure" id="_idContainer075">
<img alt="Figure 7.3 – Vertex AI experiments and TensorBoard " height="488" src="image/Figure_7.4.jpg" width="1153"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – Vertex AI experiments and TensorBoard</p>
<p>These TensorBoard visualizations are available via a web application that can be shared with other users by setting up GCP IAM permissions. With Vertex AI experiments, you can configure the following options:</p>
<ul>
<li><strong class="bold">Manage TensorBoard Instances</strong>: Users can create, update, or delete TensorBoard instances; instances are used for experiments.</li>
<li><strong class="bold">Create Experiments</strong>: By uploading pipeline log data, users can generate experiments and visualizations.</li>
<li><strong class="bold">View TensorBoard Web Application</strong>: Users can view TensorBoard via a web application generated for each TensorBoard instance.</li>
<li><strong class="bold">Export Data</strong>: Users can export pipeline metadata and TensorBoard data points using the API.</li>
</ul>
<p>Vertex AI experiments <a id="_idIndexMarker469"/>provide users with a platform to experiment and tune model parameters. With <a id="_idIndexMarker470"/>Vertex AI experiments, we can interact on the TensorBoard web and check the results. It is an important and integral part of the Google Vertex AI suite.</p>
<h1 id="_idParaDest-156"><a id="_idTextAnchor157"/>Summary</h1>
<p>In this chapter, we have introduced the Google Vertex AI suite, including its services, platforms, and tools for ML model development and deployment. With Vertex AI, you can manage the datasets, models, and pipelines easily and flexibly. Without a doubt, mastering Vertex AI needs hands-on practice for each service in the suite, and we have provided sample hands-on practice steps in <a href="B18333_14.xhtml#_idTextAnchor218"><em class="italic">Appendix 4</em></a>, <em class="italic">Practicing with Google Vertex AI</em>. Please follow these practices and understand the steps in the appendix. In the next chapter, we will discuss another Google Cloud ML service: Google Cloud ML APIs.</p>
<h1 id="_idParaDest-157"><a id="_idTextAnchor158"/>Further reading</h1>
<p>For further insights on the learning of the chapter, you can refer to the following links:</p>
<ul>
<li><em class="italic">Vertex AI documentation</em></li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/docs">https://cloud.google.com/vertex-ai/docs</a></p>
<ul>
<li><em class="italic">All dataset documentation  |  Vertex AI</em></li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/docs/datasets/datasets">https://cloud.google.com/vertex-ai/docs/datasets/datasets</a></p>
<ul>
<li><em class="italic">Introduction to Vertex AI Feature Store  </em></li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/docs/featurestore/overview">https://cloud.google.com/vertex-ai/docs/featurestore/overview</a></p>
<ul>
<li><em class="italic">Introduction to Vertex AI Workbench</em></li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/docs/workbench/introduction">https://cloud.google.com/vertex-ai/docs/workbench/introduction</a></p>
<ul>
<li><em class="italic">Choose a notebook solution  |  Vertex AI Workbench</em></li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/docs/workbench/notebook-solution">https://cloud.google.com/vertex-ai/docs/workbench/notebook-solution</a></p>
<ul>
<li><em class="italic">Introduction to Vertex AI Model Monitoring</em></li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/docs/model-monitoring/overview">https://cloud.google.com/vertex-ai/docs/model-monitoring/overview</a></p>
<ul>
<li><em class="italic">Introduction to Vertex AI Pipelines</em></li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/docs/pipelines/introduction">https://cloud.google.com/vertex-ai/docs/pipelines/introduction</a></p>
<ul>
<li><em class="italic">Vertex Explainable AI  |  Vertex AI</em></li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/docs/explainable-ai">https://cloud.google.com/vertex-ai/docs/explainable-ai</a></p>
<ul>
<li><em class="italic">Deploy a model using the Cloud console  |  Vertex AI</em></li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-console">https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-console</a></p>
<ul>
<li><a href="B18333_14.xhtml#_idTextAnchor218"><em class="italic">Appendix 4</em></a>, <em class="italic">Practicing with Google Vertex AI</em></li>
</ul>
</div>
<div>
<div id="_idContainer077">
</div>
</div>
</div>
</body></html>