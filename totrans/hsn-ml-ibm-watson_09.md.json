["```py\n!pip list â€“isolated\n```", "```py\n!pip install asn1crypto==0.23.0\n!pip install bleach==1.5.0\n!pip install certifi==2017.11.5\n!pip install cffi==1.11.2\n!pip install chardet==3.0.4\n!pip install cryptography==2.1.3\n!pip install cycler==0.10.0\n!pip install enum34==1.1.6\n!pip install html5lib==0.9999999\n!pip install idna==2.6\n!pip install Markdown==2.6.9\n!pip install matplotlib==2.1.0\n!pip install numpy==1.13.3\n!pip install olefile==0.44\n!pip install Pillow==4.3.0\n!pip install protobuf==3.5.0.post1\n!pip install pycparser==2.18\n!pip install pyOpenSSL==17.4.0\n!pip install pyparsing==2.2.0\n!pip install pysolr==3.6.0\n!pip install python-dateutil==2.6.1\n!pip install pytz==2017.3\n!pip install requests==2.18.4\n!pip install six==1.11.0\n!pip install tensorflow==1.4.0\n!pip install tensorflow-tensorboard==0.4.0rc3\n!pip install urllib3==1.22\n!pip install watson-developer-cloud==1.0.0\n!pip install Werkzeug==0.12.2\n```", "```py\npip3 install -r requirements.txt\n```", "```py\nVisual_recognition = VisualRecognitionV3('2016-05-20', api_key='API_KEY')\n```", "```py\n# --- we need pillow version of 5.3.0 to run this project\n# --- this code will uninstall the current version:\n!pip uninstall -y Pillow\n# --- install the 5.3.0 version\n!pip install Pillow==5.3.0\n# --- import the new one\nimport PIL\n# --- Should print 5.3.0\\. If it doesn't, then restart the kernel \nprint(PIL.PILLOW_VERSION)\n```", "```py\n# --- Upgrade Watson Developer\n!pip install --upgrade \"watson-developer-cloud>-2.8.0\"\n```", "```py\nSuccessfully installed watson-developer-cloud-2.8.0 websocket-client-0.48.0\n```", "```py\nfrom watson_developer_cloud import VisualRecognitionV3\n```", "```py\nimport numpy as np\nimport os\nimport six.moves.urllib as urllib\nimport sys\nimport tarfile\nimport tensorflow as tf\nimport zipfile\nimport json\nfrom io import StringIO\nfrom PIL import Image\nfrom watson_developer_cloud import VisualRecognitionV3\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n```", "```py\n# --- Replace with your api key\nvisual_recognition = VisualRecognitionV3('2016-05-20', api_key='r-1m0OdmBy9khRHJvujylJoLRJIqjwS6Bqwb6VMBfeCE')\n```", "```py\nMAX_NUMBER_OF_BOXES = 9\nMINIMUM_CONFIDENCE = .9\nCOLORS = ['b', 'g', 'r', 'c', 'm', 'y', 'b', 'w']\n```", "```py\n# --- define What model to download.\nMODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\nMODEL_FILE = MODEL_NAME + '.tar.gz'\nDOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n# --- Path to frozen detection graph. This is the actual model that  # --- is used for the object detection.\nPATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\nprint('Downloading model... (This may take over 5 minutes)')\n# --- Download model if not already downloaded\nif not os.path.exists(PATH_TO_CKPT):\n   opener = urllib.request.URLopener()\nopener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n print('Extracting...')\ntar_file = tarfile.open(MODEL_FILE)\nfor file in tar_file.getmembers():\n    file_name = os.path.basename(file.name)\nif 'frozen_inference_graph.pb' in file_name:\ntar_file.extract(file, os.getcwd())\nelse:\n   print('Model already downloaded............')\n# --- Load model into memory\nprint('Loading da model...')\ndetection_graph = tf.Graph()\nwith detection_graph.as_default():\n    od_graph_def = tf.GraphDef()\n    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n      serialized_graph = fid.read()\n        od_graph_def.ParseFromString(serialized_graph)\n       tf.import_graph_def(od_graph_def, name='')\n```", "```py\ndef load_image_into_numpy_array(image):\n   (im_width, im_height) = image.size\n    return np.array(image.getdata()).reshape(\n   (im_height, im_width, 3)).astype(np.uint8)\n# --- Path to image to test, was: \"test_image/image1.jpg\"\nTEST_IMAGE_PATH = 'image1.jpg'\n```", "```py\nprint('detecting...')\nwith detection_graph.as_default():\n   with tf.Session(graph=detection_graph) as sess: \n        image = Image.open(TEST_IMAGE_PATH)\n        image_np = load_image_into_numpy_array(image)\n        image_np_expanded = np.expand_dims(image_np, axis=0)\n        image_tensor = detection_graph.\n        get_tensor_by_name('image_tensor:0')\n        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n        scores = detection_graph.\n        get_tensor_by_name('detection_scores:0')\n        num_detections = detection_graph.\n        get_tensor_by_name('num_detections:0')\n        # --- Actual detection.\n    (boxes, scores, num_detections) = sess.run([boxes, scores, num_detections], feed_dict={image_tensor: image_np_expanded})\n  # --- Create figure and axes and display the image\n        fig, ax = plt.subplots(1)\n        ax.imshow(image_np)\n        (height, width, x) = image_np.shape\nfor i in range(0, int(min(num_detections,          MAX_NUMBER_OF_BOXES))):\n           score = np.squeeze(scores)[i]\n           # --- if the score is not greater than\n           # --- what we set the minimun score to be then\n           # --- exit the loop\n           if score < MINIMUM_CONFIDENCE:\n             break\n            box = np.squeeze(boxes)[i]\n            box_x = box[1] * width\n            box_y = box[0] * height\n            box_width = (box[3] - box[1]) * width\n            box_height = (box[2] - box[0]) * height\n            box_x2 = box[3] * width\n            box_y2 = box[2] * height\n            img2 = image.crop((box_x, box_y, box_x2, box_y2))\n            path = 'cropped/image1'\n            os.makedirs(path, exist_ok=True)\n            full_path = os.path.join(path, 'img{}.jpg'.format(i))\n            img2.save(full_path)        \n```", "```py\n# --- Classify images with Watson visual recognition\n         with open(full_path, 'rb') as images_file:\n             parameters = json.dumps({'threshold': 0.7,          'classifier_ids': ['default']})\n               results = visual_recognition.classify(images_file=images_file, parameters=parameters).get_result() \n                label = results['images'][0]['classifiers'][0]['classes'][0]['class']\n                ax.text(box_x + 5, box_y - 5, label, fontsize=10, color='white', bbox={'facecolor':COLORS[i % 8], 'edgecolor':'none'})\n            # --- Create a Rectangle patch\n            rect = patches.Rectangle((box_x, box_y), box_width, box_height, linewidth=2, edgecolor=COLORS[i % 8], facecolor='none')\n            ax.add_patch(rect)\n```", "```py\n # --- use matplotlib to show the result!\n plt.show()\n```"]