- en: '*Chapter 4*: Deep Learning with Neural Networks'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：使用神经网络的深度学习'
- en: This chapter is an introduction to neural networks with Keras. If you have already
    worked with MNIST or CIFAR-10 image classification datasets, feel free to skip
    it. But if you have never trained a neural network, this chapter might have some
    surprises in store for you.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是使用Keras介绍神经网络。如果你已经使用过MNIST或CIFAR-10图像分类数据集，可以自由跳过。但如果你从未训练过神经网络，本章可能对你来说有一些惊喜。
- en: This chapter is quite practical, to give you very quickly something to play
    with, and we will skip as much theory as reasonably possible and learn how to
    recognize handwritten numbers (composed of one single digit) with high precision.
    The theory behind what we do here, and more, will be covered in the next chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章非常实用，旨在让你很快就能玩起来，我们将尽可能跳过理论，学习如何以高精度识别由单个数字组成的手写数字。我们在这里所做以及更多内容的理论将在下一章中介绍。
- en: 'We will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习
- en: Neural networks and their parameters
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络及其参数
- en: Convolutional neural networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: Keras, a deep learning framework
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras，一个深度学习框架
- en: The MNIST dataset
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MNIST数据集
- en: How to build and train a neural network
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建和训练神经网络
- en: The CIFAR-10 dataset
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CIFAR-10数据集
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For the instructions and code in this chapter, you need the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中的说明和代码，你需要以下内容：
- en: Python 3.7
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.7
- en: NumPy
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy
- en: Matplotlib
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib
- en: TensorFlow
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow
- en: Keras
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras
- en: The OpenCV-Python module
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV-Python模块
- en: A GPU (recommended)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个GPU（推荐）
- en: 'The code for the book can be found here:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本书代码可以在以下位置找到：
- en: '[https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter4](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter4)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter4](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter4)'
- en: 'The Code in Action videos for this chapter can be found here:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的“代码实战”视频可以在以下位置找到：
- en: '[https://bit.ly/3jfOoWi](https://bit.ly/3jfOoWi)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://bit.ly/3jfOoWi](https://bit.ly/3jfOoWi)'
- en: Understanding machine learning and neural networks
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习和神经网络
- en: According to Wikipedia, **machine learning** is *"the study of computer algorithms
    that improve automatically through experience*.*"*
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 根据维基百科，**机器学习**是“*通过经验自动改进的计算机算法的研究*。”
- en: 'What that means in practice, at least for what concerns us, is that the algorithm
    itself is only moderately important, and what is critical is the data that we
    feed to this algorithm so that it can learn: we need to **train** our algorithm.
    Putting it in another way, we can use the same algorithm in many different situations
    as long as we provide the proper data for the task at hand.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，至少对我们来说，这意味着算法本身的重要性只是适度的，而关键的是我们提供给这个算法的数据，以便它能够学习：我们需要**训练**我们的算法。换一种说法，只要我们为当前任务提供适当的数据，我们就可以在许多不同的情况下使用相同的算法。
- en: For example, during this chapter, we will develop a neural network that is able
    to recognize handwritten numbers between 0 and 9; most likely, the exact same
    neural network could be used to recognize 10 letters, and with trivial modifications,
    it could recognize all letters or even different objects. In fact, we will reuse
    it basically as it is to recognize 10 objects.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在本章中，我们将开发一个能够识别0到9之间手写数字的神经网络；很可能，完全相同的神经网络可以用来识别10个字母，并且通过微小的修改，它可以识别所有字母或甚至不同的对象。实际上，我们将基本上以原样重用它来识别10个对象。
- en: This is totally different from *normal programming*, where different tasks usually
    require different code; to improve a result, we need to improve the code, and
    we might not need data at all for an algorithm to be usable (with real data).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这与*常规编程*完全不同，在常规编程中，不同的任务通常需要不同的代码；为了改进结果，我们需要改进代码，而且我们可能根本不需要数据来使算法可用（使用真实数据）。
- en: 'That said, this does not mean that the result of a neural network is always
    good so long as good data is fed to it: difficult tasks require more advanced
    neural networks to perform well.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，这并不意味着只要输入好的数据，神经网络的结果就总是好的：困难的任务需要更高级的神经网络才能表现良好。
- en: To be clear, while the algorithm (meaning the neural network model) is less
    important than the code in traditional programming, it is still important if you
    want to get very good results. In fact, with the wrong architecture, your neural
    network might not be able to learn at all.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了明确起见，虽然算法（即神经网络模型）在传统编程中不如代码重要，但如果想要获得非常好的结果，它仍然很重要。事实上，如果架构错误，你的神经网络可能根本无法学习。
- en: Neural networks are only one of the tools that you can use to develop machine
    learning models, but this is what we will focus on. The accuracy of deep learning
    is usually quite high, and you might find that applications where less-accurate
    machine learning techniques are used are heavily constrained by the amount of
    data and the cost of processing it.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络只是你可以用来开发机器学习模型的各种工具之一，但这是我们将会关注的。深度学习的准确性通常相当高，你可能会发现，在那些使用不太精确的机器学习技术的应用中，数据量和处理成本有很大的限制。
- en: '**Deep learning** can be considered a subset of machine learning, where the
    computation is performed by several computation layers, which is the *deep* part
    of the name. From a practical point of view, deep learning is achieved using neural
    networks.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度学习**可以被认为是机器学习的一个子集，其中的计算由多个计算层执行，这是名称中的“深度”部分。从实际的角度来看，深度学习是通过神经网络实现的。'
- en: 'That brings us to the question: what exactly is a neural network?'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了一个问题：神经网络究竟是什么？
- en: Neural networks
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络
- en: 'Neural networks are somewhat inspired by our brains: a neuron in our brain
    is a "computational node" that is connected to other neurons. When performing
    a computation, each of our brain''s neurons "senses" the excited state of the
    neurons that it is connected to and uses these external states to compute its
    own state. A neuron in a neural network (a perceptron) basically does the same,
    but here is more or less where the similarities end. To be clear, a perceptron
    is not a simulation of a neuron, but it is just inspired by it.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络在一定程度上受到我们大脑的启发：我们大脑中的神经元是一个“计算节点”，它连接到其他神经元。在执行计算时，我们大脑中的每个神经元“感知”它所连接的神经元的兴奋状态，并使用这些外部状态来计算它自己的状态。神经网络中的神经元（感知器）基本上做的是同样的，但这里的相似之处到此为止。为了明确起见，感知器不是神经元的模拟，但它只是受到了启发。
- en: 'The following is a mini neural network, with its neurons:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个小型神经网络，其中包含其神经元：
- en: '![Figure 4.1 – A neural network](img/Figure_4.1_B16322.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – 一个神经网络](img/Figure_4.1_B16322.jpg)'
- en: Figure 4.1 – A neural network
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 一个神经网络
- en: The first layer is the input (for example, the pixels of your image) and the
    output layer is the result (for example, your classification). The hidden layer
    is where the computation happens. Normally, you have more hidden layers, not just
    one. Every input can also be called a feature, and in the case of an RGB image,
    a feature is usually a single channel of a pixel.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 第一层是输入（例如，图像的像素）和输出层是结果（例如，分类）。隐藏层是计算发生的地方。通常，你会有更多的隐藏层，而不仅仅是单个。每个输入也可以称为特征，在
    RGB 图像的情况下，特征通常是像素的单个通道。
- en: 'In feedforward neural networks, the neurons of a layer are connected only to
    neurons of the layer before and of the following layers:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在前馈神经网络中，一个层的神经元只与前一层的神经元和下一层的神经元连接：
- en: '![Figure 4.2 – A neural network](img/Figure_4.2_B16322.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – 一个神经网络](img/Figure_4.2_B16322.jpg)'
- en: Figure 4.2 – A neural network
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 一个神经网络
- en: But what exactly is a neuron?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 但神经元究竟是什么？
- en: Neurons
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经元
- en: A neuron is a computation node that produces an output given some input. As
    for what these inputs and outputs are – well, it depends. We will come back to
    this point later.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元是一个计算节点，它根据某些输入产生输出。至于这些输入和输出是什么——嗯，这取决于。我们稍后会回到这个点。
- en: 'The following is a representation of the typical neuron of a neural network:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个神经网络中典型神经元的表示：
- en: '![Figure 4.3 – Schematic of a single neuron of a neural network. ©2016 Wikimedia
    Commons](img/Figure_4.3_B16322.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 – 神经网络中单个神经元的示意图。©2016 Wikimedia Commons](img/Figure_4.3_B16322.jpg)'
- en: Figure 4.3 – Schematic of a single neuron of a neural network. ©2016 Wikimedia
    Commons
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 神经网络中单个神经元的示意图。©2016 Wikimedia Commons
- en: 'This needs some explanation. The computation performed by a neuron can be divided
    into two parts:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要一些解释。神经元执行的计算可以分为两部分：
- en: 'The transfer function computes the sum of every input multiplied by its weight
    (just a number); what this means is that the state of the neuron depends on the
    state of its input neurons, but different neurons provide a different contribution.
    This is just a linear operation:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换函数计算每个输入乘以其权重的总和（只是一个数字）；这意味着神经元的状况取决于其输入神经元的状况，但不同的神经元提供不同的贡献。这仅仅是一个线性操作：
- en: '![](img/Formula_04_001.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![img/Formula_04_001.jpg](img/Formula_04_001.jpg)'
- en: The activation function is applied to the result of the transfer function, and
    it should be a **non-linear** operation, typically with a threshold. A function
    that we will use often, because of its performance, is called **Rectified Linear
    Unit (ReLU)**.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活函数应用于转换函数的结果，并且它应该是一个**非线性**操作，通常有一个阈值。由于性能出色，我们将经常使用的一个函数被称为**修正线性单元（ReLU）**。
- en: '![Figure 4.4 – Two activation functions: Softplus and ReLU](img/Figure_4.4_B16322.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 4.4 – Two activation functions: Softplus and ReLU](img/Figure_4.4_B16322.jpg)'
- en: 'Figure 4.4 – Two activation functions: Softplus and ReLU'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 – 两种激活函数：Softplus和ReLU
- en: There is usually also a **bias**, a value used to shift the activation function.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通常还有一个**偏差**，这是一个用于移动激活函数的值。
- en: The combination of a linear function with a non-linear function is non-linear,
    while the combination of two linear functions is still linear. This is very important
    because it means that if the activation was linear, then the output of the neurons
    will be linear, and the combination of different layers would be linear as well.
    So, the whole neural network would be linear and therefore equivalent to a single
    layer.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 线性函数与非线性函数的组合是非线性的，而两个线性函数的组合仍然是线性的。这一点非常重要，因为它意味着如果激活是线性的，那么神经元的输出将是线性的，不同层的组合也将是线性的。因此，整个神经网络将是线性的，因此等同于单层。
- en: Introducing a non-linear operation in the activation allows a network to compute
    non-linear functions that become more and more complex as the number of layers
    grows. This is one of the reasons why the most sophisticated neural networks can
    literally have hundreds of layers.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在激活函数中引入非线性操作，使得网络能够计算越来越复杂的非线性函数，随着层数的增加，这些函数变得越来越复杂。这是最复杂的神经网络实际上可以有数百层的原因之一。
- en: Parameters
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数
- en: The bias and the weights are called **parameters**, because they are not fixed
    but need to change based on the task at hand. We do this during the **training**
    phase. To be clear, the whole purpose of the training phase is to find the best
    possible value for these parameters for our task.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差和权重被称为**参数**，因为它们不是固定的，需要根据任务进行调整。我们在**训练**阶段进行这一操作。为了明确起见，训练阶段的整个目的就是为我们的任务找到这些参数的最佳可能值。
- en: This has profound implications, as it means that the same neural network, with
    different parameters, can solve different problems – very different problems.
    The trick, of course, is to find the best values (or one approximation) for these
    parameters. If you are wondering how many parameters a typical neural network
    can have, the answer is millions. Luckily, this process, called training, can
    be automated.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这具有深远的影响，因为它意味着同一个神经网络，具有不同的参数，可以解决不同的问题——非常不同的问题。当然，技巧是找到这些参数的最佳值（或一个近似值）。如果你想知道一个典型的神经网络可以有多少参数，答案是数百万。幸运的是，这个过程，即训练，可以自动化。
- en: An alternative way to imagine a neural network is to consider it as a gigantic
    system of equations, and the training phase is an attempt to find an approximate
    solution to it.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 想象神经网络的一个替代方法是将其视为一个庞大的方程组系统，而训练阶段则是一个尝试找到其近似解的过程。
- en: The success of deep learning
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习的成功
- en: You've probably noticed that deep learning has seen explosive growth in the
    past few years, but neural networks are really nothing new. I remember trying
    to write a neural network (and failing miserably!) more than 20 years ago, after
    reading a book about it. In fact, they date back to 1965, with some theories being
    even 20 years older than that.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，深度学习在过去几年中经历了爆炸性的增长，但神经网络实际上并不是什么新鲜事物。我记得在阅读了一本关于神经网络的书之后，我尝试编写一个神经网络（并且失败得很惨！）那是在20多年前。事实上，它们可以追溯到1965年，有些理论甚至比那还要早20年。
- en: Many years ago, they were dismissed basically as a curiosity, as they were too
    computationally demanding to be practical.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 多年前，它们基本上被当作一种好奇心，因为它们计算量太大，不实用。
- en: 'However, fast forward some decades, and deep learning is the new black, thanks
    to some critical advances:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，快进几十年，深度学习成为了新的热门领域，这得益于一些关键性的进步：
- en: Computers are much faster and have much more RAM available.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机运行得更快，并且有更多的RAM可用。
- en: GPUs can be used to make computations even faster.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用GPU来使计算更快。
- en: There are many datasets easily available on the internet to train neural networks.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在互联网上有许多数据集可以轻松用于训练神经网络。
- en: There are now plenty of tutorials and online courses dedicated to deep learning.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在互联网上有许多教程和在线课程专门介绍深度学习。
- en: There are several good open source libraries for neural networks.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在有多个优秀的开源库用于神经网络。
- en: Architectures have become better and more efficient.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 架构已经变得更加优秀和高效。
- en: It's the perfect storm to make neural networks much more appealing, and there
    are many applications that seem to be waiting for deep learning, such as voice
    assistants and, of course, self-driving cars.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是使神经网络更具吸引力的完美风暴，而且有许多应用似乎都在等待深度学习，例如语音助手和当然，自动驾驶汽车。
- en: 'There is a special type of neural network that is particularly good at understanding
    the content of images, and we will pay great attention to them: convolutional
    neural networks.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种特殊的神经网络特别擅长理解图像内容，我们将特别关注它们：卷积神经网络。
- en: Learning about convolutional neural networks
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习卷积神经网络
- en: 'If you look at a classical neural network, you can see that the first layer
    is composed of inputs, standing on a line. This is not only a graphical representation:
    for a classical neural network, an input is an input, and it should be independent
    of the other ones. This is probably fine if you are trying to predict the price
    of an apartment based on size, ZIP code, and floor number, but it does not seem
    optimal for an image, where pixels have neighbors and it seems intuitive that
    keeping this proximity information is important.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你观察一个经典的神经网络，你可以看到第一层由输入组成，它们排列成一行。这不仅是一个图形表示：对于一个经典神经网络来说，输入是输入，它应该独立于其他输入。如果你试图根据大小、ZIP代码和楼层号预测公寓的价格，这可能没问题，但对于图像来说，像素有邻居，保持这种邻近信息似乎很直观。
- en: '**Convolutional Neural Networks** (**CNNs**) solve exactly this problem, and
    it turns out that not only can they process images efficiently, but they can also
    be used with success for natural language processing.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNNs**）正好解决了这个问题，结果发现它们不仅能够高效地处理图像，而且还可以成功应用于自然语言处理。'
- en: A CNN is a neural network that has at least one convolutional layer, which is
    inspired by the visual cortex of animals, where individual neurons respond only
    to stimuli in a small area of the field of vision. Let's see what convolutions
    really are.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: CNN是一种至少包含一个卷积层的神经网络，它受到动物视觉皮层的启发，其中单个神经元只对视野中一个小区域内的刺激做出反应。让我们看看卷积究竟是什么。
- en: Convolutions
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积
- en: 'Convolutions are based on the concept of the **kernel**, a matrix that you
    apply to some pixels to get a single new pixel. Kernels can be used for edge detection
    or to apply filters to an image, and you normally have the option to define your
    kernel in image processing programs, if you wish to do so. The following is a
    3x3 identity kernel that replicates an image as it is, and we are applying it
    to a small image:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积基于**核**的概念，这是一个应用于某些像素以得到单个新像素的矩阵。核可以用于边缘检测或对图像应用过滤器，并且如果你愿意，你通常可以在图像处理程序中定义你的核。以下是一个3x3的单位核，它以原样复制图像，并且我们正在将其应用于一个小图像：
- en: '![Figure 4.5 – Part of an image, a 3x3 identity kernel, and the result](img/Figure_4.5_B16322.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5 – 图像的一部分、一个3x3的单位核以及结果](img/Figure_4.5_B16322.jpg)'
- en: Figure 4.5 – Part of an image, a 3x3 identity kernel, and the result
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 – 图像的一部分、一个3x3的单位核以及结果
- en: 'Just imagine putting a pixel behind each element of the kernel and multiplying
    them together, then adding the results to get the value of the new pixel; clearly,
    you would get a zero for each pixel except the central one, which would be unchanged.
    This kernel preserves the value of the pixel in the middle and discards all the
    others. If you slide this convolution kernel over the whole picture, you will
    get the original image back:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，在每个核的元素后面放置一个像素，并将它们相乘，然后将结果相加以得到新像素的值；显然，除了中央像素外，其他所有像素都会得到零，中央像素保持不变。这个核保留了中间像素的值，丢弃了所有其他像素。如果你将这个卷积核在整个图片上滑动，你会得到原始图像：
- en: '![Figure 4.6 – Identity convolution – just copying an image](img/Figure_4.6_B16322.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图4.6 – 单位卷积 – 只复制图像](img/Figure_4.6_B16322.jpg)'
- en: Figure 4.6 – Identity convolution – just copying an image
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 – 单位卷积 – 只复制图像
- en: You can see that as the convolution kernel slides over the image, the pixels
    are replicated unchanged. You can also see that the resolution is reduced, as
    we use *valid* padding.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，当卷积核在图像上滑动时，像素保持不变地复制。你还可以看到分辨率降低了，因为我们使用了 *valid* 填充。
- en: 'This is another example:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个例子：
- en: '![Figure 4.7 – Part of an image, a 3x3 kernel, and the result](img/Figure_4.7_B16322.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 图像的一部分、3x3 的核和结果](img/Figure_4.7_B16322.jpg)'
- en: Figure 4.7 – Part of an image, a 3x3 kernel, and the result
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 图像的一部分、3x3 的核和结果
- en: 'Other kernels can be more interesting than the identity kernel. The following
    kernel (on the left) can detect edges, as seen on the right:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 其他核可能比恒等核更有趣。下面的核（在左侧）可以检测边缘，如右侧所示：
- en: '![Figure 4.8 – Kernel detecting edges](img/Figure_4.8_B16322.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – 核检测边缘](img/Figure_4.8_B16322.jpg)'
- en: Figure 4.8 – Kernel detecting edges
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 核检测边缘
- en: 'If you are curious about kernels, please go ahead with OpenCV and have some
    fun:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对核感兴趣，请继续使用 OpenCV 并享受乐趣：
- en: '[PRE0]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Kernels don't need to be 3x3; they can be bigger.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 核不需要是 3x3 的；它们可以更大。
- en: If you imagine starting with the first pixel of the image, you might ask what
    happens then, as there are no pixels above it or to its left. If you position
    the top-left corner of a kernel on the top-left pixel of an image, you will lose
    one pixel on each side of the image, because you can think of it as the kernel
    *emitting a pixe*l from the center. This is not always a problem, because when
    designing a neural network, you might want the image to get smaller and smaller
    after each layer.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想象从图像的第一个像素开始，你可能会问那时会发生什么，因为上面或左边没有像素。如果你将核的左上角放在图像的左上像素上，图像的每一边都会丢失一个像素，因为你可以将它想象成核从中心发射出一个像素。这并不总是一个问题，因为在设计神经网络时，你可能希望图像在每一层之后都变得越来越小。
- en: An alternative is to use padding – for example, pretending that there are black
    pixels around the image.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是使用填充 – 例如，假装图像周围有黑色像素。
- en: The good news is that you don't need to find the values of the kernels; the
    CNN will find them for you during the training phase.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，你不需要找到核的值；CNN 会在训练阶段为你找到它们。
- en: Why are convolutions so great?
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么卷积如此出色？
- en: 'Convolutions have some great advantages. As we have already said, they preserve
    the proximity of pixels:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积有一些显著的优势。正如我们之前所说，它们保留了像素的邻近性：
- en: '![Figure 4.9 – A convolution layer, in yellow, versus a dense layer, in green](img/Figure_4.9_B16322.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.9 – 黄色的卷积层与绿色的密集层](img/Figure_4.9_B16322.jpg)'
- en: Figure 4.9 – A convolution layer, in yellow, versus a dense layer, in green
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – 黄色的卷积层与绿色的密集层
- en: As you can see from the previous figure, the convolution knows the topology
    of the image and can know, for example, that the pixel with the number 43 is right
    next to the pixel with the number 42, is below the pixel with the number 33, and
    is above the pixel with the number 53\. The dense layer in the same figure does
    not have this information and might think that the pixel with 43 and the pixel
    with 51 are close to each other. Not only that, but it does not even know whether
    the resolution is 3x3, 9x1, or 1x9\. Intuitively knowing the topology of pixels
    is an advantage.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，卷积知道图像的拓扑结构，例如，它可以知道像素 43 正好位于像素 42 的旁边，位于像素 33 的下方，位于像素 53 的上方。同一图中的密集层没有这个信息，可能会认为像素
    43 和像素 51 相近。不仅如此，它甚至不知道分辨率是 3x3、9x1 还是 1x9。直观地了解像素的拓扑结构是一个优势。
- en: An additional important advantage is that they are computationally efficient.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的优势是它们在计算上效率很高。
- en: Another great characteristic of convolutions is that they are very good at recognizing
    patterns, such as diagonal lines or circles. You might say that they can only
    do so at a small scale, which is true, but you can combine multiple convolutions
    to detect patterns at different scales, and they can be surprisingly good at that.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积的另一个显著特点是它们非常擅长识别模式，例如对角线或圆形。你可能会说它们只能在较小的尺度上做到这一点，这是真的，但你可以组合多个卷积来检测不同尺度的模式，并且它们在这方面可以出奇地好。
- en: They are also able to detect patterns in different parts of an image.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 它们也能够检测图像不同部分的模式。
- en: All these characteristics make them great to work with images, and it is not
    surprising that they are used so much for object detection.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些特性使它们非常适合处理图像，并且它们在目标检测中被广泛使用并不令人惊讶。
- en: Enough theory for now. Let's get our hands dirty and write our first neural
    network.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在理论部分就到这里。让我们动手写我们的第一个神经网络。
- en: Getting started with Keras and TensorFlow
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用Keras和TensorFlow
- en: There are many libraries dedicated to deep learning, and we will be using Keras,
    a Python library that uses multiple backends; we will be using TensorFlow as a
    backend. While the code is specific to Keras, the principles can apply to any
    other libraries.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多库专门用于深度学习，我们将使用Keras，这是一个使用多个后端的Python库；我们将使用TensorFlow作为后端。虽然代码是针对Keras的，但原则可以应用于任何其他库。
- en: Requirements
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要求
- en: 'Before starting, you need to install at least TensorFlow and Keras, using `pip`:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，你需要至少安装TensorFlow和Keras，使用`pip`：
- en: '[PRE1]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We are using TensorFlow 2.2, which has integrated GPU support, but if you are
    using TensorFlow version 1.15 or older, you need to install a separate package
    to take advantage of a GPU:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用TensorFlow 2.2，它集成了GPU支持，但如果你使用的是TensorFlow版本1.15或更早版本，你需要安装一个单独的包来利用GPU：
- en: '[PRE2]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: I would recommend using the most recent versions of both TensorFlow and Keras.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议使用TensorFlow和Keras的最新版本。
- en: 'Before starting, let''s make sure that everything is in order. You probably
    want to use a GPU, to speed up training. Unfortunately, getting TensorFlow to
    use your GPU is not necessarily straightforward; for example, it is very picky
    with the version of CUDA: if it says CUDA 10.1, it really means it – it is not
    going to work with 10.0 or with 10.2\. Hopefully, this will not affect your games
    much.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，让我们确保一切就绪。你可能想使用GPU来加速训练。不幸的是，让TensorFlow使用你的GPU并不一定简单；例如，它对CUDA的版本非常挑剔：如果它说CUDA
    10.1，那么它确实意味着它——它不会与10.0或10.2兼容。希望这不会对你的游戏造成太大影响。
- en: 'To print the version of TensorFlow, you can use this code:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要打印TensorFlow的版本，可以使用以下代码：
- en: '[PRE3]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'On my computer, that prints this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的电脑上，它会打印出以下内容：
- en: '[PRE4]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To check the GPU support, you can use this code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查GPU支持，可以使用以下代码：
- en: '[PRE5]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If everything is fine, you should see `CUDA ON`, meaning that your version of
    TensorFlow has been built with CUDA support, and `GPU ON`, meaning that TensorFlow
    is able to use your GPU.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，你应该看到`CUDA ON`，这意味着你的TensorFlow版本已经集成了CUDA支持，以及`GPU ON`，这意味着TensorFlow能够使用你的GPU。
- en: If your GPU is not NVIDIA, it might require some more work, but it should be
    possible to configure TensorFlow to run on AMD graphics cards, using ROCm.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的GPU不是NVIDIA，可能需要更多的工作，但应该可以配置TensorFlow在AMD显卡上运行，使用ROCm。
- en: Now that you have correctly installed all the software, it is time to use it
    on our first neural network. Our first task will be to recognize handwritten digits,
    using a dataset called MNIST.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经正确安装了所有软件，是时候在我们的第一个神经网络上使用了。我们的第一个任务将是使用名为MNIST的数据集来识别手写数字。
- en: Detecting MNIST handwritten digits
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测MNIST手写数字
- en: When you design a neural network, you usually start with a problem that you
    want to solve, and you might start with a design that you know performs well on
    a similar task. You need a dataset, basically as big a dataset as you can get.
    There is not really a rule on that, but we can say that the minimum to train your
    own neural network might be something around 3,000 images, but nowadays world-class
    CNNs are trained using literally millions of pictures.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 当你设计神经网络时，你通常从一个你想要解决的问题开始，你可能从一个已知在类似任务上表现良好的设计开始。你需要一个数据集，基本上是你能得到的尽可能大的数据集。在这方面没有真正的规则，但我们可以这样说，训练你自己的神经网络可能至少需要大约3000张图片，但如今，世界级的CNNs是使用数百万张图片进行训练的。
- en: Our first task is to detect handwritten digits, a classical task for CNNs. There
    is a dataset for that, the MNIST dataset (copyright of Yann LeCun and Corinna
    Cortes), and it is conveniently present in Keras. MNIST detection is an easy task,
    so we will achieve good results.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的首要任务是检测手写数字，这是CNNs的经典任务。为此有一个数据集，即MNIST数据集（版权属于Yann LeCun和Corinna Cortes），并且它方便地存在于Keras中。MNIST检测是一个简单的任务，因此我们将取得良好的结果。
- en: 'Loading the dataset is easy:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据集很容易：
- en: '[PRE6]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`reshape` just reinterprets the shape from (60000, 28, 28) to (60000, 28, 28,
    1), because Keras needs four dimensions.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`reshape`只是将形状从(60000, 28, 28)重新解释为(60000, 28, 28, 1)，因为Keras需要四个维度。'
- en: What did we just load?
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们刚刚加载了什么？
- en: 'The `load_data()` method returns four things:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`load_data()`方法返回四个东西：'
- en: '`x_train`: The images used for training'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_train`：用于训练的图像'
- en: '`y_train`: The labels used for training (that is, the correct numbers for each
    of the handwritten digits)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_train`：用于训练的标签（即每个手写数字的正确数字）'
- en: '`x_test`: The images used for testing'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_test`：用于测试的图像'
- en: '`y_test`: The labels used for testing (that is, the correct numbers for each
    of the handwritten digits)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_test`：用于测试的标签（即每个手写数字的正确数字）'
- en: Training samples and labels
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练样本和标签
- en: 'Let''s print the dimensions of the training samples (`x`) and of the labels
    (`y`):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印训练样本（`x`）和标签（`y`）的维度：
- en: '[PRE7]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It should print something like this:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 应该打印出类似以下内容：
- en: '[PRE8]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The x variable represents the input for the CNN, which means that x contains
    all our images divided into two sets, one for training and one for testing:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: x 变量代表 CNN 的输入，这意味着 x 包含所有我们的图像，分为两个集合，一个用于训练，一个用于测试：
- en: '`x_train` contains 60,000 images intended for training, each with 28x28 pixels
    and in grayscale (one channel).'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_train` 包含 60,000 张用于训练的图像，每张图像有 28x28 像素，为灰度图（一个通道）。'
- en: '`x_test` contains 10,000 images intended for testing, each with 28x28 pixels
    and in grayscale (one channel).'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_test` 包含 10,000 张用于测试的图像，每张图像有 28x28 像素，为灰度图（一个通道）。'
- en: As you can see, the training and testing images have the same resolution and
    the same number of channels.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，训练和测试图像具有相同的分辨率和相同数量的通道。
- en: 'The `y` variable represents the expected output of the CNN, also called the
    label. For many datasets, somebody manually labels all the images to say what
    they are. If the dataset is artificial, labeling might be automated:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`y` 变量代表 CNN 的预期输出，也称为标签。对于许多数据集，有人手动标记所有图像以说明它们是什么。如果数据集是人工的，标记可能是自动化的：'
- en: '`y_train` is composed of 60,000 numbers belonging to 10 classes, from 0 to
    9.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_train` 由 60,000 个属于 10 个类别的数字组成，从 0 到 9。'
- en: '`y_test` is composed of 10,000 numbers belonging to 10 classes, from 0 to 9.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_test` 由 10,000 个属于 10 个类别的数字组成，从 0 到 9。'
- en: For each image, we have one label.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每张图像，我们都有一个标签。
- en: Generally speaking, a neural network can have more than one output, and every
    output is a number. In the case of a classification task, such as MNIST, the output
    is a single integer number. In this case, we are particularly lucky, because the
    output value is actually the number we are interested in (for example, 0 means
    the number 0, and 1 means the number 1). Usually, you need to convert the number
    to a label (for example, 0 -> cat, 1 -> dog, and 2 -> duck).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，一个神经网络可以有多个输出，每个输出都是一个数字。在分类任务的情况下，例如 MNIST，输出是一个单独的整数。在这种情况下，我们特别幸运，因为输出值实际上是我们感兴趣的数字（例如，0
    表示数字 0，1 表示数字 1）。通常，你需要将数字转换为标签（例如，0 -> 猫，1 -> 狗，2 -> 鸭）。
- en: To be precise, our CNN will not output one integer result from 0 to 9, but 10
    floating-point numbers, and the position of the highest one will be the label
    (for example, if the output in position 3 is the highest value, then the output
    will be 3). We will discuss this more in the next chapter.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 严格来说，我们的 CNN 不会输出一个从 0 到 9 的整数结果，而是 10 个浮点数，最高值的位置将是标签（例如，如果位置 3 的输出是最高值，则输出将是
    3）。我们将在下一章中进一步讨论这个问题。
- en: 'To better understand MNIST, let''s see five samples from the training dataset
    and five samples from the testing dataset:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解 MNIST，让我们看看训练数据集和测试数据集的五个样本：
- en: '![Figure 4.10 – MNIST training and testing dataset samples. Copyright of Yann
    LeCun and Corinna Cortes](img/Figure_4.10_B16322.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.10 – MNIST 训练和测试数据集样本。版权属于 Yann LeCun 和 Corinna Cortes](img/Figure_4.10_B16322.jpg)'
- en: Figure 4.10 – MNIST training and testing dataset samples. Copyright of Yann
    LeCun and Corinna Cortes
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – MNIST 训练和测试数据集样本。版权属于 Yann LeCun 和 Corinna Cortes
- en: 'As you might suspect, the corresponding labels of those images are as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所料，这些图像的对应标签如下：
- en: 5, 0, 4, 1, and 9 for the training samples (`y_train`)
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练样本（`y_train`）包括 5、0、4、1 和 9。
- en: 7, 2, 1, 0, and 4 for the testing samples (`y_test`)
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试样本（`y_test`）包括 7、2、1、0 和 4。
- en: 'We should also resize the samples so that instead of being in the 0-255 range,
    they are in the 0-1 range, as that helps the neural network to achieve better
    results:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该调整样本的大小，使其范围从 0-255 变为 0-1，因为这有助于神经网络获得更好的结果：
- en: '[PRE9]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: One-hot encoding
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一维编码
- en: The labels cannot be used directly but need to be converted to a vector using
    *one-hot encoding*. As the name implies, you get a vector where only one element
    is hot (for example, its value is `1`) while all the other elements are cold (for
    example, their value is `0`). The hot element represents the position of the label,
    in a vector including all the possible positions. An example should make it easier
    to understand.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 标签不能直接使用，需要使用*one-hot encoding*将其转换为向量。正如其名所示，你得到一个向量，其中只有一个元素是热的（例如，其值为`1`），而所有其他元素都是冷的（例如，它们的值为`0`）。热的元素代表标签的位置，在一个包含所有可能位置的向量中。一个例子应该会使理解更容易。
- en: 'In the case of MINST, you have 10 labels: 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9\.
    The one-hot encoding would therefore use 10 items. This is the encoding of the
    first three items:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在MINST的情况下，你有10个标签：0、1、2、3、4、5、6、7、8和9。因此，one-hot encoding将使用10个项目。这是前三个项目的编码：
- en: '`0 ==> 1 0 0 0 0 0 0 0 0 0`'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0 ==> 1 0 0 0 0 0 0 0 0 0`'
- en: '`1 ==> 0 1 0 0 0 0 0 0 0 0`'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1 ==> 0 1 0 0 0 0 0 0 0 0`'
- en: '`2 ==> 0 0 1 0 0 0 0 0 0 0`'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2 ==> 0 0 1 0 0 0 0 0 0 0`'
- en: 'If you have three labels, dog, cat, and fish, your one-hot encoding would be
    as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有三个标签，狗、猫和鱼，你的one-hot encoding将如下所示：
- en: '`Dog ==> 1 0 0`'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Dog ==> 1 0 0`'
- en: '`Cat ==> 0 1 0`'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Cat ==> 0 1 0`'
- en: '`Fish ==> 0 0 1`'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Fish ==> 0 0 1`'
- en: 'Keras provides a handy function for that, `to_categorical()`, which accepts
    the list of labels to transform and the total number of labels:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Keras提供了一个方便的函数来处理这个问题，`to_categorical()`，它接受要转换的标签列表和标签总数：
- en: '[PRE10]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If your labels are not numeric, you can use `index()` to get access to the
    index of the specified label and use it to call `to_categorical()`:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的标签不是数字，你可以使用`index()`来获取指定标签的索引，并使用它来调用`to_categorical()`：
- en: '[PRE11]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Training and testing datasets
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和测试数据集
- en: The `x` variable contains the images, but why do we have both `x_train` and
    `x_test`?
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`x`变量包含图像，但为什么我们既有`x_train`又有`x_test`？'
- en: 'We will explain everything in detail in the next chapter, but for now let''s
    just say that Keras needs two datasets: one to train the neural network and one
    that is used to tune the hyperparameters and to evaluate the performance of the
    neural network.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章中详细解释一切，但到目前为止，我们只能说Keras需要两个数据集：一个用于训练神经网络，另一个用于调整超参数以及评估神经网络的性能。
- en: It is a bit like having a teacher first explaining things to you, then interrogating
    you, analyzing your answers to explain better what you did not understand.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这有点像有一个老师先向你解释事情，然后质问你，分析你的答案来更好地解释你没有理解的部分。
- en: Defining the model of the neural network
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义神经网络模型
- en: 'Now we want to write our neural network, which we can call our model, and train
    it. We know that it should use convolutions, but we don''t know much more than
    that. Let''s take inspiration from an old but very influential CNN: **LeNet**.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想编写我们的神经网络，我们可以称之为我们的模型，并对其进行训练。我们知道它应该使用卷积，但我们对此了解不多。让我们从一位古老但非常有影响力的CNN：**LeNet**中汲取灵感。
- en: LeNet
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LeNet
- en: LeNet was one of the first CNNs. Dating back to 1998, it's pretty small and
    simple for today's standards. But it is enough for this task.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet是第一个CNN之一。追溯到1998年，对于今天的标准来说，它相当小且简单。但对于这个任务来说已经足够了。
- en: 'This is its architecture:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的架构：
- en: '![Figure 4.11 – LeNet](img/Figure_4.11_B16322.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图4.11 – LeNet](img/Figure_4.11_B16322.jpg)'
- en: Figure 4.11 – LeNet
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11 – LeNet
- en: 'LeNet accepts 32x32 images and has the following layers:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet接受32x32像素的图像，并具有以下层：
- en: The first layer is composed of six 5x5 convolutions, emitting images of 28x28
    pixels.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一层由六个5x5卷积组成，输出28x28像素的图像。
- en: The second layer subsamples the image (for example, computing the average of
    four pixels), emitting images of 14x14 pixels.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二层对图像进行子采样（例如，计算四个像素的平均值），输出14x14像素的图像。
- en: The third layer is composed of 16 5x5 convolutions, emitting images of 10x10
    pixels.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三层由16个5x5卷积组成，输出10x10像素的图像。
- en: The fourth layer subsamples the image (for example, computing the average of
    four pixels), emitting images of 5x5 pixels.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四层对图像进行子采样（例如，计算四个像素的平均值），输出5x5像素的图像。
- en: The fifth layer is a fully connected dense layer (that is, all the neurons of
    the previous layer are connected to all the neurons of this layer) of 120 neurons.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第五层是一个包含120个神经元的全连接密集层（即，前一层中的所有神经元都连接到这一层的所有神经元）。
- en: The sixth layer is a fully connected dense layer of 84 neurons.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第六层是一个包含84个神经元的全连接密集层。
- en: The seventh and last layer is the output, a fully connected dense layer of 10
    neurons, because we need to classify the images into 10 classes, for the 10 digits.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第七个也是最后一个层是输出，一个包含10个神经元的完全连接的密集层，因为我们需要将图像分类为10个类别，对应于10个数字。
- en: We are not trying to recreate LeNet precisely, and our input images are a bit
    smaller, but we will keep it as a reference.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们并不是试图精确地重现LeNet，我们的输入图像略小一些，但我们会将其作为参考。
- en: The code
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'The first step is defining which type of neural network we are creating, which
    in Keras usually is `Sequential`:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定义我们正在创建哪种类型的神经网络，在Keras中通常是`Sequential`：
- en: '[PRE12]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now we can add the first convolutional layer:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以添加第一个卷积层：
- en: '[PRE13]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'It accepts the following parameters:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 它接受以下参数：
- en: Six filters, so that we will get six kernels, which means six convolutions.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 六个过滤器，因此我们将得到六个核，这意味着六个卷积。
- en: Kernel size 5x5.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核大小5x5。
- en: ReLU activation.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReLU激活。
- en: '`same` padding (for example, using black pixels around the image), to not reduce
    too much the size of the image too early, and to be closer to LeNet.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`same`填充（例如，在图像周围使用黑色像素），以避免过早地大幅度减小图像大小，并更接近LeNet。
- en: '`input_shape` contains the shape of the images.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_shape`包含图像的形状。'
- en: 'Then, we add subsampling using `Max Pooling (default size=2x2)`, which emits
    the value of the pixel with the maximum **activation** (for example, with the
    maximum value):'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们添加了使用`最大池化（默认大小=2x2）`的子采样，它输出具有最大**激活**（例如，最大值）的像素值：
- en: '[PRE14]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, we can add the next convolutional layer and the next max pooling layer:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以添加下一个卷积层和下一个最大池化层：
- en: '[PRE15]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And then we can add the dense layers:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以添加密集层：
- en: '[PRE16]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '`Flatten()` is used to flatten the 2D outputs of the convolutional layer into
    a single row of outputs (1D), which is required by the dense layer. Just to be
    clear, for our use case, the input of a convolutional filter is a grayscale image,
    and the output is another grayscale image.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`Flatten()`用于将卷积层的2D输出展平为单行输出（1D），这是密集层所需的。为了清楚起见，对于我们的用例，卷积滤波器的输入是一个灰度图像，输出也是另一个灰度图像。'
- en: The last activation, `softmax`, converts the prediction into a probability,
    for convenience, and the output with the highest probability will represent the
    label that the neural network associates to the image.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的激活，`softmax`，将预测转换为概率，以便方便起见，并且具有最高概率的输出将代表神经网络与图像关联的标签。
- en: 'That''s it: just a few lines of code to build a CNN that can recognize handwritten
    digits. I challenge you to do the same without machine learning!'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样：仅仅几行代码就能构建一个能够识别手写数字的CNN。我挑战你不用机器学习来做同样的事情！
- en: The architecture
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构
- en: Even if our model definition is pretty straightforward, it can be useful to
    visualize it and see whether, for example, the dimensions are as expected.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们的模型定义非常直接，可视化它并查看例如维度是否符合预期也是有用的。
- en: 'Keras has a very useful function for that – `summary()`:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Keras有一个非常有用的函数用于此目的——`summary()`：
- en: '[PRE17]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'And this is the result:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '[PRE18]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This is very interesting. Firstly, we can see that the dimensions of the output
    of the convolutional layers are the same as for LeNet: 28x28 and 10x10\. This
    is not necessarily important; it just means that the network is dimensioned as
    we were expecting.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常有趣。首先，我们可以看到卷积层的输出维度与LeNet相同：28x28和10x10。这并不一定很重要；它只是意味着网络的设计符合我们的预期。
- en: 'We can also see that the order of the layers is correct. What is interesting
    is the third value on each row: the number of parameters. The parameters are the
    variables that the neural network needs to figure out to actually learn something.
    They are the variables of our huge system of equations.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到层的顺序是正确的。有趣的是每行的第三个值：参数数量。参数是神经网络需要确定以实际学习某些东西的变量。它们是我们庞大方程系统中的变量。
- en: 'In the case of a fully connected dense layer, the number of parameters is obtained
    by multiplying the number of neurons of the previous layer, plus one, by the number
    of neurons of the current layer. If you remember the image of a neuron, there
    was one weight for each neuron it was connected to, so it is kind of intuitive
    that each of them is a trainable parameter. In addition, there is a parameter
    for the threshold (bias) of the activation. In the last layer, we therefore have
    the following:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在全连接密集层的情况下，参数的数量是通过将前一层神经元的数量乘以一，再加上当前层神经元的数量来获得的。如果您还记得神经元的图像，每个神经元都有一个与之相连的权重，所以对于每个神经元都是一个可训练的参数来说，这是很直观的。此外，还有一个用于激活阈值（偏置）的参数。因此，在最后一层，我们有以下内容：
- en: 84 inputs ==> 84 weights + 1 bias ==> 85 parameters
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 84个输入 ==> 84个权重 + 1个偏置 ==> 85个参数
- en: 10 outputs
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10个输出
- en: 85 x 10 ==> 850 parameters
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 85 x 10 ==> 850个参数
- en: 'In the case of a convolutional layer, the number of parameters is given by
    the area of the kernel plus one, the bias of the activation. In the first layer,
    we have the following:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积层的情况下，参数的数量由核的面积加一以及激活的偏置给出。在第一层，我们有以下内容：
- en: 5x5 kernel ==> 25 + 1 bias ==> 26 parameters
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5x5核 ==> 25 + 1个偏置 ==> 26个参数
- en: 6 filters
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 6个过滤器
- en: 26 x 6 ==> 156 parameters
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 26 x 6 ==> 156个参数
- en: As you can see, our network has 61,706 parameters. While this might seem like
    a lot, it's not uncommon for a neural network to have millions of them. How do
    they impact the training? As a first approximation, we can say that having more
    parameters enables our network to learn more things, but at the same time, it
    slows it down and increases the size of the model and the amount of memory it
    uses. Don't become obsessed with the number of parameters, because not all of
    them are created equal, but keep an eye on them, in case there is some layer that's
    using too many. You can see that dense layers tend to use many parameters, and
    in our case, they hold more than 95% of the parameters.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们的网络有61,706个参数。虽然这看起来可能很多，但对于神经网络来说，拥有数百万个参数并不罕见。它们如何影响训练？作为一个初步的近似，我们可以这样说，拥有更多的参数使我们的网络能够学习更多的事物，但同时也减慢了它的速度，增加了模型的大小以及它使用的内存量。不要对参数的数量过于着迷，因为并非所有参数都是相同的，但要注意它们，以防某些层使用了过多的参数。您可以看到，密集层倾向于使用许多参数，在我们的例子中，它们占据了超过95%的参数。
- en: Training a neural network
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练神经网络
- en: Now that we have our neural network, we need to train it. We will talk more
    about training in the next chapter, but as the name suggests, training is the
    phase where the neural network *studies* the training dataset and actually learns
    it. As for how well it learns – that depends.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了我们的神经网络，我们需要对其进行训练。我们将在下一章中更多地讨论训练，但正如其名所示，训练是神经网络*学习*训练数据集并真正学习它的阶段。至于它学习得有多好——这取决于。
- en: 'For the sake of quickly explaining the concepts, we will do an improper comparison
    with a student trying to learn a book for an exam:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速解释概念，我们将与学生试图为了考试学习一本书的不当比较：
- en: The book is the training dataset that the student needs to learn.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这本书是学生需要学习的学习数据集。
- en: Every time that the student reads the whole book is called an epoch. A student
    might want to read the book more than once, and it is very common for neural networks
    to do the same and train for more than one epoch.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次学生阅读整本书都称为一个epoch。学生可能想要多次阅读这本书，对于神经网络来说，做同样的事情并训练超过一个epoch是非常常见的。
- en: The optimizer is like somebody who asks the student questions from an exercise
    book (the validation dataset; though, in our example, we are going to use the
    test dataset for validation) to see how well the student is learning. One key
    difference is that the neural network does not learn from the validation dataset.
    We will see in the next chapter why this is very good.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化器就像一个人从练习册（验证数据集；尽管在我们的例子中，我们将使用测试数据集进行验证）中提问学生，以查看学生学习得有多好。一个关键的区别是，神经网络不会从验证数据集中学习。我们将在下一章中看到为什么这是非常好的。
- en: To track their progress and learn in less time, the student can ask the optimizer
    to ask questions after a certain number of pages; that number of pages would be
    the batch size.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了跟踪他们的进度并在更短的时间内学习，学生可以要求优化器在阅读一定数量的页面后提问；这个页数就是批大小。
- en: 'The first thing to do is to configure the model, using `compile()`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 首件事是配置模型，使用`compile()`：
- en: '[PRE19]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Keras has a variety of loss functions that you can use. `loss` is basically
    a measure of how distant the result of your model is from the ideal output. For
    classification tasks, we can use `categorical_crossentropy` as a loss function.
    `optimizer` is the algorithm used to train the neural network. If you imagine
    the neural network as a giant system of equations, the optimizer is the one that
    figures out how to change the parameters to improve the result. We will use `metrics`
    is just some values computed during the training, but they are not used by the
    optimizer; they are just provided to you as a reference.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Keras有多种损失函数可供使用。`loss`基本上是衡量你的模型结果与理想输出之间距离的度量。对于分类任务，我们可以使用`categorical_crossentropy`作为损失函数。`optimizer`是用于训练神经网络的算法。如果你把神经网络想象成一个巨大的方程组系统，那么优化器就是那个找出如何改变参数以改进结果的人。我们将使用`metrics`，这只是训练期间计算的一些值，但它们不是由优化器使用的；它们只是作为参考提供给你。
- en: 'We can now run the training, which might take a couple of minutes, and it will
    print the progress that is being made:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以开始训练，这可能需要几分钟，并且会打印出正在进行的进度：
- en: '[PRE20]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We need to provide several parameters:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要提供几个参数：
- en: '`x_train`: The training images.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_train`：训练图像。'
- en: '`y_train`: The training labels.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_train`：训练标签。'
- en: '`batch_size`: The default is 32, and usually it''s worth trying powers of 2,
    from 16 to 256; the batch size affects both speed and accuracy.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size`：默认值是32，通常尝试从16到256的2的幂次方是值得的；批处理大小会影响速度和准确性。'
- en: '`epochs`: The number of times that the CNN will go through the dataset.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epochs`：CNN将遍历数据集的次数。'
- en: '`validation_data`: As we''ve already said, we are using the test dataset for
    validation.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`validation_data`：正如我们之前所说的，我们正在使用测试数据集进行验证。'
- en: '`shuffle`: If we want to shuffle the training data before each epoch, which
    usually we want to.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shuffle`：如果我们想在每个epoch之前打乱训练数据，这通常是我们想要的。'
- en: 'The result of the training is `history`, which contains a lot of useful information:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的结果是`history`，它包含了很多有用的信息：
- en: '[PRE21]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We are talking about minimum and maximum because these values are measured during
    each epoch, and do not necessarily progress always toward an improvement.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在讨论最小值和最大值，因为这些值是在每个epoch期间测量的，并不一定总是朝着改进的方向前进。
- en: 'Let''s go through what we have here:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们这里有什么：
- en: The minimum loss is a measure of how close we come to the ideal output in the
    training dataset, or how well the neural network learned the training dataset.
    In general, we want this value to be as small as possible.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小损失是衡量我们接近训练数据集中理想输出的程度，或者神经网络学习训练数据集的好坏的度量。一般来说，我们希望这个值尽可能小。
- en: The minimum validation loss is how close we come to the ideal output in the
    validation dataset, or how well the neural network can do with the validation
    dataset after training. This is probably the most important value, as it is what
    we are trying to minimize, so we want this value to be as small as possible.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小验证损失是我们接近验证数据集中理想输出的程度，或者神经网络在训练后使用验证数据集所能做到的多好。这可能是最重要的值，因为这是我们试图最小化的，所以我们希望这个值尽可能小。
- en: The maximum accuracy is the maximum percentage of correct answers (predictions)
    that our CNN can give using the training dataset. For the student example from
    earlier, it would tell them how well they had memorized the book. Knowing the
    book by heart is not bad by itself – it is actually desirable – but the goal is
    not to memorize the book, but to learn from it. While we expect this value to
    be as high as possible, it can be misleading.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大准确率是我们CNN使用训练数据集所能给出的最大正确答案（预测）百分比。对于之前的学生示例，它将告诉他们他们记住了书本的程度。仅仅记住书本本身并不坏——实际上这是可取的——但目标不是记住书本，而是从中学习。虽然我们希望这个值尽可能高，但它可能会误导。
- en: The maximum validation accuracy is the maximum percentage of correct answers
    (predictions) that our CNN can give using the validation dataset. For the student
    example from earlier, it would tell them how well they had really learned the
    content of the book, so that they can answer questions that might not be present
    in the book. This will be an indication of how well our neural network can perform
    in real life.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大验证准确率是我们CNN使用验证数据集所能给出的最大正确答案（预测）百分比。对于之前的学生示例，它将告诉他们他们实际上学到了书本内容的程度，以便他们可以回答书中可能没有的问题。这将是我们神经网络在实际生活中表现如何的一个指标。
- en: 'This is the result of our CNN:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的CNN的结果：
- en: '[PRE22]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: On your computer, it will probably be slightly different, and in fact it should
    change a bit every time that you run it.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的电脑上，它可能略有不同，实际上每次运行时都应该有所变化。
- en: We can see that the losses are close to zero, which is good. Both the accuracy
    and the validation accuracy are almost 98.5%, which in general is very good.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到损失接近零，这是好的。准确率和验证准确率几乎都是98.5%，这在一般情况下是非常好的。
- en: 'We can also plot the evolution over time of these parameters:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以绘制这些参数随时间演变的图表：
- en: '[PRE23]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This is the result:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 4.12 – Plot of validation and accuracy over time for MNIST](img/Figure_4.12_B16322.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图4.12 – MNIST随时间变化的验证和准确率图](img/Figure_4.12_B16322.jpg)'
- en: Figure 4.12 – Plot of validation and accuracy over time for MNIST
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 – MNIST随时间变化的验证和准确率图
- en: Both the accuracy and the loss are very good after the first epoch and keep
    improving.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个epoch之后，准确率和损失都非常良好，并且持续改进。
- en: So far so good. Maybe you think that this was easy. But MNIST is a simple dataset.
    Let's try CIFAR-10.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止一切顺利。也许你认为这很简单。但MNIST是一个简单的数据集。让我们尝试CIFAR-10。
- en: CIFAR-10
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CIFAR-10
- en: 'To use CIFAR-10, we can just ask Keras to use a different dataset:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用CIFAR-10，我们只需请求Keras使用不同的数据集：
- en: '[PRE24]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'CIFAR-10 is a more difficult dataset. It contains 32x32 RGB images, containing
    10 types of objects:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10是一个更困难的数据集。它包含32x32的RGB图像，包含10种类型的对象：
- en: '[PRE25]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: It looks similar to MNIST.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来与MNIST相似。
- en: 'In the code on GitHub, to use CIFAR 10, you can simply change the `use_mnist`
    variable to `False`:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitHub上的代码中，要使用CIFAR 10，你只需将`use_mnist`变量更改为`False`：
- en: '[PRE26]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You don''t need to change anything else in the code, apart from removing the
    `reshape()` call because CIFAR-10 uses RGB images and, as a result, it already
    has three dimensions: width, height, and channels. Keras will adapt the model
    to the different dimensions and channels, and the neural network will just learn
    a new dataset!'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要在代码中做任何其他更改，除了移除`reshape()`调用，因为CIFAR-10使用RGB图像，因此它已经具有三个维度：宽度、高度和通道。Keras将适应不同的维度和通道，神经网络将学习一个新的数据集！
- en: 'Let''s see the new model:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看新的模型：
- en: '[PRE27]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The model is a bit bigger, because the images are slightly bigger and in RGB
    format. Let''s see how it performs:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 模型稍微大一些，因为图像稍微大一些，并且是RGB格式。让我们看看它的表现：
- en: '[PRE28]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This is not very good: the loss is high and the validation accuracy is only
    around 55%.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是很好：损失很高，验证准确率只有大约55%。
- en: 'The next graph is quite important, and you will see it many times, so please
    take some time to familiarize yourself with it. The following graph shows the
    evolution of the loss (we use mean squared error) and of the accuracy for each
    epoch, over time, for our model. On the *X* axis, you see the number of epochs,
    and then there are four lines:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个图表非常重要，你将多次看到它，所以请花些时间熟悉一下。下面的图表显示了我们的模型在时间上每个epoch的损失（我们使用均方误差）和准确率的演变。在*X*轴上，你可以看到epoch的数量，然后有四条线：
- en: '`T loss`: The training loss'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`T loss`: 训练损失'
- en: '`V loss`: The validation loss'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`V loss`: 验证损失'
- en: '`T acc`: The training accuracy'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`T acc`: 训练准确率'
- en: '`V acc`: The validation accuracy:'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`V acc`: 验证准确率：'
- en: '![Figure 4.13 – Plot of validation and accuracy over time for CIFAR-10](img/Figure_4.13_B16322.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![图4.13 – CIFAR-10随时间变化的验证和准确率图](img/Figure_4.13_B16322.jpg)'
- en: Figure 4.13 – Plot of validation and accuracy over time for CIFAR-10
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13 – CIFAR-10随时间变化的验证和准确率图
- en: We can see that the loss is going down, but it has not reached a minimum yet,
    so it probably means more epochs can be beneficial. The accuracy is low and stays
    low, probably because the model does not have enough parameters.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到损失正在下降，但还没有达到最小值，所以这可能意味着更多的epochs会有所帮助。准确率很低，并且保持低水平，可能是因为模型参数不足。
- en: 'Let''s see the result with 12 epochs:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看12个epochs的结果：
- en: '[PRE29]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The good news: the loss went down and the accuracy improved. The bad news:
    the validation loss and validation accuracy did not improve. In practice, our
    network is learning the training dataset by heart, but it cannot generalize, and
    therefore it does not perform well on the validation dataset.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息：损失下降了，准确率提高了。坏消息：验证损失和验证准确率没有提高。在实践中，我们的网络已经通过心算学习了训练数据集，但它不能泛化，因此它在验证数据集上的表现不佳。
- en: 'Let''s try to also significantly increase the size of the network:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试显著增加网络的大小：
- en: '[PRE30]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'That gives us this new model:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们带来了这个新的模型：
- en: '[PRE31]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Wow: we jumped from 83,000 to 5,000,000 parameters! That first dense layer
    is getting big...'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 哇：我们从83,000个参数跳到了5,000,000个参数！第一个密集层变得很大...
- en: 'Let''s see whether we can see some improvements:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看是否可以看到一些改进：
- en: '[PRE32]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now all the values have improved; however, while the training accuracy is now
    above 90%, the validation accuracy is just 65%:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 现在所有值都有所提高；然而，尽管训练准确率现在超过了90%，但验证准确率仅为65%：
- en: '![Figure 4.14 – Plot of validation and accuracy over time for CIFAR-10](img/Figure_4.14_B16322.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![图4.14 – CIFAR-10验证和准确率随时间的变化图](img/Figure_4.14_B16322.jpg)'
- en: Figure 4.14 – Plot of validation and accuracy over time for CIFAR-10
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14 – CIFAR-10验证和准确率随时间的变化图
- en: 'We see something a bit worrying: while the training loss goes down over time,
    the validation loss goes up. This situation is called overfitting, and it means
    that the network is not good at generalizing. It also means that we used way too
    many epochs for nothing.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到一些令人担忧的情况：虽然训练损失随时间下降，但验证损失上升。这种情况被称为过拟合，这意味着网络不擅长泛化。这也意味着我们使用了过多的epoch而没有效果。
- en: 'Not only that, but if we saved the model at the end, we would not be saving
    the best one. If you are wondering whether there is a way to save the best model
    (for example, with the lowest validation loss), then the answer is yes – Keras
    can do it:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅于此，如果我们最后保存了模型，我们也不会保存最佳模型。如果你想知道是否有保存最佳模型（例如，只有当验证损失降低时才保存）的方法，那么答案是肯定的——Keras可以做到：
- en: '[PRE33]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Here we are telling Keras to do the following:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们告诉Keras执行以下操作：
- en: Save the model with the name `'cifar-10.h5'`.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型以名称`'cifar-10.h5'`保存。
- en: Monitor the validation loss.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控验证损失。
- en: Select the model based on the minimum loss (for example, save only if the validation
    loss decreases).
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据最小损失选择模型（例如，只有当验证损失降低时才保存）。
- en: Save only the best model.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只保存最佳模型。
- en: 'You can pass the `checkpoint` object to `model.fit()`:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将`checkpoint`对象传递给`model.fit()`：
- en: '[PRE34]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This helps, but the model is not good enough. We need something radically better.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 这有所帮助，但模型还不够好。我们需要一个根本性的改进。
- en: 'In the next chapter, we will learn many things that will hopefully help us
    to get some better results. Plus, in [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142),
    *Improving Your Neural Network*, we will apply this knowledge, and more, to improve
    the results. Now, if you want, you can spend some time trying to tune and improve
    the network: you can change its size, add filters and layers, and see how it performs.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习许多有望帮助我们获得更好结果的东西。此外，在[*第6章*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142)，*提高你的神经网络*中，我们将应用这些知识，以及更多，来提高结果。现在，如果你愿意，你可以花些时间尝试调整和改进网络：你可以改变其大小，添加滤波器和层，并看看它的表现如何。
- en: Summary
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This has been a dense chapter! We discussed machine learning in general and
    deep learning in particular. We talked about neural networks and how convolutions
    can be used to make faster and more accurate neural networks, leveraging the knowledge
    of pixel proximity. We learned about weights, bias, and parameters, and how the
    goal of the training phase is to optimize all these parameters to learn the task
    at hand.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经是一个内容丰富的章节！我们讨论了机器学习的一般概念和深度学习的特别之处。我们谈论了神经网络以及如何利用像素邻近的知识来使用卷积来创建更快、更准确的神经网络。我们学习了权重、偏差和参数，以及训练阶段的目标是优化所有这些参数以学习当前的任务。
- en: After verifying the installation of Keras and TensorFlow, we described MNIST,
    and we instructed Keras to build a network similar to LeNet, to achieve more than
    98% accuracy on this dataset, meaning that we can now easily recognize handwritten
    digits. Then, we saw that the same model does not perform well in CIFAR-10, despite
    increasing the number of epochs and the size of the network.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证了Keras和TensorFlow的安装后，我们介绍了MNIST，并指导Keras构建一个类似于LeNet的网络，以在数据集上实现超过98%的准确率，这意味着我们现在可以轻松地识别手写数字。然后，我们看到同样的模型在CIFAR-10上表现不佳，尽管增加了epoch的数量和网络的大小。
- en: In the next chapter, we will study in depth many of the concepts that we introduced
    here, with the final goal, to be completed by [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142),
    *Improving Your Neural Network*, of learning how to train a neural network.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入研究我们在这里介绍的大多数概念，最终目标是完成[*第6章*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142)，*提高你的神经网络*，学习如何训练神经网络。
- en: Questions
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'After reading this chapter, you should be able to answer the following questions:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章后，你应该能够回答以下问题：
- en: What is a perceptron?
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是感知器？
- en: Can you name an optimizer that tends to perform well in many tasks?
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能说出一个在许多任务中表现良好的优化器吗？
- en: What is a convolution?
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是卷积？
- en: What is a CNN?
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是CNN？
- en: What is a dense layer?
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是密集层？
- en: What does the `Flatten()` layer do?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Flatten()`层做什么？'
- en: Which backend have we been using for Keras?
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们一直使用哪个后端进行Keras开发？
- en: What is the name of one of the first CNNs?
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一批卷积神经网络（CNN）的名字是什么？
- en: Further reading
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The original LeNet paper: [http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeNet原始论文：[http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)
- en: 'MNIST: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'MNIST: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
- en: 'CNNs: [https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'CNNs: [https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)'
