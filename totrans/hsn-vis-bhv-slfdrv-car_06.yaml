- en: '*Chapter 4*: Deep Learning with Neural Networks'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is an introduction to neural networks with Keras. If you have already
    worked with MNIST or CIFAR-10 image classification datasets, feel free to skip
    it. But if you have never trained a neural network, this chapter might have some
    surprises in store for you.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is quite practical, to give you very quickly something to play
    with, and we will skip as much theory as reasonably possible and learn how to
    recognize handwritten numbers (composed of one single digit) with high precision.
    The theory behind what we do here, and more, will be covered in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks and their parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolutional neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras, a deep learning framework
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The MNIST dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to build and train a neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The CIFAR-10 dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For the instructions and code in this chapter, you need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Python 3.7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matplotlib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The OpenCV-Python module
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A GPU (recommended)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code for the book can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter4](https://github.com/PacktPublishing/Hands-On-Vision-and-Behavior-for-Self-Driving-Cars/tree/master/Chapter4)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Code in Action videos for this chapter can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bit.ly/3jfOoWi](https://bit.ly/3jfOoWi)'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding machine learning and neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: According to Wikipedia, **machine learning** is *"the study of computer algorithms
    that improve automatically through experience*.*"*
  prefs: []
  type: TYPE_NORMAL
- en: 'What that means in practice, at least for what concerns us, is that the algorithm
    itself is only moderately important, and what is critical is the data that we
    feed to this algorithm so that it can learn: we need to **train** our algorithm.
    Putting it in another way, we can use the same algorithm in many different situations
    as long as we provide the proper data for the task at hand.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, during this chapter, we will develop a neural network that is able
    to recognize handwritten numbers between 0 and 9; most likely, the exact same
    neural network could be used to recognize 10 letters, and with trivial modifications,
    it could recognize all letters or even different objects. In fact, we will reuse
    it basically as it is to recognize 10 objects.
  prefs: []
  type: TYPE_NORMAL
- en: This is totally different from *normal programming*, where different tasks usually
    require different code; to improve a result, we need to improve the code, and
    we might not need data at all for an algorithm to be usable (with real data).
  prefs: []
  type: TYPE_NORMAL
- en: 'That said, this does not mean that the result of a neural network is always
    good so long as good data is fed to it: difficult tasks require more advanced
    neural networks to perform well.'
  prefs: []
  type: TYPE_NORMAL
- en: To be clear, while the algorithm (meaning the neural network model) is less
    important than the code in traditional programming, it is still important if you
    want to get very good results. In fact, with the wrong architecture, your neural
    network might not be able to learn at all.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks are only one of the tools that you can use to develop machine
    learning models, but this is what we will focus on. The accuracy of deep learning
    is usually quite high, and you might find that applications where less-accurate
    machine learning techniques are used are heavily constrained by the amount of
    data and the cost of processing it.
  prefs: []
  type: TYPE_NORMAL
- en: '**Deep learning** can be considered a subset of machine learning, where the
    computation is performed by several computation layers, which is the *deep* part
    of the name. From a practical point of view, deep learning is achieved using neural
    networks.'
  prefs: []
  type: TYPE_NORMAL
- en: 'That brings us to the question: what exactly is a neural network?'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Neural networks are somewhat inspired by our brains: a neuron in our brain
    is a "computational node" that is connected to other neurons. When performing
    a computation, each of our brain''s neurons "senses" the excited state of the
    neurons that it is connected to and uses these external states to compute its
    own state. A neuron in a neural network (a perceptron) basically does the same,
    but here is more or less where the similarities end. To be clear, a perceptron
    is not a simulation of a neuron, but it is just inspired by it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a mini neural network, with its neurons:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – A neural network](img/Figure_4.1_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – A neural network
  prefs: []
  type: TYPE_NORMAL
- en: The first layer is the input (for example, the pixels of your image) and the
    output layer is the result (for example, your classification). The hidden layer
    is where the computation happens. Normally, you have more hidden layers, not just
    one. Every input can also be called a feature, and in the case of an RGB image,
    a feature is usually a single channel of a pixel.
  prefs: []
  type: TYPE_NORMAL
- en: 'In feedforward neural networks, the neurons of a layer are connected only to
    neurons of the layer before and of the following layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – A neural network](img/Figure_4.2_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – A neural network
  prefs: []
  type: TYPE_NORMAL
- en: But what exactly is a neuron?
  prefs: []
  type: TYPE_NORMAL
- en: Neurons
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A neuron is a computation node that produces an output given some input. As
    for what these inputs and outputs are – well, it depends. We will come back to
    this point later.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a representation of the typical neuron of a neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Schematic of a single neuron of a neural network. ©2016 Wikimedia
    Commons](img/Figure_4.3_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – Schematic of a single neuron of a neural network. ©2016 Wikimedia
    Commons
  prefs: []
  type: TYPE_NORMAL
- en: 'This needs some explanation. The computation performed by a neuron can be divided
    into two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The transfer function computes the sum of every input multiplied by its weight
    (just a number); what this means is that the state of the neuron depends on the
    state of its input neurons, but different neurons provide a different contribution.
    This is just a linear operation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/Formula_04_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The activation function is applied to the result of the transfer function, and
    it should be a **non-linear** operation, typically with a threshold. A function
    that we will use often, because of its performance, is called **Rectified Linear
    Unit (ReLU)**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Two activation functions: Softplus and ReLU](img/Figure_4.4_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.4 – Two activation functions: Softplus and ReLU'
  prefs: []
  type: TYPE_NORMAL
- en: There is usually also a **bias**, a value used to shift the activation function.
  prefs: []
  type: TYPE_NORMAL
- en: The combination of a linear function with a non-linear function is non-linear,
    while the combination of two linear functions is still linear. This is very important
    because it means that if the activation was linear, then the output of the neurons
    will be linear, and the combination of different layers would be linear as well.
    So, the whole neural network would be linear and therefore equivalent to a single
    layer.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing a non-linear operation in the activation allows a network to compute
    non-linear functions that become more and more complex as the number of layers
    grows. This is one of the reasons why the most sophisticated neural networks can
    literally have hundreds of layers.
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The bias and the weights are called **parameters**, because they are not fixed
    but need to change based on the task at hand. We do this during the **training**
    phase. To be clear, the whole purpose of the training phase is to find the best
    possible value for these parameters for our task.
  prefs: []
  type: TYPE_NORMAL
- en: This has profound implications, as it means that the same neural network, with
    different parameters, can solve different problems – very different problems.
    The trick, of course, is to find the best values (or one approximation) for these
    parameters. If you are wondering how many parameters a typical neural network
    can have, the answer is millions. Luckily, this process, called training, can
    be automated.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative way to imagine a neural network is to consider it as a gigantic
    system of equations, and the training phase is an attempt to find an approximate
    solution to it.
  prefs: []
  type: TYPE_NORMAL
- en: The success of deep learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You've probably noticed that deep learning has seen explosive growth in the
    past few years, but neural networks are really nothing new. I remember trying
    to write a neural network (and failing miserably!) more than 20 years ago, after
    reading a book about it. In fact, they date back to 1965, with some theories being
    even 20 years older than that.
  prefs: []
  type: TYPE_NORMAL
- en: Many years ago, they were dismissed basically as a curiosity, as they were too
    computationally demanding to be practical.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, fast forward some decades, and deep learning is the new black, thanks
    to some critical advances:'
  prefs: []
  type: TYPE_NORMAL
- en: Computers are much faster and have much more RAM available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPUs can be used to make computations even faster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many datasets easily available on the internet to train neural networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are now plenty of tutorials and online courses dedicated to deep learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are several good open source libraries for neural networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architectures have become better and more efficient.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's the perfect storm to make neural networks much more appealing, and there
    are many applications that seem to be waiting for deep learning, such as voice
    assistants and, of course, self-driving cars.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a special type of neural network that is particularly good at understanding
    the content of images, and we will pay great attention to them: convolutional
    neural networks.'
  prefs: []
  type: TYPE_NORMAL
- en: Learning about convolutional neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you look at a classical neural network, you can see that the first layer
    is composed of inputs, standing on a line. This is not only a graphical representation:
    for a classical neural network, an input is an input, and it should be independent
    of the other ones. This is probably fine if you are trying to predict the price
    of an apartment based on size, ZIP code, and floor number, but it does not seem
    optimal for an image, where pixels have neighbors and it seems intuitive that
    keeping this proximity information is important.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Convolutional Neural Networks** (**CNNs**) solve exactly this problem, and
    it turns out that not only can they process images efficiently, but they can also
    be used with success for natural language processing.'
  prefs: []
  type: TYPE_NORMAL
- en: A CNN is a neural network that has at least one convolutional layer, which is
    inspired by the visual cortex of animals, where individual neurons respond only
    to stimuli in a small area of the field of vision. Let's see what convolutions
    really are.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Convolutions are based on the concept of the **kernel**, a matrix that you
    apply to some pixels to get a single new pixel. Kernels can be used for edge detection
    or to apply filters to an image, and you normally have the option to define your
    kernel in image processing programs, if you wish to do so. The following is a
    3x3 identity kernel that replicates an image as it is, and we are applying it
    to a small image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Part of an image, a 3x3 identity kernel, and the result](img/Figure_4.5_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 – Part of an image, a 3x3 identity kernel, and the result
  prefs: []
  type: TYPE_NORMAL
- en: 'Just imagine putting a pixel behind each element of the kernel and multiplying
    them together, then adding the results to get the value of the new pixel; clearly,
    you would get a zero for each pixel except the central one, which would be unchanged.
    This kernel preserves the value of the pixel in the middle and discards all the
    others. If you slide this convolution kernel over the whole picture, you will
    get the original image back:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Identity convolution – just copying an image](img/Figure_4.6_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 – Identity convolution – just copying an image
  prefs: []
  type: TYPE_NORMAL
- en: You can see that as the convolution kernel slides over the image, the pixels
    are replicated unchanged. You can also see that the resolution is reduced, as
    we use *valid* padding.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is another example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Part of an image, a 3x3 kernel, and the result](img/Figure_4.7_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 – Part of an image, a 3x3 kernel, and the result
  prefs: []
  type: TYPE_NORMAL
- en: 'Other kernels can be more interesting than the identity kernel. The following
    kernel (on the left) can detect edges, as seen on the right:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 – Kernel detecting edges](img/Figure_4.8_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 – Kernel detecting edges
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are curious about kernels, please go ahead with OpenCV and have some
    fun:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Kernels don't need to be 3x3; they can be bigger.
  prefs: []
  type: TYPE_NORMAL
- en: If you imagine starting with the first pixel of the image, you might ask what
    happens then, as there are no pixels above it or to its left. If you position
    the top-left corner of a kernel on the top-left pixel of an image, you will lose
    one pixel on each side of the image, because you can think of it as the kernel
    *emitting a pixe*l from the center. This is not always a problem, because when
    designing a neural network, you might want the image to get smaller and smaller
    after each layer.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative is to use padding – for example, pretending that there are black
    pixels around the image.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that you don't need to find the values of the kernels; the
    CNN will find them for you during the training phase.
  prefs: []
  type: TYPE_NORMAL
- en: Why are convolutions so great?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Convolutions have some great advantages. As we have already said, they preserve
    the proximity of pixels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9 – A convolution layer, in yellow, versus a dense layer, in green](img/Figure_4.9_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 – A convolution layer, in yellow, versus a dense layer, in green
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the previous figure, the convolution knows the topology
    of the image and can know, for example, that the pixel with the number 43 is right
    next to the pixel with the number 42, is below the pixel with the number 33, and
    is above the pixel with the number 53\. The dense layer in the same figure does
    not have this information and might think that the pixel with 43 and the pixel
    with 51 are close to each other. Not only that, but it does not even know whether
    the resolution is 3x3, 9x1, or 1x9\. Intuitively knowing the topology of pixels
    is an advantage.
  prefs: []
  type: TYPE_NORMAL
- en: An additional important advantage is that they are computationally efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Another great characteristic of convolutions is that they are very good at recognizing
    patterns, such as diagonal lines or circles. You might say that they can only
    do so at a small scale, which is true, but you can combine multiple convolutions
    to detect patterns at different scales, and they can be surprisingly good at that.
  prefs: []
  type: TYPE_NORMAL
- en: They are also able to detect patterns in different parts of an image.
  prefs: []
  type: TYPE_NORMAL
- en: All these characteristics make them great to work with images, and it is not
    surprising that they are used so much for object detection.
  prefs: []
  type: TYPE_NORMAL
- en: Enough theory for now. Let's get our hands dirty and write our first neural
    network.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Keras and TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many libraries dedicated to deep learning, and we will be using Keras,
    a Python library that uses multiple backends; we will be using TensorFlow as a
    backend. While the code is specific to Keras, the principles can apply to any
    other libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before starting, you need to install at least TensorFlow and Keras, using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We are using TensorFlow 2.2, which has integrated GPU support, but if you are
    using TensorFlow version 1.15 or older, you need to install a separate package
    to take advantage of a GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: I would recommend using the most recent versions of both TensorFlow and Keras.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before starting, let''s make sure that everything is in order. You probably
    want to use a GPU, to speed up training. Unfortunately, getting TensorFlow to
    use your GPU is not necessarily straightforward; for example, it is very picky
    with the version of CUDA: if it says CUDA 10.1, it really means it – it is not
    going to work with 10.0 or with 10.2\. Hopefully, this will not affect your games
    much.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To print the version of TensorFlow, you can use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'On my computer, that prints this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To check the GPU support, you can use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: If everything is fine, you should see `CUDA ON`, meaning that your version of
    TensorFlow has been built with CUDA support, and `GPU ON`, meaning that TensorFlow
    is able to use your GPU.
  prefs: []
  type: TYPE_NORMAL
- en: If your GPU is not NVIDIA, it might require some more work, but it should be
    possible to configure TensorFlow to run on AMD graphics cards, using ROCm.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have correctly installed all the software, it is time to use it
    on our first neural network. Our first task will be to recognize handwritten digits,
    using a dataset called MNIST.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting MNIST handwritten digits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you design a neural network, you usually start with a problem that you
    want to solve, and you might start with a design that you know performs well on
    a similar task. You need a dataset, basically as big a dataset as you can get.
    There is not really a rule on that, but we can say that the minimum to train your
    own neural network might be something around 3,000 images, but nowadays world-class
    CNNs are trained using literally millions of pictures.
  prefs: []
  type: TYPE_NORMAL
- en: Our first task is to detect handwritten digits, a classical task for CNNs. There
    is a dataset for that, the MNIST dataset (copyright of Yann LeCun and Corinna
    Cortes), and it is conveniently present in Keras. MNIST detection is an easy task,
    so we will achieve good results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Loading the dataset is easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`reshape` just reinterprets the shape from (60000, 28, 28) to (60000, 28, 28,
    1), because Keras needs four dimensions.'
  prefs: []
  type: TYPE_NORMAL
- en: What did we just load?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `load_data()` method returns four things:'
  prefs: []
  type: TYPE_NORMAL
- en: '`x_train`: The images used for training'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y_train`: The labels used for training (that is, the correct numbers for each
    of the handwritten digits)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x_test`: The images used for testing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y_test`: The labels used for testing (that is, the correct numbers for each
    of the handwritten digits)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training samples and labels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s print the dimensions of the training samples (`x`) and of the labels
    (`y`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'It should print something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The x variable represents the input for the CNN, which means that x contains
    all our images divided into two sets, one for training and one for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '`x_train` contains 60,000 images intended for training, each with 28x28 pixels
    and in grayscale (one channel).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x_test` contains 10,000 images intended for testing, each with 28x28 pixels
    and in grayscale (one channel).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, the training and testing images have the same resolution and
    the same number of channels.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `y` variable represents the expected output of the CNN, also called the
    label. For many datasets, somebody manually labels all the images to say what
    they are. If the dataset is artificial, labeling might be automated:'
  prefs: []
  type: TYPE_NORMAL
- en: '`y_train` is composed of 60,000 numbers belonging to 10 classes, from 0 to
    9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y_test` is composed of 10,000 numbers belonging to 10 classes, from 0 to 9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each image, we have one label.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, a neural network can have more than one output, and every
    output is a number. In the case of a classification task, such as MNIST, the output
    is a single integer number. In this case, we are particularly lucky, because the
    output value is actually the number we are interested in (for example, 0 means
    the number 0, and 1 means the number 1). Usually, you need to convert the number
    to a label (for example, 0 -> cat, 1 -> dog, and 2 -> duck).
  prefs: []
  type: TYPE_NORMAL
- en: To be precise, our CNN will not output one integer result from 0 to 9, but 10
    floating-point numbers, and the position of the highest one will be the label
    (for example, if the output in position 3 is the highest value, then the output
    will be 3). We will discuss this more in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand MNIST, let''s see five samples from the training dataset
    and five samples from the testing dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10 – MNIST training and testing dataset samples. Copyright of Yann
    LeCun and Corinna Cortes](img/Figure_4.10_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.10 – MNIST training and testing dataset samples. Copyright of Yann
    LeCun and Corinna Cortes
  prefs: []
  type: TYPE_NORMAL
- en: 'As you might suspect, the corresponding labels of those images are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 5, 0, 4, 1, and 9 for the training samples (`y_train`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7, 2, 1, 0, and 4 for the testing samples (`y_test`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We should also resize the samples so that instead of being in the 0-255 range,
    they are in the 0-1 range, as that helps the neural network to achieve better
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: One-hot encoding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The labels cannot be used directly but need to be converted to a vector using
    *one-hot encoding*. As the name implies, you get a vector where only one element
    is hot (for example, its value is `1`) while all the other elements are cold (for
    example, their value is `0`). The hot element represents the position of the label,
    in a vector including all the possible positions. An example should make it easier
    to understand.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of MINST, you have 10 labels: 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9\.
    The one-hot encoding would therefore use 10 items. This is the encoding of the
    first three items:'
  prefs: []
  type: TYPE_NORMAL
- en: '`0 ==> 1 0 0 0 0 0 0 0 0 0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`1 ==> 0 1 0 0 0 0 0 0 0 0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2 ==> 0 0 1 0 0 0 0 0 0 0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you have three labels, dog, cat, and fish, your one-hot encoding would be
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Dog ==> 1 0 0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Cat ==> 0 1 0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Fish ==> 0 0 1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keras provides a handy function for that, `to_categorical()`, which accepts
    the list of labels to transform and the total number of labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If your labels are not numeric, you can use `index()` to get access to the
    index of the specified label and use it to call `to_categorical()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Training and testing datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `x` variable contains the images, but why do we have both `x_train` and
    `x_test`?
  prefs: []
  type: TYPE_NORMAL
- en: 'We will explain everything in detail in the next chapter, but for now let''s
    just say that Keras needs two datasets: one to train the neural network and one
    that is used to tune the hyperparameters and to evaluate the performance of the
    neural network.'
  prefs: []
  type: TYPE_NORMAL
- en: It is a bit like having a teacher first explaining things to you, then interrogating
    you, analyzing your answers to explain better what you did not understand.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the model of the neural network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we want to write our neural network, which we can call our model, and train
    it. We know that it should use convolutions, but we don''t know much more than
    that. Let''s take inspiration from an old but very influential CNN: **LeNet**.'
  prefs: []
  type: TYPE_NORMAL
- en: LeNet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LeNet was one of the first CNNs. Dating back to 1998, it's pretty small and
    simple for today's standards. But it is enough for this task.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is its architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – LeNet](img/Figure_4.11_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.11 – LeNet
  prefs: []
  type: TYPE_NORMAL
- en: 'LeNet accepts 32x32 images and has the following layers:'
  prefs: []
  type: TYPE_NORMAL
- en: The first layer is composed of six 5x5 convolutions, emitting images of 28x28
    pixels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second layer subsamples the image (for example, computing the average of
    four pixels), emitting images of 14x14 pixels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third layer is composed of 16 5x5 convolutions, emitting images of 10x10
    pixels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fourth layer subsamples the image (for example, computing the average of
    four pixels), emitting images of 5x5 pixels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fifth layer is a fully connected dense layer (that is, all the neurons of
    the previous layer are connected to all the neurons of this layer) of 120 neurons.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sixth layer is a fully connected dense layer of 84 neurons.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The seventh and last layer is the output, a fully connected dense layer of 10
    neurons, because we need to classify the images into 10 classes, for the 10 digits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are not trying to recreate LeNet precisely, and our input images are a bit
    smaller, but we will keep it as a reference.
  prefs: []
  type: TYPE_NORMAL
- en: The code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step is defining which type of neural network we are creating, which
    in Keras usually is `Sequential`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can add the first convolutional layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'It accepts the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: Six filters, so that we will get six kernels, which means six convolutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kernel size 5x5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ReLU activation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`same` padding (for example, using black pixels around the image), to not reduce
    too much the size of the image too early, and to be closer to LeNet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`input_shape` contains the shape of the images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, we add subsampling using `Max Pooling (default size=2x2)`, which emits
    the value of the pixel with the maximum **activation** (for example, with the
    maximum value):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can add the next convolutional layer and the next max pooling layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'And then we can add the dense layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`Flatten()` is used to flatten the 2D outputs of the convolutional layer into
    a single row of outputs (1D), which is required by the dense layer. Just to be
    clear, for our use case, the input of a convolutional filter is a grayscale image,
    and the output is another grayscale image.'
  prefs: []
  type: TYPE_NORMAL
- en: The last activation, `softmax`, converts the prediction into a probability,
    for convenience, and the output with the highest probability will represent the
    label that the neural network associates to the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s it: just a few lines of code to build a CNN that can recognize handwritten
    digits. I challenge you to do the same without machine learning!'
  prefs: []
  type: TYPE_NORMAL
- en: The architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even if our model definition is pretty straightforward, it can be useful to
    visualize it and see whether, for example, the dimensions are as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keras has a very useful function for that – `summary()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'And this is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This is very interesting. Firstly, we can see that the dimensions of the output
    of the convolutional layers are the same as for LeNet: 28x28 and 10x10\. This
    is not necessarily important; it just means that the network is dimensioned as
    we were expecting.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also see that the order of the layers is correct. What is interesting
    is the third value on each row: the number of parameters. The parameters are the
    variables that the neural network needs to figure out to actually learn something.
    They are the variables of our huge system of equations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of a fully connected dense layer, the number of parameters is obtained
    by multiplying the number of neurons of the previous layer, plus one, by the number
    of neurons of the current layer. If you remember the image of a neuron, there
    was one weight for each neuron it was connected to, so it is kind of intuitive
    that each of them is a trainable parameter. In addition, there is a parameter
    for the threshold (bias) of the activation. In the last layer, we therefore have
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 84 inputs ==> 84 weights + 1 bias ==> 85 parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10 outputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 85 x 10 ==> 850 parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the case of a convolutional layer, the number of parameters is given by
    the area of the kernel plus one, the bias of the activation. In the first layer,
    we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 5x5 kernel ==> 25 + 1 bias ==> 26 parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6 filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 26 x 6 ==> 156 parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, our network has 61,706 parameters. While this might seem like
    a lot, it's not uncommon for a neural network to have millions of them. How do
    they impact the training? As a first approximation, we can say that having more
    parameters enables our network to learn more things, but at the same time, it
    slows it down and increases the size of the model and the amount of memory it
    uses. Don't become obsessed with the number of parameters, because not all of
    them are created equal, but keep an eye on them, in case there is some layer that's
    using too many. You can see that dense layers tend to use many parameters, and
    in our case, they hold more than 95% of the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Training a neural network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have our neural network, we need to train it. We will talk more
    about training in the next chapter, but as the name suggests, training is the
    phase where the neural network *studies* the training dataset and actually learns
    it. As for how well it learns – that depends.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sake of quickly explaining the concepts, we will do an improper comparison
    with a student trying to learn a book for an exam:'
  prefs: []
  type: TYPE_NORMAL
- en: The book is the training dataset that the student needs to learn.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every time that the student reads the whole book is called an epoch. A student
    might want to read the book more than once, and it is very common for neural networks
    to do the same and train for more than one epoch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The optimizer is like somebody who asks the student questions from an exercise
    book (the validation dataset; though, in our example, we are going to use the
    test dataset for validation) to see how well the student is learning. One key
    difference is that the neural network does not learn from the validation dataset.
    We will see in the next chapter why this is very good.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To track their progress and learn in less time, the student can ask the optimizer
    to ask questions after a certain number of pages; that number of pages would be
    the batch size.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first thing to do is to configure the model, using `compile()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Keras has a variety of loss functions that you can use. `loss` is basically
    a measure of how distant the result of your model is from the ideal output. For
    classification tasks, we can use `categorical_crossentropy` as a loss function.
    `optimizer` is the algorithm used to train the neural network. If you imagine
    the neural network as a giant system of equations, the optimizer is the one that
    figures out how to change the parameters to improve the result. We will use `metrics`
    is just some values computed during the training, but they are not used by the
    optimizer; they are just provided to you as a reference.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now run the training, which might take a couple of minutes, and it will
    print the progress that is being made:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to provide several parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`x_train`: The training images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y_train`: The training labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size`: The default is 32, and usually it''s worth trying powers of 2,
    from 16 to 256; the batch size affects both speed and accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`epochs`: The number of times that the CNN will go through the dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`validation_data`: As we''ve already said, we are using the test dataset for
    validation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`shuffle`: If we want to shuffle the training data before each epoch, which
    usually we want to.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The result of the training is `history`, which contains a lot of useful information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We are talking about minimum and maximum because these values are measured during
    each epoch, and do not necessarily progress always toward an improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go through what we have here:'
  prefs: []
  type: TYPE_NORMAL
- en: The minimum loss is a measure of how close we come to the ideal output in the
    training dataset, or how well the neural network learned the training dataset.
    In general, we want this value to be as small as possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The minimum validation loss is how close we come to the ideal output in the
    validation dataset, or how well the neural network can do with the validation
    dataset after training. This is probably the most important value, as it is what
    we are trying to minimize, so we want this value to be as small as possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum accuracy is the maximum percentage of correct answers (predictions)
    that our CNN can give using the training dataset. For the student example from
    earlier, it would tell them how well they had memorized the book. Knowing the
    book by heart is not bad by itself – it is actually desirable – but the goal is
    not to memorize the book, but to learn from it. While we expect this value to
    be as high as possible, it can be misleading.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum validation accuracy is the maximum percentage of correct answers
    (predictions) that our CNN can give using the validation dataset. For the student
    example from earlier, it would tell them how well they had really learned the
    content of the book, so that they can answer questions that might not be present
    in the book. This will be an indication of how well our neural network can perform
    in real life.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is the result of our CNN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: On your computer, it will probably be slightly different, and in fact it should
    change a bit every time that you run it.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the losses are close to zero, which is good. Both the accuracy
    and the validation accuracy are almost 98.5%, which in general is very good.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also plot the evolution over time of these parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.12 – Plot of validation and accuracy over time for MNIST](img/Figure_4.12_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.12 – Plot of validation and accuracy over time for MNIST
  prefs: []
  type: TYPE_NORMAL
- en: Both the accuracy and the loss are very good after the first epoch and keep
    improving.
  prefs: []
  type: TYPE_NORMAL
- en: So far so good. Maybe you think that this was easy. But MNIST is a simple dataset.
    Let's try CIFAR-10.
  prefs: []
  type: TYPE_NORMAL
- en: CIFAR-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To use CIFAR-10, we can just ask Keras to use a different dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'CIFAR-10 is a more difficult dataset. It contains 32x32 RGB images, containing
    10 types of objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: It looks similar to MNIST.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the code on GitHub, to use CIFAR 10, you can simply change the `use_mnist`
    variable to `False`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'You don''t need to change anything else in the code, apart from removing the
    `reshape()` call because CIFAR-10 uses RGB images and, as a result, it already
    has three dimensions: width, height, and channels. Keras will adapt the model
    to the different dimensions and channels, and the neural network will just learn
    a new dataset!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the new model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The model is a bit bigger, because the images are slightly bigger and in RGB
    format. Let''s see how it performs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This is not very good: the loss is high and the validation accuracy is only
    around 55%.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next graph is quite important, and you will see it many times, so please
    take some time to familiarize yourself with it. The following graph shows the
    evolution of the loss (we use mean squared error) and of the accuracy for each
    epoch, over time, for our model. On the *X* axis, you see the number of epochs,
    and then there are four lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '`T loss`: The training loss'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`V loss`: The validation loss'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`T acc`: The training accuracy'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`V acc`: The validation accuracy:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.13 – Plot of validation and accuracy over time for CIFAR-10](img/Figure_4.13_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.13 – Plot of validation and accuracy over time for CIFAR-10
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the loss is going down, but it has not reached a minimum yet,
    so it probably means more epochs can be beneficial. The accuracy is low and stays
    low, probably because the model does not have enough parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the result with 12 epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The good news: the loss went down and the accuracy improved. The bad news:
    the validation loss and validation accuracy did not improve. In practice, our
    network is learning the training dataset by heart, but it cannot generalize, and
    therefore it does not perform well on the validation dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try to also significantly increase the size of the network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'That gives us this new model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Wow: we jumped from 83,000 to 5,000,000 parameters! That first dense layer
    is getting big...'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see whether we can see some improvements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now all the values have improved; however, while the training accuracy is now
    above 90%, the validation accuracy is just 65%:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.14 – Plot of validation and accuracy over time for CIFAR-10](img/Figure_4.14_B16322.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.14 – Plot of validation and accuracy over time for CIFAR-10
  prefs: []
  type: TYPE_NORMAL
- en: 'We see something a bit worrying: while the training loss goes down over time,
    the validation loss goes up. This situation is called overfitting, and it means
    that the network is not good at generalizing. It also means that we used way too
    many epochs for nothing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Not only that, but if we saved the model at the end, we would not be saving
    the best one. If you are wondering whether there is a way to save the best model
    (for example, with the lowest validation loss), then the answer is yes – Keras
    can do it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we are telling Keras to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Save the model with the name `'cifar-10.h5'`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitor the validation loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select the model based on the minimum loss (for example, save only if the validation
    loss decreases).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Save only the best model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can pass the `checkpoint` object to `model.fit()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This helps, but the model is not good enough. We need something radically better.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will learn many things that will hopefully help us
    to get some better results. Plus, in [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142),
    *Improving Your Neural Network*, we will apply this knowledge, and more, to improve
    the results. Now, if you want, you can spend some time trying to tune and improve
    the network: you can change its size, add filters and layers, and see how it performs.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This has been a dense chapter! We discussed machine learning in general and
    deep learning in particular. We talked about neural networks and how convolutions
    can be used to make faster and more accurate neural networks, leveraging the knowledge
    of pixel proximity. We learned about weights, bias, and parameters, and how the
    goal of the training phase is to optimize all these parameters to learn the task
    at hand.
  prefs: []
  type: TYPE_NORMAL
- en: After verifying the installation of Keras and TensorFlow, we described MNIST,
    and we instructed Keras to build a network similar to LeNet, to achieve more than
    98% accuracy on this dataset, meaning that we can now easily recognize handwritten
    digits. Then, we saw that the same model does not perform well in CIFAR-10, despite
    increasing the number of epochs and the size of the network.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will study in depth many of the concepts that we introduced
    here, with the final goal, to be completed by [*Chapter 6*](B16322_06_Final_JM_ePUB.xhtml#_idTextAnchor142),
    *Improving Your Neural Network*, of learning how to train a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After reading this chapter, you should be able to answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What is a perceptron?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can you name an optimizer that tends to perform well in many tasks?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a convolution?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a CNN?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a dense layer?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the `Flatten()` layer do?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which backend have we been using for Keras?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the name of one of the first CNNs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The original LeNet paper: [http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MNIST: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CNNs: [https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
