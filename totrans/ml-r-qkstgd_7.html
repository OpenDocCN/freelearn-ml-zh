<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Sovereign Crisis - NLP and Topic Modeling</h1>
                </header>
            
            <article>
                
<p>Continuing with the detection of economic problems in European countries, in this chapter, we will try to replicate country ratings, provided by Standard &amp; Poor's, using both quantitative and qualitative information. </p>
<p>This chapter is an interesting real-case application, because we will use some basic text-mining techniques to replicate Standard &amp; Poor's credit ratings. For this purpose, we will use the country reports issued by the European Commission for the European member states.</p>
<p>We will perform a text-mining process to extract combinations of words or useful terms to predict sovereign ratings. </p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Predicting country ratings using macroeconomic information</li>
<li>Implementing decision trees</li>
<li class="h1">Predicting sovereign ratings using European country reports</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Predicting country ratings using macroeconomic information</h1>
                </header>
            
            <article>
                
<p>In our clustering model, discussed in <a href="5c1b431c-46f9-42b6-b3e7-e583b1996cd5.xhtml" target="_blank">Chapter 6</a>, <em>Visualizing Economic Problems in the European Union</em>, using self-organizing maps, all the available data was used. Now, in order to train a model to be able to predict sovereign ratings, we need to split the data into two samples: train and test.</p>
<p class="mce-root"/>
<p>That's not new for us. When we tried to develop different models to predict a bank's failures, we used the <kbd>caTools</kbd> package to split the data, while considering our target variable.</p>
<p>The same procedure is used again here:</p>
<pre>library(caTools)<br/> <br/>index = sample.split(macroeconomic_data$RatingMayT1, SplitRatio = .75)<br/> <br/>train_macro&lt;-subset(macroeconomic_data, index == TRUE)<br/>test_macro&lt;-subset(macroeconomic_data, index == FALSE)</pre>
<p>Now, you can print the following statements:</p>
<pre>print(paste("The number of observations in the train sample is: ",nrow(train_macro),sep=""))<br/>## [1] "The number of observations in the train sample is: 168"<br/>print(paste("The number of observations in the test sample is: ",nrow(test_macro),sep=""))<br/>## [1] "The number of observations in the test sample is: 56"</pre>
<p>Thus, the test sample represents 25% of the total data. Moreover, the relative ratios of different credit ratings are preserved in both the train and test samples.</p>
<p>Both samples will be standardized. Again, the <kbd>caret</kbd> package is used:</p>
<pre>library(caret)</pre>
<p>The transformation should be carried out considering only the training sample, and then applied on the test sample:</p>
<pre>preprocess &lt;- preProcess(train_macro[,4:13], method=c("center", "scale"))<br/> <br/>print(preprocess)<br/> ## Created from 168 samples and 10 variables<br/> ## <br/> ## Pre-processing:<br/> ##   - centered (10)<br/> ##   - ignored (0)<br/> ##   - scaled (10)</pre>
<p>Here are two additional train and test samples, replacing the original variables into transformed variables:</p>
<pre>train_macro_trn &lt;- cbind(train_macro[,c(1:3,14)],predict(preprocess, train_macro[,4:13]))<br/>test_macro_trn &lt;- cbind(test_macro[,c(1:3,14)],predict(preprocess, test_macro[,4:13]))</pre>
<p>Let's see how variables are related to the target variable (rating). For this purpose, we first convert the target variable into a <kbd>factor</kbd> variable, and then we will create different box plots by rating the category for each variable:</p>
<pre>library(ggplot2)<br/>variables&lt;-colnames(train_macro_trn[,5:14])<br/> train_macro_trn$RatingMayT1&lt;-as.factor(train_macro_trn$RatingMayT1)<br/> <br/> for (i in 5:14)<br/>{<br/> <br/> library(ggplot2)<br/> theme_set(theme_classic())<br/> <br/> var&lt;-colnames(train_macro_trn)[i]<br/> <br/> data_aux&lt;-train_macro_trn[,c(var,"RatingMayT1")]<br/> colnames(data_aux)&lt;-c("variable","RatingMayT1")<br/> <br/> g &lt;- ggplot(data_aux, aes(RatingMayT1,variable))<br/> plot(g + geom_boxplot(varwidth=T, fill="plum") + <br/>     labs(title="Box plot", <br/>          subtitle=var,<br/>          x="Rating Number",<br/>          y=var))<br/> <br/> }</pre>
<p>The following is the output for the current account balance of a country (<strong><span class="packt_screen">CARA</span></strong>) variable<span class="packt_screen">:</span> </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-730 image-border" src="assets/3e3ef41a-0d33-49b7-a76d-1c9e213f0a01.png" style=""/></div>
<p>The following is the output for the consumer prices growth rate (<strong><span class="packt_screen">DCPI</span></strong>) variable:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-731 image-border" src="assets/e3cf52a4-bf5c-47a0-b3ed-d3359a2e070b.png" style=""/></div>
<p>The following is the output for the GDP growth (<strong><span class="packt_screen">DGPD</span></strong>) variable:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-732 image-border" src="assets/621b6cc6-2722-4d9b-bcdb-32576d9809f4.png" style=""/></div>
<p>The following is the output for the international reserves (<strong><span class="packt_screen">ILMA</span></strong>) variable:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-733 image-border" src="assets/72fda116-00c0-489f-9911-6244ae3bc836.png" style=""/></div>
<p class="mce-root"/>
<p>The following is the output for the mean of the six worldwide governance indicators (<strong><span class="packt_screen">MEANWGI</span></strong>) variable:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-734 image-border" src="assets/f6736dcf-60cf-439d-877b-02febf226b48.png" style=""/></div>
<p>The <span>following is the</span>  output for the budget balance as a percentage of the GDP (<strong><span>PSBR</span></strong>) variable:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-735 image-border" src="assets/e16a2559-9660-457a-89a5-df019eed4584.png" style=""/></div>
<p>The <span>following is the output for th</span>e public debt ratio (<strong>PUDP</strong>) variable:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-736 image-border" src="assets/523d46cf-1797-4170-9f4a-a151dffa17ec.png" style=""/></div>
<p>The <span>following is output fo</span>r the total imports less total exports of goods and services as a percentage of the GDP (<strong><span class="packt_screen">TDRA</span></strong>) variable:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-737 image-border" src="assets/9dfa7f0f-8679-4fd7-99ef-0e9a92b4a17b.png" style=""/></div>
<p>The following is the output for the GDP per head (<span class="packt_screen"><strong>YPCA</strong></span>) variable:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-738 image-border" src="assets/212e3c8e-257e-4561-b4aa-4ee6e87577c6.png" style=""/></div>
<p>These graphs are useful to see certain patterns in the data and how variables can help to predict credit ratings.</p>
<p>For example, the box plot for variable public debt (% of GDP), or the <kbd>PUDP</kbd>, shows that countries with the lowest ratings display higher variables on average in this variable.</p>
<p>In the following code, let's use the last previous plot, but this time give more detail about the countries included in each rating category:</p>
<pre>library(dplyr)<br/>means_YPCA &lt;- train_macro_trn %&gt;% group_by(RatingMayT1) %&gt;%<br/>         summarise(YPCA = mean(YPCA))<br/>  <br/>ggplot(train_macro_trn, aes(x = RatingMayT1, y = YPCA, color = RatingMayT1,          fill = RatingMayT1)) +<br/>geom_bar(data = means_YPCA, stat = "identity", alpha = .3) + ggrepel::geom_text_repel(aes(label = CountryName), color = "black", size =      2.5, segment.color = "grey") + geom_point() + guides(color = "none", fill = "none") + theme_bw() +  labs(  x = "Rating", y = "GDP per capita")</pre>
<p>The following is the more detailed YPCA plot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-739 image-border" src="assets/8c31d980-eb81-46c4-8b29-555132d3fd02.png" style=""/></div>
<p>Let's look at another alternative:</p>
<pre>library(ggplot2)<br/> theme_set(theme_classic())<br/>ggplot(train_macro_trn, aes((MEANWGI))) + geom_density(aes(fill=factor(RatingMayT1)),alpha=0.8) + <br/>     labs(title="Density plot", <br/>          subtitle="Mean of the Worldwide Governance Indicators",<br/>          x=paste("MeanWGI",sep=''),<br/>          fill="RatingNum")</pre>
<p>This is the <span class="packt_screen">Density plot</span> for <span class="packt_screen">MeanWGI</span>:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-740 image-border" src="assets/66d9bf6a-505b-4af0-b19a-9cd00af92010.png" style=""/></div>
<p>Let's implement a <kbd>Density plot</kbd> for <kbd>CARA</kbd>:</p>
<pre>ggplot(train_macro_trn, aes((CARA))) + geom_density(aes(fill=factor(RatingMayT1)),alpha=0.8) +     labs(title="Density plot", <br/>          subtitle="Current account balance/GDP",<br/>          x=paste("CARA",sep=''),<br/>          fill="RatingNum")</pre>
<p>The output for the <span class="packt_screen">Density plot</span> on <span class="packt_screen">CARA</span> will look like this: </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-741 image-border" src="assets/32c7b25e-9e24-4eb4-bdbb-51e6f96efc89.png" style=""/></div>
<p>As a target value, we have a variable that takes six different values. In this problem, it is not possible to calculate six, unlike in the previous problem, in which we were predicting failed banks.</p>
<p>In order to assess the ability of each variable to predict credit ratings, we can calculate the correlations of each variable with the target variable:</p>
<pre>colnames(train_macro_trn)<br/> ##  [1] "Year"                 "CountryISO"           "CountryName"        <br/> ##  [4] "RatingMayT1"          "CARA"                 "DCPI"               <br/> ##  [7] "DGDP"                 "ILMA"                 "PSBR"               <br/> ## [10] "PUDP"                 "TDRA"                 "YPCA"               <br/> ## [13] "MEANWGI"              "YearsFromLastDefault"<br/>variables&lt;-colnames(train_macro_trn[,c(4:14)])</pre>
<p>With the following code, we first create a copy of our training sample, and then convert the target variable into a numeric format. This is because it is not possible to calculate correlations with a non-numeric variable.</p>
<p>Then we will calculate correlations using the <kbd>cor</kbd> function:</p>
<pre>aux&lt;-train_macro_trn<br/>aux$RatingMayT1&lt;-as.numeric(as.character(aux$RatingMayT1)) <br/> # Correlation matrix<br/>correlations&lt;-cor(aux[, variables], use="pairwise", method="pearson")<br/>correlations_with_Rating&lt;-as.matrix(correlations[1,])</pre>
<p>Next, print these correlations:</p>
<pre>print(correlations_with_Rating)<br/> ##                            [,1]<br/> ## RatingMayT1           1.0000000<br/> ## CARA                  0.3938594<br/> ## DCPI                  0.1517755<br/> ## DGDP                  0.1167254<br/> ## ILMA                  0.3130267<br/> ## PSBR                  0.2783237<br/> ## PUDP                 -0.4172153<br/> ## TDRA                  0.3854816<br/> ## YPCA                  0.6491449<br/> ## MEANWGI               0.8024756<br/> ## YearsFromLastDefault  0.5132374</pre>
<p>The most correlated variable with credit ratings is the mean of the governance indicators (<kbd>MEANWGI</kbd>), followed by the GDP per head (<kbd>YPCA</kbd>). In both cases, the higher the value of the variables, the higher the solvency or the credit rating value.</p>
<p>On the other hand, the least correlated variable is the change of consumer prices (<kbd>DCPI</kbd>). All variables have a positive correlation, except the <kbd>PUDP</kbd>. It means that the higher the indebtedness of a country, the lower the credit rating.</p>
<p>All the variables have an expected sign with credit ratings according to the literature and the methodological guidelines provided by the credit rating agencies.</p>
<p>At this point, we should save our workspace and remove any unnecessary objects:</p>
<pre>rm(list=setdiff(ls(), c("macroeconomic_data","train_macro","test_macro","correlations_with_Rating","train_macro_trn","test_macro_trn")))<br/> <br/>save.image("Backup3.RData")</pre>
<p>As shown, the numbers of observations and variables are quite different than in the dataset of banks which we obtained in <a href="33b2f02e-58fd-41af-89a1-27947515b379.xhtml">Chapter 2</a>, <em>Predicting Failures of Banks - Data Collection</em>. </p>
<p>Let's try some algorithms to predict credit ratings. Specifically, in the next section, we will train a decision tree and an ordered logistic regression.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing decision trees</h1>
                </header>
            
            <article>
                
<p>When we looked at random forests in the <em>Testing a random forest model</em> section of chapter 5 (<em>Predicting the Failures of Banks - Multivariate Analysis</em>) previously, decision trees were briefly introduced. In a decision tree, the training sample is split into two or more homogeneous sets based on the most significant independent variables. In a decision tree, the best variable to split the data into the different categories is found. Information gain and the Gini index are the most common ways to find this variable. Then, data is recursively split, expanding the leaf nodes of the tree until the stopping criterion is reached. </p>
<p>Let's see how a decision tree can be implemented in R and how this algorithm is able to predict credit ratings.</p>
<p>Decision trees are implemented in the <kbd>rpart</kbd> package. Moreover, the <kbd>rpart.plot</kbd> package will be useful to visualize our trained model later on. Implement the packages by doing the following:</p>
<pre>library(rpart)<br/>library(rpart.plot)</pre>
<p class="mce-root"/>
<p>To create a tree, we will use the <kbd>rpart</kbd> function. Four parameters have to be specified:</p>
<ul>
<li><strong>Formula</strong>: In the format target: <kbd>~ predictor1+predictor2+…+predictorN</kbd></li>
<li><strong>Data</strong>: Specifies the data frame</li>
<li><strong>Method</strong>: <kbd>class</kbd> for a classification tree or <kbd>anova</kbd> for a regression tree</li>
<li><strong>Control</strong>: Optional parameters for controlling tree growth</li>
</ul>
<p>In our case, the following control parameters are specified:</p>
<ul>
<li><kbd>maxdepth</kbd>: Refers to the maximum depth of any node of the final tree. It defines the number of splits or, in other words, how much the trees can grow, considering the root node depth 0.</li>
<li><strong>Complexity parameter</strong> (or <kbd>cp</kbd>): This parameter is also used to control the size of the decision tree. This parameter can be considered the minimum gain required to increase the growth or the complexity of our decision tree. If adding a new node in a tree does not increase our fit, the algorithms will stop growing.</li>
</ul>
<p>Let's train the model. First a list of our variables is created:</p>
<pre>variables&lt;-names(train_macro_trn[,4:14])<br/>print(variables)<br/> ##  [1] "RatingMayT1"          "CARA"                 "DCPI"                <br/> ##  [4] "DGDP"                 "ILMA"                 "PSBR"                <br/> ##  [7] "PUDP"                 "TDRA"                 "YPCA"                <br/> ## [10] "MEANWGI"              "YearsFromLastDefault"</pre>
<p>Now, a decision tree is trained:</p>
<pre>set.seed(1234)<br/> <br/>DT&lt;-rpart(formula = RatingMayT1 ~ ., data = train_macro_trn[,c(variables)], control=rpart.control(maxdepth=5,cp=0.001))</pre>
<p>Once the model is trained, it is possible to print all the information given by the model with the <kbd>summary</kbd> function, although this time it is not printed due the large size of the output:</p>
<pre>#summary(DT)</pre>
<p>Let's now predict credit ratings with our decision tree, for both the train and test samples:</p>
<pre>DT_pr_train &lt;- data.frame(cbind(train_macro_trn$CountryName,train_macro_trn$Year,train_macro_trn$RatingMayT1,predict(DT, newdata=train_macro_trn, type="class")))<br/>colnames(DT_pr_train)&lt;-c("Country","year","Observed","Predicted")<br/> <br/>DT_pr_test &lt;- data.frame(cbind(test_macro_trn$CountryName,test_macro_trn$Year,test_macro_trn$RatingMayT1,predict(DT, newdata=test_macro_trn, type="class")))<br/>colnames(DT_pr_test)&lt;-c("Country","year","Observed","Predicted")</pre>
<p>Here is the confusion table for the training sample:</p>
<pre>table(DT_pr_train$Observed,DT_pr_train$Predicted)<br/> ##      1  2  3  4  5  6<br/> ##   1  6  2  0  0  0  0<br/> ##   2  0 16  5  1  1  0<br/> ##   3  1  4 22  4  2  0<br/> ##   4  0  0  7 25  0  0<br/> ##   5  0  0  7  1 25  1<br/> ##   6  0  0  0  2  1 35</pre>
<p>The trained model is able to predict almost all the credit ratings in the training sample. Let's now print its accuracy in the test sample:</p>
<pre>table(DT_pr_test$Observed,DT_pr_test$Predicted)<br/> ##      1  2  3  4  5  6<br/> ##   1  2  0  0  1  0  0<br/> ##   2  0  3  5  0  0  0<br/> ##   3  0  1  8  2  0  0<br/> ##   4  0  0  1  8  1  0<br/> ##   5  0  0  2  2  7  1<br/> ##   6  0  0  0  1  1 10</pre>
<p>In order to assess the accuracy of the decision tree, we could calculate different metrics. Specifically, we can calculate which is the difference between the real rating value and the predicted one. Calculating these differences we can measure in which grade our model differs from the real rating levels.</p>
<p>For that, a function is created:</p>
<pre>model_assessment&lt;-function(data,model)<br/>{<br/> data$Observed&lt;-as.numeric(as.character(data$Observed))<br/> data$Predicted&lt;-as.numeric(as.character(data$Predicted))<br/> data$df&lt;-abs(as.numeric(data$Predicted)-as.numeric(data$Observed))<br/> comparison&lt;-as.data.frame(table(data$df))<br/> comparison$perc&lt;-comparison$Freq/nrow(data)<br/> colnames(comparison)&lt;-c("notche","N",paste("perc_",model,sep=''))<br/> comparison$N&lt;-NULL<br/> comparison$cumulative&lt;-cumsum(comparison[,ncol(comparison)]) <br/> return(comparison)<br/> }</pre>
<p>Here are the different results:</p>
<pre>model_assessment(DT_pr_train,"DT")<br/> ##   notche     perc_DT cumulative<br/> ## 1      0 0.767857143  0.7678571<br/> ## 2      1 0.148809524  0.9166667<br/> ## 3      2 0.077380952  0.9940476<br/> ## 4      3 0.005952381  1.0000000</pre>
<p>According to the preceding table, almost 77% of countries are correctly classified. On the other hand, the predictions of 14.88% of countries are not correctly classified but the difference with the real observed rating is only of one notch. On the other hand, the 7.74% of countries have a wrong predicted rating and this prediction differs in two notches from the real value, and so on.</p>
<p>The same function is now applied using the test sample:</p>
<pre>model_assessment(DT_pr_test,"DT")<br/> ##   notche    perc_DT cumulative<br/> ## 1      0 0.67857143  0.6785714<br/> ## 2      1 0.25000000  0.9285714<br/> ## 3      2 0.05357143  0.9821429<br/> ## 4      3 0.01785714  1.0000000</pre>
<p>These results are considered good enough. Credit ratings provided by external rating agencies are based on quantitative and qualitative information, the latter being most relevant. In our case, we are able to predict 68% of ratings only using quantitative public information.</p>
<p>Finally, the decision tree is drawn using the <kbd>rpart.plot</kbd> package:</p>
<pre>prp(DT)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>The <strong>YPCA</strong> decision tree will look like the following:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-742 image-border" src="assets/ffd9c3da-bb8d-422c-82a2-9ab09df569da.png" style=""/></div>
<p class="FirstParagraph" style="text-align: justify">Isn't the model easy to interpret?</p>
<p>Let's save the decision tree before starting the next section:</p>
<pre class="SourceCode"><span class="KeywordTok">save.image</span><span class="NormalTok">(</span><span class="StringTok">"Backup4.RData"</span><span class="NormalTok">)<br/></span></pre>
<p>In the next section, we will use another interesting approach, ordered logistic regression, which will be able to improve the results obtained within the decision tree. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ordered logistic regression</h1>
                </header>
            
            <article>
                
<p>As we have seen, decision trees perform well in multi-classification problems. There are other approaches we could follow too. One of them is logistic regression, which gives six possible outcomes to a problem. Nevertheless, this approach has some limitations. For example, we are assuming that there is no order to the categories in the target variable. It means that different categories or classes in the target variable are nominal. In the case of ratings, this assumption is not necessarily true, because ratings assign a ranking. Moreover, differences between credit ratings are not the same, which means that the difference between AAA and AA+ ratings is not necessarily equal to the difference between BBB and BBB- ratings.</p>
<p class="mce-root"/>
<p>Thus, in this part of the book, we are going to implement an ordered logistic regression, which assumes an order in our target variable and a non-constant difference between ratings.</p>
<p>The model can be deployed using the <kbd>polr</kbd> function from the <kbd>MASS</kbd> package. This function only needs the formula of the model, the dataset and, in our case, the <kbd>Hess=TRUE</kbd> option. This option will allow us to calculate and visualize the standard errors of the variables in our model:</p>
<pre>library(MASS)<br/>ordered_logistic &lt;- polr(RatingMayT1 ~ ., data = train_macro_trn[,c(variables)], Hess=TRUE)</pre>
<p>A summary of the model is then printed:</p>
<pre>summary(ordered_logistic)<br/> ## Call:<br/> ## polr(formula = RatingMayT1 ~ ., data = train_macro_trn[, c(variables)],<br/> ##     Hess = TRUE)<br/> ##<br/> ## Coefficients:<br/> ##                        Value Std. Error t value<br/> ## CARA                 -0.3624     0.2520 -1.4381<br/> ## DCPI                  0.1432     0.1807  0.7924<br/> ## DGDP                 -0.2225     0.2129 -1.0452<br/> ## ILMA                  1.5587     0.2592  6.0126<br/> ## PSBR                  0.6929     0.2209  3.1371<br/> ## PUDP                 -2.8039     0.3886 -7.2145<br/> ## TDRA                  0.3070     0.2464  1.2461<br/> ## YPCA                  2.6988     0.7100  3.8011<br/> ## MEANWGI               2.2565     0.4707  4.7937<br/> ## YearsFromLastDefault  0.8091     0.2191  3.6919<br/> ##<br/> ## Intercepts:<br/> ##     Value    Std. Error t value<br/> ## 1|2 -10.0770   1.1157    -9.0321<br/> ## 2|3  -5.6306   0.6134    -9.1789<br/> ## 3|4  -2.4390   0.4011    -6.0810<br/> ## 4|5   0.4135   0.3615     1.1439<br/> ## 5|6   4.8940   0.5963     8.2070<br/> ##<br/> ## Residual Deviance: 236.9271<br/> ## AIC: 266.9271</pre>
<p>The preceding table provided us with the regression coefficient table. Moreover, it shows the estimates for the different intercepts, which are sometimes called <strong>cutpoints</strong>. The intercepts indicate where the predicted result should be cut, to make the different credit ratings observed in the data.</p>
<p>Moreover, the model provides us with the residual deviance and the <kbd>AIC</kbd> metrics, which are useful metrics to compare different models.</p>
<p>In the preceding results, we cannot see any <kbd>p_values</kbd> indicating whether a variable is significant, as it is not usually displayed in any regression. So, we need to calculate them.</p>
<p>The <kbd>p_values</kbd> can be approximately calculated by comparing the <kbd>t value</kbd> against the standard normal distribution. First, we will store our coefficients using the following code:</p>
<pre>coefs &lt;- coef(summary(ordered_logistic))<br/> print(coefs)<br/> ##                            Value Std. Error    t value<br/> ## CARA                  -0.3623788  0.2519888 -1.4380749<br/> ## DCPI                   0.1432174  0.1807448  0.7923737<br/> ## DGDP                  -0.2225049  0.2128768 -1.0452282<br/> ## ILMA                   1.5586713  0.2592360  6.0125575<br/> ## PSBR                   0.6928689  0.2208629  3.1371002<br/> ## PUDP                  -2.8038553  0.3886409 -7.2145133<br/> ## TDRA                   0.3069968  0.2463570  1.2461463<br/> ## YPCA                   2.6988066  0.7100112  3.8010760<br/> ## MEANWGI                2.2564849  0.4707199  4.7936888<br/> ## YearsFromLastDefault   0.8090669  0.2191455  3.6919175<br/> ## 1|2                  -10.0770197  1.1156894 -9.0321014<br/> ## 2|3                   -5.6306456  0.6134365 -9.1788566<br/> ## 3|4                   -2.4389936  0.4010815 -6.0810418<br/> ## 4|5                    0.4134912  0.3614860  1.1438653<br/> ## 5|6                    4.8940176  0.5963226  8.2069960</pre>
<p>If we observe the sign of the coefficients, there are some negative values. Apparently, some variables display a non-intuitive or unexpected sign, but we don't need to be concerned about it in this example.</p>
<p>Coefficients of the model can be somewhat difficult to interpret, because they are scaled in terms of logs. Thus, it is common to convert previous raw coefficients into odds ratios.</p>
<p>Odds ratios will be obtained as follows: </p>
<pre>exp(coef(ordered_logistic))<br/> ##                 CARA                 DCPI                 DGDP<br/> ##           0.69601870           1.15398065           0.80051110<br/> ##                 ILMA                 PSBR                 PUDP<br/> ##           4.75250240           1.99944358           0.06057607<br/> ##                 TDRA                 YPCA              MEANWGI<br/> ##           1.35933662          14.86198455           9.54946258<br/> ## YearsFromLastDefault<br/> ##           2.24581149<br/><br/></pre>
<p>Finally, the <kbd>p_values</kbd> of the different variables are calculated and merged with our obtained coefficients:</p>
<pre>p_values &lt;- pnorm(abs(coefs[, "t value"]), lower.tail = FALSE) * 2<br/>coefs &lt;- cbind(coefs, "p value" = p_values)<br/>print(coefs)<br/> ##                            Value Std. Error    t value     p value<br/> ## CARA                  -0.3623788  0.2519888 -1.4380749 1.504128e-01<br/> ## DCPI                   0.1432174  0.1807448  0.7923737 4.281428e-01<br/> ## DGDP                  -0.2225049  0.2128768 -1.0452282 2.959175e-01<br/> ## ILMA                   1.5586713  0.2592360  6.0125575 1.826190e-09<br/> ## PSBR                   0.6928689  0.2208629  3.1371002 1.706278e-03<br/> ## PUDP                  -2.8038553  0.3886409 -7.2145133 5.412723e-13<br/> ## TDRA                   0.3069968  0.2463570  1.2461463 2.127107e-01<br/> ## YPCA                   2.6988066  0.7100112  3.8010760 1.440691e-04<br/> ## MEANWGI                2.2564849  0.4707199  4.7936888 1.637422e-06<br/> ## YearsFromLastDefault   0.8090669  0.2191455  3.6919175 2.225697e-04<br/> ## 1|2                  -10.0770197  1.1156894 -9.0321014 1.684062e-19<br/> ## 2|3                   -5.6306456  0.6134365 -9.1788566 4.356928e-20<br/> ## 3|4                   -2.4389936  0.4010815 -6.0810418 1.194042e-09<br/> ## 4|5                    0.4134912  0.3614860  1.1438653 2.526795e-01<br/> ## 5|6                    4.8940176  0.5963226  8.2069960 2.267912e-16</pre>
<p>Once we develop our model, we are going to predict the outcome of our model:</p>
<pre>Ord_log_pr_train &lt;- cbind(train_macro_trn[,c("CountryName","Year","RatingMayT1")], predict(ordered_logistic, train_macro_trn, type = "probs"))<br/> <br/>colnames(Ord_log_pr_train)&lt;-c("Country","year","Observed","X1","X2","X3","X4","X5","X6")<br/>head(Ord_log_pr_train,1)<br/>##Country year Observed      X1           X2          X3         X4<br/> 1 Austria 2010   6      5.468638e-06 4.608843e-04 0.010757249 0.15316033<br/><br/> ##      X5         X6<br/> ## 1 0.7811701 0.05444599</pre>
<p>The model gives a different probability for each rating. The predicted rating is the one with the highest predicted probability. For example, for Austria in 2010, the model assigns the highest probability to the 5 (<kbd>X5</kbd>) rating, so the predicted rating is a 5.</p>
<p>With the following code, we assign the predicted rating to the highest probability:</p>
<pre>for (j in 1:nrow(Ord_log_pr_train))<br/>{<br/>Ord_log_pr_train$maximaPD[j]&lt;-max(Ord_log_pr_train$X1[j],Ord_log_pr_train$X2[j],Ord_log_pr_train$X3[j],Ord_log_pr_train$X4[j],Ord_log_pr_train$X5[j],Ord_log_pr_train$X6[j])<br/>}<br/> <br/>Ord_log_pr_train$Predicted&lt;-ifelse(Ord_log_pr_train$X1==Ord_log_pr_train$maximaPD,1,ifelse(Ord_log_pr_train$X2==Ord_log_pr_train$maximaPD,2,ifelse(Ord_log_pr_train$X3==Ord_log_pr_train$maximaPD,3,ifelse(Ord_log_pr_train$X4==Ord_log_pr_train$maximaPD,4,ifelse(Ord_log_pr_train$X5==Ord_log_pr_train$maximaPD,5,6)))))</pre>
<p>Let's see the accuracy of the model in the train sample:</p>
<pre>model_assessment(Ord_log_pr_train,"Ordered_logistic")<br/> ##   notche perc_Ordered_logistic cumulative<br/> ## 1      0            0.69047619  0.6904762<br/> ## 2      1            0.29761905  0.9880952<br/> ## 3      2            0.01190476  1.0000000</pre>
<p>As we can see, the model is able to correctly predict 69.05% of credit ratings using the training sample. These results were better when using a decision tree.</p>
<p>Let's see the performance of the model in the test sample. <span>The following code gives us the predicted probabilities of each country for each of the rating levels. The predicted rating is given by the category with the highest probability: </span></p>
<pre>Ord_log_pr_test &lt;- cbind(test_macro_trn[,c("CountryName","Year","RatingMayT1")], predict(ordered_logistic, test_macro_trn, type = "probs"))<br/>colnames(Ord_log_pr_test)&lt;-c("Country","year","Observed","X1","X2","X3","X4","X5","X6")</pre>
<p><span>The following code finds the rating category with the highest probability and assigns this rating as the predicted rating: </span></p>
<pre>for (j in 1:nrow(Ord_log_pr_test))<br/>{<br/> <br/> Ord_log_pr_test$maximaPD[j]&lt;-max(Ord_log_pr_test$X1[j],Ord_log_pr_test$X2[j],Ord_log_pr_test$X3[j],Ord_log_pr_test$X4[j],Ord_log_pr_test$X5[j],Ord_log_pr_test$X6[j])<br/> <br/> }<br/> <br/>Ord_log_pr_test$Predicted&lt;-ifelse(Ord_log_pr_test$X1==Ord_log_pr_test$maximaPD,1,ifelse(Ord_log_pr_test$X2==Ord_log_pr_test$maximaPD,2,ifelse(Ord_log_pr_test$X3==Ord_log_pr_test$maximaPD,3,ifelse(Ord_log_pr_test$X4==Ord_log_pr_test$maximaPD,4,ifelse(Ord_log_pr_test$X5==Ord_log_pr_test$maximaPD,5,6)))))</pre>
<p>The accuracy of the model in the test sample is as follows:</p>
<pre>model_assessment(Ord_log_pr_test,"Ordered_logistic")<br/> ##   notche perc_Ordered_logistic cumulative<br/> ## 1      0            0.57142857  0.5714286<br/> ## 2      1            0.39285714  0.9642857<br/> ## 3      2            0.01785714  0.9821429<br/> ## 4      3            0.01785714  1.0000000</pre>
<p>The results are also slightly worse than in the decision tree model.</p>
<p>You can now save the workspace before starting the next section:</p>
<pre>save.image("Backup5.RData")</pre>
<p>In the next section, we will use macroeconomic data to predict country ratings. All the variables we used are quantitative variables. In the following section, we will use country reports for the same purpose.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Predicting sovereign ratings using European country reports</h1>
                </header>
            
            <article>
                
<p>According to the model based on macroeconomic information described in the <em>Predicting country ratings using macroeconomic information</em> section, decision trees can be considered a good alternative approach to predicting sovereign ratings.</p>
<p>Nevertheless, qualitative information represents an important and low transparent part of the rating assignment. In this section, we propose a model using only qualitative information based on the so-called country reports, published by the European Commission.</p>
<p>These reports, mainly published at the end of February, contain an annual analysis of the economic and social challenges for the EU member states.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>For example, at the following link, we can download the country reports published in 2018, <a href="https://ec.europa.eu/info/publications/2018-european-semester-country-reports_en" target="_blank">https://ec.europa.eu/info/publications/2018-european-semester-country-reports_en</a>. For all of the 28 EU countries, we have downloaded their country reports from 2011 to 2018, and converted them into a text format. We stored them in different folders, one for each year:</p>
<pre>directories &lt;- list.files(path = "../MachineLearning/CountryReports/", pattern = "201", full.names = TRUE)<br/> <br/>print(directories)<br/> ## [1] "../MachineLearning/CountryReports/2011"<br/> ## [2] "../MachineLearning/CountryReports/2012"<br/> ## [3] "../MachineLearning/CountryReports/2013"<br/> ## [4] "../MachineLearning/CountryReports/2014"<br/> ## [5] "../MachineLearning/CountryReports/2015"<br/> ## [6] "../MachineLearning/CountryReports/2016"<br/> ## [7] "../MachineLearning/CountryReports/2017"<br/> ## [8] "../MachineLearning/CountryReports/2018"</pre>
<p>Let's create a list that contains the names of different reports for each folder:</p>
<pre>txt_files2011&lt;-list.files(path = directories[1], pattern = ".txt",  recursive=TRUE,full.names = TRUE)<br/>txt_files2012&lt;-list.files(path = directories[2], pattern = ".txt",  recursive=TRUE,full.names = TRUE)<br/>txt_files2013&lt;-list.files(path = directories[3], pattern = ".txt",  recursive=TRUE,full.names = TRUE)<br/>txt_files2014&lt;-list.files(path = directories[4], pattern = ".txt",  recursive=TRUE,full.names = TRUE)<br/>txt_files2015&lt;-list.files(path = directories[5], pattern = ".txt",  recursive=TRUE,full.names = TRUE)<br/>txt_files2016&lt;-list.files(path = directories[6], pattern = ".txt",  recursive=TRUE,full.names = TRUE)<br/>txt_files2017&lt;-list.files(path = directories[7], pattern = ".txt",  recursive=TRUE,full.names = TRUE)<br/>txt_files2018&lt;-list.files(path = directories[8], pattern = ".txt",  recursive=TRUE,full.names = TRUE)</pre>
<p>Here, the names of the text files are stored in a list:</p>
<pre>country_reports_list&lt;-do.call(c,list(txt_files2011,txt_files2012,txt_files2013,txt_files2014,txt_files2015,txt_files2016,txt_files2017,txt_files2018))<br/>head(country_reports_list)<br/> ## [1] "../MachineLearning/CountryReports/2011/swp_austria_en_0.txt"      <br/> ## [2] "../MachineLearning/CountryReports/2011/swp_belgium_en_0.txt"      <br/> ## [3] "../MachineLearning/CountryReports/2011/swp_bulgaria_en_0.txt"     <br/> ## [4] "../MachineLearning/CountryReports/2011/swp_cyprus_en_0.txt"       <br/> ## [5] "../MachineLearning/CountryReports/2011/swp_czechrepublic_en_0.txt"<br/> ## [6] "../MachineLearning/CountryReports/2011/swp_denmark_en_0.txt"</pre>
<p>The name of files contains the roots and the filenames. Let's try to separate the country name and the year of the report:</p>
<pre>list&lt;-data.frame(country_reports_list)<br/>list&lt;-data.frame(t(data.frame(strsplit(as.character(list$country_reports_list), "/"))))<br/>list&lt;-list[,(ncol(list)-1):ncol(list)]<br/>row.names(list)&lt;-NULL<br/>list&lt;-cbind(list,country_reports_list)<br/>colnames(list)&lt;-c("Year","file","root")<br/>head(list)<br/> ##   Year                       file<br/> ## 1 2011       swp_austria_en_0.txt<br/> ## 2 2011       swp_belgium_en_0.txt<br/> ## 3 2011      swp_bulgaria_en_0.txt<br/> ## 4 2011        swp_cyprus_en_0.txt<br/> ## 5 2011 swp_czechrepublic_en_0.txt<br/> ## 6 2011       swp_denmark_en_0.txt<br/> ##                                                                root<br/> ## 1       ../MachineLearning/CountryReports/2011/swp_austria_en_0.txt<br/> ## 2       ../MachineLearning/CountryReports/2011/swp_belgium_en_0.txt<br/> ## 3      ../MachineLearning/CountryReports/2011/swp_bulgaria_en_0.txt<br/> ## 4        ../MachineLearning/CountryReports/2011/swp_cyprus_en_0.txt<br/> ## 5 ../MachineLearning/CountryReports/2011/swp_czechrepublic_en_0.txt<br/> ## 6       ../MachineLearning/CountryReports/2011/swp_denmark_en_0.txt</pre>
<p>Let's try to create a column with the country name, taking into consideration each filename. For example, if the word <kbd>czech</kbd> appears in the name of a file, a new column will be created that contains <kbd>Czech Republic</kbd>:</p>
<pre>list$CountryMapping&lt;-NA<br/> <br/> list[grep("austria",list$file),"CountryMapping"]&lt;-"Austria"<br/> list[grep("belgium",list$file),"CountryMapping"]&lt;-"Belgium"<br/> list[grep("bulgaria",list$file),"CountryMapping"]&lt;-"Bulgaria"<br/> list[grep("croatia",list$file),"CountryMapping"]&lt;-"Croatia"<br/> list[grep("cyprus",list$file),"CountryMapping"]&lt;-"Cyprus"<br/> list[grep("czech",list$file),"CountryMapping"]&lt;-"Czech Republic"<br/> list[grep("denmark",list$file),"CountryMapping"]&lt;-"Denmark"<br/> list[grep("estonia",list$file),"CountryMapping"]&lt;-"Estonia"<br/> list[grep("finland",list$file),"CountryMapping"]&lt;-"Finland"<br/> list[grep("france",list$file),"CountryMapping"]&lt;-"France"<br/> list[grep("germany",list$file),"CountryMapping"]&lt;-"Germany"<br/> list[grep("greece",list$file),"CountryMapping"]&lt;-"Greece"<br/> list[grep("hungary",list$file),"CountryMapping"]&lt;-"Hungary"<br/> list[grep("ireland",list$file),"CountryMapping"]&lt;-"Ireland"<br/> list[grep("italy",list$file),"CountryMapping"]&lt;-"Italy"<br/> list[grep("latvia",list$file),"CountryMapping"]&lt;-"Latvia"<br/> list[grep("lithuania",list$file),"CountryMapping"]&lt;-"Lithuania"<br/> list[grep("luxembourg",list$file),"CountryMapping"]&lt;-"Luxembourg"<br/> list[grep("malta",list$file),"CountryMapping"]&lt;-"Malta"<br/> list[grep("netherlands",list$file),"CountryMapping"]&lt;-"Netherlands"<br/> list[grep("poland",list$file),"CountryMapping"]&lt;-"Poland"<br/> list[grep("portugal",list$file),"CountryMapping"]&lt;-"Portugal"<br/> list[grep("romania",list$file),"CountryMapping"]&lt;-"Romania"<br/> list[grep("slovakia",list$file),"CountryMapping"]&lt;-"Slovakia"<br/> list[grep("slovenia",list$file),"CountryMapping"]&lt;-"Slovenia"<br/> list[grep("spain",list$file),"CountryMapping"]&lt;-"Spain"<br/> list[grep("sweden",list$file),"CountryMapping"]&lt;-"Sweden"<br/> list[grep("uk",list$file),"CountryMapping"]&lt;-"United Kingdom"<br/> list[grep("kingdom",list$file),"CountryMapping"]&lt;-"United Kingdom"<br/> list[grep("netherland",list$file),"CountryMapping"]&lt;-"Netherlands"</pre>
<p>Let's see the number of reports we have for each country in the European Union:</p>
<pre>table(list$CountryMapping)<br/> ## <br/> ## Austria         Belgium   Bulgaria   Croatia  Cyprus  <br/> ##    8               8         8         6         8 <br/> ## Czech Republic  Denmark   Estonia    Finland  France <br/> ##    8               8         8         8         8 <br/> ## Germany         Greece    Hungary    Ireland  Italy <br/> ##    8               4         8         8         8 <br/> ## Latvia          Lithuania Luxembourg Malta    Netherlands <br/> ##    8               8         8         8         8 <br/> ## Poland          Portugal  Romania    Slovakia Slovenia <br/> ##    8               8         8         8         8 <br/> ## Spain           Sweden    United Kingdom <br/> ##    8               8            8</pre>
<p>We have eight different reports for all the countries in the European Union, except for Croatia (with only <kbd>6</kbd> reports) and Greece (with only <kbd>4</kbd>). Croatia's accession to the EU as a full member took place on July 1, 2013. Thus, there are no reports for 2011 and 2012. In the case of Greece, there were not specific reports for Greece after 2014.</p>
<p>As we are going to train a model to predict credit ratings using the European reports, we need to select some reports to train the model and other reports to test it. The same countries we used in the model using macroeconomic information in <a href="5c1b431c-46f9-42b6-b3e7-e583b1996cd5.xhtml" target="_blank">Chapter 6</a>, <em>Visualizing Economic Problems in the European Union</em><a href="5c1b431c-46f9-42b6-b3e7-e583b1996cd5.xhtml" target="_blank"/> (P<em>redicting country ratings using macroeconomic information</em> section) will be used here again. First, we need to select the countries we previously used to train the model. Then we merge the selected countries with the name and the root where the corresponding report is located:</p>
<pre>train_list&lt;-train_macro[,c("CountryName","Year")]<br/>train_list$year_report&lt;-train_list$Year+1<br/> <br/>train_list&lt;-merge(train_list,list,by.x=c("CountryName","year_report"),by.y=c("CountryMapping","Year"),all.x=TRUE)<br/> <br/>train_list&lt;-train_list[complete.cases(train_list),]<br/> <br/>files_train&lt;-as.vector(train_list$root)</pre>
<p>Here's an example of the reports we will use to train our model:</p>
<pre>print(head(files_train))<br/> ## [1] "../MachineLearning/CountryReports/2011/swp_austria_en_0.txt"                       <br/> ## [2] "../MachineLearning/CountryReports/2012/swd2012_austria_en.txt"                                <br/> ## [3] "../MachineLearning/CountryReports/2013/swd2013_austria_en.txt"                                <br/> ## [4] "../MachineLearning/CountryReports/2014/swd2014_austria_en_0.txt"                              <br/> ## [5] "../MachineLearning/CountryReports/2016/cr2016_austria_en.txt"                                 <br/> ## [6] "../MachineLearning/CountryReports/2017/2017-european-semester-country-report-austria-en_1.txt"</pre>
<p>The same procedure is carried out to obtain the validation or test sample:</p>
<pre>test_list&lt;-test_macro[,c("CountryName","Year")]<br/>test_list$year_report&lt;-test_list$Year+1<br/> <br/>test_list&lt;-merge(test_list,list,by.x=c("CountryName","year_report"),by.y=c("CountryMapping","Year"),all.x=TRUE)<br/> <br/>test_list&lt;-test_list[complete.cases(test_list),]<br/> <br/>files_test&lt;-as.vector(test_list$root)</pre>
<p>Now let's see the output:</p>
<pre>print(head(files_test))<br/> ## [1] "../MachineLearning/CountryReports/2015/cr2015_austria_en.txt"                               <br/> ## [2] "../MachineLearning/CountryReports/2018/2018-european-semester-country-     report-austria-en.txt"<br/> ## [3] "../MachineLearning/CountryReports/2013/swd2013_belgium_en.txt"                              <br/> ## [4] "../MachineLearning/CountryReports/2011/swp_bulgaria_en_0.txt"                               <br/> ## [5] "../MachineLearning/CountryReports/2013/swd2013_bulgaria_en.txt"                             <br/> ## [6] "../MachineLearning/CountryReports/2014/swd2014_croatia_en.txt"</pre>
<p>There are some differences in the size of samples with regard to the samples used in the previous model, because there are no reports for some countries. This is shown in the following code:</p>
<pre>print(paste("The number of countries used to train previous model was formed by",nrow(train_macro_trn), "countries",sep=" "))<br/><br/> ## [1] "The number of countries used to train previous model was formed by 168      countries"</pre>
<p>This is the number of countries that we will use to train the new model:</p>
<pre>print(paste("The number of countries which we will use to train this new model will be formed by",nrow(train_list), "countries",sep=" "))<br/><br/> ## [1] "The number of countries which we will use to train this new model will      be formed by 165 countries"</pre>
<p>This is the number of countries used to validate the previous model:</p>
<pre>print(paste("The number of countries used to validate previous model was formed by",nrow(test_macro_trn), "countries",sep=" "))<br/><br/> ## [1] "The number of countries used to validate previous model was formed by      56 countries"</pre>
<p>This is the number of countries used to train the new model:</p>
<pre>print(paste("The number of countries which we will use to train this new model will be formed by",nrow(test_list), "countries",sep=" "))<br/><br/> ## [1] "The number of countries which we will use to train this new model will be formed by 53 countries"</pre>
<p>As you can see, the difference is not significant. Before reading files into R, we will create a function to read the files.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Once the following function is run, we can read the different reports iteratively:</p>
<pre>Import_txt &lt;- function(txt) <br/>{<br/> x&lt;-as.data.frame(read.delim(txt, header=FALSE, comment.char="#", stringsAsFactors=FALSE))<br/> return(x)<br/>}</pre>
<p>Two lists will be created. In each element of the lists, we can find each country report:</p>
<pre>Reports_train &lt;- lapply(files_train, <br/>                  function(x) <br/>                  read.delim(x, <br/>                             header = FALSE, comment.char="#",<br/>                             stringsAsFactors = FALSE))<br/>Reports_test &lt;-  lapply(files_test, <br/>                  function(x) <br/>                  read.delim(x, <br/>                             header = FALSE, comment.char="#",<br/>                             stringsAsFactors = FALSE))</pre>
<p>Before continuing, some unnecessary objects can be removed and the workspace should be saved:</p>
<pre>rm(list=setdiff(ls(), c("macroeconomic_data","Reports_train","Reports_test","train_list","test_list")))<br/>save.image("Backup6.RData")</pre>
<p>Reports need to be <span>pre</span>processed. Data preprocessing is necessary before extracting useful information or features to build our model.</p>
<p>Data cleaning, or preprocessing data, involves converting the data into plain text, and then removing formatting, whitespace, numbers, uppercase characters, and stopwords.</p>
<p><strong>Stopwords</strong> are defined as words in a language that are so common that their information value is practically null. As all the country reports are available in English, some examples of these stopwords are prepositions, determinants, and conjunctions.</p>
<p>In order to make these preprocessing steps, the <kbd>tm</kbd> package is loaded and reports have to be converted into a corpus format:</p>
<pre>library(tm)<br/>docs_train &lt;- as.VCorpus(Reports_train)<br/> <br/>docs_test &lt;- as.VCorpus(Reports_test)</pre>
<p>The following function is created to clean our reports one by one:</p>
<pre>corpus_treatment&lt;-function(corpus)<br/>{<br/>  <br/> toSpace &lt;- content_transformer(function(x, pattern) {return (gsub(pattern, " ", x))})<br/> <br/> corpus &lt;- tm_map(corpus,PlainTextDocument)<br/> corpus &lt;- tm_map(corpus, toSpace, "-")<br/> corpus &lt;- tm_map(corpus, toSpace, ":")<br/> corpus &lt;- tm_map(corpus, removePunctuation)<br/> corpus &lt;- tm_map(corpus, toSpace, "'")<br/> corpus &lt;- tm_map(corpus, toSpace, "'")<br/> corpus &lt;- tm_map(corpus, toSpace, " -")<br/> corpus &lt;- tm_map(corpus,content_transformer(tolower))<br/> corpus &lt;- tm_map(corpus, removeNumbers)<br/> corpus &lt;- tm_map(corpus, removeWords, stopwords("english"))<br/> corpus &lt;- tm_map(corpus, stripWhitespace)<br/> return(corpus)<br/>}</pre>
<p>These reports are transformed by applying the following function:</p>
<pre>docs_train&lt;-corpus_treatment(docs_train)<br/>docs_test&lt;-corpus_treatment(docs_test)</pre>
<p>An additional analysis will be done, called <strong>stemming</strong>. The stemming process refers to erasing suffixes to retrieve the root (or stem) of the word, which reduces the complexity of the data without significant loss of information.</p>
<p>Thus, the verb <em>argue</em> will be reduce to the stem <em>argu</em>, regardless of the form or complexity of the word in the text. Thus, other forms such as <em>argued</em>, <em>argues</em>, <em>arguing</em>, and <em>argus</em> are also reduced to the same stem. The stemming procedure reduces the number of words to consider and provides a better frequency representation.</p>
<p>The stemming process is done using the <kbd>SnowballC</kbd> package:</p>
<pre>library(SnowballC)<br/>docs_train &lt;- tm_map(docs_train,stemDocument)<br/>docs_test &lt;- tm_map(docs_test,stemDocument)</pre>
<p>After the preprocessing process, a matrix (document-term matrix) is built considering the country reports. Each row of this matrix represents each of the country reports, and each column represents all the words observed on them.</p>
<p>If a word occurs in a particular country report, the matrix entry corresponding to that row and column is 1, otherwise it is 0. When multiple occurrences within a document are recorded, that is, if a word occurs twice in a report, it is recorded as 2 in the relevant matrix entry.</p>
<p>However, some extracted single words might lack important information that was included in the original text, such as word-to-word dependencies and the contexts around high-frequency words.</p>
<p>For example, the extraction of the word <em>unemployment</em> in a report can't provide enough information to interpret whether the term is positive or negative. Thus, combinations of two words are extracted from the reports instead of individual words.</p>
<p>In this way, it is possible to find some combinations, such as <em>high unemployment</em>, that could appear more frequently in countries with lower creditworthiness.</p>
<p>The package we will use to extract combinations of words is named <kbd>Rweka</kbd>:</p>
<pre>library(RWeka)</pre>
<p>The following function is created to obtain the combinations of <kbd>1</kbd> and <kbd>2</kbd> words in the reports:</p>
<pre>options(mc.cores=4)<br/> <br/>BigramTokenizer &lt;- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 2))</pre>
<p>Document-term matrices are now obtained for the train and test samples of the reports. Only words more than <kbd>3</kbd> and less than <kbd>20</kbd> characters long will be considered:</p>
<pre>tdm2_train &lt;- TermDocumentMatrix(docs_train, control = list(tokenize = BigramTokenizer,wordLengths = c(3,20)))</pre>
<p>In the case of the validation sample, we will calculate the matrix considering the dictionary of words previously found in the training sample. New words found in the test sample will not be considered. Remember to take into consideration that we cannot use words found in the test sample to develop the model, which means that, right now, we should act as if the test sample does not exist to train the algorithm. </p>
<p>Thus, we should add a new parameter in our function when the document-term matrix is calculated on the test sample of reports: <kbd>dictionary = Terms(tdm2_train)</kbd>. This is shown in the following code:</p>
<pre>tdm2_test &lt;- TermDocumentMatrix(docs_test, control = list(dictionary = Terms(tdm2_train),tokenize = BigramTokenizer,wordLengths = c(3,20)))</pre>
<p>Let's analyze the resultant matrices:</p>
<pre>tdm2_train<br/> ## &lt;&lt;TermDocumentMatrix (terms: 609929, documents: 165)&gt;&gt;<br/> ## Non-/sparse entries: 2034690/98603595<br/> ## Sparsity           : 98%<br/> ## Maximal term length: 20<br/> ## Weighting          : term frequency (tf)<br/>tdm2_test<br/> ## &lt;&lt;TermDocumentMatrix (terms: 609929, documents: 53)&gt;&gt;<br/> ## Non-/sparse entries: 504543/31821694<br/> ## Sparsity           : 98%<br/> ## Maximal term length: 20<br/> ## Weighting          : term frequency (tf)</pre>
<p>The first line indicates the number of different terms and the number of reports in each sample. The number of columns or terms in each matrix is the same and belongs to the total list of words found in our training sample.</p>
<p>A total of 609,929 terms have appeared at least once in the training sample of country reports.</p>
<p>Moreover, in the training matrix, there are 98,603,595 cells with frequencies of 0 and 2,034,690 cells that have non zero values. Thus, 98% of all cells are zero. This situation is very common in text-mining problems. When a matrix contains many cells with zero values, it is considered a sparse matrix.   </p>
<p>The <kbd>removeSparseTerms</kbd> function will remove the infrequently used words, leaving only the most used words in the corpus.</p>
<p>In our case, we will reduce the matrix to keep a maximum of 75% empty space. This process has to be applied only on the data we will later use to train the model:</p>
<pre>tdm2_train2 &lt;- removeSparseTerms(tdm2_train, 0.75)<br/>tdm2_train2<br/> ## &lt;&lt;TermDocumentMatrix (terms: 6480, documents: 165)&gt;&gt;<br/> ## Non-/sparse entries: 589204/479996<br/> ## Sparsity           : 45%<br/> ## Maximal term length: 20<br/> ## Weighting          : term frequency (tf)</pre>
<p class="mce-root"/>
<p>Our matrix to train the model now has 6,480 terms.</p>
<p>Let's observe what our matrix looks like:</p>
<pre>print(as.matrix(tdm2_train2[1:10, 1:4]))<br/> ##             Docs<br/> ## Terms        character(0) character(0) character(0) character(0)<br/> ##   ­ gj                  0            0            0            0<br/> ##   ­ mwh                 0            0            0            0<br/> ##   ± ±                  0            0            0            0<br/> ##   à vis                1            1            1            5<br/> ##   abil                 0            1            1            2<br/> ##   abl                  0            1            1            0<br/> ##   abl afford           0            0            0            0<br/> ##   abolish              1            1            3            1<br/> ##   abroad               2            4            3            0<br/> ##   absenc               0            0            0            0</pre>
<p>For example, the word <kbd>abroad</kbd> appears <kbd>2</kbd> times in the first report and <kbd>4</kbd> times in the second. Just remember that words were stemmed in a previous step, so only the roots of words are displayed. Single words and combinations of two words are also available in the matrix.</p>
<p>The names of the reports displayed in the preceding code are ordered according to the list we originally used to import the reports. Specifically, the first four documents belong to the following:</p>
<pre>print(head(as.character(train_list$root),4))<br/>## [1] "../MachineLearning/CountryReports/2011/swp_austria_en_0.txt"   <br/>## [2] "../MachineLearning/CountryReports/2012/swd2012_austria_en.txt" <br/>## [3] "../MachineLearning/CountryReports/2013/swd2013_austria_en.txt" <br/>## [4] "../MachineLearning/CountryReports/2014/swd2014_austria_en_0.txt"</pre>
<p>It is also possible to obtain the complete list of terms and their frequency:</p>
<pre>freq &lt;- rowSums(as.matrix(tdm2_train2))<br/>ord &lt;- order(freq,decreasing=TRUE)</pre>
<p>This is the list of the most repeated terms:</p>
<pre>freq[head(ord,20)]<br/><br/> ##    gdp    rate increas  market  labour  sector     tax  growth  public<br/> ##  20566   16965   15795   15759   15751   15381   14582   14545   14515<br/> ##   year  employ  energi  invest  measur  govern    debt    bank    term<br/> ##  13118   12481   12330   12027   11341   10903   10854   10668   10470<br/> ##  averag  social<br/> ##  10059   10051</pre>
<p>For visualization, it is possible to create a word cloud plot with the most frequent words in our documents. To do this, we can use the <kbd>wordcloud</kbd> package:</p>
<pre>library(wordcloud)<br/>set.seed(1234)<br/>wordcloud(row.names(tdm2_train2), freq = freq, max.words=200,min.freq=4000,scale=c(2,.4),<br/>random.order = FALSE,rot.per=.5,vfont=c("sans serif","plain"),colors=palette())</pre>
<p>This is how the result looks:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-743 image-border" src="assets/6889a888-e48a-47da-b41a-95180134c96a.png" style=""/></div>
<p>It looks pretty, right?</p>
<p>Now, we need to convert the previous matrix to have countries in rows and terms in columns. In summary, we need to transpose both the train and test matrices:</p>
<pre>tdm2_train2 &lt;- as.matrix(tdm2_train2)<br/>dim(tdm2_train2)<br/>## [1] 6480  165<br/>tdm2_train2 &lt;- t(tdm2_train2)<br/>tdm2_test2&lt;-as.matrix(tdm2_test)<br/>tdm2_test2 &lt;- t(tdm2_test2)<br/> <br/>rm(tdm2_test)</pre>
<p>Again, some irrelevant objects are removed:</p>
<pre>rm(list=setdiff(ls(), c("macroeconomic_data","train_list","test_list","tdm2_test2","tdm2_train2")))</pre>
<p>And the workspace is again saved as a backup:</p>
<pre>save.image("Backup7.RData")</pre>
<p>At this point, we have processed our reports and we have extracted some features, terms, and combinations of words. Nevertheless, the target variable, the country rating, is not present in our new dataset. The credit rating is only present in the <kbd>macroeconomic_data</kbd> sample.</p>
<p>In the following code, we will add credit ratings to our recently created training and validation matrices:</p>
<pre>train_list&lt;-merge(train_list[,c("Year","CountryName","year_report")],macroeconomic_data[,c("CountryName","Year","RatingMayT1")],by=c("CountryName","Year"),all.x=TRUE)<br/> <br/>test_list&lt;-merge(test_list[,c("Year","CountryName","year_report")],macroeconomic_data[,c("CountryName","Year","RatingMayT1")],by=c("CountryName","Year"),all.x=TRUE)<br/>training &lt;- cbind(train_list,tdm2_train2)<br/> <br/>validation &lt;- cbind(test_list,tdm2_test2)</pre>
<p>As the number of features to train in our model is quite high (more than 6,000), we will assess how correlated our features are with the credit ratings, to help discard some of them.</p>
<p>First, we will create a data frame that contains our list of terms and the correlation with the credit ratings. The first three variables have to be excluded. This is shown in the following code:</p>
<pre>head(colnames(training),7)<br/><br/>## [1] "CountryName" "Year"        "year_report" "RatingMayT1" "­ gj"       <br/>## [6] "­ mwh"       "± ±"</pre>
<p>Now that we have the correlations, let's put them in descending order:</p>
<pre>correlations&lt;-data.frame(correlations)<br/>colnames(correlations)&lt;-c("word","correlation")<br/>correlations$abs_corr&lt;-abs(as.numeric(as.character(correlations$correlation)))<br/>correlations&lt;-correlations[order(correlations$abs_corr,decreasing = TRUE),]<br/>correlations = matrix("NA",nrow=(ncol(training)-4),2) <br/>ncolumns&lt;-ncol(training)<br/> <br/> for (i in 5:ncolumns)<br/>{<br/>   correlations[i-4,1]&lt;-colnames(training[i])<br/>   correlations[i-4,2]&lt;-  as.numeric(cor(training[,i],as.numeric(as.character(training[,"RatingMayT1"]))))<br/>}</pre>
<p>Here are the top 10 most correlated variables with credit ratings:</p>
<pre>head(correlations,10)<br/> ##               word        correlation  abs_corr<br/> ## 3245        judici -0.495216233392176 0.4952162<br/> ## 1175         court   -0.4939081009835 0.4939081<br/> ## 132      administr -0.470760214895828 0.4707602<br/> ## 3710       migrant  0.460837714113155 0.4608377<br/> ## 1343         delay  -0.46038844705712 0.4603884<br/> ## 468     background  0.455839970556903 0.4558400<br/> ## 116          adequ -0.445062248908142 0.4450622<br/> ## 2811        immigr  0.428818668867468 0.4288187<br/> ## 3246 judici system  -0.42745138771952 0.4274514<br/> ## 6106      undeclar -0.419206156830568 0.4192062</pre>
<p>Apparently, the <kbd>judici</kbd> root, which comes from words such as <em>judicial</em>, is very correlated with credit ratings. The negative sign indicates that countries in which the specific words appear very frequently in the country report have a lower credit quality. </p>
<p>We will only use the top 1,000 words to train our model. A list with the top 1,000 terms is created here:</p>
<pre>list_vars&lt;-dput(as.vector(correlations$word[1:1000]))</pre>
<p>Before training the model, let's save the workspace one more time:</p>
<pre>save.image("Backup8.RData")</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>It is time to train the model. The selected model is a pure Lasso model, because it is demonstrated that this kind of model works well where the number of columns or features is high, acting as an approach to variable selection.</p>
<p>This approach was already used in <em>chapter 5: Predicting the Failures of Banks - Multivariate Analysis </em>with the <kbd>h2o</kbd> package. <span>This time, we will use the</span><span> </span><kbd>glmnet</kbd><span> </span><span>package only for academic purposes and with the aim that the reader can apply different solutions:</span></p>
<pre>library(glmnet)</pre>
<p><span>The </span><kbd>glmnet</kbd><span> package needs a matrix with variables and a vector with the class labels or the target values. </span></p>
<p>Let's make sure that our target variable is a <kbd>factor</kbd>:</p>
<pre>training$RatingMayT1&lt;-as.factor(training$RatingMayT1)<br/>validation$RatingMayT1&lt;-as.factor(validation$RatingMayT1)</pre>
<p>Dependent and independent variables are stored in different objects to train the model, shown in the following code:</p>
<pre>xtrain&lt;-training[,list_vars]<br/>ytrain&lt;-training$RatingMayT1</pre>
<p>Like the preceding code, the same steps are carried out in the validation sample:</p>
<pre>validation$RatingMayT1&lt;-as.factor(validation$RatingMayT1)<br/>xtest&lt;-validation[,list_vars]<br/>ytest&lt;-validation$RatingMayT1</pre>
<p>We will also use the <kbd>cv.glmnet</kbd> function in the training process, which automatically performs a grid search to find the optimal value of λ, needed in the Lasso algorithm.</p>
<p>The most important parameters in this function are the following:</p>
<ul>
<li><kbd>y</kbd>: Our target variable, in our case, the credit rating.</li>
<li><kbd>x</kbd>: A matrix that contains all the independent variables of our features.</li>
<li><kbd>alpha</kbd>: In our case, with a value of <kbd>1</kbd> to indicate that the model is a Lasso.</li>
<li><kbd>family</kbd>: The type of our response variable. If target variable has only two levels, family should be defined as <kbd>binomial</kbd>. In our case, as our target variable displays more than two levels, the family should be specified as <kbd>multinomial</kbd>.</li>
<li><kbd>type.multinomial</kbd>: If <kbd>grouped</kbd>, a grouped Lasso penalty is used on the <kbd>multinomial</kbd> coefficients for a variable. The default is <kbd>ungrouped</kbd>.</li>
<li><kbd>parallel</kbd>: If <kbd>TRUE</kbd>, the algorithm is processed in parallel. This means the algorithm splits the different tasks and executes them simultaneously, significantly reducing the training time. </li>
</ul>
<p>Here is the application of this function with the current data:</p>
<pre>set.seed(1234)<br/> <br/>ModelLasso &lt;- cv.glmnet(y =  ytrain, x=data.matrix(xtrain[,list_vars]), alpha=1,family='multinomial',type.multinomial = "grouped",parallel=TRUE)</pre>
<p>During the execution of this code, a warning message arises: <kbd>one multinomial or binomial class has fewer than 8 observations; dangerous ground</kbd>.</p>
<p>The problem is that we don't have enough observations for all the categories in our target variable. We can check the number of different categories in the target variable by running the following code:</p>
<pre>table(ytrain)<br/> ## ytrain<br/> ##  1  2  3  4  5  6 <br/> ##  5 23 33 32 34 38</pre>
<p>For rating <kbd>1</kbd>, there are only <kbd>5</kbd> observations. As a consequence, it is probably not expected to have any stable estimates for this category.</p>
<p>One solution could be to merge ratings <kbd>1</kbd> and <kbd>2</kbd> into the same rating category:</p>
<pre>ytrain&lt;-gsub("1","2",ytrain)<br/>ytest&lt;-gsub("1","2",ytest)</pre>
<p>Now, the problem should not appear:</p>
<pre>table(ytrain)<br/> ## ytrain<br/> ##  2  3  4  5  6 <br/> ## 28 33 32 34 38<br/>set.seed(1234)<br/> <br/>ModelLasso &lt;- cv.glmnet(y =  ytrain, x=data.matrix(xtrain[,list_vars]), alpha=1,family='multinomial',type.multinomial = "grouped")</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>Once the model is trained, the following plot helps to find the <kbd>lambda</kbd> parameter, which reduces the model's error: </p>
<pre>plot(ModelLasso)</pre>
<p>The optimal log value <span>is approximately</span> <kbd>-3</kbd><span>, according to the following plot:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-744 image-border" src="assets/a48280b9-1bc5-4432-9405-908bdad2286f.png" style=""/></div>
<p>The exact value can be viewed by examining the <kbd>lambda_min</kbd> variable in the code:</p>
<pre>log(ModelLasso$lambda.min)<br/>## [1] -3.836699</pre>
<p>The objective of regularization methods is to find a trade-off between accuracy and simplicity, which means to obtain a model with the smallest number of coefficients that also gives a good accuracy. In this vein, the <kbd>cv.glmnet</kbd> function also helps to find the model in which the error is within one standard error of the minimum.</p>
<p>This value of <kbd>lambda</kbd> can be found in the <kbd>lambda.1se</kbd> variable. This value will be selected as the resultant <kbd>lambda</kbd> of our model:</p>
<pre>best_lambda &lt;- ModelLasso$lambda.1se<br/>print(best_lambda)<br/>## [1] 0.05727767</pre>
<p>Now, it is time to assess the accuracy of our model. First, let's look at the training sample:</p>
<pre>predictLASSO_train &lt;- predict(ModelLasso, newx = data.matrix(xtrain[,list_vars]), <br/>type = "class", s = ModelLasso$lambda.1se)<br/> <br/>predictLASSO_train&lt;-as.data.frame(cbind(training[,1:2],ytrain ,predictLASSO_train))<br/>colnames(predictLASSO_train)&lt;-c("Country","Year","Rating","Prediction")</pre>
<p>The following is the table of results for the training sample:</p>
<pre>table(predictLASSO_train$Rating,predictLASSO_train$Prediction)<br/> ##      2  3  4  5  6<br/> ##   2 27  0  0  0  1<br/> ##   3  1 32  0  0  0<br/> ##   4  0  1 30  0  1<br/> ##   5  0  0  0 33  1<br/> ##   6  0  0  0  1 37</pre>
<p>Now, let's look at the accuracy of the validation sample:</p>
<pre>predictLASSO_test &lt;- predict(ModelLasso, newx = data.matrix(xtest), <br/>type = "class", s = ModelLasso$lambda.1se)<br/> <br/>predictLASSO_test&lt;-as.data.frame(cbind(validation[,1:2],ytest ,predictLASSO_test))<br/>colnames(predictLASSO_test)&lt;-c("Country","Year","Rating","Prediction")</pre>
<p>The following is the table of results for the validation sample:</p>
<pre><br/>table(predictLASSO_test$Rating,predictLASSO_test$Prediction)<br/> ##      2  3  4  5  6<br/> ##   2  5  3  1  0  1<br/> ##   3  1  7  1  0  0<br/> ##   4  0  0  7  0  3<br/> ##   5  0  1  1  8  2<br/> ##   6  0  0  0  2 10</pre>
<p>The results seem to be good enough, considering that we used country reports. As we did when models were trained using macroeconomic data, we will calculate the percentage of correctly classified countries with the following function:</p>
<pre>model_assessment&lt;-function(data,model)<br/> {<br/> data$Observed&lt;-as.numeric(as.character(data$Rating))<br/> data$Predicted&lt;-as.numeric(as.character(data$Prediction))<br/> data$df&lt;-abs(as.numeric(data$Predicted)-as.numeric(data$Observed))<br/> comparison&lt;-as.data.frame(table(data$df))<br/> comparison$perc&lt;-comparison$Freq/nrow(data)<br/> colnames(comparison)&lt;-c("notch","N",paste("perc_",model,sep=''))<br/> comparison$N&lt;-NULL<br/> return(comparison)<br/> }</pre>
<p>Let's run the assessment for this model:</p>
<pre>model_assessment(predictLASSO_train,"Train_LASSO")<br/> ##   notch perc_Train_LASSO<br/> ## 1     0      0.963636364<br/> ## 2     1      0.024242424<br/> ## 3     2      0.006060606<br/> ## 4     4      0.006060606<br/>model_assessment(predictLASSO_test,"Test_LASSO")<br/> ##   notch perc_Test_LASSO<br/> ## 1     0      0.69811321<br/> ## 2     1      0.18867925<br/> ## 3     2      0.09433962<br/> ## 4     4      0.01886792</pre>
<p>The Lasso model is able to predict 69.81% of countries correctly on the validation sample. The resultant model slightly improves the results obtained using only macroeconomic data, with an accuracy level attained of 67.86%.</p>
<p>Finally, it is very interesting to assess the most relevant terms that appear in country reports and that determine the credit rating of a country.</p>
<p>The following function is useful to extract the coefficients of the model:</p>
<pre>coefs&lt;-coef(ModelLasso, s = "lambda.1se")</pre>
<p>The result is a list with the different coefficients for each rating level. For example, the coefficients for the credit ratings 1 and 2 (these categories were merged previously in this section) are obtained. This is shown in the following code:</p>
<pre>coefs2&lt;-coefs$`2`<br/> list_coefs2&lt;-as.data.frame(coefs2@Dimnames)<br/> colnames(list_coefs2)&lt;-c("variable","id")<br/> list_coefs2$id&lt;-as.numeric(row.names(list_coefs2))-1<br/> aux_coefs2&lt;-cbind(as.data.frame(coefs2@i),as.data.frame(coefs2@x))<br/> colnames(aux_coefs2)&lt;-c("id","coefficient")<br/> list_coefs2&lt;-merge(list_coefs2,aux_coefs2,by.x="id")<br/> rm(coefs2,aux_coefs2)</pre>
<p>Some of the most relevant terms are shown here:</p>
<pre>head(list_coefs2[order(list_coefs2$coefficient,decreasing = TRUE),],10)<br/> ##     id         variable coefficient<br/> ## 18  69      financ need  0.24991828<br/> ## 37 192        personnel  0.13635379<br/> ## 44 305          outflow  0.11243899<br/> ## 15  51    energi sector  0.06854058<br/> ## 24  97    minimum incom  0.05821313<br/> ## 39 216     gross extern  0.05237113<br/> ## 10  37          resolut  0.04807981<br/> ## 72 700           analyt  0.03036531<br/> ## 75 774 healthcar sector  0.02997181<br/> ## 26 102   social benefit  0.02572995</pre>
<p>A positive sign indicates that the more a term appears in the country report, the lower the credit quality of the country.</p>
<p>Let's check whether this is observed properly. For example, the model checked some of the sentences that contain <kbd>financ need</kbd> in the country report of Cyprus in 2018. Here are three sections of the report:</p>
<ul>
<li>Cyprus does not appear to face immediate risks of fiscal stress, owing to its favorable fiscal position. This is mainly thanks to the improvement of the general government fiscal balance and primary balance, low gross financing needs, and relatively low short-term general government debt. These more than offset the still-sizeable public debt. However, short-term risks on the macro-financial side remain significant.</li>
<li>Limited access to finance and the need to reduce debt still restrain private-sector investment.</li>
<li>Public debt has decreased significantly, but remains high, at around 99 % of GDP in 2017. High public debt makes Cyprus vulnerable to financial or economic shocks. However, the large proportion of long-term low-interest debt provided by external creditors during the economic adjustment program, the current low sovereign bond yields, and relatively low medium-term financing needs mitigate refinancing risks.</li>
</ul>
<p>In these three sections, stopwords were removed, which is the reason for finding <kbd>financ need</kbd>.</p>
<p>Different coefficients can be obtained for the best rating category as well. This can be done through the following code:</p>
<pre>coefs6&lt;-coefs$`6`<br/> list_coefs6&lt;-as.data.frame(coefs6@Dimnames)<br/> colnames(list_coefs6)&lt;-c("variable","id")<br/> list_coefs6$id&lt;-as.numeric(row.names(list_coefs6))-1<br/> aux_coefs6&lt;-cbind(as.data.frame(coefs6@i),as.data.frame(coefs6@x))<br/> colnames(aux_coefs6)&lt;-c("id","coefficient")<br/> list_coefs6&lt;-merge(list_coefs6,aux_coefs6,by.x="id")<br/> rm(coefs6,aux_coefs6)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Here are some of the most relevant terms we found:</p>
<pre>head(list_coefs6[order(list_coefs6$coefficient,decreasing = TRUE),],10)<br/> ##     id         variable coefficient<br/> ## 45 309          remaind  0.22800169<br/> ## 1    0      (Intercept)  0.20122381<br/> ## 7   20    govern balanc  0.15410796<br/> ## 81 899         stimulus  0.11734883<br/> ## 82 918   europ strategi  0.06968609<br/> ## 17  57 interest payment  0.05516403<br/> ## 49 367     fiscal posit  0.04272709<br/> ## 65 568   contribut rate  0.03101503<br/> ## 38 207            decad  0.03063200<br/> ## 2    6       background  0.03029957</pre>
<p>Some sentences are also obtained for an example report. For example, for Germany in 2018, the following sentences contain the combination <kbd>govern balanc</kbd>:</p>
<ul>
<li>Germany has consistently improved its government balance, turning it into a surplus from 2014 onward.</li>
<li>The positive government balance is also reflected in falling government debt, which reached 70.9% in 2015, falling further to 68.1% in 2016.</li>
</ul>
<p>To conclude, keep a backup of all your models in case you want to use them later:</p>
<pre>save.image("Backup9.RData")</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you learned some introductory concepts of text-mining and topic extraction. You should now know how to read text files and process raw text to obtain useful common words. Also, you are now able to use the information collected in a text format in your own problems. </p>
<p>Depending on the amount of data and the type of problem you want to solve, you could now apply a variety of techniques, both simple and complex, used previously in this book.  </p>
<p>Finally, and taking into account this chapter, you are ready to dive into other more recent and promising techniques, such as <kbd>word2vec</kbd> and <kbd>doc2vec</kbd>, which are both advanced techniques that allow you to discover relevant information or topics in a piece of text and documents. If you're curious, you can research these topics further.</p>
<p>I hope you got an in-depth view of machine learning and that this book has helped you get started with solving problems using machine learning. Thanks for reading, and all the best!</p>


            </article>

            
        </section>
    </body></html>