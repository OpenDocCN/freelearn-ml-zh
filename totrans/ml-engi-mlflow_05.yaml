- en: '*Chapter 3*: Your Data Science Workbench'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn about MLflow in the context of creating a local
    environment so that you can develop your machine learning project locally with
    the different features provided by MLflow. This chapter is focused on machine
    learning engineering, and one of the most important roles of a machine learning
    engineer is to build up an environment where model developers and practitioners
    can be efficient. We will also demonstrate a hands-on example of how we can use
    workbenches to accomplish specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will look at the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the value of a data science workbench
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating your own data science workbench
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the workbench for stock prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following prerequisites:'
  prefs: []
  type: TYPE_NORMAL
- en: The latest version of Docker installed on your machine. If you don’t already
    have it installed, please follow the instructions at [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of Docker Compose installed. If you don’t already have it
    installed, please follow the instructions at https://docs.docker.com/compose/install/.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Access to Git in the command line, and installed as described in this **Uniform
    Resource Locator** (**URL**): [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a `bash` terminal (Linux or Windows).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a browser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3.5+ installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MLflow installed locally, as described in [*Chapter 1*](B16783_01_Final_SB_epub.xhtml#_idTextAnchor015),
    *Introducing MLflow*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the value of a data science workbench
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A data science workbench is an environment to standardize the machine learning
    tools and practices of an organization, allowing for rapid onboarding and development
    of models and analytics. One critical machine learning engineering function is
    to support data science practitioners with tools that empower and accelerate their
    day-to-day activities.
  prefs: []
  type: TYPE_NORMAL
- en: In a data science team, the ability to rapidly test multiple approaches and
    techniques is paramount. Every day, new libraries and open source tools are created.
    It is common for a project to need more than a dozen libraries in order to test
    a new type of model. These multitudes of libraries, if not collated correctly,
    might cause bugs or incompatibilities in the model.
  prefs: []
  type: TYPE_NORMAL
- en: Data is at the center of a data science workflow. Having clean datasets available
    for developing and evaluating models is critical. With an abundance of huge datasets,
    specialized big data tooling is necessary to process the data. Data can appear
    in multiple formats and velocities for analysis or experimentation, and can be
    available in multiple formats and mediums. It can be available through files,
    the cloud, or **REpresentational State Transfer** (**REST**) **application programming
    interfaces** (**APIs**).
  prefs: []
  type: TYPE_NORMAL
- en: Data science is mostly a collaborative craft; it’s part of a workflow to share
    models and processes among team members. Invariably, one pain point that emerges
    from that activity is the cross-reproducibility of model development jobs among
    practitioners. Data scientist A shares a training script of a model that assumes
    version 2.6 of a library, but data scientist B is using version 2.8 environment.
    Tracing and fixing the issue can take hours in some cases. If this problem occurs
    in a production environment, it can become extremely costly to the company.
  prefs: []
  type: TYPE_NORMAL
- en: When iterating—for instance—over a model, each run contains multiple parameters
    that can be tweaked to improve it. Maintaining traceability of which parameter
    yielded a specific performance metric—such as accuracy, for instance—can be problematic
    if we don’t store details of the experiment in a structured manner. Going back
    to a specific batch of settings that produced a better model may be impossible
    if we only keep the latest settings during the model development phase.
  prefs: []
  type: TYPE_NORMAL
- en: The need to iterate quickly can cause many frustrations when translating prototype
    code to a production environment, where it can be executed in a reliable manner.
    For instance, if you are developing a new trading model in a Windows machine with
    easy access to **graphics processing units** (**GPUs**) for inference, your engineering
    team member may decide to reuse the existing Linux infrastructure without GPU
    access. This leads to a situation where your production algorithm ends up taking
    5 hours and locally runs in 30 seconds, impacting the final outcome of the project.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is clear that a data science department risks systemic technical pain if
    issues related to the environment and tools are not addressed upfront. To summarize,
    we can list the following main points as described in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: Reproducibility friction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The complexity of handling large and varied datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Poor management of experiment settings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drift between local and production environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A data science workbench addresses the pain points described in this section
    by creating a structured environment where a machine learning practitioner can
    be empowered to develop and deploy their models reliably, with reduced friction.
    A no-friction environment will allow highly costly model development hours to
    be focused on developing and iterating models, rather than on solving tooling
    and data technical issues.
  prefs: []
  type: TYPE_NORMAL
- en: After having delved into the motivation for building a data science workbench
    for a machine learning team, we will next start designing the data science workbench
    based on known pain points.
  prefs: []
  type: TYPE_NORMAL
- en: Creating your own data science workbench
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to address common frictions for developing models in data science,
    as described in the previous section, we need to provide data scientists and practitioners
    with a standardized environment in which they can develop and manage their work.
    A data science workbench should allow you to quick-start a project, and the availability
    of an environment with a set of starting tools and frameworks allows data scientists
    to rapidly jump-start a project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data scientist and machine learning practitioner are at the center of the
    workbench: they should have a reliable platform that allows them to develop and
    add value to the organization, with their models at their fingertips.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram depicts the core features of a data science workbench:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – Core features of a data science workbench'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16783_03_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.1 – Core features of a data science workbench
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to think about the design of our data science workbench and based
    on the diagram in *Figure 3.1*, we need the following core features in our data
    science workbench:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dependency Management**: Having dependency management built into your local
    environment helps in handling reproducibility issues and preventing library conflicts
    between different environments. This is generally achieved by using environment
    managers such as Docker or having environment management frameworks available
    in your programming language. MLflow provides this through the support of Docker-
    or Conda-based environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Management**: Managing data in a local environment can be complex and
    daunting if you have to handle huge datasets. Having a standardized definition
    of how you handle data in your local projects allows others to freely collaborate
    on your projects and understand the structures available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model Management**: Having the different models organized and properly stored
    provides an easy structure to be able to work through many ideas at the same time
    and persist the ones that have potential. MLflow helps support this through the
    model format abstraction and **Model Registry** component to manage models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment**: Having a development environment aligned with the production
    environment where the model will be serviced requires deliberation in the local
    environment. The production environment needs to be ready to receive a model from
    a model developer, with the least possible friction. This smooth deployment workflow
    is only possible if the local environment is engineered correctly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Experimentation Management**: Tweaking parameters is the most common thing
    that a machine learning practitioner does. Being able to keep abreast of the different
    versions and specific parameters can quickly become cumbersome for the model developer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this section, we will implement the foundations of a data science workbench
    from scratch with MLflow, with support primarily for local development. There
    are a couple of very opinionated and feature-rich options provided by cloud providers
    such as **Amazon Web Services** (**AWS**) Sagemaker, Google AI, and **Azure Machine
    Learning** (**Azure ML**).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Machine learning engineering teams have freedom in terms of the use cases and
    technologies that the team they are serving will use.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps demonstrate a good workflow for development with a data
    science workbench:'
  prefs: []
  type: TYPE_NORMAL
- en: The model developer installs the company workbench package through an installer
    or by cloning the repository.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model developer runs a command to start a project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model developer chooses a set of options based on configuration or a prompt.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The basic scaffolding is produced with specific folders for the following items:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a) `Data`: This will contain all the data assets of your current project'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) `Notebooks`: To hold all the iterative development notebooks with all the
    steps required to produce the model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) `Model`: A folder that contains the binary model or a reference to models,
    potentially in binary format'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd) `Source Code`: A folder to store the structured code component of the code
    and reusable libraries'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'e) `Output`: A folder for any specific outputs of the project—for instance,
    visualizations, reports, or predictions'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A project folder is created with the standards for the organization around packages,
    dependency management, and tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model developer is free to iterate and create models using supported tooling
    at an organizational level.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establishing a data science workbench provides a tool for acceleration and democratization
    of machine learning in the organization, due to standardization and efficient
    adoption of machine learning best practices.
  prefs: []
  type: TYPE_NORMAL
- en: We will start our workbench implementation in our chapter with sensible components
    used industrywide.
  prefs: []
  type: TYPE_NORMAL
- en: Building our workbench
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will have the following components in the architecture of our development
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Docker/Docker Compose**: Docker will be used to handle each of the main component
    dependencies of the architecture, and Docker Compose will be used as a coordinator
    between different containers of software pieces. The advantage of having each
    component of the workbench architecture in Docker is that neither element’s libraries
    will conflict with the other.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**JupyterLab**: The de facto environment to develop data science code and analytics
    in the context of machine learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MLflow**: MLflow is at the cornerstone of the workbench, providing facilities
    for experiment tracking, model management, registry, and deployment interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PostgreSQL database**: The PostgreSQL database is part of the architecture
    at this stage, as the storage layer for MLflow for backend metadata. Other relational
    databases could be used as the MLflow backend for metadata, but we will use PostgreSQL.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our data science workbench design can be seen in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Our data science workbench design'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0021.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.2 – Our data science workbench design
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.2* illustrates the layout of the proposed components that will underpin
    our data science workbench.'
  prefs: []
  type: TYPE_NORMAL
- en: The usual workflow of the practitioner, once the environment is up and running,
    is to develop their code in Jupyter and run their experiments with MLflow support.
    The environment will automatically route to the right MLflow installation configured
    to the correct backend, as shown in *Figure 3.2*.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Our data science workbench, as defined in this chapter, is a complete local
    environment. As the book progresses, we will introduce cloud-based environments
    and link our workbench to shared resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'A sample layout of the project is available in the following GitHub folder:'
  prefs: []
  type: TYPE_NORMAL
- en: https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter03/gradflow
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see a representation of the general layout of the workbench in terms
    of files here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The main elements of this folder structure are outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Makefile`: This allows control of your workbench. By issuing commands, you
    can ask your workbench to set up a new environment notebook to start MLflow in
    different formats.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`README.md`: A file that contains a sample description of your project and
    how to run it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data` folder: A folder where we store the datasets used during development
    and mount the data directories of the database when running locally.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker`: A folder that encloses the Docker images of the different subsystems
    that our environment consists of.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker-compose.yml`: A file that contains the orchestration of different services
    in our workbench environment—namely: Jupyter Notebooks, MLflow, and PostgreSQL
    to back MLflow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docs`: Contains relevant project documentation that we want persisted for
    the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`notebooks`: A folder that contains the notebook information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`requirements.txt`: A requirements file to add libraries to the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src`: A folder that encloses the source code of the project, to be updated
    in further phases of the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tests`: A folder that contains end-to-end testing for the code of the project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tox.ini`: A templated file that controls the execution of unit tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will now move on to using our own development environment for a stock-prediction
    problem, based on the framework we have just built.
  prefs: []
  type: TYPE_NORMAL
- en: Using the workbench for stock prediction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will use the workbench step by step to set up a new project.
    Follow the instructions step by step to start up your environment and use the
    workbench for the stock-prediction project.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It is critical that all packages/libraries listed in the *Technical requirements*
    section are correctly installed on your local machine to enable you to follow
    along.
  prefs: []
  type: TYPE_NORMAL
- en: Starting up your environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will move on next to exploring your own development environment, based on
    the development environment shown in this section. Please execute the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Copy the contents of the project available in https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter03/gradflow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start your local environment by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inspect the created environments, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following screenshot presents three Docker images: the first for Jupyter,
    the second for MLflow, and the third for the PostgreSQL database. The status should
    show `Up x minutes`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Running Docker images'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0031.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.3 – Running Docker images
  prefs: []
  type: TYPE_NORMAL
- en: 'The usual ports used by your workbench are listed as follows: Jupyter serves
    in port `8888`, MLflow serves in port `5000`, and PostgreSQL serves in port `5432`.'
  prefs: []
  type: TYPE_NORMAL
- en: In case any of the containers fail, you might want to check if the ports are
    used by different services. If this is the case, you will need to turn off all
    of the other services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check your Jupyter Notebooks environment at [http://localhost:8888](http://localhost:8888),
    as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Running Jupyter environment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0041.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.4 – Running Jupyter environment
  prefs: []
  type: TYPE_NORMAL
- en: You should have a usable environment, allowing you to create new `notebooks`
    file in the specified folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check your MLflow environment at http://localhost:5000, as illustrated in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – Running MLflow environment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0051.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.5 – Running MLflow environment
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.5* shows your experiment tracker environment in MLflow that you will
    use to visualize your experiments running in MLflow.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run a sample experiment in MLflow by running the `notebook` file available
    in `/notebooks/mlflow_sample.ipynb`, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – Excerpt of mlflow_sample code'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0061.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.6 – Excerpt of mlflow_sample code
  prefs: []
  type: TYPE_NORMAL
- en: The code in *Figure 3.6* imports MLflow and creates a dummy experiment manually,
    on the second line, using `mlflow.set_experiment(‘mlflow_experiment’)`.
  prefs: []
  type: TYPE_NORMAL
- en: The `with mlflow.start_run()` line is responsible for starting and tearing down
    the experiment in MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: In the three following lines, we log a couple of string-type test parameters,
    using the `mlflow.log_param` function. To log numeric values, we will use the
    `mlflow.log_metric` function.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we also log the entire file that executed the function to ensure traceability
    of the model and code that originated it, using the `mlflow.log_artifact(“mlflow_example.ipynb”)`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the sample runs, to confirm that the environment is working correctly.
    You should go back to the MLflow **user interface** (**UI**) available at http://localhost:5000
    and check if the new experiment was created, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – MLflow test experiment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0071.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.7 – MLflow test experiment
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.7* displays the additional parameters that we used on our specific
    experiment and the specific metric named `i` that is visible in the **Metrics**
    column.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you should click on the experiment created to have access to the details
    of the run we have executed so far. This is illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 – MLflow experiment details'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0081.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.8 – MLflow experiment details
  prefs: []
  type: TYPE_NORMAL
- en: Apart from details of the metrics, you also have access to the `mlflow_example`
    notebook file at a specific point in time.
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, you have your environment running and working as expected. Next,
    we will update it with our own algorithm; we’ll use the one we created in [*Chapter
    2*](B16783_02_Final_SB_epub.xhtml#_idTextAnchor030), *Your Machine Learning Project*.
  prefs: []
  type: TYPE_NORMAL
- en: Updating with your own algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s update the notebook file that we created in [*Chapter 2*](B16783_02_Final_SB_epub.xhtml#_idTextAnchor030),
    *ML Problem Framing*, and add it to the notebook folder on your local workbench.
    The code excerpt is presented here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Under the `notebook` folder in the `notebooks/stockpred_randomizer.ipynb` file,
    you can follow along with the integration of the preceding code excerpt in our
    recently created data science workbench. We will proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We will first import all the dependencies needed and run the first cell of the
    notebook, as follows:![Figure 3.9 – MLflow experiment details
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image0091.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 3.9 – MLflow experiment details
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s declare and execute the class outlined in *Figure 3.9*, represented in
    the second cell of the notebook, as follows:![Figure 3.10 – Notebook cell with
    the RandomPredictor class declaration
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image010.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 3.10 – Notebook cell with the RandomPredictor class declaration
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can now save our model in the MLflow infrastructure so that we can test the
    loading of the model. `model_path` holds the folder name where the model will
    be saved. You need to instantiate the model in an `r` variable and use `mlflow.pyfunc.save_model`
    to save the model locally, as illustrated in the following code snippet:![Figure
    3.11 – Notebook demonstrating saving the model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/image011.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 3.11 – Notebook demonstrating saving the model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can see on the left pane of your notebook environment that a new folder
    was created alongside your files to store your models. This folder will store
    the Conda environment and the pickled/binarized Python function of your model,
    as illustrated in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 3.12 – Notebook demonstrating the saved model folder'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/image012.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 3.12 – Notebook demonstrating the saved model folder
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we can load and use the model to check that the saved model is usable,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.13 – Notebook demonstrating the saved model folder'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image013.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.13 – Notebook demonstrating the saved model folder
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.14* demonstrates the creation of a random input `loaded_model` to
    predict over the input vector. We will run the experiment with the name `stockpred_experiment_days_up`,
    logging as a metric the number of days on which the market was up on each of the
    models, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.14 – Notebook cell demonstrating use of the loaded model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image014.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.14 – Notebook cell demonstrating use of the loaded model
  prefs: []
  type: TYPE_NORMAL
- en: 'To check the last runs of the experiment, you can look at http://localhost:5000
    and check that the new experiment was created, as illustrated in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.15 – Initial UI of MLflow for our stockpred experiment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image015.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.15 – Initial UI of MLflow for our stockpred experiment
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now compare multiple runs of our algorithm and see differences in the
    **Days Up** metric, as illustrated in the following screenshot. You can choose
    accordingly to delve deeper on a run that you would like to have more details
    about:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.16 – Logged details of the artifacts saved'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image016.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.16 – Logged details of the artifacts saved
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 3.16*, you can clearly see the logged details of our run—namely,
    the artifact model and the **Days Up** metric.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to tear down the environment properly, you must run the following
    command in the same folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced the concept of a data science workbench and explored some
    of the motivation behind adopting this tool as a way to accelerate our machine
    learning engineering practice.
  prefs: []
  type: TYPE_NORMAL
- en: We designed a data science workbench, using MLflow and adjacent technologies
    based on our requirements. We detailed the steps to set up your development environment
    with MLflow and illustrated how to use it with existing code. In later sections,
    we explored the workbench and added to it our stock-trading algorithm developed
    in the last chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will focus on experimentation to improve our models
    with MLflow, using the workbench developed in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to further your knowledge, you can consult the documentation in the
    following links:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cookiecutter documentation page: [https://cookiecutter.readthedocs.io/en/1.7.2/](https://cookiecutter.readthedocs.io/en/1.7.2/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reference information about cookie cutters: [https://drivendata.github.io/cookiecutter-data-science/](https://drivendata.github.io/cookiecutter-data-science/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The motivation behind data science workbenches: [https://dzone.com/articles/what-is-a-data-science-workbench-and-why-do-data-s#](https://dzone.com/articles/what-is-a-data-science-workbench-and-why-do-data-s#)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
