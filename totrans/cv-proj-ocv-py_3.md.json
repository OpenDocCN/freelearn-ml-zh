["```py\n%pylab notebook\nfigure()\nimshow(imread('tests/p1.jpg'))\n```", "```py\nimport cv2\nimport numpy as np\nimport pickle\ndef gray_thresh_img(input_image):\n     h, w, _ = input_image.shape\n     grayimg = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV)[:,:,2]\n\n     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n\n     tophat = cv2.morphologyEx(grayimg, cv2.MORPH_TOPHAT, kernel)\n     blackhat = cv2.morphologyEx(grayimg, cv2.MORPH_BLACKHAT, kernel)\n     graytop = cv2.add(grayimg, tophat)\n     contrastgray = cv2.subtract(graytop, blackhat)\n     blurred = cv2.GaussianBlur(contrastgray, (5,5), 0)\n     thesholded = cv2.adaptiveThreshold(blurred, 255.0, \n     cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n     cv2.THRESH_BINARY_INV, 19, 9)\n```", "```py\nreturn grayimg, thesholded\n```", "```py\ndef getmatchingchars(char_cands):\n    char_list = [] \n\n    for char_cand in char_cands:\n        ch_matches = [] \\n\",\n        for matching_candidate in char_cands: \n           if matching_candidate == char_cand:\n              continue \n          chardistance = np.sqrt((abs(char_cand.x_cent  - matching_candidate.x_cent) ** 2) +  \n          (abs(char_cand.y_cent - matching_candidate.y_cent)**2))\n          x = float(abs(char_cand.x_cent - matching_candidate.x_cent))\n          y = float(abs(char_cand.y_cent - matching_candidate.y_cent))\n          angle = np.rad2deg(np.arctan(y/x) if x != 0.0 else np.pi/2)\n\n          deltaarea = float(abs(matching_candidate.rect_area - char_cand.rect_area))\\\n          / float(char_cand.rect_area)\n         deltawidth = float(abs(matching_candidate.rect_w-char_cand.rect_w))\\\n         / float(char_cand.rect_w)\n         deltaheight = float(abs(matching_candidate.rect_h-char_cand.rect_h))\n         / float(char_cand.rect_h)\n\n         if (chardistance < (char_cand.hypotenuse * 5.0) and\n             angle < 12.0 and deltaarea < 0.5 and deltawidth < 0.8 \n             and deltaheight < 0.2):\n             ch_matches.append(matching_candidate) \n\n     ch_matches.append(char_cand) \n     if len(ch_matches) < 3: \n         continue \n\n     char_list.append(ch_matches) \n```", "```py\n    for charlist in getmatchingchars(list(set(char_cands)-set(ch_matches))):\n        char_list.append(charlist) \n    break \n\n return char_list\n\n# information container for possible characters in images\nclass charclass:\n     def __init__(self, _contour):\n         self.contour = _contour\n         self.boundingRect = cv2.boundingRect(self.contour)\n         self.rect_x, self.rect_y, self.rect_w, self.rect_h = self.boundingRect\n         self.rect_area = self.rect_w * self.rect_h\n         self.x_cent = (self.rect_x + self.rect_x + self.rect_w) / 2\n         self.y_cent = (self.rect_y + self.rect_y + self.rect_h) / 2\n         self.hypotenuse = np.sqrt((self.rect_w ** 2) + (self.rect_h ** 2))\n         self.aspect_ratio = float(self.rect_w) / float(self.rect_h)\n```", "```py\n# load pre-trained scikit-learn knn digit classifier\n    with open('knn.p', 'rb') as f:\n     knn = pickle.load(f) \"\n```", "```py\n%pylab notebook\n```", "```py\nimport cv2\nimport numpy as np\nimport pickle\ndef getmatchingchars(char_cands):\n    char_list = [] \n\n    for char_cand in char_cands:\n        ch_matches = [] \\n\",\n        for matching_candidate in char_cands: \n           if matching_candidate == char_cand:\n              continue \n          chardistance = np.sqrt((abs(char_cand.x_cent  - matching_candidate.x_cent) ** 2) +  \n          (abs(char_cand.y_cent - matching_candidate.y_cent)**2))\n          x = float(abs(char_cand.x_cent - matching_candidate.x_cent))\n          y = float(abs(char_cand.y_cent - matching_candidate.y_cent))\n          angle = np.rad2deg(np.arctan(y/x) if x != 0.0 else np.pi/2)\n\n          deltaarea = float(abs(matching_candidate.rect_area - char_cand.rect_area))\\\n          / float(char_cand.rect_area)\n         deltawidth = float(abs(matching_candidate.rect_w-char_cand.rect_w))\\\n         / float(char_cand.rect_w)\n         deltaheight = float(abs(matching_candidate.rect_h-char_cand.rect_h))\n         / float(char_cand.rect_h)\n\n         if (chardistance < (char_cand.hypotenuse * 5.0) and\n             angle < 12.0 and deltaarea < 0.5 and deltawidth < 0.8 \n             and deltaheight < 0.2):\n             ch_matches.append(matching_candidate) \n\n     ch_matches.append(char_cand) \n     if len(ch_matches) < 3: \n         continue \n\n     char_list.append(ch_matches) \n\n    for charlist in getmatchingchars(list(set(char_cands)-set(ch_matches))):\n        char_list.append(charlist) \n    break \n\n return char_list\n\n# information container for possible characters in images\nclass charclass:\n     def __init__(self, _contour):\n         self.contour = _contour\n         self.boundingRect = cv2.boundingRect(self.contour)\n         self.rect_x, self.rect_y, self.rect_w, self.rect_h = self.boundingRect\n         self.rect_area = self.rect_w * self.rect_h\n         self.x_cent = (self.rect_x + self.rect_x + self.rect_w) / 2\n         self.y_cent = (self.rect_y + self.rect_y + self.rect_h) / 2\n         self.hypotenuse = np.sqrt((self.rect_w ** 2) + (self.rect_h ** 2))\n         self.aspect_ratio = float(self.rect_w) / float(self.rect_h)\n```", "```py\ninput_image = plt.imread('tests/p5.jpg') #use cv2.imread or \n #import matplotlib.pyplot as plt\n #if running outside notebook\nfigure()\nimshow(input_image)\n```", "```py\ndef gray_thresh_img(input_image):\n     h, w, _ = input_image.shape\n     grayimg = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV)[:,:,2]\n\n     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n\n     tophat = cv2.morphologyEx(grayimg, cv2.MORPH_TOPHAT, kernel)\n     blackhat = cv2.morphologyEx(grayimg, cv2.MORPH_BLACKHAT, kernel)\n     graytop = cv2.add(grayimg, tophat)\n     contrastgray = cv2.subtract(graytop, blackhat)\n     blurred = cv2.GaussianBlur(contrastgray, (5,5), 0)\n     thesholded = cv2.adaptiveThreshold(blurred, 255.0, \n     cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n     cv2.THRESH_BINARY_INV, 19, 9)\n```", "```py\nh, w = input_image.shape[:2] \n\n# We don't use color information\n# + we need to binarize (theshold) image to find characters\ngrayimg, thesholded = gray_thresh_img(input_image)\ncontours = cv2.findContours(thesholded, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n\n# initialize variables for possible characters/plates in image\nchar_cands = [] \nplate_candidates = [] \n```", "```py\nfor index in range(0, len(contours)): \n    char_cand = charclass(contours[index])\n    if (char_cand.rect_area > 80 and char_cand.rect_w > 2 \n        and char_cand.rect_h > 8 and 0.25 < char_cand.aspect_ratio \n        and char_cand.aspect_ratio < 1.0):\n\n        char_cands.append(char_cand) \n```", "```py\nfor ch_matches in getmatchingchars(char_cands): \n     class blank: pass\n     plate_candidate = blank() \n\n     ch_matches.sort(key = lambda ch: ch.x_cent) \n\n     plate_w = int((ch_matches[len(ch_matches) - 1].rect_x + \\\n                    ch_matches[len(ch_matches) - 1].rect_w - ch_matches[0].rect_x) * 1.3)\n\n     sum_char_h = 0\n     for ch in ch_matches:\n         sum_char_h += ch.rect_h\n\n     avg_char_h = sum_char_h / len(ch_matches)\n     plate_h = int(avg_char_h * 1.5)\n\n     y = ch_matches[len(ch_matches) - 1].y_cent - ch_matches[0].y_cen\n     r = np.sqrt((abs(ch_matches[0].x_cent \n                   - ch_matches[len(ch_matches) - 1].x_cent) ** 2) \n                + (abs(ch_matches[0].y_cent \n                   - ch_matches[len(ch_matches) - 1].y_cent) ** 2))\n     rotate_angle = np.rad2deg(np.arcsin(y / r))\n```", "```py\n     platex = (ch_matches[0].x_cent + ch_matches[len(ch_matches) - 1].x_cent) / 2\n     platey = (ch_matches[0].y_cent + ch_matches[len(ch_matches) - 1].y_cent) / 2\n     plate_cent = platex, platey\n```", "```py\n     plate_candidate.plateloc = (tuple(plate_cent), (plate_w, plate_h), rotate_angle)\n     rotationMatrix = cv2.getRotationMatrix2D(tuple(plate_cent), rotate_angle, 1.0)\n```", "```py\n     rotated = cv2.warpAffine(input_image, rotationMatrix, tuple(np.flipud(input_image.shape[:2])))\n\n    plate_candidate.plate_im = cv2.getRectSubPix(rotated, (plate_w, plate_h), tuple(plate_cent))\n    if plate_candidate.plate_im is not None:\n        plate_candidates.append(plate_candidate)\n```", "```py\nfor plate_candidate in plate_candidates: \n\n    plate_candidate.grayimg, plate_candidate.thesholded = \\\n                              gray_thresh_img(plate_candidate.plate_im) \n    plate_candidate.thesholded = cv2.resize(plate_candidate.thesholded, \n                                             (0, 0), fx = 1.6, fy = 1.6)\n    thresholdValue, plate_candidate.thesholded = \\\n                               cv2.threshold(plate_candidate.thesholded, \n                                            0.0, 255.0, \n                                            cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n```", "```py\ncontours = cv2.findContours(plate_candidate.thesholded, cv2.RETR_LIST, \n cv2.CHAIN_APPROX_SIMPLE)[1]\nplate_chars = [] \n for contour in contours: \n char_cand = charclass(contour)\n if (char_cand.rect_area > 80 and char_cand.rect_w > 2 \n and char_cand.rect_h > 8 and 0.25 < char_cand.aspect_ratio \n and char_cand.aspect_ratio < 1.0):\n plate_chars.append(char_cand) \n```", "```py\nplate_chars = getmatchingchars(plate_chars)\n\n     if (len(plate_chars) == 0):\n     plate_candidate.chars = \\\"\n     continue\nfor index in range(0, len(plate_chars)): \n    plate_chars[index].sort(key = lambda ch: ch.x_cent) \n    filt_matching_chars = list(plate_chars[index])\n```", "```py\n    for thischar in plate_chars[index]:\n for alt_char in plate_chars[index]:\n if thischar != alt_char: \n chardistance = np.sqrt((abs(thischar.x_cent-alt_char.x_cent)**2) \n + (abs(thischar.y_cent-alt_char.y_cent) ** 2))\n if chardistance < (thischar.hypotenuse * 0.3):\n if thischar.rect_area < alt_char.rect_area: \n if thischar in filt_matching_chars: \n filt_matching_chars.remove(thischar) \n else: \n if alt_char in filt_matching_chars: \n filt_matching_chars.remove(alt_char) \n```", "```py\n     charlistlen = 0\n char_index = 0\n\n for index in range(0, len(plate_chars)):\n if len(plate_chars[index]) > charlistlen:\n charlistlen = len(plate_chars[index])\n char_index = index\n\n full_char_list = plate_chars[char_index]\n full_char_list.sort(key = lambda ch: ch.x_cent) \n\n plate_candidate.chars = \\\n for thischar in full_char_list: \n roi = plate_candidate.thesholded[thischar.rect_y : \n thischar.rect_y + thischar.rect_h,\n thischar.rect_x : \n thischar.rect_x + thischar.rect_w]\n\n resized_roi = np.float32(cv2.resize(roi, (20, 30)).reshape((1, -1)))\n plate_candidate.chars += str(chr(int(knn.predict(resized_roi)[0])))\n```", "```py\nif len(plate_candidates) > 0:\n    plate_candidates.sort(key = lambda plate_candidate: \n                           len(plate_candidate.chars), reverse = True)\n    best_plate = plate_candidates[0]\n    print(\"License plate read: \" + best_plate.chars + \"\\n\") \n```", "```py\nif len(plate_candidates) > 0: \n    plate_candidates.sort(key = lambda plate_candidate: \n                          len(plate_candidate.chars), reverse = True)\n    best_plate = plate_candidates[0]\n    print(\"License plate read: \" + best_plate.chars + \"\\n\")\n\nLicense plate read: LTLDBENZ\n```", "```py\nfigure()\nimshow(best_plate.thesholded)\n```", "```py\ninput_image = plt.imread('tests/p2.jpg') #use cv2.imread or \n                                         #import matplotlib.pyplot as plt\n                                         #if running outside notebook\nfigure()\nimshow(input_image)\n```", "```py\nimshow(best_plate.plate_im)\n```", "```py\nfigure()\n# best_plate.plate_im\nimshow(best_plate.plate_im)\nbest_plate.plateloc\n```", "```py\ninput_image = plt.imread('tests/p3.jpg') #use cv2.imread or \n                                         #import matplotlib.pyplot as plt\n                                         #if running outside notebook\nfigure()\nimshow(input_image)\n```", "```py\ninput_image = plt.imread('tests/p1.jpg') #use cv2.imread or \n                                         #import matplotlib.pyplot as plt\n                                         #if running outside notebook\nfigure()\nimshow(input_image)\n```"]