- en: '*Chapter 2*: Enabling and Operationalization'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*：启用和操作化'
- en: We have just learned the basics of what Elastic ML is doing to accomplish both
    unsupervised automated anomaly detection and supervised data frame analysis. Now
    it is time to get detailed about how Elastic ML works inside the Elastic Stack
    (Elasticsearch and Kibana).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚学习了Elastic ML的基本功能，它能够实现无监督的自动异常检测和监督数据帧分析。现在，是时候详细了解Elastic ML在Elastic
    Stack（Elasticsearch和Kibana）内部的工作原理了。
- en: 'This chapter will focus on both the installation (really, the enablement) of
    Elastic ML features and a detailed discussion of the logistics of the operation,
    especially with respect to anomaly detection. Specifically, we will cover the
    following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点介绍Elastic ML功能的安装（实际上，是启用）以及操作流程的详细讨论，特别是关于异常检测的部分。具体来说，我们将涵盖以下主题：
- en: Enabling Elastic ML features
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用Elastic ML功能
- en: Understanding operationalization
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解操作化
- en: Technical requirements
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The information in this chapter will use the Elastic Stack as it exists in v7.10
    and the workflow of the Elasticsearch Service of Elastic Cloud as of November
    2020.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的信息将使用v7.10版本的Elastic Stack以及截至2020年11月的Elastic Cloud的Elasticsearch服务的工作流程。
- en: Enabling Elastic ML features
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用Elastic ML功能
- en: The process for enabling Elastic ML features inside the Elastic Stack is slightly
    different if you are doing so within a self-managed cluster versus using the **Elasticsearch**
    **Service** (**ESS**) of Elastic Cloud. In short, on a self-managed cluster, the
    features of ML are enabled via a license key (either a commercial key or a trial
    key). In ESS, a dedicated ML node needs to be provisioned within the cluster in
    order to utilize Elastic ML. In the following sections, we will explain the details
    of how this is accomplished in both scenarios.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在Elastic Stack内部启用Elastic ML功能的流程，如果你是在自管理集群内操作，与使用Elastic Cloud的**Elasticsearch**
    **服务**（**ESS**）相比，略有不同。简而言之，在自管理集群上，ML功能通过许可证密钥（无论是商业密钥还是试用密钥）启用。在ESS中，需要在集群内配置一个专门的ML节点，以便利用Elastic
    ML。在接下来的章节中，我们将解释这两种场景下如何实现这一过程。
- en: Enabling ML on a self-managed cluster
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在自管理集群上启用ML
- en: If you have a self-managed cluster that was created from the downloading of
    Elastic's default distributions of Elasticsearch and Kibana (available at [elastic.co/downloads/](http://elastic.co/downloads/)),
    enabling Elastic ML features via a license key is very simple. Be sure to not
    use the Apache 2.0 licensed open source distributions that do not contain the
    X-Pack code base.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个通过下载Elastic的默认Elasticsearch和Kibana分发（可在[elastic.co/downloads/](http://elastic.co/downloads/)找到）创建的自管理集群，通过许可证密钥启用Elastic
    ML功能非常简单。请确保不要使用不包含X-Pack代码库的Apache 2.0许可的开源分发版。
- en: Elastic ML, unlike the bulk of the capabilities of the Elastic Stack, is not
    free – it requires a commercial (specifically, a **Platinum** level) license.
    It is, however, open source in that the source code is out in the open on GitHub
    ([github.com/elastic/ml-cpp](http://github.com/elastic/ml-cpp)) and that users
    can look at the code, file issues, make comments, or even execute pull requests.
    However, the usage of Elastic ML is governed by a commercial agreement with Elastic,
    the company.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与Elastic Stack的大部分功能不同，Elastic ML不是免费的——它需要一个商业（具体来说，是**铂金**级别）许可证。然而，它是开源的，因为源代码在GitHub上公开（[github.com/elastic/ml-cpp](http://github.com/elastic/ml-cpp)），用户可以查看代码、提交问题、发表评论，甚至执行拉取请求。但是，Elastic
    ML的使用受Elastic公司商业协议的约束。
- en: When Elastic ML was first released (back in the v5.x days), it was part of the
    closed source features known as **X-Pack** that required a separate installation
    step. However, as of version 6.3, the code of X-Pack was "opened" ([elastic.co/what-is/open-x-pack](http://elastic.co/what-is/open-x-pack))
    and folded into the default distribution of Elasticsearch and Kibana. Therefore,
    a separate X-Pack installation step was no longer necessary, just the "enablement"
    of the features via a commercial license (or a trial license).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当Elastic ML首次发布（在v5.x时代）时，它是作为名为**X-Pack**的闭源功能的一部分，需要单独的安装步骤。然而，从版本6.3开始，X-Pack的代码被“开放”([elastic.co/what-is/open-x-pack](http://elastic.co/what-is/open-x-pack))并整合到Elasticsearch和Kibana的默认分发中。因此，不再需要单独的X-Pack安装步骤，只需通过商业许可证（或试用许可证）启用功能。
- en: The installation procedure for Elasticsearch and Kibana itself is beyond the
    scope of this book, but it is easily accomplished by following the online documentation
    on the Elastic website (available at [elastic.co/guide/](http://elastic.co/guide/)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch和Kibana的安装过程本身超出了本书的范围，但通过遵循Elastic网站上的在线文档（可在[elastic.co/guide/](http://elastic.co/guide/)找到）可以轻松完成。
- en: 'Once Elasticsearch and Kibana are running, navigate to the **Stack** option
    from the left-side navigation menu and select **License Management**. You will
    see a screen like the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当Elasticsearch和Kibana启动后，从左侧导航菜单中选择**堆栈**选项，然后选择**许可证管理**。您将看到如下屏幕：
- en: '![Figure 2.1 – The License management screen in Kibana'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.1 – Kibana中的许可证管理屏幕'
- en: '](img/B17040_02_001.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_02_001.jpg)'
- en: Figure 2.1 – The License management screen in Kibana
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – Kibana中的许可证管理屏幕
- en: Notice that, by default, the license level applied is the free **Basic** tier.
    This enables you to use some of the advanced features not found in the Apache
    2.0 licensed open source distribution, or on third-party services (such as the
    Amazon Elasticsearch Service). A handy guide for comparing the features that exist
    at the different license levels can be found on the Elastic website at [elastic.co/subscriptions](http://elastic.co/subscriptions).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，默认情况下，应用的许可证级别是免费的**基本**级别。这使您能够使用一些在Apache 2.0许可的开源分发版或第三方服务（如Amazon Elasticsearch服务）中找不到的高级功能。有关比较不同许可证级别上存在的功能的实用指南，可以在Elastic网站上的[elastic.co/subscriptions](http://elastic.co/subscriptions)找到。
- en: 'As previously stated, Elastic ML requires a Platinum tier license. If you have
    purchased a Platinum license from Elastic, you can apply that license by clicking
    on the **Update license** button, as shown on the screen in *Figure 2.1*. If you
    do not have a Platinum license, you can start a free 30-day trial by clicking
    the **Start my trial** button to enable Elastic ML and the other Platinum features
    (assuming you agree to the license terms and conditions):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Elastic ML需要铂金级别的许可证。如果您从Elastic购买了铂金许可证，您可以通过点击屏幕上的**更新许可证**按钮来应用该许可证，如图2.1所示。如果您没有铂金许可证，您可以通过点击**开始我的试用**按钮来启用Elastic
    ML和其他铂金功能（假设您同意许可证条款和条件）：
- en: '![Figure 2.2 – Starting a free 30-day trial'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.2 – 开始免费30天试用'
- en: '](img/B17040_02_002.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_02_002.jpg)'
- en: Figure 2.2 – Starting a free 30-day trial
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 开始免费30天试用
- en: 'Once this is complete, the licensing screen will indicate that you are now
    in an active trial of the Platinum features of the Elastic Stack:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此操作后，许可证屏幕将指示您现在处于Elastic Stack铂金功能的活跃试用状态：
- en: '![Figure 2.3 – Trial license activated'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.3 – 试用许可证已激活'
- en: '](img/B17040_02_003.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_02_003.jpg)'
- en: Figure 2.3 – Trial license activated
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – 试用许可证已激活
- en: Once this is done, you can start to use Elastic ML right away. Additional configuration
    steps are needed to take advantage of the other Platinum features, but those steps
    are outside the scope of this book. Consult the Elastic documentation for further
    assistance on configuring those features.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此操作后，您就可以立即开始使用Elastic ML。要利用其他铂金功能，还需要进行额外的配置步骤，但这些步骤超出了本书的范围。有关配置这些功能的进一步帮助，请参阅Elastic文档。
- en: Enabling ML in the cloud – Elasticsearch Service
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在云中启用ML – Elasticsearch服务
- en: 'If downloading, installing, and self-managing the Elastic Stack is less interesting
    than just getting the Elastic Stack platform offered as a service, then head on
    over to Elastic Cloud ([cloud.elastic.co](http://cloud.elastic.co)) and sign up
    for a free trial, using only your email:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果下载、安装和自行管理Elastic Stack不如直接获取作为服务提供的Elastic Stack平台有趣，那么请前往Elastic Cloud ([cloud.elastic.co](http://cloud.elastic.co))并注册免费试用，只需使用您的电子邮件：
- en: '![Figure 2.4 – Elastic Cloud welcome screen'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.4 – Elastic Cloud欢迎屏幕'
- en: '](img/B17040_02_004.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17040_02_004.jpg)'
- en: Figure 2.4 – Elastic Cloud welcome screen
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 – Elastic Cloud欢迎屏幕
- en: 'You can then perform the following steps:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以执行以下步骤：
- en: Once inside the Elastic Cloud interface after logging in, you will have the
    ability to start a free trial by clicking the **Start your free trial** button:![Figure
    2.5 – Elastic Cloud home screen
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录Elastic Cloud界面后，您将能够通过点击**开始您的免费试用**按钮来启动免费试用：![图2.5 – Elastic Cloud主页
- en: '](img/B17040_02_005.jpg)'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17040_02_005.jpg)'
- en: Figure 2.5 – Elastic Cloud home screen
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.5 – Elastic Cloud主页
- en: 'Once the button is clicked, you will see that your 14-day free trial of ESS
    has started:'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 点击按钮后，您将看到您的ESS 14天免费试用已开始：
- en: '![Figure 2.6 – Elasticsearch Service trial enabled'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.6 – Elasticsearch 服务试用已启用'
- en: '](img/B17040_02_006.jpg)'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_02_006.jpg](img/B17040_02_006.jpg)'
- en: Figure 2.6 – Elasticsearch Service trial enabled
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.6 – Elasticsearch 服务试用已启用
- en: Of course, in order to try out Elastic ML, you first need an Elastic Stack cluster
    provisioned. There are a few options to create what ESS refers to as **deployments**,
    with some that are tailored to specific use cases. For this example, we will use
    the **Elastic Stack** template on the left of *Figure 2.6* and choose the **I/O
    Optimized** hardware profile, but feel free to experiment with the other options
    during your trial:![Figure 2.7 – Creating an ESS deployment
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当然，为了尝试 Elastic ML，你首先需要一个配置好的 Elastic Stack 集群。ESS 提供了创建所谓**部署**的几种选项，其中一些是为特定用例定制的。在这个例子中，我们将使用
    *图 2.6* 左侧的 **Elastic Stack** 模板，并选择 **I/O 优化**的硬件配置，但请随意在试用期间尝试其他选项：![图 2.7 –
    创建 ESS 部署
- en: '](img/B17040_02_007.jpg)'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_02_007.jpg](img/B17040_02_007.jpg)'
- en: Figure 2.7 – Creating an ESS deployment
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.7 – 创建 ESS 部署
- en: You can also choose what cloud provider and which region to start your cluster
    in, but most importantly, if you want to use ML features, you must enable an ML
    node by first clicking on the **Customize** button near the bottom-right corner.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你还可以选择在哪个云提供商和哪个区域启动你的集群，但最重要的是，如果你想使用 ML 功能，你必须首先通过点击底部右下角的 **自定义** 按钮来启用一个
    ML 节点。
- en: After clicking the **Customize** button, you will see a new screen that allows
    you to add an ML node:![Figure 2.8 – Customizing deployment to add an ML node
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **自定义** 按钮，你将看到一个新屏幕，允许你添加一个 ML 节点：![图 2.8 – 自定义部署以添加 ML 节点
- en: '](img/B17040_02_008.jpg)'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_02_008.jpg](img/B17040_02_008.jpg)'
- en: Figure 2.8 – Customizing deployment to add an ML node
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.8 – 自定义部署以添加 ML 节点
- en: Near the bottom of *Figure 2.8* is a link to **Add Machine Learning nodes**
    to your cluster. Clicking on this will reveal the ML node configuration:![Figure
    2.9 – Adding ML node(s)
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *图 2.8* 的底部附近有一个链接，可以 **添加机器学习节点** 到你的集群。点击此链接将显示 ML 节点配置：![图 2.9 – 添加 ML
    节点(s)
- en: '](img/B17040_02_009.jpg)'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_02_009.jpg](img/B17040_02_009.jpg)'
- en: Figure 2.9 – Adding ML node(s)
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.9 – 添加 ML 节点(s)
- en: Note
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: During the free 14-day trial period of ESS, you can only add one 1 GB ML node
    (in one or two availability zones). If you move from a free trial to a paid subscription,
    you can obviously create more or larger ML nodes.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 ESS 的免费 14 天试用期间，你只能添加一个 1 GB 的 ML 节点（在一个或两个可用区）。如果你从免费试用转为付费订阅，显然可以创建更多或更大的
    ML 节点。
- en: Once the ML node is added to the configuration, click on the **Create Deployment**
    button to initiate the process for ESS to create your cluster for you, which will
    take a few minutes. In the meantime, you will be shown the default credentials
    that you will use to access the cluster:![Figure 2.10 – Default assigned credentials
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 ML 节点添加到配置后，点击 **创建部署** 按钮以启动 ESS 为你创建集群的过程，这可能需要几分钟。在此期间，你将看到你将用于访问集群的默认凭证：![图
    2.10 – 默认分配的凭证
- en: '](img/B17040_02_010.jpg)'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B17040_02_010.jpg](img/B17040_02_010.jpg)'
- en: Figure 2.10 – Default assigned credentials
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.10 – 默认分配的凭证
- en: You can download these credentials for use later. Don't worry if you forgot
    to download them – you can always reset the password later if needed.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以下载这些凭证以备将来使用。如果你忘记下载它们，不要担心——如果需要，你总是可以在稍后重置密码。
- en: 'Once the cluster is up and running as shown in *Figure 2.11* (usually only
    after a few minutes), you will see the following view of your deployment, with
    an **Open Kibana** button that will allow you to launch into your deployment:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦集群如 *图 2.11* 所示启动并运行（通常只需几分钟），你将看到以下部署视图，其中有一个 **打开 Kibana** 按钮允许你启动到你的部署：
- en: '![Figure 2.11 – Deployment successfully created'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.11 – 部署成功创建'
- en: '](img/B17040_02_011.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_02_011.jpg](img/B17040_02_011.jpg)'
- en: Figure 2.11 – Deployment successfully created
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – 部署成功创建
- en: Once the **Open Kibana** button is clicked, you will be automatically authenticated
    into Kibana, where you will be ready to use ML straight away – no additional configuration
    steps are necessary.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 点击 **打开 Kibana** 按钮后，你将自动登录到 Kibana，在那里你将可以直接使用 ML，无需额外的配置步骤。
- en: At this point, from the perspective of the user who wants to use Elastic ML,
    there is little difference between the self-managed configuration shown earlier
    and the setup created in ESS. The one major difference, however, is that the configuration
    here in ESS has Elastic ML always isolated to a `data`, `ingest`, and `ml` roles
    all on the same node). We will discuss this concept later in this chapter.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，从想要使用Elastic ML的用户的角度来看，之前展示的自托管配置和ESS中创建的设置之间几乎没有区别。然而，一个主要的区别是，在这里ESS中的配置将Elastic
    ML始终隔离到同一节点上的`data`、`ingest`和`ml`角色）。我们将在本章后面讨论这个概念。
- en: Now that we have a functioning Elastic Stack with ML enabled, we are getting
    closer to being able to start analyzing data, which will begin in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection*. But first, let's understand the operationalization of Elastic
    ML.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有一个启用了机器学习的Elastic Stack，我们正在接近能够开始分析数据，这将在[*第3章*](B17040_03_Epub_AM.xhtml#_idTextAnchor049)
    *异常检测* 中开始。但首先，让我们了解Elastic ML的运营化。
- en: Understanding operationalization
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解运营化
- en: At some point on your journey with using Elastic ML, it will be helpful to understand
    a number of key concepts regarding how Elastic ML is operationalized within the
    Elastic Stack. This includes information about how the analytics run on the cluster
    nodes and how data that is to be analyzed by ML is retrieved and processed.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在你使用Elastic ML的旅程中，在某个时候了解有关Elastic ML如何在Elastic Stack中运营化的几个关键概念将是有帮助的。这包括有关在集群节点上运行的分析信息以及要由机器学习分析的数据如何检索和处理的详细信息。
- en: Note
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Some concepts in this section may not be intuitive until you actually start
    using Elastic ML on some real examples. Don't worry if you feel like you prefer
    to skim (or even skip) this section now and return to it later following some
    genuine experience of using Elastic ML.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个部分中，有些概念在你实际开始在一些真实示例上使用Elastic ML之前可能并不直观。如果你现在觉得更喜欢浏览（甚至跳过）这一节，稍后再根据一些真实的Elastic
    ML使用经验返回，请不要担心。
- en: ML nodes
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习节点
- en: First and foremost, since Elasticsearch is, by nature, a distributed multi-node
    solution, it is only natural that the ML feature of the Elastic Stack works as
    a native plugin that obeys many of the same operational concepts. As described
    in the documentation ([elastic.co/guide/en/elasticsearch/reference/current/ml-settings.html](http://elastic.co/guide/en/elasticsearch/reference/current/ml-settings.html)),
    ML can be enabled on any or all nodes, but it is a best practice in a production
    system to have dedicated ML nodes. We saw this best practice forced on the user
    in Elastic Cloud ESS – the user must create dedicated ML nodes if ML is desired
    to be used.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，由于Elasticsearch本质上是分布式多节点解决方案，Elastic Stack的机器学习功能作为一个遵循许多相同运营概念的本地插件工作，这是很自然的。如文档([elastic.co/guide/en/elasticsearch/reference/current/ml-settings.html](http://elastic.co/guide/en/elasticsearch/reference/current/ml-settings.html))所述，机器学习可以在任何或所有节点上启用，但在生产系统中，最好有专门的机器学习节点。我们在Elastic
    Cloud ESS中看到了这种最佳实践被强制执行——如果想要使用机器学习，用户必须创建专门的机器学习节点。
- en: Having dedicated ML nodes is also helpful in optimizing the types of resources
    specifically required by ML. Unlike data nodes that are involved in a fair amount
    of disk I/O loads due to indexing and searching, ML nodes are more compute- and
    memory-intensive. With this knowledge, you can size the hardware appropriately
    for dedicated ML nodes.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有专门的机器学习节点也有助于优化机器学习所需的具体资源类型。与因索引和搜索而涉及大量磁盘I/O负载的数据节点不同，机器学习节点更注重计算和内存密集型。有了这些知识，你可以为专门的机器学习节点适当地配置硬件。
- en: One key thing to note—the ML algorithms do not run in the `autodetect` for anomaly
    detection and `data_frame_analyzer` for data frame analytics) can be seen in the
    process list (if you were to run the `ps` command on Linux, for example). There
    will be one process for every actively running ML job. In multi-node setups, ML
    will distribute the jobs to each of the ML-enabled nodes to balance the load of
    the work.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个需要注意的关键点——机器学习算法不在`autodetect`（用于异常检测）和`data_frame_analyzer`（用于数据框分析）中运行，这可以在进程列表中看到（例如，如果你在Linux上运行`ps`命令）。对于每个正在运行的机器学习作业，将有一个进程。在多节点设置中，机器学习将作业分配给每个启用了机器学习的节点以平衡工作负载。
- en: Elastic ML obeys a setting called `xpack.ml.max_machine_memory_percent`, which
    governs how much system memory can be used by ML jobs. The default value of this
    setting is 30%. The limit is based on the total memory of the machine, not memory
    that is currently free. Don't forget that the Elasticsearch JVM may take up to
    around 50% of the available machine memory, so leaving 30% to ML and the remaining
    20% for the operating system and other ancillary processes is prudent, albeit
    conservative. Jobs are not allocated to a node if doing so would cause the estimated
    memory use of ML jobs to exceed the limit defined by this setting.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic ML遵循一个名为`xpack.ml.max_machine_memory_percent`的设置，该设置控制ML作业可以使用的系统内存量。此设置的默认值为30%。限制基于机器的总内存量，而不是当前空闲的内存量。别忘了Elasticsearch
    JVM可能占用高达约50%的可用机器内存，因此为ML保留30%，剩余20%用于操作系统和其他辅助进程是谨慎的，尽管是保守的。如果这样做会导致ML作业的估计内存使用量超过此设置定义的限制，则不会将作业分配给节点。
- en: 'While there is no empirical formula to determine the size and number of dedicated
    ML nodes, some good rules of thumb are as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有经验公式来确定专用ML节点的大小和数量，但以下是一些好的经验法则：
- en: Have one dedicated ML node (two for high availability/fault tolerance if a single
    node becomes unavailable) for cluster sizes of up to 10 data nodes.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于最多10个数据节点的集群大小，应有一个专用的ML节点（如果单个节点不可用，则为高可用性/容错提供两个节点）。
- en: Have at least two ML nodes for clusters of up to 20 nodes.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于最多20个节点的集群，至少要有两个ML节点。
- en: Add an additional ML node for every additional 10 data nodes.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个额外的10个数据节点，添加一个额外的ML节点。
- en: This general approach of reserving about 10-20% of your cluster capacity to
    dedicated ML nodes is certainly a reasonable suggestion, but it does not obviate
    the need to do your own sizing, characterization testing, and resource monitoring.
    As we will see in several later chapters, the resource demands on your ML tasks
    will greatly depend on what kind(s) of analyses are being invoked, as well as
    the density and volume of the data being analyzed.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这种保留大约10-20%的集群容量用于专用ML节点的一般方法当然是一个合理的建议，但这并不免除您进行自己的尺寸、特征测试和资源监控的需要。正如我们将在后面的几个章节中看到的那样，您的ML任务对资源的需求将极大地取决于正在调用的分析类型以及正在分析的数据的密度和体积。
- en: Jobs
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作业
- en: In Elastic ML, the job is the unit of work. There are both **anomaly detection**
    jobs and **data frame analytics** jobs. Both take some kind of data as input and
    produce new information as output. Jobs can be created using the ML UI in Kibana,
    or programmatically via the API. They also require ML-enabled nodes.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在Elastic ML中，作业是工作单元。既有**异常检测**作业，也有**数据帧分析**作业。两者都使用某种类型的数据作为输入，并以新的信息作为输出。可以使用Kibana中的ML
    UI创建作业，也可以通过API编程创建。它们还需要启用ML的节点。
- en: In general, anomaly detection jobs can be run as a single-shot batch analysis
    (over a swath of historical data) or continuously run in real time on time series
    data – data that is constantly being indexed by your Elastic Stack (or both, really).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，异常检测作业可以作为单次批量分析（在历史数据的一段时间内）运行，或者连续在实时时间序列数据上运行——这些数据由您的Elastic Stack（或两者）不断索引。实际上，两者都可以。
- en: Alternatively, data frame analytics jobs are not continuous – they are single-shot
    executions that produce output results and/or an output model that is used for
    subsequent **inferencing**, discussed in more depth in chapters 9 to 13\.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，数据帧分析作业不是连续的——它们是一次性执行，产生输出结果和/或用于后续**推断**的输出模型，这些内容在9到13章中进行了更深入的讨论。
- en: Therefore, from an operationalization standpoint, anomaly detection jobs are
    a bit more complex – as multiple can be running simultaneously, doing independent
    things and analyzing data from different indices. In other words, anomaly detection
    jobs are likely to be continuously busy within a typical cluster.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从实际操作的角度来看，异常检测作业要复杂一些——因为可能同时运行多个作业，执行独立的事情并分析来自不同索引的数据。换句话说，异常检测作业在典型的集群中可能会持续忙碌。
- en: 'As we will see in more depth later, the main configuration elements of an anomaly
    detection job are as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们稍后将更深入地看到的那样，异常检测作业的主要配置元素如下：
- en: Job name/ID
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作业名称/ID
- en: Analysis bucketization window (the **bucket span**)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析桶化窗口（即**桶跨度**）
- en: The definition and settings for the query to obtain the raw data to be analyzed
    (the **datafeed**)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取要分析的原始数据的查询定义和设置（即**数据馈送**）
- en: The anomaly detection configuration recipe (the **detector**)
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常检测配置配方（即**检测器**）
- en: With the notion of jobs understood, we'll next focus on how the bucketing of
    time series data is an important concept in the analysis of real-time data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 理解了工作的概念后，我们接下来将关注时间序列数据的分桶是如何在实时数据分析中成为一个重要的概念。
- en: Bucketing data in a time series analysis
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列分析中的数据分桶
- en: Bucketing input data is an important concept to understand in Elastic ML's anomaly
    detection. Set with a key parameter at the job level called `bucket_span`, the
    input data from the datafeed (described next) is collected into mini batches for
    processing. Think of the bucket span as a pre-analysis aggregation interval—the
    window of time in which a portion of the data is aggregated over for the purposes
    of analysis. The shorter the duration of `bucket_span`, the more granular the
    analysis, but also the higher the potential for noisy artifacts in the data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在Elastic ML的异常检测中，理解输入数据的分桶是一个重要的概念。通过在作业级别设置一个称为`bucket_span`的关键参数，数据馈送（下文将描述）中的输入数据被收集到小批量中进行处理。将桶跨度视为一个预分析聚合间隔——用于分析目的的数据部分聚合的时间窗口。`bucket_span`的持续时间越短，分析越细粒度，但也可能导致数据中存在更多的噪声伪迹。
- en: 'To illustrate, the following graph shows the same dataset aggregated over three
    different intervals:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，以下图表显示了在三个不同间隔内聚合的相同数据集：
- en: '![Figure 2.12 – Aggregations of the same data over different time intervals'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.12 – 不同时间间隔内相同数据的聚合'
- en: '](img/B17040_02_012.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17040_02_012.jpg]'
- en: Figure 2.12 – Aggregations of the same data over different time intervals
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – 不同时间间隔内相同数据的聚合
- en: Notice that the prominent anomalous spike seen in the version aggregated over
    the 5- minute interval becomes all but lost if the data is aggregated over a 60-minute
    interval due to the fact of the spike's short (<2 minute) duration. In fact, at
    this 60-minute interval, the spike doesn't even seem that anomalous any more.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到，在5分钟间隔聚合的版本中看到的突出异常峰值，如果数据是60分钟间隔聚合的，由于峰值持续时间短（<2分钟），几乎会消失。事实上，在这个60分钟间隔中，峰值甚至不再显得那么异常。
- en: This is a practical consideration behind the choice of `bucket_span`. On the
    one hand, having a shorter aggregation period is helpful because it will increase
    the frequency of the analysis (and thus reduce the interval of notification if
    there is something anomalous), but making it too short may highlight features
    in the data that you don't really care about. If the brief spike that's shown
    in the preceding data is a meaningful anomaly for you, then the 5-minute view
    of the data is sufficient. If, however, a perturbation of the data that is very
    brief seems like an unnecessary distraction, then avoid a low value of `bucket_span`.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这是选择`bucket_span`背后的一个实际考虑。一方面，拥有较短的聚合周期是有帮助的，因为它会增加分析的频率（如果存在异常，则减少通知间隔），但使其过于短暂可能会突出数据中你并不真正关心的特征。如果前面数据中显示的短暂峰值对你来说是一个有意义的异常，那么数据的5分钟视图就足够了。然而，如果数据中的非常短暂的扰动看起来像是不必要的干扰，那么请避免设置过低的`bucket_span`值。
- en: Note
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Some additional practical considerations can be found on Elastic''s blog: [elastic.co/blog/explaining-the-bucket-span-in-machine-learning-for-elasticsearch](http://elastic.co/blog/explaining-the-bucket-span-in-machine-learning-for-elasticsearch).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一些额外的实际考虑可以在Elastic的博客上找到：[elastic.co/blog/explaining-the-bucket-span-in-machine-learning-for-elasticsearch](http://elastic.co/blog/explaining-the-bucket-span-in-machine-learning-for-elasticsearch)。
- en: Feeding data to Elastic ML
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据馈送到Elastic ML
- en: Anomaly detection jobs obviously need data to analyze (and use to build and
    mature the statistical models). This data comes from your time series indices
    in Elasticsearch. The datafeed is the mechanism by which this data is retrieved
    (searched) on a routine basis and presented to the ML algorithms. Its configuration
    is mostly obscured from the user, except in the case of the creation of an advanced
    job in the UI (or by using the anomaly detection API). However, it is important
    to understand what the datafeed is doing behind the scenes.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测作业显然需要分析数据（以及用于构建和成熟统计模型的数据）。这些数据来自Elasticsearch中的时间序列索引。数据馈送是这种数据定期检索（搜索）并呈现给机器学习算法的机制。其配置大部分对用户是隐藏的，除非在UI中创建一个高级作业（或通过使用异常检测API）。然而，了解数据馈送在幕后做什么是很重要的。
- en: 'Similar to the concept of a **Watch** input in **Watcher**, the datafeed will
    routinely query for data against an index pattern (or **saved search**) that contains
    the data to be analyzed. How often (and how much data at a time) the datafeed
    queries the data depends on a number of factors:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 与 **Watcher** 中的 **Watch** 输入概念类似，数据源将定期查询一个包含要分析数据的索引模式（或 **已保存的搜索**）。数据源查询数据的频率（以及每次查询多少数据）取决于多个因素：
- en: '`query`: The actual query (expressed in Elasticsearch DSL) that will be used
    to retrieve data from the source index for analysis. The user can choose to query
    all documents in the source index or to selectively filter and/or aggregate the
    data.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query`: 实际的查询（以 Elasticsearch DSL 表达）将用于从源索引中检索数据以进行分析。用户可以选择查询源索引中的所有文档，或者选择性地过滤和/或聚合数据。'
- en: '`bucket_span`: We have already established that `bucket_span` controls the
    width of the ongoing analysis window. Therefore, the job of the datafeed is to
    make sure that the buckets are full of chronologically ordered data. You can therefore
    see that the datafeed will make a date range query to Elasticsearch.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bucket_span`: 我们已经确定 `bucket_span` 控制当前分析窗口的宽度。因此，数据源的任务是确保桶中充满了按时间顺序排列的数据。因此，你可以看到数据源将向
    Elasticsearch 执行日期范围查询。'
- en: '`frequency`: A parameter that controls how often the raw data is physically
    queried. If this is between 2 and 20 minutes, `frequency` will equal `bucket_span`
    (as in, query every 5 minutes for the last 5 minutes'' worth of data). If `bucket_span`
    is longer, `frequency`, by default, will be a smaller number (more frequent) so
    that the overall long interval is not expected to be queried all at once. This
    is helpful if the dataset is rather voluminous. In other words, the interval of
    a long `bucket_span` will be chopped up into smaller intervals simply for the
    purposes of querying.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frequency`: 一个控制原始数据物理查询频率的参数。如果这个值在 2 到 20 分钟之间，`frequency` 将等于 `bucket_span`（即，每
    5 分钟查询一次过去 5 分钟的数据）。如果 `bucket_span` 更长，默认情况下，`frequency` 将是一个更小的数字（更频繁），这样就不会期望一次性查询整个长间隔。这对于数据集相当庞大时很有帮助。换句话说，长
    `bucket_span` 的间隔将被切割成更小的间隔，仅为了查询的目的。'
- en: '`query_delay`: This controls the amount of time "behind now" that the datafeed
    should query for a bucket span''s worth of data. The default is 60 seconds when
    the job is configured via the API, or a randomized value between 60 seconds and
    120 seconds if the job is configured via the UI. Therefore, with a `bucket_span`
    value of 5 minutes and a `query_delay` value of 60 seconds at 12:01 P.M., the
    datafeed will request data in the range of 11:55 A.M. to midnight. This extra
    little delay allows for delays in the ingest pipeline to ensure that no data is
    excluded from the analysis if its ingestion is delayed for any reason. If the
    system detects that the anomaly detection job is missing data due to possible
    ingest delays, a system-generated `query_delay` might need to be increased to
    remedy it.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query_delay`: 这控制数据源查询一个桶跨度值的数据时“现在”之后的时间量。当通过 API 配置作业时，默认值为 60 秒，或者当通过 UI
    配置作业时，默认值为 60 秒到 120 秒之间的随机值。因此，当桶跨度值为 5 分钟，`query_delay` 值为 60 秒，在中午 12:01 时，数据源将请求从上午
    11:55 到午夜的数据。这个额外的延迟允许在摄入管道中存在延迟，以确保不会因为任何原因的摄入延迟而排除分析中的数据。如果系统检测到异常检测作业由于可能的摄入延迟而缺少数据，可能需要增加系统生成的
    `query_delay` 来纠正。'
- en: '`scroll_size`: In most cases, the type of search that the datafeed executes
    to Elasticsearch uses the scroll API ([elastic.co/guide/en/elasticsearch/reference/current/scroll-api.html](http://elastic.co/guide/en/elasticsearch/reference/current/scroll-api.html)).
    The scroll size defines how much the datafeed queries to Elasticsearch at a time.
    For example, if the datafeed is set to query for log data every 5 minutes, but
    in a typical 5-minute window there are 1 million events, the idea of scrolling
    that data means that not all 1 million events will be expected to be fetched with
    one giant query. Rather, it will do it with many queries in increments of `scroll_size`.
    By default, this scroll size is set conservatively to 1,000\. So, to get 1 million
    records returned to ML, the datafeed will ask Elasticsearch for 1,000 rows, 1,000
    times. Increasing `scroll_size` to 10,000 will reduce the number of scrolls to
    100\. In general, beefier clusters should be able to handle a larger `scroll_size`
    and thus be more efficient in the overall process.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scroll_size`：在大多数情况下，数据源执行到Elasticsearch的搜索类型使用滚动API（[elastic.co/guide/en/elasticsearch/reference/current/scroll-api.html](http://elastic.co/guide/en/elasticsearch/reference/current/scroll-api.html)）。滚动大小定义了数据源每次查询Elasticsearch的数据量。例如，如果数据源被设置为每5分钟查询一次日志数据，但在典型的5分钟窗口中有100万事件，滚动这些数据的概念意味着并不是期望在一次巨大的查询中获取所有100万事件。相反，它将以`scroll_size`的增量进行多次查询。默认情况下，这个滚动大小保守地设置为1,000。因此，为了获取1百万条记录返回给机器学习，数据源将向Elasticsearch请求1,000行，共请求1,000次。将`scroll_size`增加到10,000将减少滚动次数到100。一般来说，更强大的集群应该能够处理更大的`scroll_size`，从而在整体过程中更加高效。'
- en: There is an exception, however, in the case of a single metric job. The single
    metric job (described more in [*Chapter 3*](B17040_03_Epub_AM.xhtml#_idTextAnchor049),
    *Anomaly Detection*) is a simple ML job that allows only one-time series metrics
    to be analyzed. In this case, the scroll API is not used to obtain the raw data—rather,
    the datafeed will automatically create a query aggregation (using the `date_histogram`
    aggregation). This aggregation technique can also be used for any anomaly detection
    job, but it currently requires direct editing of the job's JSON configuration
    and should be reserved for expert users.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于单一指标作业来说，存在一个例外。单一指标作业（在[*第3章*](B17040_03_Epub_AM.xhtml#_idTextAnchor049)，*异常检测*）是一个简单的机器学习作业，它只允许分析一个时间序列指标。在这种情况下，不使用滚动API来获取原始数据——相反，数据源将自动创建一个查询聚合（使用`date_histogram`聚合）。这种聚合技术也可以用于任何异常检测作业，但目前需要直接编辑作业的JSON配置，并且应该仅限于专家用户使用。
- en: In terms of feeding data to Elastic ML for data frame analytics jobs, the paradigm
    is different from anomaly detection because data isn't being fed to the analytics
    continuously, in real time. The specifics on how to feed data to a data frame
    analytics job will be covered in chapters 9-13.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据馈送到Elastic ML进行数据框分析作业时，其范式与异常检测不同，因为数据不是连续、实时地馈送到分析中。如何将数据馈送到数据框分析作业的具体细节将在第9章到第13章中介绍。
- en: Now that we have a deeper understanding of how data flows into Elastic ML for
    analysis, let's now look at some of the indices that are used to support Elastic
    ML's operation.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对数据如何流入Elastic ML进行分析有了更深入的了解，接下来让我们看看一些用于支持Elastic ML操作的索引。
- en: The supporting indices
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持索引
- en: 'For Elastic ML to function, there are several supporting indices that exist
    and serve specific purposes:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了Elastic ML能够正常运行，存在几个支持索引，它们各自承担特定的功能：
- en: '`.ml-config`'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.ml-config`'
- en: '`.ml-state-*`'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.ml-state-*`'
- en: '`.ml-notifications-*`'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.ml-notifications-*`'
- en: '`.ml-annotations-*`'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.ml-annotations-*`'
- en: '`.ml-stats-*`'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.ml-stats-*`'
- en: '`.ml-anomalies-*`'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.ml-anomalies-*`'
- en: All of these indices are **system indices** (and most are **hidden indices**),
    meaning that they are not intended to be written to or manipulated by the end
    user. However, it is often helpful to understand their function/role, so let's
    take each one in turn.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些索引都是**系统索引**（并且大多数是**隐藏索引**），这意味着它们不是旨在被最终用户写入或操作的。然而，了解它们的功能/角色通常很有帮助，所以让我们逐一介绍。
- en: .ml-config
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`.ml-config`'
- en: The `.ml-config` index contains configuration information about all of the ML
    jobs that are currently defined in the system. The information contained in this
    index is readable and interpretable by the average user.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`.ml-config` 索引包含了系统中当前定义的所有机器学习作业的配置信息。该索引中的信息可以被普通用户读取和理解。'
- en: .ml-state-*
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '.ml-state-* '
- en: The `.ml-state` index is the place where Elastic ML keeps the internal information
    about the progress of data frame analytics jobs and anomaly detection statistical
    models that have been learned for a specific dataset, plus additional logistical
    information. This index is *not* meant to be understandable by a user—it is the
    backend algorithms of ML that will read and write entries in this index.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: .ml-notifications-*
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This index is the place where Elastic ML stores the audit messages that appear
    in the `elasticsearch.log` file.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: .ml-annotations-*
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This index stores records of annotations associated with anomaly detection jobs.
    This includes user-created annotations that can be defined with the anomaly detection
    UI, but also system-created annotations, such as ingest delay warnings and model
    snapshot notifications.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: .ml-stats-*
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This index retains information about the progress and performance of data frame
    analytics jobs.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: .ml-anomalies-*
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The .`ml-anomalies-*` indices contain the detailed results of ML jobs. These
    indices are instrumental in leveraging the output of the ML algorithms. All information
    displayed in the ML UI will be driven from this result data. Additionally, proactive
    alerting on anomalies will be accomplished by having queries configured against
    these indices. More information on this will be presented in [*Chapter 6*](B17040_06_Epub_AM.xhtml#_idTextAnchor117),
    *Alerting on ML Analysis*.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know the names and roles of the system indices owned and managed
    by Elastic ML, let's next look specifically at `.ml-state` and `.ml-anomalies`
    and how they contribute to the runtime orchestration of the anomaly detection
    jobs.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection orchestration
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Because anomaly detection jobs can be run continuously on live, time series
    data, a rather complex orchestration occurs. A simplified diagram of this process
    is shown in *Figure 2.13*:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Simplified sequence of an anomaly detection job''s operation'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17040_02_013.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.13 – Simplified sequence of an anomaly detection job's operation
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: The `autodetect` process, which is the physical manifestation of the anomaly
    detection job, is what is represented by the analyze versus model step in *Figure
    2.13*. The `.ml-state` index is read and written to by the `autodetect` process
    occasionally (as described in the next section). The output of the `autodetect`
    process (the results of the analysis) is stored in the `.ml-anomalies-*` indices.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: In general, the preceding procedures are done once per `bucket_span` (except
    for the actual read/write from `.ml-state`). The key takeaway is that this orchestration
    enables the anomaly detection job to be online (that is, not offline/batch) and
    constantly learning on newly ingested data. This process is also handled automatically
    by Elastic ML, so that the user doesn't have to worry about the complex logistics
    required to make it all happen.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection model snapshots
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned in the previous section, the "state" of the anomaly detection
    model is stored in the `.ml-state` index. However, it is not actually read or
    written with every bucket span. Instead, the model state is mostly kept in the
    memory of the `autodetect` process and is only periodically serialized to `.ml-state`.
    If the anomaly detection job is asked to run over a large swath of historical
    data, or is running in real time, then the model is serialized in the following
    ways:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，异常检测模型的“状态”存储在`.ml-state`索引中。然而，它并不是在每个桶跨度中实际读取或写入。相反，模型状态主要保存在`autodetect`进程的内存中，并且仅定期序列化到`.ml-state`。如果异常检测作业被要求在大量历史数据上运行，或者实时运行，那么模型将按以下方式序列化：
- en: Periodically, on a schedule of about every 3 to 4 hours (or at an interval defined
    by `background_persist_interval`, if explicitly set)
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期，大约每3到4小时（或如果明确设置，则由`background_persist_interval`定义的间隔）
- en: When the anomaly detection job is put in the **closed** state
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当异常检测作业被置于**关闭**状态时
- en: Because of this periodic serialization of the model, older snapshots are automatically
    deleted with a nightly system maintenance job. By default, if there are snapshots
    over 1 day older than the newest snapshot in the `.ml-state` index, they are deleted
    except for the first snapshot each day. Additionally, all snapshots over 10 days
    older than the newest snapshot are deleted. If you want to exempt a specific snapshot
    from this cleanup and keep it around indefinitely, use the UI in Kibana or the
    updated model snapshots API to set the value of the `retain` setting to `true`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型定期序列化，旧的快照会自动在夜间系统维护作业中删除。默认情况下，如果`.ml-state`索引中最新的快照超过1天，它们将被删除，但每天的第一张快照除外。此外，所有超过最新快照10天的快照都将被删除。如果您想免除特定的快照并无限期地保留它，请使用Kibana中的UI或更新的模型快照API将`retain`设置的值设置为`true`。
- en: It may also be apparent that having saved snapshots now allows the user to revert
    the job to use one of these previously taken snapshots of the model in the event
    of something going wrong operationally, or an unexpected situation arising. In
    one of the *Tips and tricks* sections of the [*Appendix*](B17040_14_Epub_AM.xhtml#_idTextAnchor248),
    we will work through an example that demonstrates how to ignore time periods and
    revert a job to use a model snapshot.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 可能也很明显，现在保存快照允许用户在操作过程中出现问题时，或出现意外情况时，将作业回滚到之前拍摄的模型快照之一。在[*附录*](B17040_14_Epub_AM.xhtml#_idTextAnchor248)的“技巧与窍门”部分之一，我们将通过一个示例演示如何忽略时间段并将作业回滚到使用模型快照。
- en: Summary
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: To summarize, in this chapter, we covered the procedures around the enabling
    of Elastic ML's features in both a self-managed on-premises Elastic Stack and
    within the Elasticsearch Service of Elastic Cloud. Additionally, we looked under
    the hood to see the deep integration points with the rest of the Elastic Stack
    and how Elastic ML works from an operational perspective.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在本章中，我们涵盖了在自管理的本地Elastic Stack和Elastic Cloud的Elasticsearch服务中启用Elastic
    ML功能的流程。此外，我们还深入了解了与Elastic Stack其他部分的深度集成点以及Elastic ML从操作角度是如何工作的。
- en: As we look ahead to future chapters, the focus will now shift away from the
    conceptual and background information into the realm of practical usage. Starting
    with the next chapter, we will jump right into the comprehensive capabilities
    of Elastic ML's anomaly detection and we will learn how to configure jobs to solve
    some practical use cases in log analytics, metric analysis, and user behavior
    analytics.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们展望未来的章节，现在的焦点将不再是从概念和背景信息转向实际应用领域。从下一章开始，我们将直接进入Elastic ML的全面功能，我们将学习如何配置作业以解决日志分析、指标分析和用户行为分析中的某些实际用例。
