<html><head></head><body><div class="chapter" title="Chapter&#xA0;10.&#xA0;Connecting the Pieces"><div class="titlepage"><div><div><h1 class="title"><a id="ch10"/>Chapter 10. Connecting the Pieces</h1></div></div></div><p>The previous chapter focused on the last API umbrella, covering Bing Search APIs. Throughout this chapter, we will connect the pieces. Our smart-house application can currently utilize several APIs, but mostly individually. We will see how to connect LUIS, image analysis, Bing News Search, and Bing Speech APIs. We will also look at the next steps that you can take after completing this book.</p><p>In this chapter, we will learn about the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Making an application smarter, by connecting several APIs</li><li class="listitem" style="list-style-type: disc">Real-life applications utilizing Microsoft Cognitive Services</li><li class="listitem" style="list-style-type: disc">Next steps</li></ul></div><div class="section" title="Completing our smart-house application"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec67"/>Completing our smart-house application</h1></div></div></div><p>Until now, we have <a class="indexterm" id="id532"/>seen all the different APIs, mostly as individual APIs. The whole idea behind the smart-house application is to utilize several APIs at the same time.</p><p>Throughout this chapter, we will add a new intent in LUIS. This intent is for getting the latest news for different topics.</p><p>Next, we want to actually search for news, using the Bing News API. We will do so by allowing the end user to speak a command, converting spoken audio to text, with the Bing Speech API.</p><p>When we find a news article, we want to get the headline, publishing date, and description. If there is a corresponding image to the article, we want to get a description of the image. We will do this by adding the Computer Vision API.</p><p>With all the news article information in place, we want to get that read back to us. We will do this by converting text to spoken audio.</p><div class="section" title="Creating an intent"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec82"/>Creating an intent</h2></div></div></div><p>Let us start by <a class="indexterm" id="id533"/>adding our new intent. Head over to <a class="ulink" href="https://www.luis.ai">https://www.luis.ai</a>, and log on with the credentials created in <a class="link" href="ch04.html" title="Chapter 4. Letting Applications Understand Commands">Chapter 4</a>, <span class="emphasis"><em>Letting Applications Understand Commands</em></span>. From the front page, go into your smart-house application.</p><p>Before we start creating <a class="indexterm" id="id534"/>the intent, we need to add a new entity. As we want the possibility to get updates on news within certain topics, we will add a <code class="literal">NewsCategory</code> entity, as shown in the following screenshot:</p><div class="mediaobject"><img alt="Creating an intent" src="graphics/B12373_10_01.jpg"/></div><p>As this entity will work on its own, we do not need any children.</p><p>Now we can add a new intent. Go to <span class="strong"><strong>Intents</strong></span> on the left-hand side and click <span class="strong"><strong>Add intent</strong></span>. This will open the intent creation dialog. Enter a fitting name for the intent, such as <code class="literal">GetNews</code>:</p><div class="mediaobject"><img alt="Creating an intent" src="graphics/B12373_10_02.jpg"/></div><p>We also need to add an example command:</p><div class="mediaobject"><img alt="Creating an intent" src="graphics/B12373_10_03.jpg"/></div><p>Add five or six more <a class="indexterm" id="id535"/>examples of how you would utter this intent. Make sure you train the model before continuing.</p><p>You can verify the model for testing by going to <span class="strong"><strong>Test</strong></span> in the right-hand side.</p></div><div class="section" title="Updating the code"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec83"/>Updating the code</h2></div></div></div><p>With the <a class="indexterm" id="id536"/>new intent, we can start to update the smart-house application.</p><div class="section" title="Executing actions from intents"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec54"/>Executing actions from intents</h3></div></div></div><p>The first <a class="indexterm" id="id537"/>step we need to do is to add an <code class="literal">enum</code> variable containing the intents. Create a new file called <code class="literal">LuisActions.cs</code>, in the <code class="literal">Model</code> folder, and add the following content to it:</p><div class="informalexample"><pre class="programlisting">    public enum LuisActions {
        None, GetRoomTemperature, SetRoomTemperature, GetNews
    }</pre></div><p>If you have any other intents defined, add them as well.</p><p>This <code class="literal">enum</code> will be used later, to see which action to execute when triggered. For instance, if we ask to get the latest sports news, <code class="literal">GetNews</code> will be triggered, which will go on to retrieve news.</p><p>To make things a bit easier for ourselves, we are going to use the existing LUIS example for the rest of the chapter. An alternative would be to add this to the <code class="literal">HomeView</code>, where we could continuously listen to spoken commands from the users.</p><p>In order to trigger an action, we need to open the <code class="literal">LuisViewModel.cs</code> file. Find the <code class="literal">OnLuisUtteranceResultUpdated</code> function. Let us update it to the following:</p><div class="informalexample"><pre class="programlisting">    private void OnLuisUtteranceResultUpdated(object sender, LuisUtteranceResultEventArgs e)
    {
        Application.Current.Dispatcher.Invoke(async () =&gt; {
            StringBuilder sb = new StringBuilder(ResultText);
                
            _requiresResponse = e.RequiresReply;

            sb.AppendFormat("Status: {0}\n", e.Status);
            sb.AppendFormat("Summary: {0}\n\n", e.Message);</pre></div><p>At this time, we have not added anything new. We have removed the output of entities, as we do not need this anymore.</p><p>If we find that any actions have been triggered, we want to do something. We call a new function, <code class="literal">TriggerActionExecution</code>, passing on the name of the intent as a parameter:</p><div class="informalexample"><pre class="programlisting">    if (!string.IsNullOrEmpty(e.IntentName))
        await TriggerActionExectution(e.IntentName, e.EntityName);</pre></div><p>We will get back to this function shortly.</p><p>Complete <code class="literal">OnLuisUtteranceResultUpdated</code> by adding the following code:</p><div class="informalexample"><pre class="programlisting">            ResultText = sb.ToString();
        }); 
    }</pre></div><p>Again, you should see that there are no new features. We have, however, removed the last <code class="literal">else</code> clause. We <a class="indexterm" id="id538"/>do not want to have the application speak the summary to us anymore.</p><p>Create the new <code class="literal">TriggerActionExecution</code> function. Let it accept a <code class="literal">string</code> as the parameter, and have it return a <code class="literal">Task</code>. Mark the function as <code class="literal">async</code>:</p><div class="informalexample"><pre class="programlisting">    private async Task TriggerActionExectution(string intentName) {
        LuisActions action;
        if (!Enum.TryParse(intentName, true, out action))
            return;</pre></div><p>Here, we parse the <code class="literal">actionName</code> (intent name). If we have not defined the action, we will not do anything else.</p><p>With an action defined, we go into a <code class="literal">switch</code> statement to decide what to do. As we are only interested in the <code class="literal">GetNews</code> case, we break out from the other options:</p><div class="informalexample"><pre class="programlisting">        switch(action) {
            case LuisActions.GetRoomTemperature:
            case LuisActions.SetRoomTemperature:
            case LuisActions.None:
            default:
                break;
            case LuisActions.GetNews:
          break;
        }
    }</pre></div><p>Make sure that the code compiles before continuing.</p></div><div class="section" title="Searching news on command"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec55"/>Searching news on command</h3></div></div></div><p>Next, we will <a class="indexterm" id="id539"/>need to modify the <code class="literal">Luis.cs</code> file. As we have defined an entity for the news topic, we want to ensure that we get this value from the LUIS response.</p><p>Add a new property to <code class="literal">LuisUtteranceResultEventArgs</code>:</p><div class="informalexample"><pre class="programlisting">    public string EntityName { get; set; }</pre></div><p>This will allow us to add the news topic value, if received.</p><p>We need to add this value. Locate <code class="literal">ProcessResult</code> in the <code class="literal">Luis</code> class. Modify the <code class="literal">if</code> check to look like the following:</p><div class="informalexample"><pre class="programlisting">        if (!string.IsNullOrEmpty(result.TopScoringIntent.Name)) {
            var intentName = result.TopScoringIntent.Name;
            args.IntentName = intentName;
        }

        else {
            args.IntentName = string.Empty;
        }

        if(result.Entities.Count &gt; 0) {
        var entity = result.Entities.First().Value;

        if(entity.Count &gt; 0)  {
            var entityName = entity.First().Value;
            args.EntityName = entityName;
        }
    }</pre></div><p>We make sure that the intent name, of the top-scoring intent, is set, and pass it on as an argument to the event. We also check if there is any entities set, and if so, pass on the first one. In a real-life <a class="indexterm" id="id540"/>application, you would probably check other entities as well.</p><p>Back into the <code class="literal">LuisViewModel.cs</code> file, we can now account for this new property. Let the <code class="literal">TriggerActionExecution</code> method accept a second <code class="literal">string</code> parameter. When calling the function, we can add the following parameter:</p><div class="informalexample"><pre class="programlisting">    await TriggerActionExectution(e.IntentName, e.EntityName);</pre></div><p>To be able to search for news, we need to add a new member of the <code class="literal">BingSearch</code> type. This is the class we created in the previous chapter:</p><div class="informalexample"><pre class="programlisting">    private BingSearch _bingSearch;</pre></div><p>Create the object in the constructor.</p><p>Now we can create a new function, called <code class="literal">GetLatestNews</code>. This should accept a <code class="literal">string</code> as the parameter, and return <code class="literal">Task</code>. Mark the function as <code class="literal">async</code>:</p><div class="informalexample"><pre class="programlisting">private async Task GetLatestNews(string queryString)
{
    BingNewsResponse news = await _bingSearch.SearchNews (queryString, SafeSearch.Moderate);

    if (news.value == null || news.value.Length == 0)
        return;</pre></div><p>When this function is called, we <code class="literal">SearchNews</code> on the newly created <code class="literal">_bingSearch</code> object. We pass on the <code class="literal">queryString</code>, which will be the action parameter, as the parameter. We also set the safe search to <code class="literal">Moderate</code>.</p><p>A successful API call will result in a <code class="literal">BingNewsResponse</code> object, which will contain an array of news articles. We are not going into more details on this class, as we covered it in <a class="link" href="ch09.html" title="Chapter 9. Adding Specialized Searches">Chapter 9</a>, <span class="emphasis"><em>Adding Specialized Searches</em></span>.</p><p>If no news is found, we simply return from the function. If we do find news, we do the following:</p><div class="informalexample"><pre class="programlisting">    await ParseNews(news.value[0]);</pre></div><p>We call a function, <code class="literal">ParseNews</code>, which we will get back to in a bit. We pass on the first news article, which <a class="indexterm" id="id541"/>will be parsed. Ideally, we would go through all the results, but for our case, this is enough to illustrate the point.</p><p>The <code class="literal">ParseNews</code> method should be marked as <code class="literal">async</code>. It should have the return type <code class="literal">Task</code>, and accept a parameter of type <code class="literal">Value</code>:</p><div class="informalexample"><pre class="programlisting">private async Task ParseNews(Value newsArticle)  {
    string articleDescription = $"{newsArticle.name}, published {newsArticle.datePublished}. Description:
    {newsArticle.description}. ";

    await _ttsClient.SpeakAsync(articleDescription, CancellationToken.None);
}</pre></div><p>We create a string containing the headline, the publishing date, and the news description. Using this, we call <code class="literal">SpeakAsync</code> on the <code class="literal">_ttsClient</code> to have the application read the information back to us.</p><p>With this function in place, we can execute the action. In <code class="literal">TriggerActionExecuted</code>, call <code class="literal">GetLatestNews</code> from the <code class="literal">GetNews</code> case. Make sure to await the call.</p><p>With the application compiling, we can go for a test run:</p><div class="mediaobject"><img alt="Searching news on command" src="graphics/B12373_10_04.jpg"/></div><p>Naturally, the effects are not as good in an image as in real life. With a microphone and speakers or <a class="indexterm" id="id542"/>headset connected, we can ask for the latest news, using audio, and get the news read back to us with audio.</p></div><div class="section" title="Describing news images"><div class="titlepage"><div><div><h3 class="title"><a id="ch10lvl3sec56"/>Describing news images</h3></div></div></div><p>News articles often <a class="indexterm" id="id543"/>come with corresponding images as well. As an addition to what we already have, we can add image analysis.</p><p>The first step we need to do is to add a new NuGet package. Search for the <code class="literal">Microsoft.ProjectOxford.Vision</code> package, and install this using <span class="strong"><strong>NuGet Package Manager</strong></span>.</p><p>In the <code class="literal">LuisViewModel.cs</code> file, add the following new member:</p><div class="informalexample"><pre class="programlisting">private IVisionServiceClient _visionClient;</pre></div><p>This can be created in the constructor:</p><div class="informalexample"><pre class="programlisting">_visionClient = new VisionServiceClient("FACE_API_KEY", "ROOT_URI");</pre></div><p>This member will be our access point to the Computer Vision API.</p><p>We want to get a string describing the image in the <code class="literal">ParseNews</code> function. We can achieve this by adding a new function, called <code class="literal">GetImageDescription</code>. This should accept a <code class="literal">string</code> parameter, which will be the image URL. The function should have return type <code class="literal">Task&lt;string&gt;</code> and be marked as <code class="literal">async</code>:</p><div class="informalexample"><pre class="programlisting">private async Task&lt;string&gt; GetImageDescription(string contentUrl)
{
    try {
        AnalysisResult imageAnalysisResult = await _visionClient.AnalyzeImageAsync(contentUrl, new List&lt;VisualFeature&gt;() { VisualFeature.Description });</pre></div><p>In this function, we call <code class="literal">AnalyzeImageAsync</code> on the <code class="literal">_visionClient</code>. We want the image description, so we <a class="indexterm" id="id544"/>specify this in a list of <code class="literal">VisualFeature</code>. If the call succeeds, we expect an object of type <code class="literal">AnalysisResult</code>. This should contain image descriptions, ordered by probability of correctness.</p><p>If we do not get any descriptions, we return <code class="literal">none</code>. If we do have any descriptions, we return the text of the first one:</p><div class="informalexample"><pre class="programlisting">    if (imageAnalysisResult == null || imageAnalysisResult.Description?.Captions?.Length == 0) 
        return "none";
    return imageAnalysisResult.Description.Captions.First().Text;
}</pre></div><p>If any exceptions occur, we print the exception message to the debug console. We also return <code class="literal">none</code> to the caller:</p><div class="informalexample"><pre class="programlisting">        catch(Exception ex) {
            Debug.WriteLine(ex.Message);
            return "none";
        }
    }</pre></div><p>In <code class="literal">ParseNews</code>, we can get the image description by adding the following at the top of the function:</p><div class="informalexample"><pre class="programlisting">string imageDescription = await GetImageDescription (newsArticle.image.thumbnail.contentUrl);</pre></div><p>With an image description, we can modify the <code class="literal">articleDescription</code> string to the following:</p><div class="informalexample"><pre class="programlisting">    string articleDescription = $"{newsArticle.name}, published
           {newsArticle.datePublished}. Description:
           {newsArticle.description}. Corresponding image is      
           {imageDescription}";</pre></div><p>Running the application and asking for news will now also describe any images. That concludes our smart-house application.</p></div></div></div></div>
<div class="section" title="Real-life applications using Microsoft Cognitive Services"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec68"/>Real-life applications using Microsoft Cognitive Services</h1></div></div></div><p>There <a class="indexterm" id="id545"/>are some examples of applications that currently utilize Microsoft Cognitive Services. We will look at some of <a class="indexterm" id="id546"/>them here.</p><div class="section" title="Uber"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec84"/>Uber</h2></div></div></div><p>Uber is an app that was <a class="indexterm" id="id547"/>created to match drivers with people looking for rides. People can open the app, and request a ride. Drivers (registered Uber drivers, that is) located nearby can then pick up the person requesting a ride. After a ride, the driver is paid through the app.</p><p>To ensure a more secure <a class="indexterm" id="id548"/>experience, a photo of the driver is sent to the passenger. This way, passengers can feel safe that the driver is who they say they are. This may cause problems, as drivers may not always look like their photo. They may have grown a beard, or shaved off a beard, or similar changes may have occurred.</p><p>To account for this, Uber decided to add a new feature. Each driver needs to sign in when they are using the app. Doing so will periodically request them to take a selfie. This image is then sent to the Face API for verification. If the verification fails, due to glare from glasses, or something similar, the driver is requested to remove such items.</p><p>According to Uber, they spent around 3 weeks implementing the Face API into their systems.</p></div><div class="section" title="DutchCrafters"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec85"/>DutchCrafters</h2></div></div></div><p>
<span class="strong"><strong>DutchCrafters</strong></span> is an American company that sells handmade furniture. They do have a physical store, but more <a class="indexterm" id="id549"/>importantly, they have an e-commerce website. This site contains more than 10,000 products, where each product can be customized.</p><p>They had a low conversion rate on their site, and as an attempt to improve this, they used manual recommendations. Manually <a class="indexterm" id="id550"/>adding recommended products on each product is rather time-consuming. Looking into their options, they discovered the Recommendations API from Microsoft Cognitive Services.</p><p>They were already relying on REST APIs, and as such implementing the Recommendations API was quick. <code class="literal">DutchCrafters</code> have stated that they spent 5 days in total implementing the functionality needed.</p><p>As their site was already built with ASP.NET and running on IIS, they decided to move everything to the cloud. Doing so has improved their site, and with the addition of the Recommendations API, their foundation has improved.</p><p>At the time of writing, they are utilizing the <span class="emphasis"><em>You might like this</em></span> feature, recommending 10 items per product. They <a class="indexterm" id="id551"/>are also looking into adding real-time recommendations, based on users' history, which we have seen is possible using the Recommendations API.</p><p>A direct result of implementing the <a class="indexterm" id="id552"/>Recommendations API is an improvement of the conversion rate. They have seen a three times increase in the conversion rate, with about 15% of the sales coming from recommended products.</p></div><div class="section" title="CelebsLike.me"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec86"/>CelebsLike.me</h2></div></div></div><p>
<span class="strong"><strong>CelebsLike.me</strong></span> is a web application from Microsoft. It was primarily created to show off some of the features of Microsoft Cognitive Services.</p><p>The purpose of the <a class="indexterm" id="id553"/>application is to find your celebrity doppelganger. You can upload a photo, or use one found online, and the app will match faces found with similar celebrities.</p><p>The app takes advantage of <a class="indexterm" id="id554"/>the Bing Image Search API, the Computer Vision API, and the Face API. It recognizes celebrity faces in web images. When someone uploads a photo of themselves, facial features will be used to find matching celebrities.</p></div><div class="section" title="Pivothead"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec87"/>Pivothead</h2></div></div></div><p>
<span class="strong"><strong>Pivothead</strong></span> is a company working with wearable technology. They have combined eyeglasses with high-quality <a class="indexterm" id="id555"/>cameras, providing still images and videos. These glasses allow people to capture vivid point-of-view content of what they see. Pivothead currently has customers in the consumer market, but also in the business market.</p><p>Over time, Pivothead <a class="indexterm" id="id556"/>had seen growing success, but could not seem to create a device to help visually impaired and/or blind people. They struggled with the technology, as machine learning itself can be quite complex. When they learned of Microsoft Cognitive Services, they were able to reach a breakthrough.</p><p>If a person is wearing the glasses, they can slide a finger along an earpiece. This will capture an image of what is in front of the person. The glasses utilize five APIs from Microsoft Cognitive Services. These are Computer Vision, Emotion, Face, Speech, and LUIS.</p><p>With the image of whatever is in front of a person, the image is analyzed. The person wearing the glasses <a class="indexterm" id="id557"/>will then get the image described through an earpiece. If a person is detected, the gender, how they look, what they are <a class="indexterm" id="id558"/>doing, their age, and their emotion is detected and described. If text is detected, it will be read back to the person.</p><p>According to Pivothead, they spent around three months months developing prototypes of these glasses. They also stated that they could have done it in three weeks, had they been working with it full-time.</p></div><div class="section" title="Zero Keyboard"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec88"/>Zero Keyboard</h2></div></div></div><p>The <span class="strong"><strong>Zero Keyboard</strong></span> app was created by a Finnish company called <span class="strong"><strong>Blucup</strong></span>. The company had discovered <a class="indexterm" id="id559"/>a common problem for salespeople. They wanted a way for salespeople to capture customer data and generate leads while on the go.</p><p>They started developing an app for iOS, Android, and Windows Phone to help solve this problem. The idea behind the app is to record customer information, which is then automatically stored in the <span class="strong"><strong>Customer Relationship Management</strong></span> (<span class="strong"><strong>CRM</strong></span>) system.</p><p>At the time of development, Microsoft <a class="indexterm" id="id560"/>Cognitive Services emerged, and Blucup decided to give it a go. Earlier, they had tried a few types of open source speech recognition software and image analysis software. None provided the <a class="indexterm" id="id561"/>quality and features needed.</p><p>Using the Computer Vision API, the app can take pictures of business cards or identification badges, and identify text. This data is directly uploaded to their CRM system. By using the Speech API, sales representatives can also record voice memos for each contact.</p><p>Blucup states that Microsoft Cognitive Services delivers very accurate data. In addition, they have been able to implement the needed APIs rapidly, as the APIs are a good match from a developer standpoint.</p></div><div class="section" title="The common theme"><div class="titlepage"><div><div><h2 class="title"><a id="ch10lvl2sec89"/>The common theme</h2></div></div></div><p>As you can see from all these examples, Microsoft Cognitive Services provides good quality. It is also quick <a class="indexterm" id="id562"/>to implement, which is important when considering new APIs.</p><p>Another great thing about the APIs is that you do not need to be a data scientist to use them. Even though the technology powering the APIs is complex, we, as developers, do not need to think about it. We can focus on what we do best.</p></div></div>
<div class="section" title="Where to go from here"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec69"/>Where to go from here</h1></div></div></div><p>By now, you should know the basics of Microsoft Cognitive Services, enough to get started with building your own applications.</p><p>A natural way forward is to play around with the different APIs. The APIs are continuously improved and <a class="indexterm" id="id563"/>worked upon. It is worth going through the API documentation, to keep up with changes and to learn more. In addition, Microsoft keeps adding new APIs to the services. Through the writing process of this book, I have seen three new APIs added. Those might be interesting to look into.</p><p>Another possibility is to build upon the smart-house application that we have started on. We have put down some groundwork, but there are still a lot of opportunities. Perhaps you can work on improving what we have already got. Maybe you can see some opportunities to mix in other APIs, which we have covered.</p><p>Reading through this book might have given you some ideas of your own. A great way forward would be to implement them.</p><p>As we have seen, there are many possible areas to use the APIs for. Only the imagination limits the usage.</p><p>Perhaps this book has triggered a deeper interest in machine learning. Everything we have seen so far is machine learning. Even though it is more complex than just using APIs, it is certainly worth exploring further.</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch10lvl1sec70"/>Summary</h1></div></div></div><p>With this chapter, we have completed our journey. We created a new intent for news retrieval. We learned how to deal with an action, triggered from this intent. Based on voice commands, we managed to fetch the latest news, for one topic, and have the smart-house application read it back to us. Next, we went on to see what kind of real-life applications are utilizing Microsoft Cognitive Services today. Finally, we concluded this chapter by looking at some natural next steps that you can take after completing this book.</p></div></body></html>