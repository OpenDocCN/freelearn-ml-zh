["```py\nif(!\"recommenderlab\" %in% rownames(installed.packages())){ \ninstall.packages(\"recommenderlab\")} \n\n```", "```py\nLoading required package: recommenderlab \nError in .requirePackage(package) :  \n  unable to find required package 'recommenderlab' \nIn addition: Warning message: \nIn library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  : \n  there is no package called 'recommenderlab' \nLoading required package: recommenderlab \ninstall.packages(\"recommenderlab\") \nInstalling package into 'path to installation folder/R/win-library/3.2' \n(as 'lib' is unspecified) \ntrying URL 'https://cran.rstudio.com/bin/windows/contrib/3.2/recommenderlab_0.2-0.zip' \nContent type 'application/zip' length 1405353 bytes (1.3 MB) \ndownloaded 1.3 MB \npackage 'recommenderlab' successfully unpacked and MD5 sums checked \n\n```", "```py\nlibrary(recommenderlab) \n\nLoading required package: Matrix \nLoading required package: arules \n\nAttaching package: 'arules' \n\nThe following objects are masked from 'package:base': \n\n    abbreviate, write \n\nLoading required package: proxy \n\nAttaching package: 'proxy' \n\nThe following object is masked from 'package:Matrix': \n\n    as.matrix \n\nThe following objects are masked from 'package:stats': \n\n    as.dist, dist \n\nThe following object is masked from 'package:base': \n\n    as.matrix \n\nLoading required package: registry \n\n```", "```py\nhelp(package = \"recommenderlab\") \n\n```", "```py\ndata_package <- data(package = \"recommenderlab\") \ndata_package$results[,c(\"Item\",\"Title\")] \n\n```", "```py\ndata(Jester5k) \n\n```", "```py\nnratings(Jester5k) \n\n[1] 362106 \n\nJester5k \n5000 x 100 rating matrix of class 'realRatingMatrix' with 362106 ratings. \n\n```", "```py\nclass(Jester5k) \n[1] \"realRatingMatrix\" \nattr(,\"package\") \n[1] \"recommenderlab\" \n\n```", "```py\nobject.size(Jester5k) \n4633560 bytes \n#convert the real-rating matrix into R matrix \nobject.size(as(Jester5k,\"matrix\")) \n4286048 bytes \nobject.size(as(Jester5k, \"matrix\"))/object.size(Jester5k) \n0.925001079083901 bytes \n\n```", "```py\nmethods(class = class(Jester5k)) \n\n```", "```py\nnames(recommender_models) \n\n```", "```py\nlapply(recommender_models, \"[[\", \"description\") \n$IBCF_realRatingMatrix \n[1] \"Recommender based on item-based collaborative filtering (real data).\" \n\n$POPULAR_realRatingMatrix \n[1] \"Recommender based on item popularity (real data).\" \n\n$RANDOM_realRatingMatrix \n[1] \"Produce random recommendations (real ratings).\" \n\n$RERECOMMEND_realRatingMatrix \n[1] \"Re-recommends highly rated items (real ratings).\" \n\n$SVD_realRatingMatrix \n[1] \"Recommender based on SVD approximation with column-mean imputation (real data).\" \n\n$SVDF_realRatingMatrix \n[1] \"Recommender based on Funk SVD with gradient descend (real data).\" \n\n$UBCF_realRatingMatrix \n[1] \"Recommender based on user-based collaborative filtering (real data).\" \n\n```", "```py\ndim(Jester5k) \n\n[1] 5000  100 \n\n```", "```py\nclass(Jester5k@data) \n\n[1] \"dgCMatrix\" \nattr(,\"package\") \n[1] \"Matrix\" \n\n```", "```py\nhist(getRatings(Jester5k), main=\"Distribution of ratings\") \n\n```", "```py\nlibrary(recommenderlab) \ndata(\"Jester5k\") \n\n```", "```py\nhead(as(Jester5k,\"matrix\")[,1:10]) \n\n```", "```py\nset.seed(1) \nwhich_train <- sample(x = c(TRUE, FALSE), size = nrow(Jester5k),replace = TRUE, prob = c(0.8, 0.2)) \nhead(which_train) \n[1]  TRUE  TRUE  TRUE  TRUE FALSE  TRUE \n\n```", "```py\nrec_data_train <- Jester5k[which_train, ] \nrec_data_test <- Jester5k[!which_train, ] \n\ndim(rec_data_train) \n[1] 4004  100 \n\ndim(rec_data_test) \n[1] 996  100 \n\n```", "```py\nrecommender_models <- recommenderRegistry$get_entries(dataType = \"realRatingMatrix\") \n\nrecommender_models \n\n```", "```py\nrecc_model <- Recommender(data = rec_data_train, method = \"UBCF\") \nrecc_model \n\nRecommender of type 'UBCF' for 'realRatingMatrix'  \nlearned using 4004 users. \nrecc_model@model$data \n\n4004 x 100 rating matrix of class 'realRatingMatrix' with 289640 ratings. \nNormalized using center on rows. \n\n```", "```py\nn_recommended <- 10 \nrecc_predicted <- predict(object = recc_model,newdata = rec_data_test, n = n_recommended) \nrecc_predicted \nRecommendations as 'topNList' with n = 10 for 996 users.  \n\n#Let's define list of predicted recommendations: \nrec_list <- sapply(recc_predicted@items, function(x){ \n  colnames(Jester5k)[x] \n}) \n\n```", "```py\nclass(rec_list) \n[1] \"list\" \n\n```", "```py\nrec_list [1:2] \n$u21505 \n [1] \"j81\"  \"j73\"  \"j83\"  \"j75\"  \"j100\" \"j80\"  \"j72\"  \"j95\"  \"j87\"  \"j96\"  \n\n$u5809 \n [1] \"j97\" \"j93\" \"j76\" \"j78\" \"j77\" \"j85\" \"j89\" \"j98\" \"j91\" \"j80\" \n\n```", "```py\nnumber_of_items = sort(unlist(lapply(rec_list, length)),decreasing = TRUE) \ntable(number_of_items) \n\n0   1   2   3   4   5   6   7   8   9  10  \n286   3   2   3   3   1   1   1   2   3 691  \n\n```", "```py\ntable(rowCounts(Jester5k)) \n\n```", "```py\nmodel_data = Jester5k[rowCounts(Jester5k) < 80] \ndim(model_data) \n[1] 3261  100 \n\n```", "```py\nboxplot(model_data) \n\n```", "```py\nboxplot(rowMeans(model_data [rowMeans(model_data)>=-5 & rowMeans(model_data)<= 7])) \n\n```", "```py\nmodel_data = model_data [rowMeans(model_data)>=-5 & rowMeans(model_data)<= 7] \ndim(model_data) \n[1] 3163  100 \n\n```", "```py\nimage(model_data, main = \"Rating distribution of 100 users\") \n\n```", "```py\nitems_to_keep <- 30 \nrating_threshold <- 3 \nn_fold <- 5 # 5-fold  \neval_sets <- evaluationScheme(data = model_data, method = \"cross-validation\",train = percentage_training, given = items_to_keep, goodRating = rating_threshold, k = n_fold) \n\nEvaluation scheme with 30 items given \nMethod: 'cross-validation' with 5 run(s). \nGood ratings: >=3.000000 \nData set: 3163 x 100 rating matrix of class 'realRatingMatrix' with 186086 ratings. \n\n```", "```py\nsize_sets <- sapply(eval_sets@runsTrain, length) \n size_sets \n[1] 2528 2528 2528 2528 2528 \n\n```", "```py\ngetData(eval_sets, \"train\") \n2528 x 100 rating matrix of class 'realRatingMatrix' with 149308 ratings. \n\n```", "```py\nmodel_to_evaluate <- \"UBCF\" \nmodel_parameters <- NULL \n\n```", "```py\neval_recommender <- Recommender(data = getData(eval_sets, \"train\"),method = model_to_evaluate, parameter = model_parameters) \n\nRecommender of type 'UBCF' for 'realRatingMatrix'  \nlearned using 2528 users \n\n```", "```py\nitems_to_recommend <- 10 \neval_prediction <- predict(object = eval_recommender, newdata =getData(eval_sets, \"known\"), n = items_to_recommend, type = \"ratings\") \n\neval_prediction \n635 x 100 rating matrix of class 'realRatingMatrix' with 44450 ratings \n\n```", "```py\neval_accuracy <- calcPredictionAccuracy(  x = eval_prediction, data = getData(eval_sets, \"unknown\"), byUser = TRUE) \nhead(eval_accuracy) \n           RMSE       MSE      MAE \nu17322 4.536747 20.582076 3.700842 \nu13610 4.609735 21.249655 4.117302 \nu5462  4.581905 20.993858 3.714604 \nu1143  2.178512  4.745912 1.850230 \nu5021  2.664819  7.101260 1.988018 \nu21146 2.858657  8.171922 2.194978 \n\n```", "```py\napply(eval_accuracy,2,mean) \n     RMSE       MSE       MAE  \n 4.098122 18.779567  3.377653  \n\n```", "```py\neval_accuracy <- calcPredictionAccuracy(  x = eval_prediction, data = getData(eval_sets, \"unknown\"), byUser = \n    FALSE) \n\neval_accuracy \n    RMSE       MSE       MAE  \n 4.372435 19.118191  3.431580  \n\n```", "```py\nresults <- evaluate(x = eval_sets, method = model_to_evaluate, n = seq(10, 100, 10)) \n\n```", "```py\nhead(getConfusionMatrix(results)[[1]]) \n\n         TP        FP        FN        TN precision    recall       TPR        FPR \n10  6.63622  3.363780 10.714961 49.285039 0.6636220 0.4490838 0.4490838 0.05848556 \n20 10.03150  9.968504  7.319685 42.680315 0.5015748 0.6142384 0.6142384 0.17854766 \n30 11.20787 18.792126  6.143307 33.856693 0.3735958 0.6714050 0.6714050 0.34877101 \n40 11.91181 28.088189  5.439370 24.560630 0.2977953 0.7106378 0.7106378 0.53041204 \n50 12.96850 37.031496  4.382677 15.617323 0.2593701 0.7679658 0.7679658 0.70444585 \n60 14.82362 45.176378  2.527559  7.472441 0.2470604 0.8567522 0.8567522 0.85919995 \n\n```", "```py\ncolumns_to_sum <- c(\"TP\", \"FP\", \"FN\", \"TN\") \nindices_summed <- Reduce(\"+\", getConfusionMatrix(results))[, columns_to_sum] \nhead(indices_summed) \n         TP        FP       FN        TN \n10 32.59528  17.40472 53.22520 246.77480 \n20 49.55276  50.44724 36.26772 213.73228 \n30 55.60787  94.39213 30.21260 169.78740 \n40 59.04724 140.95276 26.77323 123.22677 \n50 64.22205 185.77795 21.59843  78.40157 \n60 73.67717 226.32283 12.14331  37.85669 \n\n```", "```py\nplot(results, annotate = TRUE, main = \"ROC curve\") \n\n```", "```py\nlibrary(recommenderlab) \ndata(\"Jester5k\") \nmodel_data = Jester5k[rowCounts(Jester5k) < 80] \nmodel_data \n[1] 3261  100 \n\n```", "```py\nboxplot(rowMeans(model_data)) \n\n```", "```py\ndim(model_data[rowMeans(model_data) < -5]) \n[1]  79 100 \ndim(model_data[rowMeans(model_data) > 7]) \n[1]  19 100 \n\n```", "```py\nmodel_data = model_data [rowMeans(model_data)>=-5 & rowMeans(model_data)<= 7] \nmodel_data \n[1] 3163  100 \n\n```", "```py\nwhich_train <- sample(x = c(TRUE, FALSE), size = nrow(model_data), \n replace = TRUE, prob = c(0.8, 0.2)) \nclass(which_train) \n[1] \"logical\" \nhead(which_train) \n[1] TRUE TRUE TRUE TRUE TRUE TRUE \n\n```", "```py\n model_data_train <- model_data[which_train, ] \ndim(model_data_train) \n[1] 2506  100 \n\n```", "```py\n model_data_test <- model_data[!which_train, ] \n dim(model_data_test) \n[1] 657 100 \n\n```", "```py\nmodel_to_evaluate <- \"IBCF\" \n\nmodel_parameters <- list(k = 30) \n\n```", "```py\nmodel_recommender <- Recommender(data = model_data_train,method = model_to_evaluate, parameter = model_parameters) \n\n```", "```py\nmodel_recommender \nRecommender of type 'IBCF' for 'realRatingMatrix'  learned using 2506 users. \n\n```", "```py\nitems_to_recommend <- 10 \n\n```", "```py\nmodel_prediction <- predict(object = model_recommender, newdata = model_data_test, n = items_to_recommend) \n\nmodel_prediction \nRecommendations as 'topNList' with n = 10 for 657 users.  \n\nprint(class(model_prediction)) \n[1] \"topNList\" \nattr(,\"package\") \n[1] \"recommenderlab\" \n\n```", "```py\nslotNames(model_prediction) \n[1] \"items\"      \"itemLabels\" \"n\"          \n\n```", "```py\n model_prediction@items[[1]] \n [1]  89  76  72  87  93 100  97  80  94  86 \n\n```", "```py\n recc_user_1  = model_prediction@items[[1]] \n\n jokes_user_1 <- model_prediction@itemLabels[recc_user_1] \n\n jokes_user_1 \n [1] \"j89\"  \"j76\"  \"j72\"  \"j87\"  \"j93\"  \"j100\" \"j97\"  \"j80\"  \"j94\"  \"j86\"  \n\n```", "```py\nn_fold <- 4 \n\n```", "```py\nitems_to_keep <- 15 \n\n```", "```py\nrating_threshold <- 3 \n\n```", "```py\neval_sets <- evaluationScheme(data = model_data, method = \"cross-validation\",k = n_fold, given = items_to_keep, goodRating =rating_threshold) \nsize_sets <- sapply(eval_sets@runsTrain, length) \nsize_sets \n[1] 2370 2370 2370 2370 \n\n```", "```py\nmodel_to_evaluate <- \"IBCF\" \nmodel_parameters <- NULL \n\n```", "```py\ngetData(eval_sets,\"train\") \n2370 x 100 rating matrix of class 'realRatingMatrix' with 139148 ratings \n\n```", "```py\neval_recommender <- Recommender(data = getData(eval_sets, \"train\"),method = model_to_evaluate, parameter = model_parameters) \n#setting the number of items to be set for recommendations \nitems_to_recommend <- 10 \n\n```", "```py\neval_prediction <- predict(object = eval_recommender, newdata = getData(eval_sets, \"known\"), n = items_to_recommend, type = \"ratings\") \n\nclass(eval_prediction) \n[1] \"realRatingMatrix\" \nattr(,\"package\") \n[1] \"recommenderlab\" \n\n```", "```py\neval_accuracy <- calcPredictionAccuracy(x = eval_prediction, data = getData(eval_sets, \"unknown\"), byUser = TRUE) \n\nhead(eval_accuracy)\n           RMSE      MSE      MAE \nu238   4.625542 21.39564  4.257505 \nu17322  4.953789  24.54003  3.893797 \nu5462  4.685714   21.95591  4.093891 \nu13120   4.977421  24.77472  4.261627 \nu12519   3.875182  15.01703  2.750987 \nu17883 7.660785 58.68762 6.595489 \n\n```", "```py\napply(eval_accuracy,2,mean) \n  RMSE      MSE      MAE  \n 4.45511 21.94246  3.56437  \n\n```", "```py\neval_accuracy <- calcPredictionAccuracy(x = eval_prediction, data = getData(eval_sets, \"unknown\"), byUser = FALSE)\n\neval_accuracy \n     RMSE       MSE       MAE  \n 4.672386 21.831190  3.555721  \n\n```", "```py\nresults <- evaluate(x = eval_sets, method = model_to_evaluate, n = seq(10,100,10)) \nIBCF run fold/sample [model time/prediction time] \n 1  [0.145sec/0.327sec]  \n 2  [0.139sec/0.32sec]  \n 3  [0.139sec/0.32sec]  \n 4  [0.137sec/0.322sec]  \n\n```", "```py\nresults@results[1]\n```", "```py\ncolumns_to_sum <- c(\"TP\", \"FP\", \"FN\", \"TN\",\"precision\",\"recall\") \nindices_summed <- Reduce(\"+\", getConfusionMatrix(results))[, columns_to_sum] \n\n```", "```py\nplot(results, annotate = TRUE, main = \"ROC curve\") \n\n```", "```py\nplot(results, \"prec/rec\", annotate = TRUE, main = \"Precision-recall\") \n\n```", "```py\nvector_k <- c(5, 10, 20, 30, 40)\n```", "```py\n model1 <- lapply(vector_k, function(k,l){ list(name = \"IBCF\", param = list(method = \"cosine\", k = k)) })\nnames(model1) <- paste0(\"IBCF_cos_k_\", vector_k)\nnames(model1) [1] \"IBCF_cos_k_5\" \"IBCF_cos_k_10\" \"IBCF_cos_k_20\" \"IBCF_cos_k_30\" [5] \"IBCF_cos_k_40\" #use Pearson method for similarities model2 <- lapply(vector_k, function(k,l){ list(name = \"IBCF\", param = list(method = \"pearson\", k = k)) })\nnames(model2) <- paste0(\"IBCF_pea_k_\", vector_k)\nnames(model2) [1] \"IBCF_pea_k_5\" \"IBCF_pea_k_10\" \"IBCF_pea_k_20\" \"IBCF_pea_k_30\" [5] \"IBCF_pea_k_40\" \n#now let's combine all the methods:\nmodels = append(model1,model2)\n```", "```py\nn_recommendations <- c(1, 5, seq(10, 100, 10))\n```", "```py\n list_results <- evaluate(x = eval_sets, method = models, n= n_recommendations)\nIBCF run fold/sample [model time/prediction time] 1 [0.139sec/0.311sec] 2 [0.143sec/0.309sec] 3 [0.141sec/0.306sec] 4 [0.153sec/0.312sec]\nIBCF run fold/sample [model time/prediction time] 1 [0.141sec/0.326sec] 2 [0.145sec/0.445sec] 3 [0.147sec/0.387sec] 4 [0.133sec/0.439sec]\nIBCF run fold/sample [model time/prediction time] 1 [0.14sec/0.332sec] 2 [0.16sec/0.327sec] 3 [0.139sec/0.331sec] 4 [0.138sec/0.339sec] IBCF run fold/sample [model time/prediction time] 1 [0.139sec/0.341sec] 2 [0.157sec/0.324sec] 3 [0.144sec/0.327sec] 4 [0.133sec/0.326sec]\n```", "```py\nplot(list_results, annotate = c(1,2), legend = \"topleft\")  \ntitle(\"ROC curve\") \n\n```", "```py\nplot(list_results, \"prec/rec\", annotate = 1, legend = \"bottomright\") \ntitle(\"Precision-recall\") \n\n```", "```py\npath = \"~/udata.csv\"\ndf = pd.read_csv(path, sep='\\t')\n```", "```py\ntype(df) \n<class 'pandas.core.frame.DataFrame'> \n\n```", "```py\ndf.head() \n UserID  ItemId   Rating  Timestamp \n0     196      242       3  881250949 \n1     186      302       3  891717742 \n2      22      377       1  878887116 \n3     244       51       2  880606923 \n4     166      346       1  886397596 \n\n```", "```py\ndf.columns \nIndex([u'UserID', u'ItemId ', u'Rating', u'Timestamp'], dtype='object') \n\n```", "```py\ndf.shape \n(100000, 4) \n\n```", "```py\nimport matplotlib.pyplot as plt \nplt.hist(df['Rating']) \n\n```", "```py\nplt.hist(df.groupby(['ItemId'])['ItemId'].count()) \n\n```", "```py\nn_users = df.UserID.unique().shape[0] \n\n```", "```py\nn_items = df['ItemId '].unique().shape[0] \n\n```", "```py\nprint(str(n_users) + ' users') \n943 users \n\nprint(str(n_items) + ' movies') \n1682 movies \n\n```", "```py\nratings = np.zeros((n_users, n_items)) \n\n```", "```py\nfor  row in df.itertuples(): \nratings[row[1]-1, row[2]-1] = row[3] \n\n```", "```py\ntype(ratings) \n<type 'numpy.ndarray'> \n\n```", "```py\nratings.shape \n(943, 1682) \n\n```", "```py\nratings \narray([[ 5.,  3.,  4., ...,  0.,  0.,  0.], \n       [ 4.,  0.,  0., ...,  0.,  0.,  0.], \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.], \n       ...,  \n       [ 5.,  0.,  0., ...,  0.,  0.,  0.], \n       [ 0.,  0.,  0., ...,  0.,  0.,  0.], \n       [ 0.,  5.,  0., ...,  0.,  0.,  0.]]) \n\n```", "```py\nsparsity = float(len(ratings.nonzero()[0])) \nsparsity /= (ratings.shape[0] * ratings.shape[1]) \nsparsity *= 100 \nprint('Sparsity: {:4.2f}%'.format(sparsity)) \nSparsity: 6.30% \n\n```", "```py\nfrom sklearn.cross_validation import train_test_split\n```", "```py\n ratings_train, ratings_test = train_test_split(ratings,test_size=0.33, random_state=42)\n```", "```py\n ratings_train.shape (631, 1682) \n#let's see the dimensions of the test set \nratings_test.shape (312, 1682)\n```", "```py\ndist_out \n\n```", "```py\nuser_pred = dist_out.dot(ratings_train) / np.array([np.abs(dist_out).sum(axis=1)]).T \n\n```", "```py\nfrom sklearn.metrics import mean_squared_error \ndef get_mse(pred, actual): \n    #Ignore nonzero terms. \n    pred = pred[actual.nonzero()].flatten() \n    actual = actual[actual.nonzero()].flatten() \n    return mean_squared_error(pred, actual) \n\n```", "```py\nget_mse(user_pred, ratings_train) \n7.8821939915510031 \n\n```", "```py\nget_mse(user_pred, ratings_test) \n8.9224954316965484 \n\n```", "```py\nfrom sklearn.neighbors import NearestNeighbors \n\n```", "```py\nneigh = NearestNeighbors(k,'cosine') \n\n```", "```py\nneigh.fit(ratings_train) \n\n```", "```py\ntop_k_distances,top_k_users = neigh.kneighbors(ratings_train, return_distance=True) \n\n```", "```py\ntop_k_distances.shape \n(631, 5) \ntop_k_users.shape \n(631, 5) \n\n```", "```py\ntop_k_users[0] \narray([  0,  82, 511, 184, 207], dtype=int64) \n\n```", "```py\nuser_pred_k = np.zeros(ratings_train.shape) \nfor i in range(ratings_train.shape[0]): \n    user_pred_k[i,:] =   top_k_distances[i].T.dot(ratings_train[top_k_users][i]) \n/np.array([np.abs(top_k_distances[i].T).sum(axis=0)]).T \n\n```", "```py\nuser_pred_k.shape \n(631, 1682) \n\nuser_pred_k \n\n```", "```py\nget_mse(user_pred_k, ratings_train) \n8.9698490022546036 \nget_mse(user_pred_k, ratings_test) \n11.528758029255446 \n\n```", "```py\nk = ratings_train.shape[1] \nneigh = NearestNeighbors(k,'cosine') \n\n```", "```py\nneigh.fit(ratings_train.T) \n\n```", "```py\ntop_k_distances,top_k_users = neigh.kneighbors(ratings_train.T, return_distance=True) \ntop_k_distances.shape \n(1682, 1682) \n\n```", "```py\nitem__pred = ratings_train.dot(top_k_distances) / np.array([np.abs(top_k_distances).sum(axis=1)]) \nitem__pred.shape \n(631, 1682) \nitem__pred \n\n```", "```py\nget_mse(item_pred, ratings_train) \n11.130000188318895 \nget_mse(item_pred,ratings_test) \n12.128683035513326 \n\n```", "```py\nk = 40 \nneigh2 = NearestNeighbors(k,'cosine') \nneigh2.fit(ratings_train.T) \ntop_k_distances,top_k_movies = neigh2.kneighbors(ratings_train.T, return_distance=True) \n\n#rating prediction - top k user based  \npred = np.zeros(ratings_train.T.shape) \nfor i in range(ratings_train.T.shape[0]): \n    pred[i,:] = top_k_distances[i].dot(ratings_train.T[top_k_users][i])/np.array([np.abs(top_k_distances[i]).sum(axis=0)]).T \n\n```", "```py\nget_mse(item_pred_k, ratings_train) \n11.130000188318895 \nget_mse(item_pred_k,ratings_test) \n12.128683035513326 \n\n```"]