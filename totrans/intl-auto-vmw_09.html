<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">ML as a Service in the Cloud</h1>
                </header>
            
            <article>
                
<p>This chapter will help you to learn about <strong>machine learning as a service</strong> (<strong>MLaaS</strong>) by using vRealize Automation. The ML workflow has data cleaning, model selection, feature engineering, model training, and inference. The production of the ML infrastructure is complicated to develop and manage because all ML processes will need to have their hardware and software modified.</p>
<p>We can minimize this complication by automating the provisioning of hardware resources, configuring them along with the operating system and application package, and giving access them to the related IT team. This process customization can be introduced as MLaaS. <span>We will learn how vRealize Automation provides MLaaS with use cases of MLaaS. It will also help in the design and configuration of the blueprint to define the process with workflows in vRealize Automation. We'll also look at <strong>load balancer as a service</strong> (<strong>LBaaS</strong>) and how <strong>network as a service</strong> (<strong>NaaS</strong>) can remove bottlenecks in hardware-based network architectures.</span></p>
<p>We will cover the following topics in this chapter:</p>
<ul>
<li>VMware approaches for MLaaS and its architecture</li>
<li> LBaaS with use cases</li>
<li> Transforming network and security services</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>You can download VMware vRealize Orchestrator Appliance 7.5.0 from <a href="https://my.vmware.com/web/vmware/details?downloadGroup=VROVA_750&amp;productId=742">https://my.vmware.com/web/vmware/details?downloadGroup=VROVA_750&amp;productId=742</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">MLaaS in a private cloud</h1>
                </header>
            
            <article>
                
<p>ML helps computers to acquire a knowledge without extensive programming and its performance enhances in compute and data by improving its development.</p>
<p>High-performance computing and big-data applications leverage virtualization as it helps in concurrent support for different software infrastructures, creating resource pools, consistent research surroundings, multi-domain data security, problem diagnosis and elasticity, effective load balancing, and QoS. <strong>H</strong><strong>igh-Performance Computing</strong> (<strong>HPC</strong>) and big data merged together so ML can be consumed as services from different cloud environments. These applications have huge data volumes with data-compliance and security policies to follow. Customers like to opt private cloud for hosting these ML applications with huge data which required more compute resources. </p>
<p>We can configure MLaaS in a private cloud using vRealize Automation to provide GPU-powered ML services for design/power users. The workflow can help to build an ML-based blueprint that can fulfill the particular requirements of design users.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">VMware approach for MLaaS</h1>
                </header>
            
            <article>
                
<p>We have two private-cloud options for building <strong>Infrastructure as a Service</strong> (<strong>IaaS</strong>) with VMware:</p>
<ul>
<li>vRealize Automation</li>
<li>Integrated OpenStack</li>
</ul>
<p>vRealize Automation helps to achieve IT automation by creating a tailor-made infrastructure, workloads, and applications hosted across hybrid cloud. VMware Integrated OpenStack is an OpenStack distribution with direct support from VMware, which helps customers to build an enterprise-class OpenStack cloud on the ever-reliable vSphere engine. It enhances performance with easy-to-use and vendor-independent OpenStack API access to the VMware environment. This chapter will brief you on creating MLaaS using VMware vRealize Automation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">MLaaS using vRealize Automation and vGPU</h1>
                </header>
            
            <article>
                
<p>We can configure a TensorFlow service that end users can consume through a self-service provisioning portal built with vRealize Automation. We have the NVIDIA card installed with vSphere, vRealize Automation, NVIDIA GRID drivers to support NVIDIA vGPU and a recommended guest OS on certified servers. </p>
<p>NVIDIA GRID vGPU Manager for ESXi driver should be configured on ESXi to provision vGPUs. The physical GPU should be shown in ESXi as a vGPU device rather then default vSGA device.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NVIDIA vGPU configuration on vSphere ESXi</h1>
                </header>
            
            <article>
                
<p>We can build a vRealize Automation template for end users to leverage a TensorFlow service. The workflow for creating and provisioning a TensorFlow service is mentioned in the next diagram. There will be five steps to build and provision a TensorFlow service for end users with a CentOS VM:</p>
<ol>
<li>Add an NVIDIA GRID vGPU to the VM</li>
<li>Customize the guest OS environment</li>
<li>Convert the VM into a template and create a customization specification</li>
<li>Design the blueprint</li>
<li>Publish the blueprint</li>
</ol>
<p><span>In <a href="30c0d68f-6ece-4c7b-86d1-a7a46183306e.xhtml" target="_blank">Chapter 1</a>, <em>Machine Learning Capabilities with vSphere 6.7,</em> we learned that the first three steps are configured in vCenter Console and the last two steps can be configured with vRealize Automation. The last two steps are mentioned in the following diagram:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7eb47ec1-2123-4494-99bf-3cf095ea0c13.png" style="width:30.50em;height:10.33em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Customizing the vRealize Automation blueprint </h1>
                </header>
            
            <article>
                
<p>First, we have to power off the VM installed with the driver/all tools and vGPU configured. We have to convert it into a template, which we can use as a blueprint with vRealize Automation. Once the template is created, we can then build a uniform tailor-made blueprint with defined parameters once the required template is created. Cloud Admin can use this to create clone blueprints for TensorFlow VMs:</p>
<ol>
<li>Log into the vSphere web client as administrator.</li>
<li>Right-click on the VM object and select <span class="packt_screen">Template</span> | <span class="packt_screen">Convert to Template</span>.</li>
</ol>
<ol start="3">
<li>Click on <span class="packt_screen">Customization Specification Manager</span><span> and create a new specification based on the template on the home page.</span></li>
<li>Create a software stack that defines the software life cycle for all software to be installed and configured within a blueprint while creating the VM.</li>
<li>The blueprints have to be designed to leverage the custom functions of vRealize Automation:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a5abe05d-93e9-4e15-ba63-a4981ecaec24.png"/></p>
<ol start="6">
<li>Bundle the software stack to design how the software will be installed, configured, started, upgraded, and uninstalled within a blueprint's VM in vRealize Automation. We can drag and drop this software stack onto a specific container variation on the design console.</li>
<li>Install TensorFlow by creating a software component. Explore the <span class="packt_screen">Design</span> tab, then select <span class="packt_screen">Software Components</span>, and choose <span class="packt_screen">New.</span></li>
<li>Define a name and details for the software stack. We have to mention the container specification as the machine in the general section and then click on <span class="packt_screen">Next</span> to continue.</li>
<li>Create a command script that will fetch a TensorFlow GPU container image and customize the <kbd>/etc/motd</kbd> file to show instructions to the end user when they log in to the TensorFlow VM. vRealize Automation will install the container image and the example bash script type can be changed as per required configuration and installation steps. </li>
</ol>
<ol start="10">
<li>Design the blueprint. Blueprints define the process for services to be implemented using vRealize Automation. We can opt for a basic blueprint that can deploy only a single VM, and a multi-VM blueprint that has software stacks, networks, security, and storage policies:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/116b5a17-9945-40f6-bbfb-7aa1069950a1.png"/></p>
<ol start="11">
<li>Create a blueprint than has only a CentOS VM, TensorFlow application, and associated virtual network: explore the <span class="packt_screen">Design</span> tab, choose <span class="packt_screen">Blueprints</span>, and select <span class="packt_screen">New</span>.</li>
<li>Mention the name and details in the new blueprint section so a unique ID will be generated.</li>
<li>Add an ESXi host to the TensorFlow blueprint by choosing <span class="packt_screen">Machine Types</span> from the <span class="packt_screen">Categories</span> section and dragging the ESXi host to the design console. We have to define other parameters and mention the prefix in the <span class="packt_screen">General</span> tab to be used with all VM names built by the blueprint and gave access to users for self provisioning of up to four TensorFlow VMs.</li>
<li>Access the <span class="packt_screen">Machine Resources</span> tab to get information about the virtual CPU, memory, and storage to be configured for the VMs created by this blueprint.</li>
<li>Specify the virtual network under the <span class="packt_screen">Network</span> tab when the VM gets created.</li>
</ol>
<ol start="16">
<li>Choose the required network from the drop-down menu and select <span class="packt_screen">DHCP</span> or <span class="packt_screen">S</span><span class="packt_screen">tati</span><span class="packt_screen">c</span>. If we include a passthrough PCI device to a VM, we have to allocate full memory reservation for this configuration. The template called VM memory reservation will be not able to keep this configuration during the cloning process. To manage this, we have to add the specific<span class="packt_screen"> VMware.Memory.Reservation</span> parameter with a defined memory size by exploring the <span class="packt_screen">Properties</span> tab. </li>
</ol>
<p>We can provision this blueprint as service through the vRealize Automation service catalog from the <span class="packt_screen">Machine learning</span> category and nominate users to use it. <span>Edit the </span><span class="packt_screen">Custom Properties</span> tab and follow the below steps:</p>
<ol>
<li>Choose <span class="packt_screen">TensorFlow-GPU</span> in <span class="packt_screen">Blueprints</span></li>
<li>Click on <span class="packt_screen">Publish</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ae7c94d4-3b67-471b-ac74-16de3f30d552.png"/></p>
<p>We can see various ML/DL services with and without GPUs from a self-service provisioning portal in the preceding screenshot, which design users can use defined resources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LBaaS overview</h1>
                </header>
            
            <article>
                
<p>Customers can use LBaaS by integrating it with NSX and the vRealize automation engine, which create a workflow to include applications requirements. They can also integrate with third-party tools with this service for automated deployment and monitoring of services. We have many options to design a load balancer as a service by using the VMware software-defined approach.</p>
<p>The load balancer must offload SSL to enhance performance and its output. A global load balancer has to fail over to application services between multiple data centers. It has to use the most productive load-balancing algorithm to increase the productivity of the application services. It can monitor the application services and generate alerts as soon as it finds any threats. </p>
<p>VMware <strong>vRealize Orchestrator</strong> (<strong>vRO</strong>) assists us in building LBaaS by automating F5 virtual server deployments as per predefined workflows that contain parameters such as number of steps, virtual server addition associated with IP address, protocol, port, profile, and a monitoring report of a specific virtual server. LBaaS has to provide HTTPS as a service and offload SSL. vRO can execute scripts on a PowerShell server to generate Microsoft CA signed certificates and transfer it to the F5 server. It ensures SSL is attached to the F5 profile.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LBaaS design use cases</h1>
                </header>
            
            <article>
                
<p>LBaaS use cases are as follows:</p>
<ul>
<li>Deploying a single-site load balancer</li>
<li>Deploying a multi-site load balancer</li>
<li>Customizing a load balancer</li>
<li>Removing a VM</li>
</ul>
<p class="mce-root"/>
<p>Let us see the use cases in detail:</p>
<ul>
<li><strong>Deploying a single-site load balancer</strong>:<strong> </strong>Create the VMs and then define the load balancer with specific VMs. Users can log in through the <strong>Self-Service Portal</strong> (<strong>SSP</strong>) and request a virtual server. As per design, the load balancer is configured at one site. Users can choose data with list boxes and combo boxes along with pre-populated data to provide data entry process. vRealize has the capability to invoke vRO, which in turn will execute predefined workflow steps to provision a F5 virtual server for the group of virtual servers selected by the user.<br/>
Once vRealize Automation receives the application-specific data, it can create an F5 <strong>Local Traffic Manager</strong> <span>(</span><strong>LTM</strong><span>) virtual server with a</span> <span><strong>VMware Infrastructure Planner</strong> (</span><strong>VIP</strong><span>) and DNS name as per workflow:</span></li>
</ul>
<table border="1" style="border-collapse: collapse;width: 100%">
<thead>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Step</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Actor</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Actions</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>User</p>
</td>
<td>
<ol>
<li>Logs in to vRealize SSP</li>
<li>Requests LBaaS provisioning using a XaaS Blueprint</li>
<li>Provides necessary data to the request form</li>
</ol>
</td>
</tr>
<tr>
<td>
<p>2</p>
</td>
<td>
<p>vRealize Automation</p>
</td>
<td>
<ol>
<li>Receives and validates the data entered by users</li>
<li>Invokes vRO workflows to provision the F5 virtual server</li>
</ol>
</td>
</tr>
<tr>
<td>
<p>3</p>
</td>
<td>
<p>vRO</p>
</td>
<td>
<ol>
<li>Provisions the F5 virtual server</li>
<li>Attaches the F5 virtual server with the virtual machines selected by the user</li>
</ol>
</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Deploying a multi-site load balancer</strong>:<strong> </strong>A multi-site load balancer configuration is different from a single-site load balancer as two F5 LTMs associated with a Big-IP DNS are configured in two data centers. Big-IP DNS is not mandatory and required only as global load balancers. Its workflow helps users with various alternatives for traffic flow methods (that is, 50/50, 80/20, 60/40, 40/60, and 20/80) across two sites.<br/>
Users will enter the data into the vRealize Automation request form. vRealize Automation will invoke vRO workflows to process the data, create two F5 virtual servers (one on each site), and a F5 Big-IP DNS system:</li>
</ul>
<table border="1" style="border-collapse: collapse;width: 100%">
<thead>
<tr>
<td>
<p><strong>Step</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Actor</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Actions</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>User</p>
</td>
<td>
<ol>
<li>Logs in to vRealize SSP</li>
<li>Requests LBaaS provisioning using a XaaS Blueprint</li>
<li>Chooses the <strong>Global Traffic Manager</strong> (<strong>GTM</strong>) checkbox to create a multi-site load balancer</li>
<li>Inputs LTM and GTM information to the request form</li>
</ol>
</td>
</tr>
<tr>
<td>
<p>2</p>
</td>
<td>
<p>vRealize Automation</p>
</td>
<td>
<ol>
<li>Receives and validates the data entered by users</li>
<li>Invokes vRO workflows to provision three F5 virtual servers—<span>one per site on LTM and one for Big-IP DNS</span></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>3</p>
</td>
<td>
<p>vRO</p>
</td>
<td>
<ol>
<li>Provisions the F5 virtual servers</li>
<li>Attaches the F5 virtual server with the VMs selected by the user</li>
</ol>
</td>
</tr>
</tbody>
</table>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<ul>
<li><strong>Modifying a load balancer</strong>:<strong> </strong>The load balancer can be customized on F5 with a new VM and then we can execute a XaaS blueprint to a new VM configured with the load balancer. If the user selects the incorrect load balancer algorithm during the load balancer deployment, they can amend it through a XaaS blueprint.<br/>
The following table describes the actions for this use case:</li>
</ul>
<p style="padding-left: 60px"/>
<table border="1" style="border-collapse: collapse;width: 100%">
<thead>
<tr>
<td>
<p><strong>Step</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Actor</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Actions</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>User</p>
</td>
<td>
<ol>
<li>Logs in to vRealize SS</li>
<li>Requests LBaaS modification using a XaaS Blueprint</li>
<li>Provides the necessary data to modify an existing load balancer</li>
</ol>
</td>
</tr>
<tr>
<td>
<p>2</p>
</td>
<td>
<p>vRealize Automation</p>
</td>
<td>
<ol>
<li>Receives and validates the data entered by users</li>
<li>Invokes the vRO workflows to modify the F5 virtual server</li>
</ol>
</td>
</tr>
<tr>
<td>
<p>3</p>
</td>
<td>
<p>vRO</p>
</td>
<td>
<ol>
<li>Modifies the F5 virtual server</li>
</ol>
</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>De-provisioning a VM</strong>:<strong> </strong>We can de-provision any member VM of the F5 virtual server member pool with a vRealize Automation workflow, otherwise F5 will release alerts with the message that <span class="packt_screen">T</span><span class="packt_screen">he virtual machine is unavailable</span>.<br/>
Users can also remove the VM from a F5 virtual server pool with a modified XaaS workflow. The F5 virtual server member pool will be automatically finished as the last VM is deleted:</li>
</ul>
<table border="1" style="border-collapse: collapse;width: 100%">
<thead>
<tr>
<td>
<p><strong>Step</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Actor</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Actions</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>User</p>
</td>
<td>
<ol>
<li>Logs in to vRealize SSP</li>
<li>Requests VM de-provisioning using an existing blueprint</li>
</ol>
</td>
</tr>
<tr>
<td>
<p>2</p>
</td>
<td>
<p>vRealize Automation</p>
</td>
<td>
<ol>
<li>Calls the LBaaS XaaS workflow as part of the VM de-provisioning blueprint</li>
</ol>
</td>
</tr>
<tr>
<td>
<p>3</p>
</td>
<td>
<p>LBaaS XaaS Workflow</p>
</td>
<td>
<ol>
<li>Receives all necessary data from the VM de-provisioning request</li>
<li>Calls the vRO workflow</li>
</ol>
</td>
</tr>
<tr>
<td>
<p>4</p>
</td>
<td>
<p>vRO</p>
</td>
<td>
<ol>
<li>Creates the XaaS workflow to add/remove VMs from the F5 virtual server member pool</li>
</ol>
</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>LBaaS workflow</strong>: To provision a multi-site load balancer, two identical load balancers are deployed at each site in a multi-site design. A Big-IP DNS wide-IP is also created and the user is asked to enter other input along with the primary site and traffic flow ratio:</li>
</ul>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign"><strong> Lane</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Action</strong></p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><strong>Notes</strong></p>
</td>
</tr>
<tr>
<td>
<p>vRO</p>
</td>
<td>
<p>Advanced F5 GTM Workflow using REST API</p>
</td>
<td>
<ol>
<li>Click the GTM checkbox and enter the Big-IP DNS parameters to run a workflow to build a BIG-IP DNS global load balancer</li>
</ol>
</td>
</tr>
</tbody>
</table>
<p class="mce-root"/>
<p>The following diagram shows the workflow:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c29f89b7-9a4f-4751-9aca-fbd21ecd1bd1.png"/></p>
<p>Let's go through all of the functions mentioned in the preceding diagram. As we know, the first five steps were already discussed in the LBaaS workflow and are needed to execute the LBaaS workflow. All functions are given from a reference point of view:</p>
<ol>
<li>Create a listener. From the Big-IP DNS UI, select <span class="packt_screen">DNS</span> | <span class="packt_screen">Delivery</span> to provide the values to the listener parameters. A listener needs to be created on each site. This is a prerequisite for the LBaaS workflow.</li>
<li>Create the data centers. From the Big-IP DNS UI, select <span class="packt_screen">DNS</span> | <span class="packt_screen">GSLB</span> | <span class="packt_screen">Data Centers</span> | <span class="packt_screen">Data Center List</span> | <span class="packt_screen">New Data Center</span> to provide the data center name and other parameters. You will need to repeat this step for both data centers. This is a prerequisite for the LBaaS workflow.</li>
<li style="color: black">Create the Big-IP DNS and LTM servers. From the Big-IP DNS UI, select <span class="packt_screen">DNS</span> | <span class="packt_screen">GSLB</span> | <span class="packt_screen">Servers</span> | <span class="packt_screen">Server List</span> | <span class="packt_screen">New Server</span> to add LTM servers to Big-IP DNS. You will need to repeat this step for both data centers: the <span>Primary and Secondary sites</span>. This is a prerequisite for the LBaaS workflow.</li>
<li style="color: black">Configure the <kbd>(bigip_add utility)</kbd> iQuery:
<ol>
<li>Log in to the BIG-IP DNS at Rancho Cordova.</li>
<li>Run the <kbd># bigip_add &lt;rc-ltm-ip&gt;</kbd> command to add Rancho Cordova LTM to the GTM.</li>
<li>Upon successful communication between BIG-IP DNS and LTMs, the status in the BIG-IP DNS UI will turn green. This is a pre-requisite for the LBaaS workflow.</li>
</ol>
</li>
</ol>
<ol start="5">
<li style="color: black">Configure sync-group:
<ol>
<li>Add both DNS servers (<kbd>RC_DNS</kbd> and <kbd>FX_DNS</kbd>) to the BIG-IP DNS system.</li>
<li>Create a sync-group.</li>
<li>Use the <kbd>#gtm _add &lt;fx-gtm-ip&gt;</kbd> command to add the Fairfield Annex BIG-IP GTM appliance.</li>
<li>Use the <kbd>#bigip_add &lt;fx-ltm-ip&gt;</kbd> command to add the Fairfield Annex BIG-IP LTM appliance. This is a pre-requisite for the LBaaS workflow</li>
</ol>
</li>
<li>Create the <strong>Global Server Load Balancer</strong> (<strong>GSLB</strong>) pool:
<ol>
<li>The GSLB pool will be created as part of the LBaaS workflow. The pool name will be provided by the user as part of the XaaS UI.</li>
<li>If created manually, select <span class="packt_screen">GSLB</span> | <span class="packt_screen">Pools</span>. Click on <span class="packt_screen">Create</span><em> </em>to create a global pool.</li>
</ol>
</li>
<li>Create wide-IP:
<ol>
<li>Wide-IP will be created as part of the LBaaS workflow.</li>
<li>If created manually, select <span class="packt_screen">GSLB</span> | <span class="packt_screen">Wide IPs</span>. Click <span class="packt_screen">Create</span> to create a wide-IP. The wide-IP name will be provided by the user as part of the XaaS UI.</li>
<li>An IP address will be assigned to wide-IP through the vRO IP reserve workflow from Infoblox.</li>
</ol>
</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Challenges with network and security services </h1>
                </header>
            
            <article>
                
<p>Network and security were always the bottleneck of the infrastructure.</p>
<p>Below are the major pain points with rigid hardware defined infrastructure :</p>
<ul>
<li>Placement and mobility were limited by the physical port </li>
<li>Provisioning was slow due to lack of advanced automation capabilities, as it is not designed for automation</li>
<li>It was operationally intensive and hardware-dependent</li>
</ul>
<p class="mce-root"/>
<p>The following can be done to achieve IT as a service model:</p>
<ul>
<li>Cloud networking architectural and operational model support the evolution of <strong>IT as a service</strong> (<strong>ITaaS</strong>) model</li>
<li>End-to-end visibility with real time monitoring and troubleshooting (across virtual and physical networks) for integrated network availability and performance management</li>
<li>On-demand automated network provisioning and configuration to support rapid application deployment</li>
<li>New organizational model to facilitate collaboration between new cloud/SDDC team and existing functional teams (application, server, network and storage)</li>
<li>Skills to support the new operational model and service-oriented approach</li>
</ul>
<p>To gain an understanding of the concepts of a new IT operating model and why network and security should be part of it.</p>
<p><strong>Different phases of NaaS Model</strong></p>
<ul>
<li>Review the ITaaS and NaaS operating models</li>
<li>Identify the capabilities required to deliver and operate NaaS</li>
<li>Understand the journey to the NaaS operating model from both an operational and organizational standpoint</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The NaaS operating model</h1>
                </header>
            
            <article>
                
<p>NaaS is one of the important part of the ITaaS operating model which help customers to achieve specific IT (network,security, and so on) outcomes. We have to review current network and security operating model across people, processes and technology and how to offer NaaS using the VMware Operations Transformation model and framework.</p>
<p>We should first discover the operational capabilities required to manage and operate NaaS based services with a structured approach.</p>
<p>It focuses on three main areas:</p>
<ul>
<li>Proactive operations management</li>
<li>Network and security service provisioning</li>
<li>Security operations</li>
</ul>
<p class="mce-root"/>
<p>The key operational capabilities are identified, as well as how to transform from the current operational capabilities to operating a network virtualization environment that enables the NaaS vision for each of the following areas:</p>
<ul>
<li>Defining the vision and strategy</li>
<li>Defining key operational capabilities</li>
<li>Assessing operational readiness</li>
<li>Building an operations transformation roadmap and plan</li>
<li>Developing and implementing the target operating model <span>with </span>the NaaS vision</li>
</ul>
<p>The VMware NaaS transformation workshop service provides customers with an operational and organizational view on how to leverage the network virtualization architecture to move toward a NaaS operating model and ultimately toward the ITaaS operating model.</p>
<p>VMware defines ITaaS as a new delivery and operating model that leverages cloud technologies to enable business agility and value-based choice through readily-consumable IT services that have transparent prices and established service levels. The network plays a key role in enabling the ITaaS vision. Until now seen as a barrier to agility and speed, the new and emerging network architecture, based on network virtualization and SDDC/cloud, makes a new way to deploy, manage, and operate network and security possible.</p>
<p>The new operating model implies a paradigm shift from a device-centric operating model to a service-oriented operating model called NaaS. Though network virtualization is the technology enabler, the technology alone is not enough to achieve the full benefits of software-defined networking (and SDDC in general) but it has to be complemented by streamlined, integrated, and automated processes and a cross-functional organization that breaks silos with new skills.</p>
<p>This paradigm shift is actually an operations transformation that goes beyond the technology aspects that impact operational and organizational aspects. The operational and organizational aspects shouldn't be considered as an afterthought—they should be planned and designed in parallel to the technology plan and design.</p>
<p>The NaaS transformation workshops are directed to support the customer in the vision and strategy-definition phase, as well as in the planning of the operational and organizational capabilities required to deploy, manage, and operate the network virtualization solution that the customer is going to implement.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The goal of the workshops is to facilitate the customer to understand the NaaS operating model and identify the operational and organizational impact and challenges of network virtualization adoption as well as the capabilities required to fully leverage the benefits of the emerging network architecture.</p>
<p>The workshop service also provides an introduction to the VMware Operations Transformation model and framework and how it applies to driving the operational and organizational maturity growth toward the NaaS operating model.</p>
<p>The NaaS service can be divided into two parts: </p>
<ul>
<li class="mce-root"><strong>NaaS transformation envisioning</strong>: We have to assist customers with a clear understanding of the VMware NaaS operating model, its role as part of the ITaaS operating model, and the benefits of adopting this model in terms of IT outcomes. We will also discuss the customer's operational strategy, goals and objectives, the current network and security operating model across people, processes and technology and how it can be transformed to NaaS using the VMware Operations Transformation model and framework. This is oriented to network and IT infrastructure and operations teams that are willing to explore how network virtualization can drive the adoption of a new network and security operating model to make IT more agile, flexible, efficient, and business-aligned.</li>
<li><strong>NaaS transformation discovery</strong>: Discover the operational capabilities required to manage and operate NaaS starting from a process perspective. The end-to-end operational processes are decomposed in common process elements and the operational capabilities required to optimally execute the process elements are identified. The discovery activity focuses on three main areas: proactive operations management, network and security services automated provisioning, and life cycle management and security operations. For each area, the key operational capabilities are identified and high-level observations on how to evolve and transform from the current operational capabilities to operating a network virtualization environment that enables the NaaS vision.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Transforming traditional network by consuming NaaS:</p>
<ul>
<li><strong><span><span>Traditional</span></span> networking challenges</strong>: Networking is all about ports and its capabilities related to performance, configuration, and the power dissipation of custom <strong><span>application-specific integrated circuits</span></strong> (<strong>ASICs</strong><span>)</span>. It's also connected with related s<span>killsets and OpEx cost-related with network operations. Network services will not be agile if it sticks with particular physical device with manual deployment, </span><span>which raises the</span> <span>risk of configuration changes and human errors. It is n</span><span>ot justified to write a script for each device interfaces to orchestrate automation as it creates hindrance to utilize the full capabilities of virtualization and cloud model.</span></li>
<li><strong>Networking is a service</strong>: <span>It always has been, and will continue to be, a service by a</span><span>bstracting, creating resource pools, and automating the network. </span><span>Networking services are instantly provisioned from a capacity pool, decoupled from specific hardware, made equally mobile, deployed using templates, and controlled and managed through policies. The </span><span>NaaS operating model enables us to deliver the agile data center of the future, the service velocity and agility that modern applicatio</span><span>ns need, and the OpEx and CapEx efficiencies and cost savings we desire.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">LBaaS network design using NSX</h1>
                </header>
            
            <article>
                
<p>VMware NSX can assist us in building <strong>V</strong><span><strong>irtual Extensible LAN</strong></span><span> </span>(<strong>VXLAN</strong>) based virtual networks automated deployment to produce micro segmentation across different web, app, and DB servers. A <strong>Distributed Logical Router</strong> (<strong>DLR</strong>) will be provisioned to enable routing between networks produced by leveraging NSX logical switches. Since a DLR supports up to 1,000 logical interfaces, logical switches for several applications can be connected to DLR to leverage its routing capabilities.</p>
<p>Application-level segmentation can then be provided using NSX Service Composer features, such as security groups and security policies. BIG-IP DNS helps to maintain applications redundancy with native intelligence. Two BIG-IP DNS systems deployed at two sites will work as a single unit but accountable for primary and secondary authoritative name service. </p>
<p>The users get the most favorable IP address (which is the LTM VIP) from site A (primary) or site B (secondary) based on defined rules, such as resource redundancy, SLA, load, geographical location, or QoS.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>BIG-IP DNS assists with various kinds of queries when the <em>A</em> type query is used extensively. A BIG-IP DNS gets a query by matching the domain name and type with a wide-IP, then it chooses a pool (GSLB pool) to justify the response. Then it gets a virtual server from the pool by reacting with an IP address. GSLB pool will help in choosing a virtual server across both sites based on the load-balancing policy on each site and resources availability at runtime.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">BIG-IP DNS high-level design</h1>
                </header>
            
            <article>
                
<p>Wide-IP is a <strong>Fully-Qualified Domain Name</strong> (<strong>FQDN</strong>) to get the application URL, which is a web application hosted on a group of web servers, such as Apache or IIS. BIG-IP DNS resolves queries to define wide-IP FQDN association with a virtual server (VIP) from a GSLB pool that has two virtual servers at each site.</p>
<p>The load-balancer pool algorithms for the LTM virtual server and BIG-IP DNS virtual server are not the same, and the LTM virtual server load-balancer algorithm is chosen by the user from a drop-down field. The BIG-IP DNS GSLB pool algorithm is defined on user input. There are three kinds of GSLB pool algorithms that were chosen for the LBaaS design: global delivery, ratio, and round robin.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Customizing the BIG-IP DNS component</h1>
                </header>
            
            <article>
                
<p>The BIG-IP DNS configuration has the following components:</p>
<ul>
<li><strong>Listener</strong>: This is the BIG-IP DNS object that operates and answers to DNS queries. The listener configuration on BIG-IP DNS should be defined before executing the LBaaS workflow.</li>
<li><strong>Data center</strong>: This is a container object which host the place for application delivery components and has two LTM virtual servers from each site. The data center configuration on BIG-IP DNS should be defined before executing the LBaaS workflow.</li>
<li><strong>Server</strong>: This is a container object which host application components reside and can be a BIG-IP DNS, LTM server, or physical server instance. The server configuration on BIG-IP DNS should be defined before executing the LBaaS workflow.</li>
<li><strong>Virtual server</strong>:<strong> </strong>The virtual server has the IP address and service port configured on a physical server. BIG-IP DNS use these IP addresses and service ports to resolve queries and choose suitable virtual server.</li>
<li><strong>Pool</strong>: This is a logical object configured on the BIG-IP DNS system<strong>.</strong> Virtual servers can be set with different pools to resolve queries in a smart way. GSLB pool can be created by grouping all concerned virtual servers. Pool configuration for LBaaS will be customized on-demand using LBaaS workflow.</li>
<li><strong>Wide-IP</strong>: This is a logical container that is known as FQDN by grouping GSLB pools and have a batch of all concerned virtual servers. This object is developed and customized in the LBaaS workflow. The IP address for the FQDN will be restrained on Infoblox by leveraging a vRO workflow.</li>
<li><strong>DIG</strong>: The DNS resolution utility is a tool to experiment with wide-IP configuration and can be downloaded to a system. Users like to download the utility to the PowerShell desktop to check the acceptance of wide-IP configuration with the LBaaS workflow. The <kbd>#dig @listener-ip wide-ip-name</kbd> command will post a DNS query to the listener and show the response from BIG-IP DNS.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The BIG-IP DNS load-balancing algorithm</h1>
                </header>
            
            <article>
                
<p><span>We have three kinds of load-balancer algorithms based on the LBaaS design, which we'll explore here; they should be registered effectively to the BIG-IP DNS GSLB Pool.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Global availability</h1>
                </header>
            
            <article>
                
<p>This load-balancing algorithm will be suitable for the active/standby <span>scenario and BIG-IP DNS disperse DNS name resolution requests to the first accessible virtual server from the configured list in a pool and, if the virtual server is not accessible, then BIG-IP DNS post requests to the next virtual server in the configured list.</span></p>
<p>The vRO workflow should define the GSLB pool load-balancing algorithm as globally available when a user chooses Active/standby in the XaaS form. It also makes sure that the first reachable virtual server will be from active site.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ratio</h1>
                </header>
            
            <article>
                
<p>The LBaaS workflow has to manage traffic flow across two sites. The BIG-IP DNS Ratio load-balancing algorithm can assist you in fulfilling this use case. The ratio l<span>oad-balancing method disperses DNS name resolution requests between the virtual servers in a pool by leverag</span>ing a weighed round robin. Wei<span>ghts for both virtual servers should be measured in the vRO workflow and registered by using the REST APIs. We can choose the ratio as a user from a drop-down list in XaaS form.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Round robin</h1>
                </header>
            
            <article>
                
<p>The LBaaS workflow can distribute inbound requests by keeping an active state at both sites. The BIG-IP DNS round robin algorithm can be configured for the GSLB pool. BIG-IP DNS name-resolution requests can be distributed between the virtual servers of a GSLB pool in sequence so each virtual server will get a similar number of requests.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The LBaaS LTM design</h1>
                </header>
            
            <article>
                
<p>LBaaS design used to suppose that BIG-IP virtual editions are installed on both sites. It also suppose that <strong>Device Service Clustering</strong> (<strong>DSC</strong>) can be used for every pair of BIG-IP appliances with the active/active scenario. The LBaaS design also understands that a sync failover device configuration survives on the virtual editions pair to sync the device configuration among the members pair so the devices can failover vice versa.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuring BIG-IP LTM objects</h1>
                </header>
            
            <article>
                
<p><span>The following objects are configured automatically by using the LBaaS workflow in the F5 LTM:</span></p>
<ul>
<li><span><strong>Node</strong>:</span><span> It represents the IP address of a physical or virtual instance in a network, such as a web server or an application server. A single node can have many application services running different or same kind of services associated with a pool member.</span></li>
<li><span><strong>Pool Member</strong>:</span><span> </span><span>It is union of an IP address and a port number that defines an application service that resides on a node. A pool member is obtained by a BIG-IP system.</span></li>
<li><span><strong>Pool</strong>:</span><span> Load balancing can be accomplished by grouping one or more pool members and choosing suitable pool members. Load balancing policy should be configured on a pool with the specific pool members.</span></li>
<li><span><strong>Virtual server</strong>:</span><span> It is a kind of listener which permits matching traffic types consisting of virtual server IP and port and forward them to pool members as per load balancing policy. All traffic gets blocked as the F5 LTM is a default-deny system. Virtual servers are ideal units that connect the clients.</span></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Designing the LTM load-balancing method</h1>
                </header>
            
            <article>
                
<p>We can configure many load-balancing techniques with the LTM virtual server traffic operations. Users get a drop-down box to choose one of the following load-balancing techniques:</p>
<ul>
<li><span class="packt_screen">Round Robin</span> (Default)</li>
<li><span class="packt_screen">Least Connections</span></li>
<li><span class="packt_screen">Weighted Least Connections</span></li>
<li><span class="packt_screen">Ratio</span></li>
<li><span class="packt_screen">Observed</span></li>
<li><span class="packt_screen">Dynamic Ratio</span></li>
<li><span class="packt_screen">Least Sessions</span></li>
<li><span class="packt_screen">Fastest</span></li>
<li><span class="packt_screen">Predictive</span></li>
</ul>
<p>The <span class="packt_screen">LTM</span> tab is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b653e3bc-0e6d-4f45-90a2-8f545339e84c.png" style="width:30.00em;height:31.67em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Designing the LTM virtual server</h1>
                </header>
            
            <article>
                
<p>VMware Cloud on the AWS L2 network extension service provides customers with the capability to extend the on-premises networks to VMware Cloud on AWS over any IP network using an SSL VPN tunnel (L2VPN) by creating subnets with a single broadcast domain. This enables customers to move workloads between an on-premises network and VMware Cloud on AWS without changing the IP address.</p>
<p>This service starts by introducing it's offering and collecting details to perform a technical gap analysis and recommendation, which helps the customer to prepare the environment for L2 network extension. VMware Cloud on the AWS environment is configured, and extended network functional testing is performed.</p>
<p>Objectives with this service initiative to perform below two activities:</p>
<ul>
<li>Establishing an SSL tunnel (L2VPN) between on-premises and VMware Cloud on the AWS network</li>
<li>Extending the L2 subnets across on-premises and VMware Cloud on AWS networks using the SSL tunnel</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>We can choose from various kinds of cloud-based offerings, including SaaS and IaaS. <strong>Machine Learning as a Service</strong> (<strong>MLaaS</strong>) is one of the latest innovations in the IT industry. ML deployment basically needs huge amounts of data and advanced users who can investigate patterns from the data volumes. The ML algorithm is always a hit-and-miss scenario. MLaaS will play a crucial role in AI adoption as it'll help developers and businesses reap the benefits of ML features. It will assist in embedding AI in business apps and enable organizations to use data in better ways to achieve their business objectives.</p>
<p>VMware SDDC products and approaches can be utilized to automate various services, and not just for the VMware-offered products but even for third-party tools. The entire process of provisioning and de-provisioning services using vRealize products can be automated along with vRealize Orchestrator, vRealize Log Insight, and NSX on top of vSphere hypervisor.</p>
<p>The next chapter, <a href="54661ee3-fa2a-4640-b539-6a67f00669e9.xhtml" target="_blank">Chapter 8</a>, <em>Machine Learning-Based Rule Engine with Skyline</em>, will give you a detailed overview of VMware Skyline. We will collect information from a customer and use ML as an intelligent rule engine to monitor and provide proactive support for a faster resolution by preventing upcoming threats.</p>


            </article>

            
        </section>
    </body></html>