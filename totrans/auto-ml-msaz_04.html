<html><head></head><body>
		<div id="_idContainer046">
			<h1 id="_idParaDest-45"><em class="italic"><a id="_idTextAnchor044"/>Chapter 3</em>: Training Your First AutoML Model</h1>
			<p>With an Azure account, an Azure Machine Learning workspace, a compute cluster, and a basic understanding of how AutoML works, you're now ready to train your first automated machine learning model. It will be easy and straightforward: AutoML is an equalizer that enables even novices to create advanced models in mere minutes, and you will appreciate its power by the end of this chapter regardless of your background. Practice makes perfect, and this chapter is your first step toward becoming an AutoML practitioner.</p>
			<p>You will begin this chapter by loading data from your local machine to your <strong class="bold">Azure Machine Learning Studio </strong>(<strong class="bold">AML Studio</strong>), selecting only the columns you need for training. Then, you will proceed to train an AutoML model using the guided user interface. After training your model, you will learn how to interpret your results directly from the AMLS portal. This includes not only standard metrics such as accuracy, false positive rate, and false negative rate, but also an explainability dashboard that will wow your business end users. Lastly, there is a tips and tricks section that will assist you in future projects. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Loading data into AMLS for AutoML</li>
				<li>Creating an AutoML solution</li>
				<li>Interpreting your AutoML results</li>
				<li>Explaining your AutoML model</li>
				<li>Obtaining better AutoML performance</li>
			</ul>
			<h1 id="_idParaDest-46"><a id="_idTextAnchor045"/>Technical requirements</h1>
			<p>To follow along with this chapter, you will require the following:</p>
			<ul>
				<li>Access to the internet</li>
				<li>A web browser, preferably Google Chrome or Microsoft Edge Chromium</li>
				<li>A Microsoft Azure account</li>
				<li>An Azure Machine Learning service workspace</li>
			</ul>
			<h1 id="_idParaDest-47"><a id="_idTextAnchor046"/>Loading data into AMLS for AutoML</h1>
			<p>Just as you registered the Diabetes Open dataset in <a href="B16595_02_ePub.xhtml#_idTextAnchor023"><em class="italic">Chapter 2</em></a>, <em class="italic">Getting Started with Azure Machine Learning Service</em>, you will now be registering a publicly available Titanic dataset <a id="_idIndexMarker113"/>using AMLS. </p>
			<p>Unlike <a id="_idIndexMarker114"/>the diabetes dataset, however, you will load the data directly from your desktop to the portal. The Titanic dataset holds information relating to who survived and who died aboard the infamous <a id="_idIndexMarker115"/>ill-fated voyage. You will build a model that predicts survivors based on demographic information such as age and gender, as well as ticket information, such as passenger class and ticket price:</p>
			<ol>
				<li>First, you will need to download the Titanic data from the GitHub repository. </li>
				<li>Then, you will need to open up your <strong class="bold">Azure Machine Learning Studio</strong> by navigating to <a href="http://ml.azure.com">http://ml.azure.com</a>. </li>
				<li>Once you are in the studio, click <strong class="bold">Datasets</strong> on the right-hand side of the studio under <strong class="bold">Assets</strong>. </li>
				<li>Then, click <strong class="bold">Create dataset</strong> and select <strong class="bold">From local files</strong> from the drop-down menu as seen in <em class="italic">Figure 3.1</em>:<div id="_idContainer028" class="IMG---Figure"><img src="image/B16595_03_001.jpg" alt="Figure 3.1 – Creating a dataset from a local file"/></div><p class="figure-caption">Figure 3.1 – Creating a dataset from a local file</p></li>
				<li>Before loading in the Titanic data, you have to name your dataset. Write <strong class="source-inline">Titanic Training Data</strong> in the <strong class="bold">Dataset Name</strong> textbox. Unlike a lot of other Azure resources, you can include spaces in your dataset's name. </li>
				<li>Since <a id="_idIndexMarker116"/>the Titanic data contains columns <a id="_idIndexMarker117"/>and rows, select <strong class="bold">Tabular</strong> from <a id="_idIndexMarker118"/>the <strong class="bold">Dataset type</strong> drop-down box. Under <strong class="bold">Dataset description</strong>, write <strong class="source-inline">Titanic data containing passenger demographic information and ticket information. We will use this data to model who survived the Titanic voyage</strong>.<p>Generally speaking, it's a good idea to include the project name and use in the dataset name, for example, <em class="italic">Titanic Training Data</em> or <em class="italic">Titanic Scoring Data</em>. In the description field, it's best practice to list the type of information found in the data, as well as which problem you are trying to solve. Please see <em class="italic">Figure 3.2</em> for reference. </p></li>
				<li>Click <strong class="bold">Next</strong> at the bottom of the screen:<div id="_idContainer029" class="IMG---Figure"><img src="image/B16595_03_002.jpg" alt="Figure 3.2 – Naming and describing your dataset "/></div><p class="figure-caption">Figure 3.2 – Naming and describing your dataset</p></li>
				<li>Now, you <a id="_idIndexMarker119"/>will load your Titanic data onto your default datastore. Your default <a id="_idIndexMarker120"/>datastore points to the storage <a id="_idIndexMarker121"/>account that was created with your Azure Machine Learning workspace. Select your default datastore by clicking the appropriate circle, as shown in <em class="italic">Figure 3.3</em>. </li>
				<li>Click <strong class="bold">Browse</strong>, navigate to <strong class="source-inline">titanic.csv</strong> on your local machine, and then click <strong class="bold">Open</strong>. Notice that it will tell you the size of your file after it's loaded into Azure.</li>
				<li>With your datastore and file selected, you can also determine the path on your datastore in which to save your file. In the empty field labeled <strong class="bold">Upload path</strong>, type in <strong class="source-inline">/titanic/train</strong>. This will create a directory structure with a folder called <strong class="source-inline">titanic</strong>, a subfolder <a id="_idIndexMarker122"/>called <strong class="source-inline">train</strong>, and another <a id="_idIndexMarker123"/>folder with the current date and <a id="_idIndexMarker124"/>time in UTC format. You can also use existing folders on your datastore. Please see <em class="italic">Figure 3.3</em> for reference. </li>
				<li>Click <strong class="bold">Next</strong> at the bottom of the screen to advance:<div id="_idContainer030" class="IMG---Figure"><img src="image/B16595_03_003.jpg" alt="Figure 3.3 – Uploading Titanic data to your datastore  "/></div><p class="figure-caption">Figure 3.3 – Uploading Titanic data to your datastore </p></li>
				<li>With <a id="_idIndexMarker125"/>your <a id="_idIndexMarker126"/>data <a id="_idIndexMarker127"/>loaded onto your datastore, it's now time to set up your dataset so that the file enters your Azure Machine Learning workspace correctly. Here, there are five options: <p>a) From <strong class="bold">File format</strong>, you can select delimited files, Parquet files, text files, or JSON files. Select <strong class="bold">Delimited</strong> from the dropdown. </p><p>b) Then, choose the appropriate option under <strong class="bold">Delimiter</strong>. Since this is a CSV, a comma-separated values file, choose <strong class="bold">comma</strong> from the dropdown. Notice that every time you make a change, AMLS will generate a new preview of your data at the bottom of your screen.</p><p>c) You will <a id="_idIndexMarker128"/>rarely have to change <strong class="bold">Encoding</strong>, and <a id="_idIndexMarker129"/>it's generally best <a id="_idIndexMarker130"/>to leave it at the default setting, in this case, <strong class="bold">UTF-8</strong>. </p><p>d) <strong class="bold">Column headers</strong>, on the other hand, you will always want to specify. AMLS defaults to <strong class="bold">No headers</strong>, but most files you use will have them. Select <strong class="bold">Use headers from the first file</strong> to import your appropriate column headers. </p><p>e) <strong class="bold">Skip rows</strong> is a useful option when you import data with extraneous rows at the top or bottom of your file. While the Titanic data lacks these extra rows, often you will find that data contains a name, date, or organizational information on the very bottom row. </p><p>It is important to remove these extra rows or this will result in errors when you try to build a machine learning model. Please see <em class="italic">Figure 3.4</em> for an example of how your settings should look.</p></li>
				<li>Click <strong class="bold">Next</strong> to select only the appropriate columns for your dataset:<div id="_idContainer031" class="IMG---Figure"><img src="image/B16595_03_004.jpg" alt="Figure 3.4 – Choosing the correct settings for your file "/></div><p class="figure-caption">Figure 3.4 – Choosing the correct settings for your file</p></li>
				<li>There <a id="_idIndexMarker131"/>are certain columns that are inappropriate for machine learning. While AutoML will automatically <a id="_idIndexMarker132"/>remove most of them <a id="_idIndexMarker133"/>for you, it's best practice to remove them yourself. In no order of importance, the types of columns to remove are as follows:<ul><li>Columns that contain a unique value in each row, such as <em class="italic">Name</em>, <em class="italic">ID</em>, and <em class="italic">Ticket</em></li>
<li>Columns with an excessive number of null values, such as <em class="italic">Cabin</em></li>
<li>Columns that do not contain useful information</li>
<li>Columns that are derivations of your target column</li>
</ul></li>
				<li>To remove these columns from your dataset, all you need to do is move the slider to the left, as shown in <em class="italic">Figure 3.5</em>. Remove <strong class="bold">PassengerId</strong>, <strong class="bold">Name</strong>, <strong class="bold">Ticket</strong>, and <strong class="bold">Cabin</strong>: <p class="callout-heading">Note</p><p class="callout">When you remove a column from your dataset, the file on the datastore is not altered. You can thereby make multiple datasets from the same file point to different columns.</p><div id="_idContainer032" class="IMG---Figure"><img src="image/B16595_03_005.jpg" alt="Figure 3.5 – Selecting your columns "/></div><p class="figure-caption">Figure 3.5 – Selecting your columns</p></li>
				<li>From <a id="_idIndexMarker134"/>this menu, you can also specify the <a id="_idIndexMarker135"/>type of each column. There are five types: <strong class="bold">String</strong>, <strong class="bold">Boolean</strong>, <strong class="bold">Integer</strong>, <strong class="bold">Decimal</strong>, and <strong class="bold">Date</strong>. Booleans are for <a id="_idIndexMarker136"/>columns that have two possible values, such as 0 or 1. Change <strong class="bold">Survived</strong> to <strong class="bold">Boolean</strong>, and change <strong class="bold">Age</strong> to <strong class="bold">Integer</strong>.</li>
				<li>Click <strong class="bold">Next</strong>.</li>
				<li>You are now presented with a confirmation screen. From this screen, you can see the name you assigned to your dataset and its description, the datastore, and the path in the datastore on which the base file is located, along with the file settings. Profiling the data is also possible from this screen, as shown in <em class="italic">Figure 3.6</em>. <p>If you choose to profile your data, you will need to select a compute cluster. This <a id="_idIndexMarker137"/>option will <a id="_idIndexMarker138"/>give you summary statistics <a id="_idIndexMarker139"/>for each column, including the mean, min, max, standard deviation, number of missing values, number of errors, and number of unique values. Turn profiling on or off, and then click <strong class="bold">Next</strong> to create your dataset:</p></li>
			</ol>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B16595_03_006.jpg" alt="Figure 3.6 – Confirming your dataset details "/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.6 – Confirming your dataset details</p>
			<p>You <a id="_idIndexMarker140"/>have <a id="_idIndexMarker141"/>now created a dataset that you can use within AMLS. With it, you will build <a id="_idIndexMarker142"/>
a machine learning model that predicts which passengers survived and which passengers perished. The next step is to train a machine learning model using the AutoML guided user interface. </p>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor047"/>Creating an AutoML solution</h1>
			<p>Now that <a id="_idIndexMarker143"/>you have loaded Titanic data into your datastore and registered it as a dataset, you are ready to train an AutoML model with a few guided clicks:</p>
			<ol>
				<li value="1">To get started, click <strong class="bold">Automated ML</strong> from the left-hand menu under <strong class="bold">Author</strong>. Then, click <strong class="bold">New Automated ML run</strong>, marked by a blue cross, near the top left of the new page, as shown in <em class="italic">Figure 3.7</em>:<div id="_idContainer034" class="IMG---Figure"><img src="image/B16595_03_007.jpg" alt="Figure 3.7 – Beginning your AutoML training run "/></div><p class="figure-caption">Figure 3.7 – Beginning your AutoML training run</p></li>
				<li>Once you have advanced to the next screen, you will be presented with all of your eligible datasets for training. Currently, only tabular datasets are supported for runs from the AutoML GUI. You can also create a new dataset from this view by clicking the <strong class="bold">Create dataset</strong> button. Select <strong class="bold">Titanic Training Data</strong>, as shown in <em class="italic">Figure 3.8</em>.</li>
				<li>Click <strong class="bold">Next</strong>:<div id="_idContainer035" class="IMG---Figure"><img src="image/B16595_03_008.jpg" alt="Figure 3.8 – Selecting your dataset for training "/></div><p class="figure-caption">Figure 3.8 – Selecting your dataset for training</p><p>After selecting your dataset, the next steps involve naming your experiment, selecting <a id="_idIndexMarker144"/>a column to predict, and selecting a compute cluster for remote training. Remember that <strong class="bold">Experiments</strong> records all the information related to your training run. </p></li>
				<li>To create a new experiment, select <strong class="bold">Create new</strong> and assign it the name <strong class="source-inline">Titanic-Training</strong>. You are not allowed to have spaces in your experiment names; the only special characters allowed are dashes or underscores.</li>
				<li>Next, select your <strong class="bold">Target Column</strong> from the drop-down menu. Your target column is the number or class you are trying to predict with your machine learning model. In this case, select <strong class="bold">Survived</strong>. </li>
				<li>Likewise, select a compute cluster on which AutoML will create machine learning models. Select any compute cluster you have created from the drop-down menu. AutoML will run on this compute remotely, allowing you to continue to do other work on your AMLS workspace. </li>
				<li>Please confirm your settings using <em class="italic">Figure 3.9</em> for reference and click <strong class="bold">Next</strong> to advance to the final screen:<p class="callout-heading">Important tip</p><p class="callout">It's important to select the right size and type of compute when training an automated machine learning model. The RAM on your compute cluster should be about 20 times as large as your dataset to be on the safe side. Use GPUs when using deep learning algorithms and use CPUs for everything else. You can train AutoML models on data of up to 10 gigabytes before you should switch to a Spark-based solution.</p><div id="_idContainer036" class="IMG---Figure"><img src="image/B16595_03_009.jpg" alt="Figure 3.9 – Configuring your AutoML run "/></div><p class="figure-caption">Figure 3.9 – Configuring your AutoML run</p><p>You are <a id="_idIndexMarker145"/>only a few clicks away from creating your AutoML model. There are three options in the next menu: <strong class="bold">Classification</strong>, <strong class="bold">Forecasting</strong>, and <strong class="bold">Regression</strong>. <strong class="bold">Classification</strong> is for when you are trying to predict a category, such as whether a person is likely to default on a loan or pay it back. <strong class="bold">Regression</strong> is for when you're trying to predict a number instead of a class, for example, trying to predict the price of a house-based feature such as its size. <strong class="bold">Forecasting</strong>, on the other hand, is for when you're trying to predict a number in the future.</p></li>
				<li>Since we are trying to predict whether or not a person survived the Titanic disaster, select <strong class="bold">Classification</strong>. A green checkmark will appear next to the box on the right-hand side, as seen in <em class="italic">Figure 3.10</em>:<div id="_idContainer037" class="IMG---Figure"><img src="image/B16595_03_010.jpg" alt="Figure 3.10 – Selecting the right task type"/></div><p class="figure-caption">Figure 3.10 – Selecting the right task type</p><p>There are <a id="_idIndexMarker146"/>two additional sets of settings you can configure – <strong class="bold">additional configuration settings</strong> and <strong class="bold">featurization settings</strong>. <strong class="bold">Additional configuration settings</strong> lets you change which metrics AutoML will use to score algorithms, enables you to block AutoML from trying certain algorithms, and lets you set the overall time when AutoML runs. </p><p><strong class="bold">Featurization settings</strong> lets you deselect columns, set column types, and decide how AutoML deals with nulls for each column. More advanced data scientists are able to utilize these features for finer-grained control over how AutoML deals with missing values and how AutoML featurizes your dataset.</p></li>
				<li>Navigate to <strong class="bold">View additional configuration settings</strong>. </li>
				<li>Click <strong class="bold">Exit criterion</strong> and set the training time to 15 minutes. Note that because training time is measured in hours, you need to set it to <strong class="source-inline">0.25</strong>, as shown in <em class="italic">Figure 3.11</em>. If you <a id="_idIndexMarker147"/>accidentally set it to 15, your job will run for 15 hours before terminating:<p class="callout-heading">Important tip</p><p class="callout">For now, stick to the default metric and default validation mechanism, <strong class="bold">Accuracy</strong> and <strong class="bold">Auto</strong>, respectively. In later chapters, we will do a deeper dive into the various metrics and validation mechanisms supported by AutoML on Azure.</p><div id="_idContainer038" class="IMG---Figure"><img src="image/B16595_03_011.jpg" alt="Figure 3.11 – Setting your training job time "/></div><p class="figure-caption">Figure 3.11 – Setting your training job time</p></li>
				<li>Click <strong class="bold">Save</strong> and <strong class="bold">Finish</strong> and find something to do for the next 15 minutes. </li>
			</ol>
			<p>You have launched your first AutoML model, and soon you will have the results.</p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor048"/>Interpreting your AutoML results</h1>
			<p>Your training run should have taken about 15 minutes and produced a model with around 80% accuracy. However, there is much more to your results than this simple metric. There <a id="_idIndexMarker148"/>are data guardrails that will inform you of any problems with your data. There is also a slew of different metrics for each of the three problem types and accompanying charts and graphs that can assist you in presenting your results to the business: </p>
			<ol>
				<li value="1">To begin, click <strong class="bold">Automated ML</strong> from the left-hand menu of AMLS and click the latest run from your <strong class="source-inline">Titanic-Training</strong> experiment, as seen in <em class="italic">Figure 3.12</em>:<div id="_idContainer039" class="IMG---Figure"><img src="image/B16595_03_012.jpg" alt="Figure 3.12 – Examining your results "/></div><p class="figure-caption">Figure 3.12 – Examining your results</p><p>You will be taken to a screen with a variety of metrics regarding your model, including the type of algorithm used to train the best-performing model, its accuracy score, the date and time it was created, and how long your AutoML run took to execute. Take advantage of the <strong class="bold">Description</strong> area in the bottom-right corner of your screen to write details about your run. </p></li>
				<li>Click the pen icon and write <strong class="source-inline">My first AutoML model</strong>. <p>You'll notice <a id="_idIndexMarker149"/>that there are six tabs at the top of the screen: <strong class="bold">Details</strong>, <strong class="bold">Data</strong><em class="italic"> </em><strong class="bold">guardrails</strong>, <strong class="bold">Models</strong>, <strong class="bold">Outputs + Logs</strong>, <strong class="bold">Child runs</strong>, and <strong class="bold">Snapshot</strong>. For the purpose of interpreting results, only <strong class="bold">Data guardrails</strong> and <strong class="bold">Models</strong> are important. </p></li>
				<li>Click on the <strong class="bold">Data guardrails</strong> tab and read the results.</li>
			</ol>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/>Understanding data guardrails</h2>
			<p><strong class="bold">Data guardrails</strong> identify and <a id="_idIndexMarker150"/>correct any problems you have in your dataset, and it's essential to know what those problems are. There are different guardrails depending on whether you are trying to solve a classification, regression, or forecasting problem. Classification problems use the following:</p>
			<ul>
				<li><strong class="bold">Validation split handling</strong>: This guardrail looks at your dataset size and unique values within <a id="_idIndexMarker151"/>your columns to determine how your machine learning model should be trained and validated. For this Titanic dataset, it will choose 10-fold cross validation. Cross validation splits your data 10 ways, trains a model based on 9 of the parts, and scores the data on the remaining part. This process is repeated 10 times and the scores are averaged. </li>
				<li><strong class="bold">Class balancing detection</strong>: This guardrail looks at your target column to determine <a id="_idIndexMarker152"/>whether there are enough samples of each of the unique values. With the Titanic data, this guardrail will pass, as there are sufficient numbers of people who survived and sufficient numbers of people who perished to build a valid model. </li>
				<li><strong class="bold">Missing features values imputation</strong>: This guardrail will scan your data for null values, count <a id="_idIndexMarker153"/>them, and fill them automatically. With the Titanic data, you will find that there are 202 null values for the <strong class="source-inline">Age</strong> column, and they are filled with the mean of that column. There are also two null values for the <strong class="source-inline">Embarked</strong> column, and they are filled with <strong class="source-inline">--</strong>, the most common value for the column.</li>
				<li><strong class="bold">High-cardinality feature detection</strong>: This guardrail will look at your categorical columns <a id="_idIndexMarker154"/>and see whether any have too many unique values, in which case they will be binned. With the Titanic data, this guardrail is passed and the data is left unaltered.</li>
			</ul>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor050"/>Understanding model metrics</h2>
			<p>After exploring <a id="_idIndexMarker155"/>data guardrails, the next step involves interpreting your model: </p>
			<ol>
				<li value="1">Click <strong class="bold">Models</strong> next to the <strong class="bold">Data guardrails</strong> tab. On this tab, you will see a list of AutoML-generated models ranked in order of accuracy, with the highest-scoring model on the top. </li>
				<li>Click your highest-scoring model's name, as shown in <em class="italic">Figure 3.13</em>: <div id="_idContainer040" class="IMG---Figure"><img src="image/B16595_03_013.jpg" alt="Figure 3.13 – Navigating to your model "/></div><p class="figure-caption">Figure 3.13 – Navigating to your model</p><p>This will take you to a similar screen with a new set of tabs at the top. <strong class="bold">Metrics</strong>, the fourth tab at the top, contains not only accuracy, but all of the additional metrics and graphs associated with a classification problem. You can check and deselect any you wish. There are over 20 checkboxes, but, for the purpose of this exercise, we will check three.</p></li>
				<li>Check the <strong class="bold">accuracy</strong>, <strong class="bold">confusion_matrix</strong>, and <strong class="bold">matthews_correlation</strong> boxes.</li>
			</ol>
			<p><strong class="bold">Accuracy</strong> is a simple <a id="_idIndexMarker156"/>metric that is easy to understand, and it is what your AutoML run used to build and determine your best model. It is simply how likely your model is to be correct when making a prediction. In my case, it's 83.84%. Unlike a determinant system, machine learning models won't score exactly the same, but your best model should score similarly.</p>
			<p><strong class="bold">The Matthews correlation coefficient</strong> is a much more sophisticated metric that takes into account <a id="_idIndexMarker157"/>unbalanced classes. It's a combination of true positive, false positive, true negative, and false negative rates and ranges between -1 and 1. </p>
			<p>A score of 1 means <a id="_idIndexMarker158"/>that your model predicts perfectly, while a score of 0 means that your model is guessing randomly. A score of -1 would mean your model is perfectly wrong every time. My score was .6541, much lower than my accuracy score, as seen in <em class="italic">Figure 3.14</em>. Your model should score similarly. This indicates that your model is probably much worse at identifying one of the two classes. As you will see next, your confusion matrix confirms this:</p>
			<div>
				<div id="_idContainer041" class="IMG---Figure">
					<img src="image/B16595_03_014.jpg" alt="Figure 3.14 – Accuracy and Matthews correlation "/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.14 – Accuracy and Matthews correlation</p>
			<p><strong class="bold">Confusion matrices</strong> are visual <a id="_idIndexMarker159"/>representations of your classification output, focusing on true and false positives and negatives. While your accuracy was high, your Matthews correlation coefficient was low, and the confusion matrix is your perfect tool to investigate this relationship. Please see <em class="italic">Figure 3.15</em>:</p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B16595_03_015.jpg" alt="Figure 3.15 – Confusion matrix "/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.15 – Confusion matrix</p>
			<p>What this <a id="_idIndexMarker160"/>output says is that my model has correctly identified 509 cases where people died on the Titanic and 238 cases where people lived. However, the model misidentified 40 people who perished as survivors and 104 people who died as having survived. <em class="italic">Figure 3.16</em> shows the relative percentages by selecting <strong class="bold">Normalized</strong> from the drop-down box: </p>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="image/B16595_03_016.jpg" alt="Figure 3.16 – Normalized confusion matrix "/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.16 – Normalized confusion matrix</p>
			<p>Here, we can see that the true negative rate, people who died who were correctly classified as having died, is 92.71%. The false negative rate, people who survived but were incorrectly classified, is only 7.29%. These scores are really high. However, the true positive rate, the ability of the model to predict who survives correctly, is only 69.59%. Likewise, the false <a id="_idIndexMarker161"/>positive rate is 30.41%. What we have is a model that is much better at predicting victims of the disaster than predicting survivors.</p>
			<p>There are many other useful metrics and graphs contained under the <strong class="bold">Metrics</strong> tab. Try checking a few of the boxes and researching what they mean. You can also download any of the graphs directly to your computer from the next tab on your right, <strong class="bold">Outputs + logs</strong>. One set of useful information you will not find under the <strong class="bold">Metrics</strong> tab relates to what features were used to create your model. This data can be found under the <strong class="bold">Explanations</strong> tab, currently in preview.</p>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor051"/>Explaining your AutoML model</h1>
			<p>Knowing your results is important, but knowing how your model derived its results is just as integral <a id="_idIndexMarker162"/>to working with machine learning. Here is where model explainability plays a key role. <strong class="bold">Explainability</strong> is the ability to say which features are <a id="_idIndexMarker163"/>most important in building your AutoML model. This is especially important in industries where you have to be able to legally explain your machine learning models, for example, if you built a model to determine who is approved for a loan: </p>
			<ol>
				<li value="1">To begin, click the Explanations tab next to Metrics.</li>
				<li>Click the first ID under Explanation ID on the right-hand side of the screen.</li>
				<li>Click the slider button next to View previous dashboard experience.</li>
				<li>Click Global Importance.<p>Immediately, you will see your columns ranked in order of importance. <strong class="source-inline">Sex</strong> is the most important column, followed by <strong class="source-inline">Pclass</strong> and <strong class="source-inline">Age</strong>, as shown in Figure 3.17. With an importance value of <strong class="source-inline">1.1</strong>, Sex is roughly twice as important as Pclass, with a score of <strong class="source-inline">0.59</strong>. All values are relative to each other. From this chart, you can say that gender was the most important feature used in creating your model.</p><div id="_idContainer044" class="IMG---Figure"><img src="image/B16595_03_017.jpg" alt="Figure 3.17 – Explainability "/></div><p class="figure-caption">Figure 3.17 – Explainability</p><p>Now that <a id="_idIndexMarker164"/>you can explain your entire model, it's just as important to be able to explain individual points. </p></li>
				<li>To achieve this, click <strong class="bold">Summary Importance</strong> and select any individual data point. <p>A chart will appear below showing which features negatively or positively affected the model to predict whether the individual survived or perished. <em class="italic">Figure 3.18</em> shows the profile for a male with a first class ticket. Note that his sex negatively affects his predicted survival, while his class influences the pre<a id="_idTextAnchor052"/>diction in a positive direction:</p></li>
			</ol>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="image/B16595_03_018.jpg" alt="Figure 3.18 – Explainability for a male with a first-class ticket "/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.18 – Explainability for a male with a first-class ticket</p>
			<p><strong class="bold">Explainability</strong> can be accessed via both this dashboard interface and programmatically through Python, as we <a id="_idIndexMarker165"/>will see in later chapters. With Python, you're able to store this information in a database for safe keeping and easy retrieval. That way, you will be able to explain all of your machine learning predictions and defend any legal challenges that may arise.</p>
			<p>Having built and understood an AutoML model, you are now ready to build many more. In order to do so more efficiently, there are many small tweaks you can make to improve performance.</p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor053"/>Obtaining better AutoML performance</h1>
			<p>Congratulations! You have built your first model and it performs very well. However, there are <a id="_idIndexMarker166"/>a lot of little things you can do to improve performance. You will build many more models in the future, after all, and in order to build the best models, you need to know all of the tips and tricks. Here's a list of tips and tricks to end this chapter:</p>
			<ul>
				<li>Additional <strong class="bold">feature engineering</strong> will often provide superior results. Feature engineering just means transforming data in ways that make it easier for machine learning algorithms to find patterns. Binning ticket prices and age into buckets in the Titanic data, for example, may provide you with superior results compared to just using prices and age as numeric columns.</li>
				<li>Speaking of binning, you can always bin a regression problem to turn it into a classification problem. If you're trying to predict the average lifespan of a human being, for example, you can try to predict a range of numbers instead of a straight number, such as <em class="italic">60-65 years, </em>instead of an exact number. This is a useful tactic to employ when AutoML isn't returning great results. Classification problems are easier to solve than regression problems given the same dataset, and you can often achieve similar value for your business problem.</li>
				<li>Enabling deep learning will often provide superior results with AutoML, but it comes at the cost of using significantly more compute power and time. Deep learning algorithms create complex neural networks to make predictions and are especially useful for AutoML when you have text data as an input feature. Instead of using a CPU-based compute cluster, use a GPU-based compute cluster for necessary power and performance.</li>
				<li>Forecasting in AutoML requires a carefully constructed dataset and a keen understanding of the forecasting-specific settings. Read <a href="B16595_06_ePub.xhtml#_idTextAnchor081"><em class="italic">Chapter 6</em></a>, <em class="italic">Building an AutoML Forecasting Solution</em>, carefully before creating a forecasting solution with AutoML. </li>
				<li>Letting your AutoML job run for longer periods of time will usually mean better results, but only up to a certain point. Try letting it run for a certain amount of time and pay attention to see whether the algorithms are returning better results.</li>
				<li>AutoML intelligently tunes parameters of its algorithms to try to achieve a higher score. If you notice that it keeps trying the same algorithm over and over again, keep in mind that this is expected behavior and that it's trying to find the best combination of parameters for that algorithm.</li>
				<li>It's very likely that a voting or stack ensemble will be your best model, although it's harder <a id="_idIndexMarker167"/>to explain to people how these models work. If you have end users that need to know the math behind your models, you can <strong class="bold">blacklist</strong> ensemble models for your run. While you cannot presently do this through the AutoML GUI, it is possible to do this via code. Please refer to <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, for more details on blacklisting ensemble models. </li>
				<li>Running AutoML on compute clusters composed of small VM sizes is cheap. Feel free to experiment liberally while using low-RAM virtual machines.</li>
			</ul>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor054"/>Summary</h1>
			<p>This ends Part 1 of <em class="italic">Automated Machine Learning with Microsoft Azure</em>, and you have accomplished a lot! You learned how to load in files from your local machine to your datastore and register it as a dataset. You have created your first AutoML model. You are able to not only interpret the results of your model with graphs and metrics but also explain how your model makes predictions. Lastly, you learned various tips and tricks that will allow you to fine-tune your models. You have made the first step on your journey toward mastering AutoML on Azure. </p>
			<p>The next part of your journey will involve a lot of Python coding. In <a href="B16595_04_ePub.xhtml#_idTextAnchor056"><em class="italic">Chapter 4</em></a>, <em class="italic">Building an AutoML Regression Solution</em>, you will build a regression model using the <strong class="bold">AzureML Python Software Development Kit</strong> (<strong class="bold">AzureML SDK</strong>). This SDK is a collection of commands that will allow a Python notebook to interact with your Azure workspace. You will learn how to write AutoML scripts in Python, and you will use those scripts to create powerful solutions for predicting numbers.</p>
		</div>
</body></html>