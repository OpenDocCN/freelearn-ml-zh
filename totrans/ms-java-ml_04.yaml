- en: Chapter 4. Semi-Supervised and Active Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.html "Chapter 2. Practical Approach to Real-World Supervised
    Learning"), *Practical Approach to Real-World Supervised Learning* and [Chapter
    3](ch03.html "Chapter 3. Unsupervised Machine Learning Techniques"), *Unsupervised
    Machine Learning Techniques*, we discussed two major groups of machine learning
    techniques which apply to opposite situations when it comes to the availability
    of labeled data—one where all target values are known and the other where none
    are. In contrast, the techniques in this chapter address the situation when we
    must analyze and learn from data that is a mix of a small portion with labels
    and a large number of unlabeled instances.
  prefs: []
  type: TYPE_NORMAL
- en: In speech and image recognition, a vast quantity of data is available, and in
    various forms. However, the cost of labeling or classifying all that data is costly
    and therefore, in practice, the proportion of speech or images that are classified
    to those that are not classified is very small. Similarly, in web text or document
    classification, there are an enormous number of documents on the World Wide Web
    but classifying them based on either topics or contexts requires domain experts—this
    makes the process complex and expensive. In this chapter, we will discuss two
    broad topics that cover the area of "learning from unlabeled data", namely **Semi-Supervised
    Learning** (**SSL**) and Active Learning. We will introduce each of the topics
    and discuss the taxonomy and algorithms associated with each as we did in previous
    chapters. Since the book emphasizes the practical approach, we will discuss tools
    and libraries available for each type of learning. We will then consider real-world
    case studies and demonstrate the techniques that are useful when applying the
    tools in practical situations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the list of topics that are covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Semi-Supervised Learning:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Representation, notation, and assumptions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Semi-Supervised Learning techniques:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-training SSL
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Co-training SSL
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster and label SSL
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Transductive graph label propagation
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Transductive SVM
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Case study in Semi-Supervised Learning
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Active Learning:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Representation and notation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Active Learning scenarios
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Active Learning approaches:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Uncertainty sampling
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Least confident sampling
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Smallest margin sampling
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Label entropy sampling
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Version space sampling:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Query by disagreement
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Query by committee
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data distribution sampling:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Expected model change
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Expected error reduction
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Variance reduction
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Density weighted methods
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Case study in Active Learning
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The idea behind semi-supervised learning is to learn from labeled and unlabeled
    data to improve the predictive power of the models. The notion is explained with
    a simple illustration, *Figure 1*, which shows that when a large amount of unlabeled
    data is available, for example, HTML documents on the web, the expert can classify
    a few of them into known categories such as sports, news, entertainment, and so
    on. This small set of labeled data together with the large unlabeled dataset can
    then be used by semi-supervised learning techniques to learn models. Thus, using
    the knowledge of both labeled and unlabeled data, the model can classify unseen
    documents in the future. In contrast, supervised learning uses labeled data only:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Semi-supervised learning](img/B05137_04_003.jpg)![Semi-supervised learning](img/B05137_04_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. Semi-Supervised Learning process (bottom) contrasted with Supervised
    Learning (top) using classification of web documents as an example. The main difference
    is the amount of labeled data available for learning, highlighted by the qualifier
    "small" in the semi-supervised case.
  prefs: []
  type: TYPE_NORMAL
- en: Representation, notation, and assumptions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As before, we will introduce the notation we use in this chapter. The dataset
    *D* consists of individual data instances represented as **x**, which is also
    represented as a set {**x**[1], **x**[2],…**x**[n]}, the set of data instances
    without labels. The labels associated with these data instances are {*y*[1], *y*[2],
    … *y*[n]}. The entire labeled dataset can be represented as paired elements in
    a set, as given by *D* = {(**x**[1], *y*[1]), (**x**2,*y*[2]), … (**x**[n], *y*[n])}
    where **x**[i] ∈ ℝ^d. In semi-supervised learning, we divide the dataset *D* further
    into two sets *U* and *L* for unlabeled and labeled data respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The labeled data ![Representation, notation, and assumptions](img/B05137_04_015.jpg)
    consists of all labeled data with known outcomes {y[1], y[2], .. y[l]}. The unlabeled
    data ![Representation, notation, and assumptions](img/B05137_04_017.jpg) is the
    dataset where the outcomes are not known. |*U*| > |*L*| .
  prefs: []
  type: TYPE_NORMAL
- en: Inductive semi-supervised learning consists of a set of techniques, which, given
    the training set *D* with labeled data ![Representation, notation, and assumptions](img/B05137_04_015.jpg)
    and unlabeled data ![Representation, notation, and assumptions](img/B05137_04_017.jpg),
    learns a model represented as ![Representation, notation, and assumptions](img/B05137_04_021.jpg)
    so that the model *f* can be a good predictor on unseen data beyond the training
    unlabeled data *U*. It "induces" a model that can be used just like supervised
    learning algorithms to predict on unseen instances.
  prefs: []
  type: TYPE_NORMAL
- en: Transductive semi-supervised learning consists of a set of techniques, which,
    given the training set *D*, learns a model ![Representation, notation, and assumptions](img/B05137_04_024.jpg)
    that makes predictions on unlabeled data alone. It is not required to perform
    on unseen future instances and hence is a simpler form of SSL than inductive based
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the assumptions made in the semi-supervised learning algorithms that
    should hold true for these types of learning to be successful are noted in the
    following list. For SSL to work, one or more of these assumptions must be true:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Semi-supervised smoothness**: In simple terms, if two points are "close"
    in terms of density or distance, then their labels agree. Conversely, if two points
    are separated and in different density regions, then their labels need not agree.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cluster togetherness**: If the data instances of classes tend to form a cluster,
    then the unlabeled data can aid the clustering algorithm to find better clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manifold togetherness**: In many real-world datasets, the high-dimensional
    data lies in a low-dimensional manifold, enabling learning algorithms to overcome
    the curse of dimensionality. If this is true in the given dataset, the unlabeled
    data also maps to the manifold and can improve the learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semi-supervised learning techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will describe different SSL techniques, and some accompanying
    algorithms. We will use the same structure as in previous chapters and describe
    each method in three subsections: *Inputs and outputs*, *How does it work?*, and
    *Advantages and limitations*.'
  prefs: []
  type: TYPE_NORMAL
- en: Self-training SSL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Self-training is the simplest form of SSL, where we perform a simple iterative
    process of imputing the data from the unlabeled set by applying the model learned
    from the labeled set (*References* [1]):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Self-training SSL](img/B05137_04_025.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. Self-training SSL in binary classification with some labeled data
    shown with blue rectangles and yellow circles. After various iterations, the unlabeled
    data gets mapped to the respective classes.
  prefs: []
  type: TYPE_NORMAL
- en: Inputs and outputs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The input is training data with a small amount of labeled and a large amount
    of unlabeled data. A base classifier, either linear or non-linear, such as Naïve
    Bayes, KNN, Decision Tree, or other, is provided along with the hyper-parameters
    needed for each of the algorithms. The constraints on data types will be similar
    to the base learner. Stopping conditions such as *maximum iterations reached*
    or *unlabeled data exhausted* are choices that must be made as well. Often, we
    use base learners which give probabilities or ranks to the outputs. As output,
    this technique generates models that can be used for performing predictions on
    unseen datasets other than the unlabeled data provided.
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The entire algorithm can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'While stopping criteria not reached:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the classifier model ![How does it work?](img/B05137_04_021.jpg) with
    labeled data *L*
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the classifier model *f* on unlabeled data *U*
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose *k* most confident predictions from *U* as set *L*[u]
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Augment the labeled data with the k data points *L = L* *∪* *L*[u]
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat all the steps under 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the abstract, self-training can be seen as an expectation maximization process
    applied to a semi-supervised setting. The process of training the classifier model
    is finding the parameter θ using MLE or MAP. Computing the labels using the learned
    model is similar to the *EXPECTATION* step where ![How does it work?](img/B05137_04_031.jpg)
    is estimating the label from *U* given the parameter θ. The iterative next step
    of learning the model with augmented labels is akin to the *MAXIMIZATION* step
    where the new parameter is tuned to *θ'*.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The advantages and limitations are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple, works with most supervised learning techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outliers and noise can cause mistakes in predictions to be reinforced and the
    technique to degrade.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Co-training SSL or multi-view SSL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Co-training based SSL involves learning from two different "views" of the same
    data. It is a special case of multi-view SS (References [2]). Each view can be
    considered as a feature set of the point capturing some domain knowledge and is
    orthogonal to the other view. For example, a web documents dataset can be considered
    to have two views: one view is features representing the text and the other view
    is features representing hyperlinks to other documents. The assumption is that
    there is enough data for each view and learning from each view improves the overall
    labeling process. In datasets where such partitions of features are not possible,
    splitting features randomly into disjoint sets forms the views.'
  prefs: []
  type: TYPE_NORMAL
- en: Inputs and outputs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Input is training data with a few labeled and a large number of unlabeled data.
    In addition to providing the data points, there are feature sets corresponding
    to each view and the assumption is that these feature sets are not overlapping
    and solve different classification problems. A base classifier, linear or non-linear,
    such as Naïve Bayes, KNN, Decision Tree, or any other, is selected along with
    the hyper-parameters needed for each of the algorithms. As output, this method
    generates models that can be used for performing predictions on unseen datasets
    other than the unlabeled data provided.
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We will demonstrate the algorithm using two views of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the data as ![How does it work?](img/B05137_04_015.jpg) labeled and
    ![How does it work?](img/B05137_04_017.jpg) unlabeled. Each data point has two
    views **x = [x****¹****,x****²****]** and *L = [L**¹**,L**2**]*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'While stopping criteria not reached:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the classifier models ![How does it work?](img/B05137_04_035.jpg) and
    ![How does it work?](img/B05137_04_036.jpg) with labeled data *L*1 and *L*2 respectively.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the classifier models *f*¹ and *f*² on unlabeled data *U* using their
    own features.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose *k* the most confident predictions from *U*, applying *f*¹ and *f*² as
    set *L*[u]¹ and *L*[u]² respectively.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Augment the labeled data with the *k* data points *L*¹ = *L*¹ ∪ *L*[u]¹ and
    *L*² = *L*² ∪ *L*[u]²
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat all the steps under 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Advantages and limitations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The advantages and limitations are:'
  prefs: []
  type: TYPE_NORMAL
- en: When the features have different aspects or a mix of different domains, co-training
    becomes more beneficial than simple self-training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The necessary and sufficient condition of having orthogonal views and ability
    to learn from them poses challenges for the generality of the technique
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster and label SSL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This technique, like self-training, is quiet generic and applicable to domains
    and datasets where the clustering supposition mentioned in the assumptions section
    holds true (References [3]).
  prefs: []
  type: TYPE_NORMAL
- en: Inputs and outputs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Input is training data with a few labeled and a large number of unlabeled instances.
    A clustering algorithm and its parameters along with a classification algorithm
    with its parameters constitute additional inputs. The technique generates a classification
    model that can help predict the classes of unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The abstract algorithm can be given as:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize data as ![How does it work?](img/B05137_04_015.jpg) labeled and ![How
    does it work?](img/B05137_04_017.jpg) unlabeled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cluster the entire data, both labeled and unlabeled using the clustering algorithm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each cluster let *S* be the set of labeled instances drawn from set *L*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Learn a supervised model from *S*, *f*[s] = *L*[s].
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the model *f*[s] and classify unlabeled instances for each cluster using
    the preceding model.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Since all the unlabeled instances ![How does it work?](img/B05137_04_017.jpg)
    get assigned a label by the preceding process, a supervised classification model
    is run on the entire set.![How does it work?](img/B05137_04_048.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 3\. Clustering and label SSL – clustering followed by classification
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Advantages and limitations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The advantages and limitations are:'
  prefs: []
  type: TYPE_NORMAL
- en: Works very well when the cluster assumption holds true and the choice of clustering
    algorithm and parameters are correct
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large number of parameters and choices make this an unwieldy technique in many
    real-world problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transductive graph label propagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The key idea behind graph-based methods is to represent every instance in the
    dataset, labeled and unlabeled, as a node and compute the edges as some form of
    "similarity" between them. Known labels are used to propagate labels in the unlabeled
    data using the basic concepts of label smoothness as discussed in the assumptions
    section, that is, similar data points will lie "close" o each other graphically
    (*References* [4]).
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4 shows how the similarity indicated by the thickness of the arrow from
    the first data point to the last varies when the handwritten digit pattern changes.
    Knowing the first label, the label propagation can effectively label the next
    three digits due to the similarity in features while the last digit, though labeled
    the same, has a lower similarity as compared to the first three.
  prefs: []
  type: TYPE_NORMAL
- en: '![Transductive graph label propagation](img/B05137_04_050.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. Transductive graph label propagation – classification of hand-written
    digits. Leftmost and rightmost images are labeled, others are unlabeled. Arrow
    thickness is a visual measure of similarity to labeled digit "2" on the left.
  prefs: []
  type: TYPE_NORMAL
- en: Inputs and outputs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Input is training data with a few labeled and a large number of unlabeled data.
    The graph weighting or similarity computing method, such as k-nearest weighting,
    Gaussian decaying distance, or ϵ-radius method is chosen. Output is the labeled
    set for the entire data; it generally doesn't build inductive models like the
    algorithms seen previously.
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The general label propagation method follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Build a graph *g = (V,E)* where:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vertices *V = {1, 2…n}* correspond to data belonging to both labeled set *L*
    and unlabeled set *U*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Edges *E* are weight matrices **W**, such that **W**[i,j] represents similarity
    in some form between two data points **x**[i], **x**[j].
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute the diagonal degree matrix **D** by ![How does it work?](img/B05137_04_059.jpg).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assume the labeled set is binary and has ![How does it work?](img/B05137_04_060.jpg).
    Initialize the labels of all unlabeled data to be 0\. ![How does it work?](img/B05137_04_061.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Iterate at *t* = 0:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_04_063.jpg)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_IMG
- en: '![How does it work?](img/B05137_04_064.jpg) (reset the labels of labeled instances
    back to the original)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_IMG
- en: Go back to step 4, until convergence ![How does it work?](img/B05137_04_065.jpg)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Label the unlabeled points ![How does it work?](img/B05137_04_017.jpg) using
    the convergence labels ![How does it work?](img/B05137_04_065.jpg).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are many variations based on similarity, optimization selected in iterations,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The advantages and limitations are:'
  prefs: []
  type: TYPE_NORMAL
- en: The graph-based semi-supervised learning methods are costly in terms of computations—generally
    O(n³) where *n* is the number of instances. Though speeding and caching techniques
    help, the computational cost over large data makes it infeasible in many real-world
    data situations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The transductive nature makes it difficult for practical purposes where models
    need to be induced for unseen data. There are extensions such as Harmonic Mixtures,
    and so on, which address these concerns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transductive SVM (TSVM)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Transductive SVM is one of the oldest and most popular transductive semi-supervised
    learnig methods, introduced by Vapnik (*References* [5]). The key principle is
    that unlabeled data along with labeled data can help find the decision boundary
    using concepts of large margins. The underlying principle is that the decision
    boundaries normally don't lie in high density regions!
  prefs: []
  type: TYPE_NORMAL
- en: Inputs and outputs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Input is training data with few labeled and a large number of unlabeled data.
    Input has to be numeric features for TSVM computations. The choice of kernels,
    kernel parameters, and cost factors, which are all SVM-based parameters, are also
    input variables. The output is labels for the unlabeled dataset.
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Generally, SVM works as an optimization problem in the labeled hard boundary
    SVM formulated in terms of weight vector **w** and the bias *b* ![How does it
    work?](img/B05137_04_070.jpg) subject to ![How does it work?](img/B05137_04_072.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the data as ![How does it work?](img/B05137_04_015.jpg) labeled and
    ![How does it work?](img/B05137_04_017.jpg) unlabeled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In TSVM, the equation is modified as follows:![How does it work?](img/B05137_04_073.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This is subject to the following condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_04_074.jpg)![How does it work?](img/B05137_04_075.jpg)![How
    does it work?](img/B05137_04_076.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This is exactly like inductive SVM but using only labeled data. When we constrain
    the unlabeled data to conform to the side of the hyperplane of labeled data in
    order to maximize the margin, it results in unlabeled data being labeled with
    maximum margin separation! By adding the penalty factor to the constraints or
    replacing the dot product in the input space with kernels as in inductive SVM,
    complex non-linear noisy datasets can be labeled from unlabeled data.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5* illustrates the concept of TSVM in comparison with inductive SVM
    run on labeled data only and why TSVM can find better decision boundaries using
    the unlabeled datasets. The unlabeled datasets on either side of hyperplane are
    closer to their respective classes, thus helping find better margin separators.'
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_04_077.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. Transductive SVM
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The advantages and limitations:'
  prefs: []
  type: TYPE_NORMAL
- en: TSVMs can work very well in linear or non-linear datasets given noiseless labeled
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TSVMs have the same issues in finding hyper-parameters and tuning them to get
    the best results as inductive SVMs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Case study in semi-supervised learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this case study, we use another well-studied dataset from the UCI Repository,
    the Wisconsin Breast Cancer dataset. In the first part of the experiment, we demonstrate
    how to apply the Transductive SVM technique of semi-supervised learning using
    the open-source library called `JKernelMachines`. We choose the SVMLight algorithm
    and a Gaussian kernel for this technique.
  prefs: []
  type: TYPE_NORMAL
- en: In the second part, we use KEEL, a GUI-based framework and compare results from
    several evolutionary learning based algorithms using the UCI Breast Cancer dataset.
    The tools, methodology, and evaluation measures are described in the following
    subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Tools and software
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The two open source Java tools used in the semi-supervised learning case study
    are `JKernelMachines`, a Transductive SVM, and KEEL, a GUI-based tool that uses
    evolutionary algorithms for learning.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**JKernelMachines (Transductive SVM)**'
  prefs: []
  type: TYPE_NORMAL
- en: '`JKernelMachines` is a pure Java library that provides an efficient framework
    for using and rapidly developing specialized kernels. Kernels are similarity functions
    used in SVMs. `JKernelMachines` provides kernel implementations defined on structured
    data in addition to standard kernels on vector data such as Linear and Gaussian.
    In particular, it offers a combination of kernels, kernels defined over lists,
    and kernels with various caching strategies. The library also contains SVM optimization
    algorithm implementations including LaSVM and One-Class SVM using SMO. The creators
    of the library report that the results of JKernelMachines on some common UCI repository
    datasets are comparable to or better than the Weka library.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The example of loading data and running Transductive SVM using `JKernelMachines`
    is given here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the second approach, we use KEEL with the same dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**KEEL**'
  prefs: []
  type: TYPE_NORMAL
- en: '**KEEL** (**Knowledge Extraction based on Evolutionary Learning**) is a non-commercial
    (GPLv3) Java tool with GUI which enables users to analyze the behavior of evolutionary
    learning for a variety of data mining problems, including regression, classification,
    and unsupervised learning. It relieves users from the burden of programming sophisticated
    evolutionary algorithms and allows them to focus on new learning models created
    using the toolkit. KEEL is intended to meet the needs of researchers as well as
    students.'
  prefs: []
  type: TYPE_NORMAL
- en: KEEL contains algorithms for data preprocessing and post-processing as well
    as statistical libraries, and a Knowledge Extraction Algorithms Library which
    incorporates multiple evolutionary learning algorithms with classical learning
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'The GUI wizard included in the tool offers different functional components
    for each stage of the pipeline, including:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data management: Import, export of data, data transformation, visualization,
    and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Experiment design: Selection of classifier, estimator, unsupervised techniques,
    validation method, and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SSL experiments: Transductive and inductive classification (see image of off-line
    method for SSL experiment design in this section)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Statistical analysis: This provides tests for pair-wise and multiple comparisons,
    parametric, and non-parametric procedures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more info, visit [http://sci2s.ugr.es/keel/](http://sci2s.ugr.es/keel/)
    and [http://sci2s.ugr.es/keel/pdf/keel/articulo/Alcalaetal-SoftComputing-Keel1.0.pdf](http://sci2s.ugr.es/keel/pdf/keel/articulo/Alcalaetal-SoftComputing-Keel1.0.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: '![Tools and software](img/B05137_04_078.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: KEEL – wizard-based graphical interface'
  prefs: []
  type: TYPE_NORMAL
- en: Business problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Breast cancer is the top cancer in women worldwide and is increasing particularly
    in developing countries where the majority of cases are diagnosed in late stages.
    Examination of tumor mass using a non-surgical procedure is an inexpensive and
    preventative measure for early detection of the disease.
  prefs: []
  type: TYPE_NORMAL
- en: In this case-study, a marked dataset from such a procedure is used and the goal
    is to classify the breast cancer data into Malignant and Benign using multiple
    SSL techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning mapping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To illustrate the techniques learned in this chapter so far, we will use SSL
    to classify. Whereas the dataset contains labels for all the examples, in order
    to treat this as a problem where we can apply SSL, we will consider a fraction
    of the data to be unlabeled. In fact, we run multiple experiments using different
    fractions of unlabeled data for comparison. The different base learners used are
    classification algorithms familiar to us from previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Data collection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This dataset was collected by the University of Wisconsin Hospitals, Madison.
    The dataset is available in Weka AARF format. The data is not partitioned into
    training, validation and test.
  prefs: []
  type: TYPE_NORMAL
- en: Data quality analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The examples in the data contain no unique identifier. There are 16 examples
    for which the Bare Nuclei attribute has missing values. The target Class is the
    only categorical attribute and has two values. All other attributes are continuous
    and in the range [1, 10].
  prefs: []
  type: TYPE_NORMAL
- en: Data sampling and transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the experiments, we present results for 10-fold cross-validation. For comparison,
    four runs were performed each using a different fraction of labeled data—10%,
    20%, 30%, and 40%.
  prefs: []
  type: TYPE_NORMAL
- en: A numeric sample code number was added to each example as a unique identifier.
    The categorical values Malignant and Benign, for the class attribute, were replaced
    by the numeric values 4 and 2 respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Datasets and analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Breast Cancer Dataset Wisconsin (Original) is available from the UCI Machine
    Learning Repository at: [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)).'
  prefs: []
  type: TYPE_NORMAL
- en: This database was originally obtained from the University of Wisconsin Hospitals,
    Madison from Dr. William H. Wolberg. The dataset was created by Dr. Wolberg for
    the diagnosis and prognosis of breast tumors. The data is based exclusively on
    measurements involving the **Fine Needle Aspirate** (**FNA**) test. In this test,
    fluid from a breast mass is extracted using a small-gauge needle and then visually
    examined under a microscope.
  prefs: []
  type: TYPE_NORMAL
- en: 'A total of 699 instances with nine numeric attributes and a binary class (malignant/benign)
    constitute the dataset. The percentage of missing values is 0.2%. There are 65.5%
    malignant and 34.5% benign cases in the dataset. The feature names and range of
    valid values are listed in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Num. | Feature Name | Domain |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Sample code number | id number |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Clump Thickness | 1 - 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Uniformity of Cell Size | 1 - 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Uniformity of Cell Shape | 1 - 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | Marginal Adhesion | 1 - 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | Single Epithelial Cell Size | 1 - 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | Bare Nuclei | 1 - 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | Bland Chromatin | 1 - 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | Normal Nucleoli | 1 - 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | Mitoses | 1 - 10 |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | Class | 2 for benign, 4 for malignant |'
  prefs: []
  type: TYPE_TB
- en: Feature analysis results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Summary statistics by feature appear in Table 1.
  prefs: []
  type: TYPE_NORMAL
- en: '|   | Clump Thickness | Cell Size Unifor-mity | Cell Shape Unifor-mity | Marginal
    Adhesion | Single Epi Cell Size | Bare Nuclei | Bland Chromatin | Normal Nucleoli
    | Mitoses |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| mean | 4.418 | 3.134 | 3.207 | 2.807 | 3.216 | 3.545 | 3.438 | 2.867 | 1.589
    |'
  prefs: []
  type: TYPE_TB
- en: '| std | 2.816 | 3.051 | 2.972 | 2.855 | 2.214 | 3.644 | 2.438 | 3.054 | 1.715
    |'
  prefs: []
  type: TYPE_TB
- en: '| min | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 25% | 2 | 1 | 1 | 1 | 2 |   | 2 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 50% | 4 | 1 | 1 | 1 | 2 |   | 3 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 75% | 6 | 5 | 5 | 4 | 4 |   | 5 | 4 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| max | 10 | 10 | 10 | 10 | 10 | 10 | 10 | 10 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '*Table 1\. Features summary*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Experiments and results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Two SSL algorithms were selected for the experiments—self-training and co-training.
    In addition, four classification methods were chosen as base learners—Naïve Bayes,
    C4.5, K-NN, and SMO. Further, each experiment was run using four different partitions
    of labeled and unlabeled data (10%, 20%, 30%, and 40% labeled).
  prefs: []
  type: TYPE_NORMAL
- en: The hyper-parameters for the algorithms and base classifiers are given in Table
    2\. You can see the accuracy across the different runs corresponding to four partitions
    of labeled and unlabeled data for the two SSL algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we give the performance results for each experiment for the case of
    40% labeled. Performance metrics provided are Accuracy and the Kappa statistic
    with standard deviations.
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Parameters |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Self-Training | MAX_ITER = 40 |'
  prefs: []
  type: TYPE_TB
- en: '| Co-Training | MAX_ITER = 40, Initial Unlabeled Pool=75 |'
  prefs: []
  type: TYPE_TB
- en: '| KNN | K = 3, Euclidean distance |'
  prefs: []
  type: TYPE_TB
- en: '| C4.5 | pruned tree, confidence = 0.25, 2 examples per leaf |'
  prefs: []
  type: TYPE_TB
- en: '| NB | No parameters specified |'
  prefs: []
  type: TYPE_TB
- en: '| SMO | C = 1.0, Tolerance Parameter = 0.001, Epsilon= 1.0E-12, Kernel Type
    = Polynomial, Polynomial degree = 1, Fit logistic models = true |'
  prefs: []
  type: TYPE_TB
- en: '*Table 2\. Base classifier hyper-parameters for self-training and co-training*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '| SSL Algorithm | 10% | 20% | 30% | 40% |'
  prefs: []
  type: TYPE_TB
- en: '| Self-Training C 4.5 | 0.9 | 0.93 | 0.94 | 0.947 |'
  prefs: []
  type: TYPE_TB
- en: '| Co-Training SMO | 0.959 | 0.949 | 0.962 | 0.959 |'
  prefs: []
  type: TYPE_TB
- en: '*Table 3\. Model accuracy for samples with varying fraction of labeled examples*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '| Algorithm | Accuracy (no unlabeled) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| C4.5 10-fold CV | 0.947 |'
  prefs: []
  type: TYPE_TB
- en: '| SMO 10 fold CV | 0.967 |'
  prefs: []
  type: TYPE_TB
- en: '|   |   | 10 fold CV Wisconsin 40% Labeled Data |   |'
  prefs: []
  type: TYPE_TB
- en: '| Self-Training (kNN) | Accuracy | 0.9623 (1) | Kappa | 0.9170 (2) |'
  prefs: []
  type: TYPE_TB
- en: '|   | Std Dev | 0.0329 | Std Dev | 0.0714 |'
  prefs: []
  type: TYPE_TB
- en: '| Self-Training (C45) | Accuracy | 0.9606 (3) | Kappa | 0.9144 |'
  prefs: []
  type: TYPE_TB
- en: '|   | Std Dev | 0.0241 | Std Dev | 0.0511 |'
  prefs: []
  type: TYPE_TB
- en: '| Self-Training (NB) | Accuracy | 0.9547 | Kappa | 0.9036 |'
  prefs: []
  type: TYPE_TB
- en: '|   | Std Dev | 0.0252 | Std Dev | 0.0533 |'
  prefs: []
  type: TYPE_TB
- en: '| Self-Training (SMO) | Accuracy | 0.9547 | Kappa | 0.9035 |'
  prefs: []
  type: TYPE_TB
- en: '|   | Std Dev | 0.0208 | Std Dev | 0.0435 |'
  prefs: []
  type: TYPE_TB
- en: '| Co-Training (NN) | Accuracy | 0.9492 | Kappa | 0.8869 |'
  prefs: []
  type: TYPE_TB
- en: '|   | Std Dev | 0.0403 | Std Dev | 0.0893 |'
  prefs: []
  type: TYPE_TB
- en: '| Co-Training (C45) | Accuracy | 0.9417 | Kappa | 0.8733 |'
  prefs: []
  type: TYPE_TB
- en: '|   | Std Dev | 0.0230 | Std Dev | 0.0480 |'
  prefs: []
  type: TYPE_TB
- en: '| Co-Training (NB) | Accuracy | 0.9622 (2) | Kappa | 0.9193 (1) |'
  prefs: []
  type: TYPE_TB
- en: '|   | Std Dev | 0.0290 | Std Dev | 0.0614 |'
  prefs: []
  type: TYPE_TB
- en: '| Co-Training (SMO) | Accuracy | 0.9592 | Kappa | 0.9128 (3) |'
  prefs: []
  type: TYPE_TB
- en: '|   | Std Dev | 0.0274 | Std Dev | 0.0580 |'
  prefs: []
  type: TYPE_TB
- en: '*Table 4\. Model performance comparison using 40% labeled examples. The top
    ranking performers in each category are shown in parentheses.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Analysis of semi-supervised learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: With 40% of labeled data, semi-supervised self-training with C4.5 achieves the
    same result as 100% of labeled data with just C4.5\. This shows the strength of
    semi-supervised learning when the data is sparsely labeled.
  prefs: []
  type: TYPE_NORMAL
- en: SMO with polynomial kernel, with 30-40% data comes close to the 100% data but
    not as good as C4.5.
  prefs: []
  type: TYPE_NORMAL
- en: Self-training and co-training with four classifiers on 40% labeled training
    data shows
  prefs: []
  type: TYPE_NORMAL
- en: KNN as base classifier and self-training has the highest accuracy (0.9623) which
    indicates the non-linear boundary of the data. Co-training with Naïve Bayes comes
    very close.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Self-training with classifiers such as linear Naïve Bayes, non-linear C4.5
    and highly non-linear KNN shows steady improvements in accuracy: 0.9547, 0.9606,
    0.9623, which again shows that using self-training but choosing the right underlying
    classifier for the problem is very important.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Co-training with Naive Bayes has highest Kappa statistic (0.9193) and almost
    similar accuracy as KNN with self-training. The independence relationship between
    features—hence breaking the feature sets into orthogonal feature sets and using
    them for classifiers—improves the learning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Active learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although active learning has many similarities with semi-supervised learning,
    it has its own distinctive approach to modeling with datasets containing labeled
    and unlabeled data. It has roots in the basic human psychology that asking more
    questions often tends to solve problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main idea behind active learning is that if the learner gets to pick the
    instances to learn from rather than being handed labeled data, it can learn more
    effectively with less data (*Reference* [6]). With very small amount of labeled
    data, it can carefully pick instances from unlabeled data to get label information
    and use that to iteratively improve learning. This basic approach of querying
    for unlabeled data to get labels from a so-called oracle—an expert in the domain—distinguishes
    active learning from semi-supervised or passive learning. The following figure
    illustrates the difference and the iterative process involved:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Active learning](img/B05137_04_079.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7\. Active Machine Learning process contrasted with Supervised and Semi-Supervised
    Learning process.
  prefs: []
  type: TYPE_NORMAL
- en: Representation and notation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset *D*, which represents all the data instances and their labels, is
    given by *D* = {(**x**[1], *y*[2]), (**x**[2], *y*[2]), … (**x**[n], *y*[n])}
    where ![Representation and notation](img/B05137_04_012.jpg) are the individual
    instances of data and {*y*[1], *y*[2], … *y*[n]} is the set of associated labels.
    *D* is composed of two sets *U*, labeled data and *L*, unlabeled data. **x** is
    the set {**x**[1], **x**[2],… **x**[n]} of data instances without labels.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset ![Representation and notation](img/B05137_04_015.jpg) consists of
    all labeled data with known outcomes {*y*[1], *y*[2], … *y*[l]} whereas ![Representation
    and notation](img/B05137_04_017.jpg) is the dataset where the outcomes are not
    known. As before, |*U*|>> |*L*|.
  prefs: []
  type: TYPE_NORMAL
- en: Active learning scenarios
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Active learning scenarios can be broadly classified as:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stream-based active learning**: In this approach, an instance or example
    is picked only from the unlabeled dataset and a decision is made whether to ignore
    the data or pass it on to the oracle to get its label (*Referee*[10,11]).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pool-based active learning**: In this approach, the instances are queried
    from the unlabeled dataset and then ranked on the basis of informativeness and
    a set from these is sent to the Oracle to get the labels (*Referees* [12]).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Query synthesis**: In this method, the learner has only information about
    input space (features) and synthesizes queries from the unlabeled set for the
    membership. This is not used in practical applications, as most often it doesn''t
    consider the data generating distribution and hence often the queries are arbitrary
    or meaningless.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Active learning approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regardless of the scenario involved, every active learning approach includes
    selecting a query strategy or sampling method which establishes the mechanism
    for picking the queries in each iteration. Each method reveals a distinct way
    of seeking out unlabeled examples with the best information content for improving
    the learning process. In the following subsections, we describe the major query
    strategy frameworks, how they work, their merits and limitations, and the different
    strategies within each framework.
  prefs: []
  type: TYPE_NORMAL
- en: Uncertainty sampling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The key idea behind this form of sampling is to select instances from the unlabeled
    pool that the current model is most uncertain about. The learner can then avoid
    the instances the model is more certain or confident in classifying (*Reerences*
    [8]).
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic based models (Naïve Bayes, Logistic Regression, and so on) are
    the most natural choices for such methods as they give confidence measures on
    the given model, say *θ* for the data **x**, for a class *y*[i] *i* ϵ classes,
    and the probability ![Uncertainty sampling](img/B05137_04_086.jpg) as the posterior
    probability.
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The general process for all uncertainty-based algorithms is outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the data as labeled, ![How does it work?](img/B05137_04_015.jpg)
    and unlabeled, ![How does it work?](img/B05137_04_017.jpg).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'While there is still unlabeled data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the classifier model ![How does it work?](img/B05137_04_021.jpg) with
    the labeled data *L*.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the classifier model *f* on the unlabeled data *U* to assess informativeness
    *J* using one of the sampling mechanisms (see next section)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose *k* most informative data from *U* as set *L*[u] to get labels from the
    oracle.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Augment the labeled data with the *k* new labeled data points obtained in the
    previous step: *L* = *L* ∪ *L*[u].'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat all the steps under 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Some of the most common query synthesis algorithms to sample the informative
    instances from the data are given next.
  prefs: []
  type: TYPE_NORMAL
- en: Least confident sampling
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this technique, the data instances are sorted based on their confidence in
    reverse, and the instances most likely to be queried or selected are the ones
    the model is least confident about. The idea behind this is the least confident
    ones are the ones near the margin or separating hyperplane and getting their labels
    will be the best way to learn the boundaries effectively.
  prefs: []
  type: TYPE_NORMAL
- en: This can be formulated as ![Least confident sampling](img/B05137_04_088.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: The disadvantage of this method is that it effectively considers information
    of the best; information on the rest of the posterior distribution is not used.
  prefs: []
  type: TYPE_NORMAL
- en: Smallest margin sampling
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This is margin-based sampling, where the instances with smaller margins have
    more ambiguity than instances with larger margins.
  prefs: []
  type: TYPE_NORMAL
- en: This can be formulated as ![Smallest margin sampling](img/B05137_04_089.jpg)
    where ![Smallest margin sampling](img/B05137_04_090.jpg) and ![Smallest margin
    sampling](img/B05137_04_091.jpg) are two labels for the instance **x**.
  prefs: []
  type: TYPE_NORMAL
- en: Label entropy sampling
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Entropy, which is the measure of average information content in the data and
    is the impurity measure, can be used to sample the instances. This can be formulated
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Label entropy sampling](img/B05137_04_092.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Advantages and limitations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The advantages and limitations are:'
  prefs: []
  type: TYPE_NORMAL
- en: Label entropy sampling is the simplest approach and can work with any probabilistic
    classifiers—this is the biggest advantage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Presence of outliers or wrong feedback can go unnoticed and models can degrade
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Version space sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hypothesis *H* is the set of all the particular models that generalize or explain
    the training data; for example, all possible sets of weights that separate two
    linearly separable classes. Version spaces *V* are subsets of hypothesis *H*,
    which are consistent with the training data as defined by Tom Mitchell (*References*
    [15]) such that ![Version space sampling](img/B05137_04_095.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind this sampling is to query instances from the unlabeled dataset
    that reduce the size of the version space or minimize |*V*|.
  prefs: []
  type: TYPE_NORMAL
- en: Query by disagreement (QBD)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: QBD is one of the earliest algorithms which works on maintaining a version space
    *V*—when two hypotheses disagree on the label of new incoming data, that instance
    is selected for getting labels from the oracle or expert.
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The entire algorithm can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize ![How does it work?](img/B05137_04_095.jpg) as the set of all legal
    hypotheses.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the data as ![How does it work?](img/B05137_04_015.jpg) labeled and
    ![How does it work?](img/B05137_04_017.jpg) unlabeled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'While data **x***['']* is in *U*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If ![How does it work?](img/B05137_04_099.jpg) for any *h*[2] ∈ *V*:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Query the label of **x***[']* and get *y[']*.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '*V* = {h: h(**x**['']) = *y['']* for all points.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Otherwise:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ignore **x***[']*.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Query by Committee (QBC)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Query by Committee overcomes the limitation of Query by Disagreement related
    to maintaining all possible version spaces by creating a committee of classifiers
    and using their votes as the mechanism to capture the disagreement (*References*
    [7]).
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For this algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize the data as ![How does it work?](img/B05137_04_015.jpg) labeled and
    ![How does it work?](img/B05137_04_017.jpg) unlabeled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train the committee of models *C* = {*θ*¹*θ*², ... *θ*^c} on the labeled data
    *w* (see the following).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For all data **x***^''* in the *U*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vote for predictions on **x***'* as {![How does it work?](img/B05137_04_107.jpg).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Rank the instances based on maximum disagreement (see the following).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose *k* most informative data from *U* as set *L*[u] to get labels from the
    oracle.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Augment the labeled data with the *k* new labeled data points *L* = *L* ∪ *L*[u].
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Retrain the models {*θ*[1], *θ*[2], ... *θ*[c]} with new *L*.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: With the two tasks of training the committee of learners and choosing the disagreement
    methods, each has various choices.
  prefs: []
  type: TYPE_NORMAL
- en: Training different models can be either done using different samples from *L*
    or they can be trained using ensemble methods such as boosting and bagging.
  prefs: []
  type: TYPE_NORMAL
- en: 'Vote entropy is one of the methods chosen as the disagreement metric to rank.
    The mathematical way of representing it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_04_109.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *V(y[i])* is number of votes given to the label *y*[i] from all possible
    labels and |*C*| is size of the committee.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kullback-Leibler** (**KL**) divergence is an information theoretic measure
    of divergence between two probability distributions. The disagreement is quantified
    as the average divergence of each committee''s prediction from that of the consensus
    in the committee *C*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How does it work?](img/B05137_04_114.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Advantages and limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The advantages and limitations are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Simplicity and the fact that it can work with any supervised algorithm gives
    it a great advantage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are theoretical guarantees of minimizing errors and generalizing in some
    conditions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Query by Disagreement suffers from maintaining a large number of valid hypotheses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These methods still suffer from the issue of wrong feedback going unnoticed
    and models potentially degrading.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data distribution sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The previous methods selected the best instances from the unlabeled set based
    either on the uncertainty posed by the samples on the models or by reducing the
    hypothesis space size. Neither of these methods worked on what is best for the
    model itself. The idea behind data distribution sampling is that adding samples
    that help reduce the errors to the model serves to improve predictions on unseen
    instances using expected values (*References* [13 and 14]).
  prefs: []
  type: TYPE_NORMAL
- en: How does it work?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are different ways to find what is the best sample for the given model
    and here we will describe each one in some detail.
  prefs: []
  type: TYPE_NORMAL
- en: Expected model change
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The idea behind this is to select examples from the unlabeled set that that
    will bring maximum change in the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Expected model change](img/B05137_04_115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, P[θ] (*y*|**x**) = expectation over labels of **x**, ![Expected model
    change](img/B05137_04_117.jpg) is the sum over unlabeled instances of the entropy
    of including **x** *'* after retraining with **x**.
  prefs: []
  type: TYPE_NORMAL
- en: Expected error reduction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Here, the approach is to select examples from the unlabeled set that reduce
    the model''s generalized error the most. The generalized error is measured using
    the unlabeled set with expected labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Expected error reduction](img/B05137_04_119.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, Pθ (*y*|**x**) = expectation over labels of **x**, ![Expected error reduction](img/B05137_04_120.jpg)
    is the sum over unlabeled instances of the entropy of including x*^'* after retraining
    with **x**.
  prefs: []
  type: TYPE_NORMAL
- en: Variance reduction
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The general equation of estimation on an out-of-sample error in terms of noise-bias-variance
    is given by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Variance reduction](img/B05137_04_121.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, **G**(**x**) is the model''s prediction given the label *y*. In variance
    reduction, we select examples from the unlabeled set that most reduce the variance
    in the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Variance reduction](img/B05137_04_124.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *θ* + represents the model after it has been retrained with the new point
    **x** *^'* and its label *y^'*.
  prefs: []
  type: TYPE_NORMAL
- en: Density weighted methods
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this approach, we select examples from the unlabeled set that have average
    similarity to the labeled set.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Density weighted methods](img/B05137_04_127.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *sim*(**x**, **x** *^'*) is the density term or the similarity term where
    H[θ](*y*|**x**) is the base utility measure.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The advantages and limitations are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The biggest advantage is that they work directly on the model as an optimization
    objective rather than implicit or indirect methods described before
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These methods can work on pool- or stream-based scenarios
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These methods have some theoretical guarantees on the bounds and generalizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The biggest disadvantage of these methods is computational cost and difficulty
    in implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Case study in active learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This case study uses another well-known publicly available dataset to demonstrate
    active learning techniques using open source Java libraries. As before, we begin
    with defining the business problem, what tools and frameworks are used, how the
    principles of machine learning are realized in the solution, and what the data
    analysis steps reveal. Next, we describe the experiments that were conducted,
    evaluate the performance of the various models, and provide an analysis of the
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Tools and software
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the experiments in Active Learning, JCLAL was the tool used. JCLAL is a
    Java framework for Active Learning, supporting single-label and multi-label learning.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'JCLAL is open source and is distributed under the GNU general public license:
    [https://sourceforge.net/p/jclal/git/ci/master/tree/](https://sourceforge.net/p/jclal/git/ci/master/tree/).'
  prefs: []
  type: TYPE_NORMAL
- en: Business problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The abalone dataset, which is used in these experiments, contains data on various
    physical and anatomical characteristics of abalone—commonly known as sea snails.
    The goal is to predict the number of rings in the shell, which is indicative of
    the age of the specimen.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning mapping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have seen, active learning is characterized by starting with a small set
    of labeled data accompanied by techniques of querying the unlabeled data such
    that we incrementally add instances to the labeled set. This is performed over
    multiple iterations, a batch at a time. The number of iterations and batch size
    are hyper-parameters for these techniques. The querying strategy and the choice
    of supervised learning method used to train on the growing number of labeled instances
    are additional inputs.
  prefs: []
  type: TYPE_NORMAL
- en: Data Collection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As before, we will use an existing dataset available from the UCI repository
    ([https://archive.ics.uci.edu/ml/datasets/Abalone](https://archive.ics.uci.edu/ml/datasets/Abalone)).
    The original owners of the database are the Department of Primary Industry and
    Fisheries in Tasmania, Australia.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data types and descriptions of the attributes accompany the data and are
    reproduced in *Table 5*. The class attribute, Rings, has 29 distinct classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Data type | Measurement units | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Sex | nominal | M, F, and I (infant) | sex of specimen |'
  prefs: []
  type: TYPE_TB
- en: '| Length | continuous | mm | longest shell measurement |'
  prefs: []
  type: TYPE_TB
- en: '| Diameter | continuous | mm | perpendicular to length |'
  prefs: []
  type: TYPE_TB
- en: '| Height | continuous | mm | with meat in shell |'
  prefs: []
  type: TYPE_TB
- en: '| Whole weight | continuous | grams | whole abalone |'
  prefs: []
  type: TYPE_TB
- en: '| Shucked weight | continuous | grams | weight of meat |'
  prefs: []
  type: TYPE_TB
- en: '| Viscera weight | continuous | grams | gut weight (after bleeding) |'
  prefs: []
  type: TYPE_TB
- en: '| Shell weight | continuous | grams | after being dried |'
  prefs: []
  type: TYPE_TB
- en: '| Rings | integer | count | +1.5 gives the age in years |'
  prefs: []
  type: TYPE_TB
- en: '*Table 5\. Abalone dataset features*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Data sampling and transformation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this experiment, we treated a randomly selected 4,155 records as unlabeled
    and kept the remaining 17 as labeled. There is no transformation of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Feature analysis and dimensionality reduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With only eight features, there is no need for dimensionality reduction. The
    dataset comes with some statistics on the features, reproduced in *Table 6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '|   | **Length** | **Diameter** | **Height** | **Whole** | **Shucked** | **Viscera**
    | **Shell** | **Rings** |'
  prefs: []
  type: TYPE_TB
- en: '| Min | 0.075 | 0.055 | 0 | 0.002 | 0.001 | 0.001 | 0.002 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Max | 0.815 | 0.65 | 1.13 | 2.826 | 1.488 | 0.76 | 1.005 | 29 |'
  prefs: []
  type: TYPE_TB
- en: '| Mean | 0.524 | 0.408 | 0.14 | 0.829 | 0.359 | 0.181 | 0.239 | 9.934 |'
  prefs: []
  type: TYPE_TB
- en: '| SD | 0.12 | 0.099 | 0.042 | 0.49 | 0.222 | 0.11 | 0.139 | 3.224 |'
  prefs: []
  type: TYPE_TB
- en: '| Correl | 0.557 | 0.575 | 0.557 | 0.54 | 0.421 | 0.504 | 0.628 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '*Table 6\. Summary statistics by feature*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Models, results, and evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We conducted two sets of experiments. The first used pool-based scenarios and
    the second, stream-based. In each set, we used entropy sampling, least confident
    sampling, margin sampling, and vote entropy sampling. The classifiers used were
    Naïve Bayes, Logistic Regression, and J48 (implementation of C4.5). For every
    experiment, 100 iterations were run, with batch sizes of 1 and 10\. In *Table
    7*, we present a subset of these results, specifically, pool-based and stream-based
    scenarios for each sampling method using Naïve Bayes, Simple Logistic, and C4.5
    classifiers with a batch size of 10.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The full set of results can be seen at [https://github.com/mjmlbook/mastering-java-machine-learning/tree/master/Chapter4](https://github.com/mjmlbook/mastering-java-machine-learning/tree/master/Chapter4).
  prefs: []
  type: TYPE_NORMAL
- en: 'The JCLAL library requires an XML configuration file to specify which scenario
    to use, the query strategy selected, batch size, max iterations, and base classifier.
    The following is an example configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The tools itself is invoked via the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Pool-based scenarios
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the following three tables, we compare results using pool-based scenarios
    when using Naïve Bayes, Simple Logistic, and C4.5 classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: '**Naïve Bayes:**'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Area Under ROC | F Measure | False Positive Rate | Precision
    | Recall |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-EntropySampling-NaiveBayes-b10 | 0.6021 | 0.1032 | 0.0556(1) |
    0.1805 | 0.1304 |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-KLDivergence-NaiveBayes-b10 | 0.6639(1) | 0.1441(1) | 0.0563 |
    0.1765 | 0.1504 |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-LeastConfidentSampling-NaiveBayes-b10 | 0.6406 | 0.1300 | 0.0827
    | 0.1835(1) | 0.1810(1) |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-VoteEntropy-NaiveBayes-b10 | 0.6639(1) | 0.1441(1) | 0.0563 | 0.1765
    | 0.1504 |'
  prefs: []
  type: TYPE_TB
- en: '*Table 7\. Performance of pool-based scenario using Naïve Bayes classifier*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Logistic Regression**:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Area Under ROC | F Measure | False Positive Rate | Precision
    | Recall |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-EntropySampling-SimpleLogistic-b10 | 0.6831 | 0.1571 | 0.1157 |
    0.1651 | 0.2185(1) |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-KLDivergence-SimpleLogistic-b10 | 0.7175(1) | 0.1616 | 0.1049 |
    0.2117(1) | 0.2065 |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-LeastConfidentSampling-SimpleLogistic-b10 | 0.6629 | 0.1392 | 0.1181(1)
    | 0.1751 | 0.1961 |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-VoteEntropy-SimpleLogistic-b10 | 0.6959 | 0.1634(1) | 0.0895 |
    0.2307 | 0.1880 |'
  prefs: []
  type: TYPE_TB
- en: '*Table 8\. Performance of pool-based scenario using Logistic Regression classifier*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**C4.5**:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Area Under ROC | F Measure | False Positive Rate | Precision
    | Recall |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-EntropySampling-J48-b10 | 0.6730(1) | 0.3286(1) | 0.0737 | 0.3432(1)
    | 0.32780(1) |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-KLDivergence-J48-b10 | 0.6686 | 0.2979 | 0.0705(1) | 0.3153 | 0.2955
    |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-LeastConfidentSampling-J48-b10 | 0.6591 | 0.3094 | 0.0843 | 0.3124
    | 0.3227 |'
  prefs: []
  type: TYPE_TB
- en: '| PoolBased-VoteEntropy-J48-b10 | 0.6686 | 0.2979 | 0.0706 | 0.3153 | 0.2955
    |'
  prefs: []
  type: TYPE_TB
- en: '*Table 9\. Performance of pool-based scenario using C4.5 classifier*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Stream-based scenarios
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the following three tables, we have results for experiments on stream-based
    scenarios using Naïve Bayes, Logistic Regression, and C4.5 classifiers with four
    different sampling methods.
  prefs: []
  type: TYPE_NORMAL
- en: '**Naïve Bayes**:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Area Under ROC | F Measure | False Positive Rate | Precision
    | Recall |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-EntropySampling-NaiveBayes-b10 | 0.6673(1) | 0.1432(1) | 0.0563
    | 0.1842(1) | 0.1480 |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-LeastConfidentSampling-NaiveBayes-b10 | 0.5585 | 0.0923 | 0.1415
    | 0.1610 | 0.1807(1) |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-MarginSampling-NaiveBayes-b10 | 0.6736(1) | 0.1282 | 0.0548(1)
    | 0.1806 | 0.1475 |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-VoteEntropyQuery-NaiveBayes-b10 | 0.5585 | 0.0923 | 0.1415 |
    0.1610 | 0.1807(1) |'
  prefs: []
  type: TYPE_TB
- en: '*Table 10\. Performance of stream-based scenario using Naïve Bayes classifier*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Logistic Regression**:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Area Under ROC | F Measure | False Positive Rate | Precision
    | Recall |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-EntropySampling-SimpleLogistic-b10 | 0.7343(1) | 0.1994(1) |
    0.0871 | 0.2154 | 0.2185(1) |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-LeastConfidentSampling-SimpleLogistic-b10 | 0.7068 | 0.1750 |
    0.0906 | 0.2324(1) | 0.2019 |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-MarginSampling-SimpleLogistic-b10 | 0.7311 | 0.1994(1) | 0.0861
    | 0.2177 | 0.214 |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-VoteEntropy-SimpleLogistic-b10 | 0.5506 | 0.0963 | 0.0667(1)
    | 0.1093 | 0.1117 |'
  prefs: []
  type: TYPE_TB
- en: '*Table 11\. Performance of stream-based scenario using Logistic Regression
    classifier*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**C4.5**:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Experiment | Area Under ROC | F Measure | False Positive Rate | Precision
    | Recall |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-EntropySampling-J48-b10 | 0.6648 | 0.3053 | 0.0756 | 0.3189(1)
    | 0.3032 |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-LeastConfidentSampling-J48-b10 | 0.6748(1) | 0.3064(1) | 0.0832
    | 0.3128 | 0.3189(1) |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-MarginSampling-J48-b10 | 0.6660 | 0.2998 | 0.0728(1) | 0.3163
    | 0.2967 |'
  prefs: []
  type: TYPE_TB
- en: '| StreamBased-VoteEntropy-J48-b10 | 0.4966 | 0.0627 | 0.0742 | 0.1096 | 0.0758
    |'
  prefs: []
  type: TYPE_TB
- en: '*Table 12\. Performance of stream-based scenario using C4.5 classifier*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Analysis of active learning results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is quite interesting to see that pool-based, Query By Committee—an ensemble
    method—using KL-Divergence sampling does really well across most classifiers.
    As discussed in the section, these methods have been proven to have a theoretical
    guarantee on reducing the errors by keeping a large hypothesis space, and this
    experimental result supports that empirically.
  prefs: []
  type: TYPE_NORMAL
- en: Pool-based, entropy-based sampling using C4.5 as a classifier has the highest
    Precision, Recall, FPR and F-Measure. Also with stream-based, entropy sampling
    with C4.5, the metrics are similarly high. With different sampling techniques
    and C4.5 using pool-based as in KL-Divergence, LeastConfident or vote entropy,
    the metrics are significantly higher. Thus, this can be attributed more strongly
    to the underlying classifier C4.5 in finding non-linear patterns.
  prefs: []
  type: TYPE_NORMAL
- en: The Logistic Regression algorithm performs very well in both stream-based and
    pool-based when considering AUC. This may be completely due to the fact that LR
    has a good probabilistic approach in confidence mapping, which is an important
    factor for giving good AUC scores.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After a tour of supervised and unsupervised machine learning techniques and
    their application to real-world datasets in the previous chapters, this chapter
    introduces the concepts, techniques, and tools of **Semi-Supervised Learning**
    (**SSL**) and **Active Learning** (**AL**).
  prefs: []
  type: TYPE_NORMAL
- en: In SSL, we are given a few labeled examples and many unlabeled ones—the goal
    is either to simply train on the labeled ones in order to classify the unlabeled
    ones (transductive SSL), or use the unlabeled and labeled examples to train models
    to correctly classify new, unseen data (inductive SSL). All techniques in SSL
    are based on one or more of the assumptions related to semi-supervised smoothness,
    cluster togetherness, and manifold togetherness.
  prefs: []
  type: TYPE_NORMAL
- en: Different SSL techniques are applicable to different situations. The simple
    self-training SSL is straightforward and works with most supervised learning algorithms;
    when the data is from more than just one domain, the co-training SSL is a suitable
    method. When the cluster togetherness assumption holds, the cluster and label
    SSL technique can be used; a "closeness" measure is exploited by transductive
    graph label propagation, which can be computationally expensive. Transductive
    SVM performs well with linear or non-linear data and we see an example of training
    a TSVM with a Gaussian kernel on the UCI Breast Cancer dataset using the `JKernelMachines`
    library. We present experiments comparing SSL models using the graphical Java
    tool KEEL in the concluding part of the SSL portion of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We introduced active learning (AL) in the second half of the chapter. In this
    type of learning, various strategies are used to query the unlabeled portion of
    the dataset in order to present the expert with examples that will prove most
    effective in learning from the entire dataset. As the expert, or oracle, provides
    the labels to the selected instances, the learner steadily improves its ability
    to generalize. The techniques of AL are characterized by the choice of classifier,
    or committee of classifiers, and importantly, on the querying strategy chosen.
    These strategies include uncertainty sampling, where the instances with the least
    confidence are queries, version sampling, where a subset of the hypotheses that
    explain the training data are selected, and data distribution sampling, which
    involves improving the model by selections that would decrease the generalization
    error. We presented a case study using the UCI abalone dataset to demonstrate
    active learning in practice. The tool used here is the JCLAL Java framework for
    active learning.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Yarowsky, D (1995). *Unsupervised word sense disambiguation rivaling supervised
    methods*. Proceedings of the 33rd Annual Meeting of the Association for Computational
    Linguistics (pp. 189–196)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Blum, A., and Mitchell, T (1998). *Combining labeled and unlabeled data with
    co-training*. COLT: Proceedings of the Workshop on Computational Learning Theory.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Demiriz, A., Bennett, K., and Embrechts, M (1999). *Semi-supervised clustering
    using genetic algorithms*. Proceedings of Artificial Neural Networks in Engineering.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux (2006). *Label Propagation
    and Quadratic Criterion*. In Semi-Supervised Learning, pp. 193-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: T. Joachims (1998). *Transductive Inference for Text Classiﬁcation using Support
    Vector Machines*, ICML.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B. Settles (2008). *Curious Machines: Active Learning with Structured Instances*.
    PhD thesis, University of Wisconsin–Madison.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: D. Angluin (1988). *Queries and concept learning*. Machine Learning, 2:319–342.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: D. Lewis and W. Gale (1994). *A sequential algorithm for training text classifiers*.
    In Proceedings of the ACM SIGIR Conference on Research and Development in Information
    Retrieval, pages 3–12\. ACM/Springer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: H.S. Seung, M. Opper, and H. Sompolinsky (1992). *Query by committee*. In Proceedings
    of the ACM Workshop on Computational Learning Theory, pages 287–294.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: D. Cohn, L. Atlas, R. Ladner, M. El-Sharkawi, R. Marks II, M. Aggoune, and D.
    Park (1992). *Training connectionist networks with queries and selective sampling*.
    In Advances in Neural Information Processing Systems (NIPS). Morgan Kaufmann.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: D. Cohn, L. Atlas, and R. Ladner (1994). *Improving generalization with active
    learning*. Machine Learning, 15(2):201–221.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: D. Lewis and J. Catlett (1994). *Heterogeneous uncertainty sampling for supervised
    learning*. In Proceedings of the International Conference on Machine Learning
    (ICML), pages 148–156\. Morgan Kaufmann.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: S. Dasgupta, A. Kalai, and C. Monteleoni (2005). *Analysis of perceptron-based
    active learning*. In Proceedings of the Conference on Learning Theory (COLT),
    pages 249–263\. Springer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: S. Dasgupta, D. Hsu, and C. Monteleoni (2008). *A general agnostic active learning
    algorithm*. In Advances in Neural Information Processing Systems (NIPS), volume
    20, pages 353–360\. MIT Press.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: T. Mitchell (1982). *Generalization as search*. Artificial Intelligence, 18:203–226.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
