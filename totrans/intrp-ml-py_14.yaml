- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: What’s Next for Machine Learning Interpretability?
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习可解释性的未来是什么？
- en: Over the last thirteen chapters, we have explored the field of **Machine Learning**
    (**ML**) interpretability. As stated in the preface, it’s a broad area of research,
    most of which hasn’t even left the lab and become widely used yet, and this book
    has no intention of covering absolutely all of it. Instead, the objective is to
    present various interpretability tools in sufficient depth to be useful as a starting
    point for beginners and even complement the knowledge of more advanced readers.
    This chapter will summarize what we’ve learned in the context of the ecosystem
    of ML interpretability methods, and then speculate on what’s to come next!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的十三章中，我们探讨了机器学习（ML）可解释性的领域。正如前言所述，这是一个广泛的研究领域，其中大部分甚至还没有离开实验室，尚未得到广泛应用，本书无意涵盖所有内容。相反，目标是深入介绍各种可解释性工具，以便作为初学者的起点，甚至补充更高级读者的知识。本章将总结我们在机器学习可解释性方法生态系统中的所学，并推测接下来会发生什么！
- en: 'These are the main topics we are going to cover in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们将在本章中讨论的主要主题：
- en: Understanding the current landscape of ML interpretability
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解机器学习可解释性的当前格局
- en: Speculating on the future of ML interpretability
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对机器学习可解释性未来的推测
- en: Understanding the current landscape of ML interpretability
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习可解释性的当前格局
- en: First, we will provide some context on how the book relates to the main goals
    of ML interpretability and how practitioners can start applying the methods to
    achieve those broad goals. Then, we’ll discuss the current areas of growth in
    research.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将提供一些关于本书如何与机器学习可解释性的主要目标相关联以及从业者如何开始应用这些方法来实现这些广泛目标的背景信息。然后，我们将讨论研究中的当前增长领域。
- en: Tying everything together!
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将一切联系在一起！
- en: 'As discussed in *Chapter 1*, *Interpretation, Interpretability, and Explainability;
    and Why Does It All Matter?*, there are three main themes when talking about ML
    interpretability: **Fairness, Accountability, and Transparency** (**FAT**), and
    each of these presents a series of concerns (see *Figure 14.1*). I think we can
    all agree these are all desirable properties for a model! Indeed, these concerns
    all present opportunities for the improvement of **Artificial Intelligence** (**AI**)
    systems. These improvements start by leveraging model interpretation methods to
    evaluate models, confirm or dispute assumptions, and find problems.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如*第1章*中所述，*解释、可解释性和可解释性；以及为什么这一切都很重要？*，在讨论机器学习可解释性时，有三个主要主题：**公平性、责任和透明度**（FAT），每个主题都提出了一系列关注点（见*图14.1*）。我想我们都可以同意，这些都是模型所期望的特性！确实，这些关注点都为人工智能（AI）系统的改进提供了机会。这些改进首先通过利用模型解释方法来评估模型、确认或反驳假设以及发现问题开始。
- en: 'What your aim is will depend on what stage you are at in the ML workflow. If
    the model is already in production, the objective might be to evaluate it with
    a whole suite of metrics, but if the model is still in early development, the
    aim may be to find deeper problems that a metric won’t discover. Perhaps you are
    also just using black-box models for knowledge discovery as we did in *Chapter
    4* – in other words, leveraging the models to learn from the data with no plan
    to take it to production. If this is the case, you might confirm or dispute the
    assumptions you had about the data, and by extension, the model:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你的目标将取决于你在机器学习（ML）工作流程中的哪个阶段。如果模型已经投入生产，目标可能是用一系列指标来评估它，但如果模型仍处于早期开发阶段，目标可能是找到指标无法发现的更深层问题。也许你也在像我们在*第4章*中做的那样，仅仅使用黑盒模型进行知识发现——换句话说，利用模型从数据中学习，但没有计划将其投入生产。如果是这种情况，你可能会确认或反驳你对数据的假设，以及由此产生的模型：
- en: '![](img/18406_14_01.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/18406_14_01.png)'
- en: 'Figure 14.1: ML interpretation methods'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1：机器学习解释方法
- en: In any case, none of these aims are mutually exclusive, and you should probably
    always be looking for problems and disputing assumptions, even when the model
    appears to be performing well!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，这些目标都不是相互排斥的，你很可能始终在寻找问题并反驳假设，即使模型看起来表现良好！
- en: And regardless of the aim and primary concern, it is recommended that you use
    many interpretation methods, not only because no technique is perfect but also
    because all problems and aims are interrelated. In other words, there’s no justice
    without consistency and no reliability without transparency.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 并且无论目标是什么，主要关注点是什么，都建议您使用许多解释方法，这不仅是因为没有哪种技术是完美的，而且还因为所有问题和目标都是相互关联的。换句话说，没有一致性就没有正义，没有透明性就没有可靠性。
- en: In fact, you can read *Figure 14.1* from bottom to top as if it were a pyramid,
    because transparency is foundational, followed by accountability in the second
    tier, and, ultimately, fairness is the cherry on top.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你可以从下到上阅读*图14.1*，就像它是一座金字塔一样，因为透明性是基础，其次是第二层的问责制，最终，公平性是顶部的樱桃。
- en: Therefore, even when the goal is to assess model fairness, the model should
    be stress-tested for robustness. Most relevant feature importances and interactions
    should be understood. Otherwise, it won’t matter if predictions aren’t robust
    and transparent.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，即使目标是评估模型公平性，模型也应进行压力测试以确保其鲁棒性。应理解大多数相关特征重要性和交互作用。否则，如果预测不鲁棒且不透明，那就无关紧要了。
- en: There are many interpretation methods covered in *Figure 14.1*, and these are
    by no means every interpretation method available. They represent the most popular
    methods with well-maintained open-source libraries behind them. In this book,
    we have touched on most of them, albeit some of them only briefly. Those that
    weren’t discussed are in *italics* and those that were discussed have the relevant
    chapter numbers provided next to them. There’s been a focus on **model-agnostic**
    methods for **black-box supervised learning models**. Still, outside of this realm,
    there are also many other interpretation methods, such as those found in reinforcement
    learning, generative models, or the many statistical methods used strictly for
    linear regression. And even within the supervised learning black-box model realm,
    there are hundreds of application-specific model interpretation methods used for
    applications ranging from chemistry graph CNNs to customer churn classifiers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.1*中涵盖了多种解释方法，这些方法绝不是所有可用的解释方法。它们代表了背后有良好维护的开源库的最受欢迎的方法。在本书中，我们简要地提到了它们中的大多数，尽管其中一些只是简要提及。未讨论的用斜体表示，而讨论过的旁边提供了相关的章节编号。本书重点介绍了**模型无关**的**黑盒监督学习模型**方法。然而，在这个领域之外，还有许多其他解释方法，例如强化学习、生成模型或仅用于线性回归的许多统计方法。即使在监督学习黑盒模型领域内，也有数百种针对特定应用的应用特定模型解释方法，这些应用范围从化学图CNN到客户流失分类器。'
- en: That being said, many of the methods discussed in this book can be tailored
    to a wide variety of applications. Integrated gradients can be used to interpret
    audio classifiers and weather forecasting models. Sensitivity analysis can be
    employed in financial modeling and infectious disease risk models. Causal inference
    methods can be leveraged to improve user experience and drug trials.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，本书中讨论的许多方法可以定制用于各种应用。集成梯度可用于解释音频分类器和天气预报模型。敏感性分析可用于金融建模和传染病风险模型。因果推断方法可以用来改善用户体验和药物试验。
- en: '*Improve* is the operative word here because interpretation methods have a
    flip side!'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*改进*是这里的关键词，因为解释方法有另一面！'
- en: 'In this book, that flip side has been referred to as *tuning for interpretability*,
    which means creating solutions to problems with FAT. Those solutions can be appreciated
    in *Figure 14.2*:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，这一面被称为*为解释性调整*，这意味着为FAT问题创造解决方案。这些解决方案可以在*图14.2*中欣赏到：
- en: '![](img/18406_14_02.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/18406_14_02.png)'
- en: 'Figure 14.2: Toolset to treat FAT issues'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2：处理FAT问题的工具集
- en: 'I have observed five approaches to interpretability solutions:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我观察到五种解释性解决方案的方法：
- en: '**Mitigating Bias**: Any corrective measure that is taken to account for bias.
    Please note that this bias refers to the sampling, exclusion, prejudice, and measurement
    biases in the data, along with any other bias introduced into the ML workflow.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓解偏差**：任何为考虑偏差而采取的纠正措施。请注意，这里的偏差指的是数据中的采样、排除、偏见和测量偏差，以及任何引入到机器学习工作流程中的其他偏差。'
- en: '**Placing Guardrails**: Any solution that ensures that the model is constrained
    so that it doesn’t contradict the domain knowledge and predict without confidence.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设置护栏**：任何确保模型受到约束，使其不与领域知识相矛盾且不自信地预测的解决方案。'
- en: '**Enhancing Reliability**: Any fix that increases the confidence and consistency
    of predictions, excluding those that do so by reducing complexity.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强可靠性**：任何增加预测信心和一致性的修复，不包括通过减少复杂性来实现的修复。'
- en: '**Reducing Complexity**: Any means by which sparsity is introduced. As a side
    effect, this generally enhances reliability by generalizing better.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少复杂性**：任何引入稀疏性的方法。作为一种副作用，这通常通过更好地泛化来增强可靠性。'
- en: '**Ensuring Privacy**: Any effort to secure private data and model architecture
    from third parties. We didn’t cover this approach in this book.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**确保隐私**：任何努力确保第三方无法获取私有数据和模型架构。我们在这本书中没有涵盖这种方法。'
- en: 'There are also three areas in which these approaches can be applied:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法还可以应用于以下三个领域：
- en: '**Data (“preprocessing”)**: By modifying the training data'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据（“预处理”**）：通过修改训练数据'
- en: '**Model (“in-processing”)**: By modifying the model, its parameters, or training
    procedure'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型（“处理中”**）：通过修改模型、其参数或训练过程'
- en: '**Prediction (“postprocessing”)**: By intervening in the inference of the model'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测（“后处理”**）：通过干预模型的推理'
- en: There’s a fourth area that can impact the other three – namely, data and algorithmic
    governance. This includes regulations and standards that dictate a certain methodology
    or framework. It’s a missing column because very few industries and jurisdictions
    have laws dictating what methods and approaches should be applied to comply with
    FAT. For instance, governance could impose a standard for explaining algorithmic
    decisions, data provenance, or a robustness certification threshold. We will discuss
    this further in the next section.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个第四个领域可能会影响其他三个领域——即数据和算法治理。这包括规定某些方法或框架的法规和标准。这是一个缺失的列，因为很少有行业和司法管辖区有法律规定应该应用哪些方法和方法来遵守FAT。例如，治理可以强制执行解释算法决策、数据来源或鲁棒性认证阈值的标准。我们将在下一节中进一步讨论这一点。
- en: 'You can tell in *Figure 14.2* that many of the methods repeat themselves for
    FAT. **Feature Selection and Engineering, Monotonic Constraints**, and **Regularization**
    benefit all three but are not always leveraged by the same approach. **Data Augmentation**
    also can enhance reliability for fairness and accountability. As with *Figure
    14.1*, the items in italics were not covered in the book, of which three topics
    stand out: **Uncertainty Estimation**, **Adversarial Robustness**, and **Privacy
    Preservation** are fascinating topics and deserve books of their own.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从*图14.2*中看出，许多方法在FAT上重复使用。**特征选择和工程、单调约束**和**正则化**对三者都有益，但并不总是通过相同的方法来实现。**数据增强**也可以提高公平性和问责制的可靠性。与*图14.1*一样，斜体中的内容在书中没有涉及，其中三个主题脱颖而出：**不确定性估计**、**对抗鲁棒性**和**隐私保护**是迷人的主题，值得有自己的一本书。
- en: Current trends
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当前趋势
- en: One of the most significant deterrents of AI adoption is a lack of interpretability,
    which is partially the reason why 50-90% of AI projects never take off (see the
    *Further reading* section for articles about this), and the other is the ethical
    transgressions that happen as a result of not complying with FAT. In this aspect,
    **Interpretable Machine Learning** (**iML**) has the power to lead ML as a whole
    because it can help with both goals with the corresponding methods in *Figure
    14.1* and *Figure 14.2*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: AI采用的最重要的障碍之一是缺乏可解释性，这也是50-90%的AI项目从未起飞的部分原因（关于这一点，请参阅*进一步阅读*部分的相关文章），另一个原因是由于不遵守FAT而产生的道德违规行为。在这方面，**可解释机器学习**（**iML**）有力量引领整个ML，因为它可以帮助实现这两个目标，如图14.1和图14.2中的相应方法。
- en: 'Thankfully, we are witnessing an increase in interest and production in iML,
    mostly under **Explainable Artificial Intelligence** (**XAI**) – see *Figure 14.3*.
    In the scientific community, iML is still the most popular term, but XAI dominates
    in public settings:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们正在见证对iML的兴趣和生产力的增加，这主要是在**可解释人工智能**（**XAI**）的背景下——参见*图14.3*。在科学界，iML仍然是最受欢迎的术语，但在公共场合XAI占主导地位：
- en: '![Graphical user interface, application  Description automatically generated](img/18406_14_03.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序描述自动生成](img/18406_14_03.png)'
- en: 'Figure 14.3: Publication and search trends for iML and XAI'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3：iML和XAI的出版和搜索趋势
- en: This means that just as ML is starting to get standardized, regulated, consolidated,
    and integrated into a whole host of other disciplines, interpretation will soon
    get a seat at the table.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，正如机器学习开始标准化、监管、整合到众多其他学科一样，解释性也将很快获得一席之地。
- en: ML is replacing software in all industries. And as more is getting automated,
    more models are deployed to the cloud, and it will get worse with the **Artificial
    Intelligence of Things** (**AIoT**). Deployment is not traditionally in the ML
    practitioner’s wheelhouse. That is why ML increasingly depends on **Machine Learning
    Operations** (**MLOps**). And the pace of automation means more tools are needed
    to build, test, deploy, and monitor these models. At the same time, there’s a
    need for the standardization of tools, methods, and metrics. Slowly but surely,
    this is happening. Since 2017, we have had the **Open Neural Network Exchange**
    (**ONNX**), an open standard for interoperability. And at the time of writing,
    the **International Organization for Standardization** (**ISO**) has over two
    dozen AI standards being written (and one published), several of which involve
    interpretability. Naturally, some things will get standardized because of common
    use, due to the consolidation of ML model classes, methods, libraries, service
    providers, and practices. Over time, one or a few in each area will emerge. Lastly,
    given ML’s outsized role in algorithmic decision-making, it’s only a matter of
    time before it is regulated. Only some financial markets regulate trading algorithms,
    such as the **Securities and Exchange Commission** (**SEC**) in the United States
    and the **Financial Conduct Authority** (**FCA**) in the UK. Besides that, only
    data privacy and provenance regulations are widely enforced, such as the HIPAA
    in the US and the LGPD in Brazil. The GDPR in the European Union takes this a
    bit further with the “right to an explanation” for algorithmic decisions but the
    intended scope and methodology are still unclear.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）正在取代所有行业的软件。随着越来越多的自动化，更多的模型被部署到云端，而**人工智能物联网**（**AIoT**）的出现将使情况变得更糟。部署并不是传统上属于机器学习实践者的领域。这就是为什么机器学习越来越多地依赖于**机器学习运维**（**MLOps**）。自动化速度的加快意味着需要更多的工具来构建、测试、部署和监控这些模型。同时，还需要对工具、方法和指标进行标准化。虽然这个过程缓慢但确实在发生。自2017年以来，我们已经有了**开放神经网络交换**（**ONNX**），这是一个用于互操作性的开放标准。在撰写本文时，**国际标准化组织**（**ISO**）正在编写超过二十项AI标准（其中一项已发布），其中一些涉及可解释性。自然地，由于机器学习模型类别、方法、库、服务提供商和实践的整合，一些事物将因常用而标准化。随着时间的推移，每个领域都将出现一或几个。最后，鉴于机器学习在算法决策中的重要作用，它被监管只是时间问题。只有一些金融市场监管交易算法，例如美国的**证券交易委员会**（**SEC**）和英国的**金融服务管理局**（**FCA**）。除此之外，只有数据隐私和来源法规得到广泛执行，例如美国的HIPAA和巴西的LGPD。欧盟的**通用数据保护条例**（**GDPR**）在算法决策的“解释权”方面更进一步，但预期的范围和方法仍然不明确。
- en: '**XAI versus IML – which one to use?**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**可解释人工智能（XAI）与机器学习（IML）——哪一个该使用？**'
- en: 'My take: although they are understood as synonyms in industry and *iML* is
    regarded as more of an academic term, ML practitioners, even those in industry,
    should be wary about using the term *XAI*. Words can have outsized suggestive
    power. *Explainable* presumes full understanding, but *interpretable* leaves room
    for error, as there always should be when talking about models, and extraordinarily
    complex black-box ones at that. Furthermore, AI has captured the public imagination
    as a panacea or has been vilified as dangerous. Either way, along with the term
    *explainable*, it serves to make it even more filled with hubris for those who
    think it’s a panacea and perhaps calm some concerns for those who think it’s dangerous.
    XAI term might be serving a purpose as a marketing term. However, for those who
    build models, the suggestive power of the word *explainable* can make us overconfident
    in our interpretations. That being said, this is just an opinion.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我的看法：尽管在行业中它们被视为同义词，且*iML*被视为更学术性的术语，但机器学习实践者，即使在工业界，也应该对使用*iML*这个术语持谨慎态度。词语可能具有过大的暗示力。*可解释性*意味着完全理解，但*可解释性*留有出错的空间，这在讨论模型时总是应该如此，尤其是对于极其复杂的黑盒模型。此外，人工智能被公众想象为万能的灵丹妙药，或者被诋毁为危险的。无论哪种情况，与*iML*这个术语一样，它都使得那些认为它是万能灵丹妙药的人更加自大，也许可以平息那些认为它是危险的人的担忧。XAI这个术语可能作为一个营销术语在发挥作用。然而，对于构建模型的人来说，*可解释性*这个词语的暗示力可能会让我们对自己的解释过于自信。话虽如此，这仅仅是一个观点。
- en: ML interpretability is growing quickly but is lagging behind ML. Some interpretation
    tools have been integrated into the cloud ecosystem, from SageMaker to DataRobot.
    They are yet to be fully automated, standardized, consolidated, and regulated,
    but there’s no doubt that this will happen.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习可解释性正在快速发展，但落后于机器学习。一些解释工具已经集成到云生态系统中，从SageMaker到DataRobot。它们尚未完全自动化、标准化、整合和监管，但毫无疑问，这将会发生。
- en: Speculating on the future of ML interpretability
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对机器学习可解释性的未来进行推测
- en: I’m used to hearing the metaphor of this period being the “Wild West of AI”,
    or worse, an “AI Gold Rush!” It conjures images of an unexplored and untamed territory
    being eagerly conquered, or worse, civilized. Yet, in the 19th century, the United
    States western areas were not too different from other regions on the planet and
    had already been inhabited by Native Americans for millennia, so the metaphor
    doesn’t quite work. Predicting with the accuracy and confidence that we can achieve
    with ML would spook our ancestors and is not a “natural” position for us humans.
    It’s more akin to flying than exploring unknown land.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我习惯了听到这个时期被比喻为“人工智能的蛮荒西部”，或者更糟糕的是，“人工智能淘金热”！这让人联想到一个未开发、未驯服的领土被急切地征服，或者更糟糕的是，被文明化。然而，在19世纪，美国的西部地区与其他地区的地球上的其他地区并没有太大的不同，并且已经被美洲原住民居住了数千年，所以这个比喻并不完全适用。用我们能够通过机器学习实现的准确性和信心来预测，会让我们的祖先感到惊恐，并且对我们人类来说，这并不是一个“自然”的位置。这更像是飞行而不是探索未知土地。
- en: The article *Toward the Jet Age of machine learning* (linked in the *Further
    reading* section at the end of this chapter) presents a much more fitting metaphor
    of AI being like the dawn of aviation. It’s new and exciting, and people still
    marvel at what we can do from down below (see *Figure 14.4*)!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 文章《迈向机器学习的喷气时代》（在本章末尾的“进一步阅读”部分链接）提出了一个更适合的比喻，即人工智能就像航空业的黎明。它是新的、令人兴奋的，人们仍然对我们从下面能做什么感到惊奇（见图14.4）！
- en: 'However, aviation had yet to fulfill its potential. Decades after the barnstorming
    era, aviation matured into the safe, reliable, and efficient Jet Age of **commercial
    aviation**. In the case of aviation, the promise was that it could reliably take
    goods and people halfway around the world in less than a day. In AI’s case, the
    promise is that it can make fair, accountable, and transparent decisions – maybe
    not for any decision, but at least those it was designed to make unless it’s an
    example of **Artificial General Intelligence** (**AGI**):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，航空业还有待发挥其潜力。在 barnstorming 时代几十年后，航空业成熟为安全、可靠和高效的商业航空喷气时代。在航空业的情况下，承诺是它可以在不到一天的时间内可靠地将货物和人员运送到地球另一半。在人工智能的情况下，承诺是它可以做出公平、负责任和透明的决策——也许不是针对任何决策，但至少是它被设计去做的决策，除非它是**通用人工智能**（**AGI**）的例子：
- en: '![A picture containing text, outdoor, old  Description automatically generated](img/18406_14_04.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本、户外、旧式描述自动生成](img/18406_14_04.png)'
- en: 'Figure 14.4: Barnstorming during the 1920s (United States Library of Congress’s
    Prints and Photographs Division)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4：20世纪20年代的barnstorming（美国国会图书馆的印刷与照片部）
- en: So how do we get there? The following are a few ideas I anticipate will occur
    in the pursuit of reaching the Jet Age of ML.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何才能达到那里？以下是我预期在追求达到机器学习喷气时代的过程中可能会发生的一些想法。
- en: A new vision for ML
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的新愿景
- en: As we intend to go farther with AI than we have ever gone before, the ML practitioners
    of tomorrow must be more aware of the dangers of the sky. And by the sky, I mean
    the new frontiers of predictive and prescriptive analytics. The risks are numerous
    and involve all kinds of biases and assumptions, problems with data both known
    and potential, and our models’ mathematical properties and limitations. It’s easy
    to be deceived by ML models thinking they are software. Still, in this analogy,
    the software is completely deterministic in nature – it’s solidly anchored to
    the ground, not hovering in the sky!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们打算在人工智能方面走得更远，比以往任何时候都要远，明天的机器学习从业者必须更加意识到天空的危险。在这里，我指的是预测和规范性分析的新前沿。风险众多，涉及各种偏见和假设，已知和潜在的数据问题，以及我们模型的数学属性和局限性。很容易被机器学习模型欺骗，认为它们是软件。然而，在这个类比中，软件在本质上是完全确定性的——它牢牢地扎根于地面，而不是在天空中悬浮！
- en: For civil aviation to become safe, it required a new mindset – a new culture.
    The fighter pilots of WWII, as capable as they were, had to be retrained to work
    in civil aviation. It’s not the same mission because when you know that you are
    carrying passengers on board and the stakes are high, everything changes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使民用航空变得安全，需要一种新的思维方式——一种新的文化。二战时期的战斗机飞行员，尽管他们能力出众，但也必须重新训练以在民用航空中工作。这不是同一个任务，因为当你知道你正在携带乘客，并且风险很高时，一切都会改变。
- en: Ethical AI, and by extension, iML, ultimately require this awareness that models
    directly or indirectly carry passengers “on board,” and that models aren’t as
    robust as they seem. A robust model must be able to reliably withstand almost
    any condition over and over again in the same way the planes of today do. To that
    end, we need to be using more instruments, and those instruments come in the form
    of interpretation methods.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 伦理AI，以及由此产生的iML，最终需要这种认识，即模型直接或间接地携带乘客“在船上”，并且模型并不像看起来那样稳健。一个稳健的模型必须能够可靠地经受住几乎任何条件，一次又一次地，就像今天的飞机一样。为此，我们需要使用更多的工具，这些工具以解释方法的形式出现。
- en: A multidisciplinary approach
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多学科方法
- en: Tighter integration with many disciplines is needed for models that comply with
    the principles of FAT. This means more significant involvement of AI ethicists,
    lawyers, sociologists, psychologists, human-centered designers, and countless
    other professions. Along with AI technologists and software engineers, they will
    help code best practices into standards and regulations.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于符合FAT原则的模型，需要与许多学科更紧密地集成。这意味着AI伦理学家、律师、社会学家、心理学家、以人为本的设计师以及无数其他职业的更大参与。他们将与AI技术专家和软件工程师一起，将最佳实践编码到标准和法规中。
- en: Adequate standardization
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 足够的标准化
- en: New standards will be needed not only for code, metrics, and methodologies but
    also for language. The language behind data has mostly been derived from statistics,
    math, computer science, and econometrics, which leads to a lot of confusion.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅需要新的标准来规范代码、指标和方法，还需要规范语言。数据背后的语言主要来自统计学、数学、计算机科学和计量经济学，这导致了很多混淆。
- en: Enforcing regulation
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行监管
- en: 'It will likely be required that all production models fulfill the following
    specifications:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能需要所有生产模型满足以下规范：
- en: Are certifiably robust and fair
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够通过认证证明其稳健和公平
- en: Are capable of explaining their reasoning behind one prediction with a TRACE
    command and, in some cases, are required to deliver the reasoning with the prediction
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够使用TRACE命令解释其预测背后的推理，在某些情况下，还必须与预测一起提供推理
- en: Can abstain from a prediction they aren’t confident about
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以拒绝他们不确定的预测
- en: Yield confidence levels for all predictions (see the **conformal prediction**
    tutorial and book in the *Further reading* section)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为所有预测提供置信水平（参见“进一步阅读”部分的**一致性预测**教程和书籍）
- en: Have metadata with training data provenance (even if anonymized) and authorship
    and, when needed, regulatory compliance certificates and metadata tied to a public
    ledger – possibly a blockchain
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有训练数据的元数据（即使匿名）和作者身份，以及必要时，符合监管要求的证书和与公共账本（可能是区块链）相关的元数据
- en: Have security certificates much like websites do to ensure a certain level of
    trust
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有类似于网站的证书，以确保一定程度的信任
- en: Expire, and stop working upon expiration, until they are retrained with new
    data
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过期后停止工作，直到用新数据进行重新训练
- en: Be taken offline automatically when they fail model diagnostics and only put
    online again when they pass
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当它们在模型诊断失败时自动离线，并且只有通过诊断后才能再次上线
- en: Have **Continuous Training/Continuous Integration** (**CT/CI**) pipelines that
    help retrain the model and perform the model diagnostics at regular intervals
    to avoid any model downtime
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有**持续训练/持续集成**（**CT/CI**）管道，帮助定期重新训练模型并执行模型诊断，以避免任何模型停机时间
- en: Are diagnosed by a certified AI auditor when they fail catastrophically and
    cause public damage
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当它们在灾难性失败并造成公共损害时，由认证的AI审计师进行诊断
- en: New regulations will likely create new professions such as AI auditors and model
    diagnostics engineers. But they will also prop up MLOps engineers and ML automation
    tools.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 新法规可能会催生新的职业，例如AI审计师和模型诊断工程师。但它们也将支持MLOps工程师和ML自动化工具。
- en: Seamless machine learning automation with built-in interpretation
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 具有内置解释的无缝机器学习自动化
- en: In the future, we won’t program an ML pipeline; it will mostly be a drag-and-drop
    capability with a dashboard offering all kinds of metrics. It will evolve to be
    mostly automated. Automation shouldn’t come as a surprise because some existing
    libraries perform automated feature-selection model training. Some interpretability-enhancing
    procedures may be done automatically, but most of them will require human discretion.
    However, interpretation ought to be injected throughout the process, much like
    planes that mostly fly themselves have instruments that alert pilots of issues;
    the value is in informing the ML practitioner of potential problems and improvements
    at every step. Did it find a feature to recommend for monotonic constraints? Did
    it find some imbalances that might need adjusting? Did it find anomalies in the
    data that might need some correction? Show the practitioner what needs to be seen
    to make an informed decision and let them make it.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，我们不会编写ML管道；它将主要是一个拖放功能，带有仪表板提供各种指标。它将主要实现自动化。自动化不应令人惊讶，因为一些现有的库执行自动特征选择模型训练。一些增强可解释性的程序可能自动执行，但大多数程序将需要人工判断。然而，解释应该贯穿整个流程，就像大多数飞机主要由自己飞行，但飞机上仍然有仪器提醒飞行员问题一样；价值在于向机器学习实践者提供每一步的潜在问题和改进信息。它是否找到了推荐用于单调约束的特征？它是否发现了可能需要调整的一些不平衡？它是否发现了可能需要一些纠正的数据异常？向实践者展示他们需要看到的内容，以便做出明智的决定，并让他们做出决定。
- en: Tighter integration with MLOps engineers
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与MLOps工程师更紧密的集成
- en: Certifiably robust models trained, validated, and deployed at a click of a button
    require more than just cloud infrastructure – they also need the orchestration
    of tools, configurations, and people trained in MLOps to monitor them and perform
    maintenance at regular intervals.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一键操作训练、验证和部署的、可认证的稳健模型需要的不只是云基础设施，还需要工具、配置以及接受过MLOps培训的人员来监控它们并在定期间隔进行维护。
- en: Summary
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Interpretable machine learning is an extensive topic, and this book has only
    covered some aspects of some of its most important areas on two levels: diagnosis
    and treatment. Practitioners can leverage the tools offered by the toolkit anywhere
    in the ML pipeline. However, it’s up to the practitioner to choose when and how
    to apply them.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释机器学习是一个广泛的话题，本书只覆盖了其最重要领域的一些方面，在诊断和治疗两个层面上进行了探讨。实践者可以在机器学习管道的任何地方利用工具包提供的工具。然而，选择何时以及如何应用它们取决于实践者。
- en: What matters most is to engage with the tools. Not using the interpretable machine
    learning toolkit is like flying a plane with very few instruments or none at all.
    Much like flying a plane operates under different weather conditions, machine
    learning models operate under different data conditions, and to be a skilled pilot
    or machine learning engineer, we can’t be overconfident and validate or rule out
    hypotheses with our instruments. And much like aviation took a few decades to
    become the safest mode of transportation, it will take AI a few decades to become
    the safest mode of decision-making. It will take a global village to get us there,
    but it will be an exciting journey! And remember, *the best way to predict the
    future is to create it*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是要熟悉工具。不使用可解释的机器学习工具包就像驾驶一架几乎没有仪器或完全没有仪器的飞机。就像驾驶飞机在不同的天气条件下运行一样，机器学习模型在不同的数据条件下运行，要成为一名熟练的飞行员或机器学习工程师，我们不能过于自信，而应该用我们的仪器来验证或排除假设。就像航空业花了几十年才成为最安全的交通方式一样，人工智能也需要几十年才能成为最安全的决策方式。这将需要全球村子的共同努力，但这将是一次激动人心的旅程！记住，*预测未来的最好方法就是创造它*。
- en: Further reading
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Joury, A., 2022, January 6, *Why 90% of machine learning models never hit the
    market*. TNW | Neural. Retrieved December 4, 2022: [https://thenextweb.com/news/why-most-machine-learning-models-never-hit-market-syndication](https://thenextweb.com/news/why-most-machine-learning-models-never-hit-market-syndication)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Joury, A., 2022, January 6, *Why 90% of machine learning models never hit the
    market*. TNW | Neural. Retrieved December 4, 2022: [https://thenextweb.com/news/why-most-machine-learning-models-never-hit-market-syndication](https://thenextweb.com/news/why-most-machine-learning-models-never-hit-market-syndication)'
- en: 'Wiggers, K., 2019, July 8, *IDC: For 1 in 4 companies, half of all AI projects
    fail*. VentureBeat. Retrieved December 4, 2022: [https://venturebeat.com/ai/idc-for-1-in-4-companies-half-of-all-ai-projects-fail/](https://venturebeat.com/ai/idc-for-1-in-4-companies-half-of-all-ai-projects-fail/)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wiggers, K., 2019, July 8, *IDC: For 1 in 4 companies, half of all AI projects
    fail*. VentureBeat. Retrieved December 4, 2022: [https://venturebeat.com/ai/idc-for-1-in-4-companies-half-of-all-ai-projects-fail/](https://venturebeat.com/ai/idc-for-1-in-4-companies-half-of-all-ai-projects-fail/)'
- en: O’Neil, C., 2017, *Weapons of Math Destruction*. Penguin Books.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O’Neil, C., 2017，*数学破坏武器*。企鹅图书。
- en: 'Talwalkar, A., 2018, April 25, *Toward the Jet Age of machine learning*. O’Reilly:
    [https://www.oreilly.com/content/toward-the-jet-age-of-machine-learning/](https://www.oreilly.com/content/toward-the-jet-age-of-machine-learning/)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Talwalkar, A., 2018年4月25日，*迈向机器学习的喷气时代*。O’Reilly：[https://www.oreilly.com/content/toward-the-jet-age-of-machine-learning/](https://www.oreilly.com/content/toward-the-jet-age-of-machine-learning/)
- en: 'Rajiv, S., 2022, September 22, *Getting predictions intervals with conformal
    inference*. Getting predictions intervals with conformal inference · Rajiv Shah’s
    Projects Blog. Retrieved December 4, 2022: [http://projects.rajivshah.com/blog/2022/09/24/conformal_predictions/](http://projects.rajivshah.com/blog/2022/09/24/conformal_predictions/)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajiv, S., 2022年9月22日，*使用对齐推理获取预测区间*。获取预测区间使用对齐推理 · Rajiv Shah 的项目博客。2022年12月4日检索：[http://projects.rajivshah.com/blog/2022/09/24/conformal_predictions/](http://projects.rajivshah.com/blog/2022/09/24/conformal_predictions/)
- en: 'Angelopoulos, A.N., and Bates, S., 2021, *A Gentle Introduction to Conformal
    Prediction and Distribution-Free Uncertainty Quantification*: [https://arxiv.org/abs/2107.07511](https://arxiv.org/abs/2107.07511)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Angelopoulos, A.N., 和 Bates, S., 2021, *《对齐预测与无分布不确定性量化入门》*：[https://arxiv.org/abs/2107.07511](https://arxiv.org/abs/2107.07511)
- en: Learn more on Discord
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Discord 上了解更多
- en: 'To join the Discord community for this book – where you can share feedback,
    ask the author questions, and learn about new releases – follow the QR code below:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要加入这本书的 Discord 社区——在那里你可以分享反馈、向作者提问，并了解新书发布——请扫描下面的二维码：
- en: '[https://packt.link/inml](Chapter_14.xhtml)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/inml](Chapter_14.xhtml)'
- en: '![](img/QR_Code107161072033138125.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code107161072033138125.png)'
