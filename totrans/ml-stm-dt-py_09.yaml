- en: '*Chapter 7*: Online Regression'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After looking at online anomaly detection and online classification throughout
    the previous chapters, there is one large category of online machine learning
    that remains to be seen. **Regression** is the family of supervised machine learning
    models that applies to use cases in which the target variable is numerical.
  prefs: []
  type: TYPE_NORMAL
- en: In anomaly detection and classification, you have seen how to build models to
    predict categorical targets (yes/no and iris species), but you have not yet seen
    how to work with a target that is numerical. Working with numerical data requires
    having methods that work differently, both in the deeper layers of model training
    and model definition and also in our use of metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine being a weather forecaster trying to forecast the temperature (Celsius)
    for tomorrow. Maybe you expect a sunny day, and you have a model that you use
    to predict a temperature of 25 degrees Celsius. Imagine if the next day, you observe
    that it is cold and only 18 degrees; you were clearly wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Now, imagine that you predicted 24 degrees. In a classification use case, you
    may tend to say that 25 is not 24, so the result is wrong. However, the result
    of 24 is *less wrong* than the result of 18.
  prefs: []
  type: TYPE_NORMAL
- en: In regression, one single prediction can be more or less wrong. In practice,
    you will rarely be entirely right. In classification, you are either wrong or
    right, so this is different. This introduces a need for new metrics and a change
    in the model benchmarking process.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will first get a deeper introduction to regression models,
    focusing on online regression models in River. After that, you'll be working on
    a regression model benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use cases of regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of regression algorithms in River
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can find all the code for this book on GitHub at the following link: [https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python](https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python).
    If you are not yet familiar with Git and GitHub, the easiest way to download the
    notebooks and code samples is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to the link of the repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the green **Code** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Download ZIP**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you download the ZIP file, unzip it in your local environment, and you
    will be able to access the code through your preferred Python editor.
  prefs: []
  type: TYPE_NORMAL
- en: Python environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To follow along with this book, you can download the code in the repository
    and execute it using your preferred Python editor.
  prefs: []
  type: TYPE_NORMAL
- en: If you are not yet familiar with Python environments, I would advise you to
    check out Anaconda ([https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)),
    which comes with Jupyter Notebook and JupyterLab, which are both great for executing
    notebooks. It also comes with Spyder and VS Code for editing scripts and programs.
  prefs: []
  type: TYPE_NORMAL
- en: If you have difficulty installing Python or the associated programs on your
    machine, you can check out Google Colab ([https://colab.research.google.com/](https://colab.research.google.com/))
    or Kaggle Notebooks ([https://www.kaggle.com/code](https://www.kaggle.com/code)),
    which both allow you to run Python code in online notebooks for free, without
    any setup required.
  prefs: []
  type: TYPE_NORMAL
- en: Defining regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will discover regression. Regression is a supervised machine
    learning task in which a model is constructed that predicts or estimates a numerical
    target variable based on numerical or categorical independent variables.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest type of regression model is **linear regression**. Let's consider
    a super simple example of how a linear regression could be used for regression.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that we have a dataset in which we have observations of 10 people. Based
    on the number of hours they study per week, we have to estimate their average
    grade (on a 1 to 10 scale). Of course, this is a strongly oversimplified problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Code Block 7-1
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You will obtain the following data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – The dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_07_1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.1 – The dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s plot the data to see how this can be made into a regression problem:'
  prefs: []
  type: TYPE_NORMAL
- en: Code Block 7-2
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – A scatter plot of the data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_07_2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.2 – A scatter plot of the data
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, the goal of linear regression is to fit the line (or hyperplane) that
    best goes through these points and is able to predict an estimated `avg_grades`
    for any `nb_hrs_studies`. Other regression models each have their specific way
    to construct the prediction function, but eventually have the same goal: creating
    the best fitting formula to predict a numerical target variable using one or more
    independent variables.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you'll discover some example use cases in which regression
    can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases of regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The use cases of regression are huge: it is a very commonly used method in
    many projects. Still, let''s see some examples to get a better idea of the different
    types of use cases that can benefit from regression models.'
  prefs: []
  type: TYPE_NORMAL
- en: Use case 1 – Forecasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A very common use case for regression algorithms is forecasting. In forecasting,
    the goal is to predict future values of a variable that is measured over time.
    Such variables are called **time series**. Although a number of specific methods
    exist for time series modeling, regression models are also great contenders for
    obtaining good performance on future prediction performance.
  prefs: []
  type: TYPE_NORMAL
- en: In some forecasting use cases, real-time responses are very important. An example
    is stock trading, in which the datapoints of stock prices arrive at a huge velocity
    and forecasts have to be adapted straight away to use the best possible information
    for stock trades. Even automated stock trading algorithms exist, and they need
    to react fast in order to make the most profit on their trades as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'For further reading on this topic, you could start by checking out the following
    links:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.investopedia.com/articles/financial-theory/09/regression-analysis-basics-business.asp](https://www.investopedia.com/articles/financial-theory/09/regression-analysis-basics-business.asp)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.mathworks.com/help/econ/time-series-regression-vii-forecasting.html](https://www.mathworks.com/help/econ/time-series-regression-vii-forecasting.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use case 2 – Predicting the number of faulty products in manufacturing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second example of real-time and streaming regression models being used in
    practice is the application of predictive maintenance models in manufacturing.
    For example, you could use a real-time prediction of the number of faulty products
    per hour in a production line. This would be a regression model as well, as the
    outcome is a number rather than a categorical variable.
  prefs: []
  type: TYPE_NORMAL
- en: The production line could use this prediction for a real-time alerting system,
    for example, once a threshold of faulty products is predicted to be reached. Real-time
    data integration is important for this, as having the wrong products being produced
    is a large waste of resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following two resources will allow you to read more about this use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.sciencedirect.com/science/article/pii/S2405896316308084](https://www.sciencedirect.com/science/article/pii/S2405896316308084)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.researchgate.net/publication/315855789_Regression_Models_for_Lean_Production](https://www.researchgate.net/publication/315855789_Regression_Models_for_Lean_Production)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have explored some use cases of regression, let's get started with
    the various algorithms that we have for regression.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of regression algorithms in River
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a large number of online regression models available in the River online
    machine learning package.
  prefs: []
  type: TYPE_NORMAL
- en: 'A selection of relevant ones are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`LinearRegression`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`HoeffdingAdaptiveTreeRegressor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SGTRegressor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SRPRegressor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression algorithm 1 – LinearRegression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Linear regression is one of the most basic regression models. A simple linear
    regression is a regression model that fits a straight line through the datapoints.
    The following graph illustrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – A linear model in a scatter plot'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_07_3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.3 – A linear model in a scatter plot
  prefs: []
  type: TYPE_NORMAL
- en: 'This orange line is a result of the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Formula_07_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *y* represents `avg_grades` and *x* represents `nb_hrs_studies`. When
    fitting the model, the *a* and *b* coefficients are estimates. The *b* coefficient
    in this formula is called the intercept. It indicates the value of *y* when *x*
    equals `0`. The *a* coefficient represents the slope of the line. For each additional
    step in *x*, *a* indicates the amount that is added to *y*.
  prefs: []
  type: TYPE_NORMAL
- en: This is a version of linear regression, but there is also a version called **multiple
    linear regression**, in which there are multiple *x* variables. In this case,
    the model does not represent a line but rather a hyperplane, in which a slope
    coefficient is added for each additional *x* variable.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression in River
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s now move on to build an example of online linear regression using River
    ML in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you remember from the previous example, we used a function called `make_classification`
    from `scikit-learn`. The same can be done for regression problems using `make_regression`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-3
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'To get a better idea of what has resulted from this `make_regression` function,
    let''s inspect `X` of this dataset. You can use the following code to get a quick
    overview of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-4
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `describe()` method will put out a data frame with descriptive statistics
    of the variables, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – Descriptive statistics'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_07_4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.4 – Descriptive statistics
  prefs: []
  type: TYPE_NORMAL
- en: There are five columns in the `X` data, and there are 1,000 observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, to look at the `y` variable, also called the `target` variable, we can
    make a histogram as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-5
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting histogram can be seen in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5 – The resulting histogram'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_07_5.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.5 – The resulting histogram
  prefs: []
  type: TYPE_NORMAL
- en: There is much more exploratory data analysis that could be done here, but that
    would be out of scope for this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now move on to the creation of a train and test set to create a fair
    model validation approach. In the following code, you can see how to create the
    `train_test_split` function from `scikit-learn` to create a train-test split:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-6
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You can create the linear regression in River using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-7
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This model then has to be fitted to the training data. We use the same loop
    as you have seen earlier on in the book. This loop goes through the individual
    datapoints (`X` and `y`) and converts the `X` values into a dictionary, as required
    by River. The model is then updated datapoint by datapoint using the `learn_one`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-8
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the model has learned from the training data, it needs to be evaluated
    on the test set. This can be done by looping through the test data and making
    a prediction for the `X` values of each datapoint. The `y` values are stored in
    a list for evaluation against the actual `y` values of the test dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-9
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now compute the metric of our choice for this regression model, for
    example, the `r2` score. This can be done using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-10
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The obtained result is `0.478`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's find out whether other models are more performant at this task in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Regression algorithm 2 – HoeffdingAdaptiveTreeRegressor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second online regression model that we'll cover is a much more specific
    model for online regression. Whereas the `LinearRegression` model, just like many
    other models, is an online adaptation of an essentially offline model, many other
    models are developed specifically for online models. `HoeffdingAdaptiveTreeRegressor`
    is one of those.
  prefs: []
  type: TYPE_NORMAL
- en: The **Hoeffding Adaptive Tree regressor** (**HATR**) is a regression model that
    is based on the **Hoeffding Adaptive Tree Classifier** (**HATC**). HATC is a tree-based
    model that uses the **adaptive windowing** (**ADWIN**) methodology to monitor
    the performance of the different branches of a tree. The HATC methodology replaces
    the branches with new branches when their time is due. This is determined by observing
    the better performance of the new branches by the old branches. HATC is also available
    in River.
  prefs: []
  type: TYPE_NORMAL
- en: The HATR regression version is based on the HATC approach and uses an ADWIN
    concept-drift detector at each decision node. This allows the method to detect
    possible changes in the underlying data, which is called **drift**. Drift detection
    will be covered in more detail in a further chapter.
  prefs: []
  type: TYPE_NORMAL
- en: HoeffdingAdaptiveTreeRegressor in River
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will check out an example as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get started with fitting the model on the same data as we used in the
    previous model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-11
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This model obtains an `r2` score that is a little worse than the linear regression:
    `0.437`. Let''s see if we can do something to make it work better. Let''s write
    a grid search to see whether a number of hyperparameters can help to improve the
    model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For this, let''s write the model as a function that takes values for the hyperparameters
    and that returns the `r2` score:'
  prefs: []
  type: TYPE_NORMAL
- en: Code Block 7-12
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s specify the hyperparameters to tune as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We then loop through the data as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The results can then be obtained as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The obtained result is slightly disappointing, as none of the tested values
    were able to generate a better result. Unfortunately, this is part of data science,
    as not all models work well on each use case.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6 – The resulting output of Code Block 7-15'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_07_6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.6 – The resulting output of Code Block 7-15
  prefs: []
  type: TYPE_NORMAL
- en: Let's move on to the next model and see whether it fits better.
  prefs: []
  type: TYPE_NORMAL
- en: Regression algorithm 3 – SGTRegressor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`SGTRegressor` is a stochastic gradient tree for regression. It is another
    decision tree-based model that can learn with new data arriving. It is an incremental
    decision tree that minimizes the mean squared error by minimizing the loss function.'
  prefs: []
  type: TYPE_NORMAL
- en: SGTRegressor in River
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We''ll check this out using the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test whether this model can improve the performance of this regression
    task:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is worse than the previous models, as it is `0.07`. Let''s again
    see whether it can be optimized using hyperparameter tuning:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'For this trial, we''ll optimize the `grace_period`, `lambda_value`, and `delta`
    hyperparameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'You can run the optimization loop using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-19
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The best results can be shown using the following line of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is shown in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7 – The resulting output of Code Block 7-20'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_07_7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.7 – The resulting output of Code Block 7-20
  prefs: []
  type: TYPE_NORMAL
- en: The result is better than the non-tuned `SGTRegressor`, but much worse than
    the previous two models. The model could be optimized further, but it does not
    seem the best go-to for the current data.
  prefs: []
  type: TYPE_NORMAL
- en: Regression algorithm 4 – SRPRegressor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`SRPRegressor`, or **Streaming Random Patches regressor**, is an ensemble method
    that trains an ensemble of base learners on subsets of the input data. These subsets
    are called **patches** and are both subsets of features and subsets of observations.
    This is the same approach as the **random forest** that was seen in the previous
    chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: SRPRegressor in River
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will check this out using the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, let''s use linear regression as a base learner, as this model
    has had the best performance compared to the other models tested in this chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting score is `0.34`. Let''s try and tune the number of models used
    to see whether this can improve performance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'You can execute the tuning loop with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The following line shows the results for each value of `n_models`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code Block 7-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is shown in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.8 – The resulting output of Code Block 7-24'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18335_07_8.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.8 – The resulting output of Code Block 7-24
  prefs: []
  type: TYPE_NORMAL
- en: Apparently, the result at 12 models has found a sweet spot at which the performance
    is `0.457`. Compared to the simple `LinearRegression` model with a score of `0.478`,
    this is a worse result. This indicates that the `LinearRegression` model has the
    best score of the four models tested in this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this result is strongly related to the data-generating process that
    is behind the `make_regression` function. If the `make_regression` function were
    to add anything such as time trends, the adaptive models would probably have been
    more performant than the simple linear model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have seen the basics of regression modeling. You have learned
    that there are some similarities between classification and anomaly detection
    models, but that there are also some fundamental differences.
  prefs: []
  type: TYPE_NORMAL
- en: The main difference in regression is that the target variables are numeric,
    whereas they are categorical in classification. This introduces a difference in
    metrics, but also in the model definition and the way the models work deep down.
  prefs: []
  type: TYPE_NORMAL
- en: You have seen several traditional, offline regression models and their adaptation
    to working in an online training manner. You have also seen some online regression
    models that are made specifically for online training and streaming.
  prefs: []
  type: TYPE_NORMAL
- en: As in the previous chapters, you have seen how to implement a modeling benchmark
    using a train-test set. The field of ML does not stop evolving, and newer and
    better models are published regularly. This introduces the need for practitioners
    to be solid in their skills to evaluate models.
  prefs: []
  type: TYPE_NORMAL
- en: Mastering model evaluation is often even more important than knowing the largest
    list of models. You need to know a large number of models to start modeling, but
    it is the evaluation that will allow you to avoid pushing erroneous or overfitted
    models into production.
  prefs: []
  type: TYPE_NORMAL
- en: Although this is generally true for ML, the next chapter will introduce a category
    of models that has a fundamentally different take on this. Reinforcement learning
    is a category of online ML in which the focus is on model updating. Online models
    have the capacity to learn on each piece of data that gets into the system as
    well, but reinforcement learning is focused even more on having almost autonomous
    learning. This will be the scope of the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*LinearRegression*: [https://riverml.xyz/latest/api/linear-model/LinearRegression/](https://riverml.xyz/latest/api/linear-model/LinearRegression/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Make_regression*: [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*HoeffdingAdaptiveTreeRegressor*: [https://riverml.xyz/latest/api/tree/HoeffdingAdaptiveTreeRegressor/](https://riverml.xyz/latest/api/tree/HoeffdingAdaptiveTreeRegressor/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*HoeffdingAdaptiveTreeClassifier*: [https://riverml.xyz/latest/api/tree/HoeffdingAdaptiveTreeClassifier/](https://riverml.xyz/latest/api/tree/HoeffdingAdaptiveTreeClassifier/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Adaptive learning and mining for data streams and frequent patterns*: [https://dl.acm.org/doi/abs/10.1145/1656274.1656287](https://dl.acm.org/doi/abs/10.1145/1656274.1656287)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*SGTRegressor*: [https://riverml.xyz/latest/api/tree/SGTRegressor/](https://riverml.xyz/latest/api/tree/SGTRegressor/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*SRPRegressor*: [https://riverml.xyz/latest/api/ensemble/SRPRegressor/](https://riverml.xyz/latest/api/ensemble/SRPRegressor/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
