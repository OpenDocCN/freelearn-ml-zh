<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer013">
<h1 class="chapter-number" id="_idParaDest-15"><a id="_idTextAnchor014"/>1</h1>
<h1 id="_idParaDest-16"><a id="_idTextAnchor015"/>Machine Learning and the Need for Data</h1>
<p><strong class="bold">Machine learning</strong> (<strong class="bold">ML</strong>) is the crown jewel of <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) and has changed our lives forever. We cannot imagine our daily lives without ML tools and services such as Siri, Tesla, <span class="No-Break">and others.</span></p>
<p>In this chapter, you will be introduced to ML. You will understand the main differences between non-learning and learning-based solutions. Then, you will see why <strong class="bold">deep learning</strong> (<strong class="bold">DL</strong>) models often achieve state-of-the-art results. Following this, you will get a brief introduction to how the training process is done and why large-scale training data is needed <span class="No-Break">in ML.</span></p>
<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>AI, ML, <span class="No-Break">and DL</span></li>
<li><a id="_idTextAnchor016"/>Why are ML and DL <span class="No-Break">so powerful?</span></li>
<li>Training <span class="No-Break">ML models</span></li>
</ul>
<h1 id="_idParaDest-17"><a id="_idTextAnchor017"/>Technical requirements</h1>
<p>Any code used in this chapter will be available in the corresponding chapter folder in this book’s GitHub <span class="No-Break">repository: </span><a href="https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning"><span class="No-Break">https://github.com/PacktPublishing/Synthetic-Data-for-Machine-Learning</span></a><span class="No-Break">.</span></p>
<p>We will be using <strong class="bold">PyTorch</strong>, which is a powerful ML framework developed by <span class="No-Break">Meta AI.</span></p>
<h1 id="_idParaDest-18"><a id="_idTextAnchor018"/>Artificial intelligence, machine learning, and deep learning</h1>
<p>In this section, we learn what exactly ML is. We will learn to differentiate between learning and non-learning AI. However, before that, we’ll introduce ourselves to AI, ML, <span class="No-Break">and DL.</span></p>
<h2 id="_idParaDest-19"><a id="_idTextAnchor019"/>Artificial intelligence (AI)</h2>
<p>There are different definitions<a id="_idIndexMarker000"/> of AI. However, one of the best is John McCarthy’s definition. McCarthy was the first to coin the term <em class="italic">artificial intelligence</em> in one of his proposals for the 1956 Dartmouth Conference. He defined the outlines of this field by many major contributions such as the Lisp programming language, utility computing, and timesharing. According to the father of AI in <em class="italic">What is Artificial </em><span class="No-Break"><em class="italic">Intelligence?</em></span><span class="No-Break"> (</span><a href="https://www-formal.stanford.edu/jmc/whatisai.pdf"><span class="No-Break">https://www-formal.stanford.edu/jmc/whatisai.pdf</span></a><span class="No-Break">):</span></p>
<p class="author-quote">It is the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence, but AI does not have to confine itself to methods that are biologically observable.</p>
<p>AI is about making computers, programs, machines, or others mimic or imitate human intelligence. As humans, we perceive the world, which is a very complex task, and we reason, generalize, plan, and interact with our surroundings. Although it is fascinating to master these tasks within just a few years of our childhood, the most interesting aspect of our intelligence is the ability to improve the learning process and optimize performance <span class="No-Break">through experience!</span></p>
<p>Unfortunately, we still barely scratch the surface of knowing about our own brains, intelligence, and other associated functionalities such as vision and reasoning. Thus, the trek of creating “intelligent” machines has just started relatively recently in civilization and written history. One of the most flourishing directions of AI has been <span class="No-Break">learning-based AI.</span></p>
<p>AI can be seen as an umbrella that covers two types of intelligence: learning and non-learning AI. It is important to distinguish between AI that improves with experience and one that <span class="No-Break">does not!</span></p>
<p>For example, let’s say you want to use AI to improve the accuracy of a physician identifying a certain disease, given a set of symptoms. You can create a simple recommendation system based on some generic cases by asking domain experts (senior physicians). The pseudocode<a id="_idIndexMarker001"/> for such a system is shown in the following <span class="No-Break">code block:</span></p>
<pre class="source-code">
//Example of Non-learning AI (My AI Doctor!)
Patient.age //get the patient age
Patient. temperature //get the patient temperatur<a id="_idTextAnchor020"/>e
Patient.night_sweats //get if the patient has night sweats
Paitent.Cough //get if the patient cough
// AI program starts
if Patient.age &gt; 70:
    if Patient.temperature &gt; 39 and Paitent.Cough:
        print("Recommend Disease A")
        return
elif Patient.age &lt; 10:
    if Patient.tempreture &gt; 37 and not Paitent.Cough:
        if Patient.night_sweats:
                print("Recommend Disease B")
                return
else:
    print("I cannot resolve this case!")
    return</pre> <p>This program mimics how a physician may reason for a similar scenario. Using simple <strong class="source-inline">if-else</strong> statements with few lines of code, we can bring “intelligence” to <span class="No-Break">our program.</span></p>
<p class="callout-heading">Important note</p>
<p class="callout">This is an example of non-learning-based AI. As you may expect, the program will not evolve with experience. In other words, the logic will not improve with more patients, though the program still represents a clear form <span class="No-Break">of AI.</span></p>
<p>In this section, we learned about AI <a id="_idIndexMarker002"/>and explored how to distinguish between learning and non-learning-based AI. In the next section, we will look <span class="No-Break">at ML.</span></p>
<h2 id="_idParaDest-20"><a id="_idTextAnchor021"/>Machine learning (ML)</h2>
<p>ML is a subset of AI. The key idea of ML<a id="_idIndexMarker003"/> is to enable computer programs to learn from experience. The aim is to allow programs to learn without the need to dictate the rules by humans. In the example of the AI doctor we saw in the previous section, the main issue is creating the rules. This process is extremely difficult, time-consuming, and error-prone. For the program to work properly, you would need to ask experienced/senior physicians to express the logic they usually use to handle similar patients. In other scenarios, we do not know exactly what the rules are and what mechanisms are involved in the process, such as object recognition and <span class="No-Break">object tracking.</span></p>
<p>ML comes as a solution to learning the rules that control the process by exploring special training data collected for this task (see <span class="No-Break"><em class="italic">Figure 1</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">):</span><a id="_idTextAnchor022"/></p>
<div>
<div class="IMG---Figure" id="_idContainer009">
<img alt="Figure 1.1 – ML learns implicit rules from data" height="229" src="image/B18494_01_001.jpg" width="399"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – ML learns implicit rules from data</p>
<p>ML has three major types: <strong class="bold">supervised</strong>, <strong class="bold">unsupervised</strong>, and <strong class="bold">reinforcement learning</strong>. The main difference<a id="_idIndexMarker004"/> between them comes from the nature<a id="_idIndexMarker005"/> of the training data<a id="_idIndexMarker006"/> used and the learning process itself. This is usually<a id="_idIndexMarker007"/> related to the problem and the available <span class="No-Break">training data.</span></p>
<h2 id="_idParaDest-21"><a id="_idTextAnchor023"/>Deep learning (DL)</h2>
<p>DL is a subset<a id="_idIndexMarker008"/> of ML, and it can be seen as the heart of ML (see <span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.2</em>). Most of the amazing applications of ML are possible because of DL. DL learns and discovers complex patterns and structures<a id="_idIndexMarker009"/> in the training data that are usually hard to do using other ML approaches, such as <strong class="bold">decision trees</strong>. DL learns by using <strong class="bold">artificial neural networks</strong> (<strong class="bold">ANNs</strong>) composed of multiple layers or too many<a id="_idIndexMarker010"/> layers (an order of 10 or more), inspired by the human brain; hence the <em class="italic">neural</em> in the name. It has three types of layers: input, output, and hidden. The input layer receives the input, while the output layer gives the prediction of the ANN. The hidden layers are responsible for discovering the hidden patterns in the training data. Generally, each layer (from the input to the output layers) learns a more abstract representation of the data, given the output of the previous layer. The more hidden layers your ANN has, the more complex and non-linear the ANN will be. Thus, ANNs will have more freedom to better approximate the relationship between the input and output or to learn your training data. For example, AlexNet is composed of 8 layers, VGGNet is composed of 16 to 19 layers, and ResNet-50 is composed of <span class="No-Break">50 layers:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer010">
<img alt="Figure 1.2 – How DL, ML, and AI are related" height="359" src="image/B18494_01_002.jpg" width="432"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – How DL, ML, and AI are related</p>
<p>The main issue with DL is that it requires a large-scale training dataset to converge because we usually have a tremendous number of parameters (weights) to tweak to minimize the loss. In ML, loss is a way to penalize wrong predictions. At the same time, it is an indication of how well the model is learning the training data. Collecting and annotating such large datasets is extremely hard <span class="No-Break">and expensive.</span></p>
<p>Nowadays, using synthetic data as an alternative or complementary to real data is a hot topic. It is a trending topic in research and industry. Many companies such as Google (Google’s Waymo utilizes synthetic data to train autonomous cars) and Microsoft (they use synthetic data to handle privacy issues with sensitive data) started recently to invest in using synthetic data to train next-generation<a id="_idIndexMarker011"/> <span class="No-Break">M<a id="_idTextAnchor024"/>L models.</span></p>
<h1 id="_idParaDest-22"><a id="_idTextAnchor025"/>Why are ML and DL so powerful?</h1>
<p>Although most AI fields are flourishing and gaining more attention recently, ML and DL have been the most influential fields of AI. This is because of several factors that make them distinctly a better solution in terms of accuracy, performance, and applicability. In this section, we are going to look at some of these <span class="No-Break">essential factors.</span></p>
<h2 id="_idParaDest-23"><a id="_idTextAnchor026"/>Feature engineering</h2>
<p>In traditional AI, it is compulsory<a id="_idIndexMarker012"/> to design the features <em class="italic">manually</em> for the task. This process is extremely difficult, time-consuming, and task/problem-dependent. If you want to write a program, say to recognize car wheels, you probably need to use some filters to extract edges and corners. Then, you need to utilize these extracted features to identify the target object. As you may anticipate, it is not always easy to know what features to select or ignore. Imagine developing an AI-based solution to predict if a patient has COVID-19 based on a set of symptoms at the early beginning of the pandemic. At that time, human experts did not know how to answer such questions. ML and DL can solve <span class="No-Break">such problems.</span></p>
<p>DL models learn to <em class="italic">automatically</em> extract useful features by learning hidden patterns, structures, and associations<a id="_idIndexMarker013"/> in the training data. A <strong class="bold">loss</strong> is used to guide the learning process and help the model achieve the objectives of the training process. However, for the model to converge, it needs to be exposed to sufficiently diverse <span class="No-Break">training data.</span></p>
<h2 id="_idParaDest-24"><a id="_idTextAnchor027"/>Transfer across tasks</h2>
<p>One strong advantage of DL<a id="_idIndexMarker014"/> is that it’s more task-independent compared to traditional ML approaches. Transfer learning is an amazing and powerful feature of DL. Instead of training the model from scratch, you can start the training process using a different model trained on a similar task. This is very common in fields such as computer vision and natural language processing. Usually, you have a small dataset of your own target task, and your model would not converge using only this small dataset. Thus, training the model on a dataset close to the domain (or the task) but that’s sufficiently more diverse and larger and then fine-tuning on your task-specific dataset gives better results. This idea allows<a id="_idIndexMarker015"/> your model to transfer the learning between tasks<a id="_idIndexMarker016"/> <span class="No-Break">and domains:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer011">
<img alt="Figure 1.3 – Advantages of ML and DL" height="264" src="image/B18494_01_003.jpg" width="517"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – Advantages of ML and DL</p>
<p class="callout-heading">Important note</p>
<p class="callout">If the problem is simple or a mathematical solution is available, then you probably do not need to use ML! Unfortunately, it is common to see some ML-based solutions proposed for problems where a clear explicit mathematical solution is already available! At the same time, it is not recommended to use ML if a simple rule-based solution works fine for <span class="No-Break">your problem.</span></p>
<h1 id="_idParaDest-25"><a id="_idTextAnchor028"/>Training ML models</h1>
<p>Developing an ML model<a id="_idIndexMarker017"/> usually requires performing the following <span class="No-Break">essential steps:</span></p>
<ol>
<li><span class="No-Break">Collecting data.</span></li>
<li><span class="No-Break">Annotating data.</span></li>
<li>Designing an <span class="No-Break">ML model.</span></li>
<li>Training <span class="No-Break">the model.</span></li>
<li>Testing <span class="No-Break">the model.</span></li>
</ol>
<p>These steps are depicted in the <span class="No-Break">following diagram:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer012">
<img alt="Figure 1.4 – Developing an ML model process" height="399" src="image/B18494_01_004.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – Developing an ML model process</p>
<p>Now, let’s look at each of the steps in more detail to better understand how we can develop an <span class="No-Break">ML model.</span></p>
<h2 id="_idParaDest-26"><a id="_idTextAnchor029"/>Collecting and annotating data</h2>
<p>The first step in the process<a id="_idIndexMarker018"/> of developing an ML model is collecting<a id="_idIndexMarker019"/> the needed training data. You need to decide what training data <span class="No-Break">is needed:</span></p>
<ul>
<li><strong class="bold">Train using an existing dataset</strong>: In this case, there’s no need to collect training data. Thus, you can skip collecting and annotating data. However, you should make sure that your target task or domain is quite similar to the available dataset(s) you are planning to deploy. Otherwise, your model may train well on this dataset, but it will not perform well when tested on the new task <span class="No-Break">or domain.</span></li>
<li><strong class="bold">Train on an existing dataset and fine-tune on a new dataset</strong>: This is the most popular case in today’s ML. You can pre-train your model on a large existing dataset and then fine-tune it on the new dataset. Regarding the new dataset, it does not need to be very large as you are already leveraging other existing dataset(s). For the dataset to be collected, you need to identify what the model needs to learn and how you are planning to implement this. After collecting the training data, you will begin the <span class="No-Break">annotation process.</span></li>
<li><strong class="bold">Train from scratch on new data</strong>: In some contexts, your task or domain may be far from any available datasets. Thus, you will need to collect large-scale data. Collecting large-scale datasets is not simple. To do this, you need to identify what the model will learn and how you want it to do that. Making any modifications to the plan later may require you to recollect more data or even start the data collection process again from scratch. Following this, you need to decide what ground truth to extract, the budget, and the quality <span class="No-Break">you want.</span></li>
</ul>
<p>Next, we’ll explore<a id="_idIndexMarker020"/> the most essential element<a id="_idIndexMarker021"/> of an ML model development process. So, let’s learn how to design and train a typical <span class="No-Break">ML model.</span></p>
<h2 id="_idParaDest-27"><a id="_idTextAnchor030"/>Designing and training an ML model</h2>
<p>Selecting a suitable<a id="_idIndexMarker022"/> ML model<a id="_idIndexMarker023"/> for the problem a hand is dependent on the problem itself, any constraints, and the ML engineer. Sometimes, the same problem can be solved by different ML algorithms but in other scenarios, it is compulsory to use a specific ML model. Based on the problem and ML model, data should be collected <span class="No-Break">and annotated.</span></p>
<p>Each ML algorithm will have a different set of hyperparameters, various designs, and a set of decisions to be made throughout the process. It is recommended that you perform pilot or preliminary experiments to identify the best approach for <span class="No-Break">your problem.</span></p>
<p>When the design process is finalized, the training process can start. For some ML models, the training process could take minutes, while for others, it could take weeks, months, or more! You may need to perform different training experiments to decide which training hyperparameters you are going to continue with – for example, the number of epochs or optimization techniques. Usually, the loss will be a helpful indication of how well the training process is going. In DL, two losses are used: training and validation loss. The first tells us how well the model is learning the training data, while the latter describes<a id="_idIndexMarker024"/> the ability of the model to generalize<a id="_idIndexMarker025"/> to <span class="No-Break">new data.</span></p>
<h2 id="_idParaDest-28"><a id="_idTextAnchor031"/>Validating and testing an ML model</h2>
<p>In ML, we should differentiate<a id="_idIndexMarker026"/> between three different<a id="_idIndexMarker027"/> datasets/partitions/sets: training, validation, and testing. The <em class="italic">training</em> set is used to teach the model about the task and assess how well the model is performing in the training process. The <em class="italic">validation</em> set is a proxy of the test set and is used to tell us the expected performance of our model on new data. However, the <em class="italic">test</em> set is the proxy of the actual world – that is, where our model will be tested. This dataset should only be deployed so that we know how the model will perform in practice. Using this dataset to change a hyperparameter or design option is considered cheating because it gives a deceptive understanding of how your model will be performing or generalizing in the real world. In the real world, once your model has been deployed, say for example in industry, you will not be able to tune the model’s parameters based on <span class="No-Break">its performance!</span></p>
<h2 id="_idParaDest-29"><a id="_idTextAnchor032"/>Iterations in the ML development process</h2>
<p>In practice, developing an ML model<a id="_idIndexMarker028"/> will require many iterations between validation and testing and the other stages of the process. It could be that validation or testing results are unsatisfactory and you decide to change some aspects of the data collection, annotation, designing, <span class="No-Break">or training.</span></p>
<h1 id="_idParaDest-30"><a id="_idTextAnchor033"/>Summary</h1>
<p>In this chapter, we discussed the terms AI, ML, and DL. We uncovered some advantages of ML and DL. At the same time, we learned the basic steps for developing and training ML models. Finally, we learned why we need large-scale <span class="No-Break">training data.</span></p>
<p>In the next chapter, we will discover the main issues with annotating large-scale datasets. This will give us a good understanding of why synthetic data is the future <span class="No-Break">of ML!</span></p>
</div>
</div></body></html>