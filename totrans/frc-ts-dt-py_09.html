<html><head></head><body>
<div id="_idContainer204">
<h1 class="chapter-number" id="_idParaDest-101"><a id="_idTextAnchor599"/><a id="_idTextAnchor600"/><a id="_idTextAnchor601"/><span class="koboSpan" id="kobo.1.1">9</span></h1>
<h1 id="_idParaDest-102"><a id="_idTextAnchor602"/><span class="koboSpan" id="kobo.2.1">Including Additional Regressors</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In your first model in </span><a href="B19630_02.xhtml#_idTextAnchor104"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.4.1">Chapter 2</span></em></span></a><span class="koboSpan" id="kobo.5.1">, </span><em class="italic"><span class="koboSpan" id="kobo.6.1">Getting Started with Prophet</span></em><span class="koboSpan" id="kobo.7.1">, you forecasted carbon dioxide levels at Mauna Loa using only the date (but no other information) to predict future values. </span><span class="koboSpan" id="kobo.7.2">Later, in </span><a href="B19630_06.xhtml#_idTextAnchor375"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.8.1">Chapter 6</span></em></span></a><span class="koboSpan" id="kobo.9.1">, </span><em class="italic"><span class="koboSpan" id="kobo.10.1">Forecasting Holiday Effects</span></em><span class="koboSpan" id="kobo.11.1">, you learned how to add holidays as additional information to further refine your predictions of bicycle ridership in the Divvy bike share network </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">in Chicago.</span></span></p>
<p><span class="koboSpan" id="kobo.13.1">The way holidays are implemented in Prophet is actually a special case of adding a binary regressor. </span><span class="koboSpan" id="kobo.13.2">In fact, Prophet includes a generalized method for adding any additional regressor, both binary </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">and continuous.</span></span></p>
<p><span class="koboSpan" id="kobo.15.1">In this chapter, you’ll enrich your Divvy dataset with weather information by including it as an additional regressor. </span><span class="koboSpan" id="kobo.15.2">First, you will add binary weather conditions to describe the presence or absence of sun, clouds, or rain, and then you will bring in continuous temperature measurements. </span><span class="koboSpan" id="kobo.15.3">Using additional regressors can allow you to include more information to inform your models, which leads to greater predictive power. </span><span class="koboSpan" id="kobo.15.4">In this chapter, you will learn about the </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.17.1">Adding </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">binary regressors</span></span></li>
<li><span class="koboSpan" id="kobo.19.1">Adding </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">continuous regressors</span></span></li>
<li><span class="koboSpan" id="kobo.21.1">Interpreting the </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">regressor coefficients</span></span></li>
</ul>
<h1 id="_idParaDest-103"><a id="_idTextAnchor603"/><a id="_idTextAnchor604"/><span class="koboSpan" id="kobo.23.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.24.1">The data files and code for examples in this chapter can be found </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">at </span></span><a href="https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition"><span class="No-Break"><span class="koboSpan" id="kobo.26.1">https://github.com/PacktPublishing/Forecasting-Time-Series-Data-with-Prophet-Second-Edition</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.27.1">.</span></span></p>
<h1 id="_idParaDest-104"><a id="_idTextAnchor605"/><a id="_idTextAnchor606"/><span class="koboSpan" id="kobo.28.1">Adding binary regressors</span></h1>
<p><span class="koboSpan" id="kobo.29.1">The first </span><a id="_idIndexMarker360"/><span class="koboSpan" id="kobo.30.1">thing t</span><a id="_idTextAnchor607"/><span class="koboSpan" id="kobo.31.1">o consider with </span><strong class="bold"><span class="koboSpan" id="kobo.32.1">additional regressors</span></strong><span class="koboSpan" id="kobo.33.1">, whether binary or continuous, is that you must have known future values for your entire forecast period. </span><span class="koboSpan" id="kobo.33.2">This isn’t a problem with holidays</span><a id="_idTextAnchor608"/><span class="koboSpan" id="kobo.34.1"> because we know exactly when each future holiday will occur. </span><span class="koboSpan" id="kobo.34.2">All future values must either be known, as with holidays, or must have been forecast separately. </span><span class="koboSpan" id="kobo.34.3">You must be careful though when building a forecast using data that itself has been forecast: the error in the first forecast will compound the error in the second forecast, and the errors will continuously </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">pile up.</span></span></p>
<p><span class="koboSpan" id="kobo.36.1">If one variable is much easier to forecast than another, however, then this may be a case where these stacked</span><a id="_idTextAnchor609"/><span class="koboSpan" id="kobo.37.1"> forecasts do make sense. </span><span class="koboSpan" id="kobo.37.2">A </span><strong class="bold"><span class="koboSpan" id="kobo.38.1">hierarchical time series</span></strong><span class="koboSpan" id="kobo.39.1"> is an example case where this may be useful: you may find</span><a id="_idIndexMarker361"/><span class="koboSpan" id="kobo.40.1"> good results by forecasting the more reliable daily values of one time series, for instance, and using those values to forecast hourly values of another time series that is more difficult </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">to predict.</span></span></p>
<p><span class="koboSpan" id="kobo.42.1">In the examples in this chapter, we are going to use a weather forecast to enrich our Divvy forecast. </span><span class="koboSpan" id="kobo.42.2">This additional regressor is possible because we generally do have decent weather forecasts available looking ahead a week or so. </span><span class="koboSpan" id="kobo.42.3">In other examples in this book, in which we have used Divvy data, we often forecasted a full year. </span><span class="koboSpan" id="kobo.42.4">In this chapter though, we will only forecast 2 weeks. </span><span class="koboSpan" id="kobo.42.5">Let’s be generous to Chicago’s weather forecasters and assume that they’ll provide accurate forecasts in this </span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">time frame.</span></span></p>
<p><span class="koboSpan" id="kobo.44.1">To begin, let’s import our necessary packages and load </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">the data:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.46.1">
import pandas as pd
import matplotlib.pyplot as plt
from prophet import Prophet
df = pd.read_csv('divvy_daily.csv')</span></pre>
<p><span class="koboSpan" id="kobo.47.1">Please</span><a id="_idIndexMarker362"/><span class="koboSpan" id="kobo.48.1"> refer to </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.49.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.50.1">.6</span></em><span class="koboSpan" id="kobo.51.1"> in </span><a href="B19630_05.xhtml#_idTextAnchor254"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.52.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.53.1">, </span><em class="italic"><span class="koboSpan" id="kobo.54.1">Working with Seasonality</span></em><span class="koboSpan" id="kobo.55.1">, for a plot of the rides per day in this data. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.56.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.57.1">.7</span></em><span class="koboSpan" id="kobo.58.1"> in </span><a href="B19630_05.xhtml#_idTextAnchor254"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.59.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.60.1"> showed an excerpt of the data contained in this file. </span><span class="koboSpan" id="kobo.60.2">So far in this book, we always excluded the two columns for weather and temperature in this dataset, but we’ll use them this time around. </span><span class="koboSpan" id="kobo.60.3">For our first example, let’s consider the weather conditions. </span><span class="koboSpan" id="kobo.60.4">By counting the number of times each condition occurred in the dataset, we can see </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">their frequencies:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.62.1">
print(df.groupby('weather')['weather'].count())</span></pre>
<p><span class="koboSpan" id="kobo.63.1">The output of </span><a id="_idTextAnchor610"/><span class="koboSpan" id="kobo.64.1">the preceding </span><strong class="source-inline"><span class="koboSpan" id="kobo.65.1">print</span></strong><span class="koboSpan" id="kobo.66.1"> statement is </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">as follows</span><a id="_idTextAnchor611"/><span class="koboSpan" id="kobo.68.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer197">
<span class="koboSpan" id="kobo.69.1"><img alt="Figure 9.1 – Count of weather conditions in the Divvy dataset" src="image/Fig_9.1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.70.1">Figure 9.1 – Count of weather conditions in the Divvy dataset</span></p>
<p><span class="koboSpan" id="kobo.71.1">By </span><a id="_idIndexMarker363"/><span class="koboSpan" id="kobo.72.1">grouping the data by weather and aggregating by count, we can see the number of days each condition was reported. </span><span class="koboSpan" id="kobo.72.2">Clear weather occurred on </span><strong class="source-inline"><span class="koboSpan" id="kobo.73.1">41</span></strong><span class="koboSpan" id="kobo.74.1"> days, and cloudy weather was by far the most common, with </span><strong class="source-inline"><span class="koboSpan" id="kobo.75.1">1346</span></strong><span class="koboSpan" id="kobo.76.1"> occurrences. </span><strong class="source-inline"><span class="koboSpan" id="kobo.77.1">Not clear</span></strong><span class="koboSpan" id="kobo.78.1"> was only reported twice, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.79.1">rain or snow</span></strong><span class="koboSpan" id="kobo.80.1"> occurred </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.81.1">69</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.82.1"> times.</span></span></p>
<p><span class="koboSpan" id="kobo.83.1">Now that we understand what data we’re working with, let’s load it into our DataFrame. </span><span class="koboSpan" id="kobo.83.2">We’ll also load the </span><strong class="source-inline"><span class="koboSpan" id="kobo.84.1">temperature</span></strong><span class="koboSpan" id="kobo.85.1"> column, even though we won’t use it until the next example when we look </span><a id="_idIndexMarker364"/><span class="koboSpan" id="kobo.86.1">at </span><strong class="bold"><span class="koboSpan" id="kobo.87.1">continuous</span></strong><span class="koboSpan" id="kobo.88.1"> columns, t</span><a id="_idTextAnchor612"/><span class="koboSpan" id="kobo.89.1">hose in which the value may exist along </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">a continuum.</span></span></p>
<p><span class="koboSpan" id="kobo.91.1">To load the </span><strong class="source-inline"><span class="koboSpan" id="kobo.92.1">weather</span></strong><span class="koboSpan" id="kobo.93.1"> column, we will use pandas’ </span><strong class="source-inline"><span class="koboSpan" id="kobo.94.1">get_dummies</span></strong><span class="koboSpan" id="kobo.95.1"> method to convert it into four </span><strong class="bold"><span class="koboSpan" id="kobo.96.1">binary</span></strong><span class="koboSpan" id="kobo.97.1"> columns</span><a id="_idIndexMarker365"/><span class="koboSpan" id="kobo.98.1"> for </span><a id="_idTextAnchor613"/><span class="koboSpan" id="kobo.99.1">each unique weather condition, meaning that each column will be </span><strong class="source-inline"><span class="koboSpan" id="kobo.100.1">1</span></strong><span class="koboSpan" id="kobo.101.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.102.1">0</span></strong><span class="koboSpan" id="kobo.103.1"> – essentially, a flag indicating whether the condition </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">is present:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.105.1">
df['date'] = pd.to_datetime(df['date'])
df.columns = ['ds', 'y', 'temp', 'weather']
df = pd.get_dummies(df, columns=['weather'], prefix='',
                    prefix_sep='')</span></pre>
<p><span class="koboSpan" id="kobo.106.1">We can display the first five rows of our DataFrame at this point to see what the preceding code </span><span class="No-Break"><span class="koboSpan" id="kobo.107.1">has done:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.108.1">
df.head()</span></pre>
<p><span class="koboSpan" id="kobo.109.1">The output of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.110.1">head</span></strong><span class="koboSpan" id="kobo.111.1"> statement should appear </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">as follo</span><a id="_idTextAnchor614"/><span class="koboSpan" id="kobo.113.1">ws:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer198">
<span class="koboSpan" id="kobo.114.1"><img alt="Figure 9.2 – DataFrame with dummy weather columns" src="image/Fig_9.2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.115.1">Figure 9.2 – DataFrame with dummy weather columns</span></p>
<p><span class="koboSpan" id="kobo.116.1">You can </span><a id="_idIndexMarker366"/><span class="koboSpan" id="kobo.117.1">now see that each unique value in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.118.1">weather</span></strong><span class="koboSpan" id="kobo.119.1"> column has been converted to a new column. </span><span class="koboSpan" id="kobo.119.2">Let’s instantiate our model now, setting the seasonality mode to multiplicative and the yearly seasonality to have a Fourier order of </span><strong class="source-inline"><span class="koboSpan" id="kobo.120.1">4</span></strong><span class="koboSpan" id="kobo.121.1">, as we did in </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">previous chapters.</span></span></p>
<p><span class="koboSpan" id="kobo.123.1">We will also</span><a id="_idTextAnchor615"/><span class="koboSpan" id="kobo.124.1"> add our additional regressors using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.125.1">add_regressor</span></strong><span class="koboSpan" id="kobo.126.1"> method. </span><span class="koboSpan" id="kobo.126.2">As arguments to this method, you must pass the name of the regressor, which is the name of the corresponding column in your DataFrame. </span><span class="koboSpan" id="kobo.126.3">You may also use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.127.1">prior_scale</span></strong><span class="koboSpan" id="kobo.128.1"> argument to regularize the regressor, just as you did with holidays, seasonalities, and trend changepoints. </span><span class="koboSpan" id="kobo.128.2">If no prior scale is specified, then </span><strong class="source-inline"><span class="koboSpan" id="kobo.129.1">holidays_prior_scale</span></strong><span class="koboSpan" id="kobo.130.1"> will be used, which defaults </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.132.1">10</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.134.1">You may also specify whether the regressor should be additive or multiplicative. </span><span class="koboSpan" id="kobo.134.2">If nothing is specified, then the regressor adopts that stated in </span><strong class="source-inline"><span class="koboSpan" id="kobo.135.1">seasonality_mode</span></strong><span class="koboSpan" id="kobo.136.1">. </span><span class="koboSpan" id="kobo.136.2">Lastly, the method has a </span><strong class="source-inline"><span class="koboSpan" id="kobo.137.1">standardize</span></strong><span class="koboSpan" id="kobo.138.1"> argument, which, by default, takes the </span><strong class="source-inline"><span class="koboSpan" id="kobo.139.1">'auto'</span></strong><span class="koboSpan" id="kobo.140.1"> string. </span><span class="koboSpan" id="kobo.140.2">This means that the column will be standardized if not binary. </span><span class="koboSpan" id="kobo.140.3">You can instead explicitly set standardization by setting it to either </span><strong class="source-inline"><span class="koboSpan" id="kobo.141.1">True</span></strong><span class="koboSpan" id="kobo.142.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.143.1">False</span></strong><span class="koboSpan" id="kobo.144.1">. </span><span class="koboSpan" id="kobo.144.2">In this example, all defaults will work </span><span class="No-Break"><span class="koboSpan" id="kobo.145.1">out great.</span></span></p>
<p><span class="koboSpan" id="kobo.146.1">To make it clear, I’ll explicitly state all arguments in only the first </span><strong class="source-inline"><span class="koboSpan" id="kobo.147.1">add_regressor</span></strong><span class="koboSpan" id="kobo.148.1"> call and for the remaining, we will only state the name of the regressor and otherwise accept all </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">default values.</span></span></p>
<p><span class="koboSpan" id="kobo.150.1">We must make one </span><strong class="source-inline"><span class="koboSpan" id="kobo.151.1">add_regressor</span></strong><span class="koboSpan" id="kobo.152.1"> call for each additional regressor but note that we are leaving the regressor for </span><strong class="source-inline"><span class="koboSpan" id="kobo.153.1">cloudy</span></strong><span class="koboSpan" id="kobo.154.1"> out. </span><span class="koboSpan" id="kobo.154.2">For Prophet to get accurate forecast results, this isn’t strictly necessary. </span><span class="koboSpan" id="kobo.154.3">However, because including all four binary columns will introduce </span><strong class="bold"><span class="koboSpan" id="kobo.155.1">multicollinearity</span></strong><span class="koboSpan" id="kobo.156.1">, this </span><a id="_idTextAnchor616"/><a id="_idIndexMarker367"/><span class="koboSpan" id="kobo.157.1">makes interpreting the individual effect of each condition difficult, so we will exclude one of them. </span><span class="koboSpan" id="kobo.157.2">However, Prophet is fairly robust to</span><a id="_idIndexMarker368"/><span class="koboSpan" id="kobo.158.1"> multicollinearity in additional regressors, so it shouldn’t affect your final </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">results significantly.</span></span></p>
<p><span class="koboSpan" id="kobo.160.1">When we </span><a id="_idIndexMarker369"/><span class="koboSpan" id="kobo.161.1">called </span><strong class="source-inline"><span class="koboSpan" id="kobo.162.1">pd.get_dummies</span></strong><span class="koboSpan" id="kobo.163.1"> earlier, we could have specified the </span><strong class="source-inline"><span class="koboSpan" id="kobo.164.1">drop_first=True</span></strong><span class="koboSpan" id="kobo.165.1"> argument to exclude one of the conditions, but I decided not to so we could choose for ourselves which column to exclude. </span><span class="koboSpan" id="kobo.165.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.166.1">cloudy</span></strong><span class="koboSpan" id="kobo.167.1"> condition is by far the most frequent so, by excluding it, we are essentially stating that </span><strong class="source-inline"><span class="koboSpan" id="kobo.168.1">cloudy</span></strong><span class="koboSpan" id="kobo.169.1"> is the </span><em class="italic"><span class="koboSpan" id="kobo.170.1">default</span></em><span class="koboSpan" id="kobo.171.1"> weather co</span><a id="_idTextAnchor617"/><span class="koboSpan" id="kobo.172.1">ndition and the other conditions will be stated as deviations </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">from it:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.174.1">
model = Prophet(seasonality_mode='multiplicative',
                yearly_seasonality=4)
model.add_regressor(name='clear',
                    prior_scale=10,
                    standardize='auto',
                    mode='multiplicative')
model.add_regressor('not clear')
model.add_regressor('rain or snow')</span></pre>
<p><span class="koboSpan" id="kobo.175.1">Now, remembering that we need future data for our additional regressors and we’re only going to forecast out two weeks, we need to artificially reduce our training data by two weeks to simulate having two future weeks of weather data but no ridership data. </span><span class="koboSpan" id="kobo.175.2">To do that, we’ll need to import </span><strong class="source-inline"><span class="koboSpan" id="kobo.176.1">timedelta</span></strong><span class="koboSpan" id="kobo.177.1"> from Python’s built-in </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.178.1">datetime</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.179.1"> package.</span></span></p>
<p><span class="koboSpan" id="kobo.180.1">Using Boolean indexing in pandas, we will create a new DataFrame for training data, called </span><strong class="source-inline"><span class="koboSpan" id="kobo.181.1">train</span></strong><span class="koboSpan" id="kobo.182.1">, by selecting all dates that are less than the final date (</span><strong class="source-inline"><span class="koboSpan" id="kobo.183.1">df['ds'].max()</span></strong><span class="koboSpan" id="kobo.184.1">) minus two </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">weeks (</span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.186.1">timedelta(weeks=2)</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.188.1">
from datetime import timedelta
# Remove final 2 weeks of training data
train = df[df['ds'] &lt; df['ds'].max() - timedelta(weeks=2)]</span></pre>
<p><span class="koboSpan" id="kobo.189.1">At this point, we are essentially saying that our data ends not on December 31, 2017 (as our </span><strong class="source-inline"><span class="koboSpan" id="kobo.190.1">df</span></strong><span class="koboSpan" id="kobo.191.1"> DataFrame does), but on December 16, 2017, and that we have a weather forecast for those two missing weeks. </span><span class="koboSpan" id="kobo.191.2">We now fit our model on this </span><strong class="source-inline"><span class="koboSpan" id="kobo.192.1">train</span></strong><span class="koboSpan" id="kobo.193.1"> data and create our </span><strong class="source-inline"><span class="koboSpan" id="kobo.194.1">future</span></strong><span class="koboSpan" id="kobo.195.1"> DataFrame with </span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">14 days.</span></span></p>
<p><span class="koboSpan" id="kobo.197.1">At this point, we </span><a id="_idIndexMarker370"/><span class="koboSpan" id="kobo.198.1">need to add those additional regressor columns into our </span><strong class="source-inline"><span class="koboSpan" id="kobo.199.1">future</span></strong><span class="koboSpan" id="kobo.200.1"> DataFrame. </span><span class="koboSpan" id="kobo.200.2">Because we created that </span><strong class="source-inline"><span class="koboSpan" id="kobo.201.1">train</span></strong><span class="koboSpan" id="kobo.202.1"> DataFrame instead of </span><strong class="source-inline"><span class="koboSpan" id="kobo.203.1">future</span></strong><span class="koboSpan" id="kobo.204.1"> modifying our original </span><strong class="source-inline"><span class="koboSpan" id="kobo.205.1">df</span></strong><span class="koboSpan" id="kobo.206.1"> DataFrame, those values for the weather are stored in </span><strong class="source-inline"><span class="koboSpan" id="kobo.207.1">df</span></strong><span class="koboSpan" id="kobo.208.1"> and we can take them to use in our </span><strong class="source-inline"><span class="koboSpan" id="kobo.209.1">future</span></strong><span class="koboSpan" id="kobo.210.1"> DataFrame. </span><span class="koboSpan" id="kobo.210.2">Finally, we will predict on </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">the future.</span></span></p>
<p><span class="koboSpan" id="kobo.212.1">The forecas</span><a id="_idTextAnchor618"/><span class="koboSpan" id="kobo.213.1">t plot is going to look similar to our previous Divvy forecasts, so let’s just skip it and go straight to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.214.1">components</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.215.1"> plot:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.216.1">
model.fit(train)
future = model.make_future_dataframe(periods=14)
future['clear'] = df['clear']
future['not clear'] = df['not clear']
future['rain or snow'] = df['rain or snow']
forecast = model.predict(future)
fig2 = model.plot_components(forecast)
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.217.1">This time, you will see a new subplot included with the other components. </span><span class="koboSpan" id="kobo.217.2">The following image is a crop of the full </span><strong class="source-inline"><span class="koboSpan" id="kobo.218.1">components</span></strong><span class="koboSpan" id="kobo.219.1"> plot and only shows the yearly seasonality and this </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">new com</span><a id="_idTextAnchor619"/><span class="koboSpan" id="kobo.221.1">ponent:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer199">
<span class="koboSpan" id="kobo.222.1"><img alt="Figure 9.3 – Cropped components plot of binary additional regressors" src="image/Fig_9.3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.223.1">Figure 9.3 – Cropped components plot of binary additional regressors</span></p>
<p><span class="koboSpan" id="kobo.224.1">The trend, weekly </span><a id="_idIndexMarker371"/><span class="koboSpan" id="kobo.225.1">seasonality, and yearly seasonality, which were cropped out, look much the</span><a id="_idTextAnchor620"/><span class="koboSpan" id="kobo.226.1"> same as we’ve seen before with this dataset. </span><span class="koboSpan" id="kobo.226.2">However, we have a new addition to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.227.1">components</span></strong><span class="koboSpan" id="kobo.228.1"> plot, called </span><strong class="source-inline"><span class="koboSpan" id="kobo.229.1">extra_regressors_multiplicative</span></strong><span class="koboSpan" id="kobo.230.1">. </span><span class="koboSpan" id="kobo.230.2">Had we specified some of those regressors as </span><strong class="source-inline"><span class="koboSpan" id="kobo.231.1">additive</span></strong><span class="koboSpan" id="kobo.232.1">, we would see a second subplot here, </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">called </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.234.1">extra_regressors_additive</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.236.1">On dates where the value is at 0%, these are our </span><em class="italic"><span class="koboSpan" id="kobo.237.1">baseline</span></em><span class="koboSpan" id="kobo.238.1"> dates when the weather was cloudy, which we left out of the additional regressors. </span><span class="koboSpan" id="kobo.238.2">The other dates are those where the weather deviated from cloudy, which we included. </span><span class="koboSpan" id="kobo.238.3">We’ll take a more in-depth look at this in a bit. </span><span class="koboSpan" id="kobo.238.4">But first, let’s bring the </span><a id="_idIndexMarker372"/><span class="koboSpan" id="kobo.239.1">temperature into our model and add a </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.240.1">continuous r</span><a id="_idTextAnchor621"/><a id="_idTextAnchor622"/><span class="koboSpan" id="kobo.241.1">egressor</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">.</span></span></p>
<h1 id="_idParaDest-105"><a id="_idTextAnchor623"/><span class="koboSpan" id="kobo.243.1">Adding continuous regressors</span></h1>
<p><span class="koboSpan" id="kobo.244.1">In this ex</span><a id="_idTextAnchor624"/><span class="koboSpan" id="kobo.245.1">ample, we</span><a id="_idIndexMarker373"/><span class="koboSpan" id="kobo.246.1"> will take everything from the previous example and simply add one more regressor for temperature. </span><span class="koboSpan" id="kobo.246.2">Let’s begin by looking at the </span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">temperat</span><a id="_idTextAnchor625"/><span class="koboSpan" id="kobo.248.1">ure data:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer200">
<span class="koboSpan" id="kobo.249.1"><img alt="Figure 9.4 – Chicago temperature over time" src="image/Fig_9.4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.250.1">Figure 9.4 – Chicago temperature over time</span></p>
<p><span class="koboSpan" id="kobo.251.1">There’s nothing too surprising about the preceding plot; daily temperatures rise in summer and fall in winter. </span><span class="koboSpan" id="kobo.251.2">It does look a lot like </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.252.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.253.1">.6</span></em><span class="koboSpan" id="kobo.254.1"> from </span><a href="B19630_05.xhtml#_idTextAnchor254"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.255.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.256.1">, </span><em class="italic"><span class="koboSpan" id="kobo.257.1">Working with Seasonality</span></em><span class="koboSpan" id="kobo.258.1">, but without that increasing trend. </span><span class="koboSpan" id="kobo.258.2">Clearly, Divvy ridership and the temperature rise and </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">fall together.</span></span></p>
<p><span class="koboSpan" id="kobo.260.1">Adding temperature, a continuous variable, is no different than adding binary variables. </span><span class="koboSpan" id="kobo.260.2">We simply add another </span><strong class="source-inline"><span class="koboSpan" id="kobo.261.1">add_regressor</span></strong><span class="koboSpan" id="kobo.262.1"> call to our Prophet instance, specifying </span><strong class="source-inline"><span class="koboSpan" id="kobo.263.1">'temp'</span></strong><span class="koboSpan" id="kobo.264.1"> for the name, and also including the temperature forecast in our </span><strong class="source-inline"><span class="koboSpan" id="kobo.265.1">future</span></strong><span class="koboSpan" id="kobo.266.1"> DataFrame. </span><span class="koboSpan" id="kobo.266.2">As we did before, we are fitting our model on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.267.1">train</span></strong><span class="koboSpan" id="kobo.268.1"> DataFrame we created, which excludes the final 2 weeks’ worth of data. </span><span class="koboSpan" id="kobo.268.2">Finally, we plot the components to see what </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">we’ve got:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.270.1">
model = Prophet(seasonality_mode='multiplicative',
                yearly_seasonality=4)
model.add_regressor('temp')
model.add_regressor('clear')
model.add_regressor('not clear')
model.add_regressor('rain or snow')
model.fit(train)
future = model.make_future_dataframe(periods=14)
future['temp'] = df['temp']
future['clear'] = df['clear']
future['not clear'] = df['not clear']
future['rain or snow'] = df['rain or snow']
forecast = model.predict(future)
fig2 = model.plot_components(forecast)
plt.show(</span><a id="_idTextAnchor626"/><span class="koboSpan" id="kobo.271.1">)</span></pre>
<p><span class="koboSpan" id="kobo.272.1">Now, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.273.1">extra_regressors_multiplicative</span></strong><span class="koboSpan" id="kobo.274.1"> plot shows the same fluctuations</span><a id="_idIndexMarker374"/><span class="koboSpan" id="kobo.275.1"> that our </span><strong class="source-inline"><span class="koboSpan" id="kobo.276.1">temperature</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.277.1">plot d</span><a id="_idTextAnchor627"/><span class="koboSpan" id="kobo.278.1">isplayed:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer201">
<span class="koboSpan" id="kobo.279.1"><img alt="Figure 9.5 – Cropped components plot of both binary and continuous additional regressors" src="image/Fig_9.5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.280.1">Figure 9.5 – Cropped components plot of both binary and continuous additional regressors</span></p>
<p><span class="koboSpan" id="kobo.281.1">Also note that </span><a id="_idIndexMarker375"/><span class="koboSpan" id="kobo.282.1">in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.283.1">Figure 9</span></em></span><em class="italic"><span class="koboSpan" id="kobo.284.1">.3</span></em><span class="koboSpan" id="kobo.285.1">, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.286.1">yearly</span></strong><span class="koboSpan" id="kobo.287.1"> plot peaked at 60% effect magnitude. </span><span class="koboSpan" id="kobo.287.2">However, now we can see that temperature accounts for some of that effect. </span><span class="koboSpan" id="kobo.287.3">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.288.1">yearly</span></strong><span class="koboSpan" id="kobo.289.1"> plot in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.290.1">Figure </span><a id="_idTextAnchor628"/><span class="koboSpan" id="kobo.291.1">9</span></em></span><em class="italic"><span class="koboSpan" id="kobo.292.1">.5</span></em><span class="koboSpan" id="kobo.293.1"> shows a peak 30% effect, while the </span><strong class="source-inline"><span class="koboSpan" id="kobo.294.1">extra_regressors_multiplicative</span></strong><span class="koboSpan" id="kobo.295.1"> plot shows a 40% increase on certain summertime dates and a massive 80% decrease in ridership on certain wintertime dates. </span><span class="koboSpan" id="kobo.295.2">To break this down further, we now need to discuss how to interpret </span><a id="_idTextAnchor629"/><a id="_idTextAnchor630"/><span class="No-Break"><span class="koboSpan" id="kobo.296.1">this data.</span></span></p>
<h1 id="_idParaDest-106"><a id="_idTextAnchor631"/><span class="koboSpan" id="kobo.297.1">Interpreting the regressor coefficients</span></h1>
<p><span class="koboSpan" id="kobo.298.1">Now </span><a id="_idTextAnchor632"/><span class="koboSpan" id="kobo.299.1">let’s look at</span><a id="_idIndexMarker376"/><span class="koboSpan" id="kobo.300.1"> how to inspect the effects of these additional regressors. </span><span class="koboSpan" id="kobo.300.2">Prophet includes a package called </span><strong class="source-inline"><span class="koboSpan" id="kobo.301.1">utilities</span></strong><span class="koboSpan" id="kobo.302.1">, which has a function that will come in handy here, called </span><strong class="source-inline"><span class="koboSpan" id="kobo.303.1">regressor_coefficients</span></strong><span class="koboSpan" id="kobo.304.1">. </span><span class="koboSpan" id="kobo.304.2">Let’s import </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">it now:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.306.1">
from prophet.utilities import regressor_coefficients</span></pre>
<p><span class="koboSpan" id="kobo.307.1">Using it is straightforward. </span><span class="koboSpan" id="kobo.307.2">Just pass the model as an argument and it will output a DataFrame with some helpful information about the extra regressors included in </span><span class="No-Break"><span class="koboSpan" id="kobo.308.1">the model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.309.1">
regressor_coefficients(model)</span></pre>
<p><span class="koboSpan" id="kobo.310.1">Let’s take a look at </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">this </span><a id="_idTextAnchor633"/><span class="koboSpan" id="kobo.312.1">DataFrame:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer202">
<span class="koboSpan" id="kobo.313.1"><img alt="Figure 9.6 – The regressor coefficients DataFrame" src="image/Fig_9.6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.314.1">Figure 9.6 – The regressor coefficients DataFrame</span></p>
<p><span class="koboSpan" id="kobo.315.1">It features a</span><a id="_idIndexMarker377"/><span class="koboSpan" id="kobo.316.1"> row for each extra regressor in your model. </span><span class="koboSpan" id="kobo.316.2">In this case, we have one for temperature and three more for the weather conditions we included. </span><span class="koboSpan" id="kobo.316.3">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.317.1">regressor_mode</span></strong><span class="koboSpan" id="kobo.318.1"> colum</span><a id="_idTextAnchor634"/><span class="koboSpan" id="kobo.319.1">n naturally will have strings of either </span><strong class="source-inline"><span class="koboSpan" id="kobo.320.1">additive</span></strong><span class="koboSpan" id="kobo.321.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.322.1">multiplicative</span></strong><span class="koboSpan" id="kobo.323.1">, depending upon the effect of each specific regressor on </span><strong class="source-inline"><span class="koboSpan" id="kobo.324.1">'y'</span></strong><span class="koboSpan" id="kobo.325.1">. </span><span class="koboSpan" id="kobo.325.2">The mean value of the pre-standardized regressor (the raw input data) is saved in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.326.1">center</span></strong><span class="koboSpan" id="kobo.327.1"> column. </span><span class="koboSpan" id="kobo.327.2">If the regressor wasn’t standardized, then the value will </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">be zero.</span></span></p>
<p><span class="koboSpan" id="kobo.329.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.330.1">coef</span></strong><span class="koboSpan" id="kobo.331.1"> column is the one you really want to pay attention to. </span><span class="koboSpan" id="kobo.331.2">It denotes the expected value of the coefficient – that is, the expected impact on </span><strong class="source-inline"><span class="koboSpan" id="kobo.332.1">'y'</span></strong><span class="koboSpan" id="kobo.333.1"> of a unit increase in the regressor. </span><span class="koboSpan" id="kobo.333.2">In the preceding DataFrame, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.334.1">coef</span></strong><span class="koboSpan" id="kobo.335.1"> for </span><strong class="source-inline"><span class="koboSpan" id="kobo.336.1">temp</span></strong><span class="koboSpan" id="kobo.337.1"> is </span><strong class="source-inline"><span class="koboSpan" id="kobo.338.1">0.012282</span></strong><span class="koboSpan" id="kobo.339.1">. </span><span class="koboSpan" id="kobo.339.2">This coefficient tells us that for every degree higher than the </span><strong class="source-inline"><span class="koboSpan" id="kobo.340.1">center</span></strong><span class="koboSpan" id="kobo.341.1"> (</span><strong class="source-inline"><span class="koboSpan" id="kobo.342.1">53.4</span></strong><span class="koboSpan" id="kobo.343.1">, in this case), the expected effect on ridership will be </span><strong class="source-inline"><span class="koboSpan" id="kobo.344.1">0.012282</span></strong><span class="koboSpan" id="kobo.345.1">, or a </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">1.2% increase.</span></span></p>
<p><span class="koboSpan" id="kobo.347.1">For the </span><strong class="source-inline"><span class="koboSpan" id="kobo.348.1">rain or snow</span></strong><span class="koboSpan" id="kobo.349.1"> row, which is a binary regressor, it tells us that on those rainy or snowy days, then ridership will be down 20.6% compared to cloudy days, as that was the regressor we left out. </span><span class="koboSpan" id="kobo.349.2">Had we included all four weather conditions, to interpret this value, you would say ridership would be down 20.6% compared to the value predicted for the same day if modeled without including </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">weather conditions.</span></span></p>
<p><span class="koboSpan" id="kobo.351.1">Finally, the columns for </span><strong class="source-inline"><span class="koboSpan" id="kobo.352.1">'coef_lower'</span></strong><span class="koboSpan" id="kobo.353.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.354.1">'coef_upper'</span></strong><span class="koboSpan" id="kobo.355.1"> indicate the lower and upper bounds, respectively, of the uncertainty interval around the coefficient. </span><span class="koboSpan" id="kobo.355.2">They are only of interest if </span><strong class="source-inline"><span class="koboSpan" id="kobo.356.1">mcmc_sample</span><a id="_idTextAnchor635"/><span class="koboSpan" id="kobo.357.1">s</span></strong><span class="koboSpan" id="kobo.358.1"> is set to a value greater than zero. </span><strong class="bold"><span class="koboSpan" id="kobo.359.1">Markov Chain Monte Carlo</span></strong><span class="koboSpan" id="kobo.360.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.361.1">MCMC</span></strong><span class="koboSpan" id="kobo.362.1">) samples </span><a id="_idIndexMarker378"/><span class="koboSpan" id="kobo.363.1">is a topic you’ll learn about in </span><a href="B19630_11.xhtml#_idTextAnchor728"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.364.1">Chapter 11</span></em></span></a><span class="koboSpan" id="kobo.365.1">, </span><em class="italic"><span class="koboSpan" id="kobo.366.1">Managing Uncertainty Intervals</span></em><span class="koboSpan" id="kobo.367.1">. </span><span class="koboSpan" id="kobo.367.2">If </span><strong class="source-inline"><span class="koboSpan" id="kobo.368.1">mcmc_samples</span></strong><span class="koboSpan" id="kobo.369.1"> is left at the default value, as in these examples, </span><strong class="source-inline"><span class="koboSpan" id="kobo.370.1">'coef_lower'</span></strong><span class="koboSpan" id="kobo.371.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.372.1">'coef_upper'</span></strong><span class="koboSpan" id="kobo.373.1"> will be equal </span><span class="No-Break"><span class="koboSpan" id="kobo.374.1">to </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.375.1">coef</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.376.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.377.1">Now, to conclude, we can plot each of these extra regressors individually with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.378.1">plot_forecast_component</span></strong><span class="koboSpan" id="kobo.379.1"> function we first used in </span><a href="B19630_06.xhtml#_idTextAnchor375"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.380.1">Chapter 6</span></em></span></a><span class="koboSpan" id="kobo.381.1">, </span><em class="italic"><span class="koboSpan" id="kobo.382.1">Forecasting Holiday Effects</span></em><span class="koboSpan" id="kobo.383.1">. </span><span class="koboSpan" id="kobo.383.2">After importing it from Prophet’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.384.1">plot</span></strong><span class="koboSpan" id="kobo.385.1"> package, we will loop through each regressor in</span><a id="_idIndexMarker379"/><span class="koboSpan" id="kobo.386.1"> that </span><strong class="source-inline"><span class="koboSpan" id="kobo.387.1">regressor_coefficients</span></strong><span class="koboSpan" id="kobo.388.1"> DataFrame to </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">plot it:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.390.1">
from prophet.plot import plot_forecast_component
fig, axes = plt.subplots(
                        len(regressor_coefficients(model)),
                        figsize=(10, 15))
for i, regressor in enumerate(
    regressor_coefficients(model)['regressor']):
    plot_forecast_component(model,
                            forecast,
                            regressor,
                            axes[i])
plt.show()</span></pre>
<p><span class="koboSpan" id="kobo.391.1">We plotted all of those as subplots in one figure, resulting in the </span><span class="No-Break"><span class="koboSpan" id="kobo.392.1">follow</span><a id="_idTextAnchor636"/><span class="koboSpan" id="kobo.393.1">ing diagram:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer203">
<span class="koboSpan" id="kobo.394.1"><img alt="Figure 9.7 – Divvy extra regressor plots" src="image/Fig_9.7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.395.1">Figure 9.7 – Divvy extra regressor plots</span></p>
<p><span class="koboSpan" id="kobo.396.1">At last, we can visualize the effects of these regressors individually. </span><span class="koboSpan" id="kobo.396.2">The magnitudes of these plots should match the </span><strong class="source-inline"><span class="koboSpan" id="kobo.397.1">coef</span></strong><span class="koboSpan" id="kobo.398.1"> values in the DataFrame created with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.399.1">regressor_coefficients</span></strong><span class="koboSpan" id="kobo.400.1"> function seen in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.401.1">Figure 9</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.402.1">.6</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.403.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.404.1">One final note regarding additional regressors in Prophet: they are always modeled as a linear relationship. </span><span class="koboSpan" id="kobo.404.2">This means that, for example, our extra regressor of temperature, which was found to increase ridership by 1.2% for every degree increase, is modeling a trend that will continue to infinity. </span><span class="koboSpan" id="kobo.404.3">That is, if the temperature were to spike to 120 degrees Fahrenheit, there’s no way for us to change the linear relationship and inform Prophet that ridership will </span><a id="_idIndexMarker380"/><span class="koboSpan" id="kobo.405.1">probably decrease now that it’s getting so </span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">hot outside.</span></span></p>
<p><span class="koboSpan" id="kobo.407.1">Although this is a </span><a id="_idTextAnchor637"/><span class="koboSpan" id="kobo.408.1">limitation of Prophet as currently designed, in practice, it is not always a great problem. </span><span class="koboSpan" id="kobo.408.2">A linear relationship is very often a good proxy for the actual relationship, especially for a small range of data, and will still add a lot of additional information to your model to enrich </span><span class="No-Break"><span class="koboSpan" id="kobo.409.1">yo</span><a id="_idTextAnchor638"/><a id="_idTextAnchor639"/><span class="koboSpan" id="kobo.410.1">ur forecasts.</span></span></p>
<h1 id="_idParaDest-107"><a id="_idTextAnchor640"/><span class="koboSpan" id="kobo.411.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.412.1">In this chapter, you learned a generalized method to add any additional regressors beyond the holidays, which you learned how to add earlier. </span><span class="koboSpan" id="kobo.412.2">You learned that adding both binary regressors (such as weather conditions) and continuous regressors (such as temperature) uses the same </span><strong class="source-inline"><span class="koboSpan" id="kobo.413.1">add_regressor</span></strong><span class="koboSpan" id="kobo.414.1"> method. </span><span class="koboSpan" id="kobo.414.2">You also learned how to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.415.1">regressor_coefficients</span></strong><span class="koboSpan" id="kobo.416.1"> function in Prophet’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.417.1">utilities</span></strong><span class="koboSpan" id="kobo.418.1"> package to inspect the effects of your </span><span class="No-Break"><span class="koboSpan" id="kobo.419.1">additional regressors.</span></span></p>
<p><span class="koboSpan" id="kobo.420.1">Although you may now want to add all sorts of extra regressors to your forecasts, you also learned that Prophet requires all additional regressors to have defined values going into the future or else there’s no information to inform a forecast. </span><span class="koboSpan" id="kobo.420.2">This is why we only forecasted 2 weeks out when using </span><span class="No-Break"><span class="koboSpan" id="kobo.421.1">weather data.</span></span></p>
<p><span class="koboSpan" id="kobo.422.1">In the next chapter, we are going to look at how Prophet handles outliers and how you can exert greater control over the </span><span class="No-Break"><span class="koboSpan" id="kobo.423.1">process yourself.</span></span></p>
</div>
<div>
<div class="IMG---Figure" id="_idContainer205">
</div>
</div>
</body></html>