- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Conformal Prediction for Time Series and Forecasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will explore the exciting field of **conformal prediction**
    for time series and forecasting. Conformal prediction is a powerful tool for producing
    **prediction intervals** (**PIs**) for point forecasting models, and we will show
    you how to apply this technique to your data using open source libraries. This
    chapter will take you on a journey from understanding the fundamentals of **uncertainty
    quantification** (**UQ**) in time series to the intricate mechanisms behind conformal
    prediction in forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: With this chapter, you will have a solid understanding of the various approaches
    to producing PIs, and you will be able to build your PIs using conformal prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: UQ for time series and forecasting problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The concept of PIs in forecasting applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Various approaches to producing PIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conformal prediction for time series and forecasting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll be able to apply the concepts and open source
    tools that will be discussed to your industry applications, providing robust forecasting
    with well-defined uncertainty bounds. These lessons will enhance your forecasting
    abilities, giving your models an edge by allowing you to add confidence measures
    to your predictions.
  prefs: []
  type: TYPE_NORMAL
- en: UQ for time series and forecasting problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: UQ is not just a sophisticated addition to time series forecasting; it is a
    fundamental aspect that provides invaluable insights into the nature of the predictions.
    Let’s look at why it’s important and a brief history of its development.
  prefs: []
  type: TYPE_NORMAL
- en: The importance of UQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'UQ is a critical component of time series forecasting. While a forecast model
    may provide accurate predictions on average, understanding the uncertainty around
    those predictions is equally essential. There are several key reasons why properly
    quantifying uncertainty is vital for practical time series forecasting:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Risk assessment**: In many domains, such as finance, healthcare, and environmental
    science, forecasting is closely linked with decision-making. Understanding the
    uncertainty in predictions aids in assessing potential risks, thus enabling informed
    decisions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model confidence**: UQ provides an understanding of the confidence in each
    model’s predictions. This can lead to a more refined model selection and help
    identify areas where the model may be underperforming.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimization of resources**: By acknowledging the uncertainty, resources
    can be allocated more optimally. For example, understanding the uncertainty in
    demand forecasts in supply chain management may lead to better inventory management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regulatory compliance**: In some industries, quantifying the uncertainty
    of forecasts might be mandated by regulatory bodies, emphasizing the importance
    of a systematic approach to UQ'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having established the critical role of UQ, we now turn to its evolution.
  prefs: []
  type: TYPE_NORMAL
- en: The history of UQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The need to provide reliable measures of uncertainty alongside time series
    forecasts has long been recognized. Over the decades, advances in statistical
    and computational methods have enabled more sophisticated approaches to quantifying
    uncertainty. Some of the significant historical developments are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Early statistical methods**: The roots of UQ in time series can be traced
    back to the early statistical models. Techniques such as PIs were applied to provide
    bounds on predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bayesian approaches**: Bayesian methods brought a probabilistic perspective
    to UQ, allowing for more nuanced uncertainty descriptions. Bayesian forecasting
    models incorporate prior beliefs and likelihood functions to create posterior
    distributions, representing uncertainty comprehensively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bootstrapping and resampling**: Techniques such as bootstrapping enabled
    UQ without strong parametric assumptions, making it accessible for more complex
    models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The historical developments we’ve explored provided a critical foundation for
    UQ in time series analysis. Now, let’s dive deeper into some of those early statistical
    techniques and see how they enabled the first steps toward quantifying forecast
    uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Early statistical methods – the roots of UQ in time series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: UQ has always been a critical part of statistical analysis, and its role in
    time series forecasting is no different. The early days of statistical modeling
    laid the foundation for understanding uncertainty in predictions, and various
    techniques were developed to provide bounds on forecasts. Here, we will investigate
    some of these early statistical methods and see how they paved the way for the
    modern understanding of UQ in time series analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the seminal contributions to UQ in time series forecasting was the concept
    of confidence intervals:'
  prefs: []
  type: TYPE_NORMAL
- en: '**T-distribution for small samples**: When dealing with small sample sizes,
    the t-distribution provided more accurate intervals, accounting for the increased
    uncertainty due to limited data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interval estimation for autoregressive models**: Specific techniques were
    developed for time series models such as ARIMA, where the confidence intervals
    could be derived for the parameters and forecasts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Along with confidence intervals, prediction bounds were developed to encapsulate
    the uncertainty associated with future observations. These bounds considered the
    uncertainty in the model parameters and the random nature of future errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prediction error variance**: By estimating the prediction error variance,
    bounds could be created around the forecast values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forecast error decomposition**: Techniques were developed to decompose the
    forecast error into various components, providing insights into the sources of
    uncertainty'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While these early methods were highly influential, they often relied on strong
    assumptions about the underlying distributions and model structure. The parametric
    nature of these techniques made them less flexible in dealing with complex, non-linear
    time series data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Non-parametric methods**: Recognizing these limitations led to the development
    of non-parametric methods that didn’t rely on specific distributional assumptions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Robust statistical techniques**: Efforts were also made to create more robust
    statistical methods that could handle outliers and non-constant variance, extending
    the scope of early UQ methods'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The early statistical methods for UQ in time series laid the groundwork for
    subsequent advancements in this field. The principles embedded in these techniques,
    such as confidence intervals and prediction bounds, continue to be central to
    modern UQ approaches. They represent a legacy that’s been built upon and refined,
    leading to various current methods for understanding uncertainty in time series
    forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s dive deeper into some of those early statistical techniques and see
    how they enabled the first steps toward quantifying forecast uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Modern machine learning approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The previous sections explored the early statistical foundations of UQ for
    time series predictions. These techniques, while pioneering, relied heavily on
    parametric assumptions and simple model structures. The rise of modern machine
    learning has enabled more flexible and robust approaches to quantifying uncertainty,
    overcoming some limitations of traditional methods. Let’s look at the key innovations
    in this area:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Modern machine learning approaches**: With the rise of machine learning,
    techniques such as dropout and ensemble methods have been developed to quantify
    uncertainty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conformal prediction**: Recently, conformal prediction has emerged as a robust
    framework for UQ. It provides a non-parametric approach, guaranteeing valid PIs
    under mild assumptions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UQ is integral to time series forecasting. It enriches the understanding of
    the predictions, facilitates better decision-making, and aligns with regulatory
    requirements. The evolution of UQ over time has led to diverse approaches, each
    adding value in different contexts.
  prefs: []
  type: TYPE_NORMAL
- en: The recent advent of conformal prediction, which will be explored later in this
    chapter, represents a significant advancement in this field, offering robust and
    universally applicable uncertainty measures.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, the emergence of flexible machine learning techniques has enabled
    robust new approaches to UQ that overcome the limitations of early statistical
    methods. This evolution has provided a diverse toolkit for quantifying uncertainty
    in time series forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will explore the concepts behind PIs, a foundation for communicating
    forecast uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of PIs in forecasting applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PIs are vital tools in forecasting, providing a range of plausible values within
    which a future observation is likely to occur. Unlike point forecasts, which give
    a single best estimate, PIs communicate the uncertainty surrounding that estimate.
  prefs: []
  type: TYPE_NORMAL
- en: This section explores the fundamental concepts behind PIs and their significance
    in various forecasting applications.
  prefs: []
  type: TYPE_NORMAL
- en: Definition and construction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PIs are constructed around a point forecast to represent the range within which
    future observations are expected to lie with a given confidence level. For example,
    a 95% PI implies that 95 of 100 future observations are expected to fall within
    the defined range.
  prefs: []
  type: TYPE_NORMAL
- en: 'PIs can take several forms, depending on the approach used to generate them.
    Two key distinguishing factors are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Symmetric versus asymmetric intervals**: PIs can be symmetric, where the
    bounds are equidistant from the point forecast, or asymmetric, reflecting differing
    uncertainty in different directions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parametric versus non-parametric methods**: PIs can be created using parametric
    (for example, assuming normal distribution) or non-parametric methods, depending
    on the underlying data distribution assumptions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The importance of forecasting applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'PIs play an essential role in various forecasting domains, and here’s why:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Decision making**: PIs enable decision-makers to assess risks and opportunities
    – for instance, they allow investors to gauge the volatility of an asset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model evaluation**: Comparing actual observations with PIs can be a part
    of model diagnostic checks, helping evaluate a model’s adequacy in capturing uncertainty'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimizing operations**: In supply chain management, PIs can aid in optimizing
    inventory by reflecting the uncertainty in demand forecasts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Communicating uncertainty**: PIs effectively communicate uncertainty to non-technical
    stakeholders, facilitating more nuanced discussions and planning'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Challenges and considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While highly valuable, constructing accurate and reliable PIs is not without
    challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Assumption sensitivity**: PIs may be sensitive to the underlying assumptions
    about the data distribution, and incorrect assumptions can lead to misleading
    intervals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Coverage and width trade-off**: Achieving the correct coverage probability
    (95%) often competes with the desire for narrow intervals. Wider intervals may
    cover the desired percentage of observations but may need to be more informative.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Computational complexity**: Some methods for constructing PIs can be computationally
    intensive, particularly with large datasets or complex models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PIs are at the heart of UQ in forecasting applications, offering a more comprehensive
    view of prospects. They support strategic decision-making, enable model evaluations,
    and foster effective communication of uncertainty. Understanding the concept and
    practicalities of PIs is essential for anyone working with forecasting models,
    providing a means to navigate and leverage the inherent uncertainty in predicting
    future outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: While PIs bring invaluable insights, constructing accurate and informative intervals
    is only sometimes straightforward, as we’ve seen. However, decades of research
    have produced diverse techniques to tackle these challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Various approaches to producing PIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PIs are an essential tool in forecasting, allowing practitioners to understand
    the range within which future observations are likely to fall. Various approaches
    have been developed to produce these intervals, each with advantages, applications,
    and challenges. This section will explore the most prominent techniques for creating
    PIs.
  prefs: []
  type: TYPE_NORMAL
- en: Parametric approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Parametric approaches make specific assumptions about the distribution of forecast
    errors to derive PIs. Some standard techniques in this category are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Normal distribution assumptions**: By assuming that the forecast errors follow
    a normal distribution, we can compute symmetric PIs based on standard errors and
    critical values from the normal distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Time series models**: Models such as ARIMA and exponential smoothing can
    generate PIs by modeling the underlying stochastic process and using the estimated
    parameters to produce intervals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generalized linear models (GLMs)**: GLMs extend linear models to non-normal
    distributions, allowing for more flexible PI construction. GLMs broaden linear
    regression to response variables that follow distributions other than the normal
    distribution. GLMs allow us to model data with non-normal responses such as binary,
    count, or categorical outcomes. Like linear models, GLMs relate the mean response
    to explanatory variables through a link function and linear predictor. However,
    the response distribution can be non-normal, handled via an exponential family
    log-likelihood. Here are some common examples of GLMs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression for binary classification (logit link, binomial distribution)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Poisson regression for count data (log link, Poisson distribution)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Multinomial regression for categorical responses (logit link, multinomial distribution)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GLMs estimate coefficients for each feature, just like ordinary linear regression.
    However, by expanding the response distribution and link function, they can model
    non-normal processes needed for regression-style prediction with non-continuous
    targets.
  prefs: []
  type: TYPE_NORMAL
- en: Their flexibility makes GLMs helpful in constructing PIs for a broader range
    of problems compared to standard linear regression. The intervals incorporate
    the modeled response distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Non-parametric approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Non-parametric methods aim to construct PIs without making strict assumptions
    about the distribution of forecast errors. Some fundamental techniques in this
    category are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bootstrapping**: Bootstrapping involves resampling the observed data and
    estimating the distribution of forecasts, from which PIs can be derived'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quantile regression**: This method directly models the response variable’s
    quantiles, enabling the construction of PIs without specific distributional assumptions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Empirical percentiles**: Using historical and empirical percentiles, we can
    construct PIs without parametric assumptions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Bayesian statistical framework provides a probabilistic approach to generating
    PIs by explicitly modeling different sources of uncertainty. Two critical techniques
    for Bayesian PI construction are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bayesian forecasting models**: Bayesian models provide a probabilistic framework
    that captures uncertainty in parameters and predictions, allowing for the direct
    calculation of PIs from posterior distributions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monte Carlo Markov Chain (MCMC) sampling**: MCMC sampling can be used to
    simulate the posterior distribution of a Bayesian model, enabling the construction
    of PIs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The flexibility of modern machine learning models provides new opportunities
    for generating PIs in a data-driven manner. By leveraging techniques tailored
    for these highly complex and nonlinear models, valid PIs can be obtained without
    strict distributional assumptions. Let’s look at some machine learning approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ensemble methods**: Techniques such as random forest and gradient boosting
    machines can create PIs by using the distribution of predictions from individual
    ensemble members'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neural network quantile regression**: Neural networks can be trained to predict
    specific quantiles, forming the basis for PIs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dropout as a Bayesian approximation**: In deep learning, dropout can approximate
    Bayesian inference, allowing for UQ and PI construction'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conformal prediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a non-parametric, distribution-free framework, conformal prediction can be
    integrated with various modeling approaches to produce PIs. Producing PIs for
    time series forecasting models using conformal prediction methods is the main
    subject of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Producing PIs is multifaceted, with various approaches tailored to different
    data types, models, and requirements. From traditional statistical methods to
    cutting-edge machine learning techniques and conformal prediction, the field of
    PI construction is rich and diverse. Understanding these approaches empowers practitioners
    to select the most appropriate method for their forecasting application, balancing
    accuracy, interpretability, computational efficiency, and other considerations.
    Whether operating within rigorous parametric assumptions or exploring flexible
    non-parametric techniques, these methods offer valuable insights into the uncertainty
    inherent in forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction, a robust framework for generating PIs for point forecasting
    models, has been widely utilized in time series and forecasting applications.
    Numerous studies have chronicled the evolution and popularity of various conformal
    prediction models for time series forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction for time series and forecasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating reliable PIs for time series forecasting has been a longstanding, intricate
    challenge that remained unsolved for years until conformal prediction emerged.
  prefs: []
  type: TYPE_NORMAL
- en: This problem was underscored during the 2018 M4 Forecasting Competition, which
    necessitated participants to supply PIs and point estimates.
  prefs: []
  type: TYPE_NORMAL
- en: In the research paper titled *Combining Prediction Intervals in the M4 Competition*,
    (https://www.sciencedirect.com/science/article/abs/pii/S0169207019301141), Yael
    Grushka-Cockayne from the Darden School of Business and Victor Richmond R. Jose
    from Harvard Business School scrutinized 20 interval submissions. They assessed
    both the calibration and precision of the predictions and gauged their performances
    across different time horizons. Their analysis concluded that the submissions
    were ineffective in accurately estimating uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble batch PIs (EnbPIs)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Conformal Prediction Intervals for Dynamic Time-Series* ([http://proceedings.mlr.press/v139/xu21h/xu21h.pdf](http://proceedings.mlr.press/v139/xu21h/xu21h.pdf)),
    by researchers Chen Xu and Yao Xie from Georgia Tech University, was the first
    paper to implement conformal prediction for time series forecasting and was presented
    at the prestigious conference ICML in 2021.'
  prefs: []
  type: TYPE_NORMAL
- en: EnbPI is currently one of the most popular implementations of conformal prediction
    for time series forecasting. It has been implemented in popular open source conformal
    prediction libraries such as MAPIE, Amazon Fortuna, and PUNCC.
  prefs: []
  type: TYPE_NORMAL
- en: The study introduces a technique for creating PIs not bound by any specific
    distribution for dynamic time series data. The EnbPI method encompasses a bootstrap
    ensemble estimator to formulate sequential PIs. Unlike classical conformal prediction
    methods that require data exchangeability, EnbPI does not require data exchangeability
    and has been custom-built for time series.
  prefs: []
  type: TYPE_NORMAL
- en: The data exchangeability assumption suggests that the sequence in which observations
    appear in the dataset doesn’t matter. However, this assumption does not apply
    to time series, where the sequence of data points is crucial. EnbPI doesn’t rely
    on data exchangeability, making it aptly suited for time series analysis.
  prefs: []
  type: TYPE_NORMAL
- en: PIs generated by EnbPI attain a finite-sample, approximately valid marginal
    coverage for broad regression functions and time series under the mild assumption
    of strongly mixing stochastic errors. Additionally, EnbPI is computationally efficient
    and avoids overfitting by not requiring data splitting or training multiple ensemble
    estimators. It is also scalable to producing arbitrarily many PIs sequentially
    and is well suited to a wide range of regression functions.
  prefs: []
  type: TYPE_NORMAL
- en: Time series data is dynamic and often non-stationary, meaning the statistical
    properties can change over time. While various regression functions exist for
    predicting time series, such as those using boosted trees or neural network structures,
    these existing methods often need help constructing accurate PIs. Typically, they
    can only create reliable intervals by placing restrictive assumptions on the underlying
    distribution of the time series, which may only sometimes be appropriate or feasible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a simplified version of the steps to build an EnbPI predictor:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Select a bootstrap ensemble estimator**: Any bootstrap ensemble estimator
    can be used with EnbPI.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Train the ensemble estimators**: The base forecasting model is trained multiple
    times on different bootstrap samples drawn from the original training data to
    generate the ensemble. Each bootstrap sample is created by sampling with replacement
    from the training set. This results in an ensemble of models with slightly different
    training data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Compute residuals**: For each point in t = 1,…, T, calculate the residuals
    using ensemble estimators that did not use point *t* for training. The aim is
    to use out-of-sample errors as a nonconformity measure to indicate the variance
    of predictions. All such out-of-sample errors are compiled into a single array.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Generate predictions**: The ensemble estimator generates point predictions
    for the test data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Construct PIs**: The PIs are constructed using the predictions from the ensemble
    estimator and a chosen significance level. Like many other conformal prediction
    methods, a quantile with a specified confidence level can be applied to the distribution
    of out-of-sample errors created in *step 3*. This quantile value is then used
    to create PIs by applying the quantile value to the aggregated point prediction
    produced using a trained ensemble estimator.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To demonstrate EnbPI in action, we will use Amazon Fortuna ([https://aws-fortuna.readthedocs.io/en/latest/index.html](https://aws-fortuna.readthedocs.io/en/latest/index.html))
    and follow its example, *Time series regression with EnbPI, a conformal prediction
    method* ([https://aws-fortuna.readthedocs.io/en/latest/examples/enbpi_ts_regression.html](https://aws-fortuna.readthedocs.io/en/latest/examples/enbpi_ts_regression.html)).
    You can find the Jupyter notebook, `Chapter_08_EnbPI_ipynb.ipynb`, in this book’s
    GitHub repository: [https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_08_EnbPI.ipynb](https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_08_EnbPI.ipynb).
    Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will install Amazon Fortuna with `pip install`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will use the `Bike sharing demand` dataset, available on scikit-learn:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s inspect the dataset header:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Bike sharing demand dataset](img/B19925_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Bike sharing demand dataset
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains information about bike-sharing rentals, including additional
    information such as temperature, humidity, and wind speed. The problem requires
    forecasting bike sharing demand expressed in the count of rented bikes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can calculate the demand, grouped by weekday and hour, and illustrate the
    results with the following plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Average hourly bike demand during the week](img/B19925_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – Average hourly bike demand during the week
  prefs: []
  type: TYPE_NORMAL
- en: EnbPI requires bootstrapping the data – that is, sampling with replacement random
    subsets of the time series and training a model for each sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can test the `DataFrameBootstrapper` class and look at an example of bootstrapped
    data samples. For example, the first bootstrapped sample looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Example of a bootstrapped sample](img/B19925_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – Example of a bootstrapped sample
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check for duplicates in this bootstrapped sample – as bootstrapping
    is with replacement, as expected, we can see that some objects have been duplicated
    during bootstrapping:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Duplicated objects in the bootstrapped sample](img/B19925_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – Duplicated objects in the bootstrapped sample
  prefs: []
  type: TYPE_NORMAL
- en: We can now train the model for each bootstrapped sample. To evaluate conformal
    PIs, we can calculate the coverage probability, which measures the percentage
    of test observations that fall within the generated intervals, and check what
    proportion of intervals contain the point predictions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ultimately, we evaluate the dimension of the conformal intervals, which, in
    this scenario where no online feedback is given, are assumed by EnbPI to be uniform
    for all intervals.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The percentage of intervals containing actual targets is `0.95`, while the size
    of the conformal intervals is `0.4446`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Using EnbPI, we created PIs based on a user-defined coverage of 0.95\. Contrary
    to most other UQ methods, which often fail to meet the user-specified confidence
    level, conformal prediction meets user requirements. It consistently generates
    PIs that align with the user-defined confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s plot the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Predictions using EnbPI](img/B19925_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – Predictions using EnbPI
  prefs: []
  type: TYPE_NORMAL
- en: The EnbPI model is adept at avoiding overfitting, ensuring computational efficiency,
    and is scalable for producing numerous PIs sequentially. In practice, the EnbPI
    model creates PIs in line with user-defined confidence levels, ensuring reliability
    in its predictions. We have provided practical examples using Amazon Fortuna and
    the bike-sharing demand dataset from scikit-learn, demonstrating the model’s capability
    to accurately gauge **prediction interval coverage probability** (**PICP**) and
    the size of the conformal intervals.
  prefs: []
  type: TYPE_NORMAL
- en: NeuralProphet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`NeuralProphet` is a forecasting framework built on PyTorch that merges the
    interpretability of traditional methods with the scalability of deep learning
    models. It’s trained using standard deep learning techniques and provides accurate
    and interpretable results for various forecasting applications.'
  prefs: []
  type: TYPE_NORMAL
- en: The framework introduces local context through auto-regression and covariate
    modules, which can be set up as either classical linear regression or neural networks.
    This allows `NeuralProphet` to handle short-term forecasting while capturing complex
    nonlinear relationships between variables. The auto-regression module models the
    dependency of the target variable on its past values, while the covariate module
    addresses its dependence on other known variables.
  prefs: []
  type: TYPE_NORMAL
- en: '`NeuralProphet` is designed to be user-friendly, offering reliable defaults
    and automatic hyperparameters for beginners while allowing experienced users to
    input domain knowledge through optional model customizations. As a successor to
    Facebook Prophet, it retains the foundational components but improves precision
    and scalability.'
  prefs: []
  type: TYPE_NORMAL
- en: The essential model components of `NeuralProphet` include the trend, seasonality,
    holidays, auto-regression, and covariate modules. These additive components can
    be scaled by the trend for a multiplicative effect. Each module has its inputs
    and modeling processes, but all modules must produce *h* outputs, where *h* is
    the number of steps to be forecasted into the future at once.
  prefs: []
  type: TYPE_NORMAL
- en: '`NeuralProphet` incorporates conformal prediction techniques into its forecasting
    workflow, specifically the **inductive (split) conformal prediction** (**ICP**)
    approach. The key steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NeuralProphet` uses this data to create an initial PI.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`NeuralProphet` evaluates the accuracy of its predictions by comparing the
    actual target variable values with the predicted outputs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`NeuralProphet` measure the uncertainty in its forecasts. This is a crucial
    step as understanding this variance is essential for generating precise PIs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`NeuralProphet` formulates the final PI. This interval provides a range within
    which the actual future values are expected to lie with a predefined confidence
    level.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`NeuralProphet` integrates conformal prediction methods into its forecasting
    workflow, particularly employing the ICP strategy. This approach enables the creation
    of statistically robust uncertainty sets or intervals for model predictions, enhancing
    their reliability and confidence.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at two methodologies that are utilized by `NeuralProphet` within
    the conformal prediction framework to establish PIs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`NeuralProphet` provides a singular output as a point estimate for each instance,
    calculated based on a 50th-percentile regression. The `NeuralProphet` object requires
    at least one upper and lower quantile pair as parameters to create a PI. For instance,
    for a 90% probability of the actual value falling within the estimated interval,
    the confidence level is set at 0.9, defining two quantiles at 0.05 and 0.95, corresponding
    to the 5th and 95th percentiles of the forecast distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NeuralProphet` model, the `conformal_predict` method can be utilized to produce
    a conformal forecast. `NeuralProphet` uses two variants of UQ – naïve conformal
    prediction and **conformalized quantile regression** (**CQR**), which we looked
    at in [*Chapter 7*](B19925_07.xhtml#_idTextAnchor073).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To demonstrate how `NeuralProphet` can create PIs using conformal prediction,
    we will follow the notebook at https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_08_NeuralProphet.ipynb,
    which is based on UQ in the `NeuralProphet` tutorial ([https://neuralprophet.com/how-to-guides/feature
    guides/uncertainty_quantification.html](https://neuralprophet.com/how-to-guides/feature-guides/uncertainty_quantification.html)).
  prefs: []
  type: TYPE_NORMAL
- en: The dataset uses hospital electric load data from a San Francisco hospital electric
    load dataset ([https://github.com/ourownstory/neuralprophet-data](https://github.com/ourownstory/neuralprophet-data)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the header of the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – San Francisco hospital load dataset](img/B19925_08_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – San Francisco hospital load dataset
  prefs: []
  type: TYPE_NORMAL
- en: '`NeuralProphet` requires the data in the specific format with a time column
    named *ds* and time series values in a column called *y*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a `NeuralProphet` object that specifies a data splitting ratio
    between 0 and 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, `NeuralProphet`’s forecasting provides a singular output: a point
    estimate for each instance. This estimate is derived from a 50th percentile regression.
    A `NeuralProphet` object requires at least one upper and lower quantile pair as
    its parameters to establish a PI. Yet, within a `NeuralProphet` model, we can
    define multiple quantiles as desired.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, say we want to forecast a hospital’s electric load with 90% PIs.
    We want 90% of the actual values to fall within the generated intervals.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could train a quantile regression model to predict three quantiles – the
    5th, 50th, and 95th percentiles. The 5th and 95th quantiles would provide the
    lower and upper bounds for 90% PIs. The 50th quantile would provide the median
    point forecast:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Quantile regression is used in `NeuralProphet` to generate PIs. It trains the
    model using a specialized loss function called pinball loss, also known as quantile
    loss.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike simple error minimization, pinball loss weights errors asymmetrically
    based on the quantile. Under-prediction is penalized more heavily than over-prediction
    for an upper quantile such as 90%. The opposite is valid for a lower quantile,
    such as 10%.
  prefs: []
  type: TYPE_NORMAL
- en: This matches the inherent meaning of the quantile – 90% indicates we expect
    90% of the actual values to lie below the prediction. So, errors where the actual
    value exceeds the forecast violate that more significantly.
  prefs: []
  type: TYPE_NORMAL
- en: By minimizing the asymmetric pinball loss during training, the model learns
    quantile lines that reflect the appropriate probability of actual values falling
    above or below based on the data. The upper and lower quantiles then form the
    PI.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now fit the model and create a DataFrame with the results, forecasting
    30 periods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can visualize the PIs from quantile regression using a plot. The solid line
    shows the median forecast, while the shaded area depicts the interval between
    the lower and upper quantile lines. This represents the range expected to contain
    the actual values with the specified confidence level:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Forecasting hospital electric load using quantile regression](img/B19925_08_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – Forecasting hospital electric load using quantile regression
  prefs: []
  type: TYPE_NORMAL
- en: In summary, quantile regression allows `NeuralProphet` to generate PIs by training
    the model to forecast quantiles that serve as interval bounds. The pinball loss
    function enables quantile-based UQ.
  prefs: []
  type: TYPE_NORMAL
- en: Quantile regression relies on modeling assumptions and requires specifying the
    quantiles of interest. Next, we’ll explore how `NeuralProphet` can produce distribution-free
    PIs using conformal prediction techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Conformal prediction in NeuralProphet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`NeuralProphet` employs the split conformal prediction method. This approach
    necessitates a holdout or calibration set. The dataset must be divided into three
    sets to execute split conformal prediction: training, calibration, and testing.
    An initial PI is established using the model trained on the training dataset.
    Uncertainty is then gauged by comparing the calibration set’s target variables
    with the predicted values. This quantified uncertainty is subsequently incorporated
    into both ends of the prediction value to form the final conformal PI.'
  prefs: []
  type: TYPE_NORMAL
- en: Within `NeuralProphet`, you can choose either the naïve (based on the absolute
    residual) or CQR for conformal prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a calibration set using the data splitting function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: You can build any `NeuralProphet` model you deem fit as the base model. The
    calibration process in conformal prediction would be later added to the base model
    to quantify the uncertainty in our final estimation. We are interested in knowing
    how conformal prediction affects different models.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we will compare the conformal prediction results between a simple
    quantile regression and a complex four-layer autoregression model in our illustration.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will specify 72 hours as lags and create a simple quantile regression model
    as base model 1\. We will also create a four-layer autoregression model as base
    model 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: After configuring the model, we must fit the model with the train set. Suppose
    you have further split the training dataset into training and validation. In that
    case, you can either concatenate the two datasets in one dataset for training
    or assign the training and validation datasets as two separate parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Feed the training subset in the configured `NeuralProphet` models. Then, configure
    the hourly frequency by assigning `H` to the `freq` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s use the fitted base model to forecast both the point prediction and the
    quantile regression PIs for the testing dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Option 1 – naïve conformal prediction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After training the base model, we can carry out the calibration process using
    the naïve module. The steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Predict the output value of the instances within the calibration set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the absolute residual by comparing the actual and predicted values
    for each observation in the calibration set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sort all residuals in ascending order.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the quantile of the distribution of the absolute residuals with the desired
    confidence level.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the quantile of the distribution of the absolute residuals to make the final
    PIs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Returning to our example, we need to denote the parameter value for the calibration
    set and the significant level (alpha) for conformal prediction on top of our pre-trained
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We can now enable conformal prediction using pre-trained models.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '`NeuralProphet` can plot the one-sided interval width versus the selected confidence
    level:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – The one-side interval width versus the confidence level](img/B19925_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 – The one-side interval width versus the confidence level
  prefs: []
  type: TYPE_NORMAL
- en: This plot demonstrates how the width of the PI changes with different confidence
    levels (1-alpha).
  prefs: []
  type: TYPE_NORMAL
- en: Option 2 – CQR
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'CQR operates in the following manner within the CQR module:'
  prefs: []
  type: TYPE_NORMAL
- en: Non-conformity scores are computed as the disparities between data points from
    the calibration dataset and their closest prediction quantile. These scores offer
    insight into the fit of the data to the existing quantile regression model. Data
    points within the quantile regression interval yield negative non-conformity scores,
    while those outside the interval produce positive scores.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The non-conformity scores are then organized in order.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The alpha value is determined so that a fraction of the scores greater than
    alpha matches the error rate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An amount of alpha adjusts the regression model’s quantiles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on alpha’s value, the CQR model can be interpreted in two ways.
  prefs: []
  type: TYPE_NORMAL
- en: When the one-sided PI width adjustment is positive, the CQR expands beyond the
    QR intervals. This suggests that the CQR perceives the QR interval as overly confident.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if the adjustment is negative, the CQR narrows the QR intervals,
    indicating that the QR interval might be overly cautious.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can run the CQR option using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we can plot the PIs to examine how this CQR method affects the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Forecasting hospital electric load using quantile regression
    (the CQR option)](img/B19925_08_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 – Forecasting hospital electric load using quantile regression (the
    CQR option)
  prefs: []
  type: TYPE_NORMAL
- en: We can see that `NeuralProphet` has produced excellent PIs using conformal prediction
    with the `cqr` option.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s learn how to evaluate performance and obtain some insights by comparing
    various UQ methods we have used.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are using the interval width and miscoverage rate as the performance metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '`interval_width`: This is the average PI, or `q_hat`, multiplied by two because
    it is static or non-adaptive; this is also known as the **efficiency metric**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`miscoverage_rate`: This is the actual miscoverage error rate on the OOS test
    set; this is also known as the **validity metric**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s evaluate the models we trained earlier. Based on the results in the notebook,
    we obtain the following conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: Quantile regression does not provide the required coverage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The more complex the underlying model, the more accurate it is, hence the lower
    *interval width* of CP intervals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the default model, CQR outputs a narrower *PI width* than naïve
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conformal prediction with Nixtla
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will use the notebook at https://github.com/PacktPublishing/Practical-Guide-to-Applied-Conformal-Prediction/blob/main/Chapter_08_NixtlaStatsforecast.ipynb
    to illustrate how to use conformal prediction to create PIs for popular statistic
    and econometrics models.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the hourly dataset from the M4 Competition:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s install Nixtla’s `statsforecast`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we must import the necessary modules, including specifically Nixtla’s
    modules:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we must load the train and test datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s look at the dataset’s structure. Similar to `NeuralProphet`, `statsforecast`
    requires columns to be named in a specific way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.10 – Hourly dataset from the M4 Competition](img/B19925_08_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 – Hourly dataset from the M4 Competition
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now train the models; we will only use the first eight series of the
    dataset to reduce the total computational time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.11 – Hourly series from the M4 Competition](img/B19925_08_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.11 – Hourly series from the M4 Competition
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a list of models and instantiation parameters. To use these models,
    we need to import them from `statsforecast.models` and then instantiate them.
    Given that we’re working with hourly data, we need to set `seasonal_length=24`
    in the models that require this parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To instantiate a new `StatsForecast` object, we need the following parameters:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`df`: The DataFrame that contains the training data.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`models`: The list of models defined in the previous step.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`freq`: A string indicating the frequency of the data. See pandas’ available
    frequencies.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_jobs`: An integer that indicates the number of jobs used in parallel processing.
    Use `-1` to select all cores:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE81]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE82]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE83]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE84]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE85]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we’re ready to generate the point forecasts and the PIs. To do this, we’ll
    use the forecast method, which takes two arguments:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`h`: An integer that represents the forecasting horizon. In this case, we’ll
    forecast the next 48 hours.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`level`: A list of floats with the confidence levels of the PIs. For example,
    `level=[95]` means that the range of values should include the actual future value
    with a probability of 95%:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE87]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE88]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE89]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can plot the PIs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here’s the plot for this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.12 – Forecasting hourly series with a seasonal naïve benchmark](img/B19925_08_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.12 – Forecasting hourly series with a seasonal naïve benchmark
  prefs: []
  type: TYPE_NORMAL
- en: Multi-quantile losses and statistical models can provide PIs. Still, the problem
    is that these are uncalibrated, meaning that the actual frequency of observations
    falling within the interval does not align with its confidence level. For example,
    a calibrated 95% PI should contain the actual value in repeated sampling 95% of
    the time. On the other hand, an uncalibrated 95% PI might contain the true value
    only 80% of the time or 99% of the time. In the first case, the interval is too
    narrow and underestimates the uncertainty, while in the second case, it is too
    broad and overestimates the uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical methods also often assume normality. Here, we calibrated PIs produced
    by statistical models using conformal prediction. Conformal PIs use cross-validation
    on a point forecaster model to generate the intervals. No prior probabilities
    are needed, and the output is well calibrated. No additional training is required,
    and the model is treated as a black box. The approach is compatible with any model.
    `Statsforecast` now supports conformal prediction on all available models.
  prefs: []
  type: TYPE_NORMAL
- en: '`StatsForecast` can train multiple models on different time series efficiently.
    These models can generate probabilistic forecasts, producing point forecasts and
    PIs. For this example, we’ll use `SimpleExponentialSmoothing` and ADIDA (a model
    for intermittent demand), which do not provide a PI natively. Thus, using conformal
    prediction to generate the PI makes sense. We’ll also show how to use it with
    ARIMA to provide PIs that don’t assume normality.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To use these models, we first need to import them from `statsforecast.models`,
    after which we need to instantiate them, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s plot the forecasts that are produced using conformal prediction for ARIMA:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13 – PIs produced for ARIMA using conformal prediction](img/B19925_08_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.13 – PIs produced for ARIMA using conformal prediction
  prefs: []
  type: TYPE_NORMAL
- en: This section explored implementations of conformal prediction for time series
    forecasting in several popular open source libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Fortuna provides conformal prediction capabilities through its EnbPI
    module. This allows us to generate non-parametric PIs by wrapping any ensemble
    model with bootstrap resampling. We saw how EnbPI leverages an ensemble to approximate
    the forecast distribution without assumptions.
  prefs: []
  type: TYPE_NORMAL
- en: Nixtla, an open source library for time series modeling, includes conformal
    prediction functions for forecasting tasks. We examined how its CP module can
    take any underlying model and add conformal PIs. Nixtla also supports online conformal
    prediction for adaptive intervals.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `NeuralProphet` natively integrates conformal prediction and quantile
    regression to quantify uncertainty. We examined its ICP approach, which uses a
    calibration set to refine initial intervals. This generates valid prediction regions
    without relying on distributional assumptions.
  prefs: []
  type: TYPE_NORMAL
- en: By incorporating conformal prediction, these libraries make robust and accessible
    UQ available to time series forecasters in Python. The diversity of implementations
    demonstrates the flexibility of conformal prediction as a model-agnostic framework
    that can be applied to any forecasting method.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter taught you how to apply conformal prediction to time series forecasting.
    Conformal prediction is a powerful technique for crafting PIs for point forecasting
    models.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter also offered insights into how to harness this method using open
    source platforms.
  prefs: []
  type: TYPE_NORMAL
- en: We began by exploring UQ in a time series, delving into the significance of
    PIs, and showcasing various strategies to generate them.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of conformal prediction and its application in forecasting scenarios
    was central to this chapter. At this point, you are equipped with the knowledge
    to apply these methodologies in real-world settings, empowering your forecasting
    models with precise uncertainty bounds. Adding confidence measures to predictions
    ensures that the forecasts are accurate and reliable.
  prefs: []
  type: TYPE_NORMAL
- en: With a solid understanding of conformal prediction for time series, we will
    now focus on another critical application area – computer vision.
  prefs: []
  type: TYPE_NORMAL
