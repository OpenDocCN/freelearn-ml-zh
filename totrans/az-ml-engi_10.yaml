- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using Deep Learning in Azure Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Deep learning** is a subclass of machine learning. It is based on artificial
    neural networks, a programming paradigm inspired by the human biological nervous
    system, and it enables a computer to learn from a very large amount of observational
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: There are some machine learning problems – such as image recognition, image
    classification, object detection, speech recognition, and natural language processing
    – that traditional machine learning techniques do not provide performant solutions
    for, whereas deep learning techniques do. This chapter will show you the deep
    learning capabilities available within AML that you can use to solve some of the
    previously mentioned problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Labeling image data for training an object detection model by using the AML
    Data Labeling feature
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training an object detection model using Azure AutoML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying an object detection model to an online endpoint using the AML Python
    SDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To access your workspace, recall the steps from the previous chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://ml.azure.com](https://ml.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select your workspace name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the workspace user interface on the left side, click **Compute**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the **Compute** screen, select your compute instance and select **Start**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Start compute](img/B18003_10_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Start compute
  prefs: []
  type: TYPE_NORMAL
- en: Your compute instance status will change from **Stopped** to **Starting**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the previous chapter, we cloned the Git repository; if you have not already
    done so, continue to follow these steps. If you have already cloned the repository,
    skip to *step 7*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the terminal on your compute instance. Note the path will include your
    user in the directory. Type the following into the terminal to clone the sample
    notebooks into your working directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Clicking on the refresh icon shown in *Figure 10**.2* will update and refresh
    the notebooks displayed on your screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Refresh icon](img/B18003_10_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – Refresh icon
  prefs: []
  type: TYPE_NORMAL
- en: 'Review the notebooks in your `Azure-Machine-Learning-Engineering` directory.
    This will display the files cloned into your working directory, as shown in *Figure
    10**.3*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Azure-Machine-Learning-Engineering](img/B18003_10_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Azure-Machine-Learning-Engineering
  prefs: []
  type: TYPE_NORMAL
- en: Labeling image data using the Data Labeling feature of Azure Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the field of computer vision, object detection is a challenging task for
    predicting the location of objects in an image and predicting the object types.
    Just like any other supervised machine learning task, in order to train an object
    detection model, we need to have training data and, in this case, a lot of labeled
    data, as deep learning works best on a large labeled dataset. Data scientists
    who develop computer vision models know how tedious and time-consuming it can
    be to label images, and even more time-consuming when it comes to labeling images
    for object detection models. The **Azure Machine Learning** (**Azure ML**) service
    has a powerful feature called **Data Labeling**, which significantly enhances
    the user experience for image labeling, leveraging built-in capabilities such
    as ML-assisted labeling by automatically training a model to pre-label images
    for you to review, accelerating the labeling process.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, you will learn how to label your images for training an object
    detection model by leveraging the Data Labeling feature of Azure ML by following
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the `chapter 10` folder of the cloned repository of this book that you
    have been using. You will see the `images` folder, which has two subfolders: `train`
    and `test`. You will be using the images in the `train` folder in the next step.
    Please note that these images were cloned to our repository from the public repository
    hosted at [https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Navigate to the Azure ML workspace and select **Data Labeling** from the left
    menu bar and then click **Add project**, as shown in *Figure 10**.4*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Creating a new Data Labeling project](img/B18003_10_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – Creating a new Data Labeling project
  prefs: []
  type: TYPE_NORMAL
- en: 'Go ahead and give your project a name, then select **Image** for **Media type**
    and **Object Identification (Bounding Box)** for **Labeling task type**, and click
    **Next**, as shown in *Figure 10**.5*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Filling out the project details](img/B18003_10_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – Filling out the project details
  prefs: []
  type: TYPE_NORMAL
- en: 'You can skip the next step and go to **Select or create data** and click **Create**
    to create your dataset. Pick a name and type in a description for your image data
    asset and then click **Next**, as shown in *Figure 10**.6*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.6 – Creating an image data asset](img/B18003_10_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – Creating an image data asset
  prefs: []
  type: TYPE_NORMAL
- en: 'Select **From local files**, as shown in *Figure 10**.7*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Selecting the image data source](img/B18003_10_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – Selecting the image data source
  prefs: []
  type: TYPE_NORMAL
- en: 'Select a datastore for uploading your images, as shown in *Figure 10**.8*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Selecting the storage type and the datastore for your images](img/B18003_10_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.8 – Selecting the storage type and the datastore for your images
  prefs: []
  type: TYPE_NORMAL
- en: 'Click `train` folder from *step 1*, select all the images as shown in *Figure
    10**.9*, and click **Next**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.9 – Uploading image files from your local drive](img/B18003_10_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.9 – Uploading image files from your local drive
  prefs: []
  type: TYPE_NORMAL
- en: Review the details for your image data asset and click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this step, you need to add labels for each object found in the images, which
    in this case will be `Two`, `Three`, `Four`, and so on up to `Ten`, as well as
    `Soldier`, `Queen`, and `King`, as shown in *Figure 10**.10*. Then click **Next**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Adding labels for the objects in all images](img/B18003_10_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.10 – Adding labels for the objects in all images
  prefs: []
  type: TYPE_NORMAL
- en: You can skip **Labeling instructions (optional)** and go to **ML assisted labeling
    (optional)**. Make sure **ML assisted labeling (optional)** is enabled, as shown
    in *Figure 10**.11*, and then click **Create project**:![Figure 10.11 – Reviewing
    and creating the data labeling project](img/B18003_10_011.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.11 – Reviewing and creating the data labeling project
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the project you just created from the project list, as shown in *Figure
    10**.12*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Data labeling project list](img/B18003_10_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.12 – Data labeling project list
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see the dashboard with the different options that the **Data Labeling**
    feature gives you to assist with the labeling process. Go ahead and click on **Label
    data** near the top, as shown in *Figure 10**.13*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.13 – Data labeling dashboard](img/B18003_10_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.13 – Data labeling dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'In this step, you will start labeling the images by drawing bounding boxes
    around objects found in the images and assigning labels associated with them,
    as shown in *Figure 10**.14*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.14 – Drawing bounding boxes around the objects and assigning them
    labels](img/B18003_10_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.14 – Drawing bounding boxes around the objects and assigning them
    labels
  prefs: []
  type: TYPE_NORMAL
- en: 'Once enough images have been labeled, ML-assisted labeling will start, and
    you will see that the next images are pre-labeled for you to quickly review the
    bounding boxes around the objects and their labels. After you are done labeling
    all the images, you will see the summary of your labeled data, such as **Label
    class distribution** and so on, as shown in *Figure 10**.15*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.15 – Label class distribution](img/B18003_10_015.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.15 – Label class distribution
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click **Export** and select **Labeled** for **Asset type** and **Azure
    ML dataset** for **Export format**, as shown in *Figure 10**.16*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.16 – Exporting your label image data](img/B18003_10_016.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.16 – Exporting your label image data
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see a message indicating that your data was exported successfully,
    as shown in *Figure 10**.17*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.17 – Labeled data exported successfully](img/B18003_10_017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.17 – Labeled data exported successfully
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you learned how to leverage Azure ML-assisted labeling to accelerate
    the labeling of your images for training an object detection model, which we will
    train in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Training an object detection model using Azure AutoML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will show you how to use Azure **Automated Machine Learning**
    (**AutoML**) to train an object detection model by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Automated ML** from the left navigation bar and then click **New
    Automated** **ML job**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.18 – Creating a new Automated ML job](img/B18003_10_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.18 – Creating a new Automated ML job
  prefs: []
  type: TYPE_NORMAL
- en: Select the image data asset that you created in the last section and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this step, you will configure the training job, as shown in *Figure 10**.19*.
    The first thing to notice is that AutoML has automatically set the task type to
    `playing_cards_experiment`. For **Target column**, select **label (List)**, and
    for the compute type, select **Compute cluster**. Since you do not have a GPU
    cluster (which is needed for deep learning tasks such as object detection), you
    will need to create one by selecting **+ New** and following the steps in the
    cluster creation wizard. Once your GPU compute cluster is created, it can be selected,
    and then you can click **Next**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.19 – Configuring the object detection job](img/B18003_10_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.19 – Configuring the object detection job
  prefs: []
  type: TYPE_NORMAL
- en: 'You can leave the default values that are selected for the algorithm details
    and the hyperparameter tuning settings, as shown in *Figure 10**.20*, and then
    click **Next**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.20 – Selecting the model and configuring the hyperparameter tuning](img/B18003_10_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.20 – Selecting the model and configuring the hyperparameter tuning
  prefs: []
  type: TYPE_NORMAL
- en: 'In this final step, you will set your validation type. We will again keep the
    default selected value, which is **Auto**, as shown in *Figure 10**.21*. Then,
    click **Finish** to start the model training:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.21 – Selecting the validation type](img/B18003_10_021.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.21 – Selecting the validation type
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on the size of your dataset, it can take anywhere between 15 minutes
    to a couple of hours for the model training to complete. Once the training job
    is completed, you can see it under **Recent Automated ML jobs**, as shown in *Figure
    10**.22*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.22 – Automated ML jobs](img/B18003_10_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.22 – Automated ML jobs
  prefs: []
  type: TYPE_NORMAL
- en: 'Select your latest run to see some statistics, such as **Best model summary**,
    **Primary metric**, **Algorithm name**, and **Duration**, as shown in *Figure
    10**.23*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.23 – Completed Automated ML job](img/B18003_10_023.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.23 – Completed Automated ML job
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you learned how to leverage Azure AutoML to train an object
    detection model using the image data that you had labeled by leveraging another
    tool called **Data Labeling**. In the next section, you will learn how to deploy
    the trained model to a managed online endpoint for consumption by client applications.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the object detection model to an online endpoint using the Azure ML
    Python SDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just like any other ML model, a deep learning model is not useful unless it
    is deployed and consumers can send data for inference. In our case, it would be
    sending image data and getting results back containing object types and locations
    within the raw image.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will show you how to use the Azure ML Python SDK to register
    your previously trained model and deploy it to an online endpoint for real-time
    inference by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `chapter 10` notebook, which is inside the repository that you cloned
    by following the steps in the *Technical requirements* section of the chapter.
    Please note that our repository for this chapter uses most of the code from the
    original repository hosted at `https://github.com/Azure/azureml-examples`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The first couple of cells import the required libraries and connect your notebook
    to the Azure ML workspace, as shown in *Figure 10**.24*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.24 – Importing the required libraries and connecting to the Azure
    ML workspace](img/B18003_10_024.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.24 – Importing the required libraries and connecting to the Azure
    ML workspace
  prefs: []
  type: TYPE_NORMAL
- en: 'You are going to use the MLflow library (in particular, the MLflow client)
    to access the models and other artifacts generated by AutoML. The next couple
    of cells show how to install the latest version of the MLflow packages, how to
    obtain the URI for the MLflow tracking server, and how to initialize the MLflow
    client, as shown in *Figure 10**.25*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.25 – Setting up the MLflow client to access the AutoML-trained
    model](img/B18003_10_025.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.25 – Setting up the MLflow client to access the AutoML-trained model
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the Azure ML workspace and click on the `AutoML_ada7f120-62e2-46fd-8ef7-59cae1106262`,
    as shown in *Figure 10**.26*. We will use the job name in the next step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.26 – Getting the AutoML job name](img/B18003_10_026.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.26 – Getting the AutoML job name
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have the AutoML job name, we can get the AutoML best model ID,
    as shown in *Figure 10**.27*. This will be used in a later step to retrieve the
    actual trained model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.27 – Getting the AutoML best model ID](img/B18003_10_027.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.27 – Getting the AutoML best model ID
  prefs: []
  type: TYPE_NORMAL
- en: 'The next cell creates a local folder and downloads the best model and its artifacts
    into this folder, as shown in *Figure 10**.28*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.28 – Downloading the best model in a local folder](img/B18003_10_028.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.28 – Downloading the best model in a local folder
  prefs: []
  type: TYPE_NORMAL
- en: 'The next cell creates a managed online endpoint for the model to be invoked
    from, as shown in *Figure 10**.29*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.29 – Creating an online endpoint for the model to be invoked from](img/B18003_10_029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.29 – Creating an online endpoint for the model to be invoked from
  prefs: []
  type: TYPE_NORMAL
- en: 'The next cell registers the model to the workspace, as shown in *Figure 10**.30*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.30 – Registering the best model to the Azure ML workspace](img/B18003_10_030.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.30 – Registering the best model to the Azure ML workspace
  prefs: []
  type: TYPE_NORMAL
- en: 'The next cell creates a deployment, which contains settings such as an ID for
    the model to be deployed, the compute cluster type, the number of cluster nodes,
    and the name of the endpoint that was created a couple of steps ago, as shown
    in *Figure 10**.31*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.31 – Registering the best model to the Azure ML workspace](img/B18003_10_031.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.31 – Registering the best model to the Azure ML workspace
  prefs: []
  type: TYPE_NORMAL
- en: 'The next couple of cells show you how to invoke the endpoint and pass a test
    image to the model for inference, as shown in *Figure 10**.32*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.32 – Sending a test image to the model for inference](img/B18003_10_032.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.32 – Sending a test image to the model for inference
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s see how well the model scored the test image (which is how well
    it was able to find an object, identify its type, and find its location within
    the image). *Figure 10**.33* shows the Python code to help you to visualize the
    model output that was returned by the endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.33 – Python code to visualize the model output](img/B18003_10_033.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.33 – Python code to visualize the model output
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.34* shows the model output with a bounding box around the identified
    object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.34 – Model output showing the bounding box around the identified
    object](img/B18003_10_034.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.34 – Model output showing the bounding box around the identified object
  prefs: []
  type: TYPE_NORMAL
- en: Let’s summarize the chapter next.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered a quick introduction to deep learning and the importance
    of having a lot of labeled data for the model to perform well. We then showed
    you how to use the Azure ML Data Labeling capability to assist with labeling image
    data to train an object detection model. We then showed you how to use AutoML
    to train an object detection model, and finally, you learned how to deploy your
    model to an online endpoint and score a test image, all using Azure ML.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will show you how to do distributed model training in
    Azure ML.
  prefs: []
  type: TYPE_NORMAL
