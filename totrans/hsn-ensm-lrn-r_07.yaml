- en: Chapter 7. The General Ensemble Technique
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The previous four chapters have dealt with the ensembling techniques for decision
    trees. In each of the topics discussed in those chapters, the base learner was
    a decision tree and, consequently, we delved into the homogenous ensembling technique.
    In this chapter, we will demonstrate that the base learner can be any statistical
    or machine learning technique and their ensemble will lead to improved precision
    in predictions. An important requirement will be that the base learner should
    be better than a random guess. Through R programs, we will discuss and clarify
    the different possible cases in which ensembling will work. Voting is an important
    trait of the classifiers – we will state two different methods for this and illustrate
    them in the context of bagging and random forest ensemblers. The averaging technique
    is an ensembler for regression variables, which will follow the discussion of
    classification methods. The chapter will conclude with a detailed discussion of
    stacking methods, informally introduced in [Chapter 1](part0012_split_000.html#BE6O2-2006c10fab20488594398dc4871637ee
    "Chapter 1. Introduction to Ensemble Techniques"), *Introduction to Ensemble Techniques*.
    The topic flow unfolds as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Why does ensembling work?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensembling by voting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensembling by averaging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stack ensembles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The libraries that will be used in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`rpart`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`randomForest`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why does ensembling work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When using the bagging method, we combine the result of many decision trees
    and produce a single output/prediction by taking a majority count. Under a different
    sampling mechanism, the results had been combined to produce a single prediction
    for the random forests. Under a sequential error reduction method for decision
    trees, the boosting method also provides improved answers. Although we are dealing
    with uncertain data, which involves probabilities, we don't intend to have methodologies
    that give results out of a black box and behave without consistent solutions.
    A theory should explain the working and we need an assurance that the results
    will be consistent and there is no black magic about it. Arbitrary and uncertain
    answers are completely unwanted. In this section, we will look at how and why
    the ensembling solutions work, as well as scenarios where they will not work.
  prefs: []
  type: TYPE_NORMAL
- en: Ensembling methods have strong mathematical and statistical underpinnings that
    explain why they give the solutions that they do. We will consider the classification
    problem first. We will begin with a simplified setup and assume that we have *T*
    classifiers that are independent of each other, and that the accuracy associated
    with each of them is the same as ![Why does ensembling work?](img/00304.jpeg).
    This is one of the simplest cases, and we will generalize the scenario later.
    Now, if we have *T* classifiers and each of them votes on observations such as
    +1 or -1, it begs the question, what will the overall accuracy be? Since the number
    of correct classifications of the *T* classifiers must outnumber the misclassifications,
    we would need at least ![Why does ensembling work?](img/00305.jpeg) classifiers
    to vote the correct outcome. Here, ![Why does ensembling work?](img/00306.jpeg)
    denotes the greatest integer that is less than the given fractional number. The
    majority classification is correct whenever ![Why does ensembling work?](img/00307.jpeg)
    or a higher number of classifiers vote for the correct class.
  prefs: []
  type: TYPE_NORMAL
- en: To clarify, it is important to note that when we say a classifier has an accuracy
    *p*, we don't mean that the probability of the classifier marking the observation
    as +1 is *p*. Rather, what we mean here is that if the classifier makes 100 predictions,
    the predictions can be any combination of +1 and -1; 100*p predictions are correctly
    identified by the classifier. The accuracy is independent of the distribution
    of +1 and -1 in the population.
  prefs: []
  type: TYPE_NORMAL
- en: 'Under this setup, the probability of the number of classifiers marking a correct
    observation follows a binomial distribution with *n = T* and a probability of
    *p*. Thus, the probability of the majority vote getting the correct prediction
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Why does ensembling work?](img/00308.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since we have mentioned that the classifier must be better than a random guess,
    we will need the classifier accuracy to be in excess of 0.5\. We will then increment
    the accuracy over multiple points and see how the increase in the number of classifiers
    impacts the probability of a majority vote:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `seq` function sets up an odd-numbered sequence of the number of classifiers
    in the `classifiers R` numeric vector. The accuracy percentage varies from `0.55`
    to `0.85` in the `accuracy` vector. To kick off the proceedings, we set up an
    empty `plot` of sorts, with appropriate *x* and *y* axis labels. Now, for each
    accuracy value, we will calculate the probability of the majority vote for range
    `floor(classifiers[j]/2+1):classifiers[j]`. The `floor(./2+1)` ensures that we
    select the correct starting point. For example, if the number of classifiers is
    nine, then the value of `floor(./2+1)` is `5`. Furthermore, when we have nine
    classifiers, we need a minimum of five votes in favor of the event of interest.
    On the other hand, for an even number of classifiers (for example, eight) the
    value of `floor(./2+1)` is `5`. The `dbinom` function calculates the probability
    of that specific value for the given size and probability. Over the range of `floor(classifiers[j]/2+1):
    classifiers[j]`, it gives the probability of the majority vote, or the accuracy
    of the majority vote. The output of the preceding code is presented in *Figure
    1*. We can see from the result that as the number of classifiers increases (each
    with the same accuracy and better than the random guess), the accuracy of the
    majority voting also increases:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Why does ensembling work?](img/00309.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Why should ensembling work?'
  prefs: []
  type: TYPE_NORMAL
- en: 'It would help us to see `Prob_MV` for one choice of the accuracy – for example,
    0.65\. We will run the loop with index `j` separately for `prob=0.65` and look
    at how the accuracy of the majority vote increases as the number of classifiers
    increases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Consequently, as the number of classifiers with equal accuracy increases, we
    can see that the accuracy of the majority vote also increases. Also, what is noteworthy
    here is that even though each of our classifiers had an accuracy of a mere `0.65`,
    the ensemble has way higher accuracy and almost becomes a perfect classifier.
    This is the main advantage of ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: 'Will ensembling help any sort of classifier? If we have classifiers whose accuracy
    is worse than the random guess and hence is less than `0.5`, then we will search
    in the same way that we did with the previous case. For a host of a number of
    classifiers and accuracies less than `0.5`, we will compute the accuracy of the
    majority vote classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The result of the preceding R program is shown in *Figure 2.* Now, the first
    observation should be that it does not matter whether the accuracy is closer to
    `0.5` or to `0`, the probability/accuracy of the majority vote classifier is on
    a decline and this adversely affects the performance. In every case, we see that
    the accuracy will eventually approach zero. The changes in the block of R code
    are the classifier sequence `seq(6,50,2)`, and the accuracy levels decrease from
    `0.45` to `0.05` in `seq(0.45,0.05,-0.05)`. Now, consider the case of accuracy
    being slightly less than `0.5`. For example, let's keep it to `0.4999`. Will we
    be lucky enough to see a performance improvement now?
  prefs: []
  type: TYPE_NORMAL
- en: '![Why does ensembling work?](img/00310.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Ensemble is not alchemy!'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Again, it turns out that we can't match the accuracy of a single classifier.
    Consequently, we have the important and crucial condition that the classifier
    must be better than a random guess. What about the random guess itself? It is
    not at all difficult to pretend that we have a host of classifiers which are all
    random guesses. If the performance of the ensemble improves with the random guesses,
    we don't typically have to build any of the statistical or machine learning techniques.
    Given a set of random guesses, we can always improve the accuracy. Let's check
    this out.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two cases – an odd number of classifiers and an even number of classifiers
    – and we provide the program for both scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This is interesting! An ensemble of random guesses remains the same irrespective
    of the number of classifiers. Here, there is neither any improvement nor deterioration.
    Consequently, for ensembling purposes, we always need classifiers that are better
    than random guesses.
  prefs: []
  type: TYPE_NORMAL
- en: It is good to follow your intuition when it comes to understanding how ensembling
    works. We began with an oversimplified assumption that all models have the same
    accuracy, but such an assumption does not work well if we deal with models with
    varying accuracies. As a result, we need to consider cases in which we may have
    different accuracies for different classifiers. We will first consider a case
    where each classifier has an accuracy of higher than 0.5, or where each of them
    is better than a random guess. The approach to finding the accuracy of the majority
    vote is to evaluate the probabilities for each possible combination of the classifiers'
    outcomes. We consider the simpler case when the number of classifiers is an odd
    number.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we have *T* number of classifiers, and the accuracy of each classifier
    is ![Why does ensembling work?](img/00311.jpeg). Note that ![Why does ensembling
    work?](img/00312.jpeg), as these correspond to different measures.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps involved in evaluating the probability of a majority vote with unequal
    accuracies is given in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'List all possible elementary events. If each classifier votes TRUE or FALSE
    for a given case, this means that it has two possible outcomes, and *T* number
    of classifiers. List the ![Why does ensembling work?](img/00313.jpeg) possible
    outcomes:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example: If we have three classifiers, there would be eight possible cases,
    as follows:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Classifier 1 | Classifier 2 | Classifier 3 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| TRUE | TRUE | TRUE |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| FALSE | TRUE | TRUE |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| TRUE | FALSE | TRUE |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| FALSE | FALSE | TRUE |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| TRUE | TRUE | FALSE |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| FALSE | TRUE | FALSE |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| TRUE | FALSE | FALSE |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| FALSE | FALSE | FALSE |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: 'Compute the probability of each possible event. Since each classifier has a
    different accuracy, the probabilities would then be different for each possible
    outcome:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example: If the accuracies of the three classifiers (for TRUE) are 0.6, 0.7,
    and 0.8, then the probabilities of FALSE are, respectively, 0.4, 0.3, and 0.2,
    and the probabilities of the preceding table would be as follows:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Classifier 1 | Classifier 2 | Classifier 3 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| 0.6 | 0.7 | 0.8 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| 0.4 | 0.7 | 0.8 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| 0.6 | 0.3 | 0.8 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| 0.4 | 0.3 | 0.8 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| 0.6 | 0.7 | 0.2 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| 0.4 | 0.7 | 0.2 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| 0.6 | 0.3 | 0.2 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: '| 0.4 | 0.3 | 0.2 |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: 'In the next step, obtain the probability of the elementary event, which will
    be the product of the numbers in each column:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Classifier 1 | Classifier 2 | Classifier 3 | Probability |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 0.6 | 0.7 | 0.8 | 0.336 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 0.4 | 0.7 | 0.8 | 0.224 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 0.6 | 0.3 | 0.8 | 0.144 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 0.4 | 0.3 | 0.8 | 0.096 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 0.6 | 0.7 | 0.2 | 0.084 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 0.4 | 0.7 | 0.2 | 0.056 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 0.6 | 0.3 | 0.2 | 0.036 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| 0.4 | 0.3 | 0.2 | 0.024 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: 'Find the events which have a majority count. In this case, this refers to a
    sum greater than or equal to 2:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Classifier 1 | Classifier 2 | Classifier 3 | Vote Count |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| TRUE | TRUE | TRUE | 3 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| FALSE | TRUE | TRUE | 2 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| TRUE | FALSE | TRUE | 2 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| FALSE | FALSE | TRUE | 1 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| TRUE | TRUE | FALSE | 2 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| FALSE | TRUE | FALSE | 1 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| TRUE | FALSE | FALSE | 1 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| FALSE | FALSE | FALSE | 0 |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: The probability of the majority vote is then simply the sum of the probability
    in cases where the vote count is greater than or equal to 2\. This is the sum
    of the entries in rows 1, 2, 3, and 5 of the Probability column, as 0.336 + 0.224
    + 0.144 + 0.084 = 0.788.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We need to define a function here called `Get_Prob`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Given a logical vector and a vector of corresponding probabilities, the `Get_Prob`
    function will return a vector that consists of the probability that the logical
    condition is `TRUE`. If the logical value is `FALSE`, the complement (1 – probability)
    is returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding steps are put in an R program, and are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Given a numeric vector with accuracies, named `accuracy`, with an odd number
    of classifiers, we first find the number of classifiers in it with the `length`
    function and store it in `NT`. All possible combinations of `APC` are then generated
    using the `expand.grid` function, where the `rep` function will repeat the vector
    `(TRUE, FALSE) NT` number of times. Each element of the column of the `APC` object
    will then generate a column where the `TRUE` and `FALSE` condition will be replaced
    by the corresponding classifier''s accuracy as well as the appropriate complement
    by using the `Get_Prob` function. Since we consider an odd number of classifiers,
    the majority vote is attended in cases when the number of `TRUE` in that elementary
    event is greater than 50 percent of the number of classifiers (that is, greater
    than `NT/2`). The rest of the computations are easier to follow. If the accuracy
    of the nine classifiers is 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, and 0.9,
    then the computations show that the accuracy of the ensemble would be 0.9113,
    higher than the most accurate classifier here, which is 0.9\. However, we must
    remember that each of the eight classifiers is less accurate than 0.9\. Despite
    this, the ensemble accuracy is higher than the highest classifier we have on hand.
    To verify that the computations are working fine, we apply this approach to the
    example given on page 74 of Zhou (2012), and confirm the final majority vote probability
    at 0.933:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'What happens to the case when each classifier is worse than a random guess?
    We will simply turn out the accuracies of the nine classifier scenarios and repeat
    the program to get the following answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'When each of the classifiers is worse than a random guess, the majority vote
    classifier gives horrible results in the case of ensembling. This leaves us with
    the final case. What if we have a mixture of classifiers of which some are better
    than the random guess classifier and some are worse than the random guess classifier?
    We will put the computing code block in a function known as `Random_Accuracy`.
    The accuracies in the classifiers then become randomly generated numbers in the
    unit interval. The function `Random_Accuracy` is then run over ten times to generate
    the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: A mixed bag of results. As a result, if we need to get reasonable accuracy and
    performance from the ensembling method, it is imperative to ensure that each classifier
    is better than the random guess. A central assumption in our analysis thus far
    has been that the classifiers are independent of each other. This assumption is
    seldom true in practical settings, as the classifiers are built using the same
    dataset. However, this topic will be dealt with in the following chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We will now move on to the problem of ensembling by voting.
  prefs: []
  type: TYPE_NORMAL
- en: Ensembling by voting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensembling by voting can be used efficiently for classification problems. We
    now have a set of classifiers, and we need to use them to predict the class of
    an unknown case. The combining of the predictions of the classifiers can proceed
    in multiple ways. The two options that we will consider are majority voting, and
    weighted voting.
  prefs: []
  type: TYPE_NORMAL
- en: Majority voting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Ideas related to voting will be illustrated through an ensemble based on the
    homogeneous base learners of decision trees, as used in the development of bagging
    and random forests. First, we will create 500 base learners using the `randomForest`
    function and repeat the program in the first block, as seen in [Chapter 4](part0033_split_000.html#VF2I1-2006c10fab20488594398dc4871637ee
    "Chapter 4. Random Forests"), *Random Forests*. Ensembling has already been performed
    in that chapter, and we will elaborate on those steps here. First, the code block
    for setting up the random forest is given here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will use the standard `predict` function to predict the class for
    the `GC2_TestX` data, and then, using the option of `predict.all=TRUE`, obtain
    the prediction for each tree generated in the random forest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The predicted `GC2_RF_Test_Predict` object will consist of further `individual`
    objects, which will have the predictions for each decision tree. We will first
    define a function called `Row_Count_Max`, which will return the prediction whose
    count is a maximum in the forest. The rudimentary voting method is then compared
    with the `predict` function''s outcomes in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Consequently, we can see that the `predict` function implements the majority
    count technique. Next, we will quickly illustrate the ideas and thinking behind
    weighted voting.
  prefs: []
  type: TYPE_NORMAL
- en: Weighted voting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An implicit assumption in the use of simple voting is that all classifiers are
    equally accurate, or that all classifiers have equal voting power. Consider the
    simpler case in which we have five classifiers, three of them with an accuracy
    of 0.51 and the remaining two with an accuracy of 0.99\. If the less accurate
    classifier votes an observation as a negative case (-1) and the two more accurate
    classifiers as a positive case (+1), then the simple voting method will call the
    observation (-1). With this voting pattern, the probability of the observation
    being -1 is ![Weighted voting](img/00314.jpeg), while that of it being +1 is ![Weighted
    voting](img/00315.jpeg). Thus, we can't pretend that all classifiers should have
    the same voting power. This is where we will make good use of the weighted voting
    method.
  prefs: []
  type: TYPE_NORMAL
- en: In this analysis, we will take the accuracy of the classifiers over the training
    dataset as the weights. We will treat ![Weighted voting](img/00316.jpeg) as the
    weight associated with the classifier ![Weighted voting](img/00317.jpeg). An important
    characteristic of the weights is that they should be non-negative and should add
    up to 1, that is, ![Weighted voting](img/00318.jpeg). We will normalize the accuracy
    of the classifiers to satisfy this constraint.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will continue the analysis with the German Credit dataset. First, we will
    obtain the predictions for the 500 trees over the training dataset, and then obtain
    the accuracies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'What is the `headtail` function? It is available in the `Utilities.R` file.
    The analysis is repeated with the bagging ensemble as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we normalize the weights and calculate the weighted votes for the observations
    in the test samples, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The weighted voting analysis is repeated for the `bagging` objects, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Now, with the voting mechanisms behind us, we turn our attention to regression
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: Ensembling by averaging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Within the context of regression models, the predictions are the numeric values
    of the variables of interest. Combining the predictions of the output due to the
    various ensemblers is rather straightforward; because of the ensembling mechanism,
    we simply interpret the average of the predicted values across the ensemblers
    as the predicted value. Within the context of the classification problem, we can
    carry out simple averaging and weighted averaging. In the previous section, the
    ensemble had homogeneous base learners. However, in this section, we will deal
    with heterogeneous base learners.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now consider a regression problem that is dealt with in detail in [Chapter
    8](part0057_split_000.html#1MBG21-2006c10fab20488594398dc4871637ee "Chapter 8. Ensemble
    Diagnostics"), *Ensemble Diagnostics*. The problem is the prediction of housing
    prices based on over 60 explanatory variables. We have the dataset in training
    and testing partitions, and load them to kick off the proceedings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Consequently, we have many observations to build our models. The `SalePrice`
    is the variable of interest here. First, we create a `formula` and build a linear
    model; four regression trees with different depths; four neural networks with
    a different number of hidden neurons; and a support vector machine model in the
    following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We have the required setup here to consider the heterogeneous ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: Simple averaging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We built ten models using the training dataset, and we will now make the predictions
    for these models on the training dataset using the `predict` function, as shown
    in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'When it comes to classification problems, the predictions are either based
    on the class labels or the probability of the class of interest. Consequently,
    we don''t come across *bad predictions* in terms of the magnitude of predictions,
    though we need to at least check if the predictions give a mixture of +1s or -1s.
    If the classifiers predict only +1 or -1, such classifiers can then be discarded
    from further analysis. For the regression problems, we need to see if the models
    can make reasonable predictions in terms of the magnitude, and we will simply
    obtain a plot of the magnitude of the predictions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the preceding code block is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Simple averaging](img/00319.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: A simple plot of the predictions for the ten heterogeneous base learners'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that the predictions related to the neural network models with two
    or three hidden neurons produce no variation in the predictions. Consequently,
    we delete these two models from further analysis. The ensemble prediction is simply
    the average of the predictions across the remaining eight models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![Simple averaging](img/00320.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Ensemble predictions for the housing dataset'
  prefs: []
  type: TYPE_NORMAL
- en: As with the extension of simple voting to weighted voting, we will now look
    at weighted averaging.
  prefs: []
  type: TYPE_NORMAL
- en: Weight averaging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the case of classifiers, the weights were chosen from the accuracies of
    the classifiers for the training dataset. In this instance, we need unifying measures
    like this. A regressor model is preferred if it has less residual variance, and
    we will select the variance as a measure of accuracy. Suppose that the estimated
    residual variance for a weak base model *i* is ![Weight averaging](img/00321.jpeg).
    In the context of ensemble neural networks, Perrone and Cooper (1993) claim that
    the optimal weight for the *ith* weak base model can be obtained using the following
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Weight averaging](img/00322.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since the proportional constants do not matter, we will simply substitute ![Weight
    averaging](img/00323.jpeg) with the mean of residual squares. In this direction,
    we will first obtain the ![Weight averaging](img/00324.jpeg) up to a constant,
    by simply calculating `mean(residuals(model)^2)` for the eight models considered
    in the context of simple averaging, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we simply implement the formula of weights ![Weight averaging](img/00325.jpeg)as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The `rowMeans` and `cbind` functions simply give away the weighted averaging
    predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Weight averaging](img/00326.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Weighted averaging predictions for the housing price'
  prefs: []
  type: TYPE_NORMAL
- en: Stack ensembling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An introductory and motivational example of the stacked regression was provided
    in [Chapter 1](part0012_split_000.html#BE6O2-2006c10fab20488594398dc4871637ee
    "Chapter 1. Introduction to Ensemble Techniques"), *Introduction to Ensemble Techniques*.
    Here, we will continue the discussion of stacked ensembles for a regression problem
    which has not been previously developed.
  prefs: []
  type: TYPE_NORMAL
- en: 'With stacked ensembling, the outputs of several weak models are given as an
    input variable, along with the covariates used to build the earlier models, to
    build a stack model. The form of the stack model might be one of these, or it
    can be a different model. Here, we will simply use the eight regression models
    (used in previous sections) as weak models. The stacking regression model is selected
    as the gradient boosting model, and it will be given the original input variables
    and predictions of the new models, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This concludes our simple discussion of stacked ensemble regressions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at why ensemble works in the context of classification
    problems. A series of detailed programs illustrated the point that each classifier
    must be better than a random guess. We considered scenarios where all the classifiers
    have the same accuracy, different accuracy, and finally a scenario with completely
    arbitrary accuracies. Majority and weighted voting was illustrated within the
    context of the random forest and bagging methods. For the regression problem,
    we used a different choice of base learners and allowed them to be heterogeneous.
    Simple and weighted averaging methods were illustrated in relation to the housing
    sales price data. A simple illustration of stacked regression ultimately concluded
    the technical section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we will look at ensembling diagnostics.
  prefs: []
  type: TYPE_NORMAL
