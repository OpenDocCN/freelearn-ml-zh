- en: '*Chapter 2*: Deep Dive into TPOT'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you'll learn everything about the theoretical aspects of the
    TPOT library and its underlying architecture. Topics such as architecture and
    **genetic programming** (**GP**) will be crucial to having a full grasp of the
    inner workings of the library.
  prefs: []
  type: TYPE_NORMAL
- en: We will go through TPOT use cases and dive deep into different approaches to
    solve various machine learning problems. You can expect to learn the basics of
    automation in regression and classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: We will also go through a complete environment setup for standalone Python installation
    and the Anaconda distribution and show you how to set up a virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing TPOT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of problems TPOT can solve
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing TPOT and setting up the environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete this chapter, you only need a computer with Python installed. Both
    the standalone version and Anaconda are fine. We'll go through the installation
    for both through a virtual environment toward the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: There is no code for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing TPOT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**TPOT**, or **Tree-based Pipeline Optimization Tool**, is an open source library
    for performing machine learning in an automated fashion with the Python programming
    language. Below the surface, it uses the well-known **scikit-learn** machine learning
    library to perform data preparation, transformation, and machine learning. It
    also uses GP procedures to discover the best-performing pipeline for a given dataset.
    The concept of GP is covered in later sections.'
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, you should use TPOT every time you need an automated machine
    learning pipeline. Data science is a broad field, and libraries such as TPOT enable
    you to spend much more time on data gathering and cleaning, as everything else
    is done automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows what a typical machine learning pipeline looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Example machine learning pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16954_02_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.1 – Example machine learning pipeline
  prefs: []
  type: TYPE_NORMAL
- en: The preceding figure shows which parts of a machine learning process can and
    can't be automated. The data gathering phase (**Raw data**) is essential for any
    machine learning project. In this phase, you gather data that will serve as input
    to a machine learning model. If the input data isn't good enough, or there's not
    enough of it, machine learning algorithms can't produce good-quality models.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming there's enough data and you can access it, the next most significant
    problem is data cleaning. This step can't be automated, at least not entirely,
    for obvious reasons. Every dataset is different; hence there's no single approach
    to data cleaning. Missing and misformatted values are the most common and the
    most time-consuming types of problem, and they typically require a substantial
    amount of domain knowledge to address successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have a fair amount of well-prepared data, TPOT can come into play.
    TPOT uses GP to find the best algorithm for a particular task, so there's no need
    to manually choose and optimize a single algorithm. The *Darwinian process of
    natural selection* inspires genetic algorithms, but more on that in a couple of
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: 'The TPOT pipeline has many parameters, depending on the type of problem you
    are trying to solve (regression or classification). All of the parameters are
    discussed later in the chapter, but these are the ones you should know regardless
    of the problem type:'
  prefs: []
  type: TYPE_NORMAL
- en: '`generations`: Represents the number of iterations the pipeline optimization
    process is run for'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`population_size`: Represents the number of individuals to retain in the GP
    population in every generation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`offspring_size`: Represents the number of offspring to produce in each generation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mutation_rate`: Tells the GP algorithm how many pipelines to apply random
    changes to every generation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crossover_rate`: Tells the GP algorithm how many pipelines to breed every
    generation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv`: Cross-validation technique used for evaluating pipelines'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scoring`: A function that is used to evaluate the quality of a given pipeline'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once TPOT finishes with the optimization, it returns Python code for the best
    pipeline it found so you can proceed with model evaluation and validation on your
    own. A simplified example of a TPOT pipeline is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2 – Example TPOT pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16954_02_002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.2 – Example TPOT pipeline
  prefs: []
  type: TYPE_NORMAL
- en: 'The TPOT library was built on top of Python''s well-known machine learning
    package `scikit-learn`. As a result, TPOT has access to all of its classes and
    methods. The preceding figure shows **PCA** and **Polynomial features** as two
    possible feature preprocessing operations. TPOT isn''t limited to these two, but
    instead can use any of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PCA`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RandomizedPCA`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PolynomialFeatures`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Binarizer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`StandardScaler`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MinMaxScaler`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MaxAbsScaler`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RobustScaler`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are all classes built into `scikit-learn`, used to modify the dataset
    in some way and return a modified dataset. The next step involves some kind of
    feature selection. This step aims to select only the features with good predictive
    power and discard the others. By doing so, TPOT is reducing the dimensionality
    of the machine learning problem, which as an end result makes the problem easier
    to solve.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding figure hides this abstraction behind the **Select best features**
    step. To perform this step, TPOT can use one of the following algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '`VarianceThreshold`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SelectKBest`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SelectPercentile`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SelectFwe`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RecursiveFeatureElimination`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, TPOT is very flexible when it comes to model training approaches.
    To understand further what's going on below the surface, we'll need to cover a
    bit of GP. The following section does that.
  prefs: []
  type: TYPE_NORMAL
- en: A brief overview of genetic programming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**GP** is a type of evolutionary algorithm, a subset of machine learning (*Genetic
    Programming page, GP Team; June 1, 2019*). Evolutionary algorithms are used for
    finding solutions to problems that we as humans don''t know how to solve directly.
    These algorithms generate solutions that are, at worst, comparable to the best
    human solutions, and often better.'
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, GP can be used to discover the relationship between features
    in a dataset (**regression**), and to group data into categories (**classification**).
    In regular software engineering, GP is applied through code synthesis, genetic
    improvement, automatic bug fixing, and in developing game-playing strategies (*Genetic
    Programming page, GP Team; June 1, 2019*).
  prefs: []
  type: TYPE_NORMAL
- en: GP is inspired by biological evolution and its mechanisms. It uses algorithms
    based on random mutation, crossover, fitness functions, and generations to solve
    the previously described regression and classification tasks for machine learning.
    These properties should sound familiar, as we covered them in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind GP is essential for advancements in machine learning because
    it is based on the *Darwinian process of natural selection*. In machine learning
    terms, these processes are used to generate optimal solutions – models and hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Genetic algorithms have three properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Selection**: Consists of a population of possible solutions and the fitness
    function. Each fit is evaluated at every iteration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Crossover**: The process of selecting the best (fittest) solution and performing
    crossover to create a new population.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mutation**: Taking the children from the previous point and mutating them
    with some random modifications until the best solution is obtained.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is always a good idea to know the basics and the underlying architecture
    of the language/library you are dealing with. TPOT is user-friendly and easy to
    use, so it doesn't require us to know everything about GP and genetic algorithms.
    For that reason, this chapter won't dive deeper into the topic. If you are interested
    in learning more about GP, you'll find useful links at the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We've discussed a lot about the good sides of machine learning automation, TPOT,
    and GP. But are there any downsides? The following section addresses a couple
    of them.
  prefs: []
  type: TYPE_NORMAL
- en: TPOT limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Thus far, we have discussed only the good things about the TPOT library and
    the automation of machine learning processes in general. In this case, the pros
    outweigh the cons, but we should still talk about potential downsides. The first
    one is the execution time. It will vary based on the size of the dataset and the
    hardware specifications, but in general, it will take a lot of time to finish
    – hours or days for large datasets and minutes for smaller ones.
  prefs: []
  type: TYPE_NORMAL
- en: It is essential to understand why. With the default TPOT settings – 100 generations
    with 100 population sizes – TPOT will evaluate 10,000 pipelines before finishing.
    That is equivalent to performing feature engineering and training of a machine
    learning model 10,000 times. Because of this, TPOT is expected to run slowly.
  prefs: []
  type: TYPE_NORMAL
- en: Things get more complicated if you decide to bring **cross-validation** into
    the picture. This term represents a procedure where a machine learning model is
    trained *k* times on *k – 1* subsets and evaluated on a separate subset. The goal
    of cross-validation is to have a more accurate representation of the model's performance.
    The choice of *k* is arbitrary, but in practice, the most common value is 10.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, cross-validation makes TPOT significantly slower. When using cross-validation,
    TPOT will evaluate 100 generations with 100 population sizes and 10 cross-validation
    folds by default. This results in 100,000 different pipelines to evaluate before
    finishing.
  prefs: []
  type: TYPE_NORMAL
- en: To address this issue, TPOT introduced the `max_time_mins` parameter. It is
    set to `None` by default, but you can set its value explicitly to any integer.
    For example, specifying `max_time_mins=10` would give TPOT only 10 minutes to
    optimize the pipeline. It's not an ideal solution if you want the best results,
    but it comes in handy when you are on a tight schedule.
  prefs: []
  type: TYPE_NORMAL
- en: The second downside is that TPOT can sometimes recommend different solutions
    (pipelines) for the same dataset. This will often be a problem when the TPOT optimizer
    is run for a short amount of time. For example, if you have used the `max_time_mins`
    parameter to limit how long the optimizer would run, it's not a surprise that
    you will get a slightly different "optimal" pipeline every time.
  prefs: []
  type: TYPE_NORMAL
- en: 'This isn''t a reason to worry, as all pipelines should still outperform anything
    you can do manually in the same time frame, but it is essential to know why this
    happens. There are two possible reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The TPOT optimizer didn''t converge*: This is the most likely scenario. TPOT
    wasn''t able to find an optimal pipeline due to lack of time, or the dataset was
    too complex to optimize for in the given time period (or both).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*There are multiple "optimal" pipelines*: It''s not uncommon to see numerous
    approaches working identically for some machine learning problems. This is a more
    likely scenario if the dataset is relatively small.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This section briefly introduced the TPOT library and explained its benefits
    and shortcomings. The next section goes over the types of problems TPOT is solving
    and discusses the automation of regression and classification tasks in great detail.
  prefs: []
  type: TYPE_NORMAL
- en: Types of problems TPOT can solve
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The TPOT library was designed as a go-to tool for automating machine learning
    tasks; hence, it should be able to handle with ease anything you throw at it.
    We will start using TPOT in a practical sense soon. [*Chapter 3*](B16954_03_Final_SK_ePub.xhtml#_idTextAnchor051),
    *Exploring before Regression*, shows how to use the library to handle practical
    tasks with many examples, and the following chapters focus on other types of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, TPOT can be used to handle the following types of tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Regression**: Where the target variable is continuous, such as age, height,
    weight, score, or price. Refer to [*Chapter 1*](B16954_01_Final_SK_ePub.xhtml#_idTextAnchor014),
    *Machine Learning and the Idea of Automation*, for a brief overview of regression.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classification**: Where the target variable is categorical, such as sold/did
    not sell, churn/did not churn, or yes/no. Refer to [*Chapter 1*](B16954_01_Final_SK_ePub.xhtml#_idTextAnchor014),
    *Machine Learning and the Idea of Automation*, for a brief overview of classification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parallel training**: TPOT can handle the training of machine learning models
    in a parallel manner through the **Dask** library. Please read [*Chapter 5*](B16954_05_Final_SK_ePub.xhtml#_idTextAnchor065),
    *Parallel Training with TPOT and Dask*, to get a full picture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neural networks**: TPOT can even build models based on state-of-the-art neural
    network algorithms in a fully automated fashion. Please read [*Chapter 6*](B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073),
    *Getting Started with Deep Learning – Crash Course in Neural Networks*, for a
    quick crash course on neural networks, and [*Chapter 7*](B16954_07_Final_SK_ePub.xhtml#_idTextAnchor086),
    *Neural Network Classifier with TPOT*, for the practical implementation of TPOT.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rest of this section briefly discusses how TPOT handles regression and classification
    tasks and spends a good amount of time exploring and explaining their parameters,
    attributes, and functions. You will learn how TPOT handles parallel training with
    Dask in [*Chapter 5*](B16954_05_Final_SK_ePub.xhtml#_idTextAnchor065), *Parallel
    Training with TPOT and Dask*, and how it handles neural networks in [*Chapter
    6*](B16954_06_Final_SK_ePub.xhtml#_idTextAnchor073), *Getting Started with Deep
    Learning – Crash Course in Neural Networks*, because these topics require covering
    the prerequisites first.
  prefs: []
  type: TYPE_NORMAL
- en: How TPOT handles regression tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The TPOT library handles regression tasks through the `tpot.TPOTRegressor` class.
    This class performs an intelligent search over machine learning pipelines containing
    supervised regression models, preprocessors, feature selection techniques, and
    any other estimator or transformer that follows the `scikit-learn` API (*TPOT
    Documentation page, TPOT Team; November 5, 2019*).
  prefs: []
  type: TYPE_NORMAL
- en: The same class also performs a search over the hyperparameters of all objects
    in a pipeline. The `tpot.TPOTRegressor` class allows us to fully customize the
    models, transformers, and parameters searched over through the `config_dict` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now go over the parameters that the `tpot.TPOTRegressor` class expects
    when instantiated:'
  prefs: []
  type: TYPE_NORMAL
- en: '`generations`: Integer or None (default = `100`). An optional parameter that
    specifies the number of iterations to run the pipeline optimization process. It
    must be positive. If it is not defined, the `max_time_mins` parameter must be
    specified instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`population_size`: Integer (default = `100`). An optional parameter that specifies
    the number of individuals to retain in the GP population in every generation.
    Must be a positive number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`offspring_size`: Integer (default = the same as `population_size`). An optional
    parameter used to specify the number of offsprings to produce in each GP generation.
    Must be a positive number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mutation_rate`: Float (default = `0.9`). An optional parameter used to specify
    the mutation rate for the GP algorithm. Must be in the range [0.0, 1.0]. This
    parameter is used to instruct the algorithm on how many pipelines to apply random
    changes to every generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crossover_rate`: Float (default = `0.1`). An optional parameter that instructs
    the GP algorithm on how many pipelines to "breed" every generation. Must be in
    the range [0.0, 1.0].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scoring`: String or callable (default = `neg_mean_squared_error`). An optional
    parameter used to specify the function name for regression pipeline evaluation.
    Can be `neg_median_abs_value`, `neg_mean_abs_error`, `neg_mean_squared_error`,
    or `r2`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv`: Integer, cross-validation generator, or an iterable (default = `5`).
    An optional parameter used to specify a cross-validation strategy for evaluating
    regression pipelines. If the passed value is an integer, it expects the number
    of folds. In other cases, it expects an object to be used as a cross-validation
    generator, or an iterable yielding train/test splits, respectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subsample`: Float (default = `1.0`). An optional parameter used to specify
    a value for a fraction of training samples used in the optimization process. Must
    be in the range [0.0, 1.0].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_jobs`: Integer (default = `1`). An optional parameter used to specify the
    number of processes to use in parallel for the evaluation of pipelines during
    optimization. Set it to `-1` to use all CPU cores. Set it to `-2` to use all but
    one CPU core.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_time_mins`: Integer or None (default = `None`). An optional parameter
    used to specify how many minutes TPOT can perform the optimization. TPOT will
    optimize for less time only if all of the generations evaluate before the specified
    max time in minutes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_eval_time_mins`: Float (default = `5`). An optional parameter used to
    specify how many minutes TPOT has to evaluate a single pipeline. If the parameter
    is set to a high enough value, TPOT will evaluate more complex pipelines. At the
    same time, it also makes TPOT run longer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_state`: Integer or None (default = `None`). An optional parameter used
    to specify the seed for a pseudo-random number generator. Use it to get reproducible
    results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config_dict`: Dictionary, string, or None (default = `None`). An optional
    parameter used to specify a configuration dictionary for customizing the operators
    and parameters that TPOT searches during optimization. Possible inputs are as
    follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a) *None*: TPOT uses the default configuration.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) *Python dictionary*: TPOT uses your configuration.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) *''TPOT light''*: String; TPOT will use a built-in configuration with only
    fast models and preprocessors.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd) *''TPOT MDR''*: String; TPOT will use a built-in configuration specialized
    for genomic studies.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'e) *''TPOT sparse''*: String; TPOT will use a configuration dictionary with
    a one-hot encoder and operators that support sparse matrices.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`template`: String (default = `None`). An optional parameter used to specify
    a template of a predefined pipeline. Used to specify the desired structure for
    the machine learning pipeline evaluated by TPOT.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`warm_start`: Boolean (default = `False`). An optional parameter used to indicate
    whether the current instance should reuse the population from previous calls to
    the `fit()` function. This function is discussed later in the chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`memory`: A memory object or a string (default = `None`). An optional parameter
    used to cache each transformer after calling the `fit()` function. This function
    is discussed later in the chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_dask`: Boolean (default = `False`). An optional parameter used to specify
    whether *Dask-ML''s* pipeline optimizations should be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`periodic_checkpoint_folder`: Path string (default = `None`). An optional parameter
    used to specify in which folder TPOT will save pipelines while optimizing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`early_stop`: Integer (default = `None`). An optional parameter used to specify
    after how many generations TPOT will stop optimizing if there''s no improvement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`verbosity`: Integer (default = `0`). An optional parameter used to specify
    how much information TPOT outputs to the console while running. Possible options
    are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'a) *0*: TPOT doesn''t print anything.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'b) *1*: TPOT prints minimal information.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'c) *2*: TPOT prints more information and provides a progress bar.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'd) *3*: TPOT prints everything and provides a progress bar.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`disable_update_check`: Boolean (default = `False`). An optional parameter
    that indicates whether the TPOT version checker should be disabled. You can ignore
    this parameter because it only tells you whether a newer version of the library
    is available, and has nothing to do with the actual training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That's a lot of parameters you should know about if your goal is to truly master
    the library – at least the part of it that handles regression tasks. We've only
    covered parameters for the `tpot.TPOTRegressor` class and we will discuss attributes
    and functions next. Don't worry; there are only a couple of them available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with attributes. There are three in total. These become available
    once the pipeline is fitted:'
  prefs: []
  type: TYPE_NORMAL
- en: '`fitted_pipeline_`: Pipeline object from `scikit-learn`. Shows you the best
    pipeline that TPOT discovered during the optimization for a given training set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pareto_front_fitted_pipelines_`: Python dictionary. It contains all the pipelines
    on the TPOT Pareto front. The dictionary key is the string representing the pipeline,
    and the value is the corresponding pipeline. This argument is available only when
    the `verbosity` parameter is set to `3`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`evaluated_individuals_`: Python dictionary. It contains all evaluated pipelines.
    The dictionary key is the string representing the pipeline, and the value is a
    tuple containing the number of steps in each pipeline and the corresponding accuracy
    metric.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will see how the mentioned attributes work in practice in the following
    chapters. The only thing left to discuss for this section are functions belonging
    to the `tpot.TPOTRegressor` class. There are four in total:'
  prefs: []
  type: TYPE_NORMAL
- en: '`fit(features, target, sample_weight=None, groups=None)`: This function is
    used to run the TPOT optimization process. The `features` parameter is an array
    of the features/predictors/attributes used for predicting the target variable.
    The `target` parameter is also an array that specifies the list of target labels
    for prediction. The other two parameters are optional. The `sample_weights` parameter
    is an array indicating per-sample weights. Higher weights indicate more importance.
    The last parameter, `groups`, is an array that specifies group labels for the
    samples used when performing cross-validation. It should only be used in conjunction
    with group cross-validation functions. The `fit()` function returns a copy of
    the fitted TPOT object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predict(features)`: This function is used to generate new predictions based
    on the `features` parameter. This parameter is an array containing features/predictors/attributes
    for predicting the target variable. The function returns an array of predictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score(testing_features, testing_target)`: This function returns a score of
    the optimized pipeline on a given testing data. The function accepts two parameters.
    The first one is `testing_features`. It is an array/feature matrix of the testing
    set. The second one is `testing_target`. It is also an array, but of target labels
    for prediction in the training set. The function returns the accuracy score on
    the test set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`export(output_file_name)`: This function is used to export the optimized pipeline
    as Python code. The function accepts a single parameter, `output_file_name`. It
    is used to specify the path and a filename where the Python code should be stored.
    If the value for the mentioned parameter isn''t specified, the whole pipeline
    is returned as text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this overview of parameters, attributes, and functions, you are ready to
    use TPOT's regression capabilities in practice. [*Chapter 3*](B16954_03_Final_SK_ePub.xhtml#_idTextAnchor051),
    *Exploring before Regression*, is packed with regression examples, so don't hesitate
    to jump to it if you want to automate regression tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The next section of this chapter discusses how TPOT handles classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: How TPOT handles classification tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The TPOT library handles classification tasks through the `tpot.TPOTClassifer`
    class. This class performs a search over machine learning pipelines containing
    supervised regression models, preprocessors, feature selection techniques, and
    any other estimator or transformer that follows the `scikit-learn` API (*TPOT
    Documentation page, TPOT Team; November 5, 2019*). The class also performs a search
    over the hyperparameters of all objects in the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: The `tpot.TPOTClassifier` class allows us to fully customize the models, transformers,
    and parameters that will be searched over through the `config_dict` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: The `tpot.TPOTClassifier` class contains mostly the same parameters, attributes,
    and functions that the previously discussed `tpot.TPOTRegressor` has, so going
    over all of them again in detail would be redundant. Instead, we will just mention
    the identical parameters, attributes, and functions, and we will introduce and
    explain the ones that are unique for classification or work differently.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s go over the parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`generations`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`population_size`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`offspring_size`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mutation_rate`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crossover_rate`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scoring`: String or callable (default = `accuracy`). This is an optional parameter
    used to evaluate the quality of a given pipeline for the classification problem.
    The following scoring functions can be used: `accuracy`, `adjusted_rand_score`,
    `average_precision`, `balanced_accuracy`, `f1`, `f1_macro`, `f1_micro`, `f1_samples`,
    `f1_weighted`, `neg_log_loss`, `precision`, `recall`, `recall_macro`, `recall_micro`,
    `recall_samples`, `recall_weighted`, `jaccard`, `jaccard_macro`, `jaccard_micro`,
    `jaccard_samples`, `jaccard_weighted`, `roc_auc`, `roc_auc_ovr`, `roc_auc_ovo`,
    `roc_auc_ovr_weighted`, or `roc_auc_ovo_weighted`. If you want to use a custom
    scoring function, you can pass it as a function with the following signature:
    `scorer(estimator, X, y)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`subsample`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_jobs`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_time_mins`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_eval_time_mins`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_state`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config_dict`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`template`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`warm_start`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`memory`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_dask`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`periodic_checkpoint_folder`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`early_stop`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`verbosity`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`disable_update_check`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`log_file`: File-like class or string (default = `None`). This is an optional
    parameter used to save progress content to a file. If a string value is provided,
    it should be the path and the filename of the desired output file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we can see, one parameter has changed, and one parameter is completely new.
    To repeat – please refer to the preceding subsection for detailed clarifications
    on what every parameter does.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we have to discuss the attributes of the `tpot.TPOTClassifier` class.
    These become available once the pipeline optimization process is finished. There
    are three in total, and all of them behave identically to the `tpot.TPOTRegressor`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`fitted_pipeline_`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pareto_front_fitted_pipelines_`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`evaluated_individuals_`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we will discuss functions. As with the parameters, all are listed,
    but only the new and changed ones are discussed in detail. There are five functions
    in total:'
  prefs: []
  type: TYPE_NORMAL
- en: '`fit(features, classes, sample_weight=None, groups=None)`: This function behaves
    identically to the one in `tpot.TPOTRegressor`, but the second parameter is called
    `classes` instead of `target`. This parameter expects an array of class labels
    for prediction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predict(features)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predict_proba(features)`: This function does the same task as the `predict()`
    function but returns class probabilities instead of classes. You can see where
    the model was completely certain about predictions and where it wasn''t so certain
    by examining the probabilities. You can also use class probabilities to adjust
    the decision threshold. You will learn how to do that in [*Chapter 4*](B16954_04_Final_SK_ePub.xhtml#_idTextAnchor058),
    *Exploring before Classification*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score(testing_features, testing_target)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`export(output_file_name)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are now ready to see how TPOT works in practice. Most of the time, there's
    no need to mess around with some of the listed parameters, but you need to know
    that they exist for more advanced use cases. [*Chapter 4*](B16954_04_Final_SK_ePub.xhtml#_idTextAnchor058),
    *Exploring before Classification*, is packed with classification examples, so
    don't hesitate to jump to it if you want to learn how to automate classification
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The next section of this chapter discusses how to set up a TPOT environment
    through a virtual environment, both for standalone Python installation and installation
    through Anaconda.
  prefs: []
  type: TYPE_NORMAL
- en: Installing TPOT and setting up the environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section discusses the last required step before diving into the practical
    stuff – installation and environment setup. It is assumed that you have Python
    3 installed, either through the standalone installation or through Anaconda.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will learn how to set up a virtual environment for TPOT for the following
    scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: Standalone Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anaconda
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's no need to read both installation sections, so just pick whichever suits
    you better. There shouldn't be any difference with regards to installation between
    operating systems. If you have Python installed as a standalone installation,
    you have access to `pip` through the terminal. If you have it installed through
    Anaconda, you have access to Anaconda Navigator.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring TPOT with standalone Python installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before proceeding, make sure to have Python and `pip` (package manager for
    Python) installed. You can check whether `pip` is installed by entering the following
    line of code into the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If you see output like the one in the following figure, you are good to go:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – Checking whether pip is installed'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16954_02_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.3 – Checking whether pip is installed
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now proceed to the virtual environment setup:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing to do is to install the `virtualenv` package. To do so, execute
    this line from the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: After a couple of seconds, you should see a success message, as shown in the
    following figure:![Figure 2.4 – virtualenv installation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16954_02_004.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.4 – virtualenv installation
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The next step is to create a folder where the TPOT environment will be stored.
    Ours is located in the `Documents` folder, but you can store it anywhere. Here
    are the exact shell lines you need to execute to create the folder and install
    the Python virtual environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The execution and results are shown in the following figure:![Figure 2.5 – Creating
    a virtual environment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16954_02_005.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.5 – Creating a virtual environment
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The environment is successfully installed now.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To activate the environment, you need to execute the following line from the
    terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The text in parentheses confirms that the environment is activated. Take a look
    at the change from the `base` environment to `tpot_env` in the following figure:![Figure
    2.6 – Activating a virtual environment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16954_02_006.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.6 – Activating a virtual environment
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To deactivate the environment, enter the following line into the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`numpy`: Python''s go-to library for numerical computations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`pandas`: A well-known library for data loading, processing, preparation, transformation,
    aggregation, and even visualization.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`matplotlib`: Python''s standard data visualization library. We will use it
    sometimes for basic plots.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`seaborn`: A data visualization library with more aesthetically pleasing visuals
    than `matplotlib`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`scikit-learn`: Python''s go-to library for machine learning and everything
    related to it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`TPOT`: Used to find optimal machine learning pipelines in an automated fashion.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To install every mentioned library, you can execute the following line from
    the opened terminal window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Python will immediately start downloading and installing libraries, as shown
    in the following figure:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.8 – Installing libraries with pip'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16954_02_008.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.8 – Installing libraries with pip
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To test whether the environment was successfully configured, we can open `JupyterLab`
    from the terminal. Execute the following shell command once the libraries are
    installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you see something similar to the following, then everything went according
    to plan. The browser window with Jupyter should open immediately:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.9 – Starting JupyterLab for standalone installation'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16954_02_009.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.9 – Starting JupyterLab for standalone installation
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For the final check, we will take a look at which Python version came with the
    environment. This can be done straight from the notebooks, as shown in the following
    figure:![Figure 2.10 – Checking the Python version for the standalone installation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16954_02_010.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.10 – Checking the Python version for the standalone installation
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, we will see whether the TPOT library was installed by importing it
    and printing the version. This check can also be done from the notebooks. Follow
    the instructions in the following figure to see how:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Checking the TPOT version for the standalone installation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16954_02_011.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.11 – Checking the TPOT version for the standalone installation
  prefs: []
  type: TYPE_NORMAL
- en: TPOT is now successfully installed in a virtual environment. The next section
    covers how to install and configure the environment with Anaconda.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring TPOT through Anaconda
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before proceeding, make sure you have Anaconda installed on your machine. We
    will use Anaconda to create and manage our environment and do the configurations
    from there:'
  prefs: []
  type: TYPE_NORMAL
- en: To start, open up Anaconda Navigator:![Figure 2.12 – Anaconda Navigator
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16954_02_012.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.12 – Anaconda Navigator
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To create a new virtual environment, click on the **Create** button in the bottom-left
    portion of the screen:![Figure 2.13 – Creating a new environment in Anaconda
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16954_02_013.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.13 – Creating a new environment in Anaconda
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After clicking on the `base (root)` environment. Here's how it should look:![Figure
    2.15 – Listing of all virtual environments
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16954_02_015.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.15 – Listing of all virtual environments
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You are now ready to install libraries in your virtual environment. Anaconda
    makes it easy to open the environment from the terminal, by clicking on the play
    button and selecting the `jupyterlab`: A notebook environment required for analyzing
    and exploring data and building machine learning models in an interactive way.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`numpy`: Python''s go-to library for numerical computations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`pandas`: A well-known library for data loading, processing, preparation, transformation,
    aggregation, and even visualization.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`matplotlib`: Python''s standard data visualization library. We will use it
    sometimes for basic plots.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`seaborn`: A data visualization library with more aesthetically pleasing visuals
    than `matplotlib`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`scikit-learn`: Python''s go-to library for machine learning and everything
    related to it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`TPOT`: Used to find optimal machine learning pipelines in an automated fashion.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To install every mentioned library, you can execute the following line from
    the opened terminal window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Python should immediately start downloading and installing the libraries, as
    shown in the following figure:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Library installation through the terminal'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16954_02_017.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.17 – Library installation through the terminal
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To test whether the environment was successfully configured, we can open `JupyterLab`
    from the terminal. Execute the following shell command once the libraries are
    installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you see something similar to the following, then everything went according
    to plan. The browser window with Jupyter should open immediately:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 2.18 – Starting JupyterLab from the terminal'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16954_02_018.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.18 – Starting JupyterLab from the terminal
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For the final check, we will take a look at which Python version came with the
    environment. This can be done straight from the notebooks, as shown in the following
    figure:![Figure 2.19 – Checking the Python version
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16954_02_019.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.19 – Checking the Python version
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, we will see whether the TPOT library was installed by importing it
    and printing the version. This check can also be done from the notebooks. Follow
    the instructions in the following figure to see how:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.20 – Checking the TPOT version'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16954_02_020.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.20 – Checking the TPOT version
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to proceed with the practical uses of TPOT.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You've learned a lot in this chapter – from how TPOT works and GP to setting
    up the environment with `pip` and Anaconda. You are now ready to tackle hands-on
    tasks in an automated way.
  prefs: []
  type: TYPE_NORMAL
- en: The following chapter dives deep into handling regression tasks with TPOT with
    a couple of examples. Everything discussed during this chapter will become much
    clearer soon, after we get our hands dirty. Then, in [*Chapter 4*](B16954_04_Final_SK_ePub.xhtml#_idTextAnchor058),
    *Exploring before Classification*, you will further reinforce your knowledge by
    solving classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Q&A
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In your own words, define the TPOT library.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name and explain a couple of TPOT 's limitations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How would you limit the optimization time in TPOT?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Briefly define the term "genetic programming."
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List and explain the five parameters of the `tpot.TPOTRegressor` class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: List and explain the different and new parameters introduced in the `tpot.TPOTClassifier`
    class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are virtual environments and why are they useful?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are the sources we referenced in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Genetic programming page*: [http://geneticprogramming.com](http://geneticprogramming.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*TPOT documentation page*: [http://epistasislab.github.io/tpot/](http://epistasislab.github.io/tpot/%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
