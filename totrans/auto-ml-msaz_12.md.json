["```py\n    from azureml.core import Workspace, Dataset, Datastore\n    from azureml.core import Experiment, Environment, Model\n    from azureml.core.compute import ComputeTarget\n    ```", "```py\n    from azureml.core.runconfig import RunConfiguration, CondaDependencies, DEFAULT_CPU_IMAGE\n    from azureml.pipeline.steps import PythonScriptStep\n    from azureml.pipeline.core import Pipeline, PublishedPipeline\n    from azureml.pipeline.core import StepSequence\n    from azureml.widgets import RunDetails\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import os\n    import random as r\n    ```", "```py\n    ws = Workspace.from_config()\n    ```", "```py\n    compute_name = 'compute-cluster'\n    compute_target = ComputeTarget(ws, compute_name)\n    ```", "```py\n    datastore = Datastore.get_default(ws)\n    ```", "```py\n    sepal_length_range = np.arange(4.3, 7.9, 0.1)\n    sepal_width_range = np.arange(2, 4.4, 0.1)\n    petal_length_range = np.arange(1, 6.9, 0.1)\n    petal_width_range = np.arange(0.1, 2.5, 0.1)\n    ```", "```py\n    columns =\\ ['sepal_length','sepal_width','petal_length','petal_width']\n    IrisDF = pd.DataFrame(columns=columns)\n    IrisList = []\n    ```", "```py\n    for i in range(0,100):\n        values = \\\n    [round(r.choice(sepal_length_range),1),round(r.choice(sepal_width_range),1),round(r.choice(petal_length_range),1),round(r.choice(petal_width_range),1)]\n        iris_dictionary = pd.DataFrame(dict(zip(columns, values)),index=[0])\n        IrisList.append(iris_dictionary)\n    ```", "```py\n    IrisDF = IrisDF.append(IrisList,True)\n    ```", "```py\n    Dataset.Tabular.register_pandas_dataframe(IrisDF, datastore, 'Iris_Scoring')\n    ```", "```py\n    os.makedirs('Scoring_Scripts', exist_ok=True)\n    ```", "```py\n    import joblib\n    import numpy as np\n    import pandas as pd\n    import os\n    ```", "```py\n    run = Run.get_context()\n    ```", "```py\n    def main():\n        ws = run.experiment.workspace\n        datastore = Datastore.get_default(ws)\n        dataset = Dataset.get_by_name(ws,'Iris Scoring')\n        scoringDF = dataset.to_pandas_dataframe()\n    ```", "```py\n        model_path = Model.get_model_path('Iris-Multi-Classification-AutoML')\n        model = joblib.load(model_path)\n    ```", "```py\n        predictions = model.predict(scoringDF)\n        predSeries = pd.Series(predictions)\n        scoringDF['Prediction'] = predSeries\n    ```", "```py\n        output_datastore_path = 'Output_Folder'\n        os.makedirs(output_datastore_path, exist_ok=True) \n    ```", "```py\n        FileName = \"Iris_Predictions.csv\"\n        OutputPath = os.path.join(output_datastore_path, FileName)\n        scoringDF.to_csv(OutputPath, index = False, sep=',')\n    ```", "```py\n        datastore.upload_files(files=[OutputPath], target_path=output_datastore_path, overwrite=True)\n    ```", "```py\n        os.remove(OutputPath)\n        os.rmdir(output_datastore_path)\n    if __name__ == '__main__':\n        main()\n    ```", "```py\n    Env = Environment(name='AutoML Environment')\n    conda_dep = CondaDependencies()\n    ```", "```py\n    conda_dep.add_conda_package(\"numpy==1.18.5\")\n    conda_dep.add_conda_package(\"joblib==0.14.1\")\n    conda_dep.add_conda_package(\"pandas==0.25.3\")\n    conda_dep.add_conda_package(\"packaging==20.7\")\n    conda_dep.add_conda_package(\"xgboost==0.90\")\n    ```", "```py\n    conda_dep.add_pip_package(\"azureml-defaults==1.19.0\")\n    conda_dep.add_pip_package(\"azureml-automl-core==1.19.0\")\n    conda_dep.add_pip_package(\"azureml-automl-runtime==1.19.0\")\n    ```", "```py\n    Env.python.conda_dependencies=conda_dep\n    RegisteredEnvironment = Env.register(workspace=ws)\n    ```", "```py\n    run_config = RunConfiguration()\n    run_config.environment = Env\n    run_config.environment.docker.enabled = True\n    run_config.environment.docker.base_image =\\\n     DEFAULT_CPU_IMAGE\n    ```", "```py\n    scoring_step = PythonScriptStep(name='iris-scoring-step',\n    script_name='Iris_Scoring.py',\n    source_directory='Scoring_Scripts', \n    arguments=[],\n    inputs=[],\n    compute_target=compute_target,\n    runconfig=run_config,\n    allow_reuse=False)\n    ```", "```py\n    step_sequence = StepSequence(steps=[scoring_step])\n    pipeline = Pipeline(workspace=ws, steps=step_sequence)\n    ```", "```py\n    pipeline_experiment = Experiment(ws, 'Iris-Scoring-Pipeline-Run')\n    pipeline_run = pipeline_experiment.submit(pipeline, show_output=True)\n    ```", "```py\n    RunDetails(pipeline_run).show()\n    pipeline_run.wait_for_completion(show_output=True)\n    ```", "```py\n    published_pipeline = pipeline_run.publish_pipeline(\n        name='Iris-Scoring-Pipeline',\\\n        description='Pipeline that Scores Iris Data', version= '1.0')\n    published_pipeline\n    ```", "```py\n    from azureml.core import Workspace, Dataset, Datastore\n    from azureml.core import Experiment, Environment, Model\n    ```", "```py\n    from azureml.core.runconfig import RunConfiguration, CondaDependencies, DEFAULT_CPU_IMAGE\n    from azureml.pipeline.steps import PythonScriptStep, ParallelRunStep, ParallelRunConfig\n    from azureml.pipeline.core import Pipeline, PublishedPipeline, PipelineData\n    from azureml.pipeline.core import StepSequence\n    from azureml.widgets import RunDetails\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import os\n    import random as r\n    ```", "```py\n    ws = Workspace.from_config()\n    ```", "```py\n    compute_name = 'compute-cluster'\n    compute_target = ComputeTarget(ws, compute_name)\n    ```", "```py\n    datastore = Datastore.get_default(ws)\n    ```", "```py\n    sepal_length_range = np.arange(4.3, 7.9, 0.1)\n    sepal_width_range = np.arange(2, 4.4, 0.1)\n    petal_length_range = np.arange(1, 6.9, 0.1)\n    petal_width_range = np.arange(0.1, 2.5, 0.1)\n    ```", "```py\n    columns =\\\n    ['sepal_length','sepal_width','petal_length','petal_width']\n    IrisDF = pd.DataFrame(columns=columns)\n    IrisList = []\n    ```", "```py\n    for i in range(0,10000000):\n        values =\\\n    [round(r.choice(sepal_length_range),1),round(r.choice(sepal_width_range),1),\\\n    round(r.choice(petal_length_range),1),round(r.choice(petal_width_range),1)]\n        iris_dictionary = pd.DataFrame(dict(zip(columns, values)),index=[0])\n        IrisList.append(iris_dictionary)\n    ```", "```py\n    IrisDF = IrisDF.append(IrisList,True)\n    ```", "```py\n    Dataset.Tabular.register_pandas_dataframe(IrisDF, datastore, 'Iris_Scoring')\n    ```", "```py\n    os.makedirs('Scoring_Scripts', exist_ok=True)  \n    ```", "```py\n    %%writefile Scoring_Scripts/Iris_Scoring.py\n    from azureml.core import Run, Workspace\n    from azureml.core import Dataset, Datastore, Model\n    ```", "```py\n    import os\n    import joblib\n    import argparse\n    import numpy as np\n    import pandas as pd\n    ```", "```py\n    run = Run.get_context()\n    ```", "```py\n    def init():\n        parser = argparse.ArgumentParser()\n        parser.add_argument('--model_name',\\\n        dest=\"model_name\", required=True)\n        args, unknown_args = parser.parse_known_args()\n        global model\n        model_path = Model.get_model_path(args.model_name)\n        model = joblib.load(model_path)\n    ```", "```py\n    def run(input_data):\n        predictions = model.predict(input_data)  \n        predSeries = pd.Series(predictions)\n        input_data['Prediction'] = predSeries \n        print('Data written to parallel_run_step.txt')\n            return input_data \n    ```", "```py\n    %%writefile Scoring_Scripts/Iris_Parallel_Output_Creation.py\n    from azureml.core import Run, Workspace\n    from azureml.core import Dataset, Datastore\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import os\n    import argparse\n    ```", "```py\n    run = Run.get_context()\n    ```", "```py\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_data_folder\",type=str)\n    args = parser.parse_args()\n    ```", "```py\n    def main():  \n        FileName = \"parallel_run_step.txt\"\n        input_data_path =\\\n     os.path.join(args.input_data_folder, FileName)  \n        result =\\\n     pd.read_csv(input_data_path, delimiter=\" \", header=None)\n    ```", "```py\n        columns =\\\n    ['sepal_length','sepal_width','petal_length','petal_width', 'Prediction']\n        result.columns = columns\n    ```", "```py\n        ws = run.experiment.workspace\n        datastore = Datastore.get_default(ws)\n    ```", "```py\n        output_datastore_path = 'Output_Folder'\n        os.makedirs(output_datastore_path, exist_ok=True) \n        FileName = \"Iris_Parallel_Predictions.csv\"\n        OutputPath = os.path.join(output_datastore_path, FileName)\n        result.to_csv(OutputPath, index = False, sep=',') \n    ```", "```py\n        datastore.upload_files(files=[OutputPath], target_path = output_datastore_path, overwrite=True)\n        os.remove(OutputPath)\n        os.rmdir(output_datastore_path)\n    if __name__ == '__main__':\n        main()\n    ```", "```py\n    Env = Environment.get(ws, 'AutoML Environment') \n    ```", "```py\n    parallel_run_output =\\\n    PipelineData(name='parallel_predictions', datastore=datastore)\n    ```", "```py\n    parallel_environment = Env\n    parallel_environment.docker.enabled = True \n    parallel_environment.docker.base_image = DEFAULT_CPU_IMAGE\n    ```", "```py\n    run_config = RunConfiguration()\n    run_config.environment = Env\n    run_config.environment.docker.enabled = True\n    run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n    ```", "```py\n    parallel_run_config = ParallelRunConfig(\n        source_directory='Scoring_Scripts/',\n        entry_script=\"Iris_Parallel_Scoring.py\",\n        mini_batch_size=\"1MB\",\n        error_threshold=5,\n        output_action=\"append_row\",\n        environment=parallel_environment,\n        compute_target=compute_target,\n        run_invocation_timeout=60,\n        node_count=4,\n        logging_level=\"DEBUG\") \n    ```", "```py\n    dataset = Dataset.get_by_name(ws,'Iris Parallel Scoring')\n    input_data =\\\n    dataset.as_named_input('Iris_Parallel_Scoring')\n    model_name = 'Iris-Multi-Classification-AutoML'\n    ```", "```py\n    parallel_scoring_step = ParallelRunStep(\n        name=\"iris-parallel-scoring-step\",\n        parallel_run_config=parallel_run_config,\n        inputs=[input_data],\n        output=parallel_run_output,\n        arguments=['--model_name', model_name],\n        allow_reuse=False) \n    ```", "```py\n    output_step =\\\n     PythonScriptStep(name='iris-output-step',\n    script_name='Iris_Parallel_Output_Creation.py',\n    source_directory='Scoring_Scripts', \n    arguments=\\\n    [\"--input_data_folder\", parallel_run_output,],\n    inputs=[parallel_run_output],\n    compute_target=compute_target,\n    runconfig=run_config,\n    allow_reuse=False)\n    ```", "```py\n    step_sequence =\\\n     StepSequence(steps=[parallel_scoring_step, output_step])\n    pipeline = Pipeline(workspace=ws, steps=step_sequence)\n    ```", "```py\n    pipeline_experiment = \\\n    Experiment(ws, 'Iris-Parallel-Scoring-Pipeline-Run')\n    pipeline_run = \\\n    pipeline_experiment.submit(pipeline, show_output=True)\n    ```", "```py\n    RunDetails(pipeline_run).show()\n    pipeline_run.wait_for_completion(show_output=True)\n    ```", "```py\n    published_pipeline = pipeline_run.publish_pipeline(\n        name='Iris-Parallel-Scoring-Pipeline',\\\n        description='\\\n    Pipeline that Scores Iris Data in Parallel', version= '1.0')\n    published_pipeline\n    ```", "```py\n    from azureml.core import Workspace, Dataset, Datastore\n    from azureml.core import Experiment, Environment, Model\n    from azureml.core.compute import ComputeTarget\n    from azureml.train.automl import AutoMLConfig\n    ```", "```py\n    from azureml.core.runconfig import RunConfiguration, CondaDependencies, DEFAULT_CPU_IMAGE\n    from azureml.pipeline.steps import PythonScriptStep, AutoMLStep\n    from azureml.pipeline.core import Pipeline, PublishedPipeline, PipelineData, TrainingOutput\n    from azureml.pipeline.core import StepSequence \n    from azureml.widgets import RunDetails\n    ```", "```py\n    import os\n    ```", "```py\n    ws = Workspace.from_config()\n    ```", "```py\n    compute_name = 'compute-cluster'\n    compute_target = ComputeTarget(ws, compute_name)\n    ```", "```py\n    datastore = Datastore.get_default(ws)\n    ```", "```py\n    dataset = Dataset.get_by_name(ws, 'Iris Training')\n    ```", "```py\n    Env = Environment.get(ws,'AutoML Environment') \n    ```", "```py\n    target_column = 'species'\n    task = 'classification'\n    primary_metric = 'accuracy'\n    featurization = 'auto'\n    num_classes = 3\n    iterations = 4\n    ```", "```py\n    config = AutoMLConfig(task=task,\n                         primary_metric=primary_metric,\n                         num_classes=num_classes,\n                         featurization=featurization,\n                         compute_target=compute_target,\n                         training_data=dataset,\n                         label_column_name=target_column,\n                         experiment_timeout_minutes=15,\n                         enable_early_stopping=True,\n                         max_concurrent_iterations = iterations,\n                         n_cross_validations=5,\n                         model_explainability=True,\n                         enable_stack_ensemble=True,\n                         enable_voting_ensemble=True)\n    ```", "```py\n    metrics_data =PipelineData(name='metrics_data',\\\n     datastore=datastore,pipeline_output_name='metrics output',\\\n           training_output=TrainingOutput(type='Metrics'))\n    ```", "```py\n    model_data = PipelineData(\\\n    name='model_data', datastore=datastore, pipeline_output_name='best_model_output',\\\n             training_output=TrainingOutput(type='Model'))\n    ```", "```py\n    automl_training_step = AutoMLStep(\n        name='Multiclass_AutoML_Step',\n        automl_config=config,\n        outputs=[metrics_data, model_data],\n        allow_reuse=False)\n    ```", "```py\n    os.makedirs('Training_Scripts', exist_ok=True)  \n    ```", "```py\n    %%writefile Training_Scripts/Iris_Model_Registration.py\n    from azureml.core import Run, Workspace, Model\n    from azureml.core import Dataset, Datastore\n    import argparse\n    ```", "```py\n    run = Run.get_context()\n    ```", "```py\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model_name\", dest=\"model_name\")\n    parser.add_argument(\"--model_path\", dest=\"model_path\")\n    parser.add_argument(\"--dataset_name\", dest=\"dataset_name\")\n    args = parser.parse_args() \n    ```", "```py\n    def main():  \n        ws = run.experiment.workspace \n    ```", "```py\n        ds = Dataset.get_by_name(ws, args.dataset_name)\n        dataset = [(Dataset.Scenario.TRAINING, ds)] \n    ```", "```py\n        model = Model.register(workspace=ws,\n                               model_path=args.model_path,\n                               model_name=args.model_name,\n                               datasets=dataset)\n    if __name__ == '__main__':\n        main()\n    ```", "```py\n    run_config = RunConfiguration()\n    run_config.environment = Env\n    run_config.environment.docker.enabled = True\n    run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n    ```", "```py\n    model_name = 'Iris-Multi-Classification-AutoML'\n    dataset_name = 'Iris Training'\n    ```", "```py\n    model_registration_step = \\\n    PythonScriptStep(script_name=\"Iris_Model_Registration.py\",\\\n                   source_directory = 'Training_Scripts',\\\n                   name = \"Model-Registration-Step\",\\\n                   allow_reuse = False,\\\n                   arguments = [\"model_name\",model_name,\\\n     \"--model_path\", model_data, \"--dataset_name\",\\\n     dataset_name],\\\n                   inputs = [model_data],\\\n                   compute_target = compute_target,\\\n                   runconfig = run_config,\\\n                   allow_reuse = False)\n    ```", "```py\n    step_sequence =\\\n    StepSequence(steps=[parallel_scoring_step, output_step])\n    pipeline = Pipeline(workspace=ws, steps=step_sequence)\n    ```", "```py\n    pipeline_experiment =\\\n    Experiment(ws, 'Iris-Parallel-Scoring-Pipeline-Run')\n    pipeline_run =\\\n    pipeline_experiment.submit(pipeline, show_output=True)\n    ```", "```py\n    RunDetails(pipeline_run).show()\n    pipeline_run.wait_for_completion(show_output=True)\n    ```", "```py\n    published_pipeline = pipeline_run.publish_pipeline(\n        name='Iris-AutoML-Training-Pipeline',\\\n        description=\\\n    'Pipeline that Trains Iris Data with AutoML', version= '1.0')\n    published_pipeline\n    ```", "```py\nfrom azureml.pipeline.core import PipelineRun\nexperiment = Experiment(ws, 'your-experiment_name')\npipeline_run = PipelineRun(experiment, 'your-pipeline-run-id')\n```", "```py\n    from azureml.core import Workspace, Datastore\n    from azureml.pipeline.core import Pipeline, PublishedPipeline\n    from azureml.core.experiment import Experiment\n    from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n    ```", "```py\n    experiment =\\\n    Experiment(ws,'AutoML-Retraining-Code-Trigger')\n    published_pipeline =\\\n    PublishedPipeline.get(workspace=ws, id='your-published-pipeline-id')\n    pipeline_run = experiment.submit(published_pipeline)\n    ```", "```py\n    recurrence =\\\n    ScheduleRecurrence(frequency=\"Day\", interval=1)\n    ```", "```py\n    schedule = \\\n    Schedule.create(ws, name=\"IrisTrainingSchedule\", \n                           description=\"AutoML Training\",\n                           pipeline_id='your-pipeline-id', \n                           experiment_name='Iris-Retraining', \n                           recurrence=recurrence)\n    ```"]