- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Divide and Conquer – Classification Using Decision Trees and Rules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When deciding between job offers, many people begin by making lists of pros
    and cons, then eliminate options using simple rules. For instance, they may decide,
    “If I have to commute for more than an hour, I will be unhappy,” or “If I make
    less than $50K, I can’t support my family.” In this way, the complex decision
    of predicting one’s future career happiness can be reduced to a series of simple
    decisions.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter covers decision trees and rule learners—two machine learning methods
    that also make complex decisions from sets of simple choices. These methods present
    their knowledge in the form of logical structures that can be understood with
    no statistical knowledge. This aspect makes these models particularly useful for
    business strategy and process improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will have learned:'
  prefs: []
  type: TYPE_NORMAL
- en: How trees and rules “greedily” partition data into interesting segments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The most common decision tree and classification rule learners, including the
    C5.0, 1R, and RIPPER algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to use these algorithms for performing real-world classification tasks,
    such as identifying risky bank loans and poisonous mushrooms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will begin by examining decision trees and follow that with a look at classification
    rules. Then, we will summarize what we’ve learned by previewing later chapters,
    which discuss methods that use trees and rules as a foundation for more advanced
    machine learning techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Decision tree learners are powerful classifiers that utilize a **tree structure**
    to model the relationships among the features and the potential outcomes. As illustrated
    in the following figure, this structure earned its name because it mirrors the
    way a literal tree begins, with a wide trunk at the base that splits off into
    narrower and narrower branches as it works its way upward. In much the same way,
    a decision tree classifier uses a structure of branching decisions to channel
    examples into a final predicted class value.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand how this works in practice, let’s consider the following
    tree, which predicts whether a job offer should be accepted. A job offer under
    consideration begins at the **root node**, from where it then passes through the
    **decision nodes**, which require choices to be made based on the attributes of
    the job. These choices split the data across **branches** that indicate the potential
    outcomes of a decision. They are depicted here as yes or no outcomes, but in other
    cases, there may be more than two possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: If a final decision can be made, the tree terminates in **leaf nodes** (also
    known as **terminal nodes**) that denote the action to be taken as the result
    of the series of decisions. In the case of a predictive model, the leaf nodes
    provide the expected result given the series of events in the tree.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_05_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1: A decision tree depicting the process of determining whether to
    accept a new job offer'
  prefs: []
  type: TYPE_NORMAL
- en: 'A great benefit of decision tree algorithms is that the flowchart-like tree
    structure is not only for the machine’s internal use. After the model is created,
    many decision tree algorithms output the resulting structure in a human-readable
    format. This provides insight into how and why the model works or doesn’t work
    well for a particular task. This also makes decision trees particularly appropriate
    for applications in which the classification mechanism needs to be transparent
    for legal reasons, or if the results need to be shared with others to inform future
    business practices. With this in mind, some potential uses include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Credit scoring models in which the criteria that cause an applicant to be rejected
    need to be clearly documented and free from bias
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marketing studies of customer behavior, such as satisfaction or churn, which
    will be shared with management or advertising agencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagnosis of medical conditions based on laboratory measurements, symptoms,
    or rates of disease progression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although the previous applications illustrate the value of trees in informing
    decision-making processes, this is not to suggest that their utility ends here.
    In fact, decision trees are one of the single most widely used machine learning
    techniques, and can be applied to model almost any type of data—often with excellent
    out-of-the-box performance.
  prefs: []
  type: TYPE_NORMAL
- en: That said, despite their wide applicability, it is worth noting that there are
    some scenarios where trees may not be an ideal fit. This includes tasks where
    the data has many nominal features with many levels or a large number of numeric
    features. These cases may result in a very large number of decisions and an overly
    complex tree. They may also contribute to the tendency of decision trees to overfit
    data, though as we will soon see, even this weakness can be overcome by adjusting
    some simple parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Divide and conquer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Decision trees are built using a heuristic called **recursive partitioning**.
    This approach is also commonly known as **divide and conquer** because it splits
    the data into subsets, which are then split repeatedly into even smaller subsets,
    and so on and so forth, until the process stops when the algorithm determines
    the data within the subsets are sufficiently homogenous, or another stopping criterion
    has been met.
  prefs: []
  type: TYPE_NORMAL
- en: To see how splitting a dataset can create a decision tree, imagine a root node
    that will grow into a mature tree. At first, the root node represents the entire
    dataset, since no splitting has transpired. Here, the decision tree algorithm
    must choose a feature to split upon; ideally, it chooses the feature most predictive
    of the target class.
  prefs: []
  type: TYPE_NORMAL
- en: The examples are then partitioned into groups according to the distinct values
    of this feature, and the first set of tree branches is formed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Working down each branch, the algorithm continues to divide and conquer the
    data, choosing the best candidate feature each time to create another decision
    node until a stopping criterion is reached. Divide and conquer might stop at a
    node if:'
  prefs: []
  type: TYPE_NORMAL
- en: All (or nearly all) of the examples at the node have the same class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are no remaining features to distinguish among the examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tree has grown to a predefined size limit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To illustrate the tree-building process, let’s consider a simple example. Imagine
    that you work for a Hollywood studio, where your role is to decide whether the
    studio should move forward with producing the screenplays pitched by promising
    new authors. After returning from a vacation, your desk is piled high with proposals.
    Without the time to read each proposal cover-to-cover, you decide to develop a
    decision tree algorithm to predict whether a potential movie would fall into one
    of three categories: *Critical Success*, *Mainstream Hit*, or *Box Office Bust*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To source data to create the decision tree model, you turn to the studio archives
    to examine the factors leading to the success or failure of the company’s 30 most
    recent releases. You quickly notice a relationship between the film’s estimated
    shooting budget, the number of A-list celebrities lined up for starring roles,
    and the film’s level of success. Excited about this finding, you produce a scatterplot
    to illustrate the pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing shape  Description automatically generated](img/B17290_05_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2: A scatterplot depicting the relationship between a movie’s budget
    and celebrity count'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the divide and conquer strategy, you can build a simple decision tree
    from this data. First, to create the tree’s root node, you split the feature indicating
    the number of celebrities, partitioning the movies into groups with and without
    a significant number of A-list stars:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing shape  Description automatically generated](img/B17290_05_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.3: The decision tree’s first split divides the data into films with
    high and low celebrity counts'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, among the group of movies with a larger number of celebrities, you make
    another split between movies with and without a high budget:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing shape  Description automatically generated](img/B17290_05_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4: The decision tree’s second split further divides the films with
    a high celebrity count into those with low and high budgets'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you’ve partitioned the data into three groups. The group in the
    top-left corner of the diagram is composed entirely of critically acclaimed films.
    This group is distinguished by a high number of celebrities and a relatively low
    budget. In the top-right corner, nearly all movies are box office hits with high
    budgets and many celebrities. The final group, which has little star power but
    budgets ranging from small to large, contains the flops.
  prefs: []
  type: TYPE_NORMAL
- en: If desired, you could continue to divide and conquer the data by splitting it
    on increasingly specific ranges of budget and celebrity count until each of the
    currently misclassified values is correctly classified in its own tiny partition.
    However, it is not advisable to overfit a decision tree in this way. Although
    there is nothing stopping the algorithm from splitting the data indefinitely,
    overly specific decisions do not always generalize more broadly. Thus, you choose
    to avoid the problem of overfitting by stopping the algorithm here, since more
    than 80 percent of the examples in each group are from a single class. This is
    the stopping criterion for the decision tree model.
  prefs: []
  type: TYPE_NORMAL
- en: You might have noticed that diagonal lines might have split the data even more
    cleanly. This is one limitation of the decision tree’s knowledge representation,
    which uses **axis-parallel splits**. The fact that each split considers one feature
    at a time prevents the decision tree from forming more complex decision boundaries.
    For example, a diagonal line could be created by a decision that asks, “Is the
    number of celebrities greater than the estimated budget?” If so, then “it will
    be a critical success.”
  prefs: []
  type: TYPE_NORMAL
- en: The model for predicting the future success of movies can be represented in
    a simple tree, as shown in the following diagram. Each step in the tree shows
    the fraction of examples falling into each class, which shows how the data becomes
    more homogeneous as the branches get closer to a leaf. To evaluate a new movie
    script, follow the branches through each decision until the script’s success or
    failure has been predicted. Using this approach, you will be able to quickly identify
    the most promising options among the backlog of scripts and get back to more important
    work, such as writing an Academy Awards acceptance speech!
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_05_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.5: A decision tree built on historical movie data can forecast the
    performance of future movies'
  prefs: []
  type: TYPE_NORMAL
- en: Since real-world data contains more than two features, decision trees quickly
    become far more complex than this, with many more nodes, branches, and leaves.
    In the next section, you will learn about a popular algorithm to build decision
    tree models automatically.
  prefs: []
  type: TYPE_NORMAL
- en: The C5.0 decision tree algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are numerous implementations of decision trees, but one of the most well
    known is the C5.0 algorithm. This algorithm was developed by computer scientist
    J. Ross Quinlan as an improved version of his prior algorithm, C4.5, which itself
    is an improvement over his **Iterative Dichotomiser 3** (**ID3**) algorithm. Although
    Quinlan markets C5.0 to commercial clients (see [http://www.rulequest.com/](http://www.rulequest.com/)
    for details), the source code for a single-threaded version of the algorithm was
    made public, and has therefore been incorporated into programs such as R.
  prefs: []
  type: TYPE_NORMAL
- en: To further confuse matters, a popular Java-based open-source alternative to
    C4.5, titled **J48**, is included in R’s `RWeka` package (introduced later in
    this chapter). As the differences between C5.0, C4.5, and J48 are minor, the principles
    in this chapter apply to any of these three methods and the algorithms should
    be considered synonymous.
  prefs: []
  type: TYPE_NORMAL
- en: The C5.0 algorithm has become the industry standard for producing decision trees
    because it does well for most types of problems directly out of the box. Compared
    to other advanced machine learning models, such as those described in *Chapter
    7*, *Black-Box Methods – Neural Networks and Support Vector Machines*, the decision
    trees built by C5.0 generally perform nearly as well but are much easier to understand
    and deploy. Additionally, as shown in the following table, the algorithm’s weaknesses
    are relatively minor and can be largely avoided.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strengths** | **Weaknesses** |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: An all-purpose classifier that does well on many types of problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly automatic learning process, which can handle numeric or nominal features,
    as well as missing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Excludes unimportant features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be used on both small and large datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Results in a model that can be interpreted without a mathematical background
    (for relatively small trees)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More efficient than other complex models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Decision tree models are often biased toward splits on features having a large
    number of levels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is easy to overfit or underfit the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can have trouble modeling some relationships due to reliance on axis-parallel
    splits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Small changes in training data can result in large changes to decision logic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large trees can be difficult to interpret and the decisions they make may seem
    counterintuitive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: To keep things simple, our earlier decision tree example ignored the mathematics
    involved with how a machine would employ a divide and conquer strategy. Let’s
    explore this in more detail to examine how this heuristic works in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the best split
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first challenge that a decision tree will face is to identify which feature
    to split upon. In the previous example, we looked for a way to split the data
    such that the resulting partitions contained examples primarily of a single class.
  prefs: []
  type: TYPE_NORMAL
- en: The degree to which a subset of examples contains only a single class is known
    as **purity**, and any subset composed of only a single class is called **pure**.
  prefs: []
  type: TYPE_NORMAL
- en: There are various measurements of purity that can be used to identify the best
    decision tree splitting candidate. C5.0 uses **entropy**, a concept borrowed from
    information theory that quantifies the randomness, or disorder, within a set of
    class values. Sets with high entropy are very diverse and provide little information
    about other items that may also belong in the set, as there is no apparent commonality.
    The decision tree hopes to find splits that reduce entropy, ultimately increasing
    homogeneity within the groups.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, entropy is measured in **bits**. If there are only two possible classes,
    entropy values can range from 0 to 1\. For *n* classes, entropy ranges from 0
    to *log*[2](*n*). In each case, the minimum value indicates that the sample is
    completely homogenous, while the maximum value indicates that the data are as
    diverse as possible, and no group has even a small plurality.
  prefs: []
  type: TYPE_NORMAL
- en: 'In mathematical notion, entropy is specified as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_05_001.png)'
  prefs: []
  type: TYPE_IMG
- en: In this formula, for a given segment of data (*S*), the term *c* refers to the
    number of class levels, and *p*[i] refers to the proportion of values falling
    into the *i*th class level.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, suppose we have a partition of data with two classes: red (60
    percent) and white (40 percent). We can calculate the entropy as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can visualize the entropy for all possible two-class arrangements. If we
    know the proportion of examples in one class is *x*, then the proportion in the
    other class is *(1 – x)*. Using the `curve()` function, we can then plot the entropy
    for all possible values of *x*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17290_05_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.6: The total entropy as the proportion of one class varies in a two-class
    outcome'
  prefs: []
  type: TYPE_NORMAL
- en: As illustrated by the peak at *x = 0.50*, a 50-50 split results in the maximum
    entropy. As one class increasingly dominates the other, the entropy reduces to
    zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use entropy to determine the optimal feature to split upon, the algorithm
    calculates the change in homogeneity that would result from a split on each possible
    feature, a measure known as **information gain**. The information gain for a feature
    *F* is calculated as the difference between the entropy in the segment before
    the split (*S*[1]) and the partitions resulting from the split (*S*[2]):'
  prefs: []
  type: TYPE_NORMAL
- en: InfoGain(*F*) = Entropy(S[1]) – Entropy(S[2])
  prefs: []
  type: TYPE_NORMAL
- en: 'One complication is that after a split, the data is divided into more than
    one partition. Therefore, the function to calculate *Entropy(S*[2]*)* needs to
    consider the total entropy across all partitions resulting from the split. It
    does this by weighting each partition’s entropy according to the proportion of
    all records falling into that partition. This can be stated in a formula as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_05_002.png)'
  prefs: []
  type: TYPE_IMG
- en: In simple terms, the total entropy resulting from a split is the sum of entropy
    of each of the *n* partitions weighted by the proportion of examples falling in
    the partition (*w*[i]).
  prefs: []
  type: TYPE_NORMAL
- en: The higher the information gain, the better a feature is at creating homogeneous
    groups after a split on that feature. If the information gain is zero, there is
    no reduction in entropy for splitting on this feature. On the other hand, the
    maximum information gain is equal to the entropy prior to the split. This would
    imply the entropy after the split is zero, which means that the split results
    in completely homogeneous groups.
  prefs: []
  type: TYPE_NORMAL
- en: The previous formulas assume nominal features, but decision trees use information
    gain for splitting on numeric features as well. To do so, a common practice is
    to test various splits that divide the values into groups greater than or less
    than a threshold. This reduces the numeric feature into a two-level categorical
    feature that allows information gain to be calculated as usual. The numeric cut
    point yielding the largest information gain is chosen for the split.
  prefs: []
  type: TYPE_NORMAL
- en: Though it is used by C5.0, information gain is not the only splitting criterion
    that can be used to build decision trees. Other commonly used criteria are the
    **Gini index**, **chi-squared statistic**, and **gain ratio**. For a review of
    these (and many more) criteria, refer to *An Empirical Comparison of Selection
    Measures for Decision-Tree Induction, Mingers, J, Machine Learning, 1989, Vol.
    3, pp. 319-342*.
  prefs: []
  type: TYPE_NORMAL
- en: Pruning the decision tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned earlier, a decision tree can continue to grow indefinitely, choosing
    splitting features and dividing into smaller and smaller partitions until each
    example is perfectly classified or the algorithm runs out of features to split
    on. However, if the tree grows overly large, many of the decisions it makes will
    be overly specific and the model will be overfitted to the training data. The
    process of **pruning** a decision tree involves reducing its size such that it
    generalizes better to unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: One solution to this problem is to stop the tree from growing once it reaches
    a certain number of decisions or when the decision nodes contain only a small
    number of examples. This is called **early stopping** or **pre-pruning** the decision
    tree. As the tree avoids doing needless work, this is an appealing strategy. However,
    one downside to this approach is that there is no way to know whether the tree
    will miss subtle but important patterns that it would have learned had it grown
    to a larger size.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative, called **post-pruning**, involves growing a tree that is intentionally
    too large and pruning leaf nodes to reduce the size of the tree to a more appropriate
    level. This is often a more effective approach than pre-pruning because it is
    quite difficult to determine the optimal depth of a decision tree without growing
    it first. Pruning the tree later allows the algorithm to be certain that all the
    important data structures were discovered.
  prefs: []
  type: TYPE_NORMAL
- en: The implementation details of pruning operations are very technical and beyond
    the scope of this book. For a comparison of some of the available methods, see
    *A Comparative Analysis of Methods for Pruning Decision Trees, Esposito, F, Malerba,
    D, Semeraro, G, IEEE Transactions on Pattern Analysis and Machine Intelligence,
    1997, Vol. 19, pp. 476-491*.
  prefs: []
  type: TYPE_NORMAL
- en: One of the benefits of the C5.0 algorithm is that it is opinionated about pruning—it
    takes care of many of the decisions automatically using reasonable defaults. Its
    overall strategy is to post-prune the tree. It first grows a large tree that overfits
    the training data. Later, the nodes and branches that have little effect on the
    classification errors are removed. In some cases, entire branches are moved further
    up the tree or replaced by simpler decisions. These processes of grafting branches
    are known as **subtree raising** and **subtree replacement**, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the right balance of overfitting and underfitting is a bit of an art,
    but if model accuracy is vital, it may be worth investing some time with various
    pruning options to see if it improves the test dataset performance. As you will
    soon see, one of the strengths of the C5.0 algorithm is that it is very easy to
    adjust the training options.
  prefs: []
  type: TYPE_NORMAL
- en: Example – identifying risky bank loans using C5.0 decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The global financial crisis of 2007-2008 highlighted the importance of transparency
    and rigor in banking practices. As the availability of credit was limited, banks
    tightened their lending systems and turned to machine learning to more accurately
    identify risky loans.
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees are widely used in the banking industry due to their high accuracy
    and ability to formulate a statistical model in plain language. Since governments
    in many countries carefully monitor the fairness of lending practices, executives
    must be able to explain why one applicant was rejected for a loan while another
    was approved. This information is also useful for customers hoping to determine
    why their credit rating is unsatisfactory.
  prefs: []
  type: TYPE_NORMAL
- en: It is likely that automated credit scoring models are used for credit card mailings
    and instant online approval processes. In this section, we will develop a simple
    credit approval model using C5.0 decision trees. We will also see how the model
    results can be tuned to minimize errors that result in a financial loss.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – collecting data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The motivation for our credit model is to identify factors that are linked to
    a higher risk of loan default. To do this, we must obtain data on past bank loans
    as well as information about the loan applicants that would have been available
    at the time of credit application.
  prefs: []
  type: TYPE_NORMAL
- en: Data with these characteristics are available in a dataset donated to the UCI
    Machine Learning Repository ([http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml))
    by Hans Hofmann of the University of Hamburg. The dataset contains information
    on loans obtained from a credit agency in Germany.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset presented in this chapter has been modified slightly from the original
    in order to eliminate some preprocessing steps. To follow along with the examples,
    download the `credit.csv` file from the Packt Publishing GitHub repository for
    this chapter and save it to your R working directory.
  prefs: []
  type: TYPE_NORMAL
- en: The credit dataset includes 1,000 examples of loans, plus a set of numeric and
    nominal features indicating characteristics of the loan and the loan applicant.
    A class variable indicates whether the loan went into default. Let’s see if we
    can identify any patterns that predict this outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – exploring and preparing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we have done previously, we will import the data using the `read.csv()`
    function. Now, because the character data is entirely categorical, we can set
    the `stringsAsFactors = TRUE` to automatically convert all character type columns
    to factors in the resulting data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check the resulting object by examining the first few lines of output
    from the `str()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We see the expected 1,000 observations and 17 features, which are a combination
    of factor and integer data types.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at the `table()` output for a couple of loan features that
    seem likely to predict a default. The applicant’s checking and savings account
    balances are recorded as categorical variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The checking and savings account balances may prove to be important predictors
    of loan default status. Note that since the loan data was obtained from Germany,
    the values use the **Deutsche Mark** (**DM**), which was the currency used in
    Germany prior to the adoption of the Euro.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the loan’s features are numeric, such as its duration and the amount
    of credit requested:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The loan amounts ranged from 250 DM to 18,420 DM across terms of 4 to 72 months.
    They had a median amount of 2,320 DM and a median duration of 18 months.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `default` vector indicates whether the loan applicant was able to meet
    the agreed payment terms or if they went into default. A total of 30 percent of
    the loans in this dataset went into default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: A high rate of default is undesirable for a bank because it means that the bank
    is unlikely to fully recover its investment. If we are successful, our model will
    identify applicants who are at high risk of default, allowing the bank to refuse
    the credit request before the money is given.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation – creating random training and test datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we have done in previous chapters, we will split our data into two portions:
    a training dataset to build the decision tree and a test dataset to evaluate its
    performance on new data. We will use 90 percent of the data for training and 10
    percent for testing, which will provide us with 100 records to simulate new applicants.
    A 90-10 split is used here rather than the more common 75-25 split due to the
    relatively small size of the credit dataset; given that predicting loan defaults
    is a challenging learning task, we need as much training data as possible while
    still holding out a sufficient test sample.'
  prefs: []
  type: TYPE_NORMAL
- en: More sophisticated approaches for training and evaluating models with relatively
    small datasets are introduced in *Chapter 10*, *Evaluating Model Performance*.
  prefs: []
  type: TYPE_NORMAL
- en: As prior chapters used data that had been sorted in a random order, we simply
    divided the dataset into two portions by taking the first subset of records for
    training and the remaining subset for testing. In contrast, the credit dataset
    is not randomly ordered, making the prior approach unwise. Suppose that the bank
    had sorted the data by the loan amount, with the largest loans at the end of the
    file. If we used the first 90 percent for training and the remaining 10 percent
    for testing, we would be training a model on only the small loans and testing
    the model on the big loans. Obviously, this could be problematic.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll solve this problem by training the model on a **random sample** of the
    credit data. A random sample is simply a process that selects a subset of records
    at random. In R, the `sample()` function is used to perform random sampling. However,
    before putting it in action, a common practice is to set a **seed** value, which
    causes the randomization process to follow a sequence that can be replicated later.
    It may seem that this defeats the purpose of generating random numbers, but there
    is a good reason for doing it this way. Providing a seed value via the `set.seed()`
    function ensures that if the analysis is repeated in the future, an identical
    result is obtained.
  prefs: []
  type: TYPE_NORMAL
- en: You may wonder how a so-called random process can be seeded to produce an identical
    result. This is because computers use a mathematical function called a **pseudorandom
    number generator** to create random number sequences that appear to act very random,
    but are actually quite predictable given knowledge of the previous values in the
    sequence. In practice, modern pseudorandom number sequences are virtually indistinguishable
    from true random sequences, but have the benefit that computers can generate them
    quickly and easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following commands use `sample()` with a seed value. Note that the `set.seed()`
    function uses the arbitrary value `9829`. Omitting this seed will cause your training
    and testing splits to differ from those shown in the remainder of this chapter.
    The following commands select 900 values at random out of the sequence of integers
    from 1 to 1,000:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As expected, the resulting `train_sample` object is a vector of 900 random
    integers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'By using this vector to select rows from the credit data, we can split it into
    the 90 percent training and 10 percent test datasets we desired. Recall that the
    negation operator (the `-` character) used in the selection of the test records
    tells R to select records that are not in the specified rows; in other words,
    the test data includes only the rows that are not in the training sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'If randomization was done correctly, we should have about 30 percent of loans
    with default in each of the datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Both the training and test datasets have roughly similar distributions of loan
    defaults, so we can now build our decision tree. In the case that the proportions
    differ greatly, we may decide to resample the dataset, or attempt a more sophisticated
    sampling approach, such as those covered in *Chapter 10*, *Evaluating Model Performance*.
  prefs: []
  type: TYPE_NORMAL
- en: If your results do not match exactly, ensure that you ran the command `set.seed(9829)`
    immediately prior to creating the `train_sample` vector. Note that R’s default
    random number generator changed in R version 3.6.0 and your results will differ
    if this code is run on earlier versions. This also means that the results here
    are slightly different from those in prior editions of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – training a model on the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use the C5.0 algorithm in the `C50` package for training our decision
    tree model. If you have not done so already, install the package with `install.packages("C50")`
    and load it to your R session using `library(C50)`.
  prefs: []
  type: TYPE_NORMAL
- en: The following syntax box lists some of the most common parameters used when
    building decision trees. Compared to the machine learning approaches we have used
    previously, the C5.0 algorithm offers many more ways to tailor the model to a
    particular learning problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_05_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.7: C5.0 decision tree syntax'
  prefs: []
  type: TYPE_NORMAL
- en: The `C5.0()` function uses a new syntax known as the **R formula interface**
    to specify the model to be trained. The formula syntax uses the `~` operator (known
    as the tilde) to express the relationship between a target variable and its predictors.
    The class variable to be learned goes to the left of the tilde and the predictor
    features are written on the right, separated by `+` operators.
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to model the relationship between the target `y` and predictors
    `x1` and `x2`, you would write the formula as `y ~ x1 + x2`. To include all variables
    in the model, the period character is used. For example, `y ~ .` specifies the
    relationship between `y` and all other features in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The R formula interface is used across many R functions and offers some powerful
    features to describe the relationships among predictor variables. We will explore
    some of these features in later chapters. However, if you’re eager for a preview,
    feel free to read the documentation using the `?formula` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the first iteration of the credit approval model, we’ll use the default
    C5.0 settings, as shown in the following code. The target class is named `default`,
    so we put it on the left-hand side of the tilde, which is followed by a period
    indicating that all other columns in the `credit_train` data frame are to be used
    as predictors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The `credit_model` object now contains a C5.0 decision tree. We can see some
    basic data about the tree by typing its name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The output shows some simple facts about the tree, including the function call
    that generated it, the number of features (labeled `predictors`), and examples
    (labeled `samples`) used to grow the tree. Also listed is the tree size of `67`,
    which indicates that the tree is 67 decisions deep—quite a bit larger than the
    example trees we’ve considered so far!
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the tree’s decisions, we can call the `summary()` function on the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following output, which has been truncated to show only
    the first few lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding output shows some of the first branches in the decision tree.
    The first three lines could be represented in plain language as:'
  prefs: []
  type: TYPE_NORMAL
- en: If the checking account balance is unknown or greater than 200 DM, then classify
    as “not likely to default”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Otherwise, if the checking account balance is less than zero DM or between one
    and 200 DM...
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: …and the credit history is perfect or very good, then classify as “likely to
    default”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The numbers in parentheses indicate the number of examples meeting the criteria
    for that decision and the number incorrectly classified by the decision. For instance,
    on the first line, `415/55` indicates that, of the 415 examples reaching the decision,
    55 were incorrectly classified as “not likely to default.” In other words, 55
    out of 415 applicants actually defaulted in spite of the model’s prediction to
    the contrary.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes a tree results in decisions that make little logical sense. For example,
    why would an applicant whose credit history is perfect or very good be likely
    to default, while those whose checking balance is unknown are not likely to default?
    Contradictory rules like this occur sometimes. They might reflect a real pattern
    in the data, or they may be a statistical anomaly. In either case, it is important
    to investigate such strange decisions to see whether the tree’s logic makes sense
    for business use.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the tree, the `summary(credit_model)` output displays a confusion matrix,
    which is a cross-tabulation that indicates the model’s incorrectly classified
    records in the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The `Errors` heading shows that the model correctly classified all but 118 of
    the 900 training instances for an error rate of 13.1 percent. A total of 31 actual
    `no` values were incorrectly classified as `yes` (false positives), while 87 `yes`
    values were misclassified as `no` (false negatives). Given the tendency of decision
    trees to overfit to the training data, the error rate reported here, which is
    based on training data performance, may be overly optimistic. Therefore, it is
    especially important to apply the decision tree to an unseen test dataset, which
    we will do shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output also includes a section labeled `Attribute usage`, which provides
    a general sense of the most important predictors used in the decision tree model.
    The first few lines of this output are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The **attribute usage** statistics in decision tree output refer to the percentage
    of rows in the training data that use the listed feature to make a final prediction.
    For example, 100 percent of rows require the `checking_balance` feature, because
    the checking account balance is used at the very first split in the tree. The
    second split uses `credit_history`, but 46.11 percent of rows were already classified
    as non-default based on the checking account balance. This leaves only 53.89 percent
    of rows that need to consider the applicant’s credit history. At the bottom of
    this list, only 12.11 percent of examples require the applicant’s age to make
    a prediction, which suggests that the applicant’s age is less important than their
    checking account balance or credit history.
  prefs: []
  type: TYPE_NORMAL
- en: This information, along with the tree structure itself, provides insight into
    how the model works. Both are readily understood, even without a statistics background.
    Of course, a model that cannot make accurate predictions is useless even if it
    is easy to understand, so we will now perform a more formal evaluation of its
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: C5.0 decision tree models can be visualized using the `plot()` function, which
    relies on functionality in the `partykit` package. Unfortunately, this is useful
    only for relatively small decision trees. For example, our decision tree can be
    visualized by typing `plot(credit_model)`, but unless you have a very large display,
    the resulting plot will likely appear as a jumbled mess due to the large number
    of nodes and splits in the tree.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – evaluating model performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To apply our decision tree to the test dataset, we use the `predict()` function
    as shown in the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates a vector of predicted class values, which we can compare to the
    actual class values using the `CrossTable()` function in the `gmodels` package.
    Setting the `prop.c` and `prop.r` parameters to `FALSE` removes the column and
    row percentages from the table. The remaining percentage (`prop.t`) indicates
    the proportion of records in the cell out of the total number of records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This results in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Out of the 100 loan applications in the test set, our model correctly predicted
    that 56 did not default and 11 did default, resulting in an accuracy of 67 percent
    and an error rate of 33 percent. This is somewhat worse than its performance on
    the training data, but not unexpected, given that a model’s performance is often
    worse on unseen data. Also note that the model only correctly predicted 11 of
    the 35 actual loan defaults in the test data, or 31 percent. Unfortunately, this
    type of error is potentially a very costly mistake, as the bank loses money on
    each default. Let’s see if we can improve the result with a bit more effort.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – improving model performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our model’s error rate is likely to be too high to deploy it in a real-time
    credit scoring application. In fact, if the model had predicted “no default” for
    every test case, it would have been correct 65 percent of the time—a result barely
    worse than our model but requiring much less effort! Predicting loan defaults
    using only 900 training examples seems to be a challenging problem.
  prefs: []
  type: TYPE_NORMAL
- en: Making matters even worse, our model performed especially poorly at identifying
    applicants who do default on their loans. Luckily, there are a couple of simple
    ways to adjust the C5.0 algorithm that may help to improve the performance of
    the model, both overall and for the costlier type of mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: Boosting the accuracy of decision trees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One way the C5.0 algorithm improved upon the C4.5 algorithm was through the
    addition of **adaptive boosting**. This is a process in which many decision trees
    are built, and the trees vote on the best class for each example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea of boosting is based largely upon research by Rob Schapire and Yoav
    Freund. For more information, try searching the web for their publications or
    their textbook *Boosting: Foundations and Algorithms, Cambridge, MA, The MIT Press,
    2012*.'
  prefs: []
  type: TYPE_NORMAL
- en: As boosting can be applied more generally to any machine learning algorithm,
    it is covered in more detail later in this book in *Chapter 14*, *Building Better
    Learners*. For now, it suffices to say that boosting is rooted in the notion that
    by combining several weak-performing learners, you can create a team that is much
    stronger than any of the learners alone. Each of the models has a unique set of
    strengths and weaknesses, and may be better or worse at certain problems. Using
    a combination of several learners with complementary strengths and weaknesses
    can therefore dramatically improve the accuracy of a classifier.
  prefs: []
  type: TYPE_NORMAL
- en: The `C5.0()` function makes it easy to add boosting to our decision tree. We
    simply need to add an additional `trials` parameter indicating the number of separate
    decision trees to use in the boosted team. The `trials` parameter sets an upper
    limit; the algorithm will stop adding trees if it recognizes that additional trials
    do not seem to be improving the accuracy. We’ll start with 10 trials, a number
    that has become the de facto standard, as research suggests that this reduces
    error rates on test data by about 25 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside from the new parameter, the command is similar to before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'While examining the resulting model, we can see that the output now indicates
    the addition of boosting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The new output shows that across the 10 iterations, our tree size shrunk. If
    you would like, you can see all 10 trees by typing `summary(credit_boost10)` at
    the command prompt. Note that some of these trees, including the tree built for
    the first trial, have one or more subtrees such as the one denoted `[S1]` in the
    following excerpt of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice the line that says that if `age > 23`, the result is `[S1]`. To determine
    what this means, we must match `[S1]` to the corresponding subtree slightly further
    down in the output, where we see that the final decision requires several more
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Such subtrees are the result of post-pruning options like subtree raising and
    subtree replacement, as mentioned earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tree’s `summary()` output also shows the tree’s performance on the training
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The classifier made 19 mistakes on 900 training examples for an error rate
    of 2.1 percent. This is quite an improvement over the 13.1 percent training error
    rate we noted before boosting! However, it remains to be seen whether we see a
    similar improvement on the test data. Let’s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting table is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Here, we reduced the total error rate from 33 percent prior to boosting to 26
    percent in the boosted model. This may not seem like a large improvement, but
    it is not too far away from the 25 percent reduction we expected. That said, if
    boosting can be added this easily, why not apply it by default to every decision
    tree? The reason is twofold. First, if building a decision tree once takes a great
    deal of computation time, building many trees may be computationally impractical.
    Secondly, if the training data is very noisy, then boosting might not result in
    an improvement at all. Still, if greater accuracy is needed, it’s worth giving
    boosting a try.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the model is still doing poorly at identifying the true defaults,
    predicting only 46 percent correctly (16 out of 35) compared to 31 percent (11
    of 35) in the simpler model. Let’s investigate one more option to see if we can
    reduce these types of costly errors.
  prefs: []
  type: TYPE_NORMAL
- en: Making some mistakes cost more than others
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Giving a loan to an applicant who is likely to default can be an expensive mistake.
    One solution to reduce the number of false negatives may be to reject a larger
    number of borderline applicants under the assumption that the interest that the
    bank would earn from a risky loan is far outweighed by the massive loss it would
    incur if the money is not paid back at all.
  prefs: []
  type: TYPE_NORMAL
- en: The C5.0 algorithm allows us to assign a penalty to different types of errors
    in order to discourage a tree from making more costly mistakes. The penalties
    are designated in a **cost matrix**, which specifies how many times more costly
    each error is relative to any other.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin constructing the cost matrix, we need to start by specifying the dimensions.
    Since the predicted and actual values can both take two values, `yes` or `no`,
    we need to describe a 2x2 matrix using a list of two vectors, each with two values.
    At the same time, we’ll also name the matrix dimensions to avoid confusion later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Examining the new object shows that our dimensions have been set up correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to assign the penalty for the various types of errors by supplying
    four values to fill the matrix. Since R fills a matrix by filling columns one
    by one from top to bottom, we need to supply the values in a specific order:'
  prefs: []
  type: TYPE_NORMAL
- en: Predicted `no`, actual `no`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Predicted `yes`, actual `no`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Predicted `no`, actual `yes`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Predicted `yes`, actual `yes`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Suppose we believe that a loan default costs the bank four times as much as
    a missed opportunity. Our penalty values then could be defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates the following matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'As defined by this matrix, there is no cost assigned when the algorithm classifies
    a `no` or `yes` correctly, but a false negative has a cost of `4` versus a false
    positive’s cost of `1`. To see how this impacts classification, let’s apply it
    to our decision tree using the `costs` parameter of the `C5.0()` function. We’ll
    otherwise use the same steps as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Compared to our boosted model, this version makes more mistakes overall: 36
    percent error here versus 26 percent in the boosted case. However, the types of
    mistakes are very different. Where the previous models classified only 31 and
    46 percent of defaults correctly, in this model, *30 / 35 = 86%* of the actual
    defaults were correctly predicted to be defaults. This trade-off resulting in
    a reduction of false negatives at the expense of increasing false positives may
    be acceptable if our cost estimates were accurate.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding classification rules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Classification rules represent knowledge in the form of logical if-else statements
    that assign a class to unlabeled examples. They are specified in terms of an **antecedent**
    and a **consequent**, which form a statement stating that “if *this* happens,
    then *that* happens.” The antecedent comprises certain combinations of feature
    values, while the consequent specifies the class value to assign if the rule’s
    conditions are met. A simple rule might state, “if the computer is making a clicking
    sound, then it is about to fail.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule learners are closely related siblings of decision tree learners and are
    often used for similar types of tasks. Like decision trees, they can be used for
    applications that generate knowledge for future action, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Identifying conditions that lead to hardware failure in mechanical devices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Describing the key characteristics of groups of people for customer segmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding conditions that precede large drops or increases in the prices of shares
    on the stock market
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rule learners do have some distinct contrasts relative to decision trees. Unlike
    a tree, which must be followed through a series of branching decisions, rules
    are propositions that can be read much like independent statements of fact. Additionally,
    for reasons that will be discussed later, the results of a rule learner can be
    more simple, direct, and easier to understand than a decision tree built on the
    same data.
  prefs: []
  type: TYPE_NORMAL
- en: You may have already realized that the branches of decision trees are almost
    identical to if-else statements of rule learning algorithms, and in fact, rules
    can be generated from trees. So, why bother with a separate group of rule learning
    algorithms? Read further to discover the nuances that differentiate the two approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Rule learners are generally applied to problems where the features are primarily
    or entirely nominal. They do well at identifying rare events, even if the rare
    event occurs only for a very specific interaction among feature values.
  prefs: []
  type: TYPE_NORMAL
- en: Separate and conquer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rule learning classification algorithms utilize a heuristic known as **separate
    and conquer**. The process involves identifying a rule that covers a subset of
    examples in the training data and then separating this partition from the remaining
    data. As rules are added, additional subsets of data are separated until the entire
    dataset has been covered and no more examples remain. Although separate and conquer
    is in many ways similar to the divide and conquer heuristic covered earlier, it
    differs in subtle ways that will become clear soon.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to imagine the rule learning process of separate and conquer is to
    imagine drilling down into the data by creating increasingly specific rules to
    identify class values. Suppose you were tasked with creating rules to identify
    whether or not an animal is a mammal. You could depict the set of all animals
    as a large space, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Venn diagram  Description automatically generated with medium confidence](img/B17290_05_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.8: A rule learning algorithm may help divide animals into groups of
    mammals and non-mammals'
  prefs: []
  type: TYPE_NORMAL
- en: 'A rule learner begins by using the available features to find homogeneous groups.
    For example, using a feature that indicates whether the species travels via land,
    sea, or air, the first rule might suggest that any land-based animals are mammals:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, venn diagram  Description automatically generated](img/B17290_05_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.9: A potential rule considers animals that travel on land to be mammals'
  prefs: []
  type: TYPE_NORMAL
- en: 'Do you notice any problems with this rule? If you’re an animal lover, you might
    have realized that frogs are amphibians, not mammals. Therefore, our rule needs
    to be a bit more specific. Let’s drill down further by suggesting that mammals
    must walk on land and have a tail:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, venn diagram  Description automatically generated](img/B17290_05_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.10: A more specific rule suggests that animals that walk on land and
    have tails are mammals'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the previous figure, the new rule results in a subset of animals
    that are entirely mammals. Thus, the subset of mammals can be separated from the
    other data and the frogs are returned to the pool of remaining animals—no pun
    intended!
  prefs: []
  type: TYPE_NORMAL
- en: 'An additional rule can be defined to separate out the bats, the only remaining
    mammal. A potential feature distinguishing bats from the remaining animals would
    be the presence of fur. Using a rule built around this feature, we have then correctly
    identified all the animals:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_05_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.11: A rule stating that animals with fur are mammals perfectly classifies
    the remaining animals'
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, since all training instances have been classified, the rule
    learning process would stop. We learned a total of three rules:'
  prefs: []
  type: TYPE_NORMAL
- en: Animals that walk on land and have tails are mammals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the animal does not have fur, it is not a mammal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Otherwise, the animal is a mammal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The previous example illustrates how rules gradually consume larger and larger
    segments of data to eventually classify all instances. As the rules seem to cover
    portions of the data, separate and conquer algorithms are also known as **covering
    algorithms**, and the resulting rules are called covering rules. In the next section,
    we will learn how covering rules are applied in practice by examining a simple
    rule learning algorithm. We will then examine a more complex rule learner and
    apply both algorithms to a real-world problem.
  prefs: []
  type: TYPE_NORMAL
- en: The 1R algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose a television game show has an animal hidden behind a large curtain.
    You are asked to guess whether it is a mammal and if correct, you win a large
    cash prize. You are not given any clues about the animal’s characteristics, but
    you know that a very small portion of the world’s animals are mammals. Consequently,
    you guess “non-mammal.” What do you think about your chances of winning?
  prefs: []
  type: TYPE_NORMAL
- en: Choosing this, of course, maximizes your odds of winning the prize, as it is
    the most likely outcome under the assumption the animal was chosen at random.
    Clearly, this game show is a bit ridiculous, but it demonstrates the simplest
    classifier, **ZeroR**, which is a rule learner that considers no features and
    literally learns no rules (hence the name). For every unlabeled example, regardless
    of the values of its features, it predicts the most common class. This algorithm
    has very little real-world utility, except that it provides a simple baseline
    for comparison to other, more sophisticated, rule learners.
  prefs: []
  type: TYPE_NORMAL
- en: The **1R algorithm** (also known as **One Rule** or **OneR**), improves over
    ZeroR by selecting a single rule. Although this may seem overly simplistic, it
    tends to perform better than you might expect. As demonstrated in empirical studies,
    the accuracy of this algorithm can approach that of much more sophisticated algorithms
    for many real-world tasks.
  prefs: []
  type: TYPE_NORMAL
- en: For an in-depth look at the surprising performance of 1R, see *Very Simple Classification
    Rules Perform Well on Most Commonly Used Datasets, Holte, RC, Machine Learning,
    1993, Vol. 11, pp. 63-91*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The strengths and weaknesses of the 1R algorithm are shown in the following
    table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strengths** | **Weaknesses** |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Generates a single, easy-to- understand, human-readable rule
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often performs surprisingly well
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can serve as a benchmark for more complex algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Uses only a single feature
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probably overly simplistic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: The way this algorithm works is simple. For each feature, 1R divides the data
    into groups with similar values of the feature. Then, for each segment, the algorithm
    predicts the majority class. The error rate for the rule based on each feature
    is calculated and the rule with the fewest errors is chosen as the one rule.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following tables show how this would work for the animal data we looked
    at earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B17290_05_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.12: The 1R algorithm chooses the single rule with the lowest misclassification
    rate'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the *Travels By* feature, the dataset was divided into three groups: *Air*,
    *Land*, and *Sea*. Animals in the *Air* and *Sea* groups were predicted to be
    non-mammal, while animals in the *Land* group were predicted to be mammals. This
    resulted in two errors: bats and frogs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The *Has Fur* feature divided animals into two groups. Those with fur were
    predicted to be mammals, while those without fur were not. Three errors were counted:
    pigs, elephants, and rhinos. As the *Travels By* feature resulted in fewer errors,
    the 1R algorithm would return the following:'
  prefs: []
  type: TYPE_NORMAL
- en: If the animal travels by air, it is not a mammal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the animal travels by land, it is a mammal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the animal travels by sea, it is not a mammal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The algorithm stops here, having found the single most important rule.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, this rule learning algorithm may be too basic for some tasks. Would
    you want a medical diagnosis system to consider only a single symptom, or an automated
    driving system to stop or accelerate your car based on only a single factor? For
    these types of tasks, a more sophisticated rule learner might be useful. We’ll
    learn about one in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: The RIPPER algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Early rule learning algorithms were plagued by a couple of problems. First,
    they were notorious for being slow, which made them ineffective for the increasing
    number of large datasets. Second, they were often prone to being inaccurate on
    noisy data.
  prefs: []
  type: TYPE_NORMAL
- en: A first step toward solving these problems was proposed in 1994 by Johannes
    Furnkranz and Gerhard Widmer. Their **incremental reduced error pruning** (**IREP**)
    **algorithm** uses a combination of pre-pruning and post-pruning methods that
    grow very complex rules and prune them before separating the instances from the
    full dataset. Although this strategy helped the performance of rule learners,
    decision trees often still performed better.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on IREP, see *Incremental Reduced Error Pruning, Furnkranz,
    J and Widmer, G, Proceedings of the 11th International Conference on Machine Learning,
    1994, pp. 70-77*.
  prefs: []
  type: TYPE_NORMAL
- en: Rule learners took another step forward in 1995 when William W. Cohen introduced
    the **repeated incremental pruning to produce error reduction** (**RIPPER**) **algorithm**,
    which improved upon IREP to generate rules that match or exceed the performance
    of decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: For more detail on RIPPER, see *Fast Effective Rule Induction, Cohen, WW, Proceedings
    of the 12th International Conference on Machine Learning, 1995, pp. 115-123*.
  prefs: []
  type: TYPE_NORMAL
- en: As outlined in the following table, the strengths and weaknesses of RIPPER are
    generally comparable to decision trees. The chief benefit is that they may result
    in a slightly more parsimonious model.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strengths** | **Weaknesses** |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Generates easy-to-understand, human-readable rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient on large and noisy datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally, produces a simpler model than a comparable decision tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: May result in rules that seem to defy common sense or expert knowledge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not ideal for working with numeric data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Might not perform as well as more complex models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Having evolved from several iterations of rule learning algorithms, the RIPPER
    algorithm is a patchwork of efficient heuristics for rule learning. Due to its
    complexity, a discussion of the implementation details is beyond the scope of
    this book. However, it can be understood in general terms as a three-step process:'
  prefs: []
  type: TYPE_NORMAL
- en: Grow
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prune
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optimize
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The growing phase uses the separate and conquer technique to greedily add conditions
    to a rule until it perfectly classifies a subset of data or runs out of attributes
    for splitting. Like decision trees, the information gain criterion is used to
    identify the next splitting attribute. When increasing a rule’s specificity no
    longer reduces entropy, the rule is immediately pruned. Steps one and two are
    repeated until reaching a stopping criterion, at which point the entire set of
    rules is optimized using a variety of heuristics.
  prefs: []
  type: TYPE_NORMAL
- en: The RIPPER algorithm can create much more complex rules than the 1R algorithm
    can, as it can consider more than one feature. This means that it can create rules
    with multiple antecedents such as “if an animal flies and has fur, then it is
    a mammal.” This improves the algorithm’s ability to model complex data, but just
    like decision trees, it means that the rules can quickly become difficult to comprehend.
  prefs: []
  type: TYPE_NORMAL
- en: The evolution of classification rule learners didn’t stop with RIPPER. New rule
    learning algorithms are being proposed rapidly. A survey of literature shows algorithms
    called IREP++, SLIPPER, TRIPPER, among many others.
  prefs: []
  type: TYPE_NORMAL
- en: Rules from decision trees
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Classification rules can also be obtained directly from decision trees. Beginning
    at a leaf node and following the branches back to the root, you obtain a series
    of decisions. These can be combined into a single rule. The following figure shows
    how rules could be constructed from the decision tree for predicting movie success:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, shape, polygon  Description automatically generated](img/B17290_05_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.13: Rules can be generated from decision trees by following paths
    from the root node to each leaf node'
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the paths from the root node down to each leaf, the rules would be:'
  prefs: []
  type: TYPE_NORMAL
- en: If the number of celebrities is low, then the movie will be a *Box Office Bust*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the number of celebrities is high and the budget is high, then the movie
    will be a *Mainstream Hit*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the number of celebrities is high and the budget is low, then the movie will
    be a *Critical Success*
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For reasons that will be made clear in the following section, the chief downside
    to using a decision tree to generate rules is that the resulting rules are often
    more complex than those learned by a rule learning algorithm. The divide and conquer
    strategy employed by decision trees biases the results differently to that of
    a rule learner. On the other hand, it is sometimes more computationally efficient
    to generate rules from trees.
  prefs: []
  type: TYPE_NORMAL
- en: The `C5.0()` function in the `C50` package will generate a model using classification
    rules if you specify `rules = TRUE` when training the model.
  prefs: []
  type: TYPE_NORMAL
- en: What makes trees and rules greedy?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Decision trees and rule learners are known as **greedy learners** because they
    use data on a first-come, first-served basis. Both the divide and conquer heuristic
    used by decision trees and the separate and conquer heuristic used by rule learners
    attempt to make partitions one at a time, finding the most homogeneous partition
    first, followed by the next best, and so on, until all examples have been classified.
  prefs: []
  type: TYPE_NORMAL
- en: The downside to the greedy approach is that greedy algorithms are not guaranteed
    to generate the optimal, most accurate, or smallest number of rules for a particular
    dataset. By taking the low-hanging fruit early, a greedy learner may quickly find
    a single rule that is accurate for one subset of data; however, in doing so, the
    learner may miss the opportunity to develop a more nuanced set of rules with better
    overall accuracy on the entire set of data. However, without using the greedy
    approach to rule learning, it is likely that for all but the smallest of datasets,
    rule learning would be computationally infeasible.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_05_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.14: Both decision trees and classification rule learners are greedy
    algorithms'
  prefs: []
  type: TYPE_NORMAL
- en: Though both trees and rules employ greedy learning heuristics, there are subtle
    differences in how they build rules. Perhaps the best way to distinguish them
    is to note that once divide and conquer splits on a feature, the partitions created
    by the split may not be re-conquered, only further subdivided. In this way, a
    tree is permanently limited by its history of past decisions. In contrast, once
    separate and conquer finds a rule, any examples not covered by all the rule’s
    conditions may be re-conquered.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this contrast, consider the previous case in which we built a
    rule learner to determine whether an animal was a mammal. The rule learner identified
    three rules that perfectly classify the example animals:'
  prefs: []
  type: TYPE_NORMAL
- en: Animals that walk on land and have tails are mammals (bears, cats, dogs, elephants,
    pigs, rabbits, rats, and rhinos)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the animal does not have fur, it is not a mammal (birds, eels, fish, frogs,
    insects, and sharks)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Otherwise, the animal is a mammal (bats)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In contrast, a decision tree built on the same data might have come up with
    four rules to achieve the same perfect classification:'
  prefs: []
  type: TYPE_NORMAL
- en: If an animal walks on land and has a tail, then it is a mammal (bears, cats,
    dogs, elephants, pigs, rabbits, rats, and rhinos)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If an animal walks on land and does not have a tail, then it is not a mammal
    (frogs)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the animal does not walk on land and has fur, then it is a mammal (bats)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the animal does not walk on land and does not have fur, then it is not a
    mammal (birds, insects, sharks, fish, and eels)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The different result across these two approaches has to do with what happens
    to the frogs after they are separated by the “walk on land” decision. Where the
    rule learner allows frogs to be re-conquered by the “do not have fur” decision,
    the decision tree cannot modify the existing partitions and therefore must place
    the frog into its own rule.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_05_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.15: The handling of frogs distinguishes the divide and conquer and
    separate and conquer heuristics. The latter approach allows the frogs to be re-conquered
    by later rules.'
  prefs: []
  type: TYPE_NORMAL
- en: On the one hand, because rule learners can reexamine cases that were considered
    but ultimately not covered as part of prior rules, rule learners often find a
    more parsimonious set of rules than those generated by decision trees. On the
    other hand, this reuse of data means that the computational cost of rule learners
    may be somewhat higher than for decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: Example – identifying poisonous mushrooms with rule learners
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each year, many people fall ill and some even die from ingesting poisonous wild
    mushrooms. Since many mushrooms are very similar to each other in appearance,
    occasionally, even experienced mushroom gatherers are poisoned.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the identification of harmful plants, such as poison oak or poison ivy,
    there are no clear rules like “leaves of three, let them be” for identifying whether
    a wild mushroom is poisonous or edible.
  prefs: []
  type: TYPE_NORMAL
- en: Complicating matters, many traditional rules such as “poisonous mushrooms are
    brightly colored” provide dangerous or misleading information. If simple, clear,
    and consistent rules were available for identifying poisonous mushrooms, they
    could save the lives of foragers.
  prefs: []
  type: TYPE_NORMAL
- en: As one of the strengths of rule learning algorithms is the fact that they generate
    easy-to-understand rules, they seem like an appropriate fit for this classification
    task. However, the rules will only be as useful as they are accurate.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – collecting data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To identify rules for distinguishing poisonous mushrooms, we will use the Mushroom
    dataset by Jeff Schlimmer of Carnegie Mellon University. The raw dataset is available
    freely from the UCI Machine Learning Repository ([http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)).
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset includes information on 8,124 mushroom samples from 23 species
    of gilled mushrooms listed in the *Audubon Society Field Guide to North American
    Mushrooms* (1981). In the field guide, each of the mushroom species is identified
    as “definitely edible,” “definitely poisonous,” or “likely poisonous, and not
    recommended to be eaten.” For the purposes of this dataset, the latter group was
    combined with the “definitely poisonous” group to make two classes: poisonous
    and non-poisonous. The data dictionary available on the UCI website describes
    the 22 features of the mushroom samples, including characteristics such as cap
    shape, cap color, odor, gill size and color, stalk shape, and habitat.'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter uses a slightly modified version of the mushroom data. If you plan
    on following along with the example, download the `mushrooms.csv` file from the
    Packt Publishing GitHub repository for this chapter and save it to your R working
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – exploring and preparing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We begin by using `read.csv()` to import the data for our analysis. Since all
    22 features and the target class are nominal, we will set `stringsAsFactors =
    TRUE` to take advantage of the automatic factor conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The output of the `str(mushrooms)` command notes that the data contains 8,124
    observations of 23 variables as the data dictionary had described. While most
    of the `str()` output is unremarkable, one feature is worth mentioning. Do you
    notice anything peculiar about the `veil_type` variable in the following line?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'If you found it to be strange that a factor has only one level, you are correct.
    The data dictionary lists two levels for this feature: `partial` and `universal`;
    however, all examples in our data are classified as `partial`. It is likely that
    this data element was somehow coded incorrectly. In any case, since the veil type
    does not vary across samples, it does not provide any useful information for prediction.
    We will drop this variable from our analysis using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: By assigning `NULL` to the `veil_type` vector, R eliminates the feature from
    the mushrooms data frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before going much further, we should take a quick look at the distribution
    of the mushroom `type` variable in our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: About 52 percent of the mushroom samples are edible, while 48 percent are poisonous.
  prefs: []
  type: TYPE_NORMAL
- en: For the purposes of this experiment, we will consider the 8,214 samples in the
    mushroom data to be an exhaustive set of all the possible wild mushrooms. This
    is an important assumption because it means that we do not need to hold some samples
    out of the training data for testing purposes. We are not trying to develop rules
    that cover unforeseen types of mushrooms; we are merely trying to find rules that
    accurately depict the complete set of known mushroom types. Therefore, we can
    build and test the model on the same data.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – training a model on the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we trained a hypothetical ZeroR classifier on this data, what would it predict?
    Since ZeroR ignores all of the features and simply predicts the target’s mode,
    in plain language, its rule would state that “all mushrooms are edible.” Obviously,
    this is not a very helpful classifier because it would leave a mushroom gatherer
    sick or dead for nearly half of the mushroom samples! Our rules will need to do
    much better than this benchmark in order to provide safe advice that can be published.
    At the same time, we need simple rules that are easy to remember.
  prefs: []
  type: TYPE_NORMAL
- en: Since simple rules can still be useful, let’s see how a very simple rule learner
    performs on the mushroom data. Toward this end, we will apply the 1R classifier,
    which will identify the single feature that is the most predictive of the target
    class and use this feature to construct a rule.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the 1R implementation found in the `OneR` package by Holger von
    Jouanne-Diedrich at the Aschaffenburg University of Applied Sciences. This is
    a relatively new package, which implements 1R in native R code for speed and ease
    of use. If you don’t already have this package, it can be installed using the
    `install.packages("OneR")` command and loaded by typing `library(OneR)`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B17290_05_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.16: 1R classification rule syntax'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like C5.0, the `OneR()` function uses the R formula syntax to specify the model
    to be trained. Using the formula `type ~ .` with `OneR()` allows our first rule
    learner to consider all possible features in the mushroom data when predicting
    the mushroom type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'To examine the rules it created, we can type the name of the classifier object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Examining the output, we see that the `odor` feature was selected for rule
    generation. The categories of `odor`, such as `almond`, `anise`, and so on, specify
    rules for whether the mushroom is likely to be `edible` or `poisonous`. For instance,
    if the mushroom smells `fishy`, `foul`, `musty`, `pungent`, `spicy`, or like `creosote`,
    the mushroom is likely to be poisonous. On the other hand, mushrooms with more
    pleasant smells, like `almond` and `anise`, and those with no smell at all, are
    predicted to be `edible`. For the purposes of a field guide for mushroom gathering,
    these rules could be summarized in a simple rule of thumb: “if the mushroom smells
    unappetizing, then it is likely to be poisonous.”'
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – evaluating model performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last line of the output notes that the rules correctly predict the edibility
    for 8,004 of the 8,124 mushroom samples, or nearly 99 percent. Anything short
    of perfection, however, runs the risk of poisoning someone if the model were to
    classify a poisonous mushroom as edible.
  prefs: []
  type: TYPE_NORMAL
- en: 'To determine whether this occurred, let’s examine a confusion matrix of the
    predicted versus actual values. This requires us to first generate the 1R model’s
    predictions, then compare the predictions to the actual values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Here, we can see where our rules went wrong. The table’s columns indicate the
    predicted edibility of the mushroom while the table’s rows divide the 4,208 actually
    edible mushrooms and the 3,916 actually poisonous mushrooms. Examining the table,
    we can see that although the 1R classifier did not classify any edible mushrooms
    as poisonous, it did classify 120 poisonous mushrooms as edible, which makes for
    an incredibly dangerous mistake!
  prefs: []
  type: TYPE_NORMAL
- en: Considering that the learner utilized only a single feature, it did reasonably
    well; if you avoid unappetizing smells when foraging for mushrooms, you will almost
    always avoid a trip to the hospital. That said, close does not cut it when lives
    are involved, not to mention the field guide publisher might not be happy about
    the prospect of a lawsuit when its readers fall ill. Let’s see if we can add a
    few more rules and develop an even better classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – improving model performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a more sophisticated rule learner, we will use `JRip()`, a Java-based implementation
    of the RIPPER algorithm. The `JRip()` function is included in the `RWeka` package,
    which gives R access to the machine learning algorithms in the Java-based Weka
    software application by Ian H. Witten and Eibe Frank.
  prefs: []
  type: TYPE_NORMAL
- en: Weka is a popular open source and full-featured graphical application for performing
    data mining and machine learning tasks—one of the earliest such tools. For more
    information on Weka, see [http://www.cs.waikato.ac.nz/~ml/weka/](http://www.cs.waikato.ac.nz/~ml/weka/).
  prefs: []
  type: TYPE_NORMAL
- en: The `RWeka` package depends on the `rJava` package, which itself requires the
    **Java development kit** (**JDK**) to be installed on the host computer before
    installation. This can be downloaded from `https://www.java.com/` and installed
    using the instructions specific to your platform. After installing Java, use the
    `install.packages("RWeka")` command to install `RWeka` and its dependencies, then
    load the `RWeka` package using the `library(RWeka)` command.
  prefs: []
  type: TYPE_NORMAL
- en: Java is a set of programming tools available at no cost, which allows the development
    and use of cross-platform applications such as Weka. Although it was once included
    by default with many computers, this is no longer true. Unfortunately, it can
    be tricky to install, especially on Apple computers. If you are having trouble,
    be sure you have the latest Java version. Additionally, on Microsoft Windows,
    you may need to set your environment variables like `JAVA_HOME` correctly, and
    check your `PATH` settings (search the web for details). On macOS or Linux computers,
    you may also try executing `R CMD javareconf` from a terminal window then install
    the R package `rJava` from source using the R command `install.packages("rJava",
    type = "source")`. If all else fails, you may try a free Posit Cloud account ([https://posit.cloud/](https://posit.cloud/)),
    which offers an RStudio environment in which Java is already installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'With `rJava` and `RWeka` installed, the process of training a `JRip()` model
    is very similar to training a `OneR()` model, as shown in the syntax box that
    follows. This is one of the pleasant benefits of the R formula interface: the
    syntax is consistent across algorithms, which makes it simple to compare a variety
    of models.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B17290_05_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.17: RIPPER classification rule syntax'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s train the `JRip()` rule learner as we did with `OneR()`, allowing it
    to find rules among all of the available features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'To examine the rules, type the name of the classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: The `JRip()` classifier learned a total of eight rules from the mushroom data.
  prefs: []
  type: TYPE_NORMAL
- en: 'An easy way to read these rules is to think of them as a list of if-else statements,
    similar to programming logic. The first three rules could be expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: If the odor is foul, then the mushroom type is poisonous
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the gill size is narrow and the gill color is buff, then the mushroom type
    is poisonous
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the gill size is narrow and the odor is pungent, then the mushroom type is
    poisonous
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, the eighth rule implies that any mushroom sample that was not covered
    by the preceding seven rules is edible. Following the example of our programming
    logic, this can be read as:'
  prefs: []
  type: TYPE_NORMAL
- en: Else, the mushroom is edible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The numbers next to each rule indicate the number of instances covered by the
    rule and a count of misclassified instances. Notably, there were no misclassified
    mushroom samples using these eight rules. As a result, the number of instances
    covered by the last rule is exactly equal to the number of edible mushrooms in
    the data (N = 4,208).
  prefs: []
  type: TYPE_NORMAL
- en: The following figure provides a rough illustration of how the rules are applied
    to the mushroom data. If you imagine the large oval as containing all mushroom
    species, the rule learner identifies features, or sets of features, that separate
    homogeneous segments from the larger group. First, the algorithm found a large
    group of poisonous mushrooms uniquely distinguished by their foul odor. Next,
    it found smaller and more specific groups of poisonous mushrooms. By identifying
    covering rules for each of the varieties of poisonous mushrooms, all remaining
    mushrooms were edible.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to Mother Nature, each variety of mushrooms was unique enough that the
    classifier was able to achieve 100 percent accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_05_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.18: A sophisticated rule learning algorithm identified rules to perfectly
    cover all types of poisonous mushrooms'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covered two classification methods that use so-called “greedy”
    algorithms to partition the data according to feature values. Decision trees use
    a divide and conquer strategy to create flowchart-like structures, while rule
    learners separate and conquer data to identify logical if-else rules. Both methods
    produce models that can be interpreted without a statistical background.
  prefs: []
  type: TYPE_NORMAL
- en: One popular and highly configurable decision tree algorithm is C5.0\. We used
    the C5.0 algorithm to create a tree to predict whether a loan applicant will default.
    Using options for boosting and cost-sensitive errors, we were able to improve
    our accuracy and avoid risky loans that could cost the bank more money.
  prefs: []
  type: TYPE_NORMAL
- en: We also used two rule learners, 1R and RIPPER, to develop rules for identifying
    poisonous mushrooms. The 1R algorithm used a single feature to achieve 99 percent
    accuracy in identifying potentially fatal mushroom samples. On the other hand,
    the set of eight rules generated by the more sophisticated RIPPER algorithm correctly
    identified the edibility of every mushroom.
  prefs: []
  type: TYPE_NORMAL
- en: This merely scratches the surface of how trees and rules can be used. The next
    chapter, *Chapter 6*, *Forecasting Numeric Data – Regression Methods*, describes
    techniques known as regression trees and model trees, which use decision trees
    for numeric prediction rather than classification. In *Chapter 8*, *Finding Patterns
    – Market Basket Analysis Using Association Rules*, we will see how association
    rules—a close relative of classification rules—can be used to identify groups
    of items in transactional data. Lastly, in *Chapter 14*, *Building Better Learners*,
    we will discover how the performance of decision trees can be improved by grouping
    them together in a model known as a random forest, in addition to other advanced
    modeling techniques that rely on decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 4000 people at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/r](https://packt.link/r)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/r.jpg)'
  prefs: []
  type: TYPE_IMG
