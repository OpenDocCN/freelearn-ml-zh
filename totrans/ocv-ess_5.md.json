["```py\n#include \"opencv2/core/core.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include \"opencv2/imgproc/imgproc.hpp\"\n#include \"opencv2/features2d/features2d.hpp\"\n#include <iostream>\n\nusing namespace std;\nusing namespace cv;\n\nint main(int argc, char *argv[])\n{\n    //Load original image and convert to gray scale\n    Mat in_img = imread(\"book.png\");\n    cvtColor( in_img, in_img, COLOR_BGR2GRAY );\n\n    //Create a keypoint vectors\n    vector<KeyPoint> keypoints1,keypoints2;\n    //FAST detector with threshold value of 80 and 100\n    FastFeatureDetector detector1(80);\n    FastFeatureDetector detector2(100);\n\n    //Compute keypoints in in_img with detector1 and detector2\n    detector1.detect(in_img, keypoints1);\n    detector2.detect(in_img, keypoints2);\n\n    Mat out_img1, out_img2;\n    //Draw keypoints1 and keypoints2\n    drawKeypoints(in_img,keypoints1,out_img1,Scalar::all(-1),0);\n    drawKeypoints(in_img,keypoints2,out_img2,Scalar::all(-1),0);\n\n    //Show keypoints detected by detector1 and detector2\n    imshow( \"out_img1\", out_img1 );\n    imshow( \"out_img2\", out_img2 );\n    waitKey(0);\n    return 0;\n}\n```", "```py\nFastFeatureDetector detector1(80);\nFastFeatureDetector detector2(100);\n```", "```py\n//â€¦ (omitted for simplicity)\n#include \"opencv2/nonfree/nonfree.hpp\"\n\nint main(int argc, char *argv[])\n{\n    //Load image and convert to gray scale (omitted for\n    //simplicity)\n\n    //Create a keypoint vectors\n    vector<KeyPoint> keypoints1,keypoints2;\n\n    //SURF detector1 and detector2 with 2 and 5 Gaussian pyramid\n    //octaves respectively\n    SurfFeatureDetector detector1(3500, 2, 2, false, false);\n    SurfFeatureDetector detector2(3500, 5, 2, false, false);\n\n    //Compute keypoints in in_img with detector1 and detector2\n    detector1.detect(in_img, keypoints1);\n    detector2.detect(in_img, keypoints2);\n    Mat out_img1, out_img2;\n\n    //Draw keypoints1 and keypoints2\n    drawKeypoints(in_img,keypoints1,out_img1,Scalar::all(-1), DrawMatchesFlags::DRAW_RICH_KEYPOINTS);\n    drawKeypoints(in_img,keypoints2,out_img2,Scalar::all(-1), DrawMatchesFlags::DRAW_RICH_KEYPOINTS);\n\n//Show the 2 final images (omitted for simplicity)\nreturn 0;\n}\n```", "```py\nint main(int argc, char *argv[])\n{\n    //Load image and convert to gray scale (omitted for\n    //simplicity)\n\n    //Create a keypoint vectors\n    vector<KeyPoint> keypoints1,keypoints2;\n\n    //ORB detector with FAST (detector1) and HARRIS (detector2)\n    //score to rank the features\n    OrbFeatureDetector detector1(300, 1.1f, 2, 31,0, 2, ORB::FAST_SCORE, 31);\n    OrbFeatureDetector detector2(300, 1.1f, 2, 31,0, 2, ORB::HARRIS_SCORE, 31);\n\n    //Compute keypoints in in_img with detector1 and detector2\n    detector1.detect(in_img, keypoints1);\n    detector2.detect(in_img, keypoints2);\n\n    Mat out_img1, out_img2;\n    //Draw keypoints1 and keypoints2\n    drawKeypoints(in_img,keypoints1,out_img1,Scalar::all(-1), DrawMatchesFlags::DEFAULT);\n    drawKeypoints(in_img,keypoints2,out_img2,Scalar::all(-1), DrawMatchesFlags::DEFAULT);\n\n    //Show the 2 final images (omitted for simplicity)\n    return 0;\n}\n```", "```py\nOrbFeatureDetector detector1(300, 1.1f, 2, 31,0, 2, ORB::FAST_SCORE, 31);\nOrbFeatureDetector detector2(300, 1.1f, 2, 31,0, 2, ORB::HARRIS_SCORE, 31);\n```", "```py\nint main(int argc, char *argv[])\n{\n    //Load image and convert to gray scale (omitted for\n    //simplicity)\n\n    //Create a keypoint vectors\n    vector<KeyPoint> keypoints1,keypoints2;\n\n    //Create KAZE and AKAZE detectors\n    KAZE detector1(true,true);\n    AKAZE detector2(cv::AKAZE::DESCRIPTOR_KAZE_UPRIGHT,0,3);\n\n    //Compute keypoints in in_img with detector1 and detector2\n    detector1.detect(in_img, keypoints1);\n    detector2.detect(in_img, keypoints2,cv::Mat());\n\n    Mat out_img1, out_img2;\n    //Draw keypoints1 and keypoints2\n    drawKeypoints(in_img,keypoints1,out_img1,Scalar::all(-1), DrawMatchesFlags::DRAW_RICH_KEYPOINTS);\n    drawKeypoints(in_img,keypoints2,out_img2,Scalar::all(-1), DrawMatchesFlags::DRAW_RICH_KEYPOINTS);\n\n    //Show the 2 final images (omitted for simplicity)\n    return 0;\n}\n```", "```py\nenum DESCRIPTOR_TYPE {DESCRIPTOR_KAZE_UPRIGHT = 2, DESCRIPTOR_KAZE = 3, DESCRIPTOR_MLDB_UPRIGHT = 4, DESCRIPTOR_MLDB = 5 };\n```", "```py\n#include <iostream>\n#include \"opencv2/core/core.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include \"opencv2/nonfree/nonfree.hpp\"\n\nusing namespace std;\nusing namespace cv;\n\nint main( int argc, char** argv )\n{\n    Mat img_orig = imread( argv[1],IMREAD_GRAYSCALE);\n    Mat img_fragment = imread( argv[2], IMREAD_GRAYSCALE);\n    if(img_orig.empty() || img_fragment.empty())\n    {\n        cerr << \" Failed to load images.\" << endl;\n        return -1;\n    }\n\n     //Step 1: Detect keypoints using SURF Detector\n     vector<KeyPoint> keypoints1, keypoints2;\n     Ptr<FeatureDetector> detector = FeatureDetector::create(\"SURF\");\n\n     detector->detect(img_orig, keypoints1);\n     detector->detect(img_fragment, keypoints2);\n\n     //Step 2: Compute descriptors using SURF Extractor\n     Ptr<DescriptorExtractor> extractor = DescriptorExtractor::create(\"SURF\");\n     Mat descriptors1, descriptors2;\n     extractor->compute(img_orig, keypoints1, descriptors1);\n     extractor->compute(img_fragment, keypoints2, descriptors2);\n\n     //Step 3: Match descriptors using a FlannBased Matcher\n     Ptr<DescriptorMatcher> matcher = DescriptorMatcher::create(\"FlannBased\");\n     vector<DMatch> matches12;\n     vector<DMatch> matches21;\n     vector<DMatch> good_matches;\n\n matcher->match(descriptors1, descriptors2, matches12);\n matcher->match(descriptors2, descriptors1, matches21);\n\n     //Step 4: Filter results using cross-checking\n     for( size_t i = 0; i < matches12.size(); i++ )\n     {\n         DMatch forward = matches12[i];\n         DMatch backward = matches21[forward.trainIdx];\n         if( backward.trainIdx == forward.queryIdx )\n             good_matches.push_back( forward );\n     }\n\n     //Draw the results\n     Mat img_result_matches;\n     drawMatches(img_orig, keypoints1, img_fragment, keypoints2, good_matches, img_result_matches);\n     imshow(\"Matching SURF Descriptors\", img_result_matches);\n     waitKey(0);\n\n     return 0;\n }\n```", "```py\n    matcher->match(descriptors1, descriptors2, matches12)\n    ```", "```py\n#include <iostream>\n#include \"opencv2/core/core.hpp\"\n#include \"opencv2/features2d/features2d.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n  Mat img_orig = imread( argv[1], IMREAD_GRAYSCALE );\n  Mat img_cam = imread( argv[2], IMREAD_GRAYSCALE );\n\n  if( !img_orig.data || !img_cam.data )\n  {\n    cerr << \" Failed to load images.\" << endl;\n    return -1;\n  }\n\n  //Step 1: Detect the keypoints using AKAZE Detector\n Ptr<FeatureDetector> detector = FeatureDetector::create(\"AKAZE\");\n  std::vector<KeyPoint> keypoints1, keypoints2;\n\n  detector->detect( img_orig, keypoints1 );\n  detector->detect( img_cam, keypoints2 );\n\n  //Step 2: Compute descriptors using AKAZE Extractor\n  Ptr<DescriptorExtractor> extractor = DescriptorExtractor::create(\"AKAZE\");\n  Mat descriptors1, descriptors2;\n\n  extractor->compute( img_orig, keypoints1, descriptors1 );\n  extractor->compute( img_cam, keypoints2, descriptors2 );\n\n  //Step 3: Match descriptors using a BruteForce-Hamming Matcher\n Ptr<DescriptorMatcher> matcher = DescriptorMatcher::create(\"BruteForce-Hamming\");\n  vector<vector<DMatch> > matches;\n  vector<DMatch> good_matches;\n\n matcher.knnMatch(descriptors1, descriptors2, matches, 2);\n\n  //Step 4: Filter results using ratio-test\n  float ratioT = 0.6;\n  for(int i = 0; i < (int) matches.size(); i++)\n  {\n      if((matches[i][0].distance < ratioT*(matches[i][1].distance)) && ((int) matches[i].size()<=2 && (int) matches[i].size()>0))\n      {\n          good_matches.push_back(matches[i][0]);\n      }\n  }\n\n  //Draw the results\n  Mat img_result_matches;\n  drawMatches(img_orig, keypoints1, img_cam, keypoints2, good_matches, img_result_matches);\n  imshow(\"Matching AKAZE Descriptors\", img_result_matches);\n\n  waitKey(0);\n\n  return 0;\n}\n```"]