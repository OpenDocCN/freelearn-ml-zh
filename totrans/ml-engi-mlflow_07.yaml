- en: '*Chapter 5*: Managing Models with MLflow'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn about different features for model management
    in MLflow. You will learn about the model life cycle in MLflow and we will explain
    how to integrate it with your regular development workflow and how to create custom
    models not available in MLflow. A model life cycle will be introduced alongside
    the Model Registry feature of MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will look at the following sections in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding models in MLflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring model flavors in MLflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing models and signature schemas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing the life cycle with a model registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From a workbench perspective, we would like to use MLflow to manage our models
    and implement a clear model life cycle. The addition of managed model features
    to our benchmark leveraging MLflow will step up the quality and operations of
    our **machine learning engineering** solution.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The latest version of Docker installed on your machine. If you don’t already
    have it installed, please follow the instructions at [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of `docker-compose` installed. Please follow the instructions
    at https://docs.docker.com/compose/install/.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to Git in the command line and installed as described at [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a Bash terminal (Linux or Windows).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a browser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3.5+ installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of your machine learning workbench installed locally, described
    in [*Chapter 3*](B16783_03_Final_SB_epub.xhtml#_idTextAnchor066), *Your Data Science
    Workbench*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding models in MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On the MLflow platform, you have two main components available to manage models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Models**: This module manages the format, library, and standards enforcement
    module on the platform. It supports a variety of the most used machine learning
    models: sklearn, XGBoost, TensorFlow, H20, fastai, and others. It has features
    to manage output and input schemas of models and to facilitate deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model Registry**: This module handles a model life cycle, from registering
    and tagging model metadata so it can be retrieved by relevant systems. It supports
    models in different states, for instance, live development, testing, and production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An MLflow model is at its core a packaging format for models. The main goal
    of MLflow model packaging is to decouple the model type from the environment that
    executes the model. A good analogy of an MLflow model is that it’s a bit like
    a **Dockerfile** for a model, where you describe metadata of the model, and deployment
    tools upstream are able to interact with the model based on the specification.
  prefs: []
  type: TYPE_NORMAL
- en: 'As can be seen in the diagram in *Figure 5.1*, on one side you have your model
    library, for instance, TensorFlow or sklearn. At the core of MLflow, you have
    the MLflow model format, which is able to be served in a multitude of flavors
    (model formats) to cater to different types of inference tools on-premises and
    in the cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image0011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – MLflow models diagram
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5.1* was extracted from the URL [https://www.infoq.com/presentations/mlflow-databricks/#](https://www.infoq.com/presentations/mlflow-databricks/#).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The central piece of the definition of MLflow models is the MLflow model file,
    as depicted in the next screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image0022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – An example of an MLmodel file
  prefs: []
  type: TYPE_NORMAL
- en: 'An MLmodel example can be seen in *Figure 5.2* and provides the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**run_id**: This is a reference to the run of the model of the project that
    allowed the creation of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**time_created**: The timestamp of when the model was created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pyfunc` model provided by MLflow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**signature**: This is the component of the MLmodel that defines the model
    signature and allows you to, in some way, type the inference process of your model.
    It allows the validation of input data that needs to match the signature of the
    model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `pyfunc`. This function is supported in any environment that supports Python,
    providing flexibility to the deployer of the model on how best to run the model
    once logged in MLflow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the GitHub repo of the project, please go to the `Gradflow` folder and start
    the environment in this chapter by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can run all the cells including the model cell depicted in *Figure 5.3*:![](img/image0032.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 5.3 – An example of an MLmodel file
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The model in *Figure 5.3* should be very similar to the one used in [*Chapter
    4*](B16783_04_Final_SB_epub.xhtml#_idTextAnchor081)*, Experiment Management in
    MLflow*. Using `mlflow.start_run`, you can start logging your model in MLflow
    and use the innate capabilities of the platform to capture relevant details of
    the model being developed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can now explore the `MLmodel` file in MLflow:![](img/image0042.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 5.4 – An example of an MLmodel file
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Explore the `conda` file in MLflow:![](img/image0052.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 5.5 – An example of an MLmodel file
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Load the model as `MLflow Pyfunc` for prediction:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Alternatively, the model can be loaded in the native H5 Keras format and loaded
    to a completely different application, as shown in *Figure 5.4*, by using the
    `/data/model/model.h5 file`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After introducing in this section the concept of models in MLflow, we will next
    delve a bit deeper into the different types of models in MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring model flavors in MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Model flavors in MLflow are basically the different models of different libraries
    supported by MLflow. This functionality allows MLflow to handle the model types
    with native libraries of each specific model and support some of the native functionalities
    of the models. The following list presents a selection of representative models
    to describe and illustrate the support available in MLflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '`mlflow.tensorflow`: TensorFlow is by far one of the most used libraries, particularly
    geared toward deep learning. MLflow integrates natively with the model format
    and the monitoring abilities by saving logs in TensorBoard formats. Auto-logging
    is supported in MLflow for TensorFlow models. The Keras model in *Figure 5.5*
    is a good example of TensorFlow support in MLflow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mlflow.h2o`: H2O is a complete machine learning platform geared toward the
    automation of models and with some overlapping features with MLflow. MLflow provides
    the ability to load (`load_model`) and log models (`log_model`) in H2O native
    format, allowing interoperability between the tools. Unfortunately, as of the
    current MLflow version, you can’t use auto-logging on `h2o` models:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`mlflow.spark`: MLflow integrates with the Apache Spark library natively through
    two main interfaces: Spark MLlib for machine learning and the MLeap platform (https://combust.github.io/mleap-docs/).
    Mleap is more of a deployment platform while MLlib is more of a library that you
    can add to your projects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A very comprehensive list of flavors/formats is supported by MLflow and their
    usage and support can be read about here: [https://www.mlflow.org/docs/latest/python_api/index.html.](https://www.mlflow.org/docs/latest/python_api/index.html'
  prefs: []
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: Custom models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can delve into the next excerpt of code and the custom `RandomPredictor`
    model. As long as you provide a class with an interface with the `fit` and `predict
    methods`, you can have your own custom MLflow model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding `class`, we basically use a random probability, and it can
    be used as a sample model in a system where you want to make sure that your model
    is better than a random model.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we introduced different types of model flavors and the creation
    of a custom mode. We will next look at some of the schemas and signature features
    of MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: Managing model signatures and schemas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An important feature of MLflow is to provide an abstraction for input and output
    schemas of models and the ability to validate model data during prediction and
    training.
  prefs: []
  type: TYPE_NORMAL
- en: 'MLflow throws an error if your input does not match the schema and signature
    of the model during prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will next look at a code listing of a simple model of digit classification
    (the details of the dataset are available here: [https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits)).
    The following code flattens the image into a pandas DataFrame and fits a model
    to the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We’ll look at the previous code listing, which you can run in a new notebook
    and navigate through the MLflow UI to investigate in more depth the MLmodel generated
    in *Figure 5.6*:![](img/image0062.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 5.6 – Sample of an MLmodel file
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The MLmodel file contains the signature in JSON of input and output files.
    For some of the flavors autologged, we will not be able to infer the signature
    automatically so you can provide the signature inline when logging the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the previous code block, the signature of the model is provided by the `infer_signature`
    method. As the model is logged through `log_model`, the signature is provided.
    One important advantage of the signatures being logged alongside the model is
    that they can serve as documentation and metadata for the model. Third-party systems
    can consume the metadata and interact with the models by validating the data or
    generating documentation for the models.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we introduced the model schema and signature features of MLflow
    models. We will now move on to the other critical module in this space, namely
    the Model Registry.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Model Registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**MLflow Model Registry** is a module in MLflow that comprises a centralized
    store for Models, an API allowing the management of the life cycle of a model
    in a registry.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical workflow for a machine learning model developer is to acquire training
    data; clean, process, and train models; and from there on, hand over to a system
    or person that deploys the models. In very small settings, where you have one
    person responsible for this function, it is quite trivial. Challenges and friction
    start to arise when the variety and quantity of models in a team start to scale.
    A selection of common friction points raised by machine learning developers with
    regards to storing and retrieving models follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Collaboration in larger teams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phasing out stale models in production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The provenance of a model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A lack of documentation for models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying the correct version of a model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to integrate the model with deployment tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main idea behind **MLflow Model Registry** is to provide a central store
    model in an organization where all the relevant models are stored and can be accessed
    by humans and systems. A good analogy would be a Git repository for models with
    associated relevant metadata and centralized state management for models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the MLflow UI (available in your local environment), you should click on
    the tab on the right side of **Experiments** with the label **Models** as indicated
    by the arrow:'
  prefs: []
  type: TYPE_NORMAL
- en: Through this module, you are able to list all the models registered, search
    by name, or create by name. For each model, you can see the label of the latest
    version and the specific versions that are in staging or production:![](img/image0072.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 5.7 – Model Registry UI
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A new model can be created by clicking on the **Create Model** button where
    a relevant name can be given to a specific model as shown in *Figure 5.8*:![](img/image0082.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 5.8 – Model Registry UI – Create Model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can also create models in MLflow by running into the **Experiments** model
    and choosing one of your models, and from there, specifically deciding to register
    the model. You will have to associate your run with an existing model or create
    a new model name to associate with this particular type of model thereafter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/image0092.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – Model Tracking UI – Create New Model
  prefs: []
  type: TYPE_NORMAL
- en: When you add a new model, MLflow automatically increases the version and labels
    this version as the latest version and everyone in the organization can query
    the registry for the latest version of a model for a given problem.
  prefs: []
  type: TYPE_NORMAL
- en: Adding your best model to Model Registry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Everything that can be done in the UI in MLflow can also be implemented through
    the MLflow API.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can quickly go back to our use case of stock market prediction and add our
    first baseline model to Model Registry and run the `hyperopt_optimization_logistic_regression_mlflow.ipynb
    notebook`, available in the repo of this chapter, and sort the runs according
    to the F1 score metrics in descending order as represented by *Figure 5.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image0101.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – Selecting the best model
  prefs: []
  type: TYPE_NORMAL
- en: 'From there, you should be able to register the best model with the name `BTC
    StockPrediction` as represented in *Figure 5.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image0111.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – Naming your model
  prefs: []
  type: TYPE_NORMAL
- en: 'By returning to the models module, you will notice, as represented in *Figure
    5.12*, your newly created model under **Version 1**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image0121.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – Registered Models
  prefs: []
  type: TYPE_NORMAL
- en: Having introduced the functionalities of Model Registry, in the next section,
    we will describe a model development life cycle to help organize the management
    of your models.
  prefs: []
  type: TYPE_NORMAL
- en: Managing the model development life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Managing the model life cycle is quite important when working in a team of
    more than one model developer. It’s quite usual for multiple model developers
    to try different models within the same project, and having a reviewer decide
    on the model that ends up going to production is quite important:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image0131.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – Example of a model development life cycle
  prefs: []
  type: TYPE_NORMAL
- en: 'A model in its life cycle can undergo the following stages if using a life
    cycle similar to the one represented in *Figure 5.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Development**: The state where the model developer is still exploring and
    trying out different approaches and is still trying to find a reasonable solution
    to their machine learning problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Staging**: The state where the model can be tested automatically with production-type
    traffic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Production**: When the model is ready to handle real-life production traffic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Archive**: When the model no longer serves the business purpose that it was
    initially developed for, it will be archived and its metadata stored for future
    reference or compliance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For instance, a reviewer or supervisor, as represented in *Figure 5.14*, can
    move a model from the **Development** state to **Staging** for further deployment
    in a test environment and the model can be transitioned into production if approved
    by reviewers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image0141.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 – Example of a model development life cycle
  prefs: []
  type: TYPE_NORMAL
- en: 'When transitioning from a state in MLflow, you have the option to send the
    model in an existing state to the next state:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image0151.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.15 – Stage Transition in MLflow
  prefs: []
  type: TYPE_NORMAL
- en: The transitions from the **Staging** to **Production** stages in a mature environment
    are meant to be done automatically, as we will demonstrate in the upcoming chapters
    of the book.
  prefs: []
  type: TYPE_NORMAL
- en: With this section, we have concluded the description of the features related
    to models in MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we first introduced the Models module in MLflow and the support
    for different algorithms, from tree-based to linear to neural. We were exposed
    to the support in terms of the logging and metrics of models and the creation
    of custom metrics.
  prefs: []
  type: TYPE_NORMAL
- en: In the last two sections, we introduced the Model Registry model and how to
    use it to implement a model life cycle to manage our models.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapters and section of the book, we will focus on applying the
    concepts learned so far in terms of real-life systems and we will architect a
    machine learning system for production environments.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to solidify your knowledge and dive deeper into the concepts introduced
    in this chapter, you should look at the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.mlflow.org/docs/latest/models.html](https://www.mlflow.org/docs/latest/models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.mlflow.org/docs/latest/model-registry.html](https://www.mlflow.org/docs/latest/model-registry.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.slideshare.net/Hadoop_Summit/introducing-mlflow-an-open-source-platform-for-the-machine-learning-life
    cycle-for-onprem-or-in-the-cloud](https://www.slideshare.net/Hadoop_Summit/introducing-mlflow-an-open-source-platform-for-the-machine-learning-lifecycle-for-onprem-or-in-the-cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
