- en: Machine Learning for Recommender Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统中的机器学习
- en: I hope that you are now excited about the amazing possibilities offered by the
    recommender systems that we've built. The techniques we've learned will provide
    you with a tremendous amount of data-taming prowess and practical abilities that
    you can already apply in your projects.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你现在对我们所构建的推荐系统所提供的惊人可能性感到兴奋。我们所学的技术将为你提供大量的数据驯服能力和实际应用能力，你可以在你的项目中立即应用。
- en: However, there is more to recommendation systems than that. Due to their large-scale
    applications in recent years, as an efficient solution to the information overload
    caused by the abundance of offerings on online platforms, recommenders have received
    a lot of attention, with new algorithms being developed at a rapid pace. In fact,
    all the algorithms that we studied in the previous chapter are part of a single
    category, called **memory-based** **recommenders**. Besides these, there's another
    very important class or recommender, which is known as** model-based**.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，推荐系统不仅仅是这样。由于近年来在大型应用中的广泛应用，作为解决在线平台上大量提供所引起的信息过载的有效解决方案，推荐系统受到了很多关注，新算法的开发速度也在加快。事实上，我们在上一章研究的所有算法都属于一个单一类别，称为**基于记忆**的**推荐系统**。除此之外，还有一个非常重要的推荐系统类别，被称为**基于模型**的。
- en: 'In this chapter, we''ll learn about them. We will discuss the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习这些内容。我们将讨论以下主题：
- en: Memory-based versus model-based recommendation systems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于记忆与基于模型的推荐系统比较
- en: Data processing for training a model-based recommender
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为基于模型的推荐系统进行数据处理的训练
- en: Building a model-based recommender
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建基于模型的推荐系统
- en: Hybrid recommendation systems
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合推荐系统
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The Julia package ecosystem is under continuous development and new package
    versions are released on a daily basis. Most of the times this is great news,
    as new releases bring new features and bug fixes. However, since many of the packages
    are still in beta (version 0.x), any new release can introduce breaking changes.
    As a result, the code presented in the book can stop working. In order to ensure
    that your code will produce the same results as described in the book, it is recommended
    to use the same package versions. Here are the external packages used in this
    chapter and their specific versions:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Julia包生态系统正在持续发展中，并且每天都有新的包版本发布。大多数时候这是一个好消息，因为新版本带来了新功能和错误修复。然而，由于许多包仍在测试版（版本0.x）中，任何新版本都可能引入破坏性更改。因此，书中展示的代码可能无法正常工作。为了确保你的代码将产生与书中描述相同的结果，建议使用相同的包版本。以下是本章使用的外部包及其特定版本：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In order to install a specific version of a package you need to run:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安装特定版本的包，你需要运行：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For example:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Alternatively you can install all the used packages by downloading the `Project.toml`
    file provided with the chapter and using `pkg>` instantiate as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你也可以通过下载本章提供的`Project.toml`文件并使用`pkg>`实例化来安装所有使用的包：
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Comparing the memory-based versus model-based recommenders
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较基于记忆与基于模型的推荐系统
- en: It is important to understand the strengths and weaknesses of both memory-based
    and model-based recommenders so that we can make the right choice according to
    the available data and the business requirements. As we saw in the previous chapter,
    we can classify recommender systems according to the data they are using and the
    algorithms that are employed.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 理解基于记忆和基于模型的推荐系统的优缺点非常重要，这样我们才能根据可用的数据和业务需求做出正确的选择。正如我们在上一章所看到的，我们可以根据它们使用的数据和采用的算法来对推荐系统进行分类。
- en: First, we can talk about non-personalized versus personalized recommenders.
    Non-personalized recommenders do not take into account user preferences, but that
    doesn't make them less useful. They are successfully employed when the relevant
    data is missing, for example, for a user that is new to the system or just not
    logged in. Such recommendations can include the best apps of the week on the Apple
    App Store, trending movies on Netflix, songs of the day on Spotify, NY Times bestsellers,
    Billboard Top 10, and so on.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以谈谈非个性化与个性化推荐系统。非个性化推荐系统不考虑用户偏好，但这并不意味着它们不那么有用。当相关数据缺失时，例如，对于新加入系统的用户或未登录的用户，它们可以成功应用。这类推荐可能包括苹果应用商店每周最佳应用、Netflix的热门电影、Spotify的每日歌曲、纽约时报的畅销书、公告牌前十名等。
- en: Moving on to personalized recommender systems, these can be further split into
    content-based and collaborative system. A content-based system makes recommendations
    by matching an item, specifications. A famous example of this category is Pandora
    and its Music Genome Project. The Music Genome Project, which powers Pandora,
    is the most comprehensive analysis of music ever undertaken. They worked with
    trained musicologists who listened to music across all genres and decades, studying
    and collecting musical details on every track—450 musical attributes altogether.
    Pandora makes recommendations by picking other songs from its catalog that closely
    match the features (*features* is data-science language for attributes, properties,
    or tags) of the tracks that the user previously liked.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是个性化推荐系统，这些系统可以进一步分为基于内容和协同系统。基于内容的系统通过匹配项目规格来做出推荐。这个类别的著名例子是潘多拉及其音乐基因组项目。潘多拉背后的音乐基因组项目是对音乐进行的最为全面的分析。他们与训练有素的音乐学家合作，跨越所有流派和年代聆听音乐，研究并收集每首歌曲的音乐细节——总共450个音乐属性。潘多拉通过选择其目录中与用户之前喜欢的曲目特征紧密匹配的其他歌曲来进行推荐。（*特征*是数据科学语言中对属性、特性或标签的称呼。）
- en: As for collaborative filtering, the idea behind it is that we can identify a
    metric that correctly reflects a user's tastes and then exploit it in combination
    with a dataset of other users, whose preferences were already collected. The underlying
    supposition is that if we have a pool of users that enjoy many of the same things,
    we can recommend to one of them some items from another's user list, which were
    not yet discovered by the targeted user. Any item in the list of options that
    is not part of the targeted user's list can readily be offered as a recommendation
    because similar preferences will lead to other similar choices.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 关于协同过滤，其背后的理念是我们可以找到一个正确反映用户喜好的指标，然后结合其他用户的偏好数据集来利用它。这个基本的假设是，如果我们有一个用户群体，他们喜欢许多相同的事物，我们可以向其中的一位推荐一些来自另一位用户列表中的项目，这些项目尚未被目标用户发现。任何不在目标用户列表中的选项都可以轻易地作为推荐提供，因为相似的偏好会导致其他相似的选择。
- en: This specific type of collaborative filtering was named user-based since the
    primary focus of the algorithm is the similarity between the target user and other
    users.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种特定的协同过滤类型被称为基于用户的协同过滤，因为算法的主要焦点是目标用户与其他用户之间的相似性。
- en: Another variation of the collaborative algorithm is **item-based filtering**.
    The main difference between this and user-based filtering is that the focus is
    on similar items. Which approach is the best depends on the specific use case—item-based
    recommendations are more efficient when the product catalog is considerably smaller
    and changes less often than the number of users and their preferences.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 协同算法的另一种变体是**基于项目的过滤**。这种过滤与基于用户的过滤之间的主要区别在于，重点是相似的项目。哪种方法最好取决于具体的用例——当产品目录相对较小且变化不如用户及其偏好频繁时，基于项目的推荐更有效率。
- en: The last of the commonly accepted typologies divides the recommender systems
    into memory-based and model-based. *Memory-based* refers to the fact that the
    system requires the whole dataset to be loaded into working memory (the RAM).
    The algorithms rely on mapping to and from memory to consequently calculate the
    similarity between two users or items, and produce a prediction for the user by
    taking the weighted average of all the ratings. A few ways of computing the correlation
    can be used, such as *Pearson's r*. There are certain advantages to this approach,
    like the simplicity of the implementation, the easy facilitation of new data,
    or the fact that the results can be easily explained. But, unsurprisingly, it
    does come with significant performance downsides, creating problems when the data
    is sparse and the datasets are large.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，被普遍接受的分类方法将推荐系统分为基于内存和基于模型。*基于内存*指的是系统需要将整个数据集加载到工作内存（RAM）中。算法依赖于在内存之间映射和回映射来计算两个用户或项目之间的相似性，并通过取所有评分的加权平均来为用户生成预测。可以使用几种计算相关性的方法，例如*皮尔逊相关系数*。这种方法有一些优势，比如实现的简单性、新数据的容易引入，或者结果可以轻易解释。但是，不出所料，它也伴随着显著的性能劣势，当数据稀疏且数据集很大时，会引发问题。
- en: Because of the limitations of the memory-based recommender systems, alternative
    solutions were needed, mainly driven by the continuous growth of online businesses
    and their underlying data. These were characterized by large volumes of users
    and an increasing number of products. The most famous example is Netflix's one
    million dollar competition—in 2006, Netflix offered a one million dollar prize
    to the individual or team that could improve their existing recommendations algorithm,
    called **Cinematch**, by at least 10%. It took three years for this feat to be
    achieved, and it was done by a joint team of initial competitors, who ultimately
    decided to join forces to grab the prize.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于基于记忆的推荐系统的局限性，需要替代解决方案，这主要是由在线业务的持续增长及其背后的数据驱动的。这些解决方案的特点是用户数量庞大，产品种类不断增加。最著名的例子是Netflix的一百万美元竞赛——2006年，Netflix向能够至少提高其现有推荐算法（称为**Cinematch**）10%的个人或团队提供一百万美元的奖金。这项壮举历时三年才完成，最终是由最初的一些竞争对手组成的联合团队完成的，他们最终决定联手争夺奖金。
- en: Learning about the model-based approach
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解基于模型的方法
- en: This innovative approach to recommender systems was named *model-based*, and
    it made extensive use of matrix factorization techniques. In this approach, models
    are developed using different machine learning algorithms to predict a user's
    ratings. In a way, the model-based approach can be seen as a complementary technique
    to improve memory-based recommendations. They address the matrix sparsity problem
    by guessing how much a user will like a new item. Machine learning algorithms
    are used to train on the existing vector of ratings of a specific user, and then
    build a model that can predict the user's score for an item that the user hasn't
    tried yet. Popular model-based techniques are Bayesian Networks, **singular value
    decomposition** (**SVD**), and **Probabilistic Latent Semantic Analysis** (**PLSA**)
    or **Probabilistic Latent Semantic Indexing** (**PLSI**).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这种推荐系统创新方法被称为**基于模型**，它广泛使用了矩阵分解技术。在这种方法中，使用不同的机器学习算法开发模型来预测用户的评分。从某种意义上说，基于模型的方法可以被视为一种补充技术，以改进基于记忆的推荐。它们通过猜测用户将喜欢新项目的程度来解决矩阵稀疏问题。机器学习算法用于训练特定用户的现有评分向量，然后构建一个可以预测用户尚未尝试的项目评分的模型。流行的基于模型技术包括贝叶斯网络、**奇异值分解（SVD**）和**概率潜在语义分析（PLSA**）或**概率潜在语义索引（PLSI**）。
- en: 'There are a number of popular approaches for building the models:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 建立模型有许多流行的方法：
- en: '**Probability**: Making a recommendation is framed as a problem of predicting
    the probability of a rating being of a particular value. Bayesian networks are
    often used with this implementation.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率**：推荐被框架化为预测评分具有特定值的概率问题。贝叶斯网络通常与这种实现一起使用。'
- en: '**Enhanced ****memory-based**: This uses a model to represent the similarities
    between users or items and then predicts the ratings. The Netflix prize-winning
    ALS-WR algorithm represents this type of implementation.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强型基于记忆**：这种方法使用一个模型来表示用户或项目之间的相似性，然后预测评分。Netflix大奖的ALS-WR算法代表了这种类型的实现。'
- en: '**Linear algebra**: Finally, recommendations can be made by performing linear
    algebra operations on the matrices of users and ratings. A commonly used algorithm
    is SVD.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性代数**：最后，可以通过对用户和评分的矩阵执行线性代数运算来做出推荐。常用的算法是奇异值分解（SVD）。'
- en: In the following sections, we'll implement a model-based recommender. We'll
    use a third-party Julia package and code our business logic around it.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将实现一个基于模型的推荐器。我们将使用第三方Julia包，并围绕它编写业务逻辑。
- en: Understanding our data
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解我们的数据
- en: To get conclusive results from our **Machine Learning** (**ML**) models, we
    need data—and plenty of it. There are many open source datasets available online.
    Kaggle, for example, provides a large collection of high quality and anonymized
    data dumps that can be used for training and experimenting, and is available for
    download at [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets).
    Another famous data repository is provided by FiveThirtyEight, at [https://github.com/fivethirtyeight/data](https://github.com/fivethirtyeight/data).
    Buzzfeed also makes a large treasure of data public at [https://github.com/BuzzFeedNews](https://github.com/BuzzFeedNews).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要从我们的**机器学习**（**ML**）模型中获得结论性的结果，我们需要数据——而且需要大量的数据。网上有大量的开源数据集。例如，Kaggle提供了一个大量高质量和匿名数据集的集合，可用于培训和实验，并可在[https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)下载。另一个著名的数据仓库由FiveThirtyEight提供，在[https://github.com/fivethirtyeight/data](https://github.com/fivethirtyeight/data)。Buzzfeed也在[https://github.com/BuzzFeedNews](https://github.com/BuzzFeedNews)公开了大量数据。
- en: For our project, we'll create a book recommendation system. We'll use the *Book-Crossing
    Dataset*, which is available for download at [http://www2.informatik.uni-freiburg.de/~cziegler/BX/](http://www2.informatik.uni-freiburg.de/~cziegler/BX/).
    This data was collected during the months of August and September 2004, under
    permission, from the Book-Crossing community ([https://www.bookcrossing.com/](https://www.bookcrossing.com/)).
    It includes over 1.1 million book ratings, for more than 270,000 books, from 278,000
    users. The user data is anonymized, but still includes demographic information
    (location and age, where available). We'll use this data to train our recommendation
    system and then ask it for interesting new books for our users.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的项目，我们将创建一个书推荐系统。我们将使用*Book-Crossing Dataset*，该数据集可在[http://www2.informatik.uni-freiburg.de/~cziegler/BX/](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)下载。这些数据是在2004年8月和9月期间，在Book-Crossing社区（[https://www.bookcrossing.com/](https://www.bookcrossing.com/)）的许可下收集的。它包括超过110万条书籍评分，涉及27万多种书籍，来自27.8万名用户。用户数据已匿名化，但仍包括人口统计信息（位置和年龄，如有）。我们将使用这些数据来训练我们的推荐系统，然后要求它为我们用户推荐有趣的新书。
- en: A first look at the data
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初步查看数据
- en: The dataset is composed of three tables—one for users, one for books, and one
    for ratings. The `BX-Users` table contains the users' data. The `User-ID` is a
    sequential integer value, as the original user ID has been anonymized. The `Location`
    and `Age` columns contain the corresponding demographic information. This is not
    available for all the users and in these cases, we'll encounter the `NULL` value
    (as the `NULL` string).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集由三个表组成——一个用于用户，一个用于书籍，一个用于评分。`BX-Users` 表包含用户数据。`User-ID` 是一个顺序整数值，因为原始用户ID已被匿名化。《Location》和《Age》列包含相应的人口统计信息。并非所有用户都有这些信息，在这些情况下，我们会遇到`NULL`值（作为`NULL`字符串）。
- en: The `BX-Books` table stores the information about the books. For the unique
    identifier, we have the standard ISBN book code. Besides this, we are also provided
    with the book's title (the `Book-Title` column), author (`Book-Author`), publishing
    year (`Year-of-Publication`), and the publisher (`Publisher`). URLs of thumbnail
    cover images are also provided, corresponding to three sizes—small (`Image-URL-S`),
    medium (`Image-URL-M`), and large (`Image-URL-L`).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`BX-Books` 表存储有关书籍的信息。对于唯一标识符，我们有标准的ISBN书籍代码。除此之外，我们还提供了书籍的标题（`Book-Title`
    列）、作者（`Book-Author`）、出版年份（`Year-of-Publication`）和出版社（`Publisher`）。还提供了缩略图封面图片的URL，对应三种尺寸——小（`Image-URL-S`）、中（`Image-URL-M`）和大（`Image-URL-L`）。'
- en: Finally, the `BX-Book-Ratings` table contains the actual ratings. The table
    has a simple structure, with three columns—`User-ID`, for the user making the
    rating; the ISBN of the book; and `Book-Rating`, which is the score. The ratings
    are expressed on a scale from 1 to 10, where higher is better. The value `0` signifies
    an implicit rating.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`BX-Book-Ratings` 表包含实际的评分。该表结构简单，有三个列——`User-ID`，用于进行评分的用户；书的ISBN；以及`Book-Rating`，表示分数。评分在1到10的范围内表示，数值越高越好。数值`0`表示隐含的评分。
- en: This dataset is available in SQL and CSV formats, packaged as ZIP archives.
    Please download the CSV version from [http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip](http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集以SQL和CSV格式提供，打包为ZIP存档。请从[http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip](http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip)下载CSV版本。
- en: Unzip the file somewhere on your computer.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的计算机上某个位置解压缩文件。
- en: Loading the data
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'Loading this dataset is going to be a bit more challenging, as we have to work
    with three distinct files, and due to the particularities of the data itself.
    Here is the head of the `BX-Users.csv` file, in a plain text editor:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 加载这个数据集将会更具挑战性，因为我们必须处理三个不同的文件，以及由于数据本身的特殊性。以下是`BX-Users.csv`文件的前几行，在一个纯文本编辑器中：
- en: '![](img/9ffff291-6cef-498c-b11d-dac6f092589e.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9ffff291-6cef-498c-b11d-dac6f092589e.png)'
- en: 'We have to explicitly handle the following formatting particularities, which
    will otherwise cause the import to fail:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须明确处理以下格式特殊性，否则导入可能会失败：
- en: The columns are separated by `;` instead of the more customary comma or *Tab*
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列之间用`;`分隔，而不是更常见的逗号或*制表符*
- en: Missing values are represented by the string `NULL`
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值用字符串`NULL`表示
- en: The first row is the header, representing the column names
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一行是标题行，代表列名
- en: The data is enclosed in double quotes `" "`, and double quotes within the data
    itself are escaped by backslashes, for example, `"1273";"valladolid, \"n/a\",
    spain";"27"`
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据被双引号`"`包围，并且数据本身中的双引号通过反斜杠转义，例如，`"1273";"valladolid, \"n/a\", spain";"27"`
- en: 'Fortunately, the CSV package provides additional options for passing in all
    of this information when reading in the file:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，CSV包在读取文件时提供了额外的选项来传递所有这些信息：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: It might take a bit of time to load the table, but eventually, we'll get the
    sweet taste of success—`278858` rows loaded into memory!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 加载这个表可能需要一点时间，但最终我们会尝到成功的甜头——`278858`行已加载到内存中！
- en: '![](img/585c070e-919b-4120-8947-7a9ebd932893.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/585c070e-919b-4120-8947-7a9ebd932893.png)'
- en: 'We''ll use the same approach to load the books and rankings tables:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用相同的方法来加载书籍和排名表：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Excellent! We now have all three tables loaded into memory as `DataFrames`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们现在已经将所有三个表加载到内存中作为`DataFrames`。
- en: Handling missing data
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理缺失数据
- en: In data science, missing values occur when no data value is stored for a field
    in a record—in other words, when we don't have a value for a column in a row.
    It is a common scenario, but nonetheless, it can have a significant negative effect
    on the usefulness of the data, so it needs to be explicitly handled.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，当记录中的一个字段没有存储数据值时，会出现缺失值——换句话说，当我们没有一行中的列值时。这是一个常见的场景，但无论如何，它可能会对数据的可用性产生重大的负面影响，因此需要明确处理。
- en: The approach in `DataFrames` is to mark the missing value by using the `Missing`
    type. The default behavior is the propagation of the missing values, thus *poisoning* the
    data operations that involve `missing`—that is, operations involving valid input,
    and `missing` will return `missing` or `fail`. Hence, in most cases, the missing
    values need to be addressed in the data-cleaning phase.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在`DataFrames`中的方法是使用`Missing`类型标记缺失值。默认行为是传播缺失值，从而*污染*涉及`missing`的数据操作——也就是说，涉及有效输入的操作，`missing`将返回`missing`或失败。因此，在大多数情况下，需要在数据清洗阶段解决缺失值问题。
- en: 'The most common techniques for handling missing values are as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失值的最常见技术如下：
- en: '**Deletion**: The rows containing the missing variables are deleted (also called
    **listwise deletion**). The downside of this approach is that it leads to loss
    of information. However, if we have plenty of data and not many incomplete records
    (say, under 10%), this is the simplest approach and the most commonly used.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除**：包含缺失变量的行被删除（也称为**逐行删除**）。这种方法的不利之处在于会导致信息丢失。然而，如果我们有大量数据并且不完整的记录不多（比如，低于10%），这是最简单的方法，也是最常用的方法。'
- en: '**Imputation**: The `missing` values are inferred using some technique, usually
    `mean`, `median`, or `mode`. However, you need to be careful, as this artificially
    reduces the variation of the dataset. As an alternative, a predictive model could
    be used to infer the missing value by applying statistical methods.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**插补**：使用某些技术推断`缺失`值，通常为`均值`、`中位数`或`众数`。然而，你需要小心，因为这会人为地减少数据集的变异。作为替代，可以使用预测模型通过应用统计方法来推断缺失值。'
- en: You can read more about Julia's treatment of missing values in the documentation
    at [https://docs.julialang.org/en/v1.0/manual/missing/](https://docs.julialang.org/en/v1.0/manual/missing/),
    while a more advanced discussion of the theoretical aspects of handling missing
    data can be found at [https://datascience.ibm.com/blog/missing-data-conundrum-exploration-and-imputation-techniques/](https://datascience.ibm.com/blog/missing-data-conundrum-exploration-and-imputation-techniques/).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://docs.julialang.org/en/v1.0/manual/missing/](https://docs.julialang.org/en/v1.0/manual/missing/)的文档中了解更多关于Julia处理缺失值的信息，而关于处理缺失数据的理论方面的更深入讨论可以在[https://datascience.ibm.com/blog/missing-data-conundrum-exploration-and-imputation-techniques/](https://datascience.ibm.com/blog/missing-data-conundrum-exploration-and-imputation-techniques/)找到。
- en: Data analysis and preparation
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析和准备
- en: 'Let''s get a feel of the data, starting with the users:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从用户开始，感受一下数据：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/70cbc219-b188-4fc6-a176-9ab636781edb.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70cbc219-b188-4fc6-a176-9ab636781edb.png)'
- en: 'We chose a few key stats—the minimum and maximum values, the number of missing
    and unique values, and the type of data. Unsurprisingly, the `User-ID` column,
    which is the table''s primary key, starts at `1` and goes all the way up to `278858`
    with no missing values. However, the `Age` column shows a clear sign of data errors—the
    maximum age is `244` years! Let''s see what we have there by plotting the data
    with `Gadfly`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了一些关键统计数据——最小值和最大值、缺失值和唯一值的数量，以及数据类型。不出所料，作为表的主键的`User-ID`列从`1`开始，一直升到`278858`，没有缺失值。然而，`Age`列显示出数据错误明显的迹象——最大年龄是`244`岁！让我们通过使用`Gadfly`绘制数据来看看我们有什么：
- en: '[PRE7]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/498825bb-b25d-4f9e-99d9-78c129837a0f.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/498825bb-b25d-4f9e-99d9-78c129837a0f.png)'
- en: 'We rendered a histogram of the ages, splitting the data into 15 intervals.
    We have some outliers indicating incorrect ages, but most of the data is distributed
    within the expected range, up to 80-90 years old. Since anything after **100**
    years old is highly unlikely to be correct, let''s get rid of it. The simplest
    way is to filter out all the rows where the age is greater than **100**:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将年龄数据绘制成直方图，将数据分为15个区间。我们有一些异常值表明年龄不正确，但大部分数据分布在预期的范围内，即80-90岁。由于100岁以后的年龄几乎不可能正确，让我们将其删除。最简单的方法是过滤掉所有年龄大于**100**的行：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Oops! Our `Age` column has `missing` values that cannot be compared. We could
    remove these as well, but in this case, the missing age seems to be more of a
    symptom of the user not disclosing the information, rather than a data error.
    Therefore, I''m more inclined to keep the rows while replacing the missing data
    with valid values. The question is, what values? Imputation using the `mean` seems
    like a good option. Let''s compute it:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀！我们的`Age`列有无法比较的`missing`值。我们也可以删除这些值，但在这个情况下，缺失的年龄似乎更多是用户未披露信息的一个症状，而不是数据错误。因此，我更倾向于保留这些行，并用有效值替换缺失数据。问题是，用哪个值？使用`mean`进行插补似乎是一个不错的选择。让我们计算一下：
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We used the `skipmissing` function to iterate over all the non-missing `Age`
    values and compute the `mean`. Now, we can use this in conjunction with `coalesce`
    to replace the missing values:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`skipmissing`函数遍历所有非缺失的`Age`值并计算平均值。现在，我们可以使用这个值结合`coalesce`来替换缺失值：
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We are effectively replacing the `Age` column of the `users` `DataFrame` with
    a new array, resulting from the application of `coalesce` to the same `Age` column.
    Please notice the dot in the invocation of `coalesce`, indicating that it is applied
    element-wise.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实际上是用一个新数组替换了`users` `DataFrame`中的`Age`列，这个新数组是通过将`coalesce`应用于相同的`Age`列得到的。请注意`coalesce`调用中的点，表示它是逐元素应用的。
- en: 'Great—finally, we need to get rid of those erroneous ages:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了——最后，我们需要删除那些错误的年龄：
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/0f902d24-567b-478f-a590-6b8cf26c6159.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f902d24-567b-478f-a590-6b8cf26c6159.png)'
- en: Looking good!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不错！
- en: 'We''re done with the users, so let''s move on to the books data:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们完成了用户的数据处理，接下来让我们转向书籍数据：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output is as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/3de5518e-aeda-441a-bd2c-7b1db4d01217.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3de5518e-aeda-441a-bd2c-7b1db4d01217.png)'
- en: The data looks much cleaner—first of all, there's no missing values. Then, looking
    at the counts for `nunique`, we can tell that some of the books have identical
    titles and that there's a considerable amount of authors that have published more
    than one book. Finally, the books come from almost 17,000 publishers.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 数据看起来干净多了——首先，没有缺失值。然后，查看`nunique`的计数，我们可以知道有些书籍有相同的标题，而且有相当多的作者出版了两本以上的书籍。最后，这些书籍来自近17,000家出版社。
- en: 'So far, so good, but let''s take a look at the `Year-Of-Publication`:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切顺利，但让我们看看`Year-Of-Publication`：
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Something''s not right here—we have some publishing years that don''t make
    sense. Some are too far in the past, while others are way in the future. I wonder
    what the distribution looks like. Let''s render another histogram:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有些不对劲——我们有一些出版年份没有意义。有些太遥远，而有些则过于未来。我想知道分布是什么样的。让我们再渲染一个直方图：
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output is as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/be6a1974-795e-4fbe-9b19-bd91a4adbf8d.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/be6a1974-795e-4fbe-9b19-bd91a4adbf8d.png)'
- en: 'Most of the data seems to be correct, but there are some faulty outliers. We
    can take a look at the values:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分数据看起来是正确的，但也有一些异常值。我们可以看看这些值：
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'At first sight, we can get rid of the rows that have the publishing year equal
    to `0`. We can also safely assume that all the rows where the publishing date
    is greater than the year when the data was collected (`2004`) are also wrong,
    and so they can be removed. It''s difficult to say what to do about the rest,
    but still, it''s hard to believe that people have ranked books that were published in
    the Middle Ages. Let''s just keep the books that were published between `1970`
    and `2004`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，我们可以去掉出版年份等于`0`的行。我们还可以安全地假设所有出版日期大于数据收集年份（`2004`）的行也是错误的，因此可以删除。至于剩下的部分，虽然很难说怎么办，但仍然很难相信人们会为公元中叶出版的书籍评分。让我们只保留`1970`到`2004`年间出版的书籍：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output is as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/ab4f1089-c149-4fb8-9722-682870fa0892.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ab4f1089-c149-4fb8-9722-682870fa0892.png)'
- en: This is much better and entirely plausible.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这要好得多，完全合理。
- en: 'Finally, let''s check the ratings:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们检查评分：
- en: '[PRE17]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/66b8603b-1bbb-49e5-9f74-efe4af383200.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/66b8603b-1bbb-49e5-9f74-efe4af383200.png)'
- en: 'There''s no missing values, which is great. The `Book-Rating` values are between
    `0` (implicit rating) and `10`, where `1` to `10` represent explicit ratings.
    The median of `0.0` is a bit of a concern though, so let''s take a look:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 没有缺失值，这很好。`Book-Rating`的值在`0`（隐式评分）和`10`之间，其中`1`到`10`代表显式评分。不过，`0.0`的中位数有点令人担忧，让我们看看：
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/48211541-9958-405a-808a-a6ab7b121f2e.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/48211541-9958-405a-808a-a6ab7b121f2e.png)'
- en: 'It turns out that most of the ratings are implicit, thus set to `0`. These
    are not relevant to our recommender, so let''s get rid of them:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，大部分评分是隐式的，因此设置为`0`。这些对我们推荐系统来说并不相关，所以让我们去掉它们：
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here is the output:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '![](img/617829d8-33c4-4844-ba12-cda577faf730.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/617829d8-33c4-4844-ba12-cda577faf730.png)'
- en: We're doing great! There's one more step in our **extract, transform, load** (**ETL**)
    process—let's put the three `DataFrames` together by joining them on the matching
    columns, thus removing the various orphan entries (the ones that don't have corresponding
    rows in all the other tables).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们做得很好！在我们的**提取、转换、加载**（**ETL**）流程中还有一步——让我们通过匹配列将三个`DataFrame`合并起来，从而删除各种孤儿条目（那些在其他所有表中没有对应行的条目）。
- en: 'First, we''ll join book ratings and books:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将书籍评分和书籍连接起来：
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We're using the `join` method, indicating the two `DataFrames` we want to join,
    plus the join column and the kind of join we want. An inner join requires that
    the result contains rows for values of the key that exist in both the first and
    second `DataFrame`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`join`方法，指定我们想要连接的两个`DataFrame`，以及连接列和我们要进行的连接类型。内部连接要求结果包含键值在第一个和第二个`DataFrame`中都存在的行。
- en: 'Now, let''s join with the user''s data:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们与用户数据连接起来：
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Our dataset now contains only the valid data, nicely packed in a single `DataFrame`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集现在只包含有效数据，这些数据被很好地打包在一个单独的`DataFrame`中。
- en: 'As our ratings are on a scale between `1` and `10`, not all of these ratings
    can be considered an endorsement for the book. It''s true that the vast majority
    of the rankings are above `5`, but a `5` is still not good enough for a useful
    recommendation. Let''s simplify our data a bit to make the computations faster
    by assuming that any ranking starting with `8` represents a positive review and
    would make for a strong recommendation. Therefore, we''ll keep only these rows
    and discard the rest:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的评分是在`1`到`10`的范围内，并不是所有的评分都可以被认为是这本书的推荐。确实，大多数排名都在`5`以上，但`5`对于有用的推荐来说还不够好。让我们简化一下数据，通过假设任何以`8`开头的排名代表正面评论，并会形成强有力的推荐。因此，我们只保留这些行，丢弃其余的：
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This is looking good, but it will look even better with just a small tweak
    to make the column names more Julia-friendly:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来不错，但只需稍作调整，使列名更符合Julia的风格，就会更好：
- en: '[PRE23]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We will iterate over each column name and remove the dashes. This way, we''ll
    be able to use the names without having to explicitly use the `Symbol` constructor
    every time. We''ll end up with the following names:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遍历每个列名并删除破折号。这样，我们就能使用这些名称，而无需每次都显式使用`Symbol`构造函数。我们最终会得到以下名称：
- en: '[PRE24]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We''re getting closer—the last step in our data processing workflow is to check
    the number of reviews per user. The more reviews we have from a user, the better
    the preference profile we can create, leading to more relevant and better quality
    recommendations. Basically, we want to get a count of ratings, per user, and then
    get a count of each count (that is, how many rating of ones, twos, threes, and
    so on, up to ten ratings we have):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们越来越接近了——我们数据处理工作流程的最后一步是检查每个用户的评论数量。我们从一个用户那里得到的评论越多，我们就能创建出更好的偏好配置文件，从而产生更相关、质量更高的推荐。基本上，我们想要得到每个用户的评分计数，然后得到每个计数的计数（即，有多少个一星、二星、三星，等等，直到我们有的十个评分）：
- en: '[PRE25]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here, we group the `top_ratings` data by `UserID` and use the `size` function
    as our `aggregation` function, which returns a tuple of dimensions—out of which
    we retrieve just its first dimension. We''ll get the following result, where the
    `x1` column contains the number of ratings provided by the corresponding user:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们按`UserID`对`top_ratings`数据进行分组，并使用`size`函数作为我们的`聚合`函数，它返回一个维度元组——我们从其中检索其第一个维度。我们将得到以下结果，其中`x1`列包含相应用户提供的评分数量：
- en: 'The output is as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/b094b39c-89ef-45ac-b617-8929f72888a1.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b094b39c-89ef-45ac-b617-8929f72888a1.png)'
- en: 'Wondering what this data will reveal? Let''s find out:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 想知道这些数据会揭示什么？让我们来看看：
- en: '[PRE26]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here is the output:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出结果：
- en: '![](img/fc620be1-d226-4a70-a555-d4685ad1e86d.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fc620be1-d226-4a70-a555-d4685ad1e86d.png)'
- en: 'The minimum number of ratings is `1`, while the most productive user has provided
    no less than `5491`, with a mean of around `5` reviews per user. Considering that
    the recommendations for a user with less than `5` reviews would be pretty weak
    anyway, we''re better off removing the users without enough data:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 评分的最小数量是`1`，而最活跃的用户提供的评分不少于`5491`，平均每个用户的评论数量约为`5`。考虑到那些评论少于`5`的用户，他们的推荐可能相当薄弱，我们最好移除那些数据不足的用户：
- en: '[PRE27]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We''re only keeping the users that have at least `5` ratings. Let''s see how
    the number of ratings is distributed now:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只保留至少有`5`个评分的用户。现在让我们看看评分的分布情况：
- en: '[PRE28]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output is as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/f96dcf0d-a017-4ebe-a612-878a4f3104bc.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f96dcf0d-a017-4ebe-a612-878a4f3104bc.png)'
- en: Looks like the vast majority of users have up to `1000` ratings. What about
    the outliers with lots of reviews?
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来，大多数用户都有多达`1000`个评分。那么，有很多评论的异常值用户呢？
- en: '[PRE29]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output is as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/6075a11b-184a-4e9e-9e64-d846bbfacbf4.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6075a11b-184a-4e9e-9e64-d846bbfacbf4.png)'
- en: 'There''s only `3` users. We''d better remove them so that they don''t skew
    our results:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 只有`3`个用户。我们最好移除他们，以免他们扭曲我们的结果：
- en: '[PRE30]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now that we have the list of final users, the next step is to remove all the
    others from the `top_ratings` `DataFrame`. Again, let''s use an inner join—it''s
    pretty straightforward:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了最终用户的列表，下一步就是从`top_ratings` `DataFrame`中移除所有其他用户。再次，让我们使用内连接——这相当直接：
- en: '[PRE31]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: That's it, our data is ready. Great job!
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，我们的数据准备好了。干得好！
- en: 'If you want, you can save this data to file by using `CSV.write`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想，你可以使用`CSV.write`将此数据保存到文件中：
- en: '[PRE32]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: If you've had problems following along, don't worry. In a few paragraphs, I'll
    explain how you can load a ready-made dataset, which is provided in this chapter's
    support files.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遇到难以跟上进度的问题，请不要担心。在接下来的几段中，我将解释如何加载本章支持文件中提供的现成数据集。
- en: Training our data models
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练我们的数据模型
- en: 'Machine learning can be divided into four main types, depending on the methodology
    and the type of data that is used:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习可以根据方法和所使用的数据类型分为四种主要类型：
- en: Supervised
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督
- en: Unsupervised
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督
- en: Semi-supervised
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半监督
- en: Reinforcement
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化
- en: In supervised learning, we start with a dataset that contains training (or teaching)
    data, where each record is labeled, representing both input (let's call it *X*),
    and output values (named *Y*). Then, the algorithm's job is to identify a function
    *f* from input to output, so that *Y = f(X)*. Once this function is identified,
    it can be used on new data (that is, new inputs that are not labeled) to predict
    the output. Depending on the type of output that needs to be computed, if the
    output has to be assigned to a certain class of entities (as in, it represents
    categorical data), then a classification algorithm will be used. Alternatively,
    if the type of output is a numeric value, we'll be dealing with a regression problem.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，我们从一个包含训练（或教学）数据的数据集开始，其中每个记录都有标签，代表输入（让我们称其为 *X*），以及输出值（命名为 *Y*）。然后，算法的任务是确定一个从输入到输出的函数
    *f*，使得 *Y = f(X)*。一旦这个函数被确定，它就可以用于新数据（即未标记的新输入）来预测输出。根据需要计算输出类型的类型，如果输出需要分配给某个实体的类别（例如，它代表分类数据），则将使用分类算法。或者，如果输出类型是数值，我们将处理回归问题。
- en: With unsupervised machine learning, we have the inputs, but not the outputs.
    In such a scenario, once we use the learning dataset to train our system, the
    main goal will be data clustering, that is, generating different clusters of inputs
    and being able to assign new data to the most appropriate cluster.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督机器学习中，我们有输入，但没有输出。在这种情况下，一旦我们使用学习数据集来训练我们的系统，主要目标将是数据聚类，即生成不同的输入簇，并能够将新数据分配到最合适的簇中。
- en: Semi-supervised, as the name suggests, represents a mixture of the two previously
    described approaches, both of which are applicable when our data contains both
    labeled and unlabeled records.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，半监督代表两种先前描述方法的混合，这两种方法都适用于我们的数据包含标记和未标记记录的情况。
- en: In reinforcement learning, the algorithm is informed about the success of its
    previous decisions. Based on this, the algorithm modifies its strategy in order
    to maximize the outcome.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习中，算法会了解其先前决策的成功情况。基于此，算法修改其策略以最大化结果。
- en: Depending on the learning style and the specific problem that's meant to be
    solved, there are a multitude of algorithms that can be applied. For supervised
    learning, we can use regression (linear or logistic), decision trees, or neural
    networks, to name just a few. With unsupervised learning, we could choose k-means
    clustering or `Apriori` algorithms.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 根据学习风格和要解决的问题的具体问题，有众多算法可以应用。对于监督学习，我们可以使用回归（线性或逻辑回归）、决策树或神经网络，仅举几例。对于无监督学习，我们可以选择
    k-means 聚类或 `Apriori` 算法。
- en: Since our data is tagged (we have the rating for each user), we are dealing
    with a supervised machine learning problem. For our test case, since our data
    is represented as a matrix, we'll employ an algorithm called **Matrix Factorization**
    (**MF**).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的数据已标记（我们拥有每个用户的评分），我们正在处理一个监督机器学习问题。对于我们的测试案例，由于我们的数据以矩阵形式表示，我们将采用一种称为**矩阵分解**（**MF**）的算法。
- en: 'You can read more about the various types of ML algorithms and how to choose
    them at the following links:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下链接中了解更多关于各种机器学习算法及其选择的信息：
- en: '[https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice](https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice)
    [https://blog.statsbot.co/machine-learning-algorithms-183cc73197c](https://blog.statsbot.co/machine-learning-algorithms-183cc73197c)
    [https://elitedatascience.com/machine-learning-algorithms](https://elitedatascience.com/machine-learning-algorithms)
    [https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice](https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice)
    [https://blog.statsbot.co/machine-learning-algorithms-183cc73197c](https://blog.statsbot.co/machine-learning-algorithms-183cc73197c)
    [https://elitedatascience.com/machine-learning-algorithms](https://elitedatascience.com/machine-learning-algorithms)
    [https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)'
- en: Scaling down our dataset
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缩小我们的数据集
- en: Training machine learning models at scale usually requires (lots of) powerful
    computers and plenty of time. If you have neither of these while reading this
    book, I have prepared a smaller dataset so that you can go through our project.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模上训练机器学习模型通常需要（很多）强大的计算机和大量的时间。如果你在阅读这本书的时候没有这些条件，我准备了一个较小的数据集，这样你就可以完成我们的项目。
- en: Training the recommender on the full `top_ratings` data took over 24 hours on
    my quad-core, 16 GB RAM laptop. If you're so inclined, feel free to try it. It
    is also available for download at [https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/large/top_ratings.csv.zip](https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/large/top_ratings.csv.zip).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的四核、16 GB RAM笔记本电脑上，使用完整的`top_ratings`数据训练推荐器花费了超过24小时。如果你有兴趣，可以自由尝试。它也可以在[https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/large/top_ratings.csv.zip](https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/large/top_ratings.csv.zip)下载。
- en: However, if you'd like to follow through the code while reading this chapter,
    please download the `top_ratings.csv` file that's provided with this chapter's
    support files at [https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/top_ratings.csv](https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/top_ratings.csv).
    I will be using the data from this smaller file for the remainder of this chapter.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你想在阅读本章时跟随代码，请下载本章支持文件中提供的`top_ratings.csv`文件，网址为[https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/top_ratings.csv](https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/top_ratings.csv)。我将使用这个较小的文件中的数据来完成本章的剩余部分。
- en: 'Once you''ve downloaded the file, you can load its content into the `top_ratings`
    variable by using the `CSV.read` function:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 下载文件后，你可以使用`CSV.read`函数将其内容加载到`top_ratings`变量中：
- en: '[PRE33]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Training versus testing data
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据与测试数据
- en: 'A common strategy in machine learning implementations is to split the data
    into training (some 80-90%) and testing (the remaining 10-20%) datasets. First,
    we''ll initialize two empty `DataFrames` to store this data:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习实现中，一个常见的策略是将数据分成训练集（大约80-90%）和测试集（剩余的10-20%）。首先，我们将初始化两个空的`DataFrames`来存储这些数据：
- en: '[PRE34]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Next, we''ll iterate through our `top_ratings` and put the contents into the
    corresponding `DataFrame`. We''ll go with 10% of data for testing—so with each
    iteration, we''ll generate a random integer between `1` and `10`. The chances
    of getting a `10` are, obviously, one in ten, so when we get it, we put the corresponding
    row into the test dataset. Otherwise, it goes into the training one, as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将遍历我们的`top_ratings`，并将内容放入相应的`DataFrame`中。我们将用10%的数据进行测试——所以每次迭代，我们将生成一个介于`1`和`10`之间的随机整数。显然，得到`10`的概率是十之一，因此当我们得到它时，我们将相应的行放入测试数据集中。否则，它将进入训练集，如下所示：
- en: '[PRE35]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: There's no canonical way for pushing a `DataFrameRow` onto another `DataFrame`,
    so we're using one of the recommended approaches, which is to convert the row
    into an `Array` and `push!` it to the `DataFrame`. Our training and testing datasets
    are now ready.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 将`DataFrameRow`推送到另一个`DataFrame`上没有标准的方法，所以我们使用了一种推荐的方法，即将行转换为`Array`并使用`push!`将其推送到`DataFrame`中。我们的训练集和测试集现在已准备就绪。
- en: 'For me, they look like this, but since the data was generated randomly, it
    will be different for you:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我来说，它们看起来是这样的，但由于数据是随机生成的，所以对你们来说可能会有所不同：
- en: '[PRE36]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If you prefer for us to work with the same datasets, you can download the data
    dump from this chapter''s support files (available at [https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/training_data.csv](https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/training_data.csv) and
    [https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/test_data.csv](https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/test_data.csv),
    respectively) and read them in as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望我们使用相同的数据集，你可以从本章的支持文件中下载数据存档（可在[https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/training_data.csv](https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/training_data.csv)和[https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/test_data.csv](https://github.com/PacktPublishing/Julia-Projects/blob/master/Chapter07/data/test_data.csv)分别下载）并按以下方式读取：
- en: '[PRE37]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Machine learning-based recommendations
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于机器学习的推荐
- en: Julia's ecosystem provides access to `Recommendation.jl`, a package that implements
    a multitude of algorithms for both personalized and non-personalized recommendations.
    For model-based recommenders, it has support for SVD, MF, and content-based recommendations
    using TF-IDF scoring algorithms.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Julia的生态系统提供了访问`Recommendation.jl`包的途径，这是一个实现多种算法的包，包括个性化和非个性化推荐。对于基于模型的推荐器，它支持SVD、MF和基于TF-IDF评分算法的内容推荐。
- en: There's also another very good alternative—the `ScikitLearn.jl` package ([https://github.com/cstjean/ScikitLearn.jl](https://github.com/cstjean/ScikitLearn.jl)).
    This implements Python's very popular scikit-learn interface and algorithms in
    Julia, supporting both models from the Julia ecosystem and those of the scikit-learn
    library (via `PyCall.jl`). The Scikit website and documentation can be found at
    [http://scikit-learn.org/stable/](http://scikit-learn.org/stable/). It is very
    powerful and definitely worth keeping in mind, especially for building highly
    efficient recommenders for production usage. For learning purposes, we'll stick
    to `Recommendation`, as it provides for a simpler implementation.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 另外还有一个非常好的替代方案——`ScikitLearn.jl`包（[https://github.com/cstjean/ScikitLearn.jl](https://github.com/cstjean/ScikitLearn.jl)）。这个包在Julia中实现了Python非常流行的scikit-learn接口和算法，支持Julia生态系统中的模型以及scikit-learn库中的模型（通过`PyCall.jl`）。Scikit网站和文档可以在[http://scikit-learn.org/stable/](http://scikit-learn.org/stable/)找到。它非常强大，绝对值得记住，尤其是在构建用于生产使用的效率极高的推荐器时。出于学习目的，我们将坚持使用`Recommendation`，因为它提供了更简单的实现。
- en: Making recommendations with Recommendation
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用`Recommendation`进行推荐
- en: For our learning example, we'll use `Recommendation`. It is the simplest of
    the available options, and it's a good teaching device, as it will allow us to
    further experiment with its plug-and-play algorithms and configurable model generators.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的学习示例，我们将使用`Recommendation`。它是所有可用选项中最简单的，它是一个很好的教学工具，因为它将允许我们进一步实验其即插即用的算法和可配置的模型生成器。
- en: 'Before we can do anything interesting, though, we need to make sure that we
    have the package installed:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们能够进行任何有趣的事情之前，我们需要确保我们已经安装了该包：
- en: '[PRE38]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Please note that I'm using the `#master` version, because the tagged version,
    at the time of writing this book, was not yet fully updated for Julia 1.0.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我使用的是`#master`版本，因为在撰写本书时，标记的版本尚未完全更新以支持Julia 1.0。
- en: 'The workflow for setting up a recommender with `Recommendation` involves three
    steps:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Recommendation`设置推荐器的流程包括三个步骤：
- en: Setting up the training data
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置训练数据
- en: Instantiating and training a recommender using one of the available algorithms
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用可用的算法之一实例化和训练推荐器
- en: Once the training is complete, asking for recommendations
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦训练完成，请求推荐
- en: Let's implement these steps.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实施这些步骤。
- en: Setting up the training data
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置训练数据
- en: '`Recommendation` uses a `DataAccessor` object to set up the training data.
    This can be instantiated with a set of `Event` objects. A `Recommendation.Event`
    is an object that represents a user-item interaction. It is defined like this:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`Recommendation`使用`DataAccessor`对象来设置训练数据。这可以通过一组`Event`对象来实例化。`Recommendation.Event`是一个表示用户-项目交互的对象。它定义如下：'
- en: '[PRE39]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'In our case, the `user` field will represent the `UserID`, the `item` field
    will map to the ISBN, and the `value` field will store the `Rating`. However,
    a bit more work is needed to bring our data in the format required by `Recommendation`:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，`user`字段将代表`UserID`，`item`字段将映射到ISBN，而`value`字段将存储`Rating`。然而，我们需要做更多的工作来将我们的数据格式化为`Recommendation`所需的格式：
- en: First of all, our ISBN data is stored as a string and not as an integer.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们的ISBN数据存储为字符串，而不是整数。
- en: Second, internally, `Recommendation` builds a sparse matrix of `user` * ` item`
    and stores the corresponding values, setting up the matrix using sequential IDs.
    However, our actual user IDs are large numbers, and `Recommendation` will set
    up a very large, sparse matrix, going all the way from the minimum to the maximum
    user IDs.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其次，在内部，`Recommendation`构建了一个`user` * `item`的稀疏矩阵并存储相应的值，使用顺序ID设置矩阵。然而，我们的实际用户ID是很大的数字，`Recommendation`将设置一个非常大的稀疏矩阵，从最小用户ID到最大用户ID。
- en: What this means is that, for example, we only have 69 users in our dataset (as
    confirmed by `unique(training_data[:UserID]) |> size`), with the largest ID being
    277,427, while for books we have 9,055 unique ISBNs. If we go with this, `Recommendation`
    will create a 277,427 x 9,055 matrix instead of a 69 x 9,055 matrix. This matrix
    would be very large, sparse, and inefficient.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，例如，在我们的数据集中我们只有69个用户（如`unique(training_data[:UserID]) |> size`所确认的），最大的ID是277,427，而对于书籍，我们有9,055个独特的ISBN。如果我们这样做，`Recommendation`将创建一个277,427
    x 9,055的矩阵，而不是69 x 9,055的矩阵。这个矩阵将会非常大，稀疏且效率低下。
- en: Therefore, we'll need to do a bit more data processing to map the original user
    IDs and the ISBNs to sequential integer IDs, starting from 1.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要进行一些额外的数据处理，将原始用户ID和ISBN映射到从1开始的顺序整数ID。
- en: 'We''ll use two `Dict` objects that will store the mappings from the `UserID`
    and `ISBN` columns to the recommender''s sequential user and book IDs. Each entry
    will be of the form `dict[original_id] = sequential_id`:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用两个`Dict`对象来存储从`UserID`和`ISBN`列到推荐器的顺序用户和书籍ID的映射。每个条目都将具有以下形式`dict[original_id]
    = sequential_id`：
- en: '[PRE40]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We''ll also need two counters to keep track of, and increment, the sequential
    IDs:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要两个计数器来跟踪和增加顺序ID：
- en: '[PRE41]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We can now prepare the `Event` objects for our training data:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以准备我们的训练数据的`Event`对象：
- en: '[PRE42]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'This will fill up the events array with instances of `Recommendation.Event`,
    which represent a unique `UserID`, `ISBN`, and `Rating` combination. To give you
    an idea, it will look like this:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这将用`Recommendation.Event`实例填充事件数组，它代表一个独特的`UserID`、`ISBN`和`Rating`组合。为了给您一个概念，它看起来像这样：
- en: '[PRE43]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Please remember this very important aspect—in Julia, the `for` loop defines
    a new scope. This means that variables defined outside the `for` loop are not
    accessible inside it. To make them visible within the loop's body, we need to
    declare them as `global`.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住这个非常重要的方面——在Julia中，`for`循环定义了一个新的作用域。这意味着在`for`循环外部定义的变量在循环内部是不可访问的。为了使它们在循环体内部可见，我们需要将它们声明为`global`。
- en: 'Now, we are ready to set up our `DataAccessor`:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备设置我们的`DataAccessor`：
- en: '[PRE44]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Building and training the recommender
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建和训练推荐器
- en: At this point, we have all that we need to instantiate our recommender. A very
    efficient and common implementation uses MF—unsurprisingly, this is one of the
    options provided by the `Recommendation` package, so we'll use it.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经拥有了实例化推荐器所需的一切。一个非常高效且常见的实现使用MF——不出所料，这是`Recommendation`包提供的选项之一，所以我们将使用它。
- en: Matrix Factorization
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 矩阵分解
- en: 'The idea behind MF is that, if we''re starting with a large sparse matrix like
    the one used to represent *user x profile* ratings, then we can represent it as
    the product of multiple smaller and denser matrices. The challenge is to find
    these smaller matrices so that their product is as close to our original matrix
    as possible. Once we have these, we can fill in the blanks in the original matrix
    so that the predicted values will be consistent with the existing ratings in the
    matrix:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: MF背后的想法是，如果我们从一个大型的稀疏矩阵开始，比如用来表示*用户 x 个人资料*评分的矩阵，那么我们可以将其表示为多个较小且密集的矩阵的乘积。挑战在于找到这些较小的矩阵，使得它们的乘积尽可能接近原始矩阵。一旦我们有了这些，我们就可以在原始矩阵中填补空白，使得预测值与矩阵中现有的评分一致：
- en: '![](img/c67372c9-cbfd-4365-af58-5a1ba2baf472.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c67372c9-cbfd-4365-af58-5a1ba2baf472.png)'
- en: Our *user x books* rating matrix can be represented as the product between smaller
    and denser users and books matrices.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的*用户 x 书籍*评分矩阵可以表示为较小且密集的用户和书籍矩阵的乘积。
- en: To perform the matrix factorization, we can use a couple of algorithms, among
    which the most popular are SVD and **Stochastic Gradient Descent** (**SGD**).
    `Recommendation` uses SGD to perform matrix factorization.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行矩阵分解，我们可以使用几种算法，其中最流行的是SVD和**随机梯度下降**（**SGD**）。`Recommendation`使用SGD来执行矩阵分解。
- en: 'The code for this looks as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 代码如下：
- en: '[PRE45]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: We instantiate a new MF recommender and then we build it—that is, train it.
    The build step might take a while (a few minutes on a high-end computer using
    the small dataset that's provided in this chapter's support files).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实例化一个新的MF推荐器，然后构建它——即训练它。构建步骤可能需要一段时间（在高端计算机上使用本章支持文件中提供的小数据集，可能需要几分钟）。
- en: If we want to tweak the training process, since SGD implements an iterative
    approach for matrix factorization, we can pass a `max_iter` argument to the build
    function, asking it for a maximum number of iterations. The more iterations we
    do, in theory, the better the recommendations—but the longer it will take to train
    the model. If you want to speed things up, you can invoke the build function with
    a `max_iter` of `30` or less—`build(recommender, max_iter = 30)`.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想调整训练过程，由于SGD实现了矩阵分解的迭代方法，我们可以向构建函数传递一个`max_iter`参数，请求它提供最大迭代次数。理论上，我们进行的迭代越多，推荐效果越好——但训练模型所需的时间也会更长。如果您想加快速度，可以使用`max_iter`为`30`或更少的构建函数——`build(recommender,
    max_iter = 30)`。
- en: We can pass another optional argument for the learning rate, for example, `build
    (recommender, learning_rate=15e-4, max_iter=100)`. The learning rate specifies
    how aggressively the optimization technique should vary between each iteration.
    If the learning rate is too small, the optimization will need to be run a lot
    of times. If it's too big, then the optimization might fail, generating worse
    results than the previous iterations.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以传递另一个可选参数学习率，例如，`build (recommender, learning_rate=15e-4, max_iter=100)`。学习率指定了优化技术应在每次迭代之间如何变化。如果学习率太小，优化需要运行很多次。如果太大，那么优化可能会失败，生成比前几次迭代更差的结果。
- en: Making recommendations
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供推荐
- en: 'Now that we have successfully built and trained our model, we can ask it for
    recommendations. These are provided by the `recommend` function, which takes an
    instance of a recommender, a user ID (from the ones available in the training
    matrix), the number of recommendations, and an array of books ID from which to
    make recommendations as its arguments:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功构建并训练了我们的模型，我们可以请求它提供推荐。这些推荐由`recommend`函数提供，该函数接受一个推荐器实例、用户ID（来自训练矩阵中可用的ID）、推荐数量以及一个包含书籍ID的数组作为其参数：
- en: '[PRE46]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: With this line of code, we retrieve the recommendations for the user with the
    recommender ID `1`, which corresponds to the `UserID` `277427` in the original
    dataset. We're asking for up to `20` recommendations that have been picked from
    all the available books.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这一行代码，我们检索具有推荐器ID `1`的用户推荐，这对应于原始数据集中的`UserID` `277427`。我们请求最多`20`个推荐，这些推荐是从所有可用的书籍中挑选出来的。
- en: 'We get back an array of a `Pair` of book IDs and recommendation scores:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到一个包含书籍ID和推荐得分的`Pair`数组的数组：
- en: '[PRE47]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Testing the recommendations
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试推荐
- en: Finally, our machine learning-based recommender system is ready. It will provide
    a significant boost in user experience for any bookshop, for sure. But before
    we start advertising it, we should make sure that it's reliable. Remember that
    we put aside 10% of our dataset for testing purposes. The idea is to compare the
    recommendations with actual ratings from the test data to see what degree of similarity
    exists between the two; that is, how many of the actual ratings from the dataset
    were in fact recommended. Depending on the data that's used for the training,
    you may want to test that both correct recommendations are made, but also that
    bad recommendations are not included (that is, the recommender does not suggest
    items that got low ratings, indicating a dislike). Since we only used ratings
    of 8, 9, and 10, we won't check if low-ranked recommendations were provided. We'll
    just focus on checking how many of the recommendations are actually part of the
    user's data.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们的基于机器学习的推荐系统已经准备好了。它无疑将为任何书店的用户体验带来显著提升。但在我们开始宣传它之前，我们应该确保它是可靠的。记住，我们留出了10%的数据集用于测试目的。想法是将推荐与测试数据中的实际评分进行比较，以查看两者之间的相似程度；也就是说，数据集中的实际评分中有多少被推荐了。根据用于训练的数据，您可能想测试是否做出了正确的推荐，同时也确保没有包含不良推荐（即，推荐器不会建议得到低评分的项目，这表明不喜欢）。由于我们只使用了8、9和10的评分，我们不会检查是否提供了低排名的推荐。我们只关注检查有多少推荐实际上是用户数据的一部分。
- en: 'Because the test data uses the original user and profile IDs, and our recommender
    uses the normalized, sequential IDs, we''ll need a way to convert the data between
    the two. We already have the `user_mappings` and `book_mappings` dictionaries,
    which map from the original IDs to recommender IDs. However, we''ll also need
    the reverse. So, let''s start by defining a helper function for reversing a dictionary:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 由于测试数据使用的是原始用户和配置文件 ID，而我们的推荐器使用的是归一化、顺序 ID，我们需要一种方法在两者之间转换数据。我们已经有 `user_mappings`
    和 `book_mappings` 字典，它们将原始 ID 映射到推荐器 ID。然而，我们还需要反向映射。所以，让我们首先定义一个用于反转字典的辅助函数：
- en: '[PRE48]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This is simple, but very useful—we can now use this function to look up the
    original IDs based on the recommender IDs. For instance, if we want to test the
    recommendations for user `1`, we''ll need to retrieve this user''s actual ratings,
    so we''ll need the original ID. We can easily get it with the following code:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这很简单，但非常有用——我们现在可以使用这个函数根据推荐器 ID 查找原始 ID。例如，如果我们想测试用户 `1` 的推荐，我们需要检索此用户的实际评分，因此我们需要原始
    ID。我们可以通过以下代码轻松获取它：
- en: '[PRE49]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The same applies to the books mappings—for instance, the recommendation with
    ID `5081` corresponds to ISBN `981013004X` from the original dataset:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这同样适用于书籍映射——例如，ID 为 `5081` 的推荐对应于原始数据集中的 ISBN `981013004X`：
- en: '[PRE50]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'All right, let''s check the test data that we put aside for `UserID` `277427`
    (recommender user `1`):'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，让我们检查为 `UserID` `277427`（推荐器用户 `1`）预留的测试数据：
- en: '[PRE51]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output is as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![](img/21d47dc0-094c-4399-9181-b28e96e92e49.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21d47dc0-094c-4399-9181-b28e96e92e49.png)'
- en: '[PRE52]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'To check for recommended versus actually rated profiles, the easiest approach
    is to intersect the vector of recommendations with the vector of ratings. So,
    the first thing to do is put the test ratings into a vector, out of the `DataFrame`:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查推荐与实际评分的配置文件，最简单的方法是将推荐向量与评分向量进行交集。所以，首先要做的是将测试评分放入一个向量中，从 `DataFrame` 中取出：
- en: '[PRE53]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We just select the ISBN column data, for all the rows, as an `Array`.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只选择所有行的 ISBN 列数据，作为一个 `Array`。
- en: 'Doing the same for the recommendations is a bit more involved. Also, since
    I expect we''ll want to test with various recommender settings and with different
    numbers of recommendations, it''s best to define a function that converts the
    recommendations to a vector of ISBNs, so that we can easily reuse the code:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 对推荐进行同样的操作要复杂一些。此外，由于我预计我们可能需要测试不同的推荐器设置和不同数量的推荐，最好定义一个函数将推荐转换为 ISBN 向量，这样我们就可以轻松地重用代码：
- en: '[PRE54]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The `recommendations_to_books` function takes the vector of `id => score` pairs
    generated by the recommender as its only argument and converts it into a vector
    of original ISBNs:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '`recommendations_to_books` 函数将推荐器生成的 `id => score` 对的向量作为其唯一参数，并将其转换为原始 ISBN
    向量：'
- en: '[PRE55]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: The `recommendations_to_books` function outputs the ISBNs for the `20` recommended
    books.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`recommendations_to_books` 函数输出了 `20` 本推荐书的 ISBN。'
- en: 'Now, we have all of the pieces to check recommendations versus ratings:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经拥有了所有检查推荐与评分的部件：
- en: '[PRE56]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We use the intersect function to check what elements from the first vector—the
    list of books we put away for testing—also show up in the second vector, that
    is, the recommendations. We had to ask for `500` recommendations as the chances
    of hitting one of the eight test books in a pool of 9,055 books were very slim.
    This is due to the fact that we worked with very little data, but in a production
    environment and potentially billions of rows, we would get a lot more overlapping
    data.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用交集函数来检查第一个向量——我们为测试放置的书籍列表中的哪些元素也出现在第二个向量中，即推荐中。我们必须请求 `500` 个推荐，因为在 9,055
    本书池中击中这八本测试书的可能性非常小。这是由于我们处理的数据非常少，但在生产环境中，可能涉及数十亿行，我们会得到更多重叠的数据。
- en: 'Let''s see what the top five recommendations were:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看前五个推荐是什么：
- en: '[PRE57]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'In an IJulia Notebook, we can even look at the covers, thus rendering a small
    piece of HTML using the cover''s URLs:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在 IJulia 笔记本中，我们甚至可以查看封面，从而使用封面的 URL 渲染一小块 HTML：
- en: '[PRE58]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output will be as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![](img/60e8823b-ff1e-4113-b583-1d6a9e89ca3c.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60e8823b-ff1e-4113-b583-1d6a9e89ca3c.png)'
- en: Excellent! We did a great job. We tamed a very complex dataset, performed advanced
    analysis, and then we optimized it for usage in our recommender. We then successfully
    trained our recommender and used it to generate book recommendations for our users.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们做得很好。我们驯服了一个非常复杂的数据集，进行了高级分析，然后我们优化了它在推荐器中的使用。然后我们成功训练了推荐器，并使用它为我们的用户生成书籍推荐。
- en: Deploying and working with the `Recommendation` package is very straightforward,
    as I'm sure you've come to appreciate. Again, as in most data science projects,
    the ETL step was the most involved.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 部署和使用`Recommendation`包非常简单，正如你肯定已经体会到的。再次强调，就像大多数数据科学项目一样，ETL步骤是最复杂的。
- en: Learning about hybrid recommender systems
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解混合推荐系统
- en: There are some clear advantages when using model-based recommenders. As mentioned
    already, scalability is one of the most important. Usually, the models are much
    smaller than the initial dataset, so that even for very large data samples, the
    models are small enough to allow efficient usage. Another benefit is the speed.
    The time required to query the model, as opposed to querying the whole dataset,
    is usually considerably smaller.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用基于模型的推荐系统时，有一些明显的优势。如前所述，可扩展性是最重要的因素之一。通常，模型的大小远小于初始数据集，因此即使是对于非常大的数据样本，模型也足够小，可以允许高效的使用。另一个好处是速度。查询模型所需的时间，与查询整个数据集所需的时间相比，通常要小得多。
- en: These advantages stem from the fact that the models are generally prepared offline,
    allowing for almost instantaneous recommendations. But since there's no such thing
    as free performance, this approach also comes with a few significant negatives—on
    one hand, it is less flexible, because building the models takes considerable
    time and resources, making the updates difficult and costly; on the other hand,
    because it does not use the whole dataset, the predictions can be less accurate.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这些优势源于模型通常是在线外准备的，这使得推荐几乎可以即时完成。但是，由于没有免费的性能，这种方法也带来了一些显著的缺点——一方面，它不够灵活，因为构建模型需要相当的时间和资源，这使得更新变得困难和昂贵；另一方面，因为它没有使用整个数据集，预测可能不够准确。
- en: As with everything, there's no silver bullet, and the best approach depends
    on the data you have at hand and the problem you need to solve. However, it doesn't
    always have to be memory-based versus model-based. Even more, it doesn't have
    to be just one recommender system. It turns out that multiple algorithms and approaches
    can be efficiently combined to compensate for the limitations of one type of recommender.
    Such architectures are called **hybrid**. Due to space limitations, we won't cover
    any implementations of hybrid recommender systems, but I want to give you an idea
    of the possible approaches. I'm just going to refer you to Robin Burke's classification
    from *Chapter 12* of *The Adaptive Web*, entitled *Hybrid Web Recommender Systems*.
    The whole chapter is available online for free at [https://www.researchgate.net/publication/200121024_Hybrid_Web_Recommender_Systems](https://www.researchgate.net/publication/200121024_Hybrid_Web_Recommender_Systems).
    If you're interested in this topic, I highly recommended it.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 就像所有事情一样，没有一劳永逸的解决方案，最佳方法取决于你手头的数据和你需要解决的问题。然而，并不总是需要基于内存的与基于模型的相对比。更进一步，也不一定只有一个推荐系统。实际上，多个算法和方法的组合可以有效地弥补单一类型推荐系统的局限性。这种架构被称为**混合**。由于篇幅限制，我们不会涵盖任何混合推荐系统的实现，但我想要给你一个可能的方法的概述。我将仅引用罗宾·伯克在《自适应网络》第12章中的分类，该章节标题为《混合网络推荐系统》。整个章节可以在网上免费获取，链接为[https://www.researchgate.net/publication/200121024_Hybrid_Web_Recommender_Systems](https://www.researchgate.net/publication/200121024_Hybrid_Web_Recommender_Systems)。如果你对这个主题感兴趣，我强烈推荐阅读。
- en: Summary
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Recommender systems represent a very active and dynamic field of study. They
    started initially as a marginal application of machine learning algorithms and
    techniques, but due to their practical business value, they have become mainstream
    in recent years. These days, almost all major programming languages provide powerful
    recommendations systems libraries—and all major online businesses employ recommenders
    in one form or another.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统代表了一个非常活跃和动态的研究领域。它们最初只是机器学习算法和技术的一个边缘应用，但由于其实际的商业价值，近年来已经成为主流。如今，几乎所有主要的编程语言都提供了强大的推荐系统库，并且所有主要的在线业务都以某种形式使用推荐系统。
- en: Julia is a great language for building recommenders due to its excellent performance.
    Despite the fact that the language is still young, we already have a couple of
    interesting packages to choose from.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: Julia是一种非常适合构建推荐系统的语言，因为它具有出色的性能。尽管这种语言还很年轻，但我们已经有了一些有趣的包可供选择。
- en: Now, you have a solid understanding of the model-based recommendation systems
    and of their implementation workflow—both on a theoretical and practical level.
    Plus, throughout our journey, we've also been exposed to more advanced data wrangling
    using `DataFrames`, an invaluable tool in Julia's data science arsenal.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你对基于模型的推荐系统及其实现工作流程有了扎实的理解——无论是在理论层面还是实践层面。此外，在我们旅途中，我们还接触到了更多高级的数据处理技巧，使用了`DataFrames`，这是Julia数据科学工具库中一个无价的工具。
- en: In the next chapter, we'll further improve our mastery of `DataFrames`, as we'll
    learn the secrets of metaprogramming in Julia, while developing an unsupervised
    machine learning system.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将进一步提高我们对`DataFrames`的掌握，因为我们将会学习Julia元编程的秘密，同时开发一个无监督的机器学习系统。
