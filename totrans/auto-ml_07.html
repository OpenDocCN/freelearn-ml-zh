<html><head></head><body>
		<div id="_idContainer174">
			<h1 id="_idParaDest-77"><em class="italic"><a id="_idTextAnchor084"/>Chapter 5</em>: Automated Machine Learning with Microsoft Azure</h1>
			<p class="author-quote">"By far, the greatest danger of artificial intelligence is that people conclude too early that they understand it." </p>
			<p class="author-quote">– Eliezer Yudkowsky<a id="_idTextAnchor085"/></p>
			<p>The Microsoft Azure platform and its associated toolset are diverse and part of a larger enterprise ecosystem that is a force to be reckoned with. It enables businesses to focus on what they do best by accelerating growth via improved communication, resource management, and facilitating advance actionable analytics. In the previous chapter, you were introduced to the Azure Machine Learning platform and its services. You learned how to get started with Azure machine learning, and you took a glimpse at the end-to-end machine learning life cycle using the power of the Microsoft Azure platform and its services. That was quite literally (in the non-literal sense of the word) the tip of the iceberg. </p>
			<p>In this chapter, we will get started by looking at <strong class="bold">Automated Machine Learning</strong> (<strong class="bold">AutoML</strong>) in Microsoft Azure. You will build a classification model and perform time series prediction using Azure's AutoML capabilities. This chapter will equip you with the skills you'll need to build and deploy AutoML solutions. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>AutoML in Microsoft Azure </li>
				<li>Time series prediction using Azure AutoML and JupyterLab</li>
			</ul>
			<p>Let's get started!</p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor086"/>AutoML in Microsoft Azure </h1>
			<p>AutoML is <a id="_idIndexMarker232"/>treated as a first-class citizen in the Azure platform. The fundamental ideas behind feature engineering, network<a id="_idIndexMarker233"/> architecture search, and hyperparameter tuning are the same as what we discussed in <a href="B16890_02_Final_VK_ePub.xhtml#_idTextAnchor049"><em class="italic">Chapter 2</em></a>, <em class="italic"> Automated Machine Learning, Algorithms, and Techniques</em>, and <a href="B16890_03_Final_VK_ePub.xhtml#_idTextAnchor058"><em class="italic">Chapter 3</em></a>, <em class="italic">Automated Machine Learning with Open Source Tools and Libraries</em>. However, the layer of abstraction that's used to democratize these skills makes them much more appealing to non-machine learning experts.</p>
			<p>The key principles of AutoML in the Azure platform are shown in the following diagram. User input such as datasets target metrics, and constraints (how long to run the job, what the allocated budget is for compute, and so on) drive the AutoML "engine", which completes iterations to find the best model and rank it according to the score of <strong class="bold">Training Success</strong>:</p>
			<div>
				<div id="_idContainer120" class="IMG---Figure">
					<img src="image/Figure_5.1_B16890.jpg" alt="Figure 5.1 – Azure AutoML workflow – how AutoML works &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.1 – Azure AutoML workflow – how AutoML works </p>
			<p>In this section, we'll provide a step-by-step walkthrough of the AutoML approach. In <a href="B16890_04_Final_VK_ePub.xhtml#_idTextAnchor076"><em class="italic">Chapter 4</em></a>, <em class="italic">Getting Started with Azure Machine Learning</em>, you saw the main page for Azure machine learning. There, we created a classification model and tested it using a notebook:</p>
			<div>
				<div id="_idContainer121" class="IMG---Figure">
					<img src="image/Figure_5.2_B16890.jpg" alt="Figure 5.2 – Azure Machine Learning portal &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.2 – Azure Machine Learning portal </p>
			<p>Now, let's explore how <a id="_idIndexMarker234"/>AutoML-based model development works when it comes to training and tuning <a id="_idIndexMarker235"/>a model:</p>
			<ol>
				<li>From the Azure portal, click on <strong class="bold">Automated ML</strong> | <strong class="bold">Start now</strong>. You will be taken to the following screen, where you can create a new Automated ML run: <div id="_idContainer122" class="IMG---Figure"><img src="image/Figure_5.3_B16890.jpg" alt="Figure 5.3 – Azure Machine Learning – Creating an Automated ML run&#13;&#10;"/></div><p class="figure-caption">Figure 5.3 – Azure Machine Learning – Creating an Automated ML run</p></li>
				<li>The first step of creating an automated ML run is selecting a dataset to work with. Here, you can either create your own dataset or – better yet – select an existing one from<a id="_idIndexMarker236"/> the repository of public datasets that Azure provides:<div id="_idContainer123" class="IMG---Figure"><img src="image/Figure_5.4_B16890.jpg" alt="Figure 5.4 – AutoML dataset selection page&#13;&#10;"/></div><p class="figure-caption">Figure 5.4 – AutoML dataset selection page</p></li>
				<li>A dataset can be <a id="_idIndexMarker237"/>created from open datasets. In this case, we will use our tried and tested MNIST dataset to create the AutoML run, as shown in the following screenshot: <p class="callout-heading">MNIST dataset</p><p class="callout">Yann LeCun (Courant Institute, NYU) and Corinna Cortes (Google Labs, New York) hold the copyright for MNIST dataset, which is a derivative work from the original NIST datasets. The MNIST dataset has been made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license.</p></li>
			</ol>
			<div>
				<div id="_idContainer124" class="IMG---Figure">
					<img src="image/Figure_5.5_B16890.jpg" alt="Figure 5.5 – The Create dataset from Open Datasets page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.5 – The Create dataset from Open Datasets page</p>
			<p>Once you have<a id="_idIndexMarker238"/> selected the dataset, it will appear<a id="_idIndexMarker239"/> as part of your run, and you can also preview it. Apart from specifying the dataset's version, you can also specify if you would like to use the entire dataset, or whether it should be registered as a tabular data source or a file type data source:</p>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="image/Figure_5.6_B16890.jpg" alt="Figure 5.6 – Dataset from the Azure Machine Learning dataset repository of curated datasets&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.6 – Dataset from the Azure Machine Learning dataset repository of curated datasets</p>
			<p>Upon selecting <strong class="bold">Create</strong>, you will see the following screen as the dataset becomes part of your run: </p>
			<div>
				<div id="_idContainer126" class="IMG---Figure">
					<img src="image/Figure_5.7_B16890.jpg" alt="Figure 5.7 – Dataset from the Azure Machine Learning dataset repository of curated datasets&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.7 – Dataset from the Azure Machine Learning dataset repository of curated datasets</p>
			<p>The MNIST dataset can also be<a id="_idIndexMarker240"/> seen as part of the data preview if <a id="_idIndexMarker241"/>you click on the dataset's name, as shown in the following screenshot: </p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="image/Figure_5.8_B16890.jpg" alt="Figure 5.8 – Preview of the dataset from the Azure Machine Learning dataset repository of curated datasets&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.8 – Preview of the dataset from the Azure Machine Learning dataset repository of curated datasets</p>
			<p>Let's face it – this preview of the MNIST pixel dataset isn't that exciting, but if you had some more representative data (healthcare, retail, or financial data, and so on), the preview would help us understand that the ingestion process went well and that we are not running the risk of a delimiter fiasco. </p>
			<p>Similarly, the data statistics are shown in the following screenshot. If you are pandas-inclined, think of it as the <strong class="source-inline">describe()</strong> feature. Due to its image-based nature, this isn't quite as<a id="_idIndexMarker242"/> relevant, but when it comes to some of the other datasets we will use later in this chapter, it comes in quite handy:</p>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/Figure_5.9_B16890.jpg" alt="Figure 5.9 – Preview of the data statistics in Azure AutoML&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.9 – Preview of the data statistics in Azure AutoML</p>
			<ol>
				<li value="1">Now that we<a id="_idIndexMarker243"/> have selected the dataset, we can configure the run by providing the experiment's name, target column (the labeled feature to train on and classify), and the compute cluster, as shown in the following screenshot: <div id="_idContainer129" class="IMG---Figure"><img src="image/Figure_5.10_B16890.jpg" alt="Figure 5.10 – Configuring an AutoML run&#13;&#10;"/></div><p class="figure-caption">Figure 5.10 – Configuring an AutoML run</p></li>
				<li>The third and<a id="_idIndexMarker244"/> final step is to select the task type – classification, regression, or time series forecasting. In this case, we are <a id="_idIndexMarker245"/>classifying digits based on their associated labels. You will learn how to use the other task types in future examples: <div id="_idContainer130" class="IMG---Figure"><img src="image/Figure_5.11_B16890.jpg" alt="Figure 5.11 – Selecting the task type for the AutoML run&#13;&#10;"/></div><p class="figure-caption">Figure 5.11 – Selecting the task type for the AutoML run</p></li>
				<li>It is important to consider the additional configurations. Here, you can select a primary metric, its<a id="_idIndexMarker246"/> explainability, any allowed <a id="_idIndexMarker247"/>algorithms (by default, all of them are allowed), the exit criteria, and any validation split information, as shown in the following screenshot: <div id="_idContainer131" class="IMG---Figure"><img src="image/Figure_5.12_B16890.jpg" alt="Figure 5.12 – Additional configuration for the task type of the AutoML run&#13;&#10;"/></div><p class="figure-caption">Figure 5.12 – Additional configuration for the task type of the AutoML run</p><p>Additional configuration varies based on the task's type. The following screenshot shows the regression configuration elements:</p><div id="_idContainer132" class="IMG---Figure"><img src="image/Figure_5.13_B16890.jpg" alt="Figure 5.13 – Additional configuration for the task type of the AutoML run&#13;&#10;"/></div><p class="figure-caption">Figure 5.13 – Additional configuration for the task type of the AutoML run</p><p><strong class="bold">Featurization</strong> – that is, selecting<a id="_idIndexMarker248"/> and transforming features – is an important factor to keep in mind as you move forward with the dataset. When you click on the <strong class="bold">View Featurization Settings</strong> link, Azure <a id="_idIndexMarker249"/>machine learning provides you<a id="_idIndexMarker250"/> with the following screen. From here, you can select the feature's type, assign a specific data type, and specify what you wish to impute the feature with:</p><div id="_idContainer133" class="IMG---Figure"><img src="image/Figure_5.14_B16890.jpg" alt="Figure 5.14 – Featurization of the AutoML run&#13;&#10;"/></div><p class="figure-caption">Figure 5.14 – Featurization of the AutoML run</p><p><strong class="bold">Automatic featurization</strong> – that is, turning <a id="_idIndexMarker251"/>different data types into numerical vectors – is a typical part of any data science workflow. The following diagram shows the techniques that are applied automatically to the datasets when featurization is turned on (see the blue toggle at the top of the preceding screenshot). The following diagram shows some of the key steps that are taken during auto-featurization. You can find <a id="_idIndexMarker252"/>out more about enumerated featurization techniques at <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features</a>:</p><div id="_idContainer134" class="IMG---Figure"><img src="image/Figure_5.15_B16890.jpg" alt="Figure 5.15 – Featurization approaches for the AutoML run&#13;&#10;"/></div><p class="figure-caption">Figure 5.15 – Featurization approaches for the AutoML run</p><p><strong class="bold">Scaling</strong><strong class="bold"><a id="_idIndexMarker253"/></strong> and <strong class="bold">normalization</strong> (also sometimes <a id="_idIndexMarker254"/>referred to as <strong class="bold">regulariza<a id="_idTextAnchor087"/>tion</strong> and <strong class="bold">standaridization</strong>) are two important ways of featurization<a id="_idIndexMarker255"/> that deal with <a id="_idIndexMarker256"/>transforming data into a common range of <a id="_idIndexMarker257"/>values. The scaling and normalization <a id="_idIndexMarker258"/>techniques that are used in the automatic featurization algorithms can be seen in the following diagram. You can find out more about various enumerated scaling and featurization techniques at <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features</a>:</p><p> </p><div id="_idContainer135" class="IMG---Figure"><img src="image/Figure_5.16_B16890.jpg" alt="Figure 5.16 – Azure AutoML – scaling and featurization&#13;&#10;"/></div><p class="figure-caption">Figure 5.16 – Azure AutoML – scaling and featurization</p><p>The topic of <a id="_idIndexMarker259"/>featurization is not complete without the mention of guardrails. Data guardrails are part of the AutoML engine <a id="_idIndexMarker260"/>which helps identify and address issues with the dataset such as missing feature values, handling high cardinality features (lots of unique values), class imbalance (minority classes and outliers) and so on. The following figure outlines these guardrails you should make yourself familiar <a id="_idIndexMarker261"/>with. You can read further details about these guardrails here in the Azure documentation (<a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-features</a>):</p><div id="_idContainer136" class="IMG---Figure"><img src="image/Figure_5.17_B16890.jpg" alt="Figure 5.17 – Data guardrails for the AutoML run&#13;&#10;"/></div><p class="figure-caption">Figure 5.17 – Data guardrails for the AutoML run</p></li>
				<li>Now, when you click the <strong class="bold">Finish</strong> button, as shown in <em class="italic">Figure 5.10</em>, after setting up the given <a id="_idIndexMarker262"/>parameters for the task type and <a id="_idIndexMarker263"/>any additional configuration items, you will see the following screen, which validates the run: <div id="_idContainer137" class="IMG---Figure"><img src="image/Figure_5.18_B16890.jpg" alt="Figure 5.18 – Data guardrails for the AutoML run&#13;&#10;"/></div><p class="figure-caption">Figure 5.18 – Data guardrails for the AutoML run</p><p>One important point to keep in mind is that you need to have good compute resources to run an experiment; otherwise, it will fail. For example, in this experiment, I have set the training time to 0.25 hours; that is, 15 minutes. This is not enough time<a id="_idIndexMarker264"/> for the given compute, which <a id="_idIndexMarker265"/>means the run is bound to fail, as shown in the following screenshot: </p><div id="_idContainer138" class="IMG---Figure"><img src="image/Figure_5.19_B16890.jpg" alt="Figure 5.19 – AutoML experiment run settings&#13;&#10;"/></div><p class="figure-caption">Figure 5.19 – AutoML experiment run settings</p><p>The following screenshot shows that since we didn't allocate the right computing resources to run the AutoML experiment, it failed:</p><div id="_idContainer139" class="IMG---Figure"><img src="image/Figure_5.20_B16890.jpg" alt="Figure 5.20 – AutoML experiment run failure message&#13;&#10;"/></div><p class="figure-caption">Figure 5.20 – AutoML experiment run failure message</p><p>The following error <a id="_idIndexMarker266"/>message explains the user<a id="_idIndexMarker267"/> error in detail, along with potential solutions, such as adding compute resources, applying an experiment timeout, and making dataset sampling changes:</p><div id="_idContainer140" class="IMG---Figure"><img src="image/Figure_5.21_B16890.jpg" alt="Figure 5.21 – AutoML experiment run failure message&#13;&#10;"/></div><p class="figure-caption">Figure 5.21 – AutoML experiment run failure message</p><p>Increasing the time limit to 5 hours will help, as you will see in the following steps. Azure<a id="_idIndexMarker268"/> AutoML has now had enough time and enough resources to execute multiple experiments. This<a id="_idIndexMarker269"/> has taught you that cheapening out on time and/or resources isn't a good AutoML strategy.</p></li>
				<li>The following screen in the AutoML child run shows individual iterations. It clearly demonstrates how different data preprocessing methods, such as <strong class="source-inline">StandardScalerWrapper</strong>, <strong class="source-inline">RobustScaler</strong>, and <strong class="source-inline">MaxAbsScaler</strong>/<strong class="source-inline">MinMaxScaler</strong>, and forecasting algorithms, such as <strong class="source-inline">RandomForest</strong>, <strong class="source-inline">LightGB</strong>, <strong class="source-inline">ElasticNet</strong>, <strong class="source-inline">DecisionTree</strong>, and <strong class="source-inline">LassoLars</strong>, were used. Runs <strong class="source-inline">54</strong> and <strong class="source-inline">53</strong> in the following screenshot show how ensemble algorithms and their weights can be viewed by clicking on their associated tags:<div id="_idContainer141" class="IMG---Figure"><img src="image/Figure_5.22_B16890.jpg" alt="Figure 5.22 – AutoML experiment run details&#13;&#10;"/></div><p class="figure-caption">Figure 5.22 – AutoML experiment run details</p></li>
				<li>Click on the <strong class="bold">Models</strong> tab to see which model provided what degree of accuracy and what run it is<a id="_idIndexMarker270"/> associated with, as shown in the<a id="_idIndexMarker271"/> following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer142" class="IMG---Figure">
					<img src="image/Figure_5.23_B16890.jpg" alt="Figure 5.23 – AutoML experiment run details&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.23 – AutoML experiment run details</p>
			<p>The run metrics are also a great way to get more detailed information about the associated run. For example, you can see the algorithm's name, the associated accuracy, AUC scores, precision, F1 score, and so on:</p>
			<div>
				<div id="_idContainer143" class="IMG---Figure">
					<img src="image/Figure_5.24_B16890.jpg" alt="Figure 5.24 – AutoML experiment run details &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.24 – AutoML experiment run details </p>
			<p>The data guardrail <a id="_idIndexMarker272"/>measures that are taken to protect the quality of the data can be seen by clicking on the corresponding<a id="_idIndexMarker273"/> tab, as shown in the following screenshot. This page shows what guardrail techniques have been used to ensure that the input data used to train the model was high quality:</p>
			<div>
				<div id="_idContainer144" class="IMG---Figure">
					<img src="image/Figure_5.25_B16890.jpg" alt="Figure 5.25 – AutoML experiment data guardrails&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.25 – AutoML experiment data guardrails</p>
			<p>From the main run summary page, you can view the best model and its summarized outcome. In this case, the soft voting-based <strong class="source-inline">VotingEnsemble()</strong> method was the clear winner. It is among two of the ensemble methods currently supported in Azure AutoML. The other one is <strong class="source-inline">StackEnsemble</strong>, which creates collections from previously run iterations. Ensemble methods are techniques that are used to combine <a id="_idIndexMarker274"/>multiple models to get the best <a id="_idIndexMarker275"/>results; voting, stacking, bagging, and boosting are some of the categories available for ensemble methods:</p>
			<div>
				<div id="_idContainer145" class="IMG---Figure">
					<img src="image/Figure_5.26_B16890.jpg" alt="Figure 5.26 – AutoML experiment summary page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.26 – AutoML experiment summary page</p>
			<p>Assuming you have followed these experiments so far and tried these steps by yourself, it should be evident that each run has several child runs – that is, individual iterations that each model has. So, when we look at the <strong class="bold">Metrics</strong> tab of the <strong class="bold">Run</strong> summary page, we not only see the different metrices, but also a precision recall plot:</p>
			<div>
				<div id="_idContainer146" class="IMG---Figure">
					<img src="image/Figure_5.27_B16890.jpg" alt="Figure 5.27 – AutoML experiment accuracy metrics and PR curve&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.27 – AutoML experiment accuracy metrics and PR curve</p>
			<p>Now, let's look at the <a id="_idIndexMarker276"/>explanations for the models. The explainability of machine learning models is super important, especially for AutoML. This is because you would like to know, as a subject matter<a id="_idIndexMarker277"/> expert, which features played a critical role in the result. In the following screenshot, you can see a tabular explanation of feature importance for the top <em class="italic">k </em>features, along with a breakdown of how they are used to predict digits from 0-9:</p>
			<div>
				<div id="_idContainer147" class="IMG---Figure">
					<img src="image/Figure_5.28_B16890.jpg" alt="Figure 5.28 – AutoML experiment explanation of features&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.28 – AutoML experiment explanation of features</p>
			<p>The preceding screenshot shows which feature played what part in predicting the digits. Feature 377 was significant in predicting digit 7, features 379 and 434 were significant in predicting 9, and so on and so forth. This MNIST dataset might not appear to be relevant to you, but let's imagine you are looking at an HR hiring dataset and gender, race, or age become an important feature. This would raise an alarm since this would go against your corporate policies of sexual bias, racism, or age-related discrimination. It would also likely be against the law and you could get in serious trouble in terms of compliance and reputational damage for having a bigot in the machine. Not to mention, it's unethical (and honestly nonsensical) to discriminate based on attributes that have nothing to do with an employee's capability to get the job done.</p>
			<p>This explainability <a id="_idIndexMarker278"/>also provides summary importance for <a id="_idIndexMarker279"/>features where you can visualize the importance of individual k-features for both global and local features. The swarm chart, shown in the following screenshot, visualizes the same data at a very granular level. It shows a one-to-one mapping between the number of elements in the MNIST dataset and the features they correspond to, similar to what's shown in the tabular representation in the preceding screenshot:</p>
			<div>
				<div id="_idContainer148" class="IMG---Figure">
					<img src="image/Figure_5.29_B16890.jpg" alt="Figure 5.29 – Azure Machine Learning top k features summary importance chart&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.29 – Azure Machine Learning top k features summary importance chart</p>
			<p>With this overview of automated ML for classification, let's move on and apply the same techniques to time series forecasting. </p>
			<h1 id="_idParaDest-79"><a id="_idTextAnchor088"/>Time series prediction using AutoML</h1>
			<p>Forecasting energy demand is a real problem in the industry where energy providers like to predict the consumer's expected needs<a id="_idIndexMarker280"/> in advance. In this example, we will use the New York City energy demand dataset, which is available in the public domain. We will use historic time series data and apply AutoML for forecasting; that is, predicting energy demand for the next 48 hours.</p>
			<p>The machine learning notebook is part of the Azure model repository, which can be accessed on GitHub at <a href="https://github.com/Azure/MachineLearningNotebooks/">https://github.com/Azure/MachineLearningNotebooks/</a>. Let's get started:</p>
			<ol>
				<li value="1">Clone the aforementioned GitHub repository on your local disk and navigate to the <strong class="source-inline">forecasting-energy-demand</strong> folder: <div id="_idContainer149" class="IMG---Figure"><img src="image/Figure_5.30_B16890.jpg" alt="Figure 5.30 – Azure Machine Learning notebooks GitHub repository&#13;&#10;"/></div><p class="figure-caption">Figure 5.30 – Azure Machine Learning notebooks GitHub repository</p></li>
				<li>Click on the <strong class="bold">Upload folder</strong> icon and upload the <strong class="source-inline">forecasting-energy-demand</strong> folder to the Azure notebook repository, as shown in the following screenshot: <div id="_idContainer150" class="IMG---Figure"><img src="image/Figure_5.31_B16890.jpg" alt="Figure 5.31 – Uploading a folder in the Azure Machine Learning notebook workspace&#13;&#10;"/></div><p class="figure-caption">Figure 5.31 – Uploading a folder in the Azure Machine Learning notebook workspace</p></li>
				<li>Once the folder has been<a id="_idIndexMarker281"/> uploaded (see the files in left-hand pane of the following screenshot), double-click on the, <strong class="source-inline">ipynb</strong> (notebook) file and open it. You will see the following screen:<div id="_idContainer151" class="IMG---Figure"><img src="image/Figure_5.32_B16890.jpg" alt="Figure 5.32 – Uploading files in the AutoML notebook workspace&#13;&#10;"/></div><p class="figure-caption">Figure 5.32 – Uploading files in the AutoML notebook workspace</p></li>
				<li>Now, open this in JupyterLab by clicking on the respective dropdown, as shown in the following screenshot. It is important to remember that even though you are running the files in JupyterLab, an<a id="_idIndexMarker282"/> automated ML experiment is being run in the Azure Machine Learning workspace, and you can always track and view every experiment there. This shows the power of seamless integration with third-party tools:<div id="_idContainer152" class="IMG---Figure"><img src="image/Figure_5.33_B16890.jpg" alt="Figure 5.33 – Uploading files in the AutoML notebook workspace and opening them in JupyterLab&#13;&#10;"/></div><p class="figure-caption">Figure 5.33 – Uploading files in the AutoML notebook workspace and opening them in JupyterLab</p><p>Now, the file is running in a very familiar environment, with the kernel being Python 3.6 – the Azure Machine Learning runtime. This seamless integration with notebooks is a powerful feature of Azure Machine Learning:</p><div id="_idContainer153" class="IMG---Figure"><img src="image/Figure_5.34_B16890.jpg" alt="Figure 5.34 – Uploading files in the AutoML notebook workspace and opening them in JupyterLab&#13;&#10;"/></div><p class="figure-caption">Figure 5.34 – Uploading files in the AutoML notebook workspace and opening them in JupyterLab</p><p>Since we are working with time series <a id="_idIndexMarker283"/>data, it is useful to note that Azure AutoML offers a variety of native time series as well as deep learning models to support time series-related analytical workloads. The following screenshot shows a list of these algorithms:</p><div id="_idContainer154" class="IMG---Figure"><img src="image/Figure_5.35_B16890.jpg" alt="Figure 5.35 – Azure AutoML time series capabilities&#13;&#10;"/></div><p class="figure-caption">Figure 5.35 – Azure AutoML time series capabilities</p><p>Azure automated ML comes with a <a id="_idIndexMarker284"/>variety of regression, classification, and time series forecasting algorithms and scoring mechanisms, and you can always add custom metrics. The following screenshot shows a list of Azure AutoML classification, regression, and time series forecasting algorithms and measures:</p><div id="_idContainer155" class="IMG---Figure"><img src="image/Figure_5.36_B16890.jpg" alt=" Figure 5.36 – Azure AutoML classification, regression, and time series forecasting algorithms&#13;&#10;"/></div><p class="figure-caption"> Figure 5.36 – Azure AutoML classification, regression, and time series forecasting algorithms</p><p>The following is a list of metrics<a id="_idIndexMarker285"/> that are used to measure the accuracy of the aforementioned methods: </p><div id="_idContainer156" class="IMG---Figure"><img src="image/Figure_5.37_B16890.jpg" alt="Figure 5.37 – Azure AutoML measures for classification, regression, and time series forecasting &#13;&#10;"/></div><p class="figure-caption">Figure 5.37 – Azure AutoML measures for classification, regression, and time series forecasting </p></li>
				<li>Skimming over the boilerplate setup<a id="_idIndexMarker286"/> code, we can set up the experiment by setting the target column to demand and the time column's name to be the timestamp. Once we've done this, the data is downloaded and made part of the pandas DataFrame, as shown in the following screenshot:<div id="_idContainer157" class="IMG---Figure"><img src="image/Figure_5.38_B16890.jpg" alt="Figure 5.38 – Azure AutoML data loading for the NYC power supply in the notebook&#13;&#10;"/></div><p class="figure-caption">Figure 5.38 – Azure AutoML data loading for the NYC power supply in the notebook</p></li>
				<li>Now, let's split up the data into training and testing sets:<div id="_idContainer158" class="IMG---Figure"><img src="image/Figure_5.39_B16890.jpg" alt="Figure 5.39 – Data split for the NYC power supply in the notebook&#13;&#10;"/></div><p class="figure-caption">Figure 5.39 – Data split for the NYC power supply in the notebook</p></li>
				<li>One of the key parameters<a id="_idIndexMarker287"/> you will have to set as part of this exercise is the forecast horizon; that is, how far in the future you would like to predict for. The automated ML algorithm is smart enough to know what unit to use (hour, days, or months) based on the time series frequency of your dataset. Based on our business problem, we will set the forecast horizon to <strong class="source-inline">48</strong> (hours) and submit the job, as shown in the following screenshot:<div id="_idContainer159" class="IMG---Figure"><img src="image/Figure_5.40_B16890.jpg" alt="Figure 5.40 – Creating the AutoML configuration for the forecasting job&#13;&#10;"/></div><p class="figure-caption">Figure 5.40 – Creating the AutoML configuration for the forecasting job</p></li>
				<li>Now that we have created the<a id="_idIndexMarker288"/> configuration, let's submit the experiment, as shown in the following screenshot:<div id="_idContainer160" class="IMG---Figure"><img src="image/Figure_5.41_B16890.jpg" alt="Figure 5.41 – Submitting the AutoML experiment to the remote server for execution&#13;&#10;"/></div><p class="figure-caption">Figure 5.41 – Submitting the AutoML experiment to the remote server for execution</p></li>
				<li>To demonstrate the integration of Jupyterlab with the Azure Machine Learning service, click on the <strong class="bold">Experiments</strong> tab in the ML service portal, as shown in the following screenshot. Here, you can see that the<a id="_idIndexMarker289"/> experiment has been submitted and is now prepared to run with the associated config for the AutoML parameters:<div id="_idContainer161" class="IMG---Figure"><img src="image/Figure_5.42_B16890.jpg" alt="Figure 5.42 – The experiment pane views for the AutoML experiment on the remote server&#13;&#10;"/></div><p class="figure-caption">Figure 5.42 – The experiment pane views for the AutoML experiment on the remote server</p><p>The AutoML config elements can also be observed as part of the notebook as you wait for the job to complete:</p><div id="_idContainer162" class="IMG---Figure"><img src="image/Figure_5.43_B16890.jpg" alt="Figure 5.43 – The notebook running the wait_for_completion() method after submitting the job&#13;&#10;"/></div><p class="figure-caption">Figure 5.43 – The notebook running the wait_for_completion() method after submitting the job</p></li>
				<li>This inherent integration between the<a id="_idIndexMarker290"/> notebook and the corresponding experiment can also be seen in the following screenshot. Here, we can see how the <strong class="bold">Experiment</strong> notebook is reflected in the experiment console: <div id="_idContainer163" class="IMG---Figure"><img src="image/Figure_5.44_B16890.jpg" alt="Figure 5.44 – The experiment from the notebook shown in the Experiments pane  in Azure Machine Learning"/></div><p class="figure-caption">Figure 5.44 – The experiment from the notebook shown in the Experiments pane in Azure Machine Learning </p><p>The algorithm's name and error details are outlined for each run and shows a consistent reduction in the error rate. Normalized RMSE and accuracy metrics for MNIST classification are shown int he following screenshot: </p><div id="_idContainer164" class="IMG---Figure"><img src="image/Figure_5.45_B16890.jpg" alt="Figure 5.45 – The experiment from the notebook shown in the Experiments pane in Azure Machine Learning &#13;&#10;"/></div><p class="figure-caption">Figure 5.45 – The experiment from the notebook shown in the Experiments pane in Azure Machine Learning </p><p>The data guardrails<a id="_idIndexMarker291"/> types are also notable. In the following screenshot, you can see that they are different from the guardrails we had in the classification exercise. In this case, the data is validated against frequency detection and missing feature value imputation. The AutoML engine is smart enough to learn what types of guardrails need to be applied for different types of experiments and datasets: </p><div id="_idContainer165" class="IMG---Figure"><img src="image/Figure_5.46_B16890.jpg" alt="Figure 5.46 – The guardrails for the Experiments pane in Azure Machine Learning &#13;&#10;"/></div><p class="figure-caption">Figure 5.46 – The guardrails for the Experiments pane in Azure Machine Learning </p></li>
				<li>Now that the experiment is complete, we can retrieve the best model in the notebook, as shown in the <a id="_idIndexMarker292"/>following screenshot (or in the machine learning service console, if you are visually inclined): <div id="_idContainer166" class="IMG---Figure"><img src="image/Figure_5.47_B16890.jpg" alt="Figure 5.47 – Model retrieval in the notebook&#13;&#10;"/></div><p class="figure-caption">Figure 5.47 – Model retrieval in the notebook</p></li>
				<li>You might recall deep feature search or automated feature engineering being introduced in the previous chapters. You can<a id="_idIndexMarker293"/> access and retrieve the engineered features from the notebook with the help of the following steps by calling the <strong class="source-inline">get_engineered_feature_names()</strong> method on the model:<div id="_idContainer167" class="IMG---Figure"><img src="image/Figure_5.48_B16890.jpg" alt="Figure 5.48 – Retrieving engineered features via get_engineered_feature_names &#13;&#10;"/></div><p class="figure-caption">Figure 5.48 – Retrieving engineered features via get_engineered_feature_names </p><p>Viewing the featurization summary for these features, both engineered and organic, provides you with the rationale that was used to build these features, as shown in the following screenshot:</p><div id="_idContainer168" class="IMG---Figure"><img src="image/Figure_5.49_B16890.jpg" alt="Figure 5.49 – Viewing the engineered features summary via get_featurization_summary()&#13;&#10;"/></div><p class="figure-caption">Figure 5.49 – Viewing the engineered features summary via get_featurization_summary()</p></li>
				<li>Using the scoring method, we can create the test scores and plot the predicted points on a chart, as shown in<a id="_idIndexMarker294"/> the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer169" class="IMG---Figure">
					<img src="image/Figure_5.50_B16890.jpg" alt="Figure 5.50 – Building a scatter plot for test data scores&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.50 – Building a scatter plot for test data scores</p>
			<p>The predicted data test scores are in blue, while the actual score is in green: </p>
			<p class="callout-heading">Note</p>
			<p class="callout">This image may be black and white to you. You will understand the color reference better when practically working on the example. </p>
			<div>
				<div id="_idContainer170" class="IMG---Figure">
					<img src="image/Figure_5.51_B16890.jpg" alt="Figure 5.51 – The test data scores and the associated plot &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.51 – The test data scores and the associated plot </p>
			<p><strong class="source-inline">X_trans</strong> captures the featurization, including the automatic feature engineering changes in the dataset, as <a id="_idIndexMarker295"/>shown in the following screenshot:</p>
			<div>
				<div id="_idContainer171" class="IMG---Figure">
					<img src="image/Figure_5.52_B16890.jpg" alt="Figure 5.52 – X_trans showing the time series features for energy forecasting&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.52 – X_trans showing the time series features for energy forecasting</p>
			<p>Even though the explainability of the MNIST dataset wasn't quite as intuitive, in terms of exploring the energy demand dataset, you can visualize different models and see which<a id="_idIndexMarker296"/> features have the most impact on the predicted usage. It is quite intuitive that temperature would have a positive correlation with the global importance of power usage. A higher temperature leads to a heavier usage of air conditioning, and hence higher power usage. The time of day and day of the week are also deemed important by the model, as shown in the following chart:</p>
			<div>
				<div id="_idContainer172" class="IMG---Figure">
					<img src="image/Figure_5.53_B16890.jpg" alt="Figure 5.53 – Global importance explainability graph&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.53 – Global importance explainability graph</p>
			<p>In the following screenshot, different explanation models (engineered features versus raw) map the result against the different predicted values of Y. Model explanation views help us understand which features directly impact the model:</p>
			<div>
				<div id="_idContainer173" class="IMG---Figure">
					<img src="image/Figure_5.54_B16890.jpg" alt="Figure 5.54 – Global importance explainability graph&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.54 – Global importance explainability graph</p>
			<p>This concludes our demonstration of time <a id="_idIndexMarker297"/>series prediction using AutoML in Azure. </p>
			<h1 id="_idParaDest-80"><a id="_idTextAnchor089"/>Summary</h1>
			<p>In this chapter, you learned how to apply AutoML in Azure to a classification problem and a time series prediction problem. You were able to build a model within the Azure Machine Learning environment with an Azure notebook and via JupyterLab. You then understood how the entire workspace relates to the experiments and runs. You also see the visualization during these automated runs; this is where feature importance, the global and local impact of features, and explanations based on raw and engineered features provide an intuitive understanding. Besides your affinity with a tool, it is also important that the platform aligns with your enterprise roadmap. Azure is an overall great platform with a comprehensive set of tools, and we hope you enjoyed exploring its automated ML capabilities.  </p>
			<h1 id="_idParaDest-81"><a id="_idTextAnchor090"/>Further reading</h1>
			<p>For more information on the topics that were covered in this chapter, please take a look at the following links:</p>
			<ul>
				<li>Azure AutoML:<p><a href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml">https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml</a></p></li>
				<li>Practical AutoML on Azure:<p><a href="https://github.com/PracticalAutomatedMachineLearning/Azure">https://github.com/PracticalAutomatedMachineLearning/Azure</a><span class="hidden"> </span></p></li>
			</ul>
		</div>
	</body></html>