<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Regression Model</h1>
                </header>
            
            <article>
                
<p>With our development environment configured and our first ML.NET application completed, it is now time to dive into regression models. In this chapter, we will dive into the math behind regression models, as well as the various applications of regression models. We will also build two additional ML.NET applications, one utilizing a linear regression model and the other a logistic regression model. The linear regression application will predict employee attrition based on various employee attributes. The logistic regression application will perform basic static file analysis on a file to determine whether it is malicious or benign. Finally, we will explore how to evaluate a regression model with the properties ML.NET exposes in regression models.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Breaking down various regression models</li>
<li>Creating the linear regression application</li>
<li>Creating the logistic regression application</li>
<li>Evaluating a regression model</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Breaking down regression models</h1>
                </header>
            
            <article>
                
<p>While there are several regression model types available in the machine learning eco-system, there are two primary regression models groups: linear and logistic, both of which have rich implementations in ML.NET.</p>
<p>ML.NET provides the following linear regression trainers:</p>
<ul>
<li><kbd>FastTreeRegressionTrainer</kbd></li>
<li><kbd>FastTreeTweedieTrainer</kbd></li>
<li><kbd>FastForestRegressionTrainer</kbd></li>
<li><kbd>GamRegressionTrainer</kbd></li>
</ul>
<ul>
<li><kbd>LbfgsPoissonRegressionTrainer</kbd></li>
<li><kbd><span>LightGbmRegressionTrainer</span></kbd></li>
<li><kbd>OlsTrainer</kbd></li>
<li><kbd>OnlineGradientDescentTrainer</kbd></li>
<li><kbd>SdcaRegressionTrainer</kbd></li>
</ul>
<p><span>The employee attrition application we will be creating later in this chapter utilizes the linear regression SDCA trainer.</span></p>
<p>In addition, <span>ML.NET provides</span> the following binary logistic regression trainers:</p>
<ul>
<li><kbd>LbfgsLogisticRegressionBinaryTrainer</kbd></li>
<li><kbd>SdcaLogisticRegressionBinaryTrainer</kbd></li>
<li><kbd>SdcaNonCalibratedBinaryTrainer</kbd></li>
<li><kbd>SymbolicSgdLogisticRegressionBinaryTrainer</kbd></li>
</ul>
<p>For the file classification application, we will be utilizing the <kbd>SDCALogisticRegressionBinaryTrainer</kbd> model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Choosing the type of regression model</h1>
                </header>
            
            <article>
                
<p>With all of these options, how do you choose the right type of regression model?</p>
<p>The type of regression model you choose depends on what your expected output is. If you are looking for just a Boolean (that is, 0 or 1) value, logistic regression models should be used like in the file classification application we will be writing later in this chapter. In addition, if you are looking to return a specific pre-defined range of values, perhaps a car type such as coupe, convertible, or hatchback, a logistic regression model is the correct model to choose from. </p>
<p>Conversely, linear regression models return a numeric value, such as the employment duration example we will explore later in this chapter. </p>
<p>So, to summarize, we have the following:</p>
<ul>
<li>If your output is a Boolean value, use a logistic regression model.</li>
<li>If your output is comprised of a preset range type of values (akin to an enumeration), use a logistic regression model.</li>
<li>If your output is a numeric unknown value, use a linear regression model.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Choosing a linear regression trainer</h1>
                </header>
            
            <article>
                
<p>When looking at the list of nine linear regression trainers ML.NET, it can be a bit daunting to ask which is the best.</p>
<p>For ML.NET linear regression trainers, by and large, the most popular are FastTree and LightGBM. <span>The three FastTree algorithms utilize neighbor-joining and use heuristics to quickly identify candidate joins to build out a decision tree. </span><span>LightGBM is a very popular linear regression algorithm that utilizes a <strong>Gradient-based One Side Sampling</strong> (<strong>GOSS</strong>) to filter out the data instances for finding a split value. Both trainers provide both quick training and predict times while also providing very accurate model performance. Also, more documentation, papers, and research are available with both of these algorithms.</span></p>
<div class="packt_infobox">The remaining five trainers are useful and worth a deep dive for experimentation, but overall you will likely find equal or greater success with LightGBM and FastTree.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Choosing a logistic regression trainer</h1>
                </header>
            
            <article>
                
<p>Given the four logistic regression trainers available in ML.NET, which is the best for your problem? Whilst all four regression trainers return a binary classification, they are optimized for different datasets and workloads.</p>
<p>Are you looking to train and predict in a low memory environment? If so, the L-BFGS logistic regression trainer (<kbd>LbfgsLogisticRegressionBinaryTrainer</kbd>) is a logical choice given that it was created to handle memory-restricted environments.</p>
<p>Both of the SDCA-based trainers—<kbd>SdcaLogisticRegressionBinaryTrainer</kbd> and <kbd>SdcaNonCalibratedBinaryTrainer</kbd><span>—</span>have been optimized for scalability in training. If your training set is large and you are looking for binary classification, either of the SDCA trainers would be a good choice.</p>
<p>The <kbd>SymbolicSgdLogisticRegressionBinaryTrainer</kbd> model is different from the other three in that it is based on a <span>stochastic g</span>radient descent algorithm. This means rather than looking to maximize the error function, the algorithm looks to minimize the error function.</p>
<div class="packt_infobox">If you are curious to expand your knowledge of SCDAs and in particular how Microsoft Research experimented with scaling SCDAs, give this white paper a read: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/main-3.pdf">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/main-3.pdf</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the linear regression application</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, the application we will be creating is an employee attrition predictor. Given a set of attributes tied to an employee, we can predict how long they will remain at their current job. The attributes included in this example aren't a definitive list of attributes, nor should be used as-is in a production environment; however, we can use this as a starting point for predicting a singular numeric output based on several attributes.</p>
<div class="packt_infobox">As with <a href="b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml">Chapter 1</a>, <em>Getting Started with Machine Learning and ML.NET</em>, the completed project code, sample dataset, and project files can be downloaded here: <a href="https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_linear_regression">https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_linear_regression</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Diving into the trainer</h1>
                </header>
            
            <article>
                
<p>As previously mentioned, for this linear regression application, we will be using the SDCA trainer. <strong>SDCA</strong> stands for <strong>Stochastic Dual Coordinate Ascent</strong> and if you may recall, we used the logistic regression version of this trainer in the<span> </span><span>example in</span><span> <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter 2</a>, <em>Setting Up the ML.NET Environment</em>.</span></p>
<p>To the average reader, all four words that comprise SDCA might be unknown, so let's break down what each means to give better clarity to what happens when you utilize an SDCA trainer. Starting with <em>Stochastic</em>, which, in other words, means unpredictability. And in the case of machine learning, it means attempting to <span>probabilistically </span>predict the error function and feed random samples from your training set into the optimizer. The use of <em>Dual Coordinate</em> means two variables are coupled when training the model. As you have probably guessed, this makes the model much more complex but doesn't require any extra work to be utilized. Lastly, <em>Ascent</em> refers to maximizing the value of the error function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring the project architecture</h1>
                </header>
            
            <article>
                
<p>Building on the project architecture and code we created in <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter 2</a>, <em>Setting Up the ML.NET Environment</em>, the major change architecturally in this example is the mechanism for input. <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter 2</a>, <em>Setting Up the ML.NET Environment</em>,<strong> </strong>used a simple string to provide sentiment analysis via a command-line argument. In this application, there are several properties to pass into the model; therefore, for this application, we are now using a JSON file to contain our input data. With this addition, we are now including the popular <kbd>Newtonsoft.Json</kbd> NuGet package (version 12.0.2 is the latest at the time of this writing and what is used in the included sample). If you are building this project from scratch and do not remember how to add a NuGet reference, please refer back to <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter 2</a>, <em>Setting Up the ML.NET Environment</em>. </p>
<p>The following screenshot shows the Visual Studio Solution Explorer view of the project. The new addition to the solution is the <kbd>ExtensionMethods</kbd> class file, which we will review in the next section: </p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-581 image-border" src="assets/9759fb4f-f8f5-4bb0-93db-cd76f0ff7971.png" style="width:22.00em;height:25.08em;"/></p>
<p>The <kbd>sampledata.csv</kbd> file contains 40 rows of random data; feel free to adjust the data to fit your own observations or to adjust the trained model. Here is a snippet of the data:</p>
<pre>16,1,1,0,20,38,1,1,1<br/>23,1,1,1,17,36,0,1,0<br/>6,1,1,0,10,30,1,0,1<br/>4,0,1,0,6,26,1,0,1<br/>14,0,0,0,4,27,1,0,1<br/>24,1,1,1,14,30,1,0,1<br/>5,1,1,0,8,31,0,1,1<br/>12,1,1,0,20,50,0,1,1<br/>12,1,1,0,12,50,1,0,1<br/>6,1,1,0,10,52,0,1,1</pre>
<p>Each of these rows contains the value for the properties in the newly created <kbd>EmploymentHistory</kbd> class that we will review later on in this chapter.</p>
<div class="packt_tip">If you want to use a larger dataset to train and expand this example, the website Kaggle offers a dataset created by IBM data scientists. This dataset is available here: <a href="https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset">https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Diving into the code</h1>
                </header>
            
            <article>
                
<p>For this application as noted, we are building on top of the work completed in <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter 2</a>, <em>Setting Up the ML.NET Environment</em>. For this deep dive, we are going to focus solely on the code that was changed for this application.</p>
<p>The classes that were changed or added are as follows:</p>
<ul>
<li><kbd>ExtensionMethods</kbd></li>
<li><kbd>EmploymentHistory</kbd></li>
<li><kbd>EmploymentHistoryPrediction</kbd></li>
<li><kbd>Predictor</kbd></li>
<li><kbd>Trainer</kbd></li>
<li><kbd>Program</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The ExtensionMethods class</h1>
                </header>
            
            <article>
                
<p>This newly added class provides an easy to use an extension method to return all of the properties in a class except the label.<strong> </strong>If you are unfamiliar with extension methods, these methods provide a very simple syntax to potentially provide complex actions on a single object, like in this case, where we take an arbitrary type and return all of the properties it contains (except for <kbd>labelName</kbd>):</p>
<pre>using System;<br/>using System.Linq;<br/><br/>namespace chapter03.Common<br/>{<br/>    public static class ExtensionMethods<br/>    {<br/>        public static string[] ToPropertyList&lt;T&gt;(this Type objType, string labelName) =&gt;                     objType.GetProperties().Where(a =&gt; a.Name != labelName).Select(a =&gt;                             a.Name).ToArray();<br/>    }<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The EmploymentHistory class</h1>
                </header>
            
            <article>
                
<p>The <kbd>EmploymentHistory</kbd> class is the container class that contains the data to both predict and train our model. These columns map in order for the sample data reviewed previously. If you begin experimenting with new features and add to this list, ensure you increment the array index appropriately:</p>
<pre>using Microsoft.ML.Data;<br/><br/>namespace chapter03.ML.Objects<br/>{<br/>    public class EmploymentHistory<br/>    {<br/>        [LoadColumn(0)]<br/>        public float DurationInMonths { get; set; }<br/>        <br/>        [LoadColumn(1)]<br/>        public float IsMarried { get; set; }<br/><br/>        [LoadColumn(2)]<br/>        public float BSDegree { get; set; }<br/><br/>        [LoadColumn(3)]<br/>        public float MSDegree { get; set; }<br/><br/>        [LoadColumn(4)]<br/>        public float YearsExperience { get; set; }<br/><br/>        [LoadColumn(5)]<br/>        public float AgeAtHire { get; set; }<br/><br/>        [LoadColumn(6)]<br/>        public float HasKids { get; set; }<br/><br/>        [LoadColumn(7)]<br/>        public float WithinMonthOfVesting { get; set; }<br/><br/>        [LoadColumn(8)]<br/>        public float DeskDecorations { get; set; }<br/><br/>        [LoadColumn(9)]<br/>        public float LongCommute { get; set; }<br/>    }<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The EmploymentHistoryPrediction class</h1>
                </header>
            
            <article>
                
<p>The <kbd>EmploymentHistoryPrediction</kbd> class contains only the prediction value of how many months the employee is projected to be at his or her job in the <kbd>DurationInMonths</kbd> property:</p>
<pre>using Microsoft.ML.Data;<br/><br/>namespace chapter03.ML.Objects<br/>{<br/>    public class EmploymentHistoryPrediction<br/>    {<br/>        [ColumnName("Score")]<br/>        public float DurationInMonths;<br/>    }<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Predictor class</h1>
                </header>
            
            <article>
                
<p>There are a couple of changes in this class to handle the employment prediction scenario:</p>
<ol>
<li>First, validate that the input file exists before making a prediction on it:</li>
</ol>
<pre style="padding-left: 60px">if (!File.Exists(inputDataFile))<br/>{<br/>    Console.WriteLine($"Failed to find input data at {inputDataFile}");<br/>    <br/>    return;<br/>}</pre>
<ol start="2">
<li>The other change is in the prediction call itself. As you probably guessed, the TSrc and TDst arguments need to be adjusted to utilize both of the new classes we created, <kbd>EmploymentHistory</kbd> and <kbd>EmploymentHistoryPrediction</kbd>:</li>
</ol>
<pre style="padding-left: 60px">var predictionEngine = MlContext.Model.CreatePredictionEngine&lt;EmploymentHistory, EmploymentHistoryPrediction&gt;(mlModel);</pre>
<ol start="3">
<li>Given that we are no longer simply passing in the string and building an object on the fly, we need to first read in the file as text. We then deserialize the JSON into our <kbd>EmploymentHistory</kbd> object:</li>
</ol>
<pre style="padding-left: 60px">var json = File.ReadAllText(inputDataFile);<br/><br/>var prediction = predictionEngine.Predict(JsonConvert.DeserializeObject&lt;EmploymentHistory&gt;(json));</pre>
<ol start="4">
<li>Lastly, we need to adjust the output of our prediction to match our new <kbd>EmploymentHistoryPrediction</kbd> properties:</li>
</ol>
<pre style="padding-left: 60px">Console.WriteLine(<br/> $"Based on input json:{System.Environment.NewLine}" +<br/> $"{json}{System.Environment.NewLine}" + <br/> $"The employee is predicted to work {prediction.DurationInMonths:#.##} months");</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Trainer class</h1>
                </header>
            
            <article>
                
<p>Inside the <kbd>Trainer</kbd> class, a large portion was rewritten to handle the expanded features used and to provide regression algorithm evaluation as opposed to the binary classification we looked at in <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter 2</a>, <em>Setting Up the ML.NET Environment</em>.</p>
<p>The first change is the use of a comma to separate the data as opposed to the default tab like we used in <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter 2</a>, <em>Setting Up the ML.NET Environment</em>:</p>
<pre>var trainingDataView = MlContext.Data.LoadFromTextFile&lt;EmploymentHistory&gt;(trainingFileName, ',');</pre>
<p>The next change is in the pipeline creation itself. In our first application, we had a label and fed that straight into the pipeline. With this application, we have nine features to predict the duration of a person's employment in the <kbd>DurationInMonths</kbd> property and append each one of them to the pipeline using the C# 6.0 feature, <kbd>nameof</kbd>. You might have noticed the use of magic strings to map class properties to features in various code samples on GitHub and MSDN; personally, I find this error-prone compared to the strongly typed approach.</p>
<p><span>For every property, we call the <kbd>NormalizeMeanVariance</kbd> transform method, which as the name implies normalizes the input data both on the mean and the variance. ML.NET computes this by subtracting the mean of the input data and dividing that value by the variance of the inputted data. The purpose behind this is to nullify outliers in the input data so the model isn't skewed to handle an edge case compared to the normal range. For example, suppose the sample dataset of employment history had 20 rows and all but one of those rows had a person with 50 years experience. The one row that didn't fit would be normalized to better fit within the ranges of values entered into the model.</span></p>
<p><span>In addition, note the use of the extension method referred to earlier to help to simplify the following code, when we concatenate all of the feature columns:</span></p>
<pre>var dataProcessPipeline = MlContext.Transforms.CopyColumns("Label", nameof(EmploymentHistory.DurationInMonths))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(nameof(EmploymentHistory.IsMarried)))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(nameof(EmploymentHistory.BSDegree)))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(nameof(EmploymentHistory.MSDegree)))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(nameof(EmploymentHistory.YearsExperience))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(nameof(EmploymentHistory.AgeAtHire)))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(nameof(EmploymentHistory.HasKids)))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(nameof(EmploymentHistory.WithinMonthOfVesting)))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(nameof(EmploymentHistory.DeskDecorations)))<br/> .Append(MlContext.Transforms.NormalizeMeanVariance(nameof(EmploymentHistory.LongCommute)))<br/> .Append(MlContext.Transforms.Concatenate("Features",<br/> typeof(EmploymentHistory).ToPropertyList&lt;EmploymentHistory&gt;(nameof(EmploymentHistory.DurationInMonths)))));</pre>
<p>We can then create the <kbd>Sdca</kbd> trainer using the default parameters (<kbd>"Label"</kbd> and <kbd>"Features"</kbd>):</p>
<pre>var trainer = MlContext.Regression.Trainers.Sdca(labelColumnName: "Label", featureColumnName: "Features");</pre>
<p>Lastly, we call the <kbd>Regression.Evaluate</kbd> method to provide regression specific metrics, followed by a <kbd>Console.WriteLine</kbd> call to provide these metrics to your console output. We will go into detail about what each of these means in the last section of this chapter:</p>
<pre>var modelMetrics = MlContext.Regression.Evaluate(testSetTransform);<br/><br/>Console.WriteLine($"Loss Function: {modelMetrics.LossFunction:0.##}{Environment.NewLine}" +<br/> $"Mean Absolute Error: {modelMetrics.MeanAbsoluteError:#.##}{Environment.NewLine}" +<br/> $"Mean Squared Error: {modelMetrics.MeanSquaredError:#.##}{Environment.NewLine}" +<br/> $"RSquared: {modelMetrics.RSquared:0.##}{Environment.NewLine}" +<br/> $"Root Mean Squared Error: {modelMetrics.RootMeanSquaredError:#.##}");</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Program class</h1>
                </header>
            
            <article>
                
<p>The only change in the <kbd>Program</kbd> class was the help text to indicate usage for predict requires a filename, not a string:</p>
<pre>if (args.Length != 2)<br/>{<br/>    Console.WriteLine($"Invalid arguments passed in, exiting.{Environment.NewLine}                    {Environment.NewLine}Usage:{Environment.NewLine}" +<br/>        $"predict &lt;path to input json file&gt;{Environment.NewLine}" +<br/>        $"or {Environment.NewLine}" +<br/>        $"train &lt;path to training data file&gt;{Environment.NewLine}");<br/><br/>        return;<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the application</h1>
                </header>
            
            <article>
                
<p>To run the application the process is nearly identical to Chapter 2's sample application. To iterate more quickly, the debug configuration automatically passes in the included <kbd>sampledata.csv</kbd> file as a command-line parameter:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-669 image-border" src="assets/f4d37e52-1dcc-4cca-8fd1-b899579f0d6a.png" style="width:68.00em;height:36.58em;"/></p>
<p>Going forward, due to the increasing complexity of the applications, all sample applications will have this preset:</p>
<ol>
<li>To run the training on the command line as we did in <a href="b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml">Chapter 1</a>, <em>Getting Started with Machine Learning and ML.NET,</em> simply pass in the following command (assuming you are using the included sample dataset):</li>
</ol>
<pre style="padding-left: 60px"><strong>PS chapter03\bin\Debug\netcoreapp3.0&gt; .\chapter03.exe train ..\..\..\Data\sampledata.csv</strong> <br/>Loss Function: 324.71<br/>Mean Absolute Error: 12.68<br/>Mean Squared Error: 324.71<br/>RSquared: 0.14<br/>Root Mean Squared Error: 18.02</pre>
<p style="padding-left: 60px">Note the expanded output to include several metric data points<span>—</span>we will go through what each one of these means at the end of this chapter.</p>
<ol start="2">
<li>After training the model, build a sample JSON file and save it as <kbd>input.json</kbd>:</li>
</ol>
<pre style="padding-left: 60px">{<br/>  "durationInMonths": 0.0,<br/>  "isMarried": 0,<br/>  "bsDegree": 1,<br/>  "msDegree": 1,<br/>  "yearsExperience": 2,<br/>  "ageAtHire": 29,<br/>  "hasKids": 0,<br/>  "withinMonthOfVesting": 0,<br/>  "deskDecorations": 1,<br/>  "longCommute": 1<br/>}</pre>
<ol start="3">
<li>To run the model with this file, simply pass in the filename to the built application and the predicted output will show:</li>
</ol>
<pre style="padding-left: 60px"><strong>PS chapter03\bin\Debug\netcoreapp3.0&gt; .\chapter03.exe predict input.json</strong> <br/>Based on input json:<br/>{<br/> "durationInMonths": 0.0,<br/> "isMarried": 0,<br/> "bsDegree": 1,<br/> "msDegree": 1,<br/> "yearsExperience": 2,<br/> "ageAtHire": 29,<br/> "hasKids": 0,<br/> "withinMonthOfVesting": 0,<br/> "deskDecorations": 1,<br/> "longCommute": 1<br/>}<br/><br/>The employee is predicted to work 22.82 months</pre>
<p>Feel free to modify the values and see how the prediction changes based on the dataset that the model was trained on.  A few areas of experimentation from this point might be to do the following:</p>
<ul>
<li>Add some additional features based on your own experience.</li>
<li>Modify <kbd>sampledata.csv</kbd> to include your team's experience.</li>
<li>Modify the sample application to have a GUI to make running predicts easier.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating the logistic regression application</h1>
                </header>
            
            <article>
                
<p>As mentioned earlier, the application we will be creating to demonstrate logistic regressions is a file classifier. Given a file (of any type), we extract the strings from the file. This is a very common approach to performing file classification although, like the previous example, this is often just an element of file classification, not the only component. Therefore, don't expect this to find the next zero-day piece of malware!</p>
<div class="packt_infobox">The completed project code, sample dataset, and project files can be downloaded here:<a href="https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_logistic_regression"> </a><a href="https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_logistic_regression">https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_logistic_regression</a><a href="https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter03_logistic_regression">.</a></div>
<p>The trainer used in this application also uses SDCA but using the logistic regression variation that was discussed earlier in this chapter.</p>
<p><span>As in the previous example, we will begin by exploring the project architecture, diving into the code, and then show how you can run the example to both train and predict.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring the project architecture</h1>
                </header>
            
            <article>
                
<p>Building on the project architecture and code we created in the previous example, the major change architecturally in this example is feature extraction. <span>With this example, we will add in the <kbd>FeatureExtractor</kbd> class in addition to creating new input and prediction classes. The reason for this is going back to the idea of keeping things separate and well defined as discussed in <a href="b8decd34-4bcb-4b1b-80d2-b2bfd0fa31c1.xhtml">Chapter 2</a>, <em>Setting Up the ML.NET Environment</em>. For this example application and future applications you may write, they, more than likely, will have input files to convert into rows of data. By having a separate class handle this part of the pipeline, you can encapsulate this functionality cleanly.</span></p>
<p>The following screenshot shows the Visual Studio Solution Explorer view of the project. The new addition to the solution is the <kbd>FeatureExtractor</kbd> class file that we will review in the next section:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c49ce931-dac3-4c89-a977-ada86e7ab1a7.png" style="width:15.42em;height:21.75em;"/></p>
<p>The <kbd>sampledata.csv</kbd> file contains eight rows of random data. Feel free to adjust the data to fit your own observations or adjust the trained model. Here is the included sample data:</p>
<pre>False<span> </span>!This program cannot be run in DOS mode.L$ SUVWH\$ UVWAVAWH\$ VWAVHWATAUAVAWHA_AA]A\_l$ VWAVHt<br/>False<span> </span>!This program cannot be run in DOS mode.L$ SUVWH\$ VWAVHUVWAVAWHUVWATAUAVAWHA_AA]A\_]UVWAVAWHU<br/>False<span> </span>!This program cannot be run in DOS mode.$7ckw7ckw7ckw&gt;jv$ckw7cjwiv6ckwRich7ckw9A98u6A9xx ATAVA<br/>False<span> </span>!This program cannot be run in DOS mode.EventSetInformationmshelp URL calledLaunchFwLink"mshelp<br/>True<span> </span>!This program cannot be run in DOS mode.Fm;Ld<span> </span>&amp;~_New_ptrt(M4_Alloc_max"uJIif94H3"j?TjV*?invalid<br/>True<span> </span>&lt;&lt;/Length 17268/Type/EmbeddedFile/Filter/FlateDecode/Params&lt;&lt;/ModDate(D:20191003012641+00'00'/Size<br/>True<span> </span>!This program cannot be run in DOS mode._New_ptr7(_MaskQAlloc_maxtEqx?$xjinvalid argumC:\Program F<br/>True<span> </span>__gmon_startN_easy_cKcxa_amxBZNSt8ios_bEe4IeD1Evxxe6naDtqv_Z&lt;4endlIcgLSaQ6appw3d_ResumeCXXABI_1.3%d</pre>
<p>Each of these rows contains two columns worth of data. The first is the classification, with true being malicious and false being benign. These properties are mapped in the newly created<span> </span><kbd>FileInput</kbd><span> </span>class that we will review later on in this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Diving into the code</h1>
                </header>
            
            <article>
                
<p>For this application as noted, we are building on top of the work completed earlier within this chapter. Again, for this deep dive, we are going to focus solely on the code that was changed for this application.</p>
<p>Classes that were changed or added are as follows:</p>
<ul>
<li><kbd>FeatureExtractor</kbd></li>
<li><kbd>FileInput</kbd></li>
<li><kbd>FilePrediction</kbd></li>
<li><kbd>BaseML</kbd></li>
<li><kbd>Predictor</kbd></li>
<li><kbd>Trainer</kbd></li>
<li><kbd>Program</kbd></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The FeatureExtractor class</h1>
                </header>
            
            <article>
                
<p>This newly added class provides our feature extraction for the given folder of files<strong>. </strong>Once extraction is complete, the classification and strings data is written out to the <kbd>sampledata</kbd> file:</p>
<pre>using System;<br/>using System.IO;<br/><br/>using chapter03_logistic_regression.Common;<br/>using chapter03_logistic_regression.ML.Base;<br/><br/>namespace chapter03_logistic_regression.ML<br/>{<br/>    public class FeatureExtractor : BaseML<br/>    {<br/>        public void Extract(string folderPath)<br/>        {<br/>            var files = Directory.GetFiles(folderPath);<br/><br/>            using (var streamWriter =<br/>                new StreamWriter(Path.Combine(AppContext.BaseDirectory, $"../../../Data/{Constants.SAMPLE_DATA}")))<br/>            {<br/>                foreach (var file in files)<br/>                {<br/>                    var strings = GetStrings(File.ReadAllBytes(file));<br/><br/>                    streamWriter.WriteLine($"{file.ToLower().Contains("malicious")}\t{strings}");<br/>                }<br/>            }<br/><br/>            Console.WriteLine($"Extracted {files.Length} to {Constants.SAMPLE_DATA}");<br/>        }<br/>    }<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The FileInput class</h1>
                </header>
            
            <article>
                
<p>The <kbd>FileInput</kbd> class provides the container for the trained classification and the strings data we extract:</p>
<pre>using Microsoft.ML.Data;<br/><br/>namespace chapter03_logistic_regression.ML.Objects<br/>{<br/>    public class FileInput<br/>    {<br/>        [LoadColumn(0)]<br/>        public bool Label { get; set; }<br/><br/>        [LoadColumn(1)]<br/>        public string Strings { get; set; }<br/>    }<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The FilePrediction class</h1>
                </header>
            
            <article>
                
<p>The <kbd>FilePrediction</kbd> class provides the container for the classification, probability, and score:</p>
<pre>using Microsoft.ML.Data;<br/><br/>namespace chapter03_logistic_regression.ML.Objects<br/>{<br/>    public class FilePrediction<br/>    {<br/>        [ColumnName("PredictedLabel")]<br/>        public bool IsMalicious { get; set; }<br/><br/>        public float Probability { get; set; }<br/><br/>        public float Score { get; set; }<br/>    }<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The BaseML class</h1>
                </header>
            
            <article>
                
<p>For the <kbd>BaseML</kbd> class, we have made several enhancements, starting with the constructor. In the constructor, we initialize the <kbd>stringRex</kbd> variable to the regular expression we will use to extract strings. <kbd>Encoding.RegisterProvider</kbd> is critical to utilize the Windows-1252 encoding. This encoding is the encoding Windows Executables utilize:</p>
<pre>private static Regex _stringRex;<br/><br/>protected BaseML()<br/>{<br/>    MlContext = new MLContext(2020);<br/><br/>    Encoding.RegisterProvider(CodePagesEncodingProvider.Instance);<br/><br/>    _stringRex = new Regex(@"[ -~\t]{8,}", RegexOptions.Compiled);<br/>}</pre>
<p>The next major addition is the <kbd>GetStrings</kbd> method. This method takes the bytes, runs the previously created compiled regular expression, and extracts the string matches:</p>
<ol>
<li>To begin, we define the method definition and initialize the <kbd>stringLines</kbd> variable to hold the strings:</li>
</ol>
<pre style="padding-left: 60px">protected string GetStrings(byte[] data)<br/>{<br/>    var stringLines = new StringBuilder();</pre>
<ol start="2">
<li>Next, we will sanity check the input data is not null or empty:</li>
</ol>
<pre style="padding-left: 60px">if (data == null || data.Length == 0)<br/>{<br/>    return stringLines.ToString();<br/>}</pre>
<ol start="3">
<li>The next block of code we open a <kbd>MemoryStream</kbd> object and then a <kbd>StreamReader</kbd> object:</li>
</ol>
<pre style="padding-left: 60px"> using (var ms = new MemoryStream(data, false))<br/> {<br/>     using (var streamReader = new StreamReader(ms, Encoding.GetEncoding(1252), false, 2048, false))<br/>     {</pre>
<ol start="4">
<li>We will then loop through the <kbd>streamReader</kbd> object until an <kbd>EndOfStream</kbd> condition is reached, reading line by line:</li>
</ol>
<pre style="padding-left: 60px">while (!streamReader.EndOfStream)<br/>{<br/>    var line = streamReader.ReadLine();</pre>
<ol start="5">
<li>We then will apply some string clean up of the data and handle whether the line is empty or not gracefully:</li>
</ol>
<pre style="padding-left: 60px">if (string.IsNullOrEmpty(line))<br/>{<br/>    continue;<br/>}<br/><br/>line = line.Replace("^", "").Replace(")", "").Replace("-", "");</pre>
<ol start="6">
<li>Then, we will append the regular expression matches and append those matches to the previously defined <kbd>stringLines</kbd> variable:</li>
</ol>
<pre style="padding-left: 60px">stringLines.Append(string.Join(string.Empty,<br/>                    _stringRex.Matches(line).Where(a =&gt; !string.IsNullOrEmpty(a.Value) &amp;&amp; !string.IsNullOrWhiteSpace(a.Value)).ToList()));</pre>
<ol start="7">
<li>Lastly, we will return the <kbd>stringLines</kbd> variable converted into a single string using the <kbd>string.Join</kbd> method:</li>
</ol>
<pre style="padding-left: 60px">    return string.Join(string.Empty, stringLines);<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Predictor class</h1>
                </header>
            
            <article>
                
<p>The <kbd>Predictor</kbd> class, much like what was changed in the linear regression example, is simply modified to support the new model and return the classification:</p>
<ol>
<li>We begin by passing in the two new classes, <kbd>FileInput</kbd> and <kbd>FilePrediction</kbd>,<strong> </strong>to the <kbd>CreatePredictionEngine</kbd> method:</li>
</ol>
<pre style="padding-left: 60px">var predictionEngine = MlContext.Model.CreatePredictionEngine&lt;FileInput, FilePrediction&gt;(mlModel);</pre>
<ol start="2">
<li>Next, we create the <kbd>FileInput</kbd> object, setting the <kbd>Strings</kbd> property with the return value of the <kbd>GetStrings</kbd> method we wrote earlier:</li>
</ol>
<pre style="padding-left: 60px">var prediction = predictionEngine.Predict(new FileInput<br/>{<br/>    Strings = GetStrings(File.ReadAllBytes(inputDataFile))<br/>});</pre>
<ol start="3">
<li>Finally, we update the output call to the <kbd>Console</kbd> object with our file classification and probability:</li>
</ol>
<pre style="padding-left: 60px">Console.WriteLine(<br/>                    $"Based on the file ({inputDataFile}) the file is classified as {(prediction.IsMalicious ? "malicious" : "benign")}" + <br/>                    $" at a confidence level of {prediction.Probability:P0}");</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Trainer class</h1>
                </header>
            
            <article>
                
<p>In the <kbd>Trainer</kbd> class, we will build a new pipeline to train our model. The <kbd>FeaturizeText</kbd> transform builds NGrams from the strings data we previously extracted from the files. <strong>NGrams</strong> are a popular method to create vectors from a string to, in turn, feed the model. You can think of NGrams as breaking a longer string into ranges of characters based on the value of the NGram parameter. A bi-gram, for instance, would take the following sentence, <em>ML.NET is great</em> and convert it into <em>ML-.N-ET-is-gr-ea-t</em>. Lastly, we build the <kbd>SdcaLogisticRegression</kbd> trainer object:</p>
<pre>var dataProcessPipeline = MlContext.Transforms.CopyColumns("Label", nameof(FileInput.Label))<br/> .Append(MlContext.Transforms.Text.FeaturizeText("NGrams", nameof(FileInput.Strings)))<br/> .Append(MlContext.Transforms.Concatenate("Features", "NGrams"));<br/><br/>var trainer = MlContext.BinaryClassification.Trainers.SdcaLogisticRegression(labelColumnName: "Label", featureColumnName: "Features");</pre>
<div class="packt_tip">For those looking to deep dive further into the <kbd>Transforms</kbd> Catalog API, check out the documentation from Microsoft here: <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transformscatalog?view=ml-dotnet">https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transformscatalog?view=ml-dotnet</a>.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Program class</h1>
                </header>
            
            <article>
                
<p>In the <kbd>Program</kbd> class, we added a third option to extract features and create the sample data <kbd>.tsv</kbd> file:</p>
<ol>
<li class="mce-root">To begin, we modify the help text to indicate the new extract option that takes a path to the training folder:</li>
</ol>
<pre style="padding-left: 60px">if (args.Length != 2)<br/>{<br/>    Console.WriteLine($"Invalid arguments passed in, exiting.{Environment.NewLine}{Environment.NewLine}Usage:{Environment.NewLine}" +<br/>                      $"predict &lt;path to input file&gt;{Environment.NewLine}" +<br/>                      $"or {Environment.NewLine}" +<br/>                      $"train &lt;path to training data file&gt;{Environment.NewLine}" + <br/>                      $"or {Environment.NewLine}" +<br/>                      $"extract &lt;path to folder&gt;{Environment.NewLine}");<br/><br/>    return;<br/>}</pre>
<ol start="2">
<li>In addition, we also need to modify the main switch/case to support the <kbd>extract</kbd> argument:</li>
</ol>
<pre style="padding-left: 60px">switch (args[0])<br/>{<br/>    case "extract":<br/>        new FeatureExtractor().Extract(args[1]);<br/>        break;<br/>    case "predict":<br/>        new Predictor().Predict(args[1]);<br/>        break;<br/>    case "train":<br/>        new Trainer().Train(args[1]);<br/>        break;<br/>    default:<br/>        Console.WriteLine($"{args[0]} is an invalid option");<br/>        break;<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Running the application</h1>
                </header>
            
            <article>
                
<p>With the addition of feature extraction in our pipeline, we first need to perform feature extraction on the files:</p>
<ol>
<li>Assuming the folder of files called <kbd>temp_data</kbd> exists, execute the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>PS chapter03-logistic-regression\bin\Debug\netcoreapp3.0&gt; .\chapter03-logistic-regression.exe extract temp_data  </strong>                                              <br/>Extracted 8 to sampledata.csv</pre>
<p style="padding-left: 60px">The output shows the count of extracted files and the output sample file.</p>
<ol start="2">
<li>To train the model using either the included <kbd>sampledata.csv</kbd> or one you trained yourself, execute the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>PS chapter03-logistic-regression\bin\Debug\netcoreapp3.0&gt; .\chapter03-logistic-regression.exe train ..\..\..\Data\sampledata.csv</strong></pre>
<p style="padding-left: 60px">The <kbd>chapter3.mdl</kbd> model file should exist in the folder executed in once complete.</p>
<ol start="3">
<li>To run the newly trained model against an existing file such as the compiled <kbd>chapter3</kbd> executable, run the following command:</li>
</ol>
<pre style="padding-left: 60px"><strong>PS chapter03-logistic-regression\bin\Debug\netcoreapp3.0&gt; .\chapter03-logistic-regression.exe predict .\chapter03-logistic-regression.exe       </strong>               <br/>Based on the file (.\chapter03-logistic-regression.exe) the file is classified as benign at a confidence level of 8%</pre>
<div class="packt_tip">If you are looking for sample files, the <kbd>c:\Windows</kbd> and <kbd>c:\Windows\System32</kbd> folders contain numerous Windows Executables and DLLs. In addition, if you are looking to create malicious-looking files that are actually clean, you can create files on the fly on <a href="http://cwg.io">http://cwg.io</a> in various file formats. This is a helpful tool in the cyber-security space where testing new functionality on a development machine is much safer than detonating real zero-day threats on!</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Evaluating a regression model</h1>
                </header>
            
            <article>
                
<p>As discussed in previous chapters, evaluating a model is a critical part of the overall model building process. A poorly trained model will only provide inaccurate predictions. Fortunately, ML.NET provides many popular attributes to calculate model accuracy based on a test set at the time of training to give you an idea of how well your model will perform in a production environment. </p>
<p>In ML.NET, as noted earlier in the linear regression sample application, there are five properties that comprise the <kbd>RegressionMetrics</kbd> class object. These include the following:</p>
<ul>
<li>Loss function</li>
<li>Mean absolute error</li>
<li>Mean squared error</li>
<li>R-squared</li>
<li>Root mean squared error</li>
</ul>
<p>In the next sections, we will break down how these values are calculated and ideal values to look for.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Loss function</h1>
                </header>
            
            <article>
                
<p class="mce-root">This property uses the loss function set when the regression trainer was initialized. In the case of our linear regression example application, we used the default constructor, which for SDCA is defaulted to the <kbd>SquaredLoss</kbd> class. </p>
<p>Other regression loss functions offered by ML.NET are the following:</p>
<ul>
<li><kbd>TweedieLoss</kbd> (used for Tweedie regression models)</li>
<li><kbd>PoissonLoss</kbd> (used for Poisson regression models)</li>
</ul>
<p>The idea behind this property is to allow some flexibility when it comes to evaluating your model compared to the other four properties that use fixed algorithms for evaluation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Mean squared error</h1>
                </header>
            
            <article>
                
<p><strong>Mean Squared Error</strong>, also known as <strong>MSE</strong>, is defined as the measure of the average of the squares of the errors. To put it simply, please refer to the following plot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-670 image-border" src="assets/fb4d71a8-e7cc-4b33-bb07-776c6e17aa3b.png" style="width:14.75em;height:14.75em;"/></p>
<p>The dots correlate to data points for our model, while the blue line is the prediction line. The distance between the red dots and the prediction line is the error. For MSE, the value is calculated based on these points and their distances to the line. From that value, the mean is calculated. For MSE, the smaller the value, the better fitting and more accurate predictions you will have with your model.</p>
<p>MSE is best used to evaluate models when outliers are critical to the prediction output.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Mean absolute error</h1>
                </header>
            
            <article>
                
<p><strong>Mean Absolute Error</strong>, also known as <strong>MAE</strong>, is similar to MSE, with the critical difference that it sums the distances between the points and the prediction lines as opposed to computing the mean. It should be noted, MAE does not take into account directions in calculating the sum. For instance, if you had two data points, equidistant from the line, one being above and the other below, in effect, this would be balanced out with a positive and negative value. In machine learning, this is referred to as mean bias error, however, ML.NET does not provide this as part of the <kbd>RegressionMetrics</kbd> class at the time of this writing.</p>
<p>MAE is best used to evaluate models when outliers are considered simply anomalies and shouldn't be counted in evaluating a model's performance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">R-squared</h1>
                </header>
            
            <article>
                
<p>R-squared, also called the coefficient of determination, is another method of representing how accurate the prediction is compared to the test set. R-squared is calculated by taking the sum of the distance between every data point and the mean squared, subtracting them and then squaring it.</p>
<p>R-squared values generally range between 0 and 1, represented as a floating-point value. A negative value can occur when the fitted model is evaluated to be worse than an average fit. However, a low number does not always reflect that the model is bad. Predictions such as the one we looked at in this chapter that is based on predicting human actions are often found to be under 50%. </p>
<p>Conversely, higher values aren't necessarily a sure sign of the model's performance, as this could be considered an overfitting of the model. This happens in cases when there are a lot of features fed to the model, thereby making the model more complex than, for instance, the model we built in <a href="b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml">Chapter 1</a>, <em>Getting Started with Machine Learning and ML.NET</em>, or there is simply not enough diversity in the training and test sets. For example, if all of the employees were roughly the same values, and the test set holdout was comprised of the same ranges of values, this would be considered overfitting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Root mean squared error</h1>
                </header>
            
            <article>
                
<p><strong>Root mean squared</strong> <strong>error</strong>, also known as <strong>RMSE</strong>, is arguably the easiest to understand given the previous methods. Take the following plot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-671 image-border" src="assets/a9168326-ca8b-49d0-b37b-614cfaf918c1.png" style="width:13.42em;height:13.17em;"/></p>
<p>In the case of testing the model as we did previously with the holdout set, the red dots are the actual values from the test set, while the blue dots are the predicted values. The <em>X</em><strong> </strong>depicted is the distance between the predicted and actual values. RMSE simply takes a mean of all of those distances, squares that value, and then takes the square root. </p>
<p>A value under 180 is generally considered a good model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Throughout this chapter, we looked into the differences between linear and logistic regression models. In addition, we reviewed when to choose linear or logistic models along with the trainers ML.NET provides. We also created and trained our first linear regression application using SDCA and ML.NET to predict employee attrition. We also created a logistic regression application using SDCA and ML.NET to provide file classification. Lastly, we also dove into how to evaluate a regression model and the various properties that ML.NET exposes to achieve a proper evaluation of your regression models.</p>
<p>In the next chapter, we will deep dive into binary classification algorithms.</p>


            </article>

            
        </section>
    </body></html>