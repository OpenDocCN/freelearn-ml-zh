- en: Chapter 9. Developing a Document Scanning App
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will build a document scanning app similar to Microsoft's
    Office Lens. This app could cause a huge increase in productivity. For example,
    you can write down notes on paper and then just click on the image of it, not
    worrying about aligning it with the device. Then, using some of the algorithms
    we learned in the earlier chapters, we can detect the page and just grab that
    portion of the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will directly jump on to the code, and we will see the
    outputs at every step. To get an idea of what we will achieve at the end of this
    chapter, let''s take a look at the following figure. The following image shows
    a screenshot of Microsoft''s Office Lens in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Developing a Document Scanning App](img/B02052_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let's begin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we need to set up our Android project just like how we did in the previous
    chapters. We will use the project ID `com.masteringopencvandroid.chapter9`. We
    won't be writing any C++ code for this app as this is not a very computationally
    intensive task that relies a lot on speed. However, if you require, this project
    can be done using the native C++ code, as we did in the previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will declare the required permissions in our `AndroidManifest.xml`
    file. We will require the camera permission and the permission to save the resulting
    image to the memory for this project. So, in the manifest tag, add the following
    lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will declare the activities that we have in our project. We need only
    one activity for the purpose of demonstration. We will call it `LensActivity`.
    So, we will add the following to our application tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will set up our layout file. We will call it `activity_lens.xml`.
    Our layout will have two buttons: one of which can be used to call the camera
    intent of the Android system and the other one will be used to choose an image
    from a file. Then, we will process the image that is returned by the system to
    detect and extract the page from the image. It will also have an `ImageView` tag
    to display the resulting image, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have our layout ready, we can dive deep into the Java code. In the
    next section, we will see a step-by-step explanation of the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, let's look at the steps we will take to achieve our results.
    Our first task is to detect the paper from the background. For this, we will apply
    the k-means algorithm with two cluster centers. With the two cluster centers,
    we can detect which one of them represents the page and which one corresponds
    to the background, and create a binary image.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will use the cluster representing the paper and try to remove some noise
    and fill in some gaps with morphological opening and closing using a rectangular
    kernel.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will try to find the outer boundary of the page and use it to detect
    the corners. For this, we will detect the contours in the binary image and then
    identify the contour with the largest area.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the largest contour, we will detect the lines using a probabilistic
    Hough transformation. Then, we will join the lines and detect the corners.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the corners, we will detect which corner corresponds to which other
    corner, and then apply a perspective transformation to get just the page from
    the whole image.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image shows the steps in the form of a flowchart for a quick
    reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The algorithm](img/B02052_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Some of the assumptions and limitations of this process are that the page has
    to be white in color and must also be easily distinguishable from the background.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing on Android
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open the `LensActivity.java` file. First, we will declare and initialize our
    `Button` and `ImageView`. Then, will add `onClickListener` to the button. We will
    call the `ImageCapture` intent, which will open the camera app to click on the
    image as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we will add the part where the result of these intent calls is received,
    by our activity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we have a function called `getScaleFactor`. Due to the limited
    memory and processing power of handheld devices, we will reduce our images at
    a maximum resolution of 240x320\. The `getPage` function is where our main algorithm
    is located. In this function, we have `AsyncTask` to perform our computations,
    so as to not block our UI thread and thereby preventing Android from crashing.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we will make our image in the desired form to perform a k-means
    clustering with two clusters. The intuition behind applying k-means is that the
    background and foreground will be quite distinct from the background and most
    of the area will be occupied by the page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will apply the k-means algorithm as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have the two cluster centers and the labels for each pixel in the original
    image. We will use the two cluster centers to detect which one corresponds to
    the paper. For this, we will find the Euclidian distance between the color of
    both the centers and the color pure white. The one which is closer to the color
    pure white will be considered as the foreground:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to define two Mat objects that we will use in the next step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will perform a segmentation where we will display all the foreground
    pixels as white and all the background pixels as black:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will move on to the next step; that is, detecting contours in this
    image. First, we will apply the Canny edge detector to detect just the edges and
    then apply a contouring algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We now make an assumption that the page occupies the biggest part of the foreground
    and so it corresponds to the biggest contour we find:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will detect the lines in this image, which contain only the biggest
    contours. We will try to find the point of intersection of these lines, and use
    this to detect the corners of the page in the image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The intersection point of the two lines made by joining the points (*x1*, *y1*)
    and (*x2*, *y2*) (forming the first line), and (*x3*, *y3*) and (*x4*, *y4*) (forming
    the second line) can be calculated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing on Android](img/B02052_09_03.jpg)![Implementing on Android](img/B02052_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: If the denominator is 0, we can say that the lines are parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have the intersection points, we will try to remove some of the redundant
    points. For this, we say that the points need to have at least a 10-pixel gap
    between them for them to be distinct. This number should be modified when modifying
    the resolution you are working with. To check this, we have added a function called
    `exists` as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will check whether we were able to detect the four corners perfectly.
    If not, the algorithm returns an error message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have detected the four corners, we will try to identify their locations
    on a quadrilateral. For this, we will compare the location of each corner with
    the center of the quadrilateral, which we obtain by taking the average of the
    coordinates of each of the corners:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have multiplied the scale factor of the corner values, as those will
    most likely be the location of the corners in the original image. Now, we just
    want the page in the resulting image. We need to determine the size of the resulting
    image. For this, we will use the coordinates of the corners calculated in the
    earlier step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we need to use a perspective transformation to warp the image in order
    to occupy the entire image. For this, we need to create reference corners, corresponding
    to each corner in the `corners` array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice how the elements in the corners are in the same order as they are in
    `result_pts`. This is required so as to perform a proper perspective transformation.
    Next, we will perform the perspective transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now that you have the resulting image with just the page in it, you can perform
    any more processing that is required by your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'All we need to do now is to display the resulting image in `ImageView`. In
    `onPostExecute`, add the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This ends our algorithm to segment out a page of paper from a scene and warp
    it to form a perfect rectangle. You can see the result of the algorithm on the
    images, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Implementing on Android](img/B02052_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The original image (L) and the resulting image (R)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw how we could use multiple computer vision algorithms
    to perform a bigger task and implemented a system similar to Microsoft's Office
    Lens. This algorithm can be extended and made better using better segmentation
    and corner detection algorithms. Also, once you have the page in the resulting
    image, you can apply machine learning algorithms to detect the text on the page.
  prefs: []
  type: TYPE_NORMAL
