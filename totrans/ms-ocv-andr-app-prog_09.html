<html><head></head><body><div class="chapter" title="Chapter&#xA0;9.&#xA0;Developing a Document Scanning App"><div class="titlepage"><div><div><h1 class="title"><a id="ch09"/>Chapter 9. Developing a Document Scanning App</h1></div></div></div><p>In this chapter, we will <a id="id413" class="indexterm"/>build a document scanning app similar to Microsoft's Office Lens. This app could cause a huge increase in productivity. For example, you can write down notes on paper and then just click on the image of it, not worrying about aligning it with the device. Then, using some of the algorithms we learned in the earlier chapters, we can detect the page and just grab that portion of the image.</p><p>In this chapter, we will directly jump on to the code, and we will see the outputs at every step. To get an idea of what we will achieve at the end of this chapter, let's take a look at the following figure. The following image shows a screenshot of Microsoft's Office Lens in action:</p><div class="mediaobject"><img src="graphics/B02052_09_01.jpg" alt="Developing a Document Scanning App"/></div><div class="section" title="Let's begin"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec46"/>Let's begin</h1></div></div></div><p>First, we need to<a id="id414" class="indexterm"/> set up our Android project just like how we did in the previous chapters. We will use the project ID <code class="literal">com.masteringopencvandroid.chapter9</code>. We won't be writing any C++ code for this app as this is not a very computationally intensive task that relies a lot on speed. However, if you require, this project can be done using the native C++ code, as we did in the previous chapters.</p><p>First, we will declare the required permissions in our <code class="literal">AndroidManifest.xml</code> file. We will require the camera permission and the permission to save the resulting image to the memory for this project. So, in the manifest tag, add the following lines:</p><div class="informalexample"><pre class="programlisting">&lt;uses-permission 
        android:name="android.permission.CAMERA"/&gt;
&lt;uses-permission
        android:name="android.permission.WRITE_EXTERNAL_STORAGE"/&gt;
        &lt;uses-permission
        android:name="android.permission.READ_EXTERNAL_STORAGE"/&gt;</pre></div><p>Now, we will declare the activities that we have in our project. We need only one activity for the purpose of demonstration. We will call it <code class="literal">LensActivity</code>. So, we will add the following to our application tag:</p><div class="informalexample"><pre class="programlisting">&lt;activity
    android:name=".LensActivity"
    android:label="@string/title_activity_lens"
    android:theme="@style/AppTheme"  &gt;
    &lt;intent-filter&gt;
        &lt;action android:name="android.intent.action.MAIN" /&gt;

        &lt;category android:name="android.intent.category.LAUNCHER" /&gt;
    &lt;/intent-filter&gt;
&lt;/activity&gt;</pre></div><p>Next, we will set up our layout file. We will call it <code class="literal">activity_lens.xml</code>. Our layout will have two buttons: one of which can be used to call the camera intent of the Android system and the other one will be used to choose an image from a file. Then, we will process the image that is returned by the system to detect and extract the page from the image. It will also have an <code class="literal">ImageView</code> tag to display the resulting image, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;ScrollView 
    android:layout_width="match_parent"
    android:layout_height="match_parent" &gt;
    &lt;LinearLayout android:orientation="vertical" android:layout_width="match_parent"
        android:layout_height="wrap_content"&gt;

        &lt;ImageView
            android:layout_width="match_parent"
            android:layout_height="0dp"
            android:layout_weight="0.5"
            android:id="@+id/ivImage" /&gt;
        &lt;LinearLayout
            android:layout_width="match_parent"
            android:layout_height="wrap_content"
            android:orientation="horizontal"&gt;
            &lt;Button
                android:layout_width="match_parent"
                android:layout_height="wrap_content"
                android:layout_weight="0.5"
                android:id="@+id/bClickImage"
                android:text="Click image"/&gt;
            &lt;Button
                android:layout_width="match_parent"
                android:layout_height="wrap_content"
                android:layout_weight="0.5"
                android:id="@+id/bLoadImage"
                android:text="Load image"/&gt;
        &lt;/LinearLayout&gt;

    &lt;/LinearLayout&gt;
&lt;/ScrollView&gt;</pre></div><p>Now that we<a id="id415" class="indexterm"/> have our layout ready, we can dive deep into the Java code. In the next section, we will see a step-by-step explanation of the algorithm.</p></div></div>
<div class="section" title="The algorithm"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec47"/>The algorithm</h1></div></div></div><p>In this <a id="id416" class="indexterm"/>section, let's look at the steps we will take to achieve our results. Our first task is to detect the paper from the background. For this, we will apply the k-means algorithm with two cluster centers. With the two cluster centers, we can detect which one of them represents the page and which one corresponds to the background, and create a binary image.</p><p>Now, we will use the cluster representing the paper and try to remove some noise and fill in some gaps with morphological opening and closing using a rectangular kernel.</p><p>Next, we will try to find the outer boundary of the page and use it to detect the corners. For this, we will detect the contours in the binary image and then identify the contour with the largest area.</p><p>Once we have the largest contour, we will detect the lines using a probabilistic Hough transformation. Then, we will join the lines and detect the corners.</p><p>Once we have the corners, we will detect which corner corresponds to which other corner, and then apply a perspective transformation to get just the page from the whole image.</p><p>The following image shows the steps in the form of a flowchart for a quick reference:</p><div class="mediaobject"><img src="graphics/B02052_09_02.jpg" alt="The algorithm"/></div><p>Some of<a id="id417" class="indexterm"/> the assumptions and limitations of this process are that the page has to be white in color and must also be easily distinguishable from the background.</p></div>
<div class="section" title="Implementing on Android"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec48"/>Implementing on Android</h1></div></div></div><p>Open<a id="id418" class="indexterm"/> the <code class="literal">LensActivity.java</code> file. First, we will declare and initialize our <code class="literal">Button</code> and <code class="literal">ImageView</code>. Then, will add <code class="literal">onClickListener</code> to the button. We will call the <code class="literal">ImageCapture</code> intent, which will open the camera app to click on the image as follows:</p><div class="informalexample"><pre class="programlisting">ivImage = (ImageView)findViewById(R.id.ivImage);
Button bClickImage, bLoadImage;

bClickImage = (Button)findViewById(R.id.bClickImage);
bLoadImage = (Button)findViewById(R.id.bLoadImage);

bClickImage.setOnClickListener(new View.OnClickListener() {
    @Override
    public void onClick(View v) {
        Intent intent = new 
        Intent(MediaStore.ACTION_IMAGE_CAPTURE);
        errorMsg = null;
        File imagesFolder = new File(FILE_LOCATION);
        imagesFolder.mkdirs();
        File image = new File(imagesFolder, "image_10.jpg");
        fileUri = Uri.fromFile(image);
        Log.d("LensActivity", "File URI = " + fileUri.toString());
        intent.putExtra(MediaStore.EXTRA_OUTPUT, fileUri); 

        // start the image capture Intent
        startActivityForResult(intent, CLICK_PHOTO);
    }
});        
bLoadImage.setOnClickListener(new View.OnClickListener() {
    @Override
    public void onClick(View v) {
        Intent intent = new Intent();
        intent.setType("image/*");
        intent.setAction(Intent.ACTION_GET_CONTENT);
        intent.addCategory(Intent.CATEGORY_OPENABLE);
        errorMsg = null;
        startActivityForResult(intent, LOAD_PHOTO);
    }
});</pre></div><p>Now we will <a id="id419" class="indexterm"/>add the part where the result of these intent calls is received, by our activity:</p><div class="informalexample"><pre class="programlisting">@Override
protected void onActivityResult(int requestCode, int 
  resultCode, Intent imageReturnedIntent) {
    super.onActivityResult(requestCode, resultCode, 
      imageReturnedIntent);

    Log.d("LensActivity", requestCode + " " + CLICK_PHOTO + " 
      " + resultCode + " " + RESULT_OK);

    switch(requestCode) {
        case CLICK_PHOTO:
            if(resultCode == RESULT_OK){
                try {
                    Log.d("LensActivity", fileUri.toString());
                    final InputStream imageStream = 
                      getContentResolver().
                      openInputStream(fileUri);
                    final Bitmap selectedImage = 
                      BitmapFactory.decodeStream(imageStream);
                    srcOrig = new Mat(selectedImage.
                      getHeight(), selectedImage.
                      getWidth(), CvType.CV_8UC4);
                    src = new Mat();
                    Utils.bitmapToMat(selectedImage, srcOrig);

                    scaleFactor = calcScaleFactor(
                      srcOrig.rows(), srcOrig.cols());

                    Imgproc.resize(srcOrig, src, new 
                      Size(srcOrig.rows()/scaleFactor, 
                      srcOrig.cols()/scaleFactor));
                    getPage();
                } catch (FileNotFoundException e) {
                    e.printStackTrace();
                }
            }
            break;
        case LOAD_PHOTO:
            if(resultCode == RESULT_OK){
                try {
                    InputStream stream = getContentResolver().
                      openInputStream(
                      imageReturnedIntent.getData());
                    final Bitmap selectedImage = 
                      BitmapFactory.decodeStream(stream);
                    stream.close();
                    ivImage.setImageBitmap(selectedImage);
                    srcOrig = new Mat(selectedImage.
                      getHeight(), selectedImage.
                      getWidth(), CvType.CV_8UC4);
                    Imgproc.cvtColor(srcOrig, srcOrig, 
                      Imgproc.COLOR_BGR2RGB);
                    Utils.bitmapToMat(selectedImage, srcOrig);
                    scaleFactor = calcScaleFactor(
                      srcOrig.rows(), srcOrig.cols());
                    src = new Mat();
                    Imgproc.resize(srcOrig, src, new 
                      Size(srcOrig.rows()/scaleFactor, 
                      srcOrig.cols()/scaleFactor));
                    Imgproc.GaussianBlur(src, src, 
                      new Size(5,5), 1);
                    getPage();
                } catch (FileNotFoundException e) {
                    e.printStackTrace();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            break;
    }
}
private static int calcScaleFactor(int rows, int cols){
    int idealRow, idealCol;
    if(rows&lt;cols){
        idealRow = 240;
        idealCol = 320;
    } else {
        idealCol = 240;
        idealRow = 320;
    }
    int val = Math.min(rows / idealRow, cols / idealCol);
    if(val&lt;=0){
        return 1;
    } else {
        return val;
    }
}</pre></div><p>As you can see, we <a id="id420" class="indexterm"/>have a function called <code class="literal">getScaleFactor</code>. Due to the limited memory and processing power of handheld devices, we will reduce our images at a maximum resolution of 240x320. The <code class="literal">getPage</code> function is where our main algorithm is located. In this function, we have <code class="literal">AsyncTask</code> to perform our computations, so as to not block our UI thread and thereby preventing Android from crashing.</p><p>First of all, we will make our image in the desired form to perform a k-means clustering with two clusters. The<a id="id421" class="indexterm"/> intuition behind applying k-means is that the background and foreground will be quite distinct from the background and most of the area will be occupied by the page:</p><div class="informalexample"><pre class="programlisting">Mat samples = new Mat(src.rows() * src.cols(), 3, CvType.CV_32F);
for( int y = 0; y &lt; src.rows(); y++ ) {
    for( int x = 0; x &lt; src.cols(); x++ ) {
        for( int z = 0; z &lt; 3; z++) {
            samples.put(x + y*src.cols(), z, src.get(y,x)[z]);
        }
    }
}</pre></div><p>Then, we will apply the k-means algorithm as follows:</p><div class="informalexample"><pre class="programlisting">int clusterCount = 2;
Mat labels = new Mat();
int attempts = 5;
Mat centers = new Mat();

Core.kmeans(samples, clusterCount, labels, new 
  TermCriteria(TermCriteria.MAX_ITER | 
  TermCriteria.EPS, 10000, 0.0001), attempts, 
  Core.KMEANS_PP_CENTERS, centers);</pre></div><p>Now, we have the two cluster centers and the labels for each pixel in the original image. We will use the two cluster centers to detect which one corresponds to the paper. For this, we will find the Euclidian distance between the color of both the centers and the color pure white. The one which is closer to the color pure white will be considered as the foreground:</p><div class="informalexample"><pre class="programlisting">double dstCenter0 = calcWhiteDist(centers.get(0, 
  0)[0], centers.get(0, 1)[0], centers.get(0, 2)[0]);
double dstCenter1 = calcWhiteDist(centers.get(1, 
  0)[0], centers.get(1, 1)[0], centers.get(1, 2)[0]);
int paperCluster = (dstCenter0 &lt; dstCenter1)?0:1;

static double calcWhiteDist(double r, double g, double b){
    return Math.sqrt(Math.pow(255 - r, 2) + 
      Math.pow(255 - g, 2) + Math.pow(255 - b, 2));
}</pre></div><p>We need to define two Mat objects that we will use in the next step:</p><div class="informalexample"><pre class="programlisting">Mat srcRes = new Mat( src.size(), src.type() );
Mat srcGray = new Mat();</pre></div><p>Now, we will perform a segmentation where we will display all the foreground pixels as white and all the background pixels as black:</p><div class="informalexample"><pre class="programlisting">for( int y = 0; y &lt; src.rows(); y++ ) {
    for( int x = 0; x &lt; src.cols(); x++ )
    {
        int cluster_idx = (int)labels.get(x + y*src.cols(),0)[0];
        if(cluster_idx != paperCluster){
            srcRes.put(y,x, 0, 0, 0, 255);
        } else {
            srcRes.put(y,x, 255, 255, 255, 255);
        }
    }
}</pre></div><p>Now, we<a id="id422" class="indexterm"/> will move on to the next step; that is, detecting contours in this image. First, we will apply the Canny edge detector to detect just the edges and then apply a contouring algorithm:</p><div class="informalexample"><pre class="programlisting">Imgproc.cvtColor(src, srcGray, Imgproc.COLOR_BGR2GRAY);
Imgproc.Canny(srcGray, srcGray, 50, 150);
List&lt;MatOfPoint&gt; contours = new ArrayList&lt;MatOfPoint&gt;();
Mat hierarchy = new Mat();

Imgproc.findContours(srcGray, contours, hierarchy, 
  Imgproc.RETR_TREE, Imgproc.CHAIN_APPROX_SIMPLE);</pre></div><p>We now make an assumption that the page occupies the biggest part of the foreground and so it corresponds to the biggest contour we find:</p><div class="informalexample"><pre class="programlisting">int index = 0;
double maxim = Imgproc.contourArea(contours.get(0));

for (int contourIdx = 1; contourIdx &lt; contours.size(); 
  contourIdx++) {
    double temp;
    temp=Imgproc.contourArea(contours.get(contourIdx));
    if(maxim&lt;temp)
    {
        maxim=temp;
        index=contourIdx;
    }
}
Mat drawing = Mat.zeros(srcRes.size(), CvType.CV_8UC1);
Imgproc.drawContours(drawing, contours, index, new Scalar(255), 
  1);</pre></div><p>Now, we will<a id="id423" class="indexterm"/> detect the lines in this image, which contain only the biggest contours. We will try to find the point of intersection of these lines, and use this to detect the corners of the page in the image:</p><div class="informalexample"><pre class="programlisting">Mat lines = new Mat();
Imgproc.HoughLinesP(drawing, lines, 1, Math.PI/180, 70, 30, 10);

ArrayList&lt;Point&gt; corners = new ArrayList&lt;Point&gt;();
for (int i = 0; i &lt; lines.cols(); i++)
{
    for (int j = i+1; j &lt; lines.cols(); j++) {
        double[] line1 = lines.get(0, i);
        double[] line2 = lines.get(0, j);

        Point pt = findIntersection(line1, line2);
        Log.d("com.packtpub.chapter9", pt.x+" "+pt.y);
        if (pt.x &gt;= 0 &amp;&amp; pt.y &gt;= 0 &amp;&amp; pt.x &lt;= 
          drawing.cols() &amp;&amp; pt.y &lt;= drawing.rows()){
            if(!exists(corners, pt)){
                corners.add(pt);
            }
        }
    }
}

static Point findIntersection(double[] line1, double[] line2) {
    double start_x1 = line1[0], start_y1 = line1[1], 
      end_x1 = line1[2], end_y1 = line1[3], start_x2 = 
      line2[0], start_y2 = line2[1], end_x2 = line2[2], 
      end_y2 = line2[3];
    double denominator = ((start_x1 - end_x1) * (start_y2 - 
      end_y2)) - ((start_y1 - end_y1) * (start_x2 - end_x2));

    if (denominator!=0)
    {
        Point pt = new Point();
        pt.x = ((start_x1 * end_y1 - start_y1 * end_x1) * 
          (start_x2 - end_x2) - (start_x1 - end_x1) * 
          (start_x2 * end_y2 - start_y2 * end_x2)) / 
          denominator;
        pt.y = ((start_x1 * end_y1 - start_y1 * end_x1) * 
          (start_y2 - end_y2) - (start_y1 - end_y1) * 
          (start_x2 * end_y2 - start_y2 * end_x2)) / 
          denominator;
        return pt;
    }
    else
        return new Point(-1, -1);
}</pre></div><p>The intersection point of the two lines made by joining the points (<span class="emphasis"><em>x1</em></span>, <span class="emphasis"><em>y1</em></span>) and (<span class="emphasis"><em>x2</em></span>, <span class="emphasis"><em>y2</em></span>) (forming the first line), and (<span class="emphasis"><em>x3</em></span>, <span class="emphasis"><em>y3</em></span>) and (<span class="emphasis"><em>x4</em></span>, <span class="emphasis"><em>y4</em></span>) (forming the second line) can be calculated using the following formula:</p><div class="mediaobject"><img src="graphics/B02052_09_03.jpg" alt="Implementing on Android"/></div><div class="mediaobject"><img src="graphics/B02052_09_04.jpg" alt="Implementing on Android"/></div><p>If the denominator is 0, we can say that the lines are parallel.</p><p>Once we have the intersection points, we will try to remove some of the redundant points. For this, we say that the points need to have at least a 10-pixel gap between them for them to be distinct. This number should be modified when modifying the resolution you are working with. To check this, we have added a function called <code class="literal">exists</code> as shown here:</p><div class="informalexample"><pre class="programlisting">static boolean exists(ArrayList&lt;Point&gt; corners, Point pt){
    for(int i=0; i&lt;corners.size(); i++){
        if(Math.sqrt(Math.pow(corners.get(i).x-pt.x, 
          2)+Math.pow(corners.get(i).y-pt.y, 2)) &lt; 10){
            return true;
        }
    }
    return false;
}</pre></div><p>Now, we will check whether we were able to detect the four corners perfectly. If not, the algorithm returns an error message:</p><div class="informalexample"><pre class="programlisting">if(corners.size() != 4){
    errorMsg =  "Cannot detect perfect corners";
    return null;
}</pre></div><p>Now that <a id="id424" class="indexterm"/>we have detected the four corners, we will try to identify their locations on a quadrilateral. For this, we will compare the location of each corner with the center of the quadrilateral, which we obtain by taking the average of the coordinates of each of the corners:</p><div class="informalexample"><pre class="programlisting">static void sortCorners(ArrayList&lt;Point&gt; corners)
{
    ArrayList&lt;Point&gt; top, bottom;

    top = new ArrayList&lt;Point&gt;();
    bottom = new ArrayList&lt;Point&gt;();

    Point center = new Point();

    for(int i=0; i&lt;corners.size(); i++){
        center.x += corners.get(i).x/corners.size();
        center.y += corners.get(i).y/corners.size();
    }

    for (int i = 0; i &lt; corners.size(); i++)
    {
        if (corners.get(i).y &lt; center.y)
            top.add(corners.get(i));
        else
            bottom.add(corners.get(i));
    }
    corners.clear();

    if (top.size() == 2 &amp;&amp; bottom.size() == 2){
        Point top_left = top.get(0).x &gt; top.get(1).x ? 
          top.get(1) : top.get(0);
        Point top_right = top.get(0).x &gt; top.get(1).x ? 
          top.get(0) : top.get(1);
        Point bottom_left = bottom.get(0).x &gt; bottom.get(1).x 
          ? bottom.get(1) : bottom.get(0);
        Point bottom_right = bottom.get(0).x &gt; bottom.get(1).x 
          ? bottom.get(0) : bottom.get(1);

        top_left.x *= scaleFactor;
        top_left.y *= scaleFactor;

        top_right.x *= scaleFactor;
        top_right.y *= scaleFactor;

        bottom_left.x *= scaleFactor;
        bottom_left.y *= scaleFactor;

        bottom_right.x *= scaleFactor;
        bottom_right.y *= scaleFactor;

        corners.add(top_left);
        corners.add(top_right);
        corners.add(bottom_right);
        corners.add(bottom_left);
    }
}</pre></div><p>Here, we<a id="id425" class="indexterm"/> have multiplied the scale factor of the corner values, as those will most likely be the location of the corners in the original image. Now, we just want the page in the resulting image. We need to determine the size of the resulting image. For this, we will use the coordinates of the corners calculated in the earlier step:</p><div class="informalexample"><pre class="programlisting">double top = Math.sqrt(Math.pow(corners.get(0).x - corners.get(1).x, 2) + Math.pow(corners.get(0).y - corners.get(1).y, 2));
                
double right = Math.sqrt(Math.pow(corners.get(1).x - corners.get(2).x, 2) + Math.pow(corners.get(1).y - corners.get(2).y, 2));
                
double bottom = Math.sqrt(Math.pow(corners.get(2).x - corners.get(3).x, 2) + Math.pow(corners.get(2).y - corners.get(3).y, 2));
                
double left = Math.sqrt(Math.pow(corners.get(3).x - corners.get(1).x, 2) + Math.pow(corners.get(3).y - corners.get(1).y, 2));
Mat quad = Mat.zeros(new Size(Math.max(top, bottom), Math.max(left, right)), CvType.CV_8UC3);</pre></div><p>Now, we need to use a perspective transformation to warp the image in order to occupy the entire image. For this, we need to create reference corners, corresponding to each corner in the <code class="literal">corners</code> array:</p><div class="informalexample"><pre class="programlisting">ArrayList&lt;Point&gt; result_pts = new ArrayList&lt;Point&gt;();
result_pts.add(new Point(0, 0));
result_pts.add(new Point(quad.cols(), 0));
result_pts.add(new Point(quad.cols(), quad.rows()));
result_pts.add(new Point(0, quad.rows()));</pre></div><p>Notice how <a id="id426" class="indexterm"/>the elements in the corners are in the same order as they are in <code class="literal">result_pts</code>. This is required so as to perform a proper perspective transformation. Next, we will perform the perspective transformation:</p><div class="informalexample"><pre class="programlisting">Mat cornerPts = Converters.vector_Point2f_to_Mat(corners);
Mat resultPts = Converters.vector_Point2f_to_Mat(result_pts);

Mat transformation = Imgproc.getPerspectiveTransform(cornerPts, 
  resultPts);
Imgproc.warpPerspective(srcOrig, quad, transformation,
  quad.size());
Imgproc.cvtColor(quad, quad, Imgproc.COLOR_BGR2RGBA);
Bitmap bitmap = Bitmap.createBitmap(quad.cols(), quad.rows(),
  Bitmap.Config.ARGB_8888);
Utils.matToBitmap(quad, bitmap);

return bitmap;</pre></div><p>Now that you have the resulting image with just the page in it, you can perform any more processing that is required by your application.</p><p>All we need to do now is to display the resulting image in <code class="literal">ImageView</code>. In <code class="literal">onPostExecute</code>, add the following lines:</p><div class="informalexample"><pre class="programlisting">if(bitmap!=null) {
    ivImage.setImageBitmap(bitmap);
} else if (errorMsg != null){
    Toast.makeText(getApplicationContext(), 
      errorMsg, Toast.LENGTH_SHORT).show();
}</pre></div><p>This ends<a id="id427" class="indexterm"/> our algorithm to segment out a page of paper from a scene and warp it to form a perfect rectangle. You can see the result of the algorithm on the images, as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/B02052_09_05.jpg" alt="Implementing on Android"/><div class="caption"><p>The original image (L) and the resulting image (R)</p></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec49"/>Summary</h1></div></div></div><p>In this chapter, we saw how we could use multiple computer vision algorithms to perform a bigger task and implemented a system similar to Microsoft's Office Lens. This algorithm can be extended and made better using better segmentation and corner detection algorithms. Also, once you have the page in the resulting image, you can apply machine learning algorithms to detect the text on the page.</p></div></body></html>