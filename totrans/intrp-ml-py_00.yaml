- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The title of this book suggests its central themes: **interpretation**, **machine
    learning**, and **Python**, with the first theme being the most crucial.'
  prefs: []
  type: TYPE_NORMAL
- en: So, why is interpretation so important?
  prefs: []
  type: TYPE_NORMAL
- en: '**Interpretable machine learning**, often referred to as **Explainable AI**
    (**XAI**), encompasses a growing array of techniques that help us glean insights
    from models, aiming to ensure they are safe, fair, and reliable – a goal I believe
    we all share for our models.'
  prefs: []
  type: TYPE_NORMAL
- en: With the rise of AI superseding traditional software and even human tasks, machine
    learning models are viewed as a more advanced form of software. While they operate
    on binary data, they aren’t typical software; their logic isn’t explicitly coded
    by developers but emerges from data patterns. This is where interpretation steps
    in, helping us understand these models, pinpoint their errors, and rectify them
    before any potential mishaps. Thus, interpretation is essential in fostering trust
    and ethical considerations in these models. And it’s worth noting that in the
    not-so-distant future, training models might move away from coding to more intuitive
    drag-and-drop interfaces. In this context, understanding machine learning models
    becomes an invaluable skill.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, there’s still a significant amount of coding involved in data preprocessing,
    exploration, model training, and deployment. And while this book is rich with
    Python examples, it’s not merely a coding guide removed from practical applications
    or the bigger picture. The book’s essence is to prioritize the *why* before the
    *how* when it comes to **interpretable machine learning**, as interpretation revolves
    around the question of *why*.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, most chapters of this book kickoff by outlining a mission (the *why*)
    and then delving into the methodology (the *how*). The aim is to achieve the mission
    using the techniques discussed in the chapter, with an emphasis on understanding
    the results. The chapters wrap up by pondering on the practical insights gained
    from the exercises.
  prefs: []
  type: TYPE_NORMAL
- en: The structure of this book is progressive, starting from the basics and moving
    to more intricate topics. The tools utilized in this book are open source and
    are products of leading research institutions like Microsoft, Google, and IBM.
    Even though interpretability is a vast research field with many aspects still
    in the developmental phase, this book doesn’t aim to cover it all. Its primary
    goal is to delve deeply into a selection of interpretability tools, making it
    beneficial for those working in the machine learning domain.
  prefs: []
  type: TYPE_NORMAL
- en: The book’s initial section introduces interpretability, emphasizing its significance
    in the business landscape and discussing its core components and challenges. The
    subsequent section provides a detailed overview of various interpretation techniques
    and their applications, whether it’s for classification, regression, tabular data,
    time series, images, or text. In the final section, readers will engage in practical
    exercises on model tuning and data training for interpretability, focusing on
    simplifying models, addressing biases, setting constraints, and ensuring dependability.
  prefs: []
  type: TYPE_NORMAL
- en: By the book’s conclusion, readers will be adept at using interpretability techniques
    to gain deeper insights into machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book caters to a diverse audience, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Data professionals who face the growing challenge of explaining the functioning
    of AI systems they create and manage and seek ways to enhance them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data scientists and machine learning professionals aiming to broaden their expertise
    by learning model interpretation techniques and strategies to overcome model challenges
    from fairness to robustness.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aspiring data scientists who have a basic grasp of machine learning and proficiency
    in Python.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI ethics officers aiming to deepen their knowledge of the practical aspects
    of their role to guide their initiatives more effectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI project supervisors and business leaders eager to integrate interpretable
    machine learning in their operations, aligning with the values of fairness, responsibility,
    and transparency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Chapter 1*, *Interpretation, Interpretability, and Explainability; and Why
    Does It All Matter?*, introduces machine learning interpretation and related concepts,
    such as interpretability, explainability, black-box models, and transparency,
    providing definitions for these terms to avoid ambiguity. We then underpin the
    value of machine learning interpretability for businesses.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 2*, *Key Concepts of Interpretability*, uses a cardiovascular disease
    prediction example to introduce two fundamental concepts (feature importance and
    decision regions) and the most important taxonomies used to classify interpretation
    methods. We also detail what elements hinder machine learning interpretability
    as a primer for what lies ahead.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 3*, *Interpretation Challenges*, discusses the traditional methods
    used for machine learning interpretation for regression and classification with
    a flight delay prediction problem. We will then examine the limitations of these
    traditional methods and explain what makes “white-box” models intrinsically interpretable
    and why we cannot always use white-box models. To answer this question, we consider
    the trade-off between prediction performance and model interpretability. Finally,
    we will discover some new “glass-box” models that attempt to not compromise in
    this trade-off.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 4*, *Global Model-Agnostic Interpretation Methods*, explores **Partial
    Dependence Plots** (**PDP**) and game-theory-inspired **SHapley Additive exPlanations**
    (**SHAP**) with used car pricing regression models, then visualizes conditional
    marginal distribution **Accumulated Local Effects** (**ALE**) plots.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 5*, *Local Model-Agnostic Interpretation Methods*, covers local interpretation
    methods, explaining a single or a group of predictions. To this end, the chapter
    covers how to leverage SHAP and **Local Interpretable Model-agnostic Explanations**
    (**LIME**) for local interpretations with a chocolate bar rating example, with
    both tabular and text data.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 6*, *Anchors and Counterfactual Explanations*, continues with local
    model interpretations, but only for classification problems. We use a recidivism
    risk prediction example to understand how we can explain unfair predictions in
    a human-interpretable way. This chapter covers anchors, counterfactuals, and the
    **What-If-Tool** (**WIT**).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 7*, *Visualizing Convolutional Neural Networks*, explores interpretation
    methods that work with **Convolutional Neural Network** (**CNN**) models with
    a garbage classifier model. Once we have grasped how a CNN learns with activations,
    we will study several gradient-based attribution methods, such as saliency maps,
    Grad-CAM, and integrated gradients, to debug class attribution. Lastly, we will
    extend our attribution debugging know-how with perturbation-based attribution
    methods such as feature ablation, occlusion sensitivity, Shapley value sampling,
    and KernelSHAP.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 8*, *Interpreting NLP Transformers*, discusses how to visualize attention
    mechanisms in a restaurant review sentiment classifier transformer model, followed
    by interpreting integrated gradient attributions and exploring the **Learning
    Interpretability Tool** (**LIT**).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 9*, *Interpretation Methods for Multivariate Forecasting and Sensitivity
    Analysis*, uses a traffic forecasting problem and **Long Short-Term Memory** (**LSTM**)
    models to show how to employ integrated gradients and SHAP for this use case.
    Lastly, the chapter looks at how forecasting and uncertainty are intrinsically
    linked, and sensitivity analysis – a family of methods designed to measure the
    uncertainty of a model’s output in relation to its input. We study two methods:
    Morris for factor prioritization and Sobol for factor fixing.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 10*, *Feature Selection and Engineering for Interpretability*, uses
    a challenging non-profit direct mailing optimization problem to review filter-based
    feature selection methods, such as Spearman’s correlation and learn about embedded
    methods, such as Lasso. Then, you will discover wrapper methods, such as sequential
    feature selection and hybrid ones, such as recursive feature elimination, as well
    as more advanced ones, such as genetic algorithms. Lastly, even though feature
    engineering is typically conducted before selection, there’s value in exploring
    feature engineering for many reasons after the dust has settled.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 11*, *Bias Mitigation and Causal Inference Methods*, takes a credit
    card default problem to demonstrate leveraging fairness metrics and visualizations
    to detect undesired bias. Then, the chapter looks at how to reduce it via preprocessing
    methods such as reweighting and prejudice remover for in-processing and equalized
    odds for post-processing. Then, we test treatments for lowering credit card default
    and leverage causal modeling to determine their **Average Treatment Effects**
    (**ATE**) and **Conditional Average Treatment Effects** (**CATE**). Finally, we
    test causal assumptions and the robustness of estimates.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 12*, *Monotonic Constraints and Model Tuning for Interpretability*,
    continues with the recidivism risk prediction problem from *Chapter 7*. We will
    learn how to place guardrails with feature engineering on the data side and monotonic
    and interaction constraints on the model to ensure fairness while also learning
    how to tune a model when there are several objectives.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 13*, *Adversarial Robustness*, uses a face mask detection problem
    to cover an end-to-end adversarial solution. An adversary can purposely thwart
    a model in many ways, and we focus on evasion attacks, such as Carlini and Wagner
    infinity-norm and adversarial patches, and briefly explain other forms of attack.
    We explain two defense methods: spatial smoothing preprocessing and adversarial
    training. Lastly, we demonstrate a robustness evaluation method.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 14*, *What’s Next for Machine Learning Interpretability?*, summarizes
    what was learned in the context of the ecosystem of machine learning interpretability
    methods. And then speculates on what’s to come next!'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will need a Jupyter environment with Python 3.9+. You can do either of
    the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Install one on your machine locally via **Anaconda Navigator** or from scratch
    with `pip`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a cloud-based one, such as **Google Colaboratory**, **Kaggle Notebooks**,
    **Azure Notebooks**, or **Amazon Sagemaker**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The instructions on how to get started will vary accordingly, so we strongly
    suggest that you search online for the latest instructions for setting them up.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For instructions on installing the many packages employed throughout the book,
    please go to the GitHub repository, which will have the updated instructions in
    the `README.MD` file. We expect these to change over time, given how often packages
    change. We also tested the code with specific versions detailed in the `README.MD`,
    so should anything fail with later versions, please install the specific version
    instead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Individual chapters have instructions on how to check that the right packages
    are installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But depending on the way **Jupyter** was set up, installing packages might be
    best done through the **command line** or using `conda`, so we suggest you adapt
    these installation instructions to suit your needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are using the digital version of this book, type the code yourself or
    access the code via the GitHub repository (link available in the next section).
    Doing so will help you avoid any potential errors related to the copying and pasting
    of code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are not a machine learning practitioner or are a beginner, it is best
    to read the book sequentially since many concepts are only explained in great
    detail in earlier chapters. Practitioners skilled in machine learning but not
    acquainted with interpretability can skim the first three chapters to get the
    ethical context and concept definitions required to make sense of the rest, but
    read the rest of the chapters in order. As for advanced practitioners with foundations
    in interpretability, reading the book in any order should be fine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As for the code, you can read the book without running the code simultaneously
    or strictly for the theory. But if you plan to run the code, it is best to do
    it with the book as a guide to assist with the interpretation of outcomes and
    strengthen your understanding of the theory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While reading the book, think of ways you could use the tools learned, and by
    the end of it, hopefully, you will be inspired to put this newly gained knowledge
    into action!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The code bundle for the book is hosted on GitHub at [https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/](https://github.com/PacktPublishing/Interpretable-Machine-Learning-with-Python-2E/).
    In case there’s an update to the code, it will be updated on the existing GitHub
    repository. You can also find the hardware and software list of requirements on
    the repository in the `README.MD` file.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Download the color images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://packt.link/gbp/9781803235424](https://packt.link/gbp/9781803235424).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are several text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter/X handles.
    For example: “Next, let’s define a `device` variable because if you have a CUDA-enabled
    GPU model, inference will perform quicker.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see on
    the screen. For instance, words in menus or dialog boxes appear in the text like
    this. For example: “The **Predictions** tab is selected, and this tab has a **Data
    Table** to the left where you can select and pin individual data points and a
    pane with **Classification Results** to the left.”'
  prefs: []
  type: TYPE_NORMAL
- en: Warnings or important notes appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: Email `feedback@packtpub.com` and mention the book’s
    title in the subject of your message. If you have questions about any aspect of
    this book, please email us at `questions@packtpub.com`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you reported this to us. Please visit [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    click **Submit Errata**, and fill in the form.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packtpub.com` with a
    link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [http://authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Share your thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you’ve read *Interpretable Machine Learning with Python 2e*, we’d love
    to hear your thoughts! Please [click here to go straight to the Amazon review
    page](https://www.packtpub.com/) for this book and share your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
- en: Download a free PDF copy of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for purchasing this book!
  prefs: []
  type: TYPE_NORMAL
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  prefs: []
  type: TYPE_NORMAL
- en: Is your eBook purchase not compatible with the device of your choice?
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  prefs: []
  type: TYPE_NORMAL
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  prefs: []
  type: TYPE_NORMAL
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these simple steps to get the benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code or visit the link below
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18406_Free_PDF.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/free-ebook/9781803235424](https://packt.link/free-ebook/9781803235424)'
  prefs: []
  type: TYPE_NORMAL
- en: Submit your proof of purchase
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
