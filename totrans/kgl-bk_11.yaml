- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Ensembling with Blending and Stacking Solutions
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用混合和堆叠解决方案进行集成
- en: When you start competing on Kaggle, it doesn’t take long to realize that you
    cannot win with a single, well-devised model; you need to ensemble multiple models.
    Next, you will immediately wonder how to set up a working ensemble. There are
    few guides around, and more is left to Kaggle’s lore than to scientific papers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始在Kaggle上竞争时，很快就会意识到你不能仅凭一个精心设计的模型获胜；你需要集成多个模型。接下来，你将立即想知道如何设置一个有效的集成。周围很少有指南，而且Kaggle的经验比科学论文还要多。
- en: The point here is that if ensembling is the key to winning in Kaggle competitions,
    in the real world it is associated with complexity, poor maintainability, difficult
    reproducibility, and hidden technical costs for little advantage. Often, the small
    boost that can move you from the lower ranks to the top of the leaderboard really
    doesn’t matter for real-world applications because the costs overshadow the advantages.
    However, that doesn’t mean that ensembling is not being used at all in the real
    world. In a limited form, such as averaging and mixing a few diverse models, ensembling
    allows us to create models that can solve many data science problems in a more
    effective and efficient way.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这里要说明的是，如果集成是赢得Kaggle竞赛的关键，那么在现实世界中，它与复杂性、维护性差、难以重现以及微小的技术成本相关，而这些成本往往掩盖了优势。通常，那种能让你从排名较低跃升至排行榜顶部的微小提升，对于现实世界的应用来说并不重要，因为成本掩盖了优势。然而，这并不意味着集成在现实世界中完全没有使用。在有限的形式下，如平均和混合几个不同的模型，集成使我们能够以更有效和更高效的方式解决许多数据科学问题。
- en: Ensembling in Kaggle is not only a way to gain extra predictive performance,
    but it is also a teaming strategy. When you are working with other teammates,
    putting together everyone’s contributions produces a result that often performs
    better than individual efforts, and can also help to organize the work of the
    team by structuring everyone’s efforts toward a clear goal. In fact, when work
    is performed in different time zones and under different constraints for each
    participant, collaborative techniques like pair coding are clearly not feasible.
    One team member may be subject to constraints due to office hours, another due
    to studying and examinations, and so on.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kaggle中，集成不仅仅是提高预测性能的一种方法，它也是一种团队合作策略。当你与其他队友一起工作时，将每个人的贡献整合在一起，往往会产生比个人努力更好的结果，并且还可以通过将每个人的努力结构化，朝着明确的目标组织团队工作。实际上，当工作在不同时区进行，并且每个参与者都有不同的约束条件时，像结对编程这样的协作技术显然是不可行的。一个团队成员可能因为工作时间受到限制，另一个可能因为学习和考试，等等。
- en: Teams in a competition often don’t have the chance to, and do not necessarily
    have to, synchronize and align all participants on the same tasks. Moreover, the
    skills within a team may also differ.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在竞赛中，团队往往没有机会，也不一定需要，将所有参与者同步和协调到同一任务上。此外，团队内的技能也可能有所不同。
- en: A good ensembling strategy shared among a team means that individuals can keep
    working based on their own routines and styles, yet still contribute to the success
    of the group. Therefore, even different skills may become an advantage when using
    ensembling techniques based on diversity of predictions.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在团队中共享的良好的集成策略意味着个人可以继续根据自己的常规和风格工作，同时仍然为团队的成功做出贡献。因此，即使不同的技能在使用基于预测多样性的集成技术时也可能成为优势。
- en: In this chapter, we will start from the ensembling techniques that you already
    know, because they are embedded in algorithms such as random forests and gradient
    boosting, and then progress to ensembling techniques for multiple models such
    as averaging, blending, and stacking. We will provide you with some theory, some
    practice, and also some code examples you can use as templates when building your
    own solutions on Kaggle.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从您已经了解的集成技术开始，因为它们嵌入在随机森林和梯度提升等算法中，然后进一步介绍针对多个模型的集成技术，如平均、混合和堆叠。我们将为您提供一些理论、一些实践，以及一些代码示例，您可以在Kaggle上构建自己的解决方案时将其用作模板。
- en: 'We will cover these topics:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: A brief introduction to ensemble algorithms
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成算法简介
- en: Averaging models into an ensemble
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型平均集成到集成中
- en: Blending models using a meta-model
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用元模型混合模型
- en: Stacking models
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆叠模型
- en: Creating complex stacking and blending solutions
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建复杂的堆叠和混合解决方案
- en: 'Before leaving you to read this chapter and try all the techniques, we have
    to mention a great reference on ensembling for us and for all practitioners when
    competing on Kaggle: the blog post written in 2015 by *Triskelion* (*Hendrik Jacob
    van Veen*) and by a few collaborators (*Le Nguyen The Dat*, *Armando Segnini*).
    The *Kaggle Ensembling Guide* was originally found on the *mlwave* blog ([https://mlwave.com/kaggle-ensembling-guide](https://mlwave.com/kaggle-ensembling-guide)),
    which is no longer up, but you can retrieve the contents of the guide from [https://usermanual.wiki/Document/Kaggle20ensembling20guide.685545114.pdf](https://usermanual.wiki/Document/Kaggle20ensembling20guide.685545114.pdf).
    The post arranged most of the implicit and explicit knowledge about ensembling
    from Kaggle forums at the time.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在让您阅读本章并尝试所有技术之前，我们必须提到一个关于集成对我们和所有Kaggle竞赛者的伟大参考：由*Triskelion* (*Hendrik Jacob
    van Veen*) 和几位合作者 (*Le Nguyen The Dat*, *Armando Segnini*) 在2015年撰写的博客文章。*Kaggle集成指南*最初可以在*mlwave*博客上找到
    ([https://mlwave.com/kaggle-ensembling-guide](https://mlwave.com/kaggle-ensembling-guide))，但现在已不再更新，但您可以从[https://usermanual.wiki/Document/Kaggle20ensembling20guide.685545114.pdf](https://usermanual.wiki/Document/Kaggle20ensembling20guide.685545114.pdf)检索指南的内容。该文章整理了当时Kaggle论坛上关于集成的多数隐性和显性知识。
- en: A brief introduction to ensemble algorithms
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成算法简介
- en: The idea that ensembles of models can outperform single ones is not a recent
    one. We can trace it back to *Sir* *Francis Galton*, who was alive in Victorian
    Britain. He figured out that, in order to guess the weight of an ox at a county
    fair, it was more useful to take an average from a host of more or less educated
    estimates from a crowd than having a single carefully devised estimate from an
    expert.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 模型集成可以优于单个模型的想法并非最近才出现。我们可以追溯到维多利亚时代的英国**爵士** *弗朗西斯·高尔顿*，他发现，为了猜测在县博览会上一头牛的重量，从一群或多或少受过教育的人那里收集的大量估计的平均值比从专家那里得到的单个精心设计的估计更有用。
- en: In 1996, *Leo Breiman* formalized the idea of using multiple models combined
    into a more predictive one by illustrating the **bagging** technique (also called
    the “bootstrap aggregating” procedure) that later led to the development of the
    even more effective **random forests** algorithms. In the period that followed,
    other ensembling techniques such as **gradient boosting** and **stacking** were
    also presented, thus completing the range of ensemble methods that we use today.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在1996年，*Leo Breiman* 通过说明**袋装**技术（也称为“自助聚合”过程）来形式化使用多个模型组合成一个更具预测性的模型的想法，这后来导致了更有效的**随机森林**算法的发展。在此之后，其他集成技术如**梯度提升**和**堆叠**也被提出，从而完成了我们今天使用的集成方法范围。
- en: 'You can refer to a few articles to figure out how these ensembling algorithms
    were initially devised:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考几篇文章来了解这些集成算法最初是如何设计的：
- en: 'For random forests, read Breiman, L. *Bagging predictors*. Machine learning
    24.2 – 1996: 123-140.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '对于随机森林，请阅读Breiman, L. 的文章 *Bagging predictors*。机器学习 24.2 – 1996: 123-140。'
- en: 'If you want to know how boosting originally worked in more detail, read Freund,
    Y. and Schapire, R.E. *Experiments with a new boosting algorithm.* *icml. Vol.
    96 – 1996*, and *Friedman, J. H*. *Greedy function approximation: a gradient boosting
    machine.* *Annals of Statistics* (2001): 1189-1232\.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '如果您想更详细地了解提升最初是如何工作的，请阅读Freund, Y. 和 Schapire, R.E. 的文章 *Experiments with a
    new boosting algorithm.* *icml. Vol. 96 – 1996*，以及 *Friedman, J. H*. 的文章 *Greedy
    function approximation: a gradient boosting machine.* *Annals of Statistics* (2001):
    1189-1232。'
- en: As for stacking, refer to Ting, K. M. and Witten, *I. H.* *Stacking bagged and
    dagged models*, 1997, for a first formal draft of the technique.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至于堆叠，请参考Ting, K. M. 和 Witten, *I. H.* 的文章 *Stacking bagged and dagged models*，1997年，这是该技术的第一个正式草案。
- en: The first basic strategies for ensembling predictors in Kaggle competitions
    were taken directly from bagging and random forest strategies for classification
    and regression. They involved making an average of various predictions and were
    thus named **averaging** techniques. These approaches quickly emerged from the
    very first Kaggle competitions held over 11 years ago also because of the pre-Kaggle
    Netflix competition, where strategies based on the average of the results of different
    models dominated the scene. Given their success, basic ensembling techniques based
    on averaging set a standard for many competitions to come, and they are still
    quite useful and valid even today for scoring more highly on the leaderboard.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle竞赛中集成预测者的第一个基本策略直接来源于分类和回归的bagging和随机森林策略。它们涉及对各种预测进行平均，因此被称为**平均**技术。这些方法在11年前举办的第一个Kaggle竞赛中迅速出现，也得益于Kaggle之前的Netflix竞赛，在那里基于不同模型结果平均的策略主导了场景。鉴于它们的成功，基于平均的基本集成技术为许多即将到来的竞赛设定了标准，并且它们至今仍然非常有用和有效，有助于在排行榜上获得更高的分数。
- en: Stacking, which is more complex and computationally demanding, emerged a bit
    later, when problems in competitions become more complex and the struggle between
    participants fiercer. Just as the random forest approach has inspired averaging
    different predictions, boosting heavily inspired stacking approaches. In boosting,
    by sequentially re-processing information, your learning algorithm can model problems
    in a better and more complete way. In fact, in gradient boosting, sequential decision
    trees are built in order to model the part of data that previous iterations are
    unable to grasp. This idea is reprised in stacking ensembles, where you stack
    the results of previous models and re-process them in order to gain an increase
    in predictive performance.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Stacking，这是一种更复杂且计算量更大的方法，在竞赛问题变得更加复杂和参与者之间的竞争更加激烈时出现。正如随机森林方法启发了对不同预测的平均一样，提升法极大地启发了堆叠方法。在提升法中，通过顺序重新处理信息，你的学习算法可以以更好和更完整的方式建模问题。实际上，在梯度提升中，为了建模先前迭代无法掌握的数据部分，会构建顺序决策树。这种想法在堆叠集成中得到了重申，在那里你堆叠先前模型的输出并重新处理它们，以获得预测性能的提升。
- en: '![](img/Rob_Mulla.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Rob_Mulla.png)'
- en: Rob Mulla
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 罗布·穆拉
- en: '[https://www.kaggle.com/robikscube](https://www.kaggle.com/robikscube)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/robikscube](https://www.kaggle.com/robikscube)'
- en: Rob spoke to us about his views on ensembling and what he has learned from Kaggle.
    A Grandmaster in Competitions, Notebooks, and Discussion, and Senior Data Scientist
    at Biocore LLC, there is a lot we can learn from his experiences.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 罗布与我们分享了他在集成和从Kaggle中学到的经验。作为竞赛、笔记本和讨论的大师，以及Biocore LLC的高级数据科学家，我们可以从他丰富的经验中学到很多东西。
- en: What’s your favorite kind of competition and why? In terms of techniques and
    solving approaches, what is your specialty on Kaggle?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你最喜欢的竞赛类型是什么？为什么？在技术和解决方法方面，你在Kaggle上的专长是什么？
- en: '*My favorite type of competitions are ones that involve unique datasets requiring
    novel solutions that incorporate different types of modeling approaches. I enjoy
    when a competition isn’t just training large models on the dataset, but actually
    requires understanding the data very well and implementing ideas that leverage
    architectures specific to the tasks. I don’t try to specialize in any particular
    approach. When I first started Kaggle, I mainly stuck to gradient boosted models,
    but in order to be competitive in recent years I’ve grown in my understanding
    of deep learning, computer vision, NLP, and optimization. My favorite competitions
    require using more than just one technique.*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*我最喜欢的竞赛类型是那些涉及独特数据集，需要结合不同类型的建模方法来提出新颖解决方案的竞赛。我喜欢当竞赛不仅仅是训练大型模型，而是真正需要深入理解数据并实施利用特定任务架构的想法时。我不试图专精于任何特定的方法。当我第一次开始参加Kaggle时，我主要坚持使用梯度提升模型，但为了在近年来保持竞争力，我加深了对深度学习、计算机视觉、NLP和优化的理解。我最喜欢的竞赛需要使用不止一种技术。*'
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你是如何参加Kaggle竞赛的？这种方法和你在日常工作中所做的方法有何不同？
- en: '*I approach Kaggle competitions in some ways very similar to work projects.
    First comes data understanding. In real-world projects, you may need to work on
    defining the problem and developing a good metric. In Kaggle, that is already
    done for you. Next is understanding how the data and metric relate to each other
    – and developing and testing modeling techniques that you believe will best solve
    the problem. The biggest difference in Kaggle compared to real-life data science
    is the final bit of ensembling and tuning of models to get a slight edge – in
    many real-world applications, these types of large ensembles are not necessary
    because the computational expense to performance gain can be small.*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*我在某些方面将Kaggle比赛与工作项目非常相似。首先是对数据理解。在现实世界项目中，你可能需要定义问题和开发一个好的指标。在Kaggle中，这些已经为你准备好了。接下来是理解数据和指标之间的关系——以及开发和测试你认为将最好解决问题的建模技术。与现实生活中数据科学相比，Kaggle最大的不同之处在于最后一点，即集成和调整模型以获得微小的优势——在许多现实世界的应用中，这些类型的大型集成不是必要的，因为计算成本与性能提升之间的差距可能很小。*'
- en: Tell us about a particularly challenging competition you entered, and what insights
    you used to tackle the task.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 告诉我们你参加的一个特别具有挑战性的比赛，以及你使用了哪些见解来应对任务。
- en: '*A very challenging competition that I entered was the* NFL Helmet Impact Detection
    *competition. It involved video data, which I had no prior experience with. It
    also required researching common approaches and reading existing papers on the
    topic. I had to work on a two-stage approach, which added to the complexity of
    the solution. A different competition that I found challenging was the* Indoor
    Location Navigation *competition. It involved modeling, optimization, and really
    understanding the data well. I didn’t end up doing very well in the competition,
    but I learned a lot.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*我参加的一个极具挑战性的比赛是* NFL头盔冲击检测 *比赛。它涉及视频数据，我对这个领域没有先前的经验。它还要求研究常见的方法和阅读该主题的现有论文。我必须工作在两阶段的方法上，这增加了解决方案的复杂性。另一个我认为具有挑战性的比赛是*室内定位导航
    *比赛。它涉及建模、优化，以及真正理解数据。我在比赛中并没有做得很好，但我学到了很多。*'
- en: Has Kaggle helped you in your career? If so, how?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle是否帮助你在职业生涯中？如果是，那么是如何帮助的？
- en: '*Yes. Kaggle has played a big part in helping me gain notoriety in the data
    science space. I’ve also grown in my knowledge and understanding of new techniques
    and have met and worked with many brilliant people who have helped me grow in
    my skills and understanding of machine learning.*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*是的。Kaggle在帮助我在数据科学领域获得知名度方面发挥了重要作用。我也在知识和理解新技术方面有所增长，并且遇到了许多才华横溢的人，他们帮助我在技能和机器学习理解方面成长。*'
- en: '*My team placed second for the* NFL Helmet Impact Detection *Competition. I
    also participated in a number of NFL competitions prior to that competition. The
    hosts of the competition reached out to me and eventually it helped me land my
    current role.*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*我的团队在* NFL头盔冲击检测 *比赛中获得了第二名。在那场比赛之前，我还参加了许多NFL比赛。比赛的主持人联系了我，最终这帮助我获得了现在的职位。*'
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的经验中，不经验丰富的Kagglers通常忽略了什么？你现在知道什么，而当你刚开始时希望知道的呢？
- en: '*I think inexperienced Kagglers sometimes worry too much about the ensembling
    and hyperparameter tuning of models. These are important towards the end of a
    competition, but they are not important unless you’ve already built a good base
    model. I also think that fully understanding the competition metric is extremely
    important. Many Kagglers overlook how important it is to understand how to optimize
    your solution to the evaluation metric.*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*我认为不经验丰富的Kagglers有时过于担心模型的集成和超参数调整。这些在比赛的后期很重要，但除非你已经建立了一个良好的基础模型，否则它们并不重要。我也认为完全理解比赛指标非常重要。许多Kagglers忽略了理解如何优化解决方案以适应评估指标的重要性。*'
- en: What mistakes have you made in competitions in the past?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你在过去比赛中犯过哪些错误？
- en: '*A lot. I’ve overfit models and spent time working on things that didn’t end
    up being beneficial in the end. However, I feel like this was necessary for me
    to learn how to better tackle future competitions. The mistakes may have hurt
    me in the specific competition I was working in, but helped me to be better in
    later competitions.*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*很多。我曾经过度拟合模型，花费时间在最终没有带来益处的事情上。然而，我认为这对我在未来比赛中更好地应对是必要的。这些错误可能在特定的比赛中伤害了我，但帮助我在后来的比赛中变得更好。*'
- en: Are there any particular tools or libraries that you would recommend using for
    data analysis or machine learning?
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据分析或机器学习，您会推荐使用哪些特定的工具或库？
- en: '*For EDA, know how to manipulate data using NumPy, Pandas, and Matplotlib or
    another plotting library. For modeling, know how set up a proper cross validation
    scheme with Scikit-learn. The standard models like XGBoost/LightGBM are good to
    know how to baseline with. Deep learning libraries are mainly TensorFlow/Keras
    or PyTorch. Getting to know one of the two main deep learning libraries is important.*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*对于数据探索性分析（EDA），了解如何使用NumPy、Pandas和Matplotlib或另一个绘图库来操作数据。对于建模，了解如何使用Scikit-learn设置适当的交叉验证方案。标准模型如XGBoost/LightGBM了解如何设置基线是有用的。深度学习库主要是TensorFlow/Keras或PyTorch。了解这两个主要深度学习库中的任何一个都很重要。*'
- en: Averaging models into an ensemble
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将模型平均到一个集成中
- en: In order to introduce the averaging ensembling technique better, let’s quickly
    revise all the strategies devised by Leo Breiman for ensembling. His work represented
    a milestone for ensembling strategies, and what he found out at the time still
    works fairly well in a wide range of problems.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地介绍平均集成技术，让我们快速回顾Leo Breiman为集成设计的所有策略。他的工作代表了集成策略的一个里程碑，他在当时发现的方法在广泛的问题中仍然相当有效。
- en: Breiman explored all these possibilities in order to figure out if there was
    a way to reduce the variance of error in powerful models that tended to overfit
    the training data too much, such as decision trees.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Breiman探索了所有这些可能性，以确定是否有一种方法可以减少那些倾向于过度拟合训练数据的强大模型的误差方差，例如决策树。
- en: 'Conceptually, he discovered that ensembling effectiveness was based on three
    elements: how we deal with the **sampling of training cases**, how we **build
    the models**, and, finally, how we **combine the different models** obtained.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，他发现集成效果基于三个要素：我们如何处理**训练案例的抽样**，我们如何**构建模型**，以及最后，我们如何**组合获得的不同模型**。
- en: 'As for the sampling, the approaches tested and found were:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 关于抽样，测试并发现的方法有：
- en: '**Pasting**, where a number of models are built using subsamples (sampling
    without replacements) of the examples (the data rows)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**粘贴**，即使用示例（数据行）的子样本（不放回抽样）构建多个模型'
- en: '**Bagging**, where a number of models are built using random selections of
    bootstrapped examples (sampling with replacement)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**袋装**，即使用随机选择的bootstrap示例（放回抽样）构建多个模型'
- en: '**Random subspaces**, where a number of models are built using subsamples (sampling
    without replacements) of the features (the data columns)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机子空间**，即使用特征（数据列）的子样本（不放回抽样）构建多个模型'
- en: '**Random patches**, an approach similar to bagging, except features are also
    sampled when each model is selected, as in random subspaces'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机补丁**，一种类似于袋装的方法，除了在为每个模型选择时也抽样特征，就像在随机子空间中一样'
- en: The reason we sample instead of using the same information is because, by subsampling
    cases and features, we create models that are all relevant to the same problem
    while each being different from the others. This difference also applies to the
    way each model overfits the sample; we expect all the models to grasp the useful,
    generalizable information from the data *in the same way*, and deal with the noise
    that is not useful for making predictions *in a different way*. Hence, variation
    in modeling reduces the variation in predictions, because errors tend to cancel
    each other out.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们抽样而不是使用相同信息的原因是，通过子抽样案例和特征，我们创建了所有与同一问题相关的模型，同时每个模型又与其他模型不同。这种差异也适用于每个模型如何过度拟合样本；我们期望所有模型以相同的方式从数据中提取有用的、可推广的信息，并以不同的方式处理对预测无用的噪声。因此，建模中的变化减少了预测中的变化，因为错误往往相互抵消。
- en: 'If this variation is so useful, then the next step should not just be to modify
    the *data* the model learns from, but also *the model itself*. We have two main
    approaches for the models:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这种变化如此有用，那么下一步不应该只是修改模型学习的数据，还应该修改**模型本身**。我们有两种主要的模型方法：
- en: Ensembles of the same type of models
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同类型模型的集成
- en: Ensembles of different models
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同模型的集成
- en: 'Interestingly, ensembling in one way or the other doesn’t help too much if
    the models that we are putting together are too different in predictive power.
    The point here is that you get an advantage if you put together models that are
    able to correctly guess the same type of predictions, so they can smooth out their
    errors when averaging the predictions that they get wrong. If you are ensembling
    models with performances that are too different, you will soon find out that there
    is no point because the net effect will be negative: as you are not smoothing
    your incorrect predictions, you are also degrading the correct ones.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，如果我们将要组合的模型在预测能力上差异太大，那么以某种方式集成并不会带来太多帮助。这里的要点是，如果你能组合能够正确猜测相同类型预测的模型，那么它们可以在平均错误预测时平滑它们的错误。如果你正在集成性能差异太大的模型，你很快就会意识到这没有意义，因为总体效果将是负面的：因为你没有平滑你的错误预测，你也在降低正确的预测。
- en: 'This is an important limit of averaging: it can use a set of different models
    (for instance, because they are trained using different samples and features)
    only if they are similar in predictive power. To take an example, a linear regression
    and a *k*-nearest neighbor algorithm have different ways of modeling a problem
    and capturing signals from data; thanks to the (distinct) characteristic functional
    forms at their cores, these algorithms can grasp different predictive nuances
    from the data and perform better on specific parts of their predictive tasks,
    but you cannot really take advantage of that when using averaging. By contrast,
    the different ways algorithms have to capture signals is something that stacking
    actually can leverage, because it can take the best results from each algorithm.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是有关于平均的一个重要限制：它只能使用一组不同的模型（例如，因为它们使用不同的样本和特征进行训练）如果它们在预测能力上相似。以一个例子来说，线性回归和*k*最近邻算法在建模问题和从数据中捕捉信号方面有不同的方式；得益于它们核心的（独特的）特征函数形式，这些算法可以从数据中捕捉到不同的预测细微差别，并在预测任务的特定部分上表现更好，但当你使用平均时，你实际上无法利用这一点。相比之下，算法必须捕获信号的不同方式是堆叠实际上可以利用的，因为它可以从每个算法中获取最佳结果。
- en: 'Based on this, we can summarize that, for an ensemble based on averaging (averaging
    the results of multiple models) to be effective, it should be:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，我们可以总结出，为了使基于平均的集成（平均多个模型的输出）有效，它应该：
- en: Built on models that are trained on different samples
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立在训练在不同样本上的模型之上
- en: Built on models that use different subsamples from the available features
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立在从可用特征的不同子样本中使用的模型之上
- en: Composed of models similar in predictive power
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由具有相似预测能力的模型组成
- en: Technically, this implies that the models’ predictions should be as uncorrelated
    as possible while performing at the same level of accuracy on prediction tasks.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，这意味着模型的预测应该在预测任务上保持尽可能不相关，同时达到相同的准确度水平。
- en: 'Now that we have discussed the opportunities and limitations of averaging multiple
    machine learning models, we are finally going to delve into the technical details.
    There are three ways to average multiple classification or regression models:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了平均多个机器学习模型的机遇和限制，我们最终将深入探讨其技术细节。平均多个分类或回归模型有三种方法：
- en: Majority voting, using the most frequent classification among multiple models
    (only for classification models)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多数投票，使用多个模型中最频繁的分类（仅适用于分类模型）
- en: Averaging values or probabilities
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均值或概率
- en: Using a weighted average of values or probabilities
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用值或概率的加权平均值
- en: In the next few sections, we will discuss each approach in detail in the context
    of Kaggle competitions.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将详细讨论每种方法在Kaggle比赛中的具体应用。
- en: Majority voting
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多数投票
- en: Producing different models by varying the examples, features, and models we
    use in the ensemble (if they are comparable in predictive power, as we discussed
    before) requires a certain computational effort, but it doesn’t require you to
    build a data processing pipeline that is all that different from what you would
    set up when using a single model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通过改变我们在集成中使用的示例、特征和模型（如果它们在预测能力上相似，如我们之前讨论的）来产生不同的模型，这需要一定的计算工作量，但不需要你构建一个与使用单个模型时设置完全不同的数据处理管道。
- en: In this pipeline, you just need to collect different test predictions, keeping
    track of the models used, how you sampled examples or features when training,
    the hyperparameters that you used, and the resulting cross-validation performance.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个流程中，你只需要收集不同的测试预测，记录所使用的模型，训练时如何采样示例或特征，你使用的超参数，以及最终的交叉验证性能。
- en: If the competition requires you to predict a class, you can use **majority voting**;
    that is, for each prediction, you take the class most frequently predicted by
    your models. This works for both binary predictions and multi-class predictions,
    because it presumes that there are sometimes errors in your models, but that they
    can guess correctly most of the time. Majority voting is used as an “error correction
    procedure,” discarding noise and keeping meaningful signals.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果比赛要求你预测一个类别，你可以使用**多数投票**；也就是说，对于每个预测，你选择你的模型中最频繁预测的类别。这适用于二元预测和多类别预测，因为它假设你的模型有时会有错误，但它们大多数时候可以正确猜测。多数投票被用作“错误纠正程序”，丢弃噪声并保留有意义的信号。
- en: In our first simple example, we demonstrate how majority voting works. We start
    by creating our example dataset. Using the `make_classification` function from
    Scikit-learn, we generate a *Madelon*-like dataset.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第一个简单示例中，我们演示了多数投票是如何工作的。我们首先创建我们的示例数据集。使用Scikit-learn中的`make_classification`函数，我们生成一个类似Madelon的数据集。
- en: 'The original Madelon was an artificial dataset containing data points grouped
    in clusters placed on the vertices of some dimensional hypercube and randomly
    labeled. It comprised a few informative features, mixed with irrelevant and repeated
    ones (to create multicollinearity between features) and it has a certain amount
    of injected random noise. Ideated by *Isabelle Guyon* (one of the creators of
    the SVM algorithm) for the *NIPS 2003 Feature Selection Challenge*, the Madelon
    dataset is the model example of a challenging artificial dataset for a competition.
    Even some Kaggle competitions were inspired by it: [https://www.kaggle.com/c/overfitting](https://www.kaggle.com/c/overfitting)
    and the more recent [https://www.kaggle.com/c/dont-overfit-ii](https://www.kaggle.com/c/dont-overfit-ii).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的Madelon是一个包含数据点的合成数据集，这些数据点被分组在某个维超立方体的顶点上，并随机标记。它包含一些信息性特征，混合了无关的和重复的特征（以在特征之间创建多重共线性），并且它包含一定量的注入随机噪声。由*Isabelle
    Guyon*（SVM算法的创造者之一）为2003年NIPS特征选择挑战赛所构思，Madelon数据集是具有挑战性的合成数据集的模型示例。甚至一些Kaggle比赛也受到了它的启发：[https://www.kaggle.com/c/overfitting](https://www.kaggle.com/c/overfitting)和更近期的[https://www.kaggle.com/c/dont-overfit-ii](https://www.kaggle.com/c/dont-overfit-ii)。
- en: 'We will use this recreation of the Madelon dataset throughout this chapter
    as a basis for testing ensembling techniques:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章中用这个Madelon数据集的重建作为测试集成技术的基础：
- en: '[PRE0]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After splitting it into a training and a test set, we proceed by instantiating
    our learning algorithms. We will just use three base algorithms: SVMs, random
    forests, and *k*-nearest neighbors classifiers, with default hyperparameters for
    demonstration purposes. You can try changing them or increasing their number:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在将其分为训练集和测试集之后，我们继续实例化我们的学习算法。我们将仅使用三个基础算法：SVMs、随机森林和*k*最近邻分类器，以默认超参数进行演示。你可以尝试更改它们或增加它们的数量：
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following step is just to train each model on the training set:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步仅仅是训练每个模型在训练集上：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'At this point, we need to predict on the test set for each model and ensemble
    all these predictions using majority voting. To do this, we will be using the
    `mode` function from SciPy:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们需要对每个模型和集成进行测试集预测，并使用多数投票集成这些预测。为此，我们将使用SciPy中的`mode`函数：
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'First, we check the accuracy for each single model:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们检查每个单独模型的准确性：
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We see that the three models have similar performance, around **0.8**. Now
    it is time to check the majority voting ensemble:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到三个模型的表现相似，大约在**0.8**左右。现在是我们检查多数投票集成的时候了：
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The voting ensemble is actually more accurate: **0.817**, because it managed
    to put together the correct signals from the majority.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 投票集成实际上更准确：**0.817**，因为它成功地整合了大多数正确的信号。
- en: For multilabel problems (when you can predict multiple classes), you can just
    pick the classes that are predicted above a certain number of times, assuming
    a relevance threshold that indicates that a prediction for a class is signal,
    not noise. For instance, if you have five models, you could set this threshold
    to 3, which means if a class is predicted by at least three models, then the prediction
    should be considered correct.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多标签问题（当你可以预测多个类别时），你可以简单地选择那些被预测超过一定次数的类别，假设一个相关性阈值表示对类别的预测是信号，而不是噪声。例如，如果你有五个模型，你可以将这个阈值设置为3，这意味着如果一个类别被至少三个模型预测，那么这个预测应该被认为是正确的。
- en: In regression problems, as well as when you are predicting probabilities, you
    cannot actually use majority voting. Majority voting works exclusively with class
    ownership. Instead, when you have to predict numbers, you need to combine the
    results numerically. In this case, resorting to an **average** or a **weighted
    average** will provide you the right way to combine predictions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归问题中，以及当你预测概率时，实际上你不能使用多数投票。多数投票仅与类别所有权相关。相反，当你需要预测数字时，你需要数值地组合结果。在这种情况下，求助于**平均数**或**加权平均数**将为你提供组合预测的正确方法。
- en: Averaging of model predictions
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型预测的平均值
- en: When averaging your predictions from different models in a competition, you
    can consider all your predictions as having potentially the same predictive power
    and use the arithmetic mean to derive an average value.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在比赛中平均不同模型的预测时，你可以认为所有预测都具有潜在的相同预测能力，并使用算术平均数来得出平均值。
- en: 'Aside from the arithmetic mean, we have also found it quite effective to use:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了算术平均数之外，我们还发现使用以下方法也非常有效：
- en: 'The **geometric mean**: This is where you multiply the *n* submissions, then
    you take the *1/n*^(th) power of the resulting product.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**几何平均数**：这是将*n*个提交相乘，然后取结果的*1/n*次幂。'
- en: 'The **logarithmic mean**: Analogous to the geometric mean, you take the logarithm
    of your submission, average them together, and take the exponentiation of the
    resulting mean.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对数平均数**：类似于几何平均数，你对提交取对数，将它们平均在一起，然后取结果的指数。'
- en: 'The **harmonic mean**: Where you take the arithmetic mean of the reciprocals
    of your submissions, then you take the reciprocal of the resulting mean.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调和平均数**：这是取你提交的倒数算术平均数，然后取结果的倒数。'
- en: 'The **mean of powers**: Where you take the average of the *n*^(th) power of
    the submissions, then you take the *1/n*^(th) power of the resulting average.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**幂平均数**：这是取提交的*n*次幂的平均值，然后取结果的*1/n*次幂。'
- en: The simple arithmetic average is always quite effective and basically a no-brainer
    that works more often than expected. Sometimes, variants such as the geometric
    mean or the harmonic mean may work better.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的算术平均总是非常有效，基本上是一个无需思考就能奏效的方法，其效果往往比预期的更好。有时，像几何平均数或调和平均数这样的变体可能会更有效。
- en: 'Continuing with the previous example, we will now try to figure out what kind
    of mean works best when we switch to **ROC-AUC** as our evaluation metric. To
    begin with, we evaluate the performances of each single model:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 继续上一个例子，我们现在将尝试找出当我们切换到**ROC-AUC**作为评估指标时，哪种平均数效果最好。首先，我们将评估每个单独模型的性能：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The results give us a range from **0.875** to **0.881**.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示范围从**0.875**到**0.881**。
- en: 'Our first test is performed using the arithmetic mean:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们第一次测试使用的是算术平均数：
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The resulting ROC-AUC score is decisively better than the single performances:
    **0.90192**. We also test if the geometric, harmonic, or logarithmic mean, or
    the mean of powers, can outperform the plain mean:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的ROC-AUC分数明显优于单个性能：**0.90192**。我们还测试了几何平均数、调和平均数、对数平均数或幂平均数是否能优于普通平均数：
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Running the code will tell us that none of them can. In this case, the arithmetic
    mean is the best choice for ensembling. What actually works better than the simple
    mean, in almost all cases, is putting some *prior knowledge* into the way you
    combine the numbers. This happens when you weight your models in the mean calculation.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码将告诉我们，它们都不行。在这种情况下，算术平均数是集成时的最佳选择。实际上，在几乎所有情况下，比简单平均数更有效的是将一些*先验知识*融入到组合数字的方式中。这发生在你在平均计算中对模型进行加权时。
- en: Weighted averages
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加权平均
- en: When weighting your models, you need to find an empirical way to figure out
    the right weights. A common method, though very prone to adaptive overfitting,
    is to test different combinations on the public leaderboard until you find the
    combination that scores the best. Of course, that won’t ensure that you score
    the same on the private leaderboard. Here, the principle is to weight what works
    better. However, as we have discussed at length, very often the feedback from
    the public leaderboard cannot be trusted because of important differences with
    the private test data. Yet, you *can* use your cross-validation scores or out-of-fold
    ones (the latter will be discussed along with stacking in a later section). In
    fact, another viable strategy is to use weights that are **proportional to the
    models’ cross-validation performances**.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当对模型进行加权时，你需要找到一种经验方法来确定正确的权重。一种常见的方法是，尽管非常容易导致自适应过拟合，但可以通过在公共排行榜上测试不同的组合，直到找到得分最高的组合。当然，这并不能保证你在私人排行榜上得分相同。在这里，原则是加权效果更好的部分。然而，正如我们详细讨论过的，由于与私人测试数据的重要差异，公共排行榜的反馈往往不可信。然而，你可以使用你的交叉验证分数或出卷分数（后者将在稍后的堆叠部分中讨论）。事实上，另一种可行的策略是使用与模型交叉验证性能**成比例的权重**。
- en: Although it is a bit counterintuitive, another very effective method is weighting
    the submissions **inversely proportionally to their covariances**. In fact, since
    we are striving to cancel errors by averaging, averaging based on the unique variance
    of each submission allows us to weight more heavily the predictions that are less
    correlated and more diverse, more effectively reducing the variance of the estimates.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这有点反直觉，但另一种非常有效的方法是将提交内容**与它们的协方差成反比进行加权**。实际上，因为我们正通过平均来努力消除误差，所以基于每个提交的独特方差进行平均，使我们能够更重地加权那些相关性较低且多样性较高的预测，从而更有效地减少估计的方差。
- en: 'In the next example, we will first create a **correlation matrix** of our predicted
    probabilities, and then we proceed by:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个示例中，我们首先将我们的预测概率创建为一个**相关矩阵**，然后我们继续进行以下操作：
- en: Removing the one values on the diagonal and replacing them with zeroes
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除对角线上的一个值并用零替换
- en: Averaging the correlation matrix by row to obtain a vector
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过行平均相关矩阵以获得一个向量
- en: Taking the reciprocal of each row sum
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 取每行总和的倒数
- en: Normalizing their sum to 1.0
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将它们的总和归一化到1.0
- en: Using the resulting weighting vector in a matrix multiplication of our predicted
    probabilities
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用得到的加权向量进行预测概率的矩阵乘法
- en: 'Here is the code for this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这个代码的示例：
- en: '[PRE9]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The resulting ROC-AUC of **0.90206** is slightly better than the plain average.
    Giving more importance to more uncorrelated predictions is an ensembling strategy
    that is often successful. Even if it only provides slight improvements, this could
    suffice to turn the competition to your advantage.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的ROC-AUC值为**0.90206**，略好于简单的平均。给予更多不相关预测更高的重视是一种经常成功的集成策略。即使它只提供了轻微的改进，这也可能足以将比赛转为你的优势。
- en: Averaging in your cross-validation strategy
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在你的交叉验证策略中进行平均
- en: As we have covered, averaging doesn’t require you to build any special complex
    pipelines, only a certain number of typical data pipelines that create the models
    you are going to average, either using the same weights for all predictions or
    some empirically found weights. The only way to test it is to run a submission
    on the public leaderboard, thus risking adaptive fitting because your evaluation
    of the averaging will solely be based on the response from Kaggle.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所讨论的，平均不需要你构建任何特殊的复杂管道，只需要一定数量的典型数据管道来创建你将要平均的模型，无论是使用所有预测相同的权重，还是使用一些经验发现的权重。唯一测试它的方法是在公共排行榜上运行提交，从而冒着自适应拟合的风险，因为你的平均评估将仅基于Kaggle的响应。
- en: 'Before testing directly on the leaderboard, though, you may also test at training
    time by running the averaging operations on the validation fold (the fold that
    you are not using for training your model). This will provide you with less biased
    feedback than that from the leaderboard. In the following code, you can find an
    example of how a cross-validation prediction is arranged:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在直接在排行榜上测试之前，你也可以在训练时间通过在验证折（你未用于训练模型的折）上运行平均操作来测试。这将为你提供比排行榜上更少的偏见反馈。在下面的代码中，你可以找到一个交叉验证预测是如何安排的示例：
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Relying on the results of a cross-validation as in the code above can help you
    evaluate which averaging strategy is more promising, without testing directly
    on the public leaderboard.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于上述代码中的交叉验证结果可以帮助你评估哪种平均策略更有前途，而无需直接在公共排行榜上进行测试。
- en: Correcting averaging for ROC-AUC evaluations
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对ROC-AUC评估进行平均校正
- en: If your task will be evaluated on the ROC-AUC score, simply averaging your results
    may not suffice. This is because different models may have adopted different optimization
    strategies and their outputs may be deeply different. A solution could be to calibrate
    the models, a type of post-processing we previously discussed in *Chapter 5*,
    *Competition Tasks and Metrics*, but this obviously takes further time and computational
    effort.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的任务将根据ROC-AUC分数进行评估，简单地平均你的结果可能不够。这是因为不同的模型可能采用了不同的优化策略，它们的输出可能差异很大。一种解决方案是对模型进行校准，这是我们之前在*第五章*中讨论的一种后处理类型，但显然这需要更多的时间和计算努力。
- en: 'In these cases, the straightforward solution would be to convert output probabilities
    into ranks and just average the ranks (or make a weighted average of them). Using
    a min-max scaler approach, you simply convert each model’s estimates into the
    range 0-1 and then proceed with averaging the predictions. That will effectively
    convert your model’s probabilistic output into ranks that can be compared:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，直接的解决方案是将输出概率转换为排名，然后简单地平均这些排名（或者对它们进行加权平均）。使用min-max缩放器方法，你只需将每个模型的估计值转换为0-1的范围，然后继续进行预测的平均。这将有效地将你的模型的概率输出转换为可以比较的排名：
- en: '[PRE11]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This approach works perfectly when you are directly handling the test predictions.
    If, instead, you are working and trying to average results during cross-validation,
    you may encounter problems because the prediction range of your training data
    may differ from the range of your test predictions. In this case, you can solve
    the problem by training a calibration model (see **probability calibration** on
    Scikit-learn ([https://scikit-learn.org/stable/modules/calibration.html](https://scikit-learn.org/stable/modules/calibration.html))
    and *Chapter 5*), converting predictions into true, comparable probabilities for
    each of your models.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 当你直接处理测试预测时，这种方法工作得非常完美。如果你在交叉验证期间尝试平均结果，你可能会遇到问题，因为你的训练数据的预测范围可能与你的测试预测范围不同。在这种情况下，你可以通过训练一个校准模型来解决该问题（参见Scikit-learn上的**概率校准**[https://scikit-learn.org/stable/modules/calibration.html](https://scikit-learn.org/stable/modules/calibration.html)和*第五章*)，将预测转换为每个模型的真正、可比较的概率。
- en: Blending models using a meta-model
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用元模型进行混合模型
- en: The Netflix competition (which we discussed at length in *Chapter 1*) didn’t
    just demonstrate that averaging would be advantageous for difficult problems in
    a data science competition; it also brought about the idea that you can use a
    model to average your models’ results more effectively. The winning team, BigChaos,
    in their paper (Töscher, A., Jahrer, M., and Bell, R.M. *The BigChaos Solution
    to the Netflix Grand Prize*. Netflix prize documentation – 2009) made many mentions
    of **blending**, and provided many hints about its effectiveness and the way it
    works.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第一章*中详细讨论的Netflix竞赛不仅证明了平均对于数据科学竞赛中的难题是有利的；它还提出了你可以使用一个模型更有效地平均模型结果的想法。获胜团队BigChaos在其论文（Töscher,
    A., Jahrer, M., 和 Bell, R.M. *The BigChaos Solution to the Netflix Grand Prize*.
    Netflix prize documentation – 2009）中多次提到了**混合**，并提供了关于其有效性和工作方式的许多提示。
- en: In a few words, blending is kind of a weighted averaging procedure where the
    weights used to combine the predictions are estimated by way of a holdout set
    and a meta-model trained on it. A **meta-model** is simply a machine learning
    algorithm that learns from the output of other machine learning models. Usually,
    a meta-learner is a linear model (but sometimes it can also be a non-linear one;
    more on that in the next section), but you can actually use whatever you want,
    with some risks that we will discuss.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，混合是一种加权平均过程，其中用于组合预测的权重是通过保留集和在此之上训练的元模型来估计的。**元模型**简单来说就是从其他机器学习模型输出中学习的机器学习算法。通常，元学习器是一个线性模型（但有时也可以是非线性的；关于这一点，我们将在下一节中详细讨论），但实际上你可以使用任何你想要的，但会有一些风险，我们将在后面讨论。
- en: 'The procedure for obtaining a blending is straightforward:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 获得混合的方法非常直接：
- en: Before starting to build all your models, you randomly extract a holdout sample
    from the training data (in a team, you should all use the same holdout). Usually,
    the holdout is about 10% of the available data; however, depending on circumstances
    (for instance, the number of examples in your training data, stratifications),
    it could be less as well as more. As always in sampling, you may enforce stratification
    in order to ensure sampling representativeness, and you can test using adversarial
    validation that the sample really matches the distribution in the rest of the
    training set.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始构建所有模型之前，你应从训练数据中随机提取一个保留样本（在团队中，你们所有人都应使用相同的保留样本）。通常，保留数据大约是可用数据的10%；然而，根据情况（例如，训练数据中的示例数量，分层），它也可能更少或更多。像往常一样，在采样时，你可以强制分层以确保采样具有代表性，并且你可以使用对抗性验证来测试样本是否真的与训练集其余部分的分布相匹配。
- en: Train all your models on the remaining training data.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在剩余的训练数据上训练所有模型。
- en: Predict on the holdout and on the test data.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在保留数据和测试数据上进行预测。
- en: Use the holdout predictions as training data in a meta-learner and reuse the
    meta-learner model to compute the final test predictions using the test predictions
    from your models. Alternatively, you can use the meta-learner to figure out the
    selection of predictors and their weights that should be used in a weighted average.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将保留预测作为元学习器的训练数据，并重新使用元学习器模型，使用你的模型的测试预测来计算最终的测试预测。或者，你可以使用元学习器来确定在加权平均中应使用的预测因子及其权重。
- en: There a quite a few advantages and disadvantages to such a procedure. Let’s
    start with the advantages. First, it is easy to implement; you just have to figure
    out what the holdout sample is. In addition, using a meta-learning algorithm ensures
    you will find the best weights without testing on the public leaderboard.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法有很多优点和缺点。让我们先从优点开始。首先，它很容易实现；你只需要弄清楚保留样本是什么。此外，使用元学习算法可以确保你将找到最佳权重，而无需在公共排行榜上进行测试。
- en: 'In terms of weaknesses, sometimes, depending on sample size and the type of
    models you use, reducing the number of training examples may increase the variance
    of the predictions of your estimators. Moreover, even if you take great care over
    how you sample your holdout, you may still fall into adaptive overfitting, that
    is, finding weights that suit the holdout but are not generalizable, especially
    if you use a meta-learner that is too complex. Finally, using a holdout for testing
    purposes has the same limitations as the training and test split we discussed
    in the chapter on model validation: you won’t have a reliable estimate if the
    sample size of the holdout is too small or if, for some reason, your sampling
    is not representative.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在弱点方面，有时，根据样本大小和所使用的模型类型，减少训练示例的数量可能会增加你的估计器的预测方差。此外，即使你在采样保留数据时非常小心，你仍然可能陷入自适应过拟合，即找到适合保留数据的权重，但这些权重不具有可推广性，特别是如果你使用了一个过于复杂的元学习器。最后，使用保留数据作为测试目的具有与我们在模型验证章节中讨论的训练和测试分割相同的限制：如果保留样本的样本量太小，或者由于某种原因，你的采样不具有代表性，那么你将无法获得可靠的估计。
- en: Best practices for blending
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混合的最佳实践
- en: In blending, the kind of meta-learner you use can make a great difference. The
    most common choices are to use a linear model or a non-linear one. Among linear
    models, linear or logistic regressions are the preferred ones. Using a regularized
    model also helps to discard models that are not useful (L1 regularization) or
    reduce the influence of less useful ones (L2 regularization). One limit to using
    these kinds of meta-learners is that they may assign some models a negative contribution,
    as you will be able to see from the value of the coefficient in the model. When
    you encounter this situation, the model is usually overfitting, since all models
    should be contributing positively to the building of the ensemble (or, at worst,
    not contributing at all). The most recent versions of Scikit-learn allow you to
    impose only positive weights and to remove the intercept. These constraints act
    as a regularizer and prevent overfitting.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在混合中，你使用的元学习器的类型可以产生很大的差异。最常见的选择是使用线性模型或非线性模型。在线性模型中，线性或逻辑回归是首选。使用正则化模型也有助于排除无用的模型（L1正则化）或减少不那么有用的模型的影响（L2正则化）。使用这类元学习器的一个限制是，它们可能会给某些模型分配负贡献，正如你将从模型系数的值中看到的那样。当你遇到这种情况时，模型通常过拟合，因为所有模型都应该对集成（或最坏的情况是，完全不贡献）的建设做出积极贡献。Scikit-learn的最新版本允许你只强制执行正权重，并移除截距。这些约束作为正则化器，防止过拟合。
- en: Non-linear models as meta-learners are less common because they tend to overfit
    in regression and binary classification problems, but they often shine in multiclass
    and multilabel classification problems since they can model the complex relationships
    between the classes present. They also generally perform better if, aside from
    the models’ predictions, you also provide them with the *original features*, since
    they can spot any useful interactions that help them correctly select which models
    to trust more.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 作为元学习器的非线性模型较为少见，因为它们在回归和二分类问题中容易过拟合，但在多分类和多标签分类问题中它们通常表现出色，因为它们可以模拟现有类别之间的复杂关系。此外，如果除了模型的预测之外，你还向它们提供*原始特征*，它们通常表现更好，因为它们可以发现任何有助于它们正确选择更值得信赖的模型的交互作用。
- en: In our next example, we first try blending using a linear model (a logistic
    regression), then a non-linear approach (a random forest). We start by splitting
    the training set into a training part for the blend elements and a holdout for
    the meta-learner. Afterward, we fit the models on the trainable part and predict
    on the holdout.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的下一个例子中，我们首先尝试使用线性模型（逻辑回归）进行混合，然后使用非线性方法（随机森林）。我们首先将训练集分为用于混合元素的训练部分和用于元学习器的保留样本。之后，我们在可训练的部分上拟合模型，并在保留样本上进行预测。
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can now train our linear meta-learner using the probabilities predicted
    on the holdout:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用保留样本上的预测概率来训练我们的线性元学习器：
- en: '[PRE13]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The resulting coefficients are:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的系数如下：
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: By looking at the coefficients, we can figure out which model contributes more
    to the meta-ensemble. However, remember that coefficients also rescale probabilities
    when they are not well calibrated, so a larger coefficient for a model may not
    imply that it is the most important one. If you want to figure out the role of
    each model in the blend by looking at coefficients, you first have to rescale
    them by standardization (in our code example, this has been done using Scikit-learn’s
    `StandardScaler`).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察系数，我们可以判断哪个模型对元集成模型的贡献更大。然而，记住系数在未良好校准时也会重新调整概率，因此一个模型的系数较大并不一定意味着它是最重要的。如果你想要通过观察系数来了解每个模型在混合中的作用，你首先必须通过标准化（在我们的代码示例中，这是使用Scikit-learn的`StandardScaler`完成的）来重新调整它们。
- en: Our output shows us that the SVC and *k*-nearest neighbors models are weighted
    more in the blend than the random forest one; their coefficients are almost equivalent
    and both are larger than the random forest coefficient.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果显示，SVC和*k*最近邻模型在混合中的权重比随机森林模型更高；它们的系数几乎相同，并且都大于随机森林的系数。
- en: 'Once the meta-model is trained, we just predict on our test data and check
    its performance:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦元模型训练完成，我们只需在测试数据上预测并检查其性能：
- en: '[PRE15]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can try the same thing using a non-linear meta-learner, such as a random
    forest, for instance:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用非线性元学习器，例如随机森林，尝试相同的事情：
- en: '[PRE16]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: An alternative to using a linear or non-linear model as a meta-learner is provided
    by the **ensemble selection** technique formalized by *Caruana*, *Niculescu-Mizil*,
    *Crew*, and *Ksikes*.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**集合选择**技术由*Caruana*、*Niculescu-Mizil*、*Crew*和*Ksikes*正式化，为使用线性或非线性模型作为元学习器提供了一个替代方案。'
- en: 'If you are interested in more details, read their famous paper: Caruana, R.,
    Niculescu-Mizil, A., Crew, G., and Ksikes, A. *Ensemble selection from libraries
    of models* (Proceedings of the Twenty-First International Conference on Machine
    Learning, 2004).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对更多细节感兴趣，请阅读他们著名的论文：Caruana, R.，Niculescu-Mizil, A.，Crew, G.，和Ksikes, A.
    *从模型库中进行集合选择*（第二十一届国际机器学习会议论文集，2004年）。
- en: The ensemble selection is actually a weighted average, so it could simply be
    considered analogous to a linear combination. However, it is a constrained linear
    combination (because it is part of a hill-climbing optimization) that will also
    make a selection of models and apply only positive weights to the predictions.
    All this minimizes the risk of overfitting and ensures a more compact solution,
    because the solution will involve a model selection. From this perspective, ensemble
    selection is recommended in all problems where the risk of overfitting is high
    (for instance, because the training cases are few in number or the models are
    too complex) and in real-world applications because of its simpler yet effective
    solution.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 集合选择实际上是一个加权平均，因此它可以简单地被认为是线性组合的类似物。然而，它是一个受约束的线性组合（因为它属于爬山优化的一部分），它还将选择模型并只对预测应用正权重。所有这些都有助于最小化过拟合的风险，并确保一个更紧凑的解决方案，因为解决方案将涉及模型选择。从这个角度来看，在所有过拟合风险较高的问题上（例如，因为训练案例数量很少或模型过于复杂）以及在现实世界应用中，由于它简单而有效的解决方案，推荐使用集合选择。
- en: When using a meta-learner, you are depending on the optimization of its own
    cost function, which may differ from the metric adopted for the competition. Another
    great advantage of ensemble selection is that it can be optimized to any evaluation
    function, so it is mostly suggested when the metric for the competition is different
    from the canon of those typically optimized in machine learning models.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用元学习器时，你依赖于其自身成本函数的优化，这可能与竞赛采用的指标不同。集合选择的另一个巨大优势是它可以优化到任何评估函数，因此当竞赛的指标与机器学习模型通常优化的规范不同时，通常建议使用它。
- en: 'Implementing ensemble selection requires the following steps, as described
    in the paper mentioned previously:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 实施集合选择需要以下步骤，如前述论文所述：
- en: Start with your trained models and a holdout sample.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从你的训练模型和保留样本开始。
- en: Test all your models on the holdout sample and, based on the evaluation metric,
    retain the most effective in a selection (the **ensemble selection**).
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在保留样本上测试所有你的模型，并根据评估指标，保留最有效的模型进行选择（即**集合选择**）。
- en: Then, keep on testing other models that could be added to the one(s) in the
    ensemble selection so that the average of the proposed selection improves over
    the previous one. You can either do this with replacement or without. Without
    replacement, you only put a model into the selection ensemble once; in this case,
    the procedure is just like a simple average after a forward selection. (In a forward
    selection, you iteratively add to a solution the model that improves the performance
    the most, until adding further models no longer improves the performance.) With
    replacement, you can put a model into the selection multiple times, thus resembling
    a weighted average.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，继续测试其他可能添加到集合选择中的模型，以便所提出的选择的平均值优于之前的一个。你可以有放回或无放回地进行。无放回时，你只将一个模型放入选择集合一次；在这种情况下，程序就像在正向选择之后的一个简单平均。（在正向选择中，你迭代地向解决方案添加性能提升最大的模型，直到添加更多模型不再提升性能。）有放回时，你可以将一个模型放入选择多次，从而类似于加权平均。
- en: When you cannot get any further improvement, stop and use the ensemble selection.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你无法获得任何进一步的改进时，停止并使用集合选择。
- en: 'Here is a simple code example of an ensemble selection. We start by deriving
    a holdout sample and a training selection from our original training data. We
    fit the models and obtain the predictions on our holdout, as previously seen when
    blending with a meta-learner:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个集合选择的简单代码示例。我们首先从原始训练数据中推导出一个保留样本和一个训练选择。我们拟合模型并在我们的保留样本上获得预测，就像之前与元学习器混合时所见：
- en: '[PRE17]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the next code snippet, the ensembling is created through a series of iterations.
    At each iteration, we try adding all the models in turn to the present ensemble
    and check if they improve the model. If any of these additions outperforms the
    previous ensemble on the holdout sample, the ensemble is updated and the bar is
    raised to the present level of performance.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个代码片段中，通过一系列迭代创建集成。在每个迭代中，我们尝试依次将所有模型添加到当前的集成中，并检查它们是否提高了模型。如果这些添加中的任何一个在保留样本上优于之前的集成，则集成将被更新，并且性能水平将提高到当前水平。
- en: 'If no addition can improve the ensemble, the loop is stopped and the composition
    of the ensemble is reported back:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有额外的改进可以提高集成，循环就会停止，并报告集成的组成：
- en: '[PRE18]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Finally, we count how many times each model has been inserted into the average
    and we calculate the weights for our averaging on the test set:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算每个模型被插入平均值的次数，并计算我们在测试集上的平均权重：
- en: '[PRE19]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: You can make the procedure more sophisticated in various ways. Since this approach
    may overfit, especially at the initial stages, you could start from a randomly
    initialized ensemble set or, as the authors suggest, you may already be starting
    with the *n* best performing models in the set (you decide the value of *n*, as
    a hyperparameter). Another variation involves applying sampling to the set of
    models that can enter the selection at each iteration; in other words, you randomly
    exclude some models from being picked. Not only will this inject randomness into
    the process but it will also prevent specific models from dominating the selection.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过各种方式使该过程更加复杂。由于这种方法可能会在初始阶段过度拟合，你可以从一个随机初始化的集成集开始，或者，正如作者所建议的，你可能已经从集合并行中开始使用*n*个表现最好的模型（你决定*n*的值，作为一个超参数）。另一种变化涉及在每个迭代中对可以进入选择的模型集应用采样；换句话说，你随机排除一些模型不被选中。这不仅会将随机性注入到过程中，而且还会防止特定模型在选择中占主导地位。
- en: Stacking models together
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组合堆叠模型
- en: '**Stacking** was first mentioned in *David Wolpert*’s paper (*Wolpert, D. H*.
    *Stacked generalization.* Neural networks 5.2 – 1992), but it took years before
    the idea become widely accepted and common (only with release 0.22 in December
    2019, for instance, has Scikit-learn implemented a stacking wrapper). This was
    due principally to the Netflix competition first, and to Kaggle competitions afterward.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**堆叠**首次在*David Wolpert*的论文（*Wolpert, D. H*. *Stacked generalization.* Neural
    networks 5.2 – 1992）中提到，但这个想法在多年后才被广泛接受和普及（例如，只有到2019年12月发布的0.22版本，Scikit-learn才实现了堆叠包装器）。这主要是因为Netflix竞赛，其次是Kaggle竞赛。'
- en: In stacking, you always have a meta-learner. This time, however, it is not trained
    on a holdout, but on the entire training set, thanks to the **out-of-fold** (**OOF**)
    prediction strategy. We already discussed this strategy in *Chapter 6*, *Designing
    Good Validation*. In OOF prediction, you start from a replicable *k*-fold cross-validation
    split. *Replicable* means that, by recording the cases in each training and testing
    sets at each round or by reproducibility assured by a random seed, you can replicate
    the same validation scheme for each model you need to be part of the stacking
    ensemble.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在堆叠中，你始终有一个元学习器。然而，这次它不是在保留集上训练，而是在整个训练集上训练，这得益于**折叠外**（**OOF**）预测策略。我们已经在*第6章*，*设计良好的验证*中讨论了这种策略。在OOF预测中，你从一个可复制的*k*-折交叉验证分割开始。*可复制的*意味着，通过记录每一轮每个训练和测试集中的案例，或者通过随机种子保证的可重复性，你可以为需要成为堆叠集成一部分的每个模型复制相同的验证方案。
- en: In the Netflix competition, stacking and blending were often used interchangeably,
    though the actual method devised by Wolpert originally implied leveraging a scheme
    based on *k*-fold cross-validation, not a holdout set. In fact, the core idea
    in stacking is not to reduce the variance, as in averaging; it is mostly to reduce
    the bias, because it is expected that each model involved in the stacking will
    grasp a part of the information present in the data, to be recomposed in the final
    meta-learner.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在Netflix竞赛中，堆叠和混合经常被互换使用，尽管Wolpert最初设计的方法实际上意味着利用基于*k*-折交叉验证的方案，而不是保留集。事实上，堆叠的核心思想不是像平均那样减少方差；它主要是为了减少偏差，因为预计每个参与堆叠的模型都将掌握数据中存在的一部分信息，以便在最终的元学习器中重新组合。
- en: Let’s remind ourselves of how OOF predictions on the training data work. When
    testing a model, at each round of the validation you train a model on part of
    the training data and you validate on another part that is held out from the training.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下在训练数据上进行的OOF预测是如何工作的。在测试模型时，在每次验证中，你都在训练数据的一部分上训练一个模型，并在从训练中保留的另一部分上进行验证。
- en: By recording the validation predictions and then reordering them to reconstruct
    the ordering of the original training cases, you will obtain a prediction of your
    model on the very same training set that you have used. However, as you have used
    multiple models and each model has predicted on cases it didn’t use for training,
    you should not have any overfitting effects on your training set predictions.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 通过记录验证预测并重新排序以重建原始训练案例的顺序，你将获得对你所使用的训练集的模型预测。然而，由于你使用了多个模型，并且每个模型都预测了它没有用于训练的案例，因此你的训练集预测不应该有任何过拟合效应。
- en: 'Having obtained OOF predictions for all your models, you can proceed to build
    a meta-learner that predicts your target based on the OOF predictions (first-level
    predictions), or you can keep on producing further OOF predictions on top of your
    previous OOF predictions (second- or higher-level predictions), thus creating
    multiple stacking layers. This is compatible with an idea presented by Wolpert
    himself: by using multiple meta-learners, you are actually imitating the structure
    of a fully connected feedforward neural network without backpropagation, where
    the weights are optimally calculated in order to maximize the predictive performance
    at the level of each layer separately. From a practical point of view, stacking
    multiple layers has proven very effective and works very well for complex problems
    where single algorithms are unable to obtain the best results.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 获得所有模型的OOF预测后，你可以继续构建一个元学习器，该学习器根据OOF预测（第一级预测）预测你的目标，或者你可以在之前的OOF预测之上继续产生进一步的OOF预测（第二级或更高级预测），从而创建多个堆叠层。这与Wolpert本人提出的一个想法相兼容：通过使用多个元学习器，你实际上是在模仿一个没有反向传播的完全连接的前馈神经网络的结构，其中权重被优化计算，以单独在每个层级别最大化预测性能。从实际的角度来看，堆叠多层已被证明非常有效，对于单算法无法获得最佳结果的复杂问题，它工作得非常好。
- en: Moreover, one interesting aspect of stacking is that you don’t need models of
    comparable predictive power, as in averaging and often in blending. In fact, even
    worse-performing models may be effective as part of a stacking ensemble. A *k*-nearest
    neighbors model may not be comparable to a gradient boosting solution, but when
    you use its OOF predictions for stacking it may contribute positively and increase
    the predictive performance of the ensemble.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，堆叠的一个有趣方面是，你不需要具有可比预测能力的模型，就像在平均和通常在混合中那样。事实上，甚至表现更差的模型也可能是堆叠集成的一部分。一个*k*最近邻模型可能无法与梯度提升解决方案相提并论，但当你使用其OOF预测进行堆叠时，它可能产生积极的影响，并提高集成的预测性能。
- en: When you have trained all the stacking layers, it is time to predict. As far
    as producing the predictions used at various stacking stages, it is important
    to note that you have two ways to do this. The original Wolpert paper suggests
    re-training your models on all your training data and then using those re-trained
    models for predicting on the test set. In practice, many Kagglers don’t retrain,
    but directly use the models created for each fold and make multiple predictions
    on the test set that are averaged at the end.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当你训练了所有堆叠层后，就到了预测的时候了。至于产生在各个堆叠阶段使用的预测，重要的是要注意你有两种方法来做这件事。Wolpert的原始论文建议在所有训练数据上重新训练你的模型，然后使用这些重新训练的模型在测试集上进行预测。在实践中，许多Kagglers没有重新训练，而是直接使用为每个折叠创建的模型，并在测试集上进行多次预测，最后进行平均。
- en: In our experience, stacking is generally more effective with complete re-training
    on all available data before predicting on the test set when you are using a low
    number of *k*-folds. In these cases, the sample consistency may really make a
    difference in the quality of the prediction because training on less data means
    getting more variance in the estimates. As we discussed in *Chapter 6*, when creating
    OOF predictions it is always better to use a high number of folds, between 10
    to 20\. This limits the number of examples that are held out, and, without re-training
    on all the data, you can simply use the average of predictions obtained from the
    cross-validation trained models for obtaining your prediction on the test set.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的经验中，当使用少量*k*折时，堆叠通常在预测测试集之前在所有可用数据上完全重新训练时更有效。在这些情况下，样本一致性可能真的会在预测质量上产生差异，因为训练在较少数据上意味着估计的方差更大。正如我们在*第6章*中讨论的，在创建OOF预测时，始终最好使用高数量的折，在10到20之间。这限制了保留的示例数量，并且，在没有对所有数据进行重新训练的情况下，您可以直接使用从交叉验证训练模型获得的预测的平均值来获得您的测试集预测。
- en: 'In our next example, for illustrative purposes, we only have five CV folds
    and the results are stacked twice. In the diagram below, you can follow how the
    data and the models move between different stages of the stacking process:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的下一个例子中，为了说明目的，我们只有五个CV折，结果被堆叠了两次。在下图中，您可以跟踪数据和模型如何在堆叠过程的各个阶段之间移动：
- en: '![](img/B17574_09_01.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17574_09_01.png)'
- en: 'Figure 9.1: Diagram of a two-layer stacking process with final averaging of
    predictions'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1：两层堆叠过程的示意图，最终对预测进行平均
- en: 'Notice that:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：
- en: Training data is fed to both levels of the stacking (OOF predictions at the
    second level of the stacking are joined with the training data)
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据被输入到堆叠的每一层（堆叠的第二层中的OOF预测与训练数据相结合）
- en: After obtaining OOF predictions from the CV loops, models are re-trained on
    the entire training dataset
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在从CV循环中获得OOF预测后，模型在完整的训练数据集上重新训练：
- en: The final predictions are a simple average of all the predictions obtained by
    the stacked predictors
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终预测是所有堆叠预测器获得的预测的简单平均值
- en: 'Let’s now take a look at the code to understand how this diagram translates
    into Python commands, starting with the first level of training:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看代码，了解这个图如何转换为Python命令，从第一层训练开始：
- en: '[PRE20]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After the first layer, we retrain on the full dataset:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一层之后，我们在完整的数据集上重新训练：
- en: '[PRE21]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the second stacking, we will reuse the same models as those in the first
    layer, adding the stacked OOF predictions to the existing variables:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次堆叠中，我们将重用第一层中的相同模型，并将堆叠的OOF预测添加到现有变量中：
- en: '[PRE22]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Again, we retrain on the full data for the second layer:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们在第二层对完整数据进行重新训练：
- en: '[PRE23]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The stacking is concluded by averaging all the stacked OOF results from the
    second layer:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠通过平均第二层中所有堆叠的OOF结果来完成：
- en: '[PRE24]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The resulting ROC-AUC score is about **0.90424**, which is better than previous
    blending and averaging attempts on the same data and models.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的ROC-AUC分数约为**0.90424**，这比在相同数据和模型上之前的混合和平均尝试要好。
- en: Stacking variations
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 堆叠变体
- en: The main variations on stacking involve changing how test data is processed
    across the layers, whether to use only stacked OOF predictions or also the original
    features in all the stacking layers, what model to use as the last one, and various
    tricks in order to prevent overfitting.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠的主要变体涉及改变测试数据在层之间的处理方式，是否只使用堆叠的OOF预测，还是在所有堆叠层中也使用原始特征，以及使用什么模型作为最后一个模型，以及各种防止过拟合的技巧。
- en: 'We discuss some of the most effective here that we have personally experimented
    with:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了一些我们亲自实验过的最有效的方法：
- en: '**Optimization may or may not be used.** Some solutions do not care too much
    about optimizing single models; others optimize only the last layers; others optimize
    on the first layers. Based on our experiences, optimization of single models is
    important and we prefer to do it as early as possible in our stacking ensemble.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化可能使用也可能不使用**。有些解决方案不太关心优化单个模型；有些只优化最后一层；有些则优化第一层。根据我们的经验，优化单个模型很重要，我们更喜欢尽早在我们的堆叠集成中完成它。'
- en: '**Models can differ at the different stacking layers, or the same sequence
    of models can be repeated at every stacking layer.** Here we don’t have a general
    rule, as it really depends on the problem. The kind of models that are more effective
    may vary according to the problem. As a general suggestion, putting together gradient
    boosting solutions and neural networks has never disappointed us.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型可以在不同的堆叠层中有所不同，或者相同的模型序列可以在每个堆叠层中重复。** 这里我们没有一个普遍的规则，因为这真的取决于问题。更有效的模型类型可能因问题而异。作为一个一般建议，将梯度提升解决方案和神经网络结合起来从未让我们失望。'
- en: '**At the first level of the stacking procedure, just create as many models
    are possible.** For instance, you can try a regression model if your problem is
    a classification one, and vice versa. You can also use different models with different
    hyperparameter settings, thus avoiding too much extensive optimization because
    the stacking will decide for you. If you are using neural networks, just changing
    the random initialization seed could suffice to create a diverse bag of models.
    You can also try models using different feature engineering and even use unsupervised
    learning (like *Mike Kim* did when he used t-SNE dimensions in a solution of his:
    [https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295)).
    The idea is that the selection of all such contributions is done during the second
    level of the stacking. This means that, at that point, you do not have to experiment
    any further and you just need to focus on a narrower set of better-performing
    models. By applying stacking, you can re-use all your experiments and let the
    stacking decide for you to what degree you should use something in your modeling
    pipeline.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在堆叠过程的第一个层次，尽可能多地创建模型。** 例如，如果你的问题是分类问题，可以尝试回归模型，反之亦然。你也可以使用具有不同超参数设置的模型，从而避免过度优化，因为堆叠会为你做出决定。如果你使用神经网络，只需改变随机初始化种子就足以创建一个多样化的模型集合。你也可以尝试使用不同的特征工程，甚至使用无监督学习（例如，*Mike
    Kim* 在使用 t-SNE 维度解决他的问题时所做的那样：[https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295)）。这种想法是，所有这些贡献的选择都是在堆叠的第二层完成的。这意味着在那个点上，你不需要进一步实验，只需专注于一组表现更好的模型。通过应用堆叠，你可以重用所有实验，并让堆叠为你决定在建模过程中使用到什么程度。'
- en: 'Some stacking implementations take on all the features or a selection of them
    to further stages, reminiscent of skip layers in neural networks. We have noticed
    that bringing in features at later stages in the stacking can improve your results,
    but be careful: it also brings in more noise and risk of overfitting.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些堆叠实现会采用所有功能或其中一部分功能进入后续阶段，这让人联想到神经网络中的跳层。我们注意到，在堆叠的后期引入特征可以提高你的结果，但请注意：这也引入了更多的噪声和过拟合的风险。
- en: Ideally, your OOF predictions should be made from cross-validation schemes with
    a high number of folds, in other words, between 10 to 20, but we have also seen
    solutions working with a lower number, such as 5 folds.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理想情况下，你的 OOF 预测应该来自具有高折叠数的交叉验证方案，换句话说，在 10 到 20 之间，但我们也看到过使用较低折叠数（如 5 折）的解决方案。
- en: For each fold, bagging the data (resampling with repetition) multiple times
    for the same model and then averaging all the results from the model (OOF predictions
    and test predictions) helps to avoid overfitting and produces better results in
    the end.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个折叠，对同一模型进行多次数据袋装（重复抽样的重采样）然后平均所有模型的结果（OOF 预测和测试预测）有助于避免过拟合，并最终产生更好的结果。
- en: '**Beware of early stopping in stacking.** Using it directly on the validation
    fold may cause a certain degree of overfitting, which may or may not be mitigated
    in the end by the stacking procedure. We suggest you play it safe and always apply
    early stopping based on a validation sample from your training folds, not your
    validation one.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注意堆叠中的早期停止。** 直接在验证折上使用它可能会导致一定程度的过拟合，这最终可能或可能不会通过堆叠过程得到缓解。我们建议你谨慎行事，并始终基于训练折的验证样本应用早期停止，而不是验证折本身。'
- en: The possibilities are endless. Once you have grasped the basic concept of this
    ensembling technique, all you need is to apply your creativity to the problem
    at hand. We will discuss this key concept in the final section of this chapter,
    where we will look at a stacking solution for a Kaggle competition.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 可能性是无限的。一旦你掌握了这种集成技术的基本概念，你所需要做的就是将你的创造力应用于手头的问题。我们将在本章的最后部分讨论这个关键概念，我们将研究一个
    Kaggle 比赛的堆叠解决方案。
- en: Creating complex stacking and blending solutions
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建复杂的堆叠和混合解决方案
- en: 'At this point in the chapter, you may be wondering to what extent you should
    apply the techniques we have been discussing. In theory, you could use all the
    ensembling techniques we have presented in any competition on Kaggle, not just
    tabular ones, but you have to consider a few limiting factors:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的这一部分，你可能想知道应该将我们讨论过的技术应用到什么程度。从理论上讲，你可以在 Kaggle 上的任何比赛中使用我们提出的所有集成技术，而不仅仅是表格比赛，但你必须考虑一些限制因素：
- en: Sometimes, datasets are massive, and training a single model takes a long time.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时，数据集很大，训练单个模型需要很长时间。
- en: In image recognition competitions, you are limited to using deep learning methods.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像识别比赛中，你只能使用深度学习方法。
- en: Even if you can manage to stack models in a deep learning competition, you have
    a limited choice for stacking different models. Since you are restricted to deep
    learning solutions, you can only vary small design aspects of the networks and
    some hyperparameters (or sometimes just the initialization seed) without degrading
    the performance. In the end, given the same type of models and more similarities
    than differences in the architectures, the predictions will tend to be too similar
    and more correlated than they should be, limiting the effectiveness of ensembling.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使你能在深度学习比赛中堆叠模型，可供堆叠的不同模型的选择也很有限。由于你被限制在深度学习解决方案中，你只能改变网络的小设计方面和一些超参数（有时只是初始化种子），而不会降低性能。最终，鉴于相同的模型类型和架构中相似性多于差异，预测将过于相似，相关性过高，从而限制了集成技术的有效性。
- en: Under these conditions, complex stacking regimes are usually not feasible. By
    contrast, averaging and blending are usually possible when you have large datasets.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些条件下，复杂的堆叠制度通常不可行。相比之下，当您拥有大量数据集时，平均和混合通常是可能的。
- en: In earlier competitions, as well as in all recent tabular competitions, complex
    stacking and blending solutions ruled the day. To give you an idea of the complexity
    and creativity that needs to be put into stacking for a competition, in this last
    section we will discuss the solution provided by *Gilberto Titericz* ([https://www.kaggle.com/titericz](https://www.kaggle.com/titericz))
    and *Stanislav Semenov* ([https://www.kaggle.com/stasg7](https://www.kaggle.com/stasg7))
    to the *Otto Group Product Classification Challenge* ([https://www.kaggle.com/c/otto-group-product-classification-challenge](https://www.kaggle.com/c/otto-group-product-classification-challenge)).
    The competition was held in 2015 and its task required classifying over 200,000
    products into 9 distinct classes based on 93 features.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期的比赛中，以及所有最近的表格比赛中，复杂的堆叠和混合解决方案主导了比赛。为了给您一个关于在比赛中堆叠所需复杂性和创造性的概念，在本节的最后，我们将讨论由
    *Gilberto Titericz* ([https://www.kaggle.com/titericz](https://www.kaggle.com/titericz))
    和 *Stanislav Semenov* ([https://www.kaggle.com/stasg7](https://www.kaggle.com/stasg7))
    为 *Otto Group 产品分类挑战赛* ([https://www.kaggle.com/c/otto-group-product-classification-challenge](https://www.kaggle.com/c/otto-group-product-classification-challenge))
    提供的解决方案。该比赛于 2015 年举行，其任务要求根据 93 个特征将超过 200,000 个产品分类到 9 个不同的类别。
- en: 'The solution proposed by Gilberto and Stanislav comprised three levels:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Gilberto 和 Stanislav 提出的解决方案包含三个级别：
- en: On the first level, there were 33 models. All the models used quite different
    algorithms, apart from a cluster of *k*-nearest neighbors where only the *k* parameter
    varied. They also used unsupervised t-SNE. In addition, they engineered eight
    features based on dimensionality manipulation (computations performed on distances
    from nearest neighbors and clusters) and on row statistics (the number of non-zero
    elements in each row). All the OOF predictions and features were passed to the
    second level.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一级，有 33 个模型。除了一个 *k* 近邻簇，其中只有 *k* 参数不同之外，所有模型都使用了相当不同的算法。他们还使用了无监督的 t-SNE。此外，他们基于维度操作（在最近邻和簇的距离上执行的计算）和行统计（每行中非零元素的数量）构建了八个特征。所有
    OOF 预测和特征都传递到了第二级。
- en: 'On the second level, they started optimizing hyperparameters and doing model
    selection and bagging (they created multiple versions of the same model by resampling
    and averaged the results for each model). In the end, they had only three models
    that they re-trained on all the data: an XGBoost, an AdaBoost, and a neural network.'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二层，他们开始优化超参数，进行模型选择和袋装（通过重采样创建了多个相同模型的版本，并对每个模型的结果进行了平均）。最终，他们只对三种模型在所有数据上进行了重新训练：XGBoost、AdaBoost和神经网络。
- en: On the third level, they prepared a weighted average of the results by first
    doing a geometric mean of XGBoost and the neural network and then averaging it
    with the AdaBoost.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三层，他们首先对XGBoost和神经网络进行几何平均，然后将其与AdaBoost的结果平均，从而准备了一个加权平均的结果。
- en: We can learn a lot from this solution, and not just limited to this competition.
    Aside from the complexity (on the second level, the number of times they resampled
    was in the order of hundreds for each model), it is noticeable that there are
    multiple variations on the schemes we discussed in this chapter. Creativity and
    trial and error clearly dominate the solution. This is quite typical of many Kaggle
    competitions, where the problems are seldom the same from one competition to another
    and each solution is unique and not easily repeatable.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从这个解决方案中学到很多，而不仅仅局限于这个比赛。除了复杂性（在第二层，每个模型重采样的次数在数百次左右）之外，值得注意的是，关于本章中讨论的方案存在多种变体。创造性和试错显然主导了解决方案。这在许多Kaggle比赛中相当典型，因为问题很少从一场比赛到另一场比赛相同，每个解决方案都是独特的且难以重复。
- en: Many AutoML engines, such as **AutoGluon**, more or less explicitly try to take
    inspiration from such procedures in order to offer a predefined series of automated
    steps that can ensure you a top result by stacking and blending.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 许多AutoML引擎，例如**AutoGluon**，或多或少地试图从这些程序中汲取灵感，以提供一系列预定义的自动化步骤，通过堆叠和混合确保您获得最佳结果。
- en: See [https://arxiv.org/abs/2003.06505](https://arxiv.org/abs/2003.06505) for
    a list of the algorithms used by AutoGluon to build its stacked models. The list
    is quite long and you will find many ideas for your own stacking solutions.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[https://arxiv.org/abs/2003.06505](https://arxiv.org/abs/2003.06505)以获取AutoGluon构建其堆叠模型所使用的算法列表。列表相当长，您将找到许多为自己的堆叠解决方案提供灵感的想法。
- en: However, despite the fact they implement some of the best practices around,
    their results are always subpar compared to what can be achieved by a good team
    of Kagglers, because creativity in the way you experiment and compose the ensemble
    is the key to success. The same goes for this chapter of ours. We have shown you
    the best practices for ensembling; take them as a starting point and create your
    own by mixing ideas and innovating based on the Kaggle competition or the real-world
    problem that you are dealing with.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管他们实施了围绕最佳实践的一些最佳做法，但与一支优秀的Kagglers团队所能实现的结果相比，他们的结果总是略逊一筹，因为你在实验和组合集成的方式中的创造力是成功的关键。这一点也适用于我们本章的内容。我们向您展示了集成最佳实践；将它们作为起点，通过混合想法并根据您在Kaggle比赛或您正在处理的现实世界问题中进行创新来创建自己的解决方案。
- en: '![](img/Xavier_Conort.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![Xavier_Conort](img/Xavier_Conort.png)'
- en: Xavier Conort
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Xavier Conort
- en: '[https://www.kaggle.com/xavierconort](https://www.kaggle.com/xavierconort)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/xavierconort](https://www.kaggle.com/xavierconort)'
- en: 'To conclude the chapter, we caught up with Xavier Conort, a Competitions Grandmaster
    who ranked #1 in 2012-2013\. An inspiration for many Kagglers at the beginning
    of Kaggle history, he is now the founder and CEO of his own company, Data Mapping
    and Engineering. He spoke to us about his experiences with Kaggle, his career,
    and more.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结本章，我们采访了Xavier Conort，他是2012-2013年的比赛大师，排名第一。他是Kaggle历史初期许多Kagglers的灵感来源，现在是他自己公司的创始人兼首席执行官，Data
    Mapping and Engineering。他向我们讲述了他在Kaggle的经历、他的职业生涯以及更多内容。
- en: What’s your favourite kind of competition and why? In terms of techniques and
    solving approaches, what is your speciality on Kaggle?
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你最喜欢的比赛类型是什么？为什么？在技术和解决方法方面，你在Kaggle上的专长是什么？
- en: '*I really enjoyed competitions where feature engineering from multiple tables
    was required to get good results. I liked to mine for good features, especially
    for business problems that were new to me. This gave me a lot of confidence in
    my capacity to tackle new problems. In addition to good feature engineering, stacking
    helped me get good results. I used it to blend multiple models or transform text
    or high categorical variables into numeric features. My favorite algorithm was
    GBM, but I tested many other algorithms to add diversity to my blends.*'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '*我真的很喜欢那些需要从多个表格中进行特征工程才能获得好成绩的比赛。我喜欢挖掘好的特征，尤其是对于我来说全新的商业问题。这让我对自己的能力解决新问题充满了信心。除了好的特征工程，堆叠也帮助我获得了好成绩。我使用它来混合多个模型或转换文本或高分类变量为数值特征。我最喜欢的算法是GBM，但我测试了许多其他算法来增加我的混合多样性。*'
- en: How do you approach a Kaggle competition? How different is this approach to
    what you do in your day-to-day work?
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 您是如何处理Kaggle比赛的？这种方法和您日常工作的方法有何不同？
- en: '*My primary goal was to learn as much as possible from each competition. Before
    entering a competition, I tried to assess which skills I would develop. I was
    not afraid to go beyond my comfort zone. Thanks to the leaderboard feedback, I
    knew I could learn rapidly from my mistakes. Day-to-day work rarely offers this
    opportunity. It is difficult to assess the actual quality of the solution we are
    working on. So, we just play safe and tend to repeat past recipes. I don’t think
    I could have learnt as much as I did without Kaggle.*'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '*我的主要目标是尽可能从每次比赛中学习到知识。在参加比赛之前，我试图评估我将发展哪些技能。我不害怕超越我的舒适区。多亏了排行榜的反馈，我知道我可以快速从我的错误中学习。日常工作中很少有这样的机会。很难评估我们正在努力解决的问题的实际质量。因此，我们只是保持谨慎，倾向于重复过去的食谱。我认为没有Kaggle，我无法学到这么多。*'
- en: Tell us about a particularly challenging competition you entered, and what insights
    you used to tackle the task.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 请告诉我们您参加的一个特别具有挑战性的比赛，以及您使用了哪些见解来应对这项任务。
- en: '*My favorite competition is* GE Flight Quest*, a competition organised by GE
    where competitors had to predict arrival time of domestic flights in the US. I
    especially liked the way the competition’s private leaderboard was designed. It
    tested our capacity to predict future events by scoring our predictions on flights
    that happened after the competition deadline.*'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '*我最喜欢的比赛是* GE Flight Quest*，这是由GE组织的一项比赛，参赛者需要预测美国国内航班的到达时间。我特别喜欢比赛私人排行榜的设计方式。它通过对我们预测在比赛截止日期之后发生的航班的准确性进行评分，来测试我们预测未来事件的能力。*'
- en: '*As we had* *only a few months of history (3 or 4, if my memory is correct),
    I knew there was a strong risk of overfitting. To mitigate this risk, I decided
    to build only features that had an obvious causal relation with flight delays,
    such as features measuring weather conditions and traffic. And I was very careful
    to exclude the name of the airport from my primary feature lists. Indeed, some
    airports hadn’t experienced bad weather conditions during the few months of history.
    So, I was very concerned that my favorite ML algorithm, GBM, would use the name
    of the airport as a proxy for good weather and then fail to predict well for those
    airports in the private leaderboard. To capture the fact that some airports are
    better managed than others and improve my leaderboard score slightly, I eventually
    did use the name of the airport, but as a residual effect only. It was a feature
    of my second layer of models that used as an offset the predictions of my first
    layer of models. This approach can be considered a two-step boosting, where you
    censor some information during the first step. I learnt it from actuaries applying
    this approach in insurance to capture geospatial residual effects.*'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '*因为我们只有几个月的历史（如果我的记忆正确，是3或4个月），我知道有很强的过拟合风险。为了减轻这种风险，我决定只构建与航班延误有明显的因果关系的特征，例如测量天气条件和交通状况的特征。我非常小心地排除了机场名称从我主要特征列表中。事实上，在短短几个月的历史中，一些机场没有经历过恶劣的天气条件。因此，我非常担心我最喜欢的机器学习算法GBM会使用机场名称作为良好天气的代理，然后无法很好地预测那些在私人排行榜上的机场。为了捕捉一些机场比其他机场管理得更好的事实，并略微提高我的排行榜分数，我最终确实使用了机场名称，但仅作为残余效应。这是我的第二层模型的一个特征，它使用第一层模型的预测作为偏移量。这种方法可以被认为是一种两步提升，其中你在第一步中抑制了一些信息。我从应用此方法以捕捉地理空间残余效应的精算师那里学到了这一点。*'
- en: Has Kaggle helped you in your career? If so, how?
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle是否帮助了您的职业生涯？如果是的话，是如何帮助的？
- en: '*It definitely helped me in my career as a data scientist. Before converting
    into data science, I was an actuary in the insurance industry, didn’t know anything
    about machine learning, and didn’t know any data scientists. Thanks to Kaggle’s
    diversity of competitions, I boosted my learning curve. Thanks to my good results,
    I could show a track record and convince employers that a 39-year-old actuary
    could successfully develop new skills on his own. And thanks to Kaggle’s community,
    I connected with many passionate data scientists across the world. I first had
    a lot of fun competing with or against them. Finally, I had the chance to work
    with some of them. Jeremy Achin and Tom De Godoy, the DataRobot founders, were
    my competition teammates before they asked me to join DataRobot. Without Kaggle’s
    help, I think I would still be working as an actuary in the insurance industry.*'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '*这无疑帮助了我作为数据科学家的职业生涯。在转向数据科学之前，我是一名保险行业的精算师，对机器学习一无所知，也不认识任何数据科学家。多亏了Kaggle竞赛的多样性，我加速了我的学习曲线。多亏了我的好成绩，我能够展示我的成绩记录，并说服雇主一个39岁的精算师可以独立成功开发新技能。而且多亏了Kaggle的社区，我与世界各地的许多充满激情的数据科学家建立了联系。我最初与他们竞争或对抗时非常开心。最后，我有机会与他们中的一些人一起工作。Jeremy
    Achin和Tom De Godoy，DataRobot的创始人，在我被邀请加入DataRobot之前是我的竞争对手。如果没有Kaggle的帮助，我认为我可能还在保险行业作为精算师工作。*'
- en: Have you ever used something you have done in Kaggle competitions in order to
    build your portfolio to show to potential employers?
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经使用过你在Kaggle比赛中做过的某些事情来构建你的投资组合，以展示给潜在雇主？
- en: '*I have to confess that I did enter a few competitions with the goal to impress
    my employer or potential clients. It worked well, but it was much less fun and
    much more pressure.*'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '*我必须承认，我曾参加过一些比赛，目的是为了给我的雇主或潜在客户留下深刻印象。这很有效，但乐趣更少，压力更大。*'
- en: In your experience, what do inexperienced Kagglers often overlook? What do you
    know now that you wish you’d known when you first started?
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的经验中，没有经验的新手Kagglers经常忽略什么？你现在知道什么，而你在最初开始时希望知道的呢？
- en: '*I would advise* *inexperienced Kagglers not to look at the solutions posted
    during the competition but to try to find good solutions on their own. I am happy
    that competitors didn’t share code during the early days of Kaggle. It forced
    me to learn the hard way.*'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '*我建议没有经验的Kagglers不要在比赛期间查看发布的解决方案，而应尝试自己找到好的解决方案。我很高兴在Kaggle早期，竞争者没有分享代码。这迫使我通过艰难的方式学习。*'
- en: What mistakes have you made in competitions in the past?
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 你在过去比赛中犯过哪些错误？
- en: '*One mistake is to keep on competing in competitions that are badly designed
    with leaks. It is just a waste of time. You don’t learn much from those competitions.*'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '*一个错误是继续参加设计不良且存在泄露的比赛。这纯粹是浪费时间。你从那些比赛中学不到很多东西。*'
- en: Are there any particular tools or libraries that you would recommend using for
    data analysis or machine learning?
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 有没有你推荐的特定工具或库用于数据分析或机器学习？
- en: '*Gradient Boosting Machine is my favorite algorithm. I first used R’s gbm,
    then Scikit-learn GBM, then XGBoost, and finally LightGBM. Most of the time, it
    has been the principal ingredient of my winning solution. To get some insight
    into what GBM learns, I would recommend the SHAP package.*'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '*梯度提升机是我最喜欢的算法。我最初使用了R的gbm，然后是Scikit-learn GBM，然后是XGBoost，最后是LightGBM。大多数时候，它一直是我的获胜解决方案的主要成分。为了了解GBM学习的内容，我推荐使用SHAP包。*'
- en: What’s the most important thing someone should keep in mind or do when they’re
    entering a competition?
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 当人们参加比赛时，他们应该记住或做些什么最重要的事情？
- en: '*Compete to learn. Compete to connect with other passionate data scientists.
    Don’t compete only to win.*'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '*竞争是为了学习。竞争是为了与其他充满激情的数据科学家建立联系。不要只是为了赢得比赛而竞争。*'
- en: Summary
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed how ensembling multiple solutions works and proposed
    some basic code examples you can use to start building your own solutions. We
    started from the ideas that power model ensembles such as random forests and gradient
    boosting. Then, we moved on to explore the different ensembling approaches, from
    the simple averaging of test submissions to meta-modeling across multiple layers
    of stacked models.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何将多个解决方案进行集成，并提出了你可以用来开始构建自己解决方案的一些基本代码示例。我们从随机森林和梯度提升等模型集成背后的思想开始。然后，我们继续探讨不同的集成方法，从简单的测试提交平均到跨多层堆叠模型的元建模。
- en: As we discussed at the end, ensembling is more an art form based on some shared
    common practices. When we explored a successful complex stacking regime that won
    a Kaggle competition, we were amazed by how the combinations were tailored to
    the data and the problem itself. You cannot just take a stacking, replicate it
    on another problem, and hope that it will be the best solution. You can only follow
    guidelines and find the best solution consisting of averaging/stacking/blending
    of diverse models yourself, through lots of experimentation and computational
    effort.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论的结尾，集成更多是基于一些共享的共同实践的艺术形式。当我们探索到一个成功的复杂堆叠机制，并在 Kaggle 竞赛中获胜时，我们对其如何针对数据和问题本身进行定制组合感到惊讶。你不能只是拿一个堆叠，复制到另一个问题上，并希望它是最佳解决方案。你只能遵循指南，通过大量的实验和计算工作，自己找到由平均/堆叠/混合的多种模型组成的最佳解决方案。
- en: In the next chapter, we will start delving into deep learning competitions,
    beginning with computer vision ones for classification and segmentation tasks.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始深入研究深度学习竞赛，从计算机视觉竞赛开始，用于分类和分割任务。
- en: Join our book’s Discord space
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的 Discord 空间
- en: 'Join the book’s Discord workspace for a monthly *Ask me Anything* session with
    the authors:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 加入书籍的 Discord 工作空间，每月与作者进行一次 *问我任何问题* 的活动：
- en: '[https://packt.link/KaggleDiscord](https://packt.link/KaggleDiscord)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/KaggleDiscord](https://packt.link/KaggleDiscord)'
- en: '![](img/QR_Code40480600921811704671.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![二维码](img/QR_Code40480600921811704671.png)'
