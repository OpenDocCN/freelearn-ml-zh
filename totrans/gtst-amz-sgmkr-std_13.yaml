- en: '*Chapter 10*: Monitoring ML Models in Production with SageMaker Model Monitor'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第10章*：使用 SageMaker Model Monitor 监控生产中的机器学习模型'
- en: 'Having a model put into production for inferencing isn''t the end of the **machine
    learning** (**ML**) life cycle. It is just the beginning of an important topic:
    how do we make sure the model is performing as it is designed to and as expected
    in real life? Monitoring how the model performs in production, especially on data
    that the model has never seen before, is made easy with SageMaker Studio. You
    will learn how to set up model monitoring for models deployed in SageMaker, detect
    data drift and performance drift, and visualize results in SageMaker Studio, so
    that you can let the system detect the degradation of your ML model automatically.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型投入生产进行推理并不是机器学习生命周期的结束。这只是重要话题的开始：我们如何确保模型按照设计以及在实际生活中按预期运行？使用 SageMaker
    Studio 监控模型在生产中的表现，尤其是在模型从未见过的数据上，变得容易起来。您将学习如何为在 SageMaker 中部署的模型设置模型监控，检测数据漂移和性能漂移，并在
    SageMaker Studio 中可视化结果，以便您可以自动让系统检测您的机器学习模型的退化。
- en: 'In this chapter, we will be learning about the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习以下内容：
- en: Understanding drift in ML
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解机器学习中的漂移
- en: Monitoring data and model performance drift in SageMaker Studio
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 SageMaker Studio 中监控数据和模型性能的漂移
- en: Reviewing model monitoring results in SageMaker Studio
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 SageMaker Studio 中审查模型监控结果
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you need to access the code in [https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter10](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter10).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您需要访问[https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter10](https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter10)中的代码。
- en: Understanding drift in ML
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习中的漂移
- en: An ML model in production needs to be carefully and continuously monitored for
    its performance. There is no guarantee that once the model is trained and evaluated,
    it will be performing at the same level in production as in the testing environment.
    Unlike a software application, where unit tests can be implemented to test out
    an application in all possible edge cases, it is rather hard to monitor and detect
    issues of an ML model. This is because ML models use probabilistic, statistical,
    and fuzzy logic to infer an outcome for each incoming data point, and the testing,
    meaning the model evaluation, is typically done without true prior knowledge of
    production data. The best a data scientist can do prior to production is to create
    training data from a sample that closely represents the real-world data, and evaluate
    the model with an out-of-sample strategy in order to get an unbiased idea of how
    the model would perform on unseen data. While in production, the incoming data
    is completely unseen by the model; how to evaluate live model performance, and
    how to take action on that evaluation, is a critical topic for the productionization
    of ML models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，一个机器学习模型需要对其性能进行仔细和持续的监控。一旦模型经过训练和评估，并不能保证它在生产环境中的表现与测试环境中的表现相同。与软件应用不同，软件应用可以通过单元测试来测试所有可能的边缘情况，而监控和检测机器学习模型的问题则相对困难。这是因为机器学习模型使用概率、统计和模糊逻辑来推断每个输入数据点的结果，而测试，即模型评估，通常是在没有真正了解生产数据的情况下进行的。数据科学家在生产之前能做的最好的事情就是从与真实世界数据非常接近的样本中创建训练数据，并使用样本外策略评估模型，以便得到一个无偏的关于模型在未见数据上表现的想法。在生产中，模型对进入的数据是完全未知的；如何评估实时模型性能，以及如何对评估采取行动，是机器学习模型生产化的一个关键话题。
- en: Model performance can be monitored with two approaches. One that is more straightforward
    is to capture the ground truth for the unseen data and compare the prediction
    against the ground truth. The second approach is to compare the statistical distribution
    and characteristics of inference data against the training data as a proxy to
    determine whether the model is behaving in an expected way.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 模型性能可以通过两种方法进行监控。一种更直接的方法是捕获未见数据的真实情况，并将预测与真实情况进行比较。第二种方法是，将推理数据的统计分布和特征与训练数据进行比较，作为判断模型是否按预期行为的一个代理。
- en: The first approach requires ground-truth determination after the prediction
    event takes place so that we can directly compute the same performance metrics
    that data scientists would use during model evaluation. However, in some use cases,
    a true outcome (ground truth) may lag behind the event by a long time or may even
    not be available at all.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法需要在预测事件发生后确定真实结果（基线），这样我们就可以直接计算数据科学家在模型评估期间使用的相同性能指标。然而，在某些用例中，真实结果（基线）可能落后于事件很长时间，甚至可能根本不可用。
- en: The second approach lies in the premise that an ML model learns statistically
    and probabilistically from the training data and would behave differently when
    a new dataset from a different statistical distribution is provided. A model would
    return gibberish when data does not come from the same statistical distribution.
    This is called **covariate drift**. Therefore, detecting the covariate drift in
    data gives a more real-time estimate of how the model is going to perform.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法基于这样一个前提，即机器学习模型从训练数据中统计和概率性地学习，当提供来自不同统计分布的新数据集时，其行为会有所不同。当数据不是来自相同的统计分布时，模型会返回无意义的输出。这被称为**协变量漂移**。因此，检测数据中的协变量漂移可以更实时地估计模型的表现。
- en: '**Amazon SageMaker Model Monitor** is a feature in SageMaker that continuously
    monitors the quality of models hosted on SageMaker by setting up data capture,
    computing baseline statistics, and monitoring the drift from the traffic to your
    SageMaker endpoint on a schedule. SageMaker Model Monitor has four types of monitors:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon SageMaker模型监控器**是SageMaker中的一个功能，它通过设置数据捕获、计算基线统计信息和按计划监控流量到您的SageMaker端点的漂移，持续监控托管在SageMaker上的模型质量。SageMaker模型监控器有四种类型的监控器：'
- en: '**Model quality monitor**: Monitors the performance of a model by computing
    the accuracy from the predictions and the actual ground-truth labels'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型质量监控器**：通过计算预测的准确性和实际基线标签来监控模型的性能'
- en: '**Data quality monitor**: Monitors data statistical characteristics of the
    inference data by comparing the characteristics to that of the baseline training
    data'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据质量监控器**：通过将特征与基线训练数据的特征进行比较，监控推理数据的统计特征'
- en: '**Model explainability monitor**: Integrates with SageMaker Clarify to compute
    feature attribution, using the Shapley value, over time'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型可解释性监控器**：与SageMaker Clarify集成，使用Shapley值在时间上计算特征归因'
- en: '**Model bias monitor**: Integrates with SageMaker Clarify to monitor predictions
    for data and model prediction bias'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型偏差监控器**：与SageMaker Clarify集成，监控数据和模型预测的偏差'
- en: Once the model monitoring for an endpoint is set up, you can visualize the drift
    and any data issues over time in SageMaker Studio. Let's learn how to set up SageMaker
    Model Monitor in SageMaker Studio following an ML use case in this chapter. We
    will focus on model quality and data quality monitoring.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦为端点设置了模型监控，您就可以在SageMaker Studio中可视化随时间推移的漂移和任何数据问题。让我们按照本章中的ML用例学习如何在SageMaker
    Studio中设置SageMaker模型监控器。我们将重点关注模型质量和数据质量监控。
- en: Monitoring data and performance drift in SageMaker Studio
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在SageMaker Studio中监控数据和性能漂移
- en: 'In this chapter, let''s consider an ML scenario: we train an ML model and host
    it in an endpoint. We also create artificial inference traffic to the endpoint,
    with random perturbation injected into each data point. This is to introduce noise,
    missingness, and drift to the data. We then proceed to create a data quality monitor
    and a model quality monitor using SageMaker Model Monitor. We use a simple ML
    dataset, the abalone dataset from UCI ([https://archive.ics.uci.edu/ml/datasets/abalone](https://archive.ics.uci.edu/ml/datasets/abalone)),
    for this demonstration. Using this dataset, we train a regression model to predict
    the number of rings, which is proportionate to the age of abalone.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，让我们考虑一个ML场景：我们训练一个ML模型并将其托管在端点上。我们还向端点创建了人工推理流量，每个数据点都注入了随机扰动。这是为了向数据引入噪声、缺失和漂移。然后我们继续使用SageMaker模型监控器创建数据质量监控器和模型质量监控器。我们使用一个简单的ML数据集，即UCI的鲍鱼数据集([https://archive.ics.uci.edu/ml/datasets/abalone](https://archive.ics.uci.edu/ml/datasets/abalone))，进行此演示。使用此数据集，我们训练一个回归模型来预测环数，这与鲍鱼的年龄成比例。
- en: Training and hosting a model
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和托管模型
- en: 'We will follow the next steps to set up what we need prior to the model monitoring—getting
    data, training a model, hosting it, and creating traffic:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遵循以下步骤来设置模型监控之前所需的内容——获取数据、训练模型、托管它并创建流量：
- en: Open the notebook in `Getting-Started-with-Amazon-SageMaker-Studio/chapter10/01-train_host_predict.ipynb`
    with the **Python 3 (Data Science)** kernel and the **ml.t3.median** instance.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用**Python 3 (Data Science)**内核和**ml.t3.median**实例打开`Getting-Started-with-Amazon-SageMaker-Studio/chapter10/01-train_host_predict.ipynb`笔记本。
- en: Run the first three cells to set up the libraries and SageMaker session.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行前三个单元格以设置库和SageMaker会话。
- en: Read the data from the source and perform minimal processing, namely encoding
    the categorical variable, `Sex`, into integers so that we can later use the `XGBoost`
    algorithm to train. Also, we change the type of the target column Rings to float
    so that the values from ground truth and model prediction (regression) are consistently
    in float for the model monitor to compute.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从源读取数据并进行最小处理，即把分类变量`Sex`编码为整数，以便我们稍后可以使用`XGBoost`算法进行训练。此外，我们将目标列`Rings`的类型改为浮点数，以确保真实值和模型预测（回归）的值在模型监控中保持一致。
- en: Split the data randomly into training (80%), validation (10%), and test sets
    (10%). Then, save the data to the local drive for model inference and upload it
    to S3 for model training.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据随机分为训练集（80%）、验证集（10%）和测试集（10%）。然后，将数据保存到本地驱动器以进行模型推理，并将其上传到S3进行模型训练。
- en: 'For model training, we use `XGBoost`, a SageMaker built-in algorithm, with
    the `reg:squarederror` objective for regression problems:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于模型训练，我们使用SageMaker内置的`XGBoost`算法，对于回归问题使用`reg:squarederror`目标函数：
- en: '[PRE0]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The training takes about 5 minutes.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 训练大约需要5分钟。
- en: 'After the model training is complete, we host the model with a SageMaker endpoint
    with `xgb.deploy()` just like we learned in [*Chapter 7*](B17447_07_ePub_RK.xhtml#_idTextAnchor099),
    *Hosting ML Models in the Cloud: Best Practices*. However, by default, a SageMaker
    endpoint does not save a copy of the incoming inference data. In order to monitor
    the performance of the model and data drift, we need to instruct the endpoint
    to persist the incoming inference data. We use `sagemaker.model_monitor.DataCaptureConfig`
    to set up the data capture behind an endpoint for monitoring purposes:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练完成后，我们可以使用SageMaker端点通过`xgb.deploy()`托管模型，就像我们在[*第7章*](B17447_07_ePub_RK.xhtml#_idTextAnchor099)，“在云中托管ML模型：最佳实践”中学到的那样。然而，默认情况下，SageMaker端点不会保存传入的推理数据副本。为了监控模型性能和数据漂移，我们需要指导端点持久化传入的推理数据。我们使用`sagemaker.model_monitor.DataCaptureConfig`设置端点后的数据捕获，用于监控目的：
- en: '[PRE1]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We specify an S3 bucket location in `destination_s3_uri`. `sampling_percentage`
    can be `100` (%) or lower depending on how much real-life traffic you expect.
    We need to make sure we capture a sample size large enough for any statistical
    comparison later on. If the model inference traffic is sparse, such as 100 inferences
    per hour, you may want to use 100% of the samples for model monitoring. If you
    have a high-rate-of-model-inference use case, you may be able to use a smaller
    percentage.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在`destination_s3_uri`中指定S3存储桶位置。`sampling_percentage`可以是`100`（%）或更低，具体取决于你预期的实际流量量。我们需要确保我们捕获足够大的样本量，以便稍后进行任何统计比较。如果模型推理流量稀疏，例如每小时100次推理，你可能希望使用100%的样本进行模型监控。如果你有高频率的模型推理用例，你可能能够使用更小的百分比。
- en: 'We can deploy the model to an endpoint with `data_capture_config`:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用`data_capture_config`将模型部署到端点：
- en: '[PRE2]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once the endpoint is ready, let''s apply the regression model on the validation
    dataset in order to create a baseline dataset for the model quality monitoring.
    The baseline dataset should contain ground-truth and model prediction in two columns
    in a CSV file. We then upload the CSV to an S3 bucket location:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦端点准备就绪，让我们在验证数据集上应用回归模型，以创建用于模型质量监控的基线数据集。基线数据集应包含CSV文件中的真实值和模型预测的两列。然后，我们将CSV上传到S3存储桶位置：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Next, we can make some predictions on the endpoint with the test dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用测试数据集在端点上做一些预测。
- en: Creating inference traffic and ground truth
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建推理流量和真实值
- en: 'To simulate real-life inference traffic, we take the test dataset and add random
    perturbation, such as random scaling and dropping features. We can anticipate
    that this simulates data drift and twists model performance. Then, we send the
    perturbed data to the endpoint for prediction and save the ground truth into an
    S3 bucket location. Please follow these steps in the same notebook:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟现实生活中的推理流量，我们从测试数据集中取样本并添加随机扰动，例如随机缩放和删除特征。我们可以预期这会模拟数据漂移并扭曲模型性能。然后，我们将扰动数据发送到端点进行预测，并将真实值保存到S3存储桶位置。请按照以下步骤在同一笔记本中操作：
- en: 'Here, we have two functions to add random perturbation: `add_randomness()`
    and `drop_randomly()`. The former function randomly multiplies each feature value,
    except the `Sex` function, by a small factor, and randomly assigns a binary value
    to `Sex`. The latter function randomly drops a feature and fills it with `NaN`
    (not a number).'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We also have the `generate_load_and_ground_truth()` function to read from each
    row of the test data, apply perturbation, call the endpoint for prediction, construct
    the ground truth in a dictionary, `gt_data`, and upload it to an S3 bucket as
    a JSON file. Notably, in order to make sure we establish correspondence between
    the inference data and the ground truth, we associate each pair with `inference_id`.
    This association will allow Model Monitor to merge the inference and ground truth
    for analysis:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We wrap this function in a `while` loop in the `generate_load_and_ground_truth_forever()`
    function so that we can generate persistent traffic using a threaded process until
    the notebook is shut down:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Lastly, before we set up our first model monitor, let''s take a look how the
    inference traffic is captured:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note the `captureData.endpointInput.data` function has an entry of inference
    data through `predictor.predict()` with the unique inference ID in `eventMetadata.`
    `inferenceId`. The output from the model endpoint is in `captureData.endpointOutput.data`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: We have done all the prep work. We can now move on to creating the model monitors
    in SageMaker Studio.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Creating a data quality monitor
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A data quality monitor compares the statistics of the incoming inference data
    to that of a baseline dataset. You can set up a data quality monitor via the SageMaker
    Studio UI or SageMaker Python SDK. I will walk through the easy setup via the
    Studio UI:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the **Endpoints** registry in the left sidebar and locate your newly
    hosted endpoint, as shown in *Figure 10.1*. Double-click the entry to open it
    in the main working area:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Opening the endpoint details page'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17447_10_001.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.1 – Opening the endpoint details page
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the **Data quality** tab and then **Create monitoring schedule**, as
    shown in *Figure 10.2*:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Creating a data quality monitoring schedule on the endpoint
    details page'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17447_10_002.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – Creating a data quality monitoring schedule on the endpoint details
    page
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'In the first step of the setup, as shown in *Figure 10.3*, we choose an IAM
    role that has access permission to read and write results to the bucket location
    we specify in the following pages. Let''s choose `3600` seconds) so that a monitoring
    job does not bleed into the next hour. Toward the bottom of the page, we leave
    **Enable metrics** on so that the metrics computed by the model monitor get sent
    to Amazon CloudWatch too. This allows us to visualize and analyze the metrics
    in CloudWatch. Click **Continue**:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Data quality monitor setup step 1'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B17447_10_003.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.3 – Data quality monitor setup step 1
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 – 数据质量监控设置步骤1
- en: 'In the second step, as shown in *Figure 10.4*, we configure the infrastructure
    and output location for the hourly monitoring job. The infrastructure subject
    to configure is the SageMaker Processing job that is going to be created every
    hour. We leave the compute instance—instance type, count, and disk volume size—as
    default. We then provide an output bucket location for the monitoring result and
    encryption and networking (VPC) options:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二步中，如图*图10.4*所示，我们配置了每小时监控作业的基础设施和输出位置。需要配置的基础设施是每小时将要创建的SageMaker Processing作业。我们将计算实例（实例类型、数量和磁盘卷大小）保留为默认设置。然后，我们提供一个监控结果的输出存储桶位置以及加密和网络（VPC）选项：
- en: '![Figure 10.4 – Data quality monitor setup step 2'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.4 – 数据质量监控设置步骤2'
- en: '](img/B17447_10_004.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_004.jpg]'
- en: Figure 10.4 – Data quality monitor setup step 2
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 – 数据质量监控设置步骤2
- en: 'In the third step, as shown in *Figure 10.5*, we configure the baseline computation.
    Right after a monitor is set up, a one-time SageMaker Processing job will be launched
    to compute the baseline statistics. Future recurring monitoring jobs would use
    the baseline statistics to judge whether drift has occurred. We provide the CSV
    file location in an S3 bucket to the baseline dataset S3 location. We uploaded
    the training data to the S3 bucket and the full path is in the `train_data_s3`
    variable. We provide an S3 output location to the baseline S3 output location.
    Because our training data CSV contains a feature name in the first row, we select
    `ml.m5.xlarge` instance with 1 GB of baseline volume is sufficient. Click **Continue**:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三步中，如图*图10.5*所示，我们配置了基线计算。监控设置完成后，将启动一个一次性SageMaker Processing作业来计算基线统计数据。未来的周期性监控作业将使用基线统计数据来判断是否发生了漂移。我们将CSV文件位置提供到基线数据集的S3位置。我们将训练数据上传到S3存储桶，完整路径在`train_data_s3`变量中。我们提供一个S3输出位置到基线S3输出位置。因为我们的训练数据CSV文件的第一行包含一个特征名称，所以我们选择具有1
    GB基线卷的`ml.m5.xlarge`实例就足够了。点击**继续**：
- en: '![Figure 10.5 – Data quality monitor setup step 3'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.5 – 数据质量监控设置步骤3'
- en: '](img/B17447_10_005.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_005.jpg]'
- en: Figure 10.5 – Data quality monitor setup step 3
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 – 数据质量监控设置步骤3
- en: In the final **Additional Configuration** page, you have an option to provide
    preprocessing and postprocessing scripts to the recurring monitoring job. You
    can customize the features and model output with your own scripts. This extension
    is not supported when you use a custom container for model monitoring. In our
    case, we use the built-in container from SageMaker. For more information about
    the preprocessing and postprocessing scripts, visit [https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-and-post-processing.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-and-post-processing.html).
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在最后的**附加配置**页面，您可以选择为周期性监控作业提供预处理和后处理脚本。您可以使用自己的脚本自定义特征和模型输出。当您使用自定义容器进行模型监控时，此扩展不受支持。在我们的案例中，我们使用SageMaker的内置容器。有关预处理和后处理脚本的更多信息，请访问[https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-and-post-processing.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-pre-and-post-processing.html)。
- en: If you go back to the **ENDPOINT DETAILS** page, under the **Data quality**
    tab, as shown in *Figure 10.2*, you can now see a new monitoring schedule with
    the **Scheduled** status. A baselining job is now being launched to compute various
    statistics from the baseline training dataset. After the baselining job is finished,
    the first hourly monitoring job will be launched as a SageMaker Processing job
    within 20 minutes at the top of an hour. The monitoring job computes the statistics
    from the inference data gathered during the hour and compares it against the baseline.
    We will review the monitoring result in the *Reviewing model monitoring results
    in SageMaker Studio* section later.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您回到**端点详情**页面，在**数据质量**选项卡下，如图*图10.2*所示，您现在可以看到一个新的具有**已安排**状态的监控计划。现在正在启动一个基线作业来从基线训练数据集中计算各种统计数据。基线作业完成后，第一个每小时监控作业将在小时顶部的20分钟内作为一个SageMaker
    Processing作业启动。监控作业计算在小时内收集的推理数据的统计数据，并将其与基线进行比较。我们将在*在SageMaker Studio中查看模型监控结果*部分中回顾监控结果。
- en: Now, let's move on to creating the model quality monitor to monitor the model
    performance.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续创建模型质量监控器以监控模型性能。
- en: Creating a model quality monitor
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建模型质量监控器
- en: 'Creating a model quality monitor follows a similar process compared to creating
    a data quality monitor, with additional emphasis on handling model prediction
    and ground-truth labels in S3\. Let''s follow the next steps to set up a model
    quality monitor to monitor the model performance over time:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 创建模型质量监控器遵循与创建数据质量监控器类似的过程，但更注重处理S3中的模型预测和真实标签。让我们按照以下步骤设置一个模型质量监控器，以监控模型性能随时间的变化：
- en: 'On the **Endpoint Details** page of the same endpoint, go to the **Model quality**
    tab and click **Create monitoring schedule**, as shown in *Figure 10.6*:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在同一端点的**端点详情**页上，转到**模型质量**选项卡，并点击**创建监控计划**，如图*图10.6*所示：
- en: '![Figure 10.6 – Creating a model quality monitoring schedule on the endpoint
    details page'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.6 – 在端点详情页创建模型质量监控计划'
- en: '](img/B17447_10_006.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_006.jpg]'
- en: Figure 10.6 – Creating a model quality monitoring schedule on the endpoint details
    page
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 – 在端点详情页创建模型质量监控计划
- en: On the first page, **Schedule**, we choose an IAM role, scheduling frequency,
    and so on for the monitoring job, similar to *step 3* in the previous *Creating
    a data quality monitor section*.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一页，**计划**，我们选择监控作业的IAM角色、调度频率等，类似于之前*创建数据质量监控器部分*中的*步骤3*。
- en: 'On the second page, **Monitoring Job Configuration**, as shown in *Figure 10.7*,
    we configure the instance for the monitoring job and the input/output to a monitoring
    job:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二页，**监控作业配置**，如图*图10.7*所示，我们配置监控作业的实例和输入/输出：
- en: '![Figure 10.7 – Setting up input and output for the model quality monitor'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.7 – 设置模型质量监控器的输入和输出'
- en: '](img/B17447_10_007.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_007.jpg]'
- en: Figure 10.7 – Setting up input and output for the model quality monitor
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 – 设置模型质量监控器的输入和输出
- en: Input refers to both model prediction from the endpoint and the ground-truth
    files we are uploading in the notebook. In the `24` hours. For `0` for **Inference
    attribute** to specify the first value being the model output, and leave **Probability**
    empty.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 输入既指模型从端点预测的结果，也指我们在笔记本中上传的真实标签文件。在`24`小时内。对于**推理属性**的`0`，指定第一个值是模型输出，并保留**概率**为空。
- en: Note
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'If the content type for your model is JSON/JSON Lines, you would specify a
    JSON path in `{prediction: {"predicted_label":1, "probability":0.68}}`, you would
    specify `"prediction.predicted_label"` in `"prediction.probability"` in **Probability**.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '如果您的模型内容类型是JSON/JSON Lines，您会在`{prediction: {"predicted_label":1, "probability":0.68}}`中指定JSON路径，您会在`"prediction.probability"`中指定`"prediction.predicted_label"`，在**概率**中。'
- en: For `ground_truth_upload_path` variable in the notebook. For **S3 output location**,
    we specify an S3 bucket location for Model Monitor to save the output. Lastly,
    you can optionally configure the encryption and VPC for the monitoring jobs. Click
    **Continue** to proceed.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于笔记本中的`ground_truth_upload_path`变量。对于**S3输出位置**，我们指定一个S3存储桶位置，以便模型监控器保存输出。最后，您可以可选地配置监控作业的加密和VPC。点击**继续**以进行下一步。
- en: On the third page, `model_quality_baseline_s3` variable in the notebook to the
    **Baseline dataset S3 location** field. For **Baseline S3 output location**, we
    provide an S3 location to save the baselining result. Choose **CSV with header**
    in **Baseline dataset format**. Leave the instance type and configuration as the
    default.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三页，将笔记本中的`model_quality_baseline_s3`变量拖放到**基线数据集S3位置**字段。对于**基线S3输出位置**，我们提供一个S3位置以保存基线结果。在**基线数据集格式**中选择**带标题的CSV**。将实例类型和配置保留为默认值。
- en: 'This is to configure the SageMaker Processing job for the one-time baseline
    computation. In the last three fields, we put the corresponding CSV header names—`Rings`
    for `Prediction` for **Baseline inference attribute**—and leave the field empty
    for **Baseline probability** because, again, our model does not produce probability.
    Click **Continue**:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为了配置SageMaker Processing作业进行一次性基线计算。在最后三个字段中，我们放入相应的CSV标题名称——`Rings`用于`Prediction`的**基线推理属性**——并将字段保留为空，因为我们的模型不产生概率。点击**继续**：
- en: '![Figure 10.8 – Configuring the baseline calculation for the model quality
    monitor'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.8 – 配置模型质量监控器的基线计算'
- en: '](img/B17447_10_008.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_008.jpg]'
- en: Figure 10.8 – Configuring the baseline calculation for the model quality monitor
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8 – 配置模型质量监控器的基线计算
- en: In **Additional Configuration**, we can provide preprocessing and postprocessing
    scripts to the monitor like in the case of the data quality monitor. Let's skip
    this and proceed to complete the setup by clicking **Enable model monitoring**.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**附加配置**中，我们可以向监控器提供预处理和后处理脚本，就像数据质量监控器的情况一样。让我们跳过这一部分，通过点击**启用模型监控**来完成设置。
- en: Now, we have created the model quality monitor. You can see the monitoring schedule
    is in the **Scheduled** status under the **Model quality** tab on the **ENDPOINT**
    **DETAILS**page. Similar to the data quality monitor, a baseline processing job
    is launched to compute the baseline model performance using the baseline dataset.
    An hourly monitoring job will also be launched as a SageMaker Processing job within
    20 minutes at the top of an hour in order to compute the model performance metrics
    from the inference data gathered during the hour and compare them against the
    baseline. We will review the monitoring results in the next section, *Reviewing
    model monitoring results in SageMaker Studio*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经创建了模型质量监控器。您可以在**ENDPOINT详情**页面的**模型质量**选项卡下看到监控计划处于**已安排**状态。类似于数据质量监控器，将启动一个基线处理作业来使用基线数据集计算基线模型性能。每小时监控作业也将作为一个SageMaker
    Processing作业在每小时顶部20分钟内启动，以便从每小时收集的推理数据中计算模型性能指标，并与基线进行比较。我们将在下一节中回顾监控结果，*在SageMaker
    Studio中查看模型监控结果*。
- en: Reviewing model monitoring results in SageMaker Studio
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在SageMaker Studio中查看模型监控结果
- en: SageMaker Model Monitor computes various statistics on the incoming inference
    data, compares them against the precomputed baseline statistics, and reports the
    results back to us in a specified S3 bucket, which you can visualize in SageMaker
    Studio.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Model Monitor对传入的推理数据进行各种统计计算，将它们与预先计算的基线统计进行比较，并将结果报告回指定的S3存储桶，您可以在SageMaker
    Studio中可视化这些结果。
- en: For the data quality monitor, a SageMaker Model Monitor pre-built, default container,
    which is what we used, computes per-feature statistics on the baseline dataset
    and the inference data. The statistics include the mean, sum, standard deviation,
    min, and max. The data quality monitor also looks at data missingness and checks
    for the data type of the incoming inference data. You can find the full list at
    [https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-statistics.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-statistics.html).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据质量监控器，SageMaker Model Monitor预构建的默认容器，即我们所使用的，对基线数据集和推理数据进行每特征统计。这些统计包括平均值、总和、标准差、最小值和最大值。数据质量监控器还会检查数据缺失情况，并检查传入推理数据的数据类型。您可以在[https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-statistics.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-statistics.html)找到完整的列表。
- en: For the model quality monitor, SageMaker computes model performance metrics
    based on the ML problem type configured. For our regression example in this chapter,
    SageMaker's model quality monitor is computing the **mean absolute error** (**MAE**),
    **mean squared error** (**MSE**), **root mean square error** (**RMSE**), and **R-squared**
    (**r2**) values. You can find the full list of computed metrics for regression,
    binary classification, and multi-class classification problems at [https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型质量监控器，SageMaker根据配置的ML问题类型计算模型性能指标。在本章的回归示例中，SageMaker的模型质量监控器正在计算**平均绝对误差**（**MAE**）、**平均平方误差**（**MSE**）、**均方根误差**（**RMSE**）和**R平方**（**r2**）值。您可以在[https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html)找到回归、二分类和多分类问题计算的完整指标列表。
- en: 'You can see a list of the monitoring jobs launched over time in the **Monitoring
    job history** tab on the **ENDPOINT DETAILS** page, as shown in *Figure 10.9*:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在**ENDPOINT详情**页面的**监控作业历史记录**选项卡中查看随时间启动的监控作业列表，如图10.9所示：
- en: '![Figure 10.9 – Viewing a list of monitoring jobs. Double-clicking a row item
    takes you to the detail page of a particular job'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.9 – 查看监控作业列表。双击行项目可进入特定作业的详细信息页]'
- en: '](img/B17447_10_009.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_009.jpg]'
- en: Figure 10.9 – Viewing a list of monitoring jobs. Double-clicking a row item
    takes you to the detail page of a particular job
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 – 查看监控作业列表。双击行项目可进入特定作业的详细信息页
- en: 'When you double-click a row item, you will be taken to the detail page of a
    particular monitoring job, as shown in *Figure 10.10*. Because we perturbed the
    data prior to sending it to the endpoint, the data contains irregularities, such
    as missingness. This is captured by the data quality monitor:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 当您双击行项目时，您将被带到特定监控作业的详细信息页面，如图*图10.10*所示。由于我们在将数据发送到端点之前对其进行了扰动，因此数据包含不规则性，例如缺失。这被数据质量监控器捕获：
- en: '![Figure 10.10 – Details of a data quality monitoring job and violations'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.10 – 数据质量监控作业的详细信息及违规情况'
- en: '](img/B17447_10_010.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_010.jpg]'
- en: Figure 10.10 – Details of a data quality monitoring job and violations
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 – 数据质量监控作业的详细信息及违规情况
- en: 'We can also open a model quality monitoring job to find out whether the model
    performs as expected. As shown in *Figure 10.11*, we can see that violations have
    been raised for all the metrics computed. We know it is going to happen because
    this is largely due to the perturbation we introduced to the data. SageMaker Model
    Monitor is able to detect such problems:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以打开模型质量监控作业，以了解模型是否按预期运行。如图*图10.11*所示，我们可以看到所有计算出的指标都提出了违规。我们知道这将会发生，因为这很大程度上是由于我们对数据引入的扰动。SageMaker模型监控器能够检测到这样的问题：
- en: '![Figure 10.11 – Details of a model monitoring job and violations'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.11 – 模型监控作业的详细信息及违规情况'
- en: '](img/B17447_10_011.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_011.jpg]'
- en: Figure 10.11 – Details of a model monitoring job and violations
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11 – 模型监控作业的详细信息及违规情况
- en: 'We can also create visualizations from the monitoring jobs. Let''s follow the
    next steps to create a chart for the data quality monitor:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以从监控作业中创建可视化。让我们按照以下步骤创建数据质量监控器的图表：
- en: 'On the **ENDPOINT DETAILS** page, go to the **Data quality** tab and click
    on the **Add chart** button, as shown in *Figure 10.12*:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**端点详细信息**页面，转到**数据质量**选项卡，然后点击如图*图10.12*所示的**添加图表**按钮：
- en: '![Figure 10.12 – Adding a visualization for a data quality monitor'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.12 – 为数据质量监控器添加可视化'
- en: '](img/B17447_10_012.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_012.jpg]'
- en: Figure 10.12 – Adding a visualization for a data quality monitor
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12 – 为数据质量监控器添加可视化
- en: 'A chart properties configuration sidebar will appear on the right side, as
    shown in *Figure 10.13*. We can create a chart by specifying the timeline, the
    statistics, and the feature we would like to plot. Depending on how long you''ve
    enabled the monitor, you can choose a time span to visualize. For example, I chose
    **1 day**, the **Average** statistic, and **feature_baseline_drift_Length** to
    see the average baseline drift measure on the **Length** feature in the past day:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右侧将出现一个图表属性配置侧边栏，如图*图10.13*所示。我们可以通过指定时间线、统计信息和我们要绘制的特征来创建图表。根据您启用监控器的时间长度，您可以选择一个时间范围进行可视化。例如，我选择了**1天**的时间范围、**平均**统计信息和**feature_baseline_drift_Length**来查看过去一天中**Length**特征的平均基线漂移度量：
- en: '![Figure 10.13 – Visualizing feature drift in SageMaker Studio'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.13 – 在SageMaker Studio中可视化特征漂移'
- en: '](img/B17447_10_013.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_013.jpg]'
- en: Figure 10.13 – Visualizing feature drift in SageMaker Studio
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13 – 在SageMaker Studio中可视化特征漂移
- en: You can optionally add more charts by clicking the **Add chart** button.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过点击**添加图表**按钮来可选地添加更多图表。
- en: 'Similarly, we can visualize the model performance using the **mse** metric
    over the last 24 hours, as shown in *Figure 10.14*:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，我们可以使用过去24小时的**mse**指标来可视化模型性能，如图*图10.14*所示：
- en: '![Figure 10.14 – Visualizing the mse regression metric in SageMaker Studio'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.14 – 在SageMaker Studio中可视化mse回归指标'
- en: '](img/B17447_10_014.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17447_10_014.jpg]'
- en: Figure 10.14 – Visualizing the mse regression metric in SageMaker Studio
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14 – 在SageMaker Studio中可视化mse回归指标
- en: Note
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To save costs, when you complete the examples, make sure to uncomment and run
    the last cells in `01-train_host_predict.ipynb` to delete the monitoring schedules
    and the endpoint in order to stop incurring charges to your AWS account.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了节省成本，当您完成示例后，请确保取消注释并运行`01-train_host_predict.ipynb`中的最后几个单元格，以删除监控计划和端点，从而停止向您的AWS账户收费。
- en: Summary
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we focused on data drift and model drift in ML and how to monitor
    them using SageMaker Model Monitor and SageMaker Studio. We demonstrated how we
    set up a data quality monitor and a model quality monitor in SageMaker Studio
    to continuously monitor the behavior of a model and the characteristics of the
    incoming data, in a scenario where a regression model is deployed in a SageMaker
    endpoint and continuous inference traffic is hitting the endpoint. We introduced
    some random perturbation to the inference traffic and used SageMaker Model Monitor
    to detect unwanted behavior of the model and data. With this example, you can
    also deploy SageMaker Model Monitor to your use case and provide visibility and
    a guardrail to your models in production.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们专注于机器学习中的数据漂移和模型漂移，以及如何使用 SageMaker 模型监控器和 SageMaker Studio 来监控它们。我们演示了如何在
    SageMaker Studio 中设置数据质量监控器和模型质量监控器，以持续监控模型的行为和输入数据的特征，在一个回归模型部署在 SageMaker 端点并且持续推理流量击中端点的情况下。我们引入了一些随机扰动到推理流量中，并使用
    SageMaker 模型监控器来检测模型和数据的不当行为。通过这个例子，你还可以将 SageMaker 模型监控器部署到你的用例中，为你的生产模型提供可见性和保障。
- en: In the next chapter, we will be learning how to operationalize an ML project
    with SageMaker Projects, Pipelines, and the model registry. We will be talking
    about an important trend in ML right now, that is, **continuous integration/continuous
    delivery** (**CI/CD**) and **ML operations** (**MLOps**). We will demonstrate
    how you can use SageMaker features, such as Projects, Pipelines, and the model
    registry, to make your ML project repeatable, reliable, and reusable, and have
    strong governance.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何使用 SageMaker Projects、Pipelines 和模型注册表来操作化一个机器学习项目。我们将讨论当前机器学习中的一个重要趋势，即**持续集成/持续交付**（**CI/CD**）和**机器学习运营**（**MLOps**）。我们将演示如何使用
    SageMaker 的功能，如 Projects、Pipelines 和模型注册表，使你的机器学习项目可重复、可靠和可重用，并具有强大的治理能力。
