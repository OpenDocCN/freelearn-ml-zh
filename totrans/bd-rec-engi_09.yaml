- en: Chapter 9. Building Scalable Recommendation Engines with Mahout
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章：使用Mahout构建可扩展的推荐引擎
- en: Imagine that you have just launched an online e-commerce website to sell clothes
    designed by you and you are lucky enough to make your business kick-start well
    and make it a successful venture. With more web traffic coming to your site, the
    most obvious choice is to implement a recommendation engine on your website with
    features such as people who visited something also visited something else, items
    similar to the current item, and so on. Since your website is new and successful,
    you have implemented a recommendation engine using popular tools, such as R and
    Python. The recommendation functionality is deployed and works well, adding more
    value to the success of the business. Now with more business coming in and with
    an increase in your user base, the most likely problem you might face with the
    website is that your customers start complaining that your website is becoming
    slow.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你刚刚启动了一个在线电子商务网站，用于销售你设计的服装，并且你很幸运地让你的业务顺利启动并取得成功。随着越来越多的网站流量，最明显的选择是在你的网站上实现一个具有如下功能的推荐引擎：访问过某些内容的人也访问了其他内容，与当前物品相似的物品等。由于你的网站是新且成功的，你已经使用流行的工具，如R和Python，实现了一个推荐引擎。推荐功能已部署并运行良好，为业务的成功增添了更多价值。现在随着业务的增加和用户基础的扩大，你最可能遇到的问题是你的客户开始抱怨你的网站变得缓慢。
- en: Upon analyzing the root cause, the obvious reason would be that the recommender
    features that are added to the website are slowing down the site. This is bound
    to happen because of the limitation of collaborative filtering algorithms used
    to cater for recommendations. Every time we calculate the similarity between users,
    the entire user base will be loaded into the memory and the similarity values
    would be calculated. This operation will be fast with a small user base. Assume
    that with a large use base, such as one million users, the collaborative filtering
    model will be thrown out of the memory exception. By increasing the RAM capability,
    we might address this to some extent, but it still won't help us. Increasing the
    RAM would be bad idea as it shoots up the infrastructure cost.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析根本原因后，显而易见的原因是添加到网站上的推荐功能正在减慢网站速度。这很可能会发生，因为用于提供推荐的协同过滤算法存在限制。每次我们计算用户之间的相似性时，整个用户基础都会被加载到内存中，并计算相似性值。对于小用户基础，这个操作会很快。假设有一个大用户基础，比如一百万用户，协同过滤模型将会抛出内存异常。通过增加RAM能力，我们可能在某种程度上解决这个问题，但这仍然无济于事。增加RAM是一个糟糕的主意，因为它会大幅增加基础设施成本。
- en: The best way is to redesign the recommender engine on a distributed platform,
    such as Hadoop. This is where Apache Mahout will come in handy as it is an open
    source machine learning library built for the distributed platform, Apache Hadoop.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的方法是在分布式平台上重新设计推荐引擎，例如Hadoop。这正是Apache Mahout能派上用场的地方，因为它是一个为分布式平台Apache Hadoop构建的开源机器学习库。
- en: 'In this chapter, we will be covering the following sections:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下部分：
- en: Mahout general introduction
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahout一般介绍
- en: Setting up Mahout standalone and distributed mode
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Mahout独立和分布式模式
- en: Core building blocks of Mahout
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahout的核心构建块
- en: Building and evaluating recommendation engines with Mahout such as user-based
    collaborative filtering, item-based collaborative filtering, SVD recommendation
    engines, and ALS recommendation engines.![Building Scalable Recommendation Engines
    with Mahout](img/image00459.jpeg)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Mahout构建和评估推荐引擎，例如基于用户的协同过滤、基于物品的协同过滤、SVD推荐引擎和ALS推荐引擎。![使用Mahout构建可扩展的推荐引擎](img/image00459.jpeg)
- en: Mahout - a general introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mahout - 一般介绍
- en: '**Apache Mahout** is an open source java library built on top of Apache Hadoop,
    which provides large-scale machine learning algorithms. Though this library was
    originally started with the MapReduce paradigm, the framework currently offers
    bindings to Apache Spark, H2O, and Apache Flink. The latest version of Mahout
    supports collaborative filtering recommendation engines, clustering, classification,
    dimensionality reduction, H2O, and spark bindings.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**Apache Mahout**是一个建立在Apache Hadoop之上的开源Java库，它提供了大规模机器学习算法。尽管这个库最初是以MapReduce范式开始的，但当前框架提供了对Apache
    Spark、H2O和Apache Flink的绑定。最新的Mahout版本支持协同过滤推荐引擎、聚类、分类、降维、H2O和Spark绑定。'
- en: 'The major features of Mahout 0.12.2 are as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 0.12.2的主要功能如下：
- en: An extensible programming environment and framework for the building of scalable
    algorithms
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可扩展的编程环境和框架，用于构建可扩展的算法
- en: Support for Apache Spark, Apache Flink, and H2O algorithms
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 Apache Spark、Apache Flink 和 H2O 算法
- en: Samsara, a vector Math environment similar to the R programming language
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Samsara，一个类似于 R 编程语言的矢量数学环境
- en: As mentioned in the previous section, though many things are possible with Mahout,
    we will be limiting our discussion to building recommendation engines using Mahout.
    Mahout provides support for both the standalone mode, where the recommendation
    model or application can be deployed on a single server, and the distributed mode,
    where the recommendation model can be deployed on a distributed platform.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，尽管 Mahout 可以做很多事情，但我们将限制我们的讨论范围到使用 Mahout 构建推荐引擎。Mahout 提供了对独立模式的支持，其中推荐模型或应用程序可以部署在单个服务器上，以及分布式模式，其中推荐模型可以部署在分布式平台上。
- en: Setting up Mahout
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 Mahout
- en: In this section, we shall look at setting up Mahout in standalone and distributed
    mode.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨在独立和分布式模式下设置 Mahout。
- en: The standalone mode - using Mahout as a library
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 独立模式 - 将 Mahout 作为库使用
- en: 'The standalone mode of Mahout usually involves two steps:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 的独立模式通常涉及两个步骤：
- en: Adding Mahout libraries to the Java application that wants to use the Mahout
    capabilities
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Mahout 库添加到希望使用 Mahout 功能的 Java 应用程序中
- en: Calling Mahout recommendation engine functions to build the recommender application
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用 Mahout 推荐引擎函数以构建推荐应用程序
- en: 'Running an application that uses Mahout requires the following dependencies
    to be added to the `pom.xml` file of your Java Maven project:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 运行使用 Mahout 的应用程序需要在您的 Java Maven 项目的 `pom.xml` 文件中添加以下依赖项：
- en: '![The standalone mode - using Mahout as a library](img/image00460.jpeg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![独立模式 - 将 Mahout 作为库使用](img/image00460.jpeg)'
- en: 'The preceding dependencies will download all the required jars or libraries
    required to run the Mahout functionalities, as shown in the following screenshot:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的依赖项将下载运行 Mahout 功能所需的所有 jar 或库，如下面的截图所示：
- en: '![The standalone mode - using Mahout as a library](img/image00461.jpeg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![独立模式 - 将 Mahout 作为库使用](img/image00461.jpeg)'
- en: 'Another step is to go to the official Apache Mahout website and download the
    required Mahout jar files, as shown here:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一步是访问官方 Apache Mahout 网站，下载所需的 Mahout jar 文件，如下所示：
- en: The latest Mahout library can be downloaded from the Apache Mahout official
    website at [http://mahout.apache.org/general/downloads.html](http://mahout.apache.org/general/downloads.html).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最新版本的 Mahout 库可以从 Apache Mahout 官方网站 [http://mahout.apache.org/general/downloads.html](http://mahout.apache.org/general/downloads.html)
    下载。
- en: 'The following image shows the screenshot of the above mentioned URL:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像显示了上述 URL 的截图：
- en: '![The standalone mode - using Mahout as a library](img/image00462.jpeg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![独立模式 - 将 Mahout 作为库使用](img/image00462.jpeg)'
- en: 'Download the tar file(tar files are just executable) instead of source files,
    as we just need the jar files of Mahout to build recommendation engines:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 下载 tar 文件（tar 文件只是可执行文件）而不是源文件，因为我们只需要 Mahout 的 jar 文件来构建推荐引擎：
- en: '![The standalone mode - using Mahout as a library](img/image00463.jpeg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![独立模式 - 将 Mahout 作为库使用](img/image00463.jpeg)'
- en: 'After downloading the tar file, just extract all the files and add the required
    jars to the Java application:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 下载 tar 文件后，只需提取所有文件并将所需的 jar 添加到 Java 应用程序中：
- en: '![The standalone mode - using Mahout as a library](img/image00464.jpeg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![独立模式 - 将 Mahout 作为库使用](img/image00464.jpeg)'
- en: With this minimal setup, let's build a very basic recommendation engine using
    Java Eclipse.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种最小设置，让我们使用 Java Eclipse 构建一个非常基本的推荐引擎。
- en: 'The minimal setup just requires the following steps:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最小设置只需以下步骤：
- en: 'Create a Java Maven project in Eclipse with the following attribute selection:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Eclipse 中创建一个具有以下属性选择的 Java Maven 项目：
- en: 'The following image shows the screenshot of creating a new Maven project setup
    step 1:'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图像显示了创建新 Maven 项目设置步骤 1 的截图：
- en: '![The standalone mode - using Mahout as a library](img/image00465.jpeg)'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![独立模式 - 将 Mahout 作为库使用](img/image00465.jpeg)'
- en: 'In the following image, add the **Artifact Id** "`recommendations`":'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下图像中，添加 **Artifact Id** "recommendations"：
- en: '![The standalone mode - using Mahout as a library](img/image00466.jpeg)'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![独立模式 - 将 Mahout 作为库使用](img/image00466.jpeg)'
- en: A Maven project will be created with `app.java` as the default class. We can
    make changes in this class to build our standalone recommendation engine:![The
    standalone mode - using Mahout as a library](img/image00467.jpeg)
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将创建一个以`app.java`为默认类的Maven项目。我们可以在该类中做出更改以构建我们的独立推荐引擎：![独立模式 - 将Mahout作为库使用](img/image00467.jpeg)
- en: Set Java runtime as 1.7 or higher, as shown in the next screenshot:![The standalone
    mode - using Mahout as a library](img/image00468.jpeg)
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将Java运行时设置为1.7或更高，如下截图所示：![独立模式 - 将Mahout作为库使用](img/image00468.jpeg)
- en: Set the required Maven dependencies listed as **mahout-mr**, **mahout-math**,
    **slf4j-log4j**, **commons-math3**, and **guava**; this will download the required
    jars for the application to run, as shown in the following screenshot:![The standalone
    mode - using Mahout as a library](img/image00469.jpeg)
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置所需的Maven依赖项，包括**mahout-mr**、**mahout-math**、**slf4j-log4j**、**commons-math3**和**guava**；这将下载应用程序运行所需的所有jar文件，如下截图所示：![独立模式
    - 将Mahout作为库使用](img/image00469.jpeg)
- en: These dependencies can be seen in the following screenshot:![The standalone
    mode - using Mahout as a library](img/image00470.jpeg)
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些依赖关系可以在以下截图中看到：![独立模式 - 将Mahout作为库使用](img/image00470.jpeg)
- en: Create a folder called `data` in the project and create a sample dataset, as
    shown in the following screenshot:![The standalone mode - using Mahout as a library](img/image00471.jpeg)
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在项目中创建一个名为`data`的文件夹，并创建一个示例数据集，如下截图所示：![独立模式 - 将Mahout作为库使用](img/image00471.jpeg)
- en: 'Now rename `app.java` to the `UserbasedRecommender.java` file. Write the code
    in the java class to build the basic user-based recommender system:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将`app.java`重命名为`UserbasedRecommender.java`文件。在Java类中编写代码以构建基本的基于用户的推荐系统：
- en: '[PRE0]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Running the preceding code will generate the recommendations for user 2, as
    shown in the following screenshot:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行前面的代码将为用户2生成推荐，如下截图所示：
- en: '![The standalone mode - using Mahout as a library](img/image00472.jpeg)'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![独立模式 - 将Mahout作为库使用](img/image00472.jpeg)'
- en: Boom! We have created our first user-based recommendation engine. Don't worry
    about what we have done or what's happening; everything will become clearer in
    the next few sections. For now, just try to understand how the Mahout library
    can be used in the standalone mode to build recommendation engines.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 嘣！我们已经创建了我们的第一个基于用户的推荐引擎。不用担心我们已经做了什么或正在发生什么；在接下来的几节中，一切都会变得清晰。现在，只需尝试理解如何使用Mahout库在独立模式下构建推荐引擎。
- en: Setting Mahout for the distributed mode
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置Mahout的分布式模式
- en: 'We have seen how to use Mahout libraries in the standalone mode. In this section,
    let''s see how to setup Mahout on a distributed platform, such as HDFS. The following
    are the requirements in order to set up Mahout:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何在独立模式下使用Mahout库。在本节中，让我们看看如何在分布式平台（如HDFS）上设置Mahout。以下是要设置Mahout所需的要求：
- en: Java 7 and higher
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java 7及以上
- en: Apache Hadoop
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Hadoop
- en: Apache Mahout
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Mahout
- en: 'Setting up Java 7 and installing Hadoop is out of the scope of the is book.
    We can find very good resources online on how to set up Hadoop. Assuming Hadoop
    is already set up, follow these steps to set up Mahout:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 设置Java 7和安装Hadoop超出了本书的范围。我们可以在网上找到非常好的资源，介绍如何设置Hadoop。假设Hadoop已经设置好，按照以下步骤设置Mahout：
- en: Download and extract the latest Mahout distribution from Apache Mahout website,
    as explained earlier.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并解压Apache Mahout网站上的最新Mahout发行版，如前所述。
- en: 'Let''s set up environment values:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设置环境变量：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Tip
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Unset `MAHOUT_LOCAL` in order to run it on the Hadoop cluster.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 取消设置`MAHOUT_LOCAL`以在Hadoop集群上运行。
- en: Once the environment variables are set up, use the following commands in the
    command line to run a recommendation engine on the distributed platform.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置好环境变量，请在命令行中使用以下命令在分布式平台上运行推荐引擎。
- en: 'Using the following code, we are generating item-based recommendations using
    the log likelihood similarity:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码，我们正在使用对数似然相似度生成基于项目的推荐：
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output is as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Setting Mahout for the distributed mode](img/image00473.jpeg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![设置Mahout的分布式模式](img/image00473.jpeg)'
- en: Core building blocks of Mahout
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mahout的核心构建块
- en: Like any other recommendation engine framework, Mahout also provides a rich
    set of components to build customized recommender systems that are enterprise-ready,
    scalable, flexible, and that perform well.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何其他推荐引擎框架一样，Mahout也提供了一套丰富的组件来构建定制化的、企业级、可扩展、灵活且性能良好的推荐系统。
- en: 'The key components of Mahout are as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout的关键组件如下：
- en: DataModel
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据模型
- en: 'Similarity: UserSimilarity, ItemSimilarity'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相似度：用户相似度，项目相似度
- en: User neighborhood
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户邻域
- en: Recommender
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统
- en: Recommender evaluator
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐系统评估器
- en: Components of a user-based collaborative recommendation engine
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于用户的协同推荐引擎的组件
- en: In this section, we shall cover the components required for building a user-based
    collaborative filtering system.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍构建基于用户的协同过滤系统所需组件。
- en: '![Components of a user-based collaborative recommendation engine](img/image00474.jpeg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![基于用户的协同推荐引擎的组件](img/image00474.jpeg)'
- en: 'The components of a user-based collaborative recommendation engine are as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 基于用户的协同推荐引擎的组件如下：
- en: '**DataModel**: A DataModel implementation allows us to store and provide access
    to the user, item, and preference data required for computation. The DataModel
    component allows us to pull data from the data source. Mahout provides **MySQLJDBCDataModel**,
    which allows us to pull data from the database via JDBC and MySQL. For the purpose
    of our example, we use the **FileDataModel** interface to access data from files
    that Mahout exposes.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DataModel**：DataModel实现允许我们存储并提供访问用于计算的用户、项目和偏好数据。DataModel组件允许我们从数据源中提取数据。Mahout提供了**MySQLJDBCDataModel**，它允许我们通过JDBC和MySQL从数据库中提取数据。在我们的示例中，我们使用**FileDataModel**接口从Mahout公开的文件中访问数据。'
- en: 'Some other DataModels exposed by Mahout are as follows:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Mahout公开的其他一些DataModel如下：
- en: '**HBaseDataModel**: ([http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/hbase/HBaseDataModel.html](http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/hbase/HBaseDataModel.html))'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HBaseDataModel**：([http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/hbase/HBaseDataModel.html](http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/hbase/HBaseDataModel.html))'
- en: '**GenericJDBCDataModel**: ([http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/jdbc/GenericJDBCDataModel.html](http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/jdbc/GenericJDBCDataModel.html))'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GenericJDBCDataModel**：([http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/jdbc/GenericJDBCDataModel.html](http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/jdbc/GenericJDBCDataModel.html))'
- en: '**PostgreSQLJDBCDataModel**: ([http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/jdbc/PostgreSQLJDBCDataModel.html](http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/jdbc/PostgreSQLJDBCDataModel.html))'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PostgreSQLJDBCDataModel**：([http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/jdbc/PostgreSQLJDBCDataModel.html](http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/jdbc/PostgreSQLJDBCDataModel.html))'
- en: '**MongoDBDataModel**: ([http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/mongodb/MongoDBDataModel.html](http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/mongodb/MongoDBDataModel.html))'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MongoDBDataModel**：([http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/mongodb/MongoDBDataModel.html](http://apache.github.io/mahout/0.10.1/docs/mahout-integration/org/apache/mahout/cf/taste/impl/model/mongodb/MongoDBDataModel.html))'
- en: Mahout expects the user data to be in the format of a userID, itemID, preference
    triplet. The preference values can be either continuous or Boolean. Mahout has
    support for both continuous and Boolean preference values. Each input triplet,
    containing userID, itemID, and preference, which we supply to the DataModel, will
    be represented in a memory-efficient **Preference object** or a **PreferenceArray**
    object.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Mahout期望用户数据以用户ID、项目ID和偏好三元组的格式存在。偏好值可以是连续的或布尔值。Mahout支持连续和布尔偏好值。我们提供给DataModel的每个包含用户ID、项目ID和偏好的输入三元组，将表示为一个内存高效的**Preference对象**或**PreferenceArray对象**。
- en: '**UserSimilarity**: The UserSimilarity interface calculates the similarity
    between two users. The implementations of UserSimilarity return values in the
    range of -1.0 to 1.0 usually, with 1.0 being the perfect similarity. In previous
    chapters, we saw the multiple ways in which we can calculate the similarity between
    users, such as Euclidean Distance, Pearson Coefficient, cosine distance, and so
    on. There are many implementations of the UserSimilarity interface to calculate
    the User Similarity, which are listed as follows:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CachingUserSimilarity
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: CityBlockSimilarity
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: EuclideanDistanceSimilarity
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GenericUserSimilarity
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: LogLikelihoodSimilarity
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: PearsonCorrelationSimilarity
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: SpearmanCorrelationSimilarity
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: TanimotoCoefficientSimilarity
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: UncenteredCosineSimilarity
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ItemSimilarity**: Similar to UserSimilarity, Mahout also provides the ItemSimilarity
    interface, analogous to UserSimilarity, which can be used to calculate the similarity
    between items. The implementations of UserSimilarity return values in the range
    of -1.0 to 1.0 usually, with 1.0 being the perfect similarity:'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AbstractItemSimilarity
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: AbstractJDBCItemSimilarity
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: CachingItemSimilarity
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: CityBlockSimilarity
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: EuclideanDistanceSimilarity
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: FileItemSimilarity
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GenericItemSimilarity
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: LogLikelihoodSimilarity
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQLJDBCInMemoryItemSimilarity
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: MySQLJDBCItemSimilarity
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: PearsonCorrelationSimilarity
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL92JDBCInMemoryItemSimilarity
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL92JDBCItemSimilarity
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: TanimotoCoefficientSimilarity
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: UncenteredCosineSimilarity
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**UserNeighborhood**: In a user-based recommender, recommendations generated
    for the active user are produced by finding a neighborhood of similar users. UserNeighborhood
    usually refers to a way to determine the neighborhood for a given active user,
    for example, the ten nearest neighbors to take into account while generating recommendations.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These neighborhood classes implement the UserSimilarity interface for their
    operation. The following are the implementations of the neighborhood interface:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: CachingUserNeighborhood
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: NearestNUserNeighborhood
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: ThresholdUserNeighborhood
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recommender**: A recommender is the core abstraction in Mahout. Given the
    `DataModel` object as the input, it produces recommendations for items to users.
    The implementations of the recommender interface are as follows:'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AbstractRecommender
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: CachingRecommender
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GenericBooleanPrefItemBasedRecommender
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GenericBooleanPrefUserBasedRecommender
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GenericItemBasedRecommender
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: GenericUserBasedRecommender
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: ItemAverageRecommender
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: ItemUserAverageRecommender
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RandomRecommender
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RecommenderWrapper
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: SVDRecommender
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Building recommendation engines using Mahout
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have covered the core building blocks of the Mahout recommendation
    engine framework, let's start building recommendations. In this section, we will
    look at a series of different recommendation engines implemented using the standalone
    mode. The recommendation engine capabilities are using implementations of the
    `org.apache.mahout.cf.taste.impl` package.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 'The recommendation engines we see in this section are as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中我们看到的推荐引擎如下：
- en: User-based collaborative filtering
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于用户的协同过滤
- en: Item-based collaborative filtering
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于项目的协同过滤
- en: SVD recommenders
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVD推荐器
- en: Dataset description
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集描述
- en: 'Before we get into recommender implementations, let''s look at the dataset
    we use in this section. For this section, we use the restaurant and consumer data
    dataset available from the UCI machine learning dataset repository from the following
    URL:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入研究推荐实现之前，让我们看看本节中使用的数据集。对于本节，我们使用从以下URL可获得的UCI机器学习数据集仓库中的餐厅和消费者数据集：
- en: '[https://archive.ics.uci.edu/ml/datasets/Restaurant+%26+consumer+data](https://archive.ics.uci.edu/ml/datasets/Restaurant+%26+consumer+data)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://archive.ics.uci.edu/ml/datasets/Restaurant+%26+consumer+data](https://archive.ics.uci.edu/ml/datasets/Restaurant+%26+consumer+data)'
- en: This dataset can be used to build collaborative filtering applications using
    consumer preference information. The dataset, the file downloaded from the previous
    link, contains nine files listed in the following figure. Of all the files in
    this exercise, we use the `rating_final.csv` file, which contains attributes such
    as userID, placeID, rating, food_rating, and service_rating. But for our use cases,
    we only use userID, placeID, and rating. We can think of the data as a preference
    value given to Place by a given user.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集可用于构建使用消费者偏好信息进行协同过滤的应用程序。该数据集，从上一个链接下载的文件，包含以下图中列出的九个文件。在所有这些文件中，我们使用`rating_final.csv`文件，其中包含如userID、placeID、rating、food_rating和service_rating等属性。但对我们用例而言，我们只使用userID、placeID和rating。我们可以将数据视为给定用户对地点给出的偏好值。
- en: Note
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We will have to make use of the previously created project in the setup session.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不得不在设置会话中利用之前创建的项目。
- en: Add the input `ratings_final.csv` file to the *data* folder to the current project
    structure.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 将输入的`ratings_final.csv`文件添加到当前项目结构的`*data*`文件夹中。
- en: 'So first, let''s preprocess the original raw data into the required format
    of the userID, placeID, and rating triplet. Here''s the raw dataset used for this
    exercise:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，首先，让我们将原始的原始数据预处理成所需的用户ID、地点ID和评分三元组格式。以下是本练习使用的原始数据集：
- en: '![Dataset description](img/image00475.jpeg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![数据集描述](img/image00475.jpeg)'
- en: 'The following program will prepare the required triplet dataset, implemented
    as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 以下程序将准备所需的元组数据集，实现如下：
- en: Read each line from the `ratings_final.csv` file
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`ratings_final.csv`文件中读取每一行
- en: Extract the first three columns
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取前三个列
- en: Write the extracted columns from the previous step to a new `recoDataset.csv`
    file
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将上一步提取的列写入新的`recoDataset.csv`文件
- en: 'The following java program implements the previously explained steps:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 以下Java程序实现了之前解释的步骤：
- en: '[PRE3]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Upon running the preceding java program, the final dataset that we use to build
    recommendation engines will be created under the *data* folder as the `recoDataset.csv`
    file. The following is a sample dataset:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的Java程序后，我们用于构建推荐引擎的最终数据集将作为`recoDataset.csv`文件位于`*data*`文件夹下。以下是一个样本数据集：
- en: '![Dataset description](img/image00476.jpeg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![数据集描述](img/image00476.jpeg)'
- en: Now that we have preprocessed the required data, let's start building our recommendation
    engines with the Mahout framework.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经预处理了所需的数据，让我们开始使用Mahout框架构建我们的推荐引擎。
- en: User-based collaborative filtering
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于用户的协同过滤
- en: 'Just for the sake of a refresher: the user-based recommender system generates
    recommendations based on the UserSimilarity calculation between users and then
    uses UserNeighborhood to choose top-N users and then generate recommendations.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 仅为了复习：基于用户的推荐系统基于用户之间的用户相似度计算生成推荐，然后使用用户邻域选择前N个用户，然后生成推荐。
- en: 'Let''s first execute the following code and then we shall look at the code
    line by line. We will use the Euclidean Distance similarity and Nearest Neighborhood
    methods to generate recommendations:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先执行以下代码，然后我们将逐行查看代码。我们将使用欧几里得距离相似度和最近邻方法生成推荐：
- en: '[PRE4]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Running this program generates recommendations shown in the following figures.
    We are generating the top three user-based item recommendations to `UserId - 1068`:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此程序生成以下图所示的推荐。我们正在为`UserId - 1068`生成基于用户的三个项目推荐：
- en: 'From the result, we can conclude that for `UserId - 1068`, the top three recommended
    places along with similarity values are as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果中，我们可以得出结论，对于`UserId - 1068`，推荐的三个地方及其相似度值如下：
- en: '![User-based collaborative filtering](img/image00477.jpeg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![基于用户的协同过滤](img/image00477.jpeg)'
- en: 'Let''s now look at the code line by line; just recall the core building blocks
    of the Mahout recommendations section. We need DataModel, Similarity calculation,
    UserNeighborhood, recommender, and generating recommendations. This order is used
    in the previous code:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们一行一行地查看代码；只需回忆一下 Mahout 推荐部分的核心理念构建块。我们需要 DataModel、相似度计算、UserNeighborhood、推荐器和生成推荐。这个顺序在之前的代码中已经使用过：
- en: 'The code in the `UserbasedRecommender.main` method creates a data source from
    the `data/recoDataset.csv` CSV file using `org.apache.mahout.cf.taste.impl.model.file.FileDataModel.FileDataModel
    class`. This class constructor gets the `Java.io.File` instance containing the
    preferences data and creates the `DataModel` class instance model:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`UserbasedRecommender.main` 方法中的代码使用 `org.apache.mahout.cf.taste.impl.model.file.FileDataModel.FileDataModel`
    类从 `data/recoDataset.csv` CSV 文件创建数据源。这个类的构造函数获取包含偏好数据的 `Java.io.File` 实例，并创建
    `DataModel` 类实例模型：'
- en: '[PRE5]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this step, we create the UserSimilarity instance: the similarity calculation
    between all users using `org.apache.mahout.cf.taste.impl.similarity.EuclideanDistanceSimilarity
    class`, which takes the `FileDataModel` instance created in the previous step
    as the constructor parameter:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们创建 UserSimilarity 实例：使用 `org.apache.mahout.cf.taste.impl.similarity.EuclideanDistanceSimilarity`
    类计算所有用户之间的相似度，它将之前步骤中创建的 `FileDataModel` 实例作为构造函数参数：
- en: '[PRE6]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this step, we create the UserNeighborhood instance: the neighborhood using
    `org.apache.mahout.cf.taste.impl.neighborhood.NearestNUserNeighborhood` class,
    and it takes three parameters: the number of nearest neighbors to be considered,
    the UserSimilarity instance-similarity, the DataModel instance which is the model
    created in the previous steps as inputs:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们创建 UserNeighborhood 实例：使用 `org.apache.mahout.cf.taste.impl.neighborhood.NearestNUserNeighborhood`
    类创建邻域，它需要三个参数：要考虑的最近邻数量、UserSimilarity 实例的相似度、作为输入的 DataModel 实例，即之前步骤中创建的模型：
- en: '[PRE7]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The next step is to generate a recommender model. This is achieved using the
    `org.apache.mahout.cf.taste.impl.recommender.GenericUserBasedRecommender class`
    instance. A `GenericUserBasedRecommender` instance-the recommender is created
    by passing the DataModel instance model, the UserNeighborhood instance neighborhood,
    the UserSimilarity instance similarity as inputs to the constructer while creating
    the recommender object.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是生成推荐模型。这是通过使用 `org.apache.mahout.cf.taste.impl.recommender.GenericUserBasedRecommender`
    类实例来实现的。创建推荐器实例时，通过将 DataModel 实例模型、UserNeighborhood 实例邻域、UserSimilarity 实例相似度作为输入传递给构造函数：
- en: '[PRE8]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Kudos! We have created our user-based recommender system using the Euclidean
    Distance similarity and the `NearestNNeighborhhood` method to create a recommender
    model. Now the next step would be to generate recommendations; for this, we call
    the `recommend()` method available in the recommender object, which takes `UserId`
    for which the recommendations and the number of recommendations have to be generated:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 恭喜！我们已经使用欧几里得距离相似度和 `NearestNNeighborhhood` 方法创建了一个基于用户的推荐系统，并生成了一个推荐模型。下一步将是生成推荐；为此，我们调用推荐器对象中可用的
    `recommend()` 方法，该方法需要生成推荐的 `UserId` 和推荐的数量：
- en: '[PRE9]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This step has generated three item recommendations to the `UserId` 1068 along
    with the strength of the preference.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤已为 `UserId` 1068 生成三个基于物品的推荐，并附带偏好的强度。
- en: 'In our case, we generated the following recommendations:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们生成了以下推荐：
- en: '[PRE10]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Item-based collaborative filtering
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于物品的协同过滤
- en: Item-based recommenders recommend similar items to users by considering the
    similarity between items instead of the similarity of users, as shown in the previous
    section.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 基于物品的推荐器通过考虑物品之间的相似度而不是用户之间的相似度来向用户推荐相似物品，如前节所示。
- en: 'The following is the given java program to build item-based collaborative filtering.
    We have used `LogLikelihoodSimilarity` to calculate `ItemSimilarity`, and then
    we used the `GenericItemBasedRecommender` class to recommend items to users. In
    addition, we can see how to check similar items for a given item using the `mostSimilarItems`
    method present in `GenericItemBasedRecommender`:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个给定的 Java 程序，用于构建基于物品的协同过滤。我们使用了 `LogLikelihoodSimilarity` 来计算 `ItemSimilarity`，然后我们使用了
    `GenericItemBasedRecommender` 类向用户推荐物品。此外，我们还可以看到如何使用 `GenericItemBasedRecommender`
    中的 `mostSimilarItems` 方法检查给定物品的相似物品：
- en: '[PRE11]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Running the previous program will generate three items most similar to the
    input item, in our case, for the placeID `135104`, the most similar placeID attributes
    along with the strength of the similarity is shown in the following screenshot:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的程序将生成与输入物品最相似的三个物品，在我们的例子中，对于placeID `135104`，最相似的地方ID属性及其相似度强度如下所示：
- en: '![Item-based collaborative filtering](img/image00478.jpeg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![基于物品的协同过滤](img/image00478.jpeg)'
- en: 'Let''s look at each step of the preceding program in order to understand what''s
    happening in the preceding implementation:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们依次查看前面程序中的每个步骤，以了解前面实现中发生了什么：
- en: 'The first step, like in the previous section, is to create the DataModel instance
    using the `org.apache.mahout.cf.taste.impl.model.file.FileDataModel` class:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步，就像在上一节中一样，是使用`org.apache.mahout.cf.taste.impl.model.file.FileDataModel`类创建`DataModel`实例：
- en: '[PRE12]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In this step, we create the ItemSimilarity instance, the similarity calculation
    between all users using the `org.apache.mahout.cf.taste.impl.similarity.LogLikelihoodSimilarity`
    class, which takes the `FileDataModel` instance created in the previous step as
    the constructor parameter:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们创建了一个`ItemSimilarity`实例，使用`org.apache.mahout.cf.taste.impl.similarity.LogLikelihoodSimilarity`类计算所有用户之间的相似度，该类将之前步骤中创建的`FileDataModel`实例作为构造函数参数：
- en: '[PRE13]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The next step is to generate a recommender model. This is achieved using the
    `org.apache.mahout.cf.taste.impl.recommender.GenericItemBasedRecommender` class
    instance. A `GenericItemBasedRecommender` instance recommender is created passing
    the DataModel instance which is the model ItemSimilarity instance-similarity as
    inputs to the constructer while creating the recommender object.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是生成一个推荐模型。这是通过使用`org.apache.mahout.cf.taste.impl.recommender.GenericItemBasedRecommender`类实例来实现的。创建一个`GenericItemBasedRecommender`实例推荐器时，将数据模型实例（即模型`ItemSimilarity`实例的相似度）作为输入传递给构造函数，以创建推荐对象。
- en: '[PRE14]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The choice of the similarity metric is left to you; it is set as per your requirement.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相似度度量指标的选择留给你；它根据你的要求设置。
- en: 'Kudos! We have created our item-based recommender system using the `LogLikelihood`
    similarity to create a recommender model. Now the next step would be to generate
    recommendations, and for this, we call the `recommend()` method available in the
    recommender object, which takes `UserId` for which the recommendations and the
    number of recommendations have to be generated:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 太棒了！我们已经使用`LogLikelihood`相似度创建了基于物品的推荐系统。下一步将是生成推荐，为此，我们调用推荐对象中可用的`recommend()`方法，该方法需要`UserId`以及要生成的推荐数量：
- en: '[PRE15]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This step has generated three item recommendations to the UserID 1068 along
    with the strength of the preference.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此步骤已为UserID 1068生成了三个物品推荐，并附带了偏好的强度。
- en: 'In our case, we generated the following recommendations:'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们生成了以下推荐：
- en: '[PRE16]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Imagine that we want to see items similar to a particular item; recommender
    interfaces, such as the `GenericItemBasedRecommender` class in our example, provide
    the `mostSimilarItems()` method, which takes `UserId`, the number of items to
    be displayed as inputs, and extracts `similarItems` for a given item:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设我们想查看与特定物品相似的商品；在我们的示例中，推荐接口，如`GenericItemBasedRecommender`类，提供了`mostSimilarItems()`方法，该方法接受`UserId`和要显示的商品数量作为输入，并为给定物品提取`similarItems`：
- en: '[PRE17]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In our example, the three places most similar to `PlaceId` 135104 are shown
    as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，与`PlaceId` 135104最相似的三个地方如下所示：
- en: '[PRE18]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the following section, let's evaluate the recommendations we have created
    so far.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们评估到目前为止我们创建的推荐。
- en: Evaluating collaborative filtering
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估协同过滤
- en: We have seen how to build recommendations using collaborative filtering approaches.
    But the key thing is to build efficient recommendations. Evaluating the accuracy
    of the recommender models - what we built - is a very crucial step in building
    recommendation engines. In this section, we will look at how to evaluate both
    user-based recommenders and item-based recommenders.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何使用协同过滤方法构建推荐。但关键是要构建高效的推荐。评估推荐模型的准确性——我们所构建的——是构建推荐引擎的一个非常关键步骤。在本节中，我们将探讨如何评估基于用户的推荐器和基于物品的推荐器。
- en: Mahout provides components that enable us to evaluate the accuracy of the recommendation
    models we have built so far. We can evaluate how closely our recommendation engine
    estimates the preferences against the actual preference values. We can instruct
    Mahout to use part of the original training data to set aside and use this test
    dataset in order to calculate the accuracy of the model.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 提供了组件，使我们能够评估我们迄今为止构建的推荐模型的准确率。我们可以评估我们的推荐引擎如何接近实际偏好值来估计偏好。我们可以指示 Mahout
    使用原始训练数据的一部分来留出并使用这个测试数据集来计算模型的准确率。
- en: 'We can use any of the following listed recommender evaluators provided by Mahout
    as per our requirement:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的需求，我们可以使用 Mahout 提供的以下任何推荐器评估器：
- en: '![Evaluating collaborative filtering](img/image00479.jpeg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![评估协同过滤](img/image00479.jpeg)'
- en: 'Recommender evaluation using Mahout usually requires two steps:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Mahout 进行推荐器评估通常需要两个步骤：
- en: Creating an instance of the `org.apache.mahout.cf.taste.impl.eval.RMSRecommenderEvaluator`
    class available from the preceding list, which will create the accuracy score
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 `org.apache.mahout.cf.taste.impl.eval.RMSRecommenderEvaluator` 类的实例，该类可以从前面的列表中获取，它将创建准确率分数
- en: Implementing the inner interface for `org.apache.mahout.cf.taste.eval.RecommenderBuilder`
    so as to create the recommender that the `RecommenderEvaluator` class instance
    from the previous step can use to produce the accuracy score
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现 `org.apache.mahout.cf.taste.eval.RecommenderBuilder` 的内部接口，以便创建 `RecommenderEvaluator`
    类实例（上一步）可以使用的推荐器，以产生准确率分数
- en: The listing shows the java implementation for user-based recommender model evaluation.
    For this exercise, we have used the root mean squared error evaluation technique.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 列表显示了基于用户的推荐器模型评估的 Java 实现。对于这个练习，我们使用了均方根误差评估技术。
- en: Evaluating user-based recommenders
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估基于用户的推荐器
- en: 'In this section, we shall see the code for evaluating the user-based recommendations
    we built in the previous section:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到评估上一节中构建的基于用户的推荐的代码：
- en: '[PRE19]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Executing the preceding program will give us the model accuracy: `0.692216091226208`.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 执行前面的程序将给出模型准确率：`0.692216091226208`。
- en: Evaluating item-based recommenders
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估基于物品的推荐器
- en: 'Below code snippet will be used in evaluating the item-based recommendations:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段将用于评估基于物品的推荐：
- en: '[PRE20]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Executing the previous program will give us the model accuracy: `0.6041129199039021`.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 执行前面的程序将给出模型准确率：`0.6041129199039021`。
- en: 'Now let''s look at this evaluation implementation step by step:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们一步一步地看看这个评估实现：
- en: 'The first step is to create a DataModel instance model using the `org.apache.mahout.cf.taste.impl.model.file.FileDataModel`
    class:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是使用 `org.apache.mahout.cf.taste.impl.model.file.FileDataModel` 类创建一个 DataModel
    实例模型：
- en: '[PRE21]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In this step, we create the `org.apache.mahout.cf.taste.impl.eval.RMSRecommenderEvaluator`
    instance evaluator, which will calculate the recommendation engine accuracy:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们创建 `org.apache.mahout.cf.taste.impl.eval.RMSRecommenderEvaluator` 实例评估器，它将计算推荐引擎的准确率：
- en: '[PRE22]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this step, we implement the `org.apache.mahout.cf.taste.eval.RecommenderBuilder`
    interface to create the recommender of our choice.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们实现 `org.apache.mahout.cf.taste.eval.RecommenderBuilder` 接口以创建我们选择的推荐器。
- en: 'Let''s use the same recommender models we used for both user-based and item-based
    recommenders in the previous section:'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们使用与上一节中用于基于用户和基于物品的推荐器相同的推荐器模型：
- en: '[PRE23]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now we are ready to calculate the recommendation accuracy. For this, we use
    the `evaluate()` method from the evaluator instance. The `evaluate()` method does
    not accept a recommender instance--which we created in user-based/item-based recommenders
    directly--but it accepts RecommenderBuilder, created in step 3 of our examples/index,
    which can build the recommender to test the accuracy on top of a given DataModel.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经准备好计算推荐准确率。为此，我们使用评估器实例的 `evaluate()` 方法。`evaluate()` 方法不接受我们直接在基于用户/基于物品推荐器中创建的推荐器实例，但它接受在步骤
    3 中创建的 RecommenderBuilder，该 RecommenderBuilder 可以在给定的 DataModel 上构建推荐器以测试准确率。
- en: 'The `evaluate()` method takes four parameters: the recommender builder created
    in step 3, the DataModel object created in step 1, the DataModel builder object
    that we don''t need for our example, the training percentage--in our case, we
    used 0.7 % as the training dataset and 0.3 as the test dataset--, evaluation percentage,
    the percentage of users to be used in evaluation.'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `evaluate()` method returns the accuracy score of the model, which is how
    well the recommender-predicted preferences match the real values. Lower values
    indicate a better match, with 0 being the perfect match:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: SVD recommenders
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similar to the item-based and user-based recommender systems explained earlier,
    we can also use model-based recommender implementations in Mahout, such as `SVDRecommender`,
    which uses matrix factorization methods to generate recommendations.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps are similar to previous implementations. Two important steps that
    need to be understood here are as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'The `org.apache.mahout.cf.taste.impl.recommender.svd.ALSWRFactorizer` class,
    which factorizes the user rating matrix using *Alternating-Least-Squares with
    Weighted-λ-Regularization*. The `ALSWRFactorizer` class constructor takes parameters
    such as DataModel, the number of features, the regularization parameter, and the
    number of iterations as inputs. This `ALSWRFactorizer` class instance is passed
    as the input parameter to the recommender object: the `SVDRecommender` class.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `org.apache.mahout.cf.taste.impl.recommender.svd.SVDRecommender` class generates
    the recommendation model by taking `DataModel` and `ALSWRFactorizer` objects.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The rest of the other steps are very similar to what we saw in the previous
    examples:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code snippet shows how to build SVD recommender systems:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Distributed recommendations using Mahout
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up to now, we have seen how to build recommendation engines in the standalone
    mode. In most cases, the standalone implementations are very handy and they work
    quite efficiently in handling a million records provided we supply the dataset
    format, such as the userID, itemID, and preference triplet.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: When the size of the data increases, the standalone mode might not be able to
    address the requirements. We need to look for ways to handle the enormous amount
    of data and be able to process the data to build recommendations. One approach
    is to port our standalone solution to the distributed mode, an example of which
    is Hadoop platforms.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: The porting of the recommender solution to Hadoop is not straight forward, as
    the data will be distributed across the nodes. The memory-based models, such as
    neighbourhood recommenders, or model-based recommenders, such as Alternating Least
    Squares, requires the entire data to be available while generating the model,
    which will not be available on a distributed platform. Hence we need an entirely
    new design to build recommender systems.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, Mahout has removed the headaches in designing recommender implementations
    that can be distributed. These Mahout-distributed recommendation engine implementations
    are provided as jobs that internally run a series of map-reduce phases.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, Mahout-distributed recommendations using Alternating Least Squares
    consists of two jobs:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: A parallel matrix factorization job
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A recommendation job
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The matrix factorization job takes the user-item-rating file as the input and
    creates the user latent matrix that is a user feature matrix and an item feature
    matrix.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The recommendation job uses the latent feature matrices created using the matrix
    factorization job and computes Top-N recommendations.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The two jobs are executed sequentially, the input data is read from HDFS, and
    final recommendations are written to HDFS.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we shall look at how to generate recommendations using the
    item-based recommendation engine and Alternating Least Squares methods using Hadoop.
    Let's begin.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: ALS recommendation on Hadoop
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To build the recommendation using ALS implementations, the following are the
    steps:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'Load data to the Hadoop platform. The ALS implementation of Mahout expects
    the input to be a triplet: userID, itemID, and preference value (explicit rating/implicit
    rating).'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Execute the ALS recommendation engine implementation job; this job will create
    user and item latent matrices by taking the input dataset from step 1.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Execute the recommender job that takes the user-item latent feature matrices
    created in step 2 and generate Top-N recommendations.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's execute all the steps one by one.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the following exercise, we are using CDH 5 and Centos 6. This is assuming
    `JAVA_HOME` is set and Mahout is installed properly.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'Load data to the Hadoop platform as follows:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let''s check whether we have created the directory properly using the `ls`
    command:'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now let''s load data to the HDFS using the `copyFromLocal` command:'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: The input data is the MovieLens dataset that consists of one million rating
    data.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s verify that the data is loaded properly using the `ls` command:'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now that we have seen that the data is loaded properly, let''s look at the
    first few records of the input data:'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![ALS recommendation on Hadoop](img/image00480.jpeg)'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Create **User** and **Item latent** matrices. To create the latent feature
    matrices, we need to run the following commands from the command line:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Let''s look at each of the command parameters:'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**$MAHOUT_HOME\bin\mahout**: This is the executable file that runs the underlying
    matrix factorization job.'
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**parallelALS**: This is the name of the algorithm to be applied on the input
    dataset. The `parallelALS` command invokes the underlying `ParallelALSFactorizationJob
    class object`, which is a map-reduce implementation of the factorization algorithms
    described in *Large-scale Parallel Collaborative Filtering for the Netflix Prize*.'
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--input**: This is the HDFS input path of the input ratings data.'
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--output**: This is the path where the output latent matrices for the user
    and item will be generated.'
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--lambda**: This is the regularization parameter given in order to avoid
    overfitting.'
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--alpha**: This is the confidence parameter used for implicit feedback only.'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--implicitFeatures**: This is the Boolean value to state whether the preference
    values are true or false. In our case, they are false.'
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--numIterations**: This is the total number of times the model gets recomputed
    by applying the learnings from the previous model to the new model.'
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--tempDir**: This is the path to the temporary directory where the intermediate
    results are written.'
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On executing the command we saw, three datasets are created in the *output*
    directory:'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**U**: This contains the user latent feature matrix'
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**M**: The contains the item latent feature matrix'
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**userRatings:** All the outputs are of a sequence file format.'
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate recommendations for all the users. This step takes the *output* results
    stored to HDFS from the previous step as the input, generates recommendations,
    and writes the final recommendations to the *recommendations output* directory
    on HDFS.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following command will invoke the `org.apache.mahout.cf.taste.hadoop.als.RecommenderJob`
    recommender job, which internally calls an `org.apache.mahout.cf.taste.hadoop.als.PredictionMapper`
    class to generate recommendations:'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let''s look at each of the parameters in detail:'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**-- input**: This is the HDFS path containing the list of the userID file
    to be used to generate recommendations in the sequence file format. In our example,
    the *output/userRatings* directory contains all the userID to be used to generate
    recommendations in the sequence file format; this file is the output of step 2.'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--userFeatures**: This is the HDFS path containing user latent features generated
    as the output in step 2.'
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--itemFeatures**: This is the HDFS path containing item latent features generated
    as the output in step 2.'
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--numRecommendations**: The number of recommendations to be generated per
    user.'
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--output recommendations**: This is the HDFS path where the final recommendations
    have to be generated.'
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**--maxRating**: This is the maximum rating that the generated recommendations
    should contain.'
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Upon running the previous commands in the command line, recommendations are
    generated into the recommendations folder on HDFS, as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '![ALS recommendation on Hadoop](img/image00481.jpeg)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
- en: In the earlier result, we can see the first ten user recommendations in order.
    Each user vector contains itemID and the rating that the algorithm has predicted.
    While serving recommendations, we can just send recommendations as is.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you may get a question like this: what if I want to generate recommendations
    to specific users? Mahout supports such scenarios as well. Remember the input
    parameter in step 3? Just provide the HDFS path containing the userID which we
    need for recommendations. But make sure that the input path containing the userID
    are in a sequence file format.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可能会有这样的问题：如果我想为特定用户生成推荐怎么办？Mahout也支持这样的场景。记住步骤3中的输入参数吗？只需提供包含所需用户ID的HDFS路径即可。但请确保包含用户ID的输入路径是序列文件格式。
- en: The architecture for a scalable system
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可扩展系统的架构
- en: 'Taking the recommendation engine system to production is the same as any other
    system. The previous figure shows a very simple recommendation engine deployed
    on a production system:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 将推荐引擎系统投入生产与任何其他系统相同。前面的图显示了在生产系统上部署的一个非常简单的推荐引擎：
- en: The production system is Centos 6 with Java 8 and the Apache Tomcat server installed
    on the system. CDH 5 and the Mahout 0.12 version is also installed on it so that
    the recommender jobs we have built so far can be deployed:![The architecture for
    a scalable system](img/image00482.jpeg)
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产的系统是安装了Java 8和Apache Tomcat服务器的Centos 6。CDH 5和Mahout 0.12版本也安装在其上，以便我们可以部署我们迄今为止构建的推荐作业：![可扩展系统的架构](img/image00482.jpeg)
- en: The Java code we have written so far can be made as jar files and deployed on
    the production system. Schedule all the jobs at a regular interval as per our
    requirements.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们迄今为止编写的Java代码可以制作成jar文件并部署到生产系统。根据我们的要求，定期安排所有作业。
- en: At a defined scheduled time, the recommender jobs start executing and the data
    is pulled from data sources, computes recommendation models, and generates recommendations.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在定义的预定时间，推荐作业开始执行，从数据源拉取数据，计算推荐模型，并生成推荐。
- en: The data for the recommendation module will be read and written back to the
    HDFS file system.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐模块的数据将被读取并写回到HDFS文件系统。
- en: The frontend applications will read the final outputs from HDFS.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前端应用程序将读取HDFS中的最终输出。
- en: Summary
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we saw how to build recommendations using Apache Mahout. We
    looked at how we can leverage Mahout for both the standalone and the distributed
    mode. We have written Java code for user-based, item-based, and SVD-based recommendation
    engines in the standalone mode and Alternating Least Squares recommendations in
    the distributed mode. We also saw how we can evaluate the recommendation engine
    models. In the final section, we explored a very basic system of how to take Mahout
    to production.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了如何使用Apache Mahout构建推荐。我们探讨了如何利用Mahout在独立模式和分布式模式中。我们在独立模式下为基于用户、基于项目和基于SVD的推荐引擎编写了Java代码，在分布式模式下编写了交替最小二乘推荐。我们还看到了如何评估推荐引擎模型。在最后一节中，我们探索了一个如何将Mahout投入生产的基本系统。
- en: In the final chapter, we shall cover the future of recommendation engines, where
    the recommendation engines are heading, and the promising use cases to lookout
    for.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一章中，我们将探讨推荐引擎的未来，包括推荐引擎的发展方向和值得关注的潜在用例。
