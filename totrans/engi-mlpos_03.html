<html><head></head><body>
		<div id="_idContainer033">
			<h1 id="_idParaDest-27"><a id="_idTextAnchor028"/>Chapter 2: Characterizing Your Machine Learning Problem</h1>
			<p>In this chapter, you will get a fundamental understanding of the various types of <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) solutions that can be built for production, and will learn to categorize the relevant operations in line with the business and technological needs of your organization. You will learn how to curate an implementation roadmap for operationalizing ML solutions, followed by procuring the necessary tools and infrastructure for any given problem. By the end of this chapter, you will have a solid understanding of how to architect robust and scalable ML solutions and procure the required data and tools for implementing these solutions.</p>
			<p><strong class="bold">ML Operations</strong> (<strong class="bold">MLOps</strong>) aims to bridge academia and industry using state-of-the-art engineering principles, and we will explore different elements from both industry and academia to get a holistic understanding and awareness of the possibilities. Before beginning to craft your MLOps solution, it is important to understand the various possibilities, setups, problems, solutions, and methodologies on offer for solving business-oriented problems. To achieve this understanding, we're going to cover the following main topics in this chapter:<a id="_idTextAnchor029"/></p>
			<ul>
				<li>The ML solution development process</li>
				<li>Types of ML models </li>
				<li>Characterizing your MLOps</li>
				<li>An implementation roadmap for your solution </li>
				<li>Procuring the necessary data, tools, and infrastructure  </li>
				<li>Introduction to a real-life business problem </li>
			</ul>
			<p>Without further ado, let's jump in and explore the possibilities ML can enable by taking an in-depth look into the ML solution development process and examining different types of ML models to solve business problems.</p>
			<h1 id="_idParaDest-28"><a id="_idTextAnchor030"/>The ML solution development process</h1>
			<p>ML offers many <a id="_idIndexMarker069"/>possibilities to augment and automate business. To get the best from ML, teams and people engaged in ML-driven business transformation need to understand both ML and the business itself. Efficient business transformation begins with having a rough understanding of the business, including aspects such as value-chain analysis, use-case identification, data mapping, and business simulations to validate the business transformation. <em class="italic">Figure 2.1</em> presents a process to develop ML solutions to augment or automate business operations:</p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B16572_02_01.jpg" alt="Figure 2.1 – ML solution development process&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.1 – ML solution development process</p>
			<p>Business understanding is the genesis of developing an ML solution. After having a decent business understanding, we proceed to data analysis, where the right data is acquired, versioned, and stored. Data is consumed for ML modeling using data pipelines where feature engineering is done to get the right features to train the model. We evaluate the <a id="_idIndexMarker070"/>trained models and package them for deployment. Deployment and monitoring are done using a pipeline taking advantage of <strong class="bold">Continuous Integration/Continuous Deployment</strong> (<strong class="bold">CI/CD</strong>) features that enable real-time and continuous deployment to serve trained ML models to the users. This process ensures robust and scalable ML solutions. </p>
			<h1 id="_idParaDest-29"><a id="_idTextAnchor031"/>Types of ML models</h1>
			<p>As there is a selection of ML and deep learning models that address the same business problem, it is essential to understand the landscape of ML models in order to make an efficient algorithm <a id="_idIndexMarker071"/>selection. There <a id="_idIndexMarker072"/>are around 15 types of ML techniques, these being categorized <a id="_idIndexMarker073"/>into 4 categories, namely <strong class="bold">learning models</strong>, <strong class="bold">hybrid models</strong>, <strong class="bold">statistical models</strong>, and <strong class="bold">Human-In-The-Loop</strong> (<strong class="bold">HITL</strong>) models, as <a id="_idIndexMarker074"/>shown in the following <a id="_idIndexMarker075"/>matrix (where <a id="_idIndexMarker076"/>each grid square <a id="_idIndexMarker077"/>reflects one of these categories) in <em class="italic">Figure 2.2</em>. It is worth noting that there are other possible ways of categorizing ML models and none of them are fully complete, and as such, these categorizations will serve appropriately for some scenarios and not for others. Here is our recommended categorization with which to look at ML models:</p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B16572_02_02.jpg" alt="Figure 2.2 – Types of ML models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.2 – Types of ML models</p>
			<h2 id="_idParaDest-30"><a id="_idTextAnchor032"/>Learning models</h2>
			<p>First, we'll <a id="_idIndexMarker078"/>take a look at two types of standard learning models, <strong class="bold">supervised learning</strong> and <strong class="bold">unsupervised learning</strong>:</p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B16572_02_03.jpg" alt="Figure 2.3 – Supervised versus unsupervised learning&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.3 – Supervised versus unsupervised learning</p>
			<h3>Supervised learning </h3>
			<p>Supervised <a id="_idIndexMarker079"/>learning models or algorithms are trained <a id="_idIndexMarker080"/>based on labeled data. In the training data, the result of the input is marked or known. Hence a model is trained to predict the outcome when given an input based on the labeled data it learns from, and you tell the system which output corresponds with a given input in the system. </p>
			<p>Supervised learning models are very effective on narrow AI cases and well-defined tasks but can only be harnessed where there is sufficient and comprehensive labeled data. We can see in <em class="italic">Figure 2.3</em>, in the case of supervised learning, that the model has learned to predict and classify an input. </p>
			<p>Consider the example of an image classification model used to classify images of cats and dogs. A supervised learning model is trained on labeled data consisting of thousands of correctly labeled images of cats and dogs. The trained model then learns to classify a given input image as containing a dog or a cat.</p>
			<h3>Unsupervised learning</h3>
			<p>Unsupervised learning has nothing to do with a machine running around and doing things <a id="_idIndexMarker081"/>without human <a id="_idIndexMarker082"/>supervision. Unsupervised learning models or algorithms learn from unlabeled data. Unsupervised learning can be used to mine insights and identify patterns from unlabeled data. Unsupervised algorithms are widely used for clustering or anomaly detection without relying on any labels. These algorithms can be pattern-finding algorithms; when data is fed to such an algorithm, it will identify patterns and turn those into a recipe for taking a new data input without a label and applying the correct label to it. </p>
			<p>Unsupervised learning is used mainly for analytics, though you could also use it for automation and ML. It is recommended not to use these algorithms in production due to their dynamic nature that changes outputs on every training cycle. However, they can be useful to automate certain processes such as segmenting incoming data or identifying anomalies in real time.  </p>
			<p>Let's discuss an example of clustering news articles into relevant groups. Let's assume you have thousands of news articles without any labels and you would like to identify the types or categories of articles. To perform unsupervised learning on these articles, we can input a bunch of articles into the algorithm and converge it to put similar things together (that is, clustering) in four groups. Then, we look at the clusters and discover that similar articles have been grouped together in categories such as politics, sports, science, and health. This is a way of mining patterns in the data.</p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor033"/>Hybrid models</h2>
			<p>There have been rapid <a id="_idIndexMarker083"/>developments in ML by combining conventional methods to develop hybrid models to solve diverse business and research problems. Let's look into some hybrid models and how they work. <em class="italic">Figure 2.4</em> shows various hybrid models: </p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/B16572_02_04.jpg" alt="Figure 2.4 – Types of hybrid models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.4 – Types of hybrid models</p>
			<h3>Semi-supervised learning</h3>
			<p><strong class="bold">Semi-supervised learning</strong> is a hybrid of supervised learning, used in cases where only a few <a id="_idIndexMarker084"/>samples are labeled and a large number of samples are <a id="_idIndexMarker085"/>not labeled. Semi-supervised learning enables efficient use of the data available (though not all of it is labeled), including the unlabeled data. For example, a text document classifier is a typical example of a semi-supervised learning program. It will be very difficult to locate a large number of labeled text documents in this case, so semi-supervised learning is ideal. This is due to the fact that making someone read through entire text documents just to assign a basic classification is inefficient. As a result, semi-supervised learning enables the algorithm to learn from a limited number of labeled text documents while classifying the large number of unlabeled text documents present in the training data.</p>
			<h3>Self-supervised learning</h3>
			<p><strong class="bold">Self-supervised learning</strong> problems are unsupervised learning problems where data is not labeled; these <a id="_idIndexMarker086"/>problems are translated into <a id="_idIndexMarker087"/>supervised learning problems in order to apply algorithms for supervised learning to solve them sustainably. Usually, self-supervised algorithms are used to solve an alternate task in which they supervise themselves to solve the <a id="_idIndexMarker088"/>problem or generate an output. One example of self-supervised learning is <strong class="bold">Generative Adversarial Networks</strong> (<strong class="bold">GANs</strong>); these are commonly used to generate synthetic data by training on labeled and/or unlabeled data. With proper training, GAN models can generate a relevant output in a self-supervised manner. For example, a GAN could generate a human face based on a text description input, such as <em class="italic">gender: male, age: 30, color: brown</em>, and so on.</p>
			<h3>Multi-instance learning</h3>
			<p><strong class="bold">Multi-instance learning</strong> is a supervised learning problem in which data is not labeled by individual data <a id="_idIndexMarker089"/>samples, but cumulatively in <a id="_idIndexMarker090"/>categories or classes. Compared to typical supervised learning, where labeling is done for each data sample, such as news articles labeled in categories such as politics, science, and sports, with multi-instance learning, labeling is done categorically. In such scenarios, individual samples are collectively labeled in multiple classes, and by using supervised learning algorithms, we can make predictions. </p>
			<h3>Multitask learning</h3>
			<p><strong class="bold">Multitask learning</strong> is an incarnation <a id="_idIndexMarker091"/>of supervised <a id="_idIndexMarker092"/>learning that involves training a model on one dataset and using that model to solve multiple tasks or problems. For example, for natural language processing, we use word embeddings or <strong class="bold">Bidirectional Encoder Representations from Transformers </strong>(<strong class="bold">BERT</strong>) embeddings models, which are trained on one <a id="_idIndexMarker093"/>large corpus of data. (BERT is a pre-trained model, trained on a large text corpus. The model has a deep understanding of how a given human language works.) And these models can be used to solve many supervised learning tasks such as text classification, keyword extraction, sentiment analysis, and more. </p>
			<h3>Reinforcement learning </h3>
			<p><strong class="bold">Reinforcement learning</strong> is a type of learning in <a id="_idIndexMarker094"/>which an agent, such as <a id="_idIndexMarker095"/>a robot system, learns to operate in a defined environment to perform sequential decision-making tasks or achieve a pre-defined goal. Simultaneously, the agent learns based on continuously evaluated feedback and rewards from the environment. Both feedback and rewards are used to shape the learning of the agent, as shown in <em class="italic">Figure 2.5</em>. An example is Google's AlphaGo, which recently outperformed the world's leading Go player. After 40 days of self-training using feedback and rewards, AlphaGo was able to beat the world's best human Go player:</p>
			<div>
				<div id="_idContainer026" class="IMG---Figure">
					<img src="image/B16572_02_05.jpg" alt="Figure 2.5 – Reinforcement learning&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.5 – Reinforcement learning</p>
			<h3>Ensemble learning</h3>
			<p><strong class="bold">Ensemble learning</strong> is a hybrid model that involves two or more models trained on the same data. Predictions <a id="_idIndexMarker096"/>are made using each model individually <a id="_idIndexMarker097"/>and a collective prediction is made as a result of combining all outputs and averaging them to determine the final outcome or prediction. An example of this is the random forest algorithm, which is an ensemble learning method for classification or regression tasks. It operates by composing several decision trees while training, and creates a prediction as output by averaging the predictions of all the decision trees.</p>
			<h3>Transfer learning </h3>
			<p>We humans <a id="_idIndexMarker098"/>have an innate ability to transfer knowledge to and from <a id="_idIndexMarker099"/>one another. This same principle is translated to ML, where a model is trained to perform a task and it is transferred to another model as a starting point for training or fine-tuning for performing another task. This type of learning is popular in deep learning, where pre-trained models are used to solve computer vision or natural language processing problems by fine-tuning or training using a pre-trained model. Learning from pre-trained models gives a huge jumpstart as models don't need to be trained from scratch, saving large amounts of training data. For example, we can train a sentiment classifier model using training data containing only a <a id="_idIndexMarker100"/>few labeled data samples. This is possible with <a id="_idIndexMarker101"/>transfer learning using a pre-trained BERT model (which is trained on a large corpus of labeled data). This enables the transfer of learning from one model to another.</p>
			<h3>Federated learning </h3>
			<p><strong class="bold">Federated learning</strong> is a way of performing ML in a collaborative fashion (synergy between cloud and edge). The <a id="_idIndexMarker102"/>training process is distributed across <a id="_idIndexMarker103"/>multiple devices, storing only a local sample of the data. Data is neither exchanged nor transferred between devices or the cloud to maintain data privacy and security. Instead of sharing data, locally trained models are shared to learn from each other to train global models. Let's discuss an example of federated learning in hospitals (as shown in <em class="italic">Figure 2.6</em>) where patient data is confidential and cannot be shared with third parties. In this case, ML training is done locally in the hospitals (at the edge) and global models are trained centrally (on the cloud) without sharing the data. Models trained locally are fine-tuned to produce global models. Instead of ingesting data in the central ML pipeline, locally trained models are ingested. Global models learn by tuning their parameters from local models to converge on optimal performance, concatenating the learning of local models:</p>
			<div>
				<div id="_idContainer027" class="IMG---Figure">
					<img src="image/B16572_02_06.jpg" alt="Figure 2.6 – Federated learning architecture &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.6 – Federated learning architecture </p>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor034"/>Statistical models </h2>
			<p>In some cases, statistical <a id="_idIndexMarker104"/>models are efficient at making decisions. It is vital to know where statistical models can be used to get the best value or decisions. There are three types of statistical models: inductive learning, deductive learning, and transductive learning. <em class="italic">Figure 2.7</em> shows the relationship between these types of statistical models:</p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/B16572_02_07.jpg" alt="Figure 2.7 – Relationship between the three types of statistical models &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.7 – Relationship between the three types of statistical models </p>
			<p><strong class="bold">Inductive learning</strong> is a statistical method that generalizes from specific examples in the <a id="_idIndexMarker105"/>training data, using this evidence to <a id="_idIndexMarker106"/>determine the most likely outcome. It involves a process of learning by example, where a system tries to generalize a general function or rule from a set of observed instances. For example, when we fit an ML model, it is a process of induction. The ML model is a generalization of the specific examples in the training dataset. For instance, using linear regression when fitting the model to the training data generalizes specific examples in the training data by the function <em class="italic">Y = a + bX</em>.  Such generalizations are made in inductive learning.</p>
			<p><strong class="bold">Deductive learning</strong> refers to using general rules to determine specific outcomes. The <a id="_idIndexMarker107"/>outcomes of deductive learning <a id="_idIndexMarker108"/>are deterministic and specific, whereas for inductive reasoning, the conclusions are probabilistic or generalized. In a way, deduction is the reverse of induction. If induction goes from the specific to the general, deduction goes from the general to the specific.</p>
			<p><strong class="bold">Transductive learning</strong> is a method for reasoning about outcomes based on specific training <a id="_idIndexMarker109"/>data samples (in the training dataset). This <a id="_idIndexMarker110"/>method is different from inductive learning, where predictions are generalized over the training data. In transductive learning, specific or similar data samples from the training data are compared to reason about or predict an outcome. For example, in the case of the <em class="italic">k</em>-nearest neighbors algorithm, it uses specific data samples on which to base its outcome rather than generalizing the outcome or modeling with the training data.</p>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor035"/>HITL models</h2>
			<p>There are two types of <strong class="bold">HITL</strong> models: <strong class="bold">human-centered reinforcement learning</strong> mo<a id="_idTextAnchor036"/>dels and <strong class="bold">active learning</strong> models. In <a id="_idIndexMarker111"/>these models, human-machine collaboration enables the algorithm to mimic human-like behaviors and outcomes. A key driver for these ML solutions is the <em class="italic">human in the loop (hence HITL)</em>. Humans validate, label, and retrain the models to maintain the accuracy of the model:</p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B16572_02_08.jpg" alt="Figure 2.8 – Workflow of human-centered reinforcement learning&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.8 – Workflow of human-centered reinforcement learning</p>
			<p><strong class="bold">Human-centered reinforcement learning</strong> is a hybrid of reinforcement learning, as <a id="_idIndexMarker112"/>it involves humans in the loop to monitor the agent's learning and provide evaluative feedback to shape the learning of the agent. Human-centered reinforcement learning <a id="_idIndexMarker113"/>is also known as <em class="italic">interactive reinforcement learning</em>. Each time the agent takes action, the observing human expert can provide evaluative feedback that describes the quality of the selected action taken by the agent based on the human expert's knowledge, as shown in <em class="italic">Figure 2.8</em>.</p>
			<p>Based on the feedback received from the task environment and human expert, the agent augments its behavior and actions. Human reinforcement learning is highly efficient in environments where the agent has to learn or mimic human behavior. To learn more, read the paper <em class="italic">Human-Centered Reinforcement Learning: A Survey</em> (<a href="https://ieeexplore.ieee.org/abstract/document/8708686">https://ieeexplore.ieee.org/abstract/document/8708686</a>).</p>
			<p><strong class="bold">Active learning</strong> is a method <a id="_idIndexMarker114"/>where the trained model can query a HITL (the human user) during the inference process to resolve incertitude during the learning process. For example, this could be a question-answering chatbot asking the human user for validation by asking yes or no questions. </p>
			<p>These are the types of ML solutions possible to build for production to solve problems in the real world. Now that you are aware of the possibilities for crafting ML solutions, as the next step, it is <a id="_idIndexMarker115"/>critical to categorize your MLOps in line with your business and technological needs. It's <a id="_idIndexMarker116"/>important for you to be able to identify the right requirements, tools, methodology, and infrastructure needed to support your business and MLOps, hence we will look into structuring MLOps in the next section.</p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor037"/>Structuring your MLOps</h1>
			<p>The primary goal of MLOps is to <a id="_idIndexMarker117"/>make an organization or set of individuals collaborate efficiently to build data and ML-driven assets to solve their business problems. As a result, overall performance and transparency are increased. Working in silos or developing functionalities repeatedly can be extremely costly and time-consuming. </p>
			<p>In this section, we will explore how MLOps can be structured within organizations. Getting the MLOps process right is of prime importance. By selecting the right process and tools for your MLOps, you and your team are all set to implement a robust, scalable, frugal, and sustainable MLOps process. For example, I recently helped one of my clients in the healthcare industry to build and optimize their MLOps, which resulted in 76% cost optimization (for storage and compute resources) compared to their previous traditional operations.</p>
			<p>The client's team of data scientists witnessed having 30% of their time freed up from mundane and repetitive daily tasks (for example, data wrangling, ML pipeline, and hyperparameter tuning) – such <a id="_idIndexMarker118"/>can be the impact of having an efficient MLOps process. By implementing efficient MLOps, your team can be assured of efficiency, high performance, and great collaboration that is repeatable and traceable within your organization.</p>
			<p>MLOps can be <a id="_idIndexMarker119"/>categorized into <strong class="bold">small data ops</strong>, <strong class="bold">big data ops</strong>, <strong class="bold">large-scale MLOps</strong>, and <strong class="bold">hybrid MLOps</strong> (this <a id="_idIndexMarker120"/>categorization is <a id="_idIndexMarker121"/>based on the <a id="_idIndexMarker122"/>author's experience <a id="_idIndexMarker123"/>and is a recommended way to approach MLOps for teams and organizations):</p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B16572_02_09.jpg" alt="Figure 2.9 – Categories of MLOps &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.9 – Categories of MLOps </p>
			<p>As shown in <em class="italic">Figure 2.9</em>, MLOps within organizations can be broadly categorized into four different categories depending on team size, and the ML applications, business models, data scale, tools, and <a id="_idIndexMarker124"/>infrastructure used to execute operations. In terms of data, many scenarios do not need big data (anything above 1 TB) operations, as simple operations can be effective for small- or medium-scale data. The differences between data scales are as follows:</p>
			<ul>
				<li><strong class="bold">Big data</strong>: A quantity <a id="_idIndexMarker125"/>of data that cannot fit in the memory of a single typical computer; for instance, &gt; 1 TB</li>
				<li><strong class="bold">Medium-scale data</strong>: A quantity of data <a id="_idIndexMarker126"/>that can fit in the memory of a single server; for instance, from 10 GB to 1 TB</li>
				<li><strong class="bold">Small-scale data</strong>: A quantity of <a id="_idIndexMarker127"/>data that easily fits in the memory of a laptop or a PC; for instance, &lt; 10 GB</li>
			</ul>
			<p>With these factors in mind, let's look into the MLOps categories to identify the suitable process and scale for implementing MLOps for your business problems or organization.</p>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor038"/>Small data ops</h2>
			<p>A small start-up with a team of data scientists seeking to build ML models for narrow and well-defined problems <a id="_idIndexMarker128"/>can be agile and highly <a id="_idIndexMarker129"/>collaborative. Usually, in such cases, ML models are trained locally on the respective data scientists' computers and then forgotten about, or scaled out and deployed on the cloud for inference. In these scenarios, there can be some general pitfalls, such as the team lacking a streamlined CI/CD approach for deploying models. However, they might manage to have central or distributed data sources that are managed carefully by the team, and the training code can be versioned and maintained in a central repository. When operations start to scale, such teams are prone to the following:</p>
			<ul>
				<li>Running into situations where much of the work is repeated by multiple people including tasks such as crafting data, ML pipelines doing the same job, or training similar types of ML models.</li>
				<li>Working in silos and having minimal understanding of the parallel work of their teammates. This leads to less transparency.</li>
				<li>Incurring huge costs, or higher costs than expected, due to the mundane and repeated work.</li>
				<li>Code and data starting to grow independently.</li>
				<li>Artifacts not being audited and hence are non-repeatable. </li>
			</ul>
			<p>Any of these can be costly and <a id="_idIndexMarker130"/>unsustainable for the team. If <a id="_idIndexMarker131"/>you are working in a team or have a setup like the following, you can categorize your operations as small data ops:</p>
			<ul>
				<li>The team consists of only data scientists.</li>
				<li>You only work with Python environments and manage everything in the Python framework. Choosing Python can be a result of having many ML libraries and tools ready to plug and play for quick prototyping and building solutions. The number of ML libraries for a language such as Java, for example, is quite a lot smaller compared to those available for Python.  </li>
				<li>Little to no big data processing is required as the data scientists use small data (&lt;10 GB). </li>
				<li>Quick ML model development starts with a local computer, then scales out to the cloud for massive computation resources.</li>
				<li>High support requirements for open source technologies such as PyTorch, TensorFlow, and scikit-learn for any type of ML, from classical learning to deep, supervised, and unsupervised learning.</li>
			</ul>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor039"/>Big data ops</h2>
			<p>This can be a team of <a id="_idIndexMarker132"/>experienced data scientists and <a id="_idIndexMarker133"/>engineers working in a start-up or an SME where they have the requirement for large-scale big data processing to perform ML training or inference. They use big data tools such as <strong class="bold">Kafka</strong>, <strong class="bold">Spark</strong>, or <strong class="bold">Hadoop</strong> to build and orchestrate their data pipelines. High-powered processors such as GPUs or TPUs are used in such scenarios to speed up data processing and ML training. The development of ML models is led by data scientists and deploying the models is orchestrated by data/software engineers. A strong focus is given to developing models and less importance is placed on monitoring the models. As they continue with their operations, this type of team is prone to the following:</p>
			<ul>
				<li>A lack of traceability for model training and monitoring</li>
				<li>A lack of reproducible artifacts</li>
				<li>Incurring huge costs, or more than expected, due to mundane and repeated work</li>
				<li>Code and data starting to grow independently</li>
			</ul>
			<p>Any of these can be costly and unsustainable for a team. </p>
			<p>If you are working in a team or have a setup as described in the following points, you can categorize your operations as big data ops: </p>
			<ul>
				<li>The team consists of data scientists/engineers.</li>
				<li>There are high requirements for big data processing capacity.</li>
				<li>Databricks is a key framework to share and collaborate inside teams and between organizations.</li>
				<li>ML model development happens in the cloud by utilizing one of many ML workflow management tools such as <strong class="bold">Spark MLlib</strong>.</li>
				<li>There are low support requirements for open source technologies such as PyTorch and TensorFlow for deep learning.</li>
			</ul>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor040"/>Hybrid MLOps</h2>
			<p>Hybrid teams operate with experienced data scientists, data engineers, and DevOps engineers, and <a id="_idIndexMarker134"/>these teams make use of ML capabilities to support their <a id="_idIndexMarker135"/>business operations. They are further ahead in implementing MLOps compared to other teams. They work with big data and open source software tools such as PyTorch, TensorFlow, and scikit-learn, and hence have a requirement for efficient collaboration. They often work on well-defined problems by implementing robust and scalable software engineering practices. However, this team is still prone to challenges such as the following:</p>
			<ul>
				<li>Incurring huge costs, or more than expected, due to mundane and repeated work to be done by data scientists, such as repeating data cleaning or feature engineering.</li>
				<li>Inefficient model monitoring and retraining mechanisms. </li>
			</ul>
			<p>Any of these can be costly and unsustainable for the team. </p>
			<p>If you are working in a team or have a setup as described in the following points, you can categorize your operations as Hybrid Ops: </p>
			<ul>
				<li>The team consists of data scientists, data engineers, and DevOps engineers.</li>
				<li>High requirement for efficient and effective collaboration.</li>
				<li>High requirement for big data processing capacity.</li>
				<li>High support requirements for open source technologies such as PyTorch, TensorFlow, and scikit-learn for any kind of ML, from classical to deep learning, and from supervised to unsupervised learning.</li>
			</ul>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor041"/>Large-scale MLOps</h2>
			<p>Large-scale operations <a id="_idIndexMarker136"/>are common in big companies <a id="_idIndexMarker137"/>with large or medium-sized engineering teams consisting of data scientists, data engineers, and DevOps engineers. They have data operations on the scale of big data, or with various types of data on various scales, veracity, and velocity. Usually, their teams have multiple legacy systems to manage to support their business operations. Such teams or organizations are prone to the following:</p>
			<ul>
				<li>Incurring huge costs, or more than expected, due to mundane and repeated work.</li>
				<li>Code and data starting to grow independently.</li>
				<li>Having bureaucratic and highly regulated processes and quality checks.</li>
				<li>Highly entangled systems and processes – when one thing breaks, everything breaks.</li>
			</ul>
			<p>Any of these can be costly and unsustainable for the team. </p>
			<p>If you are working in a team or have a setup as described in the following points, you can categorize your <a id="_idIndexMarker138"/>operations as large-scale <a id="_idIndexMarker139"/>ops: </p>
			<ul>
				<li>The team consists of data scientists, data engineers, and DevOps engineers.</li>
				<li>Large-scale inference and operations.</li>
				<li>Big data operations.</li>
				<li>ML model management on multiple resources.</li>
				<li>Big or multiple teams. </li>
				<li>Multiple use cases and models.</li>
			</ul>
			<p>Once you have characterized your MLOps as per your business and technological needs, a solid implementation roadmap ensures smooth development and implementation of a robust and scalable MLOps solution for your organization. For example, a fintech start-up processing 0-1,000 transactions a day would need small-scale data ops compared to a larger financial institution that needs large-scale MLOps. Such categorization enables a team or organization to be more efficient and robust. </p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor042"/>An implementation roadmap for your solution </h1>
			<p>Having a well-defined <a id="_idIndexMarker140"/>method and milestones ensures the successful delivery of the desired ML solution (using MLOps methods). In this section, we will discuss a generic implementation roadmap that can facilitate MLOps for any ML problem in detail. The goal of this roadmap is to <a id="_idIndexMarker141"/>solve the problem with the right solution:</p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B16572_02_10.jpg" alt="Figure 2.10 – Implementation roadmap for an MLOps-based solution &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.10 – Implementation roadmap for an MLOps-based solution </p>
			<p>Using the preceding roadmap, we can transition from ML development to MLOps with clear milestones, as shown in these three phases for MLOps implementation. Now, let's look into these three phases of the roadmap in more detail. It's worth noting that after the following section on theory, we will get into the practical implementation of the roadmap and work on a real-world business use case.  </p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor043"/>Phase 1 – ML development</h2>
			<p>This is the genesis of <a id="_idIndexMarker142"/>implementing the MLOps framework for your problem; before beginning to implement the requirements, the problem and solution must be clear and vivid. In this phase, we take into account the system requirements to design and implement a robust and scalable MLOps framework. We begin by selecting the right tools and infrastructure needed (storage, compute, and so on) to implement the MLOps. </p>
			<p>When the infrastructure is set up, we should be provisioned with the necessary workspace and the development and test environments to execute ML experiments (training and testing). We train the ML models using the development environment and test the models for performance and functionality using test data in the development or test environments, depending on the workflow or requirement. When infrastructure is set up and the first ML model is trained, tested, serialized, and packaged, phase 1 of your MLOps framework is set up and validated for robustness. Serializing and containerizing is an important process to standardize and get the models ready for deployments. </p>
			<p>Next, we move to implement phase 2. </p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor044"/>Phase 2 – Transition to operations</h2>
			<p>Phase 2 is about <a id="_idIndexMarker143"/>transitioning to operations, and it involves serializing and containerizing the models trained in phase 1 and getting them ready for deployment. This enables standardized, efficient deployments. The models are served in the form of APIs or independent artifacts for batch inference. When a model is packaged and ready to be served, it is deployed in the production environment using streamlined CI/CD pipelines upon passing quality assurance checks. By the end of phase 2, you will have packaged models served and deployed in the production environment performing inference in real time.</p>
			<h2 id="_idParaDest-42"><a id="_idTextAnchor045"/>Phase 3 – Operations</h2>
			<p>Phase 3 is the core operations phase for deployed models in phase 2. In this phase, we monitor the deployed <a id="_idIndexMarker144"/>model performance in terms of model drift, bias, or other metrics (we will delve into these terms and metrics in the coming chapters). Based on the model's performance, we can enable continual learning via periodic model retraining and enable alerts and actions. Simultaneously, we monitor logs in telemetry data for the production environment to detect any possible errors and resolve them on the go to ensure the uninterrupted working of the production system. We also manage data pipelines, the ML platform, and security on the go. With the successful implementation of this phase, we can monitor the deployed models and retrain them in a robust, scalable, and secure manner. </p>
			<p>In most cases, all three phases need to be implemented for your ML solution, but in some cases just phases 1 and 2 are enough; for instance, when the ML models make batch inferences and need not do inference in real time. By achieving these milestones and implementing all three phases, we have set up a robust and scalable ML life cycle for our applications systematically and sustainably. </p>
			<h1 id="_idParaDest-43"><a id="_idTextAnchor046"/>Procuring data, requirements, and tools</h1>
			<p>Implementing successful MLOps depends on certain factors such as procuring appropriate training data, and having high standards, and appropriate requirements, tools, and infrastructure. </p>
			<p>In this section, we will delve into these factors that make robust and scalable MLOps.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor047"/>Data</h2>
			<p>I used to believe that <a id="_idIndexMarker145"/>learning about data meant mastering tools such as Python, SQL, and regression. The tool is only as good as the person and their understanding of the context around it. The context and domain matter, from data cleaning to modeling to interpretation. The best tools in the world won't fix a bad problem definition (or lack of one). Knowing what problem to solve is a very context-driven and business-dependent decision. Once you are aware of the problem and context, it enables you to discern the right training data needed to solve the problem. </p>
			<p>Training data is a vital part of ML systems. It plays a vital role in developing ML systems compared to traditional software systems. As we have seen in the previous chapter, both code and <a id="_idIndexMarker146"/>training data work in parallel to develop and maintain an ML system. It is not only about the algorithm but also about the data. There are two aspects to ensure you have the right data for algorithm training, which are to provide both the right quantity and quality of data:</p>
			<ul>
				<li><strong class="bold">Data quantity</strong>: Data scientists echo a common argument about their models, arguing that model performance is not good because the quantity of data they were given was not sufficient to produce good model performance. If they had more data, the performance would have been better – are you familiar with such arguments? In most cases, more data might not really help, as quality also is an important factor. For instance, your models can learn more insights and characteristics from your data if you have more samples for each class. For example, if you analyze anomalous financial transactions with many samples in your data, you will discover more types of anomalous transactions. If there is only one anomalous case, then ML is not useful. <p>The data requirements for ML projects should not solely focus on data quantity itself, but also on the quality, which means the focus should not be on the number of data samples but rather on the diversity of data samples. However, in some cases, there are constraints on the quantity of data available to tackle some problems. For example, let's suppose we work on models to predict the churn rate for an insurance company. In that case, we can be restricted to considering data from a limited period or using a limited number of samples due to the availability of data for a certain time period; for example, 5 years (whereas the insurance company might have operated for the last 50 years). The goal is to acquire data of the maximum possible quantity and quality to train the best-performing ML models.</p></li>
				<li><strong class="bold">Data quality</strong>: Data quality is an important factor for training ML models; it impacts model performance. The more comprehensive or higher the quality of the data, the better the ML model or application will work. Hence the process before the training is important: cleaning, augmenting, and scaling the data. There are some important dimensions of data quality to consider, such as consistency, correctness, and completeness. <p>Data consistency refers to the correspondence and coherence of the data samples throughout the dataset. Data correctness is the degree of accuracy and the degree to which you can rely on the data to truly reflect events. Data correctness is <a id="_idIndexMarker147"/>dependent on how the data was collected. The sparsity of data for each characteristic (for example, whether the data covers a comprehensive range of possible values to reflect an event) reflects data completeness.</p><p>With an appropriate quantity of good-quality data, you can be sure that your ML models and applications will perform above the required standards. Hence, having the right standards is vital for the application to perform and solve business problems in the most efficient ways. </p></li>
			</ul>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor048"/>Requirements</h2>
			<p>The <a id="_idIndexMarker148"/>product or business/tech problem owner plays a key role in facilitating the building of a robust ML system efficiently by identifying requirements and tailoring them with regard to the scope of data, collection of data, and required data formats. These requirements are vital inputs for developers of ML systems, such as data scientists or ML engineers, to start architecting the solution to address the problem by analyzing and correlating the given dataset based on the requirements. ML solution requirements should consist of comprehensive data requirements. Data requirement specifications consist of information about the quality and quantity of the data. The requirements can be more extensive; for example, they can contain estimations about anticipated or expected predictive performance expressed in terms of the performance metrics determined during requirements analysis and elicitation.</p>
			<p>Meticulous specifications can be made, such as the specification of expected or anticipated performance on the training data, as these can be rapidly validated after the model training process. Whereas, based on the training performance, inference or runtime (including in production and operations) performance can be assessed during operations. The requirements made by the product owner or business owner should consider important factors such as ethical and explainability factors. Discrimination or bias (such as who or what is predicted or classified) is critical for the application and which properties should be preserved as part of data privacy (for example, some properties should not be used for predictions or classification, such as race, age, or gender). Explainability requirements must <a id="_idIndexMarker149"/>explicitly be taken into account to explain situations and decisions of the ML solution or system to the users of the system. Lastly, the requirements must stipulate regulations and restrictions concerning the use of the data and validation of decisions made by the ML system. The following table shows some requirements to consider to ensure that you build a robust and scalable ML solution:</p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B16572_02_11.jpg" alt="Figure 2.11 – Requirements mapping for ML solutions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 2.11 – Requirements mapping for ML solutions</p>
			<p>The table in <em class="italic">Figure 2.11</em> illustrates the flow of the requirements characterization process, from elicitation to analysis to specifications to verification and validation of the system. This process ensures best-fit resources are procured to build and deploy an efficient ML system to solve your problem. When the requirements are well defined, selecting the right tools and infrastructure that support the established process and ensure the standards are met is crucial. </p>
			<h1 id="_idParaDest-46"><a id="_idTextAnchor049"/>Tools and infrastructure</h1>
			<p>The MLOps landscape has been developing rapidly over the last two years; many tools and frameworks have <a id="_idIndexMarker150"/>evolved as part of the infrastructural offering. You can visit <a href="https://landscape.lfai.foundation/">https://landscape.lfai.foundation/</a> to see how many mainstream options have been developed to <a id="_idIndexMarker151"/>orchestrate ML, deep learning, reinforcement learning, development environments, data pipelines, model management, explainable AI, security, and distributed computing.</p>
			<p>There is a surge in services provided by popular cloud service providers such as Microsoft, AWS, and Google, which are complemented by data processing tools such as Airflow, Databricks, and Data Lake. These are crafted to enable ML and deep learning, for which there are great frameworks available such as scikit-learn, Spark MLlib, PyTorch, TensorFlow, MXNet, and CNTK, among others. Tools and frameworks are many, but procuring the right tools is a matter of choice and the context of your ML solution and operations setup. Having the right tools will ensure high efficiency and automation for your MLOps workflow. The options are many, the sky's the limit, but we have to start from somewhere to reach the sky. For this reason, we will look to give you some hands-on experience from here onward. It is always better to learn from real-life problems, and we will do so by using the real-life business problem described in the next section. </p>
			<h1 id="_idParaDest-47"><a id="_idTextAnchor050"/>Discussing a real-life business problem</h1>
			<p>We will be implementing the <a id="_idIndexMarker152"/>following business problem to get hands-on experience. I recommend you read this section multiple times to get a good understanding of the business problem; it makes it easier to implement it.  </p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Problem context:</p>
			<p class="callout">You work as a data scientist in a small team with three other data scientists for a cargo shipping company based in the port of Turku in Finland. 90% of the goods imported into Finland come via cargo ships at the ports across the country. For cargo shipping, weather conditions and logistics can be challenging at times at the ports. Rainy conditions can distort operations and logistics at the ports, which can affect the supply chain operations. Forecasting rainy conditions in advance gives the possibility to optimize resources such as human resources, logistics, and transport resources for efficient supply chain operations at ports. Business-wise, forecasting rainy conditions in advance enables ports to reduce operational costs by up to ~20% by enabling efficient planning and scheduling of human resources, logistics, and transport resources for supply chain operations.</p>
			<p class="callout">Task:</p>
			<p class="callout">You as a data scientist are tasked with developing an ML-driven solution to forecast weather conditions 4 hours in advance at the port of Turku in Finland. That will enable the port to optimize its resources, thereby enabling cost-savings of up to 20%. To get started, you are provided with a historic weather dataset covering a timeline of 10 years from the port of Turku (the dataset can be accessed in the next chapter). Your task is to build a continuous-learning-driven ML solution to optimize operations at the port of Turku.</p>
			<p>To solve this problem, we will use <a id="_idIndexMarker153"/>Microsoft Azure, one of the most widely used cloud services, and MLflow, an open source ML development tool, to get hands-on with using resources. This way, we will get experience working on the cloud and with open source software. Before starting the hands-on implementation in the next chapter, please make sure to do the following:</p>
			<ol>
				<li>Create a free Azure subscription from <a href="https://azure.microsoft.com/">https://azure.microsoft.com/</a> (takes 5 minutes).</li>
				<li>Create an Azure Machine Learning service application with the name <strong class="source-inline">MLOps_WS</strong>. This can be done from your Azure portal by clicking <strong class="bold">Create a resource</strong>. Then type <strong class="source-inline">Machine Learning</strong> into the search field and select the <strong class="bold">Machine Learning</strong> option. Then, follow the detailed instructions in the next chapter (<a href="B16572_03_Final_JM_ePub.xhtml#_idTextAnchor053"><em class="italic">Chapter 3</em></a><em class="italic">, Code Meets Data</em>) to create the Azure Machine Learning service resource with the name <strong class="source-inline">MLOps_WS</strong>. </li>
			</ol>
			<p>Now, with this, you are all set to get hands-on with implementing an MLOps framework for the preceding business problem. </p>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor051"/>Summary</h1>
			<p>In this chapter, we have learned about the ML solution development process, how to identify a suitable ML solution to a problem, and how to categorize operations to implement suitable MLOps. We got a glimpse into a generic implementation roadmap and saw some tips for procuring essentials such as tools, data, and infrastructure to implement your ML application. Lastly, we went through the business problem to be solved in the next chapter by implementing an MLOps workflow (discussed in <a href="B16572_01_Final_JM_ePub.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, <em class="italic">Fundamentals of MLOps Workflow</em>) in which we'll get some hands-on experience in MLOps. </p>
			<p>In the next chapter, we will go from theory to practical implementation. The chapter gets hands-on when we start with setting up MLOps tools on Azure and start coding to clean the <a id="_idTextAnchor052"/>data to address the business problem and get plenty of hands-on experience.</p>
		</div>
	</body></html>