<html><head></head><body>
<div id="_idContainer132">
<h1 class="chapter-number" id="_idParaDest-209"><a id="_idTextAnchor342"/><span class="koboSpan" id="kobo.1.1">13</span></h1>
<h1 id="_idParaDest-210"><a id="_idTextAnchor343"/><span class="koboSpan" id="kobo.2.1">Advanced Deep Learning Techniques</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In the previous chapter, we reviewed the concept of neural network modeling and deep learning while focusing on fully connected neural networks. </span><span class="koboSpan" id="kobo.3.2">In this chapter, we will discuss more advanced techniques that let you use deep learning models across different data types and structures, such as images, texts, and graphs. </span><span class="koboSpan" id="kobo.3.3">These techniques are behind the majority of advancements across industries through artificial intelligence, such as in chatbots, medical diagnosis, drug discovery, stock trading, and fraud detection. </span><span class="koboSpan" id="kobo.3.4">Although we will present some of the most famous deep learning models across different data types, this chapter aims to help you understand the concepts and practice with PyTorch, and not provide you with state-of-the-art models for each data type or </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">subject domain.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">In this chapter, we will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.7.1">Types of </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">neural networks</span></span></li>
<li><span class="koboSpan" id="kobo.9.1">Convolutional neural networks for image </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">shape data</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">Transformers for </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">language modeling</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Modeling graphs using deep </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">neural networks</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.15.1">By the end of this chapter, you will have learned about </span><strong class="bold"><span class="koboSpan" id="kobo.16.1">convolutional neural networks</span></strong><span class="koboSpan" id="kobo.17.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.18.1">CNNs</span></strong><span class="koboSpan" id="kobo.19.1">), transformers, and graph neural networks as the three important categories of deep learning modeling to develop high-performance models in your problems of interest. </span><span class="koboSpan" id="kobo.19.2">You will have also learned how to develop such models using PyTorch </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">and Python.</span></span></p>
<h1 id="_idParaDest-211"><a id="_idTextAnchor344"/><span class="koboSpan" id="kobo.21.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.22.1">The following requirements should be considered for this chapter as they will help you better understand the concepts, use them in your projects, and practice with the </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">provided code:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.24.1">Python </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">library requirements:</span></span><ul><li><strong class="source-inline"><span class="koboSpan" id="kobo.26.1">torch</span></strong><span class="koboSpan" id="kobo.27.1"> &gt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">2.0.0</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.29.1">torchvision</span></strong><span class="koboSpan" id="kobo.30.1"> &gt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">0.15.1</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.32.1">transformers</span></strong><span class="koboSpan" id="kobo.33.1"> &gt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">4.28.0</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.35.1">datasets</span></strong><span class="koboSpan" id="kobo.36.1"> &gt;= </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">2.12.0</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.38.1">torch_geometric</span></strong><span class="koboSpan" id="kobo.39.1"> == </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">2.3.1</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.41.1">You will require basic knowledge of </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">the following:</span></span><ul><li><span class="koboSpan" id="kobo.43.1">Deep learning modeling and fully connected </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">neural networks</span></span></li><li><span class="koboSpan" id="kobo.45.1">How to use PyTorch for deep </span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">learning modeling</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.47.1">You can find the code files for this chapter on GitHub </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">at </span></span><a href="https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter13"><span class="No-Break"><span class="koboSpan" id="kobo.49.1">https://github.com/PacktPublishing/Debugging-Machine-Learning-Models-with-Python/tree/main/Chapter13</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.50.1">.</span></span></p>
<h1 id="_idParaDest-212"><a id="_idTextAnchor345"/><span class="koboSpan" id="kobo.51.1">Types of neural networks</span></h1>
<p><span class="koboSpan" id="kobo.52.1">The examples we have provided so far in this book have focused on tabular data either in machine learning or in</span><a id="_idIndexMarker685"/><span class="koboSpan" id="kobo.53.1"> deep learning modeling, as one category of machine learning modeling. </span><span class="koboSpan" id="kobo.53.2">However, machine learning, and especially deep learning, has been successful in tackling problems that deal with non-tabular, or unstructured, texts, images, and graphs. </span><span class="koboSpan" id="kobo.53.3">First, we’ll introduce different problems that involve such data types in this section; then, we’ll review deep learning techniques that can help you build reliable models </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">for them.</span></span><a id="_idTextAnchor346"/></p>
<h2 id="_idParaDest-213"><a id="_idTextAnchor347"/><span class="koboSpan" id="kobo.55.1">Categorization based on data type</span></h2>
<p><span class="koboSpan" id="kobo.56.1">Structured data, which is also referred to as tabular data, is data </span><a id="_idIndexMarker686"/><span class="koboSpan" id="kobo.57.1">that can be organized into spreadsheets and structured databases. </span><span class="koboSpan" id="kobo.57.2">As we have used this data type in this book, we usually have different</span><a id="_idIndexMarker687"/><span class="koboSpan" id="kobo.58.1"> features and even output in the columns of a table, matrix, or DataFrame. </span><span class="koboSpan" id="kobo.58.2">The rows of a DataFrame represent different data points in the dataset. </span><span class="koboSpan" id="kobo.58.3">However, we have other types of data that are not structured, and reformatting them into a DataFrame or matrix results in a loss of information. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.59.1">Figure 13</span></em></span><em class="italic"><span class="koboSpan" id="kobo.60.1">.1</span></em><span class="koboSpan" id="kobo.61.1"> shows the three most important types of unstructured data – that is, sequence data such as text, image shape data such as family photos, and graphs such as </span><span class="No-Break"><span class="koboSpan" id="kobo.62.1">social networks:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer122">
<span class="koboSpan" id="kobo.63.1"><img alt="Figure 13.1 – Different data types that can be modeled using deep learning" src="image/B16369_13_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.64.1">Figure 13.1 – Different data types that can be modeled using deep learning</span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.65.1">Table 13.1</span></em><span class="koboSpan" id="kobo.66.1"> provides some examples of problems and how their corresponding data fits within each category mentioned in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.67.1">Figure 13</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.68.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">:</span></span></p>
<table class="No-Table-Style" id="table001-10">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.70.1">Data Type</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.71.1">Examples</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.72.1">Sequence data</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.73.1">Text</span></span></p>
<p><span class="koboSpan" id="kobo.74.1">Time-series data such as </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">stock prices</span></span></p>
<p><span class="koboSpan" id="kobo.76.1">Audio data as a sequence of </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">sound waves</span></span></p>
<p><span class="koboSpan" id="kobo.78.1">Geolocation data as a sequence of </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1">object movement</span></span></p>
<p><span class="koboSpan" id="kobo.80.1">EEG data as a sequence of electrical activity of </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">the brain</span></span></p>
<p><span class="koboSpan" id="kobo.82.1">ECG data as a sequence of electrical activity of </span><span class="No-Break"><span class="koboSpan" id="kobo.83.1">the heart</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.84.1">Image </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">shape data</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.86.1">Photographs</span></span></p>
<p><span class="koboSpan" id="kobo.87.1">Security and </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">surveillance images</span></span></p>
<p><span class="koboSpan" id="kobo.89.1">Medical images such as X-rays or </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">CT scans</span></span></p>
<p><span class="koboSpan" id="kobo.91.1">Visual arts and images of drawings </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">and paintings</span></span></p>
<p><span class="koboSpan" id="kobo.93.1">Images captured by satellites, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">weather patterns</span></span></p>
<p><span class="koboSpan" id="kobo.95.1">Images captured using microscopes, such as images </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">of cells</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.97.1">Graphs</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.98.1">Road networks</span></span></p>
<p><span class="koboSpan" id="kobo.99.1">Web graphs – connections between </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">web pages</span></span></p>
<p><span class="koboSpan" id="kobo.101.1">Knowledge graphs – relationships </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">between concepts</span></span></p>
<p><span class="koboSpan" id="kobo.103.1">Social networks – connections between individuals </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">and groups</span></span></p>
<p><span class="koboSpan" id="kobo.105.1">Biological networks – connections between genes or other </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">biological entities</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.107.1">Table 13.1 – Examples of problems for each data type</span></p>
<p><span class="koboSpan" id="kobo.108.1">Some of the challenges and </span><a id="_idIndexMarker688"/><span class="koboSpan" id="kobo.109.1">issues with reformatting different data types into tabular data are </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">as follows:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.111.1">Reformatting sequence data into a table shape data object results in a loss of information regarding the order of data, such </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">as words</span></span></li>
<li><span class="koboSpan" id="kobo.113.1">Reformatting images into tabular format results in a loss of local patterns, such as the relationship between pixels of </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">two-dimensional images</span></span></li>
<li><span class="koboSpan" id="kobo.115.1">Reformatting graphs into tabular data will eliminate dependency between data points </span><span class="No-Break"><span class="koboSpan" id="kobo.116.1">or features</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.117.1">Now that we understand the importance of not reformatting all datasets and data types into tabular data, we can start working with different deep learning techniques to understand how we can</span><a id="_idIndexMarker689"/><span class="koboSpan" id="kobo.118.1"> build successful models for non-tabular data. </span><span class="koboSpan" id="kobo.118.2">We will start by looking at image </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">shape data</span><a id="_idTextAnchor348"/><span class="koboSpan" id="kobo.120.1">.</span></span></p>
<h1 id="_idParaDest-214"><a id="_idTextAnchor349"/><span class="koboSpan" id="kobo.121.1">Convolutional neural networks for image shape data</span></h1>
<p><span class="koboSpan" id="kobo.122.1">CNNs allow us to build </span><a id="_idIndexMarker690"/><span class="koboSpan" id="kobo.123.1">deep learning models on image data without the need to reformat images into a tabular format. </span><span class="koboSpan" id="kobo.123.2">The name of this category of deep learning techniques comes from the concept of convolution, which in deep learning refers to applying a filter to image shape data to produce a secondary image shape feature map (shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.124.1">Figure 13</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.125.1">.2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.126.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer123">
<span class="koboSpan" id="kobo.127.1"><img alt="Figure 13.2 – A simple example of applying a predefined convolution filter to a 3x3 image shape data point" src="image/B16369_13_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.128.1">Figure 13.2 – A simple example of applying a predefined convolution filter to a 3x3 image shape data point</span></p>
<p><span class="koboSpan" id="kobo.129.1">When training a deep learning model, for example using PyTorch, a convolution filter or other filters that we will introduce later in this chapter will not be predefined but rather learned through the learning process. </span><span class="koboSpan" id="kobo.129.2">Convolution and other filters and processes in CNN modeling let us use the methods under this category of deep learning techniques for different image shape data (as we saw in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.130.1">Figure 13</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.131.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.132.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.133.1">The application of </span><a id="_idIndexMarker691"/><span class="koboSpan" id="kobo.134.1">CNNs is beyond supervised learning for image classification, for which it might be most famous. </span><span class="koboSpan" id="kobo.134.2">CNNs have been used</span><a id="_idIndexMarker692"/><span class="koboSpan" id="kobo.135.1"> for different</span><a id="_idIndexMarker693"/><span class="koboSpan" id="kobo.136.1"> problems, including </span><strong class="bold"><span class="koboSpan" id="kobo.137.1">image segmentation</span></strong><span class="koboSpan" id="kobo.138.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.139.1">resolution enhancements</span></strong><span class="koboSpan" id="kobo.140.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.141.1">object detection</span></strong><span class="koboSpan" id="kobo.142.1">, and </span><a id="_idIndexMarker694"/><span class="koboSpan" id="kobo.143.1">more (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.144.1">Figure 13</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.145.1">.3</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer124">
<span class="koboSpan" id="kobo.147.1"><img alt="Figure 13.3 – Some of the successful applications of convolutional neural networks" src="image/B16369_13_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.148.1">Figure 13.3 – Some of the successful applications of convolutional neural networks</span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.149.1">Table 13.2</span></em><span class="koboSpan" id="kobo.150.1"> provides a list of high-performance models in different applications of CNNs that you can use in your projects or learn from to build even </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">better models:</span></span></p>
<table class="No-Table-Style" id="table002-6">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.152.1">Problem</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.153.1">Some of the Widely Used Models and </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.154.1">Related Techniques</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.155.1">Image classification</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.156.1">ResNet (He et al., 2016); EfficientNets (Tan and Le, 2019); MobileNets (Howard et al., 2017; Sandler et al., 2018); Xception (</span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">Chollet, 2017)</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.158.1">Image segmentation</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.159.1">U-Net (Ronneberger et al., 2015); Mask R-CNN (He et al., 2017); DeepLab (Chen et al., 2017); PSPNet (Chao et </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">al., 2017)</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.161.1">Object detection</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.162.1">Mask R-CNN (He et al., 2017); Faster R-CNN (Ren et al., 2015); YOLO (Redmon et </span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">al., 2016)</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.164.1">Image super-resolution</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.165.1">SRCNN (Dong et el., 2015); FSRCNN (Dong et al., 2016); EDSR (Lim et </span><span class="No-Break"><span class="koboSpan" id="kobo.166.1">al., 2017)</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.167.1">Image-to-image </span><span class="No-Break"><span class="koboSpan" id="kobo.168.1">translation</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.169.1">Pix2Pix (Isola et al., 2017); CycleGAN (Zhu et </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">al., 2017)</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.171.1">Style transfer</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.172.1">Neural Algorithm of Artistic Style (Gatys et al., 2016); AdaIN-Style (Huang et </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">al., 2017)</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.174.1">Anomaly detection</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.175.1">AnoGAN (Schlegl et al., 2017); RDA (Zhou et al., 2017); Deep SVDD (Ruff et </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">al., 2018)</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.177.1">Optical character </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">recognition</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.179.1">EAST (Zhou et al., 2017); CRAFT (Bake et </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">al., 2019)</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.181.1">Table 13.2 – High-performance CNN models across different problems</span></p>
<p><span class="koboSpan" id="kobo.182.1">You can train CNN </span><a id="_idIndexMarker695"/><span class="koboSpan" id="kobo.183.1">models on two-dimensional or three-dimensional image shape data. </span><span class="koboSpan" id="kobo.183.2">You can also build models that work on sequences of such data points, such as videos, as sequences of images. </span><span class="koboSpan" id="kobo.183.3">Some of the most famous models or approaches in terms of using CNNs on videos that you can play with are C3D (Tran et al., 2015), I3D (Carreira and Zisserman, 2017), and SlowFast (Feichtenhofer et </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">al., 2019).</span></span></p>
<p><span class="koboSpan" id="kobo.185.1">Next, we will learn about </span><a id="_idIndexMarker696"/><span class="koboSpan" id="kobo.186.1">some of the ways we can assess the performance of </span><span class="No-Break"><span class="koboSpan" id="kobo.187.1">CNN models</span><a id="_idTextAnchor350"/><span class="koboSpan" id="kobo.188.1">.</span></span></p>
<h2 id="_idParaDest-215"><a id="_idTextAnchor351"/><span class="koboSpan" id="kobo.189.1">Performance assessment</span></h2>
<p><span class="koboSpan" id="kobo.190.1">You can use the performance measures presented in </span><a href="B16369_04.xhtml#_idTextAnchor159"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.191.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.192.1">, </span><em class="italic"><span class="koboSpan" id="kobo.193.1">Detecting Performance and Efficiency Issues in Machine Learning Models</span></em><span class="koboSpan" id="kobo.194.1">, such as ROC-AUC, PR-AUC, precision, and recall, for CNN classification models. </span><span class="koboSpan" id="kobo.194.2">However, there are other measures more specific to some of the</span><a id="_idIndexMarker697"/><span class="koboSpan" id="kobo.195.1"> problems presented in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.196.1">Figure 13</span></em></span><em class="italic"><span class="koboSpan" id="kobo.197.1">.3</span></em><span class="koboSpan" id="kobo.198.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">as follows:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.200.1">Pixel accuracy</span></strong><span class="koboSpan" id="kobo.201.1">: This measure is defined as the ratio of correctly classified pixels to the total number of pixels. </span><span class="koboSpan" id="kobo.201.2">This measure works like accuracy and can be misleading when there is a class imbalance in </span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">the pixels.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.203.1">Jaccard index</span></strong><span class="koboSpan" id="kobo.204.1">: The Jaccard index is defined </span><a id="_idIndexMarker698"/><span class="koboSpan" id="kobo.205.1">as the intersection over the union and can be used to calculate the overlap between the predicted segmentation and the ground truth normalized by </span><span class="No-Break"><span class="koboSpan" id="kobo.206.1">their uni</span><a id="_idTextAnchor352"/><span class="koboSpan" id="kobo.207.1">on.</span></span></li>
</ul>
<h2 id="_idParaDest-216"><a id="_idTextAnchor353"/><span class="koboSpan" id="kobo.208.1">CNN modeling using PyTorch</span></h2>
<p><span class="koboSpan" id="kobo.209.1">The process of CNN modeling in PyTorch is very similar to building fully connected neural networks, as we </span><a id="_idIndexMarker699"/><span class="koboSpan" id="kobo.210.1">covered in the previous chapter. </span><span class="koboSpan" id="kobo.210.2">It starts with specifying the architecture of the network, then initializing the</span><a id="_idIndexMarker700"/><span class="koboSpan" id="kobo.211.1"> optimizer, and finally going through different epochs and batches to learn from training data points. </span><span class="koboSpan" id="kobo.211.2">Here, we want to </span><a id="_idIndexMarker701"/><span class="koboSpan" id="kobo.212.1">practice CNN modeling in PyTorch using the </span><strong class="bold"><span class="koboSpan" id="kobo.213.1">German Traffic Sign Recognition Benchmark</span></strong><span class="koboSpan" id="kobo.214.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.215.1">GTSRB</span></strong><span class="koboSpan" id="kobo.216.1">) dataset from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.217.1">torchvision</span></strong><span class="koboSpan" id="kobo.218.1"> library. </span><span class="koboSpan" id="kobo.218.2">Examples of the images in this dataset are shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.219.1">Figure </span><a id="_idTextAnchor354"/><span class="koboSpan" id="kobo.220.1">13</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.221.1">.4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.222.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer125">
<span class="koboSpan" id="kobo.223.1"><img alt="Figure 13.4 – Examples of images in the German Traffic Sign Recognition Benchmark (GTSRB) dataset from torchvision" src="image/B16369_13_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.224.1">Figure 13.4 – Examples of images in the German Traffic Sign Recognition Benchmark (GTSRB) dataset from torchvision</span></p>
<p><span class="koboSpan" id="kobo.225.1">There are other filters and layers</span><a id="_idIndexMarker702"/><span class="koboSpan" id="kobo.226.1"> besides the convolution filter (</span><strong class="source-inline"><span class="koboSpan" id="kobo.227.1">torch.nn.Conv2d</span></strong><span class="koboSpan" id="kobo.228.1">) available in </span><strong class="source-inline"><span class="koboSpan" id="kobo.229.1">torch.nn</span></strong><span class="koboSpan" id="kobo.230.1"> that you can use to train high-performance CNN models. </span><span class="koboSpan" id="kobo.230.2">One of those filters that is widely used besides </span><strong class="source-inline"><span class="koboSpan" id="kobo.231.1">torch.nn.Conv2d</span></strong><span class="koboSpan" id="kobo.232.1"> is </span><strong class="source-inline"><span class="koboSpan" id="kobo.233.1">torch.nn.MaxPool2d</span></strong><span class="koboSpan" id="kobo.234.1">, which can be used as </span><a id="_idIndexMarker703"/><span class="koboSpan" id="kobo.235.1">a pooling layer in CNN modeling (LeCun et al., 1989). </span><span class="koboSpan" id="kobo.235.2">You can read about the required arguments for these two filters on the PyTorch </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">website (</span></span><a href="https://pytorch.org/docs/stable/nn.html"><span class="No-Break"><span class="koboSpan" id="kobo.237.1">https://pytorch.org/docs/stable/nn.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.238.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.239.1">Let’s start practicing CNN modeling using the GTSRB dataset. </span><span class="koboSpan" id="kobo.239.2">First, we must load the data  for model training and testing, and then specify the number of classes in the </span><span class="No-Break"><span class="koboSpan" id="kobo.240.1">classification model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.241.1">
transform = transforms.Compose([    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.3337, 0.3064, 0.3171),
        ( 0.2672, 0.2564, 0.2629))
])
batch_size = 6
n_class = 43
# Loading train and test sets of
# German Traffic Sign Recognition Benchmark (GTSRB) Dataset.
</span><span class="koboSpan" id="kobo.241.2">trainset = torchvision.datasets.GTSRB(
    root='../../data',split = 'train',
    download=True,transform=transform)
trainloader = torch.utils.data.DataLoader(trainset,
    batch_size=batch_size,shuffle=True, num_workers=2)
testset = torchvision.datasets.GTSRB(
    root='../../data',split = 'test',
    download=True,transform=transform)
testloader = torch.utils.data.DataLoader(testset,
    batch_size=batch_size,shuffle=False,num_workers=2)</span></pre>
<p><span class="koboSpan" id="kobo.242.1">Then, we must define a </span><a id="_idIndexMarker704"/><span class="koboSpan" id="kobo.243.1">neural network class, called </span><strong class="source-inline"><span class="koboSpan" id="kobo.244.1">Net</span></strong><span class="koboSpan" id="kobo.245.1">, which determines the architecture of the network, including two layers of </span><a id="_idIndexMarker705"/><span class="koboSpan" id="kobo.246.1">convolutional plus pooling filters, followed by ReLU activation functions, and then three layers of fully connected neural networks with ReLU </span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">activation functions:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.248.1">
import torch.nn as nnimport torch.nn.functional as F
class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, n_class)
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x</span></pre>
<p><span class="koboSpan" id="kobo.249.1">Then, we must initialize the</span><a id="_idIndexMarker706"/><span class="koboSpan" id="kobo.250.1"> network and optimizer, </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.252.1">
import torch.optim as optimnet = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001,
    momentum=0.9)</span></pre>
<p><span class="koboSpan" id="kobo.253.1">Now, we are ready to train </span><a id="_idIndexMarker707"/><span class="koboSpan" id="kobo.254.1">the network using the initialized architecture and the optimizer. </span><span class="koboSpan" id="kobo.254.2">Here, we will use three epochs to train the network. </span><span class="koboSpan" id="kobo.254.3">The batch sizes don’t need to be specified here as they were determined when the data was loaded from </span><strong class="source-inline"><span class="koboSpan" id="kobo.255.1">torchvision</span></strong><span class="koboSpan" id="kobo.256.1">, which was specified as </span><strong class="source-inline"><span class="koboSpan" id="kobo.257.1">6</span></strong><span class="koboSpan" id="kobo.258.1"> in this case (this can be found in this book’s </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">GitHub repository):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.260.1">
n_epoch = 3for epoch in range(n_epoch):
    # running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the input data
        inputs, labels = data
        # zero the parameter gradients
        optimizer.zero_grad()
        # output identification
        outputs = net(inputs)
        # loss calculation and backward propagation for parameter update
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()</span></pre>
<p><span class="koboSpan" id="kobo.261.1">The final calculated loss after 3 epochs </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">is 0.00008.</span></span></p>
<p><span class="koboSpan" id="kobo.263.1">This was a simple example of </span><a id="_idIndexMarker708"/><span class="koboSpan" id="kobo.264.1">using PyTorch for CNN modeling. </span><span class="koboSpan" id="kobo.264.2">There are other functionalities in PyTorch</span><a id="_idIndexMarker709"/><span class="koboSpan" id="kobo.265.1"> that you can benefit from while building CNN models, such as data augmentation. </span><span class="koboSpan" id="kobo.265.2">We will discu</span><a id="_idTextAnchor355"/><span class="koboSpan" id="kobo.266.1">ss </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">this next.</span></span></p>
<h2 id="_idParaDest-217"><a id="_idTextAnchor356"/><span class="koboSpan" id="kobo.268.1">Image data transformation and augmentation for CNNs</span></h2>
<p><span class="koboSpan" id="kobo.269.1">As part of the pre-training stages of a machine learning life cycle, you might need to transform your images, such</span><a id="_idIndexMarker710"/><span class="koboSpan" id="kobo.270.1"> as by cropping them, or</span><a id="_idIndexMarker711"/><span class="koboSpan" id="kobo.271.1"> implement data augmentation as a series of techniques for synthetic data generation to improve the performance of your models, as explained in </span><a href="B16369_05.xhtml#_idTextAnchor183"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.272.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.273.1">, </span><em class="italic"><span class="koboSpan" id="kobo.274.1">Improving the Performance of Machine Learning Models</span></em><span class="koboSpan" id="kobo.275.1">. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.276.1">Figure 13</span></em></span><em class="italic"><span class="koboSpan" id="kobo.277.1">.5</span></em><span class="koboSpan" id="kobo.278.1"> shows some simple examples of data augmentation, including rotation and scaling, that help you in generating synthetic but highly relevant data points to help </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">your models:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer126">
<span class="koboSpan" id="kobo.280.1"><img alt="Figure 13.5 – Examples of rule-based data augmentation – (A) original image﻿,﻿ (B) rotated image﻿, and﻿ (C) scaled image" src="image/B16369_13_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.281.1">Figure 13.5 – Examples of rule-based data augmentation – (A) original image, (B) rotated image, and (C) scaled image</span></p>
<p><span class="koboSpan" id="kobo.282.1">Although there are </span><a id="_idIndexMarker712"/><span class="koboSpan" id="kobo.283.1">simple examples </span><a id="_idIndexMarker713"/><span class="koboSpan" id="kobo.284.1">of rules for data augmentation that you can implement in Python, there are many classes in PyTorch that you can use for both data transformation and augmentation, as explained </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">at </span></span><a href="https://pytorch.org/vision/stable/transforms.html"><span class="No-Break"><span class="koboSpan" id="kobo.286.1">https://pytorch.org/vision/stable/</span><span id="_idTextAnchor357"/><span class="koboSpan" id="kobo.287.1">transforms.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.288.1">.</span></span></p>
<h2 id="_idParaDest-218"><a id="_idTextAnchor358"/><span class="koboSpan" id="kobo.289.1">Using pre-trained models</span></h2>
<p><span class="koboSpan" id="kobo.290.1">In a deep learning setting, often, we rely </span><a id="_idIndexMarker714"/><span class="koboSpan" id="kobo.291.1">on pre-trained models either for inference or to further fine-tune for a specific problem we have at hand. </span><span class="koboSpan" id="kobo.291.2">CNNs are not an exception and you can find many pre-trained models in PyTorch for image classification or other applications of CNNs (</span><a href="https://pytorch.org/vision/stable/models.html"><span class="koboSpan" id="kobo.292.1">https://pytorch.org/vision/stable/models.html</span></a><span class="koboSpan" id="kobo.293.1">). </span><span class="koboSpan" id="kobo.293.2">You can also find code examples at the same URL on how to use these models. </span><span class="koboSpan" id="kobo.293.3">You can find the necessary code to teach you how to fine-tune these models using new data </span><span class="No-Break"><span class="koboSpan" id="kobo.294.1">at </span></span><a href="https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"><span class="No-Break"><span class="koboSpan" id="kobo.295.1">https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.296.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.297.1">Although we’ve focused on applying CNNs to image data so far, they can be used to model any image shape data. </span><span class="koboSpan" id="kobo.297.2">For example, audio data can be transformed from the time domain into the frequency domain, resulting in image shape data that can be modeled using CNNs in combination with sequence modeling algorithms, as introduced later in this </span><span class="No-Break"><span class="koboSpan" id="kobo.298.1">chapter (</span></span><a href="https://pytorch.org/audio/main/models.html"><span class="No-Break"><span class="koboSpan" id="kobo.299.1">https://pytorch.org/audio/main/models.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.300.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.301.1">In addition to images and</span><a id="_idIndexMarker715"/><span class="koboSpan" id="kobo.302.1"> image shape data, deep learning models and algorithms have been developed to properly model sequence data in a variety of applications, such as in </span><strong class="bold"><span class="koboSpan" id="kobo.303.1">natural language processing</span></strong><span class="koboSpan" id="kobo.304.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.305.1">NLP</span></strong><span class="koboSpan" id="kobo.306.1">), which we</span><a id="_idIndexMarker716"/><span class="koboSpan" id="kobo.307.1"> will refer to as language modeling here for simplicity. </span><span class="koboSpan" id="kobo.307.2">In the next section, we will review transformers for language modeling to help you start benefiting from such models if you have a relevant idea </span><a id="_idTextAnchor359"/><span class="koboSpan" id="kobo.308.1">or project </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">at hand.</span></span></p>
<h1 id="_idParaDest-219"><a id="_idTextAnchor360"/><span class="koboSpan" id="kobo.310.1">Transformers for language modeling</span></h1>
<p><span class="koboSpan" id="kobo.311.1">Transformers were introduced in a famous paper called </span><em class="italic"><span class="koboSpan" id="kobo.312.1">Attention is All You Need</span></em><span class="koboSpan" id="kobo.313.1"> (Vaswani et al., 2017) as a new approach for sequence-to-sequence data modeling tasks such as translating statements from one language into another (that is, machine translation). </span><span class="koboSpan" id="kobo.313.2">These models are built on top of the idea of self-attention, which helps the model pay attention to other important </span><a id="_idIndexMarker717"/><span class="koboSpan" id="kobo.314.1">parts of a sentence or sequence of information in the learning process during training. </span><span class="koboSpan" id="kobo.314.2">This attention mechanism helps the models better understand the relationships between the elements of input sequences – for example, between the words in the input sequences in language modeling. </span><span class="koboSpan" id="kobo.314.3">Models built using transformers usually work better than ones built using </span><a id="_idIndexMarker718"/><span class="koboSpan" id="kobo.315.1">predecessor techniques such as </span><strong class="bold"><span class="koboSpan" id="kobo.316.1">Long Short Term Memory</span></strong><span class="koboSpan" id="kobo.317.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.318.1">LSTM</span></strong><span class="koboSpan" id="kobo.319.1">) and </span><strong class="bold"><span class="koboSpan" id="kobo.320.1">Recurrent Neural Networks</span></strong><span class="koboSpan" id="kobo.321.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.322.1">RNNs</span></strong><span class="koboSpan" id="kobo.323.1">) (Vaswani et al., 2017; Devlin et</span><a id="_idIndexMarker719"/> <span class="No-Break"><span class="koboSpan" id="kobo.324.1">al., 2018).</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.325.1">Figure 13</span></em></span><em class="italic"><span class="koboSpan" id="kobo.326.1">.6</span></em><span class="koboSpan" id="kobo.327.1"> shows four traditional problems in language modeling that have been tackled successfully by </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">transformer models:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer127">
<span class="koboSpan" id="kobo.329.1"><img alt="Figure 13.6 – Four traditional problems in language modeling for which deep learning techniques have been used successfully" src="image/B16369_13_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.330.1">Figure 13.6 – Four traditional problems in language modeling for which deep learning techniques have been used successfully</span></p>
<p><span class="koboSpan" id="kobo.331.1">Some famous models </span><a id="_idIndexMarker720"/><span class="koboSpan" id="kobo.332.1">have been used either directly or with some modifications across these or other language modeling tasks. </span><span class="koboSpan" id="kobo.332.2">Here are </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1">some examples:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.334.1">BERT (Devlin et al., </span><span class="No-Break"><span class="koboSpan" id="kobo.335.1">2018; </span></span><a href="https://github.com/google-research/bert"><span class="No-Break"><span class="koboSpan" id="kobo.336.1">https://github.com/google-research/bert</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.337.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.338.1">GPT (Radford et al., 2018) and its more recent </span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">versions (</span></span><a href="https://openai.com/product/gpt-4"><span class="No-Break"><span class="koboSpan" id="kobo.340.1">https://openai.com/product/gpt-4</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.341.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.342.1">DistilBERT (Sanh et al., </span><span class="No-Break"><span class="koboSpan" id="kobo.343.1">2019; </span></span><a href="https://huggingface.co/docs/transformers/model_doc/distilbert"><span class="No-Break"><span class="koboSpan" id="kobo.344.1">https://huggingface.co/docs/transformers/model_doc/distilbert</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.345.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.346.1">RoBERTa (Liu et al., </span><span class="No-Break"><span class="koboSpan" id="kobo.347.1">2019; </span></span><a href="https://github.com/facebookresearch/fairseq/tree/main/examples/roberta"><span class="No-Break"><span class="koboSpan" id="kobo.348.1">https://github.com/facebookresearch/fairseq/tree/main/examples/roberta</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.349.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.350.1">BART (Lewis et al., </span><span class="No-Break"><span class="koboSpan" id="kobo.351.1">2019; </span></span><a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/bart"><span class="No-Break"><span class="koboSpan" id="kobo.352.1">https://github.com/huggingface/transformers/tree/main/src/transformers/models/bart</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.353.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.354.1">XLNet (Yang et al., </span><span class="No-Break"><span class="koboSpan" id="kobo.355.1">2019; </span></span><a href="https://github.com/zihangdai/xlnet/"><span class="No-Break"><span class="koboSpan" id="kobo.356.1">https://github.com/zihangdai/xlnet/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.357.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.358.1">T5 (Raffel et al., </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">2020; </span></span><a href="https://github.com/google-research/text-to-text-transfer-transformer"><span class="No-Break"><span class="koboSpan" id="kobo.360.1">https://github.com/google-research/text-to-text-transfer-transformer</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.361.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.362.1">LLaMA (Touvron et al., </span><span class="No-Break"><span class="koboSpan" id="kobo.363.1">2023; </span></span><a href="https://github.com/facebookresearch/llama"><span class="No-Break"><span class="koboSpan" id="kobo.364.1">https://github.com/facebookresearch/llama</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.365.1">)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.366.1">Transformer models have also been used in other fields and sequence data, such as for electronic health records (Li et al., 2020), protein structure prediction (Jumpter et al., 2021), and time-series anomaly detection (Xu et </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">al., 2021).</span></span></p>
<p><span class="koboSpan" id="kobo.368.1">Generative modeling is another important concept in machine learning modeling for which transformers and CNNs have been successfully used. </span><span class="koboSpan" id="kobo.368.2">Examples of such models are different versions of </span><a id="_idIndexMarker721"/><span class="koboSpan" id="kobo.369.1">GPT, such as GPT-4 (</span><a href="https://openai.com/product/gpt-4"><span class="koboSpan" id="kobo.370.1">https://openai.com/product/gpt-4</span></a><span class="koboSpan" id="kobo.371.1">). </span><span class="koboSpan" id="kobo.371.2">You will learn about</span><a id="_idIndexMarker722"/><span class="koboSpan" id="kobo.372.1"> generative modeling in </span><a href="B16369_14.xhtml#_idTextAnchor379"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.373.1">Chapter 14</span></em></span></a><span class="koboSpan" id="kobo.374.1">, </span><em class="italic"><span class="koboSpan" id="kobo.375.1">Introduction to </span></em><em class="italic"><span class="koboSpan" id="kobo.376.1">Recent Advancements in Machine Learning</span></em><span class="koboSpan" id="kobo.377.1">. </span><span class="koboSpan" id="kobo.377.2">There is an open </span><strong class="bold"><span class="koboSpan" id="kobo.378.1">Large Language Model</span></strong><span class="koboSpan" id="kobo.379.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.380.1">LLM</span></strong><span class="koboSpan" id="kobo.381.1">) leaderboard that provides a list of up-to-date open source LLM models (</span><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard"><span class="koboSpan" id="kobo.382.1">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</span></a><span class="koboSpan" id="kobo.383.1">). </span><span class="koboSpan" id="kobo.383.2">You can also check the list of practical guide resources for LLMs </span><span class="No-Break"><span class="koboSpan" id="kobo.384.1">at </span></span><a href="https://github.com/Mooler0410/LLMsPracticalGuide"><span class="No-Break"><span class="koboSpan" id="kobo.385.1">https://github.com/Mooler0410/LLMsPracticalGuide</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.386.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.387.1">We don’t want to get into the theoretical details behind transformers, but you will learn about the components of a transformer architecture while building one in PyTorch. </span><span class="koboSpan" id="kobo.387.2">However, other widely used performance measures are used in sequence data and language modeling, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">the following:</span></span></p>
<ul>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.389.1">Perplexity</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.390.1"> (</span></span><a href="https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html"><span class="No-Break"><span class="koboSpan" id="kobo.391.1">https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.392.1">)</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.393.1">Bilingual Evaluation Understudy</span></strong><span class="koboSpan" id="kobo.394.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.395.1">BLEU</span></strong><span class="koboSpan" id="kobo.396.1">)</span><strong class="bold"> </strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.397.1">score</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.398.1"> (</span></span><a href="https://torchmetrics.readthedocs.io/en/stable/text/bleu_score.html"><span class="No-Break"><span class="koboSpan" id="kobo.399.1">https://torchmetrics.readthedocs.io/en/stable/text/bleu_score.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.400.1">)</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.401.1">Recall-Oriented Understudy for Gisting Evaluation</span></strong><span class="koboSpan" id="kobo.402.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.403.1">ROUGE</span></strong><span class="koboSpan" id="kobo.404.1">)</span><strong class="bold"> </strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.405.1">score</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.406.1"> (</span></span><a href="https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html"><span class="No-Break"><span class="koboSpan" id="kobo.407.1">https://torchmetrics.readthedocs.io/en/stable/text/rouge_score.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.408.1">)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.409.1">These measures help you in evaluati</span><a id="_idTextAnchor361"/><span class="koboSpan" id="kobo.410.1">ng your </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">sequence models.</span></span></p>
<h2 id="_idParaDest-220"><a id="_idTextAnchor362"/><span class="koboSpan" id="kobo.412.1">Tokenization</span></h2>
<p><span class="koboSpan" id="kobo.413.1">Before training and testing</span><a id="_idIndexMarker723"/><span class="koboSpan" id="kobo.414.1"> transformer models, we need to transform the data into the right format through a process called tokenization. </span><span class="koboSpan" id="kobo.414.2">Tokenization </span><a id="_idIndexMarker724"/><span class="koboSpan" id="kobo.415.1">is about chunking data into smaller pieces such as words, as in </span><strong class="bold"><span class="koboSpan" id="kobo.416.1">word tokenization</span></strong><span class="koboSpan" id="kobo.417.1">, or characters, as in </span><strong class="bold"><span class="koboSpan" id="kobo.418.1">character tokenization</span></strong><span class="koboSpan" id="kobo.419.1">. </span><span class="koboSpan" id="kobo.419.2">For </span><a id="_idIndexMarker725"/><span class="koboSpan" id="kobo.420.1">example, the sentence “I like reading books” can be transformed into its contained words – that is, [“I,” “like,” “reading,” “books”]. </span><span class="koboSpan" id="kobo.420.2">When building a tokenizer, the maximum number of allowed tokens needs to be specified. </span><span class="koboSpan" id="kobo.420.3">For example, for a tokenizer with 1,000 tokens, the most frequent 1,000 words get used as tokens from a text provided to build the tokenizer. </span><span class="koboSpan" id="kobo.420.4">Then, each token will be one of those 1,000 most frequent tokens. </span><span class="koboSpan" id="kobo.420.5">After this, these tokens each get an ID; these numbers will be used later by neural network models for training and testing. </span><span class="koboSpan" id="kobo.420.6">The words and characters outside of the tokens of a tokenizer get a common value of, for example, 0 or 1. </span><span class="koboSpan" id="kobo.420.7">Another challenge in text tokenization is the different lengths of statements and sequences of words. </span><span class="koboSpan" id="kobo.420.8">To handle this challenge, a common ID, such as 0, is used before or after the IDs of tokens of words in each sequence of words or sentences in a </span><a id="_idIndexMarker726"/><span class="koboSpan" id="kobo.421.1">process </span><span class="No-Break"><span class="koboSpan" id="kobo.422.1">called padding.</span></span></p>
<p><span class="koboSpan" id="kobo.423.1">The recent LLMs have different </span><a id="_idIndexMarker727"/><span class="koboSpan" id="kobo.424.1">numbers of tokens in their </span><a id="_idIndexMarker728"/><span class="koboSpan" id="kobo.425.1">tokenization process. </span><span class="koboSpan" id="kobo.425.2">For example, the </span><strong class="bold"><span class="koboSpan" id="kobo.426.1">gpt-4-32k</span></strong><span class="koboSpan" id="kobo.427.1"> model by OpenAI offers 32,000 tokens (</span><a href="https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models"><span class="koboSpan" id="kobo.428.1">https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models</span></a><span class="koboSpan" id="kobo.429.1">), while Claude’s LLM offers 100k tokens (</span><a href="https://www.anthropic.com/index/100k-context-windows"><span class="koboSpan" id="kobo.430.1">https://www.anthropic.com/index/100k-context-windows</span></a><span class="koboSpan" id="kobo.431.1">). </span><span class="koboSpan" id="kobo.431.2">The difference in the number of tokens could impact the performance of the models in terms of the corresponding </span><span class="No-Break"><span class="koboSpan" id="kobo.432.1">text-related tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.433.1">There are commonly used libraries for tokenization, such as Hugging Face’s transformer (</span><a href="https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html"><span class="koboSpan" id="kobo.434.1">https://huggingface.co/transformers/v3.5.1/main_classes/tokenizer.html</span></a><span class="koboSpan" id="kobo.435.1">), SpaCy (</span><a href="https://spacy.io/"><span class="koboSpan" id="kobo.436.1">https://spacy.io/</span></a><span class="koboSpan" id="kobo.437.1">), and NLTK (</span><a href="https://www.nltk.org/api/nltk.tokenize.html"><span class="koboSpan" id="kobo.438.1">https://www.nltk.org/api/nltk.tokenize.html</span></a><span class="koboSpan" id="kobo.439.1">). </span><span class="koboSpan" id="kobo.439.2">Let’s practice with Hugging Face’s transformer library to better understand how </span><span class="No-Break"><span class="koboSpan" id="kobo.440.1">tokenization works.</span></span></p>
<p><span class="koboSpan" id="kobo.441.1">First, let’s import </span><strong class="source-inline"><span class="koboSpan" id="kobo.442.1">transformers.AutoTokenizer()</span></strong><span class="koboSpan" id="kobo.443.1"> and then load the </span><strong class="source-inline"><span class="koboSpan" id="kobo.444.1">bert-base-cased</span></strong><span class="koboSpan" id="kobo.445.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.446.1">gpt2</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.447.1">pre-trained tokenizers:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.448.1">
from transformers import AutoTokenizertokenizer_bertcased = AutoTokenizer.from_pretrained(
    'bert-base-cased')
tokenizer_gpt2 = AutoTokenizer.from_pretrained('gpt2')</span></pre>
<p><span class="koboSpan" id="kobo.449.1">To practice with these two tokenizers, we must make a list of two statements to use in the </span><span class="No-Break"><span class="koboSpan" id="kobo.450.1">tokenization process:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.451.1">
batch_sentences = ["I know how to use machine learning in my projects","I like reading books."]</span></pre> <p><span class="koboSpan" id="kobo.452.1">Then, we must use each of the loaded tokenizers to tokenize and encode these two statements to the corresponding lists of IDs. </span><span class="koboSpan" id="kobo.452.2">First, let’s use </span><strong class="source-inline"><span class="koboSpan" id="kobo.453.1">gpt2</span></strong><span class="koboSpan" id="kobo.454.1">, </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.456.1">
encoded_input_gpt2 = tokenizer_gpt2(batch_sentences)</span></pre> <p><span class="koboSpan" id="kobo.457.1">The preceding code converts these two statements into the following two-dimensional lists, which include IDs for </span><a id="_idIndexMarker729"/><span class="koboSpan" id="kobo.458.1">each of the tokens in each statement. </span><span class="koboSpan" id="kobo.458.2">For example, as both statements start with “I,” the first ID for both of them is 40, which is the token for “I” in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.459.1">gpt2</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.460.1"> tokenizer:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.461.1">
[[40, 760, 703, 284, 779, 4572, 4673, 287, 616, 4493], [40, 588, 3555, 3835, 13]]</span></pre>
<p><span class="koboSpan" id="kobo.462.1">Now, we will use </span><strong class="source-inline"><span class="koboSpan" id="kobo.463.1">bert-base-cased</span></strong><span class="koboSpan" id="kobo.464.1">, but this time, we will ask the tokenizer to also use padding to generate lists of IDs of the same length and return the generated IDs in tensor format, which is suitable for use later in neural network modeling, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.465.1">using PyTorch:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.466.1">
encoded_input_bertcased = tokenizer_bertcased(    batch_sentences, padding=True, return_tensors="pt")</span></pre>
<p><span class="koboSpan" id="kobo.467.1">The following tensor shows the same length for the generated IDs for </span><span class="No-Break"><span class="koboSpan" id="kobo.468.1">both sentences:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.469.1">
tensor([[ 101,  146, 1221, 1293, 1106, 1329, 3395, 3776,    1107, 1139, 3203,  102],
    [ 101,146, 1176, 3455, 2146, 119, 102, 0, 0, 0, 0, 0]])</span></pre>
<p><span class="koboSpan" id="kobo.470.1">We can also use decoding functionality from each of these tokenizers to convert the IDs back into the original statements. </span><span class="koboSpan" id="kobo.470.2">First, we must decode the generated IDs </span><span class="No-Break"><span class="koboSpan" id="kobo.471.1">using </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.472.1">gpt2</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.473.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.474.1">
[tokenizer_gpt2.decode(input_id_iter) for input_id_iter in encoded_input_gpt2["input_ids"]]</span></pre> <p><span class="koboSpan" id="kobo.475.1">This generates the following statements, which match the original </span><span class="No-Break"><span class="koboSpan" id="kobo.476.1">input statements:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.477.1">
['I know how to use machine learning in my projects', 'I like reading books.']</span></pre> <p><span class="koboSpan" id="kobo.478.1">However, let’s say we use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.479.1">bert-base-cased</span></strong><span class="koboSpan" id="kobo.480.1"> tokenizer for decoding the IDs, </span><span class="No-Break"><span class="koboSpan" id="kobo.481.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.482.1">
[tokenizer_bertcased.decode(input_id_iter) for input_id_iter in encoded_input_bertcased["input_ids"]]</span></pre> <p><span class="koboSpan" id="kobo.483.1">The resulting statements not only contain the original statements but also show how a padding token is </span><a id="_idIndexMarker730"/><span class="koboSpan" id="kobo.484.1">decoded. </span><span class="koboSpan" id="kobo.484.2">This is shown as </span><strong class="source-inline"><span class="koboSpan" id="kobo.485.1">[PAD]</span></strong><span class="koboSpan" id="kobo.486.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.487.1">[CLS]</span></strong><span class="koboSpan" id="kobo.488.1">, which is equivalent to the start of a sentence, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.489.1">[SEP]</span></strong><span class="koboSpan" id="kobo.490.1">, which shows where another second </span><span class="No-Break"><span class="koboSpan" id="kobo.491.1">sentence starts:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.492.1">
['[CLS] I know how to use machine learning in my projects [SEP]', '[CLS] I like reading books. </span><span class="koboSpan" id="kobo.492.2">[SEP]</span><a id="_idTextAnchor363"/><span class="koboSpan" id="kobo.493.1"> [PAD] [PAD] [PAD] [PAD] [PAD]']</span></pre>
<h2 id="_idParaDest-221"><a id="_idTextAnchor364"/><span class="koboSpan" id="kobo.494.1">Language embedding</span></h2>
<p><span class="koboSpan" id="kobo.495.1">We can transform</span><a id="_idIndexMarker731"/><span class="koboSpan" id="kobo.496.1"> the identified IDs per word, or sentence if we tokenize sentences and statements, into more information-rich embeddings. </span><span class="koboSpan" id="kobo.496.2">The IDs themselves can be used as one-hot encodings, as discussed in </span><a href="B16369_04.xhtml#_idTextAnchor159"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.497.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.498.1">, </span><em class="italic"><span class="koboSpan" id="kobo.499.1">Detecting Performance and Efficiency Issues in Machine Learning Models</span></em><span class="koboSpan" id="kobo.500.1">, where each word gets a long vector with zeros for all elements and one for the token dedicated to the corresponding word. </span><span class="koboSpan" id="kobo.500.2">But these one-hot encodings don’t provide us with any relationship between the words that work like data points in language modeling at the </span><span class="No-Break"><span class="koboSpan" id="kobo.501.1">word level.</span></span></p>
<p><span class="koboSpan" id="kobo.502.1">We can transform the words in a vocabulary into embeddings that can be used to capture semantic relationships between them and help our machine learning and deep learning models benefit from the new information-rich features across different language modeling tasks. </span><span class="koboSpan" id="kobo.502.2">Although models such as BERT and GPT-2 are not designed solely for embedding extraction for text, they can be used to generate embeddings for each word in a corpus of text. </span><span class="koboSpan" id="kobo.502.3">But there are other older methods such as Word2Vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), and fast-text (Bojanowski et al., 2017) that are designed for embedding generation. </span><span class="koboSpan" id="kobo.502.4">There are also more recent and more comprehensive models for word embedding such as Cohere (</span><a href="https://txt.cohere.com/embedding-archives-wikipedia/"><span class="koboSpan" id="kobo.503.1">https://txt.cohere.com/embedding-archives-wikipedia/</span></a><span class="koboSpan" id="kobo.504.1">) that you can use to generate embeddings for text, in different languages, that you a</span><a id="_idTextAnchor365"/><span class="koboSpan" id="kobo.505.1">im to embed and use </span><span class="No-Break"><span class="koboSpan" id="kobo.506.1">for modeling.</span></span></p>
<h2 id="_idParaDest-222"><a id="_idTextAnchor366"/><span class="koboSpan" id="kobo.507.1">Language modeling using pre-trained models</span></h2>
<p><span class="koboSpan" id="kobo.508.1">There are pre-trained</span><a id="_idIndexMarker732"/><span class="koboSpan" id="kobo.509.1"> models that we can import into different deep learning frameworks, such as PyTorch, to use solely for inference or further fine-tuning with new data. </span><span class="koboSpan" id="kobo.509.2">Here, we want to practice this process with DistilBERT (Sanh et al., 2019), which is a faster and lighter version of BERT (Devlin et al., 2018). </span><span class="koboSpan" id="kobo.509.3">Specifically, we want to use </span><strong class="source-inline"><span class="koboSpan" id="kobo.510.1">DistilBertForSequenceClassification()</span></strong><span class="koboSpan" id="kobo.511.1">, a model based on the DistilBERT architecture, that’s been adapted for sequence classification tasks. </span><span class="koboSpan" id="kobo.511.2">In such processes, the model gets trained and can be used for inference for the task of assigning a label to a given sentence or statement. </span><span class="koboSpan" id="kobo.511.3">Examples of such label assignments are spam detection or semantic labeling, such as positive, negative, </span><span class="No-Break"><span class="koboSpan" id="kobo.512.1">and neutral.</span></span></p>
<p><span class="koboSpan" id="kobo.513.1">First, we will import the necessary libraries and classes from </span><strong class="source-inline"><span class="koboSpan" id="kobo.514.1">torch</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.515.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.516.1">transformers</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.517.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.518.1">
import torchfrom torch.utils.data import DataLoader
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments</span></pre>
<p><span class="koboSpan" id="kobo.519.1">Then, we will load the </span><strong class="source-inline"><span class="koboSpan" id="kobo.520.1">imdb</span></strong><span class="koboSpan" id="kobo.521.1"> dataset so that we can use it to train a model, as a fine-tuned version </span><span class="No-Break"><span class="koboSpan" id="kobo.522.1">of </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.523.1">DistilBertForSequenceClassification()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.524.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.525.1">
from datasets import load_datasetdataset = load_dataset("imdb")</span></pre>
<p><span class="koboSpan" id="kobo.526.1">Now, we can define a tokenizer function on top of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.527.1">DistilBertTokenizerFast()</span></strong><span class="koboSpan" id="kobo.528.1"> tokenizer with </span><strong class="source-inline"><span class="koboSpan" id="kobo.529.1">distilbert-base-uncased</span></strong><span class="koboSpan" id="kobo.530.1"> as the </span><span class="No-Break"><span class="koboSpan" id="kobo.531.1">pre-trained tokenizer:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.532.1">
tokenizer = DistilBertTokenizerFast.from_pretrained(    "distilbert-base-uncased")
def tokenize(batch):
    return tokenizer(batch["text"], padding=True,
        truncation=True, max_length=512)</span></pre>
<p><span class="koboSpan" id="kobo.533.1">After, we can separate a small percentage (1%) of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.534.1">imdb</span></strong><span class="koboSpan" id="kobo.535.1"> data for training and testing as we want to solely practice with this process, and using the whole dataset takes a long time in terms of training </span><span class="No-Break"><span class="koboSpan" id="kobo.536.1">and testing:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.537.1">
train_dataset = dataset["train"].train_test_split(    test_size=0.01)["test"].map(tokenize, batched=True)
test_dataset = dataset["test"].train_test_split(
    test_size=0.01)["test"].map(tokenize, batched=True)</span></pre>
<p><span class="koboSpan" id="kobo.538.1">Now, we can initialize</span><a id="_idIndexMarker733"/><span class="koboSpan" id="kobo.539.1"> the </span><strong class="source-inline"><span class="koboSpan" id="kobo.540.1">DistilBertForSequenceClassification()</span></strong><span class="koboSpan" id="kobo.541.1"> model while specifying the number of labels in the classification process. </span><span class="koboSpan" id="kobo.541.2">Here, this </span><span class="No-Break"><span class="koboSpan" id="kobo.542.1">is </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.543.1">2</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.544.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.545.1">
model = DistilBertForSequenceClassification.from_pretrained(    "distilbert-base-uncased", num_labels=2)</span></pre>
<p><span class="koboSpan" id="kobo.546.1">Now, we can train the model using separate training data from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.547.1">imdb</span></strong><span class="koboSpan" id="kobo.548.1"> dataset for </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.549.1">3</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.550.1"> epochs:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.551.1">
training_args = TrainingArguments(output_dir="./results",    num_train_epochs=3,per_device_train_batch_size=8,
    per_device_eval_batch_size=8, logging_dir="./logs")
trainer = Trainer(model=model, args=training_args,
    train_dataset=train_dataset,eval_dataset=test_dataset)
trainer.train()</span></pre>
<p><span class="koboSpan" id="kobo.552.1">With that, the model has been trained and we can evaluate it on the separate test set from the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.553.1">imdb</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.554.1"> dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.555.1">
eval_results = trainer.evaluate()</span></pre> <p><span class="koboSpan" id="kobo.556.1">This results in a 0.35 </span><span class="No-Break"><span class="koboSpan" id="kobo.557.1">evaluation loss.</span></span></p>
<p><span class="koboSpan" id="kobo.558.1">There are many other available models you can use in your language modeling or inference tasks (for example, the PyTorch Transformers library: </span><a href="https://pytorch.org/hub/huggingface_pytorch-transformers/"><span class="koboSpan" id="kobo.559.1">https://pytorch.org/hub/huggingface_pytorch-transformers/</span></a><span class="koboSpan" id="kobo.560.1">). </span><span class="koboSpan" id="kobo.560.2">There are also other sequence models, outside of language modeling, for areas such as </span><span class="No-Break"><span class="koboSpan" id="kobo.561.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.562.1">Audio </span><span class="No-Break"><span class="koboSpan" id="kobo.563.1">modeling: </span></span><a href="https://pytorch.org/audio/main/models.html"><span class="No-Break"><span class="koboSpan" id="kobo.564.1">https://pytorch.org/audio/main/models.html</span></span></a></li>
<li><span class="koboSpan" id="kobo.565.1">Time-series </span><span class="No-Break"><span class="koboSpan" id="kobo.566.1">modeling: </span></span><a href="https://huggingface.co/docs/transformers/model_doc/time_series_transformer"><span class="No-Break"><span class="koboSpan" id="kobo.567.1">https://huggingface.co/docs/transformers/model_doc/time_series_transformer</span></span></a></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.568.1">Forecasting: </span></span><a href="https://pytorch-forecasting.readthedocs.io/en/stable/models.html"><span class="No-Break"><span class="koboSpan" id="kobo.569.1">https://pytorch-forecasting.readthedocs.io/en/stable/models.html</span></span></a></li>
<li><span class="koboSpan" id="kobo.570.1">Video </span><span class="No-Break"><span class="koboSpan" id="kobo.571.1">modeling: </span></span><a href="https://pytorchvideo.org/"><span class="No-Break"><span class="koboSpan" id="kobo.572.1">https://pytorchvideo.org/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.573.1">)</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.574.1">You can learn more about transformer modeling and how to make new architectures from scratch instead </span><a id="_idIndexMarker734"/><span class="koboSpan" id="kobo.575.1">of using pre-trained models in PyTorch </span><span class="No-Break"><span class="koboSpan" id="kobo.576.1">at </span></span><a href="https://pytorch.org/tutorials/beginner/transformer_tutorial.html"><span class="No-Break"><span class="koboSpan" id="kobo.577.1">https://pytorch.org/tutorials/beginner/transformer_tutorial.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.578.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.579.1">In this section, you learned about modeling text as one type of sequence data. </span><span class="koboSpan" id="kobo.579.2">Next, we will cover modeling graphs, whi</span><a id="_idTextAnchor367"/><span class="koboSpan" id="kobo.580.1">ch are more complex </span><span class="No-Break"><span class="koboSpan" id="kobo.581.1">data structures.</span></span></p>
<h1 id="_idParaDest-223"><a id="_idTextAnchor368"/><span class="koboSpan" id="kobo.582.1">Modeling graphs using deep neural networks</span></h1>
<p><span class="koboSpan" id="kobo.583.1">We can consider graphs as a</span><a id="_idIndexMarker735"/><span class="koboSpan" id="kobo.584.1"> more general structure of almost all non-tabular data we use for machine learning and deep learning modeling. </span><span class="koboSpan" id="kobo.584.2">Sequences</span><a id="_idIndexMarker736"/><span class="koboSpan" id="kobo.585.1"> can be considered </span><strong class="bold"><span class="koboSpan" id="kobo.586.1">one-dimensional</span></strong><span class="koboSpan" id="kobo.587.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.588.1">1D</span></strong><span class="koboSpan" id="kobo.589.1">), while images or image shape </span><a id="_idIndexMarker737"/><span class="koboSpan" id="kobo.590.1">data can be considered </span><strong class="bold"><span class="koboSpan" id="kobo.591.1">two-dimensional</span></strong><span class="koboSpan" id="kobo.592.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.593.1">2D</span></strong><span class="koboSpan" id="kobo.594.1">) (see </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.595.1">Figure 13</span></em></span><em class="italic"><span class="koboSpan" id="kobo.596.1">.7</span></em><span class="koboSpan" id="kobo.597.1">). </span><span class="koboSpan" id="kobo.597.2">Earlier in this chapter, you learned how to start benefiting from CNNs and transformers in Python and PyTorch for sequence and image shape data. </span><span class="koboSpan" id="kobo.597.3">But more general graphs don’t fit into these two graphs, which have predefined structures (see </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.598.1">Figure 13</span></em></span><em class="italic"><span class="koboSpan" id="kobo.599.1">.7</span></em><span class="koboSpan" id="kobo.600.1">), and we cannot simply model them using CNNs or </span><span class="No-Break"><span class="koboSpan" id="kobo.601.1">sequence models:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer128">
<span class="koboSpan" id="kobo.602.1"><img alt="Figure 13.7 – Graph representation of different unstructured data types" src="image/B16369_13_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.603.1">Figure 13.7 – Graph representation of different unstructured data types</span></p>
<p><span class="koboSpan" id="kobo.604.1">Graphs have two</span><a id="_idIndexMarker738"/><span class="koboSpan" id="kobo.605.1"> important elements, called nodes and edges. </span><span class="koboSpan" id="kobo.605.2">The edges connect the nodes. </span><span class="koboSpan" id="kobo.605.3">The nodes and edges </span><a id="_idIndexMarker739"/><span class="koboSpan" id="kobo.606.1">of graphs </span><a id="_idIndexMarker740"/><span class="koboSpan" id="kobo.607.1">can have different characteristics that differentiate them from each other (see </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.608.1">Figure 13</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.609.1">.8</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.610.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer129">
<span class="koboSpan" id="kobo.611.1"><img alt="Figure 13.8 – Graph types according to their node and edge characteristics" src="image/B16369_13_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.612.1">Figure 13.8 – Graph types according to their node and edge characteristics</span></p>
<p><span class="koboSpan" id="kobo.613.1">We can have graphs where nodes have features, edges have weights or features, or edges have directions. </span><span class="koboSpan" id="kobo.613.2">Undirected graphs (graphs with undirected edges), for example, are useful for many applications, such as social media networks. </span><span class="koboSpan" id="kobo.613.3">Assuming each node in the graph of social media is a node, then the edges can determine which people are connected. </span><span class="koboSpan" id="kobo.613.4">The features of nodes in such graphs could be different characteristics of people in the social media network, such as their age, field of study or job title, city of residence, and so on. </span><span class="koboSpan" id="kobo.613.5">Directed graphs can be used in different applications, such as for causal modeling, which we’ll discuss in </span><a href="B16369_15.xhtml#_idTextAnchor406"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.614.1">Chapter 15</span></em></span></a><span class="koboSpan" id="kobo.615.1">, </span><em class="italic"><span class="koboSpan" id="kobo.616.1">Correlation </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.617.1">versus Causality</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.618.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.619.1">As mentioned at the </span><a id="_idIndexMarker741"/><span class="koboSpan" id="kobo.620.1">beginning of this section, techniques such as CNNs and transformers cannot be used directly on graphs. </span><span class="koboSpan" id="kobo.620.2">Due to this, we’ll review other neural network techniques that can help</span><a id="_idTextAnchor369"/><span class="koboSpan" id="kobo.621.1"> you in modeling graphs in </span><span class="No-Break"><span class="koboSpan" id="kobo.622.1">your projects.</span></span></p>
<h2 id="_idParaDest-224"><a id="_idTextAnchor370"/><span class="koboSpan" id="kobo.623.1">Graph neural networks</span></h2>
<p><span class="koboSpan" id="kobo.624.1">Graphs may have complicated structures as opposed to 2D images and 1D sequence data. </span><span class="koboSpan" id="kobo.624.2">However, we can model them using deep neural networks with the same idea as in CNNs and transformer models to rely on local patterns and relationships in the data. </span><span class="koboSpan" id="kobo.624.3">We can rely on local patterns</span><a id="_idIndexMarker742"/><span class="koboSpan" id="kobo.625.1"> in graphs and let the neural network learn from neighboring nodes instead of trying to learn information about the whole graph, which might contain thousands of nodes and millions of edges all at once. </span><span class="koboSpan" id="kobo.625.2">This is the idea behind </span><strong class="bold"><span class="koboSpan" id="kobo.626.1">graph neural </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.627.1">networks</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.628.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.629.1">GNNs</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.630.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.631.1">We can use GNNs for different tasks, such as </span><span class="No-Break"><span class="koboSpan" id="kobo.632.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.633.1">Node classification</span></strong><span class="koboSpan" id="kobo.634.1">: We can aim to predict the class of each node in a graph using GNNs. </span><span class="koboSpan" id="kobo.634.2">For example, if you consider a graph of hotels in a city with edges being the shortest route </span><a id="_idIndexMarker743"/><span class="koboSpan" id="kobo.635.1">between them, you can aim to predict which one gets filled in during the holidays. </span><span class="koboSpan" id="kobo.635.2">Or if you have a background in chemistry, you can use node classification to annotate amino acids in proteins using the 3D structure of proteins (Abdollahi et </span><span class="No-Break"><span class="koboSpan" id="kobo.636.1">al., 2023).</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.637.1">Node selection</span></strong><span class="koboSpan" id="kobo.638.1">: Node selection </span><a id="_idIndexMarker744"/><span class="koboSpan" id="kobo.639.1">for GNNs is a similar task to object detection for CNNs. </span><span class="koboSpan" id="kobo.639.2">We can design GNNs to identify and select nodes with specific characteristics, such as choosing people to suggest a product to in a graph of products </span><span class="No-Break"><span class="koboSpan" id="kobo.640.1">and consumers.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.641.1">Link prediction</span></strong><span class="koboSpan" id="kobo.642.1">: We can aim to predict unknown edges between already existing nodes or new nodes in a graph. </span><span class="koboSpan" id="kobo.642.2">For example, in a graph that’s representative of a social media </span><a id="_idIndexMarker745"/><span class="koboSpan" id="kobo.643.1">network, link prediction could be about predicting connections between people. </span><span class="koboSpan" id="kobo.643.2">Then, those individuals could be suggested to each other so that they can add each other to their networks </span><span class="No-Break"><span class="koboSpan" id="kobo.644.1">of connections.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.645.1">Graph classification</span></strong><span class="koboSpan" id="kobo.646.1">: Instead of aiming to predict or select nodes or edges, we can design GNNs to</span><a id="_idIndexMarker746"/><span class="koboSpan" id="kobo.647.1"> predict the characteristics of whole graphs (</span><a href="https://chrsmrrs.github.io/datasets/"><span class="koboSpan" id="kobo.648.1">https://chrsmrrs.github.io/datasets/</span></a><span class="koboSpan" id="kobo.649.1">). </span><span class="koboSpan" id="kobo.649.2">In such cases, there could be graphs where each represents a data point, such as a drug molecule to be used in a GNN model for </span><span class="No-Break"><span class="koboSpan" id="kobo.650.1">graph classification.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.651.1">There are general taxonomies of different GNNs, such as the one suggested by Wu et al. </span><span class="koboSpan" id="kobo.651.2">(2020). </span><span class="koboSpan" id="kobo.651.3">But here, we want to focus on examples of widely used methods instead of getting too technical regarding the different categories of GNNs. </span><span class="koboSpan" id="kobo.651.4">Examples of methodologies that have been used </span><a id="_idIndexMarker747"/><span class="koboSpan" id="kobo.652.1">successfully for modeling graphs are </span><strong class="bold"><span class="koboSpan" id="kobo.653.1">Graph Convolutional Networks</span></strong><span class="koboSpan" id="kobo.654.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.655.1">GCNs</span></strong><span class="koboSpan" id="kobo.656.1">) (Kipf and Welling in 2016), </span><strong class="bold"><span class="koboSpan" id="kobo.657.1">Graph Sample and Aggregation</span></strong><span class="koboSpan" id="kobo.658.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.659.1">GraphSAGE</span></strong><span class="koboSpan" id="kobo.660.1">) (Hamilton </span><a id="_idIndexMarker748"/><span class="koboSpan" id="kobo.661.1">et al. </span><span class="koboSpan" id="kobo.661.2">in 2017), and </span><strong class="bold"><span class="koboSpan" id="kobo.662.1">Graph Attention Networks</span></strong><span class="koboSpan" id="kobo.663.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.664.1">GATs</span></strong><span class="koboSpan" id="kobo.665.1">) (Veličković </span><a id="_idIndexMarker749"/><span class="koboSpan" id="kobo.666.1">et al. </span><span class="koboSpan" id="kobo.666.2">in 2018). </span><span class="koboSpan" id="kobo.666.3">While most GNN techniques consider features for nodes, not all of them consider edge features. </span><strong class="bold"><span class="koboSpan" id="kobo.667.1">Message Passing Neural Networks</span></strong><span class="koboSpan" id="kobo.668.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.669.1">MPNNs</span></strong><span class="koboSpan" id="kobo.670.1">) is an example of a technique</span><a id="_idIndexMarker750"/><span class="koboSpan" id="kobo.671.1"> that considers both node and edge features and was initially designed for producing graphs of drug molecules (Gilmer et al. </span><span class="No-Break"><span class="koboSpan" id="kobo.672.1">in 2017).</span></span></p>
<p><span class="koboSpan" id="kobo.673.1">You can build graphs from the data you have at hand or use publicly available datasets such as </span><strong class="bold"><span class="koboSpan" id="kobo.674.1">Stanford Large Network Dataset Collection</span></strong><span class="koboSpan" id="kobo.675.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.676.1">SNAP</span></strong><span class="koboSpan" id="kobo.677.1">) to practice with different GNN techniques. </span><span class="koboSpan" id="kobo.677.2">SNAP has</span><a id="_idIndexMarker751"/><span class="koboSpan" id="kobo.678.1"> one of the largest collections of graph datasets you can download and start practicing </span><span class="No-Break"><span class="koboSpan" id="kobo.679.1">with (</span></span><a href="https://snap.stanford.edu/data/"><span class="No-Break"><span class="koboSpan" id="kobo.680.1">https://snap.stanford.edu/data/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.681.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.682.1">Next, we will practice GNN modeling using PyTorch to help you be</span><a id="_idTextAnchor371"/><span class="koboSpan" id="kobo.683.1">tter understand how to build such models </span><span class="No-Break"><span class="koboSpan" id="kobo.684.1">in Python.</span></span></p>
<h2 id="_idParaDest-225"><a id="_idTextAnchor372"/><span class="koboSpan" id="kobo.685.1">GNNs with PyTorch Geometric</span></h2>
<p><span class="koboSpan" id="kobo.686.1">PyTorch Geometric is a Python library </span><a id="_idIndexMarker752"/><span class="koboSpan" id="kobo.687.1">built upon PyTorch that helps you train and test GNNs. </span><span class="koboSpan" id="kobo.687.2">There is a series of tutorials you can benefit from to learn </span><a id="_idIndexMarker753"/><span class="koboSpan" id="kobo.688.1">about GNN modeling using PyTorch Geometric (</span><a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html"><span class="koboSpan" id="kobo.689.1">https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html</span></a><span class="koboSpan" id="kobo.690.1">). </span><span class="koboSpan" id="kobo.690.2">Here, we will practice the problem of node classification with code adapted from one of these </span><span class="No-Break"><span class="koboSpan" id="kobo.691.1">tutorials (</span></span><a href="https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=0YgHcLXMLk4o"><span class="No-Break"><span class="koboSpan" id="kobo.692.1">https://colab.research.google.com/drive/14OvFnAXgg</span></span> <span class="No-Break"><span class="koboSpan" id="kobo.693.1">xB8vM4e8vSURUp1TaKnovzX?usp=sharing#scrollTo=0YgHcLXMLk4o</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.694.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.695.1">First, let’s import the </span><em class="italic"><span class="koboSpan" id="kobo.696.1">CiteSeer</span></em><span class="koboSpan" id="kobo.697.1"> citation network dataset from </span><strong class="source-inline"><span class="koboSpan" id="kobo.698.1">Planetoid</span></strong><span class="koboSpan" id="kobo.699.1"> in PyTorch Geometric (Yang et </span><span class="No-Break"><span class="koboSpan" id="kobo.700.1">al., 2016):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.701.1">
from torch_geometric.datasets import Planetoidfrom torch_geometric.transforms import NormalizeFeatures
dataset = Planetoid(root='data/Planetoid', name='CiteSeer',
    transform=NormalizeFeatures())
data = dataset[0]</span></pre>
<p><span class="koboSpan" id="kobo.702.1">Now, similar to initializing neural networks for FCNNs and CNNs, we must initialize a </span><strong class="source-inline"><span class="koboSpan" id="kobo.703.1">GCNet</span></strong><span class="koboSpan" id="kobo.704.1"> class for GNN modeling, but instead of using linear and convolutional layers, we will use </span><strong class="source-inline"><span class="koboSpan" id="kobo.705.1">GCNConv</span></strong><span class="koboSpan" id="kobo.706.1"> graph </span><span class="No-Break"><span class="koboSpan" id="kobo.707.1">convolutional layers:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.708.1">
import torchfrom torch_geometric.nn import GCNConv
import torch.nn.functional as F
torch.manual_seed(123)
class GCNet(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        self.gcn_layer1 = GCNConv(dataset.num_features,
            hidden_channels[0])
        self.gcn_layer2 = GCNConv(hidden_channels[0],
            hidden_channels[1])
        self.gcn_layer3 = GCNConv(hidden_channels[1],
            dataset.num_classes)
    def forward(self, x, edge_index):
        x = self.gcn_layer1(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.3, training=self.training)
        x = self.gcn_layer2(x, edge_index)
        x = x.relu()
        x = self.gcn_layer3(x, edge_index)
        return x</span></pre>
<p><span class="koboSpan" id="kobo.709.1">In the previous class, we used three </span><strong class="source-inline"><span class="koboSpan" id="kobo.710.1">GCNConv</span></strong><span class="koboSpan" id="kobo.711.1"> layers in combination with the ReLU activation function and dropout </span><span class="No-Break"><span class="koboSpan" id="kobo.712.1">for regularization.</span></span></p>
<p><span class="koboSpan" id="kobo.713.1">Now, we can use the </span><a id="_idIndexMarker754"/><span class="koboSpan" id="kobo.714.1">defined </span><strong class="source-inline"><span class="koboSpan" id="kobo.715.1">GCNet</span></strong><span class="koboSpan" id="kobo.716.1"> class to initialize our model with hidden layers whose sizes are 128 and 16, both of which are arbitrary in this</span><a id="_idIndexMarker755"/><span class="koboSpan" id="kobo.717.1"> practice code. </span><span class="koboSpan" id="kobo.717.2">We must also initialize an optimizer while specifying the algorithm, which in this case is </span><strong class="source-inline"><span class="koboSpan" id="kobo.718.1">Adam</span></strong><span class="koboSpan" id="kobo.719.1">, and a learning rate of </span><strong class="source-inline"><span class="koboSpan" id="kobo.720.1">0.01</span></strong><span class="koboSpan" id="kobo.721.1"> and a weight decay of </span><strong class="source-inline"><span class="koboSpan" id="kobo.722.1">1e-4</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.723.1">for regularization:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.724.1">
model = GCNet(hidden_channels=[128, 16])optimizer = torch.optim.Adam(model.parameters(), lr=0.01,
    weight_decay=1e-4)
criterion = torch.nn.CrossEntropyLoss()</span></pre>
<p><span class="koboSpan" id="kobo.725.1">Now, we can define our training function, which will be used for </span><span class="No-Break"><span class="koboSpan" id="kobo.726.1">one-epoch training:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.727.1">
def train():        model.train()
        optimizer.zero_grad()
        out = model(data.x, data.edge_index)
        loss = criterion(out[data.train_mask],
            data.y[data.train_mask])
        loss.backward()
        optimizer.step()
        return loss</span></pre>
<p><span class="koboSpan" id="kobo.728.1">With that, we are ready to </span><a id="_idIndexMarker756"/><span class="koboSpan" id="kobo.729.1">go through a series of epochs and train</span><a id="_idIndexMarker757"/><span class="koboSpan" id="kobo.730.1"> the model. </span><span class="koboSpan" id="kobo.730.2">Please note that the following loop for training the model for 400 epochs might take a </span><span class="No-Break"><span class="koboSpan" id="kobo.731.1">long time:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.732.1">
import numpy as npepoch_list = []
loss_list = []
for epoch in np.arange(1, 401):
    loss = train()
    if epoch%20 == 0:
        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')
        epoch_list.append(epoch)
        loss_list.append(loss.detach().numpy())</span></pre>
<p><span class="koboSpan" id="kobo.733.1">The following plot shows the learning curve (loss versus epoch) in the </span><span class="No-Break"><span class="koboSpan" id="kobo.734.1">training process:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer130">
<span class="koboSpan" id="kobo.735.1"><img alt="Figure 13.9 – The learning curve for the example GCN model on the CiteSeer dataset" src="image/B16369_13_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.736.1">Figure 13.9 – The learning curve for the example GCN model on the CiteSeer dataset</span></p>
<p><span class="koboSpan" id="kobo.737.1">We can also test the </span><a id="_idIndexMarker758"/><span class="koboSpan" id="kobo.738.1">model on the test portion of the</span><a id="_idIndexMarker759"/><span class="koboSpan" id="kobo.739.1"> dataset, </span><span class="No-Break"><span class="koboSpan" id="kobo.740.1">as follows:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.741.1">
model.eval()pred = model(data.x, data.edge_index).argmax(dim=1)
test_correct = pred[data.test_mask] ==
    data.y[data.test_mask]
test_acc = int(test_correct.sum()) / int(
    data.test_mask.sum())</span></pre>
<p><span class="koboSpan" id="kobo.742.1">This results in an accuracy of 0.655. </span><span class="koboSpan" id="kobo.742.2">We can also generate a confusion matrix of the predictions on the </span><span class="No-Break"><span class="koboSpan" id="kobo.743.1">test set:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.744.1">
from sklearn.metrics import confusion_matrixcf = confusion_matrix(y_true = data.y, y_pred = model(
    data.x, data.edge_index).argmax(dim=1))
import seaborn as sns
sns.set()
sns.heatmap(cf, annot=True, fmt="d")</span></pre>
<p><span class="koboSpan" id="kobo.745.1">This results in the following matrix, shown as a heatmap. </span><span class="koboSpan" id="kobo.745.2">Although most of the predictions and true classes of data points match, many of them are misclassified and summarized outside of the diagonal elements of the </span><span class="No-Break"><span class="koboSpan" id="kobo.746.1">confusion matrix:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer131">
<span class="koboSpan" id="kobo.747.1"><img alt="Figure 13.10 – Confusion matrix of the predictions over the test set for the example GCN model on the CiteSeer dataset" src="image/B16369_13_010.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.748.1">Figure 13.10 – Confusion matrix of the predictions over the test set for the example GCN model on the CiteSeer dataset</span></p>
<p><span class="koboSpan" id="kobo.749.1">In this section, we talked </span><a id="_idIndexMarker760"/><span class="koboSpan" id="kobo.750.1">about techniques for modeling</span><a id="_idIndexMarker761"/><span class="koboSpan" id="kobo.751.1"> different data types and problems using deep learning. </span><span class="koboSpan" id="kobo.751.2">Now, you are ready to learn more abo</span><a id="_idTextAnchor373"/><span class="koboSpan" id="kobo.752.1">ut these advanced techniques and use them in </span><span class="No-Break"><span class="koboSpan" id="kobo.753.1">your projects.</span></span></p>
<h1 id="_idParaDest-226"><a id="_idTextAnchor374"/><span class="koboSpan" id="kobo.754.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.755.1">In this chapter, you learned about advanced deep learning techniques, including CNNs, transformers, and GNNs. </span><span class="koboSpan" id="kobo.755.2">You were provided with some of the widely used or famous models that have been developed using each of these techniques. </span><span class="koboSpan" id="kobo.755.3">You also practiced building these advanced models either from scratch or fine-tuning them using Python and PyTorch. </span><span class="koboSpan" id="kobo.755.4">This knowledge helped you learn more about these techniques and start using them in your projects so that you can model images and image shape data, text and sequence data, </span><span class="No-Break"><span class="koboSpan" id="kobo.756.1">and graphs.</span></span></p>
<p><span class="koboSpan" id="kobo.757.1">In the next chapter, you will learn how recent advancements in generative modeling and prompt engineering, as well as self-supervised learning, can either help you in developing your projects or provide you with opportunitie</span><a id="_idTextAnchor375"/><span class="koboSpan" id="kobo.758.1">s to develop interesting and useful tools </span><span class="No-Break"><span class="koboSpan" id="kobo.759.1">and applications.</span></span></p>
<h1 id="_idParaDest-227"><a id="_idTextAnchor376"/><span class="koboSpan" id="kobo.760.1">Questions</span></h1>
<ol>
<li><span class="koboSpan" id="kobo.761.1">What are some examples of problems you can use CNNs and </span><span class="No-Break"><span class="koboSpan" id="kobo.762.1">GNNs for?</span></span></li>
<li><span class="koboSpan" id="kobo.763.1">Does applying convolution preserve local patterns </span><span class="No-Break"><span class="koboSpan" id="kobo.764.1">in images?</span></span></li>
<li><span class="koboSpan" id="kobo.765.1">Could decreasing the number of tokens result in more mistakes in </span><span class="No-Break"><span class="koboSpan" id="kobo.766.1">language models?</span></span></li>
<li><span class="koboSpan" id="kobo.767.1">What is padding in the text </span><span class="No-Break"><span class="koboSpan" id="kobo.768.1">tokenization process?</span></span></li>
<li><span class="koboSpan" id="kobo.769.1">Are the network architecture classes we build for CNNs and GNNs in </span><span class="No-Break"><span class="koboSpan" id="kobo.770.1">PyT</span><a id="_idTextAnchor377"/><span class="koboSpan" id="kobo.771.1">orch similar?</span></span></li>
<li><span class="koboSpan" id="kobo.772.1">When do you need edge features to </span><span class="No-Break"><span class="koboSpan" id="kobo.773.1">build GNNs?</span></span></li>
</ol>
<h1 id="_idParaDest-228"><a id="_idTextAnchor378"/><span class="koboSpan" id="kobo.774.1">References</span></h1>
<ul>
<li><span class="koboSpan" id="kobo.775.1">He, Kaiming, et al. </span><em class="italic"><span class="koboSpan" id="kobo.776.1">Deep residual learning for image recognition</span></em><span class="koboSpan" id="kobo.777.1">. </span><span class="koboSpan" id="kobo.777.2">Proceedings of the IEEE conference on computer vision and pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.778.1">recognition. </span><span class="koboSpan" id="kobo.778.2">2016.</span></span></li>
<li><span class="koboSpan" id="kobo.779.1">Tan, Mingxing, and Quoc Le. </span><em class="italic"><span class="koboSpan" id="kobo.780.1">Efficientnet: Rethinking model scaling for convolutional neural networks</span></em><span class="koboSpan" id="kobo.781.1">. </span><span class="koboSpan" id="kobo.781.2">International conference on machine learning. </span><span class="No-Break"><span class="koboSpan" id="kobo.782.1">PMLR, 2019.</span></span></li>
<li><span class="koboSpan" id="kobo.783.1">Howard, Andrew G., et al. </span><em class="italic"><span class="koboSpan" id="kobo.784.1">Mobilenets: Efficient convolutional neural networks for mobile vision applications</span></em><span class="koboSpan" id="kobo.785.1">. </span><span class="koboSpan" id="kobo.785.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.786.1">arXiv:1704.04861 (2017).</span></span></li>
<li><span class="koboSpan" id="kobo.787.1">Sandler, Mark, et al. </span><em class="italic"><span class="koboSpan" id="kobo.788.1">Mobilenetv2: Inverted residuals and linear bottlenecks</span></em><span class="koboSpan" id="kobo.789.1">. </span><span class="koboSpan" id="kobo.789.2">Proceedings of the IEEE conference on computer vision and pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.790.1">recognition. </span><span class="koboSpan" id="kobo.790.2">2018.</span></span></li>
<li><span class="koboSpan" id="kobo.791.1">Chollet, François. </span><em class="italic"><span class="koboSpan" id="kobo.792.1">Xception: Deep learning with depthwise separable convolutions</span></em><span class="koboSpan" id="kobo.793.1">. </span><span class="koboSpan" id="kobo.793.2">Proceedings of the IEEE conference on computer vision and pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.794.1">recognition. </span><span class="koboSpan" id="kobo.794.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.795.1">Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. </span><em class="italic"><span class="koboSpan" id="kobo.796.1">U-net: Convolutional networks for biomedical image segmentation</span></em><span class="koboSpan" id="kobo.797.1">. </span><span class="koboSpan" id="kobo.797.2">Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18. </span><span class="koboSpan" id="kobo.797.3">Springer International </span><span class="No-Break"><span class="koboSpan" id="kobo.798.1">Publishing, 2015.</span></span></li>
<li><span class="koboSpan" id="kobo.799.1">He, Kaiming, et al. </span><em class="italic"><span class="koboSpan" id="kobo.800.1">Mask r-cnn</span></em><span class="koboSpan" id="kobo.801.1">. </span><span class="koboSpan" id="kobo.801.2">Proceedings of the IEEE international conference on computer </span><span class="No-Break"><span class="koboSpan" id="kobo.802.1">vision. </span><span class="koboSpan" id="kobo.802.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.803.1">Chen, Liang-Chieh, et al. </span><em class="italic"><span class="koboSpan" id="kobo.804.1">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</span></em><span class="koboSpan" id="kobo.805.1">. </span><span class="koboSpan" id="kobo.805.2">IEEE transactions on pattern analysis and machine intelligence 40.4 (</span><span class="No-Break"><span class="koboSpan" id="kobo.806.1">2017): 834-848.</span></span></li>
<li><span class="koboSpan" id="kobo.807.1">Zhao, Hengshuang, et al. </span><em class="italic"><span class="koboSpan" id="kobo.808.1">Pyramid scene parsing network</span></em><span class="koboSpan" id="kobo.809.1">. </span><span class="koboSpan" id="kobo.809.2">Proceedings of the IEEE conference on computer vision and pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.810.1">recognition. </span><span class="koboSpan" id="kobo.810.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.811.1">Ren, Shaoqing, et al. </span><em class="italic"><span class="koboSpan" id="kobo.812.1">Faster r-cnn: Towards real-time object detection with region proposal networks</span></em><span class="koboSpan" id="kobo.813.1">. </span><span class="koboSpan" id="kobo.813.2">Advances in neural information processing systems </span><span class="No-Break"><span class="koboSpan" id="kobo.814.1">28 (2015).</span></span></li>
<li><span class="koboSpan" id="kobo.815.1">Redmon, Joseph, et al. </span><em class="italic"><span class="koboSpan" id="kobo.816.1">You only look once: Unified, real-time object detection</span></em><span class="koboSpan" id="kobo.817.1">. </span><span class="koboSpan" id="kobo.817.2">Proceedings of the IEEE conference on computer vision and pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.818.1">recognition. </span><span class="koboSpan" id="kobo.818.2">2016.</span></span></li>
<li><span class="koboSpan" id="kobo.819.1">Dong, Chao, et al. </span><em class="italic"><span class="koboSpan" id="kobo.820.1">Image super-resolution using deep convolutional networks</span></em><span class="koboSpan" id="kobo.821.1">. </span><span class="koboSpan" id="kobo.821.2">IEEE transactions on pattern analysis and machine intelligence 38.2 (</span><span class="No-Break"><span class="koboSpan" id="kobo.822.1">2015): 295-307.</span></span></li>
<li><span class="koboSpan" id="kobo.823.1">Dong, Chao, Chen Change Loy, and Xiaoou Tang. </span><em class="italic"><span class="koboSpan" id="kobo.824.1">Accelerating the super-resolution convolutional neural network</span></em><span class="koboSpan" id="kobo.825.1">. </span><span class="koboSpan" id="kobo.825.2">Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14. </span><span class="koboSpan" id="kobo.825.3">Springer International </span><span class="No-Break"><span class="koboSpan" id="kobo.826.1">Publishing, 2016.</span></span></li>
<li><span class="koboSpan" id="kobo.827.1">Lim, Bee, et al. </span><em class="italic"><span class="koboSpan" id="kobo.828.1">Enhanced deep residual networks for single image super-resolution</span></em><span class="koboSpan" id="kobo.829.1">. </span><span class="koboSpan" id="kobo.829.2">Proceedings of the IEEE conference on computer vision and pattern recognition </span><span class="No-Break"><span class="koboSpan" id="kobo.830.1">workshops. </span><span class="koboSpan" id="kobo.830.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.831.1">Isola, Phillip, et al. </span><em class="italic"><span class="koboSpan" id="kobo.832.1">Image-to-image translation with conditional adversarial networks</span></em><span class="koboSpan" id="kobo.833.1">. </span><span class="koboSpan" id="kobo.833.2">Proceedings of the IEEE conference on computer vision and pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.834.1">recognition. </span><span class="koboSpan" id="kobo.834.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.835.1">Zhu, Jun-Yan, et al. </span><em class="italic"><span class="koboSpan" id="kobo.836.1">Unpaired image-to-image translation using cycle-consistent adversarial networks</span></em><span class="koboSpan" id="kobo.837.1">. </span><span class="koboSpan" id="kobo.837.2">Proceedings of the IEEE international conference on computer </span><span class="No-Break"><span class="koboSpan" id="kobo.838.1">vision. </span><span class="koboSpan" id="kobo.838.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.839.1">Gatys, Leon A., Alexander S. </span><span class="koboSpan" id="kobo.839.2">Ecker, and Matthias Bethge. </span><em class="italic"><span class="koboSpan" id="kobo.840.1">Image style transfer using convolutional neural networks</span></em><span class="koboSpan" id="kobo.841.1">. </span><span class="koboSpan" id="kobo.841.2">Proceedings of the IEEE conference on computer vision and pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.842.1">recognition. </span><span class="koboSpan" id="kobo.842.2">2016.</span></span></li>
<li><span class="koboSpan" id="kobo.843.1">Huang, Xun, and Serge Belongie. </span><em class="italic"><span class="koboSpan" id="kobo.844.1">Arbitrary style transfer in real-time with adaptive instance normalization</span></em><span class="koboSpan" id="kobo.845.1">. </span><span class="koboSpan" id="kobo.845.2">Proceedings of the IEEE international conference on computer </span><span class="No-Break"><span class="koboSpan" id="kobo.846.1">vision. </span><span class="koboSpan" id="kobo.846.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.847.1">Schlegl, Thomas, et al. </span><em class="italic"><span class="koboSpan" id="kobo.848.1">Unsupervised anomaly detection with generative adversarial networks to guide marker discovery</span></em><span class="koboSpan" id="kobo.849.1">. </span><span class="koboSpan" id="kobo.849.2">Information Processing in Medical Imaging: 25th International Conference, IPMI 2017, Boone, NC, USA, June 25-30, 2017, Proceedings. </span><span class="koboSpan" id="kobo.849.3">Cham: Springer International </span><span class="No-Break"><span class="koboSpan" id="kobo.850.1">Publishing, 2017.</span></span></li>
<li><span class="koboSpan" id="kobo.851.1">Ruff, Lukas, et al. </span><em class="italic"><span class="koboSpan" id="kobo.852.1">Deep one-class classification</span></em><span class="koboSpan" id="kobo.853.1">. </span><span class="koboSpan" id="kobo.853.2">International conference on machine learning. </span><span class="No-Break"><span class="koboSpan" id="kobo.854.1">PMLR, 2018.</span></span></li>
<li><span class="koboSpan" id="kobo.855.1">Zhou, Chong, and Randy C. </span><span class="koboSpan" id="kobo.855.2">Paffenroth. </span><em class="italic"><span class="koboSpan" id="kobo.856.1">Anomaly detection with robust deep autoencoders</span></em><span class="koboSpan" id="kobo.857.1">. </span><span class="koboSpan" id="kobo.857.2">Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data </span><span class="No-Break"><span class="koboSpan" id="kobo.858.1">mining. </span><span class="koboSpan" id="kobo.858.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.859.1">Baek, Youngmin, et al. </span><em class="italic"><span class="koboSpan" id="kobo.860.1">Character region awareness for text detection</span></em><span class="koboSpan" id="kobo.861.1">. </span><span class="koboSpan" id="kobo.861.2">Proceedings of the IEEE/CVF conference on computer vision and pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.862.1">recognition. </span><span class="koboSpan" id="kobo.862.2">2019.</span></span></li>
<li><span class="koboSpan" id="kobo.863.1">Zhou, Xinyu, et al. </span><em class="italic"><span class="koboSpan" id="kobo.864.1">East: an efficient and accurate scene text detector</span></em><span class="koboSpan" id="kobo.865.1">. </span><span class="koboSpan" id="kobo.865.2">Proceedings of the IEEE Conference on Computer Vision and Pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.866.1">Recognition. </span><span class="koboSpan" id="kobo.866.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.867.1">Tran, Du, et al. </span><em class="italic"><span class="koboSpan" id="kobo.868.1">Learning spatiotemporal features with 3d convolutional networks</span></em><span class="koboSpan" id="kobo.869.1">. </span><span class="koboSpan" id="kobo.869.2">Proceedings of the IEEE international conference on computer </span><span class="No-Break"><span class="koboSpan" id="kobo.870.1">vision. </span><span class="koboSpan" id="kobo.870.2">2015.</span></span></li>
<li><span class="koboSpan" id="kobo.871.1">Carreira, Joao, and Andrew Zisserman. </span><em class="italic"><span class="koboSpan" id="kobo.872.1">Quo vadis, action recognition? </span><span class="koboSpan" id="kobo.872.2">a new model and the kinetics dataset</span></em><span class="koboSpan" id="kobo.873.1">. </span><span class="koboSpan" id="kobo.873.2">Proceedings of the IEEE Conference on Computer Vision and Pattern </span><span class="No-Break"><span class="koboSpan" id="kobo.874.1">Recognition. </span><span class="koboSpan" id="kobo.874.2">2017.</span></span></li>
<li><span class="koboSpan" id="kobo.875.1">Feichtenhofer, Christoph, et al. </span><em class="italic"><span class="koboSpan" id="kobo.876.1">Slowfast networks for video recognition</span></em><span class="koboSpan" id="kobo.877.1">. </span><span class="koboSpan" id="kobo.877.2">Proceedings of the IEEE/CVF international conference on computer </span><span class="No-Break"><span class="koboSpan" id="kobo.878.1">vision. </span><span class="koboSpan" id="kobo.878.2">2019.</span></span></li>
<li><span class="koboSpan" id="kobo.879.1">LeCun, Yann, et al. </span><em class="italic"><span class="koboSpan" id="kobo.880.1">Handwritten digit recognition with a back-propagation network</span></em><span class="koboSpan" id="kobo.881.1">. </span><span class="koboSpan" id="kobo.881.2">Advances in neural information processing systems </span><span class="No-Break"><span class="koboSpan" id="kobo.882.1">2 (1989).</span></span></li>
<li><span class="koboSpan" id="kobo.883.1">Vaswani, Ashish, et al. </span><em class="italic"><span class="koboSpan" id="kobo.884.1">Attention is all you need</span></em><span class="koboSpan" id="kobo.885.1">. </span><span class="koboSpan" id="kobo.885.2">Advances in neural information processing systems </span><span class="No-Break"><span class="koboSpan" id="kobo.886.1">30 (2017).</span></span></li>
<li><span class="koboSpan" id="kobo.887.1">Devlin, Jacob, et al. </span><em class="italic"><span class="koboSpan" id="kobo.888.1">Bert: Pre-training of deep bidirectional transformers for language understanding</span></em><span class="koboSpan" id="kobo.889.1">. </span><span class="koboSpan" id="kobo.889.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.890.1">arXiv:1810.04805 (2018).</span></span></li>
<li><span class="koboSpan" id="kobo.891.1">Touvron, Hugo, et al. </span><em class="italic"><span class="koboSpan" id="kobo.892.1">Llama: Open and efficient foundation language models</span></em><span class="koboSpan" id="kobo.893.1">. </span><span class="koboSpan" id="kobo.893.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.894.1">arXiv:2302.13971 (2023).</span></span></li>
<li><span class="koboSpan" id="kobo.895.1">Li, Yikuan, et al. </span><em class="italic"><span class="koboSpan" id="kobo.896.1">BEHRT: transformer for electronic health records</span></em><span class="koboSpan" id="kobo.897.1">. </span><span class="koboSpan" id="kobo.897.2">Scientific reports 10.1 (</span><span class="No-Break"><span class="koboSpan" id="kobo.898.1">2020): 1-12.</span></span></li>
<li><span class="koboSpan" id="kobo.899.1">Jumper, John, et al. </span><em class="italic"><span class="koboSpan" id="kobo.900.1">Highly accurate protein structure prediction with AlphaFold</span></em><span class="koboSpan" id="kobo.901.1">. </span><span class="koboSpan" id="kobo.901.2">Nature 596.7873 (</span><span class="No-Break"><span class="koboSpan" id="kobo.902.1">2021): 583-589.</span></span></li>
<li><span class="koboSpan" id="kobo.903.1">Xu, Jiehui, et al. </span><em class="italic"><span class="koboSpan" id="kobo.904.1">Anomaly transformer: Time series anomaly detection with association discrepancy</span></em><span class="koboSpan" id="kobo.905.1">. </span><span class="koboSpan" id="kobo.905.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.906.1">arXiv:2110.02642 (2021).</span></span></li>
<li><span class="koboSpan" id="kobo.907.1">Yuan, Li, et al. </span><em class="italic"><span class="koboSpan" id="kobo.908.1">Tokens-to-token vit: Training vision transformers from scratch on imagenet</span></em><span class="koboSpan" id="kobo.909.1">. </span><span class="koboSpan" id="kobo.909.2">Proceedings of the IEEE/CVF international conference on computer </span><span class="No-Break"><span class="koboSpan" id="kobo.910.1">vision. </span><span class="koboSpan" id="kobo.910.2">2021.</span></span></li>
<li><span class="koboSpan" id="kobo.911.1">Liu, Yinhan, et al. </span><em class="italic"><span class="koboSpan" id="kobo.912.1">Roberta: A robustly optimized bert pretraining approach</span></em><span class="koboSpan" id="kobo.913.1">. </span><span class="koboSpan" id="kobo.913.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.914.1">arXiv:1907.11692 (2019).</span></span></li>
<li><span class="koboSpan" id="kobo.915.1">Lewis, Mike, et al. </span><em class="italic"><span class="koboSpan" id="kobo.916.1">Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</span></em><span class="koboSpan" id="kobo.917.1">. </span><span class="koboSpan" id="kobo.917.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.918.1">arXiv:1910.13461 (2019).</span></span></li>
<li><span class="koboSpan" id="kobo.919.1">Radford, Alec, et al. </span><em class="italic"><span class="koboSpan" id="kobo.920.1">Improving language understanding by generative </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.921.1">pre-training</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.922.1">. </span><span class="koboSpan" id="kobo.922.2">(2018).</span></span></li>
<li><span class="koboSpan" id="kobo.923.1">Raffel, Colin, et al. </span><em class="italic"><span class="koboSpan" id="kobo.924.1">Exploring the limits of transfer learning with a unified text-to-text transformer</span></em><span class="koboSpan" id="kobo.925.1">. </span><span class="koboSpan" id="kobo.925.2">The Journal of Machine Learning Research 21.1 (</span><span class="No-Break"><span class="koboSpan" id="kobo.926.1">2020): 5485-5551.</span></span></li>
<li><span class="koboSpan" id="kobo.927.1">Sanh, Victor, et al. </span><em class="italic"><span class="koboSpan" id="kobo.928.1">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</span></em><span class="koboSpan" id="kobo.929.1">. </span><span class="koboSpan" id="kobo.929.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.930.1">arXiv:1910.01108 (2019).</span></span></li>
<li><span class="koboSpan" id="kobo.931.1">Yang, Zhilin, et al. </span><em class="italic"><span class="koboSpan" id="kobo.932.1">Xlnet: Generalized autoregressive pretraining for language understanding</span></em><span class="koboSpan" id="kobo.933.1">. </span><span class="koboSpan" id="kobo.933.2">Advances in neural information processing systems </span><span class="No-Break"><span class="koboSpan" id="kobo.934.1">32 (2019).</span></span></li>
<li><span class="koboSpan" id="kobo.935.1">Mikolov, Tomas, et al. </span><em class="italic"><span class="koboSpan" id="kobo.936.1">Efficient estimation of word representations in vector space</span></em><span class="koboSpan" id="kobo.937.1">. </span><span class="koboSpan" id="kobo.937.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.938.1">arXiv:1301.3781 (2013).</span></span></li>
<li><span class="koboSpan" id="kobo.939.1">Pennington, Jeffrey, Richard Socher, and Christopher D. </span><span class="koboSpan" id="kobo.939.2">Manning. </span><em class="italic"><span class="koboSpan" id="kobo.940.1">Glove: Global vectors for word representation</span></em><span class="koboSpan" id="kobo.941.1">. </span><span class="koboSpan" id="kobo.941.2">Proceedings of the 2014 conference on empirical methods in natural language processing (</span><span class="No-Break"><span class="koboSpan" id="kobo.942.1">EMNLP). </span><span class="koboSpan" id="kobo.942.2">2014.</span></span></li>
<li><span class="koboSpan" id="kobo.943.1">Bojanowski, Piotr, et al. </span><em class="italic"><span class="koboSpan" id="kobo.944.1">Enriching word vectors with subword information</span></em><span class="koboSpan" id="kobo.945.1">. </span><span class="koboSpan" id="kobo.945.2">Transactions of the association for computational linguistics 5 (</span><span class="No-Break"><span class="koboSpan" id="kobo.946.1">2017): 135-146.</span></span></li>
<li><span class="koboSpan" id="kobo.947.1">Wu, Zonghan, et al. </span><em class="italic"><span class="koboSpan" id="kobo.948.1">A comprehensive survey on graph neural networks</span></em><span class="koboSpan" id="kobo.949.1">. </span><span class="koboSpan" id="kobo.949.2">IEEE transactions on neural networks and learning systems 32.1 (</span><span class="No-Break"><span class="koboSpan" id="kobo.950.1">2020): 4-24.</span></span></li>
<li><span class="koboSpan" id="kobo.951.1">Abdollahi, Nasim, et al. </span><em class="italic"><span class="koboSpan" id="kobo.952.1">NodeCoder: a graph-based machine learning platform to predict active sites of modeled protein structures</span></em><span class="koboSpan" id="kobo.953.1">. </span><span class="koboSpan" id="kobo.953.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.954.1">arXiv:2302.03590 (2023).</span></span></li>
<li><span class="koboSpan" id="kobo.955.1">Kipf, Thomas N., and Max Welling. </span><em class="italic"><span class="koboSpan" id="kobo.956.1">Semi-supervised classification with graph convolutional networks</span></em><span class="koboSpan" id="kobo.957.1">. </span><span class="koboSpan" id="kobo.957.2">arXiv preprint </span><span class="No-Break"><span class="koboSpan" id="kobo.958.1">arXiv:1609.02907 (2016).</span></span></li>
<li><span class="koboSpan" id="kobo.959.1">Hamilton, Will, Zhitao Ying, and Jure Leskovec. </span><em class="italic"><span class="koboSpan" id="kobo.960.1">Inductive representation learning on large graphs</span></em><span class="koboSpan" id="kobo.961.1">. </span><span class="koboSpan" id="kobo.961.2">Advances in neural information processing systems </span><span class="No-Break"><span class="koboSpan" id="kobo.962.1">30 (2017).</span></span></li>
<li><span class="koboSpan" id="kobo.963.1">Velickovic, Petar, et al. </span><em class="italic"><span class="koboSpan" id="kobo.964.1">Graph attention networks</span></em><span class="koboSpan" id="kobo.965.1">. </span><span class="koboSpan" id="kobo.965.2">stat 1050.20 (</span><span class="No-Break"><span class="koboSpan" id="kobo.966.1">2017): 10-48550.</span></span></li>
<li><span class="koboSpan" id="kobo.967.1">Gilmer, Justin, et al. </span><em class="italic"><span class="koboSpan" id="kobo.968.1">Neural message passing for quantum chemistry</span></em><span class="koboSpan" id="kobo.969.1">. </span><span class="koboSpan" id="kobo.969.2">International conference on machine learning. </span><span class="No-Break"><span class="koboSpan" id="kobo.970.1">PMLR, 2017.</span></span></li>
<li><span class="koboSpan" id="kobo.971.1">Yang, Zhilin, William Cohen, and Ruslan Salakhudinov. </span><em class="italic"><span class="koboSpan" id="kobo.972.1">Revisiting semi-supervised learning with graph embeddings</span></em><span class="koboSpan" id="kobo.973.1">. </span><span class="koboSpan" id="kobo.973.2">International conference on machine learning. </span><span class="No-Break"><span class="koboSpan" id="kobo.974.1">PMLR, 2016.</span></span></li>
</ul>
</div>
</body></html>