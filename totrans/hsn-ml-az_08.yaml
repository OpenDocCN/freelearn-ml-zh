- en: HDInsight
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HDInsight is a type of implementation of Hadoop that runs on the Microsoft Azure
    platform. HDInsight builds on the **Hortonworks Data Platform** (**HDP**), and
    is completely compatible with Apache Hadoop.
  prefs: []
  type: TYPE_NORMAL
- en: HDInsight can be perceived as Microsoft's **Hadoop-as-a-Service** (**Haas**). You
    can quickly deploy the system from a portal or through Windows PowerShell scripting,
    without having to create any physical or virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are features of HDInsights:'
  prefs: []
  type: TYPE_NORMAL
- en: You can implement a small or large number of nodes in a cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You pay only for what you use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When your job is complete, you can deprovision the cluster and, of course, stop
    paying for it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use Microsoft Azure Storage so that even when the cluster is deprovisioned,
    you can retain the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The HDInsight service works with input-output technologies from Microsoft and
    other vendors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As mentioned, the HDInsight service runs on Microsoft Azure, and that requires
    a little explaining before we proceed further.
  prefs: []
  type: TYPE_NORMAL
- en: Data is described as 'big data' to indicate that it is being collected in ever-escalating
    volumes, at increasingly high velocities, and for a widening variety of unstructured
    formats and variable semantic contexts. Big data collection does not provide value
    to an enterprise on its own. For big data to provide value in the form of actionable
    intelligence or insight, it must be accessible, cleaned, analyzed, and then presented
    in a useful way, often in combination with data from various other sources.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Hadoop is a software framework that facilitates big data management and
    analysis. The core of Apache Hadoop provides reliable data storage with the **Hadoop
    Distributed File System** (**HDFS**), and a simple MapReduce programming model
    to process and analyze the data stored in this distributed system in parallel. HDFS
    uses data replication to address hardware failure issues that arise when deploying
    such highly distributed systems.
  prefs: []
  type: TYPE_NORMAL
- en: Windows Azure HDInsight makes Apache Hadoop available as a service in the cloud.
    It makes the HDFS or MapReduce software framework and related projects available
    in a simpler, more scalable, and cost-efficient environment. To simplify configuring
    and running Hadoop jobs, and managing the deployed clusters, Microsoft provides
    JavaScript, and Hive interactive consoles. This simplified JavaScript approach
    enables IT professionals and a wider group of developers to deal with big data
    management and analysis by providing a more accessible path into the Hadoop framework
    for them.
  prefs: []
  type: TYPE_NORMAL
- en: For data scientists who already use R, HDInsight offers a route into the cloud
    to empower big data analytics. For IT professionals and system administrators,
    it allows the administration of big data with straightforward management.
  prefs: []
  type: TYPE_NORMAL
- en: As in the previous chapters, we will use Microsoft's TDSP as a backdrop for
    producing machine learning models with HDInsight. Now, we will use R and HDInsight
    to analyze and model a sample dataset.
  prefs: []
  type: TYPE_NORMAL
- en: R with HDInsight
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are the main features of HDInsight? It is a Microsoft proprietary solution,
    but it is a 100% Apache Hadoop solution in the Microsoft Azure cloud. Azure HDInsight
    is a service that deploys and provisions Apache Hadoop clusters in the cloud for
    big data analytics.
  prefs: []
  type: TYPE_NORMAL
- en: HDInsight provides a software framework designed to manage, analyze, and report
    on big data. You can use HDInsight to perform interactive queries at petabyte
    scales over structured or unstructured data in any format. You can also build
    models, connecting them to BI tools. HDInsight is aimed at providing big data
    analytics and insights through Excel and Power BI. Azure's HDInsight service makes
    Apache Hadoop available as a service in the cloud, providing a software ...
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Azure HDInsight and ML services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'HDInsight has a number of cluster types, which include Hadoop (Hive), HBase,
    Storm, Spark, Kafka, Interactive Hive (LLAP), and ML Services (R Server) (with
    R Studio, R 9.1). Here is the ML Cluster configuration, which is established during setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b8410df7-c2b0-4306-a016-a43783599a02.png)'
  prefs: []
  type: TYPE_IMG
- en: Setup and configuration of HDInsight
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will set up and configure HDInsight. To set up and configure
    HDInsight, carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you have an Azure account
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log into the Azure portal at [portal.azure.com](https://portal.azure.com)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you are logged into the Azure portal, click on the button to add a new
    resource
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the search query box, type in `HDInsight` and you will be given a number
    of options
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the option that simply says HDInsight
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we will set up a basic configuration of HDInsight.
  prefs: []
  type: TYPE_NORMAL
- en: Basic configuration of HDInsight
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On the basic configuration item, you will need to enter in the name you wish
    to use for your Azure HDInsight, along with the storage options. Here is an example
    configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/891fe187-132f-42f1-a98e-3a4daff41bae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For Cluster type, ensure that you select the ML Services option. Here is an
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9384125a-c80c-4ad7-9c2d-55c07740284c.png)'
  prefs: []
  type: TYPE_IMG
- en: Storage options for Azure HDInsight
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the cluster type has been selected, the next step is to consider the storage.
    At the time of writing, there are two types of storage: default Azure Storage,
    and Azure Data Lake Storage Generation 1\. For this walk-through, the default
    Azure Storage will be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90e3ce6a-8f38-43ae-adfb-144cd84421c4.png)'
  prefs: []
  type: TYPE_IMG
- en: To finalize the creation of the HDInsight cluster, click on Next. Then check
    through the settings and click Create.
  prefs: []
  type: TYPE_NORMAL
- en: The HDInsight cluster will take approximately twenty minutes to set up.
  prefs: []
  type: TYPE_NORMAL
- en: 'When setup is complete, click on the Azure HDInsight cluster in the portal.
    Here is a screenshot of the portal:'
  prefs: []
  type: TYPE_NORMAL
- en: Here is a screenshot of the Azure HDInsight ...
  prefs: []
  type: TYPE_NORMAL
- en: Connect to the HDInsight cluster using SSH
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Azure Cloud Shell permits data scientists to access the HDInsight clusters
    using SSH. The Azure Cloud Shell can be found at the top navigation of the Azure
    portal, and it is denoted with an arrow sign. Here is a screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/116610d9-6ffd-47a4-98ea-e09b9001b748.png)'
  prefs: []
  type: TYPE_IMG
- en: Click on the Azure Cloud Shell icon in the Azure portal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select a subscription to create a storage account and Microsoft Azure Files
    share.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select Create storage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check that the environment dropdown on the left-hand side of the shell window
    says Bash. Now, you can log in using the `ssh` command. Here is a screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/19ce155e-cb82-4eeb-8a1f-6eef84ba93c4.png)'
  prefs: []
  type: TYPE_IMG
- en: Once you have logged in, you can then access Microsoft ML Services on the Azure
    HDInsight cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing Microsoft ML Services on Azure HDInsight
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the bash prompt, simply type in R to access Microsoft ML Services. Here
    is a screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9b2fe719-926b-41d7-abe4-96d361a48247.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To see the files on the HDInsight cluster, use the following RevoScaleR command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The files are then read into the DOS prompt box. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9465d23a-0e91-4cb9-afcd-c07601cd2f4f.png)'
  prefs: []
  type: TYPE_IMG
- en: Once the files are read out, we can start to work with some sample datasets
    in R. The Iris dataset will be used to explain the use of R in Microsoft ML Services
    in HDInsight.
  prefs: []
  type: TYPE_NORMAL
- en: Typing in the following command will reassure the data scientist ...
  prefs: []
  type: TYPE_NORMAL
- en: HDInsight and data analytics with R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Firstly, we need to get our data into Azure so that HDInsight can see it. We
    can upload data directly to Azure Storage, or we can use functionality in **SQL
    Server Integration Services** (**SSIS**). SSIS has the capability of connecting
    to Azure Blob Storage and Azure HDInsight. It enables you to create integration
    service packages that transfer data between an Azure Blob Storage and the on-premise
    data source. Then, the Azure HDInsight process can conduct processing on the data.
  prefs: []
  type: TYPE_NORMAL
- en: In order to get the data into HDInsight using SSIS, it's necessary to install
    the Azure Feature Pack. The Microsoft SSIS Feature Pack for Azure provides SQL
    Server Integration Services with the capability to connect to many Azure services,
    such as Azure Blob Storage, Azure Data Lake Store, Azure SQL Data Warehouse, and Azure
    HDInsight. It is a separate install, and you will need to ensure that the SQL
    server is installed before installing the Azure Feature Pack on a server. Otherwise,
    the components in the Feature Pack may not be available when you deploy packages
    to the SSIS catalog database.
  prefs: []
  type: TYPE_NORMAL
- en: To install the Microsoft SQL Server 2017 Integration Services Feature Pack for
    Azure, search for the Microsoft download page by using the term `Microsoft SQL
    Server 2017 Integration Services Feature Pack for Azure`. Then, download the file
    and run through the wizard.
  prefs: []
  type: TYPE_NORMAL
- en: How do Azure Data Factory and HDInsight interact?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is possible to move files or read and write data to Azure Blob storage. The
    benefit of using Azure Data Factory means that it is possible to extend existing
    ETL pipelines with cloud storage, or cloud-based SSIS execution through Azure
    VMs. It is possible to deploy SSIS packages in Azure Data Factory Version 2, which
    went to general availability release in July 2018\. It provides powerful functionality
    that facilitates data preparation for cloud compute services such as HDInsight
    and Microsoft ML Server. It can do a range of tasks, including data archival to
    cloud storage, and straightforward enumeration of files in blob storage.
  prefs: []
  type: TYPE_NORMAL
- en: There are specific HDInsight processing tasks in the Azure ...
  prefs: []
  type: TYPE_NORMAL
- en: Running queries on Azure HDInsight with ML Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In ML Services on HDInsight, the compute context specifies the physical location
    of the computational engine handling a given workload. The default is local, which
    means that it is running on your local machine. In order to make the most of running
    in the cloud, you will need to switch from local to remote.
  prefs: []
  type: TYPE_NORMAL
- en: 'R script runs within the R interpreter on that node, if it is run in the ML
    Services cluster on the edge node. If it calls a RevoScaleR function, then it
    is executed in a compute environment that is determined by how you set the RevoScaleR
    compute context. In this case, when you run your R script from an edge node, the
    possible values of the compute context are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: local sequential (*local*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: local parallel (*localpar*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MapReduce
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parallel offers the best performance. The local and localpar options both execute
    other `rx` function calls in a parallel manner across all available cores unless
    specified otherwise. To do this, the `rxOptions numCoresToUse` setting is used,
    and here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If the amount of data to analyze is small, and is a one-off or infrequent analysis,
    then it is recommended that you stream it directly into the analysis routine using
    local or localpar. If the amount of data to analyze is on a small or medium scale,
    and requires repeated or iterative analysis, then copy it to the local filesystem,
    import it to XDF, and analyze it via local or localpar.
  prefs: []
  type: TYPE_NORMAL
- en: RevoScaleR in Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: RevoScaleR is a set of powerful Microsoft proprietary functions that are used
    for practicing data science at scale. RevoScaleR gives extra power when conducting
    big data analyzes using R, such as data-related functions for import, transformation,
    manipulation, summarization, visualization, and analysis. Using R and HDInsight
    provides you with the capability to perform these tasks against very large datasets,
    in parallel and on distributed file systems. RevoScaleR uses external memory algorithms
    that allow it to work on one chunk of data at a time, updating results, and proceeding
    through all available data.
  prefs: []
  type: TYPE_NORMAL
- en: RevoScaleR functions are provided through the RevoScaleR package, which is available
    in Azure HDInsight ML Services.  ...
  prefs: []
  type: TYPE_NORMAL
- en: How can we read data into HDInsight using ML Services?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using RevoScaleR R default commands, we can read data with ML Services on HDInsight.
    These data types include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Reading data through **Open Database Connectivity** (**ODBC**) data sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading in files from other file systems, such as SAS, SPSS, ODBC, Teradata,
    delimited, and fixed format text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using an internal dataframe as a data source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing data from sources that cannot be read natively by R Server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RevoScaleR is also embedded in Azure HDInsight, Azure DSVMs, and SQL Server. RevoScaleR
    also includes an extensible framework for writing your own analyzes for big datasets.
  prefs: []
  type: TYPE_NORMAL
- en: The preferred data format is an XDF format. From there, we can do a number of
    analyzes with HDInsight and ML Services, using R.
  prefs: []
  type: TYPE_NORMAL
- en: What kind of analyzes can we do with R in ML Services on HDinsight?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can do summaries, cross-tabs, and create cubes, and conduct modelling such
    as decision trees and forests, as well as standard R work. To execute code, we
    will execute the Microsoft R server commands using RStudio. RStudio makes R easier
    to use. It includes a code editor, as well as debugging and visualization tools.
    In the following examples, the code exercises and images will be executed using
    RStudio. We will also use R Notebooks as a tidy way to execute code. An R Notebook
    is a document with code chunks that can be executed independently and interactively.
    As we will see throughout the exercises, the output is visible immediately beneath
    the input. We can visualize ...
  prefs: []
  type: TYPE_NORMAL
- en: Reading data from files into Azure HDInsight ML Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML Services can read almost all flat text files, such as SPSS, CSV, and TXT
    files.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example where we provide the path direction and read file directory
    from the given path to R:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also import the text file into R and then view the file to read it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'It is crucial to start by checking the location of the working directory in
    R. It is good practice to confirm your path. The command is executed using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`getwd()`'
  prefs: []
  type: TYPE_NORMAL
- en: In our example, the working directory is on the `D` drive, and it is the `Demo`
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'To read in a CSV file, we provide the path, and then we read the file path,
    which is directed toward a variable name. In this example here, the file will
    be stored in the variable called `SalesRecordsFile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will take the `SalesRecordsFile`variable and we will set it to a command
    to read in a CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: Once we execute the `SalesRecordsFile` command, then Microsoft ML Server will
    read in the `SalesRecordsFile.csv` file.
  prefs: []
  type: TYPE_NORMAL
- en: Converting text and CSV files to the preferred XDF format
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An XDF file is small in size and is compressed, as compared to CSV files. This
    means that an XDF file can be read and processed much faster than a CSV file.
    The flat file contains records that have no structured inter-relationship. XDF
    file formats can only be read by Microsoft ML Server. It is a very efficient way
    of storing, and querying data stored in flat files. These files are very small
    in size compared to other files, so they are analyzed quickly, and easily. RStudio
    can easily handle the task of converting our source text or CSV files into XDF
    format.
  prefs: []
  type: TYPE_NORMAL
- en: To convert the file, we can use the `rxImport` function, which loads data held
    in a flat file, such as a text file, to the preferred ...
  prefs: []
  type: TYPE_NORMAL
- en: Using the new XDF file in Microsoft ML Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We set the `SalesRecordsXDF` variable to hold the path of the inbound data,
    and to specify where the XDF file has to be written.
  prefs: []
  type: TYPE_NORMAL
- en: We can use the `print` command to find out more about the contents in the variable
    called `SalesRecordsXDF`. When we run the code, we can see the output, which details
    the number of rows processed and the location. If we want to see the content of
    the file, we can use the `rxGetInfo` command to provide us with some information.
    In this example, we are going to obtain the first five rows of data.
  prefs: []
  type: TYPE_NORMAL
- en: XDF versus flat text files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have looked at a CSV file and an XDF file, which one is better?
    XDF files can be read and processed so they are stored on the local disk. Microsoft
    R Server, with a call to `rxImport()`, will read an XDF file and decompress it,
    and then insert it into memory as a dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: The XDF file format is a Microsoft file format. This means it is important to
    check output and export functionality, because other programs will not be able
    to read it. The XDF file is aimed at supporting the set of analytical and data
    processing functions in the RevoScaleR package.
  prefs: []
  type: TYPE_NORMAL
- en: What is the advantage of the file size? For big data, this means the data can
    be as large as the available disk on the machine without putting any strains ...
  prefs: []
  type: TYPE_NORMAL
- en: Reading data from SQL Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To connect to SQL Server, there is a sequence of events that should be followed:'
  prefs: []
  type: TYPE_NORMAL
- en: Connect to Microsoft SQL Server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Retrieve data from Microsoft SQL Server
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connecting to a SQL Server database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Microsoft ML Services can also read data through **Open Database Connectivity
    (ODBC)**, which is a well-known and commonly accepted database access method. Initially,
    the connection string is set up, and it is assigned to a variable. In this example,
    the variable name holds the connection string. Here is the example code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Extracting data from a table retrieving data from Microsoft SQL Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once we have set up the connection string information, the next step is to
    set up a variable to hold the SQL command to retrieve the data. Here is an example
    piece of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Installing R packages on Microsoft ML Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is possible to use the same R code in Azure ML Studio, Microsoft ML Server,
    and in SQL Server machine learning services.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, the `rjson` package allows users to import the data using
    the `fromJSON()` function. If the `rjson` package is not installed on Microsoft
    ML Server, then you will need to install it. The instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the folder where the R tools are installed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click `RGui.exe`, and select Run as administrator. If you do not have
    the required permissions, contact the database administrator and provide a list
    of the packages you need.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'From the command line, if you know the package name, type: `install.packages("rjson")`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note that double quotation ...
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyzing and summarizing data in Microsoft ML Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can analyze and summarize our data using different types of statistics. Some
    statistics are more basic, and we start from using simple crosstabs. Then, we
    can move onto more complex statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Cross tabs and univariate statistics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Cross tabs offer a function that aids the exploration of survey data through
    simple tabulations of respondent counts and proportions, including the ability
    to specify the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A frequency count or a row/column/joint/total table proportion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple row and column variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All margins, only grand margins, or no margins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To create crosstabs, the `rxCrossTabs()` function is used. `rxCrossTabs()`
    is also used to compute sums according to combinations of different variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `rxCrossTabs` function uses a formula containing the variables that you
    want to cross tabulate. It also has a reference to the data, which refers to the
    dataset in which you want to look for variables ...
  prefs: []
  type: TYPE_NORMAL
- en: Working with cubes of data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One important feature of analysis is the aggregation of data. In Microsoft ML
    Server, the `rxCube()` function is used when we want to aggregate data for further
    analysis within R.
  prefs: []
  type: TYPE_NORMAL
- en: '`rxCube()` performs a very similar function to `rxCrossTabs()`. `rxCube()`
    helps with the analysis by computing metrics such as tabulated sums or means.
    `rxCube()` produces the sums or means in long format rather than a table. Example
    syntax for `rxCube` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The code shows that `rxCube` requires a formula containing the variables to
    cross-tabulate. It differs from `rxCrossTabs()` in the default value of the means
    argument (true for `rxCube()`; false for `rxCrossTabs()`). As with `rxCrossTabs`,
    the data item refers to the dataset in which you want to look for variables specified
    in the formula. Here is an example piece of code, using the Iris dataset, as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to clarify its use, the following demonstrates a sample output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/54569ef2-d1fb-410e-8809-8db46d43934c.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we have seen how to do some preliminary analysis, we can further investigate
    the data by doing some grouping.
  prefs: []
  type: TYPE_NORMAL
- en: Grouping data using Microsoft ML Server and R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Business Intelligence and analytics, many data operations are completed on
    grouped data, defined by variables. In Microsoft ML Services, there is an additional
    enhanced R formula, called `rxSummary`, which summarizes data, which is a good
    starting point when investigating data. `rxSummary` works by computing summary
    statistics that include a variable mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of the output using `rxSummary` and the Iris dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/85e658c8-f540-4daa-b5d9-17f951e0e43c.png)'
  prefs: []
  type: TYPE_IMG
- en: The summary focuses on one of the columns, `Petal.Length`. It produces the same
    information that we expect from the `summary` command in R.
  prefs: []
  type: TYPE_NORMAL
- en: Computing quantiles with R in Microsoft ML Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Microsoft ML Server, the `rxQuantile` function is used to quickly compute
    approximate quantiles. Note that this computation doesn''t include any type of
    sorting. The following piece of code uses `rxQuantile` on the petal length of
    the Iris dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9d9ad502-4eba-4dfd-a55f-fcaea487385a.png)'
  prefs: []
  type: TYPE_IMG
- en: The quantile calculation provides the quantiles for the data and prints it out.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression in Microsoft ML Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Logistic regression is a standard tool for modeling data with a binary response
    variable. In R, you fit a logistic regression using the `glm` function, specifying
    a binomial family and the logit link function. In Microsoft ML Services, `rxGlm`
    is used for the same purpose, and in the same way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can type in the variable name in order to see the result. Here is
    a screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c64dfca-cb72-4451-aa87-5dcf602aec68.png)'
  prefs: []
  type: TYPE_IMG
- en: To interpret the coefficients better, we can transform them back to the original
    scale of the dependent variable. To do this, we execute the ...
  prefs: []
  type: TYPE_NORMAL
- en: Predicting values with the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If the input dataset is the same as the dataset used to fit the `rxLinMod`
    object, the resulting predictions are the fitted values for the model. If the
    input dataset is a different dataset, the resulting predictions are true predictions
    of the response for the new data from the original model. As you can see from
    the following example, the residuals for the predicted values can be obtained
    by setting the `computeResiduals` flag to `TRUE`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we use `rxPredict` to obtain the fitted values, prediction standard errors,
    and confidence intervals. By setting `writeModelVars` to `TRUE`, the variables
    used in the model will also be included in the output dataset. Sample output is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aa69a101-6000-4b50-95dc-db782aa60805.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can view the summary of the `irisGLM` model here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e45b9e4-085e-40ee-9ce1-34038a19ebec.png)'
  prefs: []
  type: TYPE_IMG
- en: The output shows that these are highly significant p-values, which means that
    the model looks like a good fit.
  prefs: []
  type: TYPE_NORMAL
- en: However, we can check that the model is sound by looking at the ratio between
    the residual deviance and the residual degrees of freedom, which is 10.2/147,
    giving us a result of 0.06\. This means that the model is quite under-dispersed.
    Another option is to redo the `irisGLM` model using a binomial instead of a gamma
    family.
  prefs: []
  type: TYPE_NORMAL
- en: In order to understand the data better, it is possible to visualize it using
    default R and custom functionality in Microsoft ML Services.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microsoft ML Services has facilities for producing graphs using R as the visualization
    engine. It is possible for you to provide a variety of charts and dashboards that
    represent both univariate and multivariate numerical and categorical data in a
    straightforward manner.
  prefs: []
  type: TYPE_NORMAL
- en: Creating histograms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`rxHistogram()` is used to create a histogram for the data. Here is an example
    of the syntax for the Iris dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: You can see in the formula that the simplest case is a formula with only a single
    variable to the right-hand side of the `~`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, the Iris dataset is the data used here, and this is the part of
    the formula in which you want to specify the dataset you are using. Here is an
    example of the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/527c2aa1-837e-4677-a1fe-88899ee27a45.png)'
  prefs: []
  type: TYPE_IMG
- en: It is very simple to create a histogram with a single line of code.
  prefs: []
  type: TYPE_NORMAL
- en: Creating line plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A histogram is only one way of visualizing the data. Another example is the
    `rxLinePlot` example, which creates the line of a scatter plot using data. For
    this function, this formula should have one variable on the left-hand side of
    the `~` that reflects the *y* axis, and one variable on the right-hand side of
    the `~` that reflects the *x* axis. Here is an example of the line plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1118ee8a-a9d4-4256-83db-d9f138264321.png)'
  prefs: []
  type: TYPE_IMG
- en: We can also transform subsets of data using other features and functionality
    in Microsoft ML Services, and then revisualize the data.
  prefs: []
  type: TYPE_NORMAL
- en: Once we can see and understand our data, we can enrich it further by using additional
    Microsoft ML Services functionalities. ...
  prefs: []
  type: TYPE_NORMAL
- en: Enriching data for analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With big data solutions, sometimes the data needs to be transformed and processed
    into smaller chunks due to its sheer size. In order to deal with this problem,
    Microsoft have introduced some functionality to help. This section will cover
    the features that are designed to assist with big data issues.
  prefs: []
  type: TYPE_NORMAL
- en: rxDataSteps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `rxDataStep` function can be used to process data in chunks. It is one of
    the important data transformation functions in Microsoft ML Services.
  prefs: []
  type: TYPE_NORMAL
- en: The `rxDataStep` function can be used to create and transform subsets of data.
    The `rxDataStep` function processes data one chunk at a time, reading from one
    data source and writing to another. `rxDataStep` allows you to modify existing
    columns or add new columns to the data. It can also enrich analysis by working
    with your columns and rows, and by filtering and excluding them before working
    with the data further.
  prefs: []
  type: TYPE_NORMAL
- en: 'A common use of `rxDataStep` is to create a new dataset with a subset of rows
    and variables, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the previous piece ...
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have examined the machine learning process for Microsoft
    ML Services on HDInsight. We have reviewed how to ingest data, how to clean it,
    how to model it, and how to visualize it.
  prefs: []
  type: TYPE_NORMAL
- en: The final step is to ensure that HDInsight is torn down when you have stopped
    using it. HDInsight is charged by the minute and it will cost you money to leave
    it running. It is recommended that you save code and tear everything down when
    you no longer need it.
  prefs: []
  type: TYPE_NORMAL
- en: If you are simply wanting to run code and learn how to use Microsoft ML Services,
    the previous code samples will also work on Microsoft ML Server in Visual Studio
    on the DSVM.
  prefs: []
  type: TYPE_NORMAL
