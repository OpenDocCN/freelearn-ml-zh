<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Mobile Application Using Google Vision</h1>
                </header>
            
            <article>
                
<p>As we saw in <a href="51fcaf51-eb68-4493-afc2-0b02f1c1d50e.xhtml" target="_blank">Chapter 1</a>, <em>Introduction to Machine Learning on Mobile,</em> we know that machine learning in mobile applications can be implemented either on-device or it can be implemented using machine learning cloud provider services. There are various machine learning cloud providers:</p>
<ul>
<li>Clarifai</li>
<li>Google Cloud Vision</li>
<li>Microsoft Azure Cognitive Services</li>
<li>IBM Watson</li>
<li>Amazon Machine Learning</li>
</ul>
<p>In this chapter, we are going to dive deeply into Google Cloud Vision to understand the following:</p>
<ul>
<li>Features of Google Cloud Vision</li>
<li>How to utilize the Google Cloud Vision label-detection technique in an Android Mobile application to determine what is the picture taken by the camera. That is, we basically feed an image into Google Cloud Vision and see how it labels the image. Google Vision is going to predict the image that it receives from the mobile application and provide a label for the image. </li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Features of Google Cloud Vision</h1>
                </header>
            
            <article>
                
<p><span>Google Cloud Vision API comprises various complex and powerful machine learning models that help to perform image analysis. It classifies images into various categories using an easy-to-use REST API. </span><span>The important features provided by Google Cloud Vision include the following:</span></p>
<ul>
<li><span><strong>Label detection</strong>: This enables us to classify images into thousands of categories. The images can be categorized into various common category labels, such as <em>animals</em> and <em>fruits</em>.</span></li>
<li><span><strong>Image attribute detection</strong>: This enables us to detect individual objects from within images. It can also detect attributes such as prominent color.</span></li>
<li><span><strong>Face detection</strong>: This enables us to detect faces from within images. If there are multiple faces in the images, each can be detected individually. It can also detect the prominent attributes associated with a face, such as wearing a helmet.</span></li>
<li><span><strong>Logo detection</strong>: This enables us to detect printed words from images. Prominent logos are trained which can be detected.</span></li>
<li><strong>Landmark detection</strong>: It is trained to detect prominent landmarks <span>–</span> natural and man-made<span>–</span><span>so</span> these are detected through Google Vision.</li>
<li><strong><span>Optical character recognition</span></strong><span>:</span><span> </span><span>This helps to detect the text within images even if they aren't in English. This supports a wide range of languages.</span></li>
<li><span><strong>Explicit content detection</strong>: This helps to identify the type of content or sentiment of the content, such as <em>violent</em> or <em>humorous</em>. </span><span>It enables us to perform sentiment analysis of images by leveraging the metadata information that can be built.</span></li>
<li><span><strong>Search web</strong>: This searches the web for similar images.</span></li>
</ul>
<p>All these features provided by Google Cloud Vision can be used by invoking simple RESTful APIs provided by Google. However, for their use, there is a price attached to using each feature. A combination of features can also be used. The pricing details can be found on the Google Cloud Vision website:<span> </span><a href="https://cloud.google.com/vision/">https://cloud.google.com/vision/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sample mobile application using Google Cloud Vision</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to try a sample Android mobile application using Google Cloud Vision. We are going to capture an image from the camera of the cell phone, upload the image to Google Cloud Vision, and see what it predicts the image to be. This is going to use the label detection feature of Google Cloud Vision, which determines the label of the uploaded image.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How does label detection work?</h1>
                </header>
            
            <article>
                
<p>The Vision API can detect and extract information about entities within an image, across a broad group of categories. Labels can identify objects, locations, activities, animal species, products, and more. Labels are returned in English only.</p>
<p>The image whose label is to be determined and the features of the Google Vision that we intend to use needs to be sent in the request API. The feature can be any of the features listed in the <em>Features of Google Cloud Vision</em> section, such as label detection or logo detection. If there is any additional image context that needs to be sent across along with the image, it can be sent as an additional parameter. The request API JSON format is provided here:</p>
<pre>{<br/>  "image": {<br/>    object(Image)// Image which needs to be processed.<br/>  },<br/>  "features": [<br/>    {<br/>      object(Feature) //Google Vision Feature that needs to be invoked.<br/>    }<br/>  ],<br/>  "imageContext": {<br/>    object(ImageContext) //additional image context if required.<br/>  },<br/>}</pre>
<p>The image object can be a base64-encoded string or it can be a URL of the image that needs to be analyzed. The URL can be a <span>Google Cloud Storage image location, or a publicly accessible image URL.</span></p>
<p>The response for the request is going to be a list of annotations based on the features requested. In our case, it is going to be label annotations:</p>
<pre>{<br/> "labelAnnotations": [<br/> {<br/> object(EntityAnnotation)<br/> }<br/> ],<br/> "error": {<br/> object(Status)<br/> },<br/>}</pre>
<p>The returned <kbd>EntityAnnotation</kbd> object is going to contain the label of the image, the prediction score, and other useful information. All labels that match the input image object are returned as an array list with the prediction score, based on which we could perform the required inference needed in our application.</p>
<p>Now that we understand the basics of how label detection works, let's start creating the Android application.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Prerequisites</h1>
                </header>
            
            <article>
                
<p>In order to get started start exploring the Google Vision and to write a program using the services exposed by Google vision, the following are required to be setup, so we can get our hands dirty:</p>
<ul>
<li>A Google Cloud Platform account</li>
<li>A Project on Google Cloud Console</li>
<li>The latest version of Android Studio</li>
<li>A mobile phone running Android 5.0 or higher</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparations</h1>
                </header>
            
            <article>
                
<p>This section gives details about the key activities we need to do before we can start using the Google Cloud Vision API from our mobile application:</p>
<ol>
<li>The Google Cloud Vision API should be enabled in the Google Cloud Console and an API key should be created that will be used in the mobile application code. Please perform the following steps to get the Cloud Vision API key:
<ol>
<li>Open<span> </span><a href="http://Google%20Cloud%20Vision">cloud.google.com/vision</a>.</li>
<li>Go to Console. If you do no have a trial account, it will ask you to create one and complete the process.</li>
<li>Enable billing so we get $300 free credit. Once we have the account, we can go to Console and complete the process of creating the key.</li>
<li>From the Console, create a project.</li>
<li>Open that project. Go to <span class="packt_screen">API services</span> | <span class="packt_screen">Library search for cloud vision API</span>.</li>
<li>Click on it and enable it.</li>
<li>Go to <span class="packt_screen">API Services</span> | <span class="packt_screen">Credentials</span>.</li>
<li>Go to <span class="packt_screen">Credentials</span> | <span class="packt_screen">API Key</span>.</li>
<li>Create the API key.</li>
<li>Copy the API key; this will be used in the mobile application code.</li>
</ol>
</li>
<li>Add the dependencies required in the mobile client application to use the Google Cloud Vision API. The Google API Client will be needed and hence this needs to be added to the client project. These will need to be specified in the Gradle build file. The sample Gradle file with the key dependencies is as follows:</li>
</ol>
<pre style="padding-left: 60px">dependencies {<br/> compile fileTree(include: ['*.jar'], dir: 'libs')<br/> testCompile 'junit:junit:4.12'<br/> compile 'com.android.support:appcompat-v7:27.0.2'<br/> compile 'com.android.support:design:27.0.2'<br/> compile 'com.google.api-client:google-api-client-android:1.23.0' exclude module: 'httpclient'<br/> compile 'com.google.http-client:google-http-client-gson:1.23.0' exclude module: 'httpclient'<br/> compile 'com.google.apis:google-api-services-vision:v1-rev369-1.23.0'<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the Application</h1>
                </header>
            
            <article>
                
<p>In this section, we will see the key flows of the source code to understand how the Google Vision API works from an Android mobile application.</p>
<p><span>The Vision </span><span>class represents the Google API Client for Cloud Vision. The</span> first step is to initialize the Vision class. We do it through the Builder, to which we specify the transport mechanism and the JSON factory to be used:</p>
<div>
<pre><span>Vision.Builder builder = </span><span>new</span><span> Vision.Builder(httpTransport, jsonFactory, null);</span><span> </span></pre>
<p><span>The next step is to assign the API key to the Vision Builder so it can start interacting with the cloud APIs. The key we have created is given here:</span></p>
<div>
<pre><span>VisionRequestInitializer requestInitializer =</span><span> </span><span>new</span><span> VisionRequestInitializer(CLOUD_VISION_API_KEY)<br/></span>builder.setVisionRequestInitializer(requestInitializer);</pre>
<p><span>The final step is to get the Vision instance through which the cloud APIs can be invoked:<br/></span></p>
<pre><span>Vision vision = builder.build();<br/></span></pre>
<p><span>Now we are going to capture a picture and send the picture to the cloud API to detect its label. The code to capture the picture through the camera is the usual Android stuff. The following code provides details on how the image is converted into a Vision Request for label detection:</span></p>
<div>
<pre><span>BatchAnnotateImagesRequest batchAnnotateImagesRequest =</span><span> </span><span>new</span><span> BatchAnnotateImagesRequest();<br/></span><span><br/>batchAnnotateImagesRequest.setRequests(</span><span>new</span><span> ArrayList&lt;AnnotateImageRequest&gt;() {{</span><span> AnnotateImageRequest annotateImageRequest = </span><span>new</span><span> AnnotateImageRequest();<br/></span><span> </span><span>// Add the image<br/></span><span> Image base64EncodedImage = </span><span>new</span><span> Image();<br/></span><span> </span><span>// Convert the bitmap to a JPEG<br/></span><span> </span><span>// Just in case it's a format that Android understands but Cloud Vision<br/></span><span> ByteArrayOutputStream byteArrayOutputStream = </span><span>new</span><span> ByteArrayOutputStream();</span><span> bitmap.compress(Bitmap.CompressFormat.JPEG, </span><span>90</span><span>, byteArrayOutputStream);<br/></span><span>byte</span><span>[] imageBytes = byteArrayOutputStream.toByteArray();<br/></span><span>// Base64 encode the JPEG<br/></span><span>base64EncodedImage.encodeContent(imageBytes);</span><span> annotateImageRequest.setImage(base64EncodedImage);<br/></span><span>// add the features we want<br/></span><span>annotateImageRequest.setFeatures(</span><span>new</span><span> ArrayList&lt;Feature&gt;() {{<br/></span><span>Feature labelDetection = </span><span>new</span><span> Feature();</span><span> labelDetection.setType(</span><span>"LABEL_DETECTION"</span><span>);</span><span> labelDetection.setMaxResults(MAX_LABEL_RESULTS);<br/></span><span>add(labelDetection);<br/></span><span>}});<br/></span><span>// Add the list of one thing to the request<br/></span><span>add(annotateImageRequest);<br/></span><span>}});<br/></span><span>Vision.Images.Annotate annotateRequest = </span><span> vision.images().annotate(batchAnnotateImagesRequest);</span></pre></div>
</div>
</div>
<p>Google Cloud Vision will be called as an <strong>async task</strong>. The response received from the API will be analyzed to provide data in user-readable format. The following code provides details of the response received from Google Vision:</p>
<div>
<pre><span> </span><span>//Formatting the response as a string<br/></span><span> </span><span>private</span><span> </span><span>static</span><span> String convertResponseToString(BatchAnnotateImagesResponse response) {<br/></span><span> StringBuilder message = </span><span>new</span><span> StringBuilder(</span><span>"I found these things:\n\n"</span><span>);</span><span> List&lt;EntityAnnotation&gt; labels = response.getResponses().get(</span><span>0</span><span>).getLabelAnnotations();<br/></span><span> </span><span>if</span><span> (labels != null) {<br/></span><span> </span><span>for</span><span> (EntityAnnotation label : labels) {<br/></span><span> message.append(String.format(Locale.US, </span><span>"%.3f: %s"</span><span>, label.getScore(), label.getDescription()));<br/></span><span> message.append(</span><span>"\n"</span><span>);<br/></span><span> }<br/></span><span> } </span><span>else</span><span> {<br/></span><span> message.append(</span><span>"nothing"</span><span>);<br/></span><span> }<br/></span><span> </span><span>return</span><span> message.toString();<br/></span><span> }<br/></span></pre></div>
<p><span>The labels returned for the image can be viewed by the user.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Output</h1>
                </header>
            
            <article>
                
<p>This section displays the Android application screen when a mobile phone has been captured and sent to the vision API. Possible labels are listed in the output screen:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/30a0c8ed-bd27-429a-a9a1-fb23cce4d065.png" style="width:19.33em;height:34.42em;"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we looked at how Google Cloud Vision works, and can how to invoke it from a mobile application without much effort. We saw how easy it is to make complex machine learning predictions without the hassles of model selection and training. In the next chapter, we will explore the future of machine learning in the field of mobile applications. </p>


            </article>

            
        </section>
    </body></html>