- en: Scala for Recommender System
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about different approaches for developing recommender
    systems. Then we will learn how to develop a book recommendation system. Technically,
    it will be a model-based recommendation engine based on **alternating least squares**
    (**ALS**) and matrix factorization algorithms. We will use Spark MLlib-based implementation
    of these algorithms in Scala. In a nutshell, we will learn the following topics
    throughout this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of recommendation systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarity-based recommender system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content-based recommender system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborative approaches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hybrid recommendation systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a model-based book recommendation system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Make sure Scala 2.11.x and Java 1.8.x are installed and configured on your machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code files of this chapters can be found on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter06](https://github.com/PacktPublishing/Machine-Learning-with-Scala-Quick-Start-Guide/tree/master/Chapter06)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://bit.ly/2UQTFHs](http://bit.ly/2UQTFHs)'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of recommendation systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A recommender system is an information filtering approach, which predicts the
    rating given by a user to an item. Then the item for which the predicted rating
    is high will be recommended to the user. Recommender systems are now being used
    more or less everywhere for recommending movies, music, news, books, research
    articles, products, videos, books, news, Facebook friends, restaurants, routes,
    search queries, social tags, products, collaborators, jokes, restaurants, garments,
    financial services, Twitter pages, Android/iOS apps, hotels, life insurance, and
    even partners, in online dating sites.
  prefs: []
  type: TYPE_NORMAL
- en: Types of recommender systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a couple of ways to develop recommendation engines that typically
    produce a list of recommendations, such as similarity-based, content-based, collaborative,
    and hybrid recommendation systems as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/93b9d48f-85a5-4b79-890a-02b006f94013.png)'
  prefs: []
  type: TYPE_IMG
- en: We will discuss the similarity-based, content-based, collaborative, and hybrid
    recommendation systems. Then based on their pros and cons, we will see a hands-on
    example showing how to develop a book recommendation system.
  prefs: []
  type: TYPE_NORMAL
- en: Similarity-based recommender systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two main types of similarity-based approaches: **user-user similarity** and **user-item
    similarity**. These can be used to build recommendation systems. To use a user-user
    item similarity approach, first construct a user-user similarity matrix. It will
    then pick items that are already liked by similar users and, finally, it recommends
    items for a specific user.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we want to develop a book recommender system: naturally, there will
    be many book users (readers) and a list of books. For the sake of brevity, let''s
    pick the following machine learning-related books as the representative ones for
    the readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/69c226c2-7250-47a8-8cb5-082aad603327.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then a user-user similarity based recommender system will recommend books based
    on a similarity measure using some similarity measure techniques. For example,
    the cosine similarity is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c323a530-2bcd-4011-bda4-da9331fdb21b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding equation, *A* and *B* represent two users. If the similarity
    threshold is greater than or equal to a defined threshold, users *A* and *B* will
    most likely have similar preferences:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f1ba9bfb-4880-4978-b3ea-84d2ba8c7696.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, user-user similarity based recommender systems are not robust. There
    are several reasons for that:'
  prefs: []
  type: TYPE_NORMAL
- en: User preferences and tastes usually change over time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are computationally very expensive because of the similarity calculation
    for so many cases from very sparse matrix calculation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amazon and YouTube have millions of subscribed users, so any user-user utility
    matrix that you created would be a very sparse one. One workaround is using item-item
    similarity, which also computes an item-item utility matrix, finding similar items
    and, finally, recommending similar items, just like in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/84c05ecb-de09-4eb0-9f9f-f0b3b82aaa71.png)'
  prefs: []
  type: TYPE_IMG
- en: This approach has one advantage over the user-user similarity approach, which
    is that usually the ratings on a given item do not change very significantly after
    an initial period. Let's take as an example the book *The Hundred Page Machine
    Learning Book*, which has already got a very good rating on Amazon even though
    it was released just a few months ago. So, even if over the next few months a
    few people give it lower ratings, its ratings would not change much after the
    initial period.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, this is also an assumption that the ratings will not change very
    significantly over time. However, this assumption works very well in cases where
    the number of users is much higher than the number of items.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based filtering approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Content-based filtering approaches are based on classical machine learning
    techniques such as classification or regression. This type of system learns how
    to represent an item (book) *I[j]* and a user *U[i]*. Then, a separate feature
    matrix for both *I[j]* and *U[i]* are created before combining them as a feature
    vector. Then the feature vector is fed into a classification or regression model
    for the training. This way, the ML model generates the label *L[ij]*, which is
    interestingly the corresponding rating given by the user *U[i]* on the item *I[j]*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ba7ca2d2-16e1-40ec-8d6c-3256f282ac04.png)'
  prefs: []
  type: TYPE_IMG
- en: A general warning is that the features should be created so they have direct
    impact on the rating (**Labels**). This means features should be as dependent
    as possible to avoid correlations.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The idea of collaborative filtering is that when we have many users who liked
    some items, then those items can be recommended to users who have not seen them
    yet. Suppose we have four readers and four books, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ee87495c-ed5a-4fae-89b7-875fdb402475.png)'
  prefs: []
  type: TYPE_IMG
- en: Also, imagine all of these users have bought item 1 (that is, **Predictive Analytics
    with TensorFlow**) and item 2 (that is, **Deep Learning with TensorFlow**). Now,
    suppose **User 4** has read items 1, 2, and 3 and say both **User 1** and **User
    2** have bought item 3 (that is, **Mastering Machine Learning Algorithms**). However,
    since **User 4** has not seen item 4 (that is, **Python Machine Learning**) yet,
    **User 3** can recommend it to him.
  prefs: []
  type: TYPE_NORMAL
- en: So, the basic assumption is that users who have recommended an item previously
    tend to give recommendations in the future, too. If this assumption does not hold
    any longer, then a collaborative filtering recommender system cannot be build.
    This is probably the reason collaborative filtering approaches suffer from cold
    start, scalability, and sparsity problems.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cold start**: Collaborative filtering approaches can get stuck and cannot
    make recommendation especially when a large amount of data about users is missing
    in the uer-item matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: The utility matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose we have a group of users who show a preference for a set of books. The
    higher a user''s preference for a book, the higher the rating would be, between
    1 and 10. Let''s try to understand the problem using a matrix, with rows representing
    users and columns representing books:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f2f5a4e2-cda6-43ec-bd76-c2075b7c81b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's assume that ratings range from 1 to 10, with 10 being the highest level
    of preference. Then, in the preceding table, a user (row 1) gives a rating of **7**
    for the first book (column 1) and rates the second book as a **6**. Also, there
    are many empty cells that indicate users have not given any ratings for those
    books.
  prefs: []
  type: TYPE_NORMAL
- en: This matrix is often called a user-item or utility matrix, where each row represents
    a user and each column represents an item (book), while a cell represents the
    corresponding rating given by the user to that item.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the utility matrix is *very sparse* because a large number of cells
    are empty. The reason is that we have so many items and it is almost impossible
    for a single user to give ratings to all of the items. Even if a user rates 10%
    of the items, the other 90% of the cells of this matrix will still be empty. These
    empty cells often represented by NaN, which means not a number, although in our
    example utility matrix we used **?**. This sparsity often creates computational
    complexity. Let me give you an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose there are 1 million users (*n*) and only 10,000 items (movies, *m*),
    which is *10,000,000 * 10,000* or *10^(11)*, a very large number. Now, even if
    a user has rated 10 books, this means that the total number of given ratings will
    be *10 * 1 million = 10⁷*. The sparsity of this matrix can be calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*S[m ]= Number of empty cells / Total number of cells = (10^(10 )- 10⁷)/10^(10) =
    0.9999*'
  prefs: []
  type: TYPE_NORMAL
- en: This means 99.99% of the cells will still be empty.
  prefs: []
  type: TYPE_NORMAL
- en: Model-based book recommendation system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will show how to develop a model-based book recommendation
    system with the Spark MLlib library. Books and the corresponding ratings were
    downloaded from this link: [http://www2.informatik.uni-freiburg.de/~cziegler/BX/](http://www2.informatik.uni-freiburg.de/~cziegler/BX/).
    There are three CSV files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`BX-Users.csv`: Contains user''s demographic data and each user is specified
    with user IDs (`User-ID`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BX-Books.csv`: Book related information such as `Book-Title`, `Book-Author`,
    `Year-Of-Publication`, and `Publisher` are there. Each book is identified by an
    ISBN. Also, `Image-URL-S`, `Image-URL-M`, and `Image-URL-L` are given.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BX-Book-Ratings.csv`: Contains the rating specified by the `Book-Rating` column.
    Ratings are on a scale from `1` to `10` (higher values denoting higher appreciation),
    or implicit, expressed by `0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we jump into the coding part, we need to know a bit more about the matrix
    factorization techniques such as **singular value decomposition** (**SVD**). SVD
    can be used to transform both the item and the user entries into the same potential
    space, which represents the interaction between users and items. The rationale
    behind matrix decomposition is that potential features represent how users score
    items.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix factorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, given the description of the users and the items, the task here is to predict
    how the user will rate those items that have not yet been rated. More formally,
    if a user *U[i]* likes item *V[1]*, *V[5]*, and *V[7]*,then the task is to recommend item *V[j]*
    touser *U[i]* that they will most probably like too as shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0b3f2bf8-844f-4507-84ab-348d3d4761b0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once we have such an application, the idea is that each time we receive new
    data, we update it to the training dataset and then update the model obtained
    by ALS training, where the collaborative filtering method is used. To handle the
    user-book utility matrix, a low-rank matrix factorization algorithm is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac9c10e4-2d13-4adf-b0d3-b2ca554b7793.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Since not all the books are rated by all the users, not all of the entries
    in this matrix are known. The collaborative filtering approach discussed in a
    preceding section comes to this party as the savior. Well, using collaborative
    filtering, we can solve an optimization problem to approximate the ratings matrix
    by factorizing **User factors (V)** and **Book factors (V)**, which can be depicted
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0a51be14-29cc-47b8-9d99-df5b82413cda.png)'
  prefs: []
  type: TYPE_IMG
- en: 'These two matrices are selected such that the error for the users-book pairs
    (in the case of known rating) gets minimized. The ALS algorithm first fills the
    user matrix with random values (between 1 and 10, in our case) and then optimizes
    those values such that the error is minimized. Then the ALS holds the book matrix
    as fixed and optimizes the value of the user''s matrix using the following mathematical
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac538922-4a7c-4f11-a300-a0753fda7574.png)'
  prefs: []
  type: TYPE_IMG
- en: Spark MLlib supports a model-based collaborative filtering approach. In such
    an approach, users and items are described by a small set of latent factors for
    predicting missing entries of a user-item utility matrix. As described earlier,
    the ALS algorithms can learn those latent factors in an iterative way. The ALS
    algorithm accepts six parameters, namely `numBlocks`, `rank`, `iterations`, `lambda`,
    `implicitPrefs`, and `alpha`. `numBlocks` is number of blocks required to parallelize
    the computation. The `rank` parameter is the number of latent factors. The `iterations` parameter
    is the number of iterations by which ALS will get converged. The `lambda` parameter
    signifies the regularization parameter. The `implicitPrefs` parameter means that
    we want to use explicit feedback from the other users, and, finally, `alpha` is
    the baseline confidence in preference observations.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this subsection, we will perform some exploratory analysis about the ratings,
    books, and related statistics. This analysis will help us understand the data
    well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code segments show you the DataFrame of books from the `BX-Books.csv`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b53d3eed-f4cf-4aef-aae8-c735fa8a3887.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see how many distinct books there are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This information will be valuable for a later case, so that we can know how
    many books are missing ratings in the rating dataset. To register both datasets,
    we can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This will help to make the in-memory querying faster by creating a temporary
    view as a in-memory table. Let''s check the ratings-related statistics. Just use
    the following code lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You should find `Got 1149780 ratings from 105283 users on 340556 books`. Now,
    let''s get the maximum and minimum ratings along with the count of users who have
    rated a book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code should generate the max and min ratings, along with the
    count of users who have rated a book:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6e045a60-3e6f-43a5-acb9-ba01529b0d7f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, to get further insight we need to know more about the users and their
    ratings, which can be done by finding the top ten most active users and how many
    times they have rated a book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding lines of code should show the top ten most active users and how
    many times they have rated a book:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/db26d027-5dc4-4dfa-bac8-2497f66622dd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now let''s have a look at a particular user, and find the books that, say,
    user `130554` rated higher than `5`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As described, the preceding line of code should show the name of all the movies
    rated by user 130554 giving more than 5 ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e0775743-029d-4fe2-a3ee-0f1de8052f07.png)'
  prefs: []
  type: TYPE_IMG
- en: Prepare training and test rating data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following code splits ratings RDD into training data RDD (60%) and test
    data RDD (40%). The second parameter (that is `1357L`) is the *seed*, which is
    typically used for the purpose of reproducibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see that there are 689,144 ratings in the training DataFrame and 345,774
    ratings in the test DataFrame. The ALS algorithm requires an RDD of ratings for
    the training. The following code illustrates the way to build the recommendation
    model using APIs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '`trainRatingsRDD` is an RDD of ratings that contains `UserID`, `ISBN`, and
    the corresponding ratings from the training dataset that we prepared in the preceding
    step. Similarly, we prepared another RDD from the test DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on the `trainRatingsRDD`, we build an ALS user model by adding the maximal
    iteration, a number of blocks, alpha, rank, lambda, seed, and implicit preferences.
    This method is generally used for analyzing and predicting missing ratings of
    specific users:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we iterated the model for learning `10` times. With this setting,
    we got good prediction accuracy. Readers are recommended to apply hyperparameter
    tuning to find the optimum values for these parameters. In order to evaluate the
    quality of the model, we compute the **root mean squared error** (**RMSE**). The
    following code calculates the RMSE value for the model that was developed with
    the help of the training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'For the preceding setting, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding method computes the RMSE to evaluate the model. The lower the
    RMSE, the better the model and its prediction capability is, which goes as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s do some movie recommendations for a specific user. Let''s get
    the top ten book predictions for user `276747`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We believe that the performance of the preceding model could be increased more.
    However, as far as we know, there is no model tuning facility available for the
    MLlib-based ALS algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Interested readers should refer to [https://spark.apache.org/docs/preview/ml-collaborative-filtering.html](https://spark.apache.org/docs/preview/ml-collaborative-filtering.html) for
    more on tuning the ML-based ALS models.
  prefs: []
  type: TYPE_NORMAL
- en: Adding new user ratings and making new predictions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can create a sequence of a new user ID, the ISBN of the book, and the rating
    predicted in the previous step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we add them to the data we will use to train our recommender model. We
    use Spark''s `union()` transformation for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we train the ALS model using all the parameters we selected before
    (when using the small dataset):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We will need to repeat that every time a user adds new ratings. Ideally, we
    will do this in batches, and not for every single rating that comes into the system
    for every user. Then we can again make recommendations for other users such as
    `276724`, whose ratings about books were missing previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we compute the RMSE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned different approaches for recommender systems,
    such as similarity-based, content-based, collaborative filtering, and hybrid.
    Additionally, we discussed the downsides of these approaches. Then we implemented
    an end-to-end book recommendation system, which is a model-based recommendation
    with Spark. We have also seen how to interoperate between ALS and matrix factorization
    to efficiently handle a utility matrix.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explain some basic concepts of **d****eep learning**
    (**DL**), which is one of the emerging branches of ML. We will briefly discuss
    some of the most well known and widely used neural network architectures. Then,
    we will look at various features of DL frameworks and libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Then we will see how to prepare a programming environment, before moving on
    to coding with some open source DL libraries, such as **Deeplearning4j** (**DL4J**). Finally, we
    will solve a real-life problem using two neural network architectures, called **multilayer
    perceptron** (**MLP**) and **long short-term memory** (**LSTM**).
  prefs: []
  type: TYPE_NORMAL
