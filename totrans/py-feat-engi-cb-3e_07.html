<html><head></head><body>
<div id="_idContainer137">
<h1 class="chapter-number" id="_idParaDest-194"><a id="_idTextAnchor873"/><span class="koboSpan" id="kobo.1.1" xmlns:="http://www.w3.org/1999/xhtml">7</span></h1>
<h1 id="_idParaDest-195"><a id="_idTextAnchor874"/><a id="_idTextAnchor875"/><span class="koboSpan" id="kobo.2.1" xmlns:="http://www.w3.org/1999/xhtml">Performing Feature Scaling</span></h1>
<p><span class="koboSpan" id="kobo.3.1" xmlns:="http://www.w3.org/1999/xhtml">Many machine learning algorithms are sensitive to the variable scale. </span><span class="koboSpan" id="kobo.3.2" xmlns:="http://www.w3.org/1999/xhtml">For example, the coefficients of linear models depend on the scale of the feature – that is, changing the feature scale will change the coefficient’s value. </span><span class="koboSpan" id="kobo.3.3" xmlns:="http://www.w3.org/1999/xhtml">In linear models, as well as in algorithms that depend on distance calculations such as clustering and principal component analysis, features with larger value ranges tend to dominate over features with smaller ranges. </span><span class="koboSpan" id="kobo.3.4" xmlns:="http://www.w3.org/1999/xhtml">Therefore, having features on a similar scale allows us to compare feature importance and may help algorithms converge faster, improving performance and </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1" xmlns:="http://www.w3.org/1999/xhtml">training times.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling techniques, in general, divide the variables by some constant; therefore, it is important to highlight that the shape of the variable distribution does not change when we rescale the variables. </span><span class="koboSpan" id="kobo.5.2" xmlns:="http://www.w3.org/1999/xhtml">If you want to change the distribution shape, check out </span><a href="B22396_03.xhtml#_idTextAnchor351"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.6.1" xmlns:="http://www.w3.org/1999/xhtml">Chapter 3</span></em></span></a><span class="koboSpan" id="kobo.7.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><em class="italic"><span class="koboSpan" id="kobo.8.1" xmlns:="http://www.w3.org/1999/xhtml">Transforming </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.9.1" xmlns:="http://www.w3.org/1999/xhtml">Numerical Variables</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.10.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.11.1" xmlns:="http://www.w3.org/1999/xhtml">In this chapter, we will describe different methods to set features on a </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1" xmlns:="http://www.w3.org/1999/xhtml">similar scale.</span></span></p>
<p><span class="koboSpan" id="kobo.13.1" xmlns:="http://www.w3.org/1999/xhtml">This chapter will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1" xmlns:="http://www.w3.org/1999/xhtml">following recipes:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.15.1" xmlns:="http://www.w3.org/1999/xhtml">Standardizing </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1" xmlns:="http://www.w3.org/1999/xhtml">the features</span></span></li>
<li><span class="koboSpan" id="kobo.17.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling to the maximum and </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1" xmlns:="http://www.w3.org/1999/xhtml">minimum values</span></span></li>
<li><span class="koboSpan" id="kobo.19.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling with the median </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1" xmlns:="http://www.w3.org/1999/xhtml">and quantiles</span></span></li>
<li><span class="koboSpan" id="kobo.21.1" xmlns:="http://www.w3.org/1999/xhtml">Performing </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1" xmlns:="http://www.w3.org/1999/xhtml">mean normalization</span></span></li>
<li><span class="koboSpan" id="kobo.23.1" xmlns:="http://www.w3.org/1999/xhtml">Implementing maximum </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1" xmlns:="http://www.w3.org/1999/xhtml">absolute scaling</span></span></li>
<li><a id="_idTextAnchor876"/><span class="koboSpan" id="kobo.25.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling to vector </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1" xmlns:="http://www.w3.org/1999/xhtml">unit length</span></span></li>
</ul>
<h1 id="_idParaDest-196"><a id="_idTextAnchor877"/><a id="_idTextAnchor878"/><span class="koboSpan" id="kobo.27.1" xmlns:="http://www.w3.org/1999/xhtml">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.28.1" xmlns:="http://www.w3.org/1999/xhtml">The main libraries that we use in this chapter are scikit-learn (</span><strong class="source-inline"><span class="koboSpan" id="kobo.29.1" xmlns:="http://www.w3.org/1999/xhtml">sklearn</span></strong><span class="koboSpan" id="kobo.30.1" xmlns:="http://www.w3.org/1999/xhtml">) for scaling, </span><strong class="source-inline"><span class="koboSpan" id="kobo.31.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.32.1" xmlns:="http://www.w3.org/1999/xhtml"> to handle the data, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.33.1" xmlns:="http://www.w3.org/1999/xhtml">matplotlib</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.34.1" xmlns:="http://www.w3.org/1999/xhtml">for plotting.</span></span></p>
<h1 id="_idParaDest-197"><a id="_idTextAnchor879"/><span class="koboSpan" id="kobo.35.1" xmlns:="http://www.w3.org/1999/xhtml">S</span><a id="_idTextAnchor880"/><span class="koboSpan" id="kobo.36.1" xmlns:="http://www.w3.org/1999/xhtml">tandardizing the features</span></h1>
<p><span class="koboSpan" id="kobo.37.1" xmlns:="http://www.w3.org/1999/xhtml">Standardization</span><a id="_idIndexMarker514"/><span class="koboSpan" id="kobo.38.1" xmlns:="http://www.w3.org/1999/xhtml"> is the process of centering the variable at </span><strong class="source-inline"><span class="koboSpan" id="kobo.39.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.40.1" xmlns:="http://www.w3.org/1999/xhtml"> and standardizing the variance to </span><strong class="source-inline"><span class="koboSpan" id="kobo.41.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.42.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.42.2" xmlns:="http://www.w3.org/1999/xhtml">To</span><a id="_idTextAnchor881"/><span class="koboSpan" id="kobo.43.1" xmlns:="http://www.w3.org/1999/xhtml"> standardize features, we subtract the mean from each observation and then divide the result by the </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1" xmlns:="http://www.w3.org/1999/xhtml">standard deviation:</span></span></p>
<p><span class="koboSpan" id="kobo.45.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/25.png" style="vertical-align:-0.675em;height:1.698em;width:7.146em"/></span></p>
<p><span class="koboSpan" id="kobo.46.1" xmlns:="http://www.w3.org/1999/xhtml">The result of the preceding transformation is called</span><a id="_idIndexMarker515"/><span class="koboSpan" id="kobo.47.1" xmlns:="http://www.w3.org/1999/xhtml"> the </span><strong class="bold"><span class="koboSpan" id="kobo.48.1" xmlns:="http://www.w3.org/1999/xhtml">z-score</span></strong><span class="koboSpan" id="kobo.49.1" xmlns:="http://www.w3.org/1999/xhtml"> and represents how many standard deviations a given observation </span><em class="italic"><span class="koboSpan" id="kobo.50.1" xmlns:="http://www.w3.org/1999/xhtml">deviates</span></em><span class="koboSpan" id="kobo.51.1" xmlns:="http://www.w3.org/1999/xhtml"> from </span><span class="No-Break"><span class="koboSpan" id="kobo.52.1" xmlns:="http://www.w3.org/1999/xhtml">the mean.</span></span></p>
<p><span class="koboSpan" id="kobo.53.1" xmlns:="http://www.w3.org/1999/xhtml">Standardization is generally useful when models require the variables to be centered at zero and data is not sparse (centering sparse data will destroy its sparse nature). </span><span class="koboSpan" id="kobo.53.2" xmlns:="http://www.w3.org/1999/xhtml">On the downside, standardization is sensitive to outliers and the z-score does not keep the symmetric properties if the variables are highly skewed, as we discuss in the </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1" xmlns:="http://www.w3.org/1999/xhtml">following section.</span></span></p>
<h2 id="_idParaDest-198"><a id="_idTextAnchor882"/><span class="koboSpan" id="kobo.55.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.56.1" xmlns:="http://www.w3.org/1999/xhtml">With standardization, the variable distribution does not change; what changes is the magnitude of their values, as we see in the </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1" xmlns:="http://www.w3.org/1999/xhtml">following figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer119">
<span class="koboSpan" id="kobo.58.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 7.1 – Distribution of a normal and skewed variable before and after standardization." src="image/B22396_07_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.59.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 7.1 – Distribution of a normal and skewed variable before and after standardization.</span></p>
<p><span class="koboSpan" id="kobo.60.1" xmlns:="http://www.w3.org/1999/xhtml">The z-score (</span><em class="italic"><span class="koboSpan" id="kobo.61.1" xmlns:="http://www.w3.org/1999/xhtml">x</span></em><span class="koboSpan" id="kobo.62.1" xmlns:="http://www.w3.org/1999/xhtml"> axis in the bottom panels) indicates</span><a id="_idIndexMarker516"/><span class="koboSpan" id="kobo.63.1" xmlns:="http://www.w3.org/1999/xhtml"> how many standard deviations an observation deviates from the mean. </span><span class="koboSpan" id="kobo.63.2" xmlns:="http://www.w3.org/1999/xhtml">When the z-score is </span><strong class="source-inline"><span class="koboSpan" id="kobo.64.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.65.1" xmlns:="http://www.w3.org/1999/xhtml">, the observation lies 1 standard deviation to the right of the mean, whereas when the z-score is </span><strong class="source-inline"><span class="koboSpan" id="kobo.66.1" xmlns:="http://www.w3.org/1999/xhtml">-1</span></strong><span class="koboSpan" id="kobo.67.1" xmlns:="http://www.w3.org/1999/xhtml">, the sample is 1 standard deviation to the left of </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1" xmlns:="http://www.w3.org/1999/xhtml">the mean.</span></span></p>
<p><span class="koboSpan" id="kobo.69.1" xmlns:="http://www.w3.org/1999/xhtml">In normally distributed variables, we can estimate the probability of a value being greater or smaller than a given z-score, and this probability distribution is symmetric. </span><span class="koboSpan" id="kobo.69.2" xmlns:="http://www.w3.org/1999/xhtml">The probability of an observation being smaller than a z-score of </span><strong class="source-inline"><span class="koboSpan" id="kobo.70.1" xmlns:="http://www.w3.org/1999/xhtml">-1</span></strong><span class="koboSpan" id="kobo.71.1" xmlns:="http://www.w3.org/1999/xhtml"> is equivalent to the probability of a value being greater than </span><strong class="source-inline"><span class="koboSpan" id="kobo.72.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.73.1" xmlns:="http://www.w3.org/1999/xhtml"> (horizontal line in the bottom-left panel). </span><span class="koboSpan" id="kobo.73.2" xmlns:="http://www.w3.org/1999/xhtml">This symmetry is fundamental to many statistical tests. </span><span class="koboSpan" id="kobo.73.3" xmlns:="http://www.w3.org/1999/xhtml">In skewed distributions, this symmetry does not hold. </span><span class="koboSpan" id="kobo.73.4" xmlns:="http://www.w3.org/1999/xhtml">As illustrated in the bottom-right panel of </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.74.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.75.1" xmlns:="http://www.w3.org/1999/xhtml">.1</span></em><span class="koboSpan" id="kobo.76.1" xmlns:="http://www.w3.org/1999/xhtml"> (horizontal lines), the probability of a value being smaller than </span><strong class="source-inline"><span class="koboSpan" id="kobo.77.1" xmlns:="http://www.w3.org/1999/xhtml">-1</span></strong><span class="koboSpan" id="kobo.78.1" xmlns:="http://www.w3.org/1999/xhtml"> is different from that of being greater </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1" xmlns:="http://www.w3.org/1999/xhtml">than </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.80.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.81.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.82.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.83.1" xmlns:="http://www.w3.org/1999/xhtml">The mean and the standard deviation are sensitive to outliers; therefore, the features may scale differently from each other in the presence of outliers when </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1" xmlns:="http://www.w3.org/1999/xhtml">using standardization.</span></span></p>
<p><span class="koboSpan" id="kobo.85.1" xmlns:="http://www.w3.org/1999/xhtml">In practice, we often apply standardization ignoring the shape of the distribution. </span><span class="koboSpan" id="kobo.85.2" xmlns:="http://www.w3.org/1999/xhtml">However, keep in mind that if the models or tests you are using make assumptions about the data’s distribution, you might benefit from transforming the variables before standardization, or trying a different </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1" xmlns:="http://www.w3.org/1999/xhtml">scaling metho</span><a id="_idTextAnchor883"/><a id="_idTextAnchor884"/><span class="koboSpan" id="kobo.87.1" xmlns:="http://www.w3.org/1999/xhtml">d.</span></span></p>
<h2 id="_idParaDest-199"><a id="_idTextAnchor885"/><span class="koboSpan" id="kobo.88.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.89.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we’ll apply </span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.90.1" xmlns:="http://www.w3.org/1999/xhtml">standardization to the variables of the California </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1" xmlns:="http://www.w3.org/1999/xhtml">housing dataset:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.92.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by importing the required Python packages, classes, </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1" xmlns:="http://www.w3.org/1999/xhtml">and functions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.94.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler</span></pre></li> <li><span class="koboSpan" id="kobo.95.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the California housing dataset from scikit-learn into a DataFrame and drop the </span><strong class="source-inline"><span class="koboSpan" id="kobo.96.1" xmlns:="http://www.w3.org/1999/xhtml">Latitude</span></strong><span class="koboSpan" id="kobo.97.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.98.1" xmlns:="http://www.w3.org/1999/xhtml">Longitude</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.99.1" xmlns:="http://www.w3.org/1999/xhtml"> variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.100.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)
X.drop(labels=["Latitude", "Longitude"], axis=1,
    inplace=True)</span></pre></li> <li><span class="koboSpan" id="kobo.101.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s divide the data into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.103.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.104.1" xmlns:="http://www.w3.org/1999/xhtml">Next, we’ll set up the </span><strong class="source-inline"><span class="koboSpan" id="kobo.105.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.106.1" xmlns:="http://www.w3.org/1999/xhtml"> function from scikit-learn and fit it</span><a id="_idTextAnchor886"/><span class="koboSpan" id="kobo.107.1" xmlns:="http://www.w3.org/1999/xhtml"> to the train set so that it learns each variable’s mean and </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1" xmlns:="http://www.w3.org/1999/xhtml">standard deviation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.109.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler = StandardScaler().set_output(
    transform="pandas")
scaler.fit(X_train)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.110.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.111.1" xmlns:="http://www.w3.org/1999/xhtml">Scikit-learn scalers, like any scikit-learn transformer, return NumPy arrays by default. </span><span class="koboSpan" id="kobo.111.2" xmlns:="http://www.w3.org/1999/xhtml">To return </span><strong class="source-inline"><span class="koboSpan" id="kobo.112.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.113.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.114.1" xmlns:="http://www.w3.org/1999/xhtml">polars</span></strong><span class="koboSpan" id="kobo.115.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrames, we need to specify the output container with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.116.1" xmlns:="http://www.w3.org/1999/xhtml">set_output()</span></strong><span class="koboSpan" id="kobo.117.1" xmlns:="http://www.w3.org/1999/xhtml"> method, as we did in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.118.1" xmlns:="http://www.w3.org/1999/xhtml">Step 4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.119.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.120.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s </span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.121.1" xmlns:="http://www.w3.org/1999/xhtml">standardize the train and test sets with the </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1" xmlns:="http://www.w3.org/1999/xhtml">trained scaler:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.123.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)</span></pre><p class="list-inset"><strong class="source-inline"><span class="koboSpan" id="kobo.124.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.125.1" xmlns:="http://www.w3.org/1999/xhtml"> stores the mean and standard deviation learned from the training set during </span><strong class="source-inline"><span class="koboSpan" id="kobo.126.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.127.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.127.2" xmlns:="http://www.w3.org/1999/xhtml">Let’s visualize the </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1" xmlns:="http://www.w3.org/1999/xhtml">learned parameters.</span></span></p></li> <li><span class="koboSpan" id="kobo.129.1" xmlns:="http://www.w3.org/1999/xhtml">First, we’ll print the mean values that were learned </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1" xmlns:="http://www.w3.org/1999/xhtml">by </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.131.1" xmlns:="http://www.w3.org/1999/xhtml">scaler</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.132.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.133.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler.mean_</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.134.1" xmlns:="http://www.w3.org/1999/xhtml">We see the mean values of each variable in the </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1" xmlns:="http://www.w3.org/1999/xhtml">following output:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.136.1" xmlns:="http://www.w3.org/1999/xhtml">array([3.86666741e+00, 2.86187016e+01, 5.42340368e+00,                 1.09477484e+00,1.42515732e+03, 3.04051776e+00])</span></strong></pre></li> <li><span class="koboSpan" id="kobo.137.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s print the standard deviation values that were learned </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1" xmlns:="http://www.w3.org/1999/xhtml">by </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.139.1" xmlns:="http://www.w3.org/1999/xhtml">scaler</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.140.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.141.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler.scale_</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.142.1" xmlns:="http://www.w3.org/1999/xhtml">We see the standard deviation of each variable in the </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1" xmlns:="http://www.w3.org/1999/xhtml">following output:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.144.1" xmlns:="http://www.w3.org/1999/xhtml">array([1.89109236e+00, 1.25962585e+01, 2.28754018e+00,                          4.52736275e-01, 1.14954037e+03, 6.86792905e+00])</span></strong></pre><p class="list-inset"><span class="koboSpan" id="kobo.145.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s compare the transformed data with the original data to understand </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1" xmlns:="http://www.w3.org/1999/xhtml">the changes.</span></span></p></li> <li><span class="koboSpan" id="kobo.147.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s print</span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.148.1" xmlns:="http://www.w3.org/1999/xhtml"> the descriptive statistics from the original variables in the </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1" xmlns:="http://www.w3.org/1999/xhtml">test set:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.150.1" xmlns:="http://www.w3.org/1999/xhtml">
X_test.describe()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.151.1" xmlns:="http://www.w3.org/1999/xhtml">In the following output, we see that the variables’ mean values are different from zero and the </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1" xmlns:="http://www.w3.org/1999/xhtml">variance varies:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer120">
<span class="koboSpan" id="kobo.153.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 7.2 – Descriptive statistical parameters of the variables before scaling" src="image/B22396_07_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.154.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 7.2 – Descriptive statistical parameters of the variables before scaling</span></p>
<ol>
<li value="9"><span class="koboSpan" id="kobo.155.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s now print</span><a id="_idTextAnchor887"/><span class="koboSpan" id="kobo.156.1" xmlns:="http://www.w3.org/1999/xhtml"> the descriptive statistical values from the </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1" xmlns:="http://www.w3.org/1999/xhtml">transformed variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.158.1" xmlns:="http://www.w3.org/1999/xhtml">
X_test_scaled.describe()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.159.1" xmlns:="http://www.w3.org/1999/xhtml">In the following output, we see that the variables’ mean is now centered at </span><strong class="source-inline"><span class="koboSpan" id="kobo.160.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.161.1" xmlns:="http://www.w3.org/1999/xhtml"> and the variance is </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1" xmlns:="http://www.w3.org/1999/xhtml">approximately </span><a id="_idTextAnchor888"/></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.163.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.164.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer121">
<span class="koboSpan" id="kobo.165.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 7.3 – Descriptive statistical parameters of the scaled variables showing a mean of 0 and variance of approximately 1" src="image/B22396_07_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.166.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 7.3 – Descriptive statistical parameters of the scaled variables showing a mean of 0 and variance of approximately 1</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.167.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.168.1" xmlns:="http://www.w3.org/1999/xhtml">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.169.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms</span></strong><span class="koboSpan" id="kobo.170.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.171.1" xmlns:="http://www.w3.org/1999/xhtml">AveBedrms</span></strong><span class="koboSpan" id="kobo.172.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.173.1" xmlns:="http://www.w3.org/1999/xhtml">AveOccup</span></strong><span class="koboSpan" id="kobo.174.1" xmlns:="http://www.w3.org/1999/xhtml"> variables are highly skewed, which can lead to observed values in the test set that are much greater or much smaller than those in the training set, and hence we see that the variance deviates from </span><strong class="source-inline"><span class="koboSpan" id="kobo.175.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.176.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.176.2" xmlns:="http://www.w3.org/1999/xhtml">This is to be expected because standardization is sensitive to outliers and very </span><span class="No-Break"><span class="koboSpan" id="kobo.177.1" xmlns:="http://www.w3.org/1999/xhtml">skewed distributions.</span></span></p>
<p><span class="koboSpan" id="kobo.178.1" xmlns:="http://www.w3.org/1999/xhtml">We mentioned, in</span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.179.1" xmlns:="http://www.w3.org/1999/xhtml"> the </span><em class="italic"><span class="koboSpan" id="kobo.180.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></em><span class="koboSpan" id="kobo.181.1" xmlns:="http://www.w3.org/1999/xhtml"> section, that the shape of the distribution does not change with standardization. </span><span class="koboSpan" id="kobo.181.2" xmlns:="http://www.w3.org/1999/xhtml">Go ahead and corroborate that by executing  </span><strong class="source-inline"><span class="koboSpan" id="kobo.182.1" xmlns:="http://www.w3.org/1999/xhtml">X_test.hist()</span></strong><span class="koboSpan" id="kobo.183.1" xmlns:="http://www.w3.org/1999/xhtml"> and then </span><strong class="source-inline"><span class="koboSpan" id="kobo.184.1" xmlns:="http://www.w3.org/1999/xhtml">X_test_scaled.hist()</span></strong><span class="koboSpan" id="kobo.185.1" xmlns:="http://www.w3.org/1999/xhtml"> to compare the variables’ distribution before and after </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1" xmlns:="http://www.w3.org/1999/xhtml">the transformati</span><a id="_idTextAnchor889"/><a id="_idTextAnchor890"/><span class="koboSpan" id="kobo.187.1" xmlns:="http://www.w3.org/1999/xhtml">on.</span></span></p>
<h2 id="_idParaDest-200"><a id="_idTextAnchor891"/><span class="koboSpan" id="kobo.188.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.189.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we standardized the variables of the California housing dataset by utilizing scikit-learn. </span><span class="koboSpan" id="kobo.189.2" xmlns:="http://www.w3.org/1999/xhtml">We split the data into train and test sets because the parameters for the standardization should be learned from the train set. </span><span class="koboSpan" id="kobo.189.3" xmlns:="http://www.w3.org/1999/xhtml">This is to avoid leaking data from the test to the train set during the preprocessing steps and to ensure the test set remains naïve to all feature </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1" xmlns:="http://www.w3.org/1999/xhtml">transformation processes.</span></span></p>
<p><span class="koboSpan" id="kobo.191.1" xmlns:="http://www.w3.org/1999/xhtml">To standardize these features, we used scikit-learn’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.192.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.193.1" xmlns:="http://www.w3.org/1999/xhtml"> function, which is able to learn and store the parameters utilized in the transformation. </span><span class="koboSpan" id="kobo.193.2" xmlns:="http://www.w3.org/1999/xhtml">Using </span><strong class="source-inline"><span class="koboSpan" id="kobo.194.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.195.1" xmlns:="http://www.w3.org/1999/xhtml">, the scaler learned each variable’s mean and standard deviation and stored them in its </span><strong class="source-inline"><span class="koboSpan" id="kobo.196.1" xmlns:="http://www.w3.org/1999/xhtml">mean_</span></strong><span class="koboSpan" id="kobo.197.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.198.1" xmlns:="http://www.w3.org/1999/xhtml">scale_</span></strong><span class="koboSpan" id="kobo.199.1" xmlns:="http://www.w3.org/1999/xhtml"> attributes. </span><span class="koboSpan" id="kobo.199.2" xmlns:="http://www.w3.org/1999/xhtml">Using </span><strong class="source-inline"><span class="koboSpan" id="kobo.200.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.201.1" xmlns:="http://www.w3.org/1999/xhtml">, the scaler standardized the variables in the train and test sets. </span><span class="koboSpan" id="kobo.201.2" xmlns:="http://www.w3.org/1999/xhtml">The default output of </span><strong class="source-inline"><span class="koboSpan" id="kobo.202.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.203.1" xmlns:="http://www.w3.org/1999/xhtml"> is a NumPy array, but through the </span><strong class="source-inline"><span class="koboSpan" id="kobo.204.1" xmlns:="http://www.w3.org/1999/xhtml">set_output()</span></strong><span class="koboSpan" id="kobo.205.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter, we can change the output </span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.206.1" xmlns:="http://www.w3.org/1999/xhtml">container to a </span><strong class="source-inline"><span class="koboSpan" id="kobo.207.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.208.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame, as we did in </span><em class="italic"><span class="koboSpan" id="kobo.209.1" xmlns:="http://www.w3.org/1999/xhtml">Step 4</span></em><span class="koboSpan" id="kobo.210.1" xmlns:="http://www.w3.org/1999/xhtml">, or to </span><strong class="source-inline"><span class="koboSpan" id="kobo.211.1" xmlns:="http://www.w3.org/1999/xhtml">polars</span></strong><span class="koboSpan" id="kobo.212.1" xmlns:="http://www.w3.org/1999/xhtml">, by </span><span class="No-Break"><span class="koboSpan" id="kobo.213.1" xmlns:="http://www.w3.org/1999/xhtml">setting </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.214.1" xmlns:="http://www.w3.org/1999/xhtml">transform="polars"</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.215.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.216.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.217.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.218.1" xmlns:="http://www.w3.org/1999/xhtml"> will subtract the mean and divide it by the standard deviation by default. </span><span class="koboSpan" id="kobo.218.2" xmlns:="http://www.w3.org/1999/xhtml">If we want to just center the distributions without standardizing the variance, we can do so by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.219.1" xmlns:="http://www.w3.org/1999/xhtml">with_std=False</span></strong><span class="koboSpan" id="kobo.220.1" xmlns:="http://www.w3.org/1999/xhtml"> when initializing the transformer. </span><span class="koboSpan" id="kobo.220.2" xmlns:="http://www.w3.org/1999/xhtml">If we want to set the variance to </span><strong class="source-inline"><span class="koboSpan" id="kobo.221.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.222.1" xmlns:="http://www.w3.org/1999/xhtml">, without cantering the distribution, we can do so by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.223.1" xmlns:="http://www.w3.org/1999/xhtml">with_mean=False</span></strong><span class="koboSpan" id="kobo.224.1" xmlns:="http://www.w3.org/1999/xhtml"> in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.225.1" xmlns:="http://www.w3.org/1999/xhtml">Step</span><a id="_idTextAnchor892"/><a id="_idTextAnchor893"/><span class="koboSpan" id="kobo.226.1" xmlns:="http://www.w3.org/1999/xhtml"> 4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.227.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h1 id="_idParaDest-201"><a id="_idTextAnchor894"/><span class="koboSpan" id="kobo.228.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling to the maximum and minimum values</span></h1>
<p><span class="koboSpan" id="kobo.229.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling </span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.230.1" xmlns:="http://www.w3.org/1999/xhtml">to the minimu</span><a id="_idTextAnchor895"/><span class="koboSpan" id="kobo.231.1" xmlns:="http://www.w3.org/1999/xhtml">m and maximum values squeezes the values of </span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.232.1" xmlns:="http://www.w3.org/1999/xhtml">the variables between </span><strong class="source-inline"><span class="koboSpan" id="kobo.233.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.234.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.235.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.236.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.236.2" xmlns:="http://www.w3.org/1999/xhtml">To implement this scaling method, we subtract the minimu</span><a id="_idTextAnchor896"/><span class="koboSpan" id="kobo.237.1" xmlns:="http://www.w3.org/1999/xhtml">m value from all the observations and divide the result by the value range – that is, the difference between the maximum and </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1" xmlns:="http://www.w3.org/1999/xhtml">minimum values:</span></span></p>
<p><span class="koboSpan" id="kobo.239.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;m&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;max&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;m&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/26.png" style="vertical-align:-0.557em;height:1.635em;width:8.738em"/></span></p>
<p><span class="koboSpan" id="kobo.240.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling to the minimum and maximum is suitable for variables with very small standard deviations, when the models do not require data to be centered at zero, and when we want to preserve zero entries in sparse data, such as in one-hot encoded variables. </span><span class="koboSpan" id="kobo.240.2" xmlns:="http://www.w3.org/1999/xhtml">On the downside, it is sensitive </span><span class="No-Break"><span class="koboSpan" id="kobo.241.1" xmlns:="http://www.w3.org/1999/xhtml">to outliers.</span></span></p>
<h2 id="_idParaDest-202"><a id="_idTextAnchor897"/><span class="koboSpan" id="kobo.242.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.243.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling to the minimum and maximum value does not change the distribution of the variables, as illustrated in the </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1" xmlns:="http://www.w3.org/1999/xhtml">following figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer123">
<span class="koboSpan" id="kobo.245.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 7.4 – Distribution of a normal and skewed variable before and after scaling to the minimum and maximum value" src="image/B22396_07_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.246.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 7.4 – Distribution of a normal and skewed variable before and after scaling to the minimum and maximum value</span></p>
<p><span class="koboSpan" id="kobo.247.1" xmlns:="http://www.w3.org/1999/xhtml">This </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.248.1" xmlns:="http://www.w3.org/1999/xhtml">scaling method standardizes the maximum value of the</span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.249.1" xmlns:="http://www.w3.org/1999/xhtml"> variables to a unit size. </span><span class="koboSpan" id="kobo.249.2" xmlns:="http://www.w3.org/1999/xhtml">Scaling to the minimum and maximum value tends to be the preferred alternative to standardization, and it is suitable for variables with very small standard deviations and when we want to preserve zero entries in sparse data, such as in one-hot encoded variables, or variables derived from counts, such as bag of words. </span><span class="koboSpan" id="kobo.249.3" xmlns:="http://www.w3.org/1999/xhtml">However, this procedure does not center the variables at zero, so if the algorithm has that requirement, this method might not be the </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1" xmlns:="http://www.w3.org/1999/xhtml">best choice.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.251.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.252.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling to the minimum and maximum values is sensitive to outliers. </span><span class="koboSpan" id="kobo.252.2" xmlns:="http://www.w3.org/1999/xhtml">If outliers are present in the training set, the scaling will squeeze the values toward one of the tails. </span><span class="koboSpan" id="kobo.252.3" xmlns:="http://www.w3.org/1999/xhtml">If, on the contrary, outliers are in the test set, the variable will show values greater than </span><strong class="source-inline"><span class="koboSpan" id="kobo.253.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.254.1" xmlns:="http://www.w3.org/1999/xhtml"> or smaller than </span><strong class="source-inline"><span class="koboSpan" id="kobo.255.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.256.1" xmlns:="http://www.w3.org/1999/xhtml"> after scaling, depending on whether the outlier is on the left or </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1" xmlns:="http://www.w3.org/1999/xhtml">righ</span><a id="_idTextAnchor898"/><a id="_idTextAnchor899"/><span class="koboSpan" id="kobo.258.1" xmlns:="http://www.w3.org/1999/xhtml">t tail.</span></span></p>
<h2 id="_idParaDest-203"><a id="_idTextAnchor900"/><span class="koboSpan" id="kobo.259.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.260.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we’ll scale </span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.261.1" xmlns:="http://www.w3.org/1999/xhtml">the variables of the California housing dataset </span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.262.1" xmlns:="http://www.w3.org/1999/xhtml">to values between </span><strong class="source-inline"><span class="koboSpan" id="kobo.263.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.264.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.265.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.266.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.267.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s start by importing </span><strong class="source-inline"><span class="koboSpan" id="kobo.268.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.269.1" xmlns:="http://www.w3.org/1999/xhtml"> and the required classes </span><span class="No-Break"><span class="koboSpan" id="kobo.270.1" xmlns:="http://www.w3.org/1999/xhtml">and functions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.271.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler</span></pre></li> <li><span class="koboSpan" id="kobo.272.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the </span><a id="_idTextAnchor901"/><span class="koboSpan" id="kobo.273.1" xmlns:="http://www.w3.org/1999/xhtml">California housing dataset from scikit-learn into a </span><strong class="source-inline"><span class="koboSpan" id="kobo.274.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.275.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame, dropping the </span><strong class="source-inline"><span class="koboSpan" id="kobo.276.1" xmlns:="http://www.w3.org/1999/xhtml">Latitude</span></strong><span class="koboSpan" id="kobo.277.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.278.1" xmlns:="http://www.w3.org/1999/xhtml">Longitude</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.279.1" xmlns:="http://www.w3.org/1999/xhtml"> variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.280.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)
X.dro</span><a id="_idTextAnchor902"/><span class="koboSpan" id="kobo.281.1" xmlns:="http://www.w3.org/1999/xhtml">p(labels=["Latitude", "Longitude"], axis=1,
    inplace=True)</span></pre></li> <li><span class="koboSpan" id="kobo.282.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s divide the data into training and </span><span class="No-Break"><span class="koboSpan" id="kobo.283.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.284.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.285.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up the scaler and then fit it to the train set so that it learns each variable’s minimum and maximum values and the </span><span class="No-Break"><span class="koboSpan" id="kobo.286.1" xmlns:="http://www.w3.org/1999/xhtml">value range:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.287.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler = MinMaxScaler().set_output(
    transform="pandas"")
scaler.fit(X_train)</span></pre></li> <li><span class="koboSpan" id="kobo.288.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s</span><a id="_idTextAnchor903"/><span class="koboSpan" id="kobo.289.1" xmlns:="http://www.w3.org/1999/xhtml"> scale the variables in the train and test sets with the </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1" xmlns:="http://www.w3.org/1999/xhtml">trained scaler:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.291.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.292.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.293.1" xmlns:="http://www.w3.org/1999/xhtml">MinMaxScale</span><a id="_idTextAnchor904"/><span class="koboSpan" id="kobo.294.1" xmlns:="http://www.w3.org/1999/xhtml">r()</span></strong><span class="koboSpan" id="kobo.295.1" xmlns:="http://www.w3.org/1999/xhtml"> stores the maximum and minimum values and the value ranges in its </span><strong class="source-inline"><span class="koboSpan" id="kobo.296.1" xmlns:="http://www.w3.org/1999/xhtml">data_max_</span></strong><span class="koboSpan" id="kobo.297.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.298.1" xmlns:="http://www.w3.org/1999/xhtml">min_</span></strong><span class="koboSpan" id="kobo.299.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.300.1" xmlns:="http://www.w3.org/1999/xhtml">data_range_</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.301.1" xmlns:="http://www.w3.org/1999/xhtml">attributes, respectively.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.302.1" xmlns:="http://www.w3.org/1999/xhtml">We can</span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.303.1" xmlns:="http://www.w3.org/1999/xhtml"> corroborate the minimum values of the</span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.304.1" xmlns:="http://www.w3.org/1999/xhtml"> transformed variables by executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.305.1" xmlns:="http://www.w3.org/1999/xhtml">X_test_scaled.min()</span></strong><span class="koboSpan" id="kobo.306.1" xmlns:="http://www.w3.org/1999/xhtml">, which will return the </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1" xmlns:="http://www.w3.org/1999/xhtml">following output:</span></span></p>
<pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.308.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc           0.000000</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.309.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge        0.000000</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.310.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms        0.004705</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.311.1" xmlns:="http://www.w3.org/1999/xhtml">AveBedrms      0.004941</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.312.1" xmlns:="http://www.w3.org/1999/xhtml">Population     0.000140</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.313.1" xmlns:="http://www.w3.org/1999/xhtml">AveOccup      -0.000096</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.314.1" xmlns:="http://www.w3.org/1999/xhtml">dtype: float64</span></strong></pre> <p class="list-inset"><span class="koboSpan" id="kobo.315.1" xmlns:="http://www.w3.org/1999/xhtml">By executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.316.1" xmlns:="http://www.w3.org/1999/xhtml">X_test_scaled.max()</span></strong><span class="koboSpan" id="kobo.317.1" xmlns:="http://www.w3.org/1999/xhtml">, we see that the maximum values of the variables are </span><span class="No-Break"><span class="koboSpan" id="kobo.318.1" xmlns:="http://www.w3.org/1999/xhtml">around </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.319.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.320.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p>
<pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.321.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc           1.000000</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.322.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge        1.000000</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.323.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms        1.071197</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.324.1" xmlns:="http://www.w3.org/1999/xhtml">AveBedrms      0.750090</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.325.1" xmlns:="http://www.w3.org/1999/xhtml">Population     0.456907</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.326.1" xmlns:="http://www.w3.org/1999/xhtml">AveOccup        2.074553</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.327.1" xmlns:="http://www.w3.org/1999/xhtml">dtype: float64</span></strong></pre> <p class="callout-heading"><span class="koboSpan" id="kobo.328.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.329.1" xmlns:="http://www.w3.org/1999/xhtml">If you check the maximum values of the variables in the train set after the transformation, you’ll see that they are exactly </span><strong class="source-inline"><span class="koboSpan" id="kobo.330.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.331.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.331.2" xmlns:="http://www.w3.org/1999/xhtml">Yet, in the test set, we see values greater and smaller than </span><strong class="source-inline"><span class="koboSpan" id="kobo.332.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.333.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.333.2" xmlns:="http://www.w3.org/1999/xhtml">This occurs because, in the test set, there are observations with larger or smaller magnitudes than those in the train set. </span><span class="koboSpan" id="kobo.333.3" xmlns:="http://www.w3.org/1999/xhtml">In fact, we see the greatest differences in the variables that deviate the most from the normal distribution (the last four variables in the dataset). </span><span class="koboSpan" id="kobo.333.4" xmlns:="http://www.w3.org/1999/xhtml">This behavior is expected because scaling to the minimum and maximum values is sensitive to outliers and very </span><span class="No-Break"><span class="koboSpan" id="kobo.334.1" xmlns:="http://www.w3.org/1999/xhtml">skewed distributions.</span></span></p>
<p><span class="koboSpan" id="kobo.335.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling to the</span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.336.1" xmlns:="http://www.w3.org/1999/xhtml"> minimum and maximum value does not change the shape</span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.337.1" xmlns:="http://www.w3.org/1999/xhtml"> of the variable’s distribution. </span><span class="koboSpan" id="kobo.337.2" xmlns:="http://www.w3.org/1999/xhtml">You can corroborate that by displaying the histograms before and after </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1" xmlns:="http://www.w3.org/1999/xhtml">the tr</span><a id="_idTextAnchor905"/><a id="_idTextAnchor906"/><span class="koboSpan" id="kobo.339.1" xmlns:="http://www.w3.org/1999/xhtml">ansformation.</span></span></p>
<h2 id="_idParaDest-204"><a id="_idTextAnchor907"/><span class="koboSpan" id="kobo.340.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.341.1" xmlns:="http://www.w3.org/1999/xhtml">In this rec</span><a id="_idTextAnchor908"/><span class="koboSpan" id="kobo.342.1" xmlns:="http://www.w3.org/1999/xhtml">ipe, we scaled the variables of the California housing dataset to values between </span><strong class="source-inline"><span class="koboSpan" id="kobo.343.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.344.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.345.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.346.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.347.1" xmlns:="http://www.w3.org/1999/xhtml">MinMaxScaler()</span></strong><span class="koboSpan" id="kobo.348.1" xmlns:="http://www.w3.org/1999/xhtml"> from scikit-learn learned the minimum and maximum values and the value range of each variable when we called the </span><strong class="source-inline"><span class="koboSpan" id="kobo.349.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.350.1" xmlns:="http://www.w3.org/1999/xhtml"> method and stored these parameters in its </span><strong class="source-inline"><span class="koboSpan" id="kobo.351.1" xmlns:="http://www.w3.org/1999/xhtml">data_max_</span></strong><span class="koboSpan" id="kobo.352.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.353.1" xmlns:="http://www.w3.org/1999/xhtml">min_</span></strong><span class="koboSpan" id="kobo.354.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.355.1" xmlns:="http://www.w3.org/1999/xhtml">data_range_</span></strong><span class="koboSpan" id="kobo.356.1" xmlns:="http://www.w3.org/1999/xhtml"> attributes. </span><span class="koboSpan" id="kobo.356.2" xmlns:="http://www.w3.org/1999/xhtml">By using </span><strong class="source-inline"><span class="koboSpan" id="kobo.357.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.358.1" xmlns:="http://www.w3.org/1999/xhtml">, we made the scaler remove the minimum value from each variable in the train and test sets and divide the result by the </span><span class="No-Break"><span class="koboSpan" id="kobo.359.1" xmlns:="http://www.w3.org/1999/xhtml">value range.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.360.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.361.1" xmlns:="http://www.w3.org/1999/xhtml">MinMaxScaler()</span></strong><span class="koboSpan" id="kobo.362.1" xmlns:="http://www.w3.org/1999/xhtml"> will scale all variables by default. </span><span class="koboSpan" id="kobo.362.2" xmlns:="http://www.w3.org/1999/xhtml">To scale only a subset of the variables in the dataset, you can use </span><strong class="source-inline"><span class="koboSpan" id="kobo.363.1" xmlns:="http://www.w3.org/1999/xhtml">ColumnTransformer()</span></strong><span class="koboSpan" id="kobo.364.1" xmlns:="http://www.w3.org/1999/xhtml"> from scikit-learn or </span><strong class="source-inline"><span class="koboSpan" id="kobo.365.1" xmlns:="http://www.w3.org/1999/xhtml">SklearnTransformerWrapper()</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.366.1" xmlns:="http://www.w3.org/1999/xhtml">from </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.367.1" xmlns:="http://www.w3.org/1999/xhtml">Feature-engine</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.368.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.369.1" xmlns:="http://www.w3.org/1999/xhtml">MinMaxScaler()</span></strong><span class="koboSpan" id="kobo.370.1" xmlns:="http://www.w3.org/1999/xhtml"> will scale the variables between </span><strong class="source-inline"><span class="koboSpan" id="kobo.371.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.372.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.373.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.374.1" xmlns:="http://www.w3.org/1999/xhtml"> by default. </span><span class="koboSpan" id="kobo.374.2" xmlns:="http://www.w3.org/1999/xhtml">However, we have the option to scale to a different range by adjusting the tuple passed to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.375.1" xmlns:="http://www.w3.org/1999/xhtml">feature_range</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.376.1" xmlns:="http://www.w3.org/1999/xhtml"> parameter.</span></span></p>
<p><span class="koboSpan" id="kobo.377.1" xmlns:="http://www.w3.org/1999/xhtml">By default, </span><strong class="source-inline"><span class="koboSpan" id="kobo.378.1" xmlns:="http://www.w3.org/1999/xhtml">MinMaxScaler()</span></strong><span class="koboSpan" id="kobo.379.1" xmlns:="http://www.w3.org/1999/xhtml"> returns </span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.380.1" xmlns:="http://www.w3.org/1999/xhtml">NumPy arrays, but we can modify this </span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.381.1" xmlns:="http://www.w3.org/1999/xhtml">behavior to return </span><strong class="source-inline"><span class="koboSpan" id="kobo.382.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.383.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrames with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.384.1" xmlns:="http://www.w3.org/1999/xhtml">set_output()</span></strong><span class="koboSpan" id="kobo.385.1" xmlns:="http://www.w3.org/1999/xhtml"> method, as we</span><a id="_idTextAnchor909"/><a id="_idTextAnchor910"/><span class="koboSpan" id="kobo.386.1" xmlns:="http://www.w3.org/1999/xhtml"> did in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.387.1" xmlns:="http://www.w3.org/1999/xhtml">Step 4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.388.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h1 id="_idParaDest-205"><a id="_idTextAnchor911"/><span class="koboSpan" id="kobo.389.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling with the median and quantiles</span></h1>
<p><span class="koboSpan" id="kobo.390.1" xmlns:="http://www.w3.org/1999/xhtml">When </span><a id="_idIndexMarker534"/><a id="_idTextAnchor912"/><span class="koboSpan" id="kobo.391.1" xmlns:="http://www.w3.org/1999/xhtml">scaling variab</span><a id="_idTextAnchor913"/><span class="koboSpan" id="kobo.392.1" xmlns:="http://www.w3.org/1999/xhtml">les to </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.393.1" xmlns:="http://www.w3.org/1999/xhtml">the median and quantiles, the median value is removed from the observations, and the result is divided by</span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.394.1" xmlns:="http://www.w3.org/1999/xhtml"> the </span><strong class="bold"><span class="koboSpan" id="kobo.395.1" xmlns:="http://www.w3.org/1999/xhtml">Inter-Quarti</span><a id="_idTextAnchor914"/><span class="koboSpan" id="kobo.396.1" xmlns:="http://www.w3.org/1999/xhtml">le Range</span></strong><span class="koboSpan" id="kobo.397.1" xmlns:="http://www.w3.org/1999/xhtml"> (</span><strong class="bold"><span class="koboSpan" id="kobo.398.1" xmlns:="http://www.w3.org/1999/xhtml">IQR</span></strong><span class="koboSpan" id="kobo.399.1" xmlns:="http://www.w3.org/1999/xhtml">). </span><span class="koboSpan" id="kobo.399.2" xmlns:="http://www.w3.org/1999/xhtml">The IQR is the difference between the 3rd quartile and the 1st quartile, or, in other words, the difference between the 75th percentile and the </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1" xmlns:="http://www.w3.org/1999/xhtml">25th percent</span><a id="_idTextAnchor915"/><span class="koboSpan" id="kobo.401.1" xmlns:="http://www.w3.org/1999/xhtml">ile:</span></span></p>
<p><span class="koboSpan" id="kobo.402.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;_&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/27.png" style="vertical-align:-0.758em;height:1.961em;width:15.169em"/></span></p>
<p><span class="koboSpan" id="kobo.403.1" xmlns:="http://www.w3.org/1999/xhtml">This method is known</span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.404.1" xmlns:="http://www.w3.org/1999/xhtml"> as </span><strong class="bold"><span class="koboSpan" id="kobo.405.1" xmlns:="http://www.w3.org/1999/xhtml">robust</span><a id="_idTextAnchor916"/><span class="koboSpan" id="kobo.406.1" xmlns:="http://www.w3.org/1999/xhtml"> scaling</span></strong><span class="koboSpan" id="kobo.407.1" xmlns:="http://www.w3.org/1999/xhtml"> because it produces more robust estimates for the center and value range of the variable. </span><span class="koboSpan" id="kobo.407.2" xmlns:="http://www.w3.org/1999/xhtml">Robust scaling is a suitable alternative to standardization when models require the variables to be centered and the data contains outliers. </span><span class="koboSpan" id="kobo.407.3" xmlns:="http://www.w3.org/1999/xhtml">It is worth noting that robust scaling will not change the overall shape of the </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1" xmlns:="http://www.w3.org/1999/xhtml">vari</span><a id="_idTextAnchor917"/><a id="_idTextAnchor918"/><span class="koboSpan" id="kobo.409.1" xmlns:="http://www.w3.org/1999/xhtml">able distribution.</span></span></p>
<h2 id="_idParaDest-206"><a id="_idTextAnchor919"/><span class="koboSpan" id="kobo.410.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.411.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will implement scaling with the median and IQR by </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1" xmlns:="http://www.w3.org/1999/xhtml">utilizing scikit-learn:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.413.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s start </span><a id="_idTextAnchor920"/><span class="koboSpan" id="kobo.414.1" xmlns:="http://www.w3.org/1999/xhtml">by importing </span><strong class="source-inline"><span class="koboSpan" id="kobo.415.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.416.1" xmlns:="http://www.w3.org/1999/xhtml"> and the required scikit-learn classes </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1" xmlns:="http://www.w3.org/1999/xhtml">and functions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.418.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler</span></pre></li> <li><span class="koboSpan" id="kobo.419.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the California housing dataset into a </span><strong class="source-inline"><span class="koboSpan" id="kobo.420.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.421.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame and drop the </span><strong class="source-inline"><span class="koboSpan" id="kobo.422.1" xmlns:="http://www.w3.org/1999/xhtml">Latitude</span></strong><span class="koboSpan" id="kobo.423.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.424.1" xmlns:="http://www.w3.org/1999/xhtml">Longitude</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.425.1" xmlns:="http://www.w3.org/1999/xhtml"> variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.426.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)
X.drop(labels=[     "Latitude", "Longitude"], axis=1,
    inplac</span><a id="_idTextAnchor921"/><span class="koboSpan" id="kobo.427.1" xmlns:="http://www.w3.org/1999/xhtml">e=True)</span></pre></li> <li><span class="koboSpan" id="kobo.428.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s divide the data into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.429.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.430.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0</span><a id="_idTextAnchor922"/><span class="koboSpan" id="kobo.431.1" xmlns:="http://www.w3.org/1999/xhtml">.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.432.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up scikit-learn’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.433.1" xmlns:="http://www.w3.org/1999/xhtml">RobustScaler()</span></strong><span class="koboSpan" id="kobo.434.1" xmlns:="http://www.w3.org/1999/xhtml">and fit it to the train set so that it learns and stores the median </span><span class="No-Break"><span class="koboSpan" id="kobo.435.1" xmlns:="http://www.w3.org/1999/xhtml">and IQR:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.436.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler = RobustScaler().set_output(
    transform="pandas")
scaler.fit(X_train)</span></pre></li> <li><span class="koboSpan" id="kobo.437.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s</span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.438.1" xmlns:="http://www.w3.org/1999/xhtml"> scale the </span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.439.1" xmlns:="http://www.w3.org/1999/xhtml">variables in the train and test sets with the </span><span class="No-Break"><span class="koboSpan" id="kobo.440.1" xmlns:="http://www.w3.org/1999/xhtml">trained scaler:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.441.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)</span></pre></li> <li><span class="koboSpan" id="kobo.442.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s print the variable median values learned </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1" xmlns:="http://www.w3.org/1999/xhtml">by </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.444.1" xmlns:="http://www.w3.org/1999/xhtml">RobustScaler()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.445.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.446.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler.center_</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.447.1" xmlns:="http://www.w3.org/1999/xhtml">We see the parameters learned by </span><strong class="source-inline"><span class="koboSpan" id="kobo.448.1" xmlns:="http://www.w3.org/1999/xhtml">RobustScaler()</span></strong><span class="koboSpan" id="kobo.449.1" xmlns:="http://www.w3.org/1999/xhtml"> in the </span><span class="No-Break"><span class="koboSpan" id="kobo.450.1" xmlns:="http://www.w3.org/1999/xhtml">following output:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.451.1" xmlns:="http://www.w3.org/1999/xhtml">array([3.53910000e+00, 2.90000000e+01, 5.22931763e+00,                 1.04878049e+00, 1.16500000e+03, 2.81635506e+00])</span></strong></pre></li> <li><span class="koboSpan" id="kobo.452.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s display the IQR learned </span><span class="No-Break"><span class="koboSpan" id="kobo.453.1" xmlns:="http://www.w3.org/1999/xhtml">by </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.454.1" xmlns:="http://www.w3.org/1999/xhtml">RobustScaler()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.455.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.456.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler.scale_</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.457.1" xmlns:="http://www.w3.org/1999/xhtml">We can see the IQR for each variable in the </span><span class="No-Break"><span class="koboSpan" id="kobo.458.1" xmlns:="http://www.w3.org/1999/xhtml">following output:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.459.1" xmlns:="http://www.w3.org/1999/xhtml">array([2.16550000e+00, 1.90000000e+01, 1.59537022e+00,</span></strong><strong class="bold"><span class="koboSpan" id="kobo.460.1" xmlns:="http://www.w3.org/1999/xhtml">                 9.41284380e-02, 9.40000000e</span><a id="_idTextAnchor923"/><span class="koboSpan" id="kobo.461.1" xmlns:="http://www.w3.org/1999/xhtml">+02, 8.53176853e-01])</span></strong></pre><p class="list-inset"><span class="koboSpan" id="kobo.462.1" xmlns:="http://www.w3.org/1999/xhtml">This scaling procedure does not change the variable distributions. </span><span class="koboSpan" id="kobo.462.2" xmlns:="http://www.w3.org/1999/xhtml">Go ahead and compare the distribution of the variables before and after the transformation</span><a id="_idTextAnchor924"/><a id="_idTextAnchor925"/><span class="koboSpan" id="kobo.463.1" xmlns:="http://www.w3.org/1999/xhtml"> by </span><span class="No-Break"><span class="koboSpan" id="kobo.464.1" xmlns:="http://www.w3.org/1999/xhtml">using histograms.</span></span></p></li> </ol>
<h2 id="_idParaDest-207"><a id="_idTextAnchor926"/><span class="koboSpan" id="kobo.465.1" xmlns:="http://www.w3.org/1999/xhtml">How it works...</span></h2>
<p><span class="koboSpan" id="kobo.466.1" xmlns:="http://www.w3.org/1999/xhtml">To scale the</span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.467.1" xmlns:="http://www.w3.org/1999/xhtml"> features using</span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.468.1" xmlns:="http://www.w3.org/1999/xhtml"> the median and IQR, we created an instance of </span><strong class="source-inline"><span class="koboSpan" id="kobo.469.1" xmlns:="http://www.w3.org/1999/xhtml">RobustScaler()</span></strong><span class="koboSpan" id="kobo.470.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.470.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.471.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.472.1" xmlns:="http://www.w3.org/1999/xhtml">, the scaler learned the median and IQR for each variable from the train set. </span><span class="koboSpan" id="kobo.472.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.473.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.474.1" xmlns:="http://www.w3.org/1999/xhtml">, the scaler subtracted the median from each variable in the train and test sets and divided the result by </span><span class="No-Break"><span class="koboSpan" id="kobo.475.1" xmlns:="http://www.w3.org/1999/xhtml">the IQR.</span></span></p>
<p><span class="koboSpan" id="kobo.476.1" xmlns:="http://www.w3.org/1999/xhtml">After the transformation, the median values of the variables were centered at </span><strong class="source-inline"><span class="koboSpan" id="kobo.477.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.478.1" xmlns:="http://www.w3.org/1999/xhtml">, but the overall shape of the distributions did not change. </span><span class="koboSpan" id="kobo.478.2" xmlns:="http://www.w3.org/1999/xhtml">You can corroborate the effect of the transformation by displaying the histograms of the variables before and after the transformation and by printing out the main statistical parameters through </span><strong class="source-inline"><span class="koboSpan" id="kobo.479.1" xmlns:="http://www.w3.org/1999/xhtml">X_test.describe()</span><a id="_idTextAnchor927"/><a id="_idTextAnchor928"/></strong> <span class="No-Break"><span class="koboSpan" id="kobo.480.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.481.1" xmlns:="http://www.w3.org/1999/xhtml">X_test_scaled.b()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.482.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h1 id="_idParaDest-208"><a id="_idTextAnchor929"/><span class="koboSpan" id="kobo.483.1" xmlns:="http://www.w3.org/1999/xhtml">Performing mean normalization</span></h1>
<p><span class="koboSpan" id="kobo.484.1" xmlns:="http://www.w3.org/1999/xhtml">I</span><a id="_idTextAnchor930"/><span class="koboSpan" id="kobo.485.1" xmlns:="http://www.w3.org/1999/xhtml">n mean normalization, we </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.486.1" xmlns:="http://www.w3.org/1999/xhtml">center the variable at </span><strong class="source-inline"><span class="koboSpan" id="kobo.487.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.488.1" xmlns:="http://www.w3.org/1999/xhtml"> and rescale the distribution to the value range, so that its values lie between </span><strong class="source-inline"><span class="koboSpan" id="kobo.489.1" xmlns:="http://www.w3.org/1999/xhtml">-1</span></strong><span class="koboSpan" id="kobo.490.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.491.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.492.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.492.2" xmlns:="http://www.w3.org/1999/xhtml">This procedure involves subtracting the mean from each observation and then dividing the result by the difference between the minimum and maximum values, as </span><span class="No-Break"><span class="koboSpan" id="kobo.493.1" xmlns:="http://www.w3.org/1999/xhtml">sh</span><a id="_idTextAnchor931"/><span class="koboSpan" id="kobo.494.1" xmlns:="http://www.w3.org/1999/xhtml">own here:</span></span></p>
<p><span class="koboSpan" id="kobo.495.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mrow&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;mrow&gt;&lt;mi&gt;max&lt;/mi&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;m&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;i&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;n&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/28.png" style="vertical-align:-0.557em;height:1.580em;width:8.713em"/></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.496.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.497.1" xmlns:="http://www.w3.org/1999/xhtml">Mean normalization is an alternative to standardization. </span><span class="koboSpan" id="kobo.497.2" xmlns:="http://www.w3.org/1999/xhtml">In both cases, the variables are centered at </span><strong class="source-inline"><span class="koboSpan" id="kobo.498.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.499.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.499.2" xmlns:="http://www.w3.org/1999/xhtml">In mean normalization, the variance varies, while the values lie between </span><strong class="source-inline"><span class="koboSpan" id="kobo.500.1" xmlns:="http://www.w3.org/1999/xhtml">-1</span></strong><span class="koboSpan" id="kobo.501.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.502.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.503.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.503.2" xmlns:="http://www.w3.org/1999/xhtml">On the other hand, in standardization, the variance is set to </span><strong class="source-inline"><span class="koboSpan" id="kobo.504.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong><span class="koboSpan" id="kobo.505.1" xmlns:="http://www.w3.org/1999/xhtml"> and the value </span><span class="No-Break"><span class="koboSpan" id="kobo.506.1" xmlns:="http://www.w3.org/1999/xhtml">range varies.</span></span></p>
<p><span class="koboSpan" id="kobo.507.1" xmlns:="http://www.w3.org/1999/xhtml">Mean </span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.508.1" xmlns:="http://www.w3.org/1999/xhtml">normalization is a suitable alternative for models that need the variables to be centered at zero. </span><span class="koboSpan" id="kobo.508.2" xmlns:="http://www.w3.org/1999/xhtml">However, it is sensitive to outliers and not a suitable option for sparse data, as it will d</span><a id="_idTextAnchor932"/><a id="_idTextAnchor933"/><span class="koboSpan" id="kobo.509.1" xmlns:="http://www.w3.org/1999/xhtml">estroy the </span><span class="No-Break"><span class="koboSpan" id="kobo.510.1" xmlns:="http://www.w3.org/1999/xhtml">sparse nature.</span></span></p>
<h2 id="_idParaDest-209"><a id="_idTextAnchor934"/><span class="koboSpan" id="kobo.511.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.512.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will implement mean normalization </span><span class="No-Break"><span class="koboSpan" id="kobo.513.1" xmlns:="http://www.w3.org/1999/xhtml">with </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.514.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.515.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.516.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import </span><strong class="source-inline"><span class="koboSpan" id="kobo.517.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.518.1" xmlns:="http://www.w3.org/1999/xhtml"> and the required scikit-learn class </span><span class="No-Break"><span class="koboSpan" id="kobo.519.1" xmlns:="http://www.w3.org/1999/xhtml">and function:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.520.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split</span></pre></li> <li><span class="koboSpan" id="kobo.521.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the California housing dataset from scikit-learn into a </span><strong class="source-inline"><span class="koboSpan" id="kobo.522.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.523.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame, dropping the </span><strong class="source-inline"><span class="koboSpan" id="kobo.524.1" xmlns:="http://www.w3.org/1999/xhtml">Latitude</span></strong><span class="koboSpan" id="kobo.525.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.526.1" xmlns:="http://www.w3.org/1999/xhtml">Longitude</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.527.1" xmlns:="http://www.w3.org/1999/xhtml"> variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.528.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)
X.drop(labels=[
   "Latitude", "Longitude"], axis=1, inplace=T</span><a id="_idTextAnchor935"/><span class="koboSpan" id="kobo.529.1" xmlns:="http://www.w3.org/1999/xhtml">rue)</span></pre></li> <li><span class="koboSpan" id="kobo.530.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s divide the data into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.531.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.532.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.533.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s learn the mean values from the variables in the </span><span class="No-Break"><span class="koboSpan" id="kobo.534.1" xmlns:="http://www.w3.org/1999/xhtml">train set:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.535.1" xmlns:="http://www.w3.org/1999/xhtml">
means = X_train.mean(axi</span><a id="_idTextAnchor936"/><span class="koboSpan" id="kobo.536.1" xmlns:="http://www.w3.org/1999/xhtml">s=0)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.537.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.538.1" xmlns:="http://www.w3.org/1999/xhtml">We set </span><strong class="source-inline"><span class="koboSpan" id="kobo.539.1" xmlns:="http://www.w3.org/1999/xhtml">axis=0</span></strong><span class="koboSpan" id="kobo.540.1" xmlns:="http://www.w3.org/1999/xhtml"> to take the mean of the rows – that is, of the observations in each variable. </span><span class="koboSpan" id="kobo.540.2" xmlns:="http://www.w3.org/1999/xhtml">If we set </span><strong class="source-inline"><span class="koboSpan" id="kobo.541.1" xmlns:="http://www.w3.org/1999/xhtml">axis=1</span></strong><span class="koboSpan" id="kobo.542.1" xmlns:="http://www.w3.org/1999/xhtml"> instead, </span><strong class="source-inline"><span class="koboSpan" id="kobo.543.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.544.1" xmlns:="http://www.w3.org/1999/xhtml"> will calculate the mean value per observation across all </span><span class="No-Break"><span class="koboSpan" id="kobo.545.1" xmlns:="http://www.w3.org/1999/xhtml">the columns.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.546.1" xmlns:="http://www.w3.org/1999/xhtml">By </span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.547.1" xmlns:="http://www.w3.org/1999/xhtml">executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.548.1" xmlns:="http://www.w3.org/1999/xhtml">print(mean)</span></strong><span class="koboSpan" id="kobo.549.1" xmlns:="http://www.w3.org/1999/xhtml">, we display the mean values </span><span class="No-Break"><span class="koboSpan" id="kobo.550.1" xmlns:="http://www.w3.org/1999/xhtml">per variable:</span></span></p>
<pre class="source-code">
<strong class="bold"><span class="koboSpan" id="kobo.551.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc           3.866667</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.552.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge        28.618702</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.553.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms         5.423404</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.554.1" xmlns:="http://www.w3.org/1999/xhtml">AveBedrms        1.094775</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.555.1" xmlns:="http://www.w3.org/1999/xhtml">Population    1425.157323</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.556.1" xmlns:="http://www.w3.org/1999/xhtml">AveOccup         3.040518</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.557.1" xmlns:="http://www.w3.org/1999/xhtml">dtype: float</span><a id="_idTextAnchor937"/><span class="koboSpan" id="kobo.558.1" xmlns:="http://www.w3.org/1999/xhtml">64</span></strong></pre> <ol>
<li value="5"><span class="koboSpan" id="kobo.559.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s determine the difference between the maximum and minimum values </span><span class="No-Break"><span class="koboSpan" id="kobo.560.1" xmlns:="http://www.w3.org/1999/xhtml">per variable:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.561.1" xmlns:="http://www.w3.org/1999/xhtml">
ranges = X_train.max(axis=0)-X_train.min(axis=0)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.562.1" xmlns:="http://www.w3.org/1999/xhtml">By executing </span><strong class="source-inline"><span class="koboSpan" id="kobo.563.1" xmlns:="http://www.w3.org/1999/xhtml">print(ranges)</span></strong><span class="koboSpan" id="kobo.564.1" xmlns:="http://www.w3.org/1999/xhtml">, we display the value ranges </span><span class="No-Break"><span class="koboSpan" id="kobo.565.1" xmlns:="http://www.w3.org/1999/xhtml">per variable:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.566.1" xmlns:="http://www.w3.org/1999/xhtml">MedInc</span></strong><strong class="bold"><span class="koboSpan" id="kobo.567.1" xmlns:="http://www.w3.org/1999/xhtml">           14.500200</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.568.1" xmlns:="http://www.w3.org/1999/xhtml">HouseAge         51.000000</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.569.1" xmlns:="http://www.w3.org/1999/xhtml">AveRooms        131.687179</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.570.1" xmlns:="http://www.w3.org/1999/xhtml">AveBedrms        33.733333</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.571.1" xmlns:="http://www.w3.org/1999/xhtml">Population    35679.000000</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.572.1" xmlns:="http://www.w3.org/1999/xhtml">AveOccup        598.964286</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.573.1" xmlns:="http://www.w3.org/1999/xhtml">dtype: float64</span></strong></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.574.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.575.1" xmlns:="http://www.w3.org/1999/xhtml">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.576.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong> <strong class="source-inline"><span class="koboSpan" id="kobo.577.1" xmlns:="http://www.w3.org/1999/xhtml">mean()</span></strong><span class="koboSpan" id="kobo.578.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.579.1" xmlns:="http://www.w3.org/1999/xhtml">max()</span></strong><span class="koboSpan" id="kobo.580.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.581.1" xmlns:="http://www.w3.org/1999/xhtml">min()</span></strong><span class="koboSpan" id="kobo.582.1" xmlns:="http://www.w3.org/1999/xhtml"> methods return a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.583.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.584.1" xmlns:="http://www.w3.org/1999/xhtml"> series.</span></span></p>
<ol>
<li value="6"><span class="koboSpan" id="kobo.585.1" xmlns:="http://www.w3.org/1999/xhtml">Now, we’ll</span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.586.1" xmlns:="http://www.w3.org/1999/xhtml"> apply mean normalization to the train and test se</span><a id="_idTextAnchor938"/><span class="koboSpan" id="kobo.587.1" xmlns:="http://www.w3.org/1999/xhtml">ts by utilizing the </span><span class="No-Break"><span class="koboSpan" id="kobo.588.1" xmlns:="http://www.w3.org/1999/xhtml">learned parameters:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.589.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train_scaled = (X_train - means) / ranges
X_test_scaled = (X_test - means) / ranges</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.590.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.591.1" xmlns:="http://www.w3.org/1999/xhtml">In order to transform future data, you will need to store these parameters, for example, in a </span><strong class="source-inline"><span class="koboSpan" id="kobo.592.1" xmlns:="http://www.w3.org/1999/xhtml">.txt</span></strong><span class="koboSpan" id="kobo.593.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.594.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.595.1" xmlns:="http://www.w3.org/1999/xhtml">csv</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.596.1" xmlns:="http://www.w3.org/1999/xhtml"> file.</span></span></p>
<p class="list-inset"><em class="italic"><span class="koboSpan" id="kobo.597.1" xmlns:="http://www.w3.org/1999/xhtml">Step 6</span></em><span class="koboSpan" id="kobo.598.1" xmlns:="http://www.w3.org/1999/xhtml"> returns </span><strong class="source-inline"><span class="koboSpan" id="kobo.599.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.600.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrames with the transformed train and test sets. </span><span class="koboSpan" id="kobo.600.2" xmlns:="http://www.w3.org/1999/xhtml">Go ahead and compare the variables before and after the transformations. </span><span class="koboSpan" id="kobo.600.3" xmlns:="http://www.w3.org/1999/xhtml">You’ll see that the distributions did not change, but the variables are centered at </span><strong class="source-inline"><span class="koboSpan" id="kobo.601.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.602.1" xmlns:="http://www.w3.org/1999/xhtml">, and their v</span><a id="_idTextAnchor939"/><a id="_idTextAnchor940"/><span class="koboSpan" id="kobo.603.1" xmlns:="http://www.w3.org/1999/xhtml">alues lie between </span><strong class="source-inline"><span class="koboSpan" id="kobo.604.1" xmlns:="http://www.w3.org/1999/xhtml">-1</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.605.1" xmlns:="http://www.w3.org/1999/xhtml">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.606.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.607.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-210"><a id="_idTextAnchor941"/><span class="koboSpan" id="kobo.608.1" xmlns:="http://www.w3.org/1999/xhtml">How it works…</span></h2>
<p><span class="koboSpan" id="kobo.609.1" xmlns:="http://www.w3.org/1999/xhtml">To implement mean normalization, we captured the mean values of the numerical variables in the train set using </span><strong class="source-inline"><span class="koboSpan" id="kobo.610.1" xmlns:="http://www.w3.org/1999/xhtml">mean()</span></strong><span class="koboSpan" id="kobo.611.1" xmlns:="http://www.w3.org/1999/xhtml"> from </span><strong class="source-inline"><span class="koboSpan" id="kobo.612.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.613.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.613.2" xmlns:="http://www.w3.org/1999/xhtml">Next, we determined the difference between the maximum and minimum values of the numerical variables in the train set by utilizing </span><strong class="source-inline"><span class="koboSpan" id="kobo.614.1" xmlns:="http://www.w3.org/1999/xhtml">max()</span></strong><span class="koboSpan" id="kobo.615.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.616.1" xmlns:="http://www.w3.org/1999/xhtml">min()</span></strong><span class="koboSpan" id="kobo.617.1" xmlns:="http://www.w3.org/1999/xhtml"> from </span><strong class="source-inline"><span class="koboSpan" id="kobo.618.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.619.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.619.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, we used the </span><strong class="source-inline"><span class="koboSpan" id="kobo.620.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.621.1" xmlns:="http://www.w3.org/1999/xhtml"> series returned by these functions containing the mean values and the value ranges to normalize the train and test sets. </span><span class="koboSpan" id="kobo.621.2" xmlns:="http://www.w3.org/1999/xhtml">We subtracted the mean from each observation in our train and test sets</span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.622.1" xmlns:="http://www.w3.org/1999/xhtml"> and divided the result by the value ranges. </span><span class="koboSpan" id="kobo.622.2" xmlns:="http://www.w3.org/1999/xhtml">This returned the normalized vari</span><a id="_idTextAnchor942"/><a id="_idTextAnchor943"/><span class="koboSpan" id="kobo.623.1" xmlns:="http://www.w3.org/1999/xhtml">ables in a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.624.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.625.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame.</span></span></p>
<h2 id="_idParaDest-211"><a id="_idTextAnchor944"/><span class="koboSpan" id="kobo.626.1" xmlns:="http://www.w3.org/1999/xhtml">There’s more...</span></h2>
<p><span class="koboSpan" id="kobo.627.1" xmlns:="http://www.w3.org/1999/xhtml">There is no dedicated scikit-learn transformer to implement mean normalization, but we can combine the use of two transformers to </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1" xmlns:="http://www.w3.org/1999/xhtml">do so.</span></span></p>
<p><span class="koboSpan" id="kobo.629.1" xmlns:="http://www.w3.org/1999/xhtml">To do this, we need to import </span><strong class="source-inline"><span class="koboSpan" id="kobo.630.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong><span class="koboSpan" id="kobo.631.1" xmlns:="http://www.w3.org/1999/xhtml"> and load the data, just like we did in </span><em class="italic"><span class="koboSpan" id="kobo.632.1" xmlns:="http://www.w3.org/1999/xhtml">Steps 1</span></em><span class="koboSpan" id="kobo.633.1" xmlns:="http://www.w3.org/1999/xhtml"> to</span><em class="italic"><span class="koboSpan" id="kobo.634.1" xmlns:="http://www.w3.org/1999/xhtml"> 3</span></em><span class="koboSpan" id="kobo.635.1" xmlns:="http://www.w3.org/1999/xhtml"> in the </span><em class="italic"><span class="koboSpan" id="kobo.636.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></em><span class="koboSpan" id="kobo.637.1" xmlns:="http://www.w3.org/1999/xhtml"> section of this recipe. </span><span class="koboSpan" id="kobo.637.2" xmlns:="http://www.w3.org/1999/xhtml">Then, follow </span><span class="No-Break"><span class="koboSpan" id="kobo.638.1" xmlns:="http://www.w3.org/1999/xhtml">these steps:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.639.1" xmlns:="http://www.w3.org/1999/xhtml">Import the </span><span class="No-Break"><span class="koboSpan" id="kobo.640.1" xmlns:="http://www.w3.org/1999/xhtml">scikit-learn transformers:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.641.1" xmlns:="http://www.w3.org/1999/xhtml">
from sklearn.preprocessing import (
    StandardScaler, RobustScaler
)</span></pre></li> <li><span class="koboSpan" id="kobo.642.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up </span><strong class="source-inline"><span class="koboSpan" id="kobo.643.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.644.1" xmlns:="http://www.w3.org/1999/xhtml"> to learn and subtract </span><a id="_idTextAnchor945"/><span class="koboSpan" id="kobo.645.1" xmlns:="http://www.w3.org/1999/xhtml">the mean without dividing the result by the </span><span class="No-Break"><span class="koboSpan" id="kobo.646.1" xmlns:="http://www.w3.org/1999/xhtml">standard deviation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.647.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler_mean = StandardScaler(
    with_mean=True, with_std=False,
).set_output(transform="pandas")</span></pre></li> <li><span class="koboSpan" id="kobo.648.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s set up </span><strong class="source-inline"><span class="koboSpan" id="kobo.649.1" xmlns:="http://www.w3.org/1999/xhtml">RobustScaler()</span></strong><span class="koboSpan" id="kobo.650.1" xmlns:="http://www.w3.org/1999/xhtml"> so that it does not remove the median from the values but divides them by the value range – that is, the difference between the maximum and </span><span class="No-Break"><span class="koboSpan" id="kobo.651.1" xmlns:="http://www.w3.org/1999/xhtml">minimum values:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.652.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler_minmax = RobustScaler(
    with_centering=False,
    with_scaling=True,
    quantile_range=(0, 100)
).set_output(transform="pandas")</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.653.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.654.1" xmlns:="http://www.w3.org/1999/xhtml">To divide by the difference between the minimum and maximum values, we need to specify </span><strong class="source-inline"><span class="koboSpan" id="kobo.655.1" xmlns:="http://www.w3.org/1999/xhtml">(0, 100)</span></strong><span class="koboSpan" id="kobo.656.1" xmlns:="http://www.w3.org/1999/xhtml"> in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.657.1" xmlns:="http://www.w3.org/1999/xhtml">quantile_range</span></strong><span class="koboSpan" id="kobo.658.1" xmlns:="http://www.w3.org/1999/xhtml"> argument </span><span class="No-Break"><span class="koboSpan" id="kobo.659.1" xmlns:="http://www.w3.org/1999/xhtml">of </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.660.1" xmlns:="http://www.w3.org/1999/xhtml">RobustScaler()</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.661.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.662.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit the scalers to the train set so that they learn and store the mean, maximum, and </span><span class="No-Break"><span class="koboSpan" id="kobo.663.1" xmlns:="http://www.w3.org/1999/xhtml">minimum values:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.664.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler_mean.fit(X_train)
scaler_minmax.fit(X_train)</span></pre></li> <li><span class="koboSpan" id="kobo.665.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s apply mean normalization to the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.666.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.667.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train_scaled = scaler_minmax.transform(
    scaler_mean.transform(X_train)
)
X_test_scaled = scaler_minmax.transform(
    scaler_mean.transform(X_test)
)</span></pre></li> </ol>
<p><span class="koboSpan" id="kobo.668.1" xmlns:="http://www.w3.org/1999/xhtml">We transformed the data with </span><strong class="source-inline"><span class="koboSpan" id="kobo.669.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.670.1" xmlns:="http://www.w3.org/1999/xhtml"> to remove the mean and then transformed the resulting DataFrame with </span><strong class="source-inline"><span class="koboSpan" id="kobo.671.1" xmlns:="http://www.w3.org/1999/xhtml">RobustScaler()</span></strong><span class="koboSpan" id="kobo.672.1" xmlns:="http://www.w3.org/1999/xhtml"> to divide the result by the range between the minimum and maximum values. </span><span class="koboSpan" id="kobo.672.2" xmlns:="http://www.w3.org/1999/xhtml">We described the functionality of </span><strong class="source-inline"><span class="koboSpan" id="kobo.673.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.674.1" xmlns:="http://www.w3.org/1999/xhtml"> in this chapter’s </span><em class="italic"><span class="koboSpan" id="kobo.675.1" xmlns:="http://www.w3.org/1999/xhtml">Standardizing the features</span></em><span class="koboSpan" id="kobo.676.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe and </span><strong class="source-inline"><span class="koboSpan" id="kobo.677.1" xmlns:="http://www.w3.org/1999/xhtml">RobustScaler()</span></strong><span class="koboSpan" id="kobo.678.1" xmlns:="http://www.w3.org/1999/xhtml"> in the </span><em class="italic"><span class="koboSpan" id="kobo.679.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling with the median and quant</span><a id="_idTextAnchor946"/><a id="_idTextAnchor947"/><span class="koboSpan" id="kobo.680.1" xmlns:="http://www.w3.org/1999/xhtml">iles</span></em><span class="koboSpan" id="kobo.681.1" xmlns:="http://www.w3.org/1999/xhtml"> recipe of </span><span class="No-Break"><span class="koboSpan" id="kobo.682.1" xmlns:="http://www.w3.org/1999/xhtml">this chapter.</span></span></p>
<h1 id="_idParaDest-212"><span class="koboSpan" id="kobo.683.1" xmlns:="http://www.w3.org/1999/xhtml">Implementing maximum absol</span><a id="_idTextAnchor948"/><span class="koboSpan" id="kobo.684.1" xmlns:="http://www.w3.org/1999/xhtml">ute scaling</span></h1>
<p><span class="koboSpan" id="kobo.685.1" xmlns:="http://www.w3.org/1999/xhtml">Maximum absolute scaling </span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.686.1" xmlns:="http://www.w3.org/1999/xhtml">scales the data to its maximum value – that is, it divides every observation by the maximum value of </span><span class="No-Break"><span class="koboSpan" id="kobo.687.1" xmlns:="http://www.w3.org/1999/xhtml">the variable:</span></span></p>
<p><span class="koboSpan" id="kobo.688.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfrac&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;m&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;a&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;x&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mfrac&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/29.png" style="vertical-align:-0.496em;height:1.312em;width:5.443em"/></span></p>
<p><span class="koboSpan" id="kobo.689.1" xmlns:="http://www.w3.org/1999/xhtml">As a result, the maximum value of each feature will be </span><strong class="source-inline"><span class="koboSpan" id="kobo.690.1" xmlns:="http://www.w3.org/1999/xhtml">1.0</span></strong><span class="koboSpan" id="kobo.691.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.691.2" xmlns:="http://www.w3.org/1999/xhtml">Note that maximum absolute scaling does not center the data, and hence, it’s suitable for scaling sparse data. </span><span class="koboSpan" id="kobo.691.3" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will implement maximum absolute scaling </span><span class="No-Break"><span class="koboSpan" id="kobo.692.1" xmlns:="http://www.w3.org/1999/xhtml">with scikit-learn.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.693.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.694.1" xmlns:="http://www.w3.org/1999/xhtml">Scikit-learn recommends using this transformer on data that is cen</span><a id="_idTextAnchor949"/><a id="_idTextAnchor950"/><span class="koboSpan" id="kobo.695.1" xmlns:="http://www.w3.org/1999/xhtml">tered at </span><strong class="source-inline"><span class="koboSpan" id="kobo.696.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.697.1" xmlns:="http://www.w3.org/1999/xhtml"> or on </span><span class="No-Break"><span class="koboSpan" id="kobo.698.1" xmlns:="http://www.w3.org/1999/xhtml">sparse data.</span></span></p>
<h2 id="_idParaDest-213"><a id="_idTextAnchor951"/><span class="koboSpan" id="kobo.699.1" xmlns:="http://www.w3.org/1999/xhtml">Getting ready</span></h2>
<p><span class="koboSpan" id="kobo.700.1" xmlns:="http://www.w3.org/1999/xhtml">Maximum absolute scaling</span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.701.1" xmlns:="http://www.w3.org/1999/xhtml"> was specifically designed to scale sparse data. </span><span class="koboSpan" id="kobo.701.2" xmlns:="http://www.w3.org/1999/xhtml">Thus, we will use a bag-of-words dataset that contains sparse variables for the recipe. </span><span class="koboSpan" id="kobo.701.3" xmlns:="http://www.w3.org/1999/xhtml">In this dataset, the variables are words, the observations are documents, and the values are the number of times each word appears in the document. </span><span class="koboSpan" id="kobo.701.4" xmlns:="http://www.w3.org/1999/xhtml">Most entries </span><a id="_idTextAnchor952"/><span class="koboSpan" id="kobo.702.1" xmlns:="http://www.w3.org/1999/xhtml">in the data </span><span class="No-Break"><span class="koboSpan" id="kobo.703.1" xmlns:="http://www.w3.org/1999/xhtml">are </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.704.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.705.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.706.1" xmlns:="http://www.w3.org/1999/xhtml">We will use a dataset consisting of a bag of words, which is available in the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Bag+of+Words), which is licensed under CC BY </span><span class="No-Break"><span class="koboSpan" id="kobo.707.1" xmlns:="http://www.w3.org/1999/xhtml">4.0 (</span></span><span class="No-Break"><span class="koboSpan" id="kobo.708.1" xmlns:="http://www.w3.org/1999/xhtml">https://creativecommons.org/licenses/by/4.0/legalcode</span></span><span class="No-Break"><span class="koboSpan" id="kobo.709.1" xmlns:="http://www.w3.org/1999/xhtml">).</span></span></p>
<p><span class="koboSpan" id="kobo.710.1" xmlns:="http://www.w3.org/1999/xhtml">I downloaded and prepared a small bag of words representing a simplified version of one of those datasets. </span><span class="koboSpan" id="kobo.710.2" xmlns:="http://www.w3.org/1999/xhtml">You will find this dataset in the accompanying GitHub </span><span class="No-Break"><span class="koboSpan" id="kobo.711.1" xmlns:="http://www.w3.org/1999/xhtml">repository: </span></span><a href="https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/tree/main/ch07-scaling"><span class="No-Break"><span class="koboSpan" id="kobo.712.1" xmlns:="http://www.w3.org/1999/xhtml">https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/tree/main/ch07-scaling</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.713.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<h2 id="_idParaDest-214"><a id="_idTextAnchor953"/><span class="koboSpan" id="kobo.714.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.715.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s begin by</span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.716.1" xmlns:="http://www.w3.org/1999/xhtml"> importing the required packages and loading </span><span class="No-Break"><span class="koboSpan" id="kobo.717.1" xmlns:="http://www.w3.org/1999/xhtml">the dataset:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.718.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the required libraries and </span><span class="No-Break"><span class="koboSpan" id="kobo.719.1" xmlns:="http://www.w3.org/1999/xhtml">the scaler:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.720.1" xmlns:="http://www.w3.org/1999/xhtml">
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MaxAbsScaler</span></pre></li> <li><span class="koboSpan" id="kobo.721.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the </span><span class="No-Break"><span class="koboSpan" id="kobo.722.1" xmlns:="http://www.w3.org/1999/xhtml">bag-of-words dataset:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.723.1" xmlns:="http://www.w3.org/1999/xhtml">
data = pd.read_csv("bag_of_words.csv")</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.724.1" xmlns:="http://www.w3.org/1999/xhtml">If we execute </span><strong class="source-inline"><span class="koboSpan" id="kobo.725.1" xmlns:="http://www.w3.org/1999/xhtml">data.head()</span></strong><span class="koboSpan" id="kobo.726.1" xmlns:="http://www.w3.org/1999/xhtml">, we will see the DataFrame consisting of the words as columns, the documents as rows, and the number of times each word appeared in a document </span><span class="No-Break"><span class="koboSpan" id="kobo.727.1" xmlns:="http://www.w3.org/1999/xhtml">as values:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer127">
<span class="koboSpan" id="kobo.728.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 7.5 – DataFrame with the bag of words" src="image/B22396_07_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.729.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 7.5 – DataFrame with the bag of words</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.730.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.731.1" xmlns:="http://www.w3.org/1999/xhtml">Although we omit this step in the recipe, remember that the maximum absolute values should be learned from a training dataset only. </span><span class="koboSpan" id="kobo.731.2" xmlns:="http://www.w3.org/1999/xhtml">Split the dataset into train and test sets when carrying out </span><span class="No-Break"><span class="koboSpan" id="kobo.732.1" xmlns:="http://www.w3.org/1999/xhtml">your analysis.</span></span></p>
<ol>
<li value="3"><span class="koboSpan" id="kobo.733.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set</span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.734.1" xmlns:="http://www.w3.org/1999/xhtml"> up </span><strong class="source-inline"><span class="koboSpan" id="kobo.735.1" xmlns:="http://www.w3.org/1999/xhtml">MaxAbsScaler()</span></strong><span class="koboSpan" id="kobo.736.1" xmlns:="http://www.w3.org/1999/xhtml"> and fit it to the data so that it learns the variables’ </span><span class="No-Break"><span class="koboSpan" id="kobo.737.1" xmlns:="http://www.w3.org/1999/xhtml">maximum values:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.738.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler = MaxAbsScaler().set_output(
    transform="pandas")
scaler.fit(data)</span></pre></li> <li><span class="koboSpan" id="kobo.739.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s scale the variables by utilizing the </span><span class="No-Break"><span class="koboSpan" id="kobo.740.1" xmlns:="http://www.w3.org/1999/xhtml">trained scaler:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.741.1" xmlns:="http://www.w3.org/1999/xhtml">
data_scaled = scaler.transform(data)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.742.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><strong class="source-inline"><span class="koboSpan" id="kobo.743.1" xmlns:="http://www.w3.org/1999/xhtml">MaxAbsScaler ()</span></strong><span class="koboSpan" id="kobo.744.1" xmlns:="http://www.w3.org/1999/xhtml"> stores the maximum values in its </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.745.1" xmlns:="http://www.w3.org/1999/xhtml">max_ab</span><a id="_idTextAnchor954"/><span class="koboSpan" id="kobo.746.1" xmlns:="http://www.w3.org/1999/xhtml">s_</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.747.1" xmlns:="http://www.w3.org/1999/xhtml"> attribute.</span></span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.748.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s display the maximum values stored by </span><span class="No-Break"><span class="koboSpan" id="kobo.749.1" xmlns:="http://www.w3.org/1999/xhtml">the scaler:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.750.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler.max_abs_</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.751.1" xmlns:="http://www.w3.org/1999/xhtml">In the following output, we see the maximum number of times each word appeared in </span><span class="No-Break"><span class="koboSpan" id="kobo.752.1" xmlns:="http://www.w3.org/1999/xhtml">a document:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.753.1" xmlns:="http://www.w3.org/1999/xhtml">array([ 7.,  6.,  2.,  2., 11.,  4.,  3.,  6., 52.,  2.])</span></strong></pre><p class="list-inset"><span class="koboSpan" id="kobo.754.1" xmlns:="http://www.w3.org/1999/xhtml">To follow up, let’s plot the distributions of the original and </span><span class="No-Break"><span class="koboSpan" id="kobo.755.1" xmlns:="http://www.w3.org/1999/xhtml">scaled variables.</span></span></p></li> <li><span class="koboSpan" id="kobo.756.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s make a histogram with the bag of words before </span><span class="No-Break"><span class="koboSpan" id="kobo.757.1" xmlns:="http://www.w3.org/1999/xhtml">the scaling:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.758.1" xmlns:="http://www.w3.org/1999/xhtml">
data.hist(bins=20, figsize=(20, 20))
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.759.1" xmlns:="http://www.w3.org/1999/xhtml">In the </span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.760.1" xmlns:="http://www.w3.org/1999/xhtml">following output, we see histograms with the number of times e</span><a id="_idTextAnchor955"/><span class="koboSpan" id="kobo.761.1" xmlns:="http://www.w3.org/1999/xhtml">ach word appears in </span><span class="No-Break"><span class="koboSpan" id="kobo.762.1" xmlns:="http://www.w3.org/1999/xhtml">a document:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer128">
<span class="koboSpan" id="kobo.763.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 7.6 – Histograms with differen﻿t word counts" src="image/B22396_07_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.764.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 7.6 – Histograms with differen</span><a id="_idTextAnchor956"/><span class="koboSpan" id="kobo.765.1" xmlns:="http://www.w3.org/1999/xhtml">t word counts</span></p>
<ol>
<li value="7"><span class="koboSpan" id="kobo.766.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s make a histogram with the </span><span class="No-Break"><span class="koboSpan" id="kobo.767.1" xmlns:="http://www.w3.org/1999/xhtml">scaled variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.768.1" xmlns:="http://www.w3.org/1999/xhtml">
data_scaled.hist(bins=20, figsize=(20, 20))
plt.show()</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.769.1" xmlns:="http://www.w3.org/1999/xhtml">In the following output, we can corroborate the change of scale of the v</span><a id="_idTextAnchor957"/><span class="koboSpan" id="kobo.770.1" xmlns:="http://www.w3.org/1999/xhtml">ariables, but their </span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.771.1" xmlns:="http://www.w3.org/1999/xhtml">distr</span><a id="_idTextAnchor958"/><span class="koboSpan" id="kobo.772.1" xmlns:="http://www.w3.org/1999/xhtml">ibution shape remains </span><span class="No-Break"><span class="koboSpan" id="kobo.773.1" xmlns:="http://www.w3.org/1999/xhtml">the same:</span></span></p></li> </ol>
<div>
<div class="IMG---Figure" id="_idContainer129">
<span class="koboSpan" id="kobo.774.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 7.7 – Histograms of the word counts after the scaling" src="image/B22396_07_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.775.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 7.7 – Histograms of the word counts after the scaling</span></p>
<p><span class="koboSpan" id="kobo.776.1" xmlns:="http://www.w3.org/1999/xhtml">With scaling to the maximum absolute value, we linearly scale down </span><a id="_idTextAnchor959"/><a id="_idTextAnchor960"/><span class="koboSpan" id="kobo.777.1" xmlns:="http://www.w3.org/1999/xhtml">the magnitude of </span><span class="No-Break"><span class="koboSpan" id="kobo.778.1" xmlns:="http://www.w3.org/1999/xhtml">the features.</span></span></p>
<p><span class="koboSpan" id="kobo.779.1" xmlns:="http://www.w3.org/1999/xhtml">How </span><span class="No-Break"><span class="koboSpan" id="kobo.780.1" xmlns:="http://www.w3.org/1999/xhtml">it works...</span></span></p>
<p><span class="koboSpan" id="kobo.781.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we</span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.782.1" xmlns:="http://www.w3.org/1999/xhtml"> scaled the sparse variables of a bag of words to their absolute maximum values by using </span><strong class="source-inline"><span class="koboSpan" id="kobo.783.1" xmlns:="http://www.w3.org/1999/xhtml">MaxAbsScaler()</span></strong><span class="koboSpan" id="kobo.784.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.784.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.785.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.786.1" xmlns:="http://www.w3.org/1999/xhtml">, the scaler learned the maximum absolute values for each variable and stored them in its </span><strong class="source-inline"><span class="koboSpan" id="kobo.787.1" xmlns:="http://www.w3.org/1999/xhtml">max_abs_</span></strong><span class="koboSpan" id="kobo.788.1" xmlns:="http://www.w3.org/1999/xhtml"> attribute. </span><span class="koboSpan" id="kobo.788.2" xmlns:="http://www.w3.org/1999/xhtml">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.789.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.790.1" xmlns:="http://www.w3.org/1999/xhtml">, the scaler divided the variables by their ab</span><a id="_idTextAnchor961"/><span class="koboSpan" id="kobo.791.1" xmlns:="http://www.w3.org/1999/xhtml">solute maximum values, returning a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.792.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.793.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.794.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.795.1" xmlns:="http://www.w3.org/1999/xhtml">Remember that you can change the output container to a NumPy array or a </span><strong class="source-inline"><span class="koboSpan" id="kobo.796.1" xmlns:="http://www.w3.org/1999/xhtml">polars</span></strong><span class="koboSpan" id="kobo.797.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame through the </span><strong class="source-inline"><span class="koboSpan" id="kobo.798.1" xmlns:="http://www.w3.org/1999/xhtml">set_output()</span></strong><span class="koboSpan" id="kobo.799.1" xmlns:="http://www.w3.org/1999/xhtml"> method of the scik</span><a id="_idTextAnchor962"/><a id="_idTextAnchor963"/><span class="koboSpan" id="kobo.800.1" xmlns:="http://www.w3.org/1999/xhtml">it-learn </span><span class="No-Break"><span class="koboSpan" id="kobo.801.1" xmlns:="http://www.w3.org/1999/xhtml">library’s transformers.</span></span></p>
<h2 id="_idParaDest-215"><span class="koboSpan" id="kobo.802.1" xmlns:="http://www.w3.org/1999/xhtml">There’s m</span><a id="_idTextAnchor964"/><span class="koboSpan" id="kobo.803.1" xmlns:="http://www.w3.org/1999/xhtml">ore...</span></h2>
<p><span class="koboSpan" id="kobo.804.1" xmlns:="http://www.w3.org/1999/xhtml">If you want to center the variables’ distribution at </span><strong class="source-inline"><span class="koboSpan" id="kobo.805.1" xmlns:="http://www.w3.org/1999/xhtml">0</span></strong><span class="koboSpan" id="kobo.806.1" xmlns:="http://www.w3.org/1999/xhtml"> and then scale them to their absolute maximum, you can do so by combining the use of two scikit-learn transformers within </span><span class="No-Break"><span class="koboSpan" id="kobo.807.1" xmlns:="http://www.w3.org/1999/xhtml">a pipeline:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.808.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the required libraries, transformers, </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1" xmlns:="http://www.w3.org/1999/xhtml">and functions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.810.1" xmlns:="http://www.w3.org/1999/xhtml">
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import (
    MaxAbsScaler, StandardScaler)
from sklearn.pipeline import Pipeline</span></pre></li> <li><span class="koboSpan" id="kobo.811.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the California housing dataset and split it into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.812.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.813.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)
X.drop( labels=[ "Latitude",
    "Longitude"], axis=1, inplace=True)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.814.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up </span><strong class="source-inline"><span class="koboSpan" id="kobo.815.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.816.1" xmlns:="http://www.w3.org/1999/xhtml"> from scikit-learn so that it learns and subtracts the mean but does not divide the result by the </span><span class="No-Break"><span class="koboSpan" id="kobo.817.1" xmlns:="http://www.w3.org/1999/xhtml">standard deviation:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.818.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler_mean = StandardScaler(
    with_mean=True, with_std=False)</span></pre></li> <li><span class="koboSpan" id="kobo.819.1" xmlns:="http://www.w3.org/1999/xhtml">Now, let’s set up </span><strong class="source-inline"><span class="koboSpan" id="kobo.820.1" xmlns:="http://www.w3.org/1999/xhtml">MaxAbsScaler()</span></strong><span class="koboSpan" id="kobo.821.1" xmlns:="http://www.w3.org/1999/xhtml"> with its </span><span class="No-Break"><span class="koboSpan" id="kobo.822.1" xmlns:="http://www.w3.org/1999/xhtml">default parameters:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.823.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler_maxabs = MaxAbsScaler()</span></pre></li> <li><span class="koboSpan" id="kobo.824.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s include both scalers within a pipeline that returns </span><span class="No-Break"><span class="koboSpan" id="kobo.825.1" xmlns:="http://www.w3.org/1999/xhtml">pandas DataFrames:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.826.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler = Pipeline([
    ("scaler_mean", scaler_mean),
    ("scaler_max", scaler_maxabs),
]).set_output(transform="pandas")</span></pre></li> <li><span class="koboSpan" id="kobo.827.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s fit the scalers to the train set so that they learn the </span><span class="No-Break"><span class="koboSpan" id="kobo.828.1" xmlns:="http://www.w3.org/1999/xhtml">required parameters:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.829.1" xmlns:="http://www.w3.org/1999/xhtml">
s</span><a id="_idTextAnchor965"/><span class="koboSpan" id="kobo.830.1" xmlns:="http://www.w3.org/1999/xhtml">caler.fit(X_train)</span></pre></li> <li><span class="koboSpan" id="kobo.831.1" xmlns:="http://www.w3.org/1999/xhtml">Finally, let’s transform the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.832.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.833.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.834.1" xmlns:="http://www.w3.org/1999/xhtml">The pipeline applies </span><strong class="source-inline"><span class="koboSpan" id="kobo.835.1" xmlns:="http://www.w3.org/1999/xhtml">StandardScaler()</span></strong><span class="koboSpan" id="kobo.836.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.837.1" xmlns:="http://www.w3.org/1999/xhtml">MaxAbsScaler()</span></strong><span class="koboSpan" id="kobo.838.1" xmlns:="http://www.w3.org/1999/xhtml"> in sequence to first remove the mean and then scale </span><a id="_idTextAnchor966"/><span class="koboSpan" id="kobo.839.1" xmlns:="http://www.w3.org/1999/xhtml">the resulting </span><a id="_idTextAnchor967"/><span class="koboSpan" id="kobo.840.1" xmlns:="http://www.w3.org/1999/xhtml">va</span><a id="_idTextAnchor968"/><a id="_idTextAnchor969"/><span class="koboSpan" id="kobo.841.1" xmlns:="http://www.w3.org/1999/xhtml">riables to their </span><span class="No-Break"><span class="koboSpan" id="kobo.842.1" xmlns:="http://www.w3.org/1999/xhtml">maximum values.</span></span></p></li> </ol>
<h1 id="_idParaDest-216"><a id="_idTextAnchor970"/><span class="koboSpan" id="kobo.843.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling to vector unit length</span></h1>
<p><span class="koboSpan" id="kobo.844.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling to the vector unit length involves scaling individual observations (not features) to have a unit norm. </span><span class="koboSpan" id="kobo.844.2" xmlns:="http://www.w3.org/1999/xhtml">Each sample (that is, each row of the data) is rescaled independently of other samples so that its norm equals one. </span><span class="koboSpan" id="kobo.844.3" xmlns:="http://www.w3.org/1999/xhtml">Each </span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.845.1" xmlns:="http://www.w3.org/1999/xhtml">row constitutes a </span><strong class="bold"><span class="koboSpan" id="kobo.846.1" xmlns:="http://www.w3.org/1999/xhtml">feature vector</span></strong><span class="koboSpan" id="kobo.847.1" xmlns:="http://www.w3.org/1999/xhtml"> containing the values of every variable for that row. </span><span class="koboSpan" id="kobo.847.2" xmlns:="http://www.w3.org/1999/xhtml">Hence, with this scaling method, we rescale the </span><span class="No-Break"><span class="koboSpan" id="kobo.848.1" xmlns:="http://www.w3.org/1999/xhtml">feature vector.</span></span></p>
<p><span class="koboSpan" id="kobo.849.1" xmlns:="http://www.w3.org/1999/xhtml">The norm of a vector is a measure of its magnitude or length in a given space and it can be determined by using the Manhattan (</span><em class="italic"><span class="koboSpan" id="kobo.850.1" xmlns:="http://www.w3.org/1999/xhtml">l1</span></em><span class="koboSpan" id="kobo.851.1" xmlns:="http://www.w3.org/1999/xhtml">) or the Euclidean (</span><em class="italic"><span class="koboSpan" id="kobo.852.1" xmlns:="http://www.w3.org/1999/xhtml">l2</span></em><span class="koboSpan" id="kobo.853.1" xmlns:="http://www.w3.org/1999/xhtml">) distance. </span><span class="koboSpan" id="kobo.853.2" xmlns:="http://www.w3.org/1999/xhtml">The Manhattan distance is given by the sum of the absolute components of </span><span class="No-Break"><span class="koboSpan" id="kobo.854.1" xmlns:="http://www.w3.org/1999/xhtml">the vector:</span></span></p>
<p><span class="koboSpan" id="kobo.855.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mfenced open=&quot;|&quot; close=&quot;|&quot;&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/mfenced&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;…&lt;/mo&gt;&lt;mo&gt;..&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;|&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/30.png" style="vertical-align:-0.383em;height:1.274em;width:11.278em"/></span></p>
<p><span class="koboSpan" id="kobo.856.1" xmlns:="http://www.w3.org/1999/xhtml">The Euclidean distance is given by the square root of the square sum of the component of </span><span class="No-Break"><span class="koboSpan" id="kobo.857.1" xmlns:="http://www.w3.org/1999/xhtml">the vector:</span></span></p>
<p><span class="koboSpan" id="kobo.858.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mfenced&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msubsup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msubsup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mo&gt;…&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;msubsup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msubsup&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/31.png" style="vertical-align:-0.380em;height:1.253em;width:10.323em"/></span></p>
<p><span class="koboSpan" id="kobo.859.1" xmlns:="http://www.w3.org/1999/xhtml">Here, </span><span class="koboSpan" id="kobo.860.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/32.png" style="vertical-align:-0.333em;height:0.781em;width:2.662em"/></span><span class="koboSpan" id="kobo.861.1" xmlns:="http://www.w3.org/1999/xhtml">and </span><span class="koboSpan" id="kobo.862.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/33.png" style="vertical-align:-0.340em;height:0.788em;width:0.999em"/></span><span class="koboSpan" id="kobo.863.1" xmlns:="http://www.w3.org/1999/xhtml">are the values of variables </span><em class="italic"><span class="koboSpan" id="kobo.864.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></em><span class="koboSpan" id="kobo.865.1" xmlns:="http://www.w3.org/1999/xhtml">, </span><em class="italic"><span class="koboSpan" id="kobo.866.1" xmlns:="http://www.w3.org/1999/xhtml">2</span></em><span class="koboSpan" id="kobo.867.1" xmlns:="http://www.w3.org/1999/xhtml">, and </span><em class="italic"><span class="koboSpan" id="kobo.868.1" xmlns:="http://www.w3.org/1999/xhtml">n</span></em><span class="koboSpan" id="kobo.869.1" xmlns:="http://www.w3.org/1999/xhtml"> for each observation. </span><span class="koboSpan" id="kobo.869.2" xmlns:="http://www.w3.org/1999/xhtml">Scaling to unit norm consists of dividing each feature vector’s value by either </span><em class="italic"><span class="koboSpan" id="kobo.870.1" xmlns:="http://www.w3.org/1999/xhtml">l1</span></em><span class="koboSpan" id="kobo.871.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><em class="italic"><span class="koboSpan" id="kobo.872.1" xmlns:="http://www.w3.org/1999/xhtml">l2</span></em><span class="koboSpan" id="kobo.873.1" xmlns:="http://www.w3.org/1999/xhtml">, so that after the</span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.874.1" xmlns:="http://www.w3.org/1999/xhtml"> scaling, the norm of the feature vector is </span><em class="italic"><span class="koboSpan" id="kobo.875.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></em><span class="koboSpan" id="kobo.876.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.876.2" xmlns:="http://www.w3.org/1999/xhtml">To be clear, we divide each of </span><span class="koboSpan" id="kobo.877.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/34.png" style="vertical-align:-0.333em;height:0.781em;width:2.626em"/></span><span class="koboSpan" id="kobo.878.1" xmlns:="http://www.w3.org/1999/xhtml">and </span><span class="koboSpan" id="kobo.879.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" src="image/35.png" style="vertical-align:-0.340em;height:0.788em;width:1.215em"/></span><span class="koboSpan" id="kobo.880.1" xmlns:="http://www.w3.org/1999/xhtml">by </span><em class="italic"><span class="koboSpan" id="kobo.881.1" xmlns:="http://www.w3.org/1999/xhtml">l1</span></em> <span class="No-Break"><span class="koboSpan" id="kobo.882.1" xmlns:="http://www.w3.org/1999/xhtml">or </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.883.1" xmlns:="http://www.w3.org/1999/xhtml">l2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.884.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<p><span class="koboSpan" id="kobo.885.1" xmlns:="http://www.w3.org/1999/xhtml">This scaling procedure changes the variables’ distribution, as illustrated in the </span><span class="No-Break"><span class="koboSpan" id="kobo.886.1" xmlns:="http://www.w3.org/1999/xhtml">following figure:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer136">
<span class="koboSpan" id="kobo.887.1" xmlns:="http://www.w3.org/1999/xhtml"><img alt="Figure 7.8 – Distribution of a normal and skewed variable before and after scaling each observation’s feature vector to its norm" src="image/B22396_07_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.888.1" xmlns:="http://www.w3.org/1999/xhtml">Figure 7.8 – Distribution of a normal and skewed variable before and after scaling each observation’s feature vector to its norm</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.889.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.890.1" xmlns:="http://www.w3.org/1999/xhtml">This scaling technique scales each observation and not each variable. </span><span class="koboSpan" id="kobo.890.2" xmlns:="http://www.w3.org/1999/xhtml">The scaling methods that we discussed so far in this chapter aimed at shifting and resetting the scale of the variables’ distribution. </span><span class="koboSpan" id="kobo.890.3" xmlns:="http://www.w3.org/1999/xhtml">When we scale to the unit length, however, we normalize each observation individually, contemplating </span><a id="_idTextAnchor971"/><span class="koboSpan" id="kobo.891.1" xmlns:="http://www.w3.org/1999/xhtml">their values across</span><a id="_idTextAnchor972"/> <span class="No-Break"><span class="koboSpan" id="kobo.892.1" xmlns:="http://www.w3.org/1999/xhtml">all features.</span></span></p>
<p><span class="koboSpan" id="kobo.893.1" xmlns:="http://www.w3.org/1999/xhtml">Scaling </span><a id="_idIndexMarker556"/><span class="koboSpan" id="kobo.894.1" xmlns:="http://www.w3.org/1999/xhtml">to the unit norm can be used when utilizing kernels to quantify similarity for text classification and clustering. </span><span class="koboSpan" id="kobo.894.2" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we will scale each observation’s feature vector to a un</span><a id="_idTextAnchor973"/><a id="_idTextAnchor974"/><span class="koboSpan" id="kobo.895.1" xmlns:="http://www.w3.org/1999/xhtml">it length of </span><strong class="source-inline"><span class="koboSpan" id="kobo.896.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.897.1" xmlns:="http://www.w3.org/1999/xhtml">using scikit-learn.</span></span></p>
<h2 id="_idParaDest-217"><a id="_idTextAnchor975"/><span class="koboSpan" id="kobo.898.1" xmlns:="http://www.w3.org/1999/xhtml">How to do it...</span></h2>
<p><span class="koboSpan" id="kobo.899.1" xmlns:="http://www.w3.org/1999/xhtml">To begin, we’ll </span><a id="_idIndexMarker557"/><span class="koboSpan" id="kobo.900.1" xmlns:="http://www.w3.org/1999/xhtml">import the required packages, load the dataset, and prepare the train and </span><span class="No-Break"><span class="koboSpan" id="kobo.901.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.902.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s import the required Python packages, classes, </span><span class="No-Break"><span class="koboSpan" id="kobo.903.1" xmlns:="http://www.w3.org/1999/xhtml">and functions:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.904.1" xmlns:="http://www.w3.org/1999/xhtml">
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import Normalizer</span></pre></li> <li><span class="koboSpan" id="kobo.905.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s load the California housing dataset into a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.906.1" xmlns:="http://www.w3.org/1999/xhtml">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.907.1" xmlns:="http://www.w3.org/1999/xhtml"> DataFrame:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.908.1" xmlns:="http://www.w3.org/1999/xhtml">
X, y = fetch_california_housing(
    return_X_y=True, as_frame=True)
X.drop(labels=[
    "Latitude", "Longitude"], axi</span><a id="_idTextAnchor976"/><span class="koboSpan" id="kobo.909.1" xmlns:="http://www.w3.org/1999/xhtml">s=1, inplace=True)</span></pre></li> <li><span class="koboSpan" id="kobo.910.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s divide the data into train and </span><span class="No-Break"><span class="koboSpan" id="kobo.911.1" xmlns:="http://www.w3.org/1999/xhtml">test sets:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.912.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)</span></pre></li> <li><span class="koboSpan" id="kobo.913.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s set up the scikit-learn library’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.914.1" xmlns:="http://www.w3.org/1999/xhtml">Normalizer()</span></strong><span class="koboSpan" id="kobo.915.1" xmlns:="http://www.w3.org/1999/xhtml"> transformer to scale each observation to the Manhattan distance </span><span class="No-Break"><span class="koboSpan" id="kobo.916.1" xmlns:="http://www.w3.org/1999/xhtml">or </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.917.1" xmlns:="http://www.w3.org/1999/xhtml">l1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.918.1" xmlns:="http://www.w3.org/1999/xhtml">:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.919.1" xmlns:="http://www.w3.org/1999/xhtml">
scaler = Normalizer(norm='l1')</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.920.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.921.1" xmlns:="http://www.w3.org/1999/xhtml">To normalize to the Euclidean distance, you need to set the norm to </span><strong class="source-inline"><span class="koboSpan" id="kobo.922.1" xmlns:="http://www.w3.org/1999/xhtml">l2</span></strong><span class="koboSpan" id="kobo.923.1" xmlns:="http://www.w3.org/1999/xhtml"> using </span><strong class="source-inline"><span class="koboSpan" id="kobo.924.1" xmlns:="http://www.w3.org/1999/xhtml">scaler = </span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.925.1" xmlns:="http://www.w3.org/1999/xhtml">Normalizer(no</span><a id="_idTextAnchor977"/><span class="koboSpan" id="kobo.926.1" xmlns:="http://www.w3.org/1999/xhtml">rm='l2')</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.927.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.928.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s </span><a id="_idIndexMarker558"/><span class="koboSpan" id="kobo.929.1" xmlns:="http://www.w3.org/1999/xhtml">transform the train and test sets – that is, we’ll divide each observation’s feature vector by </span><span class="No-Break"><span class="koboSpan" id="kobo.930.1" xmlns:="http://www.w3.org/1999/xhtml">its norm:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.931.1" xmlns:="http://www.w3.org/1999/xhtml">
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.932.1" xmlns:="http://www.w3.org/1999/xhtml">We can calculate the length (that is, the Manhattan distance of each observation’s feature vector) using </span><strong class="source-inline"><span class="koboSpan" id="kobo.933.1" xmlns:="http://www.w3.org/1999/xhtml">linalg()</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.934.1" xmlns:="http://www.w3.org/1999/xhtml">from NumPy.</span></span></p></li> <li><span class="koboSpan" id="kobo.935.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s calculate the norm (Manhattan distance) before scaling </span><span class="No-Break"><span class="koboSpan" id="kobo.936.1" xmlns:="http://www.w3.org/1999/xhtml">the variables:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.937.1" xmlns:="http://www.w3.org/1999/xhtml">
np.round(np.linalg.norm(X_train, ord=1, axis=1), 1)</span></pre><p class="list-inset"><span class="koboSpan" id="kobo.938.1" xmlns:="http://www.w3.org/1999/xhtml">As expected, the norm of each </span><span class="No-Break"><span class="koboSpan" id="kobo.939.1" xmlns:="http://www.w3.org/1999/xhtml">observation varies:</span></span></p><pre class="source-code"><strong class="bold"><span class="koboSpan" id="kobo.940.1" xmlns:="http://www.w3.org/1999/xhtml">array([ 255.3,  889.1, 1421.7, ...,  744.6, 1099.5,</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.941.1" xmlns:="http://www.w3.org/1999/xhtml">           1048.9])</span></strong></pre></li> <li><span class="koboSpan" id="kobo.942.1" xmlns:="http://www.w3.org/1999/xhtml">Let’s now calculate the norm after </span><span class="No-Break"><span class="koboSpan" id="kobo.943.1" xmlns:="http://www.w3.org/1999/xhtml">the scaling:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.944.1" xmlns:="http://www.w3.org/1999/xhtml">
np.round(np.linalg.norm(
    X_train_scaled, ord=1, axis=1), 1)</span></pre></li> </ol>
<p class="callout-heading"><span class="koboSpan" id="kobo.945.1" xmlns:="http://www.w3.org/1999/xhtml">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.946.1" xmlns:="http://www.w3.org/1999/xhtml">You need to set </span><strong class="source-inline"><span class="koboSpan" id="kobo.947.1" xmlns:="http://www.w3.org/1999/xhtml">ord=1</span></strong><span class="koboSpan" id="kobo.948.1" xmlns:="http://www.w3.org/1999/xhtml"> for the Manhattan distance and </span><strong class="source-inline"><span class="koboSpan" id="kobo.949.1" xmlns:="http://www.w3.org/1999/xhtml">ord=2</span></strong><span class="koboSpan" id="kobo.950.1" xmlns:="http://www.w3.org/1999/xhtml"> for the Euclidean distance as arguments of NumPy’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.951.1" xmlns:="http://www.w3.org/1999/xhtml">linalg()</span></strong><span class="koboSpan" id="kobo.952.1" xmlns:="http://www.w3.org/1999/xhtml">function, depending on whether you scaled the features to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.953.1" xmlns:="http://www.w3.org/1999/xhtml">l1</span></strong><span class="koboSpan" id="kobo.954.1" xmlns:="http://www.w3.org/1999/xhtml"> or </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.955.1" xmlns:="http://www.w3.org/1999/xhtml">l2</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.956.1" xmlns:="http://www.w3.org/1999/xhtml"> norm.</span></span></p>
<p class="list-inset"><span class="koboSpan" id="kobo.957.1" xmlns:="http://www.w3.org/1999/xhtml">We see that the Manhattan distance of each feature vector is </span><strong class="source-inline"><span class="koboSpan" id="kobo.958.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.959.1" xmlns:="http://www.w3.org/1999/xhtml">after scaling:</span></span></p>
<pre class="source-code">
<a id="_idTextAnchor978"/><span class="koboSpan" id="kobo.960.1" xmlns:="http://www.w3.org/1999/xhtml">array([1., 1., 1., ..., 1., 1., 1.])</span></pre> <p><span class="koboSpan" id="kobo.961.1" xmlns:="http://www.w3.org/1999/xhtml">Based on the scikit-learn library’s documentation, this scaling method can be useful when using a quadratic form such as the dot-product or any other kernel to quantify </span><a id="_idTextAnchor979"/><a id="_idTextAnchor980"/><span class="koboSpan" id="kobo.962.1" xmlns:="http://www.w3.org/1999/xhtml">the similarity of a pair </span><span class="No-Break"><span class="koboSpan" id="kobo.963.1" xmlns:="http://www.w3.org/1999/xhtml">of samples.</span></span></p>
<h2 id="_idParaDest-218"><span class="koboSpan" id="kobo.964.1" xmlns:="http://www.w3.org/1999/xhtml">How it wo</span><a id="_idTextAnchor981"/><span class="koboSpan" id="kobo.965.1" xmlns:="http://www.w3.org/1999/xhtml">rks...</span></h2>
<p><span class="koboSpan" id="kobo.966.1" xmlns:="http://www.w3.org/1999/xhtml">In this recipe, we</span><a id="_idIndexMarker559"/><span class="koboSpan" id="kobo.967.1" xmlns:="http://www.w3.org/1999/xhtml"> scaled the observations from the California housing dataset to their feature vector unit norm by utilizing the Manhattan or Euclidean distance. </span><span class="koboSpan" id="kobo.967.2" xmlns:="http://www.w3.org/1999/xhtml">To scale the feature vectors, we created an instance of </span><strong class="source-inline"><span class="koboSpan" id="kobo.968.1" xmlns:="http://www.w3.org/1999/xhtml">Normalizer()</span></strong><span class="koboSpan" id="kobo.969.1" xmlns:="http://www.w3.org/1999/xhtml"> from scikit-learn and set the norm to </span><strong class="source-inline"><span class="koboSpan" id="kobo.970.1" xmlns:="http://www.w3.org/1999/xhtml">l1</span></strong><span class="koboSpan" id="kobo.971.1" xmlns:="http://www.w3.org/1999/xhtml"> for the Manhattan distance. </span><span class="koboSpan" id="kobo.971.2" xmlns:="http://www.w3.org/1999/xhtml">For the Euclidean distance, we set the norm to </span><strong class="source-inline"><span class="koboSpan" id="kobo.972.1" xmlns:="http://www.w3.org/1999/xhtml">l2</span></strong><span class="koboSpan" id="kobo.973.1" xmlns:="http://www.w3.org/1999/xhtml">. </span><span class="koboSpan" id="kobo.973.2" xmlns:="http://www.w3.org/1999/xhtml">Then, we applied the </span><strong class="source-inline"><span class="koboSpan" id="kobo.974.1" xmlns:="http://www.w3.org/1999/xhtml">fit()</span></strong><span class="koboSpan" id="kobo.975.1" xmlns:="http://www.w3.org/1999/xhtml"> method, although there were no parameters to be learned, as this normalization procedure depends exclusively on the values of the features for each observation. </span><span class="koboSpan" id="kobo.975.2" xmlns:="http://www.w3.org/1999/xhtml">Finally, with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.976.1" xmlns:="http://www.w3.org/1999/xhtml">transform()</span></strong><span class="koboSpan" id="kobo.977.1" xmlns:="http://www.w3.org/1999/xhtml"> method, the scaler divided each observation’s feat</span><a id="_idTextAnchor982"/><span class="koboSpan" id="kobo.978.1" xmlns:="http://www.w3.org/1999/xhtml">ure vector by its norm. </span><span class="koboSpan" id="kobo.978.2" xmlns:="http://www.w3.org/1999/xhtml">This returned </span><a id="_idTextAnchor983"/><span class="koboSpan" id="kobo.979.1" xmlns:="http://www.w3.org/1999/xhtml">a NumPy array with the scaled dataset. </span><span class="koboSpan" id="kobo.979.2" xmlns:="http://www.w3.org/1999/xhtml">After the scaling, we used NumPy’s </span><strong class="source-inline"><span class="koboSpan" id="kobo.980.1" xmlns:="http://www.w3.org/1999/xhtml">linalg.norm</span></strong><span class="koboSpan" id="kobo.981.1" xmlns:="http://www.w3.org/1999/xhtml"> function to calculate the norm (</span><strong class="source-inline"><span class="koboSpan" id="kobo.982.1" xmlns:="http://www.w3.org/1999/xhtml">l1</span></strong><span class="koboSpan" id="kobo.983.1" xmlns:="http://www.w3.org/1999/xhtml"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.984.1" xmlns:="http://www.w3.org/1999/xhtml">l2</span></strong><span class="koboSpan" id="kobo.985.1" xmlns:="http://www.w3.org/1999/xhtml">) of each vector to confirm that after the transformation, it </span><span class="No-Break"><span class="koboSpan" id="kobo.986.1" xmlns:="http://www.w3.org/1999/xhtml">was </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.987.1" xmlns:="http://www.w3.org/1999/xhtml">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.988.1" xmlns:="http://www.w3.org/1999/xhtml">.</span></span></p>
</div>
</body></html>