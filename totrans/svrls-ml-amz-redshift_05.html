<html><head></head><body>
		<div id="_idContainer099">
			<h1 id="_idParaDest-67" class="chapter-number"><a id="_idTextAnchor068"/>5</h1>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor069"/>Building Your First Machine Learning Model</h1>
			<p><a id="_idTextAnchor070"/>In the previous chapter, you learned about <strong class="bold">Redshift Machine Learning</strong> (<strong class="bold">ML</strong>) benefits such as eliminating data movement and how models can be created using simple <strong class="bold">Structured Query Language</strong> (<span class="No-Break"><strong class="bold">SQL</strong></span><span class="No-Break">) commands.</span></p>
			<p>In this chapter, you are going to build your first machine learning model by using the standard SQL dialect. Amazon Redshift makes it very easy to use familiar SQL dialect to train, deploy, and run inferences against machine learning models. This approach makes it easy for different data personas, for example, database developers, database engineers, and citizen data scientists, to train and build machine learning models without moving data outside of their data warehouse platform and without having to learn a new <span class="No-Break">programming language.</span></p>
			<p>In this chapter, you will learn about using Amazon Redshift ML simple CREATE MODEL, which uses the <strong class="bold">Amazon SageMaker Autopilot</strong> framework behind the scenes, to create your first model. You will also learn how to evaluate a model to make sure the model performance is good and that it is usable and not biased. When you are done with this chapter, you should be familiar with the Redshift ML simple <strong class="source-inline">CREATE MODEL</strong> command and different methods used to evaluate your <span class="No-Break">ML model.</span></p>
			<p>In this chapter, to build your first machine learning model, we will go through the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Redshift ML simple <span class="No-Break">CREATE MODEL</span></li>
				<li>Evaluating <span class="No-Break">model performance</span></li>
			</ul>
			<h1 id="_idParaDest-69"><a id="_idTextAnchor071"/>Technical requirements</h1>
			<p>This chapter requires a web browser and <span class="No-Break">the following:</span></p>
			<ul>
				<li>An <span class="No-Break">AWS account.</span></li>
				<li>An Amazon Redshift <span class="No-Break">Serverless endpoint.</span></li>
				<li>Amazon Redshift Query <span class="No-Break">Editor v2.</span></li>
				<li>Completing the <em class="italic">Getting started with Amazon Redshift Serverless </em>section in<em class="italic"> </em><a href="B19071_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a><span class="No-Break">.</span></li>
			</ul>
			<p>You can find the code used in this chapter <span class="No-Break">here: </span><a href="https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/&#13;"><span class="No-Break">https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/</span></a></p>
			<p>Data files required for this chapter are located in a public S3 <span class="No-Break">bucket: </span><a href="https://s3://packt-serverless-ml-redshift/&#13;"><span class="No-Break">s3://packt-serverless-ml-redshift/</span></a></p>
			<p><span class="No-Break">Let’s begin!</span></p>
			<h1 id="_idParaDest-70"><a id="_idTextAnchor072"/>Redshift ML simple CREATE MODEL</h1>
			<p>Redshift ML simple <a id="_idIndexMarker216"/>CREATE MODEL is a feature in Amazon Redshift that allows users to create machine learning models using SQL commands, without the need for specialized skills or software. It simplifies the process of creating and deploying machine learning models by allowing users to use familiar SQL syntax to define the model structure and input data, and then automatically generates and trains the model using Amazon SageMaker. This feature can be used for a variety of machine learning tasks, including regression, classification, <span class="No-Break">and clustering.</span></p>
			<p>Before we dive into building the first ML model, let us set the stage by defining a problem statement that will form the basis of our <span class="No-Break">model-building solution.</span></p>
			<p>We are going to use a customer sales dataset to build the first machine learning model. Business leaders at the fictitious <em class="italic">ABC Company</em> are grappling with dwindling sales. The data team at <em class="italic">ABC Company</em> has performed descriptive and diagnostic analytics and determined that the cause of decreasing sales is departing customers. To stop this problem, data analysts who are familiar with SQL language and some machine learning concepts have tapped into Redshift ML. Business users have documented which customers have and have not churned and teamed up with <span class="No-Break">data analysts.</span></p>
			<p>To<a id="_idIndexMarker217"/> solve the business problem, the data analysts start by analyzing the sales dataset. With Redshift SQL commands, they will write SQL aggregate queries and create visualizations to understand the trends. The data analyst team then creates an ML model using the Redshift ML simple <strong class="source-inline">CREATE MODEL</strong> command. Finally, the data analysts evaluate the model performance to make sure the model <span class="No-Break">is useful.</span></p>
			<h2 id="_idParaDest-71"><a id="_idTextAnchor073"/>Uploading and analyzing the data</h2>
			<p>The dataset <a id="_idIndexMarker218"/>used for this chapter is located here: <a href="https://s3://packt-serverless-ml-redshift/">s3://packt-serverless-ml-redshift/</a>. We have <a id="_idIndexMarker219"/>modified the dataset to better fit the <span class="No-Break">chapter’s requirements.</span></p>
			<p class="callout-heading">Dataset citation</p>
			<p class="callout">This dataset is attributed to the University of California Irvine Repository of Machine Learning Datasets (Jafari-Marandi, R., Denton, J., Idris, A., Smith, B. K., &amp; Keramati, A. (2020). <em class="italic">Optimum Profit-Driven Churn Decision Making: Innovative Artificial Neural Networks in Telecom Industry. Neural Computing </em><span class="No-Break"><em class="italic">and Applications</em></span><span class="No-Break">.</span></p>
			<p>This dataset contains customer churn information. The following table lists the metadata of <span class="No-Break">the dataset:</span></p>
			<table id="table001-2" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Name</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Data Type</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Definition</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">state</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">varchar(2)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>US state in which the customer <span class="No-Break">is located</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">account_length</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">int</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Length of <span class="No-Break">customer account</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">area_code</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">int</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Area code or zip code of <span class="No-Break">the customer</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">phone</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">varchar(8)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Phone number of <span class="No-Break">the customer</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">intl_plan</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">varchar(3)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>International <span class="No-Break">plan subscriber</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">vMail_plan</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">varchar(3)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Voicemail <span class="No-Break">plan subscriber</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">vMail_message</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">int</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Voicemail <span class="No-Break">message subscriber</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">day_mins</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">float</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Aggregated <span class="No-Break">daily minutes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">day_calls</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">int</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Aggregated <span class="No-Break">daily calls</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">day_charge</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">float</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Aggregated <span class="No-Break">daily charges</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">total_charge</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">float</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Total charges</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">eve_mins</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">float</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Evening minutes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">eve_calls</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">int</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Evening calls</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">eve_charge</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">float</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Evening charges</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">night_mins</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">float</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Nightly minutes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">night_calls</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">int</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Nightly calls</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">night_charge</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">float</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Nightly charges</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">intl_mins</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">float</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">International minutes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">intl_calls</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">int</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">International calls</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">intl_charge</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">float</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">International charges</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">cust_serv_calls</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">int</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Number of calls to <span class="No-Break">customer service</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">churn</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">varchar(6)</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Whether customer churned <span class="No-Break">or not</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">record_date</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">date</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p>Record <span class="No-Break">updated date</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 5.1 – Customer call data</p>
			<p>After successfully<a id="_idIndexMarker220"/> connecting to Redshift as an admin or database<a id="_idIndexMarker221"/> developer, create the schema and load data into Amazon Redshift <span class="No-Break">as follows:</span></p>
			<ol>
				<li>Navigate to <strong class="bold">Redshift query editor v2</strong>, connect to the <strong class="bold">Serverless:default</strong> endpoint, and connect to the <span class="No-Break"><strong class="bold">dev</strong></span><span class="No-Break"> database.</span></li>
			</ol>
			<p>Create a new editor and rename the <strong class="source-inline">untitled</strong> query editor by saving it as <strong class="source-inline">Chapter5</strong>, as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B19071_05_01.jpg" alt="Figure 5.1 – Connecting to query editor v2"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – Connecting to query editor v2</p>
			<ol>
				<li value="2">Create a Redshift schema named <strong class="source-inline">Chapter5_buildfirstmodel</strong>. Redshift schemas contain tables, views, and other named objects. For this chapter, tables and machine learning models will be created in <span class="No-Break">this schema:</span><pre class="source-code">
Create schema chapter5_buildfirstmodel;</pre></li>
				<li>Create a Redshift table named <strong class="source-inline">customer_calls_fact</strong>. This table is used to load the dataset that has customer call information. This table is natively created in Redshift and used for training and validating the Redshift <span class="No-Break">ML model:</span><pre class="source-code">
CREATE TABLE IF NOT EXISTS chapter5_buildfirstmodel.customer_calls_fact (</pre><pre class="source-code">
state varchar(2),</pre><pre class="source-code">
account_length int,</pre><pre class="source-code">
area_code int,</pre><pre class="source-code">
phone varchar(8),</pre><pre class="source-code">
intl_plan varchar(3),</pre><pre class="source-code">
vMail_plan varchar(3),</pre><pre class="source-code">
vMail_message int,</pre><pre class="source-code">
day_mins float,</pre><pre class="source-code">
day_calls int,</pre><pre class="source-code">
day_charge float,</pre><pre class="source-code">
total_charge float,</pre><pre class="source-code">
eve_mins float,</pre><pre class="source-code">
eve_calls int,</pre><pre class="source-code">
eve_charge float,</pre><pre class="source-code">
night_mins float,</pre><pre class="source-code">
night_calls int,</pre><pre class="source-code">
night_charge float,</pre><pre class="source-code">
intl_mins float,</pre><pre class="source-code">
intl_calls int,</pre><pre class="source-code">
intl_charge float,</pre><pre class="source-code">
cust_serv_calls int,</pre><pre class="source-code">
churn varchar(6),</pre><pre class="source-code">
record_date date)</pre><pre class="source-code">
Diststyle AUTO;</pre></li>
				<li>Load the<a id="_idIndexMarker222"/> customer call data into the Redshift<a id="_idIndexMarker223"/> table by using the <span class="No-Break">following command:</span><pre class="source-code">
        COPY  chapter5_buildfirstmodel.customer_calls_fact</pre><pre class="source-code">
FROM 's3://packt-serverless-ml-redshift/chapter05/customerdime/'</pre><pre class="source-code">
IAM_ROLE default</pre><pre class="source-code">
delimiter ',' IGNOREHEADER 1</pre><pre class="source-code">
region 'eu-west-1';</pre></li>
			</ol>
			<p>We use the Redshift <strong class="source-inline">COPY</strong> command to load the data into our table. <strong class="source-inline">COPY</strong> commands load data in parallel into a Redshift table. You can load terabytes of data by using the <span class="No-Break"><strong class="source-inline">COPY</strong></span><span class="No-Break"> command.</span></p>
			<ol>
				<li value="5">In the final <a id="_idIndexMarker224"/>step, we will analyze the customer <a id="_idIndexMarker225"/>churn fact table by creating a histogram for customer churn. To do this, let’s use the query editor v2 chart feature to create a histogram chart. In order to create the histogram, we need to count the number of customers who have churned and not churned. To get this information, first, run the <span class="No-Break">following command:</span><pre class="source-code">
SELECT churn, count(*) Customer_Count FROM chapter5_buildfirstmodel.customer_calls_fact</pre><pre class="source-code">
GROUP BY churn</pre><pre class="source-code">
;</pre></li>
			</ol>
			<p>Now, click on the <strong class="bold">Chart</strong> option found on the right-hand side in the <strong class="bold">Result</strong> pane to view <span class="No-Break">the histogram:</span></p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B19071_05_02.jpg" alt="Figure 5.2 – Customers churned ﻿versus not churned histogram"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – Customers churned versus not churned histogram</p>
			<p>From the preceding <a id="_idIndexMarker226"/>chart, you can see that the <strong class="source-inline">customer_calls_fact</strong> table <a id="_idIndexMarker227"/>has <strong class="bold">3333</strong> customers, of which <strong class="bold">483</strong> <span class="No-Break">have churned.</span></p>
			<p>Now, we analyzed the dataset and found that there are customers who have churned. The next step is to create a machine learning model. For this, we will use the Redshift ML simple <strong class="source-inline">CREATE </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> method.</span></p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor074"/>Diving deep into the Redshift ML CREATE MODEL syntax</h1>
			<p>Since this is the first <a id="_idIndexMarker228"/>time you are going to use the <strong class="source-inline">CREATE MODEL</strong> syntax, let’s refresh the basic constructs of the <span class="No-Break">command here.</span></p>
			<p>Redshift ML provides the easy-to-use <strong class="source-inline">CREATE MODEL</strong> syntax to create ML models. In this section, we will focus on a simple form of the <strong class="source-inline">CREATE MODEL</strong> command. In later chapters, you will learn about other forms of creating <span class="No-Break">model statements.</span></p>
			<p>Simple <strong class="source-inline">CREATE MODEL</strong> is the most basic form of Redshift <strong class="source-inline">CREATE MODEL</strong> statement. It is geared toward the personas who are not yet ready to deal with all the intricacies of the machine learning process. This form of model creation is also used by experienced personas such as citizen data scientists for its simplicity in creating a machine learning model. Data cleaning is an essential step for any ML problem, otherwise, it follows the principle of <em class="italic">garbage in, garbage out</em>. Data cleaning still remains a necessary task, however, with Redshift ML data transformation, standardization <a id="_idIndexMarker229"/>and model selection won’t <span class="No-Break">be necessary.</span></p>
			<p>We use the following command for simple <span class="No-Break">model creation:</span></p>
			<pre class="source-code">
CREATE MODEL model_name
    FROM { table_name | ( select_query ) }
    TARGET column_name
    FUNCTION prediction_function_name
    IAM_ROLE { default }
    SETTINGS (
      S3_BUCKET 'bucket',
      [ MAX_CELLS integer ]
    )</pre>
			<p>In the preceding <strong class="source-inline">CREATE MODEL</strong> syntax, as a user, you specify your dataset – in our case, <strong class="source-inline">customer_calls_fact</strong> – in the <strong class="source-inline">FROM</strong> clause. We set the variable that we are targeting to predict, in our case <strong class="source-inline">churn</strong>, in the <strong class="source-inline">TARGET</strong> parameter. As a user, you also give a name to the <a id="_idIndexMarker230"/>function, which you will use in select queries to <span class="No-Break">run predictions.</span></p>
			<p>For more information about <a id="_idIndexMarker231"/>simple <strong class="source-inline">CREATE MODEL</strong> parameters, please refer to the Redshift public document <span class="No-Break">here: </span><a href="https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_simple_create_model&#13;"><span class="No-Break">https://docs.aws.amazon.com/redshift/latest/dg/r_create_model_use_cases.html#r_simple_create_model</span></a></p>
			<p>We’ve learned about the generic simple <strong class="source-inline">CREATE MODEL</strong> syntax. Now, let’s create the syntax for our dataset and <span class="No-Break">run it.</span></p>
			<h1 id="_idParaDest-73"><a id="_idTextAnchor075"/>Creating your first machine learning model</h1>
			<p>Finally, we will now build our first ML <a id="_idIndexMarker232"/>model to predict customer churn events. As this is our first machine learning model, let’s use the simple <strong class="source-inline">CREATE MODEL</strong> command. This option uses Amazon SageMaker Autopilot, which means, without the heavy lifting of building ML models, you simply provide a tabular dataset and select the target column to predict and SageMaker Autopilot automatically explores different solutions to find the best model. This includes data preprocessing, model training, and model selection and deployment. AutoMode is the <span class="No-Break">default mode:</span></p>
			<ol>
				<li>Redshift ML shares training data and artifacts between Amazon Redshift and SageMaker through an S3 bucket. If you don’t have one already, you will need to create an S3 bucket. To do this, navigate to the Amazon S3 console and click on the <strong class="bold">Create </strong><span class="No-Break"><strong class="bold">bucket</strong></span><span class="No-Break"> button:</span></li>
			</ol>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B19071_05_03.jpg" alt="Figure 5.3 – S3 console"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – S3 console</p>
			<ol>
				<li value="2">On the <strong class="bold">Create bucket</strong> page, under <strong class="bold">Bucket name</strong>, provide a name, for example, <strong class="source-inline">serverlessmachinelearningwithredshift-&lt;your account id&gt;</strong>, where <strong class="source-inline">&lt;your account id&gt;</strong> is your AWS <span class="No-Break">account number.</span></li>
			</ol>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B19071_05_04.jpg" alt="Figure 5.4 – Creating an S3 bucket"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Creating an S3 bucket</p>
			<ol>
				<li value="3">Before we<a id="_idIndexMarker233"/> send our dataset to the <strong class="source-inline">CREATE MODEL</strong> command, we will split the dataset into two parts – one is the training dataset, which is used to train the machine learning model, and the other one is for testing the model once it is created. We do this by filtering customer records that have <strong class="source-inline">record_date</strong> of less than <strong class="source-inline">'2020-08-01'</strong> for training and <strong class="source-inline">record_date</strong> greater than <strong class="source-inline">'2020-07-31'</strong> for testing. Run the following queries to check our <span class="No-Break">record split:</span><pre class="source-code">
select sum(case when record_date &lt;'2020-08-01' then 1 else 0 end) as Training_Data_Set,</pre><pre class="source-code">
sum(case when record_date &gt;'2020-07-31' then 1 else 0 end) as Test_Data_Set</pre><pre class="source-code">
from chapter5_buildfirstmodel.customer_calls_fact</pre></li>
			</ol>
			<p>In <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.5</em>, we can see we have <strong class="bold">2714</strong> records in the training set and <strong class="bold">619</strong> records in the <span class="No-Break">test set.</span></p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B19071_05_05.jpg" alt="Figure 5.5 – Training and test dataset record count"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Training and test dataset record count</p>
			<p>We apply the filtering condition when training and testing the model on our dataset. In the next step, we are going to create the model using this filter condition on <span class="No-Break">our dataset.</span></p>
			<ol>
				<li value="4">Now run the following code to create <strong class="source-inline">customer_churn_model</strong>. Make sure to replace <strong class="source-inline">&lt;your account id&gt;</strong> with the correct AWS account number. Please note that<a id="_idIndexMarker234"/> since we are going to use simple <strong class="source-inline">CREATE MODEL</strong>, we set the max allowed time through the <strong class="source-inline">MAX_RUNTIME</strong> parameter. This is the maximum training time that Autopilot will take. We have set it to 1,800 seconds, which is 30 minutes. If you don’t specify a value for <strong class="source-inline">MAX_RUNTIME</strong> it will use the default value of 5,400 seconds (<span class="No-Break">90 minutes):</span><pre class="source-code">
CREATE MODEL chapter5_buildfirstmodel.customer_churn_model</pre><pre class="source-code">
FROM (SELECT state,</pre><pre class="source-code">
              account_length,</pre><pre class="source-code">
              area_code,</pre><pre class="source-code">
              phone,</pre><pre class="source-code">
              intl_plan,</pre><pre class="source-code">
              vMail_plan,</pre><pre class="source-code">
              vMail_message,</pre><pre class="source-code">
              day_mins,</pre><pre class="source-code">
              day_calls,</pre><pre class="source-code">
              day_charge,</pre><pre class="source-code">
              total_charge,</pre><pre class="source-code">
              eve_mins,</pre><pre class="source-code">
              eve_calls,</pre><pre class="source-code">
              eve_charge,</pre><pre class="source-code">
              night_mins,</pre><pre class="source-code">
              night_calls,</pre><pre class="source-code">
              night_charge,</pre><pre class="source-code">
              intl_mins,</pre><pre class="source-code">
              intl_calls,</pre><pre class="source-code">
              intl_charge,</pre><pre class="source-code">
              cust_serv_calls,</pre><pre class="source-code">
             replace(churn,'.','') as churn</pre><pre class="source-code">
      FROM chapter5_buildfirstmodel.customer_calls_fact</pre><pre class="source-code">
         WHERE record_date &lt; '2020-08-01'</pre><pre class="source-code">
     )</pre><pre class="source-code">
TARGET churn</pre><pre class="source-code">
FUNCTION predict_customer_churn</pre><pre class="source-code">
IAM_ROLE default</pre><pre class="source-code">
SETTINGS (</pre><pre class="source-code">
  S3_BUCKET 'serverlessmachinelearningwithredshift-&lt;your account id&gt;',</pre><pre class="source-code">
  MAX_RUNTIME 1800</pre><pre class="source-code">
)</pre><pre class="source-code">
;</pre></li>
			</ol>
			<p>Let us <a id="_idIndexMarker235"/>understand more about the <span class="No-Break">preceding command:</span></p>
			<ul>
				<li>The <strong class="source-inline">SELECT</strong> query in the <strong class="source-inline">FROM</strong> clause specifies the <span class="No-Break">training data</span></li>
				<li>The <strong class="source-inline">TARGET</strong> clause specifies which column is the label for which the <strong class="source-inline">CREATE MODEL</strong> statement builds a model <span class="No-Break">to predict</span></li>
				<li>The other columns in the training query are the features (input) used to predict the <span class="No-Break">churn variable</span></li>
				<li>The <strong class="source-inline">predict_customer_churn</strong> function is the name of an inference function used in <strong class="source-inline">SELECT</strong> queries to <span class="No-Break">generate predictions</span></li>
				<li><strong class="source-inline">S3_Bucket</strong> is the location where Redshift ML saves artifacts when working <span class="No-Break">with SageMaker</span></li>
				<li>Having <strong class="source-inline">MAX_RUNTIME</strong> set as 1,800 seconds specifies the maximum time that SageMaker will take to train <span class="No-Break">our model</span></li>
			</ul>
			<p>After you run the <strong class="source-inline">CREATE MODEL</strong> command, run the following command to check the status of <span class="No-Break">the model:</span></p>
			<pre class="source-code">
<strong class="bold">SHOW MODEL</strong> chapter5_buildfirstmodel.customer_churn_model;</pre>
			<p>The Redshift ML <strong class="source-inline">CREATE MODEL</strong> statement is asynchronous, which means that when the model is under training, the query shows it is completed and the training is happening in Amazon SageMaker. To find out the status of the model, run the <strong class="source-inline">SHOW </strong><span class="No-Break"><strong class="source-inline">MODEL</strong></span><span class="No-Break"> command.</span></p>
			<p>In the following screenshot, you can see the <strong class="source-inline">SHOW MODEL</strong> output shows <strong class="bold">Model State</strong> <span class="No-Break">as </span><span class="No-Break"><strong class="bold">TRAINING</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B19071_05_06.jpg" alt="Figure 5.6 – Model State TRAINING"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.6 – Model State TRAINING</p>
			<p>When the same <strong class="source-inline">SHOW MODEL</strong> command is run after a while, <strong class="bold">Model State</strong> is displayed as <strong class="bold">READY</strong>, which means data processing, model training, model selection, and model <a id="_idIndexMarker236"/>deployment to Redshift is completed successfully. From the following screenshot, you can see that <strong class="bold">Model Status</strong> now shows <strong class="bold">READY</strong>. You can also see the <strong class="bold">Estimated Cost</strong> value, which represents Amazon SageMaker training hours. This value does not equal the elapsed training time as it is an accumulation of training time on the SageMaker <span class="No-Break">instances used.</span></p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B19071_05_07.jpg" alt="Figure 5.7 – Model State READY"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7 – Model State READY</p>
			<p>Apart <a id="_idIndexMarker237"/>from <strong class="bold">Model State</strong>, the <strong class="source-inline">SHOW MODEL</strong> command gives you other useful information about the model, for example, the query used, <strong class="bold">Target Column</strong>, <strong class="bold">Model Type</strong>, and <strong class="bold">Function Name</strong> to use when predicting. You can see that <strong class="bold">Model Type</strong> in our example is <strong class="bold">xgboost</strong>, which tells you that Amazon SageMaker has chosen the XGBoost algorithm to build the binary <span class="No-Break">classification model:</span></p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/B19071_05_08.jpg" alt="Figure 5.8 – Model State READY continuation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8 – Model State READY continuation</p>
			<p>If you read <a id="_idIndexMarker238"/>further into the output, Redshift ML has done the bulk of the work for you, for example, it has selected and set the <span class="No-Break">following parameters:</span></p>
			<ul>
				<li><strong class="bold">Problem Type</strong> is set to <strong class="bold">BinaryClassification</strong>. This is true since our target variable has two distinct values in it, true and false. So, this is a binary <span class="No-Break">classification problem.</span></li>
				<li><strong class="bold">Validation</strong> and <strong class="bold">Objective</strong> is set to <strong class="bold">F1</strong>. F1 score is a recommended approach when evaluating binary scores since it considers both precision and recall. Other objectives that <a id="_idIndexMarker239"/>SageMaker Autopilot may select for a binary classification <a id="_idIndexMarker240"/>model are <strong class="bold">accuracy</strong> and <strong class="bold">area under </strong><span class="No-Break"><strong class="bold">curve</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">AUC</strong></span><span class="No-Break">).</span></li>
			</ul>
			<p>We have created the model successfully as <strong class="bold">Model State</strong> shows as <strong class="bold">READY</strong>. The next step is to make use of prediction functions. We use them in <strong class="source-inline">SELECT</strong> queries. The next sections show how to <span class="No-Break">do so.</span></p>
			<h1 id="_idParaDest-74"><a id="_idTextAnchor076"/>Evaluating model performance</h1>
			<p>Now we<a id="_idIndexMarker241"/> have created the model, let’s dive into the details of <span class="No-Break">its performance.</span></p>
			<p>When building machine learning models, it is very important to understand the model performance. You do this to make sure your model is useful and is not biased to one class over another and to make sure that the model is not under-trained or over-trained, which will mean the model is either not predicting classes correctly or is predicting only some instances and <span class="No-Break">not others.</span></p>
			<p>To address this problem, Redshift ML provides various objectives to measure the performance of the model. It is prudent that we test the model performance with the test dataset that we set aside in the previous section. This section explains how to review the Redshift ML objectives and also validate the model performance with our <span class="No-Break">test data.</span></p>
			<p>Redshift ML uses several objective methods to measure the predictive quality of machine <span class="No-Break">learning models.</span></p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor077"/>Checking the Redshift ML objectives</h2>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.9</em> shows <a id="_idIndexMarker242"/>the <strong class="source-inline">SHOW MODEL</strong> output. It displays two values that are of interest to us. One is <strong class="bold">Objective</strong> and the other is <strong class="bold">validation:f1_binary</strong>. The first value to look at is <strong class="bold">Objective</strong>. It is set to <strong class="bold">F1</strong> for us. F1 or F-score is the most commonly used performance evaluation metric used for classification models. It is a measure for validating dataset accuracy. It is calculated from the precision and recall of the validations where precision is the number of true positive results divided by the number of all positive results included, and recall is the number of true positive results divided by the number of all records that should have been identified as positive. You can learn more about F-score <span class="No-Break">here: </span><a href="https://en.wikipedia.org/wiki/F-score"><span class="No-Break">https://en.wikipedia.org/wiki/F-score</span></a><span class="No-Break">.</span></p>
			<p>Run the following command in query <span class="No-Break">editor v2:</span></p>
			<pre class="source-code">
SHOW MODEL chapter5_buildfirstmodel.customer_churn_model;</pre>
			<p>The <a id="_idIndexMarker243"/>output in <span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.9</em> shows the value of F1 is found in <strong class="bold">validation:</strong><strong class="bold">f</strong><strong class="bold">1_binary</strong>, which is <strong class="bold">0.90</strong>. The highest possible value for an F1 score is 1 and the lowest is 0. The highest score of 1 would signify  perfect precision and recall by a model. In our case, it is 90%, which is <span class="No-Break">really good.</span></p>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="image/B19071_05_09.jpg" alt="Figure 5.9 – Model objective values"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.9 – Model objective values</p>
			<p>We <a id="_idIndexMarker244"/>have seen that the model created by Autopilot has a good F-score and is ready to use to predict whether customers are going to churn or not. In the next section, we will use the prediction function to generate the prediction values along with <span class="No-Break">probability scores.</span></p>
			<h2 id="_idParaDest-76"><a id="_idTextAnchor078"/>Running predictions</h2>
			<p>Now<a id="_idIndexMarker245"/> let’s invoke our <strong class="source-inline">predict_customer_churn</strong> and <strong class="source-inline">predict_customer_churn_prob</strong> prediction functions through the <strong class="source-inline">SELECT</strong> command. Redshift ML creates two functions for us <span class="No-Break">to use:</span></p>
			<ul>
				<li>One is created with the same name as the one we gave when creating the model, in this case, <strong class="source-inline">predict_customer_churn</strong>, which returns the class label or predicted value, for example, <strong class="source-inline">0</strong> <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">1</strong></span><span class="No-Break">.</span></li>
				<li>The other function, <strong class="source-inline">predict_customer_churn_prob</strong>, in addition to returning the class label or predicted value, also returns the probability that the predicted value <span class="No-Break">is correct.</span></li>
			</ul>
			<p>To test these functions, run the following query. In the following query, you’ll notice that we are using two prediction functions inside a <strong class="source-inline">SELECT</strong> command and passing all the input columns that were passed when creating the ML model. These two functions will return a label and probability score as output. We are also testing the prediction function by filtering rows where <strong class="source-inline">record_date</strong> is greater than <strong class="source-inline">'2022-07-31'</strong>. Since this is an unseen dataset, it should act as a challenging dataset for our <span class="No-Break">ML model.</span></p>
			<p>It is also important to note that all the predictions are happening locally on a Redshift cluster. When the <strong class="source-inline">SELECT</strong> query is run, there are no calls made to Amazon SageMaker. This makes all predictions free <span class="No-Break">of cost:</span></p>
			<pre class="source-code">
SELECT area_code ||phone  accountid, replace(churn,'.','') as Actual_churn_class,
    chapter5_buildfirstmodel.predict_customer_churn(
      state,account_length,area_code, phone,intl_plan,
      vMail_plan, vMail_message, day_mins, day_calls,
      day_charge, total_charge, eve_mins, eve_calls,
      eve_charge, night_mins, night_calls,
      night_charge, intl_mins, intl_calls, intl_charge,
      cust_serv_calls) AS predicted_class,
      chapter5_buildfirstmodel.predict_customer_churn_prob(
      state, account_length, area_code, phone, intl_plan,
      vMail_plan, vMail_message, day_mins, day_calls,
      day_charge, total_charge, eve_mins, eve_calls,
      eve_charge, night_mins, night_calls,night_charge,
      intl_mins, intl_calls, intl_charge, cust_serv_calls)
      AS probability_score
  FROM chapter5_buildfirstmodel.customer_calls_fact
WHERE record_date &gt; '2020-07-31'
;</pre>
			<p>You can see the<a id="_idIndexMarker246"/> output in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer094" class="IMG---Figure">
					<img src="image/B19071_05_10.jpg" alt="Figure 5.10 – Running predictions"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.10 – Running predictions</p>
			<p>In the <a id="_idIndexMarker247"/>preceding screenshot, observe that the <strong class="source-inline">predicted_class</strong> values and <strong class="source-inline">probability_score</strong> values for each customer are shown. From the <strong class="source-inline">predicted_class</strong> column, you can understand that our model is predicting whether the customer is going to churn or not, and from the <strong class="source-inline">probability_score</strong> column, you can understand that the model is, for example, for the first row, 99% confident that the customer with account ID <strong class="bold">415382-4657</strong> is not going <span class="No-Break">to churn.</span></p>
			<p>We have witnessed that prediction is working without any issues. In the next section, let’s check how the model is performing compared to <span class="No-Break">ground truth.</span></p>
			<h2 id="_idParaDest-77"><a id="_idTextAnchor079"/>Comparing ground truth to predictions</h2>
			<p>Run the<a id="_idIndexMarker248"/> following query to compare actual versus predicted <span class="No-Break">customer churn:</span></p>
			<pre class="source-code">
WITH infer_data AS (
  SELECT area_code ||phone  accounted,
    replace(churn,'.','') as churn,
    chapter5_buildfirstmodel.predict_customer_churn(
              state,
              account_length,
              area_code,
              phone,
              intl_plan,
              vMail_plan,
              vMail_message,
              day_mins,
              day_calls,
              day_charge,
              total_charge,
              eve_mins,
              eve_calls,
              eve_charge,
              night_mins,
              night_calls,
              night_charge,
              intl_mins,
              intl_calls,
              intl_charge,
              cust_serv_calls) AS predicted
  FROM chapter5_buildfirstmodel.customer_calls_fact
WHERE record_date &gt; '2020-07-31'
)
SELECT *  FROM infer_data where churn!=predicted;</pre>
			<p>The following <a id="_idIndexMarker249"/>screenshot shows the customers where the ML model made <span class="No-Break">a mistake:</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Results will vary as each trained model will have <span class="No-Break">slight differences.</span></p>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="image/B19071_05_11.jpg" alt="Figure 5.11 – Incorrect predictions"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.11 – Incorrect predictions</p>
			<p>We have seen the model predictions and compared them with ground truth. In the next section, we will learn about <span class="No-Break">feature importance.</span></p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor080"/>Feature importance</h2>
			<p><strong class="bold">Feature importance</strong> is a <a id="_idIndexMarker250"/>measure of how much each feature contributes to the model’s predictions. SageMaker Autopilot calculates the importance of features and Redshift ML provides <strong class="source-inline">explain_model</strong> functions to retrieve feature importance. This will help you to understand which features are strongly related to the target variable, which features are important to the model and which are not, and from this you can reduce the number of dimensions that you feed into your machine <span class="No-Break">learning model.</span></p>
			<p>The following is the SQL code that you can run to retrieve the feature importance of <span class="No-Break">our model:</span></p>
			<pre class="source-code">
Select jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata ;</pre>
			<p>The following is the JSON format output of feature importance. You can read and understand the importance of <span class="No-Break">each feature.</span></p>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="image/B19071_05_12.jpg" alt="Figure 5.12 – Feature importance raw output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.12 – Feature importance raw output</p>
			<p>For better readability of the feature importance, you may execute the following <span class="No-Break">SQL code:</span></p>
			<pre class="source-code">
select t1.feature_imp, t1.value from
(
Select
'account_length' as feature_imp,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.account_length as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'area_code' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.area_code as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'cust_serv_calls' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.cust_serv_calls as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'day_calls' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.day_calls as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'day_charge' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.day_charge as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata 
union
select 'day_mins' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.day_mins as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'eve_calls' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.eve_calls  as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'eve_charge' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.eve_charge  as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'eve_mins' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.eve_mins  as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'intl_calls' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.intl_calls   as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'intl_charge' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.intl_charge   as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'intl_mins' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.intl_mins    as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'intl_plan' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.intl_plan     as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'inight_calls' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.night_calls     as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'night_charge' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.night_charge    as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'night_mins' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.night_mins   as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'phone' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.phone   as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'state' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.state   as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'total_charge' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.total_charge   as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'vmail_message' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.vmail_message   as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
union
select 'vmail_plan' as feature_imp ,
jsondata.featureimp.explanations.kernel_shap.label0.global_shap_values.vmail_plan  as value
from ( select explain_model( 'chapter5_buildfirstmodel.customer_churn_model')as featureimp) jsondata
) t1
order by value desc</pre>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/B19071_05_13.jpg" alt="Figure 5.13 – Feature Importance"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.13 – Feature Importance</p>
			<p>You can use<a id="_idIndexMarker251"/> feature importance to understand the relationship between each feature and target variable and the features that are <span class="No-Break">not important.</span></p>
			<p>We have seen what features contribute highly to the model, now let’s look at how model performance metrics are calculated on our <span class="No-Break">test dataset.</span></p>
			<h1 id="_idParaDest-79"><a id="_idTextAnchor081"/>Model performance</h1>
			<p>Let’s use Redshift SQL to compute<a id="_idIndexMarker252"/> a <strong class="bold">confusion matrix</strong> to evaluate the performance of the <a id="_idIndexMarker253"/>classification model. Using a confusion matrix, you can identify true positives, true negatives, false positives, and false negatives, based on which various statistical measures such as accuracy, precision, recall, sensitivity, specificity, and finally, F1 score are calculated. You can<a id="_idIndexMarker254"/> read more about the concept of the confusion matrix <span class="No-Break">here: </span><a href="https://en.wikipedia.org/wiki/Confusion_matrix"><span class="No-Break">https://en.wikipedia.org/wiki/Confusion_matrix</span></a><span class="No-Break">.</span></p>
			<p>The following <a id="_idIndexMarker255"/>query uses a <strong class="source-inline">WITH</strong> clause, which implements a common table expression in Redshift. This query has the following <span class="No-Break">three parts:</span></p>
			<ul>
				<li>The first part is about the <strong class="source-inline">SELECT</strong> statement within the <strong class="source-inline">WITH</strong> clause, where we predict customer churn and save it in memory. This dataset is <span class="No-Break">named </span><span class="No-Break"><strong class="source-inline">infer_data</strong></span><span class="No-Break">.</span></li>
				<li>The second part, which is below the first <strong class="source-inline">SELECT</strong> statement, reads <strong class="source-inline">infer_data</strong> and builds the confusion matrix, and these details are stored in memory in a dataset <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">confusionmatrix</strong></span><span class="No-Break">.</span></li>
				<li>In the third part of the statement, note that the <strong class="source-inline">SELECT</strong> statement builds the model performance metrics such as F1 score, accuracy, recall, and <span class="No-Break">so on.</span></li>
			</ul>
			<p>Run the following query to build a confusion matrix for the <span class="No-Break">test dataset:</span></p>
			<pre class="source-code">
WITH infer_data AS (
  SELECT area_code ||phone  accountid, replace(churn,'.','') as churn,
    chapter5_buildfirstmodel.predict_customer_churn(
          state,  account_length, area_code, phone,
          intl_plan, vMail_plan, vMail_message, day_mins,
          day_calls,  day_charge, total_charge, eve_mins,
          eve_calls, eve_charge, night_mins, night_calls,
          night_charge, intl_mins, intl_calls,
          intl_charge,   cust_serv_calls) AS predicted
  FROM chapter5_buildfirstmodel.customer_calls_fact
WHERE record_date &gt; '2020-07-31'),
confusionmatrix as
(
SELECT case when churn  ='True' and predicted = 'True' then 1 else 0 end TruePositives,
case when churn ='False' and predicted = 'False' then 1 else 0 end TrueNegatives,
case when churn ='False' and predicted = 'True' then 1 else 0 end FalsePositives,
case when churn ='True' and predicted = 'False' then 1 else 0 end FalseNegatives
  FROM infer_data
 )
select
sum(TruePositives+TrueNegatives)*1.00/(count(*)*1.00) as Accuracy,--accuracy of the model,
sum(FalsePositives+FalseNegatives)*1.00/count(*)*1.00 as Error_Rate, --how often model is wrong,
sum(TruePositives)*1.00/sum (TruePositives+FalseNegatives) *1.00 as True_Positive_Rate, --or recall how often corrects are rights,
sum(FalsePositives)*1.00/sum (FalsePositives+TrueNegatives )*1.00 False_Positive_Rate, --or fall-out how often model said yes when it is no,
sum(TrueNegatives)*1.00/sum (FalsePositives+TrueNegatives)*1.00 True_Negative_Rate, --or specificity, how often model said no when it is yes,
sum(TruePositives)*1.00 / (sum (TruePositives+FalsePositives)*1.00) as Precision, -- when said yes how it is correct,
2*((True_Positive_Rate*Precision)/ (True_Positive_Rate+Precision) ) as F_Score --weighted avg of TPR &amp; FPR
From confusionmatrix
;</pre>
			<p>We get the <span class="No-Break">following output:</span></p>
			<div>
				<div id="_idContainer098" class="IMG---Figure">
					<img src="image/B19071_05_14.jpg" alt="Figure 5.14 – Confusion ﻿matrix for the test dataset"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.14 – Confusion matrix for the test dataset</p>
			<p>By <a id="_idIndexMarker256"/>looking at the <strong class="bold">f_score</strong> value, you can confirm that the model has performed well against our test dataset (<strong class="source-inline">record_date</strong> &gt; <strong class="source-inline">'2020-07-31'</strong>). These records have not been seen by the model before, but 97% of the time, the model is able to correctly predict the class value. This proves that the model is useful and correctly predicts both classes – churn and no churn. This model can now be given to the business units so it can be used to proactively predict the customers who are about to churn and build marketing campaigns <span class="No-Break">for them.</span></p>
			<h1 id="_idParaDest-80"><a id="_idTextAnchor082"/>Summary</h1>
			<p>In this chapter, you have learned how to create your first machine learning model using a simple <strong class="source-inline">CREATE MODEL</strong> statement. While doing so, you explored <strong class="source-inline">customer_calls_fact</strong> table data using query editor v2, learned about the basic syntax of the <strong class="source-inline">CREATE MODEL</strong> statement, created a simple ML model, learned how to read the model’s output, and finally, used Redshift SQL to compute some of the model evaluation <span class="No-Break">metrics yourself.</span></p>
			<p>In the next chapter, you will use the basics that you have learned in this chapter to build various classification models using <span class="No-Break">Redshift ML.</span></p>
		</div>
	</body></html>