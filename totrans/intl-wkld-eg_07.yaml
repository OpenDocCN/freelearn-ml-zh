- en: '*Chapter 5*: Ingesting and Streaming Data from the Edge'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*：从边缘摄取和流式传输数据'
- en: '**Edge computing** can reduce the amount of data transferred to the cloud (or
    on-premises datacenter), thus saving on network bandwidth costs. Often, high-performance
    edge applications require local compute, storage, network, data analytics, and
    machine learning capabilities to process high-fidelity data in low latencies.
    AWS extends infrastructure to the edge, beyond **Regions** and **Availability
    Zones**, as close to the endpoint as required by your workload. As you will have
    learned in previous chapters, **AWS IoT Greengrass** allows you to run sophisticated
    edge applications on devices and gateways.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**边缘计算**可以减少传输到云（或本地数据中心）的数据量，从而节省网络带宽成本。通常，高性能的边缘应用程序需要本地计算、存储、网络、数据分析以及机器学习能力，以在低延迟下处理高保真数据。AWS将基础设施扩展到边缘，超出**区域**和**可用区**，以满足您的工作负载需求。正如您在前几章中学到的，**AWS
    IoT Greengrass**允许您在设备和网关上运行复杂的边缘应用程序。'
- en: In this chapter, you will learn about the different data design and transformation
    strategies applicable for edge workloads. We will explain how you can ingest data
    from different sensors through different workflows based on **data velocity**
    (such as hot, warm, and cold), **data variety** (such as structured and unstructured),
    and **data volume** (such as high frequency or low frequency) on the edge. Thereafter,
    you will learn the approaches of streaming the raw and transformed data from the
    edge to different cloud services. By the end of this chapter, you should be familiar
    with data processing using AWS IoT Greengrass.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解适用于边缘工作负载的不同数据设计和转换策略。我们将解释您如何根据**数据速度**（如热、温和冷）、**数据多样性**（如结构化和非结构化）以及**数据量**（如高频或低频）在边缘通过不同的工作流程摄取来自不同传感器的数据。之后，您将学习从边缘将原始和转换后的数据流式传输到不同云服务的方法。到本章结束时，您应该熟悉使用AWS
    IoT Greengrass进行数据处理。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Defining data models for IoT workloads
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义物联网工作负载的数据模型
- en: Designing data patterns for the edge
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为边缘设计数据模式
- en: Getting to know Stream Manager
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解Stream Manager
- en: Building your first data orchestration workflow on the edge
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在边缘构建您的第一个数据编排工作流程
- en: Streaming from the edge to a data lake on the cloud
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从边缘流式传输到云上的数据湖
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The technical requirements for this chapter are the same as those outlined in
    [*Chapter 2*](B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032)*, Foundations of
    Edge Workloads*. See the full requirements in that chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的技术要求与在[*第二章*](B17595_02_Final_SS_ePub.xhtml#_idTextAnchor032)*，边缘工作负载基础*中概述的要求相同。请参阅该章节中的完整要求。
- en: 'You will find the GitHub code repository here: [https://github.com/PacktPublishing/Intelligent-Workloads-at-the-Edge/tree/main/chapter5](https://github.com/PacktPublishing/Intelligent-Workloads-at-the-Edge/tree/main/chapter5)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处找到GitHub代码仓库：[https://github.com/PacktPublishing/Intelligent-Workloads-at-the-Edge/tree/main/chapter5](https://github.com/PacktPublishing/Intelligent-Workloads-at-the-Edge/tree/main/chapter5)
- en: Defining data models for IoT workloads
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义物联网工作负载的数据模型
- en: According to the IDC, the sum of the world's data will grow from 33 **zettabytes**
    (**ZB**) in 2018 to 175 ZB by 2025\. Additionally, the IDC estimates that there
    will be 41.6 billion connected IoT devices or *things*, generating 79.4 ZB of
    data in 2025 ([https://www.datanami.com/2018/11/27/global-datasphere-to-hit-175-zettabytes-by-2025-idc-says/](https://www.datanami.com/2018/11/27/global-datasphere-to-hit-175-zettabytes-by-2025-idc-says/)).
    Additionally, many other sources reiterate that data and information are the *currency*,
    the *lifeblood*, and even the *new oil* of the information industry.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 根据IDC的预测，到2025年，全球数据总量将从2018年的33 **泽字节**（**ZB**）增长到175 ZB。此外，IDC估计到2025年将有416亿个连接的物联网设备或*事物*，产生79.4
    ZB的数据（[https://www.datanami.com/2018/11/27/global-datasphere-to-hit-175-zettabytes-by-2025-idc-says/](https://www.datanami.com/2018/11/27/global-datasphere-to-hit-175-zettabytes-by-2025-idc-says/)）。此外，许多其他来源重申，数据和信息是*货币*、*生命线*，甚至是信息行业中的*新石油*。
- en: Therefore, the data-driven economy is here to stay and the **Internet of Things**
    (**IoT**) will act as the enabler to ingest data from a huge number of devices
    (or endpoints), such as sensors and actuators, and generate aggregated insights
    for achieving business outcomes. Thus, as an IoT practitioner, you should be comfortable
    with the basic concepts of **data modeling** and how that enables **data management**
    on the edge.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据驱动型经济将长期存在，**物联网**（**IoT**）将作为推动者，从大量设备（或端点）如传感器和执行器中获取数据，并生成汇总见解以实现业务成果。因此，作为一名物联网从业者，你应该熟悉**数据建模**的基本概念以及它是如何实现边缘**数据管理**的。
- en: All organizations across different verticals such as industrial, commercial,
    consumer, transportation, energy, healthcare, and others are exploring new use
    cases to improve their top line or bottom line and innovate on behalf of their
    customers. IoT devices such as a connected hub in a consumer home, a smart parking
    meter on a road, or a connected car will coexist with customers and will operate
    even when there is no connectivity to the internet.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所有行业，如工业、商业、消费、交通、能源、医疗保健等，都在探索新的用例以提高其收入或利润，并为顾客创新。物联网设备，如消费者家庭中的连接中心、道路上的智能停车计费器或连接汽车，将与客户共存，即使在没有互联网连接的情况下也能运行。
- en: This is a paradigm shift from the centralized solutions that worked for enterprises
    in the past. For example, a banking employee might have hosted their workloads
    in datacenters, but now they can monitor customer activities (such as suspicious
    actions, footfalls, or availability of cash in an ATM) at their branch locations
    in near real time to serve customers better. Therefore, a new strategy is required
    to act on the data generated locally and be able to process and stream data from
    the edge to the cloud.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从过去为企业工作的集中式解决方案到的一种范式转变。例如，一位银行员工可能将他们的工作负载托管在数据中心，但现在他们可以在其分支机构实时监控客户活动（如可疑行为、人流量或ATM中的现金可用性），以更好地服务客户。因此，需要一种新的策略来处理本地生成数据，并能够从边缘处理和流式传输数据到云端。
- en: In this chapter, we are going to rethink and re-evaluate the applicability of
    different big data architectures in the context of IoT and edge computing. The
    three areas we will consider are data management, data architecture patterns,
    and anti-patterns.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重新思考和评估不同大数据架构在物联网和边缘计算环境下的适用性。我们将考虑的三个领域是数据管理、数据架构模式和反模式。
- en: What is data management?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是数据管理？
- en: As per the **Data Management Body of Knowledge** (**DMBOK2**) from the **Data
    Management Association** (**DAMA**), data management is the development, execution,
    and supervision of plans, policies, programs, and practices that deliver, control,
    protect, and enhance the value of data and information assets throughout their
    life cycles (for more information, please refer to *DAMA-DMBOK2* at [https://technicspub.com/dmbok/](https://technicspub.com/dmbok/)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 根据**数据管理协会**（**DAMA**）的**数据管理知识体系**（**DMBOK2**），数据管理是制定、执行和监督计划、政策、项目和做法，以在整个生命周期中交付、控制、保护和增强数据和信息资产的价值（更多信息，请参阅[DAMA-DMBOK2](https://technicspub.com/dmbok/)）。
- en: 'DAMA covers the data management framework in great detail, as shown in the
    following diagram:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: DAMA详细介绍了数据管理框架，如下所示：
- en: '![Figure 5.1 – The data management life cycle'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.1 – 数据管理生命周期]'
- en: '](img/B17595_05_001.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B17595_05_001.jpg]'
- en: Figure 5.1 – The data management life cycle
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.1 – 数据管理生命周期]'
- en: Here, we recognized an opportunity to augment the framework from DAMA with concepts
    that are relevant to edge computing. Therefore, in this section, we will dive
    deeper into the principles related to data modeling, data architecture, and **Data
    Integration and Interoperability** (**DII**), which we think are relevant for
    edge computing and IoT.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们认识到一个机会，即通过边缘计算的相关概念来增强DAMA框架。因此，在本节中，我们将更深入地探讨与数据建模、数据架构和**数据集成与互操作性**（**DII**）相关的原则，我们认为这些原则与边缘计算和物联网相关。
- en: 'Let''s define data in the context of IoT before we discuss how to model it.
    IoT data is generated from different sensors, actuators, and gateways. Therefore,
    they can come in different forms such as the following:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论如何建模数据之前，让我们先定义物联网环境下的数据。物联网数据来自不同的传感器、执行器和网关。因此，它们可以以不同的形式出现，如下所示：
- en: '**Structured data**: This refers to a predictable form of data; examples include
    device metadata and device relationships.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结构化数据**：这指的是一种可预测的数据形式；例如，包括设备元数据和设备关系。'
- en: '**Semi-structured data**: This is a form of data with a certain degree of variance
    and randomness; examples include sensor and actuator feeds.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**半结构化数据**：这是一种具有一定程度变异性和随机性的数据形式；例如，包括传感器和执行器馈送。'
- en: '**Unstructured data**: This is a form of data with a higher degree of variance
    and randomness; examples include raw images, audio, or videos.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非结构化数据**：这是一种具有更高程度变异性和随机性的数据形式；例如，包括原始图像、音频或视频。'
- en: Now, let's discuss how the different forms of data can be governed, organized,
    and stored using data modeling techniques.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论如何使用数据建模技术来治理、组织和存储不同形式的数据。
- en: What is data modeling?
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是数据建模？
- en: '**Data modeling** is a common practice in software engineering, where data
    requirements are defined and analyzed to support the business processes of different
    information systems in the scope of the organization. There are three different
    types of data models:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据建模**是软件工程中的一种常见实践，其中定义并分析数据需求，以支持组织范围内不同信息系统中的业务流程。存在三种不同类型的数据模型：'
- en: Conceptual data models
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概念数据模型
- en: Logical data models
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑数据模型
- en: Physical data models
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物理数据模型
- en: 'In the following diagram, the relationships between different modeling approaches
    are presented:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图中，展示了不同建模方法之间的关系：
- en: '![Figure 5.2 – Data modeling approaches'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.2 – 数据建模方法'
- en: '](img/B17595_05_002.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_05_002.jpg)'
- en: Figure 5.2 – Data modeling approaches
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 – 数据建模方法
- en: Fun fact
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: The Enigma machine was used by the German military as the primary mode of communication
    for all secure wireless communications during World War II. Alan Turing cracked
    the Enigma code roughly 80 years ago when he figured out the text that's placed
    at the end of every message. This helped to decipher key secret messages from
    the German military and helped end the world war. Additionally, this mechanism
    led to the era of unlocking insights by defining a language to decipher data,
    which was later formalized as data modeling.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次世界大战期间，德国军队使用恩尼格玛机作为所有安全无线通信的主要通信方式。大约80年前，当艾伦·图灵破解了每条消息末尾放置的文本时，他破解了恩尼格玛密码。这有助于解读德国军队的关键秘密信息，并帮助结束世界大战。此外，这种机制导致了通过定义一种解码数据的语言来解锁洞察力的时代，这后来被正式化为数据建模。
- en: 'The most common data modeling technique for a database is an **Entity-Relationship**
    (**ER**) model. An ER model in software engineering is a common way to represent
    the relationship between different entities such as people, objects, places, events,
    and more in a graphical way in order to organize information better to drive the
    business processes of an organization. In other terms, an ER model is an abstract data
    model that defines a data structure for the required information and can be independent
    of any specific database technology. In this section, we will explain the different
    data models using the ER model approach. First, let''s define, with the help of
    a use case diagram, the relationship between a customer and their devices associated
    with a connected HBS hub:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据库而言，最常见的数据建模技术是**实体-关系**（ER）模型。在软件工程中，ER模型是一种常见的以图形方式表示不同实体（如人、物体、地点、事件等）之间关系的方法，以便更好地组织信息，推动组织的业务流程。换句话说，ER模型是一种抽象的数据模型，它定义了所需信息的结构，可以独立于任何特定的数据库技术。在本节中，我们将使用ER模型方法解释不同的数据模型。首先，让我们借助用例图来定义客户与其关联的连接HBS中心设备的关联关系：
- en: '![Figure 5.3 – A use case diagram'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.3 – 用例图'
- en: '](img/B17595_05_003.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_05_003.jpg)'
- en: Figure 5.3 – A use case diagram
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 – 用例图
- en: 'Now, let''s build the ER diagram through a series of conceptual, logical, and
    physical models:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一系列概念性、逻辑性和物理模型来构建ER图：
- en: The **conceptual data model** defines the entities and their relationships.
    This is the first step of the data modeling exercise and is used by personas such
    as data architects to gather the initial set of requirements from the business
    stakeholders. For example, *sensor*, *device*, and *customer* are three entities
    in a relationship, as shown in the following diagram:![Figure 5.4 – A conceptual
    data model
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**概念数据模型**定义了实体及其关系。这是数据建模练习的第一步，由数据架构师等角色使用，从业务利益相关者那里收集初始需求集。例如，*传感器*、*设备*和*客户*是关系中的三个实体，如下所示图所示：![图5.4
    – 概念数据模型'
- en: '](img/B17595_05_004.jpg)'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17595_05_004.jpg]'
- en: Figure 5.4 – A conceptual data model
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.4 – 概念数据模型
- en: The conceptual model is then rendered into a **logical data model**. In this
    step of data modeling, the data structure along with additional properties are
    defined using a conceptual model as the foundation.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后将**概念模型**转换为**逻辑数据模型**。在数据建模的这个步骤中，使用概念模型作为基础定义了数据结构以及附加属性。
- en: 'For example, you can define the properties of the different entities in the
    relationship such as the sensor type or device identifier (generally, a serial
    number or a MAC address), as shown in the following list. Additionally, there
    could be different forms of relationships, such as the following:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，你可以定义关系中的不同实体的属性，如传感器类型或设备标识符（通常是一个序列号或MAC地址），如下所示。此外，还可能有不同形式的关系，如下所示：
- en: Association is the relationship between devices and sensors.
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联是设备和传感器之间的关系。
- en: Ownership is the relationship between customers and devices.
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有权是客户和设备之间的关系。
- en: 'The preceding points are illustrated in the following diagram:'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图示说明了前面的点：
- en: '![Figure 5.5 – A logical data model'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.5 – 逻辑数据模型'
- en: '](img/B17595_05_005.jpg)'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B17595_05_005.jpg]'
- en: Figure 5.5 – A logical data model
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.5 – 逻辑数据模型
- en: 'The final step in data modeling is to build a **physical data model** from
    the defined logical model. A physical model is often a technology or product-specific
    implementation of the data model. For example, you define the data types for the
    different properties of an entity, such as a number or a string, that will be
    deployed on a database solution from a specific vendor:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据建模的最后一步是从定义的逻辑模型构建一个**物理数据模型**。物理模型通常是数据模型的技术或产品特定实现。例如，你为实体的不同属性定义数据类型，如数字或字符串，这些将在特定供应商的数据库解决方案上部署：
- en: '![Figure 5.6 – A physical data model'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.6 – 物理数据模型'
- en: '](img/B17595_05_006.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_006.jpg]'
- en: Figure 5.6 – A physical data model
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 – 物理数据模型
- en: 'Enterprises have used ER modeling for decades to design and govern complex
    distributed data solutions. All the preceding steps can be visualized as the following
    workflow, which is not limited to any specific technology, product, subject area,
    or operating environment (such as a data center, cloud, or edge):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 企业已经使用ER建模几十年来自行设计和治理复杂分布式数据解决方案。所有前面的步骤都可以可视化为以下工作流程，这并不局限于任何特定的技术、产品、领域或操作环境（如数据中心、云或边缘）：
- en: '![Figure 5.7 – The data modeling flow'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.7 – 数据建模流程'
- en: '](img/B17595_05_007.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_007.jpg]'
- en: Figure 5.7 – The data modeling flow
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 – 数据建模流程
- en: Now that you have understood the foundations of data modeling, in the next section,
    let's examine how this can be achieved for IoT workloads.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了数据建模的基础，在下一节中，让我们看看如何为物联网工作负载实现这一点。
- en: How do you design data models for IoT?
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你如何设计物联网的数据模型？
- en: Now, let's take a look at some examples of how to apply the preceding data modeling
    concepts to the realm of structured, unstructured, and semi-structured data that
    are common with IoT workloads. Generally, when we refer to data modeling for structured
    data, a **relational database** (**RDBMS**) comes to mind first. However, for
    most IoT workloads, structured data generally includes hierarchical relationships
    between a device and other entities. And that is better illustrated using a graph
    or an ordered key-value database. Similarly, for semi-structured data, when it
    comes to IoT workloads, it's mostly illustrated as a key-value, time series, or
    document store.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何将前面提到的数据建模概念应用到物联网工作负载中常见的结构化、非结构化和半结构化数据的例子。通常，当我们提到结构化数据的数据建模时，首先想到的是**关系数据库**（**RDBMS**）。然而，对于大多数物联网工作负载，结构化数据通常包括设备与其他实体之间的层次关系。这最好用图或有序键值数据库来展示。同样，对于半结构化数据，在物联网工作负载中，它通常被表示为键值、时间序列或文档存储。
- en: In this section, we will give you a glimpse of data modeling techniques using
    NoSQL data solutions to continue building additional functionalities for HBS.
    Modeling an RDBMS is outside the scope of this book. However, if you are interested
    in learning about them, there are tons of materials available on the internet
    that you can refer to.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示使用NoSQL数据解决方案的数据建模技术，以继续为HBS构建更多功能。建模RDBMS超出了本书的范围。然而，如果您对此感兴趣，互联网上有大量可供参考的材料。
- en: 'NoSQL databases are designed to offer freedom to developers to break away from
    a longer cycle of database schema designs. However, it''s a mistake to assume
    that NoSQL databases lack any sort of data model. Designing a NoSQL solution is
    quite different from an RDBMS design. For RDBMS, developers generally create a
    data model that adheres to normalization guidelines, without focusing on access
    patterns. The data model can be modified later when new business requirements
    arise, thus leading to a lengthy release cycle. The collected data is organized
    in different tables with rows, columns, and referential integrities. In contrast,
    for a NoSQL solution design, developers cannot begin designing the models until
    they know the questions that are required to be answered. Understanding the business
    queries working backward from the use case is quintessential. Therefore, the general
    rule of thumb to remember during data modeling through a relational or NoSQL database
    is the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: NoSQL数据库旨在为开发者提供从较长的数据库模式设计周期中解脱出来的自由。然而，认为NoSQL数据库缺乏任何数据模型是错误的。设计NoSQL解决方案与RDBMS设计截然不同。对于RDBMS，开发者通常创建一个遵循规范化指南的数据模型，而不关注访问模式。数据模型可以在出现新的业务需求时进行修改，从而导致漫长的发布周期。收集的数据以不同的表格形式组织，包括行、列和参照完整性。相比之下，对于NoSQL解决方案设计，开发者必须知道需要回答的问题才能开始设计模型。从用例反向理解业务查询是至关重要的。因此，在通过关系型或NoSQL数据库进行数据建模时，要记住的一般规则如下：
- en: Relational modeling primarily cares about the structure of data. The design
    principle is *What answers do I get?*
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关系型建模主要关注数据的结构。设计原则是*我能得到什么答案？*
- en: NoSQL modeling primarily cares about application-specific access patterns. The
    design principle is *What questions do I ask?*
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NoSQL建模主要关注特定于应用程序的访问模式。设计原则是*我要问什么问题？*
- en: Fun fact
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: The common translation of the NoSQL acronym is *Not only SQL*. This highlights
    the fact that NoSQL doesn't only support NoSQL, but it can handle relational,
    semi-structured, and unstructured data. Organizations such as Amazon, Facebook,
    Twitter, LinkedIn, and Google have designed different NoSQL technologies.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: NoSQL的常见缩写翻译为*不仅SQL*。这突出了NoSQL不仅支持NoSQL，还可以处理关系型、半结构化和非结构化数据。例如，亚马逊、Facebook、Twitter、LinkedIn和谷歌等组织都设计了不同的NoSQL技术。
- en: 'Before I show you some examples of data modeling, let''s understand the five
    fundamental properties of our application''s (that is, the HBS hub) access patterns
    that need to be considered in order to come up with relevant questions:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在我向您展示一些数据建模的例子之前，让我们了解我们的应用程序（即HBS中心）的访问模式的五个基本属性，这些属性需要考虑以便提出相关的问题：
- en: '**Data type**: What''s the type of data in scope? For example, is the data
    related to telemetry, command-control, or critical events? Let''s quickly refresh
    the use of each of these data types:'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据类型**：范围内的数据类型是什么？例如，数据是否与遥测、命令控制或关键事件相关？让我们快速回顾一下这些数据类型的用法：'
- en: 'a) **Telemetry**: This is a constant stream of data transmitted by sensors/actuators,
    such as temperature or humidity readings , which can be aggregated on the edge
    or published as it is to the cloud for further processing.'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) **遥测**：这是由传感器/执行器（如温度或湿度读数）发出的持续数据流，可以在边缘进行聚合或直接发布到云中进行进一步处理。
- en: 'b) **Command and Control**: These are actionable messages, such as turning
    on/off the lights, which can occur between two devices or between an end user
    and the device.'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) **命令与控制**：这些是可执行的消息，例如开关灯，可以在两个设备之间或终端用户与设备之间发生。
- en: 'c) **Events**: These are data patterns that identify more complex scenarios
    than regular telemetry data, such as network outages in a home or a fire alarm
    in a building.'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) **事件**：这些是比常规遥测数据更复杂的场景的数据模式，例如家庭中的网络中断或建筑中的火灾警报。
- en: '**Data size**: What is the quantity of data in scope? Is it necessary to store
    and retrieve data locally (on the edge), or does the data require transmission
    to a different data persistence layer (such as a data lake on the cloud)?'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据大小**：范围内的数据量是多少？是否需要本地（在边缘）存储和检索数据，或者数据需要传输到不同的数据持久化层（如云上的数据湖）？'
- en: '**Data shape**: What''s the form of data being generated from different edge
    devices such as text, blobs, and images? Note that different data forms such as
    images and videos might have different computational needs (think of GPUs).'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据形状**：从不同的边缘设备（如文本、二进制大对象和图像）生成数据的格式是什么？请注意，图像和视频等不同数据形式可能具有不同的计算需求（例如GPU）。'
- en: '**Data velocity**: What''s the speed of data to process queries based on the
    required latencies? Do you have a hot, warm, or cold path of data?'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据速度**：基于所需延迟，数据处理查询的速度是多少？你有没有热、温或冷的数据路径？'
- en: '**Data consistency**: How much of this data needs to have strong versus eventual
    consistency?'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据一致性**：这些数据中有多少需要强一致性而不是最终一致性？'
- en: 'Answering the preceding questions will help you to determine whether the solution
    should be based on one of the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 回答前面的问题将帮助您确定解决方案是否应该基于以下之一：
- en: '**BASE methodology**: **Basically Available**, **Soft-state**, **Eventual consistency**,
    which are typical characteristics of NoSQL databases'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BASE方法**：**基本可用性**、**软状态**、**最终一致性**，这是NoSQL数据库的典型特征'
- en: '**ACID methodology**: **Atomicity**, **Consistency**, **Isolation**,and **Durability**,
    which are typical characteristics of relational databases'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ACID方法**：**原子性**、**一致性**、**隔离性**和**持久性**，这是关系数据库的典型特征'
- en: We will discuss these concepts in more detail next.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节更详细地讨论这些概念。
- en: Selecting between ACID or BASE for IoT workloads
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在物联网工作负载中选择ACID或BASE
- en: 'The following table lists some of the key differences between the two methodologies.
    This should enable you to make an informed decision working backward from your
    use case:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格列出了两种方法之间的一些关键区别。这应该能够帮助你从用例反向做出明智的决定：
- en: '![Figure 5.8 – ACID versus BASE summary'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.8 – ACID与BASE总结](img/Figure_5.8_ACID_versus_BASE_summary.jpg)'
- en: '](img/B17595_05_008.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_008.jpg](img/B17595_05_008.jpg)'
- en: Figure 5.8 – ACID versus BASE summary
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 – ACID与BASE总结
- en: Fun fact
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: 'ACID and BASE represent opposing sides of the pH spectrum. Jim Grey conceived
    the idea in 1970 and subsequently published a paper, called *The Transaction Concept:
    Virtues and Limitations*, in June 1981\.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ACID和BASE代表了pH谱的相对面。吉姆·格雷在1970年提出了这个想法，并在1981年6月发表了一篇名为《事务概念：优点与局限》的论文。
- en: So far, you have understood the fundamentals of data modeling and design approaches.
    You must be curious about how to relate those concepts to the connected HBS product,
    which you have been developing in earlier chapters. Let's explore how the rubber
    meets the road.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经理解了数据建模和设计方法的基本原理。你一定很好奇如何将这些概念与你之前章节中开发的连接型HBS产品联系起来。让我们看看如何将理论与实践相结合。
- en: Do you still remember the **first phase** of data modeling?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你还记得数据建模的第一个阶段吗？
- en: Bingo! Conceptual it is.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Bingo！概念上是这样的。
- en: Conceptual modeling of the connected HBS hub
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接型HBS中心的概念建模
- en: 'The following diagram is a hypothetical conceptual model of the HBS hub:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图是一个假设的概念模型，描述了HBS中心：
- en: '![Figure 5.9 – A conceptual data model for connected HBS'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.9 – 连接型HBS的概念数据模型](img/Figure_5.9_A_conceptual_data_model_for_connected_HBS.jpg)'
- en: '](img/B17595_05_009.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_009.jpg](img/B17595_05_009.jpg)'
- en: Figure 5.9 – A conceptual data model for connected HBS
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9 – 连接型HBS的概念数据模型
- en: In the preceding diagram, you can observe how the different devices such as
    lights, HVAC, and washing machines are installed in different rooms of a house.
    Now the conceptual model is in place, let's take a look at the logical view.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，你可以观察到不同的设备，如灯光、HVAC和洗衣机，是如何安装在一所房子的不同房间里的。现在概念模型已经建立，让我们看看逻辑视图。
- en: The logical modeling of the connected HBS hub
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接型HBS中心的逻辑建模
- en: 'To build the logical model, we need to ask ourselves the type of questions
    an end consumer might ask, such as the following:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建逻辑模型，我们需要问自己最终消费者可能会问的问题类型，例如以下问题：
- en: Show the status of a device (such as is the washing complete?).
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示设备的状态（例如，洗涤是否完成？）。
- en: Turn a device on or off (such as turn off the lights).
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打开或关闭设备（例如，关闭灯光）。
- en: Show the readings of a device (such as what's the temperature now?).
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示设备的读取（例如，现在的温度是多少？）。
- en: Take a new reading (such as how much energy is being consumed by the refrigerator?).
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行新的读取（例如，冰箱消耗了多少能量？）。
- en: Show the aggregated connectivity status of a device (or devices) for a period.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示设备（或设备）在一段时间内的聚合连接状态。
- en: 'To address these questions, let''s determine the access patterns for our end
    application:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这些问题，让我们确定我们的最终应用程序的访问模式：
- en: '![Figure 5.10 – A logical data model for connected HBS'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.10 – 连接型HBS的逻辑数据模型](img/Figure_5.10_A_logical_data_model_for_connected_HBS.jpg)'
- en: '](img/B17595_05_Table_1.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_Table_1.jpg](img/B17595_05_Table_1.jpg)'
- en: Figure 5.10 – A logical data model for connected HBS
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.10 – 连接型HBS的逻辑数据模型
- en: Now that we have captured the summary of our data modeling requirements, you
    can observe that the solution needs to ingest data in both structured and semi-structured
    formats at high frequency. Additionally, it doesn't require strong consistency.
    Therefore, it makes sense to design the data layer using a NoSQL solution that
    leverages the BASE methodology.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经捕捉到了数据建模需求的总览，您可以看到解决方案需要以高频率摄取结构化和半结构化格式的数据。此外，它不需要强一致性。因此，使用利用 BASE
    方法的 NoSQL 解决方案来设计数据层是有意义的。
- en: The physical modeling of the connected HBS hub
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接的 HBS 中心物理建模
- en: As the final step, we need to define the physical data model from the gathered
    requirements. To do that, we will define a primary and a secondary key. You are
    not required to define all of the attributes if they're not known to you, which
    is a key advantage of a NoSQL solution.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一步，我们需要根据收集到的需求定义物理数据模型。为此，我们将定义一个主键和一个二级键。如果您不知道所有属性，您不需要定义所有属性，这是 NoSQL
    解决方案的一个关键优势。
- en: Defining the primary key
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义主键
- en: As the name suggests, this is one of the required attributes in a table, which
    is often known as a **Partition key**. In a table, no two primary keys should
    have the same value. There is also a concept of a **Composite key**. It's composed
    of two attributes, a partition key and a **Sort key**.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，这是表中的一个必需属性，通常被称为**分区键**。在一个表中，没有两个主键应该有相同的值。还有一个**复合键**的概念。它由两个属性组成，一个分区键和一个**排序键**。
- en: 'In our scenario, we will create a `Sensor` table with a composite key (as depicted
    in the following screenshot). The primary key is a **device identifier**, and
    the sort key is a timestamp that enables us to query data in a time range:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的场景中，我们将创建一个具有复合键（如图所示）的`Sensor`表。主键是一个**设备标识符**，排序键是一个时间戳，它使我们能够查询时间范围内的数据：
- en: '![Figure 5.11 – Composite keys in a sensor table'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.11 – 传感器表中的复合键'
- en: '](img/B17595_05_011.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17595_05_011.jpg)'
- en: Figure 5.11 – Composite keys in a sensor table
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 – 传感器表中的复合键
- en: Defining the secondary indexes
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义二级索引
- en: A **secondary index** allows us to query the data in the table using a different
    key, in addition to queries against the primary or composite keys. This gives
    your applications more flexibility in querying the data for different use cases.
    Performing a query using a secondary index is pretty similar to querying from
    the table directly.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**二级索引**允许我们使用不同的键查询表中的数据，除了对主键或复合键的查询。这为您的应用程序在查询不同用例的数据时提供了更多的灵活性。使用二级索引进行查询与直接从表中查询非常相似。
- en: 'Therefore, for secondary indexes, as shown in the following chart, we have
    selected the primary key as a sensor identifier (`sensor_id`) along with timestamp
    as the sort key:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于二级索引，如以下图表所示，我们选择了主键作为传感器标识符（`sensor_id`）以及时间戳作为排序键：
- en: '![Figure 5.12 – Secondary indexes in a sensor table'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.12 – 传感器表中的二级索引'
- en: '](img/B17595_05_012.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17595_05_012.jpg)'
- en: Figure 5.12 – Secondary indexes in a sensor table
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 – 传感器表中的二级索引
- en: Defining the additional attributes
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义额外的属性
- en: 'The key advantage of a NoSQL solution is that there is no enforced schema.
    Therefore, other attributes can be created on the fly as data comes in. That being
    said, if some of the attributes are already known to the developer, there is no
    restriction to include those in the data model:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: NoSQL 解决方案的关键优势是没有强制性的模式。因此，可以在数据到来时动态创建其他属性。话虽如此，如果开发人员已经知道一些属性，则没有限制将它们包含在数据模型中：
- en: '![Figure 5.13 – Other attributes in a sensor table'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.13 – 传感器表中的其他属性'
- en: '](img/B17595_05_013.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B17595_05_013.jpg)'
- en: Figure 5.13 – Other attributes in a sensor table
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 – 传感器表中的其他属性
- en: Now that the data layer exists, let's create the interfaces to access this data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据层已经存在，让我们创建访问这些数据的接口。
- en: Defining the interfaces
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义接口
- en: 'Now we will create two different facets for the sensor table. A **facet** is
    a virtual construct that enables different views of the data stored in a table.
    The facets can be mapped to a functional construct such as a method or an API
    for performing various **Create, Read, Update, Delete** (**CRUD**) operations
    on a table:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将为传感器表创建两个不同的方面。**方面**是一个虚拟结构，它使您能够以不同的视图查看存储在表中的数据。方面可以映射到功能结构，如方法或 API，以执行对表的各种**创建、读取、更新、删除**（**CRUD**）操作：
- en: '`putItems`: This facet allows write operations and requires the composite keys
    at the minimum in the payload.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`putItems`：此维度允许写入操作，并在有效载荷中至少需要复合键。'
- en: '`getItems`: This facet allows read operations that can query items with all
    or selective attributes.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getItems`：此维度允许查询具有所有或选择性属性的项的读取操作。'
- en: 'The following screenshot depicts the `getItems` facet definition:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了`getItems`维度的定义：
- en: '![Figure 5.14 – The getItems facet definition'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.14 – `getItems`维度的定义'
- en: '](img/B17595_05_014.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_014.jpg](img/B17595_05_014.jpg)'
- en: Figure 5.14 – The getItems facet definition
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14 – `getItems`维度的定义
- en: So, now you have created the data model along with its interfaces. This enables
    you to understand the data characteristics that are required to develop edge applications.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在你已经创建了数据模型及其接口。这使你能够理解开发边缘应用所需的数据特性。
- en: Designing data patterns on the edge
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在边缘设计数据模式
- en: As data flows securely from different sensors/actuators on the edge to the gateway
    or cloud over different protocols or channels, it is necessary for it to be safely
    stored, processed, and cataloged for further consumption. Therefore, any IoT data
    architecture needs to take into consideration the data models (as explained earlier),
    data storage, data flow patterns, and anti-patterns, which will be covered in
    this section. Let's start with data storage.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据从边缘的不同传感器/执行器通过不同的协议或通道安全地流向网关或云端时，它需要被安全存储、处理和编目以供进一步消费。因此，任何物联网数据架构都需要考虑数据模型（如前所述）、数据存储、数据流模式以及反模式，这些内容将在本节中介绍。让我们从数据存储开始。
- en: Data storage
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据存储
- en: Big data solutions on the cloud are designed to reliably store terabytes, petabytes,
    or exabytes of data and can scale across multiple geographic locations globally
    to provide high availability and redundancy for businesses to meet their **Recovery
    Time Objective** (**RTO**) and **Recovery Point Objective** (**RPO**). However,
    edge solutions, such as our very own connected HBS hub solution, are resource-constrained
    in terms of compute, storage, and network. Therefore, we need to design the edge
    solution to cater to different time-sensitive, low-latency use cases and hand
    off the heavy lifting to the cloud. A **data lake** is a well-known pattern on
    the cloud today, which allows a centralized repository to store data as it arrives,
    without having to first structure the data. Thereafter, different types of analytics,
    machine learning, and visualizations can be performed on that data for consumers
    to achieve better business outcomes. So, what is the equivalent of a data lake
    for the edge?
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 云端的大数据解决方案旨在可靠地存储千兆字节、太字节或艾字节的数据，并能够跨全球多个地理位置进行扩展，以提供高可用性和冗余，以满足企业满足其**恢复时间目标**（**RTO**）和**恢复点目标**（**RPO**）。然而，边缘解决方案，如我们自己的连接HBS中心解决方案，在计算、存储和网络方面资源有限。因此，我们需要设计边缘解决方案以适应不同的时效性、低延迟用例，并将重负载交给云端。**数据湖**是云端的知名模式，它允许集中存储到达的数据，而无需首先对数据进行结构化。之后，可以对数据进行不同类型的分析、机器学习和可视化，以帮助消费者实现更好的业务成果。那么，边缘的数据湖是什么？
- en: 'Let''s introduce a new pattern, called a *data pond*, for the authoritative
    source of data (that is, the golden source) that is generated and temporarily
    persisted on the edge. Certain characteristics of a data pond are listed as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们介绍一种新的模式，称为*数据池塘*，用于在边缘生成并临时持久化的数据权威来源（即，金数据源）。以下列出了数据池塘的一些特性：
- en: A data pond enables the quick ingestion and consumption of data in a fast and
    flexible fashion. A data producer is only required to know where to push the data,
    that is, the local storage, local stream, or cloud. The choice of the storage
    layer, schema, ingestion frequency, and quality of the data is left to the data
    producer.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据池塘能够快速并以灵活的方式摄取和消费数据。数据生产者只需要知道将数据推送到哪里，即本地存储、本地流或云端。存储层、模式、摄取频率和数据质量的选择留给数据生产者。
- en: A data pond should work with low-cost storage. Generally, IoT devices are low
    in storage; therefore, only highly valuable data that's relevant for the edge
    operations can be persisted locally. The rest of the data is pushed to the cloud
    for additional processing or thrown away (if noisy).
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据池塘应该与低成本存储一起工作。通常，物联网设备存储空间较小；因此，只有与边缘操作高度相关的数据才能在本地持久化。其余数据被推送到云端进行进一步处理或丢弃（如果数据噪声大）。
- en: A data pond supports schema on read. There can be multiple streams supporting
    multiple schemas in a data pond.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据池塘支持读取时模式。数据池塘中可以有多个流支持多个模式。
- en: A data pond should support the data protection mechanisms at rest and in encryption.
    It's also useful to implement role-based access that allows auditing the data
    trail as it flows from the edge to the cloud.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据池塘应支持静态和加密中的数据保护机制。实现基于角色的访问控制，允许审计数据从边缘流向云的数据轨迹也是有用的。
- en: 'The following diagram shows an edge architecture of how data collected from
    different sensors/actuators can be persisted and securely governed in a data pond:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了如何将来自不同传感器/执行器的数据持久化并安全地在数据池塘中管理：
- en: '![Figure 5.15 – A data pond architecture at the edge'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.15 – 边缘数据池塘架构](img/B17595_05_015.jpg)'
- en: '](img/B17595_05_015.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_016.jpg](img/B17595_05_016.jpg)'
- en: Figure 5.15 – A data pond architecture at the edge
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15 – 边缘数据池塘架构
- en: 'The organizational entities involved in the preceding data flow include the
    following:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的数据流中涉及的实体包括以下内容：
- en: '**Data producers**: These are entities that generate data. These include physical
    (such as sensors, actuators, or associated devices) or logical (such as applications)
    entities and are configured to store data in the data pond or publish data to
    the cloud.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据生产者**：这些是生成数据的实体。这些包括物理实体（如传感器、执行器或相关设备）或逻辑实体（如应用程序），并配置为在数据池塘中存储数据或将数据发布到云中。'
- en: '**Data pond team**: Generally, the data operations team defines the data access
    mechanisms for the data pond (or lake) and the development team supports data
    management.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据池塘团队**：通常，数据操作团队定义数据池塘（或湖泊）的数据访问机制，而开发团队支持数据管理。'
- en: '**Data consumers**: Edge and cloud applications retrieve data from the data
    pond (or lake) using the mechanisms authorized to further iterate on the data
    and meet business needs.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据消费者**：边缘和云应用程序使用授权机制从数据池塘（或湖泊）检索数据，以进一步迭代数据并满足业务需求。'
- en: 'The following screenshot shows the organizational entities for the data pond:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的截图显示了数据池塘的组织实体：
- en: '![Figure 5.16 – The organizational entities for the data pond'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.16 – 数据池塘的组织实体](img/B17595_05_016.jpg)'
- en: '](img/B17595_05_016.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_017.jpg](img/B17595_05_017.jpg)'
- en: Figure 5.16 – The organizational entities for the data pond
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16 – 数据池塘的组织实体
- en: Now you have understood how data can be stored on a data pond and be managed
    or governed by different entities. Next, let's discuss the different flavors of
    data and how they can be integrated.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了数据如何在数据池塘中存储，并由不同的实体进行管理或治理。接下来，让我们讨论不同类型的数据以及它们如何被集成。
- en: Data integration concepts
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集成概念
- en: 'DII occurs through different layers, as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: DII通过不同的层发生，如下所示：
- en: '**Batch**: This layer aggregates data that has been generated by data producers.
    The goal is to increase the accuracy of data insights through the consolidation
    of data from multiple sources or dimensions.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量**：此层聚合数据生产者生成的数据。目标是通过对多个来源或维度的数据进行整合来提高数据洞察的准确性。'
- en: '**Speed**: This layer streams data generated by data producers. The goal is
    to allow a near real-time analysis of data with an acceptable level of accuracy.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：此层传输数据生产者生成数据。目标是允许以可接受的准确度进行近乎实时的数据分析。'
- en: '**Serving**: This layer merges the data from the batch layer and the speed
    layer to enable the downstream consumers or business users with holistic and incremental
    insights into the business.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务**：此层合并批量层和速度层的数据，以便下游消费者或商业用户能够获得全面和增量洞察业务。'
- en: 'The following diagram is an illustration of DII:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 下图是DII的说明图：
- en: '![Figure 5.17 -- Data Integration and Interoperability (DII)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.17 -- 数据集成与互操作性（DII）](img/B17595_05_015.jpg)'
- en: '](img/B17595_05_017.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_017.jpg](img/B17595_05_017.jpg)'
- en: Figure 5.17 -- Data Integration and Interoperability (DII)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.17 -- 数据集成与互操作性（DII）
- en: As you can see, there are multiple layers within the data flow that are commonly
    implemented using the **Extract, Transform, and Load** (**ETL**) methodology or
    the **Extract, Load, and Transform** (**ELT**) methodology in the big data world.
    The ETL methodology involves steps to extract data from different sources, implement
    data quality and consistency standards, transform (or aggregate) the data to conform
    to a standard format, and load (or deliver) data to downstream applications.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，数据流中存在多个层次，通常在大数据世界中使用**提取、转换和加载**（**ETL**）方法或**提取、加载和转换**（**ELT**）方法来实现。ETL方法包括从不同来源提取数据、实施数据质量和一致性标准、转换（或聚合）数据以符合标准格式，以及将数据加载（或交付）到下游应用。
- en: The ELT process is a variant of ETL with similar steps. The difference is that
    extracted data is loaded before the transformation. This is common for edge workloads
    as well, where the local gateway might not have enough resources to do the transformation
    locally; therefore, it publishes the data prior to additional processing.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ELT过程是ETL的一种变体，具有类似的步骤。不同之处在于，提取的数据在转换之前加载。这在边缘工作负载中也很常见，因为本地网关可能没有足够的资源在本地进行转换；因此，它在进一步处理之前发布数据。
- en: But how are these data integration patterns used in the edge? Let's explore
    this next.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 但这些数据集成模式如何在边缘使用呢？让我们接下来探索这个问题。
- en: Data flow patterns
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据流模式
- en: 'An ETL flow on the edge will include three distinct steps, as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘的ETL流程将包括以下三个不同的步骤：
- en: Data extraction from devices such as sensors/actuators
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从传感器/执行器等设备中提取数据
- en: Data transformation to clean, filter, or restructure data into an optimized
    format for further consumption
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据转换以清理、过滤或重新结构化数据，以便进一步消费
- en: Data loading to publish data to the persistence layer such as a data pond, a
    data lake, or a data warehouse
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据加载到持久层，如数据池、数据湖或数据仓库以发布数据
- en: For an ELT flow, *steps 2* and *3* will take place in the reverse order.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于ELT流程，步骤**2**和**3**将以相反的顺序进行。
- en: An ETL Scenario for a Connected Home
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 智能家居的ETL场景
- en: For example, in a connected home scenario, it's common to extract data from
    different sensors/actuators, followed by a data transformation that might include
    format changes, structural changes, semantic conversions, or deduplication. Additionally,
    data transformation allows you to filter out any noisy data from the home (think
    of a crying baby or a noisy pet), resulting in reduced network charges of publishing
    all the bits and bytes to the cloud. Based on a use case such as an intrusion
    alert or replenishing a printer toner, data transformation can be performed in
    batch or real time, by eitherphysically storing the result in a staging area or
    virtually storing the transferred data in memory until you are ready to move to
    the load step.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在智能家居场景中，通常从不同的传感器/执行器中提取数据，然后进行数据转换，这可能包括格式更改、结构更改、语义转换或去重。此外，数据转换允许您过滤掉家庭中的任何噪声数据（想想哭闹的婴儿或嘈杂的宠物），从而减少将所有比特和字节发布到云中的网络费用。基于入侵警报或补充打印机墨盒等用例，数据转换可以批量或实时进行，通过在准备移动到加载步骤之前在临时区域物理存储结果或虚拟存储传输数据到内存中。
- en: These core patterns (ETL or ELT) have evolved, with time, into different data
    flow architectures, such as event-driven, batch, lambda, and**complex event processing**
    *(***CEP***)*. We will explain each of them in the next section.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这些核心模式（ETL或ELT）随着时间的推移而演变，形成了不同的数据流架构，例如事件驱动、批量、lambda和**复杂事件处理**（**CEP**）。我们将在下一节中解释每个模式。
- en: Event-driven (or streaming)
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件驱动（或流式）
- en: It's very common for edge applications to generate and process data in smaller
    sets throughout the day when an event happens. Near real-time data processing
    has a lower latency and can be both synchronous and asynchronous.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘应用在事件发生时，在一天中生成和处理数据通常以较小的数据集进行，这是非常常见的。近实时数据处理具有较低的延迟，可以是同步的也可以是异步的。
- en: In an asynchronous data flow, the devices (such as sensors) do not wait for
    the receiving system to acknowledge updates before continuing processing. For
    example, in a connected home, a motion/occupancy sensor can trigger an intruder
    notification based on a detected event but continue to monitor without waiting
    for an acknowledgment.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在异步数据流中，设备（如传感器）在继续处理之前不会等待接收系统确认更新。例如，在智能家居中，一个运动/占用传感器可以根据检测到的事件触发入侵通知，但继续监控而无需等待确认。
- en: In comparison, in a real-time synchronous data flow, no time delay or other
    differences between source and target are acceptable. For example, in a connected
    home, if there is a fire alarm, it should notify the emergency services in a deterministic
    way.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，在实时同步数据流中，源和目标之间不允许存在任何时间延迟或其他差异。例如，在一个智能家居中，如果发生火灾警报，它应该以确定性的方式通知紧急服务。
- en: 'With AWS Greengrass, you can design both **synchronous** and **asynchronous**
    data communications. In addition to this, as we build multi-faceted architectures
    on the edge, it''s quite normal to build multiprocessing or multithreaded polyglot
    solutions on the edge to support different low-latency use cases:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AWS Greengrass，您可以设计**同步**和**异步**的数据通信。除此之外，在我们构建边缘的多面架构时，在边缘构建多进程或多线程的多语言解决方案以支持不同的低延迟用例是很常见的：
- en: '![Figure 5.18 – Event-driven architecture at the edge'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.18 – 边缘事件驱动架构'
- en: '](img/B17595_05_018.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_018.jpg](img/B17595_05_018.jpg)'
- en: Figure 5.18 – Event-driven architecture at the edge
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.18 – 边缘事件驱动架构
- en: Micro-batch (or aggregated processing)
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微批处理（或聚合处理）
- en: Most enterprises perform frequent batch processing to enable end users with
    business insights. In this mode, data moving will represent either the full set
    of data at a given point in time, such as the energy meter reading of a connected
    home at the end of a period (such as the day, week, or month), or data that has
    changed values since the last time it was sent, such as a hvac reading or a triggered
    fire alarm. Generally, batch systems are designed to scale and grow proportionally
    along with the data. However, that's not feasible on the edge due to the lack
    of horsepower, as explained earlier.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数企业执行频繁的批处理，以便为最终用户提供业务洞察。在这种模式下，数据移动将代表在特定时间点的全部数据集，例如在一段时间结束时（如一天、一周或一个月）连接家庭的能源计量读数，或者自上次发送以来值已更改的数据，例如
    hvac 读数或触发的火灾警报。通常，批处理系统被设计为随着数据的增长而按比例扩展和增长。然而，由于缺乏动力，这在边缘是不可行的，如前所述。
- en: 'Therefore, for IoT use cases, leveraging micro-batch processing is more common.
    Here, the data is stored locally and is processed on a much higher frequency,
    such as every few seconds, minutes, hours, or days (over weeks or months). This
    allows data consumers to gather insights from local data sources with reduced
    latency and cost, even when disconnected from the internet. The **Stream Manager**
    capability of AWS Greengrass allows you to perform aggregated processing on the
    edge. Stream Manager brings enhanced functionalities regarding how to process
    data on the edge such as defining a bandwidth and data prioritization for multiple
    channels, timeout behavior, and direct export mechanisms to different AWS services
    such as Amazon S3, AWS IoT Analytics, AWS IoT SiteWise, and Amazon Kinesis data
    streams:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于物联网用例，利用微批处理更为常见。在这里，数据是本地存储的，并且以更高的频率进行处理，例如每几秒、几分钟、几小时或几天（跨越几周或几个月）。这允许数据消费者从本地数据源以降低延迟和成本的方式收集见解，即使在断开互联网连接的情况下也是如此。AWS
    Greengrass 的 **Stream Manager** 功能允许您在边缘执行聚合处理。Stream Manager 带来了关于如何在边缘处理数据的增强功能，例如为多个通道定义带宽和数据优先级、超时行为以及直接导出到不同的
    AWS 服务，如 Amazon S3、AWS IoT Analytics、AWS IoT SiteWise 和 Amazon Kinesis 数据流：
- en: '![Figure 5.19 – Micro-batch architecture at the edge'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.19 – 边缘微批处理架构'
- en: '](img/B17595_05_019.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_019.jpg](img/B17595_05_019.jpg)'
- en: Figure 5.19 – Micro-batch architecture at the edge
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.19 – 边缘微批处理架构
- en: Lambda architecture
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Lambda 架构
- en: Lambda architecture is an approach that combines both micro-batch and stream
    (near real-time) data processing. It makes the consolidated data available for
    downstream consumption. For example, a refrigeration unit, a humidifier, or any
    critical piece of machinery on a manufacturing plant can be monitored and fixed
    before it becomes non-operational. So, for a connected HBS hub solution, micro-batch
    processing will allow you to detect long-term trends or failure patterns. This
    capability in turn, will help your fleet operators recommend preventive or predictive
    maintenance for the machines to end consumers. This workflow is often referred
    to as the warm or cold path of the data analytics flow.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 架构是一种结合了微批处理和流（近实时）数据处理的方法。它使综合数据可用于下游消费。例如，一个制冷单元、加湿器或制造厂上的任何关键设备都可以在它变得无法运行之前进行监控和修复。因此，对于连接的
    HBS 网关解决方案，微批处理将允许您检测长期趋势或故障模式。这种能力反过来可以帮助您的车队运营商为最终消费者推荐预防性或预测性维护。这种工作流程通常被称为数据流分析流程的温暖或冷路径。
- en: 'On the other hand, stream processing will allow the fleet operators to derive
    near real-time insights through telemetry data. This will enable consumers to
    take mission-critical actions such as locking the entire house and calling emergency
    services if any theft is detected. This is also referred to as the hot path in
    lambda architecture:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，流处理将允许车队操作员通过遥测数据获得近乎实时的洞察。这将使消费者能够在检测到任何盗窃时采取关键任务行动，例如锁定整个房屋并呼叫紧急服务。这也被称为lambda架构中的热点路径：
- en: '![Figure 5.20 – Lambda architecture at the edge'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.20 – 边缘的lambda架构]'
- en: '](img/B17595_05_020.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B17595_05_020.jpg]'
- en: Figure 5.20 – Lambda architecture at the edge
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.20 – 边缘的lambda架构
- en: Fun fact
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: Lambda architecture has nothing to do with the AWS lambda service. The term was
    coined by Nathan Marz, who worked on big-data-related technologies at *BackType*
    and *Twitter*. This is a design pattern for describing data processing that is
    scalable and fault-tolerant.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda架构与AWS Lambda服务无关。这个术语是由Nathan Marz提出的，他在BackType和Twitter等公司从事大数据相关技术工作。这是一个用于描述可扩展和容错的数据处理的设计模式。
- en: Data flow anti-patterns for the edge
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边缘的数据流反模式
- en: So far, we have learned about the common data flow patterns on the edge. Let's
    also discuss some of the anti-patterns.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了边缘上常见的数据处理模式。让我们也讨论一些反模式。
- en: Complex Event Processing (CEP)
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 复杂事件处理（CEP）
- en: Events are data patterns that identify complex circumstances from ingested data,
    such as network outages in a home or a fire alarm in a building. It might be easier
    to detect events from a few sensors or devices; however, getting visibility into
    complex events from disparate sources and being able to capture states or trigger
    conditional logic to identify and resolve issues quickly requires special treatment.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 事件是从摄入的数据中识别复杂情况的数据模式，例如家庭中的网络中断或建筑中的火灾警报。从几个传感器或设备中检测事件可能更容易；然而，要从不同的来源获得对复杂事件的可见性，并能够捕获状态或触发条件逻辑以快速识别和解决问题，则需要特殊处理。
- en: That's where the CEP pattern comes into play. CEP can be resource-intensive
    and needs to scale to all sizes of data and grow proportionally. Therefore, it's
    still not a very common pattern on the edge. On the cloud, managed services such
    as AWS IoT events or AWS EventBridge can make it easier for you to perform CEP
    on the data generated from your IoT devices.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 正是CEP模式发挥作用的地方。CEP可能资源密集，需要扩展到所有大小的数据并成比例增长。因此，它仍然不是边缘上非常常见的模式。在云上，如AWS IoT事件或AWS
    EventBridge之类的托管服务可以使您更容易地对来自您的物联网设备生成数据进行CEP。
- en: Batch
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 批处理
- en: Traditionally, in batch processing, data moves in aggregates as blobs or files
    either on an ad hoc request from a consumer or automatically on a periodic schedule.
    Data will either be a full set (referred to as snapshot) or a changed set (delta)
    from a given point in time. Batch processing requires continuous scaling of the
    underlying infrastructure to facilitate the data growth and processing requirements.
    Therefore, it's a pattern that is better suited for big data or data warehousing
    solutions on the cloud. That being said, for an edge use case, you can still leverage
    the micro-batch pattern (as explained earlier) to aggregate data that's feasible
    in the context of a resource-constrained environment.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，在批处理中，数据以聚合的形式作为块或文件移动，要么是来自消费者的临时请求，要么是自动的定期计划。数据将是从某个时间点的一个完整集合（称为快照）或一个变化集合（增量）。批处理需要不断扩展底层基础设施以促进数据增长和处理需求。因此，这是一个更适合大数据或云上数据仓库解决方案的模式。话虽如此，对于边缘用例，你仍然可以利用前面解释过的微批处理模式来聚合在资源受限环境中可行的大量数据。
- en: Replication
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 复制
- en: It's a common practice on the cloud to maintain redundant copies of datasets
    across different locations to improve business continuity, improve the end user
    experience, or enhance data resiliency. However, in the context of the edge, **data
    replication** can be expensive, as you might require redundant deployments. For
    example, with a connected HBS hub solution, if the gateway needs to support redundant
    storage for replication, it will increase the **bill of materials** (**BOM**)
    cost of the hardware, and you can lose the competitive edge on the market.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在云上，维护不同位置的重复数据集副本是一种常见做法，以提高业务连续性、改善最终用户体验或增强数据弹性。然而，在边缘的背景下，**数据复制**可能很昂贵，因为你可能需要冗余部署。例如，使用连接的HBS中心解决方案，如果网关需要支持用于复制的冗余存储，这将增加硬件的**物料清单**（BOM）成本，你可能会在市场上失去竞争优势。
- en: Archiving
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 归档
- en: Data that is used infrequently or not actively used can be moved to an alternate
    data storage solution that is more cost-effective to the organization. Similar
    to replication, for archiving data locally on the edge, additional deployment
    of hardware resource is necessary. This increases the **bill of materials** (**BOM**)
    cost of the device and leads to additional operational overhead. Therefore, it's
    common to archive the transformed data from the data lake to a cost-effective
    storage service on the cloud such as **Amazon Glacier**. Thereafter, this data
    can be used for local operations, data recovery, or regulatory needs.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 不常使用或未积极使用的数据可以迁移到对组织更具成本效益的替代数据存储解决方案。类似于复制，对于在边缘本地存档数据，需要额外部署硬件资源。这增加了设备的
    **物料清单** （**BOM**） 成本，并导致额外的运营开销。因此，通常将数据湖中的转换数据存档到云上的成本效益存储服务，如 **Amazon Glacier**。此后，这些数据可用于本地操作、数据恢复或合规性需求。
- en: A hands-on approach with the lab
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过实验室进行实践方法
- en: 'In this section, you will learn how to build a lambda architecture on the edge
    using different AWS services. The following diagram shows the lambda architecture:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何使用不同的 AWS 服务在边缘构建 lambda 架构。以下图表显示了 lambda 架构：
- en: '![Figure 5.21 – The lab architecture'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.21 – 实验室架构](img/B17595_05_021.jpg)'
- en: '](img/B17595_05_021.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_05_021.jpg)'
- en: Figure 5.21 – The lab architecture
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.21 – 实验室架构
- en: 'The preceding workflow uses the following services. In this chapter, you will
    complete *steps 1–6* (as shown in *Figure 5.21*). This includes designing and
    deploying the edge components, processing, and transforming data locally, and
    pushing the data to different cloud services:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 上述工作流程使用以下服务。在本章中，您将完成 *步骤 1–6* （如图 5.21 所示）。这包括设计并部署边缘组件、本地处理和转换数据，以及将数据推送到不同的云服务：
- en: \
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: \
- en: '![Figure 5.22 – The hands-on lab components'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.22 – 实践实验室组件](img/B17595_05_022.jpg)'
- en: '](img/B17595_05_022.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17595_05_022.jpg)'
- en: Figure 5.22 – The hands-on lab components
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.22 – 实践实验室组件
- en: 'In this hands-on section, your objective will consist of the following:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在本实践部分，您的目标将包括以下内容：
- en: Build the cloud resource (that is, Amazon Kinesis data streams, Amazon S3 bucket,
    and DynamoDB tables).
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建云资源（即 Amazon Kinesis 数据流、Amazon S3 存储桶和 DynamoDB 表）。
- en: Build and deploy the edge components (that is, artifacts and recipes) locally
    on Raspberry Pi.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Raspberry Pi 上本地构建和部署边缘组件（即工件和配方）。
- en: Validate that the data is streamed from the edge to the cloud (AWS IoT Core).
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证数据是否从边缘流式传输到云（AWS IoT Core）。
- en: Building cloud resources
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建云资源
- en: Deploy the CloudFormation template from the `chapter5/cfn` folder to create
    cloud resources such as Amazon S3 buckets, Kinesis data streams, and DynamoDB
    tables. You will need to substitute these respective names from the *Resources*
    section of the deployed stack, when requested, in the following section.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 从 `chapter5/cfn` 文件夹部署 CloudFormation 模板以创建云资源，例如 Amazon S3 存储桶、Kinesis 数据流和
    DynamoDB 表。在后续部分需要时，您需要从已部署堆栈的 *资源* 部分替换这些相应的名称。
- en: Building edge components
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建边缘组件
- en: 'Now, let''s hop on to our device to build and deploy the required edge components:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们跳转到我们的设备来构建和部署所需的边缘组件：
- en: 'Navigate to the following working directory from the Terminal of your Raspberry
    Pi device:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Raspberry Pi 设备的终端导航到以下工作目录：
- en: '[PRE0]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Open the Python script using the editor of your choice (such as *nano*, *vi*,
    or *emac*):'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您选择的编辑器（如 *nano*、*vi* 或 *emac*）打开 Python 脚本：
- en: '[PRE1]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'def read_value(self):'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'def read_value(self):'
- en: message = {}
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message = {}
- en: device_list = ['hvac', 'refrigerator', 'washingmachine']
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: device_list = ['hvac', 'refrigerator', 'washingmachine']
- en: device_name = random.choice(device_list)
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: device_name = random.choice(device_list)
- en: 'if device_name == ''hvac'' :'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if device_name == ''hvac'' :'
- en: message['device_id'] = "1"
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['device_id'] = "1"
- en: message['timestamp'] = float("%.4f" % (time()))
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['timestamp'] = float("%.4f" % (time()))
- en: message['device_name'] = device_name
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['device_name'] = device_name
- en: message['temperature'] = round(random.uniform(10.0, 99.0), 2)
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['temperature'] = round(random.uniform(10.0, 99.0), 2)
- en: message['humidity'] = round(random.uniform(10.0, 99.0), 2)
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['humidity'] = round(random.uniform(10.0, 99.0), 2)
- en: 'elif device_name == ''washingmachine'' :'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'elif device_name == ''washingmachine'' :'
- en: message['device_id'] = "2"
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['device_id'] = "2"
- en: message['timestamp'] = float("%.4f" % (time()))
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['timestamp'] = float("%.4f" % (time()))
- en: message['device_name'] = device_name
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['device_name'] = device_name
- en: message['duty_cycles'] = round(random.uniform(10.0, 99.0), 2)
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['duty_cycles'] = round(random.uniform(10.0, 99.0), 2)
- en: 'else :'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'else :'
- en: message['device_id'] = "3"
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['device_id'] = "3"
- en: message['timestamp'] = float("%.4f" % (time()))
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['timestamp'] = float("%.4f" % (time()))
- en: message['device_name'] = device_name
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['device_name'] = device_name
- en: message['vibration'] = round(random.uniform(100.0, 999.0), 2)
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message['vibration'] = round(random.uniform(100.0, 999.0), 2)
- en: return message
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return message
- en: '[PRE2]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, open the following `publisher` script and navigate through the code:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，打开以下`publisher`脚本并导航到代码：
- en: '[PRE3]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: TIMEOUT = 10
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: TIMEOUT = 10
- en: ipc_client = awsiot.greengrasscoreipc.connect()
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ipc_client = awsiot.greengrasscoreipc.connect()
- en: sensor = DummySensor()
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: sensor = DummySensor()
- en: 'while True:'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'while True:'
- en: message = sensor.read_value()
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message = sensor.read_value()
- en: message_json = json.dumps(message).encode('utf-8')
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message_json = json.dumps(message).encode('utf-8')
- en: request = PublishToTopicRequest()
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request = PublishToTopicRequest()
- en: request.topic = args.pub_topic
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request.topic = args.pub_topic
- en: publish_message = PublishMessage()
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: publish_message = PublishMessage()
- en: publish_message.json_message = JsonMessage()
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: publish_message.json_message = JsonMessage()
- en: publish_message.json_message.message = message
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: publish_message.json_message.message = message
- en: request.publish_message = publish_message
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request.publish_message = publish_message
- en: operation = ipc_client.new_publish_to_topic()
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: operation = ipc_client.new_publish_to_topic()
- en: operation.activate(request)
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: operation.activate(request)
- en: future = operation.get_response()
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: future = operation.get_response()
- en: future.result(TIMEOUT)
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: future.result(TIMEOUT)
- en: print("publish")
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print("publish")
- en: time.sleep(5)
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: time.sleep(5)
- en: '[PRE4]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now you have reviewed the code, check the following recipe file to review the
    access controls and dependencies that are required by the `Publisher` component:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您已经审查了代码，请检查以下配方文件以审查`Publisher`组件所需的访问控制和依赖项：
- en: '[PRE5]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now we have the component and the recipe, let''s create a local deployment:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了组件和配方，让我们创建一个本地部署：
- en: '[PRE6]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Verify that the component has successfully been deployed (and is running) using
    the following command:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令验证组件是否已成功部署（并正在运行）：
- en: '[PRE7]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following is the output:'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下输出：
- en: '[PRE8]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now that the `Publisher` component is up and running, let''s review the code
    in the `Subscriber` component as well:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在`Publisher`组件已经启动并运行，让我们也审查`Subscriber`组件中的代码：
- en: '[PRE9]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'def setup_subscription():'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'def setup_subscription():'
- en: request = SubscribeToTopicRequest()
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request = SubscribeToTopicRequest()
- en: request.topic = args.sub_topic
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request.topic = args.sub_topic
- en: handler = StreamHandler()
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: handler = StreamHandler()
- en: operation = ipc_client.new_subscribe_to_topic(handler)
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: operation = ipc_client.new_subscribe_to_topic(handler)
- en: future = operation.activate(request)
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: future = operation.activate(request)
- en: future.result(TIMEOUT)
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: future.result(TIMEOUT)
- en: return operation
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return operation
- en: '[PRE10]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'def send_cloud(message_json):'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'def send_cloud(message_json):'
- en: message_json_string = json.dumps(message_json)
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: message_json_string = json.dumps(message_json)
- en: request = PublishToIoTCoreRequest()
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request = PublishToIoTCoreRequest()
- en: request.topic_name = args.pub_topic
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request.topic_name = args.pub_topic
- en: request.qos = QOS.AT_LEAST_ONCE
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request.qos = QOS.AT_LEAST_ONCE
- en: request.payload = bytes(message_json_string,"utf-8")
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request.payload = bytes(message_json_string,"utf-8")
- en: publish_message = PublishMessage()
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: publish_message = PublishMessage()
- en: publish_message.json_message = JsonMessage()
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: publish_message.json_message = JsonMessage()
- en: publish_message.json_message.message = bytes(message_json_string, "utf-8")
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: publish_message.json_message.message = bytes(message_json_string, "utf-8")
- en: request.publish_message = publish_message
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: request.publish_message = publish_message
- en: operation = ipc_client.new_publish_to_iot_core()
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: operation = ipc_client.new_publish_to_iot_core()
- en: operation.activate(request)
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: operation.activate(request)
- en: logger.debug(message_json)
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: logger.debug(message_json)
- en: '[PRE11]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now you have reviewed the code, let''s check the following recipe file to review
    the access controls and dependencies required by the `Subscriber` component:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您已经审查了代码，让我们检查以下配方文件以审查`Subscriber`组件所需的访问控制和依赖项：
- en: '[PRE12]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now we have the component and the recipe, let''s create a local deployment:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了组件和配方，让我们创建一个本地部署：
- en: '[PRE13]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following is the output:'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下输出：
- en: '[PRE14]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Verify that the component has successfully been deployed (and is running) using
    the following command. Now you should see both the `Publisher` and `Subscriber`
    components running locally:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令验证组件是否已成功部署（并正在运行）。现在您应该看到`Publisher`和`Subscriber`组件在本地运行：
- en: '[PRE15]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The following is the output:'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下输出：
- en: '[PRE16]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As you have observed, in the preceding code, the `Subscriber` component will
    not only subscribe to the local `mqtt` topics on the Raspberry Pi, but it will
    also start publishing data to AWS IoT Core (on the cloud). Let''s verify that
    from the AWS IoT console:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如您所观察到的，在先前的代码中，`Subscriber`组件不仅会订阅树莓派上的本地`mqtt`主题，它还会开始向AWS IoT Core（在云中）发布数据。让我们从AWS
    IoT控制台中验证这一点：
- en: Please navigate to `hbs/cloudtopic`. | Click **Subscribe**.
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请导航到`hbs/cloudtopic`。 | 点击**订阅**。
- en: Tip
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示
- en: If you have changed the default topic names in the recipe file, please use that
    name when you subscribe; otherwise, you won't see the incoming messages.
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您已更改配方文件中的默认主题名称，请在订阅时使用该名称；否则，您将看不到传入的消息。
- en: 'Now that you have near real-time data flowing from the edge to the cloud, let''s
    work on the micro-batch flow by integrating with Stream Manager. This component
    will subscribe to the `hbslocal/topic` topic (same as the subscriber). However,
    it will append the data to a local data stream using the Stream Manager functionality
    rather than publishing it to the cloud. Stream Manager is a key functionality
    for you to build a lambda architecture on the edge. We will break down the code
    into different snippets for you to understand these concepts better. So, let''s
    navigate to the working directory:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经从边缘到云中有了近乎实时的数据流动，让我们通过集成Stream Manager来处理微批处理流程。此组件将订阅`hbslocal/topic`主题（与订阅者相同）。然而，它将使用Stream
    Manager功能将数据附加到本地数据流，而不是将其发布到云中。Stream Manager是你在边缘构建lambda架构的关键功能。我们将把代码分解成不同的片段，以便你更好地理解这些概念。因此，让我们导航到工作目录：
- en: '[PRE17]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'First, we create a local stream with the required properties such as stream
    name, data size, time to live, persistence, data flushing, data retention strategy,
    and more. Data within the stream can stay local for further processing or can
    be exported to the cloud using the export definition parameter. In our case, we
    are exporting the data to Kinesis, but you can use a similar approach to export
    the data to other supported services such as S3, IoT Analytics, and more:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们创建一个具有所需属性（如流名称、数据大小、存活时间、持久性、数据刷新、数据保留策略等）的本地流。流中的数据可以保留在本地以供进一步处理，或者可以使用导出定义参数将其导出到云中。在我们的案例中，我们将数据导出到Kinesis，但你也可以使用类似的方法将数据导出到其他支持的服务，如S3、IoT
    Analytics等：
- en: '[PRE18]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now the stream is defined, the data is appended through `append_message api`:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在流已定义，数据将通过`append_message api`附加：
- en: '[PRE19]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Fact Check
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 事实核查
- en: Stream Manager allows you to deploy a lambda architecture on the edge without
    having to deploy and manage a separate lightweight database or streaming solution.
    Therefore, you can reduce the operational overhead or BOM cost of this solution.
    In addition to this, with Stream Manager as a data pond, you can persist data
    on the edge using a schema-less approach dynamically (remember BASE?). And finally,
    you can publish data to the cloud using the native integrations between the Stream
    Manager and cloud data services, such as IoT Analytics, S3, and Kinesis, without
    having to write any additional code. Stream Manager can also be beneficial for
    use cases with larger payloads such as blobs, images, or videos that can be easily
    transmitted over HTTPS.
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Stream Manager允许你在边缘部署lambda架构，而无需部署和管理单独的轻量级数据库或流解决方案。因此，你可以减少此解决方案的操作开销或BOM成本。除此之外，作为数据湖的Stream
    Manager，你可以使用无模式的动态方法在边缘持久化数据（记得BASE吗？）。最后，你可以使用Stream Manager与云数据服务（如IoT Analytics、S3和Kinesis）之间的原生集成将数据发布到云中，而无需编写任何额外的代码。Stream
    Manager对于具有较大有效负载的用例（如blob、图像或视频，可以轻松通过HTTPS传输）也非常有益。
- en: 'Now that you have reviewed the code, let''s add the required permission for
    the Stream Manager component to update the Kinesis stream:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经审查了代码，让我们为Stream Manager组件添加更新Kinesis流的必要权限：
- en: Please navigate to **AWS IoT console**. | Select **Secure** (on the left pane).
    | Choose **Role Aliases** and select the appropriate one. | Click on the **Edit
    IAM Role**. | Attach policies. | Choose **Amazon Kinesis Full Access**. | Attach
    policy.
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请导航到**AWS IoT控制台**。 | 选择**安全**（在左侧面板上）。 | 选择**角色别名**并选择适当的选项。 | 点击**编辑IAM角色**。
    | 附加策略。 | 选择**Amazon Kinesis Full Access**。 | 附加策略。
- en: Please note that it's not recommended to use a blanket policy similar to this
    for production workloads. This is used here in order to ease the reader into operating
    in a test environment.
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，不建议在生产工作负载中使用此类通用策略。这里使用它是为了帮助读者熟悉测试环境中的操作。
- en: 'Let''s perform a quick check of the recipe file prior to deploying this component:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在部署此组件之前，让我们快速检查配方文件：
- en: '[PRE20]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'ComponentConfiguration:'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 组件配置：
- en: 'DefaultConfiguration:'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认配置：
- en: 'sub_topic: "hbs/localtopic"'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '子主题: "hbs/localtopic"'
- en: 'kinesis_stream: "<replace-with-kinesis-stream-from cfn>"'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'kinesis_stream: "<用cfn替换的kinesis流>"'
- en: 'accessControl:'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 访问控制：
- en: 'aws.greengrass.ipc.pubsub:'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: aws.greengrass.ipc.pubsub：
- en: 'com.hbs.hub.Aggregator:pubsub:1:'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'com.hbs.hub.Aggregator:pubsub:1:'
- en: 'policyDescription: "Allows access to subscribe to topics"'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '策略描述: "允许访问订阅主题"'
- en: 'operations:'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 操作：
- en: '- aws.greengrass#SubscribeToTopic'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- aws.greengrass#SubscribeToTopic'
- en: '- aws.greengrass#PublishToTopic'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- aws.greengrass#PublishToTopic'
- en: 'resources:'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 资源：
- en: '- "*"'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- "*"'
- en: 'ComponentDependencies:'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 组件依赖：
- en: 'aws.greengrass.StreamManager:'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: aws.greengrass.StreamManager：
- en: 'VersionRequirement: "^2.0.0"'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 版本要求："^2.0.0"
- en: 'Manifests:'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 清单：
- en: '- Platform:'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 平台：'
- en: 'os: all'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'os: all'
- en: 'Lifecycle:'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生命周期：
- en: 'Install:'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 安装：
- en: pip3 install awsiotsdk numpy -t .
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pip3 install awsiotsdk numpy -t .
- en: 'Run: |'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行：|
- en: export PYTHONPATH=$PYTHONPATH:{artifacts:path}/stream_manager
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: export PYTHONPATH=$PYTHONPATH:{artifacts:path}/stream_manager
- en: PYTHONPATH=$PWD python3 -u {artifacts:path}/hbs_aggregator.py --sub-topic="{configuration:/sub_topic}"
    --kinesis-stream="{configuration:/kinesis_stream}"
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: PYTHONPATH=$PWD python3 -u {artifacts:path}/hbs_aggregator.py --sub-topic="{configuration:/sub_topic}"
    --kinesis-stream="{configuration:/kinesis_stream}"
- en: '[PRE21]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, as we have the artifact and the recipe reviewed, let''s create a local
    deployment:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在我们已经审查了工件和配方之后，让我们创建一个本地部署：
- en: '[PRE22]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Verify that the component has been successfully deployed (and is running) using
    the following command. You should observe all the following components running
    locally:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令验证组件是否已成功部署（并且正在运行）。您应该观察到以下所有组件在本地运行：
- en: '[PRE23]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output is as follows:'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE24]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `Aggregator` component will publish the data directly from the local stream
    to the Kinesis stream on the cloud. Let''s navigate to the AWS S3 console to check
    whether the incoming messages are appearing:'
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Aggregator`组件将直接从本地流将数据发布到云上的Kinesis流。让我们导航到AWS S3控制台，检查传入的消息是否出现：'
- en: Go to the **Amazon Kinesis console**. | Select **Data Streams**. | Choose the
    stream. | Go to the **Monitoring** tab. | Check the metrics such as **Incoming
    data** or **Get records**.
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前往**Amazon Kinesis控制台**。| 选择**Data Streams**。| 选择流。| 前往**监控**选项卡。| 检查**传入数据**或**获取记录**等指标。
- en: If you see the metrics showing some data points on the chart, it means the data
    is successfully reaching the cloud.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在图表上看到一些数据点，这意味着数据已成功到达云。
- en: Note
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can always find the specific resource names required for this lab (such
    as the preceding Kinesis stream) in the *Resources* or *Output* section of the
    CloudFormation stack deployed earlier.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 您始终可以在之前部署的CloudFormation堆栈的*资源*或*输出*部分中找到此实验所需的具体资源名称（例如前面的Kinesis流）。
- en: Validating the data streamed from the edge to the cloud
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证从边缘到云的数据流
- en: 'In this section, you will perform some final validation to ensure the transactional
    and batch data streamed from the edge components is successfully persisted on
    the data lake:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将执行一些最终验证，以确保从边缘组件流出的交易性和批量数据成功持久化在数据湖中：
- en: 'In *step 19 of the previous section*, you validated that the Kinesis stream
    is getting data through metrics. Now, let''s understand how that data is persisted
    to the data lake from the streaming layer:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上一节的*第19步中，您已经通过指标验证了Kinesis流正在接收数据。现在，让我们了解数据是如何从流层持久化到数据湖的：
- en: Go to the **Amazon Kinesis console****.** | Select **Delivery Streams**. | Choose
    the respective delivery stream. | Click on the **Configuration** tab. | Scroll
    down to **Destination Settings**. | Click on the S3 bucket under the Amazon S3
    destination.
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前往**Amazon Kinesis控制台**。| 选择**Delivery Streams**。| 选择相应的交付流。| 点击**配置**选项卡。|
    滚动到**目标设置**。| 点击Amazon S3目标下的S3存储桶。
- en: Click on the bucket and drill down to the child buckets that store the batch
    data in a zipped format to help optimize storage costs.
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 点击存储桶，深入到存储批量数据的子存储桶中，这些数据以压缩格式存储以帮助优化存储成本。
- en: As the final step, navigate to `Tables`. Then, select the table for this lab.
    Click on **View Items**.
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为最后一步，导航到`Tables`。然后，选择此实验的表。点击**查看项目**。
- en: Can you view the time series data? Excellent work.
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您能看到时间序列数据吗？干得好。
- en: Note
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: If you are not able to complete any of the preceding steps, please refer to
    the *Troubleshooting* section in the GitHub repository or create an issue for
    additional instructions.
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您无法完成前面的任何步骤，请参阅GitHub仓库中的*故障排除*部分或创建一个问题以获取更多说明。
- en: Congratulations! You have come a long way to learn how to build a lambda architecture
    that spans from the edge to the cloud using different AWS edge and cloud services.
    Now, let's wrap up with some additional topics before we conclude this chapter.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已经走得很远了，学习如何使用不同的AWS边缘和云服务构建从边缘到云的lambda架构。现在，在我们结束这一章之前，让我们总结一些额外的主题。
- en: Additional topics for reference
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考附加主题
- en: Aside from what we have read so far, there are a couple of topics that I wish
    to mention. Whenever you have the time, please check them out, as they do have
    lots of benefits and can be found online.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们迄今为止所阅读的内容之外，还有一些我想提到的主题。无论何时您有时间，请查看它们，因为它们确实有很多好处，并且可以在网上找到。
- en: Time series databases
  id: totrans-394
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列数据库
- en: 'In this chapter, we learned how to leverage a NoSQL (key-value) data store
    such as Amazon DynamoDB for persisting time series data. Another common way to
    persist IoT data is to use a **time series database** (**TSDB**) such as **Amazon
    Timestream** or **Apache Cassandra**. As you know by now, time series data consists
    of measurements or events collected from different sources such as sensors and
    actuators that are indexed over time. Therefore, the fundamentals of modeling
    a time series database are quite similar to what was explained earlier with NoSQL
    data solutions. So, the obvious question that remains is *How do you choose between
    NoSQL and TSDB?* Take a look at the following considerations:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何利用NoSQL（键值）数据存储，例如Amazon DynamoDB，来持久化时间序列数据。另一种常见的持久化物联网数据的方式是使用**时间序列数据库**（**TSDB**），例如**Amazon
    Timestream**或**Apache Cassandra**。正如你所知，时间序列数据由来自不同来源（如传感器和执行器）的测量或事件组成，这些数据按时间索引。因此，建模时间序列数据库的基本原理与之前解释的NoSQL数据解决方案非常相似。所以，剩下显然的问题就是*你如何选择NoSQL和TSDB？*看看以下考虑因素：
- en: '**Consider the data summarization and data precision requirements**:'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**考虑数据汇总和数据精度要求**：'
- en: For example, show me the energy utilization on a monthly or yearly basis. This
    requires going over a series of data points indexed by a time range to calculate
    a percentile increase of energy over the same period in the last 12 weeks, summarized
    by weeks. This kind of querying could get expensive with a distributed key-value
    store.
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，让我看看月度或年度的能源利用率。这需要遍历一系列按时间范围索引的数据点，以计算过去12周内同一时期能源百分比的增加，按周汇总。这种查询可能会在分布式键值存储中变得昂贵。
- en: '**Consider purging the data after a period of time**:'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**考虑在一段时间后清除数据**：'
- en: For example, do consumers really care about the high precision metrics from
    an hourly basis to calculate their overall energy utilization per month? Probably
    not. Therefore, it's more efficient to store high-precision data for a short period
    of time and, thereafter, aggregated and downsampled data for identifying long-term
    trends. This functionality can partially be achieved with some NoSQL databases
    as well (such as the DynamoDB item expiry functionality). However, TSDBs are better
    suited as they can also offer downsampling and aggregation capabilities using
    different means, such as materialized views.
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，消费者真的关心从每小时到每月的整体能源利用率的精确指标吗？可能不是。因此，更有效的方法是存储短期内的精确数据，然后存储汇总和降采样数据以识别长期趋势。这种功能可以通过一些NoSQL数据库部分实现（例如DynamoDB项目过期功能）。然而，TSDB更适合，因为它们还可以通过不同的方式提供降采样和汇总功能，例如使用物化视图。
- en: Unstructured data
  id: totrans-400
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: You must be curious that most of our discussion in this chapter was related
    to structured and semi-structured data. We did not touch upon unstructured data
    (such as images, audio, and videos) at all. You are spot on. Considering IoT is
    the bridge between the physical world and the cyber world, there will be a huge
    amount of unstructured data that will need to be processed for different analytics
    and machine learning use cases.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能好奇，本章的大部分讨论都与结构化和半结构化数据相关。我们根本未触及非结构化数据（如图像、音频和视频）。你说得对。考虑到物联网是物理世界和虚拟世界之间的桥梁，将会有大量非结构化数据需要处理，以用于不同的分析和机器学习用例。
- en: For example, consider a scenario where the security cameras installed in your
    customer's home detect any infiltration or unexpected movements through the motion
    sensors and start streaming a video feed of the surroundings. The feed will be
    available through your smart hub or mobile devices for consumption. Therefore,
    in this scenario, the security camera is streaming videos that are unstructured
    data, as a P2P feed that can also be stored (if the user allows) locally on the
    hub or to an object store on the cloud. In [*Chapter 7*](B17595_07_Final_SS_ePub.xhtml#_idTextAnchor138),
    *Machine Learning Workloads at the Edge*, you will learn the techniques to ingest,
    store, and infer unstructured data from the edge. However, we will not delve into
    the modeling techniques for unstructured data, as it primarily falls under data
    science and is not very relevant in the day-to-day life of IoT practitioners.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个场景，你客户家中安装的安全摄像头通过运动传感器检测到任何入侵或意外移动，并开始流式传输周围环境的视频。该视频流将通过你的智能中心或移动设备进行消费。因此，在这种情况下，安全摄像头正在流式传输未结构化的视频数据，作为一个可以存储（如果用户允许）在中心或云对象存储上的P2P流。在[*第7章*](B17595_07_Final_SS_ePub.xhtml#_idTextAnchor138)“边缘机器学习工作负载”中，你将学习从边缘摄取、存储和推断未结构化数据的技术。然而，我们不会深入探讨未结构化数据的建模技术，因为这主要属于数据科学，并且与物联网实践者的日常生活不太相关。
- en: Summary
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about different data modeling techniques, data
    storage, and data integration patterns that are common with IoT edge workloads.
    You learned how to build, test, and deploy edge components on Greengrass. Additionally,
    you implemented a lambda architecture to collect, process, and stream data from
    disparate sources on the edge. Finally, you validated the workflow by visualizing
    the incoming data on IoT Core.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了与物联网边缘工作负载常见的数据建模技术、数据存储和数据集成模式。你学习了如何在Greengrass上构建、测试和部署边缘组件。此外，你实现了一个lambda架构来收集、处理和从边缘的不同来源流式传输数据。最后，你通过可视化物联网核心上的传入数据来验证了工作流程。
- en: In the next chapter, you will learn how all this data can be served on the cloud
    to generate valuable insights for different end consumers.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何将所有这些数据在云上提供服务，以生成不同终端用户的有价值见解。
- en: Knowledge check
  id: totrans-406
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识检查
- en: 'Before moving on to the next chapter, test your knowledge by answering these
    questions. The answers can be found at the end of the book:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入下一章之前，通过回答以下问题来测试你的知识。答案可以在书的末尾找到：
- en: 'True or false: Data modeling is only applicable for relational databases.'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正误判断：数据建模仅适用于关系型数据库。
- en: What is the benefit of performing a data modeling exercise?
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行数据建模练习的好处是什么？
- en: 'Is there any relevance of ETL architectures for edge computing? (Hint: Think
    lambda.)'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ETL架构对于边缘计算有什么相关性？（提示：考虑lambda。）
- en: 'True or false: Lambda architecture is the same as AWS lambda service.'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正误判断：Lambda架构与AWS Lambda服务相同。
- en: Can you think of at least one benefit of data processing at the edge?
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能想到至少一个在边缘进行数据处理的好处吗？
- en: Which component of Greengrass is required to be run at the bare minimum for
    the device to be functional?
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Greengrass的哪个组件是必需的，以便设备能够正常运行？
- en: 'True or false: Managing streams for real-time processing is a cloud-only thing.'
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正误判断：管理实时处理的流仅适用于云。
- en: What strategy could you implement to persist data on the edge locally for a
    longer time?
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以实施什么策略来在边缘本地持久化数据，以延长其存储时间？
- en: References
  id: totrans-416
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Take a look at the following resources for additional information on the concepts
    discussed in this chapter:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下资源，以获取本章讨论的概念的更多信息：
- en: '*Data Management Body of Knowledge*: [https://www.dama.org/cpages/body-of-knowledge](https://www.dama.org/cpages/body-of-knowledge)'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据管理知识体系*：[https://www.dama.org/cpages/body-of-knowledge](https://www.dama.org/cpages/body-of-knowledge)'
- en: '*Amazon''s Dynamo*: [https://www.allthingsdistributed.com/2007/10/amazons_dynamo.html](https://www.allthingsdistributed.com/2007/10/amazons_dynamo.html)'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*亚马逊的Dynamo*：[https://www.allthingsdistributed.com/2007/10/amazons_dynamo.html](https://www.allthingsdistributed.com/2007/10/amazons_dynamo.html)'
- en: '*NoSQL Design for DynamoDB*: [https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-general-nosql-design.html](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-general-nosql-design.html)'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DynamoDB的NoSQL设计*：[https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-general-nosql-design.html](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-general-nosql-design.html)'
- en: '*Lambda Architecture*: [http://lambda-architecture.net/](http://lambda-architecture.net/)'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Lambda 架构*：[http://lambda-architecture.net/](http://lambda-architecture.net/)'
- en: '*Managing data streams on the AWS IoT Greengrass Core*: [https://docs.aws.amazon.com/greengrass/v2/developerguide/manage-data-streams.html](https://docs.aws.amazon.com/greengrass/v2/developerguide/manage-data-streams.html)'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在AWS IoT Greengrass Core上管理数据流*: [https://docs.aws.amazon.com/greengrass/v2/developerguide/manage-data-streams.html](https://docs.aws.amazon.com/greengrass/v2/developerguide/manage-data-streams.html)'
- en: '*Data Lake on AWS*: [https://aws.amazon.com/solutions/implementations/data-lake-solution/](https://aws.amazon.com/solutions/implementations/data-lake-solution/)'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AWS上的数据湖*: [https://aws.amazon.com/solutions/implementations/data-lake-solution/](https://aws.amazon.com/solutions/implementations/data-lake-solution/)'
