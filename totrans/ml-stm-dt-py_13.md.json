["```py\nimport numpy as np\ndata = np.random.randint(0, 100, size=1000)\n```", "```py\nimport matplotlib.pyplot as plt\nplt.hist(data)\n```", "```py\n!pip install river\nfrom river import preprocessing\n# convert the data to required format\ndata_stream = [{'x':float(x)} for x in list(data)]\n# initialize list for scaled values\ndata_scaled = []\n# initialize scaler\nmy_scaler = preprocessing.MinMaxScaler()\n# streaming\nfor observation in data_stream:\n  # learn (update)\n  my_scaler.learn_one(observation)\n  # scale the observation\n  scaled_obs = my_scaler.transform_one(observation)\n\n  # store the scaled result\n  data_scaled.append(scaled_obs['x'])\n```", "```py\nimport matplotlib.pyplot as plt\nplt.hist(data_scaled)\n```", "```py\nimport numpy as np\ndata = np.random.normal(12, 15, size=1000)\n```", "```py\nimport matplotlib.pyplot as plt\nplt.hist(data)\n```", "```py\nfrom river import preprocessing\n# convert the data to required format\ndata_stream = [{'x':float(x)} for x in list(data)]\n# initialize list for scaled values\ndata_scaled = []\n# initialize scaler\nmy_scaler = preprocessing.StandardScaler()\n# streaming\nfor observation in data_stream:\n  # learn (update)\n  my_scaler.learn_one(observation)\n  # scale the observation\n  scaled_obs = my_scaler.transform_one(observation)\n\n  # store the scaled result\n  data_scaled.append(scaled_obs['x'])\n```", "```py\nplt.hist(data_scaled)\n```", "```py\nimport numpy as np\nimport pandas as pd\nX1 = np.random.normal(5, 1, size=100)\nX2 = np.random.normal(5, 0.5, size=100)\ndata = pd.DataFrame({'X1': X1, 'X2': X1 + X2})\ndata.head()\n```", "```py\nimport matplotlib.pyplot as plt\nplt.scatter(data['X1'], data['X2'])\n```", "```py\nfrom sklearn.decomposition import PCA\nmy_pca = PCA()\ntransformed_data = my_pca.fit_transform(data)\ntransformed_data = pd.DataFrame(transformed_data, columns = ['PC1', 'PC2'])\ntransformed_data.head()\n```", "```py\nplt.scatter(transformed_data['PC1'], transformed_data['PC2'])\nplt.xlim(-4, 4)\nplt.ylim(-4, 4)\nplt.show()\n```", "```py\nfrom sklearn.decomposition import IncrementalPCA\n```", "```py\nmy_incremental_pca = IncrementalPCA(batch_size = 10)\n```", "```py\ntransformed_data_2 = my_incremental_pca.fit_transform(data)\n```", "```py\ntransformed_data_2 = pd.DataFrame(transformed_data_2, columns = ['PC1', 'PC2'])\n```", "```py\ntransformed_data_2.head()\n```", "```py\nplt.scatter(transformed_data_2['PC1'], transformed_data_2['PC2'])\n```", "```py\nplt.xlim(-4, 4)\n```", "```py\nplt.ylim(-4, 4)\n```", "```py\nplt.show()\n```"]