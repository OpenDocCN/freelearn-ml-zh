- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Forecasting Numeric Data – Regression Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mathematical relationships help us to make sense of many aspects of everyday
    life. For example, body weight is a function of one’s calorie intake; income is
    often related to education and job experience; and poll numbers help to estimate
    a presidential candidate’s odds of being re-elected.
  prefs: []
  type: TYPE_NORMAL
- en: When such patterns are formulated with numbers, we gain additional clarity.
    For example, an additional 250 kilocalories consumed daily may result in nearly
    a kilogram of weight gain per month; each year of job experience may be worth
    an additional $1,000 in yearly salary; and a president is more likely to be re-elected
    when the economy is strong. Obviously, these equations do not perfectly fit every
    situation, but we expect that they are reasonably correct most of the time.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter extends our machine learning toolkit by going beyond the classification
    methods covered previously and introducing techniques for estimating relationships
    within numeric data. While examining several real-world numeric prediction tasks,
    you will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: The basic statistical principles used in regression, a technique that models
    the size and strength of numeric relationships
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to prepare data for regression analysis, estimate and interpret regression
    models, and apply regression variants such as generalized linear models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A pair of hybrid techniques known as regression trees and model trees, which
    adapt decision tree classifiers for numeric prediction tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on a large body of work in the field of statistics, the methods used in
    this chapter are a bit heavier on math than those covered previously, but don’t
    worry! Even if your algebra skills are a bit rusty, R takes care of the heavy
    lifting.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regression involves specifying the relationship between a single numeric **dependent
    variable** (the value to be predicted) and one or more numeric **independent variables**
    (the predictors). As the name implies, the dependent variable depends upon the
    value of the independent variable or variables. The simplest forms of regression
    assume that the relationship between the independent and dependent variables follows
    a straight line.
  prefs: []
  type: TYPE_NORMAL
- en: The origin of the term “regression” to describe the process of fitting lines
    to data is rooted in a study of genetics by Sir Francis Galton in the late 19th
    century. He discovered that fathers who were extremely short or tall tended to
    have sons whose heights were closer to the average height. He called this phenomenon
    “regression to the mean.”
  prefs: []
  type: TYPE_NORMAL
- en: You might recall from basic algebra that lines can be defined in a **slope-intercept
    form** similar to *y* = *a* + *bx*. In this form, the letter *y* indicates the
    dependent variable and *x* indicates the independent variable. The **slope** term
    *b* specifies how much the line rises for each increase in *x*. Positive values
    define lines that slope upward while negative values define lines that slope downward.
    The term *a* is known as the **intercept** because it specifies the point where
    the line crosses, or intercepts, the vertical *y* axis. It indicates the value
    of *y* when *x* = 0.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.1: Examples of lines with various slopes and intercepts'
  prefs: []
  type: TYPE_NORMAL
- en: Regression equations model data using a similar slope-intercept format. The
    machine’s job is to identify values of *a* and *b* such that the specified line
    is best able to relate the supplied *x* values to the values of *y*.
  prefs: []
  type: TYPE_NORMAL
- en: There may not always be a single set of *a* and *b* parameters that perfectly
    relates the values, so the machine must also have some way to quantify the margin
    of error and choose the best fit. We’ll discuss this in depth shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regression analysis is used for a huge variety of tasks—it is almost surely
    the most widely used machine learning method. It can be used both for explaining
    the past and extrapolating into the future and can be applied to nearly any task.
    Some specific use cases include:'
  prefs: []
  type: TYPE_NORMAL
- en: Examining how populations and individuals vary by their measured characteristics,
    in scientific studies in the fields of economics, sociology, psychology, physics,
    and ecology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantifying the causal relationship between an event and its response, in cases
    such as clinical drug trials, engineering safety tests, or market research
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying patterns that can be used to forecast future behavior given known
    criteria, such as for predicting insurance claims, natural disaster damage, election
    results, and crime rates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression methods are also used for **statistical hypothesis testing**, which
    determines whether a premise is likely to be true or false in light of observed
    data. The regression model’s estimates of the strength and consistency of a relationship
    provide information that can be used to assess whether the observations are due
    to chance alone.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis testing is extremely nuanced and falls outside the scope of machine
    learning. If you are interested in this topic, an introductory statistics textbook
    is a good place to get started, for instance, *Intuitive Introductory Statistics,
    Wolfe, D. A. and Schneider, G., Springer, 2017*.
  prefs: []
  type: TYPE_NORMAL
- en: Regression analysis is not synonymous with a single algorithm. Rather, it is
    an umbrella term for many methods, which can be adapted to nearly any machine
    learning task. If you were limited to choosing only a single machine learning
    method to study, regression would be a good choice. One could devote an entire
    career to nothing else and perhaps still have much to learn.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll start with the most basic **linear regression** models—those
    that use straight lines. The case when there is only a single independent variable
    is known as **simple linear regression**. In the case of two or more independent
    variables, it is known as **multiple linear regression**, or simply **multiple
    regression**. Both techniques assume a single dependent variable, which is measured
    on a continuous scale.
  prefs: []
  type: TYPE_NORMAL
- en: Regression can also be used for other types of dependent variables and even
    for some classification tasks. For instance, **logistic regression** is used to
    model a binary categorical outcome, while **Poisson regression**—named after the
    French mathematician Siméon Poisson—models integer count data. The method known
    as **multinomial logistic regression** models a categorical outcome and can therefore
    be used for classification.
  prefs: []
  type: TYPE_NORMAL
- en: These specialized regression methods fall into the class of **generalized linear
    models** (**GLMs**), which adapt the straight lines of traditional regression
    models to allow the modeling of other forms of data. These will be described later
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Because similar statistical principles apply across all regression methods,
    once you understand the linear case, learning about the other variants is straightforward.
    We’ll begin with the basic case of simple linear regression. Despite the name,
    this method is not too simple to address complex problems. In the next section,
    we’ll see how the use of a simple linear regression model might have averted a
    tragic engineering disaster.
  prefs: []
  type: TYPE_NORMAL
- en: Simple linear regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On January 28th, 1986, seven crew members of the United States space shuttle
    *Challenger* were killed when a rocket booster failed, causing a catastrophic
    disintegration. In the aftermath, experts quickly focused on the launch temperature
    as a potential culprit. The rubber O-rings responsible for sealing the rocket
    joints had never been tested below 40![](img/B17290_06_001.png)F (4![](img/B17290_06_001.png)C),
    and the weather on launch day was unusually cold and below freezing.
  prefs: []
  type: TYPE_NORMAL
- en: With the benefit of hindsight, the accident has been a case study for the importance
    of data analysis and visualization. Although it is unclear what information was
    available to the rocket engineers and decision-makers leading up to the launch,
    it is undeniable that better data, utilized carefully, might very well have averted
    this disaster.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section’s analysis is based on data presented in *Risk Analysis of the
    Space Shuttle: Pre-Challenger Prediction of Failure, Dalal, S. R., Fowlkes, E.
    B., and Hoadley, B., Journal of the American Statistical Association, 1989, Vol.
    84, pp. 945-957*. For one perspective on how data may have changed the result,
    see *Visual Explanations: Images And Quantities, Evidence And Narrative, Tufte,
    E. R., Cheshire, C. T.: Graphics Press, 1997*. For a counterpoint, see *Representation
    and misrepresentation: Tufte and the Morton Thiokol engineers on the Challenger,
    Robison, W., Boisjoly, R., Hoeker, D., and Young, S., Science and Engineering
    Ethics, 2002, Vol. 8, pp. 59-81*.'
  prefs: []
  type: TYPE_NORMAL
- en: The rocket engineers almost certainly knew that cold temperatures could make
    the components more brittle and less able to seal properly, which would result
    in a higher chance of a dangerous fuel leak. However, given the political pressure
    to continue with the launch, they needed data to support this hypothesis. A regression
    model that demonstrated a link between temperature and O-ring failures, and could
    forecast the chance of failure given the expected temperature at launch, might
    have been very helpful.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the regression model, the scientists might have used the data on launch
    temperature and component distress recorded during the 23 previous successful
    shuttle launches. Component distress indicates one of two types of problems. The
    first problem, called erosion, occurs when excessive heat burns up the O-ring.
    The second problem, called blow-by, occurs when hot gasses leak through or “blow
    by” a poorly sealed O-ring. Since the shuttle had a total of six primary O-rings,
    up to six distresses could occur per flight. Though the rocket could survive one
    or more distress events or be destroyed with as few as one, each additional distress
    increased the probability of a catastrophic failure. The following scatterplot
    shows a plot of primary O-ring distresses detected for the previous 23 launches,
    as compared to the temperature at launch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart  Description automatically generated](img/B17290_06_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.2: A visualization of space shuttle O-ring distresses versus launch
    temperature'
  prefs: []
  type: TYPE_NORMAL
- en: 'Examining the plot, there is an apparent trend: launches occurring at higher
    temperatures tend to have fewer O-ring distress events. Additionally, the coldest
    launch (53![](img/B17290_06_001.png)F) had two distress events, a level that had
    only been reached in one other launch. With this information in mind, the fact
    that the Challenger was scheduled to launch in conditions more than 20 degrees
    colder seems concerning. But exactly how concerned should they have been? To answer
    this question, we can turn to simple linear regression.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple linear regression model defines the relationship between a dependent
    variable and a single independent predictor variable using a line defined by an
    equation in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_004.png)'
  prefs: []
  type: TYPE_IMG
- en: Aside from the Greek characters, this equation is virtually identical to the
    slope-intercept form described previously. The intercept, ![](img/B17290_06_005.png)
    (alpha), describes where the line crosses the *y* axis, while the slope, ![](img/B17290_06_006.png)
    (beta), describes the change in *y* given an increase of *x*. For the shuttle
    launch data, the slope would tell us the expected change in O-ring failures for
    each degree the launch temperature increases.
  prefs: []
  type: TYPE_NORMAL
- en: Greek characters are often used in the field of statistics to indicate variables
    that are parameters of a statistical function. Therefore, performing a regression
    analysis involves finding **parameter estimates** for ![](img/B17290_06_007.png)
    and ![](img/B17290_06_008.png). The parameter estimates for alpha and beta are
    typically denoted using *a* and *b*, although you may find that some of this terminology
    and notation is used interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we know that the estimated regression parameters in the equation for
    the shuttle launch data are *a* = 3.70 and *b* = -0.048\. Consequently, the full
    linear equation is *y* = 3.70 – 0.048x. Ignoring for a moment how these numbers
    were obtained, we can plot the line on the scatterplot like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart, scatter chart  Description automatically generated](img/B17290_06_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.3: A regression line modeling the relationship between distress events
    and launch temperature'
  prefs: []
  type: TYPE_NORMAL
- en: As the line shows, at 60 degrees Fahrenheit, we predict less than one O-ring
    distress event. At 50 degrees Fahrenheit, we expect around 1.3 failures. If we
    use the model to extrapolate all the way out to 31 degrees—the forecasted temperature
    for the Challenger launch—we would expect about *3.70 - 0.048 * 31 = 2.21* O-ring
    distress events.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming that each O-ring failure is equally likely to cause a catastrophic
    fuel leak, this means that the Challenger launch at 31 degrees was nearly three
    times riskier than the typical launch at 60 degrees, and over eight times riskier
    than a launch at 70 degrees.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the line doesn’t pass through each data point exactly. Instead,
    it cuts through the data somewhat evenly, with some predictions lower or higher
    than the line. In the next section, we will learn why this particular line was
    chosen.
  prefs: []
  type: TYPE_NORMAL
- en: Ordinary least squares estimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To determine the optimal estimates of ![](img/B17290_06_005.png) and ![](img/B17290_06_006.png)
    an estimation method known as **ordinary least squares** (**OLS**) is used. In
    OLS regression, the slope and intercept are chosen such that they minimize the
    **sum of the squared errors** (**SSE**). The errors, also known as **residuals**,
    are the vertical distance between the predicted *y* value and the actual *y* value.
    Because the errors can be over-estimates or under-estimates, they can be positive
    or negative values; squaring them makes the errors positive regardless of direction.
    The residuals are illustrated for several points in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart  Description automatically generated](img/B17290_06_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.4: The regression line predictions differ from the actual values by
    a residual amount'
  prefs: []
  type: TYPE_NORMAL
- en: 'In mathematical terms, the goal of OLS regression can be expressed as the task
    of minimizing the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_011.png)'
  prefs: []
  type: TYPE_IMG
- en: In plain language, this equation defines *e* (the error) as the difference between
    the actual *y* value and the predicted *y* value. The error values are squared
    to eliminate the negative values and summed across all points in the data.
  prefs: []
  type: TYPE_NORMAL
- en: The caret character (^) above the *y* term is a commonly used feature of statistical
    notation. It indicates that the term is an estimate for the true *y* value. This
    is referred to as the *y hat*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution for *a* depends on the value of *b*. It can be obtained using
    the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_012.png)'
  prefs: []
  type: TYPE_IMG
- en: To understand these equations, you’ll need to know another bit of statistical
    notation. The horizontal bar appearing over the *x* and *y* terms indicates the
    mean value of *x* or *y*. This is referred to as the *x* bar or *y* bar.
  prefs: []
  type: TYPE_NORMAL
- en: 'Though the proof is beyond the scope of this book, it can be shown using calculus
    that the value of *b* that results in the minimum squared error is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_013.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we break this equation apart into its component pieces, we can simplify
    it somewhat. The denominator for *b* should look familiar; it is very similar
    to the variance of *x*, which is denoted as Var(*x*). As we learned in *Chapter
    2*, *Managing and Understanding Data*, the variance involves finding the average
    squared deviation from the mean of *x*. This can be expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_014.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The numerator involves taking the sum of each data point’s deviation from the
    mean *x* value multiplied by that point’s deviation away from the mean *y* value.
    This is similar to the covariance function for *x* and *y*, denoted as Cov(*x*,
    *y*). The covariance formula is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_015.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we divide the covariance function by the variance function, the *n* terms
    in the numerator and denominator cancel each other out and we can rewrite the
    formula for *b* as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_016.png)'
  prefs: []
  type: TYPE_IMG
- en: Given this restatement, it is easy to calculate the value of *b* using built-in
    R functions. Let’s apply them to the shuttle launch data to estimate the regression
    line.
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to follow along with these examples, download the `challenger.csv`
    file from the Packt Publishing website and load it to a data frame using the `launch
    <- read.csv("challenger.csv")` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the shuttle launch data is stored in a data frame named `launch`, the independent
    variable *x* is named `temperature`, and the dependent variable *y* is named `distress_ct`,
    we can then use the R functions `cov()` and `var()` to estimate `b`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then estimate `a` by using the computed `b` value and applying the `mean()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Estimating the regression equation by hand is obviously less than ideal, so
    R predictably provides a function for fitting regression models automatically.
    We will use this function shortly. Before that, it is important to expand your
    understanding of the regression model’s fit by first learning a method for measuring
    the strength of a linear relationship. Additionally, you will soon learn how to
    apply multiple linear regression to problems with more than one independent variable.
  prefs: []
  type: TYPE_NORMAL
- en: Correlations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **correlation** between two variables is a number that indicates how closely
    their relationship follows a straight line. Without additional qualification,
    correlation typically refers to the **Pearson correlation coefficient**, which
    was developed by the 20th-century mathematician Karl Pearson. A correlation falls
    in the range between -1 to +1\. The maximum and minimum values indicate a perfectly
    linear relationship, while a correlation close to zero indicates the absence of
    a linear relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following formula defines Pearson’s correlation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_017.png)'
  prefs: []
  type: TYPE_IMG
- en: 'More Greek notation has been introduced here: the first symbol (which looks
    like a lowercase *p*) is *rho*, and it is used to denote the Pearson correlation
    statistic. The symbols that look like *q* characters rotated counterclockwise
    are the lowercase Greek letter *sigma*, and they indicate the standard deviation
    of *x* or *y*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using this formula, we can calculate the correlation between the launch temperature
    and the number of O-ring distress events. Recall that the covariance function
    is `cov()` and the standard deviation function is `sd()`. We’ll store the result
    in `r`, a letter that is commonly used to indicate the estimated correlation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can obtain the same result with the `cor()` correlation function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The correlation between the temperature and the number of distressed O-rings
    is -0.51\. The negative correlation implies that increases in temperature are
    related to decreases in the number of distressed O-rings. To the NASA engineers
    studying the O-ring data, this would have been a very clear indicator that a low-temperature
    launch could be problematic. The correlation also tells us about the relative
    strength of the relationship between temperature and O-ring distress. Because
    -0.51 is halfway to the maximum negative correlation of -1, this implies that
    there is a moderately strong negative linear association.
  prefs: []
  type: TYPE_NORMAL
- en: There are various rules of thumb used to interpret correlation strength. One
    method assigns a status of “weak” to values between 0.1 and 0.3; “moderate” to
    the range of 0.3 to 0.5; and “strong” to values above 0.5 (these also apply to
    similar ranges of negative correlations). However, these thresholds may be too
    strict or too lax for certain purposes. Often, the correlation must be interpreted
    in context.
  prefs: []
  type: TYPE_NORMAL
- en: For data involving human beings, a correlation of 0.5 may be considered very
    high; for data generated by mechanical processes, a correlation of 0.5 may be
    very weak.
  prefs: []
  type: TYPE_NORMAL
- en: 'You have probably heard the expression “correlation does not imply causation.”
    This is rooted in the fact that a correlation only describes the association between
    a pair of variables, yet there could be other explanations that are unaccounted
    for and responsible for the observed relationship. For example, there may be a
    strong correlation between life expectancy and time per day spent watching movies,
    but before doctors recommend that we all watch more movies, we need to rule out
    another explanation: younger people watch more movies and younger people are (in
    general) less likely to die.'
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the correlation between two variables gives us a way to quickly check
    for linear relationships between independent variables and the dependent variable.
    This will be increasingly important as we start defining regression models with
    a larger number of predictors.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple linear regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Most real-world analyses have more than one independent variable. Therefore,
    it is likely that you will be using multiple linear regression for most numeric
    prediction tasks. The strengths and weaknesses of multiple linear regression are
    shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strengths** | **Weaknesses** |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: By far the most common approach to modeling numeric data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be adapted to model almost any modeling task
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provides estimates of both the size and strength of the relationships among
    features and the outcome
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Makes strong assumptions about the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model’s form must be specified by the user in advance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does not handle missing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Only works with numeric features, so categorical data requires additional preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requires some knowledge of statistics to understand the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: We can understand multiple regression as an extension of simple linear regression.
    The goal in both cases is similar—to find values of slope coefficients that minimize
    the prediction error of a linear equation. The key difference is that there are
    additional terms for the additional independent variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiple regression models take the form of the following equation. The dependent
    variable *y* is specified as the sum of an intercept term ![](img/B17290_06_005.png)
    plus the product of the estimated ![](img/B17290_06_006.png) value and the *x*
    variable for each of *i* features. An error term ![](img/B17290_06_020.png) (denoted
    by the Greek letter *epsilon*) has been added here as a reminder that the predictions
    are not perfect. This represents the residual term noted previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_021.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s consider for a moment the interpretation of the estimated regression parameters.
    You will note that in the preceding equation, a coefficient is provided for each
    feature. This allows each feature to have a separate estimated effect on the value
    of *y*. In other words, *y* changes by the amount ![](img/B17290_06_022.png) for
    each unit increase in feature ![](img/B17290_06_023.png). The intercept ![](img/B17290_06_005.png)
    is then the expected value of *y* when the independent variables are all zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the intercept term ![](img/B17290_06_005.png) is really no different
    than any other regression parameter, it is also sometimes denoted as ![](img/B17290_06_024.png)
    (pronounced *beta naught*) as shown in the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_025.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Just like before, the intercept is unrelated to any of the independent *x*
    variables. However, for reasons that will become clear shortly, it helps to imagine
    ![](img/B17290_06_024.png) as if it were being multiplied by a term *x*[0]. We
    assign *x*[0] to be a constant with the value of 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_027.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To estimate the regression parameters, each observed value of the dependent
    variable *y* must be related to observed values of the independent *x* variables
    using the regression equation in the previous form. The following figure is a
    graphical representation of the setup of a multiple regression task:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_06_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.5: Multiple regression seeks to find the ![](img/B17290_06_006.png)
    values that relate the X values to Y while minimizing ![](img/B17290_06_020.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The many rows and columns of data illustrated in the preceding figure can be
    described in a condensed formulation using **matrix notation** in bold font to
    indicate that each of the terms represents multiple values. Simplified in this
    way, the formula is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_030.png)'
  prefs: []
  type: TYPE_IMG
- en: In matrix notation, the dependent variable is a vector, **Y**, with a row for
    every example. The independent variables have been combined into a matrix, **X**,
    with a column for each feature plus an additional column of 1 values for the intercept.
    Each column has a row for every example. The regression coefficients ![](img/B17290_06_031.png)
    and residual errors **![](img/_eqn_032.png)** are also now vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal now is to solve for ![](img/B17290_06_031.png), the vector of regression
    coefficients that minimizes the sum of the squared errors between the predicted
    and actual **Y** values. Finding the optimal solution requires the use of matrix
    algebra; therefore, the derivation deserves more careful attention than can be
    provided in this text. However, if you’re willing to trust the work of others,
    the best estimate of the vector ![](img/B17290_06_031.png) can be computed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_034.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This solution uses a pair of matrix operations: the **T** indicates the transpose
    of matrix **X**, while the negative exponent indicates the **matrix inverse**.
    Using R’s built-in matrix operations, we can thus implement a simple multiple
    regression learner. Let’s apply this formula to the Challenger launch data.'
  prefs: []
  type: TYPE_NORMAL
- en: If you are unfamiliar with the preceding matrix operations, the Wolfram MathWorld
    pages for transpose ([http://mathworld.wolfram.com/Transpose.html](http://mathworld.wolfram.com/Transpose.html))
    and matrix inverse ([http://mathworld.wolfram.com/MatrixInverse.html](http://mathworld.wolfram.com/MatrixInverse.html))
    provide a thorough introduction and are understandable even without an advanced
    mathematics background.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the following code, we can create a basic regression function named `reg()`,
    which takes a parameter `y` and a parameter `x`, and returns a vector of estimated
    beta coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `reg()` function created here uses several R commands that we have not used
    previously. First, since we will be using the function with sets of columns from
    a data frame, the `as.matrix()` function converts the data frame into matrix form.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, the `cbind()` function binds an additional column onto the `x` matrix;
    the command `Intercept = 1` instructs R to name the new column `Intercept` and
    to fill the column with repeating `1` values. Then, a series of matrix operations
    are performed on the `x` and `y` objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '`solve()` takes the inverse of a matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`t()` is used to transpose a matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`%*%` multiplies two matrices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By combining these R functions as shown, our function will return a vector `b`,
    which contains estimated parameters for the linear model relating `x` to `y`.
    The final two lines in the function give the `b` vector a name and print the result
    on screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s apply this function to the shuttle launch data. As shown in the following
    code, the dataset includes three features and the distress count (`distress_ct`),
    which is the outcome of interest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can confirm that our function is working correctly by comparing its result
    for the simple linear regression model of O-ring failures versus temperature,
    which we found earlier to have parameters *a* = 3.70 and *b* = -0.048\. Since
    temperature is in the second column of the launch data, we can run the `reg()`
    function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'These values exactly match our prior result, so let’s use the function to build
    a multiple regression model. We’ll apply it just as before, but this time we will
    specify columns two through four for the `x` parameter to add two additional predictors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This model predicts the number of O-ring distress events using temperature,
    field check pressure, and the launch ID number. Notably, the inclusion of the
    two new predictors did not change our finding from the simple linear regression
    model. Just as before, the coefficient for the temperature variable is negative,
    which suggests that as temperature increases, the number of expected O-ring events
    decreases. The magnitude of the effect is also approximately the same: roughly
    0.05 fewer distress events are expected for each degree increase in launch temperature.'
  prefs: []
  type: TYPE_NORMAL
- en: The two new predictors also contribute to the predicted distress events. The
    field check pressure refers to the amount of pressure applied to the O-ring during
    pre-launch testing. Although the check pressure was originally 50 psi, it was
    raised to 100 and 200 psi for some launches, which led some to believe that it
    may be responsible for O-ring erosion. The coefficient is positive, but small,
    providing at least a little evidence for this hypothesis. The flight number accounts
    for the shuttle’s age. With each flight, it gets older, and parts may be more
    brittle or prone to fail. The small positive association between flight number
    and distress count may reflect this fact.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, our retrospective analysis of the space shuttle data suggests that
    there was reason to believe that the Challenger launch was highly risky given
    the weather conditions. Perhaps if the engineers had applied linear regression
    beforehand, a disaster could have been averted. Of course, the reality of the
    situation, and the political implications involved, were surely not as simple
    then as they now appear in hindsight.
  prefs: []
  type: TYPE_NORMAL
- en: Generalized linear models and logistic regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As demonstrated in the analysis of the Challenger space shuttle launch data,
    standard linear regression is a useful method for modeling the relationship between
    a numeric outcome and one or more predictors. It is no wonder that regression
    has stood the test of time. Even after over a hundred years, it remains one of
    the most important techniques in our toolkit, even though it is no more sophisticated
    than finding the best straight line to fit the data.
  prefs: []
  type: TYPE_NORMAL
- en: However, not every problem is well suited to being modeled by a line, and moreover,
    the statistical assumptions made by regression models are violated in many real-world
    tasks. Even the Challenger data is less than ideal for linear regression as it
    violates the regression assumption that the target variable is measured on a continuous
    scale. As the number of O-ring failures can only take countable values, it makes
    no sense that the model might predict exactly 2.21 distress events rather than
    either two or three.
  prefs: []
  type: TYPE_NORMAL
- en: For modeling counting values, for categorical or binary outcomes, as well as
    other cases where the target is not a normally distributed continuous variable,
    standard linear regression is not the best tool for the job—even though many still
    apply it to these types of problems, and it often performs surprisingly well.
  prefs: []
  type: TYPE_NORMAL
- en: To address these shortcomings, linear regression can be adapted to other use
    cases using the aptly named GLM, which was first described in 1972 by statisticians
    John Nelder and Robert Wedderburn. The GLM loosens two assumptions of traditional
    regression modeling. First, it allows the target to be a non-normally distributed,
    non-continuous variable. Second, it allows the variance of the target variable
    to be related to its mean. The former property opens the door for modeling categorical
    data or counting data, or even cases where there is a limited range of values
    to predict, such as probability values falling on a range between 0 to 1\. The
    latter property allows the model to better fit cases where the predictors relate
    to the predictions in a nonlinear way, such as exponential growth in which an
    increase of one unit of time leads to greater and greater increases in the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: To read the original publication about GLMs, see *Generalized linear models,
    Nelder, J. A. and Wedderburn, T. W. M., Journal of the Royal Statistical Society,
    1972, Vol. 135, pp. 370-384*. For a gentler, non-mathematical introduction, see
    *An introduction to generalized linear models, Dunteman, G. H. and Ho, M. H. R.,
    Quantitative Applications in the Social Sciences, 2006, Vol. 145*.
  prefs: []
  type: TYPE_NORMAL
- en: 'These two generalizations of linear regression are reflected in the two key
    components of any GLM:'
  prefs: []
  type: TYPE_NORMAL
- en: The **family** refers to the distribution of the target feature, which must
    be chosen from members of the **exponential family** of distributions, which includes
    the normal Gaussian distribution as well as others like Poisson, Binomial, and
    Gamma. The chosen distribution may be discrete or continuous, and it may span
    different ranges of values, such as only positive values or only values between
    zero and one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **link function** transforms the relationship between the predictors and
    the target such that it can be modeled using a linear equation, despite the original
    relationship being nonlinear. There is always a **canonical link function**, which
    is determined by the chosen family and used by default, but in some cases, one
    may choose a different link to vary how the model is interpreted or to obtain
    a better model fit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Varying the family and link functions gives the GLM approach tremendous flexibility
    to adapt to many different real-world use cases and to conform to the natural
    distribution of the target variable. Knowing which combination to use depends
    on both how the model will be applied as well as the theoretical distribution
    of the target. Understanding these factors in detail requires knowledge of the
    various distributions in the exponential family and a background in statistical
    theory. Thankfully, most GLM use cases conform to a few common combinations of
    family and link, which are listed in the table that follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Family** | **Canonical Link Function** | **Target Range** | **Notes and
    Applications** |'
  prefs: []
  type: TYPE_TB
- en: '| Gaussian (normal) | Identity | -![](img/B17290_06_036.png) to ![](img/B17290_06_036.png)
    | Used for linear response modeling; reduces the GLM to standard linear regression.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Poisson | Log | Integers 0 to ![](img/B17290_06_036.png) | Known as Poisson
    regression; models the count of an event occurring (such as the total number of
    O-ring failures) by estimating the frequency at which the event happens. |'
  prefs: []
  type: TYPE_TB
- en: '| Binomial | Logit | 0 to 1 | Known as logistic regression; used for modeling
    a binary outcome (such as whether any O-ring failed) by estimating the probability
    that the outcome occurs. |'
  prefs: []
  type: TYPE_TB
- en: '| Gamma | Negative Inverse | 0 to ![](img/B17290_06_036.png) | One of many
    possibilities for modeling right-skewed data; could be used for modeling the time
    to an event (such as seconds to an O-ring failure) or cost data (such as insurance
    claims costs for a car accident). |'
  prefs: []
  type: TYPE_TB
- en: '| Multinomial | Logit | 1 of *K* categories | Known as multinomial logistic
    regression; used for modeling a categorical outcome (such as a successful, unsuccessful,
    or aborted shuttle launch) by estimating the probability the example falls into
    each of the categories. Generally uses specialized packages rather than a GLM
    function to aid interpretation. |'
  prefs: []
  type: TYPE_TB
- en: Due to the nuances of interpreting GLMs, it takes much practice and careful
    study to be adept at applying just one, and few people can claim to be experts
    at using all of them. Entire textbooks are devoted to each GLM variant. Fortunately,
    in the domain of machine learning, interpreting and understanding are less important
    than being able to apply the correct GLM form to practical problems and produce
    useful predictions. While this chapter cannot cover each of the listed methods,
    an introduction to the key details will allow you to later pursue the GLM variants
    most relevant to your own work.
  prefs: []
  type: TYPE_NORMAL
- en: Beginning with the simplest variant listed in the table, standard linear regression
    can be thought of as a special type of GLM that uses the Gaussian family and the
    identity link function. The **identity link** implies that the relationship between
    the target *y* and a predictor *x*[i] is not transformed in any way. Thus, as
    with standard regression, an estimated regression parameter ![](img/B17290_06_022.png)
    can be interpreted quite simply as the increase in *y* given a one-unit increase
    in *x*[i], assuming all other factors are held equal.
  prefs: []
  type: TYPE_NORMAL
- en: GLM forms that use other link functions are not as simple to interpret and fully
    understanding the impact of individual predictors requires much more careful analysis.
    This is because the regression parameters must be interpreted as the additive
    increase in *y* for a one-unit increase in *x*[i], but only after being transformed
    through the link function.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the Poisson family that uses the **log link** function to model
    the expected count of events relates *y* to the predictors *x*[i] through the
    natural logarithm; consequently, the additive effect of ![](img/B17290_06_040.png)
    on *y* becomes multiplicative on the original scale of the response variable.
    This is because using the properties of logarithms, we know ![](img/B17290_06_041.png),
    and this becomes ![](img/B17290_06_042.png) after exponentiating to remove the
    logarithm.
  prefs: []
  type: TYPE_NORMAL
- en: Due to this multiplicative impact, the parameter estimates are understood as
    relative rates of increase rather than the absolute increase in *y* as with linear
    regression.
  prefs: []
  type: TYPE_NORMAL
- en: To see this in practice, suppose we built a Poisson regression model of the
    count of O-ring failures versus launch temperature. If *x*[1] is temperature and
    the estimated ![](img/B17290_06_043.png) = -0.103, then we can determine that
    there are about 9.8 percent fewer O-ring failures on average per each additional
    degree of temperature at launch. This is because *exp(-0.103) = 0.902*, or 90.2
    percent of the failures per degree, which implies that we would expect 9.8 percent
    fewer failures per degree increase. Applying this to the Challenger shuttle launch
    temperature at 36 degrees Fahrenheit, we can extrapolate that a launch 17 degrees
    warmer (53 degrees Fahrenheit was the previous coldest launch) would have had
    about *(0.902)^17 = 17.2* percent of the expected number of failures, equivalent
    to a drop of 82.8 percent.
  prefs: []
  type: TYPE_NORMAL
- en: The GLM variant that uses a binomial family distribution with a logit link function
    is known as **logistic regression**, and is perhaps the single most important
    form as it allows regression to be adapted to binary classification tasks. The
    **logit link** is a function in the form *log(p / (1 - p))*, where *p* is a probability;
    the inner portion (*p / (1 - p)*) expresses the probability as **odds**, exactly
    like the odds used in gambling and sports betting in phrases like “the team has
    a 2:1 chance of winning.” After taking the natural logarithm, the estimated regression
    coefficients are interpreted as log odds. Because we understand odds more intuitively
    than log odds, we usually exponentiate the estimated logistic regression coefficients
    to convert log odds into odds for interpretation. However, because logistic regression
    coefficients indicate the difference in the odds of *y* due to a one-unit increase
    in *x*, the exponentiated odds become **odds ratios**, which express the relative
    increase or decrease in the chances that *y* happens.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of the space shuttle data, suppose we built a logistic regression
    model for the binary classification task of predicting whether or not a launch
    would have one or more O-ring failures. A factor that does not change the probability
    of an O-ring failure would keep the odds balanced at 1:1 (50-50 probability),
    which translates to log odds of *log(0.5 / (1 - 0.5)) = 0* and the estimated regression
    coefficient ![](img/B17290_06_006.png) = 0 for this feature. Finding the odds
    ratio as *exp(0) = 1* shows that the odds remain unchanged regardless of the value
    of this factor. Now, suppose a factor like temperature reduces the chance that
    the outcome occurs, and that in the logistic regression model with *x*[1] as temperature,
    then the estimated ![](img/B17290_06_043.png) = -0.232\. By exponentiating this,
    we find the odds ratio *exp(-0.232) = 0.793*, which means that the odds of a failure
    drop by about 20 percent for a one-degree increase in temperature, assuming all
    else is held equal. It is very important to note that this does not imply that
    the *probability* of a failure drops by 20 percent for each degree increase.
  prefs: []
  type: TYPE_NORMAL
- en: Because the relationship between odds and probability is nonlinear, the impact
    of a temperature change on the failure probability depends on the context in which
    the temperature change is occurring!
  prefs: []
  type: TYPE_NORMAL
- en: Odds and probabilities are related via the inverse connection between the logit
    and logistic functions. The logistic function has the convenient property that
    for any input *x* value, the output is a value in the range between 0 to 1—exactly
    the same range as a probability. Additionally, the logistic function creates an
    S-shaped curve when graphed, as illustrated in *Figure 6.6*, which shows a hypothetical
    logistic regression model of O-ring failure probability versus launch temperature.
    The probability of failure on the *y* axis is changed most strongly in the middle
    of the temperature range; at temperature extremes, the predicted failure probability
    changes very little for each additional degree of temperature added or removed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart  Description automatically generated](img/B17290_06_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.6: Hypothetical logistic regression curve representing space shuttle
    launch data'
  prefs: []
  type: TYPE_NORMAL
- en: The fitted logistic regression model creates a curve representing a probability
    estimation on a continuous scale anywhere in the range between 0 to 1, despite
    the target outcome (represented by circles in the figure) only taking the value
    *y* = 0 or *y* = 1\. To obtain the binary prediction, simply define the probability
    threshold within which the target outcome is to be predicted. For example, if
    the predicted probability of an O-ring failure is greater than 0.50, then predict
    “failure,” and otherwise, predict “no failure.” Using a 50 percent threshold is
    common, but a higher or lower threshold can be used to adjust the cost sensitivity
    of the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Examining the logistic curve in *Figure 6.6* leads to another question: how
    does the modeling algorithm determine the curve that best fits the data? After
    all, given that this is not a straight line, the OLS algorithm used in standard
    linear regression no longer seems to apply.'
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, generalized linear models use a different technique called **maximum
    likelihood estimation** (**MLE**), which finds the parameter values for the specified
    distribution that are most likely to have generated the observed data.
  prefs: []
  type: TYPE_NORMAL
- en: Because OLS estimation is a special case of maximum likelihood estimation, using
    OLS or MLE for a linear model makes no difference given that the assumptions of
    OLS modeling are met. For applications outside of linear modeling, the MLE technique
    will produce different results and must be used instead of OLS. The MLE technique
    is built into GLM modeling software, and usually applies analytical techniques
    to identify the optimal model parameters by iterating repeatedly over the data
    rather than finding the correct solution directly. Fortunately, as we will see
    shortly, building a GLM in R is hardly more challenging than training a simpler
    linear model.
  prefs: []
  type: TYPE_NORMAL
- en: This introduction only scratched the surface of what is possible with linear
    regression and GLM. Although theory and simple examples like the Challenger dataset
    are helpful for understanding how regression models work, there is more involved
    in building a useful model than what we’ve seen so far. R’s built-in regression
    functions include the additional functionality needed to fit more sophisticated
    models while providing additional diagnostic output to aid model interpretation
    and assess the fit. Let’s apply these functions and expand our knowledge of regression
    by attempting a real-world learning task.
  prefs: []
  type: TYPE_NORMAL
- en: Example – predicting auto insurance claims costs using linear regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For an automobile insurance company to make money, it needs to collect more
    in membership premiums than it spends on claims paid to its beneficiaries in case
    of vehicle theft, damages, or loss of life in accidents. Consequently, insurers
    invest time and money to develop models that accurately forecast claims costs
    for the insured population. This is the field known as **actuarial science**,
    which uses sophisticated statistical techniques to estimate risk across insured
    populations.
  prefs: []
  type: TYPE_NORMAL
- en: Insurance expenses are difficult to predict accurately for individuals because
    accidents, and especially fatal accidents, are thankfully relatively rare—a bit
    over one fatality per 100 million vehicle miles traveled in the United States—yet,
    when they do happen, they are extremely costly. Moreover, the specific conditions
    leading to any given accident are based on factors that are so hard to measure
    that they appear to be random. An excellent driver with a clean driving record
    could have bad luck and be hit by a drunk driver, while another person can drive
    distracted by their cellular phone and, due to good fortune, never cause an accident.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the near impossibility of predicting expenses for a single person,
    insurance companies apply the law of averages and compute the average cost to
    insure segments of people with similar risk profiles. If the expense estimates
    for each risk segment are correct, the insurance company can price the insurance
    premiums lower for segments with less risk, and potentially attract new, low-risk
    customers from competing insurance companies. We will simulate this scenario in
    the analysis that follows.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – collecting data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset for this example is a simulation created for this book based on
    demographics and traffic statistics from the United States government. It is intended
    to approximate the real-world conditions of automobile insurance companies in
    the U.S. state of Michigan, which is home to about ten million residents and seven
    million licensed drivers.
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to follow along interactively, download the `autoinsurance.csv`
    file from the Packt Publishing GitHub repository for this book and save it to
    your R working folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'The insurance dataset includes 20,000 examples of beneficiaries enrolled in
    the hypothetical automobile vehicle insurance plan. This is much smaller than
    the typical datasets used by practicing actuaries, especially for very rare outcomes,
    but the size has been reduced to allow analysis even on computers with limited
    memory. Each example represents an insured individual’s characteristics and total
    insurance claims costs (`expenses`) charged to the plan for the calendar year.
    The features available at the time of enrollment are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`age`: The age of the driver, from 16 to 89'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`geo_area`: The geographic area of the vehicle owner’s primary residence, and
    where the vehicle will be used most often; zip codes were bucketed into urban,
    suburban, and rural categories'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`est_value`: The estimated market value of the vehicle(s), based on age and
    depreciation; capped at $125,000—the maximum allowed insured value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vehicle_type`: The type of passenger vehicle, either a car, truck, minivan,
    or sport utility vehicle (SUV)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`miles_driven`: The distance driven (in miles) in the calendar year'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`college_grad_ind`: A binary indicator set to `1` if the beneficiary has a
    college education or higher'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`speeding_ticket_ind`: A binary indicator set to `1` if a speeding ticket or
    infraction was received during the past five years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clean_driving_ind`: A binary indicator set to `1` if no at-fault insurance
    claims were paid during the past five years'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this example scenario, each of the 20,000 beneficiaries enrolled in a “safe
    driving discount” program, which required the use of a device or mobile phone
    application that uses location tracking to monitor safe driving conditions throughout
    the year. This helped validate the accuracy of `miles_driven` and created the
    following two additional predictors, which are intended to reflect more risky
    driving behaviors:'
  prefs: []
  type: TYPE_NORMAL
- en: '`hard_braking_ind`: A binary indicator set to `1` if the vehicle frequently
    applies “hard brakes” (as in the case of stopping suddenly)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`late_driving_ind`: A binary indicator set to `1` if the vehicle is driven
    regularly after midnight'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to give some thought to how these variables may relate to billed
    insurance expenses—some in more obvious ways than others. For instance, we would
    clearly expect cars driven more often to be at a higher risk of an accident than
    those that stay home in the garage. On the other hand, it isn’t as clear whether
    urban, rural, or suburban drivers would be riskier; rural drivers may drive farther,
    but urban driving involves more traffic and may be more at risk of vehicle theft.
    A regression model will help us disentangle these relationships, but requires
    us to specify the connections between the features ourselves rather than detecting
    them automatically, which is unlike many other machine learning methods. We’ll
    explore some of the potential relationships in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: It may also be interesting to consider which potentially useful predictors are
    not included in the training dataset. Gender is often used for automobile insurance
    pricing (and it varies whether males or females are more costly!) but the state
    of Michigan banned the use of gender and credit scoring for this purpose in 2020\.
    Such features may be highly predictive, but may lead to systematic biases against
    protected groups, as discussed in *Chapter 1*, *Introducing Machine Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – exploring and preparing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we have done before, we will use the `read.csv()` function to load the data
    for analysis. We can safely use `stringsAsFactors = TRUE` because it is appropriate
    to convert the three nominal variables into factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The `str()` function confirms that the data is formatted as we expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Our model’s dependent variable is `expenses`, which measures the loss or damages
    each person claimed under the insurance plan for the year. Prior to building a
    linear regression model, it is often helpful to check for normality. Although
    linear regression will not fail without a normally distributed dependent variable,
    the model often fits better when this is true. Let’s look at the summary statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The minimum, first quartile, median, and third quartile are all zero, which
    implies that at least 75% of the beneficiaries had no expenses in the calendar
    year. The fact that the mean value is greater than the median gives us the sense
    that the distribution of insurance expenses is right-skewed, but the skew is likely
    to be quite extreme as the average expense was $1,709 while the maximum was $232,797\.
    We can confirm this visually using a histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![Text  Description automatically generated](img/B17290_06_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.7: The distribution of annual insurance claims costs'
  prefs: []
  type: TYPE_NORMAL
- en: As expected, the figure shows a right-skewed distribution with a huge spike
    at zero, reflecting the fact that only a small portion (about 8.6%) made an insurance
    claim. Among those that did claim a vehicle loss or damages, the tail end of the
    distribution extends far to the right, beyond $200,000 worth of expenses for the
    costliest injuries. Although this distribution is not ideal for linear regression,
    knowing this weakness ahead of time may help us design a better-fitting model
    later. For now, using only the distribution of `expenses`, we can say that the
    average beneficiary should be charged an annual premium of $1,709 for the insurer
    to break even, or about $150 a month per subscriber for a slight profit. Of course,
    this assumes that the risk and costs are shared evenly. An improved insurance
    model will push greater costs onto riskier drivers and provide safe drivers with
    financial savings.
  prefs: []
  type: TYPE_NORMAL
- en: Before we add additional predictors, it is important to note that regression
    models require that every feature is numeric, yet we have two factor-type features
    in our data frame. For instance, the `geo_area` variable is divided into `urban`,
    `suburban`, and `rural` levels, while `vehicle_type` has categories for `car`,
    `truck`, `suv`, and `minivan`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a closer look to see how they are distributed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Here, we see that the data has been divided nearly evenly between urban and
    suburban areas, but rural is a much smaller portion of the data. Additionally,
    SUVs are the most popular vehicle type, followed by cars and trucks, with minivans
    in a distant fourth place. We will see how R’s linear regression function handles
    these factor variables shortly.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring relationships between features – the correlation matrix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before fitting a regression model to data, it can be useful to determine how
    the independent variables are related to the dependent variable and each other.
    A **correlation matrix** provides a quick overview of these relationships. Given
    a set of variables, it provides a correlation for each pairwise relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a correlation matrix for the four numeric, non-binary variables in
    the insurance data frame, use the `cor()` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: At the intersection of each row and column pair, the correlation is listed for
    the variables indicated by that row and column. The diagonal is always `1.0000000`
    since there is always a perfect correlation between a variable and itself. The
    values above and below the diagonal are identical since correlations are symmetrical.
    In other words, `cor(x, y)` is equal to `cor(y, x)`.
  prefs: []
  type: TYPE_NORMAL
- en: None of the correlations in the matrix are very strong, but the associations
    do match with common sense. For instance, `age` and `expenses` appear to have
    a weak negative correlation, meaning that as someone ages, their expected insurance
    cost goes down slightly—probably reflecting the greater driving experience. There
    are also positive correlations between `est_value` and `expenses` and `miles_driven`
    and `expenses`, which indicate that more valuable cars and more extensive driving
    lead to greater expenses. We’ll try to tease out these types of relationships
    more clearly when we build our final regression model.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing relationships between features – the scatterplot matrix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It can also be helpful to visualize the relationships between numeric features
    with scatterplots. Although we could create a scatterplot for each possible relationship,
    doing so for a large set of features quickly becomes tedious.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative is to create a **scatterplot matrix** (sometimes abbreviated
    as **SPLOM**), which is simply a collection of scatterplots arranged in a grid.
    It is used to detect patterns among three or more variables. The scatterplot matrix
    is not a true multi-dimensional visualization because only two features are examined
    at a time. Still, it provides a general sense of how the data may be interrelated.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use R’s graphical capabilities to create a scatterplot matrix for the
    four non-binary numeric features: `age`, `est_value`, `miles_driven`, and `expenses`.
    The `pairs()` function is provided in the default R installation and provides
    basic functionality for producing scatterplot matrices. To invoke the function,
    simply provide it with a subset of the data frame to plot. Given the relatively
    large size of our `insurance` dataset, we’ll set the plot character parameter
    `pch = "."` to a dot to make the visualization easier to read, then limit the
    columns to the four variables of interest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following scatterplot matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_06_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.8: A scatterplot matrix of the numeric features in the insurance dataset'
  prefs: []
  type: TYPE_NORMAL
- en: In the scatterplot matrix, the intersection of each row and column holds the
    scatterplot of the variables indicated by the row and column pair. The diagrams
    above and below the diagonal are transpositions because the *x* axis and *y* axis
    have been swapped. Do you notice any patterns in these plots? Although they mostly
    look like random clouds of points, a couple seem to display some subtle trends.
    The relationships of both `est_value` and `miles_driven` with `expenses` seem
    to display a slight upward trend, which confirms visually what we already learned
    from the correlation matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'By adding more information to the plot, it can be made even more useful. An
    enhanced scatterplot matrix can be created with the `pairs.panels()` function
    in the `psych` package. If you do not have this package installed, type `install.packages("psych")`
    to install it on your system and load it using the `library(psych)` command. Then,
    we can create a scatterplot matrix using the `pch` parameter to set the plotting
    character as we did previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces a more informative scatterplot matrix, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing chart  Description automatically generated](img/B17290_06_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.9: The pairs.panels() function adds detail to the scatterplot matrix'
  prefs: []
  type: TYPE_NORMAL
- en: In the `pairs.panels()` output, the scatterplots above the diagonal are replaced
    with a correlation matrix. The diagonal now contains histograms depicting the
    distribution of values for each feature. Finally, the scatterplots below the diagonal
    are presented with additional visual information.
  prefs: []
  type: TYPE_NORMAL
- en: The oval-shaped object on each scatterplot (which may be difficult to see in
    print due to the mass of black points but can be seen more easily on a computer
    screen) is a **correlation ellipse**. It provides a simple visual indicator of
    correlation strength. In this dataset, there are no strong correlations, so the
    ovals are mostly flat; with stronger correlations, the ovals would be tilted upward
    or downward to indicate a positive or negative correlation. The dot at the center
    of the ellipse is a point reflecting the means of the *x*- and *y*-axis variables.
  prefs: []
  type: TYPE_NORMAL
- en: The line superimposed across the scatterplot (which appears in red on a computer
    screen) is called a **loess curve**. It indicates the general relationship between
    the *x*-axis and *y*-axis variables. It is best understood by example. Although
    the small size of the plot makes this trend difficult to see, the curve for `age`
    and `miles_driven` slopes upward very slightly until reaching middle age, then
    levels off. This means that driving tends to increase with age up to the point
    at which it remains roughly constant over time.
  prefs: []
  type: TYPE_NORMAL
- en: Although not observed here, the loess curve can sometimes be quite dramatic
    with V- or U-shaped curves as well as stairstep patterns. Recognizing such patterns
    can assist later with developing a better-fitting regression model.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – training a model on the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To fit a linear regression model to data with R, the `lm()` function can be
    used. This is part of the `stats` package, which should be included and loaded
    by default with your R installation. The `lm()` syntax is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B17290_06_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.10: Multiple regression syntax'
  prefs: []
  type: TYPE_NORMAL
- en: The following command fits a linear regression model, which relates the ten
    independent variables to the total insurance expenses. The R formula syntax uses
    the tilde character (`~`) to describe the model; the dependent variable `expenses`
    is written to the left of the tilde while the independent variables go to the
    right, separated by `+` signs.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is no need to specify the regression model’s intercept term, as it is
    included by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Because the period character (`.`) can be used to specify all features (excluding
    those already specified in the formula), the following command is equivalent to
    the prior command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'After building the model, simply type the name of the model object to see the
    estimated beta coefficients. Note that the `options(scipen = 999)` command turns
    off scientific notation to make the output easier to read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Understanding the regression coefficients for a linear regression model is fairly
    straightforward. The intercept is the predicted value of `expenses` when the independent
    variables are equal to zero. However, in many cases, the intercept is of little
    explanatory value by itself, as it is often impossible to have values of zero
    for all features.
  prefs: []
  type: TYPE_NORMAL
- en: This is the case here, where no insured person can exist with zero age or no
    miles driven, and consequently, the intercept has no real-world interpretation.
    For this reason, in practice, the intercept is often ignored.
  prefs: []
  type: TYPE_NORMAL
- en: The beta coefficients indicate the estimated increase in insurance claims costs
    for an increase of one unit in each feature, assuming all other values are held
    constant. For instance, for each additional year of age, we would expect $1.89
    lower insurance claims costs on average, assuming everything else is held equal.
    Similarly, we would expect $0.12 higher claims for each additional mile driven
    and $0.03 higher per dollar of insured value, all else equal.
  prefs: []
  type: TYPE_NORMAL
- en: You might notice that although we only specified 10 features in our model formula,
    there are 13 coefficients reported in addition to the intercept. This happened
    because the `lm()` function automatically applies dummy coding to each of the
    factor-type variables included in the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'As explained in *Chapter 3*, *Lazy Learning – Classification Using Nearest
    Neighbors*, dummy coding allows a nominal feature to be treated as numeric by
    creating a binary variable for each category of the feature except one, which
    serves as the reference category. Each dummy variable is set to `1` if the observation
    falls into the specified category or `0` otherwise. For example, the `geo_area`
    feature has three categories: `urban`, `suburban`, and `rural`. Thus, two dummy
    variables were used, which are named `geo_areaurban` and `geo_areasuburban`. For
    the observations where the `geo_area = "rural"`, `geo_areaurban` and `geo_areasuburban`
    will both be set to zero. Similarly, for the four-category `vehicle_type` feature,
    R created three dummy variables named `vehicle_typeminivan`, `vehicle_typesuv`,
    and `vehicle_typetruck`. This left `vehicle_type = "car"` to serve as the reference
    category when the three dummy variables are all zero.'
  prefs: []
  type: TYPE_NORMAL
- en: When dummy coded features are used in a regression model, the regression coefficients
    are interpreted relative to the categories that were omitted. In our model, R
    automatically held out the `geo_arearural` and `vehicle_typecar` variables, making
    rural car owners the reference group. Thus, urban dwellers have $169.11 more claims
    costs each year relative to rural areas and trucks cost the insurer an average
    of $21.57 more than cars per year. To be clear, these differences assume all other
    features are held equal, so they are independent of the fact that rural drivers
    may drive more miles or less expensive vehicles. We would expect two people who
    are otherwise identical, except that one lives in a rural area and one lives in
    an urban area, to differ by about $170, on average.
  prefs: []
  type: TYPE_NORMAL
- en: By default, R uses the first level of the factor variable as the reference.
    If you would prefer to use another level, the `relevel()` function can be used
    to specify the reference group manually. Use the `?relevel` command in R for more
    information.
  prefs: []
  type: TYPE_NORMAL
- en: In general, the results of the linear regression model make logical sense; however,
    we currently have no sense of how well the model is fitting the data. We’ll answer
    this question in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – evaluating model performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The parameter estimates we obtained by typing `ins_model` tell us about how
    the independent variables are related to the dependent variable, but they tell
    us nothing about how well the model fits our data. To evaluate the model performance,
    we can use the `summary()` command on the stored model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following output, which has been annotated for illustrative
    purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text  Description automatically generated](img/B17290_06_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.11: The summary output from a regression model can be divided into
    three main components, which are annotated in this figure'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `summary()` output may seem overwhelming at first, but the basics are easy
    to pick up. As indicated by the numbered labels in the preceding output, there
    are three main ways to evaluate the performance, or fit, of our model:'
  prefs: []
  type: TYPE_NORMAL
- en: The **Residuals** section provides summary statistics for the prediction errors,
    some of which are apparently quite substantial. Since a residual is equal to the
    true value minus the predicted value, the maximum error of `231252` suggests that
    the model under-predicted expenses by more than $230,000 for at least one observation.
    On the other hand, the majority of errors are relatively small negative values,
    which means that we are over-estimating expenses for most enrollees. This is exactly
    how the insurance company can afford to cover the expenses for costly accidents.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each estimated regression coefficient, the **p-value**, denoted by `Pr(>|t|)`,
    provides an estimate of the probability that the true coefficient is zero given
    the value of the estimate. Small p-values suggest that the true coefficient is
    very unlikely to be zero, which means that the feature is extremely unlikely to
    have no relationship with the dependent variable. Note that some of the p-values
    have stars (`***`), which correspond to the footnotes that specify the **significance
    level** met by the estimate. This level is a threshold, chosen prior to building
    the model, which will be used to indicate “real” findings, as opposed to those
    due to chance alone; p-values less than the significance level are considered
    **statistically significant**. If the model had few such terms, it may be a cause
    for concern, since this would indicate that the features used are not very predictive
    of the outcome. Here, our model has a few highly significant variables, and they
    seem to be related to the outcome in expected ways.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The **Multiple R-squared** value (also called the coefficient of determination)
    provides a measure of how well our model as a whole explains the values of the
    dependent variable. It is similar to the correlation coefficient in that the closer
    the value is to 1.0, the better the model perfectly explains the data. Since the
    R-squared value is 0.01241, we know that the model explains about 1.2 percent
    of the variation in the dependent variable. Because models with more features
    always explain more variation, the **Adjusted R-squared** value corrects R-squared
    by penalizing models with a large number of independent variables. This is useful
    for comparing the performance of models with different numbers of explanatory
    variables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Given the preceding three performance indicators, our model is performing well
    enough. The size of some of the errors is a bit concerning, but not surprising
    given the nature of insurance expense data.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, it is not uncommon for regression models of real-world data to
    have low R-squared values. Although a value of 0.01241 is especially low, it reflects
    the fact that we have no proximate predictors of automobile accidents; to truly
    predict accidents, we would need real-time driving data, or at least some measure
    of true driving skill. This being said, as we will see in the next section, we
    still may be able to improve the model’s performance by specifying the model in
    a slightly different way.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – improving model performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned previously, a key difference between regression modeling and other
    machine learning approaches is that regression typically leaves feature selection
    and model specification to the user. Consequently, if we have subject-matter knowledge
    about how a feature is related to the outcome, we can use this information to
    inform the model specification and potentially improve the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: Model specification – adding nonlinear relationships
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In linear regression, the relationship between an independent variable and the
    dependent variable is assumed to be linear, yet this may not necessarily be true.
    For example, the effect of age on insurance expenditures may not be constant across
    all age values; the treatment may become disproportionately expensive for the
    youngest and oldest populations—a U-shaped curve, if expenses were plotted against
    age.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you recall, a typical regression equation follows a form similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_046.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To account for a nonlinear relationship, we can add a higher-order term to
    the regression equation, treating the model as a polynomial. In effect, we will
    be modeling a relationship like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_047.png)'
  prefs: []
  type: TYPE_IMG
- en: The difference between these two models is that an additional regression parameter
    will be estimated, which is intended to capture the effect of the *x*² term. This
    allows the impact of age to be measured as a function of age and age squared.
  prefs: []
  type: TYPE_NORMAL
- en: 'To add the nonlinear age to the model, we simply need to create a new variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Then, when we produce our improved model, we’ll add both `age` and `age2` to
    the `lm()` formula using the form `expenses ~ age + age2`. This will allow the
    model to separate the linear and nonlinear impact of age on medical expenses.
  prefs: []
  type: TYPE_NORMAL
- en: Model specification – adding interaction effects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we have only considered each feature’s individual contribution to the
    outcome. What if certain features have a combined impact on the dependent variable?
    For instance, a habit of hard braking and late driving may have harmful effects
    separately, but it is reasonable to assume that their combined effect may be worse
    than the sum of each one alone.
  prefs: []
  type: TYPE_NORMAL
- en: When two features have a combined effect, this is known as an **interaction**.
    If we suspect that two variables interact, we can test this hypothesis by adding
    their interaction to the model. Interaction effects are specified using the R
    formula syntax. To interact the hard braking indicator (`hard_braking_ind`) with
    the late driving indicator (`late_driving_ind`), we would write a formula in the
    form `expenses ~ hard_braking_ind*late_driving_ind`.
  prefs: []
  type: TYPE_NORMAL
- en: The `*` operator is a shorthand that instructs R to model `expenses ~ hard_braking_ind
    +` `late_driving_ind` `+ hard_braking_ind:late_driving_ind`. The colon operator
    (`:`) in the expanded form indicates that `hard_braking_ind:late_driving_ind`
    is the interaction between the two variables. Note that the expanded form automatically
    also included the individual `hard_braking_ind` and `late_driving_ind` variables
    as well as their interaction.
  prefs: []
  type: TYPE_NORMAL
- en: If you have trouble deciding whether to include a variable, a common practice
    is to include it and examine the p-value. If the variable is not statistically
    significant, you have a plausible justification for excluding it from the model.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together – an improved regression model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Based on a bit of subject-matter knowledge of how insurance costs may be related
    to enrollee characteristics, we developed what we think is a more accurately specified
    regression formula. To summarize the improvements, we:'
  prefs: []
  type: TYPE_NORMAL
- en: Added a nonlinear term for age
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specified an interaction between hard braking and late driving
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We’ll train the model using the `lm()` function as before, but this time we’ll
    add the interaction term in addition to `age2`, which will be included automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we summarize the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Although the R-squared and adjusted R-squared values didn’t change much compared
    to the previous model, the new features present some interesting insights. In
    particular, the estimate for `age` is relatively large and negative (lower expenses)
    but `age2` is relatively small and positive (higher expenses). However, because
    age squared grows faster than age, expenses will begin to rise for very high age
    groups. The overall effect is a U-shaped expense curve, where the youngest and
    oldest enrollees are predicted to have higher expenses. The interaction of `hard_braking_ind`
    and `late_driving_ind` is also interesting, as it is a relatively large positive.
    Although the interaction is not statistically significant, the direction of the
    effect implies that driving late at night is especially dangerous if you are the
    type of driver that already drives dangerously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Strictly speaking, regression modeling makes some strong assumptions about
    the data. These assumptions are not as important for numeric forecasting, as the
    model’s worth is not based upon whether it truly captures the underlying process—we
    simply care about the accuracy of its predictions. However, if you would like
    to make firm inferences from the regression model coefficients, it is necessary
    to run diagnostic tests to ensure that the regression assumptions have not been
    violated. For an excellent introduction to this topic, see *Multiple Regression:
    A Primer, Allison, P. D., Pine Forge Press, 1998*.'
  prefs: []
  type: TYPE_NORMAL
- en: Making predictions with a regression model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After examining the estimated regression coefficients and fit statistics, we
    can also use the model to predict the expenses of future enrollees on the insurance
    plan. To illustrate the process of making predictions, let’s first apply the model
    to the original training data using the `predict()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This saves the predictions as a new vector named `pred` in the insurance data
    frame. We can then compute the correlation between the predicted and actual costs
    of insurance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The correlation of 0.11 suggests a relatively weak linear relationship between
    the predicted and actual values, which is disappointing but not too surprising
    given the seemingly random nature of motor vehicle accidents. It can also be useful
    to examine this finding as a scatterplot. The following R commands plot the relationship
    and then add an identity line with an intercept equal to zero and a slope equal
    to one. The `col`, `lwd`, and `lty` parameters affect the line color, width, and
    type, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '![Chart, scatter chart  Description automatically generated](img/B17290_06_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.12: In this scatterplot, points falling on or near the diagonal dashed
    line where *y = x* indicate the predictions that were very close to the actual
    values'
  prefs: []
  type: TYPE_NORMAL
- en: The off-diagonal points falling above the line are cases where the actual expenses
    are greater than expected, while cases falling below the line are those less than
    expected. We can see here that a small number of people with much larger-than-expected
    expenses are balanced by a huge number of people with slightly smaller-than-expected
    expenses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, suppose you would like to forecast the expenses for potential new enrollees
    on the insurance plan. To do this, you must provide the `predict()` function a
    data frame with the prospective drivers’ data. In the case of many drivers, you
    may consider creating a CSV spreadsheet file to load in R, or for a smaller number,
    you may simply create a data frame within the `predict()` function itself. For
    example, to estimate the insurance expenses for a 30-year-old, rural driver of
    a truck valued at $25,000 driven for about 14,000 miles annually with a clean
    driving record:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this value, the insurance company would need to charge about $1,015 annually
    to break even for this demographic group. To compare the rate for someone who
    is otherwise similar except for a history of a recent accident, use the `predict()`
    function in much the same way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Note that the difference between these two values, *1015.059 – 1247.903 = -232.844*,
    is the same as the estimated regression model coefficient for `clean_driving_ind`.
    On average, drivers with a clean history are estimated to have about $232.84 less
    in expenses for the plan per year, all else being equal.
  prefs: []
  type: TYPE_NORMAL
- en: 'This illustrates the more general fact that the predicted expenses are a sum
    of each of the regression coefficients times their corresponding value in the
    prediction data frame. For instance, using the model’s regression coefficient
    of 0.118748 for the miles driven, we can predict that adding 10,000 additional
    miles will result in an increase in expenses of *10,000 * 0.118748 = 1187.48*,
    which can be confirmed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Following similar steps for a number of additional customer risk segments, the
    insurance company would be able to develop a pricing structure that fairly sets
    costs according to drivers’ estimated risk level while also maintaining a consistent
    profit across all segments.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting the model’s regression coefficients allows you to build your own forecasting
    function. One potential use case for doing so would be to implement the regression
    model in a customer database for real-time prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Going further – predicting insurance policyholder churn with logistic regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Actuarial estimates of claims costs are not the only potential application of
    machine learning inside an insurance company. Marketing and customer retention
    teams are likely to be very interested in predicting **churn**, or the customers
    that leave the company after choosing not to renew their insurance plan. In many
    businesses, preventing churn is highly valued, as churned customers not only reduce
    the income stream for one business but also often increase the revenue stream
    of a direct competitor. Additionally, marketing teams know that the costs of acquiring
    new customers are generally much higher than the costs of retaining an existing
    customer.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, knowing ahead of time which customers are most likely to churn can
    help direct retention resources to intervene and prevent churn before it happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Historically, marketing teams have used a simple model called **recency, frequency,
    monetary value** (**RFM**) to identify highly valuable customers as well as those
    most likely to churn. The RFM analysis considers three characteristics of each
    customer:'
  prefs: []
  type: TYPE_NORMAL
- en: How recently have they purchased? Customers that haven’t purchased in a while
    may be less valuable and more likely to never return.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How frequently do they purchase? Do they come back year after year, or are there
    irregular gaps in their purchasing behavior? Customers that exhibit loyalty may
    be more valuable and more likely to return.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much money do they spend when they purchase? Do they spend more than the
    average customer or upgrade to premium products? These customers are more valuable
    financially, but also demonstrate their love of the brand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Historical customer purchase data is collected with the intention of developing
    measures of each of these three factors. The measures are then converted into
    a standard scale (such as a scale from zero to ten) for each of the three areas
    and summed to create a final RFM score for each customer. A very recent and frequent
    purchaser that spends an average amount may have a combined score of *10 + 10
    + 5 = 25* while a customer that purchased once a long time ago may have a score
    of *2 + 1 + 4 = 7*, which places them much lower on the RFM scale.
  prefs: []
  type: TYPE_NORMAL
- en: This type of analysis is a crude but useful tool for understanding a set of
    customers and helping identify the types of data that may be useful for predicting
    churn. However, an RFM analysis is not particularly scientific and provides no
    formal estimation of the probability of churn or the factors that increase its
    likelihood. In contrast, a logistic regression model predicting a binary churn
    outcome provides both an estimated probability of churn for each customer as well
    as the impact of each predictor.
  prefs: []
  type: TYPE_NORMAL
- en: As with the insurance claims cost example, we’ll build a churn model using a
    simulated dataset created for this book, which is intended to approximate the
    behavior of customers of the automobile insurance company.
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to follow along interactively, download the `insurance_churn.csv`
    file from the Packt Publishing GitHub repository for this book and save it to
    your R working folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'The churn dataset includes 5,000 examples of current and former beneficiaries
    enrolled in the hypothetical automobile insurance plan. Each example includes
    features measuring customer behaviors in the plan year, as well as a binary indicator
    (`churn`) of whether they churned out of the plan by not renewing at the end of
    the year. The available features include:'
  prefs: []
  type: TYPE_NORMAL
- en: '`member_id`: A randomly assigned customer identification number'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`loyalty_years`: The number of consecutive years enrolled in the insurance
    plan'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vehicles_covered`: The number of vehicles covered by the insurance plan'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`premium_plan_ind`: A binary indicator that the member paid for a premium,
    high-cost version of the plan with additional benefits'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mobile_app_user`: A binary indicator that the member uses the mobile phone
    companion application'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`home_auto_bundle`: A binary indicator that the member also holds a homeowner’s
    insurance plan offered by the same company'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`auto_pay_ind`: A binary indicator that the member has automatic payments turned
    on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`recent_rate_increase`: A binary indicator that the member’s price was raised
    recently'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notice that many of these factors relate to the three components of RFM in that
    they are measures of loyalty and monetary value. Thus, even if a more sophisticated
    model is built later, it can still be helpful to perform an RFM analysis as an
    earlier step in the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'To read this dataset into R, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `table()` and `prop.table()` functions, we can see the overall churn
    rate is just over 15 percent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: In a more formal analysis, it would be wise to perform more data exploration
    before going further. Here, we will jump ahead to creating the logistic regression
    model to predict these churned customers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `glm()` function, which is part of R’s built-in `stats` package, is used
    to fit a GLM model such as logistic regression as well as the other variants like
    Poisson regression described earlier in the chapter. The syntax for logistic regression
    is shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Text, letter  Description automatically generated](img/B17290_06_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.13: Logistic regression syntax'
  prefs: []
  type: TYPE_NORMAL
- en: Note the many similarities between the `glm()` function syntax and the `lm()`
    function used earlier for standard linear regression. Aside from specifying the
    family and link function, fitting the model is no more difficult. The key differences
    are primarily in how the resulting model is interpreted.
  prefs: []
  type: TYPE_NORMAL
- en: Beware that R’s `glm()` function defaults to Gaussian with an identity link,
    so it is easy to accidentally perform standard linear regression when another
    GLM form is desired! For this reason, it is wise to form a habit of always specifying
    the family and link when building a GLM in R.
  prefs: []
  type: TYPE_NORMAL
- en: 'To fit the logistic regression churn model, we specify the `binomial` family
    with the `logit` link function. Here, we model churn as a function of all other
    features in the dataset, minus `member_id`, which is unique to each member and
    therefore useless for prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `summary()` on the resulting `churn_model` object shows the estimated
    regression parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: At a high level, the logistic regression output is fairly similar to a linear
    regression output. The p-values (labeled `Pr(>|z|)`) and significance codes (denoted
    by `*` characters) indicate whether the variables are statistically significant.
    All features aside from the `auto_pay_ind` are significant at the 0.05 level or
    better. The direction of the relationship between the predictors and the target
    outcome can also be understood simply by looking at the sign (positive or negative)
    before the `Estimate` value. Nearly all estimates are negative, which implies
    that these features reduce churn, except for `recent_rate_increase`, which is
    positive and therefore increases churn. These connections make sense; an increase
    in the price of the insurance plan would be expected to increase churn, while
    members that have been loyal for years or pay for premium plan features are less
    likely to leave.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting the impact of a specific feature on churn is where logistic regression
    is trickier than linear regression, as the estimates are shown in log odds. Suppose
    we want to know how much more likely churn is after a recent increase in the price
    of the insurance plan. Since the estimate for `recent_rate_increase` is 0.6481,
    this means that the log odds of churn increase by 0.6481 when the rate increase
    indicator is `1` versus when it is `0`. Exponentiating this to remove the logarithm
    and find the odds ratio, we find that *exp(0.6481) = 1.911905*, which implies
    that churn is almost twice as likely (or 91.2 percent more likely) after a rate
    increase.
  prefs: []
  type: TYPE_NORMAL
- en: In the opposite direction, members that use the mobile app (`mobile_app_user`)
    have an estimated difference in log odds of -0.292273 versus those that do not.
    Finding the odds ratio as *exp(-0.292273) = 0.7465647* suggests that the churn
    of app users is about 75 percent of those that do not use the app, or a decrease
    of about 25 percent for app users. Similarly, we can find that churn is reduced
    by about seven percent for each additional year of loyalty, as *exp(-0.072284)
    = 0.9302667*. Similar calculations can be performed for all other predictors in
    the model, including the intercept, which represents the odds of churn when all
    predictors are zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use this model to prevent churn, we can make predictions on a database of
    current plan members. Let’s begin by loading a dataset containing 1000 subscribers,
    using the `test` dataset available for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll then use the logistic regression model object with the `predict()` function
    to add a new column to this data frame, which contains the predictions for each
    member:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Note that the `type = "response"` parameter is set so that the predictions are
    in probabilities rather than the default `type = "link"` setting, which produces
    predictions as log odds values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Summarizing these predicted probabilities, we see that the average churn probability
    is about 15 percent, but some users are predicted to have very low churn, while
    others have a churn probability as high as 41 percent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Suppose the customer retention team has the resources to intervene in a limited
    number of cases. By sorting the members to identify those with the highest predicted
    churn likelihood, we can provide the team with the direction most likely to make
    the greatest impact.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, use the `order()` function to obtain a vector with the row numbers sorted
    in decreasing order according to their churn probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, after ordering the `churn_test` data frame according to the `churn_order`
    vector and taking the two columns of interest, use the `head()` function to take
    the top `n` rows; in this case, we’ll set `n = 5` to limit to the five members
    most likely to churn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: After saving the result to a spreadsheet with `n` set to a higher number, it
    would be possible to provide the customer retention team with a list of the insurance
    plan members that are most likely to churn. Focusing retention efforts on these
    members is likely to be a more fruitful use of the marketing budget than targeting
    members at random, as most members have a very low churn probability. In this
    way, machine learning can provide a substantial return on minimal investment,
    with an impact that is easily quantifiable by comparing the churn rates before
    and after this intervention.
  prefs: []
  type: TYPE_NORMAL
- en: Estimates of revenue retained as a result of churn prevention can be obtained
    using simple assumptions about the proportion of customers that will respond to
    retention efforts. For example, if we assume *N* of members targeted by the churn
    model will be retained, this will result in *N* times *$X* retained revenue, where
    *$X* is the average customer spend. Bringing this number to stakeholders helps
    provide justification for implementing the machine learning project.
  prefs: []
  type: TYPE_NORMAL
- en: The example is only the tip of the iceberg, as churn modeling can become much
    more sophisticated with additional efforts. For instance, rather than targeting
    the customers with the highest churn probability, it is also possible to consider
    the revenue lost if the customer churns; it may be worth prioritizing high-value
    customers even if they have a lower churn probability than a low-value customer.
    Additionally, because some customers are assured to churn regardless of intervention
    while others may be more flexible about staying, it is possible to model retention
    likelihood in addition to modeling churn probability. In any case, even in a simple
    form, churn modeling is low-hanging fruit for most businesses and a great first
    place to implement machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding regression trees and model trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you recall from *Chapter 5*, *Divide and Conquer – Classification Using Decision
    Trees and Rules*, a decision tree builds a model, much like a flowchart, in which
    decision nodes, leaf nodes, and branches define a series of decisions, which are
    used to classify examples. Such trees can also be used for numeric prediction
    by making only small adjustments to the tree-growing algorithm. In this section,
    we will consider the ways in which trees for numeric prediction differ from trees
    used for classification.
  prefs: []
  type: TYPE_NORMAL
- en: Trees for numeric prediction fall into two categories. The first, known as **regression
    trees**, were introduced in the 1980s as part of the seminal **classification
    and regression tree** (**CART**) algorithm. Despite the name, regression trees
    do not use linear regression methods as described earlier in this chapter; rather,
    they make predictions based on the average value of examples that reach a leaf.
  prefs: []
  type: TYPE_NORMAL
- en: The CART algorithm is described in detail in *Classification and Regression
    Trees, Breiman, L., Friedman, J. H., Stone, C. J., Olshen, R. A., Chapman and
    Hall, 1984*.
  prefs: []
  type: TYPE_NORMAL
- en: The second type of tree for numeric prediction is known as a **model tree**.
    Introduced several years later than regression trees, they are less widely known,
    but perhaps more powerful. Model trees are grown in much the same way as regression
    trees, but at each leaf, a multiple linear regression model is built from the
    examples reaching that node. Depending on the number of leaf nodes, a model tree
    may build tens or even hundreds of such models.
  prefs: []
  type: TYPE_NORMAL
- en: This makes model trees more difficult to understand than the equivalent regression
    tree, with the benefit that they may result in a more accurate model.
  prefs: []
  type: TYPE_NORMAL
- en: The earliest model tree algorithm, **M5**, is described in *Learning with continuous
    classes, Quinlan, J. R., Proceedings of the 5th Australian Joint Conference on
    Artificial Intelligence, 1992, pp. 343-348*.
  prefs: []
  type: TYPE_NORMAL
- en: Adding regression to trees
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Trees that can perform numeric prediction offer a compelling, yet often overlooked,
    alternative to regression modeling. The strengths and weaknesses of regression
    trees and model trees relative to the more common regression methods are listed
    in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strengths** | **Weaknesses** |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Combines the strengths of decision trees with the ability to model numeric data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does not require the user to specify the model in advance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses automatic feature selection, which allows the approach to be used with
    a very large number of features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: May fit some types of data much better than linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does not require knowledge of statistics to interpret the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Not as well known as linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requires a large amount of training data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Difficult to determine the overall net effect of individual features on the
    outcome
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large trees can become more difficult to interpret than a regression model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Though traditional regression methods are typically the first choice for numeric
    prediction tasks, in some cases, numeric decision trees offer distinct advantages.
    For instance, decision trees may be better suited for tasks with many features
    or many complex, nonlinear relationships between features and the outcome; these
    situations present challenges for regression. Regression modeling also makes assumptions
    about the data that are often violated in real-world data; this is not the case
    for trees.
  prefs: []
  type: TYPE_NORMAL
- en: Trees for numeric prediction are built in much the same way as they are for
    classification. Beginning at the root node, the data is partitioned using a divide-and-conquer
    strategy according to the feature that will result in the greatest increase in
    homogeneity in the outcome after a split is performed.
  prefs: []
  type: TYPE_NORMAL
- en: In classification trees, you will recall that homogeneity is measured by entropy.
    This is undefined for numeric data. Instead, for numeric decision trees, homogeneity
    is measured by statistics such as variance, standard deviation, or absolute deviation
    from the mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'One common splitting criterion is called the **standard deviation reduction**
    (**SDR**). It is defined by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_048.png)'
  prefs: []
  type: TYPE_IMG
- en: In this formula, the *sd*(*T*) function refers to the standard deviation of
    the values in set *T*, while *T*[1], *T*[2], ..., *T*[n] are sets of values resulting
    from a split on a feature. The *|T|* term refers to the number of observations
    in set *T*. Essentially, the formula measures the reduction in standard deviation
    by comparing the standard deviation pre-split to the weighted standard deviation
    post-split.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider the following case in which a tree is deciding whether
    to perform a split on binary feature A or a split on binary feature B:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B17290_06_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.14: The algorithm considers splits on features A and B, which creates
    different T[1] and T[2] groups'
  prefs: []
  type: TYPE_NORMAL
- en: Using the groups that would result from the proposed splits, we can compute
    the SDR for A and B as follows. The `length()` function used here returns the
    number of elements in a vector. Note that the overall group T is named `tee` to
    avoid overwriting R’s built-in `T()` and `t()` functions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s compare the SDR of A against the SDR of B:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: The SDR for the split on feature A was about 1.2 versus 1.4 for the split on
    feature B. Since the standard deviation was reduced more for the split on B, the
    decision tree would use B first. It results in slightly more homogeneous sets
    than does A.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose that the tree stopped growing here using this one and only split. A
    regression tree’s work is done. It can make predictions for new examples depending
    on whether the example’s value on feature B places the example into group *T*[1]
    or *T*[2]. If the example ends up in *T*[1], the model would predict *mean*(*bt1*)
    = *2*, otherwise it would predict *mean*(*bt2*) = *6.25*.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, a model tree would go one step further. Using the seven training
    examples falling in group *T*[1] and the eight in *T*[2], the model tree could
    build a linear regression model of the outcome versus feature A. Note that feature
    B is of no help in building the regression model because all examples at the leaf
    have the same value of B—they were placed into *T*[1] or *T*[2] according to their
    value of B. The model tree can then make predictions for new examples using either
    of the two linear models.
  prefs: []
  type: TYPE_NORMAL
- en: To further illustrate the differences between these two approaches, let’s work
    through a real-world example.
  prefs: []
  type: TYPE_NORMAL
- en: Example – estimating the quality of wines with regression trees and model trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Winemaking is a challenging and competitive business, which offers the potential
    for great profit. However, there are numerous factors that contribute to the profitability
    of a winery. As an agricultural product, variables as diverse as the weather and
    the growing environment impact the quality of a varietal. The bottling and manufacturing
    can also affect the flavor for better or worse. Even the way the product is marketed,
    from the bottle design to the price point, can affect the customer’s perception
    of the taste.
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, the winemaking industry has invested heavily in data collection
    and machine learning methods that may assist with the decision science of winemaking.
    For example, machine learning has been used to discover key differences in the
    chemical composition of wines from different regions, and to identify the chemical
    factors that lead a wine to taste sweeter.
  prefs: []
  type: TYPE_NORMAL
- en: More recently, machine learning has been employed to assist with rating the
    quality of wine—a notoriously difficult task. A review written by a renowned wine
    critic often determines whether the product ends up on the top or bottom shelf,
    in spite of the fact that even expert judges are inconsistent when rating a wine
    in a blinded test.
  prefs: []
  type: TYPE_NORMAL
- en: In this case study, we will use regression trees and model trees to create a
    system capable of mimicking expert ratings of wine. Because trees result in a
    model that is readily understood, this could allow winemakers to identify key
    factors that contribute to better-rated wines. Perhaps more importantly, the system
    does not suffer from the human elements of tasting, such as the rater’s mood or
    palate fatigue. Computer-aided wine testing may therefore result in a better product,
    as well as more objective, consistent, and fair ratings.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – collecting data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To develop the wine rating model, we will use data donated to the UCI Machine
    Learning Repository ([http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml))
    by P. Cortez, A. Cerdeira, F. Almeida, T. Matos, and J. Reis. Their dataset includes
    examples of red and white Vinho Verde wines from Portugal—one of the world’s leading
    wine-producing countries. Because the factors that contribute to a highly rated
    wine may differ between the red and white varieties, for this analysis we will
    examine only the more popular white wines.
  prefs: []
  type: TYPE_NORMAL
- en: To follow along with this example, download the `whitewines.csv` file from the
    Packt Publishing GitHub repository for this book and save it to your R working
    directory. The `redwines.csv` file is also available in case you would like to
    explore this data on your own.
  prefs: []
  type: TYPE_NORMAL
- en: The white wine data includes information on 11 chemical properties of 4,898
    wine samples. For each wine, a laboratory analysis measured characteristics such
    as acidity, sugar content, chlorides, sulfur, alcohol, pH, and density. The samples
    were then rated in a blind tasting by panels of no less than three judges on a
    quality scale ranging from 0 (very bad) to 10 (excellent). In the case that the
    judges disagreed on the rating, the median value was used.
  prefs: []
  type: TYPE_NORMAL
- en: 'The study by Cortez evaluated the ability of three machine learning approaches
    to model the wine data: multiple regression, artificial neural networks, and support
    vector machines. We covered multiple regression earlier in this chapter, and we
    will learn about neural networks and support vector machines in *Chapter 7*, *Black-Box
    Methods – Neural Networks and Support Vector Machines*. The study found that the
    support vector machine offered significantly better results than the linear regression
    model. However, unlike regression, the support vector machine model is difficult
    to interpret. Using regression trees and model trees, we may be able to improve
    the regression results while still having a model that is relatively easy to understand.'
  prefs: []
  type: TYPE_NORMAL
- en: To read more about the wine study described here, refer to *Modeling wine preferences
    by data mining from physicochemical properties, Cortez, P., Cerdeira, A., Almeida,
    F., Matos, T., and Reis, J., Decision Support Systems, 2009, Vol. 47, pp. 547-553*.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – exploring and preparing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As usual, we will use the `read.csv()` function to load the data into R. Since
    all features are numeric, we can safely ignore the `stringsAsFactors` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The `wine` data includes 11 features and the quality outcome, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Compared with other types of machine learning models, one of the advantages
    of trees is that they can handle many types of data without preprocessing. This
    means we do not need to normalize or standardize the features.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, a bit of effort to examine the distribution of the outcome variable
    is needed to inform our evaluation of the model’s performance. For instance, suppose
    that there was very little variation in quality from wine to wine, or that wines
    fell into a bimodal distribution: either very good or very bad. This may impact
    the way we design the model. To check for such extremes, we can examine the distribution
    of wine quality using a histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, bar chart  Description automatically generated](img/B17290_06_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.15: The distribution of the quality ratings of white wines'
  prefs: []
  type: TYPE_NORMAL
- en: The wine quality values appear to follow a roughly normal, bell-shaped distribution,
    centered around a value of six. This makes sense intuitively, because most wines
    are of average quality; few are particularly bad or good. Although the results
    are not shown here, it is also useful to examine the `summary(wine)` output for
    outliers or other potential data problems. Even though trees are fairly robust
    to messy data, it is always prudent to check for severe problems. For now, we’ll
    assume that the data is reliable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our last step, then, is to divide the dataset into training and testing sets.
    Since the `wine` dataset was already sorted randomly, we can partition it into
    two sets of contiguous rows as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: In order to mirror the conditions used by Cortez, we used sets of 75 percent
    and 25 percent for training and testing, respectively. We’ll evaluate the performance
    of our tree-based models on the testing data to see if we can obtain results comparable
    to the prior research study.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – training a model on the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will begin by training a regression tree model. Although almost any implementation
    of decision trees can be used to perform regression tree modeling, the `rpart`
    (recursive partitioning) package offers the most faithful implementation of regression
    trees as they were described by the CART team. As the classic R implementation
    of CART, the `rpart` package is also well documented and supported with functions
    for visualizing and evaluating the `rpart` models.
  prefs: []
  type: TYPE_NORMAL
- en: Install the `rpart` package using the `install.packages("rpart")` command. It
    can then be loaded into your R session using the `library(rpart)` statement. The
    following syntax will train a tree using the default settings, which work well
    most of the time, but not always. If you need more fine-tuned settings, refer
    to the documentation for the control parameters using the `?rpart.control` command.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B17290_06_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.16: Regression tree syntax'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the R formula interface, we can specify `quality` as the outcome variable
    and use the dot notation to allow all other columns in the `wine_train` data frame
    to be used as predictors. The resulting regression tree model object is named
    `m.rpart` to distinguish it from the model tree we will train later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'For basic information about the tree, simply type the name of the model object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: For each node in the tree, the number of examples reaching the decision point
    is listed. For instance, all 3,750 examples begin at the root node, of which 2,372
    have `alcohol < 10.85` and 1,378 have `alcohol >= 10.85`. Because `alcohol` was
    used first in the tree, it is the single most important predictor of wine quality.
  prefs: []
  type: TYPE_NORMAL
- en: Nodes indicated by `*` are terminal or leaf nodes, which means that they result
    in a prediction (listed here as `yval`). For example, node 5 has a `yval` of 5.971091\.
    When the tree is used for predictions, any wine samples with `alcohol < 10.85`
    and `volatile.acidity < 0.2275` would therefore be predicted to have a quality
    value of 5.97.
  prefs: []
  type: TYPE_NORMAL
- en: A more detailed summary of the tree’s fit, including the mean squared error
    for each of the nodes and an overall measure of feature importance, can be obtained
    using the `summary(m.rpart)` command.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing decision trees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although the tree can be understood using only the preceding output, it is often
    more readily understood using visualization. The `rpart.plot` package by Stephen
    Milborrow provides an easy-to-use function that produces publication-quality decision
    trees.
  prefs: []
  type: TYPE_NORMAL
- en: For more information on `rpart.plot`, including additional examples of the types
    of decision tree diagrams the function can produce, refer to the author’s website
    at [http://www.milbo.org/rpart-plot/](http://www.milbo.org/rpart-plot/).
  prefs: []
  type: TYPE_NORMAL
- en: 'After installing the package using the `install.packages("rpart.plot")` command,
    the `rpart.plot()` function produces a tree diagram from any `rpart` model object.
    The following commands plot the regression tree we built earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting tree diagram is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_06_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.17: A visualization of the wine quality regression tree model'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the `digits` parameter, which controls the number of numeric
    digits to include in the diagram, many other aspects of the visualization can
    be adjusted. The following command shows just a few of the useful options:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: The `fallen.leaves` parameter forces the leaf nodes to be aligned at the bottom
    of the plot, while the `type` and `extra` parameters affect the way the decisions
    and nodes are labeled. The numbers `3` and `101` refer to specific style formats,
    which can be found in the command’s documentation or via experimentation with
    various numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of these changes is a very different-looking tree diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_06_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.18: Changing the plot function parameters allows customization of
    the tree visualization'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizations like these may assist with the dissemination of regression tree
    results, as they are readily understood even without a mathematics background.
    In both cases, the numbers shown in the leaf nodes are the predicted values for
    the examples reaching that node. Showing the diagram to the wine producers may
    thus help to identify the key factors involved in predicting higher-rated wines.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4 – evaluating model performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To use the regression tree model to make predictions on the test data, we use
    the `predict()` function. By default, this returns the estimated numeric value
    for the outcome variable, which we’ll save in a vector named `p.rpart`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'A quick look at the summary statistics of our predictions suggests a potential
    problem: the predictions fall into a much narrower range than the true values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: This finding suggests that the model is not correctly identifying the extreme
    cases, and in particular, the best and worst wines. On the other hand, between
    the first and third quartile, we may be doing well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The correlation between the predicted and actual quality values provides a
    simple way to gauge the model’s performance. Recall that the `cor()` function
    can be used to measure the relationship between two equal-length vectors. We’ll
    use this to compare how well the predicted values correspond to the true values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: A correlation of `0.54` is certainly acceptable. However, the correlation only
    measures how strongly the predictions are related to the true value; it is not
    a measure of how far off the predictions were from the true values.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring performance with the mean absolute error
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another way to think about the model’s performance is to consider how far, on
    average, its prediction was from the true value. This measurement is called the
    **mean absolute error** (**MAE**).
  prefs: []
  type: TYPE_NORMAL
- en: 'The equation for MAE is as follows, where *n* indicates the number of predictions
    and *e*[i] indicates the error for prediction *i*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_06_049.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As the name implies, this equation takes the mean of the absolute value of
    the errors. Since the error is just the difference between the predicted and actual
    values, we can create a simple `MAE()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'The MAE for our predictions is then:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: This implies that, on average, the difference between our model’s predictions
    and the true quality score was about `0.59`. On a quality scale from 0 to 10,
    this seems to suggest that our model is doing fairly well.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, recall that most wines were neither very good nor very bad;
    the typical quality score was around 5 to 6\. Therefore, a classifier that did
    nothing but predict the mean value may also do fairly well according to this metric.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean quality rating in the training data is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'If we predicted the value `5.87` for every wine sample, we would have a MAE
    of only about `0.67`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: Our regression tree (*MAE* = *0.59*) comes closer on average to the true quality
    score than the imputed mean (*MAE* = *0.67*), but not by much. In comparison,
    Cortez reported an MAE of 0.58 for the neural network model and an MAE of `0.45`
    for the support vector machine. This suggests that there is room for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Step 5 – improving model performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To improve the performance of our learner, let’s apply a model tree algorithm,
    which is a more complex application of trees to numeric prediction. Recall that
    a model tree extends regression trees by replacing the leaf nodes with regression
    models. This often results in more accurate results than regression trees, which
    use only a single numeric value for the prediction at the leaf nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The current state-of-the-art in model trees is the **Cubist** algorithm, which
    itself is an enhancement of the M5 model tree algorithm—both of which were published
    by J. R. Quinlan in the early 1990s. Though the implementation details are beyond
    the scope of this book, the Cubist algorithm involves building a decision tree,
    creating decision rules based on the branches of the tree, and building a regression
    model at each of the leaf nodes. Additional heuristics, such as pruning and boosting,
    are used to improve the quality of the predictions and smoothness across the range
    of predicted values.
  prefs: []
  type: TYPE_NORMAL
- en: For more background on the Cubist and M5 algorithms, see *Learning With Continuous
    Classes, Quinlan, J. R., Proceedings of the 5th Australian Joint Conference on
    Artificial Intelligence, 1992, pp. 343-348\.* Additionally, see *Combining Instance-Based
    and Model-Based Learning, Quinlan, J. R., Proceedings of the Tenth International
    Conference on Machine Learning, 1993, pp. 236-243*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Cubist algorithm is available in R via the `Cubist` package and the associated
    `cubist()` function. The syntax of this function is shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B17290_06_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6.19: Model tree syntax'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll fit the Cubist model tree using a slightly different syntax from what
    was used for the regression tree, as the `cubist()` function does not accept the
    R formula syntax. Instead, we must specify the data frame columns used for the
    `x` independent variables and the `y` dependent variable. With the wine quality
    to be predicted residing in column 12, and using all other columns as predictors,
    the full command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Basic information about the model tree can be examined by typing its name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'In this output, we see that the algorithm generated 25 rules to model the wine
    quality. To examine some of these rules, we can apply the `summary()` function
    to the model object. Since the complete tree is very large, only the first few
    lines of output depicting the first decision rule are included here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: You will note that the `if` portion of the output is somewhat like the regression
    tree we built earlier. A series of decisions based on the wine properties of sulfur
    dioxide, sulphates, and alcohol creates a rule culminating in the final prediction.
    A key difference between this model tree output and the earlier regression tree
    output, however, is that the nodes here terminate not in a numeric prediction,
    but rather in a linear model.
  prefs: []
  type: TYPE_NORMAL
- en: The linear model for this rule is shown in the `then` output following the `outcome
    =` statement. The numbers can be interpreted exactly the same as the multiple
    regression models we built earlier in this chapter. Each value is the estimated
    impact of the associated feature, that is, the net effect of one unit increase
    of that feature on the predicted wine quality. For example, the coefficient of
    0.186 for residual sugar implies that for an increase of one unit of residual
    sugar, the wine quality rating is expected to increase by 0.186.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to note that the regression effects estimated by this model
    apply only to wine samples reaching this node; an examination of the entirety
    of the Cubist output reveals that a total of 25 linear models were built in this
    model tree, one for each decision rule, and each with different parameter estimates
    of the impact of residual sugar and the 10 other features.
  prefs: []
  type: TYPE_NORMAL
- en: 'To examine the performance of this model, we’ll look at how well it performs
    on the unseen test data. The `predict()` function gets us a vector of predicted
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'The model tree appears to be predicting a wider range of values than the regression
    tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'The correlation also seems to be substantially higher:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'Furthermore, the model slightly reduced the MAE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: Although we did not improve a great deal beyond the regression tree, we surpassed
    the performance of the neural network model published by Cortez, and we are getting
    closer to the published MAE value of 0.45 for the support vector machine model,
    all while using a much simpler learning method.
  prefs: []
  type: TYPE_NORMAL
- en: Not surprisingly, we have confirmed that predicting the quality of wines is
    a difficult problem; wine tasting, after all, is inherently subjective. If you
    would like additional practice, you may try revisiting this problem after reading
    *Chapter 14*, *Building Better Learners*, which covers additional techniques that
    may lead to better results.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we studied two methods for modeling numeric data. The first
    method, linear regression, involves fitting straight lines to data, but a technique
    called generalized linear modeling can adapt regression to other contexts as well.
    The second method uses decision trees for numeric prediction. The latter comes
    in two forms: regression trees, which use the average value of examples at leaf
    nodes to make numeric predictions, and model trees, which build a regression model
    at each leaf node in a hybrid approach that is, in some ways, the best of both
    worlds.'
  prefs: []
  type: TYPE_NORMAL
- en: We began to understand the utility of regression modeling by using it to investigate
    the causes of the Challenger space shuttle disaster. We then used linear regression
    modeling to calculate the expected insurance claims costs for various segments
    of automobile drivers.
  prefs: []
  type: TYPE_NORMAL
- en: Because the relationship between the features and the target variable is well
    documented by the estimated regression model, we were able to identify certain
    demographics, such as high-mileage and late-night drivers, who may need to be
    charged higher insurance rates to cover their higher-than-average claims costs.
    We then applied logistic regression, a variant of regression used for binary classification,
    to the task of modeling insurance customer retention. These examples demonstrated
    the ability of regression to adapt flexibly to many types of real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: In a somewhat less businesslike application of machine learning, regression
    trees and model trees were used to model the subjective quality of wines from
    measurable characteristics. In doing so, we learned how regression trees offer
    a simple way to explain the relationship between features and a numeric outcome,
    but the more complex model trees may be more accurate. Along the way, we learned
    new methods for evaluating the performance of numeric models.
  prefs: []
  type: TYPE_NORMAL
- en: In stark contrast to this chapter, which covered machine learning methods that
    result in a clear understanding of the relationships between the input and the
    output, the next chapter covers methods that result in nearly incomprehensible
    models. The upside is that they are extremely powerful techniques—among the most
    powerful stock classifiers—which can be applied to both classification and numeric
    prediction problems.
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 4000 people at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/r](https://packt.link/r)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/r.jpg)'
  prefs: []
  type: TYPE_IMG
