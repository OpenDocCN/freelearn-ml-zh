- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Forecasting Numeric Data – Regression Methods
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测数值数据 – 回归方法
- en: Mathematical relationships help us to make sense of many aspects of everyday
    life. For example, body weight is a function of one’s calorie intake; income is
    often related to education and job experience; and poll numbers help to estimate
    a presidential candidate’s odds of being re-elected.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 数学关系帮助我们理解日常生活的许多方面。例如，体重是个人摄入卡路里的函数；收入通常与教育和工作经验相关；而民意调查数字有助于估计总统候选人连任的机会。
- en: When such patterns are formulated with numbers, we gain additional clarity.
    For example, an additional 250 kilocalories consumed daily may result in nearly
    a kilogram of weight gain per month; each year of job experience may be worth
    an additional $1,000 in yearly salary; and a president is more likely to be re-elected
    when the economy is strong. Obviously, these equations do not perfectly fit every
    situation, but we expect that they are reasonably correct most of the time.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当用数字来表述这些模式时，我们能够获得额外的清晰度。例如，每天额外摄入250千卡路里可能会导致每月增加近1公斤的体重；每增加一年的工作经验可能会使年薪增加1000美元；当经济强劲时，总统更有可能获得连任。显然，这些方程并不完美地适用于每一种情况，但我们预期它们在大多数时候是相当准确的。
- en: 'This chapter extends our machine learning toolkit by going beyond the classification
    methods covered previously and introducing techniques for estimating relationships
    within numeric data. While examining several real-world numeric prediction tasks,
    you will learn:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章通过超越之前介绍的分类方法，并引入用于估计数值数据中关系的技巧，扩展了我们的机器学习工具箱。在考察几个现实世界的数值预测任务时，你将学习：
- en: The basic statistical principles used in regression, a technique that models
    the size and strength of numeric relationships
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归中使用的基本统计原理，这是一种模拟数值关系大小和强度的技术
- en: How to prepare data for regression analysis, estimate and interpret regression
    models, and apply regression variants such as generalized linear models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何为回归分析准备数据，估计和解释回归模型，以及应用回归变体，如广义线性模型
- en: A pair of hybrid techniques known as regression trees and model trees, which
    adapt decision tree classifiers for numeric prediction tasks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一对称为回归树和模型树的混合技术，这些技术将决策树分类器适应于数值预测任务
- en: Based on a large body of work in the field of statistics, the methods used in
    this chapter are a bit heavier on math than those covered previously, but don’t
    worry! Even if your algebra skills are a bit rusty, R takes care of the heavy
    lifting.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 基于统计学领域的丰富研究成果，本章所使用的方法在数学方面比之前介绍的方法更为复杂，但请放心！即使你的代数技能有些生疏，R语言会帮你处理繁重的工作。
- en: Understanding regression
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解回归
- en: Regression involves specifying the relationship between a single numeric **dependent
    variable** (the value to be predicted) and one or more numeric **independent variables**
    (the predictors). As the name implies, the dependent variable depends upon the
    value of the independent variable or variables. The simplest forms of regression
    assume that the relationship between the independent and dependent variables follows
    a straight line.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 回归涉及指定单个数值**因变量**（要预测的值）与一个或多个数值**自变量**（预测因子）之间的关系。正如其名称所暗示的，因变量依赖于自变量或变量的值。回归的最简单形式假设自变量和因变量之间的关系遵循一条直线。
- en: The origin of the term “regression” to describe the process of fitting lines
    to data is rooted in a study of genetics by Sir Francis Galton in the late 19th
    century. He discovered that fathers who were extremely short or tall tended to
    have sons whose heights were closer to the average height. He called this phenomenon
    “regression to the mean.”
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 术语“回归”用来描述将线拟合到数据的过程，其起源可以追溯到19世纪末弗朗西斯·高尔顿爵士对遗传学的研究。他发现，身高极矮或极高的父亲往往会有身高更接近平均值的儿子。他把这种现象称为“回归到平均值”。
- en: You might recall from basic algebra that lines can be defined in a **slope-intercept
    form** similar to *y* = *a* + *bx*. In this form, the letter *y* indicates the
    dependent variable and *x* indicates the independent variable. The **slope** term
    *b* specifies how much the line rises for each increase in *x*. Positive values
    define lines that slope upward while negative values define lines that slope downward.
    The term *a* is known as the **intercept** because it specifies the point where
    the line crosses, or intercepts, the vertical *y* axis. It indicates the value
    of *y* when *x* = 0.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得从基础代数中，直线可以用类似于 *y* = *a* + *bx* 的**斜率截距形式**来定义。在这种形式中，字母 *y* 表示因变量，*x*
    表示自变量。**斜率**项 *b* 指定了直线在 *x* 增加时上升的量。正值定义了向上倾斜的直线，而负值定义了向下倾斜的直线。项 *a* 被称为**截距**，因为它指定了直线与垂直
    *y* 轴相交或截取的点。它表示当 *x* = 0 时 *y* 的值。
- en: '![](img/B17290_06_01.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_06_01.png)'
- en: 'Figure 6.1: Examples of lines with various slopes and intercepts'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1：具有各种斜率和截距的直线示例
- en: Regression equations model data using a similar slope-intercept format. The
    machine’s job is to identify values of *a* and *b* such that the specified line
    is best able to relate the supplied *x* values to the values of *y*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 回归方程使用类似的斜率截距格式来模拟数据。机器的任务是确定* a* 和 *b* 的值，使得指定的直线最能将提供的 *x* 值与 *y* 的值联系起来。
- en: There may not always be a single set of *a* and *b* parameters that perfectly
    relates the values, so the machine must also have some way to quantify the margin
    of error and choose the best fit. We’ll discuss this in depth shortly.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 可能并不总是存在一组完美的 *a* 和 *b* 参数来完美地关联这些值，因此机器还必须有一些方法来量化误差范围并选择最佳拟合。我们将在稍后深入讨论这个问题。
- en: 'Regression analysis is used for a huge variety of tasks—it is almost surely
    the most widely used machine learning method. It can be used both for explaining
    the past and extrapolating into the future and can be applied to nearly any task.
    Some specific use cases include:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析被用于各种任务——它几乎肯定是应用最广泛的机器学习方法。它可以用于解释过去并预测未来，并且可以应用于几乎任何任务。一些具体的用例包括：
- en: Examining how populations and individuals vary by their measured characteristics,
    in scientific studies in the fields of economics, sociology, psychology, physics,
    and ecology
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检验人口和个体通过其测量的特征如何变化，这在经济学、社会学、心理学、物理学和生态学等科学研究中
- en: Quantifying the causal relationship between an event and its response, in cases
    such as clinical drug trials, engineering safety tests, or market research
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量化事件与其响应之间的因果关系，例如在临床试验、工程安全测试或市场研究中
- en: Identifying patterns that can be used to forecast future behavior given known
    criteria, such as for predicting insurance claims, natural disaster damage, election
    results, and crime rates
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别可以使用已知标准来预测未来行为的模式，例如用于预测保险索赔、自然灾害损失、选举结果和犯罪率
- en: Regression methods are also used for **statistical hypothesis testing**, which
    determines whether a premise is likely to be true or false in light of observed
    data. The regression model’s estimates of the strength and consistency of a relationship
    provide information that can be used to assess whether the observations are due
    to chance alone.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 回归方法也用于**统计假设检验**，这决定了在观察数据的基础上，一个前提是否可能是真实的或错误的。回归模型对关系强度和一致性的估计提供了可用于评估观察结果是否仅由偶然性引起的信息。
- en: Hypothesis testing is extremely nuanced and falls outside the scope of machine
    learning. If you are interested in this topic, an introductory statistics textbook
    is a good place to get started, for instance, *Intuitive Introductory Statistics,
    Wolfe, D. A. and Schneider, G., Springer, 2017*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设检验非常微妙，超出了机器学习的范围。如果你对这个主题感兴趣，一本入门统计学教科书是一个好的起点，例如，*直观入门统计学，沃尔夫，D. A. 和施奈德，G.，斯普林格，2017*。
- en: Regression analysis is not synonymous with a single algorithm. Rather, it is
    an umbrella term for many methods, which can be adapted to nearly any machine
    learning task. If you were limited to choosing only a single machine learning
    method to study, regression would be a good choice. One could devote an entire
    career to nothing else and perhaps still have much to learn.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析并不等同于单个算法。相反，它是一个涵盖许多方法的术语，这些方法可以适应几乎任何机器学习任务。如果你只能选择一个机器学习方法来研究，回归将是一个不错的选择。一个人可能可以将整个职业生涯都投入到这个领域，也许仍然有很多东西要学习。
- en: In this chapter, we’ll start with the most basic **linear regression** models—those
    that use straight lines. The case when there is only a single independent variable
    is known as **simple linear regression**. In the case of two or more independent
    variables, it is known as **multiple linear regression**, or simply **multiple
    regression**. Both techniques assume a single dependent variable, which is measured
    on a continuous scale.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从最基本的**线性回归**模型开始——那些使用直线的模型。只有一个自变量的情况被称为**简单线性回归**。有两个或更多自变量的情况被称为**多元线性回归**，或简称**多元回归**。这两种技术都假设有一个单一的因变量，它在连续尺度上被测量。
- en: Regression can also be used for other types of dependent variables and even
    for some classification tasks. For instance, **logistic regression** is used to
    model a binary categorical outcome, while **Poisson regression**—named after the
    French mathematician Siméon Poisson—models integer count data. The method known
    as **multinomial logistic regression** models a categorical outcome and can therefore
    be used for classification.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 回归还可以用于其他类型的因变量，甚至可以用于某些分类任务。例如，**逻辑回归**用于建模二元分类结果，而**泊松回归**（以法国数学家西莫恩·泊松的名字命名）用于建模整数计数数据。被称为**多项式逻辑回归**的方法用于建模分类结果，因此可以用于分类。
- en: These specialized regression methods fall into the class of **generalized linear
    models** (**GLMs**), which adapt the straight lines of traditional regression
    models to allow the modeling of other forms of data. These will be described later
    in this chapter.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些专门的回归方法属于**广义线性模型**（**GLMs**）类别，它们将传统回归模型的直线调整为允许建模其他形式的数据。这些将在本章后面进行描述。
- en: Because similar statistical principles apply across all regression methods,
    once you understand the linear case, learning about the other variants is straightforward.
    We’ll begin with the basic case of simple linear regression. Despite the name,
    this method is not too simple to address complex problems. In the next section,
    we’ll see how the use of a simple linear regression model might have averted a
    tragic engineering disaster.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于类似的统计原理适用于所有回归方法，一旦你理解了线性情况，了解其他变体就变得简单直接。我们将从简单线性回归的基本情况开始。尽管名称上看似简单，但这种方法并不简单到无法解决复杂问题。在下一节中，我们将看到简单线性回归模型的使用如何可能避免一场悲剧性的工程灾难。
- en: Simple linear regression
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单线性回归
- en: On January 28th, 1986, seven crew members of the United States space shuttle
    *Challenger* were killed when a rocket booster failed, causing a catastrophic
    disintegration. In the aftermath, experts quickly focused on the launch temperature
    as a potential culprit. The rubber O-rings responsible for sealing the rocket
    joints had never been tested below 40![](img/B17290_06_001.png)F (4![](img/B17290_06_001.png)C),
    and the weather on launch day was unusually cold and below freezing.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 1986年1月28日，美国航天飞机“挑战者”号的七名机组人员在火箭助推器故障导致灾难性解体时丧生。在事故发生后，专家们迅速将发射温度视为潜在的罪魁祸首。负责密封火箭接头的橡胶O形圈从未在40°F（4°C）以下进行过测试！[](img/B17290_06_001.png)F
    (4![](img/B17290_06_001.png)C)，而发射当天的天气异常寒冷，低于冰点。
- en: With the benefit of hindsight, the accident has been a case study for the importance
    of data analysis and visualization. Although it is unclear what information was
    available to the rocket engineers and decision-makers leading up to the launch,
    it is undeniable that better data, utilized carefully, might very well have averted
    this disaster.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 借助事后诸葛的优势，这次事故已成为数据分析可视化的重要性案例研究。尽管不清楚火箭工程师和决策者在发射前可以获得哪些信息，但不可否认的是，更好的数据，如果被谨慎使用，很可能避免这场灾难。
- en: 'This section’s analysis is based on data presented in *Risk Analysis of the
    Space Shuttle: Pre-Challenger Prediction of Failure, Dalal, S. R., Fowlkes, E.
    B., and Hoadley, B., Journal of the American Statistical Association, 1989, Vol.
    84, pp. 945-957*. For one perspective on how data may have changed the result,
    see *Visual Explanations: Images And Quantities, Evidence And Narrative, Tufte,
    E. R., Cheshire, C. T.: Graphics Press, 1997*. For a counterpoint, see *Representation
    and misrepresentation: Tufte and the Morton Thiokol engineers on the Challenger,
    Robison, W., Boisjoly, R., Hoeker, D., and Young, S., Science and Engineering
    Ethics, 2002, Vol. 8, pp. 59-81*.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的分析基于*《航天飞机风险分析：挑战者号之前的故障预测》，Dalal, S. R., Fowlkes, E. B., 和 Hoadley, B.，美国统计学会杂志，1989年，第84卷，第945-957页*中呈现的数据。关于数据如何可能改变结果的一个观点，请参阅*《视觉解释：图像与数量，证据与叙事》，Tufte,
    E. R.，Cheshire, C. T.：Graphics Press，1997年*。对于相反的观点，请参阅*《表现与误表现：图夫特与挑战者号上的莫顿·索尔科工程师》，Robison,
    W.，Boisjoly, R.，Hoeker, D.，和 Young, S.，《科学和工程伦理》，2002年，第8卷，第59-81页*。
- en: The rocket engineers almost certainly knew that cold temperatures could make
    the components more brittle and less able to seal properly, which would result
    in a higher chance of a dangerous fuel leak. However, given the political pressure
    to continue with the launch, they needed data to support this hypothesis. A regression
    model that demonstrated a link between temperature and O-ring failures, and could
    forecast the chance of failure given the expected temperature at launch, might
    have been very helpful.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 火箭工程师几乎肯定知道低温会使组件变得更加脆弱，密封性能降低，这会导致危险燃料泄漏的概率增加。然而，鉴于继续发射的政治压力，他们需要数据来支持这一假设。一个展示温度与O形圈故障之间联系的回归模型，并且能够根据预期的发射温度预测故障概率，可能会非常有帮助。
- en: 'To build the regression model, the scientists might have used the data on launch
    temperature and component distress recorded during the 23 previous successful
    shuttle launches. Component distress indicates one of two types of problems. The
    first problem, called erosion, occurs when excessive heat burns up the O-ring.
    The second problem, called blow-by, occurs when hot gasses leak through or “blow
    by” a poorly sealed O-ring. Since the shuttle had a total of six primary O-rings,
    up to six distresses could occur per flight. Though the rocket could survive one
    or more distress events or be destroyed with as few as one, each additional distress
    increased the probability of a catastrophic failure. The following scatterplot
    shows a plot of primary O-ring distresses detected for the previous 23 launches,
    as compared to the temperature at launch:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建回归模型，科学家可能使用了在23次之前成功的航天飞机发射中记录的发射温度和组件故障的数据。组件故障表明两种类型的问题之一。第一种问题，称为侵蚀，发生在过度的热量烧毁O形圈时。第二种问题，称为吹过，发生在热气体通过或“吹过”密封不良的O形圈时。由于航天飞机共有六个主要O形圈，每次飞行可能发生多达六个故障。尽管火箭可以生存一个或多个故障事件或被一个故障摧毁，但每个额外的故障都会增加灾难性故障的概率。以下散点图显示了之前23次发射检测到的初级O形圈故障，与发射温度的对比：
- en: '![Chart, scatter chart  Description automatically generated](img/B17290_06_02.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图表，散点图  描述自动生成](img/B17290_06_02.png)'
- en: 'Figure 6.2: A visualization of space shuttle O-ring distresses versus launch
    temperature'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2：航天飞机O形圈故障与发射温度的可视化
- en: 'Examining the plot, there is an apparent trend: launches occurring at higher
    temperatures tend to have fewer O-ring distress events. Additionally, the coldest
    launch (53![](img/B17290_06_001.png)F) had two distress events, a level that had
    only been reached in one other launch. With this information in mind, the fact
    that the Challenger was scheduled to launch in conditions more than 20 degrees
    colder seems concerning. But exactly how concerned should they have been? To answer
    this question, we can turn to simple linear regression.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 检查图表，存在一个明显的趋势：在较高温度下进行的发射往往有较少的O形圈故障事件。此外，最冷的发射（53°F）发生了两个故障事件，这个水平只在另一次发射中达到。考虑到这些信息，挑战者号计划在比这低20多度的条件下发射似乎令人担忧。但他们应该有多担心？为了回答这个问题，我们可以转向简单线性回归。
- en: 'A simple linear regression model defines the relationship between a dependent
    variable and a single independent predictor variable using a line defined by an
    equation in the following form:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归模型定义了因变量与单个自变量预测变量之间的关系，使用以下形式的方程定义的线：
- en: '![](img/B17290_06_004.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图片，散点图  自动生成的描述](img/B17290_06_004.png)'
- en: Aside from the Greek characters, this equation is virtually identical to the
    slope-intercept form described previously. The intercept, ![](img/B17290_06_005.png)
    (alpha), describes where the line crosses the *y* axis, while the slope, ![](img/B17290_06_006.png)
    (beta), describes the change in *y* given an increase of *x*. For the shuttle
    launch data, the slope would tell us the expected change in O-ring failures for
    each degree the launch temperature increases.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了希腊字母外，这个方程几乎与之前描述的斜截式相同。截距 ![](img/B17290_06_005.png)（alpha）描述了直线与 *y* 轴的交点，而斜率
    ![](img/B17290_06_006.png)（beta）描述了在 *x* 增加时 *y* 的变化。对于航天飞机发射数据，斜率将告诉我们发射温度每增加一度，O形圈故障预期的变化。
- en: Greek characters are often used in the field of statistics to indicate variables
    that are parameters of a statistical function. Therefore, performing a regression
    analysis involves finding **parameter estimates** for ![](img/B17290_06_007.png)
    and ![](img/B17290_06_008.png). The parameter estimates for alpha and beta are
    typically denoted using *a* and *b*, although you may find that some of this terminology
    and notation is used interchangeably.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学领域，希腊字母通常用于表示统计函数的参数变量。因此，进行回归分析涉及找到 ![](img/B17290_06_007.png) 和 ![](img/B17290_06_008.png)
    的**参数估计**。alpha和beta的参数估计通常用 *a* 和 *b* 表示，尽管你可能发现一些术语和符号被交替使用。
- en: 'Suppose we know that the estimated regression parameters in the equation for
    the shuttle launch data are *a* = 3.70 and *b* = -0.048\. Consequently, the full
    linear equation is *y* = 3.70 – 0.048x. Ignoring for a moment how these numbers
    were obtained, we can plot the line on the scatterplot like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们知道航天飞机发射数据方程中估计的回归参数是 *a* = 3.70 和 *b* = -0.048。因此，完整的线性方程是 *y* = 3.70 –
    0.048x。暂时忽略这些数字是如何得到的，我们可以像这样在散点图上绘制这条线：
- en: '![Chart, line chart, scatter chart  Description automatically generated](img/B17290_06_03.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图表，折线图，散点图  自动生成描述](img/B17290_06_03.png)'
- en: 'Figure 6.3: A regression line modeling the relationship between distress events
    and launch temperature'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3：一个回归线，用于模拟压力事件与发射温度之间的关系
- en: As the line shows, at 60 degrees Fahrenheit, we predict less than one O-ring
    distress event. At 50 degrees Fahrenheit, we expect around 1.3 failures. If we
    use the model to extrapolate all the way out to 31 degrees—the forecasted temperature
    for the Challenger launch—we would expect about *3.70 - 0.048 * 31 = 2.21* O-ring
    distress events.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如线所示，在60华氏度时，我们预测不到一个O形圈的故障事件。在50华氏度时，我们预计大约有1.3次故障。如果我们使用该模型外推到31度——挑战者号预测的温度——我们预计大约会有
    *3.70 - 0.048 * 31 = 2.21* 次O形圈的故障事件。
- en: Assuming that each O-ring failure is equally likely to cause a catastrophic
    fuel leak, this means that the Challenger launch at 31 degrees was nearly three
    times riskier than the typical launch at 60 degrees, and over eight times riskier
    than a launch at 70 degrees.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 假设每个O形圈故障同样可能引起灾难性的燃料泄漏，这意味着挑战者号在31度发射的风险几乎是60度典型发射的三倍，比70度发射的风险超过八倍。
- en: Notice that the line doesn’t pass through each data point exactly. Instead,
    it cuts through the data somewhat evenly, with some predictions lower or higher
    than the line. In the next section, we will learn why this particular line was
    chosen.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到直线并没有精确地穿过每个数据点。相反，它在大约均匀地穿过数据，一些预测值低于或高于直线。在下一节中，我们将学习为什么选择这条特定的线。
- en: Ordinary least squares estimation
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 普通最小二乘估计
- en: 'To determine the optimal estimates of ![](img/B17290_06_005.png) and ![](img/B17290_06_006.png)
    an estimation method known as **ordinary least squares** (**OLS**) is used. In
    OLS regression, the slope and intercept are chosen such that they minimize the
    **sum of the squared errors** (**SSE**). The errors, also known as **residuals**,
    are the vertical distance between the predicted *y* value and the actual *y* value.
    Because the errors can be over-estimates or under-estimates, they can be positive
    or negative values; squaring them makes the errors positive regardless of direction.
    The residuals are illustrated for several points in the following diagram:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定 ![](img/B17290_06_005.png) 和 ![](img/B17290_06_006.png) 的最佳估计值，使用了一种称为**普通最小二乘法**（OLS）的估计方法。在OLS回归中，斜率和截距被选择以最小化**平方误差和**（SSE）。误差，也称为**残差**，是预测的
    *y* 值与实际 *y* 值之间的垂直距离。由于误差可能是高估或低估，它们可以是正数或负数；平方它们使得误差无论方向如何都是正数。以下图表展示了几个点的残差：
- en: '![Chart, line chart  Description automatically generated](img/B17290_06_04.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图表，线形图  描述自动生成](img/B17290_06_04.png)'
- en: 'Figure 6.4: The regression line predictions differ from the actual values by
    a residual amount'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4：回归线的预测值与实际值之间的差异由残差量决定
- en: 'In mathematical terms, the goal of OLS regression can be expressed as the task
    of minimizing the following equation:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 用数学术语来说，OLS回归的目标可以表达为最小化以下方程的任务：
- en: '![](img/B17290_06_011.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片，图片编号B17290_06_011.png](img/B17290_06_011.png)'
- en: In plain language, this equation defines *e* (the error) as the difference between
    the actual *y* value and the predicted *y* value. The error values are squared
    to eliminate the negative values and summed across all points in the data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 用简单的话说，这个方程定义*e*（误差）为实际*y*值与预测*y*值之间的差异。误差值被平方以消除负值，并在数据中的所有点上进行求和。
- en: The caret character (^) above the *y* term is a commonly used feature of statistical
    notation. It indicates that the term is an estimate for the true *y* value. This
    is referred to as the *y hat*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在*y*项上方的撇号（^）是统计符号中常用的一个特征。它表示该项是对真实*y*值的估计。这被称为*y*的估计值。
- en: 'The solution for *a* depends on the value of *b*. It can be obtained using
    the following formula:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*a*的解取决于*b*的值。可以使用以下公式获得：'
- en: '![](img/B17290_06_012.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片，图片编号B17290_06_012.png](img/B17290_06_012.png)'
- en: To understand these equations, you’ll need to know another bit of statistical
    notation. The horizontal bar appearing over the *x* and *y* terms indicates the
    mean value of *x* or *y*. This is referred to as the *x* bar or *y* bar.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这些方程，你需要了解另一部分统计符号。出现在*x*和*y*项上方的水平横线表示*x*或*y*的均值值。这被称为*x*横或*y*横。
- en: 'Though the proof is beyond the scope of this book, it can be shown using calculus
    that the value of *b* that results in the minimum squared error is:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然证明超出了本书的范围，但可以使用微积分证明，导致最小平方误差的*b*的值是：
- en: '![](img/B17290_06_013.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片，图片编号B17290_06_013.png](img/B17290_06_013.png)'
- en: 'If we break this equation apart into its component pieces, we can simplify
    it somewhat. The denominator for *b* should look familiar; it is very similar
    to the variance of *x*, which is denoted as Var(*x*). As we learned in *Chapter
    2*, *Managing and Understanding Data*, the variance involves finding the average
    squared deviation from the mean of *x*. This can be expressed as:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这个方程分解为其组成部分，我们可以稍微简化它。*b*的分母应该看起来很熟悉；它与*x*的方差非常相似，表示为Var(*x*)。正如我们在*第2章*，*管理和理解数据*中学到的，方差涉及找到*x*的均值与均值的平均平方偏差。这可以表示为：
- en: '![](img/B17290_06_014.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片，图片编号B17290_06_014.png](img/B17290_06_014.png)'
- en: 'The numerator involves taking the sum of each data point’s deviation from the
    mean *x* value multiplied by that point’s deviation away from the mean *y* value.
    This is similar to the covariance function for *x* and *y*, denoted as Cov(*x*,
    *y*). The covariance formula is:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 分子涉及将每个数据点的偏差（与均值*x*值的偏差）乘以该点偏离均值*y*值的偏差之和。这与*x*和*y*的协方差函数类似，表示为Cov(*x*, *y*)。协方差公式是：
- en: '![](img/B17290_06_015.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片，图片编号B17290_06_015.png](img/B17290_06_015.png)'
- en: 'If we divide the covariance function by the variance function, the *n* terms
    in the numerator and denominator cancel each other out and we can rewrite the
    formula for *b* as:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将协方差函数除以方差函数，分子和分母中的*n*项会相互抵消，我们可以将*b*的公式重写为：
- en: '![](img/B17290_06_016.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片，线形图  自动生成描述](img/B17290_06_016.png)'
- en: Given this restatement, it is easy to calculate the value of *b* using built-in
    R functions. Let’s apply them to the shuttle launch data to estimate the regression
    line.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 给出这种重述后，使用内置的R函数很容易计算出*b*的值。让我们将它们应用于航天飞机发射数据来估计回归线。
- en: If you would like to follow along with these examples, download the `challenger.csv`
    file from the Packt Publishing website and load it to a data frame using the `launch
    <- read.csv("challenger.csv")` command.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想跟随这些示例，请从Packt Publishing网站下载`challenger.csv`文件，并使用`launch <- read.csv("challenger.csv")`命令将其加载到数据框中。
- en: 'If the shuttle launch data is stored in a data frame named `launch`, the independent
    variable *x* is named `temperature`, and the dependent variable *y* is named `distress_ct`,
    we can then use the R functions `cov()` and `var()` to estimate `b`:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果航天飞机数据存储在名为`launch`的数据框中，自变量*x*命名为`temperature`，因变量*y*命名为`distress_ct`，则可以使用R函数`cov()`和`var()`来估计*b*：
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can then estimate `a` by using the computed `b` value and applying the `mean()`
    function:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过使用计算出的`b`值并应用`mean()`函数来估计`a`：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Estimating the regression equation by hand is obviously less than ideal, so
    R predictably provides a function for fitting regression models automatically.
    We will use this function shortly. Before that, it is important to expand your
    understanding of the regression model’s fit by first learning a method for measuring
    the strength of a linear relationship. Additionally, you will soon learn how to
    apply multiple linear regression to problems with more than one independent variable.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 手动估计回归方程显然不是最佳选择，因此 R 预期地提供了一个用于自动拟合回归模型的功能。我们很快就会使用这个功能。在此之前，通过首先学习一种衡量线性关系强度的方法，来扩展你对回归模型拟合的理解是很重要的。此外，你很快就会学习如何将多元线性回归应用于具有多个自变量的问题。
- en: Correlations
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关性
- en: The **correlation** between two variables is a number that indicates how closely
    their relationship follows a straight line. Without additional qualification,
    correlation typically refers to the **Pearson correlation coefficient**, which
    was developed by the 20th-century mathematician Karl Pearson. A correlation falls
    in the range between -1 to +1\. The maximum and minimum values indicate a perfectly
    linear relationship, while a correlation close to zero indicates the absence of
    a linear relationship.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 两个变量之间的**相关性**是一个数字，表示它们之间的关系有多接近一条直线。如果没有额外的限定，相关性通常指的是**皮尔逊相关系数**，这是20世纪数学家卡尔·皮尔逊开发的。相关性的范围在
    -1 到 +1 之间。最大值和最小值表示完全的线性关系，而接近零的相关性表示没有线性关系。
- en: 'The following formula defines Pearson’s correlation:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下公式定义了皮尔逊相关系数：
- en: '![](img/B17290_06_017.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_06_017.png)'
- en: 'More Greek notation has been introduced here: the first symbol (which looks
    like a lowercase *p*) is *rho*, and it is used to denote the Pearson correlation
    statistic. The symbols that look like *q* characters rotated counterclockwise
    are the lowercase Greek letter *sigma*, and they indicate the standard deviation
    of *x* or *y*.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这里引入了更多的希腊符号：第一个符号（看起来像小写的 *p*）是 *rho*，它用来表示皮尔逊相关统计量。看起来像 *q* 字符逆时针旋转的符号是希腊字母小写
    *sigma*，它们表示 *x* 或 *y* 的标准差。
- en: 'Using this formula, we can calculate the correlation between the launch temperature
    and the number of O-ring distress events. Recall that the covariance function
    is `cov()` and the standard deviation function is `sd()`. We’ll store the result
    in `r`, a letter that is commonly used to indicate the estimated correlation:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个公式，我们可以计算发射温度和 O 型圈故障事件数之间的相关性。回想一下，协方差函数是 `cov()`，标准差函数是 `sd()`。我们将结果存储在
    `r` 中，这是一个常用来表示估计相关性的字母：
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Alternatively, we can obtain the same result with the `cor()` correlation function:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用 `cor()` 相关函数得到相同的结果：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The correlation between the temperature and the number of distressed O-rings
    is -0.51\. The negative correlation implies that increases in temperature are
    related to decreases in the number of distressed O-rings. To the NASA engineers
    studying the O-ring data, this would have been a very clear indicator that a low-temperature
    launch could be problematic. The correlation also tells us about the relative
    strength of the relationship between temperature and O-ring distress. Because
    -0.51 is halfway to the maximum negative correlation of -1, this implies that
    there is a moderately strong negative linear association.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 温度和故障 O 型圈数量之间的相关系数是 -0.51。负相关性表明温度的增加与故障 O 型圈数量的减少有关。对于研究 O 型圈数据的 NASA 工程师来说，这将是一个非常明确的指标，表明低温发射可能存在问题。相关性还告诉我们温度和
    O 型圈故障之间的相对强度。因为 -0.51 是最大负相关系数 -1 的一半，这意味着存在中等强度的负线性关联。
- en: There are various rules of thumb used to interpret correlation strength. One
    method assigns a status of “weak” to values between 0.1 and 0.3; “moderate” to
    the range of 0.3 to 0.5; and “strong” to values above 0.5 (these also apply to
    similar ranges of negative correlations). However, these thresholds may be too
    strict or too lax for certain purposes. Often, the correlation must be interpreted
    in context.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释相关性强度方面，有许多经验法则。一种方法是将 0.1 到 0.3 之间的值标记为“弱”；0.3 到 0.5 之间的范围标记为“中等”；而高于 0.5
    的值标记为“强”（这些也适用于类似范围的负相关性）。然而，这些阈值对于某些目的可能过于严格或过于宽松。通常，相关性必须在特定背景下进行解释。
- en: For data involving human beings, a correlation of 0.5 may be considered very
    high; for data generated by mechanical processes, a correlation of 0.5 may be
    very weak.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于涉及人类的数据，0.5 的相关性可能被认为非常高；对于由机械过程生成的数据，0.5 的相关性可能非常弱。
- en: 'You have probably heard the expression “correlation does not imply causation.”
    This is rooted in the fact that a correlation only describes the association between
    a pair of variables, yet there could be other explanations that are unaccounted
    for and responsible for the observed relationship. For example, there may be a
    strong correlation between life expectancy and time per day spent watching movies,
    but before doctors recommend that we all watch more movies, we need to rule out
    another explanation: younger people watch more movies and younger people are (in
    general) less likely to die.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过“相关性不等于因果关系”这个说法。这源于这样一个事实，即相关性仅描述了一对变量之间的关联，但可能存在其他未考虑的解释，这些解释可能是观察到的关系的责任。例如，寿命与每天观看电影的时间之间可能存在强烈的关联，但在医生建议我们所有人都看更多电影之前，我们需要排除另一个解释：年轻人看更多的电影，而年轻人（总的来说）不太可能死亡。
- en: Measuring the correlation between two variables gives us a way to quickly check
    for linear relationships between independent variables and the dependent variable.
    This will be increasingly important as we start defining regression models with
    a larger number of predictors.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 测量两个变量之间的相关性为我们提供了一种快速检查独立变量和因变量之间线性关系的方法。随着我们开始定义具有更多预测因子的回归模型，这一点将变得越来越重要。
- en: Multiple linear regression
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多元线性回归
- en: 'Most real-world analyses have more than one independent variable. Therefore,
    it is likely that you will be using multiple linear regression for most numeric
    prediction tasks. The strengths and weaknesses of multiple linear regression are
    shown in the following table:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现实世界的分析都有多个自变量。因此，你很可能会在大多数数值预测任务中使用多元线性回归。多元线性回归的优缺点如下表所示：
- en: '| **Strengths** | **Weaknesses** |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| **优点** | **缺点** |'
- en: '|'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: By far the most common approach to modeling numeric data
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到目前为止，建模数值数据最常见的方法
- en: Can be adapted to model almost any modeling task
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以适应几乎任何建模任务
- en: Provides estimates of both the size and strength of the relationships among
    features and the outcome
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了特征和结果之间关系的大小和强度的估计
- en: '|'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Makes strong assumptions about the data
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据有强烈的假设
- en: The model’s form must be specified by the user in advance
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的形式必须由用户事先指定
- en: Does not handle missing data
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无法处理缺失数据
- en: Only works with numeric features, so categorical data requires additional preparation
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只适用于数值特征，因此分类数据需要额外的准备
- en: Requires some knowledge of statistics to understand the model
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一些统计学知识来理解模型
- en: '|'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: We can understand multiple regression as an extension of simple linear regression.
    The goal in both cases is similar—to find values of slope coefficients that minimize
    the prediction error of a linear equation. The key difference is that there are
    additional terms for the additional independent variables.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将多元回归视为简单线性回归的扩展。在两种情况下，目标都是相似的——找到斜率系数的值，以最小化线性方程的预测误差。关键的区别是，对于额外的自变量，有额外的项。
- en: 'Multiple regression models take the form of the following equation. The dependent
    variable *y* is specified as the sum of an intercept term ![](img/B17290_06_005.png)
    plus the product of the estimated ![](img/B17290_06_006.png) value and the *x*
    variable for each of *i* features. An error term ![](img/B17290_06_020.png) (denoted
    by the Greek letter *epsilon*) has been added here as a reminder that the predictions
    are not perfect. This represents the residual term noted previously:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 多元回归模型具有以下方程的形式。因变量 *y* 被指定为截距项 ![](img/B17290_06_005.png) 与每个 *i* 个特征对应的估计值
    ![](img/B17290_06_006.png) 与 *x* 变量的乘积之和。这里增加了一个误差项 ![](img/B17290_06_020.png)（用希腊字母
    *epsilon* 表示），作为提醒预测并不完美。这代表了之前提到的残差项：
- en: '![](img/B17290_06_021.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_06_021.png)'
- en: Let’s consider for a moment the interpretation of the estimated regression parameters.
    You will note that in the preceding equation, a coefficient is provided for each
    feature. This allows each feature to have a separate estimated effect on the value
    of *y*. In other words, *y* changes by the amount ![](img/B17290_06_022.png) for
    each unit increase in feature ![](img/B17290_06_023.png). The intercept ![](img/B17290_06_005.png)
    is then the expected value of *y* when the independent variables are all zero.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时考虑一下估计的回归参数的解释。你会注意到，在前面的方程中，为每个特征提供了一个系数。这允许每个特征对 *y* 的值有单独的估计影响。换句话说，当特征
    ![img/B17290_06_023.png] 每增加一个单位时，*y* 的变化量为 ![img/B17290_06_022.png]。因此，截距 ![img/B17290_06_005.png]
    是当独立变量都为零时 *y* 的期望值。
- en: 'Since the intercept term ![](img/B17290_06_005.png) is really no different
    than any other regression parameter, it is also sometimes denoted as ![](img/B17290_06_024.png)
    (pronounced *beta naught*) as shown in the following equation:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于截距项 ![img/B17290_06_005.png] 真的与其他任何回归参数没有区别，它有时也用 ![img/B17290_06_024.png]
    （发音为 *beta naught*）表示，如下面的公式所示：
- en: '![](img/B17290_06_025.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![img/B17290_06_025.png]'
- en: 'Just like before, the intercept is unrelated to any of the independent *x*
    variables. However, for reasons that will become clear shortly, it helps to imagine
    ![](img/B17290_06_024.png) as if it were being multiplied by a term *x*[0]. We
    assign *x*[0] to be a constant with the value of 1:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前一样，截距与任何独立变量 *x* 都无关。然而，由于以下原因将在短时间内变得清楚，想象 ![img/B17290_06_024.png] 被乘以一个项
    *x*[0] 有助于理解。我们将 *x*[0] 分配为一个常量，其值为1：
- en: '![](img/B17290_06_027.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![img/B17290_06_027.png]'
- en: 'To estimate the regression parameters, each observed value of the dependent
    variable *y* must be related to observed values of the independent *x* variables
    using the regression equation in the previous form. The following figure is a
    graphical representation of the setup of a multiple regression task:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了估计回归参数，必须将因变量 *y* 的每个观测值与独立变量 *x* 的观测值通过前面形式的回归方程联系起来。以下图是多个回归任务设置的图形表示：
- en: '![Diagram  Description automatically generated](img/B17290_06_05.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![Diagram Description automatically generated](img/B17290_06_05.png)'
- en: 'Figure 6.5: Multiple regression seeks to find the ![](img/B17290_06_006.png)
    values that relate the X values to Y while minimizing ![](img/B17290_06_020.png)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5：多重回归试图找到![img/B17290_06_006.png]值，这些值将X值与Y值相关联，同时最小化![img/B17290_06_020.png]
- en: 'The many rows and columns of data illustrated in the preceding figure can be
    described in a condensed formulation using **matrix notation** in bold font to
    indicate that each of the terms represents multiple values. Simplified in this
    way, the formula is as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图中所展示的许多行和列的数据可以用加粗的矩阵符号来压缩表示，以表明每个项代表多个值。以这种方式简化后，公式如下：
- en: '![](img/B17290_06_030.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![img/B17290_06_030.png]'
- en: In matrix notation, the dependent variable is a vector, **Y**, with a row for
    every example. The independent variables have been combined into a matrix, **X**,
    with a column for each feature plus an additional column of 1 values for the intercept.
    Each column has a row for every example. The regression coefficients ![](img/B17290_06_031.png)
    and residual errors **![](img/_eqn_032.png)** are also now vectors.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在矩阵表示法中，因变量是一个向量，**Y**，其中每一行代表一个示例。独立变量被组合成一个矩阵，**X**，其中每一列代表一个特征，还有一个额外的截距列，值为1。每一列都有每一行的示例。回归系数
    ![img/B17290_06_031.png] 和残差误差 **![img/_eqn_032.png]** 现在也是向量。
- en: 'The goal now is to solve for ![](img/B17290_06_031.png), the vector of regression
    coefficients that minimizes the sum of the squared errors between the predicted
    and actual **Y** values. Finding the optimal solution requires the use of matrix
    algebra; therefore, the derivation deserves more careful attention than can be
    provided in this text. However, if you’re willing to trust the work of others,
    the best estimate of the vector ![](img/B17290_06_031.png) can be computed as:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 目标现在是要求解![img/B17290_06_031.png]，这是使预测值和实际**Y**值之间平方误差和最小的回归系数向量。找到最优解需要使用矩阵代数；因此，推导需要比本文中提供的更仔细的注意。然而，如果你愿意相信他人的工作，向量![img/B17290_06_031.png]的最佳估计可以计算如下：
- en: '![](img/B17290_06_034.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![img/B17290_06_034.png]'
- en: 'This solution uses a pair of matrix operations: the **T** indicates the transpose
    of matrix **X**, while the negative exponent indicates the **matrix inverse**.
    Using R’s built-in matrix operations, we can thus implement a simple multiple
    regression learner. Let’s apply this formula to the Challenger launch data.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案使用了一对矩阵运算：**T** 表示矩阵 **X** 的转置，而负指数表示 **矩阵逆**。利用 R 的内置矩阵运算，我们可以实现一个简单的多元回归学习器。让我们将这个公式应用到挑战者号发射数据上。
- en: If you are unfamiliar with the preceding matrix operations, the Wolfram MathWorld
    pages for transpose ([http://mathworld.wolfram.com/Transpose.html](http://mathworld.wolfram.com/Transpose.html))
    and matrix inverse ([http://mathworld.wolfram.com/MatrixInverse.html](http://mathworld.wolfram.com/MatrixInverse.html))
    provide a thorough introduction and are understandable even without an advanced
    mathematics background.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对前面的矩阵运算不熟悉，Wolfram MathWorld 的转置页面 ([http://mathworld.wolfram.com/Transpose.html](http://mathworld.wolfram.com/Transpose.html))
    和矩阵逆页面 ([http://mathworld.wolfram.com/MatrixInverse.html](http://mathworld.wolfram.com/MatrixInverse.html))
    提供了全面的介绍，即使没有高级数学背景也能理解。
- en: 'Using the following code, we can create a basic regression function named `reg()`,
    which takes a parameter `y` and a parameter `x`, and returns a vector of estimated
    beta coefficients:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码，我们可以创建一个名为 `reg()` 的基本回归函数，它接受参数 `y` 和 `x`，并返回一个估计的贝塔系数向量：
- en: '[PRE8]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `reg()` function created here uses several R commands that we have not used
    previously. First, since we will be using the function with sets of columns from
    a data frame, the `as.matrix()` function converts the data frame into matrix form.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里创建的 `reg()` 函数使用了几个我们之前没有用过的 R 命令。首先，由于我们将使用该函数与数据框的列集一起使用，`as.matrix()` 函数将数据框转换为矩阵形式。
- en: 'Next, the `cbind()` function binds an additional column onto the `x` matrix;
    the command `Intercept = 1` instructs R to name the new column `Intercept` and
    to fill the column with repeating `1` values. Then, a series of matrix operations
    are performed on the `x` and `y` objects:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，`cbind()` 函数将一个额外的列绑定到 `x` 矩阵上；命令 `Intercept = 1` 指示 R 将新列命名为 `Intercept`
    并用重复的 `1` 值填充该列。然后，对 `x` 和 `y` 对象执行一系列矩阵运算：
- en: '`solve()` takes the inverse of a matrix'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`solve()` 取矩阵的逆'
- en: '`t()` is used to transpose a matrix'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t()` 用于矩阵的转置'
- en: '`%*%` multiplies two matrices'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`%*%` 用于两个矩阵的乘法'
- en: By combining these R functions as shown, our function will return a vector `b`,
    which contains estimated parameters for the linear model relating `x` to `y`.
    The final two lines in the function give the `b` vector a name and print the result
    on screen.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将这些 R 函数组合起来，我们的函数将返回一个向量 `b`，其中包含与 `x` 到 `y` 相关的线性模型的估计参数。函数中的最后两行给 `b` 向量命名并在屏幕上打印结果。
- en: 'Let’s apply this function to the shuttle launch data. As shown in the following
    code, the dataset includes three features and the distress count (`distress_ct`),
    which is the outcome of interest:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个函数应用到航天飞机发射数据上。如下面的代码所示，数据集包括三个特征和灾情计数（`distress_ct`），这是我们感兴趣的结果：
- en: '[PRE9]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can confirm that our function is working correctly by comparing its result
    for the simple linear regression model of O-ring failures versus temperature,
    which we found earlier to have parameters *a* = 3.70 and *b* = -0.048\. Since
    temperature is in the second column of the launch data, we can run the `reg()`
    function as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过比较其对于之前找到的 O 型环故障与温度的简单线性回归模型的结果来确认我们的函数是否正确工作，该模型具有参数 *a* = 3.70 和 *b*
    = -0.048。由于温度位于发射数据的第二列，我们可以如下运行 `reg()` 函数：
- en: '[PRE11]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'These values exactly match our prior result, so let’s use the function to build
    a multiple regression model. We’ll apply it just as before, but this time we will
    specify columns two through four for the `x` parameter to add two additional predictors:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值与我们之前的结果完全匹配，因此让我们使用这个函数来构建一个多元回归模型。我们将像之前一样应用它，但这次我们将指定 `x` 参数的第二到第四列以添加两个额外的预测因子：
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This model predicts the number of O-ring distress events using temperature,
    field check pressure, and the launch ID number. Notably, the inclusion of the
    two new predictors did not change our finding from the simple linear regression
    model. Just as before, the coefficient for the temperature variable is negative,
    which suggests that as temperature increases, the number of expected O-ring events
    decreases. The magnitude of the effect is also approximately the same: roughly
    0.05 fewer distress events are expected for each degree increase in launch temperature.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型使用温度、现场检查压力和发射ID号来预测O形圈故障事件的数量。值得注意的是，加入这两个新的预测因子并没有改变我们从简单线性回归模型中得到的结果。正如之前一样，温度变量的系数为负，这表明随着温度的升高，预期的O形圈事件数量会减少。这种影响的大小也大致相同：发射温度每增加一度，预计的故障事件将减少大约0.05次。
- en: The two new predictors also contribute to the predicted distress events. The
    field check pressure refers to the amount of pressure applied to the O-ring during
    pre-launch testing. Although the check pressure was originally 50 psi, it was
    raised to 100 and 200 psi for some launches, which led some to believe that it
    may be responsible for O-ring erosion. The coefficient is positive, but small,
    providing at least a little evidence for this hypothesis. The flight number accounts
    for the shuttle’s age. With each flight, it gets older, and parts may be more
    brittle or prone to fail. The small positive association between flight number
    and distress count may reflect this fact.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个新的预测因子也对预测的故障事件有贡献。现场检查压力是指在发射前测试中对O形圈施加的压力量。虽然检查压力最初是50磅力，但在某些发射中提高到100和200磅力，这导致一些人认为这可能是O形圈侵蚀的原因。系数为正，但很小，至少为这个假设提供了一些证据。飞行次数代表了航天飞机的年龄。每次飞行，它都会变老，部件可能会更脆弱或更容易损坏。飞行次数与故障计数之间的小的正相关可能反映了这一事实。
- en: Overall, our retrospective analysis of the space shuttle data suggests that
    there was reason to believe that the Challenger launch was highly risky given
    the weather conditions. Perhaps if the engineers had applied linear regression
    beforehand, a disaster could have been averted. Of course, the reality of the
    situation, and the political implications involved, were surely not as simple
    then as they now appear in hindsight.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，我们对航天飞机数据的回顾性分析表明，考虑到天气条件，挑战者号的发射风险很高。也许如果工程师们事先应用线性回归，灾难可能就可以避免。当然，当时的情况现实，以及涉及的政治影响，肯定没有现在回望时看起来那么简单。
- en: Generalized linear models and logistic regression
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 广义线性模型和逻辑回归
- en: As demonstrated in the analysis of the Challenger space shuttle launch data,
    standard linear regression is a useful method for modeling the relationship between
    a numeric outcome and one or more predictors. It is no wonder that regression
    has stood the test of time. Even after over a hundred years, it remains one of
    the most important techniques in our toolkit, even though it is no more sophisticated
    than finding the best straight line to fit the data.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如同在挑战者号航天飞机发射数据分析中所展示的那样，标准线性回归是用于建模数值结果与一个或多个预测因子之间关系的有用方法。回归能够经受时间的考验，这并不奇怪。即使在一百多年后，它仍然是我们工具箱中最重要的技术之一，尽管它并不比找到最佳直线来拟合数据更复杂。
- en: However, not every problem is well suited to being modeled by a line, and moreover,
    the statistical assumptions made by regression models are violated in many real-world
    tasks. Even the Challenger data is less than ideal for linear regression as it
    violates the regression assumption that the target variable is measured on a continuous
    scale. As the number of O-ring failures can only take countable values, it makes
    no sense that the model might predict exactly 2.21 distress events rather than
    either two or three.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非每个问题都适合用一条线来建模，而且，回归模型在许多实际任务中违反了统计假设。即使是挑战者号的数据，对于线性回归来说也不够理想，因为它违反了回归假设，即目标变量是在连续尺度上测量的。由于O形圈的故障次数只能取可数值，因此模型预测出恰好2.21次故障事件，而不是两个或三个，这是没有意义的。
- en: For modeling counting values, for categorical or binary outcomes, as well as
    other cases where the target is not a normally distributed continuous variable,
    standard linear regression is not the best tool for the job—even though many still
    apply it to these types of problems, and it often performs surprisingly well.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于建模计数值、分类或二元结果，以及其他目标变量不是正态分布的连续变量的情况，标准线性回归并不是最佳工具——尽管许多人仍然将这些类型的问题应用于它，并且它通常表现得相当出色。
- en: To address these shortcomings, linear regression can be adapted to other use
    cases using the aptly named GLM, which was first described in 1972 by statisticians
    John Nelder and Robert Wedderburn. The GLM loosens two assumptions of traditional
    regression modeling. First, it allows the target to be a non-normally distributed,
    non-continuous variable. Second, it allows the variance of the target variable
    to be related to its mean. The former property opens the door for modeling categorical
    data or counting data, or even cases where there is a limited range of values
    to predict, such as probability values falling on a range between 0 to 1\. The
    latter property allows the model to better fit cases where the predictors relate
    to the predictions in a nonlinear way, such as exponential growth in which an
    increase of one unit of time leads to greater and greater increases in the outcome.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些不足，可以使用名为GLM的适当名称来适应其他用例，该模型最早由统计学家John Nelder和Robert Wedderburn于1972年描述。GLM放宽了传统回归模型的两个假设。首先，它允许目标变量是非正态分布的、非连续变量。其次，它允许目标变量的方差与其均值相关。前者为建模分类数据或计数数据，甚至预测值范围有限的情况（例如，落在0到1之间的概率值）打开了大门。后者允许模型更好地拟合预测变量与预测以非线性方式相关的情况，例如指数增长，其中时间的增加导致结果的增加越来越大。
- en: To read the original publication about GLMs, see *Generalized linear models,
    Nelder, J. A. and Wedderburn, T. W. M., Journal of the Royal Statistical Society,
    1972, Vol. 135, pp. 370-384*. For a gentler, non-mathematical introduction, see
    *An introduction to generalized linear models, Dunteman, G. H. and Ho, M. H. R.,
    Quantitative Applications in the Social Sciences, 2006, Vol. 145*.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 要阅读关于广义线性模型（GLM）的原始出版物，请参阅*Nelder, J. A. 和 Wedderburn, T. W. M.，皇家统计学会杂志，1972年，第135卷，第370-384页*。对于更温和、非数学性的介绍，请参阅*Dunteman,
    G. H. 和 Ho, M. H. R.，社会科学定量应用，2006年，第145卷*。
- en: 'These two generalizations of linear regression are reflected in the two key
    components of any GLM:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种对线性回归的推广反映在任何GLM的两个关键组件中：
- en: The **family** refers to the distribution of the target feature, which must
    be chosen from members of the **exponential family** of distributions, which includes
    the normal Gaussian distribution as well as others like Poisson, Binomial, and
    Gamma. The chosen distribution may be discrete or continuous, and it may span
    different ranges of values, such as only positive values or only values between
    zero and one.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**家族**指的是目标特征的分布，必须从**指数分布族**的成员中选择，该族包括正态高斯分布以及其他如泊松、二项和伽马分布。所选分布可以是离散的或连续的，并且可以跨越不同的值范围，例如仅正数或仅介于零和一之间的值。'
- en: The **link function** transforms the relationship between the predictors and
    the target such that it can be modeled using a linear equation, despite the original
    relationship being nonlinear. There is always a **canonical link function**, which
    is determined by the chosen family and used by default, but in some cases, one
    may choose a different link to vary how the model is interpreted or to obtain
    a better model fit.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**链接函数**将预测变量与目标变量之间的关系转换为可以使用线性方程进行建模的形式，尽管原始关系是非线性的。始终存在一个**标准链接函数**，它由所选的家族确定并默认使用，但在某些情况下，可以选择不同的链接来改变模型的理解方式或获得更好的模型拟合。'
- en: 'Varying the family and link functions gives the GLM approach tremendous flexibility
    to adapt to many different real-world use cases and to conform to the natural
    distribution of the target variable. Knowing which combination to use depends
    on both how the model will be applied as well as the theoretical distribution
    of the target. Understanding these factors in detail requires knowledge of the
    various distributions in the exponential family and a background in statistical
    theory. Thankfully, most GLM use cases conform to a few common combinations of
    family and link, which are listed in the table that follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 调整家族和链接函数使广义线性模型（GLM）方法具有极大的灵活性，以适应许多不同的实际应用场景，并符合目标变量的自然分布。了解使用哪种组合取决于模型的应用方式以及目标变量的理论分布。详细了解这些因素需要了解指数族中的各种分布以及统计学理论背景。幸运的是，大多数广义线性模型（GLM）的应用符合一些常见的家族和链接组合，这些组合在下面的表中列出：
- en: '| **Family** | **Canonical Link Function** | **Target Range** | **Notes and
    Applications** |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|**家族**|**规范链接函数**|**目标范围**|**注意事项和应用**|'
- en: '| Gaussian (normal) | Identity | -![](img/B17290_06_036.png) to ![](img/B17290_06_036.png)
    | Used for linear response modeling; reduces the GLM to standard linear regression.
    |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '|高斯（正态）|恒等|-![img/B17290_06_036.png]到![img/B17290_06_036.png]|用于线性响应建模；将广义线性模型（GLM）简化为标准线性回归。|'
- en: '| Poisson | Log | Integers 0 to ![](img/B17290_06_036.png) | Known as Poisson
    regression; models the count of an event occurring (such as the total number of
    O-ring failures) by estimating the frequency at which the event happens. |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|泊松|对数|整数0到![img/B17290_06_036.png]|称为泊松回归；通过估计事件发生的频率来建模事件发生的次数（如O型圈故障的总数）。|'
- en: '| Binomial | Logit | 0 to 1 | Known as logistic regression; used for modeling
    a binary outcome (such as whether any O-ring failed) by estimating the probability
    that the outcome occurs. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|二项式|对数几率|0到1|称为逻辑回归；通过估计结果发生的概率来建模二元结果（如是否有O型圈故障）。|'
- en: '| Gamma | Negative Inverse | 0 to ![](img/B17290_06_036.png) | One of many
    possibilities for modeling right-skewed data; could be used for modeling the time
    to an event (such as seconds to an O-ring failure) or cost data (such as insurance
    claims costs for a car accident). |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '|伽马|负逆|0到![img/B17290_06_036.png]|建模右偏斜数据的一种可能性；可用于建模事件发生的时间（如O型圈故障的秒数）或成本数据（如汽车事故的保险索赔成本）。|'
- en: '| Multinomial | Logit | 1 of *K* categories | Known as multinomial logistic
    regression; used for modeling a categorical outcome (such as a successful, unsuccessful,
    or aborted shuttle launch) by estimating the probability the example falls into
    each of the categories. Generally uses specialized packages rather than a GLM
    function to aid interpretation. |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|多项式|对数几率|*K*个类别中的1个|称为多项式逻辑回归；通过估计示例落在每个类别中的概率来建模分类结果（如成功、失败或中止的航天飞机发射）。通常使用专门的软件包而不是广义线性模型（GLM）函数来帮助解释。|'
- en: Due to the nuances of interpreting GLMs, it takes much practice and careful
    study to be adept at applying just one, and few people can claim to be experts
    at using all of them. Entire textbooks are devoted to each GLM variant. Fortunately,
    in the domain of machine learning, interpreting and understanding are less important
    than being able to apply the correct GLM form to practical problems and produce
    useful predictions. While this chapter cannot cover each of the listed methods,
    an introduction to the key details will allow you to later pursue the GLM variants
    most relevant to your own work.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 由于解释广义线性模型（GLM）的细微差别，要熟练应用一个模型需要大量的实践和仔细的研究，而且很少有人能声称自己是所有这些模型的专家。整本教科书都致力于每种广义线性模型（GLM）变体。幸运的是，在机器学习的领域，解释和理解的重要性不如能够将正确的广义线性模型（GLM）形式应用于实际问题并产生有用的预测。虽然本章不能涵盖列出的每种方法，但关键细节的介绍将允许你后来追求与你自己的工作最相关的广义线性模型（GLM）变体。
- en: Beginning with the simplest variant listed in the table, standard linear regression
    can be thought of as a special type of GLM that uses the Gaussian family and the
    identity link function. The **identity link** implies that the relationship between
    the target *y* and a predictor *x*[i] is not transformed in any way. Thus, as
    with standard regression, an estimated regression parameter ![](img/B17290_06_022.png)
    can be interpreted quite simply as the increase in *y* given a one-unit increase
    in *x*[i], assuming all other factors are held equal.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 从表中列出的最简单变体开始，标准线性回归可以被视为一种特殊的 GLM，它使用高斯族和恒等链接函数。**恒等链接**意味着目标 *y* 与预测变量 *x*[i]
    之间的关系没有进行任何转换。因此，与标准回归一样，一个估计的回归参数 ![](img/B17290_06_022.png) 可以相当简单地解释为在 *x*[i]
    增加1个单位时 *y* 的增加量，假设所有其他因素都保持不变。
- en: GLM forms that use other link functions are not as simple to interpret and fully
    understanding the impact of individual predictors requires much more careful analysis.
    This is because the regression parameters must be interpreted as the additive
    increase in *y* for a one-unit increase in *x*[i], but only after being transformed
    through the link function.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用其他链接函数的 GLM 形式并不容易解释，要完全理解单个预测变量的影响需要更加仔细的分析。这是因为回归参数必须被解释为在 *x* 增加1个单位时 *y*
    的增加量，但这是在通过链接函数转换之后。
- en: For instance, the Poisson family that uses the **log link** function to model
    the expected count of events relates *y* to the predictors *x*[i] through the
    natural logarithm; consequently, the additive effect of ![](img/B17290_06_040.png)
    on *y* becomes multiplicative on the original scale of the response variable.
    This is because using the properties of logarithms, we know ![](img/B17290_06_041.png),
    and this becomes ![](img/B17290_06_042.png) after exponentiating to remove the
    logarithm.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用 **对数链接** 函数来模拟事件预期计数的泊松族，通过自然对数将 *y* 与预测变量 *x*[i] 相关联；因此，![](img/B17290_06_040.png)
    对 *y* 的加性效应在响应变量的原始尺度上变成了乘性效应。这是因为利用对数的性质，我们知道 ![](img/B17290_06_041.png)，在指数化以消除对数后，这变成了
    ![](img/B17290_06_042.png)。
- en: Due to this multiplicative impact, the parameter estimates are understood as
    relative rates of increase rather than the absolute increase in *y* as with linear
    regression.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种乘性影响，参数估计被理解为相对增加率，而不是像线性回归中那样是 *y* 的绝对增加量。
- en: To see this in practice, suppose we built a Poisson regression model of the
    count of O-ring failures versus launch temperature. If *x*[1] is temperature and
    the estimated ![](img/B17290_06_043.png) = -0.103, then we can determine that
    there are about 9.8 percent fewer O-ring failures on average per each additional
    degree of temperature at launch. This is because *exp(-0.103) = 0.902*, or 90.2
    percent of the failures per degree, which implies that we would expect 9.8 percent
    fewer failures per degree increase. Applying this to the Challenger shuttle launch
    temperature at 36 degrees Fahrenheit, we can extrapolate that a launch 17 degrees
    warmer (53 degrees Fahrenheit was the previous coldest launch) would have had
    about *(0.902)^17 = 17.2* percent of the expected number of failures, equivalent
    to a drop of 82.8 percent.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在实践中看到这一点，假设我们构建了一个关于 O 型圈故障数与发射温度的泊松回归模型。如果 *x*[1] 是温度，并且估计的 ![](img/B17290_06_043.png)
    = -0.103，那么我们可以确定，在发射时每增加1度温度，平均 O 型圈故障数会减少约 9.8%。这是因为 *exp(-0.103) = 0.902*，或者说每度故障的
    90.2%，这意味着我们预计每增加1度温度，故障数会减少 9.8%。将此应用于挑战者号发射时的 36 华氏度温度，我们可以外推，如果发射温度再高 17 度（53
    华氏度是之前的最低发射温度），那么预期的故障数将大约是 *(0.902)^17 = 17.2*%，相当于减少 82.8%。
- en: The GLM variant that uses a binomial family distribution with a logit link function
    is known as **logistic regression**, and is perhaps the single most important
    form as it allows regression to be adapted to binary classification tasks. The
    **logit link** is a function in the form *log(p / (1 - p))*, where *p* is a probability;
    the inner portion (*p / (1 - p)*) expresses the probability as **odds**, exactly
    like the odds used in gambling and sports betting in phrases like “the team has
    a 2:1 chance of winning.” After taking the natural logarithm, the estimated regression
    coefficients are interpreted as log odds. Because we understand odds more intuitively
    than log odds, we usually exponentiate the estimated logistic regression coefficients
    to convert log odds into odds for interpretation. However, because logistic regression
    coefficients indicate the difference in the odds of *y* due to a one-unit increase
    in *x*, the exponentiated odds become **odds ratios**, which express the relative
    increase or decrease in the chances that *y* happens.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: In the context of the space shuttle data, suppose we built a logistic regression
    model for the binary classification task of predicting whether or not a launch
    would have one or more O-ring failures. A factor that does not change the probability
    of an O-ring failure would keep the odds balanced at 1:1 (50-50 probability),
    which translates to log odds of *log(0.5 / (1 - 0.5)) = 0* and the estimated regression
    coefficient ![](img/B17290_06_006.png) = 0 for this feature. Finding the odds
    ratio as *exp(0) = 1* shows that the odds remain unchanged regardless of the value
    of this factor. Now, suppose a factor like temperature reduces the chance that
    the outcome occurs, and that in the logistic regression model with *x*[1] as temperature,
    then the estimated ![](img/B17290_06_043.png) = -0.232\. By exponentiating this,
    we find the odds ratio *exp(-0.232) = 0.793*, which means that the odds of a failure
    drop by about 20 percent for a one-degree increase in temperature, assuming all
    else is held equal. It is very important to note that this does not imply that
    the *probability* of a failure drops by 20 percent for each degree increase.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Because the relationship between odds and probability is nonlinear, the impact
    of a temperature change on the failure probability depends on the context in which
    the temperature change is occurring!
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Odds and probabilities are related via the inverse connection between the logit
    and logistic functions. The logistic function has the convenient property that
    for any input *x* value, the output is a value in the range between 0 to 1—exactly
    the same range as a probability. Additionally, the logistic function creates an
    S-shaped curve when graphed, as illustrated in *Figure 6.6*, which shows a hypothetical
    logistic regression model of O-ring failure probability versus launch temperature.
    The probability of failure on the *y* axis is changed most strongly in the middle
    of the temperature range; at temperature extremes, the predicted failure probability
    changes very little for each additional degree of temperature added or removed.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 概率和几率通过logit和逻辑函数之间的逆关系相关联。逻辑函数有一个方便的性质，即对于任何输入*x*值，输出都在0到1的范围内——正好与概率的范围相同。此外，逻辑函数在绘制时创建一个S形曲线，如图*图6.6*所示，该图显示了O形圈故障概率与发射温度的假设逻辑回归模型。在温度范围的中间，失败概率在*y*轴上变化最为强烈；在温度极端情况下，每增加或减少一度温度，预测的失败概率变化很小。
- en: '![Chart, line chart  Description automatically generated](img/B17290_06_06.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图表，折线图  自动生成的描述](img/B17290_06_06.png)'
- en: 'Figure 6.6: Hypothetical logistic regression curve representing space shuttle
    launch data'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6：表示航天飞机发射数据的假设逻辑回归曲线
- en: The fitted logistic regression model creates a curve representing a probability
    estimation on a continuous scale anywhere in the range between 0 to 1, despite
    the target outcome (represented by circles in the figure) only taking the value
    *y* = 0 or *y* = 1\. To obtain the binary prediction, simply define the probability
    threshold within which the target outcome is to be predicted. For example, if
    the predicted probability of an O-ring failure is greater than 0.50, then predict
    “failure,” and otherwise, predict “no failure.” Using a 50 percent threshold is
    common, but a higher or lower threshold can be used to adjust the cost sensitivity
    of the model.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合的逻辑回归模型在0到1的范围内创建了一条曲线，表示对连续尺度上的概率估计，尽管目标结果（如图中圆圈所示）只取值为*y* = 0或*y* = 1。为了获得二元预测，只需定义一个概率阈值，目标结果将据此进行预测。例如，如果预测的O形圈故障概率大于0.50，则预测“故障”，否则预测“无故障”。使用50%的阈值是常见的，但可以使用更高的或更低的阈值来调整模型对成本的敏感度。
- en: 'Examining the logistic curve in *Figure 6.6* leads to another question: how
    does the modeling algorithm determine the curve that best fits the data? After
    all, given that this is not a straight line, the OLS algorithm used in standard
    linear regression no longer seems to apply.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 检视*图6.6*中的逻辑曲线会引出另一个问题：建模算法是如何确定最适合数据的曲线的呢？毕竟，鉴于这并非一条直线，标准线性回归中使用的OLS算法似乎不再适用。
- en: Indeed, generalized linear models use a different technique called **maximum
    likelihood estimation** (**MLE**), which finds the parameter values for the specified
    distribution that are most likely to have generated the observed data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，广义线性模型使用一种称为**最大似然估计**（**MLE**）的不同技术，该技术找到指定分布中最有可能生成观察数据的参数值。
- en: Because OLS estimation is a special case of maximum likelihood estimation, using
    OLS or MLE for a linear model makes no difference given that the assumptions of
    OLS modeling are met. For applications outside of linear modeling, the MLE technique
    will produce different results and must be used instead of OLS. The MLE technique
    is built into GLM modeling software, and usually applies analytical techniques
    to identify the optimal model parameters by iterating repeatedly over the data
    rather than finding the correct solution directly. Fortunately, as we will see
    shortly, building a GLM in R is hardly more challenging than training a simpler
    linear model.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 由于OLS估计是最大似然估计的特殊情况，只要满足OLS建模的假设，使用OLS或MLE对线性模型进行建模就没有区别。对于线性建模之外的应用，MLE技术会产生不同的结果，并且必须使用MLE而不是OLS。MLE技术内置在GLM建模软件中，通常通过在数据上反复迭代以识别最优模型参数，而不是直接找到正确解。幸运的是，正如我们很快将看到的，在R中构建GLM几乎不比训练一个更简单的线性模型更具挑战性。
- en: This introduction only scratched the surface of what is possible with linear
    regression and GLM. Although theory and simple examples like the Challenger dataset
    are helpful for understanding how regression models work, there is more involved
    in building a useful model than what we’ve seen so far. R’s built-in regression
    functions include the additional functionality needed to fit more sophisticated
    models while providing additional diagnostic output to aid model interpretation
    and assess the fit. Let’s apply these functions and expand our knowledge of regression
    by attempting a real-world learning task.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 本介绍仅触及了线性回归和GLM可能性的表面。尽管理论和像挑战者数据集这样的简单例子有助于理解回归模型的工作原理，但构建一个有用的模型所涉及的不仅仅是我们所看到的。R内置的回归函数包括拟合更复杂模型所需的功能，同时提供额外的诊断输出，以帮助模型解释和评估拟合度。让我们应用这些函数，通过尝试一个现实世界的学习任务来扩展我们对回归的了解。
- en: Example – predicting auto insurance claims costs using linear regression
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 – 使用线性回归预测汽车保险索赔成本
- en: For an automobile insurance company to make money, it needs to collect more
    in membership premiums than it spends on claims paid to its beneficiaries in case
    of vehicle theft, damages, or loss of life in accidents. Consequently, insurers
    invest time and money to develop models that accurately forecast claims costs
    for the insured population. This is the field known as **actuarial science**,
    which uses sophisticated statistical techniques to estimate risk across insured
    populations.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一家汽车保险公司来说，为了盈利，它需要收取的会员费比支付给其受益人的车辆盗窃、损坏或事故中生命损失索赔要多。因此，保险公司投入时间和金钱来开发模型，以准确预测受保人群的索赔成本。这是被称为**精算科学**的领域，它使用复杂的统计技术来估计受保人群的风险。
- en: Insurance expenses are difficult to predict accurately for individuals because
    accidents, and especially fatal accidents, are thankfully relatively rare—a bit
    over one fatality per 100 million vehicle miles traveled in the United States—yet,
    when they do happen, they are extremely costly. Moreover, the specific conditions
    leading to any given accident are based on factors that are so hard to measure
    that they appear to be random. An excellent driver with a clean driving record
    could have bad luck and be hit by a drunk driver, while another person can drive
    distracted by their cellular phone and, due to good fortune, never cause an accident.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 由于事故，尤其是致命事故相对罕见——在美国，每行驶1亿英里车辆中略超过1起死亡事故——因此，个人保险费用难以准确预测。然而，当事故发生时，它们代价极高。此外，导致任何特定事故的具体条件基于难以衡量的因素，它们看起来似乎是随机的。一个有良好驾驶记录的优秀驾驶员可能会遭遇不幸，被醉酒驾驶员撞到，而另一个人可能会因分心驾驶手机，由于好运，从未造成事故。
- en: Because of the near impossibility of predicting expenses for a single person,
    insurance companies apply the law of averages and compute the average cost to
    insure segments of people with similar risk profiles. If the expense estimates
    for each risk segment are correct, the insurance company can price the insurance
    premiums lower for segments with less risk, and potentially attract new, low-risk
    customers from competing insurance companies. We will simulate this scenario in
    the analysis that follows.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 由于预测个人费用的几乎不可能性，保险公司应用平均法则，计算具有相似风险特征的人群保险段的平均成本。如果每个风险段的费用估计是正确的，保险公司可以为风险较低的段定价较低的保险费，并可能从竞争的保险公司吸引新的低风险客户。在接下来的分析中，我们将模拟这种场景。
- en: Step 1 – collecting data
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1步 – 收集数据
- en: The dataset for this example is a simulation created for this book based on
    demographics and traffic statistics from the United States government. It is intended
    to approximate the real-world conditions of automobile insurance companies in
    the U.S. state of Michigan, which is home to about ten million residents and seven
    million licensed drivers.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 本例的数据集是基于美国政府的人口统计和交通统计数据创建的模拟数据。它的目的是近似美国密歇根州汽车保险公司的现实世界条件，该州约有1000万居民和700万持牌驾驶员。
- en: If you would like to follow along interactively, download the `autoinsurance.csv`
    file from the Packt Publishing GitHub repository for this book and save it to
    your R working folder.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想交互式地跟随，请从本书的Packt Publishing GitHub仓库下载`autoinsurance.csv`文件，并将其保存到你的R工作文件夹中。
- en: 'The insurance dataset includes 20,000 examples of beneficiaries enrolled in
    the hypothetical automobile vehicle insurance plan. This is much smaller than
    the typical datasets used by practicing actuaries, especially for very rare outcomes,
    but the size has been reduced to allow analysis even on computers with limited
    memory. Each example represents an insured individual’s characteristics and total
    insurance claims costs (`expenses`) charged to the plan for the calendar year.
    The features available at the time of enrollment are:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 保险数据集包括20,000个受益者参加的假设汽车车辆保险计划的示例。这比实际精算师使用的典型数据集要小得多，特别是对于非常罕见的结果，但规模已经缩小，以便即使在内存有限的计算机上也能进行分析。每个示例代表一个被保险个人的特征和计划在日历年度中收取的总保险索赔成本（费用）。在登记时可用的是以下特征：
- en: '`age`: The age of the driver, from 16 to 89'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`age`: 驾驶者的年龄，从16岁到89岁'
- en: '`geo_area`: The geographic area of the vehicle owner’s primary residence, and
    where the vehicle will be used most often; zip codes were bucketed into urban,
    suburban, and rural categories'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`geo_area`: 车主主要居住地的地理区域，以及车辆最常使用的地方；邮编被归入城市、郊区和农村类别'
- en: '`est_value`: The estimated market value of the vehicle(s), based on age and
    depreciation; capped at $125,000—the maximum allowed insured value'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`est_value`: 根据年龄和折旧估计的车辆（们）的市场价值；上限为125,000美元——允许的最大保险价值'
- en: '`vehicle_type`: The type of passenger vehicle, either a car, truck, minivan,
    or sport utility vehicle (SUV)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vehicle_type`: 乘客车辆的类型，可以是汽车、卡车、微型货车或运动型多功能车（SUV）'
- en: '`miles_driven`: The distance driven (in miles) in the calendar year'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`miles_driven`: 在日历年度内驾驶的距离（英里）'
- en: '`college_grad_ind`: A binary indicator set to `1` if the beneficiary has a
    college education or higher'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`college_grad_ind`: 如果受益者拥有大学学历或更高，则该二进制指示器设置为`1`'
- en: '`speeding_ticket_ind`: A binary indicator set to `1` if a speeding ticket or
    infraction was received during the past five years'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`speeding_ticket_ind`: 如果在过去五年内收到过超速罚单或违规，则该二进制指示器设置为`1`'
- en: '`clean_driving_ind`: A binary indicator set to `1` if no at-fault insurance
    claims were paid during the past five years'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clean_driving_ind`: 如果在过去五年内没有支付过责任保险索赔，则该二进制指示器设置为`1`'
- en: 'In this example scenario, each of the 20,000 beneficiaries enrolled in a “safe
    driving discount” program, which required the use of a device or mobile phone
    application that uses location tracking to monitor safe driving conditions throughout
    the year. This helped validate the accuracy of `miles_driven` and created the
    following two additional predictors, which are intended to reflect more risky
    driving behaviors:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例场景中，有20,000名受益者参加了“安全驾驶折扣”计划，该计划要求使用设备或手机应用程序进行位置跟踪，以监控全年安全驾驶条件。这有助于验证`miles_driven`的准确性，并创建了以下两个额外的预测因子，旨在反映更危险的驾驶行为：
- en: '`hard_braking_ind`: A binary indicator set to `1` if the vehicle frequently
    applies “hard brakes” (as in the case of stopping suddenly)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hard_braking_ind`: 如果车辆经常应用“硬刹车”（例如突然停车的情况），则该二进制指示器设置为`1`'
- en: '`late_driving_ind`: A binary indicator set to `1` if the vehicle is driven
    regularly after midnight'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`late_driving_ind`: 如果车辆在午夜后经常驾驶，则该二进制指示器设置为`1`'
- en: It is important to give some thought to how these variables may relate to billed
    insurance expenses—some in more obvious ways than others. For instance, we would
    clearly expect cars driven more often to be at a higher risk of an accident than
    those that stay home in the garage. On the other hand, it isn’t as clear whether
    urban, rural, or suburban drivers would be riskier; rural drivers may drive farther,
    but urban driving involves more traffic and may be more at risk of vehicle theft.
    A regression model will help us disentangle these relationships, but requires
    us to specify the connections between the features ourselves rather than detecting
    them automatically, which is unlike many other machine learning methods. We’ll
    explore some of the potential relationships in the next section.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这些变量如何与保险费用相关是很重要的——有些方式比其他方式更明显。例如，我们显然预期经常驾驶的汽车比那些停在车库里的汽车更容易发生事故。另一方面，城市、农村或郊区的驾驶员哪个风险更高并不那么明显；农村驾驶员可能驾驶的距离更远，但城市驾驶涉及更多的交通，可能更容易发生车辆盗窃。回归模型将帮助我们解开这些关系，但需要我们自己指定特征之间的联系，而不是自动检测，这与许多其他机器学习方法不同。我们将在下一节中探讨一些潜在的关系。
- en: It may also be interesting to consider which potentially useful predictors are
    not included in the training dataset. Gender is often used for automobile insurance
    pricing (and it varies whether males or females are more costly!) but the state
    of Michigan banned the use of gender and credit scoring for this purpose in 2020\.
    Such features may be highly predictive, but may lead to systematic biases against
    protected groups, as discussed in *Chapter 1*, *Introducing Machine Learning*.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑哪些可能的有用预测因子没有被包含在训练数据集中也许也很有趣。性别常被用于汽车保险定价（并且男女成本不同！）但密歇根州在2020年禁止了为此目的使用性别和信用评分。这些特征可能具有高度预测性，但可能导致对受保护群体的系统性偏见，如第1章*介绍机器学习*中所述。
- en: Step 2 – exploring and preparing the data
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步 – 探索和准备数据
- en: 'As we have done before, we will use the `read.csv()` function to load the data
    for analysis. We can safely use `stringsAsFactors = TRUE` because it is appropriate
    to convert the three nominal variables into factors:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所做的那样，我们将使用`read.csv()`函数来加载数据进行分析。我们可以安全地使用`stringsAsFactors = TRUE`，因为将三个名义变量转换为因子是合适的：
- en: '[PRE15]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `str()` function confirms that the data is formatted as we expected:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`str()`函数确认数据格式正如我们所期望的：'
- en: '[PRE16]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Our model’s dependent variable is `expenses`, which measures the loss or damages
    each person claimed under the insurance plan for the year. Prior to building a
    linear regression model, it is often helpful to check for normality. Although
    linear regression will not fail without a normally distributed dependent variable,
    the model often fits better when this is true. Let’s look at the summary statistics:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型因变量是`expenses`，它衡量每个人在保险计划下一年内所声称的损失或损害。在构建线性回归模型之前，检查正态性通常很有帮助。尽管没有正态分布的因变量，线性回归也不会失败，但模型在这一点上通常拟合得更好。让我们看看总结统计：
- en: '[PRE18]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The minimum, first quartile, median, and third quartile are all zero, which
    implies that at least 75% of the beneficiaries had no expenses in the calendar
    year. The fact that the mean value is greater than the median gives us the sense
    that the distribution of insurance expenses is right-skewed, but the skew is likely
    to be quite extreme as the average expense was $1,709 while the maximum was $232,797\.
    We can confirm this visually using a histogram:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 最小值、第一四分位数、中位数和第三四分位数都是零，这意味着至少75%的受益人在日历年度内没有费用。平均值大于中位数的事实让我们感觉到保险费用的分布是右偏的，但偏斜可能非常极端，因为平均费用是1,709美元，而最大值是232,797美元。我们可以使用直方图来直观地确认这一点：
- en: '[PRE20]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Text  Description automatically generated](img/B17290_06_07.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B17290_06_07.png)'
- en: 'Figure 6.7: The distribution of annual insurance claims costs'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7：年度保险索赔成本的分布
- en: As expected, the figure shows a right-skewed distribution with a huge spike
    at zero, reflecting the fact that only a small portion (about 8.6%) made an insurance
    claim. Among those that did claim a vehicle loss or damages, the tail end of the
    distribution extends far to the right, beyond $200,000 worth of expenses for the
    costliest injuries. Although this distribution is not ideal for linear regression,
    knowing this weakness ahead of time may help us design a better-fitting model
    later. For now, using only the distribution of `expenses`, we can say that the
    average beneficiary should be charged an annual premium of $1,709 for the insurer
    to break even, or about $150 a month per subscriber for a slight profit. Of course,
    this assumes that the risk and costs are shared evenly. An improved insurance
    model will push greater costs onto riskier drivers and provide safe drivers with
    financial savings.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，该图显示了一个右偏分布，在零处有一个巨大的峰值，反映了只有一小部分（大约8.6%）提出了保险索赔。在那些确实提出了车辆损失或损害索赔的人中，分布的尾部延伸到右侧，超过了200,000美元的昂贵伤害费用。尽管这种分布不适合线性回归，但提前知道这种弱点可能有助于我们稍后设计一个更好的拟合模型。现在，仅使用`expenses`的分布，我们可以这样说，平均受益人应该被收取每年1,709美元的保险费，这样保险公司才能收支平衡，或者每月每名订阅者约150美元的轻微利润。当然，这假设风险和成本是平均分担的。一个改进的保险模型会将更大的成本转嫁给风险较高的驾驶员，并为安全驾驶员提供经济上的节省。
- en: Before we add additional predictors, it is important to note that regression
    models require that every feature is numeric, yet we have two factor-type features
    in our data frame. For instance, the `geo_area` variable is divided into `urban`,
    `suburban`, and `rural` levels, while `vehicle_type` has categories for `car`,
    `truck`, `suv`, and `minivan`.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加额外的预测变量之前，重要的是要注意回归模型要求每个特征都是数值型的，而我们的数据框中有两个因素类型的特征。例如，`geo_area`变量被分为`urban`、`suburban`和`rural`等级，而`vehicle_type`有`car`、`truck`、`suv`和`minivan`等类别。
- en: 'Let’s take a closer look to see how they are distributed:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看它们的分布情况：
- en: '[PRE21]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, we see that the data has been divided nearly evenly between urban and
    suburban areas, but rural is a much smaller portion of the data. Additionally,
    SUVs are the most popular vehicle type, followed by cars and trucks, with minivans
    in a distant fourth place. We will see how R’s linear regression function handles
    these factor variables shortly.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到数据几乎均匀地分布在城市和郊区之间，但农村数据占比较小。此外，SUV是最受欢迎的车型，其次是汽车和卡车，微型货车位于遥远的第四位。我们将很快看到R的线性回归函数如何处理这些因素变量。
- en: Exploring relationships between features – the correlation matrix
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索特征之间的关系——相关矩阵
- en: Before fitting a regression model to data, it can be useful to determine how
    the independent variables are related to the dependent variable and each other.
    A **correlation matrix** provides a quick overview of these relationships. Given
    a set of variables, it provides a correlation for each pairwise relationship.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在将回归模型拟合到数据之前，确定自变量如何与因变量以及彼此相关可能很有用。**相关矩阵**提供了这些关系的快速概述。给定一组变量，它为每对关系提供相关性。
- en: 'To create a correlation matrix for the four numeric, non-binary variables in
    the insurance data frame, use the `cor()` command:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 要为保险数据框中的四个数值型、非二进制变量创建相关矩阵，请使用`cor()`命令：
- en: '[PRE25]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: At the intersection of each row and column pair, the correlation is listed for
    the variables indicated by that row and column. The diagonal is always `1.0000000`
    since there is always a perfect correlation between a variable and itself. The
    values above and below the diagonal are identical since correlations are symmetrical.
    In other words, `cor(x, y)` is equal to `cor(y, x)`.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一行和每一列的交叉处，列出该行和列所指示变量的相关性。对角线始终是`1.0000000`，因为变量与其自身之间总是存在完美的相关性。对角线上方和下方的值是相同的，因为相关性是对称的。换句话说，`cor(x,
    y)`等于`cor(y, x)`。
- en: None of the correlations in the matrix are very strong, but the associations
    do match with common sense. For instance, `age` and `expenses` appear to have
    a weak negative correlation, meaning that as someone ages, their expected insurance
    cost goes down slightly—probably reflecting the greater driving experience. There
    are also positive correlations between `est_value` and `expenses` and `miles_driven`
    and `expenses`, which indicate that more valuable cars and more extensive driving
    lead to greater expenses. We’ll try to tease out these types of relationships
    more clearly when we build our final regression model.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵中的相关性都不强，但关联与常识相符。例如，`age`和`expenses`似乎存在弱负相关性，这意味着随着年龄的增长，预期的保险费用会略有下降——这可能是由于更丰富的驾驶经验。还有`est_value`和`expenses`以及`miles_driven`和`expenses`之间的正相关性，这表明更昂贵的汽车和更广泛的驾驶会导致更高的费用。当我们构建最终的回归模型时，我们将尝试更清晰地揭示这些类型的关系。
- en: Visualizing relationships between features – the scatterplot matrix
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化特征之间的关系——散点图矩阵
- en: It can also be helpful to visualize the relationships between numeric features
    with scatterplots. Although we could create a scatterplot for each possible relationship,
    doing so for a large set of features quickly becomes tedious.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 使用散点图可视化数值特征之间的关系也可能很有帮助。尽管我们可以为每种可能的关系创建一个散点图，但对于大量特征来说，这样做很快就会变得繁琐。
- en: An alternative is to create a **scatterplot matrix** (sometimes abbreviated
    as **SPLOM**), which is simply a collection of scatterplots arranged in a grid.
    It is used to detect patterns among three or more variables. The scatterplot matrix
    is not a true multi-dimensional visualization because only two features are examined
    at a time. Still, it provides a general sense of how the data may be interrelated.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是创建一个**散点图矩阵**（有时简称为**SPLOM**），它只是按网格排列的散点图的集合。它用于检测三个或更多变量之间的模式。散点图矩阵不是真正的多维可视化，因为一次只检查两个特征。尽管如此，它提供了数据可能相互关联的一般感觉。
- en: 'We can use R’s graphical capabilities to create a scatterplot matrix for the
    four non-binary numeric features: `age`, `est_value`, `miles_driven`, and `expenses`.
    The `pairs()` function is provided in the default R installation and provides
    basic functionality for producing scatterplot matrices. To invoke the function,
    simply provide it with a subset of the data frame to plot. Given the relatively
    large size of our `insurance` dataset, we’ll set the plot character parameter
    `pch = "."` to a dot to make the visualization easier to read, then limit the
    columns to the four variables of interest:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用R的图形功能来创建四个非二进制数值特征（`age`、`est_value`、`miles_driven`和`expenses`）的散点图矩阵。`pairs()`函数是R默认安装的一部分，提供了生成散点图矩阵的基本功能。要调用此函数，只需提供要绘制的数据框的子集。鉴于我们的`insurance`数据集相对较大，我们将设置绘图字符参数`pch
    = "."`为点，以便使可视化更容易阅读，然后限制列为我们感兴趣的四个变量：
- en: '[PRE27]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This produces the following scatterplot matrix:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下散点图矩阵：
- en: '![Diagram  Description automatically generated](img/B17290_06_08.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![图表描述自动生成](img/B17290_06_08.png)'
- en: 'Figure 6.8: A scatterplot matrix of the numeric features in the insurance dataset'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8：保险数据集中数值特征的散点图矩阵
- en: In the scatterplot matrix, the intersection of each row and column holds the
    scatterplot of the variables indicated by the row and column pair. The diagrams
    above and below the diagonal are transpositions because the *x* axis and *y* axis
    have been swapped. Do you notice any patterns in these plots? Although they mostly
    look like random clouds of points, a couple seem to display some subtle trends.
    The relationships of both `est_value` and `miles_driven` with `expenses` seem
    to display a slight upward trend, which confirms visually what we already learned
    from the correlation matrix.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在散点图矩阵中，每一行和每一列的交叉处持有由行和列对指示的变量的散点图。对角线以上和以下的图是转置的，因为*x*轴和*y*轴已经交换了。您在这些图中注意到任何模式吗？尽管它们大多看起来像随机的点云，但其中一些似乎显示出一些微妙趋势。`est_value`和`miles_driven`与`expenses`的关系似乎显示出轻微的上升趋势，这从相关矩阵中我们已经学到的内容得到了视觉上的证实。
- en: 'By adding more information to the plot, it can be made even more useful. An
    enhanced scatterplot matrix can be created with the `pairs.panels()` function
    in the `psych` package. If you do not have this package installed, type `install.packages("psych")`
    to install it on your system and load it using the `library(psych)` command. Then,
    we can create a scatterplot matrix using the `pch` parameter to set the plotting
    character as we did previously:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向图中添加更多信息，可以使它变得更加有用。可以使用`psych`包中的`pairs.panels()`函数创建增强的散点图矩阵。如果您尚未安装此包，请在系统上输入`install.packages("psych")`进行安装，并使用`library(psych)`命令加载它。然后，我们可以使用`pch`参数设置绘图字符，就像我们之前做的那样来创建散点图矩阵：
- en: '[PRE28]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This produces a more informative scatterplot matrix, as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生一个更信息丰富的散点图矩阵，如下所示：
- en: '![A picture containing chart  Description automatically generated](img/B17290_06_09.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![包含图表的图片描述自动生成](img/B17290_06_09.png)'
- en: 'Figure 6.9: The pairs.panels() function adds detail to the scatterplot matrix'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9：`pairs.panels()`函数为散点图矩阵添加了细节
- en: In the `pairs.panels()` output, the scatterplots above the diagonal are replaced
    with a correlation matrix. The diagonal now contains histograms depicting the
    distribution of values for each feature. Finally, the scatterplots below the diagonal
    are presented with additional visual information.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在`pairs.panels()`输出中，对角线以上的散点图被相关矩阵所取代。对角线现在包含描述每个特征值分布的直方图。最后，对角线以下的散点图展示了额外的视觉信息。
- en: The oval-shaped object on each scatterplot (which may be difficult to see in
    print due to the mass of black points but can be seen more easily on a computer
    screen) is a **correlation ellipse**. It provides a simple visual indicator of
    correlation strength. In this dataset, there are no strong correlations, so the
    ovals are mostly flat; with stronger correlations, the ovals would be tilted upward
    or downward to indicate a positive or negative correlation. The dot at the center
    of the ellipse is a point reflecting the means of the *x*- and *y*-axis variables.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 每个散点图上的椭圆形物体（由于大量黑色点可能难以在打印中看到，但在电脑屏幕上更容易看到）是一个**相关椭圆**。它提供了一个简单的视觉指示，表示相关强度。在这个数据集中，没有强烈的关联，所以椭圆大多是平的；有更强的关联时，椭圆会向上或向下倾斜，以表示正相关或负相关。椭圆中心的小点是一个反映*x*轴和*y*轴变量平均值的点。
- en: The line superimposed across the scatterplot (which appears in red on a computer
    screen) is called a **loess curve**. It indicates the general relationship between
    the *x*-axis and *y*-axis variables. It is best understood by example. Although
    the small size of the plot makes this trend difficult to see, the curve for `age`
    and `miles_driven` slopes upward very slightly until reaching middle age, then
    levels off. This means that driving tends to increase with age up to the point
    at which it remains roughly constant over time.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 投影在散点图上的线（在计算机屏幕上显示为红色）称为**局部加权回归曲线**。它表示*x*轴和*y*轴变量之间的一般关系。最好通过例子来理解。尽管图表的小尺寸使得这种趋势难以看到，但`age`和`miles_driven`的曲线在达到中年之前略微上升，然后趋于平稳。这意味着驾驶往往随着年龄的增长而增加，直到它随时间大致保持恒定。
- en: Although not observed here, the loess curve can sometimes be quite dramatic
    with V- or U-shaped curves as well as stairstep patterns. Recognizing such patterns
    can assist later with developing a better-fitting regression model.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在此处未观察到，但局部加权回归曲线有时可以非常显著，具有V形或U形曲线以及阶梯状模式。识别这些模式可以帮助后来开发更好的拟合回归模型。
- en: Step 3 – training a model on the data
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步 – 在数据上训练模型
- en: 'To fit a linear regression model to data with R, the `lm()` function can be
    used. This is part of the `stats` package, which should be included and loaded
    by default with your R installation. The `lm()` syntax is as follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用R拟合线性回归模型，可以使用`lm()`函数。这是`stats`包的一部分，应该默认包含并加载到您的R安装中。`lm()`的语法如下：
- en: '![Text  Description automatically generated](img/B17290_06_10.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B17290_06_10.png)'
- en: 'Figure 6.10: Multiple regression syntax'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10：多重回归语法
- en: The following command fits a linear regression model, which relates the ten
    independent variables to the total insurance expenses. The R formula syntax uses
    the tilde character (`~`) to describe the model; the dependent variable `expenses`
    is written to the left of the tilde while the independent variables go to the
    right, separated by `+` signs.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令拟合了一个线性回归模型，该模型将十个独立变量与总保险费用相关联。R公式语法使用波浪线字符（`~`）来描述模型；因变量`expenses`写在波浪线的左侧，而独立变量则写在右侧，由加号（`+`）分隔。
- en: 'There is no need to specify the regression model’s intercept term, as it is
    included by default:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 没有必要指定回归模型的截距项，因为它默认包含：
- en: '[PRE29]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Because the period character (`.`) can be used to specify all features (excluding
    those already specified in the formula), the following command is equivalent to
    the prior command:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 因为点号字符（`.`）可以用来指定所有特征（不包括公式中已指定的那些），所以以下命令与之前的命令等价：
- en: '[PRE30]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'After building the model, simply type the name of the model object to see the
    estimated beta coefficients. Note that the `options(scipen = 999)` command turns
    off scientific notation to make the output easier to read:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建模型后，只需输入模型对象的名称即可查看估计的贝塔系数。请注意，`options(scipen = 999)`命令关闭了科学记数法，以便更容易阅读输出：
- en: '[PRE31]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Understanding the regression coefficients for a linear regression model is fairly
    straightforward. The intercept is the predicted value of `expenses` when the independent
    variables are equal to zero. However, in many cases, the intercept is of little
    explanatory value by itself, as it is often impossible to have values of zero
    for all features.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 理解线性回归模型的回归系数相对简单。截距是当独立变量等于零时`expenses`的预测值。然而，在许多情况下，截距本身具有很小的解释价值，因为通常不可能所有特征都具有零值。
- en: This is the case here, where no insured person can exist with zero age or no
    miles driven, and consequently, the intercept has no real-world interpretation.
    For this reason, in practice, the intercept is often ignored.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是这种情况，因为没有任何投保人可以有零岁或没有行驶英里，因此截距没有实际世界的解释。因此，在实践中，截距通常被忽略。
- en: The beta coefficients indicate the estimated increase in insurance claims costs
    for an increase of one unit in each feature, assuming all other values are held
    constant. For instance, for each additional year of age, we would expect $1.89
    lower insurance claims costs on average, assuming everything else is held equal.
    Similarly, we would expect $0.12 higher claims for each additional mile driven
    and $0.03 higher per dollar of insured value, all else equal.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 贝塔系数表示每个特征增加一个单位时，保险索赔成本的估计增加量，假设其他所有值保持不变。例如，对于每增加一岁，我们预计平均保险索赔成本将降低1.89美元，假设其他所有条件保持不变。同样，我们预计每增加一英里行驶将增加0.12美元的索赔，每增加一美元的保险价值将增加0.03美元，其他条件相同。
- en: You might notice that although we only specified 10 features in our model formula,
    there are 13 coefficients reported in addition to the intercept. This happened
    because the `lm()` function automatically applies dummy coding to each of the
    factor-type variables included in the model.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到，尽管我们在模型公式中只指定了 10 个特征，但除了截距之外，还报告了 13 个系数。这是因为 `lm()` 函数自动对模型中包含的每个因子类型变量应用虚拟编码。
- en: 'As explained in *Chapter 3*, *Lazy Learning – Classification Using Nearest
    Neighbors*, dummy coding allows a nominal feature to be treated as numeric by
    creating a binary variable for each category of the feature except one, which
    serves as the reference category. Each dummy variable is set to `1` if the observation
    falls into the specified category or `0` otherwise. For example, the `geo_area`
    feature has three categories: `urban`, `suburban`, and `rural`. Thus, two dummy
    variables were used, which are named `geo_areaurban` and `geo_areasuburban`. For
    the observations where the `geo_area = "rural"`, `geo_areaurban` and `geo_areasuburban`
    will both be set to zero. Similarly, for the four-category `vehicle_type` feature,
    R created three dummy variables named `vehicle_typeminivan`, `vehicle_typesuv`,
    and `vehicle_typetruck`. This left `vehicle_type = "car"` to serve as the reference
    category when the three dummy variables are all zero.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *第 3 章* 所述，*懒惰学习 – 使用最近邻进行分类*，虚拟编码允许将名义特征通过为特征的每个类别（除了一个参考类别外）创建一个二元变量来处理为数值。每个虚拟变量在观测值属于指定类别时设置为
    `1`，否则设置为 `0`。例如，`geo_area` 特征有三个类别：`urban`、`suburban` 和 `rural`。因此，使用了两个虚拟变量，分别命名为
    `geo_areaurban` 和 `geo_areasuburban`。对于 `geo_area = "rural"` 的观测值，`geo_areaurban`
    和 `geo_areasuburban` 都将设置为零。同样，对于四类 `vehicle_type` 特征，R 创建了三个虚拟变量，分别命名为 `vehicle_typeminivan`、`vehicle_typesuv`
    和 `vehicle_typetruck`。这使 `vehicle_type = "car"` 在三个虚拟变量都为零时作为参考类别。
- en: When dummy coded features are used in a regression model, the regression coefficients
    are interpreted relative to the categories that were omitted. In our model, R
    automatically held out the `geo_arearural` and `vehicle_typecar` variables, making
    rural car owners the reference group. Thus, urban dwellers have $169.11 more claims
    costs each year relative to rural areas and trucks cost the insurer an average
    of $21.57 more than cars per year. To be clear, these differences assume all other
    features are held equal, so they are independent of the fact that rural drivers
    may drive more miles or less expensive vehicles. We would expect two people who
    are otherwise identical, except that one lives in a rural area and one lives in
    an urban area, to differ by about $170, on average.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 当在回归模型中使用虚拟编码特征时，回归系数的解释是相对于省略的类别。在我们的模型中，R 自动保留了 `geo_arearural` 和 `vehicle_typecar`
    变量，使农村汽车所有者成为参考组。因此，与农村地区相比，城市居民每年的索赔成本高出 $169.11，而卡车每年比汽车使保险公司多花费 $21.57。为了清楚起见，这些差异假设所有其他特征都保持相等，因此它们独立于农村驾驶员可能行驶更多里程或拥有更便宜车辆的事实。我们预计两个在其他方面完全相同的人，除了一个住在农村地区，一个住在城市地区，平均差异约为
    $170。
- en: By default, R uses the first level of the factor variable as the reference.
    If you would prefer to use another level, the `relevel()` function can be used
    to specify the reference group manually. Use the `?relevel` command in R for more
    information.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，R 使用因子变量的第一级作为参考。如果您希望使用其他级别，可以使用 `relevel()` 函数手动指定参考组。在 R 中使用 `?relevel`
    命令获取更多信息。
- en: In general, the results of the linear regression model make logical sense; however,
    we currently have no sense of how well the model is fitting the data. We’ll answer
    this question in the next section.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，线性回归模型的结果具有逻辑意义；然而，我们目前还没有关于模型如何拟合数据的良好感觉。我们将在下一节回答这个问题。
- en: Step 4 – evaluating model performance
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 4 步 – 评估模型性能
- en: 'The parameter estimates we obtained by typing `ins_model` tell us about how
    the independent variables are related to the dependent variable, but they tell
    us nothing about how well the model fits our data. To evaluate the model performance,
    we can use the `summary()` command on the stored model:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 通过输入 `ins_model` 获得的参数估计告诉我们独立变量与因变量之间的关系，但它们没有告诉我们模型如何拟合我们的数据。为了评估模型性能，我们可以使用存储的模型上的
    `summary()` 命令：
- en: '[PRE33]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This produces the following output, which has been annotated for illustrative
    purposes:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下输出，其中已添加注释以供说明：
- en: '![A picture containing text  Description automatically generated](img/B17290_06_11.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本的图片 描述自动生成](img/B17290_06_11.png)'
- en: 'Figure 6.11: The summary output from a regression model can be divided into
    three main components, which are annotated in this figure'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11：回归模型的总结输出可以分为三个主要部分，如图中所示
- en: 'The `summary()` output may seem overwhelming at first, but the basics are easy
    to pick up. As indicated by the numbered labels in the preceding output, there
    are three main ways to evaluate the performance, or fit, of our model:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '`summary()`输出的内容一开始可能看起来令人不知所措，但基本内容很容易掌握。如前述输出中的编号标签所示，评估我们模型性能或拟合度主要有三种方式：'
- en: The **Residuals** section provides summary statistics for the prediction errors,
    some of which are apparently quite substantial. Since a residual is equal to the
    true value minus the predicted value, the maximum error of `231252` suggests that
    the model under-predicted expenses by more than $230,000 for at least one observation.
    On the other hand, the majority of errors are relatively small negative values,
    which means that we are over-estimating expenses for most enrollees. This is exactly
    how the insurance company can afford to cover the expenses for costly accidents.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**残差**部分提供了预测误差的汇总统计，其中一些误差显然相当大。由于残差等于真实值减去预测值，最大误差`231252`表明模型至少对一个观测值预测费用低于230,000美元以上。另一方面，大多数误差是相对较小的负值，这意味着我们对大多数受保人的费用估计过高。这正是保险公司能够承担昂贵事故费用的原因。'
- en: For each estimated regression coefficient, the **p-value**, denoted by `Pr(>|t|)`,
    provides an estimate of the probability that the true coefficient is zero given
    the value of the estimate. Small p-values suggest that the true coefficient is
    very unlikely to be zero, which means that the feature is extremely unlikely to
    have no relationship with the dependent variable. Note that some of the p-values
    have stars (`***`), which correspond to the footnotes that specify the **significance
    level** met by the estimate. This level is a threshold, chosen prior to building
    the model, which will be used to indicate “real” findings, as opposed to those
    due to chance alone; p-values less than the significance level are considered
    **statistically significant**. If the model had few such terms, it may be a cause
    for concern, since this would indicate that the features used are not very predictive
    of the outcome. Here, our model has a few highly significant variables, and they
    seem to be related to the outcome in expected ways.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个估计的回归系数，**p值**（用`Pr(>|t|)`表示），提供了在给定估计值的情况下，真实系数为零的概率估计。小的p值表明真实系数极不可能为零，这意味着该特征极不可能与因变量没有关系。请注意，一些p值有星号（`***`），这对应于指定估计所达到的**显著性水平**的脚注。这个水平是一个阈值，在构建模型之前选择，将用于指示“真实”发现，而不是仅由偶然引起的那些；小于显著性水平的p值被认为是**统计显著的**。如果模型中这样的项很少，这可能是一个值得关注的问题，因为这表明所使用的特征对结果不是很有预测性。在这里，我们的模型有几个高度显著的自变量，并且它们似乎以预期的方式与结果相关。
- en: The **Multiple R-squared** value (also called the coefficient of determination)
    provides a measure of how well our model as a whole explains the values of the
    dependent variable. It is similar to the correlation coefficient in that the closer
    the value is to 1.0, the better the model perfectly explains the data. Since the
    R-squared value is 0.01241, we know that the model explains about 1.2 percent
    of the variation in the dependent variable. Because models with more features
    always explain more variation, the **Adjusted R-squared** value corrects R-squared
    by penalizing models with a large number of independent variables. This is useful
    for comparing the performance of models with different numbers of explanatory
    variables.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多重R平方**值（也称为确定系数）提供了衡量我们的模型整体解释因变量值好坏的指标。它与相关系数类似，即值越接近1.0，模型对数据的解释就越完美。由于R平方值为0.01241，我们知道该模型解释了因变量变化的约1.2%。由于具有更多特征的模型总是解释更多的变化，**调整R平方**值通过惩罚具有大量独立变量的模型来纠正R平方。这对于比较具有不同数量解释变量的模型性能是有用的。'
- en: Given the preceding three performance indicators, our model is performing well
    enough. The size of some of the errors is a bit concerning, but not surprising
    given the nature of insurance expense data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的三个性能指标，我们的模型表现足够好。一些误差的大小有点令人担忧，但考虑到保险费用数据的性质，这并不令人惊讶。
- en: Additionally, it is not uncommon for regression models of real-world data to
    have low R-squared values. Although a value of 0.01241 is especially low, it reflects
    the fact that we have no proximate predictors of automobile accidents; to truly
    predict accidents, we would need real-time driving data, or at least some measure
    of true driving skill. This being said, as we will see in the next section, we
    still may be able to improve the model’s performance by specifying the model in
    a slightly different way.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，现实世界数据的回归模型具有低R-squared值并不罕见。尽管0.01241的值特别低，但它反映了我们没有汽车事故的近因预测因子；要真正预测事故，我们需要实时驾驶数据，或者至少需要一些衡量真实驾驶技能的指标。话虽如此，正如我们将在下一节中看到的，我们仍然可以通过以略微不同的方式指定模型来提高模型的表现。
- en: Step 5 – improving model performance
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5步 – 提高模型性能
- en: As mentioned previously, a key difference between regression modeling and other
    machine learning approaches is that regression typically leaves feature selection
    and model specification to the user. Consequently, if we have subject-matter knowledge
    about how a feature is related to the outcome, we can use this information to
    inform the model specification and potentially improve the model’s performance.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，回归建模与其他机器学习方法的显著区别在于，回归通常将特征选择和模型指定留给用户。因此，如果我们对某个特征与结果之间的关系有专业知识，我们可以利用这些信息来指导模型指定，并可能提高模型的表现。
- en: Model specification – adding nonlinear relationships
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型指定 – 添加非线性关系
- en: In linear regression, the relationship between an independent variable and the
    dependent variable is assumed to be linear, yet this may not necessarily be true.
    For example, the effect of age on insurance expenditures may not be constant across
    all age values; the treatment may become disproportionately expensive for the
    youngest and oldest populations—a U-shaped curve, if expenses were plotted against
    age.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，假设自变量和因变量之间的关系是线性的，但这并不一定正确。例如，年龄对保险支出的影响可能不会在所有年龄值上保持恒定；对于最年轻和最年长的群体，治疗可能变得不成比例地昂贵——如果将费用与年龄绘制成曲线，则呈现U形曲线。
- en: 'If you recall, a typical regression equation follows a form similar to this:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得，典型的回归方程遵循类似以下的形式：
- en: '![](img/B17290_06_046.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_06_046.png)'
- en: 'To account for a nonlinear relationship, we can add a higher-order term to
    the regression equation, treating the model as a polynomial. In effect, we will
    be modeling a relationship like this:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 为了考虑非线性关系，我们可以在回归方程中添加一个更高阶的项，将模型视为多项式。实际上，我们将模拟如下关系：
- en: '![](img/B17290_06_047.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_06_047.png)'
- en: The difference between these two models is that an additional regression parameter
    will be estimated, which is intended to capture the effect of the *x*² term. This
    allows the impact of age to be measured as a function of age and age squared.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个模型之间的区别在于，将估计一个额外的回归参数，目的是捕捉*x*²项的影响。这允许将年龄的影响作为年龄和年龄平方的函数来衡量。
- en: 'To add the nonlinear age to the model, we simply need to create a new variable:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 要将非线性年龄添加到模型中，我们只需创建一个新的变量：
- en: '[PRE34]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Then, when we produce our improved model, we’ll add both `age` and `age2` to
    the `lm()` formula using the form `expenses ~ age + age2`. This will allow the
    model to separate the linear and nonlinear impact of age on medical expenses.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，当我们生成改进的模型时，我们将使用形式`expenses ~ age + age2`将`age`和`age2`都添加到`lm()`公式中。这将允许模型分离年龄对医疗费用的线性和非线性影响。
- en: Model specification – adding interaction effects
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型指定 – 添加交互效应
- en: So far, we have only considered each feature’s individual contribution to the
    outcome. What if certain features have a combined impact on the dependent variable?
    For instance, a habit of hard braking and late driving may have harmful effects
    separately, but it is reasonable to assume that their combined effect may be worse
    than the sum of each one alone.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只考虑了每个特征对结果的单个贡献。如果某些特征对因变量有联合影响怎么办？例如，硬刹车和晚开车的不良习惯可能分别有有害的影响，但可以合理地假设它们的联合影响可能比单独每个的影响更糟。
- en: When two features have a combined effect, this is known as an **interaction**.
    If we suspect that two variables interact, we can test this hypothesis by adding
    their interaction to the model. Interaction effects are specified using the R
    formula syntax. To interact the hard braking indicator (`hard_braking_ind`) with
    the late driving indicator (`late_driving_ind`), we would write a formula in the
    form `expenses ~ hard_braking_ind*late_driving_ind`.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个特征有联合效应时，这被称为**交互作用**。如果我们怀疑两个变量之间存在交互作用，我们可以通过将它们的交互作用添加到模型中来测试这个假设。交互作用使用R公式语法来指定。为了将硬刹车指标（`hard_braking_ind`）与晚驾指标（`late_driving_ind`）进行交互，我们将编写一个形式为`expenses
    ~ hard_braking_ind*late_driving_ind`的公式。
- en: The `*` operator is a shorthand that instructs R to model `expenses ~ hard_braking_ind
    +` `late_driving_ind` `+ hard_braking_ind:late_driving_ind`. The colon operator
    (`:`) in the expanded form indicates that `hard_braking_ind:late_driving_ind`
    is the interaction between the two variables. Note that the expanded form automatically
    also included the individual `hard_braking_ind` and `late_driving_ind` variables
    as well as their interaction.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`*`运算符是一个简写，指示R对`expenses ~ hard_braking_ind +` `late_driving_ind` `+ hard_braking_ind:late_driving_ind`进行建模。在展开形式中，冒号运算符（`:`）表示`hard_braking_ind:late_driving_ind`是两个变量之间的交互作用。请注意，展开形式自动还包括了单个`hard_braking_ind`和`late_driving_ind`变量以及它们的交互作用。'
- en: If you have trouble deciding whether to include a variable, a common practice
    is to include it and examine the p-value. If the variable is not statistically
    significant, you have a plausible justification for excluding it from the model.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在决定是否包含一个变量时遇到困难，一个常见的做法是先包含它，然后检查p值。如果变量在统计上不显著，你就有了一个合理的理由将其排除在模型之外。
- en: Putting it all together – an improved regression model
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将所有内容整合在一起——一个改进的回归模型
- en: 'Based on a bit of subject-matter knowledge of how insurance costs may be related
    to enrollee characteristics, we developed what we think is a more accurately specified
    regression formula. To summarize the improvements, we:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 基于一些关于保险成本可能与报名者特征相关的主观知识，我们开发了一个我们认为更精确指定的回归公式。为了总结改进之处，我们：
- en: Added a nonlinear term for age
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为年龄添加了一个非线性项
- en: Specified an interaction between hard braking and late driving
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定硬刹车和晚驾之间的交互作用
- en: 'We’ll train the model using the `lm()` function as before, but this time we’ll
    add the interaction term in addition to `age2`, which will be included automatically:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与之前相同的`lm()`函数来训练模型，但这次我们将添加交互项以及`age2`，它将自动包含：
- en: '[PRE35]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next, we summarize the results:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们总结一下结果：
- en: '[PRE36]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output is as follows:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE37]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Although the R-squared and adjusted R-squared values didn’t change much compared
    to the previous model, the new features present some interesting insights. In
    particular, the estimate for `age` is relatively large and negative (lower expenses)
    but `age2` is relatively small and positive (higher expenses). However, because
    age squared grows faster than age, expenses will begin to rise for very high age
    groups. The overall effect is a U-shaped expense curve, where the youngest and
    oldest enrollees are predicted to have higher expenses. The interaction of `hard_braking_ind`
    and `late_driving_ind` is also interesting, as it is a relatively large positive.
    Although the interaction is not statistically significant, the direction of the
    effect implies that driving late at night is especially dangerous if you are the
    type of driver that already drives dangerously.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管与之前的模型相比，R平方和调整R平方值变化不大，但新特征提供了一些有趣的见解。特别是，`age`的估计值相对较大且为负（支出较低），而`age2`的估计值相对较小且为正（支出较高）。然而，由于年龄平方的增长速度快于年龄，对于年龄非常高的群体，支出将会开始上升。整体效果是一个U形的支出曲线，预测最年轻和最年长的报名者将有更高的支出。`hard_braking_ind`和`late_driving_ind`的交互作用也很有趣，因为它是一个相对较大的正值。尽管交互作用在统计上不显著，但效应的方向暗示了如果你是那种已经危险驾驶的司机，那么在晚上晚些时候驾驶尤其危险。
- en: 'Strictly speaking, regression modeling makes some strong assumptions about
    the data. These assumptions are not as important for numeric forecasting, as the
    model’s worth is not based upon whether it truly captures the underlying process—we
    simply care about the accuracy of its predictions. However, if you would like
    to make firm inferences from the regression model coefficients, it is necessary
    to run diagnostic tests to ensure that the regression assumptions have not been
    violated. For an excellent introduction to this topic, see *Multiple Regression:
    A Primer, Allison, P. D., Pine Forge Press, 1998*.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 严格来说，回归建模对数据做出了一些强烈的假设。这些假设对于数值预测并不那么重要，因为模型的价值并不在于它是否真正捕捉到了潜在的过程——我们只关心其预测的准确性。然而，如果你想要从回归模型系数中得出明确的推断，就必须运行诊断测试以确保回归假设没有被违反。关于这个主题的优秀介绍，请参阅
    *《多元回归：入门》，Allison, P. D.，Pine Forge Press，1998年*。
- en: Making predictions with a regression model
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用回归模型进行预测
- en: 'After examining the estimated regression coefficients and fit statistics, we
    can also use the model to predict the expenses of future enrollees on the insurance
    plan. To illustrate the process of making predictions, let’s first apply the model
    to the original training data using the `predict()` function as follows:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查了估计的回归系数和拟合统计量之后，我们还可以使用该模型来预测保险计划未来参保人的支出。为了说明预测过程，让我们首先使用 `predict()` 函数将模型应用于原始训练数据，如下所示：
- en: '[PRE38]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This saves the predictions as a new vector named `pred` in the insurance data
    frame. We can then compute the correlation between the predicted and actual costs
    of insurance:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这将预测结果保存为名为 `pred` 的新向量，在保险数据框中。然后我们可以计算预测的保险成本与实际成本之间的相关性：
- en: '[PRE39]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The correlation of 0.11 suggests a relatively weak linear relationship between
    the predicted and actual values, which is disappointing but not too surprising
    given the seemingly random nature of motor vehicle accidents. It can also be useful
    to examine this finding as a scatterplot. The following R commands plot the relationship
    and then add an identity line with an intercept equal to zero and a slope equal
    to one. The `col`, `lwd`, and `lty` parameters affect the line color, width, and
    type, respectively:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 0.11的相关性表明预测值和实际值之间存在着相对较弱的线性关系，这在某种程度上令人失望，但鉴于交通事故看似随机的性质，这并不太令人惊讶。将这一发现作为散点图来考察也是有用的。以下R命令绘制了这种关系，并添加了一条截距为零、斜率为一的识别线。`col`、`lwd`
    和 `lty` 参数分别影响线的颜色、宽度和类型：
- en: '[PRE41]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![Chart, scatter chart  Description automatically generated](img/B17290_06_12.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![图表，散点图  自动生成的描述](img/B17290_06_12.png)'
- en: 'Figure 6.12: In this scatterplot, points falling on or near the diagonal dashed
    line where *y = x* indicate the predictions that were very close to the actual
    values'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.12：在这个散点图中，落在或接近对角虚线（*y = x*）上的点表示预测值与实际值非常接近
- en: The off-diagonal points falling above the line are cases where the actual expenses
    are greater than expected, while cases falling below the line are those less than
    expected. We can see here that a small number of people with much larger-than-expected
    expenses are balanced by a huge number of people with slightly smaller-than-expected
    expenses.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 位于线上方的非对角点表示实际支出大于预期的案例，而位于线下方的案例表示支出小于预期的案例。我们可以看到，少数支出远大于预期的个人被大量支出略小于预期的个人所平衡。
- en: 'Now, suppose you would like to forecast the expenses for potential new enrollees
    on the insurance plan. To do this, you must provide the `predict()` function a
    data frame with the prospective drivers’ data. In the case of many drivers, you
    may consider creating a CSV spreadsheet file to load in R, or for a smaller number,
    you may simply create a data frame within the `predict()` function itself. For
    example, to estimate the insurance expenses for a 30-year-old, rural driver of
    a truck valued at $25,000 driven for about 14,000 miles annually with a clean
    driving record:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设你想预测保险计划中潜在新参保人的支出。为此，你必须向 `predict()` 函数提供一个包含潜在驾驶员数据的数据框。对于许多驾驶员，你可能考虑创建一个CSV电子表格文件以在R中加载，或者对于较少的驾驶员，你可以在
    `predict()` 函数内部直接创建一个数据框。例如，为了估计一个30岁、居住在农村、驾驶价值为25,000美元的卡车、每年行驶约14,000英里且驾驶记录良好的驾驶员的保险费用：
- en: '[PRE42]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Using this value, the insurance company would need to charge about $1,015 annually
    to break even for this demographic group. To compare the rate for someone who
    is otherwise similar except for a history of a recent accident, use the `predict()`
    function in much the same way:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个值，保险公司需要每年收取约1015美元才能为这个人口群体实现盈亏平衡。要比较一个在其他方面都与上述情况相似，但最近有过事故记录的人的费率，可以使用`predict()`函数以类似的方式：
- en: '[PRE44]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Note that the difference between these two values, *1015.059 – 1247.903 = -232.844*,
    is the same as the estimated regression model coefficient for `clean_driving_ind`.
    On average, drivers with a clean history are estimated to have about $232.84 less
    in expenses for the plan per year, all else being equal.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这两个值之间的差异，*1015.059 – 1247.903 = -232.844*，与估计的回归模型系数`clean_driving_ind`相同。平均而言，拥有良好驾驶记录的驾驶员预计每年在计划上的支出将少约232.84美元，其他条件相同。
- en: 'This illustrates the more general fact that the predicted expenses are a sum
    of each of the regression coefficients times their corresponding value in the
    prediction data frame. For instance, using the model’s regression coefficient
    of 0.118748 for the miles driven, we can predict that adding 10,000 additional
    miles will result in an increase in expenses of *10,000 * 0.118748 = 1187.48*,
    which can be confirmed as follows:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 这说明了更普遍的事实，即预测的支出是每个回归系数与其预测数据框中相应值的乘积之和。例如，使用模型对行驶里程的回归系数0.118748，我们可以预测增加10,000英里将导致支出增加*10,000
    * 0.118748 = 1187.48*，如下所示：
- en: '[PRE46]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Following similar steps for a number of additional customer risk segments, the
    insurance company would be able to develop a pricing structure that fairly sets
    costs according to drivers’ estimated risk level while also maintaining a consistent
    profit across all segments.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对多个额外的客户风险细分进行类似的步骤，保险公司能够开发出一个定价结构，该结构根据驾驶员的估计风险水平公平地设定成本，同时在整个细分市场保持一致的利润。
- en: Exporting the model’s regression coefficients allows you to build your own forecasting
    function. One potential use case for doing so would be to implement the regression
    model in a customer database for real-time prediction.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 导出模型的回归系数允许你构建自己的预测函数。这样做的一个潜在用例是在客户数据库中实现回归模型，以进行实时预测。
- en: Going further – predicting insurance policyholder churn with logistic regression
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步——使用逻辑回归预测保险保单持有人流失率
- en: Actuarial estimates of claims costs are not the only potential application of
    machine learning inside an insurance company. Marketing and customer retention
    teams are likely to be very interested in predicting **churn**, or the customers
    that leave the company after choosing not to renew their insurance plan. In many
    businesses, preventing churn is highly valued, as churned customers not only reduce
    the income stream for one business but also often increase the revenue stream
    of a direct competitor. Additionally, marketing teams know that the costs of acquiring
    new customers are generally much higher than the costs of retaining an existing
    customer.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在保险公司内部，机器学习的潜在应用不仅限于对索赔成本的精算估计。营销和客户保留团队很可能对预测**流失率**，即选择不续保保险计划后离开公司的客户感兴趣。在许多业务中，防止流失率被高度重视，因为流失的客户不仅会减少一个企业的收入流，而且通常还会增加直接竞争对手的收入流。此外，营销团队知道，获取新客户的成本通常远高于保留现有客户的成本。
- en: Therefore, knowing ahead of time which customers are most likely to churn can
    help direct retention resources to intervene and prevent churn before it happens.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，提前知道哪些客户最有可能流失可以帮助将保留资源用于干预，防止流失发生。
- en: 'Historically, marketing teams have used a simple model called **recency, frequency,
    monetary value** (**RFM**) to identify highly valuable customers as well as those
    most likely to churn. The RFM analysis considers three characteristics of each
    customer:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上，营销团队使用一个名为**最近购买频率、货币价值**（**RFM**）的简单模型来识别高价值客户以及最有可能流失的客户。RFM分析考虑了每位客户的三个特征：
- en: How recently have they purchased? Customers that haven’t purchased in a while
    may be less valuable and more likely to never return.
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们最近一次购买是什么时候？一段时间没有购买的客户可能价值较低，也更可能永远不会回来。
- en: How frequently do they purchase? Do they come back year after year, or are there
    irregular gaps in their purchasing behavior? Customers that exhibit loyalty may
    be more valuable and more likely to return.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们购买频率如何？他们是一年复一年地回来，还是购买行为中存在不规则的间隔？表现出忠诚度的客户可能更有价值，也更可能回头。
- en: How much money do they spend when they purchase? Do they spend more than the
    average customer or upgrade to premium products? These customers are more valuable
    financially, but also demonstrate their love of the brand.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们在购买时花费多少钱？他们是否比平均客户花费更多或升级到高级产品？这些客户在财务上更有价值，同时也表现出对品牌的喜爱。
- en: Historical customer purchase data is collected with the intention of developing
    measures of each of these three factors. The measures are then converted into
    a standard scale (such as a scale from zero to ten) for each of the three areas
    and summed to create a final RFM score for each customer. A very recent and frequent
    purchaser that spends an average amount may have a combined score of *10 + 10
    + 5 = 25* while a customer that purchased once a long time ago may have a score
    of *2 + 1 + 4 = 7*, which places them much lower on the RFM scale.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 收集历史客户购买数据是为了开发这三个因素中每个因素的度量标准。然后，将这些度量标准转换为每个三个领域的标准尺度（例如，从零到十的尺度），并将它们相加以创建每个客户的最终
    RFM 分数。一个最近且频繁购买且平均花费的客户可能的总分为 *10 + 10 + 5 = 25*，而一个很久以前只购买过一次的客户可能得分为 *2 + 1
    + 4 = 7*，这在 RFM 尺度上要低得多。
- en: This type of analysis is a crude but useful tool for understanding a set of
    customers and helping identify the types of data that may be useful for predicting
    churn. However, an RFM analysis is not particularly scientific and provides no
    formal estimation of the probability of churn or the factors that increase its
    likelihood. In contrast, a logistic regression model predicting a binary churn
    outcome provides both an estimated probability of churn for each customer as well
    as the impact of each predictor.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分析是一种粗略但有用的工具，用于理解一组客户并帮助识别可能对预测流失有用的数据类型。然而，RFM 分析并不特别科学，也不提供正式的流失概率估计或增加其可能性的因素。相比之下，预测二元流失结果的逻辑回归模型为每个客户提供流失的估计概率，以及每个预测变量的影响。
- en: As with the insurance claims cost example, we’ll build a churn model using a
    simulated dataset created for this book, which is intended to approximate the
    behavior of customers of the automobile insurance company.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 就像保险索赔成本示例一样，我们将使用为本书创建的模拟数据集构建一个流失模型，该数据集旨在模拟汽车保险公司的客户行为。
- en: If you would like to follow along interactively, download the `insurance_churn.csv`
    file from the Packt Publishing GitHub repository for this book and save it to
    your R working folder.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想交互式地跟随学习，请从本书的 Packt Publishing GitHub 仓库下载 `insurance_churn.csv` 文件，并将其保存到您的
    R 工作文件夹中。
- en: 'The churn dataset includes 5,000 examples of current and former beneficiaries
    enrolled in the hypothetical automobile insurance plan. Each example includes
    features measuring customer behaviors in the plan year, as well as a binary indicator
    (`churn`) of whether they churned out of the plan by not renewing at the end of
    the year. The available features include:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 流失数据集包括 5,000 个当前和以前的受益人，他们参加了假设的汽车保险计划。每个示例包括衡量计划年度客户行为的特征，以及一个二进制指标（`churn`），表示他们是否在年底未续约而退出计划。可用的特征包括：
- en: '`member_id`: A randomly assigned customer identification number'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`member_id`：一个随机分配的客户识别号。'
- en: '`loyalty_years`: The number of consecutive years enrolled in the insurance
    plan'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loyalty_years`：连续参加保险计划的年数。'
- en: '`vehicles_covered`: The number of vehicles covered by the insurance plan'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vehicles_covered`：保险计划覆盖的车辆数量。'
- en: '`premium_plan_ind`: A binary indicator that the member paid for a premium,
    high-cost version of the plan with additional benefits'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`premium_plan_ind`：一个二进制指标，表示成员支付了包含额外福利的昂贵计划的高级版本。'
- en: '`mobile_app_user`: A binary indicator that the member uses the mobile phone
    companion application'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mobile_app_user`：一个二进制指标，表示成员使用手机伴侣应用程序。'
- en: '`home_auto_bundle`: A binary indicator that the member also holds a homeowner’s
    insurance plan offered by the same company'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`home_auto_bundle`：一个二进制指标，表示成员还持有由同一家公司提供的房主保险计划。'
- en: '`auto_pay_ind`: A binary indicator that the member has automatic payments turned
    on'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto_pay_ind`：一个二进制指标，表示成员已开启自动支付。'
- en: '`recent_rate_increase`: A binary indicator that the member’s price was raised
    recently'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`recent_rate_increase`：一个二进制指标，表示成员的价格最近有所提高。'
- en: Notice that many of these factors relate to the three components of RFM in that
    they are measures of loyalty and monetary value. Thus, even if a more sophisticated
    model is built later, it can still be helpful to perform an RFM analysis as an
    earlier step in the process.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，许多这些因素与RFM的三个组成部分相关，因为它们是忠诚度和货币价值的衡量标准。因此，即使后来构建了一个更复杂的模型，仍然可以在处理过程的早期步骤中进行RFM分析，这仍然是有帮助的。
- en: 'To read this dataset into R, type:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 要将此数据集读入R，请输入：
- en: '[PRE50]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Using the `table()` and `prop.table()` functions, we can see the overall churn
    rate is just over 15 percent:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `table()` 和 `prop.table()` 函数，我们可以看到整体流失率仅为15%以上：
- en: '[PRE51]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: In a more formal analysis, it would be wise to perform more data exploration
    before going further. Here, we will jump ahead to creating the logistic regression
    model to predict these churned customers.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在更正式的分析中，在进行进一步分析之前进行更多数据探索是明智的。在这里，我们将跳过创建逻辑回归模型来预测这些流失客户。
- en: 'The `glm()` function, which is part of R’s built-in `stats` package, is used
    to fit a GLM model such as logistic regression as well as the other variants like
    Poisson regression described earlier in the chapter. The syntax for logistic regression
    is shown in the following figure:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '`glm()` 函数是R内置的 `stats` 包的一部分，用于拟合GLM模型，如逻辑回归以及本章前面描述的其他变体，如泊松回归。逻辑回归的语法如下所示：'
- en: '![Text, letter  Description automatically generated](img/B17290_06_13.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![文本，字母  描述自动生成](img/B17290_06_13.png)'
- en: 'Figure 6.13: Logistic regression syntax'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.13：逻辑回归语法
- en: Note the many similarities between the `glm()` function syntax and the `lm()`
    function used earlier for standard linear regression. Aside from specifying the
    family and link function, fitting the model is no more difficult. The key differences
    are primarily in how the resulting model is interpreted.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 `glm()` 函数语法与之前用于标准线性回归的 `lm()` 函数之间的许多相似之处。除了指定家族和链接函数外，拟合模型并不更困难。主要差异主要在于如何解释生成的模型。
- en: Beware that R’s `glm()` function defaults to Gaussian with an identity link,
    so it is easy to accidentally perform standard linear regression when another
    GLM form is desired! For this reason, it is wise to form a habit of always specifying
    the family and link when building a GLM in R.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，R的 `glm()` 函数默认使用高斯分布和恒等链接，因此在需要其他GLM形式时，很容易意外地执行标准线性回归！因此，在R中构建GLM时，始终指定家族和链接是一个明智的习惯。
- en: 'To fit the logistic regression churn model, we specify the `binomial` family
    with the `logit` link function. Here, we model churn as a function of all other
    features in the dataset, minus `member_id`, which is unique to each member and
    therefore useless for prediction:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 要拟合逻辑回归流失模型，我们指定 `binomial` 家族和 `logit` 链接函数。在这里，我们将流失建模为数据集中除 `member_id` 之外所有其他特征的函数，`member_id`
    对每个成员来说是唯一的，因此对预测无用：
- en: '[PRE53]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Using `summary()` on the resulting `churn_model` object shows the estimated
    regression parameters:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `summary()` 对生成的 `churn_model` 对象进行操作，可以显示估计的回归参数：
- en: '[PRE54]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: At a high level, the logistic regression output is fairly similar to a linear
    regression output. The p-values (labeled `Pr(>|z|)`) and significance codes (denoted
    by `*` characters) indicate whether the variables are statistically significant.
    All features aside from the `auto_pay_ind` are significant at the 0.05 level or
    better. The direction of the relationship between the predictors and the target
    outcome can also be understood simply by looking at the sign (positive or negative)
    before the `Estimate` value. Nearly all estimates are negative, which implies
    that these features reduce churn, except for `recent_rate_increase`, which is
    positive and therefore increases churn. These connections make sense; an increase
    in the price of the insurance plan would be expected to increase churn, while
    members that have been loyal for years or pay for premium plan features are less
    likely to leave.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，逻辑回归的输出与线性回归的输出相当相似。p值（标记为 `Pr(>|z|)`) 和显著性代码（由 `*` 字符表示）表明变量是否具有统计学意义。除了
    `auto_pay_ind` 之外的所有特征在0.05水平或更好上都是显著的。通过查看 `Estimate` 值之前的关系（正或负）也可以简单地理解预测变量与目标结果之间的关系。几乎所有估计值都是负的，这意味着这些特征会减少流失，除了
    `recent_rate_increase` 是正的，因此会增加流失。这些联系是有意义的；预计保险计划的价格上涨会增加流失，而忠诚度多年或支付高级计划特征的成员不太可能离开。
- en: Interpreting the impact of a specific feature on churn is where logistic regression
    is trickier than linear regression, as the estimates are shown in log odds. Suppose
    we want to know how much more likely churn is after a recent increase in the price
    of the insurance plan. Since the estimate for `recent_rate_increase` is 0.6481,
    this means that the log odds of churn increase by 0.6481 when the rate increase
    indicator is `1` versus when it is `0`. Exponentiating this to remove the logarithm
    and find the odds ratio, we find that *exp(0.6481) = 1.911905*, which implies
    that churn is almost twice as likely (or 91.2 percent more likely) after a rate
    increase.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 解释特定特征对流失的影响比线性回归更困难，因为估计值以对数优势形式显示。假设我们想知道在保险计划价格最近增加后，流失的可能性增加了多少。由于`recent_rate_increase`的估计值为0.6481，这意味着当增加指标为`1`时，流失的对数优势增加0.6481，而当它为`0`时。对此进行指数化以消除对数并找到优势比，我们发现*exp(0.6481)
    = 1.911905*，这意味着在增加费率后，流失的可能性几乎是两倍（或增加了91.2%）。
- en: In the opposite direction, members that use the mobile app (`mobile_app_user`)
    have an estimated difference in log odds of -0.292273 versus those that do not.
    Finding the odds ratio as *exp(-0.292273) = 0.7465647* suggests that the churn
    of app users is about 75 percent of those that do not use the app, or a decrease
    of about 25 percent for app users. Similarly, we can find that churn is reduced
    by about seven percent for each additional year of loyalty, as *exp(-0.072284)
    = 0.9302667*. Similar calculations can be performed for all other predictors in
    the model, including the intercept, which represents the odds of churn when all
    predictors are zero.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在相反的方向上，使用移动应用（`mobile_app_user`）的成员与未使用应用的成员相比，估计的对数优势差异为-0.292273。将优势比计算为*exp(-0.292273)
    = 0.7465647*表明，应用用户的流失率大约是未使用应用用户的75%，或者应用用户减少了大约25%。同样，我们可以发现，对于忠诚度每增加一年，流失率会减少大约7%，如*exp(-0.072284)
    = 0.9302667*。对于模型中的所有其他预测因子，包括截距（代表所有预测因子为零时的流失优势），都可以进行类似的计算。
- en: 'To use this model to prevent churn, we can make predictions on a database of
    current plan members. Let’s begin by loading a dataset containing 1000 subscribers,
    using the `test` dataset available for this chapter:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用此模型来防止流失，我们可以在当前计划成员的数据库上进行预测。让我们从这个章节可用的`test`数据集开始，加载包含1000个订阅者的数据集：
- en: '[PRE56]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We’ll then use the logistic regression model object with the `predict()` function
    to add a new column to this data frame, which contains the predictions for each
    member:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用带有`predict()`函数的逻辑回归模型对象来向这个数据框添加一个新列，其中包含每个成员的预测值：
- en: '[PRE57]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Note that the `type = "response"` parameter is set so that the predictions are
    in probabilities rather than the default `type = "link"` setting, which produces
    predictions as log odds values.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`type = "response"`参数被设置为使预测以概率形式呈现，而不是默认的`type = "link"`设置，后者以对数优势值的形式产生预测。
- en: 'Summarizing these predicted probabilities, we see that the average churn probability
    is about 15 percent, but some users are predicted to have very low churn, while
    others have a churn probability as high as 41 percent:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 总结这些预测概率，我们看到平均流失概率大约为15%，但一些用户预测的流失率非常低，而其他用户的流失概率高达41%：
- en: '[PRE58]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Suppose the customer retention team has the resources to intervene in a limited
    number of cases. By sorting the members to identify those with the highest predicted
    churn likelihood, we can provide the team with the direction most likely to make
    the greatest impact.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 假设客户保留团队有资源在有限数量的案例中干预。通过排序成员以识别那些预测流失可能性最高的成员，我们可以为团队提供最有可能产生最大影响的指导方向。
- en: 'First, use the `order()` function to obtain a vector with the row numbers sorted
    in decreasing order according to their churn probability:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用`order()`函数获取一个按流失概率降序排列的行号向量：
- en: '[PRE60]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Next, after ordering the `churn_test` data frame according to the `churn_order`
    vector and taking the two columns of interest, use the `head()` function to take
    the top `n` rows; in this case, we’ll set `n = 5` to limit to the five members
    most likely to churn:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在根据`churn_order`向量对`churn_test`数据框进行排序并取两个感兴趣的列之后，使用`head()`函数取前`n`行；在这种情况下，我们将`n
    = 5`设置为限制流失可能性最高的五个成员：
- en: '[PRE61]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: After saving the result to a spreadsheet with `n` set to a higher number, it
    would be possible to provide the customer retention team with a list of the insurance
    plan members that are most likely to churn. Focusing retention efforts on these
    members is likely to be a more fruitful use of the marketing budget than targeting
    members at random, as most members have a very low churn probability. In this
    way, machine learning can provide a substantial return on minimal investment,
    with an impact that is easily quantifiable by comparing the churn rates before
    and after this intervention.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在将结果保存到具有`n`设置为更高数值的电子表格后，就可以为保留团队提供一份最有可能流失的保险计划成员名单。将保留努力集中在这些成员上，可能比随机针对成员更有利于营销预算的利用，因为大多数成员的流失概率非常低。通过这种方式，机器学习可以在最小投资的情况下提供实质性的回报，其影响可以通过比较干预前后的流失率来轻松量化。
- en: Estimates of revenue retained as a result of churn prevention can be obtained
    using simple assumptions about the proportion of customers that will respond to
    retention efforts. For example, if we assume *N* of members targeted by the churn
    model will be retained, this will result in *N* times *$X* retained revenue, where
    *$X* is the average customer spend. Bringing this number to stakeholders helps
    provide justification for implementing the machine learning project.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过关于将响应保留努力的客户比例的简单假设来获得防止客户流失所保留的收益的估计。例如，如果我们假设流失模型针对的*N*名成员将被保留，这将导致*N*倍的*$X*保留收入，其中*$X*是平均客户消费。将这个数字带给利益相关者有助于为实施机器学习项目提供正当理由。
- en: The example is only the tip of the iceberg, as churn modeling can become much
    more sophisticated with additional efforts. For instance, rather than targeting
    the customers with the highest churn probability, it is also possible to consider
    the revenue lost if the customer churns; it may be worth prioritizing high-value
    customers even if they have a lower churn probability than a low-value customer.
    Additionally, because some customers are assured to churn regardless of intervention
    while others may be more flexible about staying, it is possible to model retention
    likelihood in addition to modeling churn probability. In any case, even in a simple
    form, churn modeling is low-hanging fruit for most businesses and a great first
    place to implement machine learning.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子只是冰山一角，因为通过额外的努力，客户流失建模可以变得更加复杂。例如，我们不仅可以将目标对准流失概率最高的客户，还可以考虑如果客户流失将失去的收入；即使比低价值客户流失概率低，优先考虑高价值客户也可能是值得的。此外，由于一些客户无论是否干预都肯定会流失，而另一些客户可能更愿意留下，因此除了建模流失概率外，还可以建模保留的可能性。在任何情况下，即使以简单形式，客户流失建模对大多数企业来说都是低垂的果实，并且是实施机器学习的绝佳起点。
- en: Understanding regression trees and model trees
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解回归树和模型树
- en: If you recall from *Chapter 5*, *Divide and Conquer – Classification Using Decision
    Trees and Rules*, a decision tree builds a model, much like a flowchart, in which
    decision nodes, leaf nodes, and branches define a series of decisions, which are
    used to classify examples. Such trees can also be used for numeric prediction
    by making only small adjustments to the tree-growing algorithm. In this section,
    we will consider the ways in which trees for numeric prediction differ from trees
    used for classification.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得*第5章*，*分而治之 – 使用决策树和规则进行分类*，决策树构建了一个模型，就像流程图一样，其中决策节点、叶节点和分支定义了一系列决策，这些决策用于分类示例。这样的树也可以通过仅对树生长算法进行微小调整来用于数值预测。在本节中，我们将考虑用于数值预测的树与用于分类的树的不同之处。
- en: Trees for numeric prediction fall into two categories. The first, known as **regression
    trees**, were introduced in the 1980s as part of the seminal **classification
    and regression tree** (**CART**) algorithm. Despite the name, regression trees
    do not use linear regression methods as described earlier in this chapter; rather,
    they make predictions based on the average value of examples that reach a leaf.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 用于数值预测的树分为两类。第一类，称为**回归树**，在20世纪80年代作为**分类与回归树**（**CART**）算法的一部分被引入。尽管名称如此，回归树并不使用本章前面描述的线性回归方法；相反，它们根据达到叶节点的示例的平均值进行预测。
- en: The CART algorithm is described in detail in *Classification and Regression
    Trees, Breiman, L., Friedman, J. H., Stone, C. J., Olshen, R. A., Chapman and
    Hall, 1984*.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: CART算法在*《分类与回归树》，Breiman, L.，Friedman, J. H.，Stone, C. J.，Olshen, R. A.，Chapman
    and Hall，1984*中有详细描述。
- en: The second type of tree for numeric prediction is known as a **model tree**.
    Introduced several years later than regression trees, they are less widely known,
    but perhaps more powerful. Model trees are grown in much the same way as regression
    trees, but at each leaf, a multiple linear regression model is built from the
    examples reaching that node. Depending on the number of leaf nodes, a model tree
    may build tens or even hundreds of such models.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 用于数值预测的第二种树被称为**模型树**。比回归树晚几年引入，它们不太为人所知，但可能更强大。模型树的生长方式与回归树非常相似，但在每个叶节点，都会从到达该节点的示例中构建一个多元线性回归模型。根据叶节点的数量，模型树可能会构建数十甚至数百个这样的模型。
- en: This makes model trees more difficult to understand than the equivalent regression
    tree, with the benefit that they may result in a more accurate model.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得模型树比等效的回归树更难以理解，但它们可能产生更精确的模型。
- en: The earliest model tree algorithm, **M5**, is described in *Learning with continuous
    classes, Quinlan, J. R., Proceedings of the 5th Australian Joint Conference on
    Artificial Intelligence, 1992, pp. 343-348*.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 最早的模型树算法**M5**在*使用连续类别的学习，Quinlan, J. R.，第五次澳大利亚联合人工智能会议论文集，1992年，第343-348页*中进行了描述。
- en: Adding regression to trees
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将回归添加到树中
- en: 'Trees that can perform numeric prediction offer a compelling, yet often overlooked,
    alternative to regression modeling. The strengths and weaknesses of regression
    trees and model trees relative to the more common regression methods are listed
    in the following table:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 能够执行数值预测的树提供了一个引人注目但往往被忽视的回归建模替代方案。以下表格列出了相对于更常见的回归方法，回归树和模型树的优缺点：
- en: '| **Strengths** | **Weaknesses** |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| **优点** | **缺点** |'
- en: '|'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Combines the strengths of decision trees with the ability to model numeric data
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合了决策树的优势以及建模数值数据的能力
- en: Does not require the user to specify the model in advance
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不需要用户事先指定模型
- en: Uses automatic feature selection, which allows the approach to be used with
    a very large number of features
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自动特征选择，这使得方法可以与大量特征一起使用
- en: May fit some types of data much better than linear regression
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能比线性回归更适合某些类型的数据
- en: Does not require knowledge of statistics to interpret the model
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释模型不需要了解统计学知识
- en: '|'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Not as well known as linear regression
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不如线性回归知名
- en: Requires a large amount of training data
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要大量的训练数据
- en: Difficult to determine the overall net effect of individual features on the
    outcome
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难以确定单个特征对结果的整体净效应
- en: Large trees can become more difficult to interpret than a regression model
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大树可能比回归模型更难以解释
- en: '|'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Though traditional regression methods are typically the first choice for numeric
    prediction tasks, in some cases, numeric decision trees offer distinct advantages.
    For instance, decision trees may be better suited for tasks with many features
    or many complex, nonlinear relationships between features and the outcome; these
    situations present challenges for regression. Regression modeling also makes assumptions
    about the data that are often violated in real-world data; this is not the case
    for trees.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管传统的回归方法通常是数值预测任务的第一个选择，但在某些情况下，数值决策树提供了独特的优势。例如，决策树可能更适合具有许多特征或特征与结果之间存在许多复杂、非线性关系的任务；这些情况对回归构成了挑战。回归建模也假设数据具有某些属性，但在现实世界的数据中这些属性通常被违反；而对于树来说并非如此。
- en: Trees for numeric prediction are built in much the same way as they are for
    classification. Beginning at the root node, the data is partitioned using a divide-and-conquer
    strategy according to the feature that will result in the greatest increase in
    homogeneity in the outcome after a split is performed.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 用于数值预测的树与用于分类的树构建方式非常相似。从根节点开始，数据根据将导致分割后结果同质性最大增加的特征，使用分而治之的策略进行分区。
- en: In classification trees, you will recall that homogeneity is measured by entropy.
    This is undefined for numeric data. Instead, for numeric decision trees, homogeneity
    is measured by statistics such as variance, standard deviation, or absolute deviation
    from the mean.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类树中，你可能记得同质性是通过熵来衡量的。对于数值数据，这将是未定义的。相反，对于数值决策树，同质性是通过诸如方差、标准差或平均值的绝对偏差等统计量来衡量的。
- en: 'One common splitting criterion is called the **standard deviation reduction**
    (**SDR**). It is defined by the following formula:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的分割标准被称为**标准差减少**（**SDR**）。它由以下公式定义：
- en: '![](img/B17290_06_048.png)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B17290_06_048.png)'
- en: In this formula, the *sd*(*T*) function refers to the standard deviation of
    the values in set *T*, while *T*[1], *T*[2], ..., *T*[n] are sets of values resulting
    from a split on a feature. The *|T|* term refers to the number of observations
    in set *T*. Essentially, the formula measures the reduction in standard deviation
    by comparing the standard deviation pre-split to the weighted standard deviation
    post-split.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，*sd*(*T*)函数指的是集合*T*中值的标准差，而*T*[1]，*T*[2]，...，*T*[n]是特征分割后得到的值集。*|T|*项指的是集合*T*中的观测值数量。本质上，该公式通过比较分割前后的加权标准差来衡量标准差的减少。
- en: 'For example, consider the following case in which a tree is deciding whether
    to perform a split on binary feature A or a split on binary feature B:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下情况，其中树正在决定是否在二元特征A上进行分割或在二元特征B上进行分割：
- en: '![Table  Description automatically generated](img/B17290_06_14.png)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![表格描述自动生成](img/B17290_06_14.png)'
- en: 'Figure 6.14: The algorithm considers splits on features A and B, which creates
    different T[1] and T[2] groups'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.14：算法考虑在特征A和B上进行分割，这会创建不同的T[1]和T[2]组
- en: Using the groups that would result from the proposed splits, we can compute
    the SDR for A and B as follows. The `length()` function used here returns the
    number of elements in a vector. Note that the overall group T is named `tee` to
    avoid overwriting R’s built-in `T()` and `t()` functions.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 使用由提议的分割产生的组，我们可以计算A和B的SDR如下。这里使用的`length()`函数返回向量的元素数量。请注意，整体组T被命名为`tee`，以避免覆盖R的内置`T()`和`t()`函数。
- en: '[PRE63]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Let’s compare the SDR of A against the SDR of B:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较A的SDR与B的SDR：
- en: '[PRE64]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: The SDR for the split on feature A was about 1.2 versus 1.4 for the split on
    feature B. Since the standard deviation was reduced more for the split on B, the
    decision tree would use B first. It results in slightly more homogeneous sets
    than does A.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征A上的分割SDR约为1.2，而在特征B上的分割SDR为1.4。由于B的分割降低了更多的标准差，决策树将首先使用B。这比A产生了稍微更均匀的集合。
- en: Suppose that the tree stopped growing here using this one and only split. A
    regression tree’s work is done. It can make predictions for new examples depending
    on whether the example’s value on feature B places the example into group *T*[1]
    or *T*[2]. If the example ends up in *T*[1], the model would predict *mean*(*bt1*)
    = *2*, otherwise it would predict *mean*(*bt2*) = *6.25*.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 假设树在这里停止生长，使用这个唯一的一次分割。回归树的工作就完成了。它可以根据示例在特征B上的值，将示例放入组*T*[1]或*T*[2]，从而对新示例进行预测。如果示例最终落在*T*[1]中，模型将预测*mean*(*bt1*)
    = *2*，否则它将预测*mean*(*bt2*) = *6.25*。
- en: In contrast, a model tree would go one step further. Using the seven training
    examples falling in group *T*[1] and the eight in *T*[2], the model tree could
    build a linear regression model of the outcome versus feature A. Note that feature
    B is of no help in building the regression model because all examples at the leaf
    have the same value of B—they were placed into *T*[1] or *T*[2] according to their
    value of B. The model tree can then make predictions for new examples using either
    of the two linear models.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，模型树会更进一步。使用落在*T*[1]组的七个训练示例和*T*[2]组的八个示例，模型树可以构建一个关于特征A的线性回归模型。请注意，特征B在构建回归模型时没有帮助，因为所有叶节点上的B值都相同——它们根据B的值被放入*T*[1]或*T*[2]。然后模型树可以使用这两个线性模型中的任何一个对新示例进行预测。
- en: To further illustrate the differences between these two approaches, let’s work
    through a real-world example.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步说明这两种方法之间的差异，让我们通过一个现实世界的例子来分析。
- en: Example – estimating the quality of wines with regression trees and model trees
  id: totrans-428
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 - 使用回归树和模型树估计葡萄酒的质量
- en: Winemaking is a challenging and competitive business, which offers the potential
    for great profit. However, there are numerous factors that contribute to the profitability
    of a winery. As an agricultural product, variables as diverse as the weather and
    the growing environment impact the quality of a varietal. The bottling and manufacturing
    can also affect the flavor for better or worse. Even the way the product is marketed,
    from the bottle design to the price point, can affect the customer’s perception
    of the taste.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 葡萄酒酿造是一项具有挑战性和竞争性的业务，具有巨大的盈利潜力。然而，有许多因素会影响酒庄的盈利能力。作为一个农产品，从天气到生长环境等各种各样的变量都会影响品种的质量。装瓶和制造也可能影响口味，无论是好是坏。甚至产品的营销方式，从瓶子设计到价格点，都可能影响顾客对味道的认知。
- en: Consequently, the winemaking industry has invested heavily in data collection
    and machine learning methods that may assist with the decision science of winemaking.
    For example, machine learning has been used to discover key differences in the
    chemical composition of wines from different regions, and to identify the chemical
    factors that lead a wine to taste sweeter.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，酿酒业在数据收集和可能协助酿酒决策科学的机器学习方法上投入了大量资金。例如，机器学习已被用于发现不同地区葡萄酒化学成分的关键差异，以及识别导致葡萄酒味道更甜的化学因素。
- en: More recently, machine learning has been employed to assist with rating the
    quality of wine—a notoriously difficult task. A review written by a renowned wine
    critic often determines whether the product ends up on the top or bottom shelf,
    in spite of the fact that even expert judges are inconsistent when rating a wine
    in a blinded test.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，机器学习已被用于协助评估葡萄酒的质量——这是一个众所周知困难的任务。一篇由著名葡萄酒评论家撰写的评论通常决定了产品最终会放在货架的顶部还是底部，尽管即使是专家评委在盲品测试中对葡萄酒的评分也不一致。
- en: In this case study, we will use regression trees and model trees to create a
    system capable of mimicking expert ratings of wine. Because trees result in a
    model that is readily understood, this could allow winemakers to identify key
    factors that contribute to better-rated wines. Perhaps more importantly, the system
    does not suffer from the human elements of tasting, such as the rater’s mood or
    palate fatigue. Computer-aided wine testing may therefore result in a better product,
    as well as more objective, consistent, and fair ratings.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 在本案例研究中，我们将使用回归树和模型树创建一个能够模仿专家葡萄酒评分的系统。由于树可以产生易于理解的模型，这可能会让酿酒师识别出有助于获得更高评分的关键因素。也许更重要的是，该系统不受品尝过程中的人类因素影响，如评分者的情绪或味蕾疲劳。因此，计算机辅助的葡萄酒测试可能因此产生更好的产品，以及更客观、一致和公平的评分。
- en: Step 1 – collecting data
  id: totrans-433
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步 – 收集数据
- en: To develop the wine rating model, we will use data donated to the UCI Machine
    Learning Repository ([http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml))
    by P. Cortez, A. Cerdeira, F. Almeida, T. Matos, and J. Reis. Their dataset includes
    examples of red and white Vinho Verde wines from Portugal—one of the world’s leading
    wine-producing countries. Because the factors that contribute to a highly rated
    wine may differ between the red and white varieties, for this analysis we will
    examine only the more popular white wines.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开发葡萄酒评分模型，我们将使用P. Cortez、A. Cerdeira、F. Almeida、T. Matos和J. Reis捐赠给UCI机器学习仓库（[http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)）的数据。他们的数据集包括来自葡萄牙的红色和白色Vinho
    Verde葡萄酒的示例——葡萄牙是世界上领先的葡萄酒生产国之一。由于影响高度评分葡萄酒的因素可能在红葡萄酒和白葡萄酒品种之间有所不同，因此，在本分析中，我们将仅检查更受欢迎的白葡萄酒。
- en: To follow along with this example, download the `whitewines.csv` file from the
    Packt Publishing GitHub repository for this book and save it to your R working
    directory. The `redwines.csv` file is also available in case you would like to
    explore this data on your own.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟随这个示例，请从本书的Packt Publishing GitHub仓库下载`whitewines.csv`文件，并将其保存到您的R工作目录中。如果您想自己探索这些数据，`redwines.csv`文件也是可用的。
- en: The white wine data includes information on 11 chemical properties of 4,898
    wine samples. For each wine, a laboratory analysis measured characteristics such
    as acidity, sugar content, chlorides, sulfur, alcohol, pH, and density. The samples
    were then rated in a blind tasting by panels of no less than three judges on a
    quality scale ranging from 0 (very bad) to 10 (excellent). In the case that the
    judges disagreed on the rating, the median value was used.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 白葡萄酒数据包括4,898个酒样11种化学特性的信息。对于每一款酒，实验室分析测量了如酸度、糖含量、氯化物、硫、酒精、pH值和密度等特征。然后，由不少于三位评委在从0（非常差）到10（优秀）的质量等级上进行盲品评分。如果评委对评分有分歧，则使用中位数值。
- en: 'The study by Cortez evaluated the ability of three machine learning approaches
    to model the wine data: multiple regression, artificial neural networks, and support
    vector machines. We covered multiple regression earlier in this chapter, and we
    will learn about neural networks and support vector machines in *Chapter 7*, *Black-Box
    Methods – Neural Networks and Support Vector Machines*. The study found that the
    support vector machine offered significantly better results than the linear regression
    model. However, unlike regression, the support vector machine model is difficult
    to interpret. Using regression trees and model trees, we may be able to improve
    the regression results while still having a model that is relatively easy to understand.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: Cortez的研究评估了三种机器学习方法建模葡萄酒数据的能力：多元回归、人工神经网络和支持向量机。我们在本章前面介绍了多元回归，我们将在*第7章*，*黑盒方法
    – 神经网络和支持向量机*中学习神经网络和支持向量机。该研究发现，支持向量机模型比线性回归模型提供了显著更好的结果。然而，与回归不同，支持向量机模型难以解释。使用回归树和模型树，我们可能能够在保持模型相对容易理解的同时提高回归结果。
- en: To read more about the wine study described here, refer to *Modeling wine preferences
    by data mining from physicochemical properties, Cortez, P., Cerdeira, A., Almeida,
    F., Matos, T., and Reis, J., Decision Support Systems, 2009, Vol. 47, pp. 547-553*.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于这里描述的葡萄酒研究的信息，请参阅*Cortez, P.，Cerdeira, A.，Almeida, F.，Matos, T.，和Reis,
    J.，通过数据挖掘物理化学特性建模葡萄酒偏好，决策支持系统，2009年，第47卷，第547-553页*。
- en: Step 2 – exploring and preparing the data
  id: totrans-439
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步 – 探索和准备数据
- en: 'As usual, we will use the `read.csv()` function to load the data into R. Since
    all features are numeric, we can safely ignore the `stringsAsFactors` parameter:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，我们将使用`read.csv()`函数将数据加载到R中。由于所有特征都是数值型的，我们可以安全地忽略`stringsAsFactors`参数：
- en: '[PRE68]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The `wine` data includes 11 features and the quality outcome, as follows:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '`wine`数据包括11个特征和品质结果，如下所示：'
- en: '[PRE69]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Compared with other types of machine learning models, one of the advantages
    of trees is that they can handle many types of data without preprocessing. This
    means we do not need to normalize or standardize the features.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他类型的机器学习模型相比，树模型的一个优点是它们可以处理许多类型的数据而无需预处理。这意味着我们不需要对特征进行归一化或标准化。
- en: 'However, a bit of effort to examine the distribution of the outcome variable
    is needed to inform our evaluation of the model’s performance. For instance, suppose
    that there was very little variation in quality from wine to wine, or that wines
    fell into a bimodal distribution: either very good or very bad. This may impact
    the way we design the model. To check for such extremes, we can examine the distribution
    of wine quality using a histogram:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了了解模型性能的评估，我们需要对结果变量的分布进行一些检查。例如，假设葡萄酒之间的质量变化非常小，或者葡萄酒落入双峰分布：要么非常好，要么非常差。这可能会影响我们设计模型的方式。为了检查这种极端情况，我们可以使用直方图检查葡萄酒质量的分布：
- en: '[PRE71]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'This produces the following figure:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下图示：
- en: '![Chart, bar chart  Description automatically generated](img/B17290_06_15.png)'
  id: totrans-449
  prefs: []
  type: TYPE_IMG
  zh: '![图表，条形图  自动生成的描述](img/B17290_06_15.png)'
- en: 'Figure 6.15: The distribution of the quality ratings of white wines'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.15：白葡萄酒质量评分的分布
- en: The wine quality values appear to follow a roughly normal, bell-shaped distribution,
    centered around a value of six. This makes sense intuitively, because most wines
    are of average quality; few are particularly bad or good. Although the results
    are not shown here, it is also useful to examine the `summary(wine)` output for
    outliers or other potential data problems. Even though trees are fairly robust
    to messy data, it is always prudent to check for severe problems. For now, we’ll
    assume that the data is reliable.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 葡萄酒质量值似乎遵循一个大致正常的、钟形的分布，中心值为六。从直观上看，这是有道理的，因为大多数葡萄酒的平均质量；很少有特别差或好的。尽管这里没有显示结果，但检查`summary(wine)`输出以查找异常值或其他潜在的数据问题也是有用的。尽管树模型对杂乱的数据相当稳健，但始终检查严重问题总是谨慎的。目前，我们假设数据是可靠的。
- en: 'Our last step, then, is to divide the dataset into training and testing sets.
    Since the `wine` dataset was already sorted randomly, we can partition it into
    two sets of contiguous rows as follows:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的最后一步是将数据集划分为训练集和测试集。由于`wine`数据集已经被随机排序，我们可以将其划分为两个连续行集，如下所示：
- en: '[PRE72]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: In order to mirror the conditions used by Cortez, we used sets of 75 percent
    and 25 percent for training and testing, respectively. We’ll evaluate the performance
    of our tree-based models on the testing data to see if we can obtain results comparable
    to the prior research study.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与 Cortez 使用的条件相匹配，我们分别使用了 75% 和 25% 的数据集用于训练和测试。我们将评估基于树的模型在测试数据上的性能，以查看我们是否能获得与先前研究相似的结果。
- en: Step 3 – training a model on the data
  id: totrans-455
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 3 步 – 在数据上训练模型
- en: We will begin by training a regression tree model. Although almost any implementation
    of decision trees can be used to perform regression tree modeling, the `rpart`
    (recursive partitioning) package offers the most faithful implementation of regression
    trees as they were described by the CART team. As the classic R implementation
    of CART, the `rpart` package is also well documented and supported with functions
    for visualizing and evaluating the `rpart` models.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先训练一个回归树模型。尽管几乎任何决策树的实现都可以用于回归树建模，但 `rpart`（递归分区）包提供了最忠实的回归树实现，正如 CART 团队所描述的那样。作为经典的
    R 实现 CART，`rpart` 包也具有良好的文档支持，并提供了用于可视化和评估 `rpart` 模型的函数。
- en: Install the `rpart` package using the `install.packages("rpart")` command. It
    can then be loaded into your R session using the `library(rpart)` statement. The
    following syntax will train a tree using the default settings, which work well
    most of the time, but not always. If you need more fine-tuned settings, refer
    to the documentation for the control parameters using the `?rpart.control` command.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `install.packages("rpart")` 命令安装 `rpart` 包。然后可以使用 `library(rpart)` 语句将其加载到您的
    R 会话中。以下语法将使用默认设置训练一个树，这些设置在大多数情况下都很好，但并不总是如此。如果您需要更精细的设置，请参阅 `?rpart.control`
    命令的文档以了解控制参数。
- en: '![Text  Description automatically generated](img/B17290_06_16.png)'
  id: totrans-458
  prefs: []
  type: TYPE_IMG
  zh: '![文本描述自动生成](img/B17290_06_16.png)'
- en: 'Figure 6.16: Regression tree syntax'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.16：回归树语法
- en: 'Using the R formula interface, we can specify `quality` as the outcome variable
    and use the dot notation to allow all other columns in the `wine_train` data frame
    to be used as predictors. The resulting regression tree model object is named
    `m.rpart` to distinguish it from the model tree we will train later:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 R 公式接口，我们可以将 `quality` 指定为结果变量，并使用点符号允许 `wine_train` 数据框中的所有其他列用作预测变量。生成的回归树模型对象命名为
    `m.rpart`，以区分我们稍后将要训练的模型树：
- en: '[PRE73]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'For basic information about the tree, simply type the name of the model object:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取关于树的基本信息，只需输入模型对象的名称：
- en: '[PRE74]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: For each node in the tree, the number of examples reaching the decision point
    is listed. For instance, all 3,750 examples begin at the root node, of which 2,372
    have `alcohol < 10.85` and 1,378 have `alcohol >= 10.85`. Because `alcohol` was
    used first in the tree, it is the single most important predictor of wine quality.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 对于树中的每个节点，都会列出到达决策点的示例数量。例如，所有 3,750 个示例都从根节点开始，其中 2,372 个具有 `alcohol < 10.85`，1,378
    个具有 `alcohol >= 10.85`。因为 `alcohol` 在树中首先被使用，所以它是葡萄酒质量的最重要预测变量。
- en: Nodes indicated by `*` are terminal or leaf nodes, which means that they result
    in a prediction (listed here as `yval`). For example, node 5 has a `yval` of 5.971091\.
    When the tree is used for predictions, any wine samples with `alcohol < 10.85`
    and `volatile.acidity < 0.2275` would therefore be predicted to have a quality
    value of 5.97.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 由 `*` 标记的节点是终端或叶节点，这意味着它们会导致一个预测（在此处列为 `yval`）。例如，节点 5 的 `yval` 值为 5.971091。当使用此树进行预测时，任何酒精含量小于
    10.85 且挥发性酸度小于 0.2275 的葡萄酒样品都会被预测为具有 5.97 的质量值。
- en: A more detailed summary of the tree’s fit, including the mean squared error
    for each of the nodes and an overall measure of feature importance, can be obtained
    using the `summary(m.rpart)` command.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `summary(m.rpart)` 命令可以获得关于树拟合的更详细摘要，包括每个节点的均方误差以及特征重要性的总体度量。
- en: Visualizing decision trees
  id: totrans-468
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化决策树
- en: Although the tree can be understood using only the preceding output, it is often
    more readily understood using visualization. The `rpart.plot` package by Stephen
    Milborrow provides an easy-to-use function that produces publication-quality decision
    trees.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以使用前面的输出理解树，但使用可视化通常更容易理解。Stephen Milborrow 的 `rpart.plot` 包提供了一个易于使用的函数，可以生成高质量的决策树。
- en: For more information on `rpart.plot`, including additional examples of the types
    of decision tree diagrams the function can produce, refer to the author’s website
    at [http://www.milbo.org/rpart-plot/](http://www.milbo.org/rpart-plot/).
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`rpart.plot`的更多信息，包括该函数可以生成的决策树图类型的额外示例，请参阅作者的网站[http://www.milbo.org/rpart-plot/](http://www.milbo.org/rpart-plot/)。
- en: 'After installing the package using the `install.packages("rpart.plot")` command,
    the `rpart.plot()` function produces a tree diagram from any `rpart` model object.
    The following commands plot the regression tree we built earlier:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`install.packages("rpart.plot")`命令安装包后，`rpart.plot()`函数可以从任何`rpart`模型对象生成树形图。以下命令绘制了我们之前构建的回归树：
- en: '[PRE76]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The resulting tree diagram is as follows:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的树形图如下：
- en: '![Diagram  Description automatically generated](img/B17290_06_17.png)'
  id: totrans-474
  prefs: []
  type: TYPE_IMG
  zh: '![图示  描述自动生成](img/B17290_06_17.png)'
- en: 'Figure 6.17: A visualization of the wine quality regression tree model'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.17：葡萄酒质量回归树模型的可视化
- en: 'In addition to the `digits` parameter, which controls the number of numeric
    digits to include in the diagram, many other aspects of the visualization can
    be adjusted. The following command shows just a few of the useful options:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 除了控制图中包含的数字位数的`digits`参数外，许多其他可视化方面都可以进行调整。以下命令显示了其中一些有用的选项：
- en: '[PRE77]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: The `fallen.leaves` parameter forces the leaf nodes to be aligned at the bottom
    of the plot, while the `type` and `extra` parameters affect the way the decisions
    and nodes are labeled. The numbers `3` and `101` refer to specific style formats,
    which can be found in the command’s documentation or via experimentation with
    various numbers.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '`fallen.leaves`参数强制叶节点对齐在图的底部，而`type`和`extra`参数影响决策和节点标签的方式。数字`3`和`101`指的是特定的样式格式，可以在命令的文档中找到，或者通过尝试不同的数字进行实验。'
- en: 'The result of these changes is a very different-looking tree diagram:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 这些更改的结果是一个看起来非常不同的树形图：
- en: '![Diagram  Description automatically generated](img/B17290_06_18.png)'
  id: totrans-480
  prefs: []
  type: TYPE_IMG
  zh: '![图示  描述自动生成](img/B17290_06_18.png)'
- en: 'Figure 6.18: Changing the plot function parameters allows customization of
    the tree visualization'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.18：更改绘图函数参数允许自定义树形可视化
- en: Visualizations like these may assist with the dissemination of regression tree
    results, as they are readily understood even without a mathematics background.
    In both cases, the numbers shown in the leaf nodes are the predicted values for
    the examples reaching that node. Showing the diagram to the wine producers may
    thus help to identify the key factors involved in predicting higher-rated wines.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的可视化有助于传播回归树结果，因为即使没有数学背景也能轻松理解。在两种情况下，叶节点中显示的数字都是到达该节点的示例的预测值。因此，向葡萄酒生产商展示此图可能有助于识别预测高分葡萄酒的关键因素。
- en: Step 4 – evaluating model performance
  id: totrans-483
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步 – 评估模型性能
- en: 'To use the regression tree model to make predictions on the test data, we use
    the `predict()` function. By default, this returns the estimated numeric value
    for the outcome variable, which we’ll save in a vector named `p.rpart`:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用回归树模型对测试数据进行预测，我们使用`predict()`函数。默认情况下，这返回了结果变量的估计数值，我们将将其保存在名为`p.rpart`的向量中：
- en: '[PRE78]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'A quick look at the summary statistics of our predictions suggests a potential
    problem: the predictions fall into a much narrower range than the true values:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查看预测的摘要统计数据显示了一个潜在问题：预测值落在比真实值更窄的范围内：
- en: '[PRE79]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: This finding suggests that the model is not correctly identifying the extreme
    cases, and in particular, the best and worst wines. On the other hand, between
    the first and third quartile, we may be doing well.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 这个发现表明，模型没有正确识别极端情况，特别是最好的和最差的葡萄酒。另一方面，在第一和第三四分位数之间，我们可能做得很好。
- en: 'The correlation between the predicted and actual quality values provides a
    simple way to gauge the model’s performance. Recall that the `cor()` function
    can be used to measure the relationship between two equal-length vectors. We’ll
    use this to compare how well the predicted values correspond to the true values:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 预测值和实际质量值之间的相关性提供了一个简单的方法来衡量模型的表现。回想一下，`cor()`函数可以用来测量两个等长向量之间的关系。我们将使用它来比较预测值与真实值之间的对应程度：
- en: '[PRE83]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: A correlation of `0.54` is certainly acceptable. However, the correlation only
    measures how strongly the predictions are related to the true value; it is not
    a measure of how far off the predictions were from the true values.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '`0.54`的相关性当然是可以接受的。然而，相关性仅衡量预测与真实值之间的相关性强度；它不是衡量预测偏离真实值程度的指标。'
- en: Measuring performance with the mean absolute error
  id: totrans-496
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用平均绝对误差衡量性能
- en: Another way to think about the model’s performance is to consider how far, on
    average, its prediction was from the true value. This measurement is called the
    **mean absolute error** (**MAE**).
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种思考模型性能的方法是考虑其预测值平均偏离真实值的程度。这种测量称为**平均绝对误差**（**MAE**）。
- en: 'The equation for MAE is as follows, where *n* indicates the number of predictions
    and *e*[i] indicates the error for prediction *i*:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: MAE的公式如下，其中*n*表示预测的数量，而*e*[i]表示预测*i*的错误：
- en: '![](img/B17290_06_049.png)'
  id: totrans-499
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_06_049.png)'
- en: 'As the name implies, this equation takes the mean of the absolute value of
    the errors. Since the error is just the difference between the predicted and actual
    values, we can create a simple `MAE()` function as follows:'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，此公式计算误差绝对值的平均值。由于误差仅仅是预测值与实际值之间的差异，我们可以创建一个简单的`MAE()`函数，如下所示：
- en: '[PRE85]'
  id: totrans-501
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'The MAE for our predictions is then:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的预测的MAE如下：
- en: '[PRE86]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: This implies that, on average, the difference between our model’s predictions
    and the true quality score was about `0.59`. On a quality scale from 0 to 10,
    this seems to suggest that our model is doing fairly well.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，平均而言，我们的模型预测与真实质量评分之间的差异约为`0.59`。在0到10的质量尺度上，这似乎表明我们的模型表现相当不错。
- en: On the other hand, recall that most wines were neither very good nor very bad;
    the typical quality score was around 5 to 6\. Therefore, a classifier that did
    nothing but predict the mean value may also do fairly well according to this metric.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，回想一下，大多数酒既不是非常好也不是非常差；典型的质量评分在5到6之间。因此，仅预测平均值的分类器根据这个指标也可能表现相当不错。
- en: 'The mean quality rating in the training data is as follows:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据中的平均质量评分如下：
- en: '[PRE88]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-509
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'If we predicted the value `5.87` for every wine sample, we would have a MAE
    of only about `0.67`:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们预测每个酒样值为`5.87`，我们的MAE将只有大约`0.67`：
- en: '[PRE90]'
  id: totrans-511
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-512
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Our regression tree (*MAE* = *0.59*) comes closer on average to the true quality
    score than the imputed mean (*MAE* = *0.67*), but not by much. In comparison,
    Cortez reported an MAE of 0.58 for the neural network model and an MAE of `0.45`
    for the support vector machine. This suggests that there is room for improvement.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的回归树（**MAE** = **0.59**）平均来说比插补的均值（**MAE** = **0.67**）更接近真实质量评分，但差距不大。相比之下，Cortez报告了神经网络模型的MAE为0.58，支持向量机的MAE为`0.45`。这表明还有改进的空间。
- en: Step 5 – improving model performance
  id: totrans-514
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5步 - 提高模型性能
- en: To improve the performance of our learner, let’s apply a model tree algorithm,
    which is a more complex application of trees to numeric prediction. Recall that
    a model tree extends regression trees by replacing the leaf nodes with regression
    models. This often results in more accurate results than regression trees, which
    use only a single numeric value for the prediction at the leaf nodes.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高学习器的性能，让我们应用模型树算法，这是一种更复杂的将树应用于数值预测的应用。回想一下，模型树通过用回归模型替换叶节点来扩展回归树。这通常比只使用单个数值值进行叶节点预测的回归树产生更准确的结果。
- en: The current state-of-the-art in model trees is the **Cubist** algorithm, which
    itself is an enhancement of the M5 model tree algorithm—both of which were published
    by J. R. Quinlan in the early 1990s. Though the implementation details are beyond
    the scope of this book, the Cubist algorithm involves building a decision tree,
    creating decision rules based on the branches of the tree, and building a regression
    model at each of the leaf nodes. Additional heuristics, such as pruning and boosting,
    are used to improve the quality of the predictions and smoothness across the range
    of predicted values.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型树领域，当前最先进的技术是**Cubist**算法，该算法本身是对M5模型树算法的改进——这两者都是由J. R. Quinlan在20世纪90年代初发表的。尽管实现细节超出了本书的范围，但Cubist算法涉及构建决策树，根据树的分支创建决策规则，并在每个叶节点构建回归模型。使用额外的启发式方法，如剪枝和提升，以提高预测质量并平滑预测值的范围。
- en: For more background on the Cubist and M5 algorithms, see *Learning With Continuous
    Classes, Quinlan, J. R., Proceedings of the 5th Australian Joint Conference on
    Artificial Intelligence, 1992, pp. 343-348\.* Additionally, see *Combining Instance-Based
    and Model-Based Learning, Quinlan, J. R., Proceedings of the Tenth International
    Conference on Machine Learning, 1993, pp. 236-243*.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Cubist和M5算法的更多背景信息，请参阅*《使用连续类学习》，Quinlan, J. R.，1992年第五次澳大利亚联合人工智能会议论文集，第343-348页*。此外，请参阅*《结合实例学习和基于模型的学习》，Quinlan,
    J. R.，1993年第十次国际机器学习会议论文集，第236-243页*。
- en: 'The Cubist algorithm is available in R via the `Cubist` package and the associated
    `cubist()` function. The syntax of this function is shown in the following table:'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: Cubist算法在R中通过`Cubist`包和相关的`cubist()`函数可用。此函数的语法在以下表格中显示：
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B17290_06_19.png)'
  id: totrans-519
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序，电子邮件  自动生成的描述](img/B17290_06_19.png)'
- en: 'Figure 6.19: Model tree syntax'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.19：模型树语法
- en: 'We’ll fit the Cubist model tree using a slightly different syntax from what
    was used for the regression tree, as the `cubist()` function does not accept the
    R formula syntax. Instead, we must specify the data frame columns used for the
    `x` independent variables and the `y` dependent variable. With the wine quality
    to be predicted residing in column 12, and using all other columns as predictors,
    the full command is as follows:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与回归树不同的语法来拟合Cubist模型树，因为`cubist()`函数不接受R公式语法。相反，我们必须指定用于`x`独立变量和`y`因变量的数据帧列。由于要预测的葡萄酒质量位于第12列，并使用所有其他列作为预测变量，完整的命令如下：
- en: '[PRE92]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Basic information about the model tree can be examined by typing its name:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 模型树的基本信息可以通过输入其名称来检查：
- en: '[PRE93]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'In this output, we see that the algorithm generated 25 rules to model the wine
    quality. To examine some of these rules, we can apply the `summary()` function
    to the model object. Since the complete tree is very large, only the first few
    lines of output depicting the first decision rule are included here:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个输出中，我们看到算法生成了25条规则来模拟葡萄酒质量。要检查这些规则中的几个，我们可以对模型对象应用`summary()`函数。由于完整的树非常大，这里只包括描述第一个决策规则的输出前几行：
- en: '[PRE95]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-528
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: You will note that the `if` portion of the output is somewhat like the regression
    tree we built earlier. A series of decisions based on the wine properties of sulfur
    dioxide, sulphates, and alcohol creates a rule culminating in the final prediction.
    A key difference between this model tree output and the earlier regression tree
    output, however, is that the nodes here terminate not in a numeric prediction,
    but rather in a linear model.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到输出中的`if`部分与我们在早期构建的回归树有些相似。一系列基于二氧化硫、硫酸盐和酒精的葡萄酒特性的决策创建了一个以最终预测为终点的规则。然而，这个模型树输出与早期回归树输出的一个关键区别是，这里的节点不是以数值预测结束，而是一个线性模型。
- en: The linear model for this rule is shown in the `then` output following the `outcome
    =` statement. The numbers can be interpreted exactly the same as the multiple
    regression models we built earlier in this chapter. Each value is the estimated
    impact of the associated feature, that is, the net effect of one unit increase
    of that feature on the predicted wine quality. For example, the coefficient of
    0.186 for residual sugar implies that for an increase of one unit of residual
    sugar, the wine quality rating is expected to increase by 0.186.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 该规则的线性模型显示在`outcome =`语句之后的`then`输出中。这些数字可以与我们在本章早期构建的多元回归模型完全相同地解释。每个值都是相关特征的估计影响，即该特征单位增加对预测葡萄酒质量的净效应。例如，残留糖的系数为0.186意味着残留糖增加一个单位时，预计葡萄酒质量评分将增加0.186。
- en: It is important to note that the regression effects estimated by this model
    apply only to wine samples reaching this node; an examination of the entirety
    of the Cubist output reveals that a total of 25 linear models were built in this
    model tree, one for each decision rule, and each with different parameter estimates
    of the impact of residual sugar and the 10 other features.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，此模型估计的回归效应仅适用于达到此节点的葡萄酒样本；检查Cubist输出的全部内容揭示，在这个模型树中总共构建了25个线性模型，每个决策规则一个，每个模型对残留糖和10个其他特征的参数估计都不同。
- en: 'To examine the performance of this model, we’ll look at how well it performs
    on the unseen test data. The `predict()` function gets us a vector of predicted
    values:'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检验这个模型的表现，我们将查看它在未见过的测试数据上的表现如何。`predict()`函数为我们提供了一个预测值的向量：
- en: '[PRE97]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'The model tree appears to be predicting a wider range of values than the regression
    tree:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 模型树似乎在预测值范围上比回归树更广：
- en: '[PRE98]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'The correlation also seems to be substantially higher:'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性似乎也显著更高：
- en: '[PRE100]'
  id: totrans-538
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'Furthermore, the model slightly reduced the MAE:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该模型略微降低了MAE：
- en: '[PRE102]'
  id: totrans-541
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: Although we did not improve a great deal beyond the regression tree, we surpassed
    the performance of the neural network model published by Cortez, and we are getting
    closer to the published MAE value of 0.45 for the support vector machine model,
    all while using a much simpler learning method.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们没有在回归树模型上取得很大的改进，但我们超越了Cortez发布的神经网络模型的性能，并且在使用一个简单得多的学习方法的同时，我们正接近支持向量机模型发布的MAE值0.45。
- en: Not surprisingly, we have confirmed that predicting the quality of wines is
    a difficult problem; wine tasting, after all, is inherently subjective. If you
    would like additional practice, you may try revisiting this problem after reading
    *Chapter 14*, *Building Better Learners*, which covers additional techniques that
    may lead to better results.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，我们证实了预测葡萄酒质量是一个困难的问题；毕竟，品酒本质上是一种主观行为。如果您想进行额外的练习，您可以在阅读*第14章*，*构建更好的学习者*之后，再次尝试这个问题，该章节涵盖了可能带来更好结果的技术。
- en: Summary
  id: totrans-545
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we studied two methods for modeling numeric data. The first
    method, linear regression, involves fitting straight lines to data, but a technique
    called generalized linear modeling can adapt regression to other contexts as well.
    The second method uses decision trees for numeric prediction. The latter comes
    in two forms: regression trees, which use the average value of examples at leaf
    nodes to make numeric predictions, and model trees, which build a regression model
    at each leaf node in a hybrid approach that is, in some ways, the best of both
    worlds.'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了两种建模数值数据的方法。第一种方法，线性回归，涉及将直线拟合到数据上，但一种称为广义线性建模的技术可以使回归适应其他环境。第二种方法使用决策树进行数值预测。后者有两种形式：回归树，它使用叶节点上示例的平均值进行数值预测，以及模型树，它以混合方法在每个叶节点构建回归模型，这种混合方法在某些方面是两者的最佳结合。
- en: We began to understand the utility of regression modeling by using it to investigate
    the causes of the Challenger space shuttle disaster. We then used linear regression
    modeling to calculate the expected insurance claims costs for various segments
    of automobile drivers.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用回归模型来调查挑战者号航天飞机灾难的原因，开始理解回归模型的有用性。然后，我们使用线性回归模型来计算各种汽车驾驶者的预期保险索赔成本。
- en: Because the relationship between the features and the target variable is well
    documented by the estimated regression model, we were able to identify certain
    demographics, such as high-mileage and late-night drivers, who may need to be
    charged higher insurance rates to cover their higher-than-average claims costs.
    We then applied logistic regression, a variant of regression used for binary classification,
    to the task of modeling insurance customer retention. These examples demonstrated
    the ability of regression to adapt flexibly to many types of real-world problems.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 由于估计的回归模型很好地记录了特征与目标变量之间的关系，我们能够识别出某些人口统计特征，例如高里程和深夜驾驶者，他们可能需要支付更高的保险费来覆盖他们高于平均的索赔成本。然后，我们将逻辑回归，一种用于二元分类的回归变体，应用于建模保险客户保留的任务。这些例子展示了回归如何灵活地适应许多类型的现实世界问题。
- en: In a somewhat less businesslike application of machine learning, regression
    trees and model trees were used to model the subjective quality of wines from
    measurable characteristics. In doing so, we learned how regression trees offer
    a simple way to explain the relationship between features and a numeric outcome,
    but the more complex model trees may be more accurate. Along the way, we learned
    new methods for evaluating the performance of numeric models.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的某种不太商业化的应用中，回归树和模型树被用来根据可测量的特征建模葡萄酒的主观质量。在这个过程中，我们了解到回归树提供了一种简单的方法来解释特征与数值结果之间的关系，但更复杂的模型树可能更准确。在这个过程中，我们还学习了新的方法来评估数值模型的表现。
- en: In stark contrast to this chapter, which covered machine learning methods that
    result in a clear understanding of the relationships between the input and the
    output, the next chapter covers methods that result in nearly incomprehensible
    models. The upside is that they are extremely powerful techniques—among the most
    powerful stock classifiers—which can be applied to both classification and numeric
    prediction problems.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章所涵盖的、导致对输入和输出之间关系有清晰理解的机器学习方法截然不同，下一章涵盖了导致几乎无法理解模型的算法。优点是它们是极其强大的技术——属于最强大的股票分类器之一——可以应用于分类和数值预测问题。
- en: Join our book’s Discord space
  id: totrans-551
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的 Discord 空间
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 4000 people at:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区，与志同道合的人相聚，并与其他4000多人一起学习：
- en: '[https://packt.link/r](https://packt.link/r)'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/r](https://packt.link/r)'
- en: '![](img/r.jpg)'
  id: totrans-554
  prefs: []
  type: TYPE_IMG
  zh: '![](img/r.jpg)'
