<html><head></head><body>
<div id="_idContainer090">
<h1 class="chapter-number" id="_idParaDest-103"><a id="_idTextAnchor111"/><span class="koboSpan" id="kobo.1.1">7</span></h1>
<h1 id="_idParaDest-104"><a id="_idTextAnchor112"/><span class="koboSpan" id="kobo.2.1">Using Synthetic Data in Data-Centric Machine Learning</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In previous chapters, we discussed various approaches to improving data quality for machine learning purposes through better collection </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">and labeling.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">Although human labelers, data ownership, and technical data quality improvement practices are critical to data centricity, there are limits to the kind of labeling and data creation that can be performed by individuals or through </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">empirical observation.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">Synthetic data has the potential to fill in these gaps and produce comprehensive training data at a fraction of the cost and time of </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">other approaches.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">This chapter provides an introduction to synthetic data generation. </span><span class="koboSpan" id="kobo.9.2">We will cover the following </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">main topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.11.1">What synthetic data is and why it matters for </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">data centricity</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">How synthetic data is being used to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">better models</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">Common techniques used to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">synthetic data</span></span></li>
<li><span class="koboSpan" id="kobo.17.1">The risks and challenges with synthetic </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">data use</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.19.1">Let’s start by defining what synthetic </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">data is.</span></span></p>
<h1 id="_idParaDest-105"><a id="_idTextAnchor113"/><span class="koboSpan" id="kobo.21.1">Understanding synthetic data</span></h1>
<p><span class="koboSpan" id="kobo.22.1">Synthetic data</span><a id="_idIndexMarker430"/><span class="koboSpan" id="kobo.23.1"> is artificially created data that, if done right, contains all the characteristics of </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">production data.</span></span></p>
<p><span class="koboSpan" id="kobo.25.1">The reason it’s called synthetic data is that it doesn’t have a physical existence – that is, it doesn’t come from real-life observations or experiments that we create to gather data that we subsequently use to run analysis or build machine learning </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">models on.</span></span></p>
<p><span class="koboSpan" id="kobo.27.1">A foundational principle of machine learning is that you need a lot of data, ranging from thousands to billions of observations. </span><span class="koboSpan" id="kobo.27.2">The amount you need depends on </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">your model.</span></span></p>
<p><span class="koboSpan" id="kobo.29.1">As we have </span><a id="_idIndexMarker431"/><span class="koboSpan" id="kobo.30.1">outlined many times already, when the required volume of data is difficult to come by, one approach is to improve the signal in your data to make it possible to produce accurate and relevant outputs, even on </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">smaller datasets.</span></span></p>
<p><span class="koboSpan" id="kobo.32.1">Another option is to create synthetic data to cover the gaps. </span><span class="koboSpan" id="kobo.32.2">A major benefit of synthetic data is its scalability. </span><span class="koboSpan" id="kobo.32.3">Real training data is collected linearly, one example at a time, which can be both time-consuming </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">and expensive.</span></span></p>
<p><span class="koboSpan" id="kobo.34.1">In contrast, synthetic data can be generated in very large quantities in a relatively short time and typically at a lower cost. </span><span class="koboSpan" id="kobo.34.2">As an example, a training image that may cost $5 if it’s obtained from a labeling service might cost $0.05 if it’s </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">produced artificially</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.36.1">1</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.38.1">Synthetic data is touted as the answer to many challenges in the development of more powerful machine learning and AI solutions. </span><span class="koboSpan" id="kobo.38.2">From solving privacy issues to inexpensively generating rare but important observations for your modeling and training data, synthetic data can fill the gaps where real-world data </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">falls short.</span></span></p>
<p><span class="koboSpan" id="kobo.40.1">According to Gartner predictions</span><span class="superscript"><span class="koboSpan" id="kobo.41.1">2</span></span><span class="koboSpan" id="kobo.42.1">, 60% of the data used in AI and analytics projects will be synthetically generated rather than gathered through real-world observations </span><span class="No-Break"><span class="koboSpan" id="kobo.43.1">by 2024.</span></span></p>
<p><span class="koboSpan" id="kobo.44.1">Traditionally, the use of data for analytical purposes has been driven by the data we have available and its limitations. </span><span class="koboSpan" id="kobo.44.2">We might imagine the perfect data solution, but often, the depth, breadth, reliability, and privacy constraints of a dataset limit what we can do in reality. </span><span class="koboSpan" id="kobo.44.3">To a large extent, this is what synthetic data aims </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">to fix.</span></span></p>
<p><span class="koboSpan" id="kobo.46.1">There are different ways to create synthetic data, and to some extent, the technical creation of the data is the least complex part. </span><span class="koboSpan" id="kobo.46.2">Validating whether a synthetic dataset is a relevant reflection of potential real-world scenarios and defending against unwanted bias can be time-consuming </span><span class="No-Break"><span class="koboSpan" id="kobo.47.1">and challenging.</span></span></p>
<p><span class="koboSpan" id="kobo.48.1">If you choose to use synthetic data for your next project, the first important question is always, “</span><em class="italic"><span class="koboSpan" id="kobo.49.1">What are you going to use the data for?</span></em><span class="koboSpan" id="kobo.50.1">” The answer to this question determines your data needs, which, in turn, will highlight your </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">data gaps.</span></span></p>
<p><span class="koboSpan" id="kobo.52.1">Let’s take a closer look at the typical reasons for using synthetic data and explore some common </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">use cases.</span></span></p>
<h2 id="_idParaDest-106"><a id="_idTextAnchor114"/><span class="koboSpan" id="kobo.54.1">The use case for synthetic data</span></h2>
<p><span class="koboSpan" id="kobo.55.1">The reasons for using</span><a id="_idIndexMarker432"/><span class="koboSpan" id="kobo.56.1"> synthetic data generally fall into the following </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">four categories:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.58.1">Availability</span></strong><span class="koboSpan" id="kobo.59.1">: Synthetic data creation is used to compensate for the lack of data in a domain. </span><span class="koboSpan" id="kobo.59.2">It may be that we have imbalanced classes in a dataset compared to the real-life distribution, so to make those classes balanced, we create synthetic data </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">to compensate.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.61.1">Cost</span></strong><span class="koboSpan" id="kobo.62.1">: It can be very costly and time-consuming to collect certain types of data, in which case it can be useful to generate synthetic data to reduce the time and cost spent on </span><span class="No-Break"><span class="koboSpan" id="kobo.63.1">a project.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.64.1">Risk management</span></strong><span class="koboSpan" id="kobo.65.1">: In some cases, synthetic data can also be used to lower the risk of human or financial damage. </span><span class="koboSpan" id="kobo.65.2">An example of this is flight simulators, which are used to train new and experienced pilots in all sorts of situations. </span><span class="koboSpan" id="kobo.65.3">Training pilots in a simulated environment allows us to safely and knowingly introduce rare events that would be hard to create in a natural environment without </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">unacceptable risk.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.67.1">Security and legal compliance</span></strong><span class="koboSpan" id="kobo.68.1">: The data you need may already exist but it is unsafe or illegal to use it for machine learning purposes. </span><span class="koboSpan" id="kobo.68.2">For example, some regulations, such as Europe’s </span><strong class="bold"><span class="koboSpan" id="kobo.69.1">General Data Protection Regulation</span></strong><span class="koboSpan" id="kobo.70.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.71.1">GDPR</span></strong><span class="koboSpan" id="kobo.72.1">), forbid </span><a id="_idIndexMarker433"/><span class="koboSpan" id="kobo.73.1">the use of certain kinds of data without clear consent from the underlying individual. </span><span class="koboSpan" id="kobo.73.2">Alternatively, it might just be too slow and cumbersome to get signoff in </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">your organization.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.75.1">Here are some</span><a id="_idIndexMarker434"/><span class="koboSpan" id="kobo.76.1"> examples of common and potential use cases for </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">synthetic data:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.78.1">Computer vision and image and </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1">video processing</span></span></li>
<li><span class="koboSpan" id="kobo.80.1">Natural </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">language processing</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.82.1">Privacy preservation</span></span></li>
<li><span class="koboSpan" id="kobo.83.1">Correcting bias (discussed in </span><a href="B19297_08.xhtml#_idTextAnchor125"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.84.1">Chapter 8</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.85.1">, Techniques for Identifying and </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.86.1">Removing Bias</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">)</span></span></li>
<li><span class="koboSpan" id="kobo.88.1">Improving data quality or gaps (</span><span class="No-Break"><span class="koboSpan" id="kobo.89.1">more cheaply)</span></span></li>
<li><span class="koboSpan" id="kobo.90.1">Increasing modeling data volumes for rare events (discussed in </span><a href="B19297_09.xhtml#_idTextAnchor141"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.91.1">Chapter 9</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.92.1">, Dealing with Edge Cases and Rare Events in </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.93.1">Machine Learning</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">)</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.95.1">Simulation</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.96.1">We will </span><a id="_idIndexMarker435"/><span class="koboSpan" id="kobo.97.1">explore some of these topics in this chapter to illustrate how synthetic data can be used as part of your model </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">development strategy.</span></span></p>
<p><span class="koboSpan" id="kobo.99.1">To set the scene, let’s look at an example of just how powerful synthetic data can be in the right setting, courtesy of the world’s leading computer games software development company, Unity Technologies. </span><span class="koboSpan" id="kobo.99.2">By way of background, the Unity platform was used to create 72% of the top 1,000 mobile phone games and 50% of all computer games across mobile, PC, and consoles </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">in 2021</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.101.1">3</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.103.1">The users of Unity’s technology have improved object recognition rates from 70% to almost 100% simply by augmenting real-world data with synthetic data. </span><span class="koboSpan" id="kobo.103.2">Synthetic data adds a lot more variety and many more scenarios to the training data, which enables objects to be recognized from </span><span class="No-Break"><span class="koboSpan" id="kobo.104.1">many angles</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.105.1">4</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.107.1">Unity’s Vice President of AI and machine learning, David Lange, says </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">the following:</span></span></p>
<p><span class="koboSpan" id="kobo.109.1">“</span><em class="italic"><span class="koboSpan" id="kobo.110.1">We’re using the Unity engine to recreate three-dimensional worlds with objects in there. </span><span class="koboSpan" id="kobo.110.2">Then, we can generate synthetic images that look very much like what they would look like in the real world, </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.111.1">perfectly labeled.</span></em></span></p>
<p><span class="koboSpan" id="kobo.112.1">“</span><em class="italic"><span class="koboSpan" id="kobo.113.1">Real-world data is really just a snapshot of the situation. </span><span class="koboSpan" id="kobo.113.2">What you can do with the synthetic data is augment that real world with special use cases, special situations, special events. </span><span class="koboSpan" id="kobo.113.3">You can improve the diversity of your data by adding synthetic data to </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.114.1">your dataset.</span></em></span></p>
<p><span class="koboSpan" id="kobo.115.1">“</span><em class="italic"><span class="koboSpan" id="kobo.116.1">We can create improbable situations because it’s not going to cost us anything in milliseconds, rather than trying to stage them in reality. </span><span class="koboSpan" id="kobo.116.2">The ease with which you can create all these scenarios is driving the use of </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.117.1">synthetic data.</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">”</span></span></p>
<p><span class="koboSpan" id="kobo.119.1">David Lange shares the view of Gartner in that synthetic data is going to be the predominant raw material for machine learning in </span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">the future:</span></span></p>
<p><span class="koboSpan" id="kobo.121.1">“</span><em class="italic"><span class="koboSpan" id="kobo.122.1">I believe that the vast majority of training data will be synthetic. </span><span class="koboSpan" id="kobo.122.2">You have to have the real world as a baseline, but synthetic data eliminates privacy concerns because there are no real people involved. </span><span class="koboSpan" id="kobo.122.3">You can eliminate bias. </span><span class="koboSpan" id="kobo.122.4">You can do your data analytics and ensure that your data represents the real world in a very even way, better than the real </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.123.1">world does.</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">”</span></span></p>
<p><span class="koboSpan" id="kobo.125.1">Take note of the </span><a id="_idIndexMarker436"/><span class="koboSpan" id="kobo.126.1">benefits of synthetic data that David </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">Lange mentions:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.128.1">Objects can be perfectly labeled, thereby avoiding the labeling ambiguities discussed in </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">previous chapters</span></span></li>
<li><span class="koboSpan" id="kobo.130.1">The diversity of the dataset can be increased substantially to cover slight variations in probable scenarios, as well as rare events and </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">edge cases</span></span></li>
<li><span class="koboSpan" id="kobo.132.1">Datasets can be scaled quickly </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">and cheaply</span></span></li>
<li><span class="koboSpan" id="kobo.134.1">Bias and privacy concerns can be reduced because data is cleaner </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">and depersonalized</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.136.1">Let’s dig deeper into the various uses of synthetic data to understand the possibilities, benefits, risks, and constraints associated </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">with it.</span></span></p>
<h2 id="_idParaDest-107"><a id="_idTextAnchor115"/><span class="koboSpan" id="kobo.138.1">Synthetic data for computer vision and image and video processing</span></h2>
<p><span class="koboSpan" id="kobo.139.1">At the time </span><a id="_idIndexMarker437"/><span class="koboSpan" id="kobo.140.1">of writing, the most prevalent use of synthetic data is in computer vision problems. </span><span class="koboSpan" id="kobo.140.2">This is because we can often create this type of data with limited risk, while outliers (often rare but impactful events) can be particularly hard to get hold of in </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">image data.</span></span></p>
<p><span class="koboSpan" id="kobo.142.1">A </span><a id="_idIndexMarker438"/><span class="koboSpan" id="kobo.143.1">common challenge in computer vision (and most other machine learning problems for that matter) is that real-world data typically contains a large proportion of observations describing the most probable scenarios, and very few or no examples of </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">rare events.</span></span></p>
<p><span class="koboSpan" id="kobo.145.1">At the same time, real-world data can be difficult, expensive, or outright dangerous to collect. </span><span class="koboSpan" id="kobo.145.2">As an example, autonomous vehicle models can’t be trained to avoid car crashes by putting real cars into dangerous situations. </span><span class="koboSpan" id="kobo.145.3">Instead, these crashes and other rare but significant events must </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">be simulated.</span></span></p>
<p><span class="koboSpan" id="kobo.147.1">A common problem for image classification algorithms is recognizing familiar objects in slightly unfamiliar positions or environments. </span><span class="koboSpan" id="kobo.147.2">Because machine learning algorithms don’t reason by logic or abstraction, even models that perform very well on both training and test datasets will often fail to generalize to out-of-distribution observations. </span><span class="koboSpan" id="kobo.147.3">This is true whether these observations are introduced as an adversarial test of model performance or </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">occur naturally.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.149.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.150.1">.1</span></em><span class="koboSpan" id="kobo.151.1"> provides a simplified example of this phenomenon. </span><span class="koboSpan" id="kobo.151.2">A square that is rotated 45 degrees may be interpreted by some – humans and algorithms alike – as a diamond, and not simply a tilted square with the same dimensions as a square positioned on </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">its side:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer072">
<span class="koboSpan" id="kobo.153.1"><img alt="Figure 7.1 – These two squares are either identical or different, depending on the rules we use to interpret them" src="image/B19297_07_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.154.1">Figure 7.1 – These two squares are either identical or different, depending on the rules we use to interpret them</span></p>
<p><span class="koboSpan" id="kobo.155.1">The implications</span><a id="_idIndexMarker439"/><span class="koboSpan" id="kobo.156.1"> of this bias are often substantial. </span><span class="koboSpan" id="kobo.156.2">In an analysis of deep neural networks’ performance on images from the ImageNet dataset, Alcorn et al. </span><span class="koboSpan" id="kobo.156.3">(2019)</span><span class="superscript"><span class="koboSpan" id="kobo.157.1">5</span></span><span class="koboSpan" id="kobo.158.1"> describe how the common image classifiers </span><em class="italic"><span class="koboSpan" id="kobo.159.1">Google Inception-v3</span></em><span class="koboSpan" id="kobo.160.1">, </span><em class="italic"><span class="koboSpan" id="kobo.161.1">AlexNet</span></em><span class="koboSpan" id="kobo.162.1">, and </span><em class="italic"><span class="koboSpan" id="kobo.163.1">ResNet-50</span></em><span class="koboSpan" id="kobo.164.1"> can easily be fooled by slight changes to the positioning of an object within </span><span class="No-Break"><span class="koboSpan" id="kobo.165.1">an image.</span></span></p>
<p><span class="koboSpan" id="kobo.166.1">In </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.167.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.168.1">.2</span></em><span class="koboSpan" id="kobo.169.1">, the images in column (d) are real photographs collected from the internet, whereas columns (a) to (c) are out-of-distribution images of the same objects in unusual positions. </span><span class="koboSpan" id="kobo.169.2">The main object within the image is flipped and rotated, but the background is </span><span class="No-Break"><span class="koboSpan" id="kobo.170.1">kept constant:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer073">
<span class="koboSpan" id="kobo.171.1"><img alt="Figure 7.2 – Deep neural networks can easily be fooled when familiar objects are in uncommon positions. Column (d) represents real-life images, while columns (a) to (c) are synthetic" src="image/B19297_07_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.172.1">Figure 7.2 – Deep neural networks can easily be fooled when familiar objects are in uncommon positions. </span><span class="koboSpan" id="kobo.172.2">Column (d) represents real-life images, while columns (a) to (c) are synthetic</span></p>
<p><span class="koboSpan" id="kobo.173.1">The authors</span><a id="_idIndexMarker440"/><span class="koboSpan" id="kobo.174.1"> then used </span><em class="italic"><span class="koboSpan" id="kobo.175.1">Inception-v3</span></em><span class="koboSpan" id="kobo.176.1"> to classify these images, with the resulting label and confidence score depicted under each image. </span><span class="koboSpan" id="kobo.176.2">In these examples, the algorithm was able to classify with a high degree of accuracy and confidence when objects were in a commonly observed position in real-life scenarios. </span><span class="koboSpan" id="kobo.176.3">However, the algorithm misclassified images with a high degree of confidence when objects were being flipped, rotated, or moved </span><span class="No-Break"><span class="koboSpan" id="kobo.177.1">very close.</span></span></p>
<p><span class="koboSpan" id="kobo.178.1">Not only did the algorithm misclassify objects, but it also confidently mislabeled them as objects they are not. </span><span class="koboSpan" id="kobo.178.2">A rolling bus and a punching bag are like chalk and cheese, and an overturned scooter is nowhere close to looking like </span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">a parachute.</span></span></p>
<p><span class="koboSpan" id="kobo.180.1">Being able to recognize familiar objects in unfamiliar positions is especially critical when it comes to observing and classifying moving objects. </span><span class="koboSpan" id="kobo.180.2">In the example of self-driving cars, algorithmic misinterpretations introduce novel and unexpected events into the traffic environment, even though these vehicles are statistically safer than </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">human drivers</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.182.1">6</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.183.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.184.1">The following </span><a id="_idIndexMarker441"/><span class="koboSpan" id="kobo.185.1">image, which was captured from a traffic camera in Taiwan, shows an example of this issue. </span><span class="koboSpan" id="kobo.185.2">A truck has overturned on a busy highway, and an autonomous Tesla sedan doesn’t recognize the truck as an obstacle in the way and crashes into the truck at </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">high speed:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer074">
<span class="koboSpan" id="kobo.187.1"><img alt="Figure 7.3 – An autonomous vehicle crashes into an overturned truck at high speed. Algorithms can be trained to handle novel situations like this using synthetic data" src="image/B19297_07_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.188.1">Figure 7.3 – An autonomous vehicle crashes into an overturned truck at high speed. </span><span class="koboSpan" id="kobo.188.2">Algorithms can be trained to handle novel situations like this using synthetic data</span></p>
<p><span class="koboSpan" id="kobo.189.1">In this very unlikely but highly dangerous scenario, the car’s algorithms are not equipped to correctly assess the statistical probability that the object in front of it is blocking </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">the road.</span></span></p>
<p><span class="koboSpan" id="kobo.191.1">This is a scenario where synthetic data proves highly valuable. </span><span class="koboSpan" id="kobo.191.2">As we have just learned, even best-in-class computer vision algorithms have a high degree of sensitivity to variations in the position of common objects. </span><span class="koboSpan" id="kobo.191.3">Therefore, objects must be introduced in various positions and lighting conditions in the training data to cover all possible combinations, especially highly </span><span class="No-Break"><span class="koboSpan" id="kobo.192.1">improbable ones.</span></span></p>
<p><span class="koboSpan" id="kobo.193.1">When we use machine learning to figure out what’s happening in an image, we are extracting the concave and convex curves within the image, also known as the features within a deep </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">neural network.</span></span></p>
<p><span class="koboSpan" id="kobo.195.1">To create these</span><a id="_idIndexMarker442"/><span class="koboSpan" id="kobo.196.1"> curves from a synthetic data perspective, you would simply be recreating those formations within images. </span><span class="koboSpan" id="kobo.196.2">This would typically involve flipping, rotating, zooming, cropping, making light changes, and resizing images to create slight variations on the </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">same scenario.</span></span></p>
<p><span class="koboSpan" id="kobo.198.1">In the example of the Tesla accident, we might create images with the truck driving as normal, rolled on its side, rolled on its back, driving in the wrong direction, in the dark, partially covered by other objects, and so on. </span><span class="koboSpan" id="kobo.198.2">These scenarios are hard to get a hold of in real-life imagery, yet they’re very important to be able to deal with when the </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">situation arises.</span></span></p>
<h2 id="_idParaDest-108"><a id="_idTextAnchor116"/><span class="koboSpan" id="kobo.200.1">Generating synthetic data using generative adversarial networks (GANs)</span></h2>
<p><span class="koboSpan" id="kobo.201.1">GANs are</span><a id="_idIndexMarker443"/><span class="koboSpan" id="kobo.202.1"> common tools for generating synthetic image</span><a id="_idIndexMarker444"/><span class="koboSpan" id="kobo.203.1"> data with properties similar to real-world data. </span><span class="koboSpan" id="kobo.203.2">GANs were invented by computer scientist Ian Goodfellow in 2014 and have since led to an explosion in generative models that can create all sorts of content, including text, art, video, </span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">and images.</span></span></p>
<p><span class="koboSpan" id="kobo.205.1">GANs are a</span><a id="_idIndexMarker445"/><span class="koboSpan" id="kobo.206.1"> form of unsupervised learning where a generator model is pitted against a discriminator model (hence the “adversarial” aspect). </span><span class="koboSpan" id="kobo.206.2">Both models are neural networks that compete against each other to turn the exercise into a “pseudo-supervised” </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">learning problem.</span></span></p>
<p><span class="koboSpan" id="kobo.208.1">The generator identifies patterns in the original dataset that are then used to generate synthetic output that could have conceivably existed in the input data. </span><span class="koboSpan" id="kobo.208.2">The generated examples become negative training samples for the </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">discriminator model.</span></span></p>
<p><span class="koboSpan" id="kobo.210.1">It is the discriminator’s job to classify the newly generated data as fake or real. </span><span class="koboSpan" id="kobo.210.2">This zero-sum contest continues until the discriminator picks </span><em class="italic"><span class="koboSpan" id="kobo.211.1">fake</span></em><span class="koboSpan" id="kobo.212.1"> observations as </span><em class="italic"><span class="koboSpan" id="kobo.213.1">real</span></em><span class="koboSpan" id="kobo.214.1"> close to 50% of </span><span class="No-Break"><span class="koboSpan" id="kobo.215.1">the time.</span></span></p>
<p><span class="koboSpan" id="kobo.216.1">Mathematically, the training process for a GAN can be thought of as minimizing a loss function that measures the difference between the generated examples and the real examples. </span><span class="koboSpan" id="kobo.216.2">This loss function is typically a combination of two terms: one that measures how well the generative model can produce examples that are similar to the real examples, and one that measures how well the discriminative model can distinguish between real and </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">generated examples.</span></span></p>
<p><span class="koboSpan" id="kobo.218.1">By training </span><a id="_idIndexMarker446"/><span class="koboSpan" id="kobo.219.1">the two parts of the GAN in this way, the generative model can learn the patterns and features of the real examples in the training </span><a id="_idIndexMarker447"/><span class="koboSpan" id="kobo.220.1">dataset, and then use that information to generate new examples that are similar to the real ones. </span><span class="koboSpan" id="kobo.220.2">This allows GANs to be used for a wide range of applications, including image generation, text generation, and </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">many others.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.222.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.223.1">.4</span></em><span class="koboSpan" id="kobo.224.1"> provides a conceptual illustration of how GANs iterate through a large number of mini-contests to arrive at a model that can generate very </span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">realistic outputs:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer075">
<span class="koboSpan" id="kobo.226.1"><img alt="Figure 7.4 – A conceptual illustration of how a GAN works" src="image/B19297_07_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.227.1">Figure 7.4 – A conceptual illustration of how a GAN works</span></p>
<p><span class="koboSpan" id="kobo.228.1">The generator starts with some very basic presentations of the desired output but gets better at fooling the discriminator as it iterates through many examples. </span><span class="koboSpan" id="kobo.228.2">Training is completed when the discriminator struggles to recognize real </span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">from fake.</span></span></p>
<h3><span class="koboSpan" id="kobo.230.1">The progressive growth of GANs</span></h3>
<p><span class="koboSpan" id="kobo.231.1">As you can </span><a id="_idIndexMarker448"/><span class="koboSpan" id="kobo.232.1">imagine, the first few examples that are created by the generator will be relatively easy for the discriminator to pick. </span><span class="koboSpan" id="kobo.232.2">There is a lot for the generator model to learn and it can be challenging to make the GAN follow a learning path we would like it </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">to take.</span></span></p>
<p><span class="koboSpan" id="kobo.234.1">GANs are inherently unstable models, especially when it comes to generating complex structures, such as images. </span><span class="koboSpan" id="kobo.234.2">To fool the discriminator, the generator must pick up the small details and larger structures of an image, which can be difficult on high-resolution images. </span><span class="koboSpan" id="kobo.234.3">If the generator can’t do this, it will get stuck in a no-man’s land of never fooling </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">the discriminator.</span></span></p>
<p><span class="koboSpan" id="kobo.236.1">Another challenge is that large images require lots of computer memory. </span><span class="koboSpan" id="kobo.236.2">As a result, the batch size (the number of images used to update model weights each training iteration) must often be reduced to make sure the images will fit into memory. </span><span class="koboSpan" id="kobo.236.3">Again, this makes the training process </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">less stable.</span></span></p>
<p><span class="koboSpan" id="kobo.238.1">A solution to these problems is to progressively increase the detail and complexity of the model’s input and output. </span><span class="koboSpan" id="kobo.238.2">Progressive growing was first proposed by NVIDIA researchers Karras et al.</span><span class="superscript"><span class="koboSpan" id="kobo.239.1">7</span></span><span class="koboSpan" id="kobo.240.1"> in 2017, and is a technique for training GANs that allows the model to gradually increase the resolution of the generated images over </span><span class="No-Break"><span class="koboSpan" id="kobo.241.1">many iterations.</span></span></p>
<p><span class="koboSpan" id="kobo.242.1">Under progressive growing, the model is trained using a step-wise approach. </span><span class="koboSpan" id="kobo.242.2">First, the generator and discriminator models are trained with low-resolution images and seek to improve image quality by changing their parameters to optimize loss functions. </span><span class="koboSpan" id="kobo.242.3">Then, the resolution of the generated images is increased while fine-tuning occurs based on the understanding gathered from the initial training stage until the desired resolution is reached. </span><span class="koboSpan" id="kobo.242.4">In other words, the model learns in steps, rather than all </span><span class="No-Break"><span class="koboSpan" id="kobo.243.1">at once.</span></span></p>
<p><span class="koboSpan" id="kobo.244.1">Karras et al. </span><span class="koboSpan" id="kobo.244.2">propose training both the generator and discriminator with a batch of low-resolution images of 4x4 pixels. </span><span class="koboSpan" id="kobo.244.3">Then, a new sampling layer is used to gradually grow the image complexity to 8x8, using nearest </span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">neighbor interpolation.</span></span></p>
<p><span class="koboSpan" id="kobo.246.1">New network layers are introduced gradually to create minimal disruption between resolution layers. </span><span class="koboSpan" id="kobo.246.2">This approach allows for the smooth and seamless integration of newer components into the </span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">existing infrastructure.</span></span></p>
<p><span class="koboSpan" id="kobo.248.1">The gradual phasing in of a new block of layers is done by adding higher-resolution inputs to the existing input or output layer. </span><span class="koboSpan" id="kobo.248.2">The relative influence of the new outputs is controlled using a weighting, α, where the weight of the original output is 1 - α . </span><span class="koboSpan" id="kobo.248.3">As α increases, the old layer is gradually faded out, while the new layer </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">takes over.</span></span></p>
<p><span class="koboSpan" id="kobo.250.1">This</span><a id="_idIndexMarker449"/><span class="koboSpan" id="kobo.251.1"> process continues until the desired image resolution is reached. </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.252.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.253.1">.5</span></em><span class="koboSpan" id="kobo.254.1">, from Kerras et al., highlights the process of progressively growing from 4x4 to </span><span class="No-Break"><span class="koboSpan" id="kobo.255.1">1,024x1,024-pixel images:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer076">
<span class="koboSpan" id="kobo.256.1"><img alt="Figure 7.5 – Visualization of the progressive growth of a GAN from Kerras et al. (2017)" src="image/B19297_07_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.257.1">Figure 7.5 – Visualization of the progressive growth of a GAN from Kerras et al. </span><span class="koboSpan" id="kobo.257.2">(2017)</span></p>
<p><span class="koboSpan" id="kobo.258.1">This means that the model can first learn about the big picture of the image, and then focus on smaller details. </span><span class="koboSpan" id="kobo.258.2">This typically yields better results than trying to learn everything at once. </span><span class="koboSpan" id="kobo.258.3">By leveraging this approach, GANs can grasp the essential architecture and characteristics of low-resolution datasets, thus creating higher-quality images with </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">greater precision.</span></span></p>
<h3><span class="koboSpan" id="kobo.260.1">Achieving greater accuracy with StyleGANs</span></h3>
<p><span class="koboSpan" id="kobo.261.1">The</span><a id="_idIndexMarker450"/><span class="koboSpan" id="kobo.262.1"> research</span><a id="_idIndexMarker451"/><span class="koboSpan" id="kobo.263.1"> team at NVIDIA built on their progressive GAN architecture to introduce the first StyleGAN in December 2018</span><span class="superscript"><span class="koboSpan" id="kobo.264.1">8</span></span><span class="koboSpan" id="kobo.265.1">. </span><span class="koboSpan" id="kobo.265.2">Since then, StyleGAN-2 and StyleGAN-3 architectures have been released. </span><span class="koboSpan" id="kobo.265.3">These incremental upgrades resolved some systemic issues in the output from the original StyleGAN, but are otherwise similar </span><span class="No-Break"><span class="koboSpan" id="kobo.266.1">in structure.</span></span></p>
<p><span class="koboSpan" id="kobo.267.1">The primary innovation of </span><a id="_idIndexMarker452"/><span class="koboSpan" id="kobo.268.1">StyleGANs is the ability to control the </span><em class="italic"><span class="koboSpan" id="kobo.269.1">style</span></em><span class="koboSpan" id="kobo.270.1"> of the output created by the generator model. </span><span class="koboSpan" id="kobo.270.2">The new architecture allows the generator to automatically separate broader features from stochastic/random features in an image. </span><span class="koboSpan" id="kobo.270.3">Examples of broad features are a person’s pose and identity; hair and freckles are </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">considered stochastic.</span></span></p>
<p><span class="koboSpan" id="kobo.272.1">Before the</span><a id="_idIndexMarker453"/><span class="koboSpan" id="kobo.273.1"> introduction of StyleGANs, the inner workings of image generators were partially a mystery </span><a id="_idIndexMarker454"/><span class="koboSpan" id="kobo.274.1">and therefore hard to control. </span><span class="koboSpan" id="kobo.274.2">With no effective method to compare different images produced by various models and a limited understanding of how features originated, the original GAN generators were </span><span class="No-Break"><span class="koboSpan" id="kobo.275.1">black boxes.</span></span></p>
<p><span class="koboSpan" id="kobo.276.1">Let’s take a look at a comparison between </span><a id="_idIndexMarker455"/><span class="koboSpan" id="kobo.277.1">the </span><strong class="bold"><span class="koboSpan" id="kobo.278.1">progressive GAN</span></strong><span class="koboSpan" id="kobo.279.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.280.1">ProGAN</span></strong><span class="koboSpan" id="kobo.281.1">) and StyleGAN architectures in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.282.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.283.1">.6</span></em><span class="koboSpan" id="kobo.284.1"> to understand why StyleGAN has been so successful in generating highly realistic </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">synthetic images:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer077">
<span class="koboSpan" id="kobo.286.1"><img alt="Figure 7.6 – Comparison between ProGAN (a) and StyleGAN (b) from Kerras et al. (2018)" src="image/B19297_07_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.287.1">Figure 7.6 – Comparison between ProGAN (a) and StyleGAN (b) from Kerras et al. </span><span class="koboSpan" id="kobo.287.2">(2018)</span></p>
<p><span class="koboSpan" id="kobo.288.1">While ProGANs use a progressive training methodology to grow the resolution of generated images layer by layer, StyleGAN gives users more control over the generated images via the use of a Mapping Network and </span><span class="No-Break"><span class="koboSpan" id="kobo.289.1">Synthesis Network.</span></span></p>
<p><span class="koboSpan" id="kobo.290.1">StyleGAN’s </span><a id="_idIndexMarker456"/><span class="koboSpan" id="kobo.291.1">Mapping Network</span><a id="_idIndexMarker457"/><span class="koboSpan" id="kobo.292.1"> is a type of neural network that maps a low-dimensional vector, </span><em class="italic"><span class="koboSpan" id="kobo.293.1">z</span></em><span class="koboSpan" id="kobo.294.1">, to an intermediate </span><a id="_idIndexMarker458"/><span class="koboSpan" id="kobo.295.1">latent space, </span><em class="italic"><span class="koboSpan" id="kobo.296.1">w</span></em><span class="koboSpan" id="kobo.297.1">. </span><span class="koboSpan" id="kobo.297.2">This is known as disentangled representation learning. </span><span class="koboSpan" id="kobo.297.3">By </span><a id="_idIndexMarker459"/><span class="koboSpan" id="kobo.298.1">disentangling the features in these two spaces, users can more easily control the different aspects of the generated image, such as its physiology, hairstyle, or clothing. </span><span class="koboSpan" id="kobo.298.2">In simpler terms, it allows for separated control over high-level features of the image rather than specific </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">pixel values.</span></span></p>
<p><span class="koboSpan" id="kobo.300.1">The Synthesis Network is </span><a id="_idIndexMarker460"/><span class="koboSpan" id="kobo.301.1">a deep convolutional neural network that works by receiving style vectors, </span><em class="italic"><span class="koboSpan" id="kobo.302.1">w</span></em><span class="koboSpan" id="kobo.303.1">, as input and returns an output image. </span><span class="koboSpan" id="kobo.303.2">In synthesizing a realistic image, features are pulled from the feature vector and applied to the image layer by layer, beginning with the lowest layer and progressing one layer at a time to </span><span class="No-Break"><span class="koboSpan" id="kobo.304.1">higher resolutions.</span></span></p>
<p><span class="koboSpan" id="kobo.305.1">The Synthesis Network interacts with a learned </span><strong class="bold"><span class="koboSpan" id="kobo.306.1">adaptive instance normalization</span></strong><span class="koboSpan" id="kobo.307.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.308.1">AdaIN</span></strong><span class="koboSpan" id="kobo.309.1">) module that rescales image features to increase diversity in image outputs. </span><span class="koboSpan" id="kobo.309.2">The module accepts the feature vector and a style vector as inputs and adjusts image features’ scaling and bias by subtracting the feature map’s mean and dividing it by the standard deviation. </span><span class="koboSpan" id="kobo.309.3">As a result, StyleGAN can produce highly detailed images by focusing on specific features such as hairstyle or </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">eye color.</span></span></p>
<h3><span class="koboSpan" id="kobo.311.1">Understanding the challenges of GANs</span></h3>
<p><span class="koboSpan" id="kobo.312.1">Although </span><a id="_idIndexMarker461"/><span class="koboSpan" id="kobo.313.1">GANs are a wonderful addition to the machine learning toolbox, they are not without </span><span class="No-Break"><span class="koboSpan" id="kobo.314.1">their challenges.</span></span></p>
<p><span class="koboSpan" id="kobo.315.1">GANs are based on zero-sum game theory. </span><span class="koboSpan" id="kobo.315.2">Essentially, if one player triumphs, then the other will be defeated. </span><span class="koboSpan" id="kobo.315.3">This kind of situation is also known as minimax: your opponent looks to maximize their output while you seek to minimize it. </span><span class="koboSpan" id="kobo.315.4">The theory behind GANs states that the game between the generator and discriminator models will continue until a Nash Equilibrium </span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">is reached.</span></span></p>
<p><span class="koboSpan" id="kobo.317.1">The Nash Equilibrium </span><a id="_idIndexMarker462"/><span class="koboSpan" id="kobo.318.1">is an important solution concept within economics, politics, and evolutionary biology that can be seen in a wide variety of real-world scenarios. </span><span class="koboSpan" id="kobo.318.2">A Nash Equilibrium is a situation where no player has an incentive to do something different than what they are already doing. </span><span class="koboSpan" id="kobo.318.3">This is because they have considered what everyone else is doing and they think that their current strategy is the best </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">possible option.</span></span></p>
<p><span class="koboSpan" id="kobo.320.1">In such situations, all players are said to be at equilibrium as they have no incentive to change their behavior because any changes made by one player will likely lead to a worse outcome for that particular player. </span><span class="koboSpan" id="kobo.320.2">Therefore, it is in each individual’s best interest not to make any sudden changes in this type of </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">equilibrium situation.</span></span></p>
<p><span class="koboSpan" id="kobo.322.1">For example, consider</span><a id="_idIndexMarker463"/><span class="koboSpan" id="kobo.323.1"> a scenario where competing firms are trying to set prices for their products or services. </span><span class="koboSpan" id="kobo.323.2">If each firm sets its price too high, it may lose customers to its competitors. </span><span class="koboSpan" id="kobo.323.3">However, if each firm sets its price too low, it will not be able to cover its costs and make a profit. </span><span class="koboSpan" id="kobo.323.4">Thus, the Nash Equilibrium for this situation is for each firm to set their prices at a level that is low enough to deter customers from buying from their competitors without being so low that they are unable to make </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">a profit.</span></span></p>
<p><span class="koboSpan" id="kobo.325.1">Although this theory can work, it is often difficult to achieve in practice. </span><span class="koboSpan" id="kobo.325.2">There is no guarantee that cost functions will </span><em class="italic"><span class="koboSpan" id="kobo.326.1">converge</span></em><span class="koboSpan" id="kobo.327.1"> and find a Nash Equilibrium. </span><span class="koboSpan" id="kobo.327.2">In this situation, the game </span><span class="No-Break"><span class="koboSpan" id="kobo.328.1">continues indefinitely.</span></span></p>
<p><span class="koboSpan" id="kobo.329.1">Moreover, when one agent outmatches the other in terms of power and efficacy, the learning signal for their counterpart becomes useless; consequently, no knowledge is gained by either side. </span><span class="koboSpan" id="kobo.329.2">The most common scenario is that the discriminator becomes so good at picking the generator’s faults that the generator never learns how to advance in </span><span class="No-Break"><span class="koboSpan" id="kobo.330.1">the game.</span></span></p>
<p><span class="koboSpan" id="kobo.331.1">One of the main challenges with GANs is called mode collapse. </span><span class="koboSpan" id="kobo.331.2">Like any other statistical model, GANs tend to find the easiest way through the underlying data, which can lead to the overrepresentation of </span><span class="No-Break"><span class="koboSpan" id="kobo.332.1">modal observations.</span></span></p>
<p><span class="koboSpan" id="kobo.333.1">Mode collapse is another common issue that occurs when the generator produces an especially plausible output, which causes it to only produce that output. </span><span class="koboSpan" id="kobo.333.2">Once this happens, the discriminator is more likely to fall into a local minimum, unable to find a better output that it </span><span class="No-Break"><span class="koboSpan" id="kobo.334.1">deems valid.</span></span></p>
<p><span class="koboSpan" id="kobo.335.1">Consequently, the generator is driven to tailor its outputs toward the criteria used by this static discriminator rather than attempting to create realistic or dynamic outputs. </span><span class="koboSpan" id="kobo.335.2">As such, generators tend to “over-optimize” for a particular outcome, as determined by their </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">single discriminator.</span></span></p>
<p><span class="koboSpan" id="kobo.337.1">An example of mode collapse is illustrated in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.338.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.339.1">.7</span></em><span class="koboSpan" id="kobo.340.1"> and is from Metz et al. </span><span class="koboSpan" id="kobo.340.2">(2017)</span><span class="superscript"><span class="koboSpan" id="kobo.341.1">9</span></span><span class="koboSpan" id="kobo.342.1">. </span><span class="koboSpan" id="kobo.342.2">In this example, the researchers used the MNIST dataset of handwritten digits to train two different GANs. </span><span class="koboSpan" id="kobo.342.3">The MNIST dataset contains 10 different modes that represent </span><span class="No-Break"><span class="koboSpan" id="kobo.343.1">digits 0-9.</span></span></p>
<p><span class="koboSpan" id="kobo.344.1">The top four</span><a id="_idIndexMarker464"/><span class="koboSpan" id="kobo.345.1"> quadrants of numbers have been successfully generated (using an unrolled GAN training method) to look like real handwritten digits with a representation of all possible digits. </span><span class="koboSpan" id="kobo.345.2">The bottom four quadrants, on the other hand (generated using the original GAN architecture), have suffered from mode collapse early on in the process and produce only representations of the </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">number 6:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer078">
<span class="koboSpan" id="kobo.347.1"><img alt="Figure 7.7 – Two different GAN architectures trained on the MNIST dataset from Metz et al. (2017)" src="image/B19297_07_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.348.1">Figure 7.7 – Two different GAN architectures trained on the MNIST dataset from Metz et al. </span><span class="koboSpan" id="kobo.348.2">(2017)</span></p>
<p><span class="koboSpan" id="kobo.349.1">Since the development of the original GAN architecture in 2014, several new GAN variants have been introduced to deal with mode collapse. </span><span class="koboSpan" id="kobo.349.2">As a result, this is now a less common issue, but it’s something to always watch </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">out for.</span></span></p>
<p><span class="koboSpan" id="kobo.351.1">The mode collapse in the MNIST example is relatively easy to spot, but it is important to note that GANs may potentially preserve and exacerbate existing biases in more </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">subtle ways.</span></span></p>
<p><span class="koboSpan" id="kobo.353.1">In a 2021 study (Jain et at, 2021)</span><span class="superscript"><span class="koboSpan" id="kobo.354.1">10</span></span><span class="koboSpan" id="kobo.355.1">, researchers from Arizona State University and Rensselaer Polytechnic Institute assessed the performance of GANs in generating synthetic facial data. </span><span class="koboSpan" id="kobo.355.2">The researchers wanted to test whether GANs would exacerbate the modal facial characteristics from a (naturally) biased input dataset, thus increasing the most common features in the </span><span class="No-Break"><span class="koboSpan" id="kobo.356.1">synthetic output.</span></span></p>
<p><span class="koboSpan" id="kobo.357.1">Two </span><a id="_idIndexMarker465"/><span class="koboSpan" id="kobo.358.1">model architectures were compared: </span><strong class="bold"><span class="koboSpan" id="kobo.359.1">deep convolutional GAN</span></strong><span class="koboSpan" id="kobo.360.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.361.1">DCGAN</span></strong><span class="koboSpan" id="kobo.362.1">) and ProGAN. </span><span class="koboSpan" id="kobo.362.2">The experiment involved a </span><a id="_idIndexMarker466"/><span class="koboSpan" id="kobo.363.1">dataset of 17,245 images of engineering professors from US universities, of which 80% were classified as male and 76% were classified as white. </span><span class="koboSpan" id="kobo.363.2">The experiment used human classifiers (Turkers) to classify the faces in the original dataset and those produced by </span><span class="No-Break"><span class="koboSpan" id="kobo.364.1">the GANs.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.365.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.366.1">.8</span></em><span class="koboSpan" id="kobo.367.1"> shows the outcomes of two of the GANs tested against the original dataset. </span><span class="koboSpan" id="kobo.367.2">The DCGAN model resulted in heavily biased data generation, with a large overrepresentation of males and whites in the synthetic images. </span><span class="koboSpan" id="kobo.367.3">While the ProGAN model carried less of a bias, it still wasn’t a reasonable representation of the features in the </span><span class="No-Break"><span class="koboSpan" id="kobo.368.1">original dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.369.1">Both DCGAN and ProGAN penalized images with mostly feminine features. </span><span class="koboSpan" id="kobo.369.2">DCGAN generated the most biased output, reducing the percentage of feminine faces from 20% </span><span class="No-Break"><span class="koboSpan" id="kobo.370.1">to 6.67%.</span></span></p>
<p><span class="koboSpan" id="kobo.371.1">In comparison to the 24% non-white faces in the original dataset, both DCGAN and ProGAN reduced that rate significantly – 1.33%% for DCGAN and 11.33% for </span><span class="No-Break"><span class="koboSpan" id="kobo.372.1">ProGAN, respectively:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer079">
<span class="koboSpan" id="kobo.373.1"><img alt="Figure 7.8 – Comparison of gender and skin color distributions from synthetic facial images generated by GANs versus the original dataset. Source: Jain et al., 2021" src="image/B19297_07_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.374.1">Figure 7.8 – Comparison of gender and skin color distributions from synthetic facial images generated by GANs versus the original dataset. </span><span class="koboSpan" id="kobo.374.2">Source: Jain et al., 2021</span></p>
<p><span class="koboSpan" id="kobo.375.1">In other words, GANs can produce highly realistic synthetic datasets that may still be a biased representation of the latent features in the original dataset. </span><span class="koboSpan" id="kobo.375.2">Ironically, this partial mode collapse may produce more realistic images because the GAN has specialized to perform well for </span><span class="No-Break"><span class="koboSpan" id="kobo.376.1">certain dimensions.</span></span></p>
<p><span class="koboSpan" id="kobo.377.1">Following</span><a id="_idIndexMarker467"/><span class="koboSpan" id="kobo.378.1"> our principles of data-centric machine learning, it is important to identify modal bias across all dimensions of a synthetic dataset to ensure it is useful and ethically appropriate for your intended purpose. </span><span class="koboSpan" id="kobo.378.2">It is typically a process of trial and error to empirically validate and remove bias in </span><span class="No-Break"><span class="koboSpan" id="kobo.379.1">GAN outputs.</span></span></p>
<p><span class="koboSpan" id="kobo.380.1">Finally, a notable weakness of GANs is that generating high-quality outputs requires a lot of computational resources, and without these, the images that are produced may appear blurry or unrealistic. </span><span class="koboSpan" id="kobo.380.2">Furthermore, without an experienced person choosing the appropriate directions to use for image generation, using GANs may not produce the </span><span class="No-Break"><span class="koboSpan" id="kobo.381.1">desired outcome.</span></span></p>
<h2 id="_idParaDest-109"><a id="_idTextAnchor117"/><span class="koboSpan" id="kobo.382.1">Exploring image augmentation with a practical example</span></h2>
<p><span class="koboSpan" id="kobo.383.1">Despite</span><a id="_idIndexMarker468"/><span class="koboSpan" id="kobo.384.1"> the complexity</span><a id="_idIndexMarker469"/><span class="koboSpan" id="kobo.385.1"> involved in synthetic image data generation, we want to finish this section with a practical example that gets you inspired to apply these techniques in </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1">your work.</span></span></p>
<p><span class="koboSpan" id="kobo.387.1">In this section, we will cover data augmentation, a mechanism for generating synthetic data for image data. </span><span class="koboSpan" id="kobo.387.2">We will use a pre-trained Xception model that was trained on ImageNet data and fine-tune it to accommodate clothing examples. </span><span class="koboSpan" id="kobo.387.3">We will achieve this by applying transfer learning to fine-tune the clothing examples, and then generate synthetic data to enhance its performance. </span><span class="koboSpan" id="kobo.387.4">With transfer learning, we can freeze the pre-trained </span><a id="_idIndexMarker470"/><span class="koboSpan" id="kobo.388.1">layers of the network and only train the new layers by updating the final output. </span><span class="koboSpan" id="kobo.388.2">This helps the model to quickly adapt to the new dataset with less </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">training time.</span></span></p>
<p><span class="koboSpan" id="kobo.390.1">By applying</span><a id="_idIndexMarker471"/><span class="koboSpan" id="kobo.391.1"> transfer learning and image augmentation techniques on top of a pre-trained Xception model, we can generate synthetic data that can improve the performance of the model on new data. </span><span class="koboSpan" id="kobo.391.2">This approach is widely used in various applications, including image classification, object detection, </span><span class="No-Break"><span class="koboSpan" id="kobo.392.1">and segmentation.</span></span></p>
<p><span class="koboSpan" id="kobo.393.1">To start, we need to load the pre-trained Xception model using the TensorFlow library. </span><span class="koboSpan" id="kobo.393.2">We can do this by simply importing the Xception model from the TensorFlow module and setting the </span><strong class="source-inline"><span class="koboSpan" id="kobo.394.1">include_top</span></strong><span class="koboSpan" id="kobo.395.1"> parameter to </span><strong class="source-inline"><span class="koboSpan" id="kobo.396.1">False</span></strong><span class="koboSpan" id="kobo.397.1"> to exclude the top layer of </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">the model.</span></span></p>
<p><span class="koboSpan" id="kobo.399.1">Next, we must add a custom classifier on top of the pre-trained Xception model. </span><span class="koboSpan" id="kobo.399.2">We can achieve this by adding a few dense layers and a final output layer with the number of classes equal to the number of clothing categories we want </span><span class="No-Break"><span class="koboSpan" id="kobo.400.1">to classify.</span></span></p>
<p><span class="koboSpan" id="kobo.401.1">To further improve the model’s performance, we will apply image augmentation using the out-of-the-box TensorFlow features. </span><span class="koboSpan" id="kobo.401.2">This can include rotation, zooming, flipping, and other techniques to create variations in the training data and make the model </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1">more robust.</span></span></p>
<p><span class="koboSpan" id="kobo.403.1">Finally, we will train the model using the augmented training data and evaluate its performance on the validation set. </span><span class="koboSpan" id="kobo.403.2">We can fine-tune the hyperparameters of the model and the augmentation techniques to achieve </span><span class="No-Break"><span class="koboSpan" id="kobo.404.1">better accuracy.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.405.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.406.1">This example has been adapted from </span><a href="B19297_07.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.407.1">Chapter 7</span></em></span></a><span class="koboSpan" id="kobo.408.1"> of </span><em class="italic"><span class="koboSpan" id="kobo.409.1">Machine Learning Bookcamp</span></em><span class="koboSpan" id="kobo.410.1"> (</span><a href="http://book/machine-learning-bookcamp/chapter-7/"><span class="koboSpan" id="kobo.411.1">https://livebook.manning.com/book/machine-learning-bookcamp/chapter-7/</span></a><span class="koboSpan" id="kobo.412.1">) and has also been made available by the author of the book through a course run by the author’s company, DataTalks </span><span class="No-Break"><span class="koboSpan" id="kobo.413.1">Club (</span></span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">https://github.com/alexeygrigorev/mlbookcamp-code</span></span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.416.1">To start, we </span><a id="_idIndexMarker472"/><span class="koboSpan" id="kobo.417.1">will import all the </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">necessary libraries:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.419.1">
import tensorflow as tf
from tensorflow.keras.applications.xception import Xception, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator
import numpy as np
from tensorflow import keras
import matplotlib.pyplot as plt
2024-01-29 17:34:32.614910: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. </span><span class="koboSpan" id="kobo.419.2">You may see slightly different numerical results due to floating-point round-off errors from different computation orders. </span><span class="koboSpan" id="kobo.419.3">To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.</span></pre> <p><span class="koboSpan" id="kobo.420.1">Next, we will </span><a id="_idIndexMarker473"/><span class="koboSpan" id="kobo.421.1">download the data by cloning the dataset from its respective </span><span class="No-Break"><span class="koboSpan" id="kobo.422.1">GitHub repository:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.423.1">
!git clone git@github.com:alexeygrigorev/clothing-dataset-small.git</span></pre> <p><span class="koboSpan" id="kobo.424.1">Next, we will load an image of pants that we have downloaded from the clothing dataset repository. </span><span class="koboSpan" id="kobo.424.2">To load the image, we will use the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.425.1">load_img</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.426.1"> function:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.427.1">
path = './clothing-dataset-small/train/pants/12bfe0f0-accc-4539-ab51-53f63534938e.jpg'
load_img(path)</span></pre> <p><span class="koboSpan" id="kobo.428.1">This will display the </span><span class="No-Break"><span class="koboSpan" id="kobo.429.1">following output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer080">
<span class="koboSpan" id="kobo.430.1"><img alt="Figure 7.9 – A pair of pants as output from the load_img function" src="image/B19297_07_9.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.431.1">Figure 7.9 – A pair of pants as output from the load_img function</span></p>
<p><span class="koboSpan" id="kobo.432.1">Next, we </span><a id="_idIndexMarker474"/><span class="koboSpan" id="kobo.433.1">will represent the image as a NumPy array as this is the format in which the model expects the image. </span><span class="koboSpan" id="kobo.433.2">We</span><a id="_idIndexMarker475"/><span class="koboSpan" id="kobo.434.1"> also need to ensure that all images are passed to the model with the same dimensions, so we will choose a standard of (299, 299, 3), which means 299 pixels top to bottom, 299 pixels left to right, and three color channels, which are red, green, and blue. </span><span class="koboSpan" id="kobo.434.2">Each pixel will be represented three times with values from 0-255 for each </span><span class="No-Break"><span class="koboSpan" id="kobo.435.1">color channel.</span></span></p>
<p><span class="koboSpan" id="kobo.436.1">Now, we must load the preceding image with a target size </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">of (299,299):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.438.1">
img = load_img(path=path, target_size=(299,299))
img_input = np.array(img)
img_input.shape
(299, 299, 3)</span></pre> <p><span class="koboSpan" id="kobo.439.1">Let’s see the image with our </span><span class="No-Break"><span class="koboSpan" id="kobo.440.1">new dimension:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.441.1">
img</span></pre> <p><span class="koboSpan" id="kobo.442.1">The output is </span><span class="No-Break"><span class="koboSpan" id="kobo.443.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer081">
<span class="koboSpan" id="kobo.444.1"><img alt="Figure 7.10 – Our image of a pair of pants, resized to be 299x299 pixels" src="image/B19297_07_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.445.1">Figure 7.10 – Our image of a pair of pants, resized to be 299x299 pixels</span></p>
<p><span class="koboSpan" id="kobo.446.1">Now that </span><a id="_idIndexMarker476"/><span class="koboSpan" id="kobo.447.1">we have ensured the dimensions, we will load the pretrained Xception model and specify the input</span><a id="_idIndexMarker477"/><span class="koboSpan" id="kobo.448.1"> format, which is the same as the dimensions specified for the preceding image. </span><span class="koboSpan" id="kobo.448.2">Once we’ve loaded the model, we will score the image and check </span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">the prediction:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.450.1">
model = Xception(weights='imagenet', input_shape=(299,299,3))</span></pre> <p><span class="koboSpan" id="kobo.451.1">The model expects the list of images in a particular format; hence, we will pass the previous image as a list and convert it into a NumPy array. </span><span class="koboSpan" id="kobo.451.2">Then, we will preprocess the image using </span><strong class="source-inline"><span class="koboSpan" id="kobo.452.1">preprocess_input</span></strong><span class="koboSpan" id="kobo.453.1"> and use and then score the input. </span><span class="koboSpan" id="kobo.453.2">The prediction will be stored </span><span class="No-Break"><span class="koboSpan" id="kobo.454.1">in </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.455.1">pred</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.456.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.457.1">
img_preprocessed = preprocess_input(np.array([img_input]))
pred = model.predict(img_preprocessed)
pred.shape
1/1 [==============================] - 3s 3s/step
(1, 1000)</span></pre> <p><span class="koboSpan" id="kobo.458.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.459.1">preprocess_input</span></strong><span class="koboSpan" id="kobo.460.1"> function is required to preprocess the image data required by the model since when the Xception model was trained, the input values were transformed from 0-255 and scaled to have values between -1 and 1. </span><span class="koboSpan" id="kobo.460.2">This is important because the distribution of color scales may affect the prediction. </span><span class="koboSpan" id="kobo.460.3">Imagine that red color scales were between 0-100, while blue color scales were between 200-300; this may have led to an unstable model. </span><span class="koboSpan" id="kobo.460.4">Hence, scaling is important. </span><span class="koboSpan" id="kobo.460.5">Without the correct preprocessing, the predictions won’t </span><span class="No-Break"><span class="koboSpan" id="kobo.461.1">make sense.</span></span></p>
<p><span class="koboSpan" id="kobo.462.1">Next, we </span><a id="_idIndexMarker478"/><span class="koboSpan" id="kobo.463.1">will decode these predictions with a convenience function. </span><span class="koboSpan" id="kobo.463.2">The model will provide a probability of the</span><a id="_idIndexMarker479"/><span class="koboSpan" id="kobo.464.1"> top five labels out of 1,000 different classes since the Xception model was trained to predict 1,000 labels. </span><span class="koboSpan" id="kobo.464.2">We don’t believe the target labels consist of clothing examples, so after the next few steps, we will move on to transfer learning. </span><span class="koboSpan" id="kobo.464.3">To decode the predictions, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.465.1">decode_predictions</span></strong><span class="koboSpan" id="kobo.466.1"> function. </span><strong class="source-inline"><span class="koboSpan" id="kobo.467.1">decode_predictions</span></strong><span class="koboSpan" id="kobo.468.1"> is a convenience function that provides predictions in such a format that they can be </span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">easily understood:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.470.1">
decode_predictions(pred)
[[('n03594734', 'jean', 0.651147),
  ('n04371430', 'swimming_trunks', 0.22369406),
  ('n03710637', 'maillot', 0.004711655),
  ('n04525038', 'velvet', 0.0038891942),
  ('n03595614', 'jersey', 0.003085624)]]</span></pre> <p><span class="koboSpan" id="kobo.471.1">It’s quite clear that the image of the pants is closest to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.472.1">jean</span></strong><span class="koboSpan" id="kobo.473.1"> label and then the </span><strong class="source-inline"><span class="koboSpan" id="kobo.474.1">swimming_trunks</span></strong><span class="koboSpan" id="kobo.475.1"> label, as per the labels used in the Xception model. </span><span class="koboSpan" id="kobo.475.2">However, in the training data, there is no </span><strong class="source-inline"><span class="koboSpan" id="kobo.476.1">jean</span></strong><span class="koboSpan" id="kobo.477.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.478.1">swimming_trunks</span></strong><span class="koboSpan" id="kobo.479.1"> label. </span><span class="koboSpan" id="kobo.479.2">Next, we will extract the training data and make sure it is preprocessed before we pass it </span><span class="No-Break"><span class="koboSpan" id="kobo.480.1">for training.</span></span></p>
<p><span class="koboSpan" id="kobo.481.1">For this, we will use transfer learning and leverage the entire training data. </span><span class="koboSpan" id="kobo.481.2">We will use </span><strong class="source-inline"><span class="koboSpan" id="kobo.482.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.483.1"> to help process the input data that the model requires and then create training and validation datasets. </span><span class="koboSpan" id="kobo.483.2">The training data will consist of 3,041 images, while the validation data will consist of 341 images. </span><span class="koboSpan" id="kobo.483.3">For preprocessing, we will use 150x150 pixels instead of 299x299 pixels to reduce the </span><span class="No-Break"><span class="koboSpan" id="kobo.484.1">training time:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.485.1">
train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)</span></pre> <p><span class="koboSpan" id="kobo.486.1">Next, we </span><a id="_idIndexMarker480"/><span class="koboSpan" id="kobo.487.1">will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.488.1">flow_from_directory</span></strong><span class="koboSpan" id="kobo.489.1"> property to process the entire training and validation dataset. </span><span class="koboSpan" id="kobo.489.2">We will use </span><strong class="source-inline"><span class="koboSpan" id="kobo.490.1">seed=42</span></strong><span class="koboSpan" id="kobo.491.1"> to ensure data is passed to the network, it’s passed with the</span><a id="_idIndexMarker481"/><span class="koboSpan" id="kobo.492.1"> same randomization, and the result at each training layer is reproducible. </span><span class="koboSpan" id="kobo.492.2">For the validation data, we will utilize </span><strong class="source-inline"><span class="koboSpan" id="kobo.493.1">shuffle=False</span></strong><span class="koboSpan" id="kobo.494.1"> to ensure that there is no randomization at each training step but data is </span><span class="No-Break"><span class="koboSpan" id="kobo.495.1">passed sequentially:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.496.1">
train_ds = train_gen.flow_from_directory(directory='./clothing-dataset-small/train/', target_size=(150,150), batch_size=32, seed=42)
validation_ds = train_gen.flow_from_directory(directory="./clothing-dataset-small/validation/", target_size=(150,150), batch_size=32, shuffle=False)
Found 3081 images belonging to 10 classes.
</span><span class="koboSpan" id="kobo.496.2">Found 341 images belonging to 10 classes.</span></pre> <p><span class="koboSpan" id="kobo.497.1">Now, we can view the target classes of </span><span class="No-Break"><span class="koboSpan" id="kobo.498.1">our dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.499.1">
train_ds.class_indices
{'dress': 0,
 'hat': 1,
 'longsleeve': 2,
 'outwear': 3,
 'pants': 4,
 'shirt': 5,
 'shoes': 6,
 'shorts': 7,
 'skirt': 8,
 't-shirt': 9}</span></pre> <p><span class="koboSpan" id="kobo.500.1">Next, we</span><a id="_idIndexMarker482"/><span class="koboSpan" id="kobo.501.1"> will apply transfer learning. </span><span class="koboSpan" id="kobo.501.2">To do so, we must first extract the base layer – in other words, we must extract the convolutional layer of the Xception model and ensure it is frozen. </span><span class="koboSpan" id="kobo.501.3">This will ensure we get access to the feature map of the image data of 1 million+ images. </span><span class="koboSpan" id="kobo.501.4">To </span><a id="_idIndexMarker483"/><span class="koboSpan" id="kobo.502.1">do so, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.503.1">include_top=False</span></strong><span class="koboSpan" id="kobo.504.1"> parameter, which will ignore the dense layers and return the bottom layer of the convolutional neural network. </span><span class="koboSpan" id="kobo.504.2">Next, we will build a custom dense layer with the 10 class labels highlighted previously and train the dense layer for our </span><span class="No-Break"><span class="koboSpan" id="kobo.505.1">use case:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.506.1">
base_cnn_model = Xception(weights='imagenet', include_top=False, input_shape=(150,150,3))
base_cnn_model.trainable = False</span></pre> <p><span class="koboSpan" id="kobo.507.1">Next, we will build the architecture of the dense layer and combine it with the base layer. </span><span class="koboSpan" id="kobo.507.2">First, we will define the input standard such that the base model can provide the vector that’s suitable for input of the same standard. </span><span class="koboSpan" id="kobo.507.3">We will use (150,150,3) so that the model can be trained faster as more pixels can slow down the training process. </span><span class="koboSpan" id="kobo.507.4">Next, we will transform the vector from a base layer into a two-dimensional array. </span><span class="koboSpan" id="kobo.507.5">For that, we will use a method called pooling, which can help reduce the spatial size of feature maps but still retain the key information about the base layer. </span><span class="koboSpan" id="kobo.507.6">After that, we will create a dense layer where we specify the number of outputs, which is 10 in this case, and apply softmax activation to return </span><span class="No-Break"><span class="koboSpan" id="kobo.508.1">a probability.</span></span></p>
<p><span class="koboSpan" id="kobo.509.1">At this point, we can define the loss function, utilize the Adam optimizer with a learning rate of 0.005, and choose accuracy as </span><span class="No-Break"><span class="koboSpan" id="kobo.510.1">a metric:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.511.1">
inputs = keras.Input(shape=(150,150,3))
base = base_cnn_model(inputs)
vectors = keras.layers.GlobalAveragePooling2D()(base)
inner = keras.layers.Dense(100, activation='relu')(vectors)
drop = keras.layers.Dropout(rate=0.2)(inner)
outputs = keras.layers.Dense(10, activation='softmax')(drop)
model = keras.Model(inputs, outputs)
learning_rate = 0.005
optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
loss = keras.losses.CategoricalCrossentropy()</span></pre> <p><span class="koboSpan" id="kobo.512.1">Next, we </span><a id="_idIndexMarker484"/><span class="koboSpan" id="kobo.513.1">will compile the </span><a id="_idIndexMarker485"/><span class="koboSpan" id="kobo.514.1">model with the optimizer and loss to achieve the </span><span class="No-Break"><span class="koboSpan" id="kobo.515.1">best accuracy:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.516.1">
model.compile(optimizer=optimizer, loss=loss, metrics=["accuracy"])</span></pre> <p><span class="koboSpan" id="kobo.517.1">Now, we will train the network with the </span><span class="No-Break"><span class="koboSpan" id="kobo.518.1">clothing dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.519.1">
model.fit(train_ds, validation_data=validation_ds, epochs=10)
Epoch 1/10
97/97 [==============================] - 18s 156ms/step - loss: 1.1373 - accuracy: 0.6228 - val_loss: 0.7507 - val_accuracy: 0.7830
...
</span><span class="koboSpan" id="kobo.519.2">Epoch 10/10
97/97 [==============================] - 12s 118ms/step - loss: 0.1951 - accuracy: 0.9289 - val_loss: 0.7641 - val_accuracy: 0.7918</span></pre> <p><span class="koboSpan" id="kobo.520.1">Looking at these results, it is clear that the model is overfitted since the model achieved 92.7% accuracy on the training data and only 81.52% accuracy on the validation data, which is almost a 10-11% difference at the end of </span><span class="No-Break"><span class="koboSpan" id="kobo.521.1">10 epochs.</span></span></p>
<p><span class="koboSpan" id="kobo.522.1">We could try</span><a id="_idIndexMarker486"/><span class="koboSpan" id="kobo.523.1"> training dense layers with different learning rates to obtain a more generalized model. </span><span class="koboSpan" id="kobo.523.2">A learning rate controls how quickly we want the model to learn from training data and adjust its weights to fit </span><span class="No-Break"><span class="koboSpan" id="kobo.524.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.525.1">A low </span><a id="_idIndexMarker487"/><span class="koboSpan" id="kobo.526.1">learning rate is like watching a video at a slow pace to ensure most of the details are covered, whereas a high learning rate is like watching a video at a faster pace and some details may be missed. </span><span class="koboSpan" id="kobo.526.2">An optimized learning rate is crucial for successful training, but it often requires tuning to find a balance between convergence speed </span><span class="No-Break"><span class="koboSpan" id="kobo.527.1">and accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.528.1">Another way to reduce overfitting is by adjusting the dropout rate, which is a regularization technique in which a percentage of data is omitted at random. </span><span class="koboSpan" id="kobo.528.2">Both adjustments require experimentation and are more </span><span class="No-Break"><span class="koboSpan" id="kobo.529.1">model-centric approaches.</span></span></p>
<p><span class="koboSpan" id="kobo.530.1">Following a data-centric approach, we want to test more data examples or better data examples. </span><span class="koboSpan" id="kobo.530.2">We need examples where the model doesn’t try to memorize specific pixels so that if it sees 120 red in the 130th-pixel location, it starts believing the image is of pants. </span><span class="koboSpan" id="kobo.530.3">Hence, to ensure a well-generalized model, we could leverage </span><span class="No-Break"><span class="koboSpan" id="kobo.531.1">data augmentation.</span></span></p>
<p><span class="koboSpan" id="kobo.532.1">Concerning data-centric AI, data augmentation can be referred to as a technique to artificially increase the size and diversity of a training dataset by applying various transformations to the existing data. </span><span class="koboSpan" id="kobo.532.2">These transformations can include rotation, scaling, cropping, flipping, adding noise, and many others, depending on the type of data </span><span class="No-Break"><span class="koboSpan" id="kobo.533.1">being augmented.</span></span></p>
<p><span class="koboSpan" id="kobo.534.1">There are some common augmentation techniques, such as creating different angles of the image, shifting images, zooming images in and out, flipping them upside down, and more. </span><span class="koboSpan" id="kobo.534.2">However, before applying augmenting techniques, we must first consider different ways data will be generated. </span><span class="koboSpan" id="kobo.534.3">For instance, if users don’t generate pictures upside down, then augmenting images to create flipped images may only add noise and not provide a good signal to the model. </span><span class="koboSpan" id="kobo.534.4">For the following example, we will apply zoom augmentation, where images will be zoomed in and out a little, some shifting where clothing in the images will shift close to the edges, and apply vertical flips so that if some images are taken using a mirror, we can capture additional data for each scenario. </span><span class="koboSpan" id="kobo.534.5">We will achieve this by updating the image generator function, adding these extra parameters, and then training the model on the </span><span class="No-Break"><span class="koboSpan" id="kobo.535.1">best parameters.</span></span></p>
<p><span class="koboSpan" id="kobo.536.1">We will apply a</span><a id="_idIndexMarker488"/><span class="koboSpan" id="kobo.537.1"> rotation range of 10, a shear range of 10, a width and height shift range of 0.2, a zoom range of 0.1, and </span><a id="_idIndexMarker489"/><span class="koboSpan" id="kobo.538.1">vertical flip. </span><span class="koboSpan" id="kobo.538.2">To achieve this, we will tweak the </span><strong class="source-inline"><span class="koboSpan" id="kobo.539.1">ImageDataGenerator</span></strong><span class="koboSpan" id="kobo.540.1"> function as this will create more examples of the training data under </span><span class="No-Break"><span class="koboSpan" id="kobo.541.1">the hood:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.542.1">
train_gen = ImageDataGenerator(preprocessing_function=preprocess_input,
                               rotation_range=10,
                               shear_range=10,
                               width_shift_range=0.2,
                               height_shift_range=0.2,
                               zoom_range=0.1,
                               vertical_flip=True)
train_ds = train_gen.flow_from_directory(directory='./clothing-dataset-small/train/', target_size=(150,150), batch_size=32, seed=42)
val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)
validation_ds = val_gen.flow_from_directory(directory="./clothing-dataset-small/validation/", target_size=(150,150), batch_size=32, shuffle=False)
Found 3081 images belonging to 10 classes.
</span><span class="koboSpan" id="kobo.542.2">Found 341 images belonging to 10 classes.</span></pre> <p><span class="koboSpan" id="kobo.543.1">We will also create a function that will take in the learning rate and return the model and </span><span class="No-Break"><span class="koboSpan" id="kobo.544.1">its parameters:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.545.1">
def make_fashion_classification_model(learning_rate: float=0.1):
    """Function to create a dense custom model"""
    #### Base model ####
    inputs = keras.Input(shape=(150,150,3))
    base = base_cnn_model(inputs)
    vectors = keras.layers.GlobalAveragePooling2D()(base)
    #### Dense model ####
    outputs = keras.layers.Dense(10, activation='softmax')(vectors)
    model = keras.Model(inputs, outputs)
    #### Optimizing the model ####
    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    loss = keras.losses.CategoricalCrossentropy()
    model.compile(optimizer=optimizer, loss=loss, metrics=["accuracy"])
    return model</span></pre> <p><span class="koboSpan" id="kobo.546.1">Next, we </span><a id="_idIndexMarker490"/><span class="koboSpan" id="kobo.547.1">will use this function </span><a id="_idIndexMarker491"/><span class="koboSpan" id="kobo.548.1">and pass </span><strong class="source-inline"><span class="koboSpan" id="kobo.549.1">0.005</span></strong><span class="koboSpan" id="kobo.550.1"> as the learning rate and add 50 epochs since we have generated a lot more data </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1">for augmentation:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.552.1">
model = make_fashion_classification_model(learning_rate=0.005)
model_run = model.fit(train_ds, validation_data=validation_ds, epochs=50)
Epoch 1/50
97/97 [==============================] - 28s 266ms/step - loss: 1.5281 - accuracy: 0.4920 - val_loss: 0.9664 - val_accuracy: 0.6686
...
</span><span class="koboSpan" id="kobo.552.2">Epoch 32/50
97/97 [==============================] - 25s 253ms/step - loss: 0.7445 - accuracy: 0.7491 - val_loss: 0.6161 - val_accuracy: 0.8123</span></pre> <p><span class="koboSpan" id="kobo.553.1">The </span><a id="_idIndexMarker492"/><span class="koboSpan" id="kobo.554.1">model achieved lower training accuracy, but the model is more generalizable and not overfitted. </span><span class="koboSpan" id="kobo.554.2">Also, note that the best validation accuracy was achieved at the 32nd epoch. </span><span class="koboSpan" id="kobo.554.3">However, it is </span><a id="_idIndexMarker493"/><span class="koboSpan" id="kobo.555.1">difficult to note at which epoch a model will achieve the </span><span class="No-Break"><span class="koboSpan" id="kobo.556.1">best accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.557.1">To achieve this, we can further utilize the model checkpoint functionality to ensure only a model that achieves a minimum validation accuracy of 78% at a given epoch will be created and saved, and only when a previous best accuracy is surpassed will a new model be created. </span><span class="koboSpan" id="kobo.557.2">We can then use these saved models to score </span><span class="No-Break"><span class="koboSpan" id="kobo.558.1">test data.</span></span></p>
<p><span class="koboSpan" id="kobo.559.1">In the next step, we will add a dropout rate of 0.2 and an inner layer of 50. </span><span class="koboSpan" id="kobo.559.2">We will update the function for training the network and add the checkpoint functionality. </span><span class="koboSpan" id="kobo.559.3">Once the checkpoint has been created, we’ll add it as a callback to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.560.1">fit</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.561.1"> function.</span></span></p>
<p><span class="koboSpan" id="kobo.562.1">We encourage you to utilize hyperparameterization with the learning rate, dropout rate, and inner layer while using the checkpoint to ensure the </span><span class="No-Break"><span class="koboSpan" id="kobo.563.1">best accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.564.1">First, we will define a function that takes three inputs – the learning rate, the inner layer, and the </span><span class="No-Break"><span class="koboSpan" id="kobo.565.1">dropout rate:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.566.1">
def make_fashion_classification_model(learning_rate: float=0.001, inner_layer: int=50, drop_rate: float=0.2):
    """Function to create a dense custom model with learning rate, inner layer and dropout rate"""
    #### Base model ####
    inputs = keras.Input(shape=(150,150,3))
    base = base_cnn_model(inputs)
    vectors = keras.layers.GlobalAveragePooling2D()(base)
    #### Dense model layers ####
    inner = keras.layers.Dense(inner_layer, activation='relu')(vectors)
    drop = keras.layers.Dropout(rate=drop_rate)(inner)
    outputs = keras.layers.Dense(10, activation='softmax')(drop)
    model = keras.Model(inputs, outputs)
    #### Optimizing the model ####
    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    loss = keras.losses.CategoricalCrossentropy()
    model.compile(optimizer=optimizer, loss=loss, metrics=["accuracy"])
    return model</span></pre> <p><span class="koboSpan" id="kobo.567.1">Next, we will define the checkpoint. </span><span class="koboSpan" id="kobo.567.2">This is where we will save all the models with various epochs where the validation accuracy has reached a minimum of 78%. </span><span class="koboSpan" id="kobo.567.3">Then, we will add this checkpoint to the callback of the </span><span class="No-Break"><span class="koboSpan" id="kobo.568.1">fitting function:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.569.1">
checkpoint_model = keras.callbacks.ModelCheckpoint(
    filepath="xception_v1_{epoch:02d}_{val_accuracy:.4f}.h5",
    monitor="val_accuracy",
    save_best_only=True,
    initial_value_threshold=0.8,
    mode="max")
model = make_fashion_classification_model()
model.fit(train_ds, validation_data=validation_ds, epochs=50, callbacks=[checkpoint_model])
Epoch 1/50
97/97 [==============================] - 28s 266ms/step - loss: 1.4822 - accuracy: 0.5138 - val_loss: 0.8920 - val_accuracy: 0.7155
...
</span><span class="koboSpan" id="kobo.569.2">Epoch 37/50
97/97 [==============================] - 24s 250ms/step - loss: 0.5789 - accuracy: 0.7916 - val_loss: 0.5809 - val_accuracy: 0.8123</span></pre> <p><span class="koboSpan" id="kobo.570.1">Now that</span><a id="_idIndexMarker494"/><span class="koboSpan" id="kobo.571.1"> the best </span><a id="_idIndexMarker495"/><span class="koboSpan" id="kobo.572.1">model has been trained and saved, we will import the saved model, score all the data, and calculate the </span><span class="No-Break"><span class="koboSpan" id="kobo.573.1">test accuracy:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.574.1">
model = keras.models.load_model('xception_v1_37_0.8123.h5')
test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)
test_ds = test_gen.flow_from_directory(directory="./clothing-dataset-small/test/", target_size=(150,150), batch_size=32, shuffle=False, seed=42)
accuracy = model.evaluate(test_ds)[1]
print(f"accuracy on train data was 79.16, where as validation accuracy was 81.23, but test accuracy is {accuracy*100:.2f}")
Found 372 images belonging to 10 classes.
</span><span class="koboSpan" id="kobo.574.2">12/12 [==============================] - 2s 94ms/step - loss: 0.6317 - accuracy: 0.7715
accuracy on train data was 79.16, whereas validation accuracy was 81.23, but test accuracy is 77.15</span></pre> <p><span class="koboSpan" id="kobo.575.1">The </span><a id="_idIndexMarker496"/><span class="koboSpan" id="kobo.576.1">model that we used to</span><a id="_idIndexMarker497"/><span class="koboSpan" id="kobo.577.1"> predict the test data had a training accuracy of 79.16% and a validation accuracy of 81.23%. </span><span class="koboSpan" id="kobo.577.2">The test accuracy we achieved was only 77.15%, which can be improved iteratively – but beyond the scope of this example – by utilizing hyperparameter tuning for data augmentation parameters and model-centric parameters, which is encouraged in real life. </span><span class="koboSpan" id="kobo.577.3">However, due to computing and time constraints, this is outside the scope of </span><span class="No-Break"><span class="koboSpan" id="kobo.578.1">this book.</span></span></p>
<p><span class="koboSpan" id="kobo.579.1">Next, we will extract the target labels and build a function to provide a predicted probability score along with the relevant classes. </span><span class="koboSpan" id="kobo.579.2">First, we will load the image and preprocess it, and then we will </span><span class="No-Break"><span class="koboSpan" id="kobo.580.1">score it:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.581.1">
labels = [i for i in train_ds.class_indices.keys()]
def preprocess_image(path: str, target_size: tuple):
    """Function to preprocess image"""
    img = load_img(path=path, target_size=target_size)
    img_input = np.array([np.array(img)])
    preprocessed_image = preprocess_input(img_input)
    return preprocessed_image
def decode_predictions(pred):
    """Function to decode prediction"""
    result = {c: format(float(p), '.8f') for c, p in zip(labels, pred)}
    final_prediction = sorted(result.items(), key=lambda x:x[1],  reverse=True)[0]
    return final_prediction</span></pre> <p><span class="koboSpan" id="kobo.582.1">Next, we </span><a id="_idIndexMarker498"/><span class="koboSpan" id="kobo.583.1">will extract a random</span><a id="_idIndexMarker499"/><span class="koboSpan" id="kobo.584.1"> image of pants and run it through the model to get </span><span class="No-Break"><span class="koboSpan" id="kobo.585.1">the prediction:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.586.1">
path = './clothing-dataset-small/train/pants/188eaa2d-1a69-49b1-a9fb-7b3789ac93b4.jpg'
load_img(path)</span></pre> <p><span class="koboSpan" id="kobo.587.1">This will result in the </span><span class="No-Break"><span class="koboSpan" id="kobo.588.1">following output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer082">
<span class="koboSpan" id="kobo.589.1"><img alt="Figure 7.11 – A randomly selected pair of pants from the clothing dataset" src="image/B19297_07_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.590.1">Figure 7.11 – A randomly selected pair of pants from the clothing dataset</span></p>
<p><span class="koboSpan" id="kobo.591.1">Next, we </span><a id="_idIndexMarker500"/><span class="koboSpan" id="kobo.592.1">will load and preprocess the image before scoring it. </span><span class="koboSpan" id="kobo.592.2">Finally, we will decode the predictions to </span><a id="_idIndexMarker501"/><span class="koboSpan" id="kobo.593.1">extract the final prediction. </span><span class="koboSpan" id="kobo.593.2">For this, we will leverage the functions we </span><span class="No-Break"><span class="koboSpan" id="kobo.594.1">created earlier:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.595.1">
preprocessed_image = preprocess_image(path=path, target_size=(150,150))
preds = model.predict(preprocessed_image)
results = decode_predictions(preds[0])
results
1/1 [==============================] - 0s 26ms/step
('pants', '0.99980551')</span></pre> <p><span class="koboSpan" id="kobo.596.1">According to the model, the image has a probability of 99% to be classified as a pair of pants, which is </span><span class="No-Break"><span class="koboSpan" id="kobo.597.1">quite accurate.</span></span></p>
<p><span class="koboSpan" id="kobo.598.1">In this section, we have been able to demonstrate, through the data-centric technique of data augmentation, how to generalize the model. </span><span class="koboSpan" id="kobo.598.2">We believe that by iterating over data augmentation parameters, we can further improve the quality of the model. </span><span class="koboSpan" id="kobo.598.3">Once the </span><a id="_idIndexMarker502"/><span class="koboSpan" id="kobo.599.1">parameters have</span><a id="_idIndexMarker503"/><span class="koboSpan" id="kobo.600.1"> been tuned, we recommend that practitioners combine model-centric techniques such as regularization, the learning rate, inner layers, and the dropout rate to further tune and improve </span><span class="No-Break"><span class="koboSpan" id="kobo.601.1">the model.</span></span></p>
<p><span class="koboSpan" id="kobo.602.1">We will now move on to exploring another topic that relies on unstructured data: synthetic data for text and natural </span><span class="No-Break"><span class="koboSpan" id="kobo.603.1">language processing.</span></span></p>
<h2 id="_idParaDest-110"><a id="_idTextAnchor118"/><span class="koboSpan" id="kobo.604.1">Natural language processing</span></h2>
<p><span class="koboSpan" id="kobo.605.1">Synthetic text data </span><a id="_idIndexMarker504"/><span class="koboSpan" id="kobo.606.1">is typically used to increase the depth and breadth of written words and sentences with a similar semantic meaning to </span><span class="No-Break"><span class="koboSpan" id="kobo.607.1">real-life observations.</span></span></p>
<p><span class="koboSpan" id="kobo.608.1">The most </span><a id="_idIndexMarker505"/><span class="koboSpan" id="kobo.609.1">common augmentation techniques that are used to create synthetic data for natural language processing involve replacing words with synonyms, randomly shuffling the position of words in a sentence, and inserting or deleting words in </span><span class="No-Break"><span class="koboSpan" id="kobo.610.1">a sentence.</span></span></p>
<p><span class="koboSpan" id="kobo.611.1">For example, the sentence “I love drinking tea” could be transformed into “I take great pleasure in consuming tea” without losing the contextual meaning of the statement. </span><span class="koboSpan" id="kobo.611.2">This is an example of </span><em class="italic"><span class="koboSpan" id="kobo.612.1">synonym replacement</span></em><span class="koboSpan" id="kobo.613.1">, where “love” has been replaced with “take great pleasure in” and “drinking” has been replaced </span><span class="No-Break"><span class="koboSpan" id="kobo.614.1">with “consuming.”</span></span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.615.1">Back translation</span></em><span class="koboSpan" id="kobo.616.1"> is another NLP technique that involves translating a sentence in one language into another language, and then back into the original language. </span><span class="koboSpan" id="kobo.616.2">Often, this will generate slightly different sentence structures with a similar semantic meaning, which makes it a great way to combat overfitting while increasing the size of your </span><span class="No-Break"><span class="koboSpan" id="kobo.617.1">training data.</span></span></p>
<p><span class="koboSpan" id="kobo.618.1">We will illustrate a simple example of how to perform back translation using </span><em class="italic"><span class="koboSpan" id="kobo.619.1">Hugging Face Transformers</span></em><span class="koboSpan" id="kobo.620.1"> – specifically, the </span><em class="italic"><span class="koboSpan" id="kobo.621.1">MarianMT</span></em><span class="koboSpan" id="kobo.622.1"> suite of language models. </span><span class="koboSpan" id="kobo.622.2">MarianMT models were first created by Jörg Tiedemann using the Marian C++ library for fast training and translation but are now offered through the Hugging Face suite of </span><span class="No-Break"><span class="koboSpan" id="kobo.623.1">Python libraries.</span></span></p>
<p><span class="koboSpan" id="kobo.624.1">At the time of writing, the resource offers 1,440 transformer encoder-decoder models, each with six layers. </span><span class="koboSpan" id="kobo.624.2">These models support various language pairs, based on the </span><em class="italic"><span class="koboSpan" id="kobo.625.1">Helsinki-NLP</span></em><span class="koboSpan" id="kobo.626.1"> framework developed by the Language Technology Research Group at the University of Helsinki </span><span class="No-Break"><span class="koboSpan" id="kobo.627.1">in Finland.</span></span></p>
<p><span class="koboSpan" id="kobo.628.1">In this example, we</span><a id="_idIndexMarker506"/><span class="koboSpan" id="kobo.629.1"> want to translate the following three sentences from English into Spanish, and then use the same technique to translate the Spanish sentences back </span><span class="No-Break"><span class="koboSpan" id="kobo.630.1">into English:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.631.1">The man glanced suspiciously at </span><span class="No-Break"><span class="koboSpan" id="kobo.632.1">the door</span></span></li>
<li><span class="koboSpan" id="kobo.633.1">Peter thought he looked </span><span class="No-Break"><span class="koboSpan" id="kobo.634.1">very cool</span></span></li>
<li><span class="koboSpan" id="kobo.635.1">Most individuals are </span><span class="No-Break"><span class="koboSpan" id="kobo.636.1">rather nice</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.637.1">The goal is</span><a id="_idIndexMarker507"/><span class="koboSpan" id="kobo.638.1"> to generate similar sentences with the same semantic meaning but slightly different wording as this synthetic data will give our eventual model more data to </span><span class="No-Break"><span class="koboSpan" id="kobo.639.1">learn from.</span></span></p>
<p><span class="koboSpan" id="kobo.640.1">First, we’ll install the required </span><span class="No-Break"><span class="koboSpan" id="kobo.641.1">Python libraries:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.642.1">
pip install transformers sentencepiece
pip install mosestokenizer sacremoses</span></pre> <p><span class="koboSpan" id="kobo.643.1">Then, we’ll import the </span><strong class="source-inline"><span class="koboSpan" id="kobo.644.1">MarianMTModel</span></strong><span class="koboSpan" id="kobo.645.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.646.1">MarianTokenizer</span></strong><span class="koboSpan" id="kobo.647.1"> packages from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.648.1">transformers</span></strong><span class="koboSpan" id="kobo.649.1"> library and define our input text string </span><span class="No-Break"><span class="koboSpan" id="kobo.650.1">as </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.651.1">src_text</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.652.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.653.1">
from transformers import MarianMTModel, MarianTokenizer
src_text = ['The man glanced suspiciously at the door', 'Peter thought he looked very cool', 'Most individuals are rather nice']</span></pre> <p><span class="koboSpan" id="kobo.654.1">Now, we’ll define our </span><strong class="source-inline"><span class="koboSpan" id="kobo.655.1">translator</span></strong><span class="koboSpan" id="kobo.656.1"> model using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.657.1">Helsinki-NLP/opus-mt-en-es</span></strong><span class="koboSpan" id="kobo.658.1"> language model, which translates from English into Spanish. </span><span class="koboSpan" id="kobo.658.2">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.659.1">MarianTokenizer</span></strong><span class="koboSpan" id="kobo.660.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.661.1">MarianMTModel</span></strong><span class="koboSpan" id="kobo.662.1"> functions are used to define and execute our tokenizer and translation </span><span class="No-Break"><span class="koboSpan" id="kobo.663.1">model, respectively.</span></span></p>
<p><span class="koboSpan" id="kobo.664.1">The final output is stored as </span><strong class="source-inline"><span class="koboSpan" id="kobo.665.1">trans_out</span></strong><span class="koboSpan" id="kobo.666.1">, which is then used as the input for our back </span><span class="No-Break"><span class="koboSpan" id="kobo.667.1">translation model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.668.1">
translator = 'Helsinki-NLP/opus-mt-en-es'
tokenizer = MarianTokenizer.from_pretrained(translator)
model = MarianMTModel.from_pretrained(translator)
translated = model.generate(**tokenizer(src_text, return_tensors="pt", padding=True))
trans_out = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]</span></pre> <p><span class="koboSpan" id="kobo.669.1">In this basic </span><a id="_idIndexMarker508"/><span class="koboSpan" id="kobo.670.1">example, we simply repeat the same modeling exercise in reverse to produce slightly altered versions of the original input sentences. </span><span class="koboSpan" id="kobo.670.2">We use ‘</span><strong class="source-inline"><span class="koboSpan" id="kobo.671.1">Helsinki-NLP/opus-mt-es-en</span></strong><span class="koboSpan" id="kobo.672.1">’ to translate back </span><span class="No-Break"><span class="koboSpan" id="kobo.673.1">into English:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.674.1">
back_translator = 'Helsinki-NLP/opus-mt-es-en'
tokenizer = MarianTokenizer.from_pretrained(back_translator)
model_es = MarianMTModel.from_pretrained(back_translator)
back_translated = model_es.generate(**tokenizer(trans_out, return_tensors="pt", padding=True))
[tokenizer.decode(t, skip_special_tokens=True) for t in back_translated]</span></pre> <p><span class="koboSpan" id="kobo.675.1">The following</span><a id="_idIndexMarker509"/><span class="koboSpan" id="kobo.676.1"> table shows the original input sentences against the model’s output. </span><span class="koboSpan" id="kobo.676.2">The generated sentences have slightly different wording, but generally, they have the same semantic meaning as the originals. </span><span class="koboSpan" id="kobo.676.3">To use these sentences in a training dataset for a supervised model, they must inherit the labels of their original “</span><span class="No-Break"><span class="koboSpan" id="kobo.677.1">parent” sentences:</span></span></p>
<table class="No-Table-Style" id="table001-1">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.678.1">Input Sentence</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.679.1">Back Translation</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.680.1">The man glanced suspiciously at </span><span class="No-Break"><span class="koboSpan" id="kobo.681.1">the door</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.682.1">The man looked suspiciously at </span><span class="No-Break"><span class="koboSpan" id="kobo.683.1">the door</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.684.1">Peter thought he looked </span><span class="No-Break"><span class="koboSpan" id="kobo.685.1">very cool</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.686.1">Peter thought he </span><span class="No-Break"><span class="koboSpan" id="kobo.687.1">looked great</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.688.1">Most individuals are </span><span class="No-Break"><span class="koboSpan" id="kobo.689.1">rather nice</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.690.1">Most individuals are </span><span class="No-Break"><span class="koboSpan" id="kobo.691.1">quite pleasant</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.692.1">Table 7.1 – Examples of back translation using Hugging Face Transformers</span></p>
<h2 id="_idParaDest-111"><a id="_idTextAnchor119"/><span class="koboSpan" id="kobo.693.1">Privacy preservation</span></h2>
<p><span class="koboSpan" id="kobo.694.1">Synthetic data</span><a id="_idIndexMarker510"/><span class="koboSpan" id="kobo.695.1"> is also extremely useful for protecting the privacy and identity of individuals. </span><span class="koboSpan" id="kobo.695.2">The main aim of using synthetic data for privacy preservation is to make it impossible to identify individuals in a dataset while still keeping the statistical properties of the original dataset (close </span><span class="No-Break"><span class="koboSpan" id="kobo.696.1">to) intact.</span></span></p>
<p><span class="koboSpan" id="kobo.697.1">Synthetic data</span><a id="_idIndexMarker511"/><span class="koboSpan" id="kobo.698.1"> is an excellent option for privacy preservation since it allows information to be shared without revealing private or sensitive information. </span><span class="koboSpan" id="kobo.698.2">To achieve this, we must create data that resembles the original but does not contain any personally </span><span class="No-Break"><span class="koboSpan" id="kobo.699.1">identifiable information.</span></span></p>
<p><span class="koboSpan" id="kobo.700.1">The use of synthetic data allows organizations to share data for research or other purposes without compromising the privacy of individuals. </span><span class="koboSpan" id="kobo.700.2">There are several benefits to using synthetic data for privacy preservation – for example, you can reduce the risk of data breaches since the data contains no personal or </span><span class="No-Break"><span class="koboSpan" id="kobo.701.1">sensitive information.</span></span></p>
<p><span class="koboSpan" id="kobo.702.1">Data privacy regulations around the world are increasingly making it mandatory to protect individuals’ privacy when using consumer data for analytical purposes. </span><span class="koboSpan" id="kobo.702.2">Synthetic data can be used to comply with privacy regulations, such as GDPR in the European Union or the HIPAA privacy rule in the United States, which sets standards for protecting personal data and preventing it from being shared </span><span class="No-Break"><span class="koboSpan" id="kobo.703.1">without consent.</span></span></p>
<p><span class="koboSpan" id="kobo.704.1">In general, synthetic data is a useful tool for preserving privacy because it allows organizations to share data without revealing sensitive or personal information. </span><span class="koboSpan" id="kobo.704.2">It is particularly useful for managing the trade-off between data quality and individual privacy in machine learning, making it an integral part of the </span><span class="No-Break"><span class="koboSpan" id="kobo.705.1">data-centric toolbox.</span></span></p>
<p><span class="koboSpan" id="kobo.706.1">Consider, for example, a bank that wants to use sensitive customer data for analytical activities such as churn modeling, fraud detection, and credit assessments. </span><span class="koboSpan" id="kobo.706.2">Using customer data for these activities typically brings about many compliance risks and mandated requirements that must be managed to avoid privacy breaches and heavy fines </span><span class="No-Break"><span class="koboSpan" id="kobo.707.1">from regulators.</span></span></p>
<p><span class="koboSpan" id="kobo.708.1">By having pre-generated synthetic datasets at hand, data scientists from various parts of the business can quickly and safely build models that would yield similar results to models built on real-world data. </span><span class="koboSpan" id="kobo.708.2">By using </span><em class="italic"><span class="koboSpan" id="kobo.709.1">appropriately constructed</span></em><span class="koboSpan" id="kobo.710.1"> synthetic data, the organization avoids going through cumbersome compliance and governance processes every time a new model is built </span><span class="No-Break"><span class="koboSpan" id="kobo.711.1">and productionized.</span></span></p>
<p><span class="koboSpan" id="kobo.712.1">However, this</span><a id="_idIndexMarker512"/><span class="koboSpan" id="kobo.713.1"> doesn’t mean the use of privacy-preserving data is without its risks. </span><span class="koboSpan" id="kobo.713.2">It may happen, for example, that the generative model overfits the original data and produces synthetic instances too close to the </span><span class="No-Break"><span class="koboSpan" id="kobo.714.1">original data.</span></span></p>
<p><span class="koboSpan" id="kobo.715.1">Also, although</span><a id="_idIndexMarker513"/><span class="koboSpan" id="kobo.716.1"> synthetic data may appear anonymous, there may be instances where sophisticated hacks can reveal the identities of individuals. </span><span class="koboSpan" id="kobo.716.2">The aim of privacy-preserving synthetic data is to limit the risk of </span><span class="No-Break"><span class="koboSpan" id="kobo.717.1">this happening.</span></span></p>
<p><span class="koboSpan" id="kobo.718.1">Let’s explore some common privacy disclosure scenarios to understand these risks and how we might </span><span class="No-Break"><span class="koboSpan" id="kobo.719.1">limit them.</span></span></p>
<h3><span class="koboSpan" id="kobo.720.1">Types of privacy disclosure</span></h3>
<p><span class="koboSpan" id="kobo.721.1">To further</span><a id="_idIndexMarker514"/><span class="koboSpan" id="kobo.722.1"> understand and appreciate the usefulness of synthetic data for privacy preservation, let’s have a look at three different types of privacy disclosure that can occur. </span><span class="koboSpan" id="kobo.722.2">This is not an exhaustive list of potential disclosure events, but it does help build an understanding of the potential and limitations of using synthetic data for </span><span class="No-Break"><span class="koboSpan" id="kobo.723.1">this purpose.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.724.1">Direct identity disclosure</span></strong><span class="koboSpan" id="kobo.725.1"> is the</span><a id="_idIndexMarker515"/><span class="koboSpan" id="kobo.726.1"> most obvious type of privacy disclosure. </span><span class="koboSpan" id="kobo.726.2">This is where an external adversary, such as a hacker, tries to gain information by matching the identity of an individual to records of private information. </span><span class="koboSpan" id="kobo.726.3">An example of this could be matching a person’s identity with </span><span class="No-Break"><span class="koboSpan" id="kobo.727.1">medical records.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.728.1">Inferential identity disclosure</span></strong><span class="koboSpan" id="kobo.729.1"> is a</span><a id="_idIndexMarker516"/><span class="koboSpan" id="kobo.730.1"> form of data privacy breach where certain pieces of personal information can be derived from data that has been made publicly available, without explicitly revealing an individual’s identity. </span><span class="koboSpan" id="kobo.730.2">This type of privacy breach occurs when an attacker uses statistical analysis to infer characteristics about an individual by analyzing patterns and correlations in a dataset. </span><span class="koboSpan" id="kobo.730.3">For example, an attacker may be able to determine the gender of an individual from publicly available data by analyzing patterns between particular characteristics and the </span><span class="No-Break"><span class="koboSpan" id="kobo.731.1">corresponding gender.</span></span></p>
<p><span class="koboSpan" id="kobo.732.1">Fully synthetic data, by design, makes direct identity disclosure almost impossible. </span><span class="koboSpan" id="kobo.732.2">However, an attacker could use the analysis of a synthetic dataset to infer information about a particular group of people, despite not being able to identify individuals in </span><span class="No-Break"><span class="koboSpan" id="kobo.733.1">the dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.734.1">For example, say an original dataset contains sensitive medical information. </span><span class="koboSpan" id="kobo.734.2">The synthetic version of this data preserves the same statistical properties as the original data. </span><span class="koboSpan" id="kobo.734.3">With basic statistical methods or more advanced machine learning models, an adversary can identify groups of people with similar characteristics and deduce their risk of a certain disease. </span><span class="koboSpan" id="kobo.734.4">An adversary could then leverage this knowledge to infer the risk of any individual that shares those same characteristics, without any direct identity disclosure </span><span class="No-Break"><span class="koboSpan" id="kobo.735.1">taking place.</span></span></p>
<p><span class="koboSpan" id="kobo.736.1">Another</span><a id="_idIndexMarker517"/><span class="koboSpan" id="kobo.737.1"> example of inferential disclosure is when an attacker can infer someone’s financial status or income level based on certain behaviors, such as shopping habits or credit card usage patterns. </span><span class="koboSpan" id="kobo.737.2">In addition, an attacker may be able to determine the medical history of a person by analyzing health insurance claims and other related records. </span><span class="koboSpan" id="kobo.737.3">This can lead to serious consequences, such as discrimination or exploitation of sensitive information. </span><span class="koboSpan" id="kobo.737.4">Therefore, organizations must take appropriate steps to protect their data from inferential disclosure to ensure that it is not used for </span><span class="No-Break"><span class="koboSpan" id="kobo.738.1">malicious purposes.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.739.1">Membership inference attacks</span></strong><span class="koboSpan" id="kobo.740.1"> are</span><a id="_idIndexMarker518"/><span class="koboSpan" id="kobo.741.1"> similar to inferential disclosure, but they are not exactly the same. </span><span class="koboSpan" id="kobo.741.2">Rather than inferring personal information about an individual based on a group that shares similar characteristics, membership inference attacks aim to deduce if an individual who was present in the original dataset was used to create the synthetic dataset. </span><span class="koboSpan" id="kobo.741.3">This presents a huge privacy risk as, for example, it may reveal that someone has a certain illness without ever having disclosed their medical information. </span><span class="koboSpan" id="kobo.741.4">Preventing these attacks through synthetic data is difficult as the statistical properties of the original dataset have </span><span class="No-Break"><span class="koboSpan" id="kobo.742.1">been maintained.</span></span></p>
<p><span class="koboSpan" id="kobo.743.1">In other words, synthetic data is a potent weapon against direct identity disclosure but does not remove the risk of identity disclosure entirely. </span><span class="koboSpan" id="kobo.743.2">Let’s examine why synthetic data is still superior to traditional </span><span class="No-Break"><span class="koboSpan" id="kobo.744.1">identity-masking techniques.</span></span></p>
<h3><span class="koboSpan" id="kobo.745.1">Why we need synthetic data for privacy preservation</span></h3>
<p><span class="koboSpan" id="kobo.746.1">Traditional data de-identification</span><a id="_idIndexMarker519"/><span class="koboSpan" id="kobo.747.1"> techniques rely on two </span><span class="No-Break"><span class="koboSpan" id="kobo.748.1">main approaches:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.749.1">Anonymization</span></strong><span class="koboSpan" id="kobo.750.1">: This is the simplest form of de-identification and is where columns </span><a id="_idIndexMarker520"/><span class="koboSpan" id="kobo.751.1">containing direct (customer ID, name, address) and quasi-identifiers (ZIP code, birth date) and other sensitive information are removed, hashed, encrypted, or masked. </span><span class="koboSpan" id="kobo.751.2">Metrics such as k-anonymity, l-diversity, and t-closeness are then used to validate the level of privacy preservation in a </span><span class="No-Break"><span class="koboSpan" id="kobo.752.1">given dataset.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.753.1">Differential privacy</span></strong><span class="koboSpan" id="kobo.754.1">: An</span><a id="_idIndexMarker521"/><span class="koboSpan" id="kobo.755.1"> algorithm for differential privacy uses statistical distributions such as Gaussian and Laplace to add randomly generated noise to the identifying features in a dataset. </span><span class="koboSpan" id="kobo.755.2">As a consequence, individuals’ privacy will be protected because identifying information is concealed behind </span><span class="No-Break"><span class="koboSpan" id="kobo.756.1">the noise.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.757.1">Although</span><a id="_idIndexMarker522"/><span class="koboSpan" id="kobo.758.1"> these techniques lower the risk of individuals being identified directly, they aren’t necessarily enough to completely </span><span class="No-Break"><span class="koboSpan" id="kobo.759.1">remove it.</span></span></p>
<p><span class="koboSpan" id="kobo.760.1">A 2019 study by Rocher et al</span><span class="superscript"><span class="koboSpan" id="kobo.761.1">11</span></span><span class="koboSpan" id="kobo.762.1"> demonstrated that 99.98% of Americans could be re-identified with no more than 15 demographic attributes based on a sample size of the population of Massachusetts. </span><span class="koboSpan" id="kobo.762.2">The authors conclude that “</span><em class="italic"><span class="koboSpan" id="kobo.763.1">heavily sampled anonymized datasets are unlikely to satisfy the modern standards for anonymization set forth by GDPR and seriously challenge the technical and legal adequacy of the de-identification </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.764.1">release-and-forget model.</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.765.1">”</span></span></p>
<p><span class="koboSpan" id="kobo.766.1">Another study, this time by Sweeney, 2000,</span><span class="superscript"><span class="koboSpan" id="kobo.767.1">12</span></span><span class="koboSpan" id="kobo.768.1"> found that 87% of the population in the US had reported characteristics that likely made them unique based only on ZIP code, gender, and date of birth. </span><span class="koboSpan" id="kobo.768.2">53% of the US population is identifiable by only location, gender, and date of birth, where “location” is the city, town, or municipality where the person lives. </span><span class="koboSpan" id="kobo.768.3">18% of the population are identifiable based on a combination of their county, gender, and date </span><span class="No-Break"><span class="koboSpan" id="kobo.769.1">of birth.</span></span></p>
<p><span class="koboSpan" id="kobo.770.1">In other words, it is quite possible to identify unique individuals based on only a few quasi-identifiers. </span><span class="koboSpan" id="kobo.770.2">By using synthetically generated data, we can remove these individual combinations from the dataset while preserving the overall statistical properties of </span><span class="No-Break"><span class="koboSpan" id="kobo.771.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.772.1">Let’s examine how this </span><span class="No-Break"><span class="koboSpan" id="kobo.773.1">is done.</span></span></p>
<h2 id="_idParaDest-112"><a id="_idTextAnchor120"/><span class="koboSpan" id="kobo.774.1">Generating synthetic data for privacy preservation</span></h2>
<p><span class="koboSpan" id="kobo.775.1">When we </span><a id="_idIndexMarker523"/><span class="koboSpan" id="kobo.776.1">create synthetic data for privacy preservation, we have </span><span class="No-Break"><span class="koboSpan" id="kobo.777.1">three goals:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.778.1">To maintain the utility of the original data by reflecting its statistical properties in the </span><span class="No-Break"><span class="koboSpan" id="kobo.779.1">synthetic dataset.</span></span></li>
<li><span class="koboSpan" id="kobo.780.1">To ensure the data structure is the same as the original data. </span><span class="koboSpan" id="kobo.780.2">This means that we can use the same code and tools on synthetic data as on the original data, without needing to </span><span class="No-Break"><span class="koboSpan" id="kobo.781.1">change anything.</span></span></li>
<li><span class="koboSpan" id="kobo.782.1">It should not be possible to tell which real-world individuals were part of the original dataset when using privacy-preserving </span><span class="No-Break"><span class="koboSpan" id="kobo.783.1">synthetic data.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.784.1">It is worth </span><a id="_idIndexMarker524"/><span class="koboSpan" id="kobo.785.1">noting that there are different ways to create synthetic data. </span><span class="koboSpan" id="kobo.785.2">Partial synthetic data just replaces some of the data with synthetic data, while fully synthetic information is created from scratch, without any of the </span><span class="No-Break"><span class="koboSpan" id="kobo.786.1">original data.</span></span></p>
<p><span class="koboSpan" id="kobo.787.1">Depending on the approach taken, fully synthetic information can provide a stronger guarantee against personal identity breaches, without sacrificing much in terms of usability </span><span class="No-Break"><span class="koboSpan" id="kobo.788.1">and convenience.</span></span></p>
<p><span class="koboSpan" id="kobo.789.1">A great way for you to start practicing synthetic data generation is through the tools created by the </span><strong class="bold"><span class="koboSpan" id="kobo.790.1">Synthetic Data Vault</span></strong><span class="koboSpan" id="kobo.791.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.792.1">SDV</span></strong><span class="koboSpan" id="kobo.793.1">) project. </span><span class="koboSpan" id="kobo.793.2">The </span><a id="_idIndexMarker525"/><span class="koboSpan" id="kobo.794.1">project was first established by MIT’s Data to AI Lab in 2016 and is a comprehensive ecosystem of Python libraries that allows users to learn single-table, multi-table, and time series datasets, which can then be used as the basis for generating synthetic data that replicates the format and statistical properties of the </span><span class="No-Break"><span class="koboSpan" id="kobo.795.1">original data.</span></span></p>
<p><span class="koboSpan" id="kobo.796.1">Thanks to this project, it’s possible to easily supplement, augment, and – in some cases – replace real data with synthetic data when training machine learning models. </span><span class="koboSpan" id="kobo.796.2">Additionally, it enables machine learning models or other data-dependent software systems to be tested without the risk of exposure that comes with sharing </span><span class="No-Break"><span class="koboSpan" id="kobo.797.1">actual data.</span></span></p>
<p><span class="koboSpan" id="kobo.798.1">The SDV suite is comprised of several probabilistic graphical modeling and deep learning-based techniques. </span><span class="koboSpan" id="kobo.798.2">They are used to generate hierarchical generative models and recursive sampling algorithms, which enable synthetic versions of a variety of </span><span class="No-Break"><span class="koboSpan" id="kobo.799.1">data structures.</span></span></p>
<p><span class="koboSpan" id="kobo.800.1">We will use two different techniques from the SDV suite – </span><strong class="source-inline"><span class="koboSpan" id="kobo.801.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.802.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.803.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.804.1"> – to illustrate how to generate synthetic data for privacy preservation purposes. </span><span class="koboSpan" id="kobo.804.2">Then, we’ll briefly look at how to measure the </span><em class="italic"><span class="koboSpan" id="kobo.805.1">quality</span></em><span class="koboSpan" id="kobo.806.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.807.1">score</span></em><span class="koboSpan" id="kobo.808.1"> using metrics </span><span class="No-Break"><span class="koboSpan" id="kobo.809.1">and charts.</span></span></p>
<h3><span class="koboSpan" id="kobo.810.1">GaussianCopula</span></h3>
<p><span class="koboSpan" id="kobo.811.1">A copula </span><a id="_idIndexMarker526"/><span class="koboSpan" id="kobo.812.1">is a tool that’s used to measure the dependence among random variables. </span><strong class="source-inline"><span class="koboSpan" id="kobo.813.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.814.1"> is a collection of multiple (that is, multivariate) normally distributed pieces of data. </span><span class="koboSpan" id="kobo.814.2">Taken together as one set, the copula lets us describe how these independent normal distributions are related by showing how changes in one element in the set affect the others – that is, their </span><em class="italic"><span class="koboSpan" id="kobo.815.1">marginal distributions</span></em><span class="koboSpan" id="kobo.816.1">. </span><span class="koboSpan" id="kobo.816.2">This is important because this exercise aims to augment any one unique combination of variables while preserving the overall statistical properties of </span><span class="No-Break"><span class="koboSpan" id="kobo.817.1">the dataset.</span></span></p>
<h3><span class="koboSpan" id="kobo.818.1">Example GaussianCopula Python program</span></h3>
<p><span class="koboSpan" id="kobo.819.1">Now, we </span><a id="_idIndexMarker527"/><span class="koboSpan" id="kobo.820.1">will write</span><a id="_idIndexMarker528"/><span class="koboSpan" id="kobo.821.1"> a sample program to show how this works. </span><span class="koboSpan" id="kobo.821.2">It will do </span><span class="No-Break"><span class="koboSpan" id="kobo.822.1">the following:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.823.1">Load a sample dataset and then calculate the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.824.1">GaussianCopula</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.825.1"> model.</span></span></li>
<li><span class="koboSpan" id="kobo.826.1">Use that model to generate some sample data given the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.827.1">GaussianCopula</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.828.1"> model.</span></span></li>
<li><span class="koboSpan" id="kobo.829.1">Visualize the output and its statistical properties to understand how our model </span><span class="No-Break"><span class="koboSpan" id="kobo.830.1">is performing.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.831.1">First, we must install the necessary Python packages – </span><strong class="source-inline"><span class="koboSpan" id="kobo.832.1">sdv</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.833.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.834.1">pandas</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.835.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.836.1">
pip install sdv
pip install pandas</span></pre> <p><span class="koboSpan" id="kobo.837.1">For this exercise, we will use the publicly available </span><em class="italic"><span class="koboSpan" id="kobo.838.1">Adult</span></em><span class="koboSpan" id="kobo.839.1"> dataset, also known as the </span><em class="italic"><span class="koboSpan" id="kobo.840.1">Census Income</span></em><span class="koboSpan" id="kobo.841.1"> dataset. </span><span class="koboSpan" id="kobo.841.2">To get started, download it </span><span class="No-Break"><span class="koboSpan" id="kobo.842.1">from </span></span><a href="http://ml/machine-learning-databases/adult/adult.data"><span class="No-Break"><span class="koboSpan" id="kobo.843.1">https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.844.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.845.1">We’ll use standard </span><strong class="source-inline"><span class="koboSpan" id="kobo.846.1">pandas</span></strong><span class="koboSpan" id="kobo.847.1"> functions to create a DataFrame, </span><strong class="source-inline"><span class="koboSpan" id="kobo.848.1">df</span></strong><span class="koboSpan" id="kobo.849.1">, from the </span><span class="No-Break"><span class="koboSpan" id="kobo.850.1">preceding URL:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.851.1">
names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
                 'marital-status', 'occupation', 'relationship', 'race', 'sex',
                 'capital-gain', 'capital-loss', 'hours-per-week',
                 'native-country', 'income']
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'
df = pd.read_csv(url, header=None, names=names, na_values=['?', ' ?'])</span></pre> <p><span class="koboSpan" id="kobo.852.1">This will</span><a id="_idIndexMarker529"/><span class="koboSpan" id="kobo.853.1"> output the </span><span class="No-Break"><span class="koboSpan" id="kobo.854.1">following DataFrame:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer083">
<span class="koboSpan" id="kobo.855.1"><img alt="Figure 7.12 – The first five rows of the Adult dataset – our input dataset for synthetic data generation" src="image/B19297_07_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.856.1">Figure 7.12 – The first five rows of the Adult dataset – our input dataset for synthetic data generation</span></p>
<p><span class="koboSpan" id="kobo.857.1">With our DataFrame created, we will import </span><strong class="source-inline"><span class="koboSpan" id="kobo.858.1">SingleTableMetadata</span></strong><span class="koboSpan" id="kobo.859.1">, which is a class that provides methods to manage metadata about a single table of data, such as the names and types of columns, relationships between columns, and more. </span><span class="koboSpan" id="kobo.859.2">SDV’s modeling suite needs this metadata object </span><span class="No-Break"><span class="koboSpan" id="kobo.860.1">as input.</span></span></p>
<p><span class="koboSpan" id="kobo.861.1">Then, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.862.1">detect_from_dataframe()</span></strong><span class="koboSpan" id="kobo.863.1"> method to analyze the pandas </span><strong class="source-inline"><span class="koboSpan" id="kobo.864.1">df</span></strong><span class="koboSpan" id="kobo.865.1"> DataFrame and automatically detect and set metadata about </span><span class="No-Break"><span class="koboSpan" id="kobo.866.1">the table.</span></span></p>
<p><span class="koboSpan" id="kobo.867.1">Finally, we will load the appropriate APIs and objects from SDV and instantiate the </span><strong class="source-inline"><span class="koboSpan" id="kobo.868.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.869.1"> model. </span><span class="koboSpan" id="kobo.869.2">Then, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.870.1">fit()</span></strong><span class="koboSpan" id="kobo.871.1"> method to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.872.1">the model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.873.1">
from sdv.metadata import SingleTableMetadata
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(df)
from sdv.single_table import GaussianCopulaSynthesizer
gc_model = GaussianCopulaSynthesizer(metadata)
gc_model.fit(df)</span></pre> <p><span class="koboSpan" id="kobo.874.1">Normally, we </span><a id="_idIndexMarker530"/><span class="koboSpan" id="kobo.875.1">would take a sample of the input dataset that is smaller than the full input dataset to generate the model, but in this case, we’ll take the entire input data since it isn’t </span><span class="No-Break"><span class="koboSpan" id="kobo.876.1">too large.</span></span></p>
<p><span class="koboSpan" id="kobo.877.1">Now, let’s generate the </span><span class="No-Break"><span class="koboSpan" id="kobo.878.1">synthetic dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.879.1">
gc_synthetic = gc_model.sample(num_rows=df.shape[0] )</span></pre> <p><span class="koboSpan" id="kobo.880.1">Once we have generated our synthetic data, we can assess its quality by comparing it to the attributes of the real data. </span><span class="koboSpan" id="kobo.880.2">This can be done by using several </span><span class="No-Break"><span class="koboSpan" id="kobo.881.1">quality metrics.</span></span></p>
<p><span class="koboSpan" id="kobo.882.1">Let’s go ahead and </span><span class="No-Break"><span class="koboSpan" id="kobo.883.1">do that.</span></span></p>
<h3><span class="koboSpan" id="kobo.884.1">Calculating quality scores</span></h3>
<p><span class="koboSpan" id="kobo.885.1">To measure</span><a id="_idIndexMarker531"/><span class="koboSpan" id="kobo.886.1"> the quality of the synthetic data, we can use various </span><em class="italic"><span class="koboSpan" id="kobo.887.1">score</span></em><span class="koboSpan" id="kobo.888.1"> metrics from the </span><em class="italic"><span class="koboSpan" id="kobo.889.1">SDV</span></em><span class="koboSpan" id="kobo.890.1"> package. </span><span class="koboSpan" id="kobo.890.2">The definition and interpretation of the scores vary depending on which metric we are </span><span class="No-Break"><span class="koboSpan" id="kobo.891.1">looking at.</span></span></p>
<p><span class="koboSpan" id="kobo.892.1">Let’s look at some relevant metrics for measuring statistical similarity between original and synthetic data, as well as the risk of inference attacks being successful. </span><span class="koboSpan" id="kobo.892.2">Scores range between 0 and 1. </span><span class="koboSpan" id="kobo.892.3">The interpretation of 0 or 1 varies according to what metric you </span><span class="No-Break"><span class="koboSpan" id="kobo.893.1">are using:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.894.1">BoundaryAdherence</span></strong><span class="koboSpan" id="kobo.895.1">: This describes whether the synthetic data lies within the range of the max and min for a column in the real data. </span><span class="koboSpan" id="kobo.895.2">1 means yes and 0 </span><span class="No-Break"><span class="koboSpan" id="kobo.896.1">means no.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.897.1">StatisticSimilarity</span></strong><span class="koboSpan" id="kobo.898.1">: This compares the mean, median, and standard deviation in a column between real and </span><span class="No-Break"><span class="koboSpan" id="kobo.899.1">synthetic data.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.900.1">CategoricalCAP</span></strong><span class="koboSpan" id="kobo.901.1">: This is the risk of disclosing private information using an inference attack – that is, a hacker knows some of the real data and can match it up with the synthetic. </span><span class="koboSpan" id="kobo.901.2">A score of 1 means there is a </span><span class="No-Break"><span class="koboSpan" id="kobo.902.1">high risk.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.903.1">Data Likelihood</span></strong><span class="koboSpan" id="kobo.904.1">: This calculates how likely it is that the data will match observations</span><a id="_idIndexMarker532"/><span class="koboSpan" id="kobo.905.1"> in the original data. </span><span class="koboSpan" id="kobo.905.2">This is similar to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.906.1">Detection</span></strong><span class="koboSpan" id="kobo.907.1"> metric, which asks whether the machine learning model can tell which is the original dataset and which is the </span><span class="No-Break"><span class="koboSpan" id="kobo.908.1">fabricated one.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.909.1">KSComplement</span></strong><span class="koboSpan" id="kobo.910.1">: This shows whether the column shape of the real and synthetic data are the same using</span><a id="_idIndexMarker533"/><span class="koboSpan" id="kobo.911.1"> the </span><strong class="bold"><span class="koboSpan" id="kobo.912.1">Kolmogorov-Smirnov</span></strong><span class="koboSpan" id="kobo.913.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.914.1">K-S</span></strong><span class="koboSpan" id="kobo.915.1">) test. </span><span class="koboSpan" id="kobo.915.2">The K-S test measures the maximum distance between</span><a id="_idIndexMarker534"/><span class="koboSpan" id="kobo.916.1"> the </span><strong class="bold"><span class="koboSpan" id="kobo.917.1">cumulative distribution function</span></strong><span class="koboSpan" id="kobo.918.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.919.1">CDF</span></strong><span class="koboSpan" id="kobo.920.1">) of the two datasets. </span><span class="koboSpan" id="kobo.920.2">However, it uses its complement (the 1 - </span><span class="No-Break"><span class="koboSpan" id="kobo.921.1">KS statistic).</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.922.1">MissingValueSimilarity</span></strong><span class="koboSpan" id="kobo.923.1">: This measures the proportion of missing data in the real and </span><span class="No-Break"><span class="koboSpan" id="kobo.924.1">synthetic datasets.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.925.1">The code for showing all of these metrics is nearly the same. </span><span class="koboSpan" id="kobo.925.2">Simply call the appropriate package, then run the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.926.1">compute</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.927.1"> method:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.928.1">
from sdmetrics.single_column import CategoryCoverage
CategoryCoverage.compute(
    real_data=df['workclass'],
    synthetic_data=synthetic['workclass']
)</span></pre> <p><span class="koboSpan" id="kobo.929.1">Here is an example </span><span class="No-Break"><span class="koboSpan" id="kobo.930.1">for </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.931.1">MissingValueSimilarity</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.932.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.933.1">
from sdmetrics.single_column import MissingValueSimilarity
MissingValueSimilarity.compute(
    real_data=df['marital-status'],
    synthetic_data=synthetic['marital-status']
)</span></pre> <p><span class="koboSpan" id="kobo.934.1">The output </span><a id="_idIndexMarker535"/><span class="koboSpan" id="kobo.935.1">score is equal to 1.0, which means the model has successfully matched the proportion of missing values in the </span><span class="No-Break"><span class="koboSpan" id="kobo.936.1">synthetic dataset.</span></span></p>
<h3><span class="koboSpan" id="kobo.937.1">Quantifying and visualizing data quality</span></h3>
<p><span class="koboSpan" id="kobo.938.1">We also</span><a id="_idIndexMarker536"/><span class="koboSpan" id="kobo.939.1"> want to quantify and visualize the quality of our synthetic data compared to the original set. </span><span class="koboSpan" id="kobo.939.2">For this purpose, we’ll use the </span><em class="italic"><span class="koboSpan" id="kobo.940.1">diagnostic</span></em><span class="koboSpan" id="kobo.941.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.942.1">quality</span></em><span class="koboSpan" id="kobo.943.1"> reports from the </span><span class="No-Break"><span class="koboSpan" id="kobo.944.1">SDV library.</span></span></p>
<p><span class="koboSpan" id="kobo.945.1">The </span><a id="_idIndexMarker537"/><span class="koboSpan" id="kobo.946.1">diagnostic report should always produce a score of 100%, which tells us that primary keys are unique and non-null, continuous values in the synthetic data adhere to the min/max range in the original data, discrete values line up with the same categories across real and synthetic data, and column names are </span><span class="No-Break"><span class="koboSpan" id="kobo.947.1">the same:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.948.1">
from sdv.evaluation.single_table import run_diagnostic
diagnostic = run_diagnostic(
    real_data=df,
    synthetic_data=gc_synthetic,
    metadata=metadata
)</span></pre> <p><span class="koboSpan" id="kobo.949.1">Here’s </span><span class="No-Break"><span class="koboSpan" id="kobo.950.1">our output:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.951.1">
Overall Score: 100.0%
Properties:
- Data Validity: 100.0%
- Data Structure: 100.0%</span></pre> <p><span class="koboSpan" id="kobo.952.1">The SDV quality report evaluates how well your synthetic data captures the mathematical properties of our original real data. </span><span class="koboSpan" id="kobo.952.2">It does this through a set of metrics that measure </span><a id="_idIndexMarker538"/><span class="koboSpan" id="kobo.953.1">various aspects of the </span><em class="italic"><span class="koboSpan" id="kobo.954.1">fidelity</span></em><span class="koboSpan" id="kobo.955.1"> between the two datasets. </span><strong class="bold"><span class="koboSpan" id="kobo.956.1">Data fidelity</span></strong><span class="koboSpan" id="kobo.957.1"> refers to how accurate a dataset is at representing the features of </span><span class="No-Break"><span class="koboSpan" id="kobo.958.1">its source.</span></span></p>
<p><span class="koboSpan" id="kobo.959.1">The </span><a id="_idIndexMarker539"/><span class="koboSpan" id="kobo.960.1">report </span><a id="_idIndexMarker540"/><span class="koboSpan" id="kobo.961.1">provides an overview of the results, as well as detailed visualizations and explanations for each metric so that you can quickly understand the strengths and weaknesses of your synthetic data. </span><span class="koboSpan" id="kobo.961.2">By understanding how well your synthetic data captures the mathematical properties of the real data, you can take steps to improve it </span><span class="No-Break"><span class="koboSpan" id="kobo.962.1">if needed.</span></span></p>
<p><span class="koboSpan" id="kobo.963.1">The SDMetrics quality report is a valuable tool that helps you ensure your synthetic data is as accurate and reliable as possible. </span><span class="koboSpan" id="kobo.963.2">Here’s how we can </span><span class="No-Break"><span class="koboSpan" id="kobo.964.1">use it:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.965.1">
from sdv.evaluation.single_table import evaluate_quality
quality_report = evaluate_quality(
    real_data=df,
    synthetic_data=gc_synthetic,
    metadata=metadata
)</span></pre> <p><span class="koboSpan" id="kobo.966.1">The preceding code produces a quality report with various metrics and visualizations that show the overall similarities between the original and </span><span class="No-Break"><span class="koboSpan" id="kobo.967.1">synthetic data:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.968.1">
Overall Score: 84.6%
Properties:
- Column Shapes: 87.57%
- Column Pair Trends: 81.63%</span></pre> <p><span class="koboSpan" id="kobo.969.1">Here are a couple of important metrics to </span><span class="No-Break"><span class="koboSpan" id="kobo.970.1">know about:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.971.1">Column Shapes</span></strong><span class="koboSpan" id="kobo.972.1">: A column’s shape tells us how data is distributed. </span><span class="koboSpan" id="kobo.972.2">A higher score means that the real and synthetic data are more similar. </span><span class="koboSpan" id="kobo.972.3">A separate column shape score for every column is calculated, but the final score is the average of </span><span class="No-Break"><span class="koboSpan" id="kobo.973.1">all columns.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.974.1">Column Pair Trends</span></strong><span class="koboSpan" id="kobo.975.1">: The correlation between two columns indicates how their trends compare to each other; the higher the score, the more similar those trends are. </span><span class="koboSpan" id="kobo.975.2">A score is produced for each column pair in the data, while the final score is the average of all columns. </span><span class="koboSpan" id="kobo.975.3">This is an important score that tells us whether our synthetic data has captured the relationships between variables in the </span><span class="No-Break"><span class="koboSpan" id="kobo.976.1">original dataset.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.977.1">We can </span><a id="_idIndexMarker541"/><span class="koboSpan" id="kobo.978.1">also visualize </span><a id="_idIndexMarker542"/><span class="koboSpan" id="kobo.979.1">the dimensions of these metrics with the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.980.1">get_visualization</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.981.1"> command:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.982.1">
fig = quality_report.get_visualization(property_name='Column Pair Trends')
fig.show()</span></pre> <p><span class="koboSpan" id="kobo.983.1">This will generate the </span><span class="No-Break"><span class="koboSpan" id="kobo.984.1">following plot:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer084">
<span class="koboSpan" id="kobo.985.1"><img alt="Figure 7.13 – A correlation matrix comparing column pair trends between the original and synthetic datasets" src="image/B19297_07_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.986.1">Figure 7.13 – A correlation matrix comparing column pair trends between the original and synthetic datasets</span></p>
<p><span class="koboSpan" id="kobo.987.1">As you can </span><a id="_idIndexMarker543"/><span class="koboSpan" id="kobo.988.1">see, most </span><a id="_idIndexMarker544"/><span class="koboSpan" id="kobo.989.1">column pairs have a high similarity score, but the </span><strong class="source-inline"><span class="koboSpan" id="kobo.990.1">capital-gain</span></strong><span class="koboSpan" id="kobo.991.1"> column is far apart. </span><span class="koboSpan" id="kobo.991.2">We can use the following code to visualize the real and synthetic </span><strong class="source-inline"><span class="koboSpan" id="kobo.992.1">capital-gain</span></strong><span class="koboSpan" id="kobo.993.1"> column distributions side </span><span class="No-Break"><span class="koboSpan" id="kobo.994.1">by side:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.995.1">
from sdv.evaluation.single_table import get_column_plot
fig = get_column_plot(
    real_data=df,
    synthetic_data=gc_synthetic,
    metadata=metadata,
    column_name='capital-gain'
)
fig.show()</span></pre> <p><span class="koboSpan" id="kobo.996.1">The output is generated </span><span class="No-Break"><span class="koboSpan" id="kobo.997.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer085">
<span class="koboSpan" id="kobo.998.1"><img alt="Figure 7.14 – A comparison of the distribution of the real and synthetic capital-gain columns. The GaussianCopula model hasn’t done a good job of matching the distribution﻿" src="image/B19297_07_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.999.1">Figure 7.14 – A comparison of the distribution of the real and synthetic capital-gain columns. </span><span class="koboSpan" id="kobo.999.2">The GaussianCopula model hasn’t done a good job of matching the distribution</span></p>
<p><span class="koboSpan" id="kobo.1000.1">In this </span><a id="_idIndexMarker545"/><span class="koboSpan" id="kobo.1001.1">case, we </span><a id="_idIndexMarker546"/><span class="koboSpan" id="kobo.1002.1">would test various column distribution functions to find a better match for this particular column. </span><span class="koboSpan" id="kobo.1002.2">In this example, we used the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1003.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.1004.1"> function to create a synthetic dataset. </span><span class="koboSpan" id="kobo.1004.2">However, the SDV library contains several other distributions that can be useful, depending on the characteristics of your original dataset. </span><span class="koboSpan" id="kobo.1004.3">Let’s explore how to change the </span><span class="No-Break"><span class="koboSpan" id="kobo.1005.1">default distribution.</span></span></p>
<h3><span class="koboSpan" id="kobo.1006.1">Varying column distribution functions</span></h3>
<p><span class="koboSpan" id="kobo.1007.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.1008.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.1009.1"> function </span><a id="_idIndexMarker547"/><span class="koboSpan" id="kobo.1010.1">determines which statistical distribution best describes each copula, but it doesn’t always get it right. </span><span class="koboSpan" id="kobo.1010.2">Luckily, we can override the preselection and pick our </span><span class="No-Break"><span class="koboSpan" id="kobo.1011.1">preferred distribution.</span></span></p>
<p><span class="koboSpan" id="kobo.1012.1">We have the </span><span class="No-Break"><span class="koboSpan" id="kobo.1013.1">following choices:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.1014.1">Gaussian (normal) distribution</span></strong><span class="koboSpan" id="kobo.1015.1">: Use this if your data is continuous and symmetrically </span><a id="_idIndexMarker548"/><span class="koboSpan" id="kobo.1016.1">distributed around the mean. </span><span class="koboSpan" id="kobo.1016.2">It’s often used for naturally occurring data, such as the heights or weights of </span><span class="No-Break"><span class="koboSpan" id="kobo.1017.1">a population.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1018.1">Gamma distribution</span></strong><span class="koboSpan" id="kobo.1019.1">: This is</span><a id="_idIndexMarker549"/><span class="koboSpan" id="kobo.1020.1"> used for positive-only, skewed data. </span><span class="koboSpan" id="kobo.1020.2">It’s often used for things such as wait times or </span><span class="No-Break"><span class="koboSpan" id="kobo.1021.1">service times.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1022.1">Beta distribution</span></strong><span class="koboSpan" id="kobo.1023.1">: This is used </span><a id="_idIndexMarker550"/><span class="koboSpan" id="kobo.1024.1">for variables that are bounded between 0 and 1, such as proportions </span><span class="No-Break"><span class="koboSpan" id="kobo.1025.1">or probabilities.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1026.1">Student’s t-distribution</span></strong><span class="koboSpan" id="kobo.1027.1">: This</span><a id="_idIndexMarker551"/><span class="koboSpan" id="kobo.1028.1"> is similar to the Gaussian distribution but has heavier tails. </span><span class="koboSpan" id="kobo.1028.2">It’s often used when the sample size is small or the standard deviation </span><span class="No-Break"><span class="koboSpan" id="kobo.1029.1">is unknown.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1030.1">Gaussian kernel density estimation</span></strong><span class="koboSpan" id="kobo.1031.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1032.1">KDE</span></strong><span class="koboSpan" id="kobo.1033.1">): Use this for non-parametric data – that is, when</span><a id="_idIndexMarker552"/><span class="koboSpan" id="kobo.1034.1"> you don’t know or want to assume a specific distribution. </span><span class="koboSpan" id="kobo.1034.2">The KDE uses the data itself to estimate </span><span class="No-Break"><span class="koboSpan" id="kobo.1035.1">its distribution.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1036.1">Truncated Gaussian distribution</span></strong><span class="koboSpan" id="kobo.1037.1">: Use this when you have data that follows a Gaussian </span><a id="_idIndexMarker553"/><span class="koboSpan" id="kobo.1038.1">distribution but is bounded within a </span><span class="No-Break"><span class="koboSpan" id="kobo.1039.1">specific range.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1040.1">First, here is</span><a id="_idIndexMarker554"/><span class="koboSpan" id="kobo.1041.1"> how to show the distributions </span><span class="No-Break"><span class="koboSpan" id="kobo.1042.1">it calculated:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1043.1">
gc_model.get_learned_distributions()</span></pre> <p><span class="koboSpan" id="kobo.1044.1">This statement produces a detailed list of all the columns in the dataset. </span><span class="koboSpan" id="kobo.1044.2">Instead of showing the output here, the model defaulted to a beta distribution for </span><span class="No-Break"><span class="koboSpan" id="kobo.1045.1">all columns.</span></span></p>
<p><span class="koboSpan" id="kobo.1046.1">To change a distribution function for a given column, just create a model again but this time explicitly apply a specific distribution to that column. </span><span class="koboSpan" id="kobo.1046.2">In this case, we will apply a gamma distribution to the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1047.1">capital-gain</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1048.1"> column:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1049.1">
gc_model2 = GaussianCopulaSynthesizer(
    metadata,
    numerical_distributions={
        'capital-gain': 'gamma',
    })
gc_model2.fit(df)</span></pre> <p><span class="koboSpan" id="kobo.1050.1">The resulting output is a new synthetic dataset with a </span><strong class="source-inline"><span class="koboSpan" id="kobo.1051.1">capital-gain</span></strong><span class="koboSpan" id="kobo.1052.1"> column distribution much closer to the </span><span class="No-Break"><span class="koboSpan" id="kobo.1053.1">real data:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer086">
<span class="koboSpan" id="kobo.1054.1"><img alt="Figure 7.15 – A new comparison of the capital-gain columns. Using the gamma distribution on this column improved the similarity between the synthetic and original data" src="image/B19297_07_15.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1055.1">Figure 7.15 – A new comparison of the capital-gain columns. </span><span class="koboSpan" id="kobo.1055.2">Using the gamma distribution on this column improved the similarity between the synthetic and original data</span></p>
<p><span class="koboSpan" id="kobo.1056.1">Another</span><a id="_idIndexMarker555"/><span class="koboSpan" id="kobo.1057.1"> useful package from the SDV library is </span><strong class="source-inline"><span class="koboSpan" id="kobo.1058.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1059.1">. </span><span class="koboSpan" id="kobo.1059.2">This algorithm is a blend of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1060.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.1061.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1062.1">CTGAN</span></strong><span class="koboSpan" id="kobo.1063.1"> algorithms. </span><span class="koboSpan" id="kobo.1063.2">Let’s compare the performance of </span><strong class="source-inline"><span class="koboSpan" id="kobo.1064.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1065.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.1066.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.1067.1"> on the </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1068.1">Adult</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1069.1"> dataset.</span></span></p>
<h3><span class="koboSpan" id="kobo.1070.1">CopulaGAN code example</span></h3>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1071.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1072.1"> is a</span><a id="_idIndexMarker556"/><span class="koboSpan" id="kobo.1073.1"> variation of </span><strong class="source-inline"><span class="koboSpan" id="kobo.1074.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.1075.1"> that can yield better results using a simplified GAN model. </span><span class="koboSpan" id="kobo.1075.2">We</span><a id="_idIndexMarker557"/><span class="koboSpan" id="kobo.1076.1"> will compare the two models in this section, but first, here is the code to generate </span><strong class="source-inline"><span class="koboSpan" id="kobo.1077.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1078.1"> using the same input dataset and </span><span class="No-Break"><span class="koboSpan" id="kobo.1079.1">metadata object:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1080.1">
from sdv.single_table import CopulaGANSynthesizer
cg_model = CopulaGANSynthesizer(metadata)
cg_model.fit(df)</span></pre> <h3><span class="koboSpan" id="kobo.1081.1">Measuring data quality from CopulaGAN</span></h3>
<p><span class="koboSpan" id="kobo.1082.1">Now, let’s look at data quality regarding the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1083.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1084.1"> model, repeating some of the same techniques </span><a id="_idIndexMarker558"/><span class="koboSpan" id="kobo.1085.1">we used </span><span class="No-Break"><span class="koboSpan" id="kobo.1086.1">with </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1087.1">GaussianCopula</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1088.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1089.1">
quality_report = evaluate_quality(
    real_data=df,
    synthetic_data=cg_synthetic,
    metadata=metadata
)
Overall Score: 87.39%
Properties:
- Column Shapes: 91.75%
- Column Pair Trends: 83.04%</span></pre> <p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1090.1">Figure 7</span></em></span><em class="italic"><span class="koboSpan" id="kobo.1091.1">.16</span></em><span class="koboSpan" id="kobo.1092.1"> provides a visual representation of the column pair trends of the original and </span><span class="No-Break"><span class="koboSpan" id="kobo.1093.1">synthetic datasets:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer087">
<span class="koboSpan" id="kobo.1094.1"><img alt="Figure 7.16 – Column pair trends for the Adult dataset using CopulaGAN" src="image/B19297_07_16.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1095.1">Figure 7.16 – Column pair trends for the Adult dataset using CopulaGAN</span></p>
<h3><span class="koboSpan" id="kobo.1096.1">Understanding the difference between GaussianCopula and CopulaGAN</span></h3>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1097.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1098.1"> is a</span><a id="_idIndexMarker559"/><span class="koboSpan" id="kobo.1099.1"> hybrid AI model that combines the human accessibility of Gaussian copulas with the robust accuracy </span><span class="No-Break"><span class="koboSpan" id="kobo.1100.1">of GANs</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.1101.1">13</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.1102.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.1103.1">A GAN is a deep learning algorithm. </span><span class="koboSpan" id="kobo.1103.2">If you’ve worked with neural networks, you know that they are a kind of black box, meaning the coefficients of the nodes in the network are functions and not numbers. </span><span class="koboSpan" id="kobo.1103.3">They are very hard to explain or understand compared to, for example, a polynomial or </span><span class="No-Break"><span class="koboSpan" id="kobo.1104.1">linear model.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.1105.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.1106.1"> is </span><a id="_idIndexMarker560"/><span class="koboSpan" id="kobo.1107.1">easier to explain. </span><span class="koboSpan" id="kobo.1107.2">It works by trying different known statistical distributions (normal, Weibull, and others), which is very useful for known or easily observable distributions. </span><span class="koboSpan" id="kobo.1107.3">Then, for each column, it picks the one that matches </span><span class="No-Break"><span class="koboSpan" id="kobo.1108.1">the closest.</span></span></p>
<p><span class="koboSpan" id="kobo.1109.1">The team behind the SDV project developed </span><strong class="source-inline"><span class="koboSpan" id="kobo.1110.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1111.1"> to get the best of both worlds: a more accurate model that is </span><span class="No-Break"><span class="koboSpan" id="kobo.1112.1">still explainable.</span></span></p>
<p><span class="koboSpan" id="kobo.1113.1">The following table compares the results from our two models in the previous examples. </span><strong class="source-inline"><span class="koboSpan" id="kobo.1114.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1115.1"> achieved a higher overall quality score because it was able to match the column </span><span class="No-Break"><span class="koboSpan" id="kobo.1116.1">shapes more:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table002">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style"/>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1117.1">GaussianCopula</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1118.1">CopulaGAN</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.1119.1">Overall </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1120.1">Quality Score</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1121.1">84.6%</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1122.1">87.39%</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1123.1">Column Shapes</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1124.1">87.57%</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1125.1">91.75%</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.1126.1">Column </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.1127.1">Pair Trends</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1128.1">81.63%</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.1129.1">83.04%</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1130.1">Table 7.2 – Data quality comparison of the GaussianCopula and CopulaGAN algorithms on the Adult dataset</span></p>
<p><span class="koboSpan" id="kobo.1131.1">Of course, quality is a highly complex topic and our example is not exhaustive in that regard. </span><span class="koboSpan" id="kobo.1131.2">You would have to look at the scores across all columns and all the different types of scores to validate the accuracy of the synthetically generated data. </span><span class="koboSpan" id="kobo.1131.3">In other words, you cannot say for definite that </span><strong class="source-inline"><span class="koboSpan" id="kobo.1132.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1133.1"> is more accurate in all cases without doing a deeper review of the variables in the dataset. </span><span class="koboSpan" id="kobo.1133.2">This is particularly important when you are dealing with high-stakes datasets and </span><span class="No-Break"><span class="koboSpan" id="kobo.1134.1">use cases.</span></span></p>
<p><span class="koboSpan" id="kobo.1135.1">One additional metric to consider is run speed. </span><span class="koboSpan" id="kobo.1135.2">Anecdotally, when we wrote this example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1136.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1137.1"> took 1 hour to complete, while </span><strong class="source-inline"><span class="koboSpan" id="kobo.1138.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.1139.1"> took 15 seconds </span><span class="No-Break"><span class="koboSpan" id="kobo.1140.1">to complete.</span></span></p>
<h3><span class="koboSpan" id="kobo.1141.1">Validating the privacy of our new dataset</span></h3>
<p><span class="koboSpan" id="kobo.1142.1">Now </span><a id="_idIndexMarker561"/><span class="koboSpan" id="kobo.1143.1">that we have constructed a synthetic dataset for our use case, we need to ensure we have prevented the ability to re-identify individuals from the </span><span class="No-Break"><span class="koboSpan" id="kobo.1144.1">original dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.1145.1">To know the likelihood that individuals can be re-identified, we need an accurate measure of the difference or “distance” between the original and synthetic records. </span><span class="koboSpan" id="kobo.1145.2">The farther the two are apart, the less probable that they can be identified as one entity. </span><span class="koboSpan" id="kobo.1145.3">If we are discussing personal information in tabular form, we need a methodology for measuring the distance between qualitative and quantitative </span><span class="No-Break"><span class="koboSpan" id="kobo.1146.1">attributes alike.</span></span></p>
<p><span class="koboSpan" id="kobo.1147.1">To accurately measure the closeness of two rows within a dataset containing both qualitative and quantitative information, we can utilize a similarity coefficient called </span><span class="No-Break"><span class="koboSpan" id="kobo.1148.1">Gower’s distance.</span></span></p>
<p><span class="koboSpan" id="kobo.1149.1">Gower’s distance is a unique type of distance measure that differs from distance measures. </span><span class="koboSpan" id="kobo.1149.2">It stands out in terms of its ability to calculate the difference between two entities with both numerical and categorical values. </span><span class="koboSpan" id="kobo.1149.3">This is important because many common clustering algorithms, such as K-means clustering, only work when all of the variables </span><span class="No-Break"><span class="koboSpan" id="kobo.1150.1">are numeric.</span></span></p>
<p><span class="koboSpan" id="kobo.1151.1">Gower’s distance returns a similarity coefficient between 0 (indicating identical observations) and 1 (showing that they are at the </span><span class="No-Break"><span class="koboSpan" id="kobo.1152.1">maximum distance).</span></span></p>
<p><span class="koboSpan" id="kobo.1153.1">Suppose we have a set of </span><em class="italic"><span class="koboSpan" id="kobo.1154.1">p</span></em><span class="koboSpan" id="kobo.1155.1"> features in the original (</span><em class="italic"><span class="koboSpan" id="kobo.1156.1">o</span></em><span class="koboSpan" id="kobo.1157.1">) and synthetic (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1158.1">s</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1159.1">) datasets:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.1160.1">For ordinal numbers, the distance from one feature to the other is simply the absolute value of their difference divided by the range of that variable. </span><span class="koboSpan" id="kobo.1160.2">We divide by the range to normalize the data so that large numbers won’t be given greater weight than </span><span class="No-Break"><span class="koboSpan" id="kobo.1161.1">small ones.</span></span></li>
<li><span class="koboSpan" id="kobo.1162.1">Categorical variables are turned into numbers so that we can do math. </span><span class="koboSpan" id="kobo.1162.2">The formula is simple – if those values are the same, their distance is 0; otherwise, it </span><span class="No-Break"><span class="koboSpan" id="kobo.1163.1">is 1.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1164.1">Gower’s distance is the sum of the distances divided by the number of features – the average of the terms. </span><span class="koboSpan" id="kobo.1164.2">Since we divide these differences by the number of features, this is the same as saying Gower’s distance is the </span><span class="No-Break"><span class="koboSpan" id="kobo.1165.1">average distance.</span></span></p>
<p><span class="koboSpan" id="kobo.1166.1">Then, we make </span><a id="_idIndexMarker562"/><span class="koboSpan" id="kobo.1167.1">a definition for </span><strong class="bold"><span class="koboSpan" id="kobo.1168.1">closeness</span></strong><span class="koboSpan" id="kobo.1169.1"> and call it the </span><strong class="bold"><span class="koboSpan" id="kobo.1170.1">distance to the closest record</span></strong><span class="koboSpan" id="kobo.1171.1">. </span><span class="koboSpan" id="kobo.1171.2">For every element in </span><em class="italic"><span class="koboSpan" id="kobo.1172.1">s</span></em><span class="koboSpan" id="kobo.1173.1">, the closest row in </span><em class="italic"><span class="koboSpan" id="kobo.1174.1">o</span></em><span class="koboSpan" id="kobo.1175.1"> is the one with the minimum Gower’s distance. </span><span class="koboSpan" id="kobo.1175.2">A distance of 0 means that two rows of data are the same, while a distance of 1 means that two rows are as different as possible given the observations in the dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.1176.1">we’re using.</span></span></p>
<p><span class="koboSpan" id="kobo.1177.1">Let’s practice applying Gower’s distance using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1178.1">Gower</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.1179.1">Python package.</span></span></p>
<h3><span class="koboSpan" id="kobo.1180.1">Gower’s distance Python example</span></h3>
<p><span class="koboSpan" id="kobo.1181.1">In </span><a id="_idIndexMarker563"/><span class="koboSpan" id="kobo.1182.1">our Gower’s distance practice example, we’ll use the </span><em class="italic"><span class="koboSpan" id="kobo.1183.1">Adult</span></em><span class="koboSpan" id="kobo.1184.1"> dataset and compare the </span><a id="_idIndexMarker564"/><span class="koboSpan" id="kobo.1185.1">synthetic output generated by </span><strong class="source-inline"><span class="koboSpan" id="kobo.1186.1">CopulaGAN</span></strong><span class="koboSpan" id="kobo.1187.1"> to the original data. </span><span class="koboSpan" id="kobo.1187.2">We recommend using a small subset of the </span><em class="italic"><span class="koboSpan" id="kobo.1188.1">Adult</span></em><span class="koboSpan" id="kobo.1189.1"> dataset (for example, 1,000 rows) to practice as Gower’s matrix calculation can take a long time to run on </span><span class="No-Break"><span class="koboSpan" id="kobo.1190.1">larger sets.</span></span></p>
<p><span class="koboSpan" id="kobo.1191.1">First, we’ll create the DataFrame for our model based on the top 1,000 rows from the existing </span><strong class="source-inline"><span class="koboSpan" id="kobo.1192.1">df</span></strong><span class="koboSpan" id="kobo.1193.1"> DataFrame, which contains the full </span><em class="italic"><span class="koboSpan" id="kobo.1194.1">Adult</span></em><span class="koboSpan" id="kobo.1195.1"> dataset. </span><span class="koboSpan" id="kobo.1195.2">Then, we’ll fit a </span><strong class="source-inline"><span class="koboSpan" id="kobo.1196.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.1197.1"> model on this dataset and generate a new synthetic dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.1198.1">called </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1199.1">synthetic</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1200.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1201.1">
new_df = df.head(1000)
model = GaussianCopulaSynthesizer(metadata)
model.fit(new_df)
synthetic = model.sample(num_rows=df.shape[0] )</span></pre> <p><span class="koboSpan" id="kobo.1202.1">Next, we’ll install the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1203.1">Gower</span></strong><span class="koboSpan" id="kobo.1204.1"> package and calculate the Gower’s distance matrix between our </span><span class="No-Break"><span class="koboSpan" id="kobo.1205.1">two datasets:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1206.1">
pip install gower
import gower
gowerMatrix=gower.gower_matrix(new_df, synthetic)
print(gowerMatrix)</span></pre> <p><span class="koboSpan" id="kobo.1207.1">This will generate results similar to the following, where the distance between each row in the dataset </span><span class="No-Break"><span class="koboSpan" id="kobo.1208.1">is calculated:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer088">
<span class="koboSpan" id="kobo.1209.1"><img alt="Figure 7.17 – The resulting gowerMatrix" src="image/B19297_07_17.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1210.1">Figure 7.17 – The resulting gowerMatrix</span></p>
<p><span class="koboSpan" id="kobo.1211.1">Now, we’ll use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1212.1">gower_topn()</span></strong><span class="koboSpan" id="kobo.1213.1"> function to find the top </span><em class="italic"><span class="koboSpan" id="kobo.1214.1">n</span></em><span class="koboSpan" id="kobo.1215.1"> (in this case, 10) closest (that is, most </span><span class="No-Break"><span class="koboSpan" id="kobo.1216.1">similar) rows.</span></span></p>
<p><span class="koboSpan" id="kobo.1217.1">To </span><a id="_idIndexMarker565"/><span class="koboSpan" id="kobo.1218.1">ensure the synthetic dataset passes our test, we must make sure none of its values are equal to 0; otherwise, this would indicate that some rows in the synthetic data resemble those from the original. </span><span class="koboSpan" id="kobo.1218.2">Generally speaking, we want the top values to be sufficiently distanced from 0 as this reduces the risk </span><span class="No-Break"><span class="koboSpan" id="kobo.1219.1">of reidentification:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1220.1">
gower.gower_topn(df.iloc[:,], synthetic.iloc[:,], n = 10)</span></pre> <p><span class="koboSpan" id="kobo.1221.1">The result is the index of the top 10 closest rows and their Gower’s distance. </span><span class="koboSpan" id="kobo.1221.2">In this case, the smallest distance between two rows in our datasets is 0.02205, which means our synthetic dataset is not sufficiently different from the original at the individual </span><span class="No-Break"><span class="koboSpan" id="kobo.1222.1">row level:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1223.1">
{'index': array([26320, 29200, 18735, 24149, 18316, 22925,  4836, 15360, 42, 3523]),'values': array([0.02205753, 0.02578343, 0.03649067, 0.0374441 , 0.03785798, 0.04503146, 0.06345809, 0.08126822, 0.08237292, 0.08368524], dtype=float32)}</span></pre> <p><span class="koboSpan" id="kobo.1224.1">In this case, we would have more work to do to reduce the similarity between sets. </span><span class="koboSpan" id="kobo.1224.2">Here are a few techniques you could use to </span><span class="No-Break"><span class="koboSpan" id="kobo.1225.1">achieve this:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.1226.1">Change the synthetic data generation process</span></strong><span class="koboSpan" id="kobo.1227.1">: The first step would be to test different settings for </span><strong class="source-inline"><span class="koboSpan" id="kobo.1228.1">GaussianCopula</span></strong><span class="koboSpan" id="kobo.1229.1"> or test other synthesizers in the SDV catalog, such as CTGAN </span><span class="No-Break"><span class="koboSpan" id="kobo.1230.1">or </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1231.1">CopulaGAN</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1232.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1233.1">Add noise</span></strong><span class="koboSpan" id="kobo.1234.1">: You can add random noise to the synthetic data. </span><span class="koboSpan" id="kobo.1234.2">This will make the synthetic data more “unique” compared to the </span><span class="No-Break"><span class="koboSpan" id="kobo.1235.1">original data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1236.1">Perform feature transformation</span></strong><span class="koboSpan" id="kobo.1237.1">: Apply some kind of transformation (for example, logarithmic, square root, exponential, and so on) to the features in the </span><span class="No-Break"><span class="koboSpan" id="kobo.1238.1">synthetic dataset.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.1239.1">Perform data augmentation</span></strong><span class="koboSpan" id="kobo.1240.1">: Generate new synthetic data points that are not direct copies of the real data. </span><span class="koboSpan" id="kobo.1240.2">You </span><a id="_idIndexMarker566"/><span class="koboSpan" id="kobo.1241.1">can do this by using techniques such as the </span><strong class="bold"><span class="koboSpan" id="kobo.1242.1">Synthetic Minority Over-Sampling Technique</span></strong><span class="koboSpan" id="kobo.1243.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1244.1">SMOTE</span></strong><span class="koboSpan" id="kobo.1245.1">) or </span><strong class="bold"><span class="koboSpan" id="kobo.1246.1">Adaptive Synthetic Sampling</span></strong><span class="koboSpan" id="kobo.1247.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.1248.1">ADASYN</span></strong><span class="koboSpan" id="kobo.1249.1">), both </span><a id="_idIndexMarker567"/><span class="koboSpan" id="kobo.1250.1">of which we’ll discuss later in </span><span class="No-Break"><span class="koboSpan" id="kobo.1251.1">this chapter.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.1252.1">Remember </span><a id="_idIndexMarker568"/><span class="koboSpan" id="kobo.1253.1">that while your goal is to reduce similarity, you also want the synthetic data to be useful and representative of the real data. </span><span class="koboSpan" id="kobo.1253.2">If you make the synthetic data too dissimilar, it may not serve its </span><span class="No-Break"><span class="koboSpan" id="kobo.1254.1">intended purpose.</span></span></p>
<p><span class="koboSpan" id="kobo.1255.1">As a side note, Gower’s distance can also be used to find rows of data that are very similar to each other, which is useful for tasks such as creating lookalike audiences, clustering, or identifying </span><span class="No-Break"><span class="koboSpan" id="kobo.1256.1">at-risk populations.</span></span></p>
<p><span class="koboSpan" id="kobo.1257.1">For instance, imagine that you have just run a very successful email marketing campaign to a group of customers and you want to expand the campaign to customers who look like the ones in the original </span><span class="No-Break"><span class="koboSpan" id="kobo.1258.1">target group.</span></span></p>
<p><span class="koboSpan" id="kobo.1259.1">To do this, simply calculate Gower’s distance between customers in the original target group and the rest of your customer base, and pick a target group based on the lowest </span><span class="No-Break"><span class="koboSpan" id="kobo.1260.1">Gower’s distances.</span></span></p>
<h2 id="_idParaDest-113"><a id="_idTextAnchor121"/><span class="koboSpan" id="kobo.1261.1">Using synthetic data to improve model performance</span></h2>
<p><span class="koboSpan" id="kobo.1262.1">In </span><a href="B19297_05.xhtml#_idTextAnchor070"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1263.1">Chapter 5</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.1264.1">, Techniques for Data Cleaning</span></em><span class="koboSpan" id="kobo.1265.1"> and </span><a href="B19297_06.xhtml#_idTextAnchor089"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1266.1">Chapter 6</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.1267.1">, Techniques for Programmatic Labeling in Machine Learning</span></em><span class="koboSpan" id="kobo.1268.1">, we dealt with improving model performance by refining data quality. </span><span class="koboSpan" id="kobo.1268.2">However, there are times when improving data quality may not be enough, especially when</span><a id="_idIndexMarker569"/><span class="koboSpan" id="kobo.1269.1"> datasets are small. </span><span class="koboSpan" id="kobo.1269.2">In such situations, we can take advantage of generating synthetic data to boost </span><span class="No-Break"><span class="koboSpan" id="kobo.1270.1">model performance.</span></span></p>
<p><span class="koboSpan" id="kobo.1271.1">As we covered previously in this chapter, synthetic data can help with generating more training examples, as well as generalizing the performance of the model by providing more examples of different variations and distributions of the data. </span><span class="koboSpan" id="kobo.1271.2">Both of these uses can make the model more robust and less likely to overfit the </span><span class="No-Break"><span class="koboSpan" id="kobo.1272.1">training data.</span></span></p>
<p><span class="koboSpan" id="kobo.1273.1">With imbalanced datasets, a model gets biased toward the majority class as there are more examples of one class over another. </span><span class="koboSpan" id="kobo.1273.2">This is the problem with the loan prediction dataset, where 30% of the data belongs to the </span><span class="No-Break"><span class="koboSpan" id="kobo.1274.1">minority class.</span></span></p>
<p><span class="koboSpan" id="kobo.1275.1">In this section, we will cover generating synthetic data for the minority class so that the model can generalize further and model performance metrics can improve. </span><span class="koboSpan" id="kobo.1275.2">We will stick with a decision tree model and use synthetic data generation to further improve the signal strength of the data. </span><span class="koboSpan" id="kobo.1275.3">We will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1276.1">imblearn</span></strong><span class="koboSpan" id="kobo.1277.1"> library from Python to generate </span><span class="No-Break"><span class="koboSpan" id="kobo.1278.1">synthetic data.</span></span></p>
<p><span class="koboSpan" id="kobo.1279.1">Let’s import the library and two oversampling methods, </span><strong class="source-inline"><span class="koboSpan" id="kobo.1280.1">SMOTE</span></strong><span class="koboSpan" id="kobo.1281.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1282.1">ADASYN</span></strong><span class="koboSpan" id="kobo.1283.1">, to oversample the minority class. </span><span class="koboSpan" id="kobo.1283.2">We will also leverage the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1284.1">Counter</span></strong><span class="koboSpan" id="kobo.1285.1"> method to count data samples pre- and post-synthetic </span><span class="No-Break"><span class="koboSpan" id="kobo.1286.1">data generation:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1287.1">
import imblearn
from imblearn.over_sampling import SMOTE, ADASYN
from collections import Counter
print(imblearn.__version__)
0.10.1</span></pre> <p><span class="koboSpan" id="kobo.1288.1">Both the SMOTE </span><a id="_idIndexMarker570"/><span class="koboSpan" id="kobo.1289.1">and ADASYN algorithms </span><a id="_idIndexMarker571"/><span class="koboSpan" id="kobo.1290.1">are used to generate synthetic data. </span><span class="koboSpan" id="kobo.1290.2">However, ADASYN is more robust as it considers the density of points to generate synthetic data. </span><span class="koboSpan" id="kobo.1290.3">SMOTE may generate synthetic data around the minority class, but it does so uniformly without considering how rare a data </span><span class="No-Break"><span class="koboSpan" id="kobo.1291.1">point is.</span></span></p>
<p><span class="koboSpan" id="kobo.1292.1">SMOTE creates</span><a id="_idIndexMarker572"/><span class="koboSpan" id="kobo.1293.1"> synthetic samples by randomly selecting pairs of minority-class samples and interpolating new samples around the existing samples. </span><span class="koboSpan" id="kobo.1293.2">This technique spreads out further into the space to increase the number of minority class samples. </span><span class="koboSpan" id="kobo.1293.3">However, as the samples are chosen randomly, no weighting is given to rare </span><span class="No-Break"><span class="koboSpan" id="kobo.1294.1">sample points.</span></span></p>
<p><span class="koboSpan" id="kobo.1295.1">On the other hand, ADASYN considers rare data points in the feature space by computing the density distribution of the minority class samples. </span><span class="koboSpan" id="kobo.1295.2">It generates synthetic samples in regions of the feature space where the density is low to ensure that synthetic samples are generated where they are most needed to balance the dataset. </span><span class="koboSpan" id="kobo.1295.3">ADASYN uses the k-nearest neighbors algorithm to estimate the density distribution of the minority class samples. </span><span class="koboSpan" id="kobo.1295.4">For each minority class sample, ADASYN computes the density based on the number of k-nearest neighbors that belong to the minority class. </span><span class="koboSpan" id="kobo.1295.5">The value of k is a user-defined parameter, typically set to a small value such as 5 to 10. </span><span class="koboSpan" id="kobo.1295.6">The density is the average distance from k nearest points. </span><span class="koboSpan" id="kobo.1295.7">A higher average distance means lower density, and </span><span class="No-Break"><span class="koboSpan" id="kobo.1296.1">vice versa.</span></span></p>
<p><span class="koboSpan" id="kobo.1297.1">We iterate over</span><a id="_idIndexMarker573"/><span class="koboSpan" id="kobo.1298.1"> different thresholds of the algorithm parameters, such as the number of nearest neighbors and the percentage of </span><a id="_idIndexMarker574"/><span class="koboSpan" id="kobo.1299.1">data to oversample. </span><span class="koboSpan" id="kobo.1299.2">This helps us find the best parameters to generate the optimal number of samples so that both the test ROC and test accuracy get the maximum boost. </span><span class="koboSpan" id="kobo.1299.3">Then, we combine those results in a DataFrame and choose the best parameters. </span><span class="koboSpan" id="kobo.1299.4">This is done to measure the performance of the model that is using synthetic </span><span class="No-Break"><span class="koboSpan" id="kobo.1300.1">data generation.</span></span></p>
<p><span class="koboSpan" id="kobo.1301.1">For our example, we will only use ADASYN, but we encourage you to try different techniques, including SMOTE, for the problem </span><span class="No-Break"><span class="koboSpan" id="kobo.1302.1">at hand:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1303.1">
results = []
over_sampling = [0.65,0.7, 0.75, 0.8, 'auto']
n_neighbours = [1,3,5,7,9,10]
for os in over_sampling:
    for k in n_neighbours:
        oversample = ADASYN(random_state=1, sampling_strategy=os, n_neighbors=k)
        counter = Counter(y_train)
        print(f"data size before applying smote technique is {counter}")
        X_train_synthetic, y_train_synthetic = oversample.fit_resample(X_train_transformed, y_train)
        counter = Counter(y_train_synthetic)
        print(f"data size after applying smote technique is {counter}")
        model, test_predictions, train_roc, test_roc, train_acc, test_acc = train_custom_classifier(
        X_train=X_train_synthetic,
        y_train=y_train_synthetic,
        X_test=X_test_transformed,
        y_test=y_test,
        clf=d_clf,
        params=d_param_grid)
        results.append((os, k, train_roc, test_roc, train_acc, test_acc))
synthetic_df = pd.DataFrame(columns=['os_strategy', "n_neighbours", "train_roc", "test_roc", "train_acc", "test_acc"], data=results)</span></pre> <p><span class="koboSpan" id="kobo.1304.1">Next, we </span><a id="_idIndexMarker575"/><span class="koboSpan" id="kobo.1305.1">must generate a DataFrame that </span><a id="_idIndexMarker576"/><span class="koboSpan" id="kobo.1306.1">contains our generated combinations of model parameters and model performance metrics and sort it by test accuracy. </span><span class="koboSpan" id="kobo.1306.2">The DataFrame indicates that an oversampling strategy with a ratio of 75% for the minority to majority class, and a nearest neighbors value of 7, will provide the best accuracy and </span><span class="No-Break"><span class="koboSpan" id="kobo.1307.1">ROC score:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer089">
<span class="koboSpan" id="kobo.1308.1"><img alt="Figure 7.18 – Output DataFrame" src="image/B19297_07_18.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1309.1">Figure 7.18 – Output DataFrame</span></p>
<p><span class="koboSpan" id="kobo.1310.1">Now, we must </span><a id="_idIndexMarker577"/><span class="koboSpan" id="kobo.1311.1">apply the parameters from our highest-performing oversampling strategy and retrain the decision </span><span class="No-Break"><span class="koboSpan" id="kobo.1312.1">tree model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1313.1">
counter = Counter(y_train)
print(f"data size before applying smote technique {tech_name} is {counter}")
# transform the dataset
oversample = ADASYN(random_state=1, n_neighbors=7, sampling_strategy=0.75)
X_train_synthetic, y_train_synthetic = oversample.fit_resample(X_train_transformed, y_train)
counter = Counter(y_train_synthetic)
print(f"data size after applying smote technique {tech_name} is {counter}")
model, test_predictions, train_roc, test_roc, train_acc, test_acc = train_custom_classifier(
X_train=X_train_synthetic,
y_train=y_train_synthetic,
X_test=X_test_transformed,
y_test=y_test,
clf=d_clf,
params=d_param_grid)
data size before applying smote technique adasyn is Counter({1: 379, 0: 173})
data size after applying smote technique adasyn is Counter({1: 379, 0: 321})
Decision tree optimised
Getting the best params which are {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 30, 'random_state': 1}
Training roc is 0.8816528164788466, and testing roc is 0.8629130966952264
             training accuracy is 0.8371428571428572, testing_acc as 0.8387096774193549</span></pre> <p><span class="koboSpan" id="kobo.1314.1">ADASYN increased </span><a id="_idIndexMarker578"/><span class="koboSpan" id="kobo.1315.1">the number of minority class samples from 173 to 321 using synthetic data generation, which boosted the test accuracy to 83.8%. </span><span class="koboSpan" id="kobo.1315.2">This is an almost 2% increase in accuracy. </span><span class="koboSpan" id="kobo.1315.3">The ROC score was also boosted to 86.2%, which is a further increase </span><span class="No-Break"><span class="koboSpan" id="kobo.1316.1">of 4.4%.</span></span></p>
<p><span class="koboSpan" id="kobo.1317.1">These results demonstrate that synthetic data generation can provide significant gains in model performance, even for small datasets. </span><span class="koboSpan" id="kobo.1317.2">However, it is important to note that this may not always</span><a id="_idIndexMarker579"/><span class="koboSpan" id="kobo.1318.1"> be the case, especially if error analysis suggests that adding new data doesn’t contribute to an improvement in model performance. </span><span class="koboSpan" id="kobo.1318.2">In such cases, you may turn to collecting more data or features, or even performing feature engineering, before moving on to synthetic </span><span class="No-Break"><span class="koboSpan" id="kobo.1319.1">data generation.</span></span></p>
<h2 id="_idParaDest-114"><a id="_idTextAnchor122"/><span class="koboSpan" id="kobo.1320.1">When should you use synthetic data?</span></h2>
<p><span class="koboSpan" id="kobo.1321.1">So far, we’ve </span><a id="_idIndexMarker580"/><span class="koboSpan" id="kobo.1322.1">established that synthetic data can be used for several purposes, but how do you decide whether to use synthetic data for your project </span><span class="No-Break"><span class="koboSpan" id="kobo.1323.1">or not?</span></span></p>
<p><span class="koboSpan" id="kobo.1324.1">For businesses seeking to gain an edge over their competitors through innovative or unconventional approaches, synthetic data provides an accessible middle ground between experimentation and reality. </span><span class="koboSpan" id="kobo.1324.2">For governmental organizations wanting to learn from their vast stores of population data, synthetic data allows highly sensitive datasets to be analyzed without compromising </span><span class="No-Break"><span class="koboSpan" id="kobo.1325.1">individual privacy.</span></span></p>
<p><span class="koboSpan" id="kobo.1326.1">Experimentation and exploring the boundaries of your data (synthetic or real) can be incredibly valuable, but the benefit of introducing synthetic data should always be assessed against the cost and risk of making damaging predictions with that </span><span class="No-Break"><span class="koboSpan" id="kobo.1327.1">same data.</span></span></p>
<p><span class="koboSpan" id="kobo.1328.1">The central question is, “</span><em class="italic"><span class="koboSpan" id="kobo.1329.1">What is the acceptable cost of an experiment?</span></em><span class="koboSpan" id="kobo.1330.1">,” especially if it includes human collateral damage or reputational or </span><span class="No-Break"><span class="koboSpan" id="kobo.1331.1">financial loss.</span></span></p>
<p><span class="koboSpan" id="kobo.1332.1">In our opinion, synthetic data should be used when obtaining real-world data may be difficult, expensive, or unethical. </span><span class="koboSpan" id="kobo.1332.2">The most common and practical use cases for synthetic data are for preserving the privacy of individuals and for creating simulations that are very difficult or impossible in traditional test environments. </span><span class="koboSpan" id="kobo.1332.3">For these use cases, the benefits are more likely to outweigh the risks of using synthetic data, but that is not a guarantee, so make sure you manage </span><span class="No-Break"><span class="koboSpan" id="kobo.1333.1">risks appropriately.</span></span></p>
<p><span class="koboSpan" id="kobo.1334.1">The main risks to mitigate are perpetuation and exacerbation of bias. </span><span class="koboSpan" id="kobo.1334.2">Machine learning models are inherently prone to overfitting and finding the “easiest” path through the data, so synthetic datasets should be rigorously tested to ensure they are fit </span><span class="No-Break"><span class="koboSpan" id="kobo.1335.1">for purpose.</span></span></p>
<p><span class="koboSpan" id="kobo.1336.1">Synthetic data can also accelerate the process of testing and training machine learning models, saving companies time and money in their development and deployment cycles. </span><span class="koboSpan" id="kobo.1336.2">Furthermore, synthetic data is a useful tool for creating simulations that are not possible in traditional </span><span class="No-Break"><span class="koboSpan" id="kobo.1337.1">test environments.</span></span></p>
<p><span class="koboSpan" id="kobo.1338.1">Bear in mind </span><a id="_idIndexMarker581"/><span class="koboSpan" id="kobo.1339.1">that using synthetic data is typically just one of many avenues to take when building models or improving the accuracy of your predictions. </span><span class="koboSpan" id="kobo.1339.2">It should only be used when the potential risk and effect on those impacted is understood and managed appropriately. </span><span class="koboSpan" id="kobo.1339.3">On the other hand, if you can mitigate this risk – or in some cases, avoid “real-world” risks altogether – then it is a wonderful tool to have in </span><span class="No-Break"><span class="koboSpan" id="kobo.1340.1">your toolkit.</span></span></p>
<h1 id="_idParaDest-115"><a id="_idTextAnchor123"/><span class="koboSpan" id="kobo.1341.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.1342.1">In this chapter, we provided a primer on synthetic data and its common uses. </span><span class="koboSpan" id="kobo.1342.2">Synthetic data is a key part of the data-centric toolkit because it gives us yet another avenue to much better input data, especially when collecting new data is </span><span class="No-Break"><span class="koboSpan" id="kobo.1343.1">not feasible.</span></span></p>
<p><span class="koboSpan" id="kobo.1344.1">By now, you should have a clear understanding of the fundamentals of synthetic data and its potential applications. </span><span class="koboSpan" id="kobo.1344.2">Synthetic data is often used for computer vision, natural language processing, and privacy protection applications. </span><span class="koboSpan" id="kobo.1344.3">However, the potential of synthetic data goes well beyond these </span><span class="No-Break"><span class="koboSpan" id="kobo.1345.1">three realms.</span></span></p>
<p><span class="koboSpan" id="kobo.1346.1">Whole books have been dedicated to the topic of synthetic data and we recommend that you dive deeper into the subject if you want to become a true expert in synthetic </span><span class="No-Break"><span class="koboSpan" id="kobo.1347.1">data generation.</span></span></p>
<p><span class="koboSpan" id="kobo.1348.1">In the next chapter, we’ll explore another powerful technique for improving your data without the need for collecting new data: </span><span class="No-Break"><span class="koboSpan" id="kobo.1349.1">programmatic labeling.</span></span></p>
<h1 id="_idParaDest-116"><a id="_idTextAnchor124"/><span class="koboSpan" id="kobo.1350.1">References</span></h1>
<ol>
<li><a href="https://datagen.tech/guides/synthetic-data/synthetic-data"><span class="koboSpan" id="kobo.1351.1">https://datagen.tech/guides/synthetic-data/synthetic-data</span></a><span class="koboSpan" id="kobo.1352.1">, viewed on 12 </span><span class="No-Break"><span class="koboSpan" id="kobo.1353.1">November 2022</span></span></li>
<li><a href="https://blogs.gartner.com/andrew_white/2021/07/24/by-2024-60-of-the-data-used-for-the-development-of-ai-and-analytics-projects-will-be-synthetically-generated/"><span class="No-Break"><span class="koboSpan" id="kobo.1354.1">https://blogs.gartner.com/andrew_white/2021/07/24/by-2024-60-of-the-data-used-for-the-development-of-ai-and-analytics-projects-will-be-synthetically-generated/</span></span></a></li>
<li><a href="https://unity.com/our-company"><span class="koboSpan" id="kobo.1355.1">https://unity.com/our-company</span></a><span class="koboSpan" id="kobo.1356.1">, viewed on 15 </span><span class="No-Break"><span class="koboSpan" id="kobo.1357.1">November 2022</span></span></li>
<li><span class="koboSpan" id="kobo.1358.1">https://venturebeat.com/ai/unitys-danny-lange-explains-why-synthetic-data-is-better-than-the-real-thing-at-transform-2021-2/, viewed on 15 </span><span class="No-Break"><span class="koboSpan" id="kobo.1359.1">November 2022</span></span></li>
<li><span class="koboSpan" id="kobo.1360.1">Alcorn, M A et al 2019, </span><em class="italic"><span class="koboSpan" id="kobo.1361.1">Strike (with) a Pose: Neural Networks Are Easily Fooled by Strange Poses of Familiar Objects</span></em><span class="koboSpan" id="kobo.1362.1">, viewed 13 November </span><span class="No-Break"><span class="koboSpan" id="kobo.1363.1">2022: </span></span><a href="http://pdf/1811.11553.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.1364.1">https://arxiv.org/pdf/1811.11553.pdf</span></span></a></li>
<li><a href="https://www.tesla.com/VehicleSafetyReport"><span class="koboSpan" id="kobo.1365.1">https://www.tesla.com/VehicleSafetyReport</span></a><span class="koboSpan" id="kobo.1366.1">, viewed 13 </span><span class="No-Break"><span class="koboSpan" id="kobo.1367.1">November 2022</span></span></li>
<li><span class="koboSpan" id="kobo.1368.1">Karras T, Aila T, Laine S, Lethtinen J, 2017, </span><em class="italic"><span class="koboSpan" id="kobo.1369.1">Progressive Growing of GANs for Improved Quality, Stability, and </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1370.1">Variation</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1371.1">: </span></span><a href="https://arxiv.org/abs/1710.10196"><span class="No-Break"><span class="koboSpan" id="kobo.1372.1">https://arxiv.org/abs/1710.10196</span></span></a></li>
<li><span class="koboSpan" id="kobo.1373.1">Karras T, Aila T, Laine S 2018, </span><em class="italic"><span class="koboSpan" id="kobo.1374.1">A Style-Based Generator Architecture for Generative Adversarial </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1375.1">Networks</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1376.1">: </span></span><a href="https://arxiv.org/pdf/1812.04948.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.1377.1">https://arxiv.org/pdf/1812.04948.pdf</span></span></a></li>
<li><span class="koboSpan" id="kobo.1378.1">Metz L, Poole B, Pfau D, Sohl-Dickstein J 2017, </span><em class="italic"><span class="koboSpan" id="kobo.1379.1">Unrolled Generative Adversarial Networks</span></em><span class="koboSpan" id="kobo.1380.1">, ICLR </span><span class="No-Break"><span class="koboSpan" id="kobo.1381.1">2017: </span></span><a href="https://arxiv.org/pdf/1611.02163.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.1382.1">https://arxiv.org/pdf/1611.02163.pdf</span></span></a></li>
<li><span class="koboSpan" id="kobo.1383.1">Jain N, Olmo A, Sengupta S, Manikonda L, Kambhampati S, 2021, </span><em class="italic"><span class="koboSpan" id="kobo.1384.1">Imperfect ImaGANation: Implications of GANs Exacerbating Biases on Facial Data</span></em><span class="koboSpan" id="kobo.1385.1">, ICLR 2021 Workshop on Synthetic Data Generation – Quality, Privacy, </span><span class="No-Break"><span class="koboSpan" id="kobo.1386.1">Bias: </span></span><a href="https://arxiv.org/pdf/2001.09528.pdf "><span class="No-Break"><span class="koboSpan" id="kobo.1387.1">https://arxiv.org/pdf/2001.09528.pdf</span></span></a></li>
<li><span class="koboSpan" id="kobo.1388.1">Rocher L, Hendrickx J M, de Montjoye Y A 2019, </span><em class="italic"><span class="koboSpan" id="kobo.1389.1">Estimating the success of re-identifications in incomplete datasets using generative </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.1390.1">models</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.1391.1">: </span></span><a href="https://www.nature.com/articles/s41467-019-10933-3 "><span class="No-Break"><span class="koboSpan" id="kobo.1392.1">https://www.nature.com/articles/s41467-019-10933-3</span></span></a></li>
<li><span class="koboSpan" id="kobo.1393.1">L. </span><span class="koboSpan" id="kobo.1393.2">Sweeney, </span><em class="italic"><span class="koboSpan" id="kobo.1394.1">Simple Demographics Often Identify People Uniquely, Carnegie Mellon University</span></em><span class="koboSpan" id="kobo.1395.1">, Data Privacy Working Paper 3. </span><span class="koboSpan" id="kobo.1395.2">Pittsburgh </span><span class="No-Break"><span class="koboSpan" id="kobo.1396.1">2000: </span></span><a href="https://dataprivacylab.org/projects/identifiability/paper1.pdf"><span class="No-Break"><span class="koboSpan" id="kobo.1397.1">https://dataprivacylab.org/projects/identifiability/paper1.pdf</span></span></a></li>
<li><a href="https://mobile.twitter.com/sdv_dev/status/1519747462088507393"><span class="koboSpan" id="kobo.1398.1">https://mobile.twitter.com/sdv_dev/status/1519747462088507393</span></a><span class="koboSpan" id="kobo.1399.1">, viewed on 25 </span><span class="No-Break"><span class="koboSpan" id="kobo.1400.1">January 2023</span></span></li>
</ol>
</div>
</body></html>