<html><head></head><body><div class="chapter" title="Chapter&#xA0;9.&#xA0;Neural Networks with OpenCV &#x2013; an Introduction" id="aid-1MBG21"><div class="titlepage"><div><div><h1 class="title"><a id="ch09"/>Chapter 9. Neural Networks with OpenCV – an Introduction</h1></div></div></div><p>Machine learning is a branch of artificial intelligence, one that deals specifically with algorithms that enable a machine to recognize patterns and trends in data and successfully make predictions and classifications.</p><p>Many of the algorithms and techniques used by OpenCV to accomplish some of the more advanced tasks in computer vision are directly related to artificial intelligence and machine learning.</p><p>This chapter will introduce you to the Machine Learning concepts in OpenCV such as artificial neural networks. This is a gentle introduction that barely scratches the surface of a vast world, that of Machine Learning, which is continuously evolving.</p><div class="section" title="Artificial neural networks"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec51"/>Artificial neural networks</h1></div></div></div><p>Let's start <a id="id504" class="indexterm"/>by defining <span class="strong"><strong>Artificial Neural Networks</strong></span> (<span class="strong"><strong>ANN</strong></span>) with a number of logical steps, rather than a classic monolithic sentence using obscure jargon with an even more obscure meaning.</p><p>First of all, an ANN is a <a id="id505" class="indexterm"/>
<span class="strong"><strong>statistical model</strong></span>. What <a id="id506" class="indexterm"/>is a statistical model? A statistical model is a pair of elements, namely the space <code class="literal">S</code> (a set of observations) and the probability <code class="literal">P</code>, where <code class="literal">P</code> is a distribution that approximates <code class="literal">S</code> (in other words, a function that would generate a set of observations that is very similar to <code class="literal">S</code>).</p><p>I like to think of <code class="literal">P</code> in two ways: as a simplification of a complex scenario, and as the function that generated <code class="literal">S</code> in the first place, or at the very least a set of observations very similar to <code class="literal">S</code>.</p><p>So ANNs are models that take a complex reality, simplify it, and deduce a function to (approximately) represent statistical observations one would expect from that reality, in mathematical form.</p><p>The next step in our journey towards comprehending ANNs is to understand how an ANN improves on the concept of a simple statistical model.</p><p>What if the function that generated the dataset is likely to take a large amount of (unknown) inputs?</p><p>The approach that ANNs take is to delegate work to a number of <span class="strong"><strong>neurons</strong></span>, <span class="strong"><strong>nodes</strong></span>, or <span class="strong"><strong>units</strong></span>, each of which is capable of "approximating" the function that created the inputs. Approximation is <a id="id507" class="indexterm"/>mathematically the definition of a simpler function that approximates a more complex function, which enables us to define errors (relative to the application domain). Furthermore, for accuracy's sake, a network is generally recognized to be neural if the neurons or units are capable of approximating a nonlinear function.</p><p>Let's take a closer look at neurons.</p><div class="section" title="Neurons and perceptrons"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec54"/>Neurons and perceptrons</h2></div></div></div><p>The <span class="strong"><strong>perceptron</strong></span> <a id="id508" class="indexterm"/>is a concept that dates back to the 1950s, and (to put it simply) a perceptron is a function that takes a number of inputs and <a id="id509" class="indexterm"/>produces a single value.</p><p>Each of the inputs has an associated weight that signifies the importance of the input in the function. The sigmoid function produces a single value:</p><div class="mediaobject"><img src="../Images/image00251.jpeg" alt="Neurons and perceptrons"/></div><p style="clear:both; height: 1em;"> </p><p>A sigmoid <a id="id510" class="indexterm"/>function is a term that indicates that the function produces either a 0 or 1 value. The discriminant is a threshold value; if the weighted sum of the inputs is greater than a certain threshold, the perceptron produces a binary classification of 1, otherwise 0.</p><p>How are these weights determined, and what do they represent?</p><p>Neurons are interconnected <a id="id511" class="indexterm"/>to each other, and each neuron's set of weights (these are just numerical parameters) defines the strength of the connection to other neurons. These weights are "adaptive", meaning they change in time according to a learning algorithm.</p></div></div></div>
<div class="section" title="The structure of an ANN" id="aid-1NA0K1"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec52"/>The structure of an ANN</h1></div></div></div><p>Here's a <a id="id512" class="indexterm"/>visual representation of a neural network:</p><div class="mediaobject"><img src="../Images/image00252.jpeg" alt="The structure of an ANN"/></div><p style="clear:both; height: 1em;"> </p><p>As you can see from the figure, there are three distinct layers in a neural network: <span class="strong"><strong>Input layer</strong></span>, <span class="strong"><strong>Hidden layer</strong></span> (or middle), and <span class="strong"><strong>Output layer</strong></span>.</p><p>There can be more than one hidden layer; however, one hidden layer would be enough to resolve the majority of real-life problems.</p><div class="section" title="Network layers by example"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec55"/>Network layers by example</h2></div></div></div><p>How do we determine the network's topology, and how many neurons to create for each layer? Let's make <a id="id513" class="indexterm"/>this determination <a id="id514" class="indexterm"/>layer by layer.</p><div class="section" title="The input layer"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec38"/>The input layer</h3></div></div></div><p>The input layer defines <a id="id515" class="indexterm"/>the number of inputs into the network. For example, let's say you want to create an ANN, which will help you determine what animal <a id="id516" class="indexterm"/>you're looking at given a description of its attributes. Let's fix these attributes to weight, length, and teeth. That's a set of three attributes; our network will need to contain three input nodes.</p></div><div class="section" title="The output layer"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec39"/>The output layer</h3></div></div></div><p>The output layer is <a id="id517" class="indexterm"/>equal to the number of classes we identified. Continuing with the preceding example of an animal classification network, we will arbitrarily set <a id="id518" class="indexterm"/>the output layer to <code class="literal">4</code>, because we know we're going to deal with the following animals: dog, condor, dolphin, and dragon. If we feed in data for an animal that is not in one of these categories, the network will return the class most likely to resemble this unclassified animal.</p></div><div class="section" title="The hidden layer"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec40"/>The hidden layer</h3></div></div></div><p>The hidden layer <a id="id519" class="indexterm"/>contains perceptrons. As mentioned, the vast <a id="id520" class="indexterm"/>majority of problems only require one hidden layer; mathematically speaking, there is no verified reason to have more than two hidden layers. We will, therefore, stick to one hidden layer and work with that.</p><p>There are a number of rules of thumb to determine the number of neurons contained in the hidden layer, but there is no hard-and-fast rule. The empirical way is your friend in this particular circumstance: test your network with different settings, and choose the one that fits best.</p><p>These are some of the most common rules used when building an ANN:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The number of hidden neurons should be between the size of the input layer and the size of the output layer. If the difference between the input layer size and the output layer is large, it is my experience that a hidden layer size much closer to the output layer is preferable.</li><li class="listitem">For relatively small input layers, the number of hidden neurons is two-thirds the size of the input layer, plus the size of the output layer, or less than twice the size of the input layer.</li></ul></div><p>One very important <a id="id521" class="indexterm"/>factor to keep in mind is <span class="strong"><strong>overfitting</strong></span>. Overfitting occurs when there's such an inordinate amount of information contained in the hidden layer (for example, a disproportionate amount of neurons in the layer) compared to the information provided by the training data that classification is not very meaningful.</p><p>The larger the hidden layer, the more training information is required for the network to be trained properly. And, needless to say, this is going to lengthen the time required by the network to properly train.</p><p>So, following the second rules of thumb illustrated earlier, our network will have a hidden layer of size 8, just because after a few runs of the network, I found it to yield the best results. As a side note, the empirical approach is very much encouraged in the world of ANNs. The best network topology is related to the type of data fed to the network, so don't refrain from <a id="id522" class="indexterm"/>testing ANNs in a trial-and-error fashion.</p><p>In summary, our network <a id="id523" class="indexterm"/>has the following sizes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Input</strong></span>: <code class="literal">3</code></li><li class="listitem"><span class="strong"><strong>Hidden</strong></span>: <code class="literal">8</code></li><li class="listitem"><span class="strong"><strong>Output</strong></span>: <code class="literal">4</code></li></ul></div><div class="section" title="The learning algorithms"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec06"/>The learning algorithms</h4></div></div></div><p>There are a number <a id="id524" class="indexterm"/>of learning algorithms used by ANNs, but we can identify three major ones:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Supervised learning</strong></span>: With <a id="id525" class="indexterm"/>this algorithm, we <a id="id526" class="indexterm"/>want to obtain a function from the ANN, which describes the data we labeled. We know, a priori, the nature of this data, and we delegate to the ANN the process of finding a function that describes the data.</li><li class="listitem"><span class="strong"><strong>Unsupervised learning</strong></span>: This algorithm differs from supervised learning; in this, the data is <a id="id527" class="indexterm"/>unlabeled. This implies <a id="id528" class="indexterm"/>that we don't have to select and label data, but it also means the ANN has a lot more work to do. The classification of the data is usually obtained through techniques such as (but not only) clustering, which we explored in <a class="link" title="Chapter 7. Detecting and Recognizing Objects" href="part0049.xhtml#aid-1ENBI2">Chapter 7</a>, <span class="emphasis"><em>Detecting and Recognizing Objects</em></span>.</li><li class="listitem"><span class="strong"><strong>Reinforcement learning</strong></span>: Reinforcement learning is a little more complex. A system <a id="id529" class="indexterm"/>receives an input; a decision-making mechanism determines an action, which is performed and scored (success/failure and grades in between); and finally the input and the action are <a id="id530" class="indexterm"/>paired with their score, so the system learns to repeat or change the action to be performed for a certain input or state.</li></ul></div><p>Now that we have a general idea of what ANNs are, let's see how OpenCV implements them, and how to put them to good use. Finally, we'll work our way up to a full blown application, in which we will attempt to recognize handwritten digits.</p></div></div></div></div>
<div class="section" title="ANNs in OpenCV"><div class="titlepage" id="aid-1O8H62"><div><div><h1 class="title"><a id="ch09lvl1sec53"/>ANNs in OpenCV</h1></div></div></div><p>Unsurprisingly, ANNs <a id="id531" class="indexterm"/>reside in the <code class="literal">ml</code> module of OpenCV.</p><p>Let's examine a dummy example, as a gentle introduction to ANNs:</p><div class="informalexample"><pre class="programlisting">import cv2
import numpy as np

ann = cv2.ml.ANN_MLP_create()
ann.setLayerSizes(np.array([9, 5, 9], dtype=np.uint8))
ann.setTrainMethod(cv2.ml.ANN_MLP_BACKPROP)

ann.train(np.array([[1.2, 1.3, 1.9, 2.2, 2.3, 2.9, 3.0, 3.2, 3.3]], dtype=np.float32),
  cv2.ml.ROW_SAMPLE,
  np.array([[0, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=np.float32))

print ann.predict(np.array([[1.4, 1.5, 1.2, 2., 2.5, 2.8, 3., 3.1, 3.8]], dtype=np.float32))</pre></div><p>First, we create an ANN:</p><div class="informalexample"><pre class="programlisting">ann = cv2.ml.ANN_MLP_create()</pre></div><p>You may wonder about <a id="id532" class="indexterm"/>the <code class="literal">MLP</code> acronym in the <a id="id533" class="indexterm"/>function name; it stands for <span class="strong"><strong>multilayer perceptron</strong></span>. By now, you should know what a perceptron is.</p><p>After creating the network, we need to set its topology:</p><div class="informalexample"><pre class="programlisting">ann.setLayerSizes(np.array([9, 5, 9], dtype=np.uint8))
ann.setTrainMethod(cv2.ml.ANN_MLP_BACKPROP)</pre></div><p>The layer sizes are defined by the NumPy array that is passed into the <code class="literal">setLayerSizes</code> method. The first element sets the size of the input layer, the last element sets the size of the output layer, and all intermediary elements define the size of the hidden layers.</p><p>We then set the train method to be backpropagation. There are two choices here: <code class="literal">BACKPROP</code> and <code class="literal">RPROP</code>.</p><p>Both <code class="literal">BACKPROP</code> and <code class="literal">RPROP</code> are backpropagation algorithms—in simple terms, algorithms that have an effect on weights based on errors in classification.</p><p>These two algorithms work in the context of supervised learning, which is what we are using in the example. How can we tell this particular detail? Look at the next statement:</p><div class="informalexample"><pre class="programlisting">ann.train(np.array([[1.2, 1.3, 1.9, 2.2, 2.3, 2.9, 3.0, 3.2, 3.3]], dtype=np.float32),
  cv2.ml.ROW_SAMPLE,
  np.array([[0, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=np.float32))</pre></div><p>You should notice a number of details. The method looks extremely similar to the <code class="literal">train()</code> method of support vector machine. The method contains three parameters: <code class="literal">samples</code>, <code class="literal">layout</code>, and <code class="literal">responses</code>. Only <code class="literal">samples</code> is the required parameter; the other two are optional.</p><p>This reveals the following information:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">First, ANN, like <a id="id534" class="indexterm"/>SVM, is an OpenCV <code class="literal">StatModel</code> (<span class="strong"><strong>statistical model</strong></span>); <code class="literal">train</code> and <code class="literal">predict</code> are the methods inherited from the base <code class="literal">StatModel</code> class.</li><li class="listitem">Second, a statistical model trained with only <code class="literal">samples</code> is adopting an unsupervised learning algorithm. If we provide <code class="literal">layout</code> and <code class="literal">responses</code>, we're in a supervised learning context.</li></ul></div><p>As we're using ANNs, we can specify the type of back propagation algorithm we're going to use (<code class="literal">BACKPROP</code> or <code class="literal">RPROP</code>), because—as we said—we're in a supervised learning environment.</p><p>So what is back <a id="id535" class="indexterm"/>propagation? Back propagation is a two-phase algorithm that calculates the error of predictions and updates in both directions of the network (the input and output layers); it then updates the neuron weights accordingly.</p><p>Let's train the ANN; as we specified an input layer of size 9, we need to provide 9 inputs, and 9 outputs to reflect the size of the output layer:</p><div class="informalexample"><pre class="programlisting">ann.train(np.array([[1.2, 1.3, 1.9, 2.2, 2.3, 2.9, 3.0, 3.2, 3.3]], dtype=np.float32),
  cv2.ml.ROW_SAMPLE,
    np.array([[0, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=np.float32))</pre></div><p>The structure of the response is simply an array of zeros, with a <code class="literal">1</code> value in the position indicating the class we want to associate the input with. In our preceding example, we indicated that the specified input array corresponds to class 5 (classes are zero-indexed) of classes 0 to 8.</p><p>Lastly, we perform classification:</p><div class="informalexample"><pre class="programlisting">print ann.predict(np.array([[1.4, 1.5, 1.2, 2., 2.5, 2.8, 3., 3.1, 3.8]], dtype=np.float32))</pre></div><p>This will yield the following result:</p><div class="informalexample"><pre class="programlisting">(5.0, array([[-0.06419383, -0.13360272, -0.1681568 , -0.18708915,  0.0970564 ,
  0.89237726,  0.05093023,  0.17537238,  0.13388439]], dtype=float32))</pre></div><p>This means that the provided input was classified as belonging to class 5. This is only a dummy example and the classification is pretty meaningless; however, the network behaved correctly. In this code, we only provided one training record for class 5, so the network classified a new input as belonging to class 5.</p><p>As you may have <a id="id536" class="indexterm"/>guessed, the output of a prediction is a tuple, with the first value being the class and the second being an array containing the probabilities for each class. The predicted class will have the highest value. Let's move on to a slightly more useful example: animal classification.</p><div class="section" title="ANN-imal classification"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec56"/>ANN-imal classification</h2></div></div></div><p>Picking <a id="id537" class="indexterm"/>up from where we left off, let's illustrate a very simple example of an ANN that attempts to classify animals based on their statistics (weight, length, and teeth). My intent is to describe a mock real-life scenario to improve our understanding of ANNs before we start applying it to computer vision and, specifically, OpenCV:</p><div class="informalexample"><pre class="programlisting">import cv2
import numpy as np
from random import randint

animals_net = cv2.ml.ANN_MLP_create()
animals_net.setTrainMethod(cv2.ml.ANN_MLP_RPROP | cv2.ml.ANN_MLP_UPDATE_WEIGHTS)
animals_net.setActivationFunction(cv2.ml.ANN_MLP_SIGMOID_SYM)
animals_net.setLayerSizes(np.array([3, 8, 4]))
animals_net.setTermCriteria(( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 ))

"""Input arrays
weight, length, teeth
"""

"""Output arrays
dog, eagle, dolphin and dragon
"""

def dog_sample():
  return [randint(5, 20), 1, randint(38, 42)]

def dog_class():
  return [1, 0, 0, 0]

def condor_sample():
  return [randint(3,13), 3, 0]

def condor_class():
  return [0, 1, 0, 0]

def dolphin_sample():
  return [randint(30, 190), randint(5, 15), randint(80, 100)]

def dolphin_class():
  return [0, 0, 1, 0]

def dragon_sample():
  return [randint(1200, 1800), randint(15, 40), randint(110, 180)]

def dragon_class():
  return [0, 0, 0, 1]

SAMPLES = 5000
for x in range(0, SAMPLES):
  print "Samples %d/%d" % (x, SAMPLES)
  animals_net.train(np.array([dog_sample()], dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array([dog_class()], dtype=np.float32))
  animals_net.train(np.array([condor_sample()], dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array([condor_class()], dtype=np.float32))
  animals_net.train(np.array([dolphin_sample()], dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array([dolphin_class()], dtype=np.float32))
  animals_net.train(np.array([dragon_sample()], dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array([dragon_class()], dtype=np.float32))

print animals_net.predict(np.array([dog_sample()], dtype=np.float32))
print animals_net.predict(np.array([condor_sample()], dtype=np.float32))
print animals_net.predict(np.array([dragon_sample()], dtype=np.float32))</pre></div><p>There are a <a id="id538" class="indexterm"/>good few differences between this example and the dummy example, so let's examine them in order.</p><p>First, the usual imports. Then, we import <code class="literal">randint</code>, just because we want to generate some relatively random data:</p><div class="informalexample"><pre class="programlisting">import cv2
import numpy as np
from random import randint</pre></div><p>Then, we create the ANN. This time, we specify the <code class="literal">train</code> method to be resilient back propagation (an improved version of back propagation) and the activation function to be a sigmoid function:</p><div class="informalexample"><pre class="programlisting">animals_net = cv2.ml.ANN_MLP_create()
animals_net.setTrainMethod(cv2.ml.ANN_MLP_RPROP | cv2.ml.ANN_MLP_UPDATE_WEIGHTS)
animals_net.setActivationFunction(cv2.ml.ANN_MLP_SIGMOID_SYM)
animals_net.setLayerSizes(np.array([3, 8, 4]))</pre></div><p>Also, we <a id="id539" class="indexterm"/>specify the termination criteria similarly to the way we did in the CAMShift algorithm in the previous chapter:</p><div class="informalexample"><pre class="programlisting">animals_net.setTermCriteria(( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 ))</pre></div><p>Now we need some data. We're not really so much interested in representing animals accurately, as requiring a bunch of records to be used as training data. So we basically define four sample creation functions and four classification functions that will help us train the network:</p><div class="informalexample"><pre class="programlisting">"""Input arrays
weight, length, teeth
"""

"""Output arrays
dog, eagle, dolphin and dragon
"""

def dog_sample():
  return [randint(5, 20), 1, randint(38, 42)]

def dog_class():
  return [1, 0, 0, 0]

def condor_sample():
  return [randint(3,13), 3, 0]

def condor_class():
  return [0, 1, 0, 0]

def dolphin_sample():
  return [randint(30, 190), randint(5, 15), randint(80, 100)]

def dolphin_class():
  return [0, 0, 1, 0]

def dragon_sample():
  return [randint(1200, 1800), randint(15, 40), randint(110, 180)]

def dragon_class():
  return [0, 0, 0, 1]</pre></div><p>Let's <a id="id540" class="indexterm"/>proceed with the creation of our fake animal data; we'll create 5,000 samples per class:</p><div class="informalexample"><pre class="programlisting">SAMPLES = 5000
for x in range(0, SAMPLES):
  print "Samples %d/%d" % (x, SAMPLES)
  animals_net.train(np.array([dog_sample()], dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array([dog_class()], dtype=np.float32))
animals_net.train(np.array([condor_sample()], dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array([condor_class()], dtype=np.float32))
  animals_net.train(np.array([dolphin_sample()], dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array([dolphin_class()], dtype=np.float32))
        animals_net.train(np.array([dragon_sample()], dtype=np.float32),        cv2.ml.ROW_SAMPLE, np.array([dragon_class()], dtype=np.float32))</pre></div><p>In the end, we print the results that yield the following code:</p><div class="informalexample"><pre class="programlisting">(1.0, array([[ 1.49817729,  1.60551953, -1.56444871, -0.04313202]], dtype=float32))
(1.0, array([[ 1.49817729,  1.60551953, -1.56444871, -0.04313202]], dtype=float32))
(3.0, array([[-1.54576635, -1.68725526,  1.6469276 ,  2.23223686]], dtype=float32))</pre></div><p>From these results, we deduce the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The network got two out of three samples correct, which is not perfect but serves as a good example to illustrate the importance of all the elements involved in building and training an ANN. The size of the input layer is very important to create diversification between the different classes. In our case, we only had three statistics and there is a relative overlapping in features.</li><li class="listitem">The size of the hidden layer needs to be tested. You will find that increasing neurons may improve accuracy to a point, and then it will overfit, unless you start compensating with enormous amounts of data: the number of training records. Definitely, avoid having too few records or feeding a lot of identical records as the ANN won't learn much from them.</li></ul></div></div><div class="section" title="Training epochs"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec57"/>Training epochs</h2></div></div></div><p>Another important concept in training ANNs is the idea of epochs. A training epoch is an iteration <a id="id541" class="indexterm"/>through the training data, after which the data is tested for classification. Most ANNs train over several epochs; you'll find that some of the most common examples of ANNs, classifying handwritten digits, will have the training data iterated several hundred times.</p><p>I personally suggest you spend a lot of time playing with ANNs and the number of epochs, until you reach convergence, which means that further iterations will no longer improve (at least not noticeably) the accuracy of the results.</p><p>The preceding example can be modified as follows to leverage epochs:</p><div class="informalexample"><pre class="programlisting">def record(sample, classification):
  return (np.array([sample], dtype=np.float32), np.array([classification], dtype=np.float32))

records = []
RECORDS = 5000
for x in range(0, RECORDS):
  records.append(record(dog_sample(), dog_class()))
  records.append(record(condor_sample(), condor_class()))
  records.append(record(dolphin_sample(), dolphin_class()))
  records.append(record(dragon_sample(), dragon_class()))

EPOCHS = 5
for e in range(0, EPOCHS):
  print "Epoch %d:" % e
  for t, c in records:
    animals_net.train(t, cv2.ml.ROW_SAMPLE, c)</pre></div><p>Then, do some tests, starting with the <code class="literal">dog</code> class:</p><div class="informalexample"><pre class="programlisting">dog_results = 0
for x in range(0, 100):
  clas = int(animals_net.predict(np.array([dog_sample()], dtype=np.float32))[0])
  print "class: %d" % clas
  if (clas) == 0:
    dog_results += 1</pre></div><p>Repeat over all classes and output the results:</p><div class="informalexample"><pre class="programlisting">print "Dog accuracy: %f" % (dog_results)
print "condor accuracy: %f" % (condor_results)
print "dolphin accuracy: %f" % (dolphin_results)
print "dragon accuracy: %f" % (dragon_results)</pre></div><p>Finally, we obtain the following results:</p><div class="informalexample"><pre class="programlisting">Dog accuracy: 100.000000%
condor accuracy: 0.000000%
dolphin accuracy: 0.000000%
dragon accuracy: 92.000000%</pre></div><p>Consider <a id="id542" class="indexterm"/>the fact that we're only playing with toy/fake data and the size of training data/training iterations; this teaches us quite a lot. We can diagnose the ANN as overfitting towards certain classes, so it's important to improve the quality of the data you feed into the training process.</p><p>All that said, time for a real-life example: handwritten digit recognition.</p></div></div>
<div class="section" title="Handwritten digit recognition with ANNs"><div class="titlepage" id="aid-1P71O2"><div><div><h1 class="title"><a id="ch09lvl1sec54"/>Handwritten digit recognition with ANNs</h1></div></div></div><p>The world of <a id="id543" class="indexterm"/>Machine <a id="id544" class="indexterm"/>Learning is vast and mostly unexplored, and ANNs are but one of the many concepts related to <a id="id545" class="indexterm"/>Machine Learning, which is one of the many subdisciplines of Artificial Intelligence. For the purpose of this chapter, we will only be exploring the concept of ANNs in the context of OpenCV. It is by no means an exhaustive treatise on the subject of Artificial Intelligence.</p><p>Ultimately, we're interested in seeing ANNs work in the real world. So let's go ahead and make it happen.</p><div class="section" title="MNIST – the handwritten digit database"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec58"/>MNIST – the handwritten digit database</h2></div></div></div><p>One of the <a id="id546" class="indexterm"/>most popular resources on the <a id="id547" class="indexterm"/>Web for the training of classifiers dealing with OCR and handwritten character recognition is the MNIST database, publicly available at <a class="ulink" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>.</p><p>This particular <a id="id548" class="indexterm"/>database is a freely available resource to kick-start the creation of a program that utilizes ANNs to recognize handwritten digits.</p></div><div class="section" title="Customized training data"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec59"/>Customized training data</h2></div></div></div><p>It is <a id="id549" class="indexterm"/>always possible to build your own training data. It will take a little bit of patience but it's fairly easy; collect a vast number of handwritten digits and create images containing a single digit, making sure all the images are the same size and in grayscale.</p><p>After this, you will have to create a mechanism that keeps a training sample in sync with the expected classification.</p></div><div class="section" title="The initial parameters"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec60"/>The initial parameters</h2></div></div></div><p>Let's take a <a id="id550" class="indexterm"/>look at the individual layers in the network:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Input layer</li><li class="listitem">Hidden layer</li><li class="listitem">Output layer</li></ul></div><div class="section" title="The input layer"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec41"/>The input layer</h3></div></div></div><p>Since we're going to <a id="id551" class="indexterm"/>utilize the MNIST database, the input layer will have a size of 784 input nodes: that's because MNIST samples are 28x28 pixel images, which means 784 pixels.</p></div><div class="section" title="The hidden layer"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec42"/>The hidden layer</h3></div></div></div><p>As we have <a id="id552" class="indexterm"/>seen, there's no hard-and-fast rule for the size of the hidden layer, I've found—through several attempts—that 50 to 60 nodes yields the best result while not necessitating an inordinate amount of training data.</p><p>You can increase the size of the hidden layer with the amount of data, but beyond a certain point, there will be no advantage to that; you will also have to be prepared for your network to take hours to train (the more hidden neurons, the longer it takes to train the network).</p></div><div class="section" title="The output layer"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec43"/>The output layer</h3></div></div></div><p>The output layer will have a <a id="id553" class="indexterm"/>size of 10. This should not be a surprise as we want to classify 10 digits (0-9).</p></div></div><div class="section" title="Training epochs"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec61"/>Training epochs</h2></div></div></div><p>We will initially use <a id="id554" class="indexterm"/>the entire set of the <code class="literal">train</code> data from MNIST, which consists of over 60,000 handwritten images, half of which were written by US government employees, and the other half by high-school students. That's a lot of data, so we won't need more than one epoch to achieve an acceptably high accuracy on detection.</p><p>From there on, it is up to you to train the network iteratively on the same <code class="literal">train</code> data, and my suggestion is that you use an accuracy test, and find the epoch at which the accuracy "peaks". By doing so, you will have a precise measurement of the highest possible accuracy achieved by your network given its current configuration.</p></div><div class="section" title="Other parameters"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec62"/>Other parameters</h2></div></div></div><p>We will use a <a id="id555" class="indexterm"/>sigmoid activation function, <span class="strong"><strong>Resilient Back Propagation</strong></span> (<span class="strong"><strong>RPROP</strong></span>), and extend the termination criteria for each calculation to <a id="id556" class="indexterm"/>20 iterations instead of 10, like we did for every other operation in this book that involved <code class="literal">cv2.TermCriteria</code>.</p><div class="note" title="Note"><h3 class="title"><a id="note33"/>Note</h3><p>
<span class="strong"><strong>Important notes on train data and ANNs libraries</strong></span>
</p><p>Exploring the Internet for sources, I found an amazing article by Michael Nielsen at <a class="ulink" href="http://neuralnetworksanddeeplearning.com/chap1.html">http://neuralnetworksanddeeplearning.com/chap1.html</a>, which illustrates how <a id="id557" class="indexterm"/>to write an ANN library from scratch, and the code for this library is freely available on GitHub at <a class="ulink" href="https://github.com/mnielsen/neural-networks-and-deep-learning">https://github.com/mnielsen/neural-networks-and-deep-learning</a>; this is the source code for a book, <span class="emphasis"><em>Neural Networks and Deep Learning</em></span>, by Michael Nielsen.</p></div><p>In the <code class="literal">data</code> folder, you will find a <code class="literal">pickle</code> file, signifying data that has been saved to disk through the popular Python library, <code class="literal">cPickle</code>, which makes loading and saving the Python data a trivial task.</p><p>This pickle file is a <code class="literal">cPickle</code> library-serialized version of the MNIST data and, as it is so useful and ready to work with, I strongly suggest you use that. Nothing stops you from loading the MNIST dataset but the process of deserializing the training data is quite tedious and—strictly speaking—outside the remit of this book.</p><p>Second, I would like to point out that OpenCV is not the only Python library that allows you to use ANNs, not by any stretch of the imagination. The Web is full of alternatives that I strongly encourage you to try out, most notably <span class="strong"><strong>PyBrain</strong></span>, a library called <span class="strong"><strong>Lasagna</strong></span> (which—as an Italian—I find exceptionally attractive) and many custom-written <a id="id558" class="indexterm"/>implementations, such as the aforementioned Michael Nielsen's implementation.</p><p>Enough introductory <a id="id559" class="indexterm"/>details, though. Let's get going.</p></div><div class="section" title="Mini-libraries"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec63"/>Mini-libraries</h2></div></div></div><p>Setting up an <a id="id560" class="indexterm"/>ANN in OpenCV is not difficult, but you will almost definitely find yourself training your network countless times, in search of that elusive percentage point that boosts the accuracy of your results.</p><p>To automate this as much as possible, we will build a mini-library that wraps the OpenCV's native implementation of ANNs and lets us rerun and retrain the network easily.</p><p>Here's an example of a wrapper library:</p><div class="informalexample"><pre class="programlisting">import cv2
import cPickle
import numpy as np
import gzip

def load_data():
  mnist = gzip.open('./data/mnist.pkl.gz', 'rb')
  training_data, classification_data, test_data = cPickle.load(mnist)
  mnist.close()
  return (training_data, classification_data, test_data)

def wrap_data():
  tr_d, va_d, te_d = load_data()
  training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]
  training_results = [vectorized_result(y) for y in tr_d[1]]
  training_data = zip(training_inputs, training_results)
  validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]
  validation_data = zip(validation_inputs, va_d[1])
  test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]
  test_data = zip(test_inputs, te_d[1])
  return (training_data, validation_data, test_data)

def vectorized_result(j):
  e = np.zeros((10, 1))
  e[j] = 1.0
  return e

def create_ANN(hidden = 20):
  ann = cv2.ml.ANN_MLP_create()
  ann.setLayerSizes(np.array([784, hidden, 10]))
  ann.setTrainMethod(cv2.ml.ANN_MLP_RPROP)
  ann.setActivationFunction(cv2.ml.ANN_MLP_SIGMOID_SYM)
  ann.setTermCriteria(( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 1 ))
  return ann

def train(ann, samples = 10000, epochs = 1):
  tr, val, test = wrap_data()
  
  
  for x in xrange(epochs):
    counter = 0
    for img in tr:
      
      if (counter &gt; samples):
        break
      if (counter % 1000 == 0):
        print "Epoch %d: Trained %d/%d" % (x, counter, samples)
      counter += 1
      data, digit = img
      ann.train(np.array([data.ravel()], dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array([digit.ravel()], dtype=np.float32))
    print "Epoch %d complete" % x
  return ann, test
  
def test(ann, test_data):
  sample = np.array(test_data[0][0].ravel(), dtype=np.float32).reshape(28, 28)
  cv2.imshow("sample", sample)
  cv2.waitKey()
  print ann.predict(np.array([test_data[0][0].ravel()], dtype=np.float32))

def predict(ann, sample):
  resized = sample.copy()
  rows, cols = resized.shape
  if (rows != 28 or cols != 28) and rows * cols &gt; 0:
    resized = cv2.resize(resized, (28, 28), interpolation = cv2.INTER_CUBIC)
  return ann.predict(np.array([resized.ravel()], dtype=np.float32))</pre></div><p>Let's examine it in order. First, the <code class="literal">load_data</code>, <code class="literal">wrap_data</code>, and <code class="literal">vectorized_result</code> functions are included in Michael Nielsen's code for loading the <code class="literal">pickle</code> file.</p><p>It's a relatively <a id="id561" class="indexterm"/>straightforward loading of a <code class="literal">pickle</code> file. Most notably, though, the loaded data has been split into the <code class="literal">train</code> and <code class="literal">test</code> data. Both <code class="literal">train</code> and <code class="literal">test</code> data are arrays containing two-element tuples: the first one is the data itself; the second one is the expected classification. So we can use the <code class="literal">train</code> data to train the ANN and the <code class="literal">test</code> data to evaluate its accuracy.</p><p>The <code class="literal">vectorized_result</code> function is a very clever function that—given an expected classification—creates a 10-element array of zeros, setting a single 1 for the expected result. This 10-element array, you may have guessed, will be used as a classification for the output layer.</p><p>The first ANN-related function is <code class="literal">create_ANN</code>:</p><div class="informalexample"><pre class="programlisting">def create_ANN(hidden = 20):
  ann = cv2.ml.ANN_MLP_create()
  ann.setLayerSizes(np.array([784, hidden, 10]))
  ann.setTrainMethod(cv2.ml.ANN_MLP_RPROP)
  ann.setActivationFunction(cv2.ml.ANN_MLP_SIGMOID_SYM)
  ann.setTermCriteria(( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 1 ))
  return ann</pre></div><p>This function creates an ANN specifically geared towards handwritten digit recognition with MNIST, by specifying layer sizes as illustrated in the <span class="emphasis"><em>Initial parameters</em></span> section.</p><p>We now need a training function:</p><div class="informalexample"><pre class="programlisting">def train(ann, samples = 10000, epochs = 1):
  tr, val, test = wrap_data()
  
  
  for x in xrange(epochs):
    counter = 0
    for img in tr:
      
      if (counter &gt; samples):
        break
      if (counter % 1000 == 0):
        print "Epoch %d: Trained %d/%d" % (x, counter, samples)
      counter += 1
      data, digit = img
      ann.train(np.array([data.ravel()], dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array([digit.ravel()], dtype=np.float32))
    print "Epoch %d complete" % x
  return ann, test</pre></div><p>Again, this is <a id="id562" class="indexterm"/>quite simple: given a number of samples and training epochs, we load the data, and then iterate through the samples an x-number-of-epochs times.</p><p>The important section of this function is the deconstruction of the single training record into the <code class="literal">train</code> data and an expected classification, which is then passed into the ANN.</p><p>To do so, we utilize the <code class="literal">numpy</code> array function, <code class="literal">ravel()</code>, which takes an array of any shape and "flattens" it into a single-row array. So, for example, consider this array:</p><div class="informalexample"><pre class="programlisting">data = [[ 1, 2, 3], [4, 5, 6], [7, 8, 9]]</pre></div><p>The preceding array once "raveled", becomes the following array:</p><div class="informalexample"><pre class="programlisting">      [1, 2, 3, 4, 5, 6, 7, 8, 9] </pre></div><p>This is the format that OpenCV's ANN expects data to look like in its <code class="literal">train()</code> method.</p><p>Finally, we return both the <code class="literal">network</code> and <code class="literal">test</code> data. We could have just returned the data, but having the <code class="literal">test</code> data at hand for accuracy checking is quite useful.</p><p>The last function we need is a <code class="literal">predict()</code> function to wrap ANN's own <code class="literal">predict()</code> method:</p><div class="informalexample"><pre class="programlisting">def predict(ann, sample):
  resized = sample.copy()
  rows, cols = resized.shape
  if (rows != 28 or cols != 28) and rows * cols &gt; 0:
    resized = cv2.resize(resized, (28, 28), interpolation = cv2.INTER_CUBIC)
  return ann.predict(np.array([resized.ravel()], dtype=np.float32))</pre></div><p>This function takes an ANN and a sample image; it operates a minimum of "sanitization" by making sure the shape of the data is as expected and resizing it if it's not, and then raveling it for a successful prediction.</p><p>The file I created <a id="id563" class="indexterm"/>also contains a <code class="literal">test</code> function to verify that the network works and it displays the sample provided for classification.</p></div><div class="section" title="The main file"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec64"/>The main file</h2></div></div></div><p>This whole <a id="id564" class="indexterm"/>chapter has been an introductory journey leading us to this point. In fact, many of the techniques we're going to use are from previous chapters, so in a way the entire book has led us to this point. So let's put all our knowledge to good use.</p><p>Let's take an initial look at the file, and then decompose it for a better understanding:</p><div class="informalexample"><pre class="programlisting">import cv2
import numpy as np
import digits_ann as ANN

def inside(r1, r2):
  x1,y1,w1,h1 = r1
  x2,y2,w2,h2 = r2
  if (x1 &gt; x2) and (y1 &gt; y2) and (x1+w1 &lt; x2+w2) and (y1+h1 &lt; y2 + h2):
    return True
  else:
    return False

def wrap_digit(rect):
  x, y, w, h = rect
  padding = 5
  hcenter = x + w/2
  vcenter = y + h/2
  if (h &gt; w):
    w = h
    x = hcenter - (w/2)
  else:
    h = w
    y = vcenter - (h/2)
  return (x-padding, y-padding, w+padding, h+padding)

ann, test_data = ANN.train(ANN.create_ANN(56), 20000)
font = cv2.FONT_HERSHEY_SIMPLEX

path = "./images/numbers.jpg"
img = cv2.imread(path, cv2.IMREAD_UNCHANGED)
bw = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
bw = cv2.GaussianBlur(bw, (7,7), 0)
ret, thbw = cv2.threshold(bw, 127, 255, cv2.THRESH_BINARY_INV)
thbw = cv2.erode(thbw, np.ones((2,2), np.uint8), iterations = 2)
image, cntrs, hier = cv2.findContours(thbw.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

rectangles = []

for c in cntrs:
  r = x,y,w,h = cv2.boundingRect(c)
  a = cv2.contourArea(c)
  b = (img.shape[0]-3) * (img.shape[1] - 3)
  
  is_inside = False
  for q in rectangles:
    if inside(r, q):
      is_inside = True
      break
  if not is_inside:
    if not a == b:
      rectangles.append(r)

for r in rectangles:
  x,y,w,h = wrap_digit(r) 
  cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)
  roi = thbw[y:y+h, x:x+w]
  
  try:
    digit_class = int(ANN.predict(ann, roi.copy())[0])
  except:
    continue
  cv2.putText(img, "%d" % digit_class, (x, y-1), font, 1, (0, 255, 0))

cv2.imshow("thbw", thbw)
cv2.imshow("contours", img)
cv2.imwrite("sample.jpg", img)
cv2.waitKey()</pre></div><p>After the initial usual imports, we import the mini-library we created, which is stored in <code class="literal">digits_ann.py</code>.</p><p>I find it good practice <a id="id565" class="indexterm"/>to define functions at the top of the file, so let's examine those. The <code class="literal">inside()</code> function determines whether a rectangle is entirely contained in another rectangle:</p><div class="informalexample"><pre class="programlisting">def inside(r1, r2):
  x1,y1,w1,h1 = r1
  x2,y2,w2,h2 = r2
  if (x1 &gt; x2) and (y1 &gt; y2) and (x1+w1 &lt; x2+w2) and (y1+h1 &lt; y2 + h2):
    return True
  else:
    return False</pre></div><p>The <code class="literal">wrap_digit()</code> function takes a rectangle that surrounds a digit, turns it into a square, and centers it on the digit itself, with 5-point padding to make sure the digit is entirely contained in it:</p><div class="informalexample"><pre class="programlisting">def wrap_digit(rect):
  x, y, w, h = rect
  padding = 5
  hcenter = x + w/2
  vcenter = y + h/2
  if (h &gt; w):
    w = h
    x = hcenter - (w/2)
  else:
    h = w
    y = vcenter - (h/2)
  return (x-padding, y-padding, w+padding, h+padding)</pre></div><p>The point of this function will become clearer later on; let's not dwell on it too much at the moment.</p><p>Now, let's create the network. We will use 58 hidden nodes, and train over 20,000 samples:</p><div class="informalexample"><pre class="programlisting">ann, test_data = ANN.train(ANN.create_ANN(58), 20000)</pre></div><p>This is good enough for a preliminary test to keep the training time down to a minute or two (depending on the processing power of your machine). The ideal is to use the full set of training data (50,000), and iterate through it several times, until some convergence is reached (as we discussed earlier, the accuracy "peak"). You would do this by calling the following function:</p><div class="informalexample"><pre class="programlisting">ann, test_data = ANN.train(ANN.create_ANN(100), 50000, 30)</pre></div><p>We can now prepare the data to test. To do that, we're going to load an image, and clean up a little:</p><div class="informalexample"><pre class="programlisting">path = "./images/numbers.jpg"
img = cv2.imread(path, cv2.IMREAD_UNCHANGED)
bw = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
bw = cv2.GaussianBlur(bw, (7,7), 0)</pre></div><p>Now that we have a <a id="id566" class="indexterm"/>grayscale smoothed image, we can apply a threshold and some morphology operations to make sure the numbers are properly standing out from the background and relatively cleaned up for irregularities, which might throw the prediction operation off:</p><div class="informalexample"><pre class="programlisting">ret, thbw = cv2.threshold(bw, 127, 255, cv2.THRESH_BINARY_INV)
thbw = cv2.erode(thbw, np.ones((2,2), np.uint8), iterations = 2)</pre></div><div class="note" title="Note"><h3 class="title"><a id="note34"/>Note</h3><p>Note the threshold flag, which is for an inverse binary threshold: as the samples of the MNIST database are white on black (and not black on white), we turn the image into a black background with white numbers.</p></div><p>After the morphology operation, we need to identify and separate each number in the picture. To do this, we first identify the contours in the image:</p><div class="informalexample"><pre class="programlisting">image, cntrs, hier = cv2.findContours(thbw.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</pre></div><p>Then, we iterate through the contours, and discard all the rectangles that are entirely contained in other rectangles; we only append to the list of good rectangles the ones that are not contained in other rectangles and are also not as wide as the image itself. In some of the tests, <code class="literal">findContours</code> yielded the entire image as a contour itself, which meant no other rectangle passed the <code class="literal">inside</code> test:</p><div class="informalexample"><pre class="programlisting">rectangles = []

for c in cntrs:
  r = x,y,w,h = cv2.boundingRect(c)
  a = cv2.contourArea(c)
  b = (img.shape[0]-3) * (img.shape[1] - 3)
  
  is_inside = False
  for q in rectangles:
    if inside(r, q):
      is_inside = True
      break
  if not is_inside:
    if not a == b:
      rectangles.append(r)</pre></div><p>Now that we have a list of good rectangles, we can iterate through them and define a region of interest for each of the rectangles we identified:</p><div class="informalexample"><pre class="programlisting">for r in rectangles:
  x,y,w,h = wrap_digit(r) </pre></div><p>This is where the <code class="literal">wrap_digit()</code> function we defined at the beginning of the program comes into play: we need to pass a square region of interest to the predictor function; if we simply resized a rectangle into a square, we'd ruin our test data.</p><p>You may wonder why think of the number one. A rectangle surrounding the number one would be very narrow, especially if it has been drawn without too much of a lean to either side. If you simply <a id="id567" class="indexterm"/>resized it to a square, you would "fatten" the number one in such a way that nearly the entire square would turn black, rendering the prediction impossible. Instead, we want to create a square around the identified number, which is exactly what <code class="literal">wrap_digit()</code> does.</p><p>This approach is quick-and-dirty; it allows us to draw a square around a number and simultaneously pass that square as a region of interest for the prediction. A purer approach would be to take the original rectangle and "center" it into a square <code class="literal">numpy</code> array with rows and columns equal to the larger of the two dimensions of the original rectangle. The reason for this is you will notice that some of the square will include tiny bits of adjacent numbers, which can throw the prediction off. With a square created from a <code class="literal">np.zeros()</code> function, no impurities will be accidentally dragged in:</p><div class="informalexample"><pre class="programlisting">  cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)
  roi = thbw[y:y+h, x:x+w]
  
  try:
    digit_class = int(ANN.predict(ann, roi.copy())[0])
  except:
    continue
  cv2.putText(img, "%d" % digit_class, (x, y-1), font, 1, (0, 255, 0))</pre></div><p>Once the prediction for the square region is complete, we draw it on the original image:</p><div class="informalexample"><pre class="programlisting">cv2.imshow("thbw", thbw)
cv2.imshow("contours", img)
cv2.imwrite("sample.jpg", img)
cv2.waitKey()</pre></div><p>And that's it! The <a id="id568" class="indexterm"/>final result will look similar to this:</p><div class="mediaobject"><img src="../Images/image00253.jpeg" alt="The main file"/></div><p style="clear:both; height: 1em;"> </p></div></div>
<div class="section" title="Possible improvements and potential applications" id="aid-1Q5IA1"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec55"/>Possible improvements and potential applications</h1></div></div></div><p>We have illustrated how to build an ANN, feed it training data, and use it for classification. There are a number of aspects we can improve, depending on the task at hand, and a number of potential applications of our new-found knowledge.</p><div class="section" title="Improvements"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec65"/>Improvements</h2></div></div></div><p>There are a <a id="id569" class="indexterm"/>number of improvements that can be applied to this approach, some of which we have already discussed:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">For example, you could enlarge your dataset and iterate more times, until a performance peak is reached</li><li class="listitem">You could also experiment with the several activation functions (<code class="literal">cv2.ml.ANN_MLP_SIGMOID_SYM</code> is not the only one; there is also <code class="literal">cv2.ml.ANN_MLP_IDENTITY</code> and <code class="literal">cv2.ml.ANN_MLP_GAUSSIAN</code>)</li><li class="listitem">You could utilize different training flags (<code class="literal">cv2.ml.ANN_MLP_UPDATE_WEIGHTS</code>, <code class="literal">cv2.ml.ANN_MLP_NO_INPUT_SCALE</code>, <code class="literal">cv2.ml.ANN_MLP_NO_OUTPUT_SCALE</code>), and training methods (back propagation or resilient back propagation)</li></ul></div><p>Aside from that, bear in mind one of the mantras of software development: there is no single best technology, there is only the best tool for the job at hand. So, careful analysis of the application requirements will lead you to the best choices of parameters. For example, not everyone draws digits the same way. In fact, you will even find that some countries draw numbers in a slightly different way.</p><p>The MNIST database was compiled in the US, in which the number seven is drawn like the character 7. But you will find that the number 7 in Europe is often drawn with a small horizontal line half way through the diagonal portion of the number, which was introduced to distinguish it from the number 1.</p><div class="note" title="Note"><h3 class="title"><a id="note35"/>Note</h3><p>For a more <a id="id570" class="indexterm"/>detailed overview of regional handwriting variations, check the Wikipedia article on the subject, which is a good introduction, available at <a class="ulink" href="https://en.wikipedia.org/wiki/Regional_handwriting_variation">https://en.wikipedia.org/wiki/Regional_handwriting_variation</a>.</p></div><p>This means the MNIST database has limited accuracy when applied to European handwriting; some numbers will be classified more accurately than others. So you may end up creating your own dataset. In almost all circumstances, it is preferable to utilize the <code class="literal">train</code> data that's relevant and belongs to the current application domain.</p><p>Finally, remember <a id="id571" class="indexterm"/>that once you're happy with the accuracy of your network, you can always save it and reload it later, so it can be utilized in third-party applications without having to train the ANN every time.</p><div class="section" title="Potential applications"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec44"/>Potential applications</h3></div></div></div><p>The preceding <a id="id572" class="indexterm"/>program is only the foundation of a handwriting recognition application. Straightaway, you can quickly extend the earlier approach to videos and detect handwritten digits in real-time, or you could train your ANN to recognize the entire alphabet for a full-blown OCR system.</p><p>Car registration plate detection seems like an obvious extension of the lessons learned to this point, and it should be an even easier domain to work with, as registration plates use consistent characters.</p><p>Also, for your own edification or business purposes, you may try to build a classifier with ANNs and plain SVMs (with feature detectors such as SIFT) and see how they benchmark.</p></div></div></div>
<div class="section" title="Summary" id="aid-1R42S1"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec56"/>Summary</h1></div></div></div><p>In this chapter, we scratched the surface of the vast and fascinating world of ANNs, focusing on OpenCV's implementation of it. We learned about the structure of ANNs, and how to design a network topology based on application requirements.</p><p>Finally, we utilized various concepts that we explored in the previous chapters to build a handwritten digit recognition application.</p><div class="section" title="To boldly go…"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec66"/>To boldly go…</h2></div></div></div><p>I hope you enjoyed the journey through the Python bindings for OpenCV 3. Although covering OpenCV 3 would take a series of books, we explored very fascinating and futuristic concepts, and I encourage you to get in touch and let me and the OpenCV community know what your next groundbreaking computer-vision-based project is!</p></div></div></body></html>