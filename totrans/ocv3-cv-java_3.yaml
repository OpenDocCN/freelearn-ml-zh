- en: Chapter 3. Image Filters and Morphological Operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After learning the basics of setting up OpenCV for Java and dealing with a graphical
    user interface, it is time to explore some of the core operators in image processing.
    Some of them come from signal processing and we call them filters, as they usually
    help you to get away with noise from images. It is important to know that several
    digital filters have their optical counterparts. Other operators play a useful
    role when dealing with binary images, such as the morphological operators, which
    will help you to isolate regions or glue some of them together. We will also cover,
    in detail, the famous **bucket fill tool**, which is very useful in segmentation.
    When dealing with large images, it is important to know how image pyramids can
    help you decrease your image size without losing important information and by
    achieving performance. We will finish this chapter with one of the simplest and
    most useful techniques for segmentation, which is applying a threshold to separate
    regions as well as studying a dynamic threshold that will not suffer much from
    lighting problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Smoothing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Morphological operators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flood filling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image pyramids
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thresholding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to perform several filtering procedures
    over an image, such as removing noise, growing, shrinking and filling some areas,
    as well as deciding whether some pixels fit or not in accordance with a given
    criteria.
  prefs: []
  type: TYPE_NORMAL
- en: Smoothing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just like in one-dimensional signals, we are always susceptible to receiving
    some noise in our images and we generally apply some preprocessing filters to
    them before we perform our main work on the images. We can consider noise as a
    random variation of color or brightness information that is not present in the
    imaged object, which can take place undesirably due to a sensor and circuitry
    of a digital camera or scanner. This section uses the ideas of low-pass filter
    kernels to smoothen our images. These filters remove high frequency content, such
    as edges and noises, although some techniques allow edges not to be blurred. We
    will cover the four main image filters available in OpenCV: averaging, Gaussian,
    median filtering, and bilateral filtering.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**2D Kernel** **Convolution** is a form of mathematical convolution. An output
    image is calculated by sweeping each of the pixels of a given image and applying
    a kernel operator to them, yielding an output pixel for each resulting operation.
    For instance, the kernel operator can be a 3 x 3 matrix of 1s divided by 9\. This
    way, each output pixel will be the average value of the 9 neighbor pixels for
    each pixel in the input image, yielding an average output image.'
  prefs: []
  type: TYPE_NORMAL
- en: Averaging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Most of the blurring techniques will use a 2D kernel convolution to filter
    images. The simplest idea is to have a 3 x 3 kernel that has a total of 9 pixels.
    Suppose we want to have the average value of 9 pixels, we will only need to add
    them and divide by 9\. This is accomplished by the convolution with the following
    kernel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Averaging](img/3972OS_03_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to apply this transformation, we will use Imgproc''s `blur` function.
    Its syntax is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The parameters are, simply, the source image, destination, and the kernel size,
    which is as simple as `new Size(3.0, 3.0)` for our 3 x 3 kernel. You can optionally
    add the `Point` anchor parameter, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding line will let you position the anchor as well as an `int borderType`
    integer variable outside the center point. This `borderType` parameter lets you
    define how you want the behavior when part of the kernel is inside and outside
    the image. Note that in the first row, the preceding kernel will look for values
    that will be on top of the row, so OpenCV will need to extrapolate them. There
    are a few options available to extrapolate borders. From the documentation, we
    have the following types of borders, all available from `Core` constants, for
    instance: `Core.BORDER_REPLICATE`. For example, consider `|` as one of the image
    borders and `abcdefgh` as pixel values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The default value is `Core.BORDER_DEFAULT` that maps to `Core.BORDER_REFLECT_101`.
    For more information on how to use this function, look for the source code of
    this chapter''s `imageFilter` project. The following is a screenshot of the main
    application, which lets you try out each of these filters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Averaging](img/3972OS_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that this application also provides some simple Gaussian noise, whose probability
    density function is equal to that of the normal distribution, to see the benefits
    of each filter.
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The idea behind Gaussian is the same as average filtering except for the fact
    that instead of using the same weight for each of the pixels, a two-dimensional
    Gaussian function is used for the kernel that gives the highest weightage to the
    pixel in the center. The following graph displays the behavior of a 2D Gaussian
    curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gaussian](img/3972OS_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In order to use this function, employ the following basic signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `Mat src` and `Mat dst` parameters are straightforward since they describe
    the input and output images. The `Size ksize` parameter describes the kernel's
    width and height. Hence, if you want to set its size, this parameter must be positive
    and odd, so that the kernel can be symmetrical and have a center. In case you
    set the parameter to zero, the size will be calculated from `double sigmaX`. Sigma
    is its standard deviation, which is roughly *half width at half max* of the Gaussian
    value, which means that it is half the width of the Gaussian value when its height
    is half the highest Gaussian value. Optionally, you can also provide the fifth
    parameter as `sigmaY`, which is the standard deviation for the *y* axis. In case
    you don't use this parameter, `sigmaY` will be equal to `sigmaX`. Also, if both
    `sigmaX`, and `sigmaY` are zero, they are computed from the kernel's width and
    height. The `getGaussianKernel` function returns all the Gaussian coefficients
    in case they are required. A sixth parameter can also be given to the `GaussianBlur`
    function, which is how borders will behave. This parameters works just like the
    `int borderType` parameter from the *Averaging* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of how to use `GaussianBlur` can be taken from the sample `imageFilter`
    project from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding line sets sigma to `0` and makes the function calculate it from
    the kernel''s size by using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, `ksize` is the kernel's aperture size, which would be `3` for our example.
  prefs: []
  type: TYPE_NORMAL
- en: Median filtering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another idea to make a filter is to select the median pixel in a kernel instead
    of the mean value, which is to select the pixel that would be in the middle of
    a line of intensity-sorted pixels. This is accomplished by using the following
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `Mat src` and `dst` parameters are the input and output images, respectively,
    while `int ksize` is the kernel's aperture size, which must be odd and greater
    than 1.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, the image noise is very high and it can appear as large isolated
    outlier points, which would cause a noticeable average shift. In order to overcome
    these problems, a median filter can be used to ignore these outliers.
  prefs: []
  type: TYPE_NORMAL
- en: Bilateral filtering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While median, Gaussian, and averaging filters tend to smoothen noise and edges,
    the main advantage of using bilateral filtering is the fact that it will preserve
    them, since they present important information, such as, the boundary of a cell
    in some medical imaging, which should not be filtered out. The tricky part of
    this filter is that it considers both the spatial distance and pixel intensity
    difference when calculating the average, which means that it will not include
    pixels that have intensity differences above a given threshold when calculating
    the output image. Note the effect of bilateral filtering in a marble checkboard
    using the `imageFilter` sample project from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Bilateral filtering](img/3972OS_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The right-hand image shows a filtered marble while preserving the edges, something
    that does not happen when you use other filters. One of the drawbacks of this
    method is that soft texture details tend to be removed, like in the white square
    of the third line and second column of the previous image. The function signature
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: While `Mat src` and `Mat dst` are the input and output images, respectively,
    the `int d` parameter is the diameter of the considered neighborhood. If it is
    non-positive, the diameter will be calculated from the `sigmaSpace` parameter.
    The filter sigma in color space is defined by the `double sigmaColor` parameter,
    which means that for higher values, farther colors in the neighborhood will be
    considered when calculating the output color of a pixel, creating a watercolor
    effect. `Double sigmaSpace` is the sigma value in the coordinate space, which
    means that as long as colors are not skipped because of `sigmaColor`, they will
    have pretty much the same average component as in Gaussian. Remember that the
    watercolor effect can be very useful as a first step when segmenting images. If
    you need control over the border type, the `int borderType` parameter can be added
    as the last one, like in the previous filters.
  prefs: []
  type: TYPE_NORMAL
- en: When considering intensity differences to calculate the new average value of
    a pixel, another Gaussian function is used. Note that because of this additional
    step, bilateral filtering should be used with smaller kernel sizes (for instance,
    5) when dealing with real-time images, while a kernel of size 9 might be good
    enough for offline applications. Note that when using a 3 x 3 neighborhood for
    a kernel of size 3, only 9 pixels are verified in the convolution of each pixel.
    On the other hand, when using a kernel of size 9, 9 x 9 pixels are verified, which
    makes the algorithm search for around 81 pixels. This could take 9 times longer.
  prefs: []
  type: TYPE_NORMAL
- en: Morphological operators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some image operations are called morphological operations, since they change
    the shape of an underlying object. We will discuss erosion and dilation, which
    are some very useful morphological transformations in this section as well as
    some derived transformations. They usually appear in the context of isolating
    elements, removing noise, and joining distanced elements in an image.
  prefs: []
  type: TYPE_NORMAL
- en: 'These operators work through the convolution of a given kernel with the image.
    This kernel is described with an anchor point, which is the one that is probed
    against a region of pixels, depending on its shape:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Morphological operators](img/3972OS_03_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding image shows a bright region on the image, which we will call **A**.
    Note that the complement region is completely dark. Our kernel is made of a 3
    x 3 block with an anchor at its center, described as **B**. The **C** region is
    the result of applying the erosion morphological transformation over the image.
    Note that this operation takes place when you scan each pixel of the image, center
    the kernel anchor on each of these pixels, and then retrieve the local minimum
    over the kernel area. Note that erosion will reduce the bright areas.
  prefs: []
  type: TYPE_NORMAL
- en: The opposite operation is called dilation and the difference between these two
    is that in dilation, instead of computing the local minimum over the kernel area
    it will compute the local maximum over that area. This operation will expand a
    bright region of 3 x 3 square blocked kernels.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to get a better picture of how these operators work, a good idea is
    to try the `morphology` project from this chapter''s source code. It is basically
    OpenCV''s official C++ `morphology2` example translated to Java with some minor
    GUI enhancements. Note that in case of multichannel images, each channel is processed
    independently. The following screenshot shows the running application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Morphological operators](img/3972OS_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that our kernel bounding box is 2 times the kernel size slider parameter
    plus 1, so, if the kernel size parameter is selected as 1, we will have a 3 x
    3 kernel bounding box. We also described our example in terms of a square kernel,
    but it could be of any shape, so the shape parameter is also there for us to choose
    from. In order to create these kernels easily, Imgproc's `getStructuringElement`
    function is used. This function will take the kernel's shape, its size, and zero
    indexed anchor position as its parameters. The kernel shape can be `Imgproc.CV_SHAPE_RECT`
    (for rectangles), `Imgproc.CV_SHAPE_ELLIPSE` (for ellipses), or `Imgproc.CV_SHAPE_CROSS`
    (for a cross-shaped kernel).
  prefs: []
  type: TYPE_NORMAL
- en: 'We have put all image operations in the `ImageProcessor` class, which we will
    highlight in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As all our methods create a kernel in the same way, we have extracted the `getKernelFromShape`
    method, which will simply call the `getStructuringElement` function with the size
    described in the preceding code. As we have a custom kernel, we will call the
    overloaded `Imgproc.erode` function with the input image, output image, and kernel
    as a third parameter. The following screenshot is a result of the erosion function
    over a given input image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Morphological operators](img/3972OS_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note that this operator is frequently used to remove speckle noise from an
    image, as it will be eroded to nothing, while larger regions that contain important
    information will practically not be affected. Note that smoothing filters will
    not completely remove speckle noise as they tend to decrease its amplitude. Also
    pay attention that these operations are sensitive to kernel size, so a size adjustment
    and some experimenting is required. We can also check out the result of applying
    dilation in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Morphological operators](img/3972OS_03_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that besides making areas thicker, the dilate morphological transformation
    is also very useful in searching for connected components, which are large regions
    of similar pixel intensity. It might be necessary when a large region is broken
    into smaller ones because of shadows, noise, or other effects, as can be seen
    in the lower part of the image in the preceding screenshot. Applying dilation
    will make them link together to a bigger element.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also derived morphological transformations, which are **open** and **close**.
    Open is defined by erosion followed by a dilation, while in a close operation,
    the dilation happens first. The following is a screenshot of an open transform:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Morphological operators](img/3972OS_03_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This operation is generally used while counting regions from a binary image.
    For example, we might use it to separate regions that are too near each other
    before counting them. Note that in the bottom part of our example, only larger
    areas have survived the operation while preserving the non-connectedness between
    the large areas that were apart. On the other hand, we can see the effects of
    applying the close operation to the same image, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Morphological operators](img/3972OS_03_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Check whether this tends to connect nearby regions. Depending on the kernel
    size, it might be useful in connected component algorithms to reduce segments
    generated by noise. Unlike erosion and dilation, both open and close morphological
    transformations tend to preserve the areas of their regions of interest.
  prefs: []
  type: TYPE_NORMAL
- en: Flood filling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another very important algorithm for segmentation is flood fill, also known
    as region growing. Most of you who have already worked with popular computer graphic
    programs, such as Microsoft Paint or GIMP will have probably used the bucket fill
    or paint bucket tool, which fills an area with a color. Although it might look
    like a very simple algorithm at first sight, it has a very interesting implementation
    and has several parameters that can make it work well to segment images.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind the algorithm is to check for connected components, which are
    the areas with similar color or brightness, starting from a given point—the so-called
    seed point—and then examining this particular point's neighbors. These can include
    either 4 (north, south, east, and west) or 8 neighbors (north, north-east, east,
    south-east, south, south-west, west, and north-west) that check for a condition
    and then recursively, call the same procedure on each of the neighbors in case
    they have passed that condition. It will, naturally, add that point to the given
    connected component in case the condition is true. We generally seek for pixels
    that are either like the seed point or like their neighbor points, depending on
    which mode of flood fill will operate. We call it a fixed range when pixels are
    compared against the seed point and we call it a floating range when pixels are
    compared against neighbor pixels. This condition also accepts lower difference
    *loDiff* and higher difference *upDiff* parameters, which enter in the condition
    according to the *src(x',y') – loDiff < src (x,y) < src(x',y') + upDiff* equation.
    In this equation, *src(x,y)* is the value of the pixel at the *x*, *y* coordinates
    that are tested to check whether it belongs to the same domain as the seed point,
    while *src(x',y')* is the value of one of the pixels that is already known to
    belong to that component in case of a grayscale image operating in a floating
    range. In case we have a fixed range flood fill, the equation turns into *src(seed.x,seed.y)
    – loDiff < src (x,y) < src(seed.x,seed.y) + upDiff*, where *seed.x* and *seed.y*
    are the seed's coordinates. Also note that in case of a colored image, each of
    the pixel's components are tested against the condition, while *loDiff* and *highDiff*
    are tridimensional scalars. All in all, a new pixel will be added to the domain
    in case its brightness or color is close enough to one of its neighbors that already
    belongs to the connected component in case of a floating range flood fill or close
    enough to the seed's properties in the case of a fixed range one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The flood fill''s signature is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Mat image` parameter is the input/output `Mat` containing the image to
    perform the flood fill, while `Mat mask` is a single channel 8-bit mat 2 rows
    taller and 2 columns wider than `Mat image`, for performance reasons. The `Point
    seedpoint` parameter contains the coordinates of the seed point, while `Rect rect`
    is an output rectangle with the smallest bounding box that contains the segmented
    area. The `Scalar loDiff` and `upDiff` parameters are discussed in the preceding
    condition. The `int flags` parameter contains options for the operating mode of
    the algorithm. The source code containing a *façade* class for the `floodFill`
    method is available in the `floodfill` project in this chapter. The following
    is a screenshot of the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Flood filling](img/3972OS_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: On the left-hand side of the preceding screenshot, there is a `JLabel` like
    the one explained in [Chapter 2](ch02.html "Chapter 2. Handling Matrices, Files,
    Cameras, and GUIs"), *Handling Matrices, Files, Cameras, and GUIs*, used to load
    images, but this one has `MouseListener` that sends the captured clicks to the
    `FloodFillFacade` class. On the right-hand side of the preceding screenshot, the
    mask is shown in case the **Mask** radio button is turned on. The algorithm operation
    mode is chosen through the `Range radio` buttons, which will be relative (checks
    the conditions against neighbors), fixed (the condition is probed against the
    seed), or null (when `loDiff` and `hiDiff` are both zero). A radio button for
    connectivity is also available for 4 or 8 neighbors, while the lower and upper
    thresholds refer to the `loDiff` and `hiDiff` parameters, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'While most fields from `FloodFillFacade` are just `getters` and `setters`,
    the flag configuration is something that you need to pay attention to. Note that
    a *façade* is just an object that creates a simplified interface to a larger part
    of code, making it easier to use. Here are some important pieces of `FloodFillFacade`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here, firstly, `newVal` is created as the new color that is to be filled in
    the connected component. Java random classes are used to generate the color and
    in case it's a grayscale image, it is converted to grayscale. Then, we set the
    `lowerDifference` and `higherDifference` scalars, which will be used in accordance
    with the equations described previously. Then, the `flags` variable is defined.
    Note that connectivity is set on lower bits, while `newMaskVal` is shifted to
    the left 8 times. This parameter is the color used to fill the mask in case it's
    being used. Then, in case a fixed range is required for flood fill, its flag is
    set. We are then able to chose from the masked or unmasked version of flood fill.
    Pay attention to `new Mat()`, which is passed when does not use a mask. Observe
    that the `seedPoint` parameter is built from the given coordinates from our `MouseListener`.
  prefs: []
  type: TYPE_NORMAL
- en: Image pyramids
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Image pyramids are simply a collection of images obtained by downsampling an
    original image, so that each image is one-fourth the area of its predecessor.
    It is mainly used in image segmentation, since it can generate a very meaningful
    representation of the image in low resolution, so that a time consuming algorithm
    can run on it. This makes it easy for us to map this result back to a higher resolution
    image in the pyramid and makes it possible to refine the results there. Besides,
    an approximation to a Laplacian, by means of difference of Gaussians, can be generated.
    Note that a Laplacian image is the one that will show its edges.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to produce the downsample image, which we will call the layer `i+1`
    in the Gaussian pyramid (`Gi+1`), we first convolve `Gi` with a Gaussian kernel,
    just like in Gaussian filtering, followed by removing every even numbered row
    and column. Then, we yield an image with one quarter of the area of the above
    layer. Averaging before downsampling is important because this way, information
    from odd numbered columns and rows gets captured. The function to get a downsampled
    image has the following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Mat src` and `Mat dst` parameters are the input and output images. Note
    that the output image will have a width of `(src.width+1)/2` and a height of `(src.height+1)/2`,
    where `/` denotes an integer division. You should be careful when working with
    odd dimensions, since an upsampled image generated from a downsampled one will
    not have the same dimensions. Take for instance, an 11 x 11 image. When you use
    `pyrDown`, it will become a 6 x 6 image. In case you upsample it, it will become
    a 12 x 12 image, so you can''t add or subtract it from the original image. Note
    that when using `pyrDown`, a 5 x 5 Gaussian kernel is used. In case you want,
    the `pyrDown` function is overloaded with the `Size dstsize` and `int borderType`
    properties. The `dstsize` property will allow you to define the output image size,
    but you must satisfy the following conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This means that you won't have much freedom when deciding the output image size.
    Also, `borderType` follows the same considerations as those are given in the *Smoothing*
    section.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the `pyrUp` function will upsample an image and then blur
    it. First, it will inject zero rows and columns on even locations and then, it
    convolve with the same kernel from the pyramid down operation. Note that `pyrDown`
    is a transformation that loses information, so `pyrUp` won''t be able to recover
    the original image. Its usage is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Also, its parameters are just like the `pyrDown` parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In case you want to build the Laplacian, just note that it can be achieved
    by using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image pyramids](img/3972OS_03_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '`UP` is the upsampling operation and `⊗G5` is the convolution with a 5 x 5
    Gaussian kernel. Since `pyrUp` has already been implemented as an upsampling followed
    by a Gaussian blurring, all we need to do is downsample the original image, upsample
    it, and then subtract it from the original image. This can be accomplished by
    using the following code, as it appears in this chapter''s `imagePyramid` sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we assume that `image` is the image we are working on.
    Be careful when upsampling and then subtracting an image, since if the original
    image dimension is odd, they will have different dimensions. The `Core.subtract`
    function simply subtracts one image from another, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image pyramids](img/3972OS_03_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In order to see some code working with pyramids, consider checking out this
    chapter's `imagePyramid` project. The preceding screenshot shows the application
    running the Laplacian filter. Also, play with the buttons to get a feeling of
    how pyramids work.
  prefs: []
  type: TYPE_NORMAL
- en: Thresholding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the simplest methods of segmenting a grayscale image is using the threshold
    technique. It will basically set pixels below a given value as belonging to the
    interested object and the other pixels as not being part of it. Although it might
    suffer from illumination issues as well as problems that arise from variation
    inside the object, this can be enough when segmenting text in a page scan for
    OCR or to find a checkboard when calibrating the camera. Besides, some more interesting
    approaches, such as the adaptive threshold, can also yield good results in images
    that suffer from non-homogeneous lightning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Basic thresholding is accomplished by means of Imgproc''s `threshold` function,
    whose signature is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Mats src` and `dst` parameters are the input and output matrices, while
    `thresh` is the level used to threshold the image. double maxval is only used
    in the `Binary` and `Binary_Inv` modes and this will be explained in the following
    table. The `type` are Imgproc''s constants used to describe the thresholding type,
    as in the following table, when tested in the next condition, the source pixel
    value is greater than the given threshold:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Thresholding type | Output when true | Output when false |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `CV_THRESH_BINARY` | `maxval` | `0` |'
  prefs: []
  type: TYPE_TB
- en: '| `CV_THRESH_BINARY_INV` | `0` | `maxval` |'
  prefs: []
  type: TYPE_TB
- en: '| `CV_THRESH_BINARY` | `threshold` | `source value` |'
  prefs: []
  type: TYPE_TB
- en: '| `CV_TOZERO` | `source value` | `0` |'
  prefs: []
  type: TYPE_TB
- en: '| `CV_TOZERO_INV` | `0` | `source value` |'
  prefs: []
  type: TYPE_TB
- en: 'The following diagram will help you to easily understand the preceding table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Thresholding](img/3972OS_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When thresholding, it is important to experiment with several values using,
    for instance, a slider bar. The sample project `threshold` from this chapter makes
    it really easy to change the function''s arguments and test the results. A screenshot
    of the project is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Thresholding](img/3972OS_03_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that although the apple might pose a simple problem for segmentation, when
    applying the binary thresholding method, the apple is almost completely identified,
    except for the lighting spot above the middle line, which clearly has pixels above
    the 205 level, since they are almost pure white, which would be the 255 level.
    Besides, the shadow area under the apple is also identified as belonging to it.
    Aside from these minor problems, it is simple to use and will generally be part
    of one of the steps in any computer vision application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another interesting approach to this type of segmentation is related to the
    use of a dynamic threshold value. Instead of using a given value, the threshold
    is calculated as a mean of a square block around each pixel minus a given constant.
    This method is implemented in OpenCV through the `adaptiveThreshold` function,
    which has the following signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Mat src` and `dst` parameters are the input and output matrices, respectively.
    `Maxvalue` is used the same way as the ordinary threshold function, which is described
    in the preceding section. The adaptive method can either be `ADAPTIVE_THRESH_MEAN_C`
    or `ADAPTIVE_THRESH_GAUSSIAN_C`. The first one will calculate the mean as the
    pixel value sum divided by the number of pixels in the block, while the latter
    will use Gaussian weighting for the average. `BlockSize` is the square `blockSize`
    by the `blockSize` region used for the mean whose value must be odd and greater
    than 1\. The `C` constant is the value subtracted from the mean to compose the
    dynamic threshold. Note the result obtained for the same image with the adaptive
    threshold using `blocksize` of `13` and a constant `C` of `6`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Thresholding](img/3972OS_03_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that the shadow area is now much better, although the irregular texture
    from the apple can cause other problems. The sample code uses a binary and `ADAPTIVE_THRESH_MEAN_C`
    adaptive thresholding, but changing it for Gaussian is just a matter of changing
    the type parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter explained the theory and practice of basic image processing operations
    that will be required in any computer vision project. We started with filters
    that work with simple average or using a Gaussian weighting as well as a median
    and discussed the interesting bilateral filter, which maintains edges. Then, we
    explored the important morphological operators, such as erosion, dilation, opening,
    and closing, which appear in the context of isolating elements, removing noise,
    and joining distanced elements in an image. We followed this with the well-known
    paint bucket operation through flood filling. Then, we explored time and processing
    saving image pyramids, which make segmentation faster in higher levels by decreasing
    the image area to one quarter in each layer. We finally explained the important
    image segmentation technique called thresholding and tested the adaptive thresholding
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will focus on important image transforms, which will
    allow us to find edges, lines, and circles in images. Then, you will learn stretch,
    shrink, warp, and rotate operations, which will be followed by the Fourier transform,
    which is a nice tool to change image from the spatial domain to the frequency
    domain. Finally, we will check out integral images, which boost some face-tracking
    algorithms.
  prefs: []
  type: TYPE_NORMAL
