- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Building Better Learners
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建更好的学习者
- en: When a sports team falls short of meeting its goal—whether it is to obtain an
    Olympic gold medal, a league championship, or a world record time—it must search
    for possible improvements. Imagine that you’re the team’s coach. How would you
    spend your practice sessions? Perhaps you’d direct the athletes to train harder
    or train differently in order to maximize every bit of their potential. You might
    also focus on teamwork to use each athlete’s strengths and weaknesses more smartly.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当一支运动队未能达到其目标时——无论是获得奥运金牌、联赛冠军还是世界纪录时间——它必须寻找可能的改进。想象一下你是这支球队的教练。你会在训练中如何安排？也许你会指导运动员更加努力或以不同的方式训练，以最大限度地发挥他们的潜力。你也可能会专注于团队合作，更明智地利用每位运动员的优势和劣势。
- en: Now imagine that you’re training a championship machine learning algorithm.
    Perhaps you hope to compete in machine learning competitions or maybe you simply
    need to outperform business competitors. Where do you begin? Despite the different
    context, the strategies for improving a sports team’s performance are like those
    used for improving the performance of statistical learners. As the coach, it is
    your job to find the combination of training techniques and teamwork skills that
    allow the machine learning project to meet your performance goals.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下你正在训练一个冠军机器学习算法。也许你希望参加机器学习竞赛，或者你可能只是需要超越商业竞争对手。你从哪里开始？尽管背景不同，提高运动队表现的战略与提高统计学习器表现的战略相似。作为教练，你的任务是找到训练技巧和团队合作技能的组合，使机器学习项目能够达到你的性能目标。
- en: 'This chapter builds on the material covered throughout this book to introduce
    techniques that improve the predictive ability of learning algorithms. You will
    learn:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章基于本书所涵盖的内容，介绍了提高学习算法预测能力的技巧。你将学习：
- en: Techniques for automating model performance tuning by systematically searching
    for the optimal set of training conditions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过系统地搜索最佳训练条件集来自动化模型性能调整的技术
- en: Methods for combining models into groups that use teamwork to tackle tough learning
    tasks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型组合成团队，利用团队合作解决困难的学习任务的方法
- en: How to use and differentiate among popular variants of decision trees that have
    become popular due to their impressive performance
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用并区分因表现卓越而流行的决策树的不同变体
- en: None of these methods will be successful for every problem. Yet looking at the
    winning entries to machine learning competitions, you’ll likely find at least
    one of them has been employed. To be competitive, you too will need to add these
    skills to your repertoire.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法并不适用于每个问题。然而，查看机器学习竞赛的获胜作品，你可能会发现至少其中之一已被采用。为了具有竞争力，你也需要将这些技能添加到你的技能库中。
- en: Tuning stock models for better performance
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整股票模型以获得更好的性能
- en: Some machine learning tasks are well suited to be solved by the stock models
    presented in prior chapters. For these tasks, it may not be necessary to spend
    much time iterating and refining the model, because it may perform well enough
    without additional effort. On the other hand, many real-world tasks are inherently
    more difficult. For these tasks, the underlying concepts to be learned tend to
    be extremely complex, requiring an understanding of many subtle relationships,
    or the problem may be affected by substantial amounts of random variability, which
    makes it difficult to find the signal within the noise.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一些机器学习任务非常适合由前几章中介绍的股票模型来解决。对于这些任务，可能没有必要花费太多时间迭代和改进模型，因为它可能在没有额外努力的情况下表现良好。另一方面，许多现实世界的任务本质上是更困难的。对于这些任务，需要学习的基本概念往往非常复杂，需要理解许多微妙的关系，或者问题可能受到大量随机变异性的影响，这使得在噪声中找到信号变得困难。
- en: Developing models that perform extremely well on these types of challenging
    problems is every bit an art as it is a science. Sometimes a bit of intuition
    is helpful when trying to identify areas where performance can be improved. In
    other cases, finding improvements will require a brute-force, trial-and-error
    approach. Of course, this is one of the strengths of using machines that never
    tire and never become bored; searching for numerous potential improvements can
    be made easier by automated programs. As we will see, however, human effort and
    computing time are not always fungible, and creating a finely-tuned learning algorithm
    can come with its own costs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 开发在这些具有挑战性的问题上表现极好的模型，既是一门艺术，也是一门科学。有时，在尝试确定可以改进性能的领域时，一点直觉是有帮助的。在其他情况下，找到改进可能需要一种暴力搜索、尝试和错误的办法。当然，这是使用机器的一个优点，因为机器永远不会感到疲倦，也永远不会感到无聊；通过自动化程序可以更容易地搜索众多潜在改进。然而，我们将看到，人力和计算时间并不总是可以互换的，创建一个精心调整的学习算法可能会带来自己的成本。
- en: We attempted a difficult machine learning problem *in* *Chapter 5*, *Divide
    and Conquer – Classification Using Decision Trees and Rules*, as we attempted
    to predict bank loans that were likely to enter default. Although we were able
    to achieve a respectable classification accuracy of 82 percent, upon more careful
    examination in *Chapter 10*, *Evaluating Model Performance*, we realized that
    the accuracy statistic was a bit misleading. The kappa statistic—a better measure
    of performance for unbalanced outcomes­—was only about 0.294 as measured via 10-fold
    **cross-validation** (**CV**), which suggested that the model was performing somewhat
    poorly, despite the high accuracy. In this section, we’ll revisit the credit scoring
    model to see whether we can improve the results.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第5章*《分而治之 - 使用决策树和规则进行分类》*中尝试了一个困难的机器学习问题，我们试图预测可能进入违约的银行贷款。尽管我们能够实现82%的可敬的分类准确率，但在第10章*《评估模型性能》*中更仔细地检查后，我们发现准确度统计指标有些误导。kappa统计量——不平衡结果性能的更好衡量指标——通过10折**交叉验证**（**CV**）测量仅为0.294，这表明尽管准确率很高，但模型的表现有些不佳。在本节中，我们将重新审视信用评分模型，看看我们是否可以改进结果。
- en: 'To follow along with the examples, download the `credit.csv` file from the
    Packt Publishing website and save it to your R working directory. Load the file
    into R using the following command: `credit <- read.csv("credit.csv")`.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随示例进行操作，请从Packt Publishing网站下载`credit.csv`文件，并将其保存到你的R工作目录中。使用以下命令将文件加载到R中：`credit
    <- read.csv("credit.csv")`。
- en: You may recall that we first used a stock C5.0 decision tree to build the classifier
    for the credit data and later attempted to improve the classifier’s performance
    by adjusting the `trials` option to increase the number of boosting iterations.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得，我们最初使用了一个标准的C5.0决策树来构建信用数据的分类器，后来尝试通过调整`trials`选项来增加提升迭代的次数，以提高分类器的性能。
- en: By changing the number of iterations from the default value of 1 up to the value
    of 10, we were able to increase the model’s accuracy. As defined in *Chapter 11*,
    *Being Successful with Machine Learning*, these model options, known as hyperparameters,
    are not learned automatically from the data but are instead set before training.
    The process of testing various hyperparameter settings to achieve a better model
    fit is thus called **hyperparameter tuning**, and strategies for tuning range
    from simple ad hoc trial and error to more rigorous and systematic iteration.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将迭代次数从默认值1增加到10，我们能够提高模型的准确度。如第11章*《用机器学习取得成功》*中定义的，这些被称为超参数的模型选项不是从数据中自动学习的，而是在训练之前设置的。因此，测试各种超参数设置以实现更好的模型拟合的过程被称为**超参数调整**，调整策略从简单的临时尝试和错误到更严格和系统的迭代。
- en: Hyperparameter tuning is not limited to decision trees. For instance, we tuned
    k-NN models when we searched for the best value of *k*. We also tuned neural networks
    and support vector machines as we adjusted the number of nodes and the number
    of hidden layers, or chose different kernel functions. Most machine learning algorithms
    allow the adjustment of at least one hyperparameter, and the most sophisticated
    models offer many ways to tweak the model fit. Although this allows the model
    to be tailored closely to the learning task, the complexity of the many options
    can be daunting. A more systematic approach is warranted.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调整不仅限于决策树。例如，我们在寻找最佳 *k* 值时调整了 k-NN 模型。我们还调整了神经网络和支持向量机，当我们调整节点数和隐藏层数，或选择不同的核函数时。大多数机器学习算法至少允许调整一个超参数，而最复杂的模型提供了许多调整模型拟合的方法。虽然这允许模型紧密地适应学习任务，但众多选项的复杂性可能会令人望而却步。需要一种更系统的方法。
- en: Determining the scope of hyperparameter tuning
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定超参数调整的范围
- en: When performing hyperparameter tuning, it is important to put bounds on the
    scope to prevent the search from proceeding endlessly. The computer provides the
    muscle, but it is up to the human to dictate where to look and for how long. Even
    as computing power is growing and cloud computing costs are shrinking, the search
    can easily get out of hand when sifting through nearly endless combinations of
    values. A narrow or shallow tuning scope may last long enough to grab a cup of
    coffee, while a wide or deep scope may give you time to get a good night of sleep—or
    more!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行超参数调整时，重要的是要对范围设定界限，以防止搜索无休止地进行。计算机提供力量，但决定在哪里寻找以及寻找多长时间的责任在于人类。即使计算能力在增长，云计算成本在下降，但在筛选几乎无尽的值组合时，搜索很容易失控。一个狭窄或浅层次的调整范围可能足以让你喝上一杯咖啡，而一个广泛或深层次的调整范围可能会给你足够的时间好好睡一觉——或者更多！
- en: Time and money are often fungible, as you may be able to buy time in the form
    of additional computing resources or by enlisting additional team members to build
    models faster or in parallel. Even so, taking this for granted can lead to ruin
    in the form of budget overruns or missed deadlines because it is easy for the
    scope to balloon quickly when work proceeds down countless tangents and dead ends
    without a plan. To avoid such pitfalls, it is wise to strategize about the breadth
    and depth of the tuning process beforehand.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 时间和金钱往往是可互换的，因为你可能能够通过购买额外的计算资源或招募额外的团队成员来更快或并行地构建模型来购买时间。即便如此，这种假设可能导致预算超支或错过截止日期，因为如果没有计划，工作可能会迅速偏离无数的方向和死胡同。为了避免这样的陷阱，事先对调整过程的广度和深度进行战略规划是明智的。
- en: You might start by thinking about tuning as a process much like playing the
    classic board game *Battleship*. In this game, your opponent has placed a fleet
    of battleships on a two-dimensional grid, which is hidden out of your view. Your
    goal is to destroy the opponent’s fleet by guessing the coordinates of all their
    ships before they do the same to yours. Because the ships are known sizes and
    shapes, a smart player will begin by broadly probing the search grid in a checkerboard
    pattern but quickly focus on a specific target once it has been hit.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会首先将调整过程想象成玩经典的棋盘游戏 *Battleship*。在这个游戏中，你的对手在一个二维网格上放置了一支舰队，而你无法看到。你的目标是猜测他们所有舰船的坐标，并在他们对你做同样的事情之前摧毁他们的舰队。因为舰船的大小和形状是已知的，一个聪明的玩家会首先以棋盘格的图案广泛地探测搜索网格，但一旦被击中，就会迅速聚焦于一个特定的目标。
- en: This is a better strategy than guessing coordinates at random or iterating across
    each coordinate systematically, both of which are inefficient in comparison.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这比随机猜测坐标或系统地迭代每个坐标都要好，这两种方法在效率上都比较低。
- en: '![Diagram  Description automatically generated](img/B17290_14_01.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图描述自动生成](img/B17290_14_01.png)'
- en: 'Figure 14.1: The hunt for the optimal machine learning hyperparameters can
    be much like playing the classic Battleship board game'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1：寻找最优机器学习超参数的过程可以类似于玩经典的“战舰”棋盘游戏
- en: 'Similarly, there are methods for tuning that are more efficient than systematic
    iteration over endless values and combinations of values. With experience, you
    will develop an intuition for how to proceed, but for the first few attempts,
    it may be useful to think intentionally about the process. The following general
    strategy, listed as a series of steps, can be adapted to your machine learning
    project, computing and staffing resources, and work style:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，有一些比在无限值和值组合上系统迭代更有效的调整方法。随着经验的积累，你会发展出如何进行的感觉，但最初的几次尝试，有意识地思考这个过程可能是有用的。以下列出的一系列一般策略，可以根据你的机器学习项目、计算和人力资源以及工作风格进行调整：
- en: '**Replicate the real-world evaluation criteria**: To find the single best set
    of model hyperparameters, it is important that the models are evaluated using
    the same criteria as will be used in deployment. This may mean choosing an evaluation
    metric that mirrors the final, real-world metric, or it may involve writing a
    function that simulates the deployment environment.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**复制现实世界的评估标准**：为了找到最佳的模型超参数集，重要的是模型应该使用与部署时相同的标准进行评估。这可能意味着选择一个反映最终现实指标的评估指标，或者可能涉及编写一个模拟部署环境的函数。'
- en: '**Consider the resource usage for one iteration**: As tuning will be iterating
    many times on the same algorithm, you should have an estimate of the time and
    computing resources needed for a single iteration. If it takes one hour to train
    a single model, it will take 100 hours or more for 100 iterations. If the computer
    memory is already at its limit, it is likely that you will exceed the limit during
    tuning. If this is a problem, you will need to invest in additional computing
    power, run the experiment in parallel, or reduce the size of the dataset via random
    sampling.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**考虑一次迭代的资源使用**：由于调整将在同一算法上迭代多次，你应该有一个关于单次迭代所需的时间和计算资源的估计。如果训练单个模型需要一小时，那么100次迭代将需要100小时或更多。如果计算机内存已经达到极限，那么在调整过程中很可能会超过这个限制。如果这是一个问题，你需要投资额外的计算能力，并行运行实验，或者通过随机抽样减少数据集的大小。'
- en: '**Begin with a shallow search to probe for patterns**: The initial tuning process
    should be interactive and shallow. It is intended to develop your own understanding
    of what options and values are important. When probing a single hyperparameter,
    keep increasing or decreasing its setting in reasonable increments until the performance
    stops improving (or starts decreasing). Depending on the option, this may be increments
    of one, multiples of five or ten, or incrementally small fractions, such as 0.1,
    0.01, 0.001, and so on. When tuning two or more hyperparameters, it may help to
    focus on one at a time and keep the other values static. This is a more efficient
    approach than testing all possible combinations of settings, but may ultimately
    miss important combinations that would have been discovered if all combinations
    were tested.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**从浅层搜索开始以寻找模式**：初始调整过程应该是交互式的和浅层的。它的目的是发展你对自己认为哪些选项和值是重要的理解。在探测单个超参数时，应合理地增加或减少其设置，直到性能停止提高（或开始下降）。根据选项，这可能是1的增量，5或10的倍数，或者增量很小的分数，如0.1、0.01、0.001等。当调整两个或更多超参数时，一次关注一个并保持其他值不变可能会有所帮助。这种方法比测试所有可能的设置组合更有效，但最终可能会错过如果测试了所有组合本可以发现的组合。'
- en: '**Narrow in on the optimal set of hyperparameter values**: Once you have a
    sense of a range of values suspected to contain the optimal settings, you can
    reduce the increments between the tested values and test a narrower range with
    greater precision or test a greater number of combinations of values. The previous
    step should have already resulted in a reasonable set of hyperparameters, so this
    step should only improve and never detract from the model’s performance; it can
    be stopped at any time.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聚焦于最优的超参数值集**：一旦你对包含最优设置的值范围有了感觉，你可以减少测试值之间的增量，并使用更高的精度测试更窄的范围，或者测试更多值的组合。前一步应该已经产生了一组合理的超参数，所以这一步应该只会提高而不会降低模型的性能；它可以在任何时候停止。'
- en: '**Determine a reasonable stopping point**: Deciding when to stop the tuning
    process is easier said than done—the thrill of the hunt and the possibility of
    a slightly better model can lead to a stubborn desire to keep going! Sometimes,
    the stopping point is a project deadline when time is running out. In other cases,
    the work can only stop once the desired performance level has been reached. In
    any case, because the only way to guarantee finding the optimal hyperparameter
    values is to test an infinite number of possibilities, rather than working toward
    burnout, you will need to define the point at which performance is “good enough”
    to stop the process.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**确定一个合理的停止点**：决定何时停止调整过程比说起来容易——追求更好模型的冲动和可能出现的略微改进可以导致固执地继续下去！有时，停止点是一个项目截止日期，当时时间正在流逝。在其他情况下，只有在达到期望的性能水平后，工作才能停止。在任何情况下，因为保证找到最佳超参数值的唯一方法是在无限多的可能性中进行测试，而不是朝着燃尽努力，你需要定义性能“足够好”以停止过程的点。'
- en: '*Figure 14.2* illustrates the process of homing in on hyperparameter values
    for single-parameter tuning. Five potential values (1, 2, 3, 4, and 5) denoted
    by solid circles were evaluated in the initial pass, and the accuracy was highest
    when the hyperparameter was set to 3\. To check whether an even better hyperparameter
    setting might exist, eight additional values (from 2.2 to 3.8 in increments of
    0.2, denoted by vertical tick marks) were tested within the range between 2 and
    4, which led to the discovery of a higher accuracy when the hyperparameter was
    set to 3.2\. If time allows, one could test even more values in a narrower range
    around this value to possibly find an even better setting.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14.2*说明了针对单参数调整聚焦超参数值的过程。在初始遍历中，对五个潜在值（1、2、3、4和5）进行了评估，当超参数设置为3时，准确率最高。为了检查是否存在更好的超参数设置，在2到4的范围内测试了八个额外的值（从2.2到3.8，以0.2的增量，由垂直刻度表示），当超参数设置为3.2时，发现了更高的准确率。如果时间允许，可以在围绕这个值更窄的范围内测试更多的值，以可能找到更好的设置。'
- en: '![](img/B17290_14_02.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B17290_14_02.png)'
- en: 'Figure 14.2: Strategies for parameter tuning home in on the optimal value by
    searching broadly and then narrowly'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2：参数调整策略通过广泛搜索然后缩小搜索范围来聚焦于最佳值
- en: 'Tuning two or more hyperparameters is more complicated, because the optimal
    value of one parameter may depend on the value of the others. Constructing a visualization
    like the one depicted in *Figure 14.3* may help in understanding how to find the
    best combinations of parameters; within hot spots where certain combinations of
    values result in better model performance, one might test more values in narrower
    and narrower ranges:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 调整两个或更多超参数更为复杂，因为一个参数的最佳值可能取决于其他参数的值。构建类似于*图14.3*所示的可视化可以帮助理解如何找到最佳参数组合；在那些某些值组合导致模型性能更好的热点区域，可以在越来越窄的范围内测试更多的值：
- en: '![Chart, diagram  Description automatically generated](img/B17290_14_03.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图表，图解 自动生成描述](img/B17290_14_03.png)'
- en: 'Figure 14.3: Tuning strategies become more challenging as more hyperparameters
    are added, as the model’s best performance depends on combinations of values'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3：随着更多超参数的添加，调整策略变得更加具有挑战性，因为模型的最佳性能取决于值的组合
- en: This *Battleship*-style **grid search**, in which hyperparameters and combinations
    of hyperparameters are tested systematically, is not the only approach to tuning,
    although it may be the most widely used. A more intelligent approach called **Bayesian
    optimization** treats the tuning process as a learning problem that can be solved
    using modeling. This approach is included in some automated machine learning software
    but is outside the scope of this book. Instead, for the remainder of this section,
    we will focus on applying the idea of grid search to our real-world dataset.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类似*战舰*风格的**网格搜索**，其中系统地测试超参数及其组合，虽然不是调整的唯一方法，但可能是最广泛使用的方法。一种更智能的方法称为**贝叶斯优化**，将调整过程视为一个可以通过建模解决的问题。这种方法包含在一些自动机器学习软件中，但超出了本书的范围。相反，在本节的剩余部分，我们将专注于将网格搜索的理念应用于我们的实际数据集。
- en: Example – using caret for automated tuning
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 - 使用caret进行自动调整
- en: Thankfully, we can use R to conduct the iterative search through many possible
    hyperparameter values and combinations of values to find the best set. This approach
    is a relatively easy yet sometimes computationally expensive brute-force method
    of optimizing a learning algorithm’s performance.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: The `caret` package, which was used previously in *Chapter 10*, *Evaluating
    Model Performance*, provides tools to assist with this form of automated tuning.
    The core tuning functionality is provided by a `train()` function that serves
    as a standardized interface for over 200 different machine learning models for
    both classification and numeric prediction tasks. Using this function, it is possible
    to automate the search for optimal models using a choice of evaluation methods
    and metrics.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'Automated parameter tuning with `caret` will require you to consider three
    questions:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: What type of machine learning algorithm (and specific R implementation of this
    algorithm) should be trained on the data?
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which hyperparameters can be adjusted for this algorithm, and how extensively
    should they be tuned to find the optimal settings?
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What criterion should be used to evaluate the candidate models to identify the
    best overall set of tuning values?
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answering the first question involves finding a match between the machine learning
    task and one of the many models available to the `caret` package. This requires
    a general understanding of the types of machine learning models, which you may
    already have if you’ve been working through this book chronologically. It can
    also help to work through a process of elimination. Nearly half of the models
    can be eliminated depending on whether the task is classification or numeric prediction;
    others can be excluded based on the format of the training data or the need to
    avoid black box models, and so on. In any case, there’s also no reason you can’t
    create several highly tuned models and compare them across the set.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Addressing the second question is a matter largely dictated by the choice of
    model since each algorithm utilizes its own set of hyperparameters. The available
    tuning options for the predictive models covered in this book are listed in the
    following table. Keep in mind that although some models have additional options
    not shown, only those listed in the table are supported by `caret` for automatic
    tuning.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '| **Model** | **Learning Task** | **Method Name** | **Hyperparameters** |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
- en: '| *k-Nearest Neighbors* | *Classification* | `knn` | `k` |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
- en: '| *Naive Bayes* | *Classification* | `nb` | `fL, usekernel` |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
- en: '| *Decision Trees* | *Classification* | `C5.0` | `model, trials, winnow` |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: '| *OneR Rule Learner* | *Classification* | `OneR` | `None` |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
- en: '| *RIPPER Rule Learner* | *Classification* | `JRip` | `NumOpt` |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
- en: '| *Linear Regression* | *Regression* | `lm` | `None` |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
- en: '| *Regression Trees* | *Regression* | `rpart` | `cp` |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
- en: '| *Model Trees* | *Regression* | `M5` | `pruned, smoothed, rules` |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: '| *Neural Networks* | *Dual Use* | `nnet` | `size, decay` |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: '| *Support Vector Machines (Linear Kernel)* | *Dual Use* | `svmLinear` | `C`
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| *支持向量机（线性核）* | *双重用途* | `svmLinear` | `C` |'
- en: '| *Support Vector Machines (Radial Basis Kernel)* | *Dual Use* | `svmRadial`
    | `C, sigma` |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| *支持向量机（径向基核）* | *双重用途* | `svmRadial` | `C, sigma` |'
- en: '| *Random Forests* | *Dual Use* | `rf` | `mtry` |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| *随机森林* | *双重用途* | `rf` | `mtry` |'
- en: '| *Gradient Boosting Machines (GBM)* | *Dual Use* | `gbm` | `n.trees, interaction.depth,
    shrinkage, n.minobsinnode` |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| *梯度提升机（GBM）* | *双重用途* | `gbm` | `n.trees, interaction.depth, shrinkage, n.minobsinnode`
    |'
- en: '| *XGBoost (XGB)* | *Dual Use* | `xgboost` | `eta, max_depth, colsample_bytree,
    subsample, nrounds, gamma, min_child_weight` |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| *XGBoost (XGB)* | *双重用途* | `xgboost` | `eta, max_depth, colsample_bytree,
    subsample, nrounds, gamma, min_child_weight` |'
- en: For a complete list of the models and corresponding tuning options covered by
    `caret`, refer to the table provided by package author Max Kuhn at [http://topepo.github.io/caret/available-models.html](http://topepo.github.io/caret/available-models.html).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取`caret`支持的模型和相应调优选项的完整列表，请参阅包作者Max Kuhn提供的表格，链接为[http://topepo.github.io/caret/available-models.html](http://topepo.github.io/caret/available-models.html)。
- en: 'If you ever forget the tuning parameters for a particular model, the `modelLookup()`
    function can be used to find them. Simply supply the method name as illustrated
    for the C5.0 model:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你忘记了特定模型的调优参数，可以使用`modelLookup()`函数来查找它们。只需提供如C5.0模型所示的方法名：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The goal of automatic tuning is to iterate over the set of candidate models
    comprising the search grid of potential parameter combinations. As it is impractical
    to search every conceivable combination, only a subset of possibilities is used
    to construct the grid. By default, `caret` searches, at most, three values for
    each of the model’s *p* hyperparameters, which means that, at most, *3*^p candidate
    models will be tested. For example, by default, the automatic tuning of k-nearest
    neighbors will compare *3*¹ *= 3* candidate models with `k=5`, `k=7`, and `k=9`.
    Similarly, tuning a decision tree will result in a comparison of up to 27 different
    candidate models, comprising the grid of *3*³ *= 27* combinations of `model`,
    `trials`, and `winnow` settings. In practice, however, only 12 models are tested.
    This is because `model` and `winnow` can only take two values (`tree` versus `rules`
    and `TRUE` versus `FALSE`, respectively), which makes the grid size *3*2*2 = 12*.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 自动调优的目标是在由潜在参数组合的搜索网格组成的候选模型集合上进行迭代。由于搜索所有可能的组合是不切实际的，因此只使用可能性的子集来构建网格。默认情况下，`caret`为每个模型的*p*个超参数最多搜索三个值，这意味着最多将测试*3*^p个候选模型。例如，默认情况下，k-近邻自动调优将比较*3*¹
    *= 3*个候选模型，其中`k=5`、`k=7`和`k=9`。同样，调整决策树将导致最多27个不同候选模型的比较，包括`model`、`trials`和`winnow`设置的*3*³
    *= 27*组合网格。然而，在实践中，只测试了12个模型。这是因为`model`和`winnow`只能取两个值（`tree`与`rules`以及`TRUE`与`FALSE`），这使得网格大小为*3*²*²
    = 12*。
- en: Since the default search grid may not be ideal for your learning problem, `caret`
    allows you to provide a custom search grid defined by a simple command, which
    we will cover later.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 由于默认的搜索网格可能不适合你的学习问题，`caret`允许你通过简单的命令提供自定义搜索网格，我们将在后面进行介绍。
- en: The third and final step in automatic model tuning involves identifying the
    best model among the candidates. This uses the methods discussed in *Chapter 10*,
    *Evaluating Model Performance*, including the choice of resampling strategy for
    creating training and test datasets, and the use of model performance statistics
    to measure the predictive accuracy. All the resampling strategies and many of
    the performance statistics we’ve learned are supported by `caret`. These include
    statistics such as accuracy and kappa for classifiers and R-squared or **root-mean-square
    error** (**RMSE**) for numeric models. Cost-sensitive measures like sensitivity,
    specificity, and AUC can also be used if desired.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 自动模型调优的第三步和最后一步是确定候选模型中最好的模型。这使用了在第10章“评估模型性能”中讨论的方法，包括选择重采样策略来创建训练和测试数据集，以及使用模型性能统计来衡量预测准确性。我们学到的所有重采样策略和许多性能统计都由`caret`支持。这些包括如分类器的准确率和kappa，以及数值模型的R-squared或**均方根误差**（**RMSE**）。如果需要，也可以使用成本敏感度指标，如灵敏度、特异性和AUC。
- en: By default, `caret` will select the candidate model with the best value of the
    desired performance measure. Because this practice sometimes results in the selection
    of models that achieve minor performance improvements via large increases in model
    complexity, alternative model selection functions are provided. These alternatives
    allow us to choose simpler models that are still reasonably close to the best
    model, which may be desirable in the case where a bit of predictive performance
    is worth sacrificing for an improvement in computational efficiency.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`caret` 将选择具有所需性能度量最佳值的候选模型。由于这种做法有时会导致选择通过增加模型复杂度来实现微小性能改进的模型，因此提供了替代模型选择函数。这些替代方案允许我们选择更简单的模型，这些模型仍然与最佳模型相当接近，这在需要牺牲一点预测性能以换取计算效率提高的情况下可能是可取的。
- en: Given the wide variety of options in the `caret` tuning process, it is helpful
    that many of the function’s defaults are reasonable. For instance, without specifying
    the settings manually, `caret` uses prediction accuracy or RMSE on a bootstrap
    sample to choose the best performer for classification and numeric prediction
    models, respectively. Similarly, it will automatically define a limited grid to
    search. These defaults allow us to start with a simple tuning process and learn
    to tweak the `train()` function to design a wide variety of experiments of our
    choosing.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `caret` 调优过程中有各种各样的选项，许多函数的默认设置是合理的，这很有帮助。例如，不手动指定设置，`caret` 会使用在自助样本上的预测准确度或
    RMSE 来选择分类和数值预测模型的最佳表现者。同样，它将自动定义一个有限的网格进行搜索。这些默认设置使我们能够从简单的调优过程开始，并学习如何调整 `train()`
    函数来设计我们选择的广泛实验。
- en: Creating a simple tuned model
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个简单的调优模型
- en: 'To illustrate the process of tuning a model, let’s begin by observing what
    happens when we attempt to tune the credit scoring model using the `caret` package’s
    default settings. The simplest way to tune a learner requires only that you specify
    a model type via the `method` parameter. Since we used C5.0 decision trees previously
    with the credit model, we’ll continue our work by optimizing this learner. The
    basic `train()` command for tuning a C5.0 decision tree using the default settings
    is as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明调优模型的过程，让我们首先观察当我们尝试使用 `caret` 包的默认设置来调优信用评分模型时会发生什么。调整学习者的最简单方法只需要你通过 `method`
    参数指定一个模型类型。由于我们之前已经使用 C5.0 决策树与信用模型一起使用，我们将通过优化这个学习者继续我们的工作。使用默认设置调优 C5.0 决策树的基本
    `train()` 命令如下：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: First, the `set.seed()` function is used to initialize R’s random number generator
    to a set starting position. You may recall that we used this function in several
    prior chapters. By setting the `seed` parameter (in this case, to the arbitrary
    number 300), the random numbers will follow a predefined sequence. This allows
    simulations that use random sampling to be repeated with identical results—a very
    helpful feature if you are sharing code or attempting to replicate a prior result.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用 `set.seed()` 函数初始化 R 的随机数生成器到一个固定的起始位置。你可能还记得我们在几个先前的章节中使用了这个函数。通过设置 `seed`
    参数（在这种情况下，为任意数 300），随机数将遵循预定义的序列。这允许使用随机抽样的模拟能够重复产生相同的结果——如果你正在共享代码或尝试复制先前的结果，这是一个非常有帮助的特性。
- en: Next, we define a tree as `default ~ .` using the R formula interface. This
    models a loan default status (`yes` or `no`) using all the other features in the
    `credit` dataset. The parameter `method = "C5.0"` tells the function to use the
    C5.0 decision tree algorithm.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用 R 公式接口定义一棵树为 `default ~ .`。这使用 `credit` 数据集中的所有其他特征来模拟贷款违约状态（`是`或`否`）。参数
    `method = "C5.0"` 告诉函数使用 C5.0 决策树算法。
- en: After you’ve entered the preceding command, depending upon your computer’s capabilities,
    there may be a significant delay as the tuning process occurs. Even though this
    is a small dataset, a substantial amount of calculation must occur. R must repeatedly
    generate random bootstrap samples of data, build decision trees, compute performance
    statistics, and evaluate the result. Because there are 12 candidate models with
    varying hyperparameter values to be evaluated, and 25 bootstrap samples per candidate
    model to compute an average performance measure, there are *25*12 = 300* decision
    tree models being built using C5.0—and this doesn’t even count the additional
    decision trees being built when the boosting trials are set!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'A list named `m` stores the result of the `train()` experiment, and the command
    `str(m)` will display the associated results, but the contents can be substantial.
    Instead, simply type the name of the object for a condensed summary of the results.
    For instance, typing `m` yields the following output (note that numbered labels
    have been added for clarity):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_14_04.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.4: The results of a caret experiment are separated into four components,
    as annotated in this figure'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'The labels highlight four main components in the output:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '**A brief description of the input dataset**: If you are familiar with your
    data and have applied the `train()` function correctly, this information should
    not be surprising.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**A report of the preprocessing and resampling methods applied**: Here we see
    that 25 bootstrap samples, each including 1,000 examples, were used to train the
    models.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**A list of the candidate models evaluated**: In this section, we can confirm
    that 12 different models were tested, based on the combinations of three C5.0
    hyperparameters: `model`, `trials`, and `winnow`. The average accuracy and kappa
    statistics for each candidate model are also shown.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The choice of best model**: As the footnote describes, the model with the
    best accuracy (in other words, “largest”) was selected. This was the C5.0 model
    that used a decision tree with the settings `winnow = FALSE` and `trials = 20`.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After identifying the best model, the `train()` function uses the tuned hyperparameters
    to build a model on the full input dataset, which is stored in `m` as `m$finalModel`.
    In most cases, you will not need to work directly with the `finalModel` sub-object.
    Instead, simply use the `predict()` function with the `m` object as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The resulting vector of predictions works as expected, allowing us to create
    a confusion matrix that compares the predicted and actual values:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Of the 1,000 examples used for training the final model, only two were misclassified,
    for an accuracy of 99.8 percent. However, it is very important to note that since
    the model was built on both the training and test data, this accuracy is optimistic
    and thus should not be viewed as indicative of performance on unseen data. The
    bootstrap accuracy estimate of 72.996 percent, which can be found in the last
    row of section three of the `train()`output in *Figure 14.4*, is a far more realistic
    estimate of future accuracy.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: In addition to automatic hyperparameter tuning, using the `caret` package’s
    `train()` and `predict()` functions also offers a pair of benefits beyond the
    functions found in the stock packages.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: First, any data preparation steps applied by the `train()` function will be
    similarly applied to the data used for generating predictions. This includes transformations
    like centering and scaling, as well as the imputation of missing values. Allowing
    `caret` to handle the data preparation will ensure that the steps that contributed
    to the best model’s performance will remain in place when the model is deployed.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, the `predict()` function provides a standardized interface for obtaining
    predicted class values and predicted class probabilities, even for model types
    that ordinarily would require additional steps to obtain this information. For
    a classification model, the predicted classes are provided by default:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To obtain the estimated probabilities for each class, use the `type = "prob"`
    parameter:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Even in cases where the underlying model refers to the prediction probabilities
    using a different string (for example, `"raw"` for a `naiveBayes` model), the
    `predict()` function will translate `type = "prob"` to the appropriate parameter
    setting automatically.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Customizing the tuning process
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The decision tree we created previously demonstrates the `caret` package’s
    ability to produce an optimized model with minimal intervention. The default settings
    allow optimized models to be created easily. However, it is also possible to change
    the default settings as desired, which may assist with unlocking the upper echelon
    of performance. Before the tuning process begins, it’s worth answering a series
    of questions that will help guide the setup of the `caret` experiment:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: How long does it take for one iteration? In other words, how long does it take
    to train a single instance of the model being tuned?
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given the time it takes to train a single instance, how long will it take to
    perform the model evaluation using the chosen resampling method? For example,
    10-fold CV will require 10 times as much time as training a single model.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much time are you willing to spend on tuning? Based on this number, one
    can determine the total number of hyperparameter values that can be tested. For
    instance, if it takes one minute to evaluate a model using 10-fold CV, then 60
    hyperparameter settings can be tested per hour.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using time as the key limiting factor will help put bounds on the tuning process
    and prevent you from chasing better and better performance endlessly.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve decided how much time to spend on the trials, it is easy to customize
    the process to your liking. To illustrate this flexibility, let’s modify our work
    on the credit decision tree to mirror the process we used in *Chapter 10*, *Evaluating
    Model Performance*. In that chapter, we estimated the kappa statistic using 10-fold
    CV. We’ll do the same here, using kappa to tune the boosting trials for the C5.0
    decision tree algorithm and find the optimal setting for our data. Note that decision
    tree boosting was first covered in *Chapter 5*, *Divide and Conquer – Classification
    Using Decision Trees and Rules*, and will also be covered in greater detail later
    in this chapter.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: 'The `trainControl()` function is used to create a set of configuration options
    known as a **control object**. This object guides the `train()` function and allows
    for the selection of model evaluation criteria such as the resampling strategy
    and the measure used for choosing the best model. Although this function can be
    used to modify nearly every aspect of a `caret` tuning experiment, we’ll focus
    on two important parameters: `method` and `selectionFunction`.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: If you’re eager for more details about the control object, you can use the `?trainControl`
    command for a list of all the parameters.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: When using the `trainControl()` function, the `method` parameter sets the resampling
    method, such as holdout sampling or k-fold CV. The following table lists the possible
    `method` values, as well as any additional parameters for adjusting the sample
    size and the number of iterations. Although the default options for these resampling
    methods follow popular conventions, you may choose to adjust these depending on
    the size of your dataset and the complexity of your model.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '| **Resampling method** | **Method name** | **Additional options and default
    values** |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: '| *Holdout sampling* | `LGOCV` | `p = 0.75` (training data proportion) |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
- en: '| *k-fold CV* | `cv` | `number = 10` (number of folds) |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
- en: '| *Repeated k-fold CV* | `repeatedcv` | `number = 10` (number of folds)`repeats
    = 10` (number of iterations) |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
- en: '| *Bootstrap sampling* | `boot` | `number = 25` (resampling iterations) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
- en: '| *0.632 bootstrap* | `boot632` | `number = 25` (resampling iterations) |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
- en: '| *Leave-one-out CV* | `LOOCV` | *None* |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: The `selectionFunction` parameter is used to specify the function that will
    choose the optimal model among the candidates. Three such functions are included.
    The `best` function simply chooses the candidate with the best value on the specified
    performance measure. This is used by default. The other two functions are used
    to choose the most parsimonious, or simplest, model that is within a certain threshold
    of the best model’s performance. The `oneSE` function chooses the simplest candidate
    within one standard error of the best performance, and `tolerance` uses the simplest
    candidate within a user-specified percentage.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Some subjectivity is involved with the `caret` package’s ranking of models by
    simplicity. For information on how models are ranked, see the help page for the
    selection functions by typing `?best` at the R command prompt.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a control object named `ctrl` that uses 10-fold CV and the `oneSE`
    selection function, use the following command, noting that `number = 10` is included
    only for clarity; since this is the default value for `method = "cv"`, it could
    have been omitted:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We’ll use the result of this function shortly.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: In the meantime, the next step in setting up our experiment is to create the
    search grid for hyperparameter tuning. The grid must include a column named for
    each hyperparameter in the desired model, regardless of whether it will be tuned.
    It must also include a row for each desired combination of values to test. Since
    we are using a C5.0 decision tree, this means we’ll need columns named `model`,
    `trials`, and `winnow`, corresponding to the three options that can be tuned.
    For other machine learning models, refer to the table presented earlier in this
    chapter or use the `modelLookup()` function to find the hyperparameters as described
    previously.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Rather than filling the grid data frame cell by cell—a tedious task if there
    are many possible combinations of values—we can use the `expand.grid()` function,
    which creates data frames from the combinations of all values supplied. For example,
    suppose we would like to hold constant `model = "tree"` and `winnow = FALSE` while
    searching eight different values of `trials`.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be created as:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The resulting `grid` data frame contains *1*8*1 = 8* rows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `train()` function will build a candidate model for evaluation using each
    `grid` row’s combination of model parameters.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the search grid and the control object created previously, we are ready
    to run a thoroughly customized `train()` experiment. As before, we’ll set the
    random seed to the arbitrary number `300` in order to ensure repeatable results.
    But this time, we’ll pass our control object and tuning grid while adding a parameter
    `metric = "Kappa"`, indicating the statistic to be used by the model evaluation
    function—in this case, `"oneSE"`. The full set of commands is as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This results in an object that we can view by typing its name:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Although the output is similar to the automatically tuned model, there are a
    few notable differences. Because 10-fold CV was used, the sample size to build
    each candidate model was reduced to 900 rather than the 1,000 used in the bootstrap.
    Furthermore, eight candidate models were tested rather than the 12 in the prior
    experiment. Lastly, because `model` and `winnow` were held constant, their values
    are no longer shown in the results; instead, they are listed as a footnote.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: The best model here differs quite significantly from the prior experiment. Before,
    the best model used `trials = 20`, whereas here, it used `trials = 1`. This change
    is because we used the `oneSE` function rather than the `best` function to select
    the optimal model. Even though the model with `trials = 35` obtained the best
    kappa, the single-trial model offers reasonably close performance with a much
    simpler algorithm.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to the large number of configuration parameters, `caret` can seem overwhelming
    at first. Don’t let this deter you—there is no easier way to test the performance
    of models using 10-fold CV. Instead, think of the experiment as defined by two
    parts: a `trainControl()` object that dictates the testing criteria, and a tuning
    grid that determines what model parameters to evaluate. Supply these to the `train()`
    function and with a bit of computing time, your experiment will be complete!'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Of course, tuning is just one possibility for building better learners. In the
    next section, you will discover that in addition to buffing up a single learner
    to make it stronger, it is also possible to combine several weaker models to form
    a more powerful team.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Improving model performance with ensembles
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just as the best sports teams have players with complementary rather than overlapping
    skillsets, some of the best machine learning algorithms utilize teams of complementary
    models. Since a model brings a unique bias to a learning task, it may readily
    learn one subset of examples but have trouble with another. Therefore, by intelligently
    using the talents of several diverse team members, it is possible to create a
    strong team of multiple weak learners.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: This technique of combining and managing the predictions of multiple models
    falls into a wider set of **meta-learning methods**, which are techniques that
    involve learning how to learn. This includes anything from simple algorithms that
    gradually improve performance by iterating over design decisions—for instance,
    the automated parameter tuning used earlier in this chapter—to highly complex
    algorithms that use concepts borrowed from evolutionary biology and genetics for
    self-modifying and adapting to learning tasks.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you were a contestant on a television trivia show that allowed you to
    choose a panel of five friends to assist you with answering the final question
    for the million-dollar prize. Most people would try to stack the panel with a
    diverse set of subject matter experts. A panel containing professors of literature,
    science, history, and art, along with a current pop-culture expert, would be safely
    well-rounded. Given their breadth of knowledge, it would be unlikely that a question
    would stump the group.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: The meta-learning approach that utilizes a similar principle of creating a varied
    team of experts is known as an **ensemble**. For the remainder of this chapter,
    we’ll focus on meta-learning only as it pertains to ensembling—the task of modeling
    a relationship between the predictions of several models and the desired outcome.
    The teamwork-based methods covered here are quite powerful and are used often
    to build more effective classifiers.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Understanding ensemble learning
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All ensemble methods are based on the idea that by combining multiple weaker
    learners, a stronger learner is created. Ensembles contain two or more machine
    learning models, which can be of the same type, such as several decision trees,
    or of different types, such as a decision tree and a neural network. Though there
    are myriad ways to construct an ensemble, they tend to fall into several general
    categories, which can be distinguished, in large part, by the answers to two questions:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: How are the ensemble’s models chosen and trained?
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How are the models’ predictions combined to make a single final prediction?
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When answering these questions, it can be helpful to imagine the ensemble in
    terms of the following process diagram, which encompasses nearly all ensembling
    approaches:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B17290_14_05.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.5: Ensembles combine multiple weaker models into a single stronger
    model'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: In this design pattern, input training data is used to build several models.
    The **allocation function** dictates how much and what subsets of the training
    data each model receives. Do they each receive the full training dataset or merely
    a sample? Do they each receive every feature or a subset of features? The decisions
    made here will shape the training of the weaker learners that comprise the stronger
    ensemble.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Just as you’d want a variety of experts to advise your appearance on a television
    trivia game show, ensembles depend on a **diverse** set of classifiers, which
    means that they have uncorrelated classifications but still perform better than
    random chance. In other words, each classifier must be making an independent prediction,
    but each must also be doing more than merely guessing.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Diversity can be added to the ensemble by including a variety of machine learning
    techniques, such as an ensemble that groups a decision tree, a neural network,
    and a logistic regression model.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, the allocation function itself can also be a source of diversity
    by acting as a **data manipulator** and artificially varying the input data to
    bias the resulting learners, even if they use the same learning algorithm. As
    we will see in practice later, the allocation and data manipulation processes
    may be automated or included as part of the ensembling algorithm itself, or they
    may be performed by hand as part of the data engineering and model-building process.
    Overall, modes of increasing the ensemble’s diversity generally fall into five
    categories:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Using assorted base learning algorithms
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating the training sample by taking different samples at random, often
    by using bootstrapping
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating a single learning algorithm by using different hyperparameter settings
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing how the target feature is represented, such as representing an outcome
    as binary, categorical, or numeric
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Partitioning the training data into subgroups that represent different patterns
    to be learned; for instance, one might stratify the examples by key features,
    and let models in the ensemble become experts on different subsets of the training
    data
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For instance, in an ensemble of decision trees, the allocation function might
    use bootstrap sampling to construct unique training datasets for each tree, or
    it may pass each one a different subset of features. On the other hand, if the
    ensemble already includes a diverse set of algorithms—such as a neural network,
    a decision tree, and a k-NN classifier—then the allocation function might pass
    the training data on to each algorithm relatively unchanged.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: After the ensemble’s models are trained, they can be used to generate predictions
    on future data, but this set of multiple predictions must be reconciled somehow
    to generate a single final prediction. The **combination function** is the step
    in the ensembling process that takes each of these predictions and combines them
    into a single authoritative prediction for the set. Of course, because some of
    the models may disagree on the predicted value, the function must somehow blend
    or unify the information from the learners. The combination function is also known
    as a **composer** due to its work synthesizing the final prediction.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: There are two main strategies for merging or composing final predictions. The
    simpler of the two approaches involves **weighting methods**, which assign a score
    to each prediction that dictates how heavily it will factor into the final prediction.
    These range from a simple majority vote in which each classifier is weighted evenly,
    to more complex performance-based methods that grant more authority to some models
    than others if they have proven to be more reliable on past data.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: The second approach uses more complex meta-learning methods, such as the model
    stacking technique, which will be covered in depth later in this chapter. These
    use the initial set of predictions from the weak learners to train a secondary
    machine learning algorithm to make the final prediction—a process that is analogous
    to a committee making recommendations to a leader that makes the final decision.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: 'Ensembling methods are used to gain better performance than what is possible
    using only a single learning algorithm—the primary goal of the ensemble is to
    turn a group of weaker learners into a stronger, unified team. Still, there are
    many additional benefits, some of which may be surprising. These suggest additional
    reasons why one might turn to an ensemble, even outside of a machine learning
    competition environment:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '**The use of independent ensembles allows work in parallel**: Training independent
    classifiers separately means that work can be divided across multiple people.
    This allows more rapid iteration and may increase creativity. Each team member
    builds their best model, and the results can be easily combined into an ensemble
    at the end.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improved performance on massive or minuscule datasets**: Many algorithms
    run into memory or complexity limits when an extremely large set of features or
    examples are used. An ensemble of independent models can be fed subsets of features
    or examples, which are more computationally efficient to train than a single full
    model, and importantly, can often be run in parallel using distributed computing
    methods. On the other side of the spectrum, ensembles also do well on the smallest
    datasets because resampling methods like bootstrapping are inherently part of
    the allocation function of many ensemble designs.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The ability to synthesize data from distinct domains**: Since there is no
    one-size-fits-all learning algorithm, and each learning algorithm has its own
    biases and heuristics, the ensemble’s ability to incorporate evidence from multiple
    types of learners is increasingly important for modeling the most challenging
    learning tasks relying on data drawn from diverse domains.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A more nuanced understanding of difficult learning tasks**: Real-world phenomena
    are often extremely complex, with many interacting intricacies. Methods like ensembles,
    which divide the task into smaller modeled portions, are more able to capture
    subtle patterns that a single model might miss. Some learners in the set can go
    narrower and deeper to learn a specific subset of the most challenging cases.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: None of these benefits would be very helpful if you weren’t able to easily apply
    ensemble methods in R, and there are many packages available to do just that.
    Let’s look at several of the most popular ensemble methods and how they can be
    used to improve the performance of the credit model we’ve been working on.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Popular ensemble-based algorithms
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Thankfully, using teams of machine learners to improve the predictive performance
    doesn’t mean you’ll need to train each ensemble member separately by hand, although
    this option does exist, as you will learn later in this chapter. Instead, there
    are ensemble-based algorithms that manipulate the allocation function to train
    a very large number of simpler models in a single step automatically. In this
    way, an ensemble that includes a hundred learners or more can be trained with
    no more human time and input than training a single learner. As easily as one
    might build a single decision tree model, it is possible to build an ensemble
    with hundreds of such trees and harness the power of teamwork. Although it would
    be tempting to assume this is a magic bullet, such power, of course, comes with
    downsides such as loss of interpretability and a less diverse set of base algorithms
    from which to choose. This will be apparent in the sections that follow, which
    cover the evolution of two decades’ worth of popular ensembling algorithms—all
    of which, not coincidentally, are based on decision trees.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Bagging
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the first ensemble methods to gain widespread acceptance used a technique
    called **bootstrap aggregating** or **bagging** for short. As described by Leo
    Breiman in the mid-1990s, bagging begins by generating several new training datasets
    using bootstrap sampling on the original training data. These datasets are then
    used to generate a set of models using a single learning algorithm. The models’
    predictions are combined using voting for classification and averaging for numeric
    prediction.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: For additional information on bagging, refer to *Bagging predictors. Breiman
    L., Machine Learning, 1996, Vol. 24, pp. 123-140*.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Although bagging is a relatively simple ensemble, it can perform quite well
    if it is used with relatively **unstable** learners, that is, those generating
    models that tend to change substantially when the input data changes only slightly.
    Unstable models are essential for ensuring the ensemble’s diversity despite only
    minor variations across the bootstrap training datasets.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, bagging is most often used with decision trees, which have
    the tendency to vary dramatically given minor changes in input data.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: The `ipred` package offers a classic implementation of bagged decision trees.
    To train the model, the `bagging()` function works similarly to many of the models
    used previously. The `nbagg` parameter is used to control the number of decision
    trees voting in the ensemble, with a default value of `25`. Depending on the difficulty
    of the learning task and the amount of training data, increasing this number may
    improve the model’s performance, up to a limit. The downside is that this creates
    additional computational expense, and a large number of trees may take some time
    to train.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'After installing the `ipred` package, we can create the ensemble as follows.
    We’ll stick to the default value of `25` decision trees:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The resulting `mybag` model works as expected in concert with the `predict()`
    function:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Given the preceding results, the model seems to have fit the data extremely
    well—*too well*, probably, as the results are based only on the training data
    and thus may reflect overfitting rather than true performance on future unseen
    data. To obtain a better estimate of future performance, we can use the bagged
    decision tree method in the `caret` package to obtain a 10-fold CV estimate of
    accuracy and kappa. Note that the method name for the `ipred` bagging function
    is `treebag`:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The kappa statistic of 0.33 for this model suggests that the bagged tree model
    performs roughly as well as the C5.0 decision tree we tuned earlier in this chapter,
    which had a kappa statistic ranging from 0.32 to 0.34, depending on the tuning
    parameters. Keep this performance in mind as you read the next section, and consider
    the differences between the simple bagging technique and the more complex methods
    that build upon it.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Boosting
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another common ensemble-based method is called **boosting** because it improves
    or “boosts” the performance of weak learners to attain the performance of stronger
    learners. This method is based largely on the work of Robert Schapire and Yoav
    Freund, who have published extensively on the topic since the 1990s.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'For additional information on boosting, refer to *Boosting: Foundations and
    Algorithms, Schapire, RE, Freund, Y, Cambridge, MA: The MIT Press, 2012*.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Like bagging, boosting uses ensembles of models trained on resampled data and
    a vote to determine the final prediction. There are two key distinctions. First,
    the resampled datasets in boosting are constructed specifically to generate complementary
    learners. This means that the work cannot occur in parallel, as the ensemble’s
    models are no longer independent from one another. Second, rather than giving
    each learner an equal vote, boosting gives each learner a vote that is weighted
    based on its past performance. Models that perform better have greater influence
    over the ensemble’s final prediction.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Boosting will result in performance that is often somewhat better and certainly
    no worse than the best model in the ensemble. Since the models in the ensemble
    are purposely built to be complementary, it is possible to increase ensemble performance
    to an arbitrary threshold simply by adding additional classifiers to the group,
    assuming that each additional classifier performs better than random chance. Given
    the obvious utility of this finding, boosting is thought to be one of the most
    significant discoveries in machine learning.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Although boosting can create a model that meets an arbitrarily low error rate,
    this may not always be reasonable in practice. One reason for this is that the
    performance gains are incrementally smaller as additional learners are gained,
    making some thresholds practically infeasible. Additionally, the pursuit of pure
    accuracy may result in the model being overfitted to the training data and not
    generalizable to unseen data.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: A boosting algorithm called **AdaBoost**, short for **adaptive boosting**, was
    proposed by Freund and Schapire in 1997\. The algorithm is based on the idea of
    generating weak learners that iteratively learn a larger portion of the difficult-to-classify
    examples in the training data by paying more attention (that is, giving more weight)
    to often misclassified examples.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Beginning from an unweighted dataset, the first classifier attempts to model
    the outcome. Examples that the classifier predicted correctly will be less likely
    to appear in the training dataset for the following classifier, and conversely,
    the difficult-to-classify examples will appear more frequently. As additional
    rounds of weak learners are added, they are trained on data with successively
    more difficult examples. The process continues until the desired overall error
    rate is reached or performance no longer improves. At that point, each classifier’s
    vote is weighted according to its accuracy on the training data on which it was
    built.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Though boosting principles can be applied to nearly any type of model, the principles
    are most often used with decision trees. We already applied the boosting technique
    earlier in this chapter, as well as in *Chapter 5*, *Divide and Conquer – Classification
    Using Decision Trees and Rules*, as a method to improve the performance of a C5.0
    decision tree. With C5.0, boosting can be enabled by simply setting a `trials`
    parameter to an integer value greater than one.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The **AdaBoost.M1** algorithm provides a standalone implementation of AdaBoost
    for classification with trees. The algorithm can be found in the `adabag` package.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information about the `adabag` package, refer to *adabag: An R Package
    for Classification with Boosting and Bagging, Alfaro, E, Gamez, M, Garcia, N,
    Journal of Statistical Software, 2013, Vol. 54, pp. 1-35*.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create an `AdaBoost.M1` classifier for the credit data. The general syntax
    for this algorithm is similar to other modeling techniques:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As usual, the `predict()` function is applied to the resulting object to make
    predictions:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Departing from convention, rather than returning a vector of predictions, this
    returns an object with information about the model. The predictions are stored
    in a sub-object called `class`:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'A confusion matrix can be found in the `confusion` sub-object:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Before you get your hopes up about the perfect accuracy, note that the preceding
    confusion matrix is based on the model’s performance on the training data. Since
    boosting allows the error rate to be reduced to an arbitrarily low level, the
    learner simply continued until it made no more errors. This likely resulted in
    overfitting on the training dataset.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'For a more accurate assessment of performance on unseen data, we need to use
    another evaluation method. The `adabag` package provides a simple function to
    use 10-fold CV:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Depending on your computer’s capabilities, this may take some time to run,
    during which it will log each iteration to the screen—on a recent MacBook Pro
    computer, it took about a minute. After it completes, we can view a more reasonable
    confusion matrix:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can find the kappa statistic using the `vcd` package, as demonstrated in
    *Chapter 10*, *Evaluating Model Performance*:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: With a kappa of `0.3397`, the boosted model is slightly outperforming the bagged
    decision trees, which had a kappa of around `0.3319`. Let’s see how boosting compares
    to another ensemble method.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Note that the prior results were obtained using R version 4.2.3 on a Windows
    PC and verified on Linux. At the time this was written, slightly different results
    are obtained using R 4.2.3 for Apple silicon on a recent MacBook Pro. Also note
    that the AdaBoost.M1 algorithm can be tuned with `caret` by specifying `method
    = "AdaBoost.M1"`.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Random forests
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Yet another tree-based ensemble-based method, called **random forests**, builds
    upon the principles of bagging but adds additional diversity to the decision trees
    by only allowing the algorithm to choose from a randomly selected subset of features
    each time it attempts to split. Beginning at the root node, the random forest
    algorithm might only be allowed to choose from a small number of features selected
    at random from the full set of predictors; at each subsequent split, a different
    random subset is provided. As is the case for bagging, once the ensemble of trees
    (the forest) is generated, the algorithm performs a simple vote to make the final
    prediction.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: For more detail on how random forests are constructed, refer to *Random Forests,
    Breiman L, Machine Learning, 2001, Vol. 45, pp. 5-32*. Note that the phrase “random
    forests” is trademarked by Breiman and Cutler but is used colloquially to refer
    to any type of decision tree ensemble. A pedant would use the more general term
    **decision tree forests** except when referring to their specific implementation.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: The fact that each tree is built on different and randomly selected sets of
    features helps ensure that each tree in the ensemble is unique. It is even possible
    that two trees in the forest may have been built from completely different sets
    of features. Random feature selection limits the decision tree’s greedy heuristic
    from picking the same low-hanging fruit each time the tree is grown, which may
    help the algorithm discover subtle patterns that the standard tree-growing method
    may miss. On the other hand, the potential for overfitting is limited given that
    each tree has just one vote of many in the forest.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'Given these strengths, it is no surprise that the random forest algorithm quickly
    grew to become one of the most popular learning algorithms—only recently has its
    hype been surpassed by a newer ensemble method, which you will learn about shortly.
    Random forests combine versatility and power into a single machine learning approach
    and are not especially prone to overfitting or underfitting. Because the tree-growing
    algorithm uses only a small, random portion of the full feature set, random forests
    can handle extremely large datasets, where the so-called curse of dimensionality
    might cause other models to fail. At the same time, its predictive performance
    on most learning tasks is as good as, if not better than, all but the most sophisticated
    methods. The following table summarizes the strengths and weaknesses of random
    forest models:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strengths** | **Weaknesses** |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
- en: '|'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: An all-purpose model that performs well on most problems, including both classification
    and numeric prediction
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can handle noisy or missing data as well as categorical or continuous features
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selects only the most important features
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be used on data with an extremely large number of features or examples
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Unlike a decision tree, the model is not easily interpretable
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: May struggle with categorical features with very large numbers of levels
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cannot be extensively tuned if greater performance is desired
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Their strong performance combined with the ease of use makes random forests
    a terrific place to begin most real-world machine learning projects. The algorithm
    also provides a solid benchmark for other comparisons with highly tuned models,
    as well as the other, more complex approaches you will learn about later.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'For a hands-on demonstration of random forests, we’ll apply the technique to
    the credit-scoring data we’ve been using in this chapter. Although there are several
    packages with random forest implementations in R, the aptly named `randomForest`
    package is perhaps the simplest, while the `ranger` package offers much better
    performance on large datasets. Both are supported by the `caret` package for experimentation
    and automated parameter tuning. The syntax for training a model with `randomForest`
    is as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B17290_14_06.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.6: Random forest syntax'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: By default, the `randomForest()` function creates an ensemble of 500 decision
    trees that each consider `sqrt(p)` random features at each split, where `p` is
    the number of features in the training dataset and `sqrt()` refers to R’s square
    root function. For example, since the credit data has 16 features, each of the
    500 decision trees would be allowed to consider only *sqrt*(*16*) = *4* predictors
    each time the algorithm attempts to split.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Whether or not these default `ntree` and `mtry` parameters are appropriate depends
    on the nature of the learning task and training data. Generally, more complex
    learning problems and larger datasets (both more features as well as more examples)
    warrant a larger number of trees, though this needs to be balanced with the computational
    expense of training more trees. Once the `ntree` parameter is set to a sufficiently
    large value, the `mtry` parameter can be tuned to determine the best setting;
    however, the default tends to work well in practice. Assuming the number of trees
    is large enough, the number of randomly selected features can be surprisingly
    low before performance is degraded—but trying a few values is still a good practice.
    Ideally, the number of trees should be set large enough such that each feature
    has a chance of appearing in several models.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how the default `randomForest()` parameters work with the credit
    data. We’ll train the model just as we have done with other learners. As usual,
    the `set.seed()` function ensures that the result can be replicated:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'For a summary of model performance, we can simply type the resulting object’s
    name:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The output shows that the random forest included 500 trees and tried four variables
    at each split, as expected. At first glance, you might be alarmed at the seemingly
    poor performance according to the confusion matrix—the error rate of 23.3 percent
    is far worse than the resubstitution error of any of the other ensemble methods
    so far. However, this confusion matrix does not show a resubstitution error. Instead,
    it reflects the **out-of-bag error rate** (listed in the output as `OOB estimate
    of error rate`), which, unlike a resubstitution error, is an unbiased estimate
    of the test set error. This means that it should be a fair estimate of future
    performance.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The out-of-bag estimate is computed using a clever technique during the construction
    of the random forest. Essentially, any example not selected for a single tree’s
    bootstrap sample can be used to test the model’s performance on unseen data. At
    the end of the forest construction, for each of the 1,000 examples in the dataset,
    any trees that did not use the example in training are allowed to make a prediction.
    These predictions are tallied, and a vote is taken to determine the single final
    prediction for the example. The total error rate of such predictions across all
    1,000 examples becomes the out-of-bag error rate. Because each prediction uses
    only a subset of the forest, it is not equivalent to a true validation or test
    set estimation, but it is a reasonable substitute.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapter 10*, *Evaluating Model Performance*, it was stated that any given
    example has a 63.2 percent chance of being included in a bootstrap sample. This
    implies that an average of 36.8 percent of the 500 trees in the random forest
    voted for each of the 1,000 examples in the out-of-bag estimate.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: 'To calculate the kappa statistic on the out-of-bag predictions, we can use
    the function in the `vcd` package as follows. The code applies the `Kappa()` function
    to the first two rows and columns of the `confusion` object, which stores the
    confusion matrix of the out-of-bag predictions for the `rf` random forest model
    object:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: With a kappa statistic of `0.381`, the random forest is our best-performing
    model yet. Its performance was better than the bagged decision tree ensemble,
    which had a kappa of about `0.332`, as well as the AdaBoost.M1 model, which had
    a kappa of about `0.340`.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: The `ranger` package, as mentioned previously, is a substantially faster implementation
    of the random forest algorithm. For a dataset as small as the credit dataset,
    optimizing for computational efficiency may be less important than ease of use,
    and by default, `ranger` sacrifices some conveniences in order to increase speed
    and reduce the memory footprint. Consequently, although the `ranger` function
    is nearly identical to `randomForest()` in syntax, in practice, you may find that
    it breaks existing code or takes a bit of digging through the help pages.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: 'To recreate the previous model using `ranger`, we simply change the function
    name:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The resulting model has quite a similar out-of-bag prediction error:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We can compute kappa much as before while noting the slight difference in how
    the model’s confusion matrix sub-object was named:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The kappa value is `0.381`, which is the same as the result from the earlier
    random forest model. Note that this is coincidental, as the two algorithms are
    not guaranteed to produce identical results.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: As with AdaBoost, the prior results were obtained using R version 4.2.3 on a
    Windows PC and verified on Linux. At the time this was written, slightly different
    results are obtained using R 4.2.3 for Apple silicon on a recent MacBook Pro.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: Gradient boosting
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Gradient boosting** is an evolution of the boosting algorithm based on the
    finding that it is possible to treat the boosting process as an optimization problem
    to be solved using the gradient descent technique. We first encountered gradient
    descent in *Chapter 7*, *Black-Box Methods – Neural Networks and Support Vector
    Machines*, where it was introduced as a solution to optimize the weights in a
    neural network. You may recall that a cost function—essentially, the prediction
    error—relates the input values to the target. Then, by systematically analyzing
    how changes to the weights affect the cost, it is possible to find the set of
    weights that minimizes the cost. Gradient boosting treats the process of boosting
    in much the same way, with the weak learners in the ensemble being treated as
    the parameters to optimize. Models using this technique are termed **gradient
    boosting machines** or **generalized boosting models**—both of which can be abbreviated
    as **GBMs**.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'For more on GBMs, see *Greedy Function Approximation: A Gradient Boosting Machine,
    Friedman JH, 2001, Annals of Statistics 29(5):1189-1232*.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: The following table summarizes the strengths and weaknesses of GBMs. In short,
    gradient boosting is extremely powerful and can produce some of the most accurate
    models but may require tuning to find the balance between over- and underfitting.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strengths** | **Weaknesses** |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
- en: '|'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: An all-purpose classifier that can perform extremely well on both classification
    and numeric prediction
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can achieve even better performance than random forests
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performs well on large datasets
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: May require tuning to match the performance of the random forest algorithm and
    more extensive tuning to exceed its performance
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because there are several hyperparameters to tune, finding the best combination
    requires many iterations and more computing power
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the `gbm()` function in the `gbm` package for creating GBMs for both
    classification and numeric prediction. You’ll need to install and load this package
    to your R session if you haven’t already. As the following box shows, the syntax
    is like the machine learning functions used previously, but it has several new
    parameters that may need to be adjusted. These parameters control the complexity
    of the model and the balance between over- and underfitting. Without tuning, the
    GBM may not perform as well as simpler methods, but it generally can surpass the
    performance of most other methods once parameter values have been optimized.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_14_07.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.7: Gradient boosting machine (GBM) syntax'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: 'We can train a simple GBM to predict loan defaults on the `credit` dataset
    as follows. For simplicity, we set `stringsAsFactors = TRUE` to avoid recoding
    the predictors, but then the target `default` feature must be converted back to
    a binary outcome, as the `gbm()` function requires this for binary classification.
    We’ll create a random sample for training and testing, then apply the `gbm()`
    function to the training data, leaving the parameters set to their defaults:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Typing the name of the model provides some basic information about the GBM
    process:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'More importantly, we can evaluate the model on the test set. Note that we need
    to convert the predictions to binary, as they are given as probabilities. If the
    probability of loan default is greater than 50 percent, we will predict default,
    otherwise, we predict non-default. The table shows the agreement between the predicted
    and actual values:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'To measure the performance, we’ll apply the `Kappa()` function to this table:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The resulting kappa value of about `0.361` is better than what was obtained
    with the boosted decision tree, but worse than the random forest model. Perhaps
    with a bit of tuning, we can get this higher.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use the `caret` package to tune the GBM model and obtain a more robust
    performance measure. Recall that tuning needs a search grid, which we can define
    for GBM as follows. This will test three values for three of the `gbm()` function
    parameters and one value for the remaining parameter, which results in *3 * 3
    * 3 * 1 = 27* models to evaluate:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Next, we set the `trainControl` object to select the best model from a 10-fold
    CV experiment:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Lastly, we read in the `credit` dataset and supply the required objects to
    the `caret()` function while specifying the `gbm` method and the `Kappa` performance
    metric. Depending on the capabilities of your computer, this may take a few minutes
    to run:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Typing the name of the object shows the results of the experiment. Note that
    some lines of output have been omitted for brevity, but the full output contains
    27 rows—one for each model evaluated:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: From the output, we can see that the best GBM model had a kappa of `0.394`,
    which exceeds the random forest trained previously. With additional tuning, it
    may be possible to bring the kappa up even higher. Or, as you will see in the
    next section, a more intensive form of boosting can be employed in the pursuit
    of even better performance.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Extreme gradient boosting with XGBoost
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A cutting-edge implementation of the gradient boosting technique can be found
    in the **XGBoost** algorithm (`https://xgboost.ai`), which takes boosting to the
    “extreme” by improving the algorithm’s efficiency and performance. In the time
    since the algorithm was introduced in 2014, XGBoost has been found on top of the
    leaderboards of many machine learning competitions. In fact, according to the
    algorithm’s authors, among 29 winning solutions on Kaggle in 2015, a total of
    17 used the XGBoost algorithm. Likewise, in the 2015 KDD Cup (described in *Chapter
    11*, *Being Successful with Machine Learning*), all of the top 10 winners used
    XGBoost. Today, the algorithm is still the champion for traditional machine learning
    problems involving classification and numeric prediction, whereas its closest
    challenger, deep neural networks, tends to win only on unstructured data, such
    as image, audio, and text processing.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information on XGBoost, see *XGBoost: A Scalable Tree Boosting System,
    Chen T and Guestrin C, 2016*. [https://arxiv.org/abs/1603.02754](https://arxiv.org/abs/1603.02754).'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: 'The great power of the XGBoost algorithm comes with the downside that the algorithm
    is not quite as easy to use and requires substantially more tuning than other
    methods examined so far. On the other hand, its performance ceiling tends to be
    higher than any other approach. The strengths and weaknesses of XGBoost are found
    in the following table:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '| **Strengths** | **Weaknesses** |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
- en: '|'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: An all-purpose classifier that can perform extremely well on both classification
    and numeric prediction
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perhaps undisputedly, the current champion of performance on traditional learning
    problems; wins virtually every machine learning competition on structured data
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Highly scalable, performs well on large datasets, and can be run in parallel
    on distributed computing platforms
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: More challenging to use than other functions, as it relies on external frameworks
    that do not use native R data structures
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requires extensive tuning of a large set of hyperparameters that can be difficult
    to understand without a strong math background
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because there are many tuning parameters, finding the best combination requires
    many iterations and more computing power
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Results in a “black box” model that is nearly impossible to interpret without
    explainability tools
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply the algorithm, we’ll use the `xgboost()` function in the `xgboost`
    package, which provides an R interface to the XGBoost framework. Entire books
    could be written about this framework, as it includes features for many types
    of machine learning tasks, and is highly extensible and adaptable to many high-performance
    computing environments. For more information about the XGBoost framework, see
    the excellent documentation on the web at [https://xgboost.readthedocs.io](https://xgboost.readthedocs.io).
    Our work will focus on a narrow slice of its functionality, as shown in the following
    syntax box, which is much denser than those for other algorithms due to a large
    increase in complexity and hyperparameters that may be tuned:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_14_08.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.8: XGBoost (XGB) syntax'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: One of the challenges with using XGBoost in R is its need to use data in matrix
    format rather than R’s preferred formats of tibbles or data frames. Because XGBoost
    is designed for extremely large datasets, it can also use sparse matrices, such
    as those discussed in previous chapters. You may recall that a sparse matrix only
    stores non-zero values, which makes it more memory-efficient than traditional
    matrices when many feature values are zeros.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: Data in matrix form is often sparse because factors are typically one-hot or
    dummy coded during the transition between the data frame and matrix. These encodings
    create additional columns for additional levels of the factor, and all columns
    are set to zero except the one “hot” value that indicates the level for the given
    example. In the case of dummy coding, one feature level is left out of the transformation,
    so it results in one fewer column than one-hot; the missing level can be indicated
    by the presence of zeros in all of the *n* - *1* columns.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: One-hot and dummy coding generally produce the same results, with the exception
    that statistics-based models like regression require dummy coding and will present
    errors or warning messages if one-hot is used instead.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin by reading the `credit.csv` file and creating a sparse matrix of
    data from the `credit` data frame. The `Matrix` package provides a function to
    perform this task, which uses the R formula interface to determine the columns
    to include in the matrix. Here, the formula `~ . -default` tells the function
    to use all features except `default`, which we don’t want in the matrix, as this
    is our target feature for prediction:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'To confirm our work, let’s check the dimensions of the matrix:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We still have 1,000 rows, but the columns have increased from 16 features in
    the original data frame to 36 in the sparse matrix. This is due to the dummy coding
    that was applied automatically when converting to matrix form. We can see this
    if we examine the first five rows and 15 columns of the sparse matrix using the
    `print()` function:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The matrix is depicted with the dot (`.`) character indicating cells with zero
    values. The first column (`1`, `2`, `3`, `4`, `5`) is the row number and the second
    column (`1`, `1`, `1`, `1`, `1`) is a column for the intercept term, which was
    added automatically by the R formula interface. Two columns have numbers (`6`,
    `48`, …) and (`1169`, `5951`, …) that correspond to the numeric values of the
    `months_loan_duration` and `amount` features, respectively. All other columns
    are dummy-coded versions of factor variables. For instance, the third, fourth,
    and fifth columns reflect the `checking_balance` feature, with a `1` in the third
    column indicating a value of `'> 200 DM'`, a `1` in the fourth column indicating
    `'1 – 200 DM'`, and a 1 in the fifth column indicating the `'unknown'` feature
    value. Rows showing the sequence `. . .` in columns 3, 4, and 5 fall into the
    reference category, which was the `'< 0 DM'` feature level.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we are not building a regression model, the intercept column full of
    `1` values is useless for this analysis and can be removed from the matrix:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Next, we’ll split the matrix at random into training and test sets using a
    90-10 split as we’ve done before:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'To confirm the work was done correctly, we’ll check the dimensions of these
    matrices:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: As expected, the training set has 900 rows and 35 columns, and the test set
    has 100 rows and a matching set of columns.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we’ll create training and test vectors of labels for `default`, the
    target to be predicted. These are transformed from factors to binary `1` or `0`
    values using an `ifelse()` function so that they can be used to train and evaluate
    the XGBoost model, respectively:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We’re now ready to start building the model. After installing the `xgboost`
    package, we’ll load the library and start to define the hyperparameters for training.
    Without knowing where else to begin, we’ll set the values to their defaults:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Next, after setting the random seed, we’ll train the model, supplying our parameters
    object as well as the matrix of training data and the target labels. The `nrounds`
    parameter determines the number of boosting iterations. Without a better guess,
    we’ll set this to `100`, which is a common starting point due to empirical evidence
    suggesting that results tend to improve very little beyond this value. Lastly,
    the `verbose` and `print_every_n` options are used to turn on diagnostic output
    and display the progress after every 10 boosting iterations:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The output should appear as the training is completed, showing that all 100
    iterations occurred and the training error (labeled `train-logloss`) continued
    to decline with additional rounds of boosting:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Knowing whether additional iterations would help the model performance or result
    in overfitting is something we can determine via tuning later. Before doing so,
    let’s look at the performance of this trained model on the test set, which we
    held out earlier. First, the `predict()` function obtains the predicted probability
    of loan default for each row of test data:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Then, we use `ifelse()` to predict a default (value `1`) if the probability
    of a default is at least 0.50, or non-default (value `0`) otherwise:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Comparing the predicted to actual values, we find an accuracy of *(62 + 14)
    / 100 = 76* percent:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'On the other hand, the kappa statistic suggests there is still room to improve:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The value of `0.3766` is a bit lower than the `0.394` we obtained with the
    GBM model, so perhaps a bit of hyperparameter tuning can help. For this, we’ll
    use `caret`, starting with a tuning grid comprising a variety of options for each
    of the hyperparameters:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The resulting grid contains *2 * 3 * 2 * 3 * 3 * 2 * 1 = 216* different combinations
    of `xgboost` hyperparameter values. We’ll evaluate each of these potential models
    in `caret` using 10-fold CV, as we’ve done for other models. Note that the `verbosity`
    parameter is set to zero so that the `xgboost()` function output is suppressed
    for the many iterations:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Depending on the capabilities of your computer, the experiment may take a few
    minutes to complete, but once it finishes, typing `m_xgb` will provide the results
    of all 216 models tested. We can also obtain the best model directly as follows:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The kappa value for this model can be found using the `max()` function to find
    the highest value as follows:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: The kappa value of `0.406` is our best-performing model so far, exceeding the
    `0.394` of the GBM model and the `0.381` of the random forest. The fact that XGBoost
    required so little effort to train—with a bit of fine-tuning—yet still surpassed
    other powerful techniques provides examples of why it always seems to win machine
    learning competitions. Yet, with even more tuning, it may be possible to go higher
    still! Leaving that as an exercise to you, the reader, we’ll now turn our attention
    to the question of why all of these popular ensembles seem to focus exclusively
    on decision tree-based methods.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: Why are tree-based ensembles so popular?
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After reading the prior sections, you would not be the first person to wonder
    why ensembling algorithms seem to always be built upon decision trees. Although
    trees are not required for building an ensemble, there are several reasons why
    they are especially well-suited for this process. You may have noted some of them
    already:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: Ensembles work best with diversity, and because decision trees are not robust
    to small changes in the data, random sampling the same training data can easily
    create a diverse set of tree-based models
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because of the greedy “divide-and-conquer” based algorithm, decision trees are
    computationally efficient and perform relatively well despite this fact
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision trees can be grown purposely large or small to overfit and underfit
    as needed
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision trees can automatically ignore irrelevant features, which reduces the
    negative impact of the “curse of dimensionality”
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision trees can be used for numeric prediction as well as classification
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on these characteristics, it is not difficult to see why we’ve ended up
    with a wealth of tree-based ensembling approaches such as bagging, boosting, and
    random forests. The distinctions among them are subtle but important.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table may help contrast the tree-based ensembling algorithms
    covered in this chapter:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '| **Ensembling Algorithm** | **Allocation Function** | **Combination Function**
    | **Other Notes** |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
- en: '| Bagging | Provides each learner with a bootstrap sample of the training data
    | The learners are combined using a vote for classification or a weighted average
    for numeric prediction | Uses an independent ensemble — the learners can be run
    in parallel |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
- en: '| Boosting | The first learner is given a random sample; subsequent samples
    are weighted to have more difficult-to-predict cases | The learners’ predictions
    are combined as above but weighted according to their performance on training
    data | Uses a dependent ensemble — each tree in the sequence receives data that
    earlier trees found challenging |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
- en: '| Random Forest | Like bagging, each tree receives a bootstrap sample of training
    data; however, features are also randomly selected for each tree split | Similar
    to bagging | Similar to bagging, but the added diversity via random feature selection
    allows additional benefits for larger ensembles |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
- en: '| Gradient Boosting Machine (GBM) | Conceptually similar to boosting | Similar
    to boosting, but there are many more learners and they comprise a complex mathematical
    function | Uses gradient descent to make a more efficient boosting algorithm;
    the trees are generally not very deep (decision tree “stumps”) but there are many
    more of them; requires more tuning |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
- en: '| eXtreme Gradient Boosting (XGB) | Similar to GBM | Similar to GBM | Similar
    to GBM but more extreme; uses optimized data structures, parallel processing,
    and heuristics to create a very performant boosting algorithm; tuning is essential
    |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
- en: To be able to distinguish among these approaches reveals a deep understanding
    of several aspects of ensembling. Additionally, the most recent techniques, such
    as random forests and gradient boosting, are among the best-performing learning
    algorithms and are being used as off-the-shelf solutions to solve some of the
    most challenging business problems. This may help explain why companies hiring
    data scientists and machine learning engineers often ask candidates to describe
    or compare these algorithms as part of the interview process. Thus, even though
    tree-based ensembling algorithms are not the only approach to machine learning,
    it is important to be aware of their potential uses. However, as the next section
    describes, trees aren’t the only approach to building a diverse ensemble.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: Stacking models for meta-learning
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rather than using a canned ensembling method like bagging, boosting, or random
    forests, there are situations in which a tailored approach to ensembling is warranted.
    Although these tree-based ensembling techniques combine hundreds or even thousands
    of learners into a single, stronger learner, the process is not much different
    than training a traditional machine learning algorithm, and suffers some of the
    same limitations, albeit to a lesser degree. Being based on decision trees that
    have been weakly trained and minimally tuned may, in some cases, put a ceiling
    on the ensemble’s performance relative to one composed of a more diverse set of
    learning algorithms that have been extensively tuned with the benefit of human
    intelligence. Furthermore, although it is possible to parallelize tree-based ensembles
    like random forests and XGB, this only parallelizes the computer’s effort—not
    the human effort of model building.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, it is possible to increase an ensemble’s diversity by not only adding
    additional learning algorithms but by distributing the work of model building
    to additional human teams working in parallel. In fact, many of the world’s competition-winning
    models were built by taking other teams’ best models and ensembling them together.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: This type of ensemble is conceptually quite simple, offering performance boosts
    that would be otherwise unobtainable, but can become complex in practice. Getting
    the implementation details correct is crucial to avoid disastrous levels of overfitting.
    Done correctly, the ensemble will perform at least as well as the strongest model
    in the ensemble, and often substantially better.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: 'Examining **receiver operating characteristic** (**ROC**) curves, as introduced
    in *Chapter 10*, *Evaluating Model Performance*, provides a simple method to determine
    whether two or more models would benefit from ensembling. If two models have intersecting
    ROC curves, their **convex hull**—the outermost boundary that would be obtained
    by stretching an imaginary rubber band around the curves—represents a hypothetical
    model that can be obtained by interpolating, or combining, the predictions from
    these models. As depicted in *Figure 14.9*, two ROC curves with identical **area
    under the curve** (**AUC**) values of *0.70* might create a new model with an
    AUC of *0.72* when paired in an ensemble:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, radar chart  Description automatically generated](img/B17290_14_09.png)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.9: When two or more ROC curves intersect, their convex hull represents
    a potentially better classifier that can be generated by combining their predictions
    in an ensemble'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: Because this form of ensembling is performed largely by hand, a human needs
    to provide the allocation and combination functions for the models in the ensemble.
    In their simplest form, these can be implemented quite pragmatically. For example,
    suppose that the same training dataset has been given to three different teams.
    This is the allocation function. These teams can use this dataset however they
    see fit to build the best possible model using evaluation criteria of their choosing.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, each team is given the test set, and their models are used to make predictions,
    which must be combined into a single, final prediction. The combination function
    can take multiple different forms: the groups could vote, the predictions could
    be averaged, or the predictions could be weighted according to how well each group
    performed in the past. Even the simple approach of choosing one group at random
    is a viable strategy, assuming each group performs better than all others at least
    once in a while. Of course, even more intelligent approaches are possible, as
    you will soon learn.'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: Understanding model stacking and blending
  id: totrans-395
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some of the most sophisticated custom ensembles apply machine learning to learn
    a combination function for the final prediction. Essentially, it is trying to
    learn which models can and cannot be trusted. This arbiter learner may realize
    that one model in the ensemble is a poor performer and shouldn’t be trusted or
    that another deserves more weight in the ensemble. The arbiter function may also
    learn more complex patterns. For example, suppose that when models *M1* and *M2*
    agree on the outcome, the prediction is almost always accurate, but otherwise
    *M3* is generally more accurate than either of the two. In this case, an additional
    arbiter model could learn to ignore the vote of *M1* and *M2* except when they
    agree. This process of using the predictions of several models to train a final
    model is called **stacking**.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, clipart  Description automatically generated](img/B17290_14_10.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.10: Stacking is a sophisticated ensemble that uses an arbiter learning
    algorithm to combine the predictions of a set of learners and make a final prediction'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: More broadly, stacking falls within a methodology known as **stacked generalization**.
    As formally defined, the stack is constructed using first-level models that have
    been trained via CV, and a second-level model or **meta-model** that is trained
    using the predictions for the out-of-fold samples—the examples the model does
    not see during training but is tested on during the CV process.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose three first-level models are included in the stack and
    each one is trained using 10-fold CV. If the training dataset includes 1,000 rows,
    each of the three first-stage models is trained on 900 rows and tested on 100
    rows ten times. The 100-row test sets, when combined, comprise the entire training
    dataset.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: 'As all three models have made a prediction for every row of the training data,
    a new table can be constructed with four columns and 1,000 rows: the first three
    columns represent the predictions for the three models and column four represents
    the true value of the target. Note that because the predictions made for each
    of these 100 rows were made on the other 900 rows, all 1,000 rows are predictions
    on unseen data. This allows the second-stage meta-model, which is often a regression
    or logistic regression model, to learn which first-stage models perform better
    by training using the predicted values as the predictors of the true value. This
    process of finding the optimal combination of learners is sometimes called **super
    learning**, and the resulting model may be called a **super learner**. This process
    is often performed by machine learning software or packages, which train numerous
    learning algorithms in parallel and stack them together automatically.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated with medium confidence](img/B17290_14_11.png)'
  id: totrans-402
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.11: In a stacked ensemble, the second-stage meta-model or “super
    learner” learns from the predictions of the first-stage models on out-of-fold
    samples'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: For a more hands-on approach, a special case of stacked generalization called
    **blending** or **holdout stacking** provides a simplified way to implement stacking
    by replacing CV with a holdout sample. This allows the work to be distributed
    across teams more easily by merely dividing the training data into a training
    set for the first-level models and using a holdout set for the second-level meta-learner.
    It may also be less prone to overfitting the CV “information leak” described in
    *Chapter 11*, *Being Successful with Machine Learning*. Thus, even though it is
    a simple approach, it can be quite effective; blending is often what competition-winning
    teams do when they take other models and ensemble them together for better results.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: The terminology around stacking, blending, and super learning is somewhat fuzzy,
    and many use the terms interchangeably.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: Practical methods for blending and stacking in R
  id: totrans-406
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To perform blending in R requires a careful roadmap, as getting the details
    wrong can lead to extreme overfitting and models that perform no better than random
    guessing. The following figure illustrates the process. Begin by imagining that
    you are tasked with predicting loan defaults and have access to one million rows
    of past data. Immediately, you should partition the dataset into training and
    test sets; of course, the test set should be kept in a vault for evaluating the
    ensemble later. Assume the training set is 750,000 rows and the test set is 250,000
    rows. The training set must then be divided yet again to create datasets for training
    the level one models and the level two meta-learner. The exact proportions are
    somewhat arbitrary, but it is customary to use a smaller set for the second-stage
    model—sometimes as low as ten percent. As *Figure 14.12* depicts, we might use
    500,000 rows for level one and 250,000 rows for level two:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_14_12.png)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.12: The full training dataset must be divided into distinct subsets
    for training the level one and level two models'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: The 500,000-row level one training dataset is used to train the first-level
    models exactly as we have done many times throughout this book. The *M1*, *M2*,
    and *M3* models may use any learning algorithm, and the work of building these
    models can even be distributed across different teams working independently.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: There is no need for the models or teams to use the same set of features from
    the training data or the same form of feature engineering, assuming each team’s
    feature engineering pipeline can be replicated or automated in the future when
    the ensemble is to be deployed. The important thing is that *M1*, *M2*, and *M3*
    should be able to take a dataset with identical features and produce a prediction
    for each row.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: 'The 250,000-row level two training dataset is then fed into the *M1*, *M2*,
    and *M3* models after being processed through their associated feature engineering
    pipelines, and three vectors of 250,000 predictions are obtained. These vectors
    are labeled *p1*, *p2*, and *p3* in the diagram. When combined with the 250,000
    true values of the target (labeled *c* in the diagram) obtained from the level
    two training dataset, a four-column data frame is produced, as depicted in *Figure
    14.13*:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B17290_14_13.png)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.13: The dataset used to train the meta-model is composed of the predictions
    from the first-level models and the actual target value from the level two training
    data'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: This type of data frame is used to create a meta-model, typically using regression
    or logistic regression, which predicts the actual target value (*c* in *Figure
    14.12*) using the predictions of *M1*, *M2*, and *M3* (*p1*, *p2*, and *p3* in
    *Figure 14.12*) as predictors. In an R formula, this might be specified in a form
    like `c ~ p1 + p2 + p3`, which results in a model that weighs the input from three
    different predictions to make its own final prediction.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: To estimate the future performance of this final meta-model, we must use the
    250,000-row test set, which, as illustrated in *Figure 14.12* previously, was
    held out during the training process. As shown in *Figure 14.14*, the test dataset
    is then fed to the *M1*, *M2*, and *M3* models and their associated feature engineering
    pipelines, and much like in the previous step, three vectors of 250,000 predictions
    are obtained. However, rather than *p1*, *p2*, and *p3* being used to train a
    meta-model, they are now used as predictors for the existing meta-model to obtain
    a final prediction (labeled *p4*) for each of the 250,000 test cases. This vector
    can be compared to the 250,000 true values of the target in the test set to perform
    the performance evaluation and obtain an unbiased estimate of the ensemble’s future
    performance.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17290_14_14.png)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.14: To obtain an unbiased estimate of the ensemble’s future performance,
    the test set is used to generate predictions for the level one models, which are
    then used to obtain the meta-model’s final predictions'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: 'The above methodology is flexible to create other interesting types of ensembles.
    *Figure 14.15* illustrates a blended ensemble that combines models trained on
    completely different subsets of features. Specifically, it envisions a learning
    task in which Twitter profile data is used to make a prediction about the user—perhaps
    their gender or whether they would be interested in purchasing a particular product:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram, timeline  Description automatically generated](img/B17290_14_15.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.15: The stack’s first-level models can be trained on different features
    in the training set, while the second-level model is trained on their predictions'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: The first model receives the profile’s picture and trains a deep learning neural
    network with the image data to predict the outcome. Model two receives a set of
    tweets for the user and uses a text-based model like Naive Bayes to predict the
    outcome. Lastly, model three is a more conventional model using a traditional
    data frame of demographic data like location, total number of tweets, last login
    date, and so on.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: All three models are combined, and the meta-model can learn whether the image,
    text, or profile data is most helpful for predicting the gender or purchasing
    behavior. Alternatively, because the meta-model is a logistic regression model
    like *M3*, it would be possible to supply the profile data directly to the second-stage
    model and skip the construction of *M3* altogether.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: Aside from constructing blended ensembles by hand as described here, there is
    a growing set of R packages to assist with this process. The `caretEnsemble` package
    can assist with ensemble models trained with the `caret` package and ensure that
    the stack’s sampling is handled correctly for stacking or blending. The `SuperLearner`
    package provides an easy way to create a super learner; it can apply dozens of
    base algorithms to the same dataset and stack them together automatically. As
    an off-the-shelf algorithm, this may be useful for building a powerful ensemble
    with the least amount of effort.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-425
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After reading this chapter, you should now know the approaches that are used
    to win data mining and machine learning competitions. Automated tuning methods
    can assist with squeezing every bit of performance out of a single model. On the
    other hand, tremendous gains are possible by creating groups of machine learning
    models called ensembles, which work together to achieve greater performance than
    single models can by working alone. A variety of tree-based algorithms, including
    random forests and gradient boosting, provide the benefits of ensembles but can
    be trained as easily as a single model. On the other hand, learners can be stacked
    or blended into ensembles by hand, which allows the approach to be carefully tailored
    to a learning problem.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: With a variety of options for improving the performance of a model, where should
    someone begin? There is no single best approach, but practitioners tend to fall
    into one of three camps. First, some begin with one of the more sophisticated
    ensembles such as random forests or XGBoost, and spend most of their time tuning
    and feature engineering to achieve the highest possible performance for this model.
    A second group might try a variety of approaches, then collect the models into
    a single stacked or blended ensemble to create a more powerful learner. The third
    approach might be described as “throw everything at the computer and see what
    sticks.” This attempts to feed the learning algorithm as much data as possible
    and as quickly as possible, and is sometimes combined with automated feature engineering
    or dimensionality reduction techniques like those described in the previous chapters.
    With practice, you may be drawn to some of these ideas more than others, so feel
    free to use whichever works best for you.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: Although this chapter was designed to help you prepare competition-ready models,
    note that your fellow competitors have access to the same techniques. You won’t
    be able to get away with stagnancy; therefore, continue to add proprietary methods
    to your bag of tricks. Perhaps you can bring unique subject-matter expertise to
    the table, or perhaps your strengths include an eye for detail in data preparation.
    In any case, practice makes perfect, so take advantage of competitions to test,
    evaluate, and improve your machine learning skillset. In the next chapter—the
    last in this book—we’ll look at ways to apply cutting-edge “big data” techniques
    to some highly specialized and difficult data tasks using R.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  id: totrans-429
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 4000 people at:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/r](https://packt.link/r)'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/r.jpg)'
  id: totrans-432
  prefs: []
  type: TYPE_IMG
