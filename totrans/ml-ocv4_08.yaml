- en: Detecting Pedestrians with Support Vector Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we talked about how to use decision trees for classification
    and regression. In this chapter, we want to direct our attention to another well-established
    supervised learner in the machine learning world: **support vector machines** (**SVMs**).
    Soon after their introduction in early 1990, SVMs quickly became popular in the
    machine learning community, largely because of their success in early handwritten
    digit classification. They remain relevant to this day, especially in application
    domains, such as computer vision.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of this chapter is to apply SVMs to a popular problem in computer vision: pedestrian
    detection. In contrast to a recognition task (where we name the category of an
    object), the goal of a detection task is to say whether a particular object (or
    in our case, a pedestrian) is present in an image or not. You might already know
    that OpenCV can do this in two to three lines of code. But, we won't learn anything
    if we do it that way. So instead, we'll build the whole pipeline from scratch!
    We will obtain a real-world dataset, perform feature extraction using the **histogram
    of oriented gradients** (**HOG**), and apply an SVM to it.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will implement SVMs in OpenCV with Python. We will learn
    to deal with nonlinear decision boundaries and understand the kernel trick. By
    the end of the chapter, we will learn to detect pedestrians in the wild.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along the way, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing SVMs in OpenCV with Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with nonlinear decision boundaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the kernel trick
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting pedestrians in the wild
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Excited? Then let's go!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can refer to the codes for this chapter from the following link: [https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter06](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter06).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a short summary of the software and hardware requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: OpenCV version 4.1.x (4.1.0 or 4.1.1 will both work just fine).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python version 3.6 (any Python version 3.x will be fine).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anaconda Python 3 for installing Python and the required modules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use any operating system—macOS, Windows, and Linux-based OS—with this
    book. We recommend you to have at least 4 GB RAM in your system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You don't need to have a GPU to run the code provided with the book.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding linear SVMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to understand how SVMs work, we have to think about decision boundaries.
    When we used linear classifiers or decision trees in earlier chapters, our goal
    was always to minimize the classification error. We did this by assessing the
    accuracy using mean squared error. An SVM tries to achieve low classification
    errors too, but it does so only implicitly. An SVM's explicit objective is to
    maximize the margins between data points of
  prefs: []
  type: TYPE_NORMAL
- en: Learning optimal decision boundaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's look at a simple example. Consider some training samples with only two
    features (*x* and *y* values) and a corresponding target label (positive (+) or
    negative (-)). Since the labels are categorical, we know that this is a classification
    task. Moreover, because we only have two distinct classes (+ and -), it's a binary
    classification task.
  prefs: []
  type: TYPE_NORMAL
- en: In a binary classification task, a decision boundary is a line that partitions the
    training set into two subsets, one for each class. An **optimal** **decision** **boundary** partitions
    the data so that all data samples from one class (say, +) are to the left of the
    decision boundary, and all other data samples (say, -) are to the right of it.
  prefs: []
  type: TYPE_NORMAL
- en: An SVM updates its choice of a decision ...
  prefs: []
  type: TYPE_NORMAL
- en: Implementing our first SVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: But enough with the theory. Let's do some coding!
  prefs: []
  type: TYPE_NORMAL
- en: It might be a good idea to pace ourselves. For our very first SVM, we should
    probably focus on a simple dataset, perhaps a binary classification task.
  prefs: []
  type: TYPE_NORMAL
- en: 'A cool trick about scikit-learn''s `datasets` module that I haven''t told you
    about is that you can generate random datasets of controlled size and complexity.
    A few notable ones are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`datasets.make_classification([n_samples, ...])`: This function generates a
    random *n*-class classification problem, where we can specify the number of samples,
    the number of features, and the number of target labels'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`datasets.make_regression([n_samples, ...])`: This function generates a random
    regression problem'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`datasets.make_blobs([n_samples, n_features, ...])`: This function generates
    a number of Gaussian blobs we can use for clustering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This means that we can use `make_classification` to build a custom dataset for
    a binary classification task.
  prefs: []
  type: TYPE_NORMAL
- en: Generating the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we can now recite in our sleep, a binary classification problem has exactly
    two distinct target labels (`n_classes=2`). For the sake of simplicity, let''s
    limit ourselves to only two feature values (`n_features=2`; for example, an *x* and
    a *y* value). Let''s say we want to create 100 data samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We expect `X` to have 100 rows (data samples) and 2 columns (features), whereas
    the `y` vector should have a single column that contains all the target labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Visualizing the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can plot these data points in a scatter plot using Matplotlib. Here, the
    idea is to plot the *x* values (found in the first column of `X`, `X[:, 0]`) against
    the *y* values (found in the second column of `X`, `X[:, 1]`). A neat trick is
    to pass the target labels as color values (`c=y`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/446f1f5d-ef34-4521-952f-09087174d16e.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding output shows the randomly generated data for a binary classification
    problem. You can see that, for the most part, data points of the two classes are
    clearly separated. However, there are a few regions (particularly near the left
    and bottom of the plot) where the data points of both classes intermingle. These
    will be hard to classify correctly, as we will see in just a second.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next step is to split the data points into training and test sets, as we
    have done before. But, before we do that, we have to prepare the data for OpenCV
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: All feature values in `X` must be 32-bit floating point numbers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Target labels must be either -1 or +1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can achieve this with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can pass the data to scikit-learn''s `train_test_split` function as
    we did in the earlier chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here, I chose to reserve 20 percent of all data points for the test set, but
    ...
  prefs: []
  type: TYPE_NORMAL
- en: Building the support vector machine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In OpenCV, SVMs are built, trained, and scored the same exact way as every
    other learning algorithm we have encountered so far, using the following four
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Call the `create` method to construct a new SVM:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in the following command, there are different *modes* in which we
    can operate an SVM. For now, all we care about is the case we discussed in the
    previous example: an SVM that tries to partition the data with a straight line.
    This can be specified with the `setKernel` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Call the classifier''s `train` method to find the optimal decision boundary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Call the classifier''s `predict` method to predict the target labels of all
    data samples in the test set:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Use scikit-learn''s `metrics` module to score the classifier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations, we got 80 percent correctly classified test samples!
  prefs: []
  type: TYPE_NORMAL
- en: Of course, so far we have no idea what happened under the hood. For all we know,
    we might as well have got these commands off a web search and typed them into
    the Terminal, without really knowing what we're doing. But this is not who we
    want to be. Getting a system to work is one thing and understanding it is another. Let's
    get to that!
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the decision boundary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'What was true in trying to understand our data is true for trying to understand
    our classifier: visualization is the first step in understanding a system. We
    know the SVM somehow came up with a decision boundary that allowed us to correctly
    classify 80 percent of the test samples. But how can we find out what that decision
    boundary actually looks like?'
  prefs: []
  type: TYPE_NORMAL
- en: For this, we will borrow a trick from the guys behind scikit-learn. The idea
    is to generate a fine grid of *x* and *y* coordinates and run that through the
    SVM's `predict` method. This will allow us to know, for every *(x, y)* point,
    what target label the classifier would have predicted.
  prefs: []
  type: TYPE_NORMAL
- en: We will do this in a dedicated function, which we call `plot_decision_boundary
    ...`
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with nonlinear decision boundaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What if the data cannot be optimally partitioned using a linear decision boundary?
    In such a case, we say the data is not linearly separable*.*
  prefs: []
  type: TYPE_NORMAL
- en: The basic idea to deal with data that is not linearly separable is to create nonlinear
    combinations of the original features. This is the same as saying we want to project
    our data to a higher-dimensional space (for example, from 2D to 3D), in which
    the data suddenly becomes linearly separable.
  prefs: []
  type: TYPE_NORMAL
- en: 'This concept is illustrated in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/61a436e0-d761-4823-bdb7-339eac903fe7.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram shows how to find linear hyperplanes in higher-dimensional
    spaces. If data in its original input space (left) cannot be linearly separated,
    we can apply a mapping function *ϕ(.)* that projects the data from 2D into a 3D
    (or a high-dimensional) space. In this higher-dimensional space, we may find that
    there is now a linear decision boundary (which, in 3D, is a plane) that can separate the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: A linear decision boundary in an *n*-dimensional space is called a **hyperplane**.
    For example, a decision boundary in 6D feature space is a 5D hyperplane; in 3D
    feature space, it's a regular 2D plane; and in 2D space, it's a straight line.
  prefs: []
  type: TYPE_NORMAL
- en: However, one problem with this mapping approach is that it is impractical in
    large dimensions because it adds a lot of extra terms to do the mathematical projections
    between the dimensions. This is where the so-called **kernel trick** comes into
    play.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the kernel trick
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Granted, we won't have time to develop all the mathematics needed to truly understand
    the kernel trick. A more realistic section title would have been *Acknowledging
    that something called the kernel trick exists and accepting that it works,* but
    that would have been a bit wordy.
  prefs: []
  type: TYPE_NORMAL
- en: Here's the kernel trick in a nutshell.
  prefs: []
  type: TYPE_NORMAL
- en: In order to figure out the slope and orientation of the decision hyperplane
    in the high-dimensional space, we have to multiply all the feature values with
    appropriate weight values and sum them all up. The more dimensions our feature
    space has, the more work we have to do.
  prefs: []
  type: TYPE_NORMAL
- en: However, mathematicians smarter than us have long realized that an SVM has no
    need to explicitly work in the higher-dimensional ...
  prefs: []
  type: TYPE_NORMAL
- en: Knowing our kernels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'OpenCV provides a whole range of SVM kernels to experiment with. Some of the
    most commonly used ones include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cv2.ml.SVM_LINEAR`: This is the kernel we used previously. It provides a linear
    decision boundary in the original feature space (the *x* and *y* values).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.ml.SVM_POLY`: This kernel provides a decision boundary that is a polynomial
    function in the original feature space. In order to use this kernel, we also have
    to specify a coefficient via `svm.setCoef0` (usually set to `0`) and the degree
    of the polynomial via `svm.setDegree`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.ml.SVM_RBF`: This kernel implements the kind of Gaussian function we discussed
    earlier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.ml.SVM_SIGMOID`: This kernel implements a sigmoid function, similar to
    the one we encountered when talking about logistic regression in [Chapter 3](323dbb44-1e2b-4eaa-8cd1-2575e6766ffc.xhtml), *First
    Steps in Supervised Learning*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cv2.ml.SVM_INTER`: This kernel is a new addition to OpenCV 3\. It separates
    classes based on the similarity of their histograms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing nonlinear SVMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to test some of the SVM kernels we just talked about, we will return
    to our code sample mentioned earlier. We want to repeat the process of building
    and training the SVM on the dataset generated earlier, but this time, we want
    to use a whole range of different kernels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Do you remember what all of these stand for?
  prefs: []
  type: TYPE_NORMAL
- en: Setting a different SVM kernel is relatively simple. We take an entry from the `kernels` list
    and pass it to the `setKernels` method of the SVM class. That's all.
  prefs: []
  type: TYPE_NORMAL
- en: 'The laziest way to repeat things is to use a `for` loop as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then the steps are as follows: ...'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting pedestrians in the wild
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We briefly talked about the difference between detection and recognition. While
    recognition is concerned with classifying objects (for example, as pedestrians,
    cars, bicycles, and so on), detection is basically answering the question: is
    there a pedestrian present in this image?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The core idea behind most detection algorithms is to split up an image into
    many small patches, and then classify each image patch as either containing a
    pedestrian or not. This is exactly what we are going to do in this section. In
    order to arrive at our own pedestrian detection algorithm, we need to perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Build a database of images containing pedestrians. These will be our positive
    data samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a database of images not containing pedestrians. These will be our negative
    data samples.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train an SVM on the dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the SVM to every possible patch of a test image in order to decide whether
    the overall image contains a pedestrian.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Obtaining the dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the purpose of this section, we will work with the MIT People dataset, which
    we are free to use for non-commercial purposes. So make sure not to use this in
    your groundbreaking autonomous start-up company before obtaining a corresponding
    software license.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you followed our installation instructions from earlier and checked
    out the code on GitHub, you already have the dataset and are ready to go! The
    file can be found at [https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/blob/master/data/chapter6/pedestrians128x64.tar.gz](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/blob/master/data/chapter6/pedestrians128x64.tar.gz).
  prefs: []
  type: TYPE_NORMAL
- en: 'By referring to the following steps, you will learn to detect pedestrians in
    the wild:'
  prefs: []
  type: TYPE_NORMAL
- en: Since we are supposed to run this code from a Jupyter Notebook in the ...
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Taking a glimpse at the histogram of oriented gradients (HOG)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The HOG might just provide the help we're looking for in order to get this project
    done. The HOG is a feature descriptor for images, much like the ones we discussed
    in [Chapter 4](142fec63-a847-4cde-9de9-c34805d2bb84.xhtml), *Representing Data
    and Engineering Features*. It has been successfully applied to many different
    tasks in computer vision but seems to work especially well for classifying people.
  prefs: []
  type: TYPE_NORMAL
- en: The essential idea behind HOG features is that the local shapes and appearance
    of objects within an image can be described by the distribution of edge directions.
    The image is divided into small connected regions, within which a histogram of
    gradient directions (or edge directions) is compiled. Then, the descriptor is
    assembled by concatenating the different histograms. For improved performance,
    the local histograms can also be contrast-normalized, which results in better
    invariance to changes in illumination and shadowing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The HOG descriptor is fairly accessible in OpenCV by means of `cv2.HOGDescriptor`,
    which takes a bunch of input arguments, such as the detection window size (minimum
    size of the object to be detected, 48 x 96), the block size (how large each box
    is, 16 x 16), the cell size (8 x 8), and the cell stride (how many pixels to move
    from one cell to the next, 8 x 8). For each of these cells, the HOG descriptor
    then calculates a histogram of oriented gradients using nine bins:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Although this function call looks fairly complicated, these are actually the
    only values for which the HOG descriptor is implemented. The argument that matters
    the most is the window size (`win_size`).
  prefs: []
  type: TYPE_NORMAL
- en: 'All that''s left to do is call `hog.compute` on our data samples. For this,
    we build a dataset of positive samples (`X_pos`) by randomly picking pedestrian
    images from our data directory. In the following code snippet, we randomly select
    400 pictures from the over 900 available, and apply the HOG descriptor to them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We should also remember that OpenCV wants the feature matrix to contain 32-bit
    floating point numbers, and the target labels to be 32-bit integers. We don''t
    mind, since converting to NumPy arrays will allow us to easily investigate the
    sizes of the matrices we created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: It looks like we picked a total of 399 training samples, each of which has 1,980
    feature values (which are the HOG feature values).
  prefs: []
  type: TYPE_NORMAL
- en: Generating negatives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The real challenge, however, is to come up with the perfect example of a non-pedestrian.
    After all, it's easy to think of example images of pedestrians. But what is the
    opposite of a pedestrian?
  prefs: []
  type: TYPE_NORMAL
- en: This is actually a common problem when trying to solve new machine learning
    problems. Both research labs and companies spend a lot of time creating and annotating
    new datasets that fit their specific purpose.
  prefs: []
  type: TYPE_NORMAL
- en: If you're stumped, let me give you a hint on how to approach this. A good first
    approximation to finding the opposite of a pedestrian is to assemble a dataset
    of images that look like the images of the positive class but do not contain pedestrians.
    These images could contain anything like cars, bicycles, streets, houses, ...
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the SVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We already know how to build an SVM in OpenCV, so there''s nothing much to
    see here. Planning ahead, we wrap the training procedure into a function, so that
    it''s easier to repeat the procedure in the future:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The same can be done for the scoring function. Here we pass a feature matrix, `X` and
    a label vector, `y`, but we do not specify whether we''re talking about the training
    or the test set. In fact, from the viewpoint of the function, it doesn''t matter
    what set the data samples belong to, as long as they have the right format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can train and score the SVM with two short function calls:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Thanks to the HOG feature descriptor, we make no mistake on the training set.
    However, our generalization performance is quite abysmal (64.6 percent), as it
    is much less than the training performance (100 percent). This is an indication
    that the model is overfitting the data. The fact that it is performing way better
    on the training set than the test set means that the model has resorted to memorizing
    the training samples, rather than trying to abstract it into a meaningful decision
    rule. What can we do to improve the model performance?
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrapping the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An interesting way to improve the performance of our model is to use bootstrapping.
    This idea was actually applied in one of the first papers on using SVMs in combination with
    HOG features for pedestrian detection. So let's pay a little tribute to the pioneers
    and try to understand what they did.
  prefs: []
  type: TYPE_NORMAL
- en: Their idea was quite simple. After training the SVM on the training set, they
    scored the model and found that the model produced some false positives. Remember
    that false positive means that the model predicted a positive (+) for a sample
    that was really a negative (-). In our context, this would mean the SVM falsely
    believed an image to contain a pedestrian. If this happens for a particular image
    in the dataset, this example ...
  prefs: []
  type: TYPE_NORMAL
- en: Detecting pedestrians in a larger image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What's left to do is to connect the SVM classification procedure with the process
    of detection. The way to do this is to repeat our classification for every possible
    patch in the image. This is similar to what we did earlier when we visualized
    decision boundaries; we created a fine grid and classified every point on that
    grid. The same idea applies here. We divide the image into patches and classify
    every patch as either containing a pedestrian or not.
  prefs: []
  type: TYPE_NORMAL
- en: 'By following these steps, you will be able to detect a pedestrian in an image:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We first have to loop over all possible patches in an image as follows, each
    time shifting our region of interest by a small number of `stride` pixels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We want to make sure that we do not go beyond the image boundaries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we cut out the ROI, preprocess it, and classify it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'If that particular patch happens to be classified as a pedestrian, we add it
    to the list of successes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Because pedestrians could appear not just at various locations but also in
    various sizes, we would have to rescale the image and repeat the whole process.
    Thankfully, OpenCV has a convenience function for this multi-scale detection task in
    the form of the `detectMultiScale` function. This is a bit of a hack, but we can
    pass all SVM parameters to the `hog` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then it''s possible to call the detection function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The function will return a list of bounding boxes that contain detected pedestrians.
  prefs: []
  type: TYPE_NORMAL
- en: This seems to work only for linear SVM classifiers. The OpenCV documentation
    is terribly inconsistent across versions in this regard, so I'm not sure at which
    version this started or stopped working. Be careful!
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, when people are faced with a standard task such as pedestrian
    detection, they often rely on pre-scanned SVM classifiers that are built into
    OpenCV. This is the method that I hinted at in the very beginning of this chapter.
    By loading either `cv2.HOGDescriptor_getDaimlerPeopleDetector()` or `cv2.HOGDescriptor_getDefaultPeopleDetector()`,
    we can get started with only a few lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s easy to plot the test image with matplotlib as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can mark the detected pedestrians in the image by looping over the
    bounding boxes in `found`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d871221-d88e-4ca8-9913-5c9e6c669582.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot shows detected pedestrians in a test image.
  prefs: []
  type: TYPE_NORMAL
- en: Further improving the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the RBF kernel makes for a good default kernel, it is not always the
    one that works best for our problem. The only real way to know which kernel works
    best on our data is to try them all and compare the classification performance
    across models. There are strategic ways to perform this so-called **hyperparameter
    tuning**, which we'll talk about in detail in [Chapter 11](904bc419-cb0e-44cd-ae3f-8ce97e15baa2.xhtml), *Selecting
    the Right Model with Hyperparameter Tuning.*
  prefs: []
  type: TYPE_NORMAL
- en: What if we don't know how to do hyperparameter tuning properly yet?
  prefs: []
  type: TYPE_NORMAL
- en: Well, I'm sure you remember the first step in data understanding, *visualize
    the data*. Visualizing the data could help us understand if a linear SVM was powerful
    enough to classify the data, in which case there would be no ...
  prefs: []
  type: TYPE_NORMAL
- en: Multiclass classification using SVMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SVMs are inherently two-class classifiers. In particular, the most prevalent
    method of multi-class classification in practice has been to create *|C|* one-versus-rest
    classifiers (commonly referred to as **one-versus-all** (**OVA**) classification)
    where *|C|* is the number of classesand to choose the class that classifies the
    test datum with the highest margin. Another approach is to develop a set of one-versus-one
    classifiers and to select the class that is chosen by the most classifiers. While
    this involves building *|C|(|C| - 1)/2* classifiers, the time for training classifiers
    may decrease, since the training data set for each classifier is much smaller.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's quickly jump onto how you can apply multi-class classification using
    SVMs with the help of a real-life dataset.
  prefs: []
  type: TYPE_NORMAL
- en: For the purpose of this section, we will work with the UCI Human Activity Recognition
    using smartphones dataset, which we are free to use for non-commercial purposes.
    So make sure not to use this in your groundbreaking autonomous start-up company
    before obtaining a corresponding software license.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset can be obtained from the Kaggle website, [https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones](https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones).
    There you should find a Download button that leads you to a file called [https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/downloads/human-activity-recognition-with-smartphones.zip/1](https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/downloads/human-activity-recognition-with-smartphones.zip/1).
  prefs: []
  type: TYPE_NORMAL
- en: However, if you followed our installation instructions from earlier and checked
    out the code on GitHub, you already have the dataset and are ready to go! The
    file can be found at `notebooks/data/multiclass`.
  prefs: []
  type: TYPE_NORMAL
- en: About the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A group of 30 volunteers were chosen within an age group of 19-48 years and
    the experiments were carried out on them. Six activities were performed by each
    person, namely `Walking`, `Walking_Upstairs`, `Walking_Downstairs`, `Sitting`,
    `Standing`, and `Laying` with the help of a smartphone fastened around the waist.
    Mainly three-axial linear acceleration and three-axial angular velocity at a constant
    rate of 50 Hz were captured using embedded accelerometer and gyroscope. To label
    the data, the experiments have been video-recorded. The dataset has been randomly
    split into two sets, where 70% of the volunteers were selected for generating
    the training data and 30% the test data.
  prefs: []
  type: TYPE_NORMAL
- en: Attribute information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For each entry in the dataset, the following is provided:'
  prefs: []
  type: TYPE_NORMAL
- en: Triaxial acceleration from the accelerometer and the approximate acceleration
    of the body
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Triaxial angular velocity from the gyroscope
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time and frequency domain variables with 561-feature vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Various labels of activity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An identifier of the subject who was observed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By referring to the following steps, you will learn how to build a multi-class
    classification using SVMs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s quickly import all the necessary libraries that you will need in order
    to implement an SVM with multi-class classification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, you will be loading the dataset. Since we are supposed to run this code
    from a Jupyter Notebook in the `notebooks/` directory, the relative path to the
    data directory is simply `data/`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check whether there are any missing values in the training and testing
    dataset; if there are any, then we will simply drop them from the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will find the frequency distribution of the classes in the data, which
    means that we will check how many samples belong to each of the six classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'From the following screenshot, you can observe that the `LAYING` class has
    the most samples, but overall, the data is approximately equally distributed and
    there are no major signs of class imbalance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5196c8be-e10f-4176-ad2a-e2fb5e211252.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Next, we will separate out the predictors (input values) and outcome values
    (class labels) from the train and test datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the SVM expects numerical input and labels, you will now transform the
    non-numerical labels into numerical labels. But first, we will have to import
    a  `preprocessing` module from the `sklearn` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will encode the train and test labels into numerical values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will scale (normalise) the train and test feature set and for this,
    you will import `StandardScaler` from `sklearn`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the data is scaled and the labels are in a correct format, now is the
    time when we will fit the data. But before that, we will define a dictionary with
    the different parameter settings that the SVM will use while training itself,
    and this technique is called `GridSearchCV`. The parameter grid will be based
    on the results of a random search:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will call `GridSearchCV` on the data using the preceding parameters
    for the best SVM fit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s time to check how well the SVM model was trained on the data; in short,
    we will find the accuracy. Not only that, but we will also check what the parameter
    settings were for which SVM performed the best:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Voila! As we can see, the SVM achieved 98.6% accuracy on the training data
    on a multi-class classification problem. But hold down your horses until we find
    the accuracy on the test data. So, let''s quickly check that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Wow! Isn't that amazing? We were able to achieve 95.86% accuracy on the testing
    set; that's the power of SVMs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about SVMs in all their forms and flavors. We now
    know how to draw decision boundaries in 2D and hyperplanes in high-dimensional
    spaces. We learned about different SVM kernels and look at how to implement them
    in OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we also applied our newly gained knowledge to the practical example
    of pedestrian detection. For this, we had to learn about the HOG feature descriptor,
    and how to collect suitable data for the task. We used bootstrapping to improve
    the performance of our classifier and combined the classifier with OpenCV's multi-scale
    detection mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Not only was that a lot to digest in a single chapter, but you have also made
    it through half of the book. Congrats!
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, ...
  prefs: []
  type: TYPE_NORMAL
