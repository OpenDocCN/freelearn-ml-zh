- en: Detecting Pedestrians with Support Vector Machines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用支持向量机检测行人
- en: In the previous chapter, we talked about how to use decision trees for classification
    and regression. In this chapter, we want to direct our attention to another well-established
    supervised learner in the machine learning world: **support vector machines** (**SVMs**).
    Soon after their introduction in early 1990, SVMs quickly became popular in the
    machine learning community, largely because of their success in early handwritten
    digit classification. They remain relevant to this day, especially in application
    domains, such as computer vision.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了如何使用决策树进行分类和回归。在这一章中，我们想要将注意力转向机器学习世界中另一个已确立的监督学习器：**支持向量机（SVMs**）。在1990年代初引入后不久，SVMs迅速在机器学习社区中流行起来，这主要归功于它们在早期手写数字分类中的成功。它们至今仍然相关，尤其是在应用领域，如计算机视觉。
- en: The goal of this chapter is to apply SVMs to a popular problem in computer vision: pedestrian
    detection. In contrast to a recognition task (where we name the category of an
    object), the goal of a detection task is to say whether a particular object (or
    in our case, a pedestrian) is present in an image or not. You might already know
    that OpenCV can do this in two to three lines of code. But, we won't learn anything
    if we do it that way. So instead, we'll build the whole pipeline from scratch!
    We will obtain a real-world dataset, perform feature extraction using the **histogram
    of oriented gradients** (**HOG**), and apply an SVM to it.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是将支持向量机（SVMs）应用于计算机视觉中一个流行的问题：行人检测。与识别任务（我们命名对象的类别）不同，检测任务的目标是判断特定对象（在我们的案例中，是行人）是否在图像中存在。你可能已经知道OpenCV可以在两到三行代码中完成这项任务。但是，如果我们那样做，我们将一无所获。所以，我们将从头开始构建整个流程！我们将获取一个真实世界的数据集，使用**方向梯度直方图（HOG**）进行特征提取，并将其应用于SVM。
- en: In this chapter, we will implement SVMs in OpenCV with Python. We will learn
    to deal with nonlinear decision boundaries and understand the kernel trick. By
    the end of the chapter, we will learn to detect pedestrians in the wild.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Python在OpenCV中实现SVMs。我们将学习如何处理非线性决策边界并理解核技巧。到本章结束时，我们将学习如何在野外检测行人。
- en: 'Along the way, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，我们将涵盖以下主题：
- en: Implementing SVMs in OpenCV with Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python在OpenCV中实现SVMs
- en: Dealing with nonlinear decision boundaries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理非线性决策边界
- en: Understanding the kernel trick
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解核技巧
- en: Detecting pedestrians in the wild
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在野外检测行人
- en: Excited? Then let's go!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 激动吗？那么让我们开始吧！
- en: Technical requirement
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can refer to the codes for this chapter from the following link: [https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter06](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter06).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从以下链接获取本章的代码：[https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter06](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/tree/master/Chapter06).
- en: 'Here is a short summary of the software and hardware requirements:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是软件和硬件要求的简要总结：
- en: OpenCV version 4.1.x (4.1.0 or 4.1.1 will both work just fine).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV版本4.1.x（4.1.0或4.1.1都完全可以工作）。
- en: Python version 3.6 (any Python version 3.x will be fine).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python版本3.6（任何3.x版本的Python都可以）。
- en: Anaconda Python 3 for installing Python and the required modules.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Python和所需模块的Anaconda Python 3。
- en: You can use any operating system—macOS, Windows, and Linux-based OS—with this
    book. We recommend you to have at least 4 GB RAM in your system.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用任何操作系统——macOS、Windows和基于Linux的操作系统——使用这本书。我们建议您系统至少有4GB RAM。
- en: You don't need to have a GPU to run the code provided with the book.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不需要GPU来运行书中提供的代码。
- en: Understanding linear SVMs
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解线性SVMs
- en: In order to understand how SVMs work, we have to think about decision boundaries.
    When we used linear classifiers or decision trees in earlier chapters, our goal
    was always to minimize the classification error. We did this by assessing the
    accuracy using mean squared error. An SVM tries to achieve low classification
    errors too, but it does so only implicitly. An SVM's explicit objective is to
    maximize the margins between data points of
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解SVMs是如何工作的，我们必须考虑决策边界。当我们使用早期章节中的线性分类器或决策树时，我们的目标始终是尽量减少分类错误。我们通过使用均方误差来评估准确性来实现这一点。SVM试图实现低分类错误，但它只是隐式地这样做。SVM的明确目标是最大化数据点之间的**间隔**。
- en: Learning optimal decision boundaries
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习最优决策边界
- en: Let's look at a simple example. Consider some training samples with only two
    features (*x* and *y* values) and a corresponding target label (positive (+) or
    negative (-)). Since the labels are categorical, we know that this is a classification
    task. Moreover, because we only have two distinct classes (+ and -), it's a binary
    classification task.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个简单的例子。考虑一些只有两个特征（*x*值和*y*值）和相应的目标标签（正（+）或负（-））的训练样本。由于标签是分类的，我们知道这是一个分类任务。此外，因为我们只有两个不同的类别（+和-），所以这是一个二分类任务。
- en: In a binary classification task, a decision boundary is a line that partitions the
    training set into two subsets, one for each class. An **optimal** **decision** **boundary** partitions
    the data so that all data samples from one class (say, +) are to the left of the
    decision boundary, and all other data samples (say, -) are to the right of it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在二分类任务中，决策边界是一条将训练集分割成两个子集的线，每个类别一个。一个**最优**的**决策****边界**将数据分割，使得一个类别的所有数据样本（比如+）位于决策边界左侧，而所有其他数据样本（比如-）位于其右侧。
- en: An SVM updates its choice of a decision ...
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: SVM更新其决策选择 ...
- en: Implementing our first SVM
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现我们的第一个SVM
- en: But enough with the theory. Let's do some coding!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但理论就到这里吧。让我们来写一些代码！
- en: It might be a good idea to pace ourselves. For our very first SVM, we should
    probably focus on a simple dataset, perhaps a binary classification task.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 可能有一个好主意，放慢我们的步伐。对于我们的第一个SVM，我们可能应该专注于一个简单的数据集，也许是一个二分类任务。
- en: 'A cool trick about scikit-learn''s `datasets` module that I haven''t told you
    about is that you can generate random datasets of controlled size and complexity.
    A few notable ones are as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关于scikit-learn的`datasets`模块的一个酷技巧，我没有告诉你的是，你可以生成具有可控大小和复杂度的随机数据集。以下是一些值得注意的例子：
- en: '`datasets.make_classification([n_samples, ...])`: This function generates a
    random *n*-class classification problem, where we can specify the number of samples,
    the number of features, and the number of target labels'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`datasets.make_classification([n_samples, ...])`: 这个函数生成一个随机的*n*类分类问题，其中我们可以指定样本数量、特征数量和目标标签数量。'
- en: '`datasets.make_regression([n_samples, ...])`: This function generates a random
    regression problem'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`datasets.make_regression([n_samples, ...])`: 这个函数生成一个随机的回归问题。'
- en: '`datasets.make_blobs([n_samples, n_features, ...])`: This function generates
    a number of Gaussian blobs we can use for clustering'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`datasets.make_blobs([n_samples, n_features, ...])`: 这个函数生成一系列高斯云团，我们可以用它们来进行聚类。'
- en: This means that we can use `make_classification` to build a custom dataset for
    a binary classification task.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以使用`make_classification`为二分类任务构建一个自定义数据集。
- en: Generating the dataset
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成数据集
- en: 'As we can now recite in our sleep, a binary classification problem has exactly
    two distinct target labels (`n_classes=2`). For the sake of simplicity, let''s
    limit ourselves to only two feature values (`n_features=2`; for example, an *x* and
    a *y* value). Let''s say we want to create 100 data samples:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们现在可以睡梦中背诵一样，一个二分类问题恰好有两个不同的目标标签（`n_classes=2`）。为了简化，让我们只限制自己使用两个特征值（`n_features=2`；例如，一个*x*值和一个*y*值）。假设我们想要创建100个数据样本：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We expect `X` to have 100 rows (data samples) and 2 columns (features), whereas
    the `y` vector should have a single column that contains all the target labels:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望`X`有100行（数据样本）和2列（特征），而`y`向量应该只有一个列，包含所有目标标签：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Visualizing the dataset
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化数据集
- en: 'We can plot these data points in a scatter plot using Matplotlib. Here, the
    idea is to plot the *x* values (found in the first column of `X`, `X[:, 0]`) against
    the *y* values (found in the second column of `X`, `X[:, 1]`). A neat trick is
    to pass the target labels as color values (`c=y`):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Matplotlib将这些数据点绘制在散点图上。在这里，我们的想法是将*x*值（在`X`的第一个列中找到，`X[:, 0]`）与*y*值（在`X`的第二个列中找到，`X[:,
    1]`）进行绘图。一个巧妙的技巧是将目标标签作为颜色值传递（`c=y`）：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will produce the following output:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/446f1f5d-ef34-4521-952f-09087174d16e.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/446f1f5d-ef34-4521-952f-09087174d16e.png)'
- en: The preceding output shows the randomly generated data for a binary classification
    problem. You can see that, for the most part, data points of the two classes are
    clearly separated. However, there are a few regions (particularly near the left
    and bottom of the plot) where the data points of both classes intermingle. These
    will be hard to classify correctly, as we will see in just a second.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的输出显示了用于二分类问题的随机生成数据。你可以看到，大部分数据点的两个类别是明显分开的。然而，有几个区域（尤其是图表的左下角附近）两个类别的数据点交织在一起。这些区域将很难正确分类，正如我们将在下一秒看到的那样。
- en: Preprocessing the dataset
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预处理数据集
- en: 'The next step is to split the data points into training and test sets, as we
    have done before. But, before we do that, we have to prepare the data for OpenCV
    as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将数据点划分为训练集和测试集，就像我们之前做的那样。但在我们这样做之前，我们必须按照以下方式准备数据：
- en: All feature values in `X` must be 32-bit floating point numbers
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X`中的所有特征值必须是32位浮点数'
- en: Target labels must be either -1 or +1
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标标签必须是-1或+1
- en: 'We can achieve this with the following code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下代码实现这一点：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we can pass the data to scikit-learn''s `train_test_split` function as
    we did in the earlier chapters:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以像在早期章节中做的那样，将数据传递给scikit-learn的`train_test_split`函数：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, I chose to reserve 20 percent of all data points for the test set, but
    ...
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我选择保留所有数据点的20%作为测试集，但...
- en: Building the support vector machine
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建支持向量机
- en: 'In OpenCV, SVMs are built, trained, and scored the same exact way as every
    other learning algorithm we have encountered so far, using the following four
    steps:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCV中，SVM的构建、训练和评分与迄今为止我们遇到的所有其他学习算法完全相同，使用以下四个步骤：
- en: 'Call the `create` method to construct a new SVM:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用`create`方法来构建一个新的SVM：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As shown in the following command, there are different *modes* in which we
    can operate an SVM. For now, all we care about is the case we discussed in the
    previous example: an SVM that tries to partition the data with a straight line.
    This can be specified with the `setKernel` method:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下命令所示，有几种不同的*modes*可以操作SVM。目前，我们只关心之前讨论过的例子：一个试图用直线划分数据的SVM。这可以通过`setKernel`方法指定：
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Call the classifier''s `train` method to find the optimal decision boundary:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用分类器的`train`方法以找到最佳决策边界：
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Call the classifier''s `predict` method to predict the target labels of all
    data samples in the test set:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用分类器的`predict`方法来预测测试集中所有数据样本的目标标签：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Use scikit-learn''s `metrics` module to score the classifier:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用scikit-learn的`metrics`模块对分类器进行评分：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Congratulations, we got 80 percent correctly classified test samples!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，我们得到了80%正确分类的测试样本！
- en: Of course, so far we have no idea what happened under the hood. For all we know,
    we might as well have got these commands off a web search and typed them into
    the Terminal, without really knowing what we're doing. But this is not who we
    want to be. Getting a system to work is one thing and understanding it is another. Let's
    get to that!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，到目前为止，我们并不知道内部发生了什么。据我们所知，我们可能只是从网络搜索中获取了这些命令，并将它们输入到终端中，而实际上并不了解我们在做什么。但这不是我们想要成为的人。让系统工作是一回事，而理解它是另一回事。让我们来了解这一点！
- en: Visualizing the decision boundary
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化决策边界
- en: 'What was true in trying to understand our data is true for trying to understand
    our classifier: visualization is the first step in understanding a system. We
    know the SVM somehow came up with a decision boundary that allowed us to correctly
    classify 80 percent of the test samples. But how can we find out what that decision
    boundary actually looks like?'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试理解我们的数据时是正确的，对于尝试理解我们的分类器也是正确的：可视化是理解系统的第一步。我们知道SVM以某种方式找到了一个决策边界，使我们能够正确分类80%的测试样本。但我们如何找出这个决策边界实际上是什么样子呢？
- en: For this, we will borrow a trick from the guys behind scikit-learn. The idea
    is to generate a fine grid of *x* and *y* coordinates and run that through the
    SVM's `predict` method. This will allow us to know, for every *(x, y)* point,
    what target label the classifier would have predicted.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将从scikit-learn背后的那些人那里借用一个技巧。想法是生成一个细密的*x*和*y*坐标网格，并通过SVM的`predict`方法运行它。这将使我们能够知道，对于每个*(x,
    y)*点，分类器会预测什么目标标签。
- en: We will do this in a dedicated function, which we call `plot_decision_boundary
    ...`
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在一个专门的函数中完成这项工作，我们称之为`plot_decision_boundary ...`
- en: Dealing with nonlinear decision boundaries
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理非线性决策边界
- en: What if the data cannot be optimally partitioned using a linear decision boundary?
    In such a case, we say the data is not linearly separable*.*
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据无法使用线性决策边界进行最佳划分，会怎样呢？在这种情况下，我们说数据是不可线性划分的*.*
- en: The basic idea to deal with data that is not linearly separable is to create nonlinear
    combinations of the original features. This is the same as saying we want to project
    our data to a higher-dimensional space (for example, from 2D to 3D), in which
    the data suddenly becomes linearly separable.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 处理不可线性划分的数据的基本想法是创建原始特征的非线性组合。这相当于说我们希望将我们的数据投影到一个更高维的空间（例如，从2D到3D），在那里数据突然变得线性可分。
- en: 'This concept is illustrated in the following diagram:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念在以下图中得到了说明：
- en: '![](img/61a436e0-d761-4823-bdb7-339eac903fe7.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/61a436e0-d761-4823-bdb7-339eac903fe7.png)'
- en: The preceding diagram shows how to find linear hyperplanes in higher-dimensional
    spaces. If data in its original input space (left) cannot be linearly separated,
    we can apply a mapping function *ϕ(.)* that projects the data from 2D into a 3D
    (or a high-dimensional) space. In this higher-dimensional space, we may find that
    there is now a linear decision boundary (which, in 3D, is a plane) that can separate the
    data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图示展示了如何在更高维空间中找到线性超平面。如果原始输入空间（左侧）中的数据不能线性分离，我们可以应用一个映射函数*ϕ(.)*，将数据从2D投影到3D（或高维）空间。在这个更高维的空间中，我们可能会发现现在有一个线性决策边界（在3D中是一个平面），可以分离数据。
- en: A linear decision boundary in an *n*-dimensional space is called a **hyperplane**.
    For example, a decision boundary in 6D feature space is a 5D hyperplane; in 3D
    feature space, it's a regular 2D plane; and in 2D space, it's a straight line.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个**n**维空间中的线性决策边界被称为**超平面**。例如，在6D特征空间中的决策边界是一个5D超平面；在3D特征空间中，它是一个常规的2D平面；在2D空间中，它是一条直线。
- en: However, one problem with this mapping approach is that it is impractical in
    large dimensions because it adds a lot of extra terms to do the mathematical projections
    between the dimensions. This is where the so-called **kernel trick** comes into
    play.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种映射方法的一个问题是，在大维度中它不太实用，因为它在维度之间进行数学投影时增加了许多额外的项。这就是所谓的**核技巧**发挥作用的地方。
- en: Understanding the kernel trick
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解核技巧
- en: Granted, we won't have time to develop all the mathematics needed to truly understand
    the kernel trick. A more realistic section title would have been *Acknowledging
    that something called the kernel trick exists and accepting that it works,* but
    that would have been a bit wordy.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们没有时间开发出真正理解核技巧所需的所有数学。一个更现实的章节标题可能是*承认存在所谓的核技巧并接受它有效*，但这会有些冗长。
- en: Here's the kernel trick in a nutshell.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是所谓的核技巧的精髓。
- en: In order to figure out the slope and orientation of the decision hyperplane
    in the high-dimensional space, we have to multiply all the feature values with
    appropriate weight values and sum them all up. The more dimensions our feature
    space has, the more work we have to do.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定高维空间中决策超平面的斜率和方向，我们必须将所有特征值与适当的权重值相乘并将它们全部加起来。我们的特征空间维度越多，我们就要做更多的工作。
- en: However, mathematicians smarter than us have long realized that an SVM has no
    need to explicitly work in the higher-dimensional ...
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，比我们聪明的数学家早已意识到，支持向量机（SVM）没有必要在更高维空间中显式地工作...
- en: Knowing our kernels
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解我们的核
- en: 'OpenCV provides a whole range of SVM kernels to experiment with. Some of the
    most commonly used ones include the following:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV提供了一系列SVM核以供实验。其中一些最常用的包括以下内容：
- en: '`cv2.ml.SVM_LINEAR`: This is the kernel we used previously. It provides a linear
    decision boundary in the original feature space (the *x* and *y* values).'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv2.ml.SVM_LINEAR`：这是我们之前使用的核。它提供了原始特征空间（*x*和*y*值）中的线性决策边界。'
- en: '`cv2.ml.SVM_POLY`: This kernel provides a decision boundary that is a polynomial
    function in the original feature space. In order to use this kernel, we also have
    to specify a coefficient via `svm.setCoef0` (usually set to `0`) and the degree
    of the polynomial via `svm.setDegree`.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv2.ml.SVM_POLY`：这个核提供了一个在原始特征空间中的多项式函数作为决策边界。为了使用这个核，我们还需要通过`svm.setCoef0`（通常设置为`0`）指定一个系数，并通过`svm.setDegree`指定多项式的次数。'
- en: '`cv2.ml.SVM_RBF`: This kernel implements the kind of Gaussian function we discussed
    earlier.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv2.ml.SVM_RBF`：这个核实现了我们之前讨论过的那种高斯函数。'
- en: '`cv2.ml.SVM_SIGMOID`: This kernel implements a sigmoid function, similar to
    the one we encountered when talking about logistic regression in [Chapter 3](323dbb44-1e2b-4eaa-8cd1-2575e6766ffc.xhtml), *First
    Steps in Supervised Learning*.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv2.ml.SVM_SIGMOID`：这个核实现了与我们在[第3章](323dbb44-1e2b-4eaa-8cd1-2575e6766ffc.xhtml)中讨论逻辑回归时遇到的sigmoid函数类似的功能。'
- en: '`cv2.ml.SVM_INTER`: This kernel is a new addition to OpenCV 3\. It separates
    classes based on the similarity of their histograms.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cv2.ml.SVM_INTER`：这个核是OpenCV 3的新增功能。它根据类之间直方图的相似性来分离类。'
- en: Implementing nonlinear SVMs
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现非线性SVM
- en: 'In order to test some of the SVM kernels we just talked about, we will return
    to our code sample mentioned earlier. We want to repeat the process of building
    and training the SVM on the dataset generated earlier, but this time, we want
    to use a whole range of different kernels:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们刚才提到的某些SVM核，我们将回到之前提到的代码示例。我们想要重复在之前生成的数据集上构建和训练SVM的过程，但这次，我们想要使用一系列不同的核：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Do you remember what all of these stand for?
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你还记得所有这些代表什么吗？
- en: Setting a different SVM kernel is relatively simple. We take an entry from the `kernels` list
    and pass it to the `setKernels` method of the SVM class. That's all.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 设置不同的SVM核相对简单。我们从`kernels`列表中取一个条目，并将其传递给SVM类的`setKernels`方法。就是这样。
- en: 'The laziest way to repeat things is to use a `for` loop as shown here:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 重复事物的最懒惰的方法是使用像这里所示的`for`循环：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then the steps are as follows: ...'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后步骤如下：...
- en: Detecting pedestrians in the wild
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在野外检测行人
- en: 'We briefly talked about the difference between detection and recognition. While
    recognition is concerned with classifying objects (for example, as pedestrians,
    cars, bicycles, and so on), detection is basically answering the question: is
    there a pedestrian present in this image?'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简要地讨论了检测和识别之间的区别。虽然识别关注的是对对象进行分类（例如，作为行人、汽车、自行车等），但检测基本上是在回答这样一个问题：这张图片中是否有行人存在？
- en: 'The core idea behind most detection algorithms is to split up an image into
    many small patches, and then classify each image patch as either containing a
    pedestrian or not. This is exactly what we are going to do in this section. In
    order to arrive at our own pedestrian detection algorithm, we need to perform
    the following steps:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数检测算法背后的核心思想是将图像分割成许多小块，然后对每个图像块进行分类，判断其是否包含行人。这正是我们将在本节中要做的。为了达到我们自己的行人检测算法，我们需要执行以下步骤：
- en: Build a database of images containing pedestrians. These will be our positive
    data samples.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建立一个包含行人的图像数据库。这些将成为我们的正数据样本。
- en: Build a database of images not containing pedestrians. These will be our negative
    data samples.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建立一个不包含行人的图像数据库。这些将成为我们的负数据样本。
- en: Train an SVM on the dataset.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据集上训练一个支持向量机（SVM）。
- en: Apply the SVM to every possible patch of a test image in order to decide whether
    the overall image contains a pedestrian.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将SVM应用于测试图像的每个可能的块，以判断整体图像是否包含行人。
- en: Obtaining the dataset
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据集
- en: For the purpose of this section, we will work with the MIT People dataset, which
    we are free to use for non-commercial purposes. So make sure not to use this in
    your groundbreaking autonomous start-up company before obtaining a corresponding
    software license.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本节的目的，我们将使用麻省理工学院人群数据集，我们可以自由地用于非商业目的。所以请确保在获得相应的软件许可之前，不要将其用于您开创性的自主初创公司。
- en: However, if you followed our installation instructions from earlier and checked
    out the code on GitHub, you already have the dataset and are ready to go! The
    file can be found at [https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/blob/master/data/chapter6/pedestrians128x64.tar.gz](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/blob/master/data/chapter6/pedestrians128x64.tar.gz).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您遵循我们之前提供的安装说明并在GitHub上检查了代码，您已经拥有了数据集，并准备好了！文件可以在[https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/blob/master/data/chapter6/pedestrians128x64.tar.gz](https://github.com/PacktPublishing/Machine-Learning-for-OpenCV-Second-Edition/blob/master/data/chapter6/pedestrians128x64.tar.gz)找到。
- en: 'By referring to the following steps, you will learn to detect pedestrians in
    the wild:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 通过参考以下步骤，您将学习如何在野外检测行人：
- en: Since we are supposed to run this code from a Jupyter Notebook in the ...
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们打算从Jupyter Notebook中运行此代码，...
- en: Taking a glimpse at the histogram of oriented gradients (HOG)
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 看一眼方向梯度直方图（HOG）
- en: The HOG might just provide the help we're looking for in order to get this project
    done. The HOG is a feature descriptor for images, much like the ones we discussed
    in [Chapter 4](142fec63-a847-4cde-9de9-c34805d2bb84.xhtml), *Representing Data
    and Engineering Features*. It has been successfully applied to many different
    tasks in computer vision but seems to work especially well for classifying people.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: HOG可能正是我们为了完成这个项目所需要的帮助。HOG是一种图像特征描述符，就像我们在[第4章](142fec63-a847-4cde-9de9-c34805d2bb84.xhtml)中讨论的那样，*表示数据和工程特征*。它已经在计算机视觉的许多不同任务中得到了成功应用，但似乎在分类行人方面特别有效。
- en: The essential idea behind HOG features is that the local shapes and appearance
    of objects within an image can be described by the distribution of edge directions.
    The image is divided into small connected regions, within which a histogram of
    gradient directions (or edge directions) is compiled. Then, the descriptor is
    assembled by concatenating the different histograms. For improved performance,
    the local histograms can also be contrast-normalized, which results in better
    invariance to changes in illumination and shadowing.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: HOG 特征背后的基本思想是，图像中对象的局部形状和外观可以通过边缘方向的分布来描述。图像被分成小的连接区域，在这些区域内，编译了梯度方向（或边缘方向）的直方图。然后，通过连接不同的直方图来组装描述符。为了提高性能，局部直方图也可以进行对比度归一化，这有助于提高对光照和阴影变化的鲁棒性。
- en: 'The HOG descriptor is fairly accessible in OpenCV by means of `cv2.HOGDescriptor`,
    which takes a bunch of input arguments, such as the detection window size (minimum
    size of the object to be detected, 48 x 96), the block size (how large each box
    is, 16 x 16), the cell size (8 x 8), and the cell stride (how many pixels to move
    from one cell to the next, 8 x 8). For each of these cells, the HOG descriptor
    then calculates a histogram of oriented gradients using nine bins:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在 OpenCV 中，通过 `cv2.HOGDescriptor` 可以方便地访问 HOG 描述符，它接受一系列输入参数，例如检测窗口大小（要检测的对象的最小尺寸，48
    x 96）、块大小（每个框的大小，16 x 16）、单元格大小（8 x 8）和单元格步长（从一个单元格移动到下一个单元格的像素数，8 x 8）。对于这些单元格中的每一个，HOG
    描述符然后使用九个桶计算方向梯度直方图：
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Although this function call looks fairly complicated, these are actually the
    only values for which the HOG descriptor is implemented. The argument that matters
    the most is the window size (`win_size`).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个函数调用看起来相当复杂，但实际上这些是 HOG 描述符实现的唯一值。最重要的参数是窗口大小（`win_size`）。
- en: 'All that''s left to do is call `hog.compute` on our data samples. For this,
    we build a dataset of positive samples (`X_pos`) by randomly picking pedestrian
    images from our data directory. In the following code snippet, we randomly select
    400 pictures from the over 900 available, and apply the HOG descriptor to them:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的只是调用 `hog.compute` 对我们的数据样本进行操作。为此，我们通过从我们的数据目录中随机选择行人图像来构建正样本数据集（`X_pos`）。在下面的代码片段中，我们从超过
    900 张图片中随机选择 400 张，并应用 HOG 描述符：
- en: '[PRE13]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We should also remember that OpenCV wants the feature matrix to contain 32-bit
    floating point numbers, and the target labels to be 32-bit integers. We don''t
    mind, since converting to NumPy arrays will allow us to easily investigate the
    sizes of the matrices we created:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也应该记住，OpenCV 希望特征矩阵包含 32 位浮点数，目标标签是 32 位整数。我们并不介意，因为转换为 NumPy 数组将允许我们轻松地调查我们创建的矩阵的大小：
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: It looks like we picked a total of 399 training samples, each of which has 1,980
    feature values (which are the HOG feature values).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们总共选择了 399 个训练样本，每个样本有 1,980 个特征值（这些是 HOG 特征值）。
- en: Generating negatives
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成负样本
- en: The real challenge, however, is to come up with the perfect example of a non-pedestrian.
    After all, it's easy to think of example images of pedestrians. But what is the
    opposite of a pedestrian?
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，真正的挑战是找到非行人的完美示例。毕竟，想到行人的示例图像很容易。但行人的对立面是什么？
- en: This is actually a common problem when trying to solve new machine learning
    problems. Both research labs and companies spend a lot of time creating and annotating
    new datasets that fit their specific purpose.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是在尝试解决新的机器学习问题时遇到的一个常见问题。研究实验室和公司都花费大量时间创建和注释新的数据集，以满足他们的特定目的。
- en: If you're stumped, let me give you a hint on how to approach this. A good first
    approximation to finding the opposite of a pedestrian is to assemble a dataset
    of images that look like the images of the positive class but do not contain pedestrians.
    These images could contain anything like cars, bicycles, streets, houses, ...
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遇到了难题，让我给你一个提示，如何来处理这个问题。找到一个行人的相反的一个好的初步近似是组装一个数据集，其中的图像看起来像正类图像，但不包含行人。这些图像可能包含任何像汽车、自行车、街道、房屋等的东西...
- en: Implementing the SVM
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现 SVM
- en: 'We already know how to build an SVM in OpenCV, so there''s nothing much to
    see here. Planning ahead, we wrap the training procedure into a function, so that
    it''s easier to repeat the procedure in the future:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道如何在 OpenCV 中构建 SVM，所以这里没有太多可看的。提前规划，我们将训练过程封装成一个函数，这样在未来重复该过程会更方便：
- en: '[PRE15]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The same can be done for the scoring function. Here we pass a feature matrix, `X` and
    a label vector, `y`, but we do not specify whether we''re talking about the training
    or the test set. In fact, from the viewpoint of the function, it doesn''t matter
    what set the data samples belong to, as long as they have the right format:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 对于评分函数也可以这样做。在这里，我们传递一个特征矩阵，`X`和一个标签向量，`y`，但我们没有指定我们是在谈论训练集还是测试集。实际上，从函数的角度来看，数据样本属于哪个集合并不重要，只要它们有正确的格式：
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then we can train and score the SVM with two short function calls:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过两个简短的功能调用来训练和评分SVM：
- en: '[PRE17]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Thanks to the HOG feature descriptor, we make no mistake on the training set.
    However, our generalization performance is quite abysmal (64.6 percent), as it
    is much less than the training performance (100 percent). This is an indication
    that the model is overfitting the data. The fact that it is performing way better
    on the training set than the test set means that the model has resorted to memorizing
    the training samples, rather than trying to abstract it into a meaningful decision
    rule. What can we do to improve the model performance?
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了HOG特征描述符，我们在训练集上没有犯错误。然而，我们的泛化性能相当糟糕（64.6%），这比训练性能（100%）低得多。这表明模型正在对数据进行过度拟合。它在训练集上的表现远好于测试集，这意味着模型已经退而求其次，只是记住训练样本，而不是试图将其抽象成一个有意义的决策规则。我们该如何提高模型性能？
- en: Bootstrapping the model
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对模型进行bootstrapping
- en: An interesting way to improve the performance of our model is to use bootstrapping.
    This idea was actually applied in one of the first papers on using SVMs in combination with
    HOG features for pedestrian detection. So let's pay a little tribute to the pioneers
    and try to understand what they did.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 提高我们模型性能的一个有趣方法是使用**bootstrapping**。这个想法实际上被应用在第一篇关于使用SVMs结合HOG特征进行行人检测的论文中。所以，让我们向这些先驱者表示一点敬意，并尝试理解他们所做的事情。
- en: Their idea was quite simple. After training the SVM on the training set, they
    scored the model and found that the model produced some false positives. Remember
    that false positive means that the model predicted a positive (+) for a sample
    that was really a negative (-). In our context, this would mean the SVM falsely
    believed an image to contain a pedestrian. If this happens for a particular image
    in the dataset, this example ...
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的想法非常简单。在训练集上训练SVM后，他们对模型进行了评分，发现模型产生了一些误报。记住，误报意味着模型对一个实际上是负例（-）的样本预测了正例（+）。在我们的上下文中，这意味着SVM错误地认为一个图像包含行人。如果这种情况发生在数据集的某个特定图像中，这个例子...
- en: Detecting pedestrians in a larger image
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在较大图像中检测行人
- en: What's left to do is to connect the SVM classification procedure with the process
    of detection. The way to do this is to repeat our classification for every possible
    patch in the image. This is similar to what we did earlier when we visualized
    decision boundaries; we created a fine grid and classified every point on that
    grid. The same idea applies here. We divide the image into patches and classify
    every patch as either containing a pedestrian or not.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的工作是将SVM分类过程与检测过程连接起来。要做到这一点，我们需要对图像中的每个可能的补丁重复我们的分类。这与我们之前可视化决策边界时所做的类似；我们创建了一个精细的网格，并对网格上的每个点进行了分类。同样的想法也适用于这里。我们将图像划分为补丁，并判断每个补丁是否包含行人。
- en: 'By following these steps, you will be able to detect a pedestrian in an image:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这些步骤，你将能够在图像中检测到行人：
- en: 'We first have to loop over all possible patches in an image as follows, each
    time shifting our region of interest by a small number of `stride` pixels:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先必须遍历图像中所有可能的补丁，如下所示，每次将我们的感兴趣区域移动一小段`stride`像素：
- en: '[PRE18]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We want to make sure that we do not go beyond the image boundaries:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们要确保我们不会超出图像边界：
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Then we cut out the ROI, preprocess it, and classify it:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们裁剪出ROI，对其进行预处理，并进行分类：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'If that particular patch happens to be classified as a pedestrian, we add it
    to the list of successes:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果那个特定的补丁被分类为行人，我们就将其添加到成功列表中：
- en: '[PRE21]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Because pedestrians could appear not just at various locations but also in
    various sizes, we would have to rescale the image and repeat the whole process.
    Thankfully, OpenCV has a convenience function for this multi-scale detection task in
    the form of the `detectMultiScale` function. This is a bit of a hack, but we can
    pass all SVM parameters to the `hog` object:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为行人不仅可能出现在各种位置，也可能出现在各种大小，我们可能需要重新缩放图像并重复整个过程。幸运的是，OpenCV有一个方便的函数用于这种多尺度检测任务，即`detectMultiScale`函数。这有点像是一个技巧，但我们可以将所有SVM参数传递给`hog`对象：
- en: '[PRE22]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then it''s possible to call the detection function:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以调用检测函数：
- en: '[PRE23]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The function will return a list of bounding boxes that contain detected pedestrians.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数将返回一个包含检测到行人的边界框列表。
- en: This seems to work only for linear SVM classifiers. The OpenCV documentation
    is terribly inconsistent across versions in this regard, so I'm not sure at which
    version this started or stopped working. Be careful!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎只适用于线性SVM分类器。在这一点上，OpenCV的文档在不同版本之间非常不一致，因此我不确定这个功能是从哪个版本开始或停止工作的。请小心！
- en: 'In practice, when people are faced with a standard task such as pedestrian
    detection, they often rely on pre-scanned SVM classifiers that are built into
    OpenCV. This is the method that I hinted at in the very beginning of this chapter.
    By loading either `cv2.HOGDescriptor_getDaimlerPeopleDetector()` or `cv2.HOGDescriptor_getDefaultPeopleDetector()`,
    we can get started with only a few lines of code:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在实践中，当人们面对标准任务，如行人检测时，他们通常会依赖于OpenCV中内置的预扫描SVM分类器。这正是我在本章开头暗示的方法。通过加载`cv2.HOGDescriptor_getDaimlerPeopleDetector()`或`cv2.HOGDescriptor_getDefaultPeopleDetector()`，我们只需几行代码就可以开始：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'It''s easy to plot the test image with matplotlib as shown here:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用matplotlib绘制测试图像非常简单，如下所示：
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Then we can mark the detected pedestrians in the image by looping over the
    bounding boxes in `found`:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们可以通过遍历`found`中的边界框来在图像中标记检测到的行人：
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The result looks like this:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来像这样：
- en: '![](img/7d871221-d88e-4ca8-9913-5c9e6c669582.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d871221-d88e-4ca8-9913-5c9e6c669582.png)'
- en: The preceding screenshot shows detected pedestrians in a test image.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图显示了测试图像中检测到的行人。
- en: Further improving the model
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步改进模型
- en: Although the RBF kernel makes for a good default kernel, it is not always the
    one that works best for our problem. The only real way to know which kernel works
    best on our data is to try them all and compare the classification performance
    across models. There are strategic ways to perform this so-called **hyperparameter
    tuning**, which we'll talk about in detail in [Chapter 11](904bc419-cb0e-44cd-ae3f-8ce97e15baa2.xhtml), *Selecting
    the Right Model with Hyperparameter Tuning.*
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然径向基函数核是一个很好的默认核，但它并不总是我们问题的最佳选择。了解哪种核最适合我们的数据的唯一真正方法是尝试所有核并比较模型间的分类性能。有策略的方法来执行这种所谓的**超参数调整**，我们将在第11章[选择合适的模型：超参数调整](904bc419-cb0e-44cd-ae3f-8ce97e15baa2.xhtml)中详细讨论。
- en: What if we don't know how to do hyperparameter tuning properly yet?
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们还不懂得如何正确地进行超参数调整怎么办？
- en: Well, I'm sure you remember the first step in data understanding, *visualize
    the data*. Visualizing the data could help us understand if a linear SVM was powerful
    enough to classify the data, in which case there would be no ...
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，我相信你记得数据理解的第一步，*可视化数据*。可视化数据可以帮助我们了解线性SVM是否足够强大以对数据进行分类，在这种情况下，将不会有……
- en: Multiclass classification using SVMs
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SVM进行多分类
- en: SVMs are inherently two-class classifiers. In particular, the most prevalent
    method of multi-class classification in practice has been to create *|C|* one-versus-rest
    classifiers (commonly referred to as **one-versus-all** (**OVA**) classification)
    where *|C|* is the number of classesand to choose the class that classifies the
    test datum with the highest margin. Another approach is to develop a set of one-versus-one
    classifiers and to select the class that is chosen by the most classifiers. While
    this involves building *|C|(|C| - 1)/2* classifiers, the time for training classifiers
    may decrease, since the training data set for each classifier is much smaller.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: SVMs本质上是二分类器。特别是，实践中最普遍的多分类方法一直是创建*|C|*个一对多分类器（通常称为**一对多**（**OVA**）分类），其中*|C|*是类的数量，并选择分类测试数据具有最高边界的类别。另一种方法是开发一组一对一分类器，并选择被最多分类器选择的类别。虽然这涉及到构建*|C|(|C|
    - 1)/2*个分类器，但由于每个分类器的训练数据集要小得多，因此训练分类器的时间可能会减少。
- en: Now let's quickly jump onto how you can apply multi-class classification using
    SVMs with the help of a real-life dataset.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们快速了解一下如何使用真实数据集应用SVM的多类分类。
- en: For the purpose of this section, we will work with the UCI Human Activity Recognition
    using smartphones dataset, which we are free to use for non-commercial purposes.
    So make sure not to use this in your groundbreaking autonomous start-up company
    before obtaining a corresponding software license.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本节的目的，我们将使用UCI智能手机人体活动识别数据集，我们可以免费用于非商业目的。所以请确保在获得相应的软件许可之前，不要将其用于您开创性的自主初创公司。
- en: The dataset can be obtained from the Kaggle website, [https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones](https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones).
    There you should find a Download button that leads you to a file called [https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/downloads/human-activity-recognition-with-smartphones.zip/1](https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/downloads/human-activity-recognition-with-smartphones.zip/1).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以从Kaggle网站获取，[https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones](https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones)。在那里你应该找到一个`下载`按钮，它会带你到一个名为[https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/downloads/human-activity-recognition-with-smartphones.zip/1](https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/downloads/human-activity-recognition-with-smartphones.zip/1)的文件。
- en: However, if you followed our installation instructions from earlier and checked
    out the code on GitHub, you already have the dataset and are ready to go! The
    file can be found at `notebooks/data/multiclass`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您遵循我们之前提供的安装说明并在GitHub上检查了代码，您已经拥有了数据集，并且已经准备好开始了！文件可以在`notebooks/data/multiclass`中找到。
- en: About the data
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于数据
- en: A group of 30 volunteers were chosen within an age group of 19-48 years and
    the experiments were carried out on them. Six activities were performed by each
    person, namely `Walking`, `Walking_Upstairs`, `Walking_Downstairs`, `Sitting`,
    `Standing`, and `Laying` with the help of a smartphone fastened around the waist.
    Mainly three-axial linear acceleration and three-axial angular velocity at a constant
    rate of 50 Hz were captured using embedded accelerometer and gyroscope. To label
    the data, the experiments have been video-recorded. The dataset has been randomly
    split into two sets, where 70% of the volunteers were selected for generating
    the training data and 30% the test data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在19-48岁年龄组内选择了30名志愿者，并在他们身上进行了实验。每个人进行了六项活动，即`步行`、`上楼行走`、`下楼行走`、`坐着`、`站立`和`躺下`，这些活动是在腰间固定智能手机的帮助下完成的。主要捕获了以50
    Hz恒定速率的三轴线性加速度和三轴角速度。为了标记数据，实验已被录像。数据集已被随机分为两组，其中70%的志愿者用于生成训练数据，30%用于测试数据。
- en: Attribute information
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 属性信息
- en: 'For each entry in the dataset, the following is provided:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据集中的每个条目，以下信息提供：
- en: Triaxial acceleration from the accelerometer and the approximate acceleration
    of the body
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自加速度计的三轴加速度和身体的近似加速度
- en: Triaxial angular velocity from the gyroscope
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自陀螺仪的三轴角速度
- en: Time and frequency domain variables with 561-feature vector
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间域和频率域变量，561特征向量
- en: Various labels of activity
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活动的各种标签
- en: An identifier of the subject who was observed
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 被观察者的标识符
- en: 'By referring to the following steps, you will learn how to build a multi-class
    classification using SVMs:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 通过参考以下步骤，您将学习如何使用SVM构建多类分类：
- en: 'Let''s quickly import all the necessary libraries that you will need in order
    to implement an SVM with multi-class classification:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们快速导入实现SVM多类分类所需的所有必要库：
- en: '[PRE27]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Next, you will be loading the dataset. Since we are supposed to run this code
    from a Jupyter Notebook in the `notebooks/` directory, the relative path to the
    data directory is simply `data/`:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，您将加载数据集。由于我们打算从`notebooks/`目录中的Jupyter Notebook运行此代码，因此数据目录的相对路径只是`data/`：
- en: '[PRE28]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s check whether there are any missing values in the training and testing
    dataset; if there are any, then we will simply drop them from the dataset:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查训练和测试数据集中是否有任何缺失值；如果有，我们将简单地从数据集中删除它们：
- en: '[PRE29]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, we will find the frequency distribution of the classes in the data, which
    means that we will check how many samples belong to each of the six classes:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将找到数据集中类别的频率分布，这意味着我们将检查有多少样本属于六个类别中的每一个：
- en: '[PRE30]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'From the following screenshot, you can observe that the `LAYING` class has
    the most samples, but overall, the data is approximately equally distributed and
    there are no major signs of class imbalance:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 从下面的截图可以看出，`LAYING`类有最多的样本，但总体上，数据分布得相当均匀，没有明显的类别不平衡迹象：
- en: '![](img/5196c8be-e10f-4176-ad2a-e2fb5e211252.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5196c8be-e10f-4176-ad2a-e2fb5e211252.png)'
- en: 'Next, we will separate out the predictors (input values) and outcome values
    (class labels) from the train and test datasets:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将从训练和测试数据集中分离出预测值（输入值）和结果值（类别标签）：
- en: '[PRE31]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Since the SVM expects numerical input and labels, you will now transform the
    non-numerical labels into numerical labels. But first, we will have to import
    a  `preprocessing` module from the `sklearn` library:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于SVM期望数值输入和标签，你现在需要将非数值标签转换为数值标签。但首先，你必须从`sklearn`库中导入一个`preprocessing`模块：
- en: '[PRE32]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, we will encode the train and test labels into numerical values:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将训练和测试标签编码成数值：
- en: '[PRE33]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, we will scale (normalise) the train and test feature set and for this,
    you will import `StandardScaler` from `sklearn`:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将对训练和测试特征集进行缩放（归一化），为此，你需要从`sklearn`导入`StandardScaler`：
- en: '[PRE34]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Once the data is scaled and the labels are in a correct format, now is the
    time when we will fit the data. But before that, we will define a dictionary with
    the different parameter settings that the SVM will use while training itself,
    and this technique is called `GridSearchCV`. The parameter grid will be based
    on the results of a random search:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据被缩放，标签格式正确，现在是我们拟合数据的时候了。但在那之前，我们将定义一个包含SVM在训练过程中将使用的不同参数设置的字典，这种技术称为`GridSearchCV`。参数网格将基于随机搜索的结果：
- en: '[PRE35]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, we will call `GridSearchCV` on the data using the preceding parameters
    for the best SVM fit:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将使用前面提到的参数在数据上调用`GridSearchCV`以获得最佳的SVM拟合：
- en: '[PRE36]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'It''s time to check how well the SVM model was trained on the data; in short,
    we will find the accuracy. Not only that, but we will also check what the parameter
    settings were for which SVM performed the best:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候检查SVM模型在数据上的训练效果了；简而言之，我们将找到准确率。不仅如此，我们还将检查哪个参数设置下的SVM表现最佳：
- en: '[PRE37]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Voila! As we can see, the SVM achieved 98.6% accuracy on the training data
    on a multi-class classification problem. But hold down your horses until we find
    the accuracy on the test data. So, let''s quickly check that:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！正如我们所见，在多类分类问题上，SVM在训练数据上达到了98.6%的准确率。但请稍等，直到我们找到测试数据的准确率。所以，让我们快速检查一下：
- en: '[PRE38]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Wow! Isn't that amazing? We were able to achieve 95.86% accuracy on the testing
    set; that's the power of SVMs.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！这不令人惊叹吗？我们能够在测试集上达到95.86%的准确率；这就是SVM的力量。
- en: Summary
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about SVMs in all their forms and flavors. We now
    know how to draw decision boundaries in 2D and hyperplanes in high-dimensional
    spaces. We learned about different SVM kernels and look at how to implement them
    in OpenCV.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们学习了所有形式的SVM。我们现在知道如何在二维空间中绘制决策边界，在高维空间中绘制超平面。我们学习了不同的SVM核，并探讨了如何在OpenCV中实现它们。
- en: In addition, we also applied our newly gained knowledge to the practical example
    of pedestrian detection. For this, we had to learn about the HOG feature descriptor,
    and how to collect suitable data for the task. We used bootstrapping to improve
    the performance of our classifier and combined the classifier with OpenCV's multi-scale
    detection mechanism.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还把新获得的知识应用到行人检测的实际例子中。为此，我们必须学习HOG特征描述符，以及如何收集适合这项任务的数据。我们使用bootstrapping来提高分类器的性能，并将分类器与OpenCV的多尺度检测机制相结合。
- en: Not only was that a lot to digest in a single chapter, but you have also made
    it through half of the book. Congrats!
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅这一章的内容很多，而且你已经读完了这本书的一半。恭喜你！
- en: In the next chapter, ...
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，...
