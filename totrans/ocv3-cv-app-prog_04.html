<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch04" class="calibre6"/>Chapter 4. Counting the Pixels with Histograms</h1></div></div></div><p class="calibre8">In this chapter, we will cover the following recipes:</p><div><ul class="itemizedlist"><li class="listitem">Computing an image histogram</li><li class="listitem">Applying look-up tables to modify the image's appearance</li><li class="listitem">Equalizing the image histogram</li><li class="listitem">Backprojecting a histogram to detect specific image content</li><li class="listitem">Using the mean shift algorithm to find an object</li><li class="listitem">Retrieving similar images using the histogram comparison</li><li class="listitem">Counting pixels with integral images</li></ul></div><div><div><div><div><h1 class="title1"><a id="ch04lvl1sec26" class="calibre6"/>Introduction</h1></div></div></div><p class="calibre8">An image is composed of pixels of different values (colors). The distribution of pixel values across an image constitutes an important characteristic of that image. This chapter introduces the concept of image histograms. You will learn how to compute a histogram and how to use it to modify an image's appearance. Histograms can also be used to characterize an image's content and detect specific objects or textures in an image. Some of these techniques will be presented in this chapter.</p></div></div>
<div><div><div><div><h1 class="title1"><a id="ch04lvl1sec27" class="calibre6"/>Computing an image histogram</h1></div></div></div><p class="calibre8">An image is made of pixels that have different values. For example, in a 1-channel gray-level image, each pixel has an integer value between 0 (black) and 255 (white). Depending on the picture content, you will find different amounts of each gray shade laid out inside the image.</p><p class="calibre8">A <strong class="calibre15">histogram</strong> is a simple table that gives you the number of pixels that have a given value in an image (or sometimes, a set of images). The histogram of a gray-level image will, therefore, have 256 entries (or bins). Bin 0 gives you the number of pixels that have the value 0, bin 1 gives you the number of pixels that have the value 1, and so on. Obviously, if you sum all of the entries of a histogram, you should get the total number of pixels. Histograms can also be normalized so that the sum of the bins equals 1. In this case, each bin gives you the percentage of pixels that have this specific value in the image.</p><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec77" class="calibre6"/>Getting ready</h2></div></div></div><p class="calibre8">The first three recipes of this chapter will use the following image:</p><p class="calibre8">
</p><div><img alt="Getting ready" src="img/image_04_001.jpg" class="calibre17"/></div><p class="calibre8">
</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec78" class="calibre6"/>How to do it...</h2></div></div></div><p class="calibre8">Computing a histogram with OpenCV can be easily done by using the <code class="literal">cv::calcHist</code> function. This is a general function that can compute the histogram of multiple channel images of any pixel value type and range. Here, we will make this one simpler to use by specializing a class for the case of 1-channel gray-level images. For other types of image, you can always directly use the <code class="literal">cv::calcHist</code> function, which offers you all the flexibility required. The next section will explain each of its parameters.</p><p class="calibre8">For now, the initialization of our specialized class looks as follows:</p><pre class="programlisting">    //To create histograms of gray-level images 
    class Histogram1D { 
 
      private: 
        int histSize[1];          // number of bins in histogram 
        float hranges[2];         // range of values 
        const float* ranges[1];   // pointer to the value ranges 
        int channels[1];          // channel number to be examined 
 
      public: 
      Histogram1D() { 
 
        // Prepare default arguments for 1D histogram 
        histSize[0]= 256;        // 256 bins 
        hranges[0]= 0.0;         // from 0 (inclusive) 
        hranges[1]= 256.0;       // to 256 (exclusive) 
        ranges[0]= hranges;  
        channels[0]= 0;          // we look at channel 0 
      }
</pre><p class="calibre8">With the defined member variables, computing a gray-level histogram can then be accomplished using the following method:</p><pre class="programlisting">    // Computes the 1D histogram. 
    cv::Mat getHistogram(const cv::Mat &amp;image) { 
 
      cv::Mat hist; 
      // Compute 1D histogram with calcHist 
      cv::calcHist(&amp;image, 1, // histogram of 1 image only 
                   channels,  // the channel used 
                   cv::Mat(), // no mask is used 
                   hist,      // the resulting histogram 
                   1,         // it is a 1D histogram 
                   histSize,  // number of bins 
                   ranges     // pixel value range 
      ); 
 
      return hist; 
    } 
</pre><p class="calibre8">Now, your program simply needs to open an image, create a <code class="literal">Histogram1D</code> instance, and call the <code class="literal">getHistogram</code> method:</p><pre class="programlisting">    // Read input image 
    cv::Mat image= cv::imread("group.jpg", 0); // open in b&amp;w 
 
    // The histogram object 
    Histogram1D h; 
 
    // Compute the histogram 
    cv::Mat histo= h.getHistogram(image); 
</pre><p class="calibre8">The <code class="literal">histo</code> object here is a simple one-dimensional array with <code class="literal">256</code> entries. Therefore, you can read each bin by simply looping over this array:</p><pre class="programlisting">    // Loop over each bin 
    for (int i=0; i&lt;256; i++) 
      cout &lt;&lt; "Value " &lt;&lt; i &lt;&lt; " = " 
           &lt;&lt;histo.at&lt;float&gt;(i) &lt;&lt; endl; 
</pre><p class="calibre8">With the image shown at the start of this chapter, some of the displayed values would read as follows:</p><pre class="programlisting">    Value 7 = 159 
    Value 8 = 208 
    Value 9 = 271 
    Value 10 = 288 
    Value 11 = 340 
    Value 12 = 418 
    Value 13 = 432 
    Value 14 = 472 
    Value 15 = 525 
</pre><p class="calibre8">It is obviously difficult to extract any intuitive meaning from this sequence of values. For this reason, it is often convenient to display a histogram as a function, for example, using bar graphs. The following methods create such a graph:</p><pre class="programlisting">    // Computes the 1D histogram and returns an image of it. 
    cv::Mat getHistogramImage(const cv::Mat &amp;image, int zoom=1) { 
 
      // Compute histogram first 
      cv::Mat hist= getHistogram(image); 
      // Creates image 
      return getImageOfHistogram(hist, zoom); 
    } 
 
    // Create an image representing a histogram (static method) 
    static cv::Mat getImageOfHistogram (const cv::Mat &amp;hist, int zoom) { 
      // Get min and max bin values 
      double maxVal = 0; 
      double minVal = 0; 
      cv::minMaxLoc(hist, &amp;minVal, &amp;maxVal, 0, 0); 
 
      // get histogram size 
      int histSize = hist.rows; 
 
      // Square image on which to display histogram 
      cv::Mat histImg(histSize*zoom, histSize*zoom,
                      CV_8U, cv::Scalar(255)); 
 
      // set highest point at 90% of nbins (i.e. image height) 
      int hpt = static_cast&lt;int&gt;(0.9*histSize); 
 
      // Draw vertical line for each bin  
      for (int h = 0; h &lt; histSize; h++) { 
 
        float binVal = hist.at&lt;float&gt;(h); 
        if (binVal&gt;0) { 
          int intensity = static_cast&lt;int&gt;(binVal*hpt / maxVal); 
          cv::line(histImg, cv::Point(h*zoom, histSize*zoom),
                   cv::Point(h*zoom, (histSize - intensity)*zoom),
                   cv::Scalar(0), zoom); 
        } 
      } 
 
      return histImg; 
    }
</pre><p class="calibre8">Using the <code class="literal">getImageOfHistogram</code> method, you can obtain an image of the histogram function in the form of a bar graph that is drawn using lines:</p><pre class="programlisting">    //Display a histogram as an image 
    cv::namedWindow("Histogram"); 
    cv::imshow("Histogram", h.getHistogramImage(image)); 
</pre><p class="calibre8">The result is the following image:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_002.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">From the preceding histogram, it can be seen that the image exhibits a large peak of mid-gray level values and a good quantity of darker pixels. Coincidentally, these two groups mostly correspond to, respectively, the background and foreground of the image. This can be verified by thresholding the image at the transition between these two groups. A convenient OpenCV function can be used for this, namely the <code class="literal">cv::threshold</code> function, which was introduced in the previous chapter. Here, to create our binary image, we threshold the image at the minimum value just before it increases toward the high peak of the histogram (gray value <code class="literal">70</code>):</p><pre class="programlisting">    cv::Mat thresholded;                 // output binary image 
    cv::threshold(image,thresholded,70,  // threshold value 
                  255,                   // value assigned to  
                                         // pixels over threshold value 
                  cv::THRESH_BINARY);    // thresholding type 
</pre><p class="calibre8">The resulting binary image clearly shows you the background/foreground segmentation:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_004.jpg" class="calibre17"/></div><p class="calibre8">
</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec79" class="calibre6"/>How it works...</h2></div></div></div><p class="calibre8">The <code class="literal">cv::calcHist</code> function has many parameters to permit its use in many contexts, which are as follows:</p><pre class="programlisting">    void calcHist(const Mat*images, // source images 
          int nimages,          // number of source images (usually 1) 
          const int*channels,   // list the channels to be used 
          InputArray mask,      // input mask (pixels to consider) 
          OutputArray hist,     // output histogram 
          int dims,             // histogram dimension (number of channels) 
          const int*histSize,   // number of bins in each dimension 
          const float**ranges,  // range of each dimension 
          bool uniform=true,    // true if equally spaced bins 
          bool accumulate=false) // to cumulate over several calls 
</pre><p class="calibre8">Most of the time, your histogram will be one of a single 1-channel or 3-channel image. However, the function allows you to specify a multiple-channel image distributed over several images (that is, several <code class="literal">cv::Mat</code>). This is why an array of input images is the first parameter of this function. The sixth parameter, <code class="literal">dims</code>, specifies the dimensionality of the histogram, for example, 1 for a 1D histogram. Even if you are analyzing a multichannel image, you do not have to use all its <code class="literal">channels</code> in the computation of the histogram. The channels to be considered are listed in the <code class="literal">channel</code> array that has the specified dimensionality. In our class implementation, this single channel is channel <code class="literal">0</code> by default. The histogram itself is described by the number of bins in each dimension (this is the <code class="literal">histSize</code> array of integers) and by the minimum (inclusive) and maximum (exclusive) values in each dimension (given by the <code class="literal">ranges</code> array of 2-element arrays). It is also possible to define a non-uniform histogram (the second-last parameter would be set to <code class="literal">false</code> in that case), in which case, you need to specify the limits of each bin.</p><p class="calibre8">As with many OpenCV functions, a mask can be specified, indicating which pixels you want to include in the count (all pixels for which the mask value is <code class="literal">0</code> are then ignored). Two additional parameters can be specified, both of which are Boolean values. The first one indicates whether the histogram is uniform or not (<code class="literal">true</code> is the default). The second allows you to accumulate the result of several histogram computations. If this last parameter is <code class="literal">true</code>, then the pixel count of the image will be added to the current values found in the input histogram. This is useful when you want to compute the histogram of a group of images.</p><p class="calibre8">The resulting histogram is stored in a <code class="literal">cv::Mat</code> instance. Indeed, the <code class="literal">cv::Mat</code> class can be used to manipulate general N-dimensional matrices. Recall from 
<a href="ch02.html" title="Chapter 2. Manipulating Pixels">Chapter 2</a>
, <em class="calibre16">Manipulating Pixels</em>, that this class has defined the <code class="literal">at</code> method for matrices of dimension 1, 2, and 3. This is why we were able to write the following code when accessing each bin of the 1D histogram in the <code class="literal">getHistogramImage</code> method:</p><pre class="programlisting">    float binVal = hist.at&lt;float&gt;(h); 
</pre><p class="calibre8">Note that the values in the histogram are stored as <code class="literal">float</code> values.</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec80" class="calibre6"/>There's more...</h2></div></div></div><p class="calibre8">The <code class="literal">Histogram1D</code> class presented in this recipe has simplified the <code class="literal">cv::calcHist</code> function by restricting it to a 1D histogram. This is useful for gray-level images, but what about color images?</p><div><div><div><div><h3 class="title3"><a id="ch04lvl3sec20" class="calibre6"/>Computing histograms of color images</h3></div></div></div><p class="calibre8">Using the same <code class="literal">cv::calcHist</code> function, we can compute histograms of multichannel images. For example, a class that computes histograms of color BGR images can be defined as follows:</p><pre class="programlisting">    class ColorHistogram { 
 
      private: 
        int histSize[3];        // size of each dimension 
        float hranges[2];       // range of values (same for the 3 dimensions) 
        const float* ranges[3]; // ranges for each dimension 
        int channels[3];        // channel to be considered 
 
      public: 
      ColorHistogram() { 
 
        // Prepare default arguments for a color histogram 
        // each dimension has equal size and range 
        histSize[0]= histSize[1]= histSize[2]= 256; 
        hranges[0]= 0.0;    // BRG range from 0 to 256 
        hranges[1]= 256.0; 
        ranges[0]= hranges; // in this class,   
        ranges[1]= hranges; // all channels have the same range 
        ranges[2]= hranges; 
        channels[0]= 0;     // the three channels: B 
        channels[1]= 1;     // G 
        channels[2]= 2;     // R 
      }
</pre><p class="calibre8">In this case, the histogram will be three-dimensional. Therefore, we need to specify a range for each of the three dimensions. In the case of our BGR image, the three channels have the same <code class="literal">[0,255]</code> range. With the arguments thus prepared, the color histogram is computed by the following method:</p><pre class="programlisting">    //Computes the histogram. 
    cv::Mat getHistogram(const cv::Mat &amp;image) { 
      cv::Mat hist; 
 
      //Compute histogram 
      cv::calcHist(&amp;image, 1,  // histogram of 1 image only 
                   channels,   // the channel used 
                   cv::Mat(),  // no mask is used 
                   hist,       // the resulting histogram 
                   3,          // it is a 3D histogram 
                   histSize,   // number of bins 
                   ranges      // pixel value range 
      ); 
 
      return hist; 
    }
</pre><p class="calibre8">A three-dimensional <code class="literal">cv::Mat</code> instance is returned. When a histogram of <code class="literal">256</code> bins is selected, this matrix has <code class="literal">(256)^3</code> elements, which represents more than 16 million entries. In many applications, it would be better to reduce the number of bins in the computation of the histogram. It is also possible to use the <code class="literal">cv::SparseMat</code> data structure, which is designed to represent large sparse matrices (that is, matrices with very few non-zero elements) without consuming too much memory. The <code class="literal">cv::calcHist</code> function has a version that returns one such matrix. It is, therefore, simple to modify the previous method in order to use <code class="literal">cv::SparseMatrix</code>:</p><pre class="programlisting">    //Computes the histogram. 
    cv::SparseMat getSparseHistogram(const cv::Mat &amp;image) { 
 
      cv::SparseMat hist(3,        // number of dimensions 
                    histSize,      // size of each dimension 
                    CV_32F); 
 
      //Compute histogram 
      cv::calcHist(&amp;image, 1, // histogram of 1 image only 
                   channels,  // the channel used 
                   cv::Mat(), // no mask is used 
                   hist,      // the resulting histogram 
                   3,         // it is a 3D histogram 
                   histSize,  // number of bins 
                   ranges     // pixel value range 
      ); 
      return hist; 
    }
</pre><p class="calibre8">The histogram in this case is three-dimensional, which makes it more difficult to represent. A possible option to illustrate the color distribution in an image could be by showing the individual R, G, and B histograms.</p></div></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec81" class="calibre6"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The <em class="calibre16">Backprojecting a histogram to detect specific image content</em> recipe later in this chapter makes use of color histograms in order to detect specific image content</li></ul></div></div></div>
<div><div><div><div><h1 class="title1"><a id="ch04lvl1sec28" class="calibre6"/>Applying look-up tables to modify the image's appearance</h1></div></div></div><p class="calibre8">Image histograms capture the way a scene is rendered using the available pixel intensity values. By analyzing the distribution of the pixel values over an image, it is possible to use this information to modify and possibly improve an image. This recipe explains how we can use a simple mapping function, represented by a look-up table, to modify the pixel values of an image. As we will see, look-up tables are often produced from histogram distributions.</p><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec82" class="calibre6"/>How to do it...</h2></div></div></div><p class="calibre8">A <strong class="calibre15">look-up table</strong> is a simple one-to-one (or many-to-one) function that defines how pixel values are transformed into new values. It is a 1D array with, in the case of regular gray-level images, <code class="literal">256</code> entries. Entry <code class="literal">i</code> of the table gives you the new intensity value of the corresponding gray level, which is expressed as follows:</p><pre class="programlisting">    newIntensity= lookup[oldIntensity]; 
</pre><p class="calibre8"> 
The <code class="literal">cv::LUT</code> function in OpenCV applies a look-up table to an image in order to produce a new image. Since look-up tables are often built from histograms, we have added this function to our <code class="literal">Histogram1D</code> class:</p><pre class="programlisting">    static cv::Mat applyLookUp(const cv::Mat&amp; image,   // input image 
                               const cv::Mat&amp; lookup) {// 1x256 8U 
      // the output image 
      cv::Mat result; 
 
      // apply lookup table 
      cv::LUT(image,lookup,result); 
      return result; 
    }
</pre></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec83" class="calibre6"/>How it works...</h2></div></div></div><p class="calibre8">When a look-up table is applied to an image, it results in a new image in which the pixel intensity values have been modified as prescribed by the look-up table. A simple transformation could be defined as follows:</p><pre class="programlisting">    //Create an image inversion table 
    cv::Mat lut(1,256,CV_8U); // 256x1 matrix 
 
    for (int i=0; i&lt;256; i++) { 
      //0 becomes 255, 1 becomes 254, etc. 
      lut.at&lt;uchar&gt;(i)= 255-i; 
    } 
</pre><p class="calibre8">This transformation simply inverts the pixel intensities, that is, intensity <code class="literal">0</code> becomes <code class="literal">255</code>, <code class="literal">1</code> becomes <code class="literal">254</code>, and so on up to <code class="literal">255</code> that becomes <code class="literal">0</code>. Applying such a look-up table to an image will produce the negative of the original image.</p><p class="calibre8">With the image in the previous recipe, the result is seen here:</p><p class="calibre8">
</p><div><img alt="How it works..." src="img/image_04_005.jpg" class="calibre17"/></div><p class="calibre8">
</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec84" class="calibre6"/>There's more...</h2></div></div></div><p class="calibre8">Look-up tables are useful for any application in which all pixel intensities are given a new intensity value. The transformation, however, has to be global; that is, all pixels of each intensity value must undergo the same transformation.</p><div><div><div><div><h3 class="title3"><a id="ch04lvl3sec21" class="calibre6"/>Stretching a histogram to improve the image contrast</h3></div></div></div><p class="calibre8">It is possible to improve an image's contrast by defining a look-up table that modifies the original image's histogram. For example, if you observe the histogram of the image shown in the first recipe of this chapter, you will notice that there are practically no pixels in the image with a value higher than <code class="literal">200</code>. We can, therefore, stretch the histogram in order to produce an image with an expanded contrast. To do so, the procedure uses a percentile threshold that defines the percentage of pixels that can be assigned the minimum intensity value (<code class="literal">0</code>) and the maximum intensity value (<code class="literal">255</code>) in the stretched image.</p><p class="calibre8">We must, therefore, find the lowest (<code class="literal">imin</code>) and the highest (<code class="literal">imax</code>) intensity values so that we have the required number of pixels below or above the specified percentile. This is accomplished by the following loops (where <code class="literal">hist</code> is the computed 1D histogram):</p><pre class="programlisting">    // number of pixels in percentile 
    float number= image.total()*percentile; 
 
    // find left extremity of the histogram 
    int imin = 0; 
    for (float count=0.0; imin &lt; 256; imin++) { 
      // number of pixel at imin and below must be &gt; number 
      if ((count+=hist.at&lt;float&gt;(imin)) &gt;= number) 
        break; 
    } 
 
    // find right extremity of the histogram 
    int imax = 255; 
    for (float count=0.0; imax &gt;= 0; imax--) { 
      // number of pixel at imax and below must be &gt; number 
      if ((count += hist.at&lt;float&gt;(imax)) &gt;= number) 
        break; 
    }
</pre><p class="calibre8">The intensity values can then be remapped so that the <code class="literal">imin</code> value is repositioned at intensity <code class="literal">0</code> and the <code class="literal">imax</code> value is assigned the value of <code class="literal">255</code>. The in-between <code class="literal">i</code> intensities are simply linearly remapped, as follows:</p><pre class="programlisting">    255.0*(i-imin)/(imax-imin); 
</pre><p class="calibre8">The resulting stretched image with a percentile cut-off of 1% is then as follows:</p><p class="calibre8">
</p><div><img alt="Stretching a histogram to improve the image contrast" src="img/image_04_006.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">The expanded histogram then looks as follows:</p><p class="calibre8">
</p><div><img alt="Stretching a histogram to improve the image contrast" src="img/image_04_007.jpg" class="calibre17"/></div><p class="calibre8">
</p></div><div><div><div><div><h3 class="title3"><a id="ch04lvl3sec22" class="calibre6"/>Applying a look-up table to color images</h3></div></div></div><p class="calibre8">In 
<a href="ch02.html" title="Chapter 2. Manipulating Pixels">Chapter 2</a>
, <em class="calibre16">Manipulating Pixels</em>, we defined a color-reduction function that modifies the BGR values of an image in order to reduce the number of possible colors. We did this by looping through the image's pixels and applying the color-reduction function to each of them. In fact, it would be much more efficient to precompute all color reductions and then modify each pixel by using a look-up table. This is indeed very easy to accomplish from what we learned in this recipe. The new color-reduction function would then be written as follows:</p><pre class="programlisting">    void colorReduce(cv::Mat &amp;image, int div=64) { 
 
      // creating the 1D lookup table 
      cv::Mat lookup(1,256,CV_8U); 
 
      // defining the color reduction lookup 
      for (int i=0; i&lt;256; i++)  
        lookup.at&lt;uchar&gt;(i)= i/div*div + div/2; 
 
      // lookup table applied on all channels 
      cv::LUT(image,lookup,image); 
    }
</pre><p class="calibre8">The color-reduction scheme is correctly applied here because when a one-dimensional look-up table is applied to a multichannel image, then the same table is individually applied to all channels. When a look-up table has more than one dimension, then it must be applied to an image with the same number of channels.</p></div></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec85" class="calibre6"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The next recipe, <em class="calibre16">Equalizing the image histogram</em>, shows you another way to improve the image contrast</li></ul></div></div></div>
<div><div><div><div><h1 class="title1"><a id="ch04lvl1sec29" class="calibre6"/>Equalizing the image histogram</h1></div></div></div><p class="calibre8">In the previous recipe, we showed you how the contrast of an image can be improved by stretching a histogram so that it occupies the full range of the available intensity values. This strategy indeed constitutes an easy fix that can effectively improve the quality of an image. However, in many cases, the visual deficiency of an image is not that it uses a too-narrow range of intensities.</p><p class="calibre8">Rather, it is that some intensity values are used much more frequently than others. The histogram shown in the first recipe of this chapter is a good example of this phenomenon. The middle-gray intensities are indeed heavily represented, while darker and brighter pixel values are rather rare. One possible way to improve the quality of an image could therefore be to make equal use of all available pixel intensities. This is the idea behind the concept of <strong class="calibre15">histogram equalization</strong>, that is making the image histogram as flat as possible.</p><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec86" class="calibre6"/>How to do it...</h2></div></div></div><p class="calibre8">OpenCV offers an easy-to-use function that performs histogram equalization. It is called as follows:</p><pre class="programlisting">    cv::equalizeHist(image,result); 
</pre><p class="calibre8">After applying it on our image, the following image is obtained:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_008.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">This equalized image has the following histogram:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_009.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">Of course, the histogram cannot be perfectly flat because the look-up table is a global many-to-one transformation. However, it can be seen that the general distribution of the histogram is now more uniform than the original one.</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec87" class="calibre6"/>How it works...</h2></div></div></div><p class="calibre8">In a perfectly uniform histogram, all bins would have an equal number of pixels. This implies that 50 percent of the pixels should have an intensity lower than <code class="literal">128</code> (the median intensity value), 25 percent should have an intensity lower than <code class="literal">64</code>, and so on. This observation can be expressed using the rule that in a uniform histogram, <code class="literal">p%</code> of the pixels must have an intensity value lower than or equal to <code class="literal">255*p%</code>. The rule used to equalize a histogram is that the mapping of intensity <code class="literal">i</code> should be at the intensity that corresponds to the percentage of pixels that have an intensity value below <code class="literal">i</code>. Therefore, the required look-up table can be built from the following equation:</p><pre class="programlisting">    lookup.at&lt;uchar&gt;(i)= static_cast&lt;uchar&gt;(255.0*p[i]/image.total()); 
</pre><p class="calibre8">Here, <code class="literal">p[i]</code> is the number of pixels that have an intensity lower than or equal to <code class="literal">i</code>. The <code class="literal">p[i]</code> function is often referred to as a cumulative histogram, that is it is a histogram that contains the count of pixels lower than or equal to a given intensity instead of containing the count of pixels that have a specific intensity value. Recall that <code class="literal">image.total()</code> returns the number of pixels in an image, so <code class="literal">p[i]/image.total()</code> is a percentage of pixels.</p><p class="calibre8">Generally, the histogram equalization greatly improves the image's appearance. However, depending on the visual content, the quality of the result can vary from image to image.</p></div></div>
<div><div><div><div><h1 class="title1"><a id="ch04lvl1sec30" class="calibre6"/>Backprojecting a histogram to detect specific image content</h1></div></div></div><p class="calibre8">A histogram is an important characteristic of an image's content. If you look at an image area that shows a particular texture or a particular object, then the histogram of this area can be seen as a function that gives the probability that a given pixel belongs to this specific texture or object. In this recipe, you will learn how the concept of <strong class="calibre15">histogram backprojection</strong> can be advantageously used to detect specific image content.</p><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec88" class="calibre6"/>How to do it...</h2></div></div></div><p class="calibre8">Suppose you have an image and you wish to detect specific content inside it (for example, in the following image, the clouds in the sky). The first thing to do is to select a region of interest that contains a sample of what you are looking for. This region is the one inside the rectangle drawn on the following test image:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_010.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">In our program, the region of interest is obtained as follows:</p><pre class="programlisting">    cv::Mat imageROI; 
    imageROI= image(cv::Rect(216,33,24,30)); // Cloud region 
</pre><p class="calibre8">You then extract the histogram of this ROI. This is easily accomplished using the <code class="literal">Histogram1D</code> class defined in the first recipe of this chapter, as follows:</p><pre class="programlisting">    Histogram1D h; 
    cv::Mat hist= h.getHistogram(imageROI); 
</pre><p class="calibre8">By normalizing this histogram, we obtain a function that gives us the probability that a pixel of a given intensity value belongs to the defined area, as follows:</p><pre class="programlisting">    cv::normalize(histogram,histogram,1.0); 
</pre><p class="calibre8">Backprojecting a histogram consists of replacing each pixel value in an input image with its corresponding probability value read in the normalized histogram. An OpenCV function performs this task as follows:</p><pre class="programlisting">    cv::calcBackProject(&amp;image,
             1,          // one image 
             channels,   // the channels used,  
                         // based on histogram dimension 
             histogram,  // the histogram we are backprojecting 
             result,     // the resulting back projection image 
             ranges,     // the ranges of values 
             255.0       // the scaling factor is chosen  
                         // such that a probability value of 1 maps to 255 
    ); 
</pre><p class="calibre8">The <code class="literal">result</code> is the following probability map. For better readability, we display the negative of the <code class="literal">result</code> image, with probability of belonging to the reference area ranging from bright (low probability) to dark (high probability):</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_011.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">If we apply a threshold on this image, we obtain the most probable cloud pixels:</p><pre class="programlisting">    cv::threshold(result, result, threshold, 255, cv::THRESH_BINARY); 
</pre><p class="calibre8">The result is shown in the following screenshot:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_012.jpg" class="calibre17"/></div><p class="calibre8">
</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec89" class="calibre6"/>How it works...</h2></div></div></div><p class="calibre8">The preceding result is disappointing because, in addition to the clouds, other areas have been wrongly detected as well. It is important to understand that the probability function has been extracted from a simple gray-level histogram. Many other pixels in the image share the same intensities as the cloud pixels, and pixels of the same intensity are replaced with the same probability value when backprojecting the histogram. One solution to improve the detection result would be to use the color information. However, in order to do this, we need to modify the call to <code class="literal">cv::calBackProject</code>. This will be explained in the <em class="calibre16">There's more...</em> section.</p><p class="calibre8">The <code class="literal">cv::calBackProject</code> function is similar to the <code class="literal">cv::calcHist</code> function. The values associated with a pixel refer to one bin of a (potentially multi-dimensional) histogram. But instead of incrementing the bin count, the <code class="literal">cv::calBackProject</code> function assigns to the corresponding pixel in the output backprojection image the value read in that bin. The first parameter of this function specifies the input images (most of the time, only one). You then need to list the channel numbers you wish to use. The histogram that is passed to the function is, this time, an input parameter; its dimension should match the one of the channel list arrays. As with <code class="literal">cv::calcHist</code>, the ranges parameter specifies the bin boundaries of the input histogram in the form of an array of float arrays, each specifying the range (minimum and maximum values) of each channel.</p><p class="calibre8">The resulting output is an image containing the computed probability map. Since each pixel is replaced by the value found in the histogram at the corresponding bin position, the resulting image has values between <code class="literal">0.0</code> and <code class="literal">1.0</code> (assuming a normalized histogram has been provided as input). A last parameter allows you to optionally rescale these values by multiplying them by a given factor.</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec90" class="calibre6"/>There's more...</h2></div></div></div><p class="calibre8">Let's now see how we can use the color information in the histogram backprojection algorithm.</p><div><div><div><div><h3 class="title3"><a id="ch04lvl3sec23" class="calibre6"/>Backprojecting color histograms</h3></div></div></div><p class="calibre8">Multidimensional histograms can also be backprojected onto an image. Let's define a class that encapsulates the backprojection process. We first define the required attributes and initialize the data as follows:</p><pre class="programlisting">    class ContentFinder { 
      private: 
        // histogram parameters 
        float hranges[2]; 
        const float* ranges[3]; 
        int channels[3]; 
        float threshold;         // decision threshold 
        cv::Mat histogram;       // input histogram  
 
      public: 
      ContentFinder() : threshold(0.1f) { 
        // in this class, all channels have the same range 
        ranges[0]= hranges;   
        ranges[1]= hranges;  
        ranges[2]= hranges;  
      }
</pre><p class="calibre8">A <code class="literal">threshold</code> attribute used to create the binary map showing the detection result is introduced. If this parameter is set to a negative value, the raw probability map will be returned. The input histogram is normalized (this is, however, not required) as follows:</p><pre class="programlisting">    // Sets the reference histogram 
    void setHistogram(const cv::Mat&amp; h) { 
      histogram= h; 
      cv::normalize(histogram,histogram,1.0); 
    }
</pre><p class="calibre8">To backproject the histogram, you simply need to specify the image, the range (we assumed here that all channels have the same range), and the list of channels used. The <code class="literal">find</code> method performs the backprojection. Two versions of this method are available; the first one that uses the three channels of the image calls the more general version:</p><pre class="programlisting">    // Simplified version in which 
    // all channels used, with range [0,256[ by default 
    cv::Mat find(const cv::Mat&amp; image) { 
 
      cv::Mat result; 
      hranges[0]= 0.0;   // default range [0,256[hranges[1]= 256.0; 
      channels[0]= 0;    // the three channels  
      channels[1]= 1;  
      channels[2]= 2;  
      return find(image, hranges[0], hranges[1], channels); 
    } 
 
    // Finds the pixels belonging to the histogram 
    cv::Mat find(const cv::Mat&amp; image, float minValue, float maxValue,
                 int *channels) { 
 
      cv::Mat result; 
      hranges[0]= minValue; 
      hranges[1]= maxValue; 
      // histogram dim matches channel list 
      for (int i=0; i&lt;histogram.dims; i++) 
        this-&gt;channels[i]= channels[i]; 
 
      cv::calcBackProject(&amp;image, 1, // we only use one image  
                  channels,    // channels used  
                  histogram,   // the histogram we are using 
                  result,      // the back projection image 
                  ranges,      // the range of values, 
                               // for each dimension 
                  255.0        //the scaling factor is chosen such  
                               //that a histogram value of 1 maps to 255 
      ); 
    } 
 
    // Threshold back projection to obtain a binary image 
    if (threshold&gt;0.0) 
      cv::threshold(result, result, 255.0*threshold,
                    255.0, cv::THRESH_BINARY); 
 
      return result; 
    } 
</pre><p class="calibre8">Let's now use a BGR histogram on the color version of the image we used previously (see the book's website to see this image in color). This time, we will try to detect the blue sky area. We will first load the color image, define the region of interest, and compute the 3D histogram on a reduced color space, as follows:</p><pre class="programlisting">    // Load color image 
    ColorHistogram hc; 
    cv::Mat color= cv::imread("waves.jpg"); 
 
    // extract region of interest 
    imageROI= color(cv::Rect(0,0,100,45)); // blue sky area 
 
    // Get 3D color histogram (8 bins per channel) 
    hc.setSize(8); // 8x8x8 
    cv::Mat shist= hc.getHistogram(imageROI); 
</pre><p class="calibre8">Next, you compute the histogram and use the <code class="literal">find</code> method to detect the sky portion of the image, as follows:</p><pre class="programlisting">    // Create the content finder 
    ContentFinder finder; 
    // set histogram to be back-projected 
    finder.setHistogram(shist); 
    finder.setThreshold(0.05f); 
 
    // Get back-projection of color histogram 
    Cv::Mat result= finder.find(color); 
</pre><p class="calibre8">The result of the detection on the color version of the image in the previous section is seen here:</p><p class="calibre8">
</p><div><img alt="Backprojecting color histograms" src="img/image_04_013.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">The BGR color space is generally not the best one to identify color objects in an image. Here, to make it more reliable, we reduced the number of colors before computing the histogram (remember that the original BGR space counts more than 16 million colors). The histogram extracted represents the typical color distribution for a sky area. Try to backproject it on another image. It should also detect the sky portion. Note that using a histogram built from multiple sky images should increase the accuracy of this detection.</p><p class="calibre8">In this case, computing a sparse histogram would have been better in terms of memory usage. You should be able to redo this exercise using <code class="literal">cv::SparseMat</code> this time. Also, if you are looking for a bright-colored object, using the hue channel of the HSV color space would probably be more efficient. In other cases, the use of the chromaticity components of a perceptually uniform space (such as L*a*b*) might constitute a better choice.</p></div></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec91" class="calibre6"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The <em class="calibre16">Using the mean shift algorithm to find an object</em> recipe uses the HSV color space to detect an object in an image. This is one of the many alternative solutions you can use in the detection of some image content.</li><li class="listitem">The last two recipes of <a href="ch03.html" title="Chapter 3. Processing the Colors of an Image">Chapter 3</a>, <em class="calibre16">Processing the Colors of an Image</em>, discusses the different color spaces that you could use for histogram backprojection.</li></ul></div></div></div>
<div><div><div><div><h1 class="title1"><a id="ch04lvl1sec31" class="calibre6"/>Using the mean shift algorithm to find an object</h1></div></div></div><p class="calibre8">The result of a histogram backprojection is a probability map that expresses the probability that a given piece of image content is found at a specific image location. Suppose we now know the approximate location of an object in an image; the probability map can be used to find the exact location of the object. The most probable location will be the one that maximizes this probability inside a given window. Therefore, if we start from an initial location and iteratively move around in an attempt to increase the local probability measure, it should be possible to find the exact object location. This is what is accomplished by the <strong class="calibre15">mean shift algorithm</strong>.</p><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec92" class="calibre6"/>How to do it...</h2></div></div></div><p class="calibre8">Suppose we have identified an object of interest here, a baboon's face, as shown in the following image:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_015.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">This time, we will describe this object by using the hue channel of the HSV color space. This means that we need to convert the image into an HSV one and then extract the hue channel and compute the 1D hue histogram of the defined ROI. Refer to the following code:</p><pre class="programlisting">    // Read reference image 
    cv::Mat image= cv::imread("baboon01.jpg"); 
    // Baboon's face ROI 
    cv::Rect rect(110, 45, 35, 45); 
    cv::Mat imageROI= image(rect); 
    // Get the Hue histogram of baboon's face 
    int minSat=65; 
    ColorHistogram hc; 
    cv::Mat colorhist= hc.getHueHistogram(imageROI,minSat); 
</pre><p class="calibre8">As can be seen, the hue histogram is obtained using a convenient method that we have added to our <code class="literal">ColorHistogram</code> class as follows:</p><pre class="programlisting">    // Computes the 1D Hue histogram  
    // BGR source image is converted to HSV 
    // Pixels with low saturation are ignored 
    cv::Mat getHueHistogram(const cv::Mat &amp;image, int minSaturation=0) { 
 
      cv::Mat hist; 
 
      // Convert to HSV colour space 
      cv::Mat hsv; 
      cv::cvtColor(image, hsv, CV_BGR2HSV); 
 
      // Mask to be used (or not) 
      cv::Mat mask; 
      // creating the mask if required 
      if (minSaturation&gt;0) { 
 
        // Spliting the 3 channels into 3 images 
        std::vector&lt;cv::Mat&gt; v; 
        cv::split(hsv,v); 
 
        // Mask out the low saturated pixels 
        cv::threshold(v[1],mask,minSaturation,
                      255, cv::THRESH_BINARY); 
      } 
 
      //Prepare arguments for a 1D hue histogram 
      hranges[0]= 0.0;    // range is from 0 to 180 
      hranges[1]= 180.0; 
      channels[0]= 0;     // the hue channel  
 
      //Compute histogram 
      cv::calcHist(&amp;hsv, 1,  // histogram of 1 image only 
                   channels, //the channel used 
                   mask,     //binary mask 
                   hist,     //the resulting histogram 
                   1,        //it is a 1D histogram 
                   histSize, //number of bins 
                   ranges    //pixel value range 
      ); 
 
      return hist; 
    } 
</pre><p class="calibre8">The resulting histogram is then passed to our <code class="literal">ContentFinder</code> class instance, as follows:</p><pre class="programlisting">    ContentFinder finder; 
    finder.setHistogram(colorhist); 
</pre><p class="calibre8">Let's now open a second image, where we want to locate the new baboon's face position. This image needs to be converted to the HSV space first, and then we backproject the histogram of the first image. Refer to the following code:</p><pre class="programlisting">    image= cv::imread("baboon3.jpg"); 
    // Convert to HSV space 
    cv::cvtColor(image, hsv, CV_BGR2HSV); 
    // Get back-projection of hue histogram 
    int ch[1]={0}; 
    finder.setThreshold(-1.0f); // no thresholding 
    cv::Mat result= finder.find(hsv,0.0f,180.0f,ch); 
</pre><p class="calibre8">Now, from an initial rectangular area (that is, the position of the baboon's face in the initial image), the <code class="literal">cv::meanShift</code> algorithm of OpenCV will update the <code class="literal">rect</code> object at the new baboon's face location, as follows:</p><pre class="programlisting">    // initial window position 
    cv::Rect rect(110,260,35,40); 
 
    // search object with mean shift 
    cv::TermCriteria criteria( 
               cv::TermCriteria::MAX_ITER | cv::TermCriteria::EPS,  
               10, // iterate max 10 times 
               1); // or until the change in centroid position is less than 1px 
    cv::meanShift(result,rect,criteria); 
</pre><p class="calibre8">The initial (red) and new (green) face locations are displayed here:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_017.jpg" class="calibre17"/></div><p class="calibre8">
</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec93" class="calibre6"/>How it works...</h2></div></div></div><p class="calibre8">In this example, we used the hue component of the HSV color space in order to characterize the object we were looking for. We made this choice because the baboon's face has a very distinctive pink color; consequently, the pixels' hue should make the face easily identifiable. The first step, therefore, is to convert the image to the HSV color space. The hue component is the first channel of the resulting image when the <code class="literal">CV_BGR2HSV</code> flag is used. This is an 8-bit component that varies from <code class="literal">0</code> to <code class="literal">180</code> (with <code class="literal">cv::cvtColor</code>, the converted image is of the same type as the source image). In order to extract the hue image, the 3-channel HSV image is split into three 1-channel images using the <code class="literal">cv::split</code> function. The three images are inserted into a <code class="literal">std::vector</code> instance, and the hue image is the first entry of the vector (that is, at index <code class="literal">0</code>).</p><p class="calibre8">When using the hue component of a color, it is always important to take its saturation into account (which is the second entry of the vector). Indeed, when the saturation of a color is low, the hue information becomes unstable and unreliable. This is due to the fact that for low-saturated color, the B, G, and R components are almost equal. This makes difficult to determine the exact color that is represented. Consequently, we decided to ignore the hue component of colors with low saturation. That is, they are not counted in the histogram (using the <code class="literal">minSat</code>, parameter which masks out pixels with saturation below this threshold in the <code class="literal">getHueHistogram</code> method).</p><p class="calibre8">The mean shift algorithm is an iterative procedure that locates the local maxima of a probability function. It does this by finding the centroid, or weighted mean, of the data point inside a predefined window. The algorithm then moves the window center to the centroid location and repeats the procedure until the window center converges to a stable point. The OpenCV implementation defines two stopping criteria: a maximum number of iterations (<code class="literal">MAX_ITER</code>) and a window center displacement value below which the position is considered to have converged to a stable point (<code class="literal">EPS</code>). These two criteria are stored in a <code class="literal">cv::TermCriteria</code> instance. The <code class="literal">cv::meanShift</code> function returns the number of iterations that have been performed. Obviously, the quality of the result depends on the quality of the probability map provided on the given initial position. Note that here, we used a histogram of colors to represent an image's appearance; it is also possible to use histograms of other features to represent the object (for example, a histogram of edge orientation).</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec94" class="calibre6"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The mean shift algorithm has been largely used for visual tracking. <a href="ch13.html" title="Chapter 13. Tracking Visual Motion">
Chapter 13
</a>, <em class="calibre16">Tracking Visual Motion</em>, will explore the problem of object tracking in more detail</li><li class="listitem">The mean shift algorithm has been introduced in the article <em class="calibre16">Mean Shift: A robust approach toward feature space analysis</em> by <em class="calibre16">D. Comaniciu and P. Meer</em> in <em class="calibre16">IEEE transactions on Pattern Analysis and Machine Intelligence</em>, volume 24, number 5, May 2002</li><li class="listitem">OpenCV also offers an implementation of the <strong class="calibre15">CamShift</strong> algorithm, which is an improved version of the mean shift algorithm in which the size and the orientation of the window can change</li></ul></div></div></div>
<div><div><div><div><h1 class="title1"><a id="ch04lvl1sec32" class="calibre6"/>Retrieving similar images using the histogram comparison</h1></div></div></div><p class="calibre8">Content-based image retrieval is an important problem in computer vision. It consists of finding a set of images that present content that is similar to a given query image. Since we have learned that histograms constitute an effective way to characterize an image's content, it makes sense to think that they can be used to solve the <strong class="calibre15">content-based</strong> image<strong class="calibre15"> retrieval</strong> problem.</p><p class="calibre8">The key here is to be able to measure the similarity between two images by simply comparing their histograms. A measurement function that will estimate how different, or how similar, two histograms are will need to be defined. Various such measures have been proposed in the past, and OpenCV proposes a few of them in its implementation of the <code class="literal">cv::compareHist</code> function.</p><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec95" class="calibre6"/>How to do it...</h2></div></div></div><p class="calibre8">In order to compare a reference image with a collection of images and find the ones that are the most similar to this query image, we created an <code class="literal">ImageComparator</code> class. This class contains a reference to a query image and an input image, together with their histograms. In addition, since we will perform the comparison using color histograms, the <code class="literal">ColorHistogram</code> class is used inside our <code class="literal">ImageComparator</code> class:</p><pre class="programlisting">    class ImageComparator { 
 
      private: 
  
      cv::Mat refH;         // reference histogram 
      cv::Mat inputH;       // histogram of input image 
 
      ColorHistogram hist;  // to generate the histograms 
      int nBins;           // number of bins used in each color channel 
 
      public: 
      ImageComparator() :nBins(8) { 
 
      } 
</pre><p class="calibre8">To get a reliable similarity measure, the histogram should be computed over a reduced number of bins. Therefore, the class allows you to specify the number of bins to be used in each BGR channel. The query image is specified using an appropriate setter that also computes the reference histogram, as follows:</p><pre class="programlisting">    // set and compute histogram of reference image 
    void setReferenceImage(const cv::Mat&amp; image) { 
 
      hist.setSize(nBins); 
      refH= hist.getHistogram(image); 
    } 
</pre><p class="calibre8">Finally, a <code class="literal">compare</code> method compares the reference image with a given input image. The following method returns a score that indicates how similar the two images are:</p><pre class="programlisting">    // compare the images using their BGR histograms 
    double compare(const cv::Mat&amp; image) { 
 
      inputH= hist.getHistogram(image); 
 
      // histogram comparison using intersection 
      return cv::compareHist(refH,inputH, cv::HISTCMP_INTERSECT); 
    } 
</pre><p class="calibre8">The preceding class can be used to retrieve images that are similar to a given query image. A reference image is provided to the class instance as follows:</p><pre class="programlisting">    ImageComparator c; 
    c.setReferenceImage(image); 
</pre><p class="calibre8">Here, the query image we used is the color version of the beach image shown in the <em class="calibre16">Backprojecting a histogram to detect specific image content</em> recipe earlier in the chapter. This image was compared to the following series of images. The images are shown in order from the most similar to the least similar:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_018.jpg" class="calibre17"/></div><p class="calibre8">
</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec96" class="calibre6"/>How it works...</h2></div></div></div><p class="calibre8">Most histogram comparison measures are based on bin-by-bin comparisons. This is why it is important to work with a reduced histogram that will combine neighboring color into the same bin when measuring the similarity of two color histograms. The call to <code class="literal">cv::compareHist</code> is straightforward. You just input the two histograms and the function returns the measured distance. The specific measurement method you want to use is specified using a flag. In the <code class="literal">ImageComparator</code> class, the intersection method is used (with the <code class="literal">cv::HISTCMP_INTERSECT</code> flag). This method simply compares, for each bin, the two values in each histogram and keeps the minimum one. The similarity measure, then, is the sum of these minimum values. Consequently, two images that have histograms with no colors in common would get an intersection value of <code class="literal">0</code>, while two identical histograms would get a value that is equal to the total number of pixels.</p><p class="calibre8">The other available methods are the Chi-Square measure (the <code class="literal">cv::HISTCMP_CHISQR</code> flag), which sums the normalized square difference between the bins; the correlation method (the <code class="literal">cv::HISTCMP_CORREL</code> flag), which is based on the normalized cross-correlation operator used in signal processing to measure the similarity between two signals; and the Bhattacharyya measure (the <code class="literal">cv::HISTCMP_BHATTACHARYYA</code> flag) and Kullback-Leibler divergence (the <code class="literal">cv::HISTCMP_KL_DIV</code> flag), both used in statistics to estimate the similarity between two probabilistic distributions.</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec97" class="calibre6"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">The OpenCV documentation provides a description of the exact formulas used in the different histogram comparison measures.</li><li class="listitem">Earth Mover Distance is another popular histogram comparison method. It is implemented in OpenCV as the <code class="literal">cv::EMD</code> function. The main advantage of this method is that it takes into account the values found in adjacent bins to evaluate the similarity of two histograms. It is described in the article <em class="calibre16">The Earth Mover's Distance as a Metric for Image Retrieval</em> by <em class="calibre16">Y. Rubner, C. Tomasi, and L. J. Guibas in Int. Journal of Computer Vision</em>, Volume 40, No 2, 2000, pp. 99-121.</li></ul></div></div></div>
<div><div><div><div><h1 class="title1"><a id="ch04lvl1sec33" class="calibre6"/>Counting pixels with integral images</h1></div></div></div><p class="calibre8">In the previous recipes, we learned that a histogram is computed by going through all the pixels of an image and cumulating a count of how often each intensity value occurs in this image. We have also seen that, sometimes, we are only interested in computing our histogram in a certain area of the image. In fact, having to accumulate a sum of pixels inside an image's subregion is a common task in many computer vision algorithms. Now, suppose you have to compute several such histograms over multiple regions of interest inside your image. All these computations could rapidly become very costly. In such a situation, there is a tool that can drastically improve the efficiency of counting pixels over image subregions: the integral image.</p><p class="calibre8">Integral images have been introduced as an efficient way of summing pixels in image regions of interest. They are widely used in applications that involve, for example, computations over sliding windows at multiple scales.</p><p class="calibre8">This recipe will explain the principle behind integral images. Our objective here is to show how pixels can be summed over a rectangular region by using only three arithmetic operations. Once we have learned this concept, the <em class="calibre16">There's more...</em> section of this recipe will show you two examples where integral images can be advantageously used.</p><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec98" class="calibre6"/>How to do it...</h2></div></div></div><p class="calibre8">This recipe will play with the following picture, in which a region of interest showing a girl on her bike is identified:</p><p class="calibre8">
</p><div><img alt="How to do it..." src="img/image_04_021.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">Integral images are useful when you need to sum pixels over several image areas. Normally, if you wish to get the sum of all pixels over a region of interest, you would write the following code:</p><pre class="programlisting">    // Open image 
    cv::Mat image= cv::imread("bike55.bmp",0); 
    // define image roi (here the girl on bike) 
    int xo=97, yo=112; 
    int width=25, height=30; 
    cv::Mat roi(image,cv::Rect(xo,yo,width,height)); 
    // compute sum 
    // returns a Scalar to work with multi-channel images 
    cv::Scalar sum= cv::sum(roi); 
</pre><p class="calibre8">The <code class="literal">cv::sum</code> function simply loops over all the pixels of the region and accumulates the sum. Using an integral image, this can be achieved using only three additive operations. However, first you need to compute the integral image, as follows:</p><pre class="programlisting">      // compute integral image 
      cv::Mat integralImage; 
      cv::integral(image,integralImage,CV_32S); 
</pre><p class="calibre8">As will be explained in the next section, the same result can be obtained using this simple arithmetic expression on the computed integral image, as follows:</p><pre class="programlisting">    // get sum over an area using three additions/subtractions 
    int sumInt= integralImage.at&lt;int&gt;(yo+height,xo+width)- 
                integralImage.at&lt;int&gt;(yo+height,xo)- 
                integralImage.at&lt;int&gt;(yo,xo+width)+ 
                integralImage.at&lt;int&gt;(yo,xo); 
</pre><p class="calibre8">Both approaches give you the same result. However, computing the integral image is costly, since you have to loop over all the image pixels. The key is that once this initial computation is done, you will only need to add four values to get a sum over a region of interest no matter what the size of this region is. Integral images then become advantageous to use when multiple such pixel sums have to be computed over multiple regions of different sizes.</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec99" class="calibre6"/>How it works...</h2></div></div></div><p class="calibre8">In the previous section, you were introduced to the concept of integral images through a brief demonstration of the magic behind them, that is, how they can be used to cheaply compute the sum of pixels inside rectangular regions. To understand how they work, let's now define what an integral image is. An integral image is obtained by replacing each pixel with the value of the sum of all the pixels located inside the upper-left quadrant delimited by this pixel. The integral image can be computed by scanning the image once. Indeed, the integral value of a current pixel is given by the integral value of the pixel above this current pixel plus the value of the cumulative sum of the current line. The integral image is therefore a new image containing pixel sums. To avoid overflows, this image is usually an image of <code class="literal">int</code> values (<code class="literal">CV_32S</code>) or <code class="literal">float</code> values (<code class="literal">CV_32F</code>).</p><p class="calibre8">For example, in the following figure, pixel A in this integral image would contain the sum of the pixels contained inside the upper-left corner area, which is identified with a double-hatched pattern:</p><p class="calibre8">
</p><div><img alt="How it works..." src="img/image_04_022.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">Once the integral image has been computed, any summation over a rectangular region can be easily obtained through four pixel accesses, and here is why. Referring to the preceding figure, we can see that the sum of the pixels inside the region delimited by the pixels <strong class="calibre15">A</strong>, <strong class="calibre15">B</strong>, <strong class="calibre15">C</strong>, and <strong class="calibre15">D</strong> can be obtained by reading the integral value at pixel <strong class="calibre15">D</strong>, from which you subtract the values of the pixels over <strong class="calibre15">B</strong> and to the left-hand side of <strong class="calibre15">C</strong>. However, by doing so, you have subtracted twice the sum of pixels located in the upper-left corner of <strong class="calibre15">A</strong>; this is why you have to re-add the integral sum at <strong class="calibre15">A</strong>. Formally, then, the sum of pixels inside <strong class="calibre15">A</strong>, <strong class="calibre15">B</strong>, <strong class="calibre15">C</strong>, and <strong class="calibre15">D</strong> is given by <code class="literal">A-B-C+D</code>. If we use the <code class="literal">cv::Mat</code> method to access pixel values, this formula translates to the following:</p><pre class="programlisting">    // window at (xo,yo) of size width by height 
    return (integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo+height,xo+width)- 
            integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo+height,xo)- 
            integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo,xo+width)+ 
            integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo,xo)); 
</pre><p class="calibre8">The complexity of this computation is, therefore, constant, no matter what the size of the region of interest is. Note that, for simplicity, we used the <code class="literal">at</code> method of the <code class="literal">cv::Mat</code> class, which is not the most efficient way to access pixel values (see 
<a href="ch02.html" title="Chapter 2. Manipulating Pixels">Chapter 2</a>
, <em class="calibre16">Manipulating Pixels</em>). This aspect will be discussed in the <em class="calibre16">There's more...</em> section of this recipe, which presents two applications that benefit from the efficiency of the integral image concept.</p></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec100" class="calibre6"/>There's more...</h2></div></div></div><p class="calibre8">Integral images are used whenever multiple pixel summations must be performed. In this section, we will illustrate the use of integral images by introducing the concept of adaptive thresholding. Integral images are also useful for the efficient computation of histograms over multiple windows. This is also explained in this section.</p><div><div><div><div><h3 class="title3"><a id="ch04lvl3sec24" class="calibre6"/>Adaptive thresholding</h3></div></div></div><p class="calibre8">Applying a threshold on an image in order to create a binary image could be a good way to extract the meaningful elements of an image. Suppose that you have the following image of a book:</p><p class="calibre8">
</p><div><img alt="Adaptive thresholding" src="img/image_04_025.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">Since you are interested in analyzing the text in this image, you apply a threshold to this image as follows:</p><pre class="programlisting">    // using a fixed threshold  
    cv::Mat binaryFixed; 
    cv::threshold(image,binaryFixed,70,255,cv::THRESH_BINARY); 
</pre><p class="calibre8">You obtain the following result:</p><p class="calibre8">
</p><div><img alt="Adaptive thresholding" src="img/image_04_026.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">In fact, no matter what value you choose for the threshold, in some parts of the image you get missing text, whereas in other parts, the text disappears under the shadow. To overcome this problem, one possible solution consists of using a local threshold that is computed from each pixel's neighborhood. This strategy is called <strong class="calibre15">adaptive thresholding</strong>, and it consists of comparing each pixel with the mean value of the neighboring pixels. Pixels that clearly differ from their local mean will then be considered as outliers and will be cut off by the thresholding process.</p><p class="calibre8">Adaptive thresholding, therefore, requires the computation of a local mean around every pixel. This requires multiple image window summations that can be computed efficiently through the integral image. Consequently, the first step is to compute the following integral image:</p><pre class="programlisting">    // compute integral image 
    cv::Mat iimage; 
    cv::integral(image,iimage,CV_32S); 
</pre><p class="calibre8">Now we can go through all the pixels and compute the mean over a square neighborhood. We could use our <code class="literal">IntegralImage</code> class to do so, but this one uses the inefficient <code class="literal">at</code> method for pixel access. This time, let's get efficient by looping over the image using the pointers, as we learned in 
<a href="ch02.html" title="Chapter 2. Manipulating Pixels">Chapter 2</a>
, <em class="calibre16">Manipulating Pixels</em>. This loop looks as follows:</p><pre class="programlisting">    int blockSize= 21;  // size of the neighborhood 
    int threshold=10;   // pixel will be compared 
                        // to (mean-threshold) 
 
    // for each row 
    int halfSize= blockSize/2; 
    for (int j=halfSize; j&lt;nl-halfSize-1; j++) { 
 
      // get the address of row j 
      uchar* data= binary.ptr&lt;uchar&gt;(j); 
      int* idata1= iimage.ptr&lt;int&gt;(j-halfSize); 
      int* idata2= iimage.ptr&lt;int&gt;(j+halfSize+1); 
 
      // for each pixel of a line 
      for (int i=halfSize; i&lt;nc-halfSize-1; i++) { 
    
        // compute sum 
        int sum= (idata2[i+halfSize+1]-data2[i-halfSize]-  
                  idata1[i+halfSize+1]+idata1[i-halfSize]) 
                                      /(blockSize*blockSize); 
 
        // apply adaptive threshold 
        if (data[i]&lt;(sum-threshold)) 
          data[i]= 0; 
        else 
          data[i]=255; 
      } 
    } 
</pre><p class="calibre8">In this example, a neighborhood of size <code class="literal">21x21</code> is used. To compute each mean, we need to access the four integral pixels that delimit the square neighborhood: two located on the line pointed by <code class="literal">idata1</code> and two on the line pointed by <code class="literal">idata2</code>. The current pixel is compared to the computed mean, from which we subtract a threshold value (here, set to <code class="literal">10</code>); this is to make sure that rejected pixels clearly differ from their local mean. The following binary image is then obtained:</p><p class="calibre8">
</p><div><img alt="Adaptive thresholding" src="img/image_04_028.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">Clearly, this is a much better result than the one we got using a fixed threshold. Adaptive thresholding is a common image-processing technique. As such, it is also implemented in OpenCV as follows:</p><pre class="programlisting">    cv::adaptiveThreshold(image,        // input image 
            binaryAdaptive,             // output binary image 
            255,                        // max value for output 
            cv::ADAPTIVE_THRESH_MEAN_C, // method 
            cv::THRESH_BINARY,          // threshold type 
            blockSize,                  // size of the block       
            threshold);                 // threshold used 
</pre><p class="calibre8">This function call produces exactly the same result as the one we obtained using our integral image. In addition, instead of using the local mean for thresholding, this function allows you to use a Gaussian weighted sum (the method flag would be <code class="literal">cv::ADAPTIVE_THRESH_GAUSSIAN_C</code>) in this case. It is interesting to note that our implementation is slightly faster than the <code class="literal">cv::adaptiveThreshold</code> call.</p><p class="calibre8">Finally, it is worth mentioning that we can also write an adaptive thresholding procedure by using the OpenCV image operators. This would be done as follows:</p><pre class="programlisting">    cv::Mat filtered; 
    cv::Mat binaryFiltered;     
    // box filter compute avg of pixels over a rectangular region 
    cv::boxFilter(image,filtered,CV_8U,cv::Size(blockSize,blockSize)); 
    // check if pixel greater than (mean + threshold) 
    binaryFiltered= image&gt;= (filtered-threshold); 
</pre><p class="calibre8">Image filtering will be covered in 
<a href="ch06.html" title="Chapter 6. Filtering the Images">Chapter 6</a>
, <em class="calibre16">Filtering the Images</em>.</p></div><div><div><div><div><h3 class="title3"><a id="ch04lvl3sec25" class="calibre6"/>Visual tracking using histograms</h3></div></div></div><p class="calibre8">As we learned in the previous recipes, a histogram constitutes a reliable global representation of an object's appearance. In this section, we will demonstrate the usefulness of integral images by showing you how we can locate an object in an image by searching for an image area that presents a histogram similar to a target object. We accomplished this in the <em class="calibre16">Using the mean shift algorithm to find an object</em> recipe by using the concepts of histogram backprojection and local search through mean shift. This time, we will find our object by performing an explicit search for regions of similar histograms over the full image.</p><p class="calibre8">In the special case where an integral image is used on a binary image made of <code class="literal">0</code> and <code class="literal">1</code> values, the integral sum gives you the number of pixels that have a value of <code class="literal">1</code> inside the specified region. We will exploit this fact in this recipe to compute the histogram of a gray-level image.</p><p class="calibre8">The <code class="literal">cv::integral</code> function also works for multichannel images. You can take advantage of this fact to compute histograms of image subregions using integral images. You simply need to convert your image into a multichannel image made of binary planes; each of these planes is associated to a bin of your histogram and shows you which pixels have a value that falls into this bin. The following function creates such multiplane images from a gray-level one:</p><pre class="programlisting">    // convert to a multi-channel image made of binary planes 
    // nPlanes must be a power of 2 
    void convertToBinaryPlanes(const cv::Mat&amp; input,              
                               cv::Mat&amp; output, int nPlanes) { 
 
      // number of bits to mask out 
      int n= 8-static_cast&lt;int&gt;( 
                     log(static_cast&lt;double&gt;(nPlanes))/log(2.0)); 
      // mask used to eliminate least significant bits 
      uchar mask= 0xFF&lt;&lt;n;  
 
      // create a vector of binary images 
      std::vector&lt;cv::Mat&gt; planes; 
      // reduce to nBins by eliminating least significant bits 
      cv::Mat reduced= input&amp;mask; 
   
      // compute each binary image plane 
      for (int i=0; i&lt;nPlanes; i++) { 
        // 1 for each pixel equals to i&lt;&lt;shift 
        planes.push_back((reduced==(i&lt;&lt;n))&amp;0x1); 
      } 
 
      // create multi-channel image 
      cv::merge(planes,output); 
    } 
</pre><p class="calibre8">The integral image computations can also be encapsulated into one convenient template class as follows:</p><pre class="programlisting">    template &lt;typename T, int N&gt; 
    class IntegralImage { 
 
      cv::Mat integralImage; 
 
      public: 
 
      IntegralImage(cv::Mat image) { 
 
       // (costly) computation of the integral image          
       cv::integral(image,integralImage, 
                    cv::DataType&lt;T&gt;::type); 
      } 
 
      // compute sum over sub-regions of any size  
      // from 4 pixel accesses 
      cv::Vec&lt;T,N&gt; operator()(int xo, int yo, int width, int height) { 
 
      // window at (xo,yo) of size width by height 
      return (integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo+height,xo+width)- 
              integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo+height,xo)- 
              integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo,xo+width)+ 
              integralImage.at&lt;cv::Vec&lt;T,N&gt;&gt;(yo,xo)); 
      } 
 
    }; 
</pre><p class="calibre8">We now want to find where the girl on the bicycle, whom we identified in the previous image, is in a subsequent image. Let's first compute the histogram of the girl in the original image. We can accomplish this using the <code class="literal">Histogram1D</code> class we built in the recipe <em class="calibre16">Computing an image histogram</em> of this chapter. Here, we produce a 16-bin histogram as follows:</p><pre class="programlisting">    // histogram of 16 bins 
    Histogram1D h; 
    h.setNBins(16); 
    // compute histogram over image roi
    cv::Mat refHistogram=  h.getHistogram(roi); 
</pre><p class="calibre8">The preceding histogram will be used as a referential representation to locate the target object (the girl on her bike) in a subsequent image.</p><p class="calibre8">Suppose that the only information we have is that the girl is moving more or less horizontally across the image. Since we will have many histograms to compute at various locations, we compute the integral image as a preliminary step. Refer to the following code:</p><pre class="programlisting">    // first create 16-plane binary image 
    cv::Mat planes; 
    convertToBinaryPlanes(secondIimage,planes,16); 
    // then compute integral image 
    IntegralImage&lt;float,16&gt; intHistogram(planes); 
</pre><p class="calibre8">To perform the search, we loop over a range of possible locations and compare the current histogram with the referential one. Our goal is to find the location with the most similar histogram. Refer to the following code:</p><pre class="programlisting">    double maxSimilarity=0.0; 
    int xbest, ybest; 
    // loop over a horizontal strip around girl 
    // location in initial image 
    for (int y=110; y&lt;120; y++) { 
      for (int x=0; x&lt;secondImage.cols-width; x++) { 
 
        // compute histogram of 16 bins using integral image 
        histogram= intHistogram(x,y,width,height); 
        // compute distance with reference histogram 
        double distance= cv::compareHist(refHistogram,
                                         histogram,
                                         CV_COMP_INTERSECT); 
        //find position of most similar histogram 
        if (distance&gt;maxSimilarity) { 
 
          xbest= x; 
          ybest= y; 
          maxSimilarity= distance; 
        } 
      } 
    } 
    //draw rectangle at best location 
    cv::rectangle(secondImage, cv::Rect(xbest,ybest,width,height),0)); 
</pre><p class="calibre8">The location with the most similar histogram is then identified as followings:</p><p class="calibre8">
</p><div><img alt="Visual tracking using histograms" src="img/image_04_031.jpg" class="calibre17"/></div><p class="calibre8">
</p><p class="calibre8">The white rectangle represents the search area. Histograms of all windows that fit inside this area have been computed. We kept the window size constant, but it could have been a good strategy to also search for slightly smaller or larger windows in order to take into account the eventual changes in scale. Note that in order to limit the complexity of this computation, the number of bins in the histograms to be computed should be kept low. In our example, we reduced this to <code class="literal">16</code> bins. Consequently, plane <code class="literal">0</code> of this multiplane image contains a binary image that shows you all pixels that have a value between <code class="literal">0</code> and <code class="literal">15</code>, while plane <code class="literal">1</code> shows you pixels with values between <code class="literal">16</code> and <code class="literal">31</code>, and so on.</p><p class="calibre8">The search for an object consisted of computing the histograms of all windows of the given size over a predetermined range of pixels. This represents the computation of <code class="literal">3200</code> different histograms that have been efficiently computed from our integral image. All the histograms returned by our <code class="literal">IntegralImage</code> class are contained in a <code class="literal">cv::Vec</code> object (because of the use of the <code class="literal">at</code> method). We then use the <code class="literal">cv::compareHist</code> function to identify the most similar histogram (remember that this function, like most OpenCV functions, can accept either the <code class="literal">cv::Mat</code> or <code class="literal">cv::Vec</code> object through the convenient <code class="literal">cv::InputArray</code> generic parameter type).</p></div></div><div><div><div><div><h2 class="title2"><a id="ch04lvl2sec101" class="calibre6"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem"><a href="ch08.html" title="Chapter 8. Detecting Interest Points">
Chapter 8
</a>, <em class="calibre16">Detecting Interest Points</em>, will present the SURF operator that also relies on the use of integral images</li><li class="listitem">The <em class="calibre16">Finding objects and faces with a cascade of Haar features</em> recipe in<a href="ch14.html" title="Chapter 14. Learning from Examples">Chapter 14</a>, <em class="calibre16">Learning from Examples, </em>presents the Haar features that are computed using integral images</li><li class="listitem">The <em class="calibre16">Applying morphological operators on gray-level images</em> recipe in <a href="ch05.html" title="Chapter 5. Transforming Images with Morphological Operations">Chapter 5</a>,<p class="calibre8">
<em class="calibre16">Transforming Images with Morphological Operations</em>, presents an operator that can produce results similar to the presented adaptive thresholding technique</p></li><li class="listitem">The article <em class="calibre16">Robust Fragments-based Tracking using the Integral Histogram</em> by <em class="calibre16">A. Adam</em>, <em class="calibre16">E. Rivlin</em>, and <em class="calibre16">I. Shimshoni</em> in the <em class="calibre16">Proceedings of the International Conference on Computer Vision and Pattern Recognition</em>, 2006, pp. 798-805, describes an interesting approach that uses integral images to track objects in an image sequence</li></ul></div></div></div></body></html>