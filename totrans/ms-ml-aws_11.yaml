- en: Implementing Deep Learning with TensorFlow on AWS
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is a very popular deep learning framework that can be used to train
    deep neural networks, such as those described in the previous chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: About TensorFlow
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow as a general machine learning library
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training and serving the TensorFlow model through SageMaker
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a custom neural net with TensorFlow
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: About TensorFlow
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorFlow is a library for deep learning, first released by Google in 2015\.
    Initially, it included a core library that allowed users to work with tensors
    (multidimensional arrays) in symbolic form, thus enabling low-level neural network design
    and training at high performance. Nowadays, it's a fully fledged deep learning
    library that allows data scientists to build models for complex problems, such
    as image recognition, using high-level primitives. You can also use TensorFlow
    for solving standard machine learning problems, such as the ones we've been considering
    in the past chapters. TensorFlow has similar abstractions to the ones we have
    been using in `scikit-learn`, Apache Spark, and SageMaker. For example, it allows
    the user to create classification models or regression models using high-level
    abstractions, such as estimators, predictors, and evaluators.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow as a general machine learning library
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section we will  show how we use TensorFlow to create a regression
    model for the house estimation problem of [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml), *Predicting
    House Value with Regression Algorithms*. To get started, we will first launch
    a SageMaker notebook and choose the TensorFlow kernel (`conda_tensorflow_p36`),
    which has all the necessary TensorFlow dependencies needed for this section:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3d9cd933-f996-44b9-972a-bf56df7f2ace.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s consider the estimation problem from [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml), *Predicting
    House Value with Regression Algorithms*. Recall that we had a set of indicators
    (age of the house, distance to nearest center, and so on) to estimate the median
    value of the house (expressed in the `medv` column, which is our target feature),
    as shown in the following screenshot:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d2519263-cc3e-49ff-90f5-505b78a5769b.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: 'In [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml), *Predicting House
    Value with Regression Algorithms*, we identified 11 learning features to use for
    predicting the target feature (`medv`):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'With this information, we define a TensorFlow linear regressor capable of solving
    our regression problem with a pre-built neural net:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For the regressor, we decided to create a single-feature input, which assembles
    the rest of the features into a vector of numbers that will represent the input
    layer. It is also possible to create one named feature per training feature (as
    we did in [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml), *Predicting
    House Value with Regression Algorithms*), but we'll just have a single vector
    feature to simplify the prediction service discussed at the end of the section.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归器，我们决定创建一个单特征输入，它将其他特征组装成一个代表输入层的数字向量。也有可能为每个训练特征创建一个命名特征（就像我们在第3章中做的，*使用回归算法预测房屋价值*），但我们将只有一个向量特征来简化本节末尾讨论的预测服务。
- en: To construct a regressor, we need to pass in the TensorFlow feature columns,
    which can be of several different kinds. The `tf.feature_column` package provides
    functions to construct different kinds of columns, depending on the encoding being
    used by the model (for example, categorical, bucketized, and so on.). The feature
    columns inform the model on the expected format of the data being submitted as
    input. In our case, we will just tell the model to expect vector rows of length
    11.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个回归器，我们需要传递 TensorFlow 特征列，这些列可以是几种不同类型之一。`tf.feature_column` 包提供根据模型使用的编码构建不同类型列的函数（例如，分类、分桶等）。特征列通知模型提交为输入的数据的预期格式。在我们的情况下，我们只需告诉模型期望长度为11的向量行。
- en: 'To construct the actual data to be passed into the model, we need to create
    a matrix. The `pandas` library has a convenient method, `as_matrix()`, so we''ll
    slice the training features and build a matrix:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建要传递给模型的实际数据，我们需要创建一个矩阵。`pandas` 库有一个方便的方法，`as_matrix()`，因此我们将切片训练特征并构建一个矩阵：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Similarly, we''ll create the vector of features:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们将创建特征向量：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Once we have these two things, we can start plugging the data into the model.
    TensorFlow expects the data to be fed by defining a function that knows how to
    source the data into tensors (the building blocks of TensorFlow that represents
    a multidimensional array).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了这两样东西，我们就可以开始将数据插入到模型中。TensorFlow期望通过定义一个知道如何将数据源到张量（TensorFlow的多维数组的基本构建块）的函数来提供数据。
- en: 'The following is the code block for plugging in the data:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将数据插入的代码块：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `tf.estimator.inputs.numpy_input_fn` utility is able to construct such a
    function by providing the training matrix and target feature vectors. It will
    also create partitions of the data for running through the network a number of
    epochs. It also allows the user to pick the size of the batch (recall the mini-batch
    method mentioned in [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml), *Predicting
    House Value with Regression Algorithms*, for stochastic gradient descent) and
    other data feeding parameters. In essence, the underlying regressor's neural network
    relies on the `training_input_fn` function for creating the input tensors at each
    stage of the algorithm.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.estimator.inputs.numpy_input_fn` 工具能够通过提供训练矩阵和目标特征向量来构建这样一个函数。它还将创建数据分区，以便在多个epoch中运行网络。它还允许用户选择批次的尺寸（回想一下第3章中提到的迷你批次方法，*使用回归算法预测房屋价值*，用于随机梯度下降）。本质上，底层回归器的神经网络依赖于
    `training_input_fn` 函数在每个算法阶段创建输入张量。'
- en: 'Likewise, we create a similar function for feeding the testing data, in preparation
    for model evaluation:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们创建一个类似的函数来提供测试数据，为模型评估做准备：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To train the model, we call the usual `fit()` method, providing the function
    we created for sourcing the data:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练模型，我们调用常规的 `fit()` 方法，提供我们创建的数据来源函数：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `steps` argument is a limit we can impose on the number of total steps.
    A step, here, is one gradient descent update for one batch. Hence, each epoch
    runs a number of steps.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`steps` 参数是我们可以对总步数施加的限制。在这里，一个步骤是指对一个批次进行一次梯度下降更新。因此，每个epoch运行一定数量的步骤。'
- en: 'Once it completes the training, TensorFlow will output the loss metric in the
    `final` epoch:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成训练，TensorFlow将在 `final` epoch 输出损失度量：
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can then evaluate the accuracy of our model by running the test dataset
    (by providing the test dataset sourcing function):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过运行测试数据集（通过提供测试数据集来源函数）来评估我们模型的准确性：
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The preceding code generates the following output:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The average loss depends on the units of the target feature, so let's look at
    building a scatter plot like the one we created in [Chapter 3](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml), *Predicting
    House Value with Regression Algorithms*, to compare actual versus predicted house
    values. To do that, we first need to obtain `predictions`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 平均损失取决于目标特征的单位，因此让我们看看构建一个类似于我们在[第3章](eeb8abad-c8a9-40f2-8639-a9385d95f80f.xhtml)中创建的散点图，*使用回归算法预测房价*，以比较实际与预测的房价。为此，我们首先需要获得`predictions`。
- en: 'We simply call the `predict()` function to get `predictions`, again providing
    the test dataset sourcing function:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需调用`predict()`函数来获取`predictions`，再次提供测试数据集来源函数：
- en: '[PRE10]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `predictions` returned a value that is actually a Python generator of single-value
    vectors, so we can obtain a list of `predictions` by constructing the list-through-list
    comprehension:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`predictions`返回了一个实际上是单值向量的Python生成器，因此我们可以通过构造列表来获取`predictions`：'
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can thus examine `predicted_values`:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以检查`predicted_values`：
- en: '[PRE12]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding code generates the following output:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码生成了以下输出：
- en: '[PRE13]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can plug in the predicted values as a column to our original `pandas` test
    dataframe:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将预测值作为列插入到原始的`pandas`测试数据框中：
- en: '[PRE14]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This allows us to use the pandas plotting method to create the chart:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许我们使用pandas绘图方法来创建图表：
- en: '[PRE15]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can see the result in the following screenshot:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下屏幕截图中看到结果：
- en: '![](img/18617ff1-e19b-487e-be7b-4b62070de8c1.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/18617ff1-e19b-487e-be7b-4b62070de8c1.png)'
- en: Note that there is a clear correlation. To improve the performance, we would
    have to tune our regression model, the size of the batches, steps, epochs, and
    so on.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到存在明显的相关性。为了提高性能，我们可能需要调整我们的回归模型、批大小、步骤、周期等。
- en: Training and serving the TensorFlow model through SageMaker
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过SageMaker训练和部署TensorFlow模型
- en: Instead of training the model in a notebook instance, we train the model using
    the SageMaker infrastructure. In previous chapters, we used built-in estimators,
    such as BlazingText, XGBoost, and **Factorization Machines** (**FMs**). In this
    section, we will show how we can build our own TensorFlow models and train them
    through SageMaker, much like we did with these pre-built models. To do this, we
    just have to teach SageMaker how our TensorFlow model should be constructed and
    comply with some conventions regarding the format, location, and structure of
    the data. Through a Python script, we specify all of this.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 与在笔记本实例中训练模型不同，我们使用SageMaker基础设施来训练模型。在之前的章节中，我们使用了内置的估计器，如BlazingText、XGBoost和**因子分解机**（**FMs**）。在本节中，我们将展示如何构建自己的TensorFlow模型并通过SageMaker训练它们，就像我们处理这些预构建模型一样。为此，我们只需教会SageMaker如何构建我们的TensorFlow模型，并遵守一些关于数据格式、位置和结构的约定。通过一个Python脚本，我们指定所有这些。
- en: 'SageMaker will rely on this Python script to perform the training within SageMaker
    training instances:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker将依赖于这个Python脚本来在SageMaker训练实例中执行训练：
- en: '[PRE16]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The first few lines in the preceding code block are the usual imports and session
    creation necessary for getting started with SageMaker. The next important thing
    is the creation of a TensorFlow estimator. Note how we provide the constructor
    with a Python script, TensorFlow version, and Python version, as well as the usual
    parameters for instance number and type.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块的前几行是启动SageMaker所需的常规导入和会话创建。下一个重要的事情是创建一个TensorFlow估计器。注意我们如何向构造函数提供Python脚本、TensorFlow版本和Python版本，以及实例数量和类型的常规参数。
- en: 'Upon calling the `tf_estimator.fit(training_data_s3_path)` function, SageMaker
    will do the following tasks:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当调用`tf_estimator.fit(training_data_s3_path)`函数时，SageMaker将执行以下任务：
- en: Launch an EC2 instance (server).
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动一个EC2实例（服务器）。
- en: Download the S3 data to a local directory.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将S3数据下载到本地目录。
- en: Call the `tf_train.py` Python script to train the model. The Python script is
    expected to store the model on a certain local directory of the EC2 instance.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用`tf_train.py` Python脚本来训练模型。Python脚本预计将模型存储在EC2实例的某个本地目录中。
- en: Package the stored model in a `.tar.gz` file and upload it to S3\. Additionally,
    it will create an Amazon container and SageMaker model identifier.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将存储的模型打包成`.tar.gz`文件并上传到S3。此外，它还将创建一个Amazon容器和SageMaker模型标识符。
- en: Hence, the training happens on a SageMaker managed server, but the model it
    produces is a SageMaker compatible model, which can be used to serve predictions
    or run batch transform jobs, like the ones we worked with in previous chapters.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，训练是在 SageMaker 管理的服务器上进行的，但它产生的模型是 SageMaker 兼容的模型，可以用于提供预测或运行批量转换作业，就像我们在前几章中所做的那样。
- en: Let's take a look at the `tf_train.py` Python script, which is responsible for
    the model training and saving the model.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 `tf_train.py` Python 脚本，它负责模型训练和保存模型。
- en: 'This Python script must receive some information from the SageMaker container.
    In particular, it must receive the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Python 脚本必须从 SageMaker 容器接收一些信息。特别是，它必须接收以下信息：
- en: The local directory where SageMaker has downloaded the data (from S3)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker 下载数据的本地目录（从 S3）
- en: The location where the Python script needs to store the trained model
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 脚本需要存储训练好的模型的位置
- en: Other hyperparameters needed by the model (we will not dive into this yet and
    work with just fixed values, but we will show in [Chapter 14](7de65295-dd1f-4eb3-af00-3868ed7e2df9.xhtml), *Optimizing*
    *Models in Spark and SageMaker*, how these can be used for hyperparameter tuning)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型需要的其他超参数（我们目前不会深入探讨，而只是使用固定值，但我们将展示在 [第 14 章](7de65295-dd1f-4eb3-af00-3868ed7e2df9.xhtml)，*在
    Spark 和 SageMaker 中优化模型*，如何使用这些参数进行超参数调整）
- en: 'Take a look at the following code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 看看下面的代码：
- en: '[PRE17]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first part of the script is just setting up an argument parser. Since SageMaker
    calls this script as a black box, it needs to be able to inject such arguments
    to the script. With these arguments, it can train the TensorFlow model. You might
    notice that the training is exactly the same as what we did in the previous section.
    The only new part is saving the model and the definition of a new kind of function
    (`serving_input_fn`). This function has a similar purpose to the ones we used
    for training and testing, but instead, it will be used at the serving time (that
    is, each time a prediction request is made to the service). It is responsible
    for defining the necessary transformation from an input tensor placeholder to
    the features expected by the model. The `tf.estimator.export.build_parsing_serving_input_receiver_fn` utility
    can conveniently build a function for such purposes. It builds a function that
    expects `tf.Example` (a `protobuf`-serialized dictionary of features) fed into
    a string placeholder, so that it can parse such examples into feature tensors.
    In our case, we just have a single vector as input, so the transformation is straightforward.
    The last line in our script saves the model into the location requested by SageMaker
    through the `local_model_dir` argument. In order for the deserialization and unpacking
    to work, the convention is to save the model in a `/export/Servo` subdirectory.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本的前一部分只是设置一个参数解析器。由于 SageMaker 将此脚本作为黑盒调用，它需要能够将此类参数注入脚本中。有了这些参数，它可以训练 TensorFlow
    模型。你可能注意到，训练与我们在前一部分所做的是一样的。唯一的新部分是保存模型和定义一种新的函数（`serving_input_fn`）。这个函数与我们在训练和测试中使用的函数有类似的目的，但它在服务时间（即每次向服务发出预测请求时）将被使用。它负责定义从输入张量占位符到模型期望的特征的必要转换。`tf.estimator.export.build_parsing_serving_input_receiver_fn`
    工具可以方便地构建用于此类目的的函数。它构建一个期望 `tf.Example`（特征的一个 `protobuf` 序列化字典）被输入到字符串占位符中的函数，以便它可以解析这样的示例到特征张量。在我们的例子中，我们只有一个向量作为输入，所以转换是直接的。我们脚本中的最后一行将模型保存到
    SageMaker 通过 `local_model_dir` 参数请求的位置。为了使反序列化和解包工作，惯例是将模型保存到 `/export/Servo`
    子目录中。
- en: 'Once we run the `fit()` command, we can deploy the model as usual:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们运行 `fit()` 命令，我们就可以像往常一样部署模型：
- en: '[PRE18]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: For this example, we used a non-GPU instance type, but these are largely recommended
    for serious serving and training. We will dive into this in [Chapter 15](691fc3d8-e4b8-4e3f-a8d9-e13f53f058c4.xhtml), *Tuning
    Clusters for Machine Learning**.*
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们使用了一个非 GPU 实例类型，但这些在很大程度上被推荐用于严肃的服务和训练。我们将在 [第 15 章](691fc3d8-e4b8-4e3f-a8d9-e13f53f058c4.xhtml)，*调整机器学习集群*
    中深入探讨这一点。
- en: The `deploy()` command will launch a container capable of serving the model
    we constructed. However, constructing the payload to send to such service is not
    as trivial as the examples in the previous chapter, as we need to construct `tf.Example`.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`deploy()` 命令将启动一个容器，该容器能够为我们构建的模型提供服务。然而，构造要发送给此类服务的有效负载并不像前一章中的示例那样简单，因为我们需要构造
    `tf.Example`。'
- en: 'At prediction time we want to obtain the price given a specific feature vector.
    Suppose we want to find the price for these features:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测时，我们希望根据特定的特征向量获得价格。假设我们想要找到以下特征的价格：
- en: '[PRE19]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The first step is to construct a `tf.train.Example` instance, which in our
    case consists of a single feature called `inputs` with the floating point values
    of `features_vector`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是构建一个 `tf.train.Example` 实例，在我们的情况下，它由一个名为 `inputs` 的单个特征组成，该特征包含 `features_vector`
    的浮点值：
- en: '[PRE20]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The next step is to serialize the `model_input protobuf` message using `SerializeToString`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用 `SerializeToString` 将 `model_input protobuf` 消息序列化：
- en: '[PRE21]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Since this is really a string of bytes, we need to further encode `model_input`
    so that it can be sent in the payload as a string without special characters.
    We use `base64` encoding to do such a thing:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这实际上是一个字节字符串，我们需要进一步编码 `model_input`，以便它可以作为字符串发送到负载中，而不包含特殊字符。我们使用 `base64`
    编码来完成这项工作：
- en: '[PRE22]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Lastly, we call our `predictor` service by assembling a JSON request:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过组装一个 JSON 请求来调用我们的 `predictor` 服务：
- en: '[PRE23]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Note there is a special convention used for sending base64, encoded `protobuf`
    examples by creating a dictionary keyed with `b64`. The output decoded from JSON
    is a dictionary with the following prediction:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在发送通过创建以 `b64` 为键的字典来编码的 base64 `protobuf` 示例时，有一个特殊的约定。从 JSON 解码的输出是一个包含以下预测的字典：
- en: '[PRE24]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `inputs` and `outputs` payload JSON keys are part of the contract for SageMaker
    and should not be confused with the name of our single feature, `inputs`, which
    can be an arbitrary string.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`inputs` 和 `outputs` 负载 JSON 键是 SageMaker 的合约的一部分，不应与我们的单个特征 `inputs` 的名称混淆，`inputs`
    可以是任意字符串。'
- en: Creating a custom neural net with TensorFlow
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 创建自定义神经网络
- en: In the previous section, *Training and serving the TensorFlow model through
    SageMaker*, we used the high-level library of TensorFlow to construct a regression
    model using a `LinearRegressor`. In this section, we will show how we can construct
    an actual neural network using the Keras library from TensorFlow. Keras facilitates
    the design of neural networks by hiding some of the complexity behind the core
    (low-level) TensorFlow library.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节“通过 SageMaker 训练和部署 TensorFlow 模型”中，我们使用了 TensorFlow 的高级库，使用 `LinearRegressor`
    构建了一个回归模型。在本节中，我们将展示如何使用 TensorFlow 的 Keras 库构建一个实际的神经网络。Keras 通过隐藏核心（低级）TensorFlow
    库背后的某些复杂性来简化神经网络的设计。
- en: In this chapter, we will use the ubiquitous MNIST dataset, which consists of
    a series of images of handwritten digits along with the real label (values between
    0 and 1). The MNIST dataset can be downloaded from [https://www.kaggle.com/c/digit-recognizer/data](https://www.kaggle.com/c/digit-recognizer/data).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用无处不在的 MNIST 数据集，它包含一系列手写数字的图像以及真实的标签（0 到 1 之间的值）。MNIST 数据集可以从 [https://www.kaggle.com/c/digit-recognizer/data](https://www.kaggle.com/c/digit-recognizer/data)
    下载。
- en: The dataset comes as a CSV with 784 columns corresponding to each of the pixels
    in the 28 x 28 image. The values for each column represent the strength of the
    pixel in a gray scale from 0 to 255\. It also has an additional column for the
    label with a value between 0 and 9, corresponding to the actual digit.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集以 CSV 格式提供，包含 784 列，对应于 28 x 28 图像中的每个像素。每列的值代表像素在 0 到 255 的灰度强度。它还有一个额外的列用于标签，其值介于
    0 到 9 之间，对应于实际的数字。
- en: 'Let''s download the dataset and do our usual splitting into testing and training
    using `pandas` and `scikit-learn`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们下载数据集，并使用 `pandas` 和 `scikit-learn` 进行我们通常的测试和训练分割：
- en: '[PRE25]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can inspect the dataset through `train.head()`:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 `train.head()` 检查数据集：
- en: '![](img/144dc974-87ff-464d-97f6-8521f09e3286.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/144dc974-87ff-464d-97f6-8521f09e3286.png)'
- en: 'As we can see, the columns are labeled `pixelX`, where `x` is a number between
    `0` and `783`. Let''s define the names of these columns in distinct variables:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，列被标记为 `pixelX`，其中 `x` 是介于 `0` 和 `783` 之间的数字。让我们将这些列的名称定义为不同的变量：
- en: '[PRE26]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Each row in this dataset becomes a training example and thus represent the input
    layer of our network. On the other end of the network, we will have 10 nodes,
    each representing the probability of each digit given each input vector. For our
    example, we will just use one middle layer.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的每一行都成为了一个训练示例，因此代表了我们的网络输入层。在网络的另一端，我们将有 10 个节点，每个节点代表给定每个输入向量的每个数字的概率。在我们的例子中，我们将只使用一个中间层。
- en: 'The following diagram depicts our network structure:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了我们的网络结构：
- en: '![](img/cd1bc0d1-990d-4431-9d49-ca56f9657017.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cd1bc0d1-990d-4431-9d49-ca56f9657017.png)'
- en: 'To define such a network in Keras is very simple:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Keras 中定义这样的网络非常简单：
- en: '[PRE27]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Note how easy it is to define such a model. It consists of three layers:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 注意定义这样一个模型是多么容易。它由三个层组成：
- en: An input layer, where each vector is of size 784, and each gradient descent
    update will feed a mini-batch of five examples
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个输入层，其中每个向量的大小为784，并且每个梯度下降更新将提供五个示例的迷你批次
- en: A middle dense layer (meaning each node will connect to every other node in
    the next layer) with a **Rectified Linear Unit** (**ReLU**) activation function
    on each node
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个中间密集层（意味着每个节点将连接到下一层的每个节点）在每个节点上具有**Rectified Linear Unit**（**ReLU**）激活函数
- en: An output layer of size 10 using a softmax activation function (as we want a
    probability distribution over the digits)
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个大小为10的输出层，使用softmax激活函数（因为我们想要数字的概率分布）
- en: 'In addition to defining the network through a sequence of layers, TensorFlow
    will need to compile the model. This basically entails providing the kind of optimization
    method to use, the `loss` function, and the required metrics:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 除了通过一系列层定义网络之外，TensorFlow还需要编译模型。这基本上意味着提供要使用的优化方法、`loss`函数和所需的指标：
- en: '[PRE28]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The next stage will be to fit the model with our data. In order to feed the
    dataset into TensorFlow, we need to create `numpy` matrices, where each row is
    a training instance and each column represents a node in the input layer. Conveniently,
    the `pandas` method `dataframe.as_matrix()` does exactly that, so we will slice
    the dataset to include the training columns and construct such a matrix. Additionally,
    we will normalize the matrix to have each grayscale value between 0 and 1:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个阶段将是将模型与我们的数据拟合。为了将数据集输入到TensorFlow中，我们需要创建`numpy`矩阵，其中每一行是一个训练实例，每一列代表输入层中的一个节点。方便的是，`pandas`方法`dataframe.as_matrix()`正好能完成这个任务，因此我们将数据集切片以包含训练列并构建这样一个矩阵。此外，我们将矩阵归一化，以便每个灰度值介于0和1之间：
- en: '[PRE29]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Likewise, we obtain the `labels` vector by transforming the `pandas` series
    into a vector of digits:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们通过将`pandas`序列转换为数字向量来获得`labels`向量：
- en: '[PRE30]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now that we have our training matrix and labels, we are ready to fit our model. We
    do this by simply calling `fit()` and providing the labeled training data:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了训练矩阵和标签，我们准备拟合我们的模型。我们通过简单地调用`fit()`并提供标记的训练数据来完成此操作：
- en: '[PRE31]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The training will end with the loss and accuracy metrics on the training dataset:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 训练将以训练数据集中的损失和准确度指标结束：
- en: '[PRE32]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In order to determine whether our model is overfitting (that is, it just learns
    how to classify the images in our training dataset but fails to generalize over
    new images), we need to test our model in the testing dataset. For this, we will
    perform the same transformations we made on our training dataset, but for the
    test dataset.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定我们的模型是否过拟合（即，它只是学会了如何分类我们的训练数据集中的图像，但无法推广到新的图像），我们需要在测试数据集中测试我们的模型。为此，我们将对测试数据集执行我们在训练数据集上所做的相同转换。
- en: 'The `evaluate()` function of our model will provide accuracy evaluation metrics:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型的`evaluate()`函数将提供准确度评估指标：
- en: '[PRE33]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The preceding code generates the following output:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '[PRE34]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Note that our simple model is, in fact, fairly accurate. Let''s examine a few
    images in the testing dataset to see how the prediction matches the actual digit.
    For doing this, we will plot the images and compare them to the predicted digit
    by performing the following steps:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们的简单模型实际上相当准确。让我们检查测试数据集中的几个图像，看看预测是否与实际数字匹配。为此，我们将绘制图像，并通过以下步骤将它们与预测数字进行比较：
- en: 'First, we will define a function that obtains the predicted label for a particular
    row (`index`) on our testing dataset matrix:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将定义一个函数，该函数可以获得测试数据集矩阵中特定行（`index`）的预测标签：
- en: '[PRE35]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '`model.predict()` will obtain the predictions given a matrix of features. In
    this case, we just need one single row, so we slice our matrix into a single row
    to obtain the prediction for just the index in question. The predictions will
    be a vector of 10 components, each representing the strength of each digit. We
    use the `argmax` function to find the digit that maximizes the strength (that
    is, finding the most probable digit).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.predict()`将根据特征矩阵获得预测。在这种情况下，我们只需要一行，所以我们切片我们的矩阵为单行以获得特定索引的预测。预测将是一个包含10个组件的向量，每个组件代表每个数字的强度。我们使用`argmax`函数找到强度最大的数字（即，找到最可能的数字）。'
- en: 'Next, we define a function, `show_image()`, which, given an index, will plot
    the image:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个函数，`show_image()`，它将根据索引绘制图像：
- en: '[PRE36]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: We rely on the `PIL` library to perform the plotting. In order to plot the image,
    we need to denormalize our values back to the 0-255 range and reshape the 784
    pixels into a 28x28 image.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们依赖`PIL`库来进行绘图。为了绘制图像，我们需要将我们的值反归一化到0-255的范围，并将784个像素重塑为28x28的图像。
- en: 'Let''s examine a few instances in the following screenshots:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下截图中的几个实例来考察一下：
- en: '![](img/39b4fed9-a53d-4633-8af1-6d0fd46d561b.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/39b4fed9-a53d-4633-8af1-6d0fd46d561b.png)'
- en: 'And the second instance:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个例子：
- en: '![](img/757408e6-a4fa-48d0-9342-1d07f478acb2.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/757408e6-a4fa-48d0-9342-1d07f478acb2.png)'
- en: 'The following images were not able to be recognized correctly by the model:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像无法被模型正确识别：
- en: '![](img/bf05441b-f53d-491c-b1dc-093e51b57567.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/bf05441b-f53d-491c-b1dc-093e51b57567.png)'
- en: 'And the second instance:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个例子：
- en: '![](img/490e171f-14d4-4147-ac00-87a704f37b3c.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/490e171f-14d4-4147-ac00-87a704f37b3c.png)'
- en: You may probably agree that even a human could make similar mistakes.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能同意，即使是人类也可能犯类似的错误。
- en: So, how can we build a service on top of our `model`?
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何在我们的`model`之上构建一个服务呢？
- en: 'One simple way to do this is to create an `estimator` instance from our `model`:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 做这件事的一个简单方法是从我们的`model`创建一个`estimator`实例：
- en: '[PRE37]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Recall that `LinearRegressor` we used in the previous section was also an `estimator` instance,
    so the same process for training, serializing, and serving the model would apply
    starting from this `estimator` instance.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们在上一节中使用的`LinearRegressor`也是一个`estimator`实例，因此从这个`estimator`实例开始，训练、序列化和部署模型的过程是相同的。
- en: Summary
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we went through the process of creating two different TensorFlow
    models: one using the high-level library of estimators, and the other using Keras
    to build a custom neural network. In the process, we also showed how SageMaker
    can seamlessly handle the training and serving of TensorFlow models.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了创建两个不同的TensorFlow模型的过程：一个使用高级estimator库，另一个使用Keras构建自定义神经网络。在这个过程中，我们还展示了SageMaker如何无缝处理TensorFlow模型的训练和部署。
- en: In the next chapter, *Image Classification and Detection with SageMaker*,  we
    will show how to use deep learning out-of-the-box on AWS to detect and recognize
    images.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，*使用SageMaker进行图像分类和检测*中，我们将展示如何在AWS上使用深度学习直接检测和识别图像。
- en: Exercises
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'The following are the questions for this chapter:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的问题如下：
- en: What is the difference between an epoch, batch, and step?
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个epoch、batch和step之间的区别是什么？
- en: How would you design a network that would be able to provide recommendations
    for the theme park dataset considered in [Chapter 6](c940bfe6-b849-4179-b8f8-65e5d44652d6.xhtml),
    *Analyzing Visitor Patterns to Make Recommendations*?
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你会如何设计一个网络，能够为[第6章](c940bfe6-b849-4179-b8f8-65e5d44652d6.xhtml)中考虑的主题公园数据集提供推荐，该章节名为*分析游客模式以提供推荐*？
- en: How would you build a network that is capable of classifying the ads in [Chapter
    5](ccd8e969-f651-4fb9-8ef2-026286577e70.xhtml), *Customer Segmentation Using Clustering
    Algorithms*, as clicks/not-clicks?
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你会如何构建一个能够将[第5章](ccd8e969-f651-4fb9-8ef2-026286577e70.xhtml)中提到的广告分类为点击/未点击的网络，该章节名为*使用聚类算法进行客户细分*？
