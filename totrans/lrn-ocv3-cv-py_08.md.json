["```py\nimport cv2\nimport numpy as np\n\ncamera = cv2.VideoCapture(0)\n\nes = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,4))\nkernel = np.ones((5,5),np.uint8)\nbackground = None\n\nwhile (True):\n  ret, frame = camera.read()\n  if background is None:\n    background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    background = cv2.GaussianBlur(background, (21, 21), 0)\n    continue\n\n  gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n  gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n\n  diff = cv2.absdiff(background, gray_frame)\n  diff = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]\n  diff = cv2.dilate(diff, es, iterations = 2)\n  image, cnts, hierarchy = cv2.findContours(diff.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n  for c in cnts:\n    if cv2.contourArea(c) < 1500:\n      continue\n    (x, y, w, h) = cv2.boundingRect(c)\n    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n\n  cv2.imshow(\"contours\", frame)\n  cv2.imshow(\"dif\", diff)\n  if cv2.waitKey(1000 / 12) & 0xff == ord(\"q\"):\n      break\n\ncv2.destroyAllWindows()\ncamera.release()\n```", "```py\ndiff = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]\n```", "```py\ngray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\ngray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n```", "```py\ndiff = cv2.absdiff(background, gray_frame)  \ndiff = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]\ndiff = cv2.dilate(diff, es, iterations = 2)\n```", "```py\nimage, cnts, hierarchy = cv2.findContours(diff.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\nfor c in cnts:\n    if cv2.contourArea(c) < 1500:\n      continue\n    (x, y, w, h) = cv2.boundingRect(c)\n    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)\n\ncv2.imshow(\"contours\", frame)\ncv2.imshow(\"dif\", diff)\n```", "```py\nimport numpy as np\nimport cv2\n\ncap = cv2.VideoCapture')\n\nmog = cv2.createBackgroundSubtractorMOG2()\n\nwhile(1):\n    ret, frame = cap.read()\n    fgmask = mog.apply(frame)\n    cv2.imshow('frame',fgmask)\n    if cv2.waitKey(30) & 0xff:\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n```", "```py\nimport cv2\nimport numpy as np\n\nbs = cv2.createBackgroundSubtractorKNN(detectShadows = True)\ncamera = cv2.VideoCapture(\"/path/to/movie.flv\")\n\nwhile True:\n  ret, frame = camera.read()\n  fgmask = bs.apply(frame)\n  th = cv2.threshold(fgmask.copy(), 244, 255, cv2.THRESH_BINARY)[1]\n  dilated = cv2.dilate(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)), iterations = 2)\n  image, contours, hier = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n  for c in contours:\n    if cv2.contourArea(c) > 1600:\n      (x,y,w,h) = cv2.boundingRect(c)\n      cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 255, 0), 2)\n\n  cv2.imshow(\"mog\", fgmask)\n  cv2.imshow(\"thresh\", th)\n  cv2.imshow(\"detection\", frame)\n  if cv2.waitKey(30) & 0xff == 27:\n      break\n\ncamera.release()\ncv2.destroyAllWindows()\n```", "```py\nfgmask = bs.apply(frame)\nth = cv2.threshold(fgmask.copy(), 244, 255, cv2.THRESH_BINARY)[1]\ndilated = cv2.dilate(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)), iterations = 2)\nimage, contours, hier = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\nfor c in contours:\n    if cv2.contourArea(c) > 1600:\n        (x,y,w,h) = cv2.boundingRect(c)\n        cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 255, 0), 2)\n```", "```py\nimport numpy as np\nimport cv2\n\ncap = cv2.VideoCapture(0)\nret,frame = cap.read()\nr,h,c,w = 10, 200, 10, 200\ntrack_window = (c,r,w,h)\n\nroi = frame[r:r+h, c:c+w]\nhsv_roi =  cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\nmask = cv2.inRange(hsv_roi, np.array((100., 30.,32.)), np.array((180.,120.,255.)))\n\nroi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\ncv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n\nterm_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n\nwhile True:\n    ret ,frame = cap.read()\n\n    if ret == True:\n        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n\n        # apply meanshift to get the new location\n        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n\n        # Draw it on image\n        x,y,w,h = track_window\n        img2 = cv2.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n        cv2.imshow('img2',img2)\n\n        k = cv2.waitKey(60) & 0xff\n        if k == 27:\n            break\n\n    else:\n        break\n\ncv2.destroyAllWindows()\ncap.release()\n```", "```py\ncalcHist(...)\n    calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]]) -> hist\n```", "```py\nroi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n```", "```py\ncap = cv2.VideoCapture(0)\nret,frame = cap.read()\nr,h,c,w = 10, 200, 10, 200\ntrack_window = (c,r,w,h)\n```", "```py\nroi = frame[r:r+h, c:c+w]\nhsv_roi =  cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n```", "```py\nmask = cv2.inRange(hsv_roi, np.array((100., 30.,32.)), np.array((180.,120.,255.)))\n```", "```py\nroi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\ncv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n```", "```py\nterm_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n```", "```py\nif ret == True:\n        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n```", "```py\n        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n```", "```py\n[[  0   0   0 ...,   0   0   0]\n [  0   0   0 ...,   0   0   0]\n [  0   0   0 ...,   0   0   0]\n ..., \n [  0   0  20 ...,   0   0   0]\n [ 78  20   0 ...,   0   0   0]\n [255 137  20 ...,   0   0   0]]\n```", "```py\nmeanShift(...)\n    meanShift(probImage, window, criteria) -> retval, window\n```", "```py\nret, track_window = cv2.meanShift(dst, track_window, term_crit)\n```", "```py\nx,y,w,h = track_window\nimg2 = cv2.rectangle(frame, (x,y), (x+w,y+h), 255,2)\ncv2.imshow('img2',img2)\n```", "```py\nimport numpy as np\nimport cv2\n\ncap = cv2.VideoCapture(0)\n\n# take first frame of the video\nret,frame = cap.read()\n\n# setup initial location of window\nr,h,c,w = 300,200,400,300  # simply hardcoded the values\ntrack_window = (c,r,w,h)\n\nroi = frame[r:r+h, c:c+w]\nhsv_roi =  cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\nmask = cv2.inRange(hsv_roi, np.array((100., 30.,32.)), np.array((180.,120.,255.)))\nroi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\ncv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\nterm_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n\nwhile(1):\n    ret ,frame = cap.read()\n\n    if ret == True:\n        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n\n        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n        pts = cv2.boxPoints(ret)\n        pts = np.int0(pts)\n        img2 = cv2.polylines(frame,[pts],True, 255,2)\n\n        cv2.imshow('img2',img2)\n        k = cv2.waitKey(60) & 0xff\n        if k == 27:\n            break\n\n    else:\n        break\n\ncv2.destroyAllWindows()\ncap.release()\n```", "```py\nret, track_window = cv2.CamShift(dst, track_window, term_crit)\npts = cv2.boxPoints(ret)\npts = np.int0(pts)\nimg2 = cv2.polylines(frame,[pts],True, 255,2)\n```", "```py\n class KalmanFilter(__builtin__.object)\n |  Methods defined here:\n |  \n |  __repr__(...)\n |      x.__repr__() <==> repr(x)\n |  \n |  correct(...)\n |      correct(measurement) -> retval\n |  \n |  predict(...)\n |      predict([, control]) -> retval\n```", "```py\nimport cv2\nimport numpy as np\n\nframe = np.zeros((800, 800, 3), np.uint8)\nlast_measurement = current_measurement = np.array((2,1), np.float32) \nlast_prediction = current_prediction = np.zeros((2,1), np.float32)\n\ndef mousemove(event, x, y, s, p):\n    global frame, current_measurement, measurements, last_measurement, current_prediction, last_prediction\n    last_prediction = current_prediction\n    last_measurement = current_measurement\n    current_measurement = np.array([[np.float32(x)],[np.float32(y)]])\n    kalman.correct(current_measurement)\n    current_prediction = kalman.predict()\n    lmx, lmy = last_measurement[0], last_measurement[1]\n    cmx, cmy = current_measurement[0], current_measurement[1]\n    lpx, lpy = last_prediction[0], last_prediction[1]\n    cpx, cpy = current_prediction[0], current_prediction[1]\n    cv2.line(frame, (lmx, lmy), (cmx, cmy), (0,100,0))\n    cv2.line(frame, (lpx, lpy), (cpx, cpy), (0,0,200))\n\ncv2.namedWindow(\"kalman_tracker\")\ncv2.setMouseCallback(\"kalman_tracker\", mousemove)\n\nkalman = cv2.KalmanFilter(4,2)\nkalman.measurementMatrix = np.array([[1,0,0,0],[0,1,0,0]],np.float32)\nkalman.transitionMatrix = np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]],np.float32)\nkalman.processNoiseCov = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],np.float32) * 0.03\n\nwhile True:\n    cv2.imshow(\"kalman_tracker\", frame)\n    if (cv2.waitKey(30) & 0xFF) == 27:\n        break\n\ncv2.destroyAllWindows()\n```", "```py\nframe = np.zeros((800, 800, 3), np.uint8)\nlast_measurement = current_measurement = np.array((2,1), np.float32) \nlast_prediction = current_prediction = np.zeros((2,1), np.float32)\n```", "```py\ndef mousemove(event, x, y, s, p):\n    global frame, current_measurement, measurements, last_measurement, current_prediction, last_prediction\n    last_prediction = current_prediction\n    last_measurement = current_measurement\n    current_measurement = np.array([[np.float32(x)],[np.float32(y)]])\n    kalman.correct(current_measurement)\n    current_prediction = kalman.predict()\n    lmx, lmy = last_measurement[0], last_measurement[1]\n    cmx, cmy = current_measurement[0], current_measurement[1]\n    lpx, lpy = last_prediction[0], last_prediction[1]\n    cpx, cpy = current_prediction[0], current_prediction[1]\n    cv2.line(frame, (lmx, lmy), (cmx, cmy), (0,100,0))\n    cv2.line(frame, (lpx, lpy), (cpx, cpy), (0,0,200))\n```", "```py\ncv2.namedWindow(\"kalman_tracker\")\ncv2.setMouseCallback(\"kalman_tracker\", mousemove)\n```", "```py\nkalman = cv2.KalmanFilter(4,2)\nkalman.measurementMatrix = np.array([[1,0,0,0],[0,1,0,0]],np.float32)\nkalman.transitionMatrix = np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]],np.float32)\nkalman.processNoiseCov = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],np.float32) * 0.03\n```", "```py\ndef drawRect(frame, topLeft, bottomRight, color, thickness, fill = cv2.LINE_AA):\n    newframe = frame.copy()\n    cv2.rectangle(newframe, topLeft, bottomRight, color, thickness, fill)\n    return newframe\n```", "```py\nframe = camera.read()\nframe = drawRect(frame, (0,0), (10,10), (0, 255,0), 1)\n```", "```py\nclass Pedestrian():\n  \"\"\"Pedestrian class\n\n  each pedestrian is composed of a ROI, an ID and a Kalman filter\n  so we create a Pedestrian class to hold the object state\n  \"\"\"\n  def __init__(self, id, frame, track_window):\n    \"\"\"init the pedestrian object with track window coordinates\"\"\"\n    # set up the roi\n    self.id = int(id)\n    x,y,w,h = track_window\n    self.track_window = track_window\n    self.roi = cv2.cvtColor(frame[y:y+h, x:x+w], cv2.COLOR_BGR2HSV)\n    roi_hist = cv2.calcHist([self.roi], [0], None, [16], [0, 180])\n    self.roi_hist = cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n\n    # set up the kalman\n    self.kalman = cv2.KalmanFilter(4,2)\n    self.kalman.measurementMatrix = np.array([[1,0,0,0],[0,1,0,0]],np.float32)\n    self.kalman.transitionMatrix = np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]],np.float32)\n    self.kalman.processNoiseCov = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],np.float32) * 0.03\n    self.measurement = np.array((2,1), np.float32) \n    self.prediction = np.zeros((2,1), np.float32)\n    self.term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n    self.center = None\n    self.update(frame)\n\n  def __del__(self):\n    print \"Pedestrian %d destroyed\" % self.id\n\n  def update(self, frame):\n    # print \"updating %d \" % self.id\n    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n    back_project = cv2.calcBackProject([hsv],[0], self.roi_hist,[0,180],1)\n\n    if args.get(\"algorithm\") == \"c\":\n      ret, self.track_window = cv2.CamShift(back_project, self.track_window, self.term_crit)\n      pts = cv2.boxPoints(ret)\n      pts = np.int0(pts)\n      self.center = center(pts)\n      cv2.polylines(frame,[pts],True, 255,1)\n\n    if not args.get(\"algorithm\") or args.get(\"algorithm\") == \"m\":\n      ret, self.track_window = cv2.meanShift(back_project, self.track_window, self.term_crit)\n      x,y,w,h = self.track_window\n      self.center = center([[x,y],[x+w, y],[x,y+h],[x+w, y+h]])  \n      cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 255, 0), 1)\n\n    self.kalman.correct(self.center)\n    prediction = self.kalman.predict()\n    cv2.circle(frame, (int(prediction[0]), int(prediction[1])), 4, (0, 255, 0), -1)\n    # fake shadow\n    cv2.putText(frame, \"ID: %d -> %s\" % (self.id, self.center), (11, (self.id + 1) * 25 + 1),\n        font, 0.6,\n        (0, 0, 0),\n        1,\n        cv2.LINE_AA)\n    # actual info\n    cv2.putText(frame, \"ID: %d -> %s\" % (self.id, self.center), (10, (self.id + 1) * 25),\n        font, 0.6,\n        (0, 255, 0),\n        1,\n        cv2.LINE_AA)\n```", "```py\nhistory = 20\nbs = cv2.createBackgroundSubtractorKNN(detectShadows = True)\nbs.setHistory(history)\n```", "```py\ncv2.namedWindow(\"surveillance\")\n  pedestrians = {}\n  firstFrame = True\n  frames = 0\n```", "```py\nwhile True:\n    print \" -------------------- FRAME %d --------------------\" % frames\n    grabbed, frane = camera.read()\n    if (grabbed is False):\n      print \"failed to grab frame.\"\n      break\n\n    ret, frame = camera.read()\n```", "```py\n    fgmask = bs.apply(frame)\n    # this is just to let the background subtractor build a bit of history\n    if frames < history:\n      frames += 1\n      continue\n```", "```py\n    th = cv2.threshold(fgmask.copy(), 127, 255, cv2.THRESH_BINARY)[1]\n    th = cv2.erode(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)), iterations = 2)\n    dilated = cv2.dilate(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,3)), iterations = 2)\n    image, contours, hier = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n```", "```py\n    counter = 0\n    for c in contours:\n      if cv2.contourArea(c) > 500:\n        (x,y,w,h) = cv2.boundingRect(c)\n        cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 1)\n        # only create pedestrians in the first frame, then just follow the ones you have\n        if firstFrame is True:\n          pedestrians[counter] = Pedestrian(counter, frame, (x,y,w,h))\n        counter += 1\n```", "```py\n    for i, p in pedestrians.iteritems():\n        p.update(frame)\n```", "```py\n    firstFrame = False\n    frames += 1\n```", "```py\n    cv2.imshow(\"surveillance\", frame)\n    if cv2.waitKey(110) & 0xff == 27:\n        break\n\nif __name__ == \"__main__\":\n  main()\n```"]