["```py\nimport tensorflow as tf\nx = tf.constant(35, name='x')\ny = tf.Variable(x + 5, name='y')\nmodel = tf.global_variables_initializer()\nwith tf.Session() as session:\n    session.run(model)\n    print(session.run(y))\n```", "```py\nconda create -n tensorflow pip python=3.6\n```", "```py\n(project) D:\\Users\\vavinas>\n```", "```py\npip install tensorflow\n```", "```py\npip list\n```", "```py\n git clone https://github.com/googlecodelabs/tensorflow-for-poets-2\n```", "```py\ncd tensorflow-for-poets-2\n```", "```py\npython -m scripts.retrain \\\n  --bottleneck_dir=tf_files/bottlenecks \\\n  --how_many_training_steps=500 \\\n  --model_dir=tf_files/models/ \\\n  --summaries_dir=tf_files/training_summaries/ mobilenet_0.50_224  \\\n  --output_graph=tf_files/retrained_graph.pb \\\n  --output_labels=tf_files/retrained_labels.txt \\\n  --architecture=mobilenet_0.50_224  \\\n  --image_dir=tf_files/food_photos\n```", "```py\npython -m scripts.label_image \\\n    --graph=tf_files/retrained_graph.pb  \\\n    --image=tf_files\\food_photos\\pizza\\1.jpg\n```", "```py\nPip install tfcoreml\n```", "```py\nimport tensorflow as tf\nfrom tensorflow.core.framework import graph_pb2\nimport time\nimport operator\nimport sys\n\ndef inspect(model_pb, output_txt_file):\n    graph_def = graph_pb2.GraphDef()\n    with open(model_pb, \"rb\") as f:\n        graph_def.ParseFromString(f.read())\n\n    tf.import_graph_def(graph_def)\n\n    sess = tf.Session()\n    OPS = sess.graph.get_operations()\n\n    ops_dict = {}\n\n    sys.stdout = open(output_txt_file, 'w')\n    for i, op in enumerate(OPS):\n        print('---------------------------------------------------------------------------------------------------------------------------------------------')\n        print(\"{}: op name = {}, op type = ( {} ), inputs = {}, outputs = {}\".format(i, op.name, op.type, \", \".join([x.name for x in op.inputs]), \", \".join([x.name for x in op.outputs])))\n        print('@input shapes:')\n        for x in op.inputs:\n            print(\"name = {} : {}\".format(x.name, x.get_shape()))\n        print('@output shapes:')\n        for x in op.outputs:\n            print(\"name = {} : {}\".format(x.name, x.get_shape()))\n        if op.type in ops_dict:\n            ops_dict[op.type] += 1\n        else:\n            ops_dict[op.type] = 1\n\n    print('---------------------------------------------------------------------------------------------------------------------------------------------')\n    sorted_ops_count = sorted(ops_dict.items(), key=operator.itemgetter(1))\n    print('OPS counts:')\n    for i in sorted_ops_count:\n        print(\"{} : {}\".format(i[0], i[1]))\n\nif __name__ == \"__main__\":\n    \"\"\"\n    Write a summary of the frozen TF graph to a text file.\n    Summary includes op name, type, input and output names and shapes.\n\n    Arguments\n    ----------\n    - path to the frozen .pb graph\n    - path to the output .txt file where the summary is written\n\n    Usage\n    ----------\n    python inspect_pb.py frozen.pb text_file.txt\n\n    \"\"\"\n    if len(sys.argv) != 3:\n        raise ValueError(\"Script expects two arguments. \" +\n              \"Usage: python inspect_pb.py /path/to/the/frozen.pb /path/to/the/output/text/file.txt\")\n    inspect(sys.argv[1], sys.argv[2])\n```", "```py\nPython inspect.py retrained_graph.pb summeries.txt\n```", "```py\nimport UIKit class ViewController: UIViewController {\n @IBOutlet weak var pictureImageView :UIImageView! @IBOutlet weak var titleLabel :UILabel!\n```", "```py\nprivate var model : converted = converted()\n```", "```py\n var content : [ String : String ] = [ \"cheeseburger\" : \"A cheeseburger is a hamburger topped with cheese. Traditionally, the slice of cheese is placed on top of the meat patty, but the burger can include many variations in structure, ingredients, and composition.\\nIt has 303 calories per 100 grams.\", \"carbonara\" : \"Carbonara is an Italian pasta dish from Rome made with egg, hard cheese, guanciale, and pepper. The recipe is not fixed by a specific type of hard cheese or pasta. The cheese is usually Pecorino Romano.\", \"meat loaf\" : \"Meatloaf is a dish of ground meat mixed with other ingredients and formed into a loaf shape, then baked or smoked. The shape is created by either cooking it in a loaf pan, or forming it by hand on a flat pan.\\nIt has 149 calories / 100 grams\", \"pizza\" : \"Pizza is a traditional Italian dish consisting of a yeasted flatbread typically topped with tomato sauce and cheese and baked in an oven. It can also be topped with additional vegetables, meats, and condiments, and can be made without cheese.\\nIt has 285 calories / 100 grams\" *]*\n```", "```py\n let images = [\"burger.jpg\",\"pizza.png\", \"pasta.jpg\",\"meatloaf.png\"]\n```", "```py\n var index = 0 override func viewDidLoad() {\n super.viewDidLoad() nextImage() } @IBAction func nextButtonPressed() { nextImage() } func nextImage() { defer { index = index < images.count - 1 ? index + 1 : 0 }        let filename = images[index]\n guard let img = UIImage(named: filename) else { self.titleLabel.text = \"Failed to load image \\(filename)\" return } self.pictureImageView.image = img let resizedImage = img.resizeTo(size: CGSize(width: 224, height: 224)) guard let buffer = resizedImage.toBuffer() else { self.titleLabel.text = \"Failed to make buffer from image \\(filename)\" return }\n```", "```py\n do { let prediction = try self.model.prediction(input: MymodelInput(input__0: buffer))\n```", "```py\n if content.keys.contains(prediction.classLabel) { self.titleLabel.text = content[prediction.classLabel] } else { self.titleLabel.text = prediction.classLabel; }\n```", "```py\n } catch let error { self.titleLabel.text = error.localizedDescription } } }\n```", "```py\npip install tensorflow\npip install keras\npip install h5py\n```", "```py\nfrom __future__ import print_function\nfrom matplotlib import pyplot as plt\nimport keras\nfrom keras.datasets import mnist\n```", "```py\nfrom keras.models import Sequential\n```", "```py\nfrom keras.layers import Dense, Dropout, Flatten\n```", "```py\nfrom keras.layers import Conv2D, MaxPooling2D\n```", "```py\nfrom keras.utils import np_utils\n```", "```py\nfrom keras import backend as K \nimport coremltools\n```", "```py\n(x_train, y_train), (x_val, y_val) = mnist.load_data()\n```", "```py\n# Inspect x data\nprint('x_train shape: ', x_train.shape)\nprint(x_train.shape[0], 'training samples')\nprint('x_val shape: ', x_val.shape)\nprint(x_val.shape[0], 'validation samples')\nprint('First x sample\\n', x_train[0])\n```", "```py\nplt.imshow(x_train[0])\n```", "```py\nprint('y_train shape: ', y_train.shape)\nprint('First 10 y_train elements:', y_train[:10])\n```", "```py\nimg_rows, img_cols = x_train.shape[1], x_train.shape[2]\nnum_classes = 10\n\n# Set input_shape for channels_first or channels_last\nif K.image_data_format() == 'channels_first': \nx_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\nx_val = x_val.reshape(x_val.shape[0], 1, img_rows, img_cols)\ninput_shape = (1, img_rows, img_cols)\nelse: \n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)                     \n\nprint('x_train shape:', x_train.shape)\n# x_train shape: (60000, 28, 28, 1)\nprint('x_val shape:', x_val.shape)\n# x_val shape: (10000, 28, 28, 1)\nprint('input_shape:', input_shape)\n```", "```py\nx_train = x_train.astype('float32')\nx_val = x_val.astype('float32')\nx_train /= 255\nx_val /= 255\n```", "```py\ny_train = np_utils.to_categorical(y_train, num_classes)\ny_val = np_utils.to_categorical(y_val, num_classes)\nprint('New y_train shape: ', y_train.shape)\n# (60000, 10)\nprint('New y_train shape: ', y_train.shape)\n# (60000, 10)\nprint('First 10 y_train elements, reshaped:\\n', y_train[:10])\n```", "```py\nmodel_m = Sequential()\n```", "```py\nmodel_m.add(Conv2D(32, (5, 5), input_shape=(1,28,28), activation='relu'))\n```", "```py\nmodel_m.add(MaxPooling2D(pool_size=(2, 2)))\n```", "```py\nmodel_m.add(Dropout(0.5))\n```", "```py\nmodel_m.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_m.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_m.add(Dropout(0.2))\nmodel_m.add(Conv2D(128, (1, 1), activation='relu'))\nmodel_m.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_m.add(Dropout(0.2))\nmodel_m.add(Flatten())\nmodel_m.add(Dense(128, activation='relu'))\nmodel_m.add(Dense(num_classes, activation='softmax'))\nprint(model_m.summary())\n```", "```py\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n        monitor='val_loss', save_best_only=True),\n    keras.callbacks.EarlyStopping(monitor='acc', patience=1)]\n```", "```py\nmodel_m.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n```", "```py\n# Hyper-parameters\nbatch_size = 200\nepochs = 10\n```", "```py\n# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.model_m.fit(\n    x_train, y_train, batch_size=batch_size, epochs=epochs,    callbacks=callbacks_list, validation_data=(x_val, y_val), verbose=1)\n```", "```py\noutput_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\ncoreml_mnist = coremltools.converters.keras.convert(\n    'best_model.10-0.04.h5', input_names=['image'], output_names=['output'],    class_labels=output_labels, image_input_names='image')\ncoreml_mnist.save(\"minsit_classifier.mlmodel\")\n```", "```py\nlazy var classificationRequest: VNCoreMLRequest = {\n        // Load the ML model through its generated class and create a Vision request for it.\n        do {\n            let model = try VNCoreMLModel(for: MNISTClassifier().model)\n            return VNCoreMLRequest(model: model, completionHandler: self.handleClassification)\n        } catch {\n            fatalError(\"can't load Vision ML model: \\(error)\")\n        }\n    }()\n    func handleClassification(request: VNRequest, error: Error?) {\n        guard let observations = request.results as? [VNClassificationObservation]\n            else { fatalError(\"unexpected result type from VNCoreMLRequest\") }\n        guard let best = observations.first\n            else { fatalError(\"can't get best result\") }        DispatchQueue.main.async {\n            self.classificationLabel.text = \"Classification: \\\"\\(best.identifier)\\\" Confidence: \\(best.confidence)\"\n        }\n    }\n```"]