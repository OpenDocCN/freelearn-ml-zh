<html><head></head><body>
		<div id="_idContainer054">
			<h1 id="_idParaDest-44"><em class="italic"><a id="_idTextAnchor043"/>Chapter 3</em>: Data Preparation with SageMaker Data Wrangler</h1>
			<p>With SageMaker Data Wrangler, you can perform exploratory data analysis and data preprocessing for ML modeling with a point and click experience. You will be able to quickly iterate through data transformation and quick modeling to see if your transform recipe improves model performance, learning if there is implicit bias in the data against sensitive groups, and having a clear record of what transformation has been done on the processed data.</p>
			<p>In this chapter, we will be learning how to use <strong class="bold">SageMaker Data Wrangler</strong> in the following sections:</p>
			<ul>
				<li>Getting started with SageMaker Data Wrangler for customer churn prediction</li>
				<li>Importing data from sources</li>
				<li>Exploring data with visualization</li>
				<li>Applying transformation</li>
				<li>Exporting data for ML training</li>
			</ul>
			<h1 id="_idParaDest-45"><a id="_idTextAnchor044"/>Technical requirements</h1>
			<p>For this chapter, you will need to access materials in <a href="https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter03">https://github.com/PacktPublishing/Getting-Started-with-Amazon-SageMaker-Studio/tree/main/chapter03</a>. You need to make sure your IAM execution role has the AmazonAthenaFullAccess policy.</p>
			<h1 id="_idParaDest-46"><a id="_idTextAnchor045"/>Getting started with SageMaker Data Wrangler for customer churn prediction</h1>
			<p>Customer churn is a serious problem for businesses. Losing a customer is definitely not something <a id="_idIndexMarker177"/>you want to see if you are a business owner. You want to your customers to be happy with your product or service and continue to use them for, well, forever. Customer churn is always going to happen but being able to understand how and why a customer leaves the service or why a customer is not buying your product anymore is critical for your business. Being able to predict ahead of time would be even better.</p>
			<p>In this chapter, we will <a id="_idIndexMarker178"/>perform exploratory data analysis and data transformation with SageMaker Data Wrangler, and at the end of the chapter, we will be training an ML model using the <strong class="bold">XGBoost algorithm</strong> on the wrangled data.</p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor046"/>Preparing the use case</h2>
			<p>We are going <a id="_idIndexMarker179"/>to take a synthetic <strong class="bold">telecommunication</strong> (<strong class="bold">telco</strong>) customer churn dataset for this chapter to demonstrate what <a id="_idIndexMarker180"/>it takes to prepare a dataset for machine learning purposes. Please open the <strong class="source-inline">chapter03/1-prepare_data.ipynb</strong> notebook and execute the it. You will get a copy of the data, then perform these steps:</p>
			<ol>
				<li>Split the data into three data frames, <strong class="source-inline">customer_info</strong>, <strong class="source-inline">account_info</strong>, and <strong class="source-inline">utility</strong>, so that we can demonstrate joining in SageMaker Data Wrangler.</li>
				<li>Mask out values randomly to create missingness in the data so that we can demonstrate functionalities of SageMaker Data Wrangler.</li>
				<li>Save the three data frames in an S3 bucket and make <strong class="source-inline">utility</strong> available in Amazon Athena so that we can simulate importing data from multiple sources.</li>
			</ol>
			<h2 id="_idParaDest-48"><a id="_idTextAnchor047"/>Launching SageMaker Data Wrangler</h2>
			<p>You can <a id="_idIndexMarker181"/>access SageMaker Data Wrangler in any of the following ways:</p>
			<ul>
				<li>Click through <strong class="bold">File</strong> | <strong class="bold">New</strong> | <strong class="bold">Data Wrangler Flow</strong> (<em class="italic">Figure 3.1</em>).</li>
				<li>From <a id="_idIndexMarker182"/>the Launcher, click on <strong class="bold">New data flow</strong> (<em class="italic">Figure 3.1</em>).</li>
			</ul>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B17447_03_01.jpg" alt="Figure 3.1 – Creating a new Data Wrangler flow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.1 – Creating a new Data Wrangler flow</p>
			<ul>
				<li>From the left sidebar, <strong class="bold">SageMaker resources</strong>, choose Data Wrangler in the drop-down menu and click <strong class="bold">New flow</strong> (<em class="italic">Figure 3.2</em>).</li>
			</ul>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B17447_03_02.jpg" alt="Figure 3.2 – Creating a new Data Wrangler flow file from the registry. You can find all the flow files you have here too&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.2 – Creating a new Data Wrangler flow file from the registry. You can find all the flow files you have here too</p>
			<p>Notably, from <strong class="bold">SageMaker Components and registries</strong>, you can also see a list of flow files <a id="_idIndexMarker183"/>you have created. Once you create a new data flow file, you will see a new tab in the main working area with a progress bar indicating that it is creating an instance and will take a couple of minutes. At the same time, you will see a new file, <strong class="source-inline">untitled.flow</strong>, created in the current working directory. A <em class="italic">data flow file</em>, with the extension <strong class="source-inline">.flow</strong>, is a file that records all the steps you do with SageMaker Data Wrangler from the UI. It is a JSON-based file that can be easily transferred and reused. SageMaker Studio and Data Wrangler can interpret the content of the JSON file and render the transformations and analyses you do for the dataset. What's happening behind the scenes during this wait time is SageMaker Studio is launching a data wrangler <em class="italic">KernelGateway</em> app with a dedicated <em class="italic">ml.m5.4xlarge</em> instance to support the activities we are going to perform inside SageMaker Data Wrangler <a id="_idIndexMarker184"/>and to avoid contention with other notebook kernels. Once it's ready, you should see the view presented in <em class="italic">Figure 3.3</em>. </p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B17447_03_03.jpg" alt="Figure 3.3 – Starting point of a data wrangling journey with SageMaker Data Wrangler&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.3 – Starting point of a data wrangling journey with SageMaker Data Wrangler</p>
			<p>Before we proceed, let's rename the flow file to <strong class="source-inline">wrangling-customer-churn.flow</strong> or something to your liking by right-clicking on the file in the file explorer and selecting <strong class="bold">Rename</strong>.</p>
			<p>Now let's get started with SageMaker Data Wrangler.</p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor048"/>Importing data from sources</h1>
			<p>The first step in the data preparation journey is to import data from a source(s). There are four <a id="_idIndexMarker185"/>options from which data can be imported: <strong class="bold">Amazon S3</strong>, <strong class="bold">Amazon Athena</strong>, <strong class="bold">Amazon Redshift</strong>, and <strong class="bold">Snowflake</strong>. Amazon S3 is an object store service for developers to store virtually any kind of data, including text files, spreadsheets, archives, and ML models. Amazon Athena is an analytic service that gives developers an interactive and serverless SQL-based query experience for data stored in Amazon S3. Amazon Redshift is a data warehouse service that makes it easy to query and process exabytes of data. Snowflake is a data warehouse service from Snowflake Inc. In this chapter, we will be importing data from Amazon S3 and Amazon Athena, which are the two most common data sources. We have two tables in CSV format <a id="_idIndexMarker186"/>saved in the SageMaker default S3 bucket and a table available in Amazon Athena as we did in the <strong class="source-inline">chapter03/1-prepare_data.ipynb</strong> notebook.</p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/>Importing from S3</h2>
			<p>Please <a id="_idIndexMarker187"/>follow the next steps to import the CSV files into <a id="_idIndexMarker188"/>the S3 bucket. We want to load the <strong class="source-inline">customer_info</strong> and <strong class="source-inline">account_info</strong> tables:</p>
			<ol>
				<li value="1">From the view in <em class="italic">Figure 3.3</em>, select <strong class="bold">Amazon S3</strong> as the source. You should see a list of S3 buckets.</li>
				<li>Locate the data following the path of the SageMaker default bucket that has the naming convention <strong class="source-inline">sagemaker-&lt;region&gt;-&lt;accountid&gt;</strong>. Then descend into the <strong class="source-inline">sagemaker-studio-book/chapter03/data/</strong> folder to find the CSV files.</li>
				<li>Select <strong class="source-inline">telco_churn_customer_info.csv</strong> and inspect the data. Make sure the file type is CSV and <strong class="bold">First row is header</strong> is checked because our first row is indeed the header or variable names. <strong class="bold">Enable sampling</strong> can be left as the default in order to allow Data Wrangler to sample the data. Note that Data Wrangler is backed by an <strong class="source-inline">ml.m5.4xlarge</strong> instance with 16 vCPUs and 64 GiB of RAM. Sampling can be helpful to make sure the dataset fits into the memory when you have a large dataset. Click <strong class="bold">Import</strong>.</li>
				<li>Repeat steps 1–3 for <strong class="source-inline">telco_churn_account_info.csv</strong>.</li>
			</ol>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B17447_03_04.jpg" alt="Figure 3.4 – Data flow after two CSV files are imported&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.4 – Data flow after two CSV files are imported</p>
			<p>Once the <a id="_idIndexMarker189"/>two CSV files are loaded, you should see the <a id="_idIndexMarker190"/>view in <em class="italic">Figure 3.4</em> in the <strong class="bold">Data flow</strong> tab. Now let's move onto the last table, <strong class="source-inline">utility</strong>.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor050"/>Importing from Athena</h2>
			<p>As our <strong class="source-inline">utility</strong> table <a id="_idIndexMarker191"/>is being registered as an Amazon <a id="_idIndexMarker192"/>Athena table, we can import it from Athena with the following steps:</p>
			<ol>
				<li value="1">Click on the <strong class="bold">Import</strong> tab and select <strong class="bold">Amazon Athena</strong> as the source. You should see the view shown in <em class="italic">Figure 3.5</em>.</li>
				<li>For the two drop-down options, select <strong class="bold">AwsDataCatalog</strong> for <strong class="bold">Data catalog</strong> and select <strong class="bold">telco_db</strong> for <strong class="bold">Database</strong>. And for <strong class="bold">Advanced configuration</strong>, you can <a id="_idIndexMarker193"/>check/uncheck <strong class="bold">Enable sampling</strong>. As <a id="_idIndexMarker194"/>shown in <strong class="bold">Location of query results</strong>, you can find the output of the query in the location.</li>
			</ol>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B17447_03_05.jpg" alt="Figure 3.5 – Importing data from Amazon Athena&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.5 – Importing data from Amazon Athena</p>
			<ol>
				<li value="3">After you select the database, you will see the available tables on the right side in the <strong class="bold">DETAILS</strong> section, confirming that we have a <strong class="source-inline">telco_churn_utility</strong> table in our Amazon Athena database. You can click on the eye icon to preview the table so that we know how the table looks, as in <em class="italic">Figure 3.6</em>, and how to form a more complex query.</li>
			</ol>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B17447_03_06.jpg" alt="Figure 3.6 – Previewing the table&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.6 – Previewing the table</p>
			<ol>
				<li value="4">Let's <a id="_idIndexMarker195"/>get all the data through a query. Please <a id="_idIndexMarker196"/>put the following query statement into the query box. Then click <strong class="bold">Run</strong>:<p class="source-code">select * from telco_churn_utility</p></li>
				<li>You will find the query result below the query box. We get all the rows and columns with the previous statement. Inspect the data and click on the <strong class="bold">Import</strong> button at the top.</li>
				<li>Provide a dataset name, such as <strong class="source-inline">telco_churn_utility</strong>.</li>
			</ol>
			<p>You should see all three tables being loaded into the data flow in the <strong class="bold">Data Flow</strong> tab. By clicking on the plus sign when you hover over any of the rightmost nodes, you will see actions that you can perform on such tables, as shown in <em class="italic">Figure 3.7</em>.</p>
			<div>
				<div id="_idContainer035" class="IMG---Figure">
					<img src="image/B17447_03_07.jpg" alt="Figure 3.7 – Actions after tables are imported&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.7 – Actions after tables are imported</p>
			<p>Next, we <a id="_idIndexMarker197"/>should check the data types, or the schema <a id="_idIndexMarker198"/>of the tables, to make sure that they are being inferred correctly during the import process.</p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor051"/>Editing the data type</h2>
			<p>The data type dictates how each data column is read by Data Wrangler and how it should be <a id="_idIndexMarker199"/>processed. There are <strong class="bold">Long</strong>, <strong class="bold">Float</strong>, <strong class="bold">Boolean</strong>, <strong class="bold">String</strong>, and <strong class="bold">Date</strong> types in Data Wrangler. <strong class="bold">Long</strong> holds <a id="_idIndexMarker200"/>data that is in integer form. <strong class="bold">Float</strong> allows <a id="_idIndexMarker201"/>floating points <a id="_idIndexMarker202"/>in the data. <strong class="bold">Boolean</strong> represents binary values such as <em class="italic">0/1</em> and <em class="italic">Yes/No</em>. <strong class="bold">String</strong> makes the data a text-based entry. <strong class="bold">Date</strong> holds <a id="_idIndexMarker203"/>data that is in the form of text (<em class="italic">dd-MM-yyyy</em>) but is interpreted as a date instead of a string and allows date-related operations and comparison. </p>
			<p>The types of transformation that can be applied to data depends on the data type. For example, you can only apply a numerical operation on columns of the <strong class="source-inline">Long</strong> and <strong class="source-inline">Float</strong> types. Therefore, it is important to get the data types correctly defined before proceeding even though Data Wrangler does infer data types while importing.</p>
			<p>So, let's check and edit the data types of the imported tables in Data Wrangler:</p>
			<ol>
				<li value="1">From the view shown in <em class="italic">Figure 3.7</em>, click on the plus sign next to <strong class="source-inline">telco_churn_account_info.csv</strong> and select <strong class="bold">Edit data types</strong>.</li>
				<li>As shown in <em class="italic">Figure 3.8</em>, <strong class="bold">Account Length</strong>, which is all integers in the data, is inferred as the Float type. To avoid unnecessary floating and rounding issues, let's change it to the <strong class="source-inline">Long</strong> integer type. To change it, in <strong class="bold">CONFIGURE TYPES</strong> in the right panel, click on <strong class="bold">Type</strong> for the <strong class="bold">Account Length</strong> column, and select <strong class="bold">Long</strong>.</li>
				<li><strong class="bold">Int'l Plan</strong> and <strong class="bold">VMail Plan</strong> are inferred as <strong class="source-inline">String</strong>. But they should be of the Boolean type to conserve memory. Change them to <strong class="source-inline">Boolean</strong> by selecting <strong class="source-inline">Boolean</strong> in <strong class="bold">CONFIGURE TYPES</strong>.</li>
				<li>Click <strong class="bold">Preview</strong> to see how the data looks after the data type change. See <em class="italic">Figure 3.8</em>.</li>
			</ol>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="image/B17447_03_08.jpg" alt="Figure 3.8 – Editing data types in Data Wrangler&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.8 – Editing data types in Data Wrangler</p>
			<p>We can <a id="_idIndexMarker204"/>see that <strong class="bold">Account Length</strong> is now of the <strong class="bold">Long</strong> type with integer values intact and that <strong class="bold">Int'l Plan</strong> and <strong class="bold">Vmail Plan</strong> are <strong class="bold">Boolean</strong> with yes/no converted to true/false, as shown in the table. Data type conversion does not result in data loss or anything so we can proceed to apply the edit.</p>
			<ol>
				<li value="5">Click <strong class="bold">Apply</strong> to apply the changes to the table.<p class="callout-heading">Note</p><p class="callout">You can only make the change take effect if you first hit <strong class="bold">Preview</strong> then hit <strong class="bold">Apply</strong>.</p><p class="callout">You may be wondering why we do not change the <strong class="bold">Churn?</strong> Column, which has True/False. in the column from <strong class="source-inline">String</strong> type to <strong class="source-inline">Boolean</strong> type. This is because the period, <strong class="bold">.</strong>, in the values would invalidate the conversion. You can try changing it and preview the change. You will see the whole column being erased. We will deal with this column with transformation later.</p></li>
			</ol>
			<p>We've <a id="_idIndexMarker205"/>changed and confirmed the data type for the first table. We should do the same for the other two tables:</p>
			<ol>
				<li value="1">Click <strong class="bold">Back to data flow</strong> to return to the data flow.</li>
				<li>Click on the plus sign next to <strong class="source-inline">telco_churn_customer_info.csv</strong> and select <strong class="bold">Edit data types</strong>.</li>
				<li>Change <strong class="bold">Area Code</strong> from <strong class="source-inline">Long</strong> to <strong class="source-inline">String</strong>. Though this column has integer values, they should be treated as <strong class="source-inline">locality</strong> rather than numeric features.</li>
				<li>Click <strong class="bold">Preview</strong>, then <strong class="bold">Apply</strong>.</li>
				<li>Click <strong class="bold">Back to data flow</strong> to return to the data flow.</li>
				<li>Click on the plus sign next to the last table, <strong class="source-inline">telco_churn_utility</strong>, then select <strong class="bold">Edit data types</strong>.</li>
				<li>Change <strong class="source-inline">cust_serv_calls</strong> from <strong class="source-inline">Float</strong> to <strong class="source-inline">Long</strong>.</li>
				<li>Click <strong class="bold">Preview</strong>, then <strong class="bold">Apply</strong>.</li>
				<li>Click <strong class="bold">Back to data flow</strong> to return to the data flow.</li>
			</ol>
			<p>We've verified and fixed the data type for the three tables. Now it is time to join them together as one table.</p>
			<h2 id="_idParaDest-53"><a id="_idTextAnchor052"/>Joining tables</h2>
			<p>Joining tables is <a id="_idIndexMarker206"/>one of the most common steps when you are working with multiple data sources and the most important step to enrich your features when you are building an ML model. Think on relational database terms. Your tables maintain some sort of relationship that allows you to put them all together to get a big picture. We will be joining the three tables by <strong class="source-inline">customerID</strong> column with Data Wrangler. Please follow <a id="_idIndexMarker207"/>the next steps:</p>
			<ol>
				<li value="1">Click on the plus sign next to <strong class="source-inline">telco_churn_account_info.csv</strong> and select <strong class="bold">Join</strong>. You should see the view shown in <em class="italic">Figure 3.9</em>.</li>
			</ol>
			<div>
				<div id="_idContainer037" class="IMG---Figure">
					<img src="image/B17447_03_09.jpg" alt="Figure 3.9 – Joining tables in SageMaker Data Wrangler&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.9 – Joining tables in SageMaker Data Wrangler</p>
			<ol>
				<li value="2"><strong class="source-inline">telco_churn_account_info.csv</strong> is chosen as <strong class="bold">Left</strong>. We can now choose the rightmost node of <strong class="source-inline">telco_churn_customer_info.csv</strong> as <strong class="bold">Right</strong>. You should see the linkage between the two tables, as shown in <em class="italic">Figure 3.10</em>.</li>
			</ol>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="image/B17447_03_10.jpg" alt="Figure 3.10 – Joining tables &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.10 – Joining tables </p>
			<ol>
				<li value="3">Click <strong class="bold">Configure</strong> to continue.</li>
				<li>As <a id="_idIndexMarker208"/>shown in <em class="italic">Figure 3.11</em>, select <strong class="bold">Full outer</strong> as the <strong class="source-inline">join</strong> type as we expect to get all the data in, then select <strong class="bold">CustomerID</strong> for both <strong class="bold">Left</strong> and <strong class="bold">Right</strong> as the key to join.</li>
			</ol>
			<div>
				<div id="_idContainer039" class="IMG---Figure">
					<img src="image/B17447_03_11.jpg" alt="Figure 3.11 – Joining tables with Full outer and select keys&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.11 – Joining tables with Full outer and select keys</p>
			<ol>
				<li value="5">Click <strong class="bold">Apply</strong> to <a id="_idIndexMarker209"/>see the preview on the right, as shown in <em class="italic">Figure 3.12</em>. Notice that the data is successfully joined but with the joining key duplicated in the table: <strong class="source-inline">CustomerID_0</strong> and <strong class="source-inline">CustomerID_1</strong>. We will deal with this later in the <em class="italic">Applying transformation</em> section.</li>
				<li>Click <strong class="bold">Add</strong> in the top right to complete the join.</li>
				<li>Now we need to join the last table. Click on the plus sign next to the joined table and select <strong class="bold">Join</strong>.</li>
				<li>Select <strong class="source-inline">telco_churn_utility</strong> as <strong class="bold">Right</strong>, then click <strong class="bold">Configure</strong>.</li>
				<li>Again, select <strong class="bold">Full outer</strong> as the join type. Select <strong class="source-inline">CustomerID_0</strong> for <strong class="bold">Left</strong> and <strong class="source-inline">customer_id</strong> for <strong class="bold">Right</strong> to join.</li>
				<li>Click <strong class="bold">Apply</strong> to preview the joined dataset. Yes, the tables are joined, but with the keys duplicated, which can be addressed later in the <em class="italic">Applying transformation</em> section. No worries.</li>
				<li>Click <strong class="bold">Add</strong> in the <a id="_idIndexMarker210"/>top right to complete the join. You will be brought back to the data flow. You should see the flow, as shown in <em class="italic">Figure 3.12</em>.</li>
			</ol>
			<div>
				<div id="_idContainer040" class="IMG---Figure">
					<img src="image/B17447_03_12.jpg" alt="Figure 3.12 – Data flow after joining three tables&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.12 – Data flow after joining three tables</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you find anything that was done wrong, don't worry, just click on the plus sign on the node that has the mistake and select <strong class="bold">Delete</strong> to remove the node. But do keep in mind that if you delete a node that is not the last node, all the downstream nodes will be deleted too.</p>
			<p>We are ready to move on to the next phase: getting to explore the dataset!</p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/>Exploring data with visualization</h1>
			<p><strong class="bold">Exploratory data analysis</strong> (<strong class="bold">EDA</strong>) provides <a id="_idIndexMarker211"/>insights into the data at hand and helps us strategize the data transformation so that ML modeling can <a id="_idIndexMarker212"/>be the most performant. Analyzing and visualizing data with programming is robust and scalable but it requires lots of coding and development. Using SageMaker Data Wrangler, you can easily create charts and figures in the UI. Currently, SageMaker Data Wrangler supports the following types of chart and analysis that do not require coding: <strong class="bold">histogram</strong>, <strong class="bold">scatter plot</strong>, <strong class="bold">bias report</strong>, <strong class="bold">multicollinearity</strong>, <strong class="bold">quick model</strong>, <strong class="bold">target leakage</strong>, and <strong class="bold">table summary</strong>. Let's take a look at how they work one by one.</p>
			<h2 id="_idParaDest-55"><a id="_idTextAnchor054"/>Understanding the frequency distribution with a histogram</h2>
			<p>The histogram helps <a id="_idIndexMarker213"/>us understand the frequency distribution of a variable whose values <a id="_idIndexMarker214"/>are bucketed into discrete intervals with <a id="_idIndexMarker215"/>a bar graph. We can use the histogram function in SageMaker Data Wrangler to see, for example, how long callers spend making calls in the daytime. To do this, please follow these steps:</p>
			<ol>
				<li value="1">Click the plus sign next to the <strong class="bold">2nd Join</strong> node and select <strong class="bold">Add analysis</strong>. You should see the view shown in <em class="italic">Figure 3.13</em>.</li>
			</ol>
			<div>
				<div id="_idContainer041" class="IMG---Figure">
					<img src="image/B17447_03_13.jpg" alt="Figure 3.13 – Adding an analysis in SageMaker Data Wrangler&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.13 – Adding an analysis in SageMaker Data Wrangler</p>
			<ol>
				<li value="2">Fill in <a id="_idIndexMarker216"/>a name for the analysis in <strong class="bold">Analysis name</strong>, for <a id="_idIndexMarker217"/>example, <strong class="source-inline">day_mins_histogram</strong>.</li>
				<li>Choose <strong class="bold">day_mins</strong> for <strong class="bold">X axis</strong>.</li>
				<li>Click <strong class="bold">Preview</strong> to see the chart, as shown in <em class="italic">Figure 3.14</em>.</li>
			</ol>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B17447_03_14.jpg" alt="Figure 3.14 – Histogram of minutes of call time in the daytime&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.14 – Histogram of minutes of call time in the daytime</p>
			<p>This is great! You created your first visualization in SageMaker Data Wrangler to see the <a id="_idIndexMarker218"/>frequency distribution of call time <a id="_idIndexMarker219"/>in the daytime among all customers. We see that most customers' calls are shorter than 8 minutes and few calls are longer than 12 minutes. But this is an overall view. As a data scientist, you might want to know how customers who left the service behave differently from the customers who continue to use the service. We should slice and dice the data based on the target status: <strong class="bold">Churn?</strong>. We can do it through the <strong class="bold">Facet by</strong> option. We will proceed to modify the chart and not save the current chart.</p>
			<ol>
				<li value="5">Choose <strong class="bold">Churn?</strong> for <strong class="bold">Facet by</strong> and click <strong class="bold">Preview</strong>. You should see an updated chart, as in <em class="italic">Figure 3.15</em>.</li>
			</ol>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="image/B17447_03_15.jpg" alt="Figure 3.15 – Histogram of the day_mins variable by target &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.15 – Histogram of the day_mins variable by target </p>
			<p>We can <a id="_idIndexMarker220"/>conclude that customers who <a id="_idIndexMarker221"/>left the service (the <strong class="bold">True.</strong> chart) most frequently make calls for around 6-10 minutes while the customers who stayed with the service (the <strong class="bold">False.</strong> chart) talk less on calls. What an interesting observation. Let's save the analysis.</p>
			<ol>
				<li value="6">Click <strong class="bold">Save</strong> to save and return to the page where all analyses are saved.</li>
			</ol>
			<p>In the <strong class="bold">All Analyses</strong> view, you can see charts and analyses you created for each node at any given state. We have created a histogram. Let's go on to create another chart.</p>
			<h2 id="_idParaDest-56"><a id="_idTextAnchor055"/>Scatter plots</h2>
			<p>A data scientist <a id="_idIndexMarker222"/>might be wondering if customers who call more in the daytime also call often in the evening. Or you might be curious if any correlation exists between the customer's account length and call time. You can use a <strong class="bold">scatter plot</strong> to visualize this characteristic. Let's create a scatter plot for the data:</p>
			<ol>
				<li value="1">On the <strong class="bold">Analysis</strong> page, click <strong class="bold">Create new analysis</strong> at the top right.</li>
				<li>Choose <strong class="bold">Scatter Plot</strong> for <strong class="bold">Analysis type</strong>. Provide a name for the analysis, such as <strong class="source-inline">AccountLength_CallTime_Scatter</strong>.</li>
				<li>Choose <strong class="bold">Account Length</strong> for <strong class="bold">X axis</strong> and <strong class="bold">day_mins</strong> for <strong class="bold">Y axis</strong>.</li>
				<li>Click <strong class="bold">Preview</strong>. You should <a id="_idIndexMarker223"/>see a chart, as shown in <em class="italic">Figure 3.16</em>.</li>
			</ol>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="image/B17447_03_16.jpg" alt="Figure 3.16 – Scatter plot of Account Length versus day_mins&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.16 – Scatter plot of Account Length versus day_mins</p>
			<p>There does not seem to be any correlation visually between the two variables.</p>
			<p>Histograms and scatter plots are the two most common tools for EDA that you probably are familiar with. With SageMaker Data Wrangler, you can use ML-oriented analyses such as Quick Model to help you determine your data transformation strategy.</p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor056"/>Previewing ML model performance with Quick Model</h2>
			<p>Quick <a id="_idIndexMarker224"/>Model <a id="_idIndexMarker225"/>is another <a id="_idIndexMarker226"/>tool that helps you quickly get a sense of whether your data provides any predictive power with the variables presented in the data. This tool is useful and can be used frequently. Let's see how it works:</p>
			<ol>
				<li value="1">On the <strong class="bold">Analysis</strong> page, click <strong class="bold">Create new analysis</strong> in the top right.</li>
				<li>Choose <strong class="bold">Quick Model</strong> for <strong class="bold">Analysis type</strong>.</li>
				<li>Add a name in <strong class="bold">Analysis name</strong>, such as <strong class="source-inline">first_quickmodel</strong>.</li>
				<li>Choose <strong class="bold">Churn?</strong> for <strong class="bold">Label</strong> and click <strong class="bold">Preview</strong>.</li>
			</ol>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="image/B17447_03_17.jpg" alt="Figure 3.17 – Quick Model result that shows the F1 score of the model performance on a test set and feature importance&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.17 – Quick Model result that shows the F1 score of the model performance on a test set and feature importance</p>
			<p>SageMaker <a id="_idIndexMarker227"/>Data Wrangler takes <a id="_idIndexMarker228"/>a minute or so and returns a bar chart, as shown in <em class="italic">Figure 3.17</em>, showing the feature importance and an F1 score on a randomly split test set from the given dataset. We have not applied any transformation or data cleaning, as you can see in the following data table. SageMaker <a id="_idIndexMarker229"/>Data Wrangler employs a popular algorithm called <strong class="bold">random forest classification</strong> to train a model and test it out on a hold-out test set. We can see a preliminary result of a 0.851 F1 score, with <strong class="bold">night_charge</strong> being the most important feature in predicting customer churn status. We can also see that there are features that do not provide much predictive power, such as <strong class="bold">Int'l Plan</strong> and <strong class="bold">VMail Plan</strong>. And there are redundant features such as <strong class="bold">CustomerID_*</strong> that should not have been included in the modeling. This gives us hints to make sure to include <strong class="bold">night_charge</strong> and other high-importance features in the actual modeling and that we can leave out <strong class="bold">Int'l Plan</strong> and <strong class="bold">VMail Plan</strong> if we are restricted by the number of features we can use. Let's ink the analysis on the paper.</p>
			<ol>
				<li value="5">Click <strong class="bold">Save</strong> to save the analysis.</li>
			</ol>
			<p>As we <a id="_idIndexMarker230"/>just did our first quick modeling, to get <a id="_idIndexMarker231"/>a sense of the model performance we are getting, it is also a good idea to test whether we are running  into any data leakage or target leakage problems.</p>
			<h2 id="_idParaDest-58"><a id="_idTextAnchor057"/>Revealing target leakage</h2>
			<p>Target leakage means <a id="_idIndexMarker232"/>that there are features in the data that are highly correlated or basically a proxy representation of the target variable. For example, if our dataset contains a column that records the date of termination for each churned customer, then this column is going to contain those who churned, resulting in an extremely high modeling accuracy if we include it in the modeling. The problem in this example is that come prediction time in the real world, it is very unlikely to have the date of termination when the job of the model is to predict future churn. Let's see if our dataset contains any target leakage:</p>
			<ol>
				<li value="1">On the <strong class="bold">Analysis</strong> page, click <strong class="bold">Create new analysis</strong> in the top right.</li>
				<li>Choose <strong class="bold">Target Leakage</strong> for <strong class="bold">Analysis type</strong>.</li>
				<li>Add a name in <strong class="bold">Analysis name</strong>, such as <strong class="source-inline">churn_target_leakage</strong>.</li>
				<li>Input <strong class="source-inline">25</strong> for <strong class="bold">Max features</strong> because we have 24 columns in the table.</li>
				<li>Choose <strong class="bold">classification</strong> for <strong class="bold">Problem Type</strong>.</li>
				<li>Choose <strong class="bold">Churn?</strong> for <strong class="bold">Target</strong> and click <strong class="bold">Preview</strong>.</li>
			</ol>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="image/B17447_03_18.jpg" alt="Figure 3.18 – Target leakage result showing features that are safe and that are possibly redundant (color-coded with a legend to the right of the chart)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.18 – Target leakage result showing features that are safe and that are possibly redundant (color-coded with a legend to the right of the chart)</p>
			<p>The target leakage <a id="_idIndexMarker233"/>analysis computes the cross-validated area under the ROC for each individual feature against the target, as explained in the text above the chart in <em class="italic">Figure 3.18</em>. This analysis shows that no feature is determined as potential target leakage, which is a good sign. The result also confirms the conclusions we learned from the quick modeling exercise:</p>
			<p>a) <strong class="source-inline">night_charge</strong> is important in predicting churn and provides a high level of predictive ability.</p>
			<p>b) <strong class="source-inline">VMail Plan</strong> is providing little predictive ability.</p>
			<p>c) <strong class="source-inline">CustomerID_*</strong> is redundant in the dataset.</p>
			<p>Let's save the analysis.</p>
			<ol>
				<li value="7">Click <strong class="bold">Save</strong> to save the analysis.</li>
			</ol>
			<p>We learned about feature predictive power through the last two analyses. We should also take a look at how we can create a custom visualization with SageMaker Data Wrangler.</p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor058"/>Creating custom visualizations</h2>
			<p>SageMaker Data Wrangler uses <strong class="bold">Altair</strong> (<a href="https://altair-viz.github.io/">https://altair-viz.github.io/</a>) to create visualizations <a id="_idIndexMarker234"/>programmatically. We can create any custom visualization with code in SageMaker Data Wrangler as well for greater flexibility. For example, we can create a boxplot for <strong class="bold">night_charge</strong> by <strong class="bold">Churn?</strong> status to understand the statistical distribution of the two groups:</p>
			<ol>
				<li value="1">On the <strong class="bold">All Analyses</strong> page, click <strong class="bold">Create new analysis</strong> in the top right.</li>
				<li>Click the <strong class="bold">Code</strong> tab right next to <strong class="bold">Configure</strong>.</li>
				<li>Add a name, such as <strong class="source-inline">boxplot_night_charge_by_churn</strong>.</li>
				<li>Input the following code in the coding area. Be sure to import the <strong class="source-inline">altair</strong> library:<p class="source-code"># Table is available as variable 'df' of pandas dataframe</p><p class="source-code"># Output Altair chart is available as variable 'chart'</p><p class="source-code">import altair as alt</p><p class="source-code">chart=alt.Chart(df).mark_boxplot().encode(</p><p class="source-code">    x='Churn?',</p><p class="source-code">    y='night_charge')</p></li>
				<li>Click <strong class="bold">Preview</strong>.</li>
			</ol>
			<p>You should see a box plot representing the distribution of <strong class="bold">night_charge</strong> by <strong class="source-inline">Churn?</strong> status, as shown in <em class="italic">Figure 3.19</em>. If you hover over the box plot, you can see the descriptive statistics of the data.</p>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="image/B17447_03_19.jpg" alt="Figure 3.19 – Creating a custom boxplot using the Altair library&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.19 – Creating a custom boxplot using the Altair library</p>
			<ol>
				<li value="6">Click <strong class="bold">Save</strong> to save the custom visualization.</li>
			</ol>
			<p>What's worth <a id="_idIndexMarker235"/>noting is that these analyses and visualizations are saved as part of the flow file so that you can have full visibility of how you wrangle the data. </p>
			<p>With these analyses, we now have a good understanding of how we should transform and wrangle the data.</p>
			<h1 id="_idParaDest-60"><a id="_idTextAnchor059"/>Applying transformation</h1>
			<p>You can easily apply data transformation using SageMaker Data Wrangler because there are numerous <a id="_idIndexMarker236"/>built-in transformations you can use out of the box without any coding. So far, we have observed the following from the analyses that we need to handle next in order to build up an ML dataset:</p>
			<ul>
				<li>Missing data in some features.</li>
				<li>The <strong class="source-inline">Churn?</strong> column is now in string format with <strong class="source-inline">True.</strong> and <strong class="source-inline">False.</strong> as values.</li>
				<li>Redundant <strong class="source-inline">CustomerID_*</strong> columns after joins.</li>
				<li>Features that are not providing predictive power, including but not limited to <strong class="source-inline">Phone</strong>, <strong class="source-inline">VMail Plan</strong>, and <strong class="source-inline">Int'l Plan</strong>.</li>
			</ul>
			<p>We also would like to perform the following transformations for ML purposes because we want to train an XGBoost model to predict the <strong class="source-inline">Churn?</strong> status afterwards.</p>
			<ul>
				<li>Encoding categorical variables, that is, <strong class="source-inline">State</strong> and <strong class="source-inline">Area Code</strong> features.</li>
			</ul>
			<p>Let's <a id="_idIndexMarker237"/>get started:</p>
			<ol>
				<li value="1">In the <strong class="bold">Data Flow</strong> tab, click on the plus sign next to the <strong class="bold">2nd Join</strong> node, and select <strong class="bold">Add transform</strong>. You should see the view shown in <em class="italic">Figure 3.20,</em> with a table on the left and a list of transformations on the right.</li>
			</ol>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="image/B17447_03_20.jpg" alt="Figure 3.20 – A workspace to transform your data. You can expand each transform on the right side to see options&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.20 – A workspace to transform your data. You can expand each transform on the right side to see options</p>
			<ol>
				<li value="2">To drop <strong class="bold">CustomerID_*</strong>, click <strong class="bold">Manage columns</strong> to expand the transform, select <strong class="bold">Drop column</strong> in <strong class="bold">Transform</strong>, and select <strong class="bold">CustomerID_0</strong> for <strong class="bold">Column to drop</strong>.</li>
				<li>Click <strong class="bold">Preview</strong> to see <a id="_idIndexMarker238"/>the effect. <strong class="source-inline">CustomerID_0</strong> is now gone, as shown in <em class="italic">Figure 3.21</em>.</li>
			</ol>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/B17447_03_21.jpg" alt="Figure 3.21 – Dropping columns in SageMaker Data Wrangler&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.21 – Dropping columns in SageMaker Data Wrangler</p>
			<ol>
				<li value="4">Click <strong class="bold">Add</strong> to put the transformation into effect.</li>
				<li>Repeat steps 2–4 to drop <strong class="source-inline">CustomerID_1</strong> and <strong class="source-inline">customer_id</strong>.</li>
			</ol>
			<p>If done correctly, you should see four steps applied on the <strong class="bold">Previous steps</strong> tab to the right, as shown  in <em class="italic">Figure 3.22</em>.</p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B17447_03_22.jpg" alt="Figure 3.22 – Reviewing previous steps in the Previous steps tab&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.22 – Reviewing previous steps in the Previous steps tab</p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you realize you did anything incorrectly and want to revert to a previous transformation, you can <strong class="bold">Remove</strong> steps from the last one, one at a time, as shown in <em class="italic">Figure 3.22</em>.</p>
			<ol>
				<li value="6">Moving on <a id="_idIndexMarker239"/>to handling missing data in <strong class="bold">Account Length</strong> and <strong class="source-inline">cust_serv_calls</strong>, expand <strong class="bold">Handle missing</strong> in the transform list, select <strong class="bold">Impute</strong> for <strong class="bold">Transform</strong>, <strong class="bold">Numeric</strong> for <strong class="bold">Column type</strong>, <strong class="source-inline">Account Length</strong> for <strong class="bold">Input column</strong>, and <strong class="bold">Approximate Median</strong> for <strong class="bold">Imputing strategy</strong>. We can leave <strong class="bold">Output column</strong> empty to instruct SageMaker Data Wrangler to overwrite the existing column.</li>
				<li>Click <strong class="bold">Preview</strong>. You should see that a missing cell in the <strong class="bold">Account Length</strong> column is filled with the value <strong class="source-inline">102,</strong> as shown in <em class="italic">Figure 3.23</em>.</li>
			</ol>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/B17447_03_23.jpg" alt="Figure 3.23 – Account Length is filled with the median value, 102&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.23 – Account Length is filled with the median value, 102</p>
			<ol>
				<li value="8">Click <strong class="bold">Add</strong> to put <a id="_idIndexMarker240"/>the transformation into effect.</li>
				<li>Repeat steps 6–8 for <strong class="source-inline">cust_serv_calls</strong>.</li>
			</ol>
			<p>There are features that do not provide much predictive capability based on the quick model and target leakage analyses worth dropping too. <strong class="source-inline">Phone</strong> is one of the features that is shown to contain little to no useful information. Also, as is common knowledge, we know phone numbers are mostly randomly assigned when you sign up for a service. On the other hand, even though <strong class="source-inline">VMail Plan</strong> and <strong class="source-inline">Int'l Plan</strong> provide no predictive information, they are of the simple <strong class="source-inline">Boolean</strong> type and do have real meaning. It might not hurt as much to carry these features into modeling. So, let's drop the <strong class="source-inline">Phone</strong> feature.</p>
			<ol>
				<li value="10">Repeat steps 2–4 to drop <strong class="source-inline">Phone</strong>.</li>
			</ol>
			<p>Moving on to transforming categorical features, we have <strong class="source-inline">State</strong> and <strong class="source-inline">Area Code</strong>, which represent the location of a customer. We could apply one-hot encoding to transform them. However, we may risk the <strong class="bold">curse of dimensionality</strong> if one-hot encoding both features could result in too many features. Also, there is a limit of 1,000 columns allowed in SageMaker Data Wrangler. If we <a id="_idIndexMarker241"/>are not encoding <strong class="source-inline">Area Code</strong>, the next best action would be to drop it. Let's perform one-hot encoding to <strong class="source-inline">State</strong> and drop <strong class="source-inline">Area Code</strong>. </p>
			<ol>
				<li value="11">Expand <strong class="bold">Encode categorical</strong>, choose <strong class="bold">One-hot encode</strong> for <strong class="bold">Transform</strong>, select <strong class="bold">State</strong> for <strong class="bold">Input column</strong>, select <strong class="bold">Columns</strong> for <strong class="bold">Output style</strong>, and leave other options as their defaults.</li>
				<li>Click <strong class="bold">Preview</strong> to see the transformation. You should see the <strong class="source-inline">State</strong> column is replaced with <strong class="source-inline">State_*</strong> sparse features, with each representing whether customers are of a particular state (0 for false and 1 for true).</li>
				<li>Click <strong class="bold">Add</strong> to put the transformation into effect.</li>
				<li>Repeat steps 2–4 to drop <strong class="source-inline">Area Code</strong>.</li>
			</ol>
			<p>Last but not least, the target feature, <strong class="source-inline">Churn?,</strong> needs some wrangling. It has a weird period that messed up the data type conversion previously. Furthermore, the SageMaker built-in XGBoost algorithm we are going to use for modeling later requires the target feature to be in the first column. Let's apply a text operation and move the column.</p>
			<ol>
				<li value="15">Expand <strong class="bold">Format string</strong>, choose <strong class="bold">Remove symbols</strong> for <strong class="bold">Transform</strong>, select <strong class="source-inline">Churn?</strong> for <strong class="bold">Input column</strong>, and input <strong class="source-inline">.</strong> (a period) for <strong class="bold">Symbols</strong>.</li>
				<li>Click <strong class="bold">Preview</strong> to see the transformation. Now the ending period in <strong class="source-inline">Churn?</strong> has been removed, as shown in <em class="italic">Figure 3.24</em>. Click <strong class="bold">Add</strong> to put the transformation into effect.</li>
			</ol>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/B17447_03_24.jpg" alt="Figure 3.24 – Ending period removed in the Churn? column&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.24 – Ending period removed in the Churn? column</p>
			<ol>
				<li value="17">We can <a id="_idIndexMarker242"/>now use the data type parser to convert the True/False into a Boolean representation. Expand <strong class="bold">Parse column as type</strong>, choose <strong class="bold">Churn?</strong> for <strong class="bold">Column</strong>, and select <strong class="bold">Boolean</strong> in the <strong class="bold">To</strong> drop-down menu.</li>
				<li>Click <strong class="bold">Preview</strong> to see the transformation. Now the <strong class="bold">Churn?</strong> column is of the <strong class="source-inline">Boolean</strong> type. Click <strong class="bold">Add</strong> to put the transformation into effect.</li>
				<li>To move <strong class="bold">Churn?</strong> to the front, expand <strong class="bold">Manage columns</strong>, select <strong class="bold">Move column</strong> for <strong class="bold">Transform</strong>, select <strong class="bold">Move to start</strong> for <strong class="bold">Move type</strong>, and choose <strong class="bold">Churn?</strong> for <strong class="bold">Column to move</strong>.</li>
				<li>Click <strong class="bold">Preview</strong> to see the transformation. Now the <strong class="bold">Churn?</strong> column becomes the first feature. Click <strong class="bold">Add</strong> to put the transformation into effect.</li>
			</ol>
			<p>We've just applied eleven transformations to the dataset. We can run a quick modeling analysis to make sure we are on the right track in terms of modeling.</p>
			<h2 id="_idParaDest-61"><a id="_idTextAnchor060"/>Exploring performance while wrangling</h2>
			<p>You can always add an analysis at any point in time while wrangling the data in SageMaker <a id="_idIndexMarker243"/>Data Wrangler. This allows you to analyze the data after key transformation and verify the predictive power with Quick Model. Let's add an analysis for the wrangled data:</p>
			<ol>
				<li value="1">Click the <strong class="bold">Analysis</strong> tab.</li>
				<li>Choose <strong class="bold">Quick Model</strong> for <strong class="bold">Analysis type</strong>, add a name in <strong class="bold">Analysis name</strong>, and select <strong class="bold">Churn?</strong> for <strong class="bold">Label</strong>.</li>
				<li>Click <strong class="bold">Preview</strong> to see the modeling result, as shown in <em class="italic">Figure 3.25</em>. The model's F1 score has improved from <em class="italic">0.851</em> to <em class="italic">0.871</em>. We are on the right track.</li>
			</ol>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/B17447_03_25.jpg" alt="Figure 3.25 – Quick modeling after all transformations&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.25 – Quick modeling after all transformations</p>
			<ol>
				<li value="4">Click <strong class="bold">Add</strong> to put the analysis on the canvas.</li>
			</ol>
			<p>So far, we have used SageMaker Data Wrangler to analyze the telco churn dataset in depth and <a id="_idIndexMarker244"/>wrangled the data according to the findings from the analyses. Quick Model is showing an improved F1 score in predicting customer churn. We should move on to see what options we have with this work.</p>
			<h1 id="_idParaDest-62"><a id="_idTextAnchor061"/>Exporting data for ML training</h1>
			<p>SageMaker Data Wrangler supports the following export options: <strong class="bold">Save to S3</strong>, <strong class="bold">Pipeline</strong>, <strong class="bold">Python Code</strong>, and <strong class="bold">Feature Store</strong>. The data transformations we have applied so far are not really applied to the data yet. The transformation steps need to be executed <a id="_idIndexMarker245"/>to get the final transformed data. When we export our flow file with the preceding options, SageMaker Data Wrangler automatically generates code and notebooks to guide you through the execution process so that we do not have to write any code, but it leaves flexibility for us to customize the code.</p>
			<p>The four export options satisfy many use cases. <strong class="bold">Save to S3</strong> is an obvious one and offers lots of flexibility. If you would like to get the transformed data in an S3 bucket so that you can train an ML model in Amazon SageMaker, you can also download it locally from S3 and import it to other tools if you need to. The <strong class="bold">Pipeline</strong> option creates a SageMaker pipeline that can easily be called a repeatable workflow. Such workflows can be configured as event-triggered or time-triggered so that you can automate the data transformation as a pipeline. We will learn more about SageMaker Pipelines in <a href="B17447_10_ePub_RK.xhtml#_idTextAnchor134"><em class="italic">Chapter 10</em></a>, <em class="italic">Monitoring ML Models in Production with SageMaker Model Monitor</em>. <strong class="bold">Python Code</strong> offers the most visibility and flexibility. You can see how each transformation is implemented by Amazon SageMaker, run the code in a Spark environment, and get the data processed. With the <strong class="bold">Feature Store</strong> option, you get an automatically generated Jupyter notebook that will process the data and create a feature group in SageMaker Feature Store. We will learn more about SageMaker Feature Store in <a href="B17447_05_ePub_RK.xhtml#_idTextAnchor077"><em class="italic">Chapter 5</em></a>, <em class="italic">Building and Training ML Models with SageMaker Studio IDE</em>.</p>
			<p>For this example, I'd like to show you the option <strong class="bold">Save to S3</strong>, which includes ML training in the automatically generated notebook:</p>
			<ol>
				<li value="1">First, save the flow file so that the exported resource will pick up the latest change. In the menu bar, select <strong class="bold">File</strong>-&gt;<strong class="bold">Save Data Wrangler Flow</strong>.</li>
				<li>Click on the <strong class="bold">Export</strong> tab, click the <strong class="bold">Steps</strong> node, and select the last step, <strong class="bold">Move column</strong>, in the list of transformations. By clicking a step, all the steps leading to the step chosen will be selected.</li>
				<li>Click <strong class="bold">Export step</strong> in the top right, and click <strong class="bold">Save to S3</strong>. </li>
			</ol>
			<p>A new Python <a id="_idIndexMarker246"/>Jupyter notebook should pop out. This notebook contains code to process the SageMaker Data Wrangler flow file using SageMaker Processing and to save the processed data in S3. This is our first encounter with SageMaker Processing in action. In short, it allows us to use appropriate compute resources to perform data processing, model evaluation, and statistical analysis. With SageMaker Processing, you are no longer bound by the compute resource available locally in the Studio notebook environment; instead, the processing script and Data Wrangler flow file can be run on a right-size compute instance(s). You can see things in action in the following steps.</p>
			<ol>
				<li value="4">Please execute all the cells before <strong class="bold">(Optional) Next Steps</strong> section.<p class="callout-heading">Note</p><p class="callout">You may configure the notebook in the section where you see 💡 <strong class="bold">Configurable Settings</strong>.</p></li>
			</ol>
			<p>The SageMaker Processing job may take a couple of minutes. At the end of the processing job, the processed data is available in an S3 bucket. You should see the following output from the cell:</p>
			<p class="source-code"><strong class="bold">Job results are saved to S3 path: </strong>s3://sagemaker-us-west-2-&lt;account-id&gt;/export-flow-04-01-52-59-xxxxxx/output/data-wrangler-flow-processing-04-01-52-59-xxxxxx</p>
			<p>The following optional sections are the interesting modeling part. Let's run these steps to train an ML model to predict churn using SageMaker's built-in XGBoost algorithm.</p>
			<ol>
				<li value="5">Reassign the value of <strong class="source-inline">run_optional_steps</strong> to <strong class="source-inline">True</strong>:<p class="source-code">run_optional_steps = True</p></li>
				<li>The default <a id="_idIndexMarker247"/>objective metric, <strong class="source-inline">reg:squarederror</strong>, for XGBoost is for regression use cases. Change it to <strong class="source-inline">binary:logistic</strong> because we have a binary classification use case:<p class="source-code">hyperparameters = {</p><p class="source-code">    "max_depth":"5",</p><p class="source-code">    "objective": "binary:logistic",</p><p class="source-code">    "num_round": "10",</p><p class="source-code">}</p></li>
				<li>Execute all the remaining cells in the notebook to start a training job.</li>
			</ol>
			<p>The training job will take a minute or two to finish. You can see the actions behind the scenes printed out as output in the last cell. We will learn more about SageMaker training and training algorithms in <a href="B17447_05_ePub_RK.xhtml#_idTextAnchor077"><em class="italic">Chapter 5</em></a><em class="italic">, Building and Training ML Models with SageMaker Studio IDE</em>. Once finished, the model is saved in S3 as well, which can be used in hosting in Amazon SageMaker or the model can be used locally. We will learn more about hosting options in <a href="B17447_07_ePub_RK.xhtml#_idTextAnchor099"><em class="italic">Chapter 7</em></a>, <em class="italic">Hosting ML Models in the Cloud: Best Practices</em></p>
			<h1 id="_idParaDest-63"><a id="_idTextAnchor062"/>Summary</h1>
			<p>In this chapter, we showed how to use SageMaker Data Wrangler using a telco customer churn dataset. We learned how to import data from various sources, join tables, analyze with advanced ML-based analyses, and create visualizations with SageMaker Data Wrangler. We then applied transformations easily with built-in transforms available out of the box from SageMaker Data Wrangler without any code. At the end of the chapter, we showed how to export the transformed data to an S3 bucket and how to easily train an ML model using the automatically generated notebook.</p>
			<p>In the next chapter, we will learn about the concept of a feature store in a machine learning project, and how to set up a feature store using <strong class="bold">SageMaker Feature Store</strong>. SageMaker Feature Store unifies the features across teams so that teams can remove redundant feature engineering pipelines. It also serves as a central repository for both model training and model serving use cases because of its unique design pattern to have an offline store for easy querying for selecting training datasets and an online store for low latency transactions required in the model serving environment. </p>
		</div>
	</body></html>