- en: Stopping Time and Seeing like a Bee
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '"You never can tell with bees."'
  prefs: []
  type: TYPE_NORMAL
- en: – A. A. Milne, Winnie-the-Pooh (1926)
  prefs: []
  type: TYPE_NORMAL
- en: The silent threat of radiation is everywhere in James Bond's world. Of course,
    stolen nuclear warheads are one cause for concern, but the excessively sunny weather
    is almost as bad, exposing the hero and his lovely traveling companions to an
    overdose of UV rays. Then, in *Moonraker* (1979), there is a high-budget mission
    to outer space, where the radiation hazards include cosmic rays, solar flares,
    and the turquoise lasers that everyone is shooting.
  prefs: []
  type: TYPE_NORMAL
- en: James Bond is not afraid of all this radiation. Perhaps he is able to take a
    cool, rational view of it by reminding himself that *electromagnetic radiation* can
    refer to various kinds of waves that move at the speed of light, including the
    rainbow-colored range of *visible light* we all see and love, but also including
    radio waves, microwaves, thermal infrared emissions, near-infrared light, ultraviolet
    light, X-rays, and gamma rays.
  prefs: []
  type: TYPE_NORMAL
- en: With specialized cameras, it is possible to capture images of other kinds of
    radiation besides visible light. Moreover, it is possible to capture videos at
    high frame rates, revealing patterns of motion or of pulsing light that are too
    fast for human vision to perceive. These capabilities would nicely complement
    the `Lazy Eyes` application that we developed in [Chapter 7](7cc1c0b9-a764-4069-9d45-e8bf129efc57.xhtml),
    *Seeing a Heartbeat with a Motion-Amplifying Camera*. Recall that `Lazy Eyes`
    implements the Eulerian video magnification algorithm, which amplifies a specified
    range of frequencies of motion. If we can increase the frame rate, we can improve
    the precision of this range of frequencies; thus, we can isolate high frequencies
    (fast motion) more effectively. This could also be described as an improvement
    in **selectivity**.
  prefs: []
  type: TYPE_NORMAL
- en: From a programming perspective, our goal in this chapter is simply to develop
    a variant of `Lazy Eyes` with support for more types of cameras. We will name
    this variant `Sunbaker`. We will make `Sunbaker` compatible with the Point Grey
    brand of industrial cameras from FLIR Systems. These cameras can be controlled
    using a C++ library called **Spinnaker SDK**, which has a Python wrapper called
    `PySpin`. We will learn how to integrate PySpin (and, in principle, any Python
    module for camera control) seamlessly with OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: PySpin (with a capital *P* and capital *S*) should not be confused with pyspin
    (all lowercase letters). The latter is a different Python library that can display
    spinning icons in a Terminal.
  prefs: []
  type: TYPE_NORMAL
- en: More broadly, our objective is to learn about some of the specialized cameras
    available on the market today, work with images from them, and understand how
    these kinds of imaging relate to the natural world. Did you know that a honey
    bee flies at an average speed of 24 kilometers (15 miles) per hour, and that it
    can see ultraviolet patterns on flowers? A different camera can give us an appreciation
    of how this creature might perceive the passing of light and time.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter''s project has the following software dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A Python environment with the following modules**: OpenCV, NumPy, SciPy,
    PyFFTW, and wxPython.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optional**: Spinnaker SDK and PySpin. These are available for Windows and
    Linux, but not Mac.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where not otherwise noted, setup instructions are covered in [Chapter 1](e3ac8266-975b-43ca-8221-482a15eb0e05.xhtml),
    *Preparing for the Mission*. Setup instructions for PyFFTW are covered in [Chapter
    7](7cc1c0b9-a764-4069-9d45-e8bf129efc57.xhtml), *Seeing a Heartbeat with a Motion-Amplifying
    Camera*, in the *Choosing and setting up an FFT library* section. Setup instructions
    for Spinnaker SDK and PySpin are covered in the current chapter, in the *Installing
    Spinnaker SDK and PySpin* section. Always refer to the setup instructions for
    any version requirements. Basic instructions for running Python code are covered
    in [Appendix C](c44b1aaa-fe12-4054-85fb-37d584f15d3b.xhtml), *Running with Snakes
    (or First Steps with Python)*.
  prefs: []
  type: TYPE_NORMAL
- en: The completed project for this chapter can be found in the book's GitHub repository, [https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition](https://github.com/PacktPublishing/OpenCV-4-for-Secret-Agents-Second-Edition),
    in the `Chapter008` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Planning the Sunbaker app
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Compared to `Lazy Eyes`, `Sunbaker` has the same GUI and, substantially, the
    same implementation of Eulerian video magnification. However, `Sunbaker` can capture
    input from a Point Grey industrial camera if one is connected. The following screenshot
    shows `Sunbaker` running with a high-speed monochrome camera called the **Point
    Grey Grasshopper 3 GS3-U3-23S6M-C**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c4b7657a-28b5-477d-a917-0c6e4e076d04.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot shows my monochromatic friend, Eiffel Einstein Rocket.
    The effect of the Eulerian video magnification is visible as a halo along the
    edge of his back, which is moving as he breathes. The frame rate (98.7 **frames
    per second** (**FPS**) as shown in the screenshot) happens to be limited by the
    processing of the images; on a faster system, the camera could potentially capture
    up to 163 FPS.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a fallback, if PySpin is unavailable or no PySpin-compatible camera is connected,
    `Sunbaker` can also capture input from any OpenCV-compatible camera. The following
    screenshot shows `Sunbaker` running with an OpenCV-compatible ultraviolet webcam
    called the **XNiteUSB2S-MUV**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e2656730-565a-4812-92c8-67693ce2865d.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding screenshot shows a small dandelion. Of course, in visible light,
    a dandelion's petals are entirely yellow. However, to the ultraviolet camera,
    the dandelion petals look like a dark circle inside a bright circle. This bull's-eye
    pattern is what a bee would see. Note that, in this screenshot, `Sunbaker` is
    still building up its history of frames, so it does not yet show a frame rate
    yet or an Eulerian video magnification effect. Potentially, Eulerian video magnification
    could amplify the pattern of the petals' motion in the wind.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's take a moment to put the capabilities of an *ultraviolet webcam *in
    context by looking at the electromagnetic spectrum.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the spectrum
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The universe is flooded with light, or electromagnetic radiation, and astronomers
    can use all wavelengths to capture images of distant objects. However, the Earth''s
    atmosphere partly or wholly reflects some wavelengths of light or radiation back
    into outer space, so typically we deal with more limited ranges of wavelengths
    in imaging on Earth. NASA provides the following illustration, showing various
    wavelengths of electromagnetic radiation, their day-to-day importance to human
    beings, and their ability (or inability) to penetrate the Earth''s atmosphere:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/16c79807-4104-4a98-ade2-900a09cf7a08.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that the axis in the preceding diagram runs from longer wavelengths on
    the left to shorter wavelengths on the right. The Earth's atmosphere is relatively
    opaque in the range from the longest radio wavelengths down to the short end of
    the shortwave band (10 m). This **opacity** or **reflectivity** is an important
    principle in worldwide radio broadcasting, as it enables certain radio wavelengths
    to propagate around the Earth by bouncing back and forth between the surface and
    the upper atmosphere.
  prefs: []
  type: TYPE_NORMAL
- en: Next in the spectrum, the atmosphere is relatively transparent in the so-called **radio
    window**, including very high frequency or FM radio (which does not propagate
    beyond the horizon), cellular and Wi-Fi ranges, and the longer part of the microwave
    range. Then, the atmosphere is relatively opaque to the shorter part of the microwave
    range and the longer part of the **infrared** (**IR**) range (which starts around
    1 mm).
  prefs: []
  type: TYPE_NORMAL
- en: Longwave infrared is also called **thermal infrared** or **far infrared** (**FIR**),
    and shortwave infrared is also called **near infrared** (**NIR**). Here, the terms
    *far* and *near* mean *farther from visible light* and *nearer to visible light*,
    respectively. So, past the opposite end of the visible range, longwave ultraviolet
    is also called **near ultraviolet** (**NUV**), and shortwave ultraviolet is also
    called **far ultraviolet** (**FUV**).
  prefs: []
  type: TYPE_NORMAL
- en: The radio and microwave ranges have relatively poor potential for terrestrial
    (earthbound) imaging. Only low-resolution imaging would be possible in these ranges
    because wavelength is a limiting factor of resolution. On the other hand, starting
    in the IR range, it becomes feasible to capture recognizable images of human-sized
    or smaller objects. Fortunately, there are good sources of natural illumination
    in the IR and visible ranges. Warm-blooded animals and other warm objects emit
    FIR radiation, which makes them visible to thermal cameras (even at night and
    even behind cold obstacles such as trees or walls). Moreover, the atmosphere is
    relatively transparent in the so-called **optical window**, including the NIR
    range, the visible range, and to a lesser extent the NUV range. NIR and NUV cameras
    produce images that look fairly similar to visible-light images, but with some
    differences in objects' coloration, opacity, and sharpness.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout most of the UV range, as well as the X-ray and gamma ranges, the
    Earth's atmosphere is relatively opaque again. This is also fortunate—perhaps
    not from a computer vision perspective, but certainly from a biological perspective.
    Shortwave radiation can penetrate unprotected skin, flesh, and even bone, quickly
    causing burns and more slowly causing cancer. However, in short, controlled exposures
    from an artificial source, **ultraviolet** (**UV**) and X-ray imaging can be very
    useful in medicine. For example, UV imaging can record invisible bruises that
    are deep beneath the surface of the skin, and this kind of image is often used
    as forensic evidence in domestic abuse cases. X-ray imaging, of course, can go
    even deeper to reveal the bones or the inside of the lungs. Shortwave or *hard* X-rays,
    as well as gamma rays, are widely used to scan the inside of containers and vehicles,
    for example at security checkpoints.
  prefs: []
  type: TYPE_NORMAL
- en: For many decades, X-ray images have been commonplace in much of the world. During
    the 1950s and 1960s in the Soviet Union, discarded X-ray slides were sufficiently
    plentiful that music bootleggers used them as a cheap substitute for vinyl records.
    People listened to *jazz on bones* or *rock on bones* because this banned, foreign
    music was unobtainable in any other form. However, in contrast to a world where
    an X-ray scan might be less troublesome than a jazz record, the world in 1895-1896
    was astonished by the first X-ray images. *I have seen my death,* said Anna Bertha
    Ludwig, the wife of the pioneering X-ray scientist Wilhelm Röntgen, when she first
    saw a skeletal scan of her hand. She, and other viewers at the time, had never
    imagined that a photograph could uncover the skeleton of a living person.
  prefs: []
  type: TYPE_NORMAL
- en: Today, specialized imaging technology is continuing to become more pervasive,
    and it will continue to change the way people see themselves and the world. For
    example, IR and UV cameras are now widely used for surveillance and detection
    in police work, many members of the public are aware of this due to police dramas
    on television, and we might begin to question our old assumptions about what can
    and cannot be seen. Forget about secret agents and even police detectives for
    a moment; we might even see a thermal camera on a **do-it-yourself** (**DIY**) show,
    since FIR imaging can be used to locate a cold draft around a window or a hot
    water pipe inside a wall. IR and UV cameras are becoming more affordable even
    for home use, and we will consider some examples of these and other specialized
    cameras in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Finding specialized cameras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following table provides a few examples of cameras that can capture video
    at high frame rates, in IR, or in UV:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Price** | **Purpose** | **Modes** | **Optics** | **Compatibility**
    |'
  prefs: []
  type: TYPE_TB
- en: '| XNiteUSB2S-MUV | $135 | Monochrome imaging in near ultraviolet | Monochrome
    *1920 x 1080* @ 30 FPSMonochrome *1280 x 720* @ 60 FPSMonochrome *640 x 480* @
    120 FPS(and other modes) | Diagonal field of view—86 degrees3.6 mm lens on 1/2.7"
    sensor | OpenCV on Windows, Mac, Linux |'
  prefs: []
  type: TYPE_TB
- en: '| XNiteUSB2S-IR715 | $135 | Monochrome imaging in NIR | Monochrome *1920 x
    1080* @ 30 FPSMonochrome *1280 x 720* @ 60 FPSMonochrome *640 x 480* @ 120 FPS(and
    other modes) | Diagonal field of view—86 degrees3.6 mm lens on 1/2.7" sensor |
    OpenCV on Windows, Mac, Linux |'
  prefs: []
  type: TYPE_TB
- en: '| Sony PlayStation Eye | $10 | High-speed color imaging in visible light |
    Color *640 x 480* @ 60 FPSColor *320 x 240* @ 187 FPS | Diagonal field of view—75
    degrees or 56 degrees (two zoom settings) | OpenCV on Linux only (V4L backend)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Point Grey Grasshopper 3 GS3-U3-23S6C-C | $1045 | High-speed color imaging
    in visible light | Color *1920 x 1200* @ 162 FPS(and other modes) | C-mount lens
    (not included) on 1/1.2" sensor | Spinnaker SDK and PySpin on Windows, Linux |'
  prefs: []
  type: TYPE_TB
- en: '| Point Grey Grasshopper 3 GS3-U3-23S6M-C | $1045 | High-speed monochrome imaging
    in visible light | Monochrome *1920 x 1200* @ 162 FPS(and other modes) | C-mount
    lens (not included) on 1/1.2" sensor | Spinnaker SDK and PySpin on Windows, Linux
    |'
  prefs: []
  type: TYPE_TB
- en: '| Point Grey Grasshopper 3 GS3-U3-41C6NIR-C | $1359 | Monochrome imaging in
    NIR | Monochrome *2048 x 2048* @ 90 FPS(and other modes) | C-mount lens (not included)
    on 1" sensor | Spinnaker SDK and PySpin on Windows, Linux |'
  prefs: []
  type: TYPE_TB
- en: Of course, there are many other specialized cameras on the market besides these
    few examples. Many industrial cameras, including the Point Grey cameras previously
    listed, conform to an industry standard called **GenICam**, which, in principle,
    makes them compatible with third-party software libraries that are based on this
    standard. Harvesters ([https://github.com/genicam/harvesters](https://github.com/genicam/harvesters))
    is an example of an open source Python library that can control GenICam-compliant
    cameras. You may want to look into Harvesters if you are interested in support
    for additional brands of industrial cameras and additional platforms (Mac as well
    as Windows and Linux). For now, though, let's discuss some of the cameras in the
    preceding table in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: XNiteUSB2S-MUV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The XNiteUSB2S-MUV, available from MaxMax.com ([https://maxmax.com/](https://maxmax.com/)),
    is a true UV camera in the sense that it blocks out visible and infrared light
    in order to capture ultraviolet light alone. This is accomplished by means of
    a permanently attached lens filter that is opaque to visible light but relatively
    transparent to part of the NUV range. The lens''s glass itself also filters out
    some ultraviolet light, and the result is that the camera captures the range from
    360 nm to 380 nm. The following photograph of the camera and a black-eyed Susan
    (a North American flower with yellow petals and black stamens) shows an opaque
    reflection of the flower in the lens filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f007010c-0f0b-4094-91a9-edca3688ff7f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following photo, captured by the UV camera, shows the same flower with
    petals that are dark at the base and bright at the tip, forming a typical ultraviolet
    bull''s-eye pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0aed955c-35e4-4196-91e7-78137eb72666.png)'
  prefs: []
  type: TYPE_IMG
- en: To a bee, this big splash of two contrasting colors would stand out like a fast-food
    logo. Pollen is here!
  prefs: []
  type: TYPE_NORMAL
- en: The XNiteUSB2S-MUV can capture images outdoors in sunlight, but if you want
    to use it indoors, you will need a UV light source that covers the camera's range
    of sensitivity, 360 nm to 380 nm. MaxMax.com can provide sales advice on UV light
    sources, and on options to customize the XNiteUSB2S-MUV with a quartz lens that
    extends the range of sensitivity down to approximately 300 nm (at a significantly
    higher cost). See the camera's product page at [https://maxmax.com/maincamerapage/uvcameras/usb2-small](https://maxmax.com/maincamerapage/uvcameras/usb2-small)
    and MaxMax.com's contact page at [https://maxmax.com/contact-us](https://maxmax.com/contact-us).
  prefs: []
  type: TYPE_NORMAL
- en: MaxMax.com also offers a series of infrared cameras that have the same electronics
    and lens as the XNiteUSB2S-MUV, only they use a different filter in order to block
    out visible and ultraviolet light while capturing part of the NIR range. The XNiteUSB2S-IR715
    captures the broadest part of the NIR range, down to a wavelength of approximately
    715 nm (for comparison, visible red starts at 700 nm). The product lineup includes
    several similarly named alternatives for other wavelength cutoffs.
  prefs: []
  type: TYPE_NORMAL
- en: Sony PlayStation Eye
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The PlayStation Eye holds a unique position as a low-cost camera with a high
    maximum frame rate (albeit at a low resolution). Sony released the Eye in 2007
    as an accessory for the PlayStation 3 game console, and game developers used the
    camera to support motion tracking, face tracking, or simply video chat. Later,
    the Eye's driver was reverse-engineered for other platforms, and the device gained
    popularity among computer vision experimenters. The Linux kernel (specifically,
    the Video4Linux or V4L module) officially supports the Eye. So, on Linux (and
    only on Linux), OpenCV can use the Eye just like an ordinary webcam.
  prefs: []
  type: TYPE_NORMAL
- en: PS3EYE Driver ([https://github.com/inspirit/PS3EYEDriver](https://github.com/inspirit/PS3EYEDriver))
    is an open-source C++ library that can control the PlayStation Eye on Windows
    or Mac. Potentially, you could write your own wrapper around PS3EYEDriver to provide
    an OpenCV-friendly interface. PS3EYEDriver reuses a lot of code from the Eye's
    Linux driver, which is GPL-licensed, so be careful about the licensing implications
    of using PS3EYE Driver; it might not be right for you unless your project is also
    GPL-licensed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a screenshot of `Sunbaker` running at a high frame rate with a PlayStation
    Eye camera on Linux:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8dd357e8-6990-40af-afa6-bdddcdcda706.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding photo shows my monochromatic friend, Eiffel Einstein Rocket, at
    rest. As he breathes, the effect of the Eulerian video magnification is visible
    as a halo along the edge of his back. Note that the frame rate (60.7 FPS, as displayed)
    is actually limited by the processing of the images; we could approach or even
    reach the camera's maximum rate of 187 FPS on a faster system.
  prefs: []
  type: TYPE_NORMAL
- en: Point Grey Grasshopper 3 GS3-U3-23S6M-C
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Point Grey Grasshopper 3 GS3-U3-23S6M-C is a highly configurable, monochrome
    camera with interchangeable lenses and a high-speed USB 3 interface. Depending
    on the configuration and the attached lens, it can capture detailed images of
    a wide variety of subjects, under a wide variety of conditions, at a high frame
    rate. Consider the following set of images. We see a headshot of the author, a
    close-up shot of veins in the author''s eye, and a long-distance shot of the moon,
    all captured with the GS3-U3-23S6M-C camera and various low-cost lenses (each
    $50 or less):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8323d73f-0484-4ed0-99c1-f32cdb13ede6.png)'
  prefs: []
  type: TYPE_IMG
- en: The camera uses a type of lens mount called a **C-mount**, and its sensor size
    is the so-called **1/1.2" format**. This is the same lens mount and nearly the
    same sensor size as two formats called **16 mm** and Super 16, which have been
    popular in amateur movie cameras ever since 1923\. So, the camera is compatible
    with a wide range of inexpensive, old *cine* (cinematography) lenses, as well
    as newer and more expensive machine vision lenses.
  prefs: []
  type: TYPE_NORMAL
- en: Before even sending the frames through USB, the camera itself can efficiently
    perform some image processing operations, such as cropping the image and binning
    (summing) neighboring pixels to increase brightness and reduce noise. We will
    see how to control these features later in this chapter, in the *Capturing images
    from industrial cameras using PySpin* section.
  prefs: []
  type: TYPE_NORMAL
- en: The Point Grey Grasshopper 3 GS3-U3-23S6C-C is the same as the camera described
    previously, except it captures visible light in color instead of in monochrome.
    The Point Grey Grasshopper 3 GS3-U3-41C6NIR-C also belongs to the same family
    of cameras, but it is a monochrome NIR camera with a larger sensor (1" format),
    higher resolution, and lower frame rate. There are many other interesting Point
    Grey cameras, and you can search through a list of the available models and features
    at [https://www.flir.com/browse/camera-cores--components/machine-vision-cameras](https://www.flir.com/browse/camera-cores--components/machine-vision-cameras).
  prefs: []
  type: TYPE_NORMAL
- en: Next, let's look at how we can set up software libraries to control Point Grey
    cameras.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Spinnaker SDK and PySpin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To obtain drivers and libraries that will enable us to interface with Point
    Grey cameras, let''s take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to the Spinnaker SDK section of the FLIR website at [https://www.flir.com/products/spinnaker-sdk/](https://www.flir.com/products/spinnaker-sdk/).
    Click the DOWNLOAD NOW button. You will be prompted to go to a different download
    site. Click the DOWNLOAD FROM BOX button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will see a page that allows you to navigate a file structure to find the
    available downloads. Select the folder that matches your operating system, such
    as Windows or Linux/Ubuntu18.04.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Within the selected folder or its subfolders, find and download a version of
    Spinnaker SDK that matches your operating system and architecture. (For Windows,
    you may choose either the Web installer or the Full SDK.) Also, find and download
    a version of PySpin (the Python Spinnaker bindings) that matches your Python version,
    operating system, and architecture, such as `spinnaker_python-1.20.0.15-cp36-cp36m-win_amd64.zip`
    for 64-bit Python 3.6 on Windows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Close the web browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The instructions for installation for the various systems are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For Windows, the Spinnaker SDK installer is an `.exe` installer. Run it and
    follow the installer's prompts. If you are prompted to select an Installation
    Profile, choose Application Development. If you are prompted to select Installation
    Components, choose Documentation, Drivers, and any other components you want.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For Linux, the Spinnaker SDK download is a `TAR.GZ` archive. Unzip it to any
    destination, which we will refer to as `<spinnaker_sdk_unzip_destination>`. Open
    a Terminal, run `$ cd <spinnaker_sdk_unzip_destination> && ./install_spinnaker.sh`,
    and answer all the installer's prompts by entering `Yes`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Python Spinnaker download is a ZIP archive (for Windows) or a TAR archive
    (for Linux). Unzip it to any destination. We will refer to its unzip destination
    as `<PySpin_whl_unzip_destination>` because it contains a WHL file, such as `spinnaker_python-1.20.0.15-cp36-cp36m-win_amd64.whl`.
    We will refer to the `WHL` file as `<PySpin_whl_file>`. The WHL file is a package
    that can be installed using Python''s package manager, `pip`. Open a Terminal
    and run the following commands (but substitute the actual folder name and filename):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For some Python 3 environments, you may need to run `pip3` instead of `pip` in
    the preceding command.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have all the software we need in order to control Point Grey
    cameras from Python scripts. Let's proceed to write a Python class that supports
    interoperability between PySpin and OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: Capturing images from industrial cameras using PySpin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create a file called `PySpinCapture.py`. Not surprisingly, we will begin
    its implementation with the following `import` statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As a practical introduction to `PySpin`, let''s add the following function,
    which returns the number of PySpin-compatible cameras currently connected to the
    system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Here, we see that our standalone `getNumCameras` function (like any self-contained
    module of code that uses `PySpin`) is responsible for acquiring and releasing
    a reference to the `PySpin` system. We also see that the `PySpin` system is a
    gateway, providing access to any connected PySpin-compatible cameras.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our primary goal in this file is to implement a class, `PySpinCapture`, which
    will provide some of the same public methods as the `cv2.VideoCapture` class in
    OpenCV''s Python bindings. An instance of `PySpinCapture` will provide access
    to a single PySpin-compatible camera in a self-contained way. However, the class
    can be instantiated multiple times for simultaneous access to different cameras
    through different instances. `PySpinCapture` will implement the following methods
    to partly mimic the behavior of `cv2.VideoCapture`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`get(propId)`: This method returns the value of the camera property identified by
    the `propId` argument. We will support two of OpenCV''s `propId` constants, namely
    `cv2.CAP_PROP_FRAME_WIDTH` and `cv2.CAP_PROP_FRAME_HEIGHT`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`read(image=None)`: This method reads a camera frame and returns a tuple, `(retval,
    image_out)`, where `retval` is a Boolean indicating success (`True`) or failure
    (`False`), and `image_out` is the captured frame (or `None` if the capture failed).
    If the `image` argument is not `None` and the capture succeeds, then `image_out`
    is the same object as `image`, but it contains new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`release()`: This method releases the camera''s resources. `cv2.VideoCapture`
    is implemented such that the destructor calls `release`, and `PySpinCapture` will
    be implemented this way too.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other Python scripts will be able to call these methods on an object without
    needing to know whether the object is an instance of `cv2.VideoCapture`, `PySpinCapture`,
    or some other class that has the same methods. This is the case even though these
    classes have no relationship in terms of object-oriented inheritance. This feature
    of Python is called **duck typing**. *If it looks like a duck, swims like a duck,
    and quacks like a duck, then it probably is a duck,* or so the saying goes. If
    it provides a `read` method that returns a frame, then it probably *is* a frame-capture
    object. Later in this chapter, in the *Adapting the Lazy Eyes app to make Sunbaker*
    section, we will instantiate `PySpinCapture` if `PySpin` is available, and `cv2.VideoCapture`
    otherwise; then, we will use the instantiated object without further concern about
    its type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Point Grey cameras are more configurable than most cameras supported by `cv2.VideoCapture`.
    Our `__init__` method for `PySpinCapture` will accept the following arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`index`: This is the camera''s device index.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roi`: This is a region of interest in the `(x, y, w, h)` format, relative
    to the camera''s native image dimensions. Data outside the region of interest
    will not be captured. For example, if the native image dimensions are *800 x 600*
    pixels, and the `roi` is `(0, 300, 800, 300)`, the captured image will cover only
    the bottom half of the image sensor.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binningRadius`: This is `1` if an unfiltered image should be captured, and
    `2` or more if neighboring pixels in the specified radius should be summed to
    produce a smaller, brighter, less noisy image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`isMonochrome`: This is `True` if the captured image should be grayscale, and
    `False` if it should be BGR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code shows how we declare the `PySpinCapture` class and its `__init__`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'PySpin and the underlying Spinnaker SDK are organized around a hierarchical
    model of a system, the cameras in the system, and the respective configurations
    of the cameras. Each camera''s configuration is organized into a so-called **node
    map**, which defines properties, their supported values, and their current current
    values. To begin the implementation of our `__init__` method, we get an instance
    of the system, a list of cameras, and a specific camera by index. We initialize
    this camera and get its node map. All of this is seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We are interested in capturing a continuous series of video frames, rather
    than isolated still images. To support video capture, `PySpin` allows us to set
    a camera''s `''AcquisitionMode''` property to a value for a `''Continuous''` capture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: For more information about nodes, their names, and relevant documentation, see
    the technical note* Spinnaker Nodes* on the FLIR website at [https://www.flir.com/support-center/iis/machine-vision/application-note/spinnaker-nodes/](https://www.flir.com/support-center/iis/machine-vision/application-note/spinnaker-nodes/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we set a property called `''PixelFormat''` to either a value called `''Mono8''`
    or a value called `''BGR8''`, depending on whether our `__init__` method''s `isMonochrome`
    argument is `True`. Here is the relevant code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we set a `''BinningVertical''` property based on our `binningRadius`
    argument (the horizontal binning radius is automatically set to the same value
    as the vertical binning radius). Here is the relevant code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Likewise, based on the `roi` argument, we set the values of properties named
    `''OffsetX''`, `''OffsetY''`, `''Width''`, and `''Height''`, as seen in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`cv2.VideoCapture` starts a capture session as soon as it is constructed, so
    we want to do the same thing in `PySpinCapture`. So, we finish the `__init__`
    method''s implementation with the following line of code, which tells the camera
    to start acquiring frames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We use the node map again in the implementation of the `get` method. If `cv2.CAP_PROP_FRAME_WIDTH`
    is requested, we return the value of the `''Width''` property. If, instead, `cv2.CAP_PROP_FRAME_HEIGHT`
    is requested, we return the value of the `''Height''` property. For any other
    request, we return `0.0`. Here is the method''s implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We begin the implementation of the `read` method by telling the camera to capture
    a frame. If this fails, we return `False` and `None` (no image). Otherwise, we
    get the frame''s dimensions and number of channels, get its data as a NumPy array,
    and reshape this array to match the format that OpenCV expects. We copy the data,
    release the original frame, and then return `True` and the copied image. Here
    is the method''s implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We implement the `release` method by telling the camera to stop acquiring frames,
    de-initializing and deleting the camera, clearing the list of cameras, and releasing
    the `PySpin` system. Here is the relevant code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To complete the implementation of the `PySpinCapture` class, we provide the
    following destructor or `__del__` method, which simply calls the `release` method
    that we implemented previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Next, let's look at how to use `PySpinCapture` or `cv2.VideoCapture` interchangeably
    in our application.
  prefs: []
  type: TYPE_NORMAL
- en: Adapting the Lazy Eyes app to make Sunbaker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed at the start of this chapter, `Sunbaker` is a variant of `Lazy
    Eyes` with support for more cameras. As a starting point, make a copy of the completed
    `LazyEyes.py` script from [Chapter 7](7cc1c0b9-a764-4069-9d45-e8bf129efc57.xhtml),
    *Seeing a Heartbeat with a Motion-Amplifying Camera*, and rename it `Sunbaker.py`.
    The supported cameras in `Sunbaker` will vary depending on the modules that are
    available at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the following `try`/`except` block after the other `import` statements
    in `Sunbaker.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The preceding block of code tries to import our `PySpinCapture` module, which
    contains our `getNumCameras` function and our `PySpinCapture` class. The `PySpinCapture`
    module, in turn, imports the `PySpin` module, as we saw earlier in this chapter
    in the *Capturing images from industrial cameras using PySpin* section. If the
    `PySpin` module is not found, `ImportError` is thrown. The preceding block of
    code catches this error and it defines `PySpinCapture = None` as a way to note that
    we failed to import an optional dependency, namely the `PySpinCapture` module.
    Later in `Sunbaker.py`, we will use the `PySpinCapture` module only when `PySpinCapture`
    is not `None`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We must modify the `__init__` method of the `Sunbaker` class to remove the `cameraDeviceID`
    and `imageSize` arguments, and instead add a `capture` argument and an `isCaptureMonochrome`
    argument. The `capture` argument can be either a `cv2.VideoCapture` object or
    a `PySpinCapture` object. We assume that `capture` argument''s width, height,
    and other properties are already fully configured before capture is passed to
    `__init__`. So, we have no need to call `ResizeUtils.cvResizeCapture` in `__init__` (and we
    can remove `ResizeUtils` from the list of imports). We attempt to get the image
    dimensions and format (grayscale or not) from an actual frame. If this fails,
    we will instead rely on getting the dimensions from the `capture` argument''s
    properties and the format from the `isCaptureMonochrome` argument. The modifications
    to `__init__` are marked in bold in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The `_applyEulerianVideoMagnification` method needs minor modifications to
    support the possibility that the input is not a BGR image, but rather a grayscale
    image from a monochrome camera. Again, the modifications are marked in bold in
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `main` function needs modifications to provide appropriate `capture`
    and `isCaptureMonochrome` arguments to `Sunbaker` application''s `__init__` method.
    As an example, let''s suppose that if `PySpin` is available, we want to use a
    monochrome camera with a binning radius of `2` and a capture resolution of *960
    x 600*. (The GS3-U3-23S6M-C camera supports this configuration.) Alternatively,
    if `PySpin` is unavailable or if no PySpin-compatible camera is connected, let''s
    use an OpenCV-compatible camera with a capture resolution of *640 x 480* at 60
    FPS. The relevant modifications are marked in bold in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: You might need to modify the preceding code based on the capture modes that
    are supported by your cameras. If you are interested in using the PlayStation
    Eye camera at its maximum frame rate, you should comment out the lines of code
    that pertain to *640 x 480* resolution at 60 FPS, and uncomment the lines of code
    that pertain to *320 x 240* resolution at 187 FPS.
  prefs: []
  type: TYPE_NORMAL
- en: This brings us to the end of the code revisions. Now, you can test `Sunbaker`
    with either a Point Grey camera or an OpenCV-compatible camera such as a USB webcam.
    Take some time to adjust the camera parameters, as well as the parameters of the
    Eulerian video magnification algorithm (the latter are described in detail in [Chapter
    7](7cc1c0b9-a764-4069-9d45-e8bf129efc57.xhtml), *Seeing a Heartbeat with a Motion-Amplifying
    Camera*, in the *Configuring and testing the app for various motions* section).
    Experiment with a variety of subjects and lighting conditions, including outdoor
    sunlight. If you are using a UV camera, remember to look at the flowers!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has broadened our view of the things cameras can see. We have considered
    video capture at high frame rates and at wavelengths of light that are invisible
    to the human eye. As programmers, we have learned to wrap a third-party camera
    API in a way that allows us to use industrial cameras and OpenCV-compatible webcams
    interchangeably, thanks to Python's duck typing. As experimenters, we have extended
    our study of Eulerian video magnification into higher frequencies of motion, as
    well as more surprising patterns of pulsing light beyond the visible spectrum.
  prefs: []
  type: TYPE_NORMAL
- en: Let's reflect on all our progress. From finding the head of SPECTRE to exploring
    the electromagnetic spectrum, our journey as secret agents has taken us far. At
    this proud moment, however, our adventure must reach its conclusion. We will meet
    again. Look out for future books, webcasts, and presentations, to be announced
    on my website at [http://nummist.com/opencv](http://nummist.com/opencv). Also,
    email me at [josephhowse@nummist.com](mailto:josephhowse@nummist.com) to report
    issues, ask questions, and tell me how you are using OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: The book is ending now and I am waiting to find out whether I disappear into
    the sunset with a femme fatale or whether I have a melancholy debriefing with
    M.
  prefs: []
  type: TYPE_NORMAL
