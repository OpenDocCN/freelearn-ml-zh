<html><head></head><body>
		<div id="_idContainer176">
			<h1 id="_idParaDest-125" class="chapter-number"><a id="_idTextAnchor157"/>9</h1>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor158"/>Deep Learning with  Redshift ML<a id="_idTextAnchor159"/></h1>
			<p>We <a id="_idIndexMarker425"/>explored <strong class="bold">supervised learning</strong> in <em class="italic">Chapters 6</em> and <em class="italic">7</em> and <strong class="bold">unsupervised learning</strong> models <a id="_idIndexMarker426"/>in <a href="B19071_08.xhtml#_idTextAnchor139"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>. In this chapter, we<a id="_idIndexMarker427"/> will explore <strong class="bold">deep learning algorithms</strong>, a <strong class="bold">multilayer perceptron</strong> (<strong class="bold">MLP</strong>), which is a <strong class="bold">feedforward artificial neural network </strong>(<strong class="bold">ANN</strong>), and<a id="_idIndexMarker428"/> understand how it handles data that is not linearly <a id="_idIndexMarker429"/>separable (which means the data points in your data cannot be separated by a clear line). This chapter will provide detailed steps on how to perform deep learning in Amazon Redshift ML using MLP. By the end of this chapter, you will be in a position to identify a business problem that can be solved using MLP and know how to create the model, evaluate the performance of the model, and <span class="No-Break">run predictions.</span></p>
			<p>In this chapter, we will go through the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Introduction to <span class="No-Break">deep learning</span></li>
				<li><span class="No-Break">Business problem</span></li>
				<li>Uploading and analyzing <span class="No-Break">the data</span></li>
				<li>Creating a multiclass classification model <span class="No-Break">using MLP</span></li>
				<li><span class="No-Break">Running predict<a id="_idTextAnchor160"/>ions</span></li>
			</ul>
			<h1 id="_idParaDest-127"><a id="_idTextAnchor161"/>Technical requirements</h1>
			<p>This chapter requires a web browser and access to <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break">AWS account</span></li>
				<li>Amazon Redshift <span class="No-Break">Serverless endpoint</span></li>
				<li>Amazon Redshift Query <span class="No-Break">Editor v2</span></li>
			</ul>
			<p>You can find the code used in this chapter <span class="No-Break">here: </span><a href="https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter9/chapter9.sql"><span class="No-Break">https://github.com/PacktPublishing/Serverless-Machine-Learning-with-Amazon-Redshift/blob/main/CodeFiles/chapter9/chapter9.<span id="_idTextAnchor162"/>sql</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-128"><a id="_idTextAnchor163"/>Introduction to deep learning</h1>
			<p>Deep learning <a id="_idIndexMarker430"/>is a type of <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) that uses algorithms to analyze<a id="_idIndexMarker431"/> and learn data to draw output similar to the way humans do. Deep learning can leverage both supervised and unsupervised<a id="_idIndexMarker432"/> learning using <strong class="bold">artificial neural networks</strong> (<strong class="bold">ANNs</strong>). In deep learning, a set of outputs is generated from the input layers using a feedforward ANN called an MLP. The MLP utilizes backpropagation to feed the errors from the outputs back into the layers to compute one layer at a time and iterates until the model has learned the patterns and relationships in the input data to arrive at a <span class="No-Break">specific output.</span></p>
			<p><strong class="bold">Feature learning</strong> is a<a id="_idIndexMarker433"/> set of techniques where the machine uses raw data to derive the characteristics of a class in the data to derive a specific task at hand. Deep learning models use feature learning efficiently to learn complex, redundant, and variable input data and classify the specified task. Thus, it eliminates the need for manual feature engineering for designing and selecting the input features. Deep learning is very useful when your datasets cannot be separated by a straight line, known as <span class="No-Break">non-linear data.</span></p>
			<p>For example, in classifying financial transactions as fraudulent or legitimate, there may not be a clear linear boundary between the two classes of data. In such cases, deep learning models can learn these variable and complex non-linear relationships between the features of the input data and thus improve the accuracy of the <span class="No-Break">target classification.</span></p>
			<p>When working on classification problems, an easy way to determine whether your dataset is linearly separated is to draw a scatter plot for classes and see whether two classes can be separated by a line or not. In the following diagram, the left-hand chart shows that two classes are linearly separated and the right-hand chart shows that they <span class="No-Break">are not:</span></p>
			<div>
				<div id="_idContainer161" class="IMG---Figure">
					<img src="image/B19071_09_001.jpg" alt="Figure 9.1 – Linear versus non-linear datasets"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – Linear versus non-linear datasets</p>
			<p>You can create models in Redshift ML when your dataset cannot be linearly separated by using the MLP algorithm. Common use cases where MLP algorithms are useful are <a id="_idIndexMarker434"/><span class="No-Break">as follows:</span></p>
			<ul>
				<li><span class="No-Break">Speech recognition</span></li>
				<li><span class="No-Break">Image recognition</span></li>
				<li><span class="No-Break">Machine translation</span></li>
			</ul>
			<p>This chapter will show you how to build deep learning models in Amazon Redshift ML using the <span class="No-Break">MLP a<a id="_idTextAnchor164"/>lgorithm.</span></p>
			<h1 id="_idParaDest-129"><a id="_idTextAnchor165"/>Business problem</h1>
			<p>We will use <a id="_idIndexMarker435"/>a wall-following robot navigation dataset to build a machine learning model using the MLP algorithm. The robot is equipped with ultrasound sensors and data is collected as the robot navigates through the room in a clockwise direction. The goal here is to guide the robot to follow the wall by giving simple directions such as <em class="italic">Move-Forward</em>, <em class="italic">Slight-Right-Turn</em>, <em class="italic">Sharp-Right-Turn</em>, <span class="No-Break">and </span><span class="No-Break"><em class="italic">Slight-Left-Turn</em></span><span class="No-Break">.</span></p>
			<p>Since there are classes to predict for a given set of sensor readings, this is going to be a multiclass problem. We will use MLP to correctly guide the robot to follow the wall. (This data is taken from <a href="https://archive.ics.uci.edu/ml/datasets/Wall-Following+Robot+Navigation+Data">https://archive.ics.uci.edu/ml/datasets/Wall-Following+Robot+Navigation+Data</a> and is attributed to Ananda Freire, Marcus Veloso, and Guilherme Barreto (2019). UCI Machine Learning Repository [<a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>]. Irvine, CA: University of California, School of Information and <span class="No-Break">Computer Science.)</span></p>
			<p>Please follow <a id="_idIndexMarker436"/>the detailed document on the page to gain more understanding of the <span class="No-Break">use case.</span></p>
			<p>Now, you will upload the data, analyze it, and prepare for training<a id="_idTextAnchor166"/> <span class="No-Break">the model.</span></p>
			<h2 id="_idParaDest-130"><a id="_idTextAnchor167"/>Uploading and analyzing the data</h2>
			<p>We have sensor<a id="_idIndexMarker437"/> readings data stored in the following <span class="No-Break">S3 location:</span></p>
			<p><span class="No-Break"><strong class="source-inline">s3://packt-serverless-ml-redshift/chapter09/</strong></span></p>
			<p>After successfully connecting to Redshift as an admin or database developer, load data into <span class="No-Break">Amazon Redshift:</span></p>
			<ol>
				<li>Navigate to <strong class="bold">Redshift query editor v2</strong> and connect to <strong class="bold">Serverless: workgroup2</strong> and then to the <span class="No-Break"><strong class="bold">dev</strong></span><span class="No-Break"> database:</span></li>
			</ol>
			<div>
				<div id="_idContainer162" class="IMG---Figure">
					<img src="image/B19071_09_002.jpg" alt="Figure 9.2 – Connect to the dev database"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Connect to the dev database</p>
			<ol>
				<li value="2">Execute <a id="_idIndexMarker438"/>the following steps to create the schema and customer table, and load <span class="No-Break">the data:</span><pre class="source-code">
create schema chapter9_deeplearning;</pre><pre class="source-code">
create table chapter9_deeplearning.robot_navigation (</pre><pre class="source-code">
     id bigint identity(0,1),</pre><pre class="source-code">
us1 float, us2 float, us3 float, us4 float, us5 float, us6 float, us7 float, us8 float, us9 float,us10 float, us11 float, us12 float, us13 float, us14 float, us15 float, us16 float, us17 float, us18 float, us19 float, us20 float, us21 float, us22 float, us23 float, us24 float, direction varchar(256)</pre><pre class="source-code">
)</pre><pre class="source-code">
diststyle auto;</pre><pre class="source-code">
copy chapter9_deeplearning.robot_navigation from 's3://packt-serverless-ml-redshift/chapter09/sensor_readings_24.data'</pre><pre class="source-code">
iam_role  default</pre><pre class="source-code">
format as csv</pre><pre class="source-code">
delimiter ','</pre><pre class="source-code">
quote '"'</pre><pre class="source-code">
region as 'eu-west-1'</pre><pre class="source-code">
;</pre></li>
				<li>Run the following query to examine some <span class="No-Break">sample data:</span><pre class="source-code">
select * from</pre><pre class="source-code">
chapter9_deeplearning.robot_navigation</pre><pre class="source-code">
limit 10;</pre></li>
			</ol>
			<p>In <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.3</em>, we can see<a id="_idIndexMarker439"/> that our data has been <span class="No-Break">loaded successfully:</span></p>
			<div>
				<div id="_idContainer163" class="IMG---Figure">
					<img src="image/B19071_09_003.jpg" alt="Figure 9.3 – Sample output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Sample output</p>
			<p>From the preceding screenshot, we can see that there are several sensor readings. Run the following query to see the distribution of the different directions of the robot’s movements, as shown in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">:</span></p>
			<pre class="source-code">
select direction, count(*)
from chapter9_deeplearning.robot_navigation
group by 1;</pre>
			<p>To view the results as a bar graph, please click on the toggle <strong class="bold">C</strong><strong class="bold">hart</strong> button (<img src="image/B19071_09_Icone_1.png" alt=""/>) on the <strong class="bold">Result</strong> pane. Under <strong class="bold">Traces</strong>, click on <strong class="bold">+ Trace</strong> (<img src="image/B19071_09_Icone_2.png" alt=""/>) and set <strong class="bold">Type</strong> as <strong class="bold">Bar</strong>, <strong class="bold">X-axis</strong> as <strong class="bold">Direction</strong>, and <strong class="bold">Y-axis</strong> as <strong class="bold">Count</strong> from the dropdown. Keep <strong class="bold">Orientation</strong> <span class="No-Break">as </span><span class="No-Break"><strong class="bold">Vertical</strong></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer166" class="IMG---Figure">
					<img src="image/B19071_09_004.jpg" alt="Figure 9.4 – Graph generated using Query Editor v2"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Graph generated using Query Editor v2</p>
			<p>You can notice <a id="_idIndexMarker440"/>that there are more <em class="italic">Sharp-Right-Turn</em> and <em class="italic">Move-Forward</em> directions than <em class="italic">Slight-Right-Turn</em> and <em class="italic">Slight-Left-Turn</em> directions. We will use these inputs to predict the future movement of <span class="No-Break">t<a id="_idTextAnchor168"/>he robot.</span></p>
			<h2 id="_idParaDest-131"><a id="_idTextAnchor169"/>Prediction goal</h2>
			<p>Since this<a id="_idIndexMarker441"/> is a multiclass classification problem, the goal of this model is to predict which direction the robot will take next based on the 24 <span class="No-Break">sensor readings.</span></p>
			<p>The dataset has one ID column, which uniquely identifies a row of 24 sensor readings named <strong class="source-inline">us1</strong>, <strong class="source-inline">us2</strong>, …, <strong class="source-inline">us24</strong>, and a <strong class="source-inline">direction</strong> variable, which has 4 values in it. The <strong class="source-inline">direction</strong> variable is the class variable that we are trying <span class="No-Break">to predict.</span></p>
			<p>Now let’s split the dataset into a training dataset, which will be input to our model, and a test dataset, which we will use to do <span class="No-Break">our pre<a id="_idTextAnchor170"/>dictions.</span></p>
			<h2 id="_idParaDest-132"><a id="_idTextAnchor171"/>Splitting data into training and test datasets</h2>
			<p>We are <a id="_idIndexMarker442"/>going to split our table into two datasets, train and test, with an approximately 80:20 split. Let’s use the <strong class="source-inline">mod</strong> function in Redshift to split our table. The <strong class="source-inline">mod</strong> function returns the remainder of two numbers. We will pass in the ID and the <span class="No-Break">number </span><span class="No-Break"><strong class="source-inline">5</strong></span><span class="No-Break">.</span></p>
			<p>To train <a id="_idIndexMarker443"/>the model, let’s use <strong class="source-inline">where mod(id,5)</strong> is not equal to <strong class="source-inline">0</strong>, which represents our training set of 80%. Run the following command in Query <span class="No-Break">Editor v2:</span></p>
			<pre class="source-code">
select direction, count(*)
from chapter9_deeplearning.robot_navigation
where mod(id,5) &lt;&gt; 0
group by 1;</pre>
			<p>In <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.5</em>, we see the data distribution based on ~80% of <span class="No-Break">the data:</span></p>
			<div>
				<div id="_idContainer167" class="IMG---Figure">
					<img src="image/B19071_09_005.jpg" alt="Figure 9.5 – Training dataset distribution"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – Training dataset distribution</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You might see a different count than we have shown. We are using Redshift’s <strong class="source-inline">Identity</strong> function to generate the values for the <strong class="source-inline">id</strong> column. To be sure that the identity values are unique, Amazon Redshift skips some values when creating the identity values. Identity values are unique but the order might not match. Hence, you might see a different count but the data is 80% of the total count (<span class="No-Break">5,456 rows).</span></p>
			<p>The <strong class="bold">Chart</strong> function in Query Editor v2 depicts this in a bar chart format as shown in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer168" class="IMG---Figure">
					<img src="image/B19071_09_006.jpg" alt="Figure 9.6 – Training set bar chart"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – Training set bar chart</p>
			<p>To test <a id="_idIndexMarker444"/>the model, let’s use <strong class="source-inline">where mod(id,5)</strong> is equal to <strong class="source-inline">0</strong>, which represents our test dataset <span class="No-Break">of 20%:</span></p>
			<pre class="source-code">
select direction, count(*) from chapter9_deeplearning.robot_navigation
where mod(id,5) = 0
group by 1;</pre>
			<p>In <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.7</em>, we see the data distribution based on ~20% of <span class="No-Break">the data:</span></p>
			<div>
				<div id="_idContainer169" class="IMG---Figure">
					<img src="image/B19071_09_007.jpg" alt="Figure 9.7 – Test dataset distribution"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – Test dataset distribution</p>
			<p>The <strong class="bold">Chart</strong> function <a id="_idIndexMarker445"/>in Query Editor v2 depicts this in a bar chart format as shown in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer170" class="IMG---Figure">
					<img src="image/B19071_09_008.jpg" alt="Figure 9.8 – Test data bar chart"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – Test data bar chart</p>
			<p>Now that we have analyzed our data and determined how we will split it into training and test datasets, let’s create our model using the <span class="No-Break">MLP <a id="_idTextAnchor172"/>algorithm.</span></p>
			<h1 id="_idParaDest-133"><a id="_idTextAnchor173"/>Creating a multiclass classification model using MLP</h1>
			<p>In this exercise, we are <a id="_idIndexMarker446"/>going to guide the <strong class="source-inline">CREATE MODEL</strong> statement to use the MLP model. You will achieve that by setting the <strong class="source-inline">model_type</strong> parameter to <strong class="source-inline">MLP</strong>. The rest of the parameters can be set <span class="No-Break">t<a id="_idTextAnchor174"/>o default.</span></p>
			<p>Let’s create a model to predict the direction of <span class="No-Break">the robot:</span></p>
			<pre class="source-code">
CREATE MODEL chapter9_deeplearning.predict_robot_direction
from  (select
us1 ,us2 , us3 , us4 , us5 , us6 ,us7 , us8 , us9 ,
us10 ,us11 ,us12 ,us13 ,us14 ,us15 ,us16 ,us17 ,
us18 ,us19 ,us20 ,us21 , us22 ,us23 ,us24 , direction
  from chapter9_deeplearning.robot_navigation
  where mod(id,5) !=0)
target direction
function predict_robot_direction_fn
iam_role default
model_type mlp
settings (s3_bucket 'replace-with-your-s3-bucket',
max_runtime 1800);</pre>
			<p>The <strong class="source-inline">CREATE MODEL</strong> function is run with a <strong class="source-inline">max_runtime</strong> value of <strong class="source-inline">1800</strong> seconds. This means the maximum amount of time to train the model is 30 minutes. Training jobs often complete sooner depending on the dataset size. Since we have not set other parameters (for example, objective or problem type), Amazon SageMaker Autopilot will be doing the bulk of the <a id="_idIndexMarker447"/>work to identify the parameters <span class="No-Break">for us.</span></p>
			<p>Run the <strong class="source-inline">SHOW MODEL</strong> command to check whether model training <span class="No-Break">is completed:</span></p>
			<pre class="source-code">
SHOW MODEL chapter9_deeplearning.predict_robot_direction;</pre>
			<p>Check <strong class="bold">Model State</strong> in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.9</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer171" class="IMG---Figure">
					<img src="image/B19071_09_009.jpg" alt="Figure 9.9 – SHOW MODEL output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.9 – SHOW MODEL output</p>
			<p>From the preceding <a id="_idIndexMarker448"/>screenshot, we can see that the <strong class="bold">Model State</strong> field shows the status as <strong class="bold">TRAINING</strong>, which means the model is still under training. But notice that Redshift ML has picked up <strong class="bold">Model Type</strong> as <strong class="bold">mlp</strong>; other parameters such as <strong class="bold">Problem Type</strong> and <strong class="bold">Objective</strong> are empty now, but after the model has been trained, we will see <span class="No-Break">these values.</span></p>
			<p>Run the <strong class="source-inline">SHOW MODEL</strong> command again after some time to check whether model training is complete or not. From the following screenshot, notice that model training has finished and <strong class="bold">Accuracy</strong> has been selected as the objective for model evaluation. This is auto-selected by Redshift ML. Also notice that Redshift ML correctly recognized this as a multiclass <span class="No-Break">classification problem:</span></p>
			<div>
				<div id="_idContainer172" class="IMG---Figure">
					<img src="image/B19071_09_010.jpg" alt="Figure 9.10 – SHOW MODEL output"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.10 – SHOW MODEL output</p>
			<p>Now that our<a id="_idIndexMarker449"/> model has finished training, let’s run predictions using the function that was created. In <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.10</em>, <strong class="bold">Function Name</strong> is <strong class="source-inline">predict_robot_direction_fn</strong> and we will refer to that in our <span class="No-Break">prediction query.</span></p>
			<p>Also note the <strong class="source-inline">validation:accuracy</strong> value of <strong class="source-inline">.940026</strong> in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.10</em>. This means our model has an accuracy of &gt;94%, which is <span class="No-Break">very good.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">You might get a different accuracy value due to different hyperparameters selected for the algorithm in the background, and this can slightly <span class="No-Break">affect accuracy.</span></p>
			<p>Since our model has been successfully trained, let’s run some predictions on our <span class="No-Break">te<a id="_idTextAnchor175"/>st dataset.</span></p>
			<h2 id="_idParaDest-134"><a id="_idTextAnchor176"/>Running predictions</h2>
			<p>In this first query, we<a id="_idIndexMarker450"/> will be using the function returned by the <strong class="source-inline">CREATE MODEL</strong> command to compare the actual direction with our predicted directions. Run the following query in Query Editor v2 to see how many times we <span class="No-Break">predicted correctly:</span></p>
			<pre class="source-code">
select correct, count(*)
from
(select  DIRECTION as actual, chapter9_deeplearning.predict_robot_direction_fn (
US1,US2,US3,US4,US5,US6,US7,US8,US9,US10,US11,US12,
US13,US14,US15,US16,US17,US18,US19,US20,US21,US22,US23,US24
 ) as  predicted,
  CASE WHEN actual = predicted THEN 1::INT
         ELSE 0::INT END AS correct
from chapter9_deeplearning.robot_navigation
where MOD(id,5) =0
) t1
group by 1;</pre>
			<p>In <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.11</em>, we see that our model correctly predicted the robot’s direction <span class="No-Break">1,033 times.</span></p>
			<p>Please note that your count might be <span class="No-Break">slightly different:</span></p>
			<div>
				<div id="_idContainer173" class="IMG---Figure">
					<img src="image/B19071_09_011.jpg" alt="Figure 9.11 – Actual directions versus predicted direction"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.11 – Actual directions versus predicted direction</p>
			<p>Now, let’s <a id="_idIndexMarker451"/>run a query against the test dataset to predict which direction the robot will move. Run the following query in Query Editor v2 to return the first <span class="No-Break">10 rows:</span></p>
			<pre class="source-code">
 select  id, chapter9_deeplearning.predict_robot_direction_fn (
US1,US2,US3,US4,US5,US6,US7,US8,US9,US10,US11,US12,
US13,US14,US15,US16,US17,US18,US19,US20,US21,US22,US23,US24
 ) as  predicted_direction
from chapter9_deeplearning.robot_navigation
where MOD(id,5) &lt;&gt; 0
limit 10;</pre>
			<p>In <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.12</em>, we show the first 10 rows and the direction based on <span class="No-Break">the ID:</span></p>
			<div>
				<div id="_idContainer174" class="IMG---Figure">
					<img src="image/B19071_09_012.jpg" alt="Figure 9.12 – Predicted direction by ID"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.12 – Predicted direction by ID</p>
			<p>Now, let’s<a id="_idIndexMarker452"/> modify the query to summarize our predicted robot movements. Run the following in Query <span class="No-Break">Editor v2:</span></p>
			<pre class="source-code">
select chapter9_deeplearning.predict_robot_direction_fn (
US1,US2,US3,US4,US5,US6,US7,US8,US9,US10,US11,US12,
US13,US14,US15,US16,US17,US18,US19,US20,US21,US22,US23,US24
 ) as  predicted_direction, count(*)
from chapter9_deeplearning.robot_navigation
where MOD(id,5) &lt;&gt; 0
group by 1;</pre>
			<p>In <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.13</em>, we<a id="_idIndexMarker453"/> can see that <strong class="bold">Move-Forward</strong> is the most popular direction, followed closely by <strong class="bold">Sharp-Right-Turn</strong>. Please note that your counts might <span class="No-Break">differ slightly.</span></p>
			<div>
				<div id="_idContainer175" class="IMG---Figure">
					<img src="image/B19071_09_013.jpg" alt="Figure 9.13 – Summary of predicted direction"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.13 – Summary of predicted direction</p>
			<p>You have now created a model using the MLP algorithm and run predictions on the <span class="No-Break">test dataset.</span></p>
			<h1 id="_idParaDest-135"><a id="_idTextAnchor177"/>Summary</h1>
			<p>In this chapter, we discussed deep learning models and why you need them and showed you how to create an MLP model on sensor-reading data to predict the next movement of the robot. You learned that non-linear datasets are suited for deep learning and created a multiclass classification model using the <span class="No-Break">MLP algorithm.</span></p>
			<p>In the next chapter, we will show you how to create a model with complete control of hyper-tuning parameters using <span class="No-Break">XGBoost algorithms.</span></p>
		</div>
	</body></html>