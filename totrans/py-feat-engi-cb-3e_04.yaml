- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Performing Variable Discretization
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行变量离散化
- en: Discretization is the process of transforming continuous variables into discrete
    features by creating a set of contiguous intervals, also called **bins**, which
    span the range of the variable values. Subsequently, these intervals are treated
    as categorical data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化是将连续变量通过创建一系列连续区间（也称为**bins**，跨越变量值的范围）转换为离散特征的过程。随后，这些区间被视为分类数据。
- en: Many machine learning models, such as decision trees and Naïve Bayes, work better
    with discrete attributes. In fact, decision tree-based models make decisions based
    on discrete partitions over the attributes. During induction, a decision tree
    evaluates all possible feature values to find the best cut-point. Therefore, the
    more values the feature has, the longer the induction time of the tree is. In
    this sense, discretization can reduce the time it takes to train the models.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习模型，如决策树和朴素贝叶斯，与离散属性配合工作效果更好。事实上，基于决策树的模型是根据属性上的离散分区做出决策的。在归纳过程中，决策树评估所有可能的特征值以找到最佳分割点。因此，特征值越多，树的归纳时间就越长。从这个意义上说，离散化可以减少模型训练所需的时间。
- en: Discretization has additional advantages. Data is reduced and simplified; discrete
    features can be easier to understand by domain experts. Discretization can change
    the distribution of skewed variables; when sorting observations across bins with
    equal-frequency, the values are spread more homogeneously across the range. Additionally,
    discretization can minimize the influence of outliers by placing them at lower
    or higher intervals, together with the remaining **inlier** values of the distribution.
    Overall, discretization reduces and simplifies data, making the learning process
    faster and potentially yielding more accurate results.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化还有额外的优势。数据被减少和简化；离散特征可以更容易被领域专家理解。离散化可以改变偏斜变量的分布；在按等频对区间进行排序时，值在范围内分布得更均匀。此外，离散化可以通过将它们放置在较低或较高的区间中，与分布的剩余**内点**值一起，最小化异常值的影响。总的来说，离散化减少了数据并简化了数据，使学习过程更快，并可能产生更准确的结果。
- en: Discretization can also lead to a loss of information, for example, by combining
    values that are strongly associated with different classes or target values into
    the same bin. Therefore, the aim of a discretization algorithm is to find the
    minimal number of intervals without incurring a significant loss of information.
    In practice, many discretization procedures require the user to input the number
    of intervals into which the values will be sorted. Then, the job of the algorithm
    is to find the cut points for those intervals. Among these procedures, we find
    the most widely used equal-width and equal-frequency discretization methods. Discretization
    methods based on decision trees are, otherwise, able to find the optimal number
    of partitions, as well as the cut points.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化也可能导致信息丢失，例如，通过将强烈关联不同类别或目标值的值组合到同一个区间中。因此，离散化算法的目标是在不造成重大信息丢失的情况下找到最小数量的区间。在实践中，许多离散化过程需要用户输入将值排序到的区间数量。然后，算法的任务是找到这些区间的分割点。在这些过程中，我们发现最广泛使用的等宽和等频离散化方法。基于决策树的离散化方法则能够找到最佳分区数量以及分割点。
- en: Discretization procedures can be classified as **supervised** and **unsupervised**.
    Unsupervised discretization methods only use the variable’s distribution to determine
    the limits of the contiguous bins. On the other hand, supervised methods use target
    information to create the intervals.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化过程可以分为**监督**和**非监督**。非监督离散化方法仅使用变量的分布来确定连续区间的界限。另一方面，监督方法使用目标信息来创建区间。
- en: In this chapter, we will discuss widely used supervised and unsupervised discretization
    procedures that are available in established open source libraries. Among these,
    we will cover equal-width, equal-frequency, arbitrary, k-means, and decision tree-based
    discretization. More elaborate methods, such as ChiMerge and CAIM, are out of
    the scope of this chapter, as their implementation is not yet open source available.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论在成熟的开源库中广泛使用的监督和非监督离散化过程。在这些过程中，我们将涵盖等宽、等频、任意、k-均值和基于决策树的离散化。更详细的方法，如ChiMerge和CAIM，超出了本章的范围，因为它们的实现尚未开源。
- en: 'This chapter contains the following recipes:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含以下食谱：
- en: Performing equal-width discretization
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行等宽离散化
- en: Implementing equal-frequency discretization
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现等频率离散化
- en: Discretizing the variable into arbitrary intervals
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将变量离散化到任意区间
- en: Performing discretization with k-means clustering
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用k-means聚类进行离散化
- en: Implementing feature binarization
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现特征二值化
- en: Using decision trees for discretization
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用决策树进行离散化
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will use the numerical computing libraries `pandas`, `numpy`,
    `matplotlib`, `scikit-learn`, and `feature-engine`. We will also use the `yellowbrick`
    Python open source library, which you can install with `pip`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用数值计算库`pandas`、`numpy`、`matplotlib`、`scikit-learn`和`feature-engine`。我们还将使用`yellowbrick`
    Python开源库，您可以使用`pip`进行安装：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For more details about `yellowbrick`, visit the documentation here:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于`yellowbrick`的信息，请访问以下文档：
- en: https://www.scikit-yb.org/en/latest/index.html
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: https://www.scikit-yb.org/en/latest/index.html
- en: Performing equal-width discretization
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行等宽离散化
- en: 'Equal-width discretization consists of dividing the range of observed values
    for a variable into *k* equally sized intervals, where *k* is supplied by the
    user. The interval width for the *X* variable is given by the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 等宽离散化包括将变量的观测值范围划分为用户提供的*k*个等大小的区间。*X*变量的区间宽度如下所示：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="bold-italic">W</mi><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">d</mi><mi
    mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">h</mi><mo>=</mo><mfrac><mrow><mi
    mathvariant="bold-italic">M</mi><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">x</mi><mfenced
    open="(" close=")"><mi mathvariant="bold-italic">X</mi></mfenced><mo>−</mo><mi
    mathvariant="bold-italic">M</mi><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">n</mi><mo>(</mo><mi
    mathvariant="bold-italic">X</mi><mo>)</mo></mrow><mi mathvariant="bold-italic">k</mi></mfrac></mrow></mrow></math>](img/20.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi
    mathvariant="bold-italic">W</mi><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">d</mi><mi
    mathvariant="bold-italic">t</mi><mi mathvariant="bold-italic">h</mi><mo>=</mo><mfrac><mrow><mi
    mathvariant="bold-italic">M</mi><mi mathvariant="bold-italic">a</mi><mi mathvariant="bold-italic">x</mi><mfenced
    open="(" close=")"><mi mathvariant="bold-italic">X</mi></mfenced><mo>−</mo><mi
    mathvariant="bold-italic">M</mi><mi mathvariant="bold-italic">i</mi><mi mathvariant="bold-italic">n</mi><mo>(</mo><mi
    mathvariant="bold-italic">X</mi><mo>)</mo></mrow><mi mathvariant="bold-italic">k</mi></mfrac></mrow></mrow></math>](img/20.png)'
- en: 'Then, if the values of the variable vary between 0 and 100, we can create five
    bins like this: *width = (100-0) / 5 = 20*. The bins will be 0–20, 20–40, 40–60,
    and 80–100\. The first and final bins (0–20 and 80–100) can be expanded to accommodate
    values smaller than 0 or greater than 100 by extending the limits to minus and
    plus infinity.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果变量的值在0到100之间变化，我们可以创建五个箱，如下所示：*width = (100-0) / 5 = 20*。箱将分别是0–20、20–40、40–60和80–100。第一个和最后一个箱（0–20和80–100）可以通过扩展限制到负无穷和正无穷来扩展，以容纳小于0或大于100的值。
- en: In this recipe, we will carry out equal-width discretization using `pandas`,
    `scikit-learn`, and `feature-engine`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将使用`pandas`、`scikit-learn`和`feature-engine`进行等宽离散化。
- en: How to do it...
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'First, let’s import the necessary Python libraries and get the dataset ready:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入必要的Python库并准备好数据集：
- en: 'Let’s import the libraries and functions:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入库和函数：
- en: '[PRE1]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s load the predictor and target variables of the California housing dataset:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载加利福尼亚住房数据集的预测变量和目标变量：
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To avoid data leakage, we will find the intervals’ limits by using the variables
    in the train set. Then, we will use these limits to discretize the variables in
    train and test sets.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免数据泄露，我们将通过使用训练集中的变量来找到区间的限制。然后，我们将使用这些限制来对训练集和测试集中的变量进行离散化。
- en: 'Let’s divide the data into train and test sets:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将数据分为训练集和测试集：
- en: '[PRE3]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Next, we will divide the continuous `HouseAge` variable into 10 intervals using
    `pandas` and the formula described at the beginning of the recipe.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们将使用`pandas`和配方开头描述的公式将连续的`HouseAge`变量划分为10个区间。
- en: 'Let’s capture the minimum and maximum values of `HouseAge`:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们捕获`HouseAge`的最小和最大值：
- en: '[PRE4]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s determine the interval width, which is the variable’s value range divided
    by the number of bins:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们确定区间宽度，即变量的值范围除以箱数：
- en: '[PRE5]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If we execute `print(width)`, we will obtain `5`, which is the size of the intervals.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们执行`print(width)`，我们将获得`5`，这是区间的尺寸。
- en: 'Now we need to define the interval limits and store them in a list:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要定义区间限制并将它们存储在一个列表中：
- en: '[PRE6]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If we now execute `print(interval_limits)`, we will see the interval limits:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们现在执行 `print(interval_limits)`，我们将看到区间限制：
- en: '[PRE7]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let’s expand the limits of the first and last intervals to accommodate smaller
    or greater values that we could find in the test set or in future data sources:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将第一个和最后一个区间的限制范围扩展，以适应测试集或未来数据源中可能找到的较小或较大的值：
- en: '[PRE8]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s make a copy of the DataFrames so we don’t overwrite the original ones,
    which we will need for later steps in the recipe:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们复制 DataFrame，这样我们就不会覆盖原始的 DataFrame，我们将在后续步骤中需要它们：
- en: '[PRE9]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let’s sort the `HouseAge` variable into the intervals that we defined in *step
    6*:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将 `HouseAge` 变量排序到我们在 *步骤 6* 中定义的区间中：
- en: '[PRE10]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We have set `include_lowest=True` to include the lowest value in the first interval.
    Note that we used the train set to find the intervals and then used those limits
    to sort the variable in both datasets.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将 `include_lowest=True` 设置为包含第一个区间中的最低值。请注意，我们使用训练集来找到区间，然后使用这些限制对两个数据集中的变量进行排序。
- en: 'Let’s print the top `5` observations of the discretized and original variables:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打印离散化和原始变量的前 `5` 个观测值：
- en: '[PRE11]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the following output, we can see that the `52` value was allocated to the
    46–infinite interval, the `43` value was allocated to the 41–46 interval, and
    so on:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下输出中，我们可以看到 `52` 值被分配到 46–无限区间，`43` 值被分配到 41–46 区间，依此类推：
- en: '[PRE12]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The parentheses and brackets in the intervals indicate whether a value is included
    in the interval or not. For example, the (41, 46] interval contains all values
    greater than 41 and smaller than or equal to 46.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 区间中的括号和方括号表示一个值是否包含在区间内。例如，(41, 46] 区间包含所有大于 41 且小于或等于 46 的值。
- en: Equal-width discretization allocates a different number of observations to each
    interval.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 等宽离散化将不同数量的观测值分配给每个区间。
- en: 'Let’s make a bar plot with the proportion of observations across the intervals
    of `HouseAge` in the train and test sets:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制一个条形图，显示训练集和测试集中 `HouseAge` 区间的观测值比例：
- en: '[PRE13]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the following output, we can see that the proportion of observations per
    interval is approximately the same in the train and test sets, but different across
    intervals:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下输出中，我们可以看到训练集和测试集中每个区间的观测值比例大致相同，但区间之间不同：
- en: '![Figure 4.1 – The proportion of observations per interval after the discretization](img/B22396_04_1.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – 离散化后每个区间的观测值比例](img/B22396_04_1.jpg)'
- en: Figure 4.1 – The proportion of observations per interval after the discretization
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 离散化后每个区间的观测值比例
- en: With `feature-engine`, we can perform equal-width discretization in fewer lines
    of code and for many variables at a time.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `feature-engine`，我们可以用更少的代码行和一次对多个变量执行等宽离散化。
- en: 'First, let’s import the discretizer:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们导入离散化器：
- en: '[PRE14]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let’s set up the discretizer to sort three continuous variables into eight
    intervals:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将离散化器设置为将三个连续变量排序到八个区间中：
- en: '[PRE15]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`EqualWidthDiscretiser()` returns an integer indicating whether the value was
    sorted into the first, second, or eighth bin by default. That is the equivalent
    of ordinal encoding, which we described in the *Replacing categories with ordinal
    numbers* recipe of [*Chapter 2*](B22396_02.xhtml#_idTextAnchor182), *Encoding
    Categorical Variables*. To carry out a different encoding with the `feature-engine`
    or `category` `encoders` Python libraries, cast the returned variables as objects
    by setting `return_object` to `True`. Alternatively, make the transformer return
    the interval limits by setting `return_boundaries` to `True`.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`EqualWidthDiscretiser()` 返回一个整数，表示默认情况下值是否被排序到第一个、第二个或第八个箱中。这相当于顺序编码，我们在 [*第
    2 章*](B22396_02.xhtml#_idTextAnchor182) 的 *用顺序数字替换类别* 菜谱中描述过，*编码分类变量*。要使用 `feature-engine`
    或 `category` `encoders` Python 库执行不同的编码，请将返回的变量作为对象类型，通过设置 `return_object` 为 `True`。或者，通过设置
    `return_boundaries` 为 `True`，让转换器返回区间限制。'
- en: 'Let’s fit the discretizer to the train set so that it learns the cut points
    for each variable:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将离散化器适配到训练集，以便它为每个变量学习切点：
- en: '[PRE16]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: After fitting, we can inspect the cut points in the `binner_dict_` attribute
    by executing `print(disc.binner_dict_)`.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 适配后，我们可以通过执行 `print(disc.binner_dict_)` 来检查 `binner_dict_` 属性中的切点。
- en: Note
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`feature-engine` will automatically extend the limits of the lower and upper
    intervals to infinite to accommodate potential outliers in future data.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature-engine` 将自动将下限和上限区间的范围扩展到无限大，以适应未来数据中的潜在异常值。'
- en: 'Let’s discretize the variables in the train and test sets:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将训练集和测试集中的变量进行离散化：
- en: '[PRE17]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`EqualWidthDiscretiser()` returns a DataFrame where the selected variables
    are discretized. If we run `test_t.head()`, we will see the following output where
    the original values of `MedInc`, `HouseAge`, and `AveRooms` are replaced by the
    interval numbers:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`EqualWidthDiscretiser()` 返回一个 DataFrame，其中选定的变量已离散化。如果我们运行 `test_t.head()`，我们将看到以下输出，其中
    `MedInc`、`HouseAge` 和 `AveRooms` 的原始值被区间编号所取代：'
- en: '![Figure 4.2 – A DataFrame with three discretized variables: HouseAge, MedInc,
    and AveRooms](img/B22396_04_2.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – 包含三个离散化变量：HouseAge、MedInc 和 AveRooms 的 DataFrame](img/B22396_04_2.jpg)'
- en: 'Figure 4.2 – A DataFrame with three discretized variables: HouseAge, MedInc,
    and AveRooms'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 包含三个离散化变量：HouseAge、MedInc 和 AveRooms 的 DataFrame
- en: 'Now, let’s make bar plots with the proportion of observations per interval
    to better understand the effect of equal-width discretization:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们通过绘制每个区间的观测比例的条形图来更好地理解等宽离散化的效果：
- en: '[PRE18]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The intervals contain a different number of observations, as shown in the following
    plots:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如以下图表所示，区间包含不同数量的观测值：
- en: '![Figure 4.3 – Bar plots with the proportion of observations per interval after
    the discretization](img/B22396_04_3.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 – 离散化后每个区间的观测比例的条形图](img/B22396_04_3.jpg)'
- en: Figure 4.3 – Bar plots with the proportion of observations per interval after
    the discretization
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 离散化后每个区间的观测比例的条形图
- en: Now, let’s implement equal-width discretization with scikit-learn.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 scikit-learn 实现等宽离散化。
- en: 'Let’s import the classes from scikit-learn:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入 scikit-learn 中的类：
- en: '[PRE19]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Let’s set up an equal-width discretizer by setting its `strategy` to `uniform`:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过将其 `strategy` 设置为 `uniform` 来设置一个等宽离散化器：
- en: '[PRE20]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Note
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`KBinsDiscretiser()` can return the bins as integers by setting `encoding`
    to `''ordinal''` or one-hot encoded by setting `encoding` to `''onehot-dense''`.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`KBinsDiscretiser()` 可以通过将 `encoding` 设置为 `''ordinal''` 返回整数箱，或者通过将 `encoding`
    设置为 `''onehot-dense''` 返回独热编码。'
- en: 'Let’s use `ColumnTransformer()` to restrict the discretization to the selected
    variables from *step 13*:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用 `ColumnTransformer()` 来将离散化限制为从 *步骤 13* 中选择的变量：
- en: '[PRE21]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: With `remainder` set to `passthrough`, `ColumnTransformer()` returns all the
    variables in the input DataFrame after the transformation. To return only the
    transformed variables, set `remainder` to `drop`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `remainder` 设置为 `passthrough`，`ColumnTransformer()` 返回变换后的输入 DataFrame 中的所有变量。要仅返回变换后的变量，将
    `remainder` 设置为 `drop`。
- en: 'Let’s fit the discretizer to the train set so that it learns the interval limits:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将离散化器拟合到训练集，以便它学习区间界限：
- en: '[PRE22]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, let’s discretize the selected variables in the train and test sets:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们对训练集和测试集中的选定变量进行离散化：
- en: '[PRE23]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We can inspect the cut points learned by the transformer by executing `ct.named_transformers_["discretizer"].bin_edges_`.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过执行 `ct.named_transformers_["discretizer"].bin_edges_` 来检查变压器学习到的切分点。
- en: Note
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`ColumnTransformer()` will append `discretize` to the variables that were discretized
    and `remainder` to those that were not modified.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`ColumnTransformer()` 将 `discretize` 添加到已离散化的变量，将 `remainder` 添加到未修改的变量。'
- en: We can check the output by executing `test_t.head()`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行 `test_t.head()` 来检查输出。
- en: How it works…
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this recipe, we sorted the variable values into equidistant intervals. To
    perform discretization with `pandas`, we first found the maximum and minimum values
    of the `HouseAge` variable using the `max()` and `min()` methods. Then, we estimated
    the interval width by dividing the value range by the number of arbitrary bins.
    With the width and the minimum and maximum values, we determined the interval
    limits and stored them in a list. We used this list with pandas `cut()` to sort
    the variable values into the intervals.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将变量值排序到等距区间中。要使用 `pandas` 进行离散化，我们首先使用 `max()` 和 `min()` 方法找到 `HouseAge`
    变量的最大值和最小值。然后，我们通过将值范围除以任意箱子的数量来估计区间宽度。有了宽度和最小值、最大值，我们确定了区间界限并将它们存储在一个列表中。我们使用这个列表与
    pandas 的 `cut()` 方法将变量值排序到区间中。
- en: Note
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Pandas `cut()` sorts the variable into intervals of equal size by default. It
    will extend the variable range by .1% on each side to include the minimum and
    maximum values. The reason why we generated the intervals manually is to accommodate
    potentially smaller or larger values than those seen in the dataset in future
    data sources when we deploy our model.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 的 `cut()` 默认按等大小区间对变量进行排序。它将在每侧扩展变量范围的 .1%，以包含最小值和最大值。我们手动生成区间的理由是为了适应在部署我们的模型时，未来数据源中可能出现的比数据集中看到的更小或更大的值。
- en: After discretization, we normally treat the intervals as categorical values.
    By default, pandas `cut()` returns the interval values as ordered integers, which
    is the equivalent of ordinal encoding. Alternatively, we can return the interval
    limits by setting the `labels` parameter to `None`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化后，我们通常将区间视为分类值。默认情况下，pandas 的 `cut()` 函数返回区间值作为有序整数，这相当于顺序编码。或者，我们可以通过将 `labels`
    参数设置为 `None` 来返回区间限制。
- en: To display the number of observations per interval, we created a bar plot. We
    used the pandas `value_counts()` function to obtain the fraction of observations
    per interval, which returns the result in pandas Series, where the index is the
    interval and the counts are the values. To plot these proportions, first, we concatenated
    the train and test set series using the pandas `concat()`function in a DataFrame,
    and then we assigned the `train` and `test` column names to it. Finally, we used
    `plot.bar()` to display a bar plot. We rotated the labels with Matplotlib’s `xticks()`function,
    and added the *x* and *y* legend with `xlabels()` and `ylabel()`, as well as the
    title with `title()`.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了显示每个区间的观测数，我们创建了一个条形图。我们使用 pandas 的 `value_counts()` 函数来获取每个区间的观测数比例，该函数返回一个
    pandas Series，其中索引是区间，计数是值。为了绘制这些比例，首先，我们使用 pandas 的 `concat()` 函数在一个 DataFrame
    中连接了训练集和测试集系列，并将其分配给 `train` 和 `test` 列名称。最后，我们使用 `plot.bar()` 显示条形图。我们使用 Matplotlib
    的 `xticks()` 函数旋转标签，并使用 `xlabels()` 和 `ylabel()` 添加了 *x* 和 *y* 图例，以及使用 `title()`
    添加了标题。
- en: 'To perform equal-width discretization with `feature-engine`, we used `EqualWidth``     Discretiser()`, which takes the number of bins and the variables to discretize
    as arguments. With `fit()`, the discretizer learned the interval limits for each
    variable. With `transform()`, it sorted the values into each bin.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 `feature-engine` 进行等宽离散化，我们使用了 `EqualWidthDiscretiser()`，它接受区间数量和要离散化的变量作为参数。通过
    `fit()`，离散化器为每个变量学习了区间限制。通过 `transform()`，它将值排序到每个区间。
- en: '`EqualWidthDiscretiser()` returns the bins as sorted integers by default, which
    is the equivalent of ordinal encoding. To follow up the discretization with any
    other encoding procedure available in the `feature-engine` or `category encoders`
    libraries, we need to return the bins cast as objects by setting `return_object`
    to `True` when we set up the transformer.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`EqualWidthDiscretiser()` 默认返回按顺序排列的整数作为区间，这相当于顺序编码。为了在 `feature-engine` 或
    `category encoders` 库中跟随任何其他编码过程进行离散化，我们需要通过在设置转换器时将 `return_object` 设置为 `True`
    来返回作为对象的区间。'
- en: Note
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`EqualWidthDiscretiser()` extends the values of the first and last interval
    to minus and plus infinity by default to automatically accommodate smaller and
    greater values than those seen in the training set.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`EqualWidthDiscretiser()` 默认将第一个和最后一个区间的值扩展到负无穷和正无穷，以自动适应训练集中未见到的较小和较大的值。'
- en: We followed the discretization with bar plots to display the fraction of observations
    per interval for each of the transformed variables. We could see that if the original
    variable was skewed, the bar plot was also skewed. Note how some of the intervals
    of the `MedInc` and `AveRooms` variables, which had skewed distributions, contained
    very few observations. In particular, even though we wanted to create eight bins
    for `AveRooms`, there were only enough values to create five, and most values
    of the variables were allocated to the first interval.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用条形图跟随离散化，以显示每个转换变量的每个区间的观测数比例。我们可以看到，如果原始变量是偏斜的，条形图也是偏斜的。注意 `MedInc` 和 `AveRooms`
    变量的某些区间，这些变量具有偏斜分布，其中包含非常少的观测值。特别是，尽管我们想要为 `AveRooms` 创建八个区间，但只有足够的数据来创建五个，并且大多数变量的值都被分配到了第一个区间。
- en: Finally, we discretized three continuous variables into equal-width bins with
    `KBinsDiscretizer()` from scikit-learn. To create equal-width bins, we set the
    `strategy` argument to `uniform`. With `fit()`, the transformer learned the limits
    of the intervals, and with `transform()`, it sorted the values into each interval.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用 scikit-learn 的 `KBinsDiscretizer()` 将三个连续变量离散化到等宽区间。为了创建等宽区间，我们将 `strategy`
    参数设置为 `uniform`。通过 `fit()`，转换器学习了区间的限制，而通过 `transform()`，它将值排序到每个区间。
- en: We used the `ColumnTransformer()` to restrict the discretization to the selected
    variables, setting the transform output to pandas to obtain a DataFrame after
    the transformation. `KBinsDiscretizer()` can return the intervals as ordinal numbers,
    as we had it do in the recipe, or as one-hot-encoded variables. The behavior can
    be modified through the `encode` parameter.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 `ColumnTransformer()` 来限制离散化到选定的变量，并将转换输出设置为 pandas，以在转换后获得 DataFrame。`KBinsDiscretizer()`
    可以返回作为序数的区间，正如我们在配方中所做的那样，或者作为 one-hot 编码的变量。这种行为可以通过 `encode` 参数进行修改。
- en: See also
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考以下内容
- en: 'For a comparison of equal-width discretization with more sophisticated methods,
    see Dougherty J, Kohavi R, Sahami M. *Supervised and unsupervised discretization
    of continuous features*. In: Proceedings of the 12th international conference
    on machine learning. San Francisco: Morgan Kaufmann; 1995\. p. 194–202.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '为了比较等宽离散化与更复杂的方法，请参阅 Dougherty J, Kohavi R, Sahami M. *Supervised and unsupervised
    discretization of continuous features*. In: Proceedings of the 12th international
    conference on machine learning. San Francisco: Morgan Kaufmann; 1995\. p. 194–202.'
- en: Implementing equal-frequency discretization
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现等频离散化
- en: Equal-width discretization is intuitive and easy to compute. However, if the
    variables are skewed, then there will be many empty bins or bins with only a few
    values, while most observations will be allocated to a few intervals. This could
    result in a loss of information. This problem can be solved by adaptively finding
    the interval cut-points so that each interval contains a similar fraction of observations.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 等宽离散化直观且易于计算。然而，如果变量是偏斜的，那么将会有很多空区间或只有少数值的区间，而大多数观测值将被分配到少数几个区间。这可能导致信息丢失。这个问题可以通过自适应地找到区间切点来解决，使得每个区间包含相似比例的观测值。
- en: Equal-frequency discretization divides the values of the variable into intervals
    that carry the same proportion of observations. The interval width is determined
    by **quantiles**. Quantiles are values that divide data into equal portions. For
    example, the median is a quantile that divides the data into two halves. Quartiles
    divide the data into four equal portions, and percentiles divide the data into
    100 equal-sized portions. As a result, the intervals will most likely have different
    widths, but a similar number of observations. The number of intervals is defined
    by the user.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 等频离散化将变量的值划分为具有相同观测比例的区间。区间宽度由 **分位数** 决定。分位数是分割数据为相等部分的值。例如，中位数是一个将数据分为两半的分位数。四分位数将数据分为四个相等的部分，而百分位数将数据分为
    100 个相等大小的部分。因此，区间可能具有不同的宽度，但观测数数量相似。区间的数量由用户定义。
- en: In this recipe, we will perform equal-frequency discretization using `pandas`,
    `scikit-learn`, and `feature-engine`.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将使用 `pandas`、`scikit-learn` 和 `feature-engine` 来执行等频离散化。
- en: How to do it...
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'First, let’s import the necessary Python libraries and get the dataset ready:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入必要的 Python 库并准备数据集：
- en: 'Let’s import the required Python libraries and functions:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入所需的 Python 库和函数：
- en: '[PRE24]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s load the California housing dataset into a DataFrame:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将加利福尼亚住房数据集加载到 DataFrame 中：
- en: '[PRE25]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To avoid data leakage, we will determine the interval boundaries or quantiles
    from the train set.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免数据泄露，我们将从训练集中确定区间界限或分位数。
- en: 'Let’s divide the data into train and test sets:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将数据分为训练集和测试集：
- en: '[PRE26]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let’s make a copy of the DataFrames:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们复制 DataFrame：
- en: '[PRE27]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We’ll use pandas `qcut()`to obtain a discretized copy of the `HouseAge` variable,
    which we will store as a new column in the training set, and the limits of eight
    equal-frequency intervals:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 pandas 的 `qcut()` 函数来获取 `HouseAge` 变量的离散化副本，并将其存储为训练集中的一个新列，以及八个等频区间的界限：
- en: '[PRE28]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'If you execute `print(interval_limits)`, you’ll see the following interval
    limits: `array([ 1., 14., 18., 24., 29., 34., 37.,` `44., 52.])`.'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你执行 `print(interval_limits)`，你会看到以下区间界限：`array([ 1., 14., 18., 24., 29., 34.,
    37., 44., 52.])`。
- en: 'Let’s print the top five observations of the discretized and original variables:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打印离散化和原始变量的前五个观测值：
- en: '[PRE29]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In the following output, we see that the `52` value was allocated to the 44–52
    interval, the `43` value was allocated to the 37–44 interval, and so on:'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下输出中，我们可以看到 `52` 值被分配到 44–52 区间，`43` 值被分配到 37–44 区间，依此类推：
- en: '[PRE30]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: test_t["House_disc"] = pd.cut(
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: test_t["House_disc"] = pd.cut(
- en: x=X_test["HouseAge"],
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: x=X_test["HouseAge"],
- en: bins=interval_limits,
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: bins=interval_limits,
- en: include_lowest=True)
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: include_lowest=True)
- en: '[PRE31]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let’s make a bar plot with the proportion of observations per interval in the
    train and test sets:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们制作一个条形图，展示训练集和测试集中每个区间的观测比例：
- en: '[PRE32]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In the following plot, we can see that the bins contain a similar fraction
    of observations:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下图中，我们可以看到每个区间包含相似比例的观测值：
- en: '![Figure 4.4 – The proportion of observations per interval of HouseAge after
    equal-frequency discretization](img/B22396_04_4.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图4.4 – HouseAge在等频率离散化后的每个区间的观测比例](img/B22396_04_4.jpg)'
- en: Figure 4.4 – The proportion of observations per interval of HouseAge after equal-frequency
    discretization
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 – HouseAge在等频率离散化后的每个区间的观测比例
- en: With `feature-engine`, we can apply equal-frequency discretization to multiple
    variables.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`feature-engine`，我们可以将多个变量应用等频率离散化。
- en: 'Let’s import the discretizer:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入离散化器：
- en: '[PRE33]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s set up the transformer to discretize three continuous variables into
    eight bins:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置转换器，将三个连续变量离散化到八个区间：
- en: '[PRE34]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: With `return_boundaries=True`, the transformer will return the interval boundaries
    after the discretization. To return the interval number, set it to `False`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`return_boundaries=True`，转换器将在离散化后返回区间边界。要返回区间编号，将其设置为`False`。
- en: 'Let’s fit the discretizer to the train set so that it learns the interval limits:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将离散化器拟合到训练集，以便它学习区间限制：
- en: '[PRE35]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Note
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: '`feature-engine` will automatically extend the limits of the lower and upper
    intervals to infinite to accommodate potential outliers in future data.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature-engine`将自动将下限和上限区间的限制扩展到无限，以适应未来数据中的潜在异常值。'
- en: 'Let’s transform the variables in the train and test sets:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将训练集和测试集中的变量进行转换：
- en: '[PRE36]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let’s make bar plots with the fraction of observations per interval to better
    understand the effect of equal-frequency discretization:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们用每个区间的观测比例制作条形图，以便更好地理解等频率离散化的效果：
- en: '[PRE37]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In the following figure, we can see that the intervals have a similar fraction
    of observations:'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下图中，我们可以看到区间具有相似比例的观测值：
- en: "![Figure 4.5 – The proportion of observations per interval after  equal-frequency\
    \ discretization of three va\uFEFFriables.](img/B22396_04_5.jpg)"
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5 – 对三个变量进行等频率离散化后每个区间的观测比例](img/B22396_04_5.jpg)'
- en: Figure 4.5 – The proportion of observations per interval after equal-frequency
    discretization of three variables.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 – 对三个变量进行等频率离散化后每个区间的观测比例。
- en: 'Now, let’s carry out equal-frequency discretization with scikit-learn:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用scikit-learn进行等频率离散化：
- en: 'Let’s import the transformer:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入转换器：
- en: '[PRE38]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let’s set up the discretizer to sort variables into eight equal-frequency bins:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置离散化器，将变量排序到八个等频率的区间：
- en: '[PRE39]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let’s fit the discretizer to a slice of the train set containing the variables
    from *step 10* so that it learns the interval limits:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将离散化器拟合到包含从*步骤10*的变量的训练集切片，以便它学习区间限制：
- en: '[PRE40]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Note
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: scikit-learn’s `KBinsDiscretiser()` will discretize all the variables in the
    dataset. To discretize only a subset, we apply the transformer to the slice of
    the DataFrame that contains the variables of interest. Alternatively, we can restrict
    the discretization to a subset of variables by using the `ColumnTransformer()`,
    as we did in the *Performing equal-width* *discretization* recipe.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn的`KBinsDiscretiser()`将离散化数据集中的所有变量。要仅对子集进行离散化，我们将转换器应用于包含感兴趣变量的DataFrame切片。或者，我们可以通过使用`ColumnTransformer()`来限制离散化到变量的子集，就像我们在*执行等宽*
    *离散化*配方中所做的那样。
- en: 'Let’s make a copy of the DataFrames where we’ll store the discretized variables:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们复制包含我们将存储离散化变量的DataFrames：
- en: '[PRE41]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Finally, let’s transform the variables in both the train and test sets:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们将训练集和测试集中的变量进行转换：
- en: '[PRE42]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: We can inspect the cut points by executing `disc.bin_edges_`.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行`disc.bin_edges_`来检查切分点。
- en: How it works…
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we sorted the variable values into intervals with a similar
    proportion of observations.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将变量值排序到具有相似观测比例的区间中。
- en: We used pandas `qcut()` to identify the interval limits from the train set and
    sort the values of the `HouseAge` variable into those intervals. Next, we passed
    those interval limits to pandas `cut()` to discretize `HouseAge` in the test set.
    Note that pandas `qcut()`, like pandas `cut()`, returned the interval values as
    ordered integers, which is the equivalent of ordinal encoding,
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 pandas 的 `qcut()` 从训练集中识别区间限制，并将 `HouseAge` 变量的值排序到这些区间中。接下来，我们将这些区间限制传递给
    pandas 的 `cut()`，以在测试集中对 `HouseAge` 进行离散化。请注意，pandas 的 `qcut()`，就像 pandas 的 `cut()`
    一样，返回区间值作为有序整数，这相当于顺序编码，
- en: Note
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: With equal-frequency discretization, many occurrences of values within a small
    continuous range could cause observations with very similar values, resulting
    in different intervals. The problem with this is that it can introduce artificial
    distinctions between data points that are actually quite similar in nature, biasing
    models or subsequent data analysis.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在等频率离散化中，小连续范围内值的许多出现可能导致具有非常相似值的观测值，从而产生不同的区间。这个问题在于，它可能会在实际上性质相当相似的数据点之间引入人为的区别，从而偏置模型或后续数据分析。
- en: With Feature-engine’s `EqualFrequencyDiscretiser()`, we discretized three variables
    into eight bins. With `fit()`, the discretizer learned the interval limits and
    stored them in the `binner_dict_` attribute. With `transform()`, the observations
    were allocated to the bins.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Feature-engine 的 `EqualFrequencyDiscretiser()`，我们将三个变量离散化到八个箱中。通过 `fit()`，离散化器学习了区间限制并将它们存储在
    `binner_dict_` 属性中。通过 `transform()`，观测值被分配到各个箱中。
- en: Note
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`EqualFrequencyDiscretiser()` returns an integer indicating whether the value
    was sorted into the first, second, or eighth bin by default. That is the equivalent
    of ordinal encoding, which we described in the *Replacing categories with ordinal
    numbers* recipe in [*Chapter 2*](B22396_02.xhtml#_idTextAnchor182), *Encoding*
    *Categorical Variables*.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`EqualFrequencyDiscretiser()` 返回一个整数，表示默认情况下值是否被排序到第一个、第二个或第八个箱中。这相当于顺序编码，我们在[*第2章*](B22396_02.xhtml#_idTextAnchor182)的*用顺序数字替换类别*食谱中描述过，*编码*
    *分类变量*。'
- en: To follow up the discretization with a different type of encoding, we can return
    the variables cast as objects by setting `return_object` to `True` and then use
    any of the `feature-engine` or `category encoders` transformers . Alternatively,
    we can return the interval limits, as we did in this recipe.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用不同类型的编码来跟进离散化，我们可以通过将 `return_object` 设置为 `True` 来返回作为对象的变量，然后使用任何 `feature-engine`
    或 `category encoders` 转换器。或者，我们可以返回区间限制，就像在这个食谱中所做的那样。
- en: Finally, we discretized variables into eight equal-frequency bins using `scikit-learn`’s
    `KBinsDiscretizer()`. With `fit()`, the transformer learned the cut points and
    stored them in its `bin_edges_` attribute. With `transform()`, it sorted the values
    into each interval. Note that, differently from `EqualFrequencyDiscretiser()`,
    `KBinsDiscretizer()` will transform all of the variables in the dataset. To avoid
    this, we only applied the discretizer on a slice of the data with the variables
    to modify.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用 `scikit-learn` 的 `KBinsDiscretizer()` 将变量离散化到八个等频率箱中。通过 `fit()`，转换器学习了切点并将它们存储在其
    `bin_edges_` 属性中。通过 `transform()`，它将值排序到每个区间中。请注意，与 `EqualFrequencyDiscretiser()`
    不同，`KBinsDiscretizer()` 将转换数据集中的所有变量。为了避免这种情况，我们只在需要修改变量的数据子集上应用离散化器。
- en: Note
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: scikit-learn’s `KbinsDiscretizer` has the option to return the intervals as
    ordinal numbers or one-hot encoded. The behavior can be modified through the `encode`
    parameter.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 的 `KbinsDiscretizer` 有一个选项可以返回作为顺序数字或独热编码的区间。可以通过 `encode` 参数修改行为。
- en: Discretizing the variable into arbitrary intervals
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将变量离散化到任意区间
- en: In various industries, it is common to group variable values into segments that
    make sense for the business. For example, we might want to group the variable
    age in intervals representing children, young adults, middle-aged people, and
    retirees. Alternatively, we might group ratings into bad, good, and excellent.
    On occasion, if we know that the variable is in a certain scale (for example,
    logarithmic), we might want to define the interval cut points within that scale.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在各个行业中，将变量值分组到对业务有意义的段是常见的。例如，我们可能希望将变量年龄分组到代表儿童、年轻人、中年人和退休人员的区间。或者，我们可能将评级分为差、好和优秀。有时，如果我们知道变量处于某个尺度（例如，对数尺度），我们可能希望在尺度内定义区间切点。
- en: In this recipe, we will discretize a variable into pre-defined user intervals
    using `pandas` and `feature-engine`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用 `pandas` 和 `feature-engine` 将变量离散化到预定义的用户区间。
- en: How to do it...
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人口值在0到大约40,000之间变化：
- en: 'First, let’s import the necessary Python libraries and get the dataset ready:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查原始变量和离散化变量的前五行：
- en: 'Import Python libraries and classes:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入Python库和类：
- en: '[PRE43]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Let’s load the California housing dataset into a `pandas` DataFrame:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将加利福尼亚住房数据集加载到`pandas` DataFrame中：
- en: '[PRE44]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let’s plot a histogram of the `Population` variable to find out its value range:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制`Population`变量的直方图以找出其值范围：
- en: '[PRE45]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Population values vary between 0 and approximately 40,000:'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.6 – Population变量的直方图](img/B22396_04_6.jpg)'
- en: "![Figure 4.6 – Histogram of the \uFEFFPopulation variable](img/B22396_04_6.jpg)"
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: 首先，让我们导入必要的Python库并准备好数据集：
- en: Figure 4.6 – Histogram of the Population variable
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 – Population变量的直方图
- en: 'Let’s create a list with arbitrary interval limits, setting the upper limit
    to infinity to accommodate bigger values:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个具有任意区间限制的列表，将上限设置为无穷大以适应更大的值：
- en: '[PRE46]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let’s create a list with the interval limits as strings:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个包含区间限制的字符串列表：
- en: '[PRE47]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Let’s make a copy of the dataset and discretize the `Population` variable into
    the pre-defined limits from *step 4*:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们复制数据集并使用*步骤4*中的预定义限制对`Population`变量进行离散化：
- en: '[PRE48]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, let’s discretize `Population` into pre-defined intervals and name the
    intervals with the labels that we defined in *step 5* for comparison:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将`Population`离散化到预定义的区间，并使用我们在*步骤5*中定义的标签来命名这些区间以进行比较：
- en: '[PRE49]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Let’s inspect the first five rows of the original and discretized variables:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何操作...
- en: '[PRE50]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'In the last two columns of the DataFrame, we can see the discretized variables:
    the first one with the strings that we created in *step 5* as values, and the
    second one with the interval limits:'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在DataFrame的最后两列中，我们可以看到离散化变量：第一个以我们在*步骤5*中创建的字符串作为值，第二个以区间限制作为值：
- en: '[PRE51]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Note
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We only need one of the variable versions, either the one with the value range
    or the one with the interval limits. In this recipe, I created both to highlight
    the different options offered by `pandas`.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要变量版本中的一个，无论是值范围还是区间限制。在这个菜谱中，我创建了两个来突出`pandas`提供的不同选项。
- en: 'Finally, we can count and plot the number of observations within each interval:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以计算并绘制每个区间内的观测数：
- en: '[PRE52]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'In the following figure, we can see that the number of observations per interval
    varies:'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下图中，我们可以看到每个区间的观测数不同：
- en: '![Figure 4.7 – The proportion of observations per interval after the discretization.](img/B22396_04_7.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![图4.7 – 离散化后每个区间的观测数比例](img/B22396_04_7.jpg)'
- en: Figure 4.7 – The proportion of observations per interval after the discretization.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7 – 离散化后每个区间的观测数比例。
- en: 'To wrap up the recipe, let’s discretize multiple variables utilizing `feature-engine`:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结这个菜谱，让我们利用`feature-engine`对多个变量进行离散化：
- en: 'Let’s import the transformer:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入转换器：
- en: '[PRE53]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Let’s create a dictionary with the variables as keys and the interval limits
    as values:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个字典，以变量作为键，以区间限制作为值：
- en: '[PRE54]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Let’s set up the discretizer with the limits from *step 11*:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用*步骤11*中的限制设置离散化器：
- en: '[PRE55]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Now, we can go ahead and discretize the variables:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以继续对变量进行离散化：
- en: '[PRE56]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'If we execute `X_t.head()`, we will see the following output, where the `Population`
    and `MedInc` variables have been discretized:'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们执行`X_t.head()`，我们将看到以下输出，其中`Population`和`MedInc`变量已被离散化：
- en: '![Figure 4.8 – A DataFrame containing the discretized variables](img/B22396_04_8.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图4.8 – 包含离散化变量的DataFrame](img/B22396_04_8.jpg)'
- en: Figure 4.8 – A DataFrame containing the discretized variables
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 – 包含离散化变量的DataFrame
- en: The advantage of using `feature-engine` is that we can discretize multiple variables
    at the same time and apply arbitrary discretization as part of a scikit-learn
    `Pipeline`.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查原始变量和离散化变量的前五行：
- en: How it works...
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人口值在0到大约40,000之间变化：
- en: 'In this recipe, we sorted the values of a variable into user-defined intervals.
    First, we plotted a histogram of the `Population` variable to get an idea of its
    value range. Next, we arbitrarily determined the limits of the intervals and captured
    them in a list. We created intervals that included 0–200, 200–500, 500–1000, 1000–2000,
    and more than 2,000 by setting the upper limit to infinite with `np.inf`. Next,
    we created a list with the interval names as strings. Using pandas `cut()` and
    passing the list with the interval limits, we sorted the variable values into
    the pre-defined bins. We executed the command twice; in the first run, we set
    the `labels` argument to `None`, returning the interval limits as a result. In
    the second run, we set the `labels` argument to the list of strings. We captured
    the returned output in two variables: the first one displays the interval limits
    as values and the second one has strings as values. Finally, we counted the number
    of observations per variable using pandas `value_counts()`.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将一个变量的值排序到用户定义的区间中。首先，我们绘制了`Population`变量的直方图，以了解其值范围。接下来，我们任意确定了区间的界限，并将它们记录在一个列表中。我们创建了包含0–200、200–500、500–1000、1000–2000以及超过2,000的区间，通过将上限设置为`np.inf`来表示无限大。然后，我们创建了一个包含区间名称的字符串列表。使用pandas的`cut()`函数并传递包含区间界限的列表，我们将变量值排序到预先定义的箱中。我们执行了两次命令；在第一次运行中，我们将`labels`参数设置为`None`，结果返回区间界限。在第二次运行中，我们将`labels`参数设置为字符串列表。我们将返回的输出捕获在两个变量中：第一个变量显示区间界限作为值，第二个变量具有字符串作为值。最后，我们使用pandas的`value_counts()`函数统计每个变量的观测数。
- en: Finally, we automated the procedure with `feature-engine`’s `ArbitraryDiscretiser()`.
    This transformer takes a dictionary with the variables to discretize as keys and
    the interval limits in a list as values, and then uses pandas `cut()` under the
    hood to discretize the variables. With `fit()`, the transformer does not learn
    any parameters but checks that the variables are numerical. With `transform()`,
    it discretizes the variables.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`feature-engine`的`ArbitraryDiscretiser()`函数自动化了该过程。这个转换器接受一个字典，其中包含要离散化的变量作为键，以及作为值的区间界限列表，然后在底层使用pandas的`cut()`函数来离散化变量。使用`fit()`时，转换器不会学习任何参数，但会检查变量是否为数值型。使用`transform()`时，它会离散化变量。
- en: Performing discretization with k-means clustering
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用k-means聚类进行离散化
- en: The aim of a discretization procedure is to find a set of cut points that partition
    a variable into a small number of intervals that have good class coherence. To
    create partitions that group similar observations, we can use clustering algorithms
    such as k-means.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 离散化过程的目标是找到一组切割点，将变量划分为具有良好类别一致性的少量区间。为了创建将相似观测值分组在一起的分区，我们可以使用k-means等聚类算法。
- en: In discretization using k-means clustering, the partitions are the clusters
    identified by the k-means algorithm. The k-means clustering algorithm has two
    main steps. In the initialization step, *k* observations are chosen randomly as
    the initial centers of the *k* clusters, and the remaining data points are assigned
    to the closest cluster. The proximity to the cluster is measured by a distance
    measure, such as the Euclidean distance. In the iteration step, the centers of
    the clusters are re-computed as the average of all of the observations within
    the cluster, and the observations are reassigned to the newly created closest
    cluster. The iteration step continues until the optimal *k* centers are found.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用k-means聚类进行离散化时，分区是由k-means算法识别的聚类。k-means聚类算法有两个主要步骤。在初始化步骤中，随机选择*k*个观测值作为*k*个聚类的初始中心，剩余的数据点被分配到最近的聚类中。聚类接近度是通过距离度量来衡量的，例如欧几里得距离。在迭代步骤中，聚类的中心被重新计算为聚类内所有观测值的平均值，观测值被重新分配到新创建的最近聚类。迭代步骤会继续进行，直到找到最优的*k*个中心。
- en: Discretization with k-means requires one parameter, which is *k*, the number
    of clusters. There are a few methods to determine the optimal number of clusters.
    One of them is the elbow method, which we will use in this recipe. This method
    consists of training several k-means algorithms over the data using different
    values of *k*, and then determining the explained variation returned by the clustering.
    In the next step, we plot the explained variation as a function of the number
    of clusters, *k*, and pick the *elbow* of the curve as the number of clusters
    to use. The elbow is the inflection point that indicates that increasing the number
    of *k* further does not significantly increase the variance explained by the model.
    There are different metrics to quantify the explained variation. We will use the
    sum of the square distances from each point to its assigned center.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 使用k-means进行离散化需要一个参数，即*k*，即聚类数量。有几种方法可以确定最佳聚类数量。其中之一是肘部法，我们将在本食谱中使用这种方法。该方法包括使用不同的*k*值在数据上训练几个k-means算法，然后确定聚类返回的解释变异。在下一步中，我们将解释变异作为聚类数量*k*的函数进行绘图，并选择曲线的*肘部*作为要使用的聚类数量。肘部是表明增加*k*的数量不会显著增加模型解释的变异的拐点。有不同指标可以量化解释变异。我们将使用每个点到其分配中心的平方距离之和。
- en: In this recipe, we will use the Python library `yellowbrick` to determine the
    optimal number of clusters and then carry out k-means discretization with scikit-learn.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将使用Python库`yellowbrick`来确定最佳聚类数量，然后使用scikit-learn执行k-means离散化。
- en: How to do it...
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let’s start by importing the necessary Python libraries and get the dataset
    ready:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先导入必要的Python库并准备好数据集：
- en: 'Import the required Python libraries and classes:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的Python库和类：
- en: '[PRE57]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Let’s load the California housing dataset into a `pandas` DataFrame:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将加利福尼亚住房数据集加载到`pandas` DataFrame中：
- en: '[PRE58]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The k-means optimal clusters should be determined using the train set, so let’s
    divide the data into train and test sets:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应该使用训练集来确定k-means最佳聚类，因此让我们将数据分为训练集和测试集：
- en: '[PRE59]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Let’s make a list with the variables to transform:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个包含要转换的变量的列表：
- en: '[PRE60]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Let’s set up a k-means clustering algorithm:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置一个k-means聚类算法：
- en: '[PRE61]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Now, using Yellowbrick’s visualizer and the elbow method, let’s find the optimal
    number of clusters for each variable:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用Yellowbrick的可视化器和肘部法，让我们找到每个变量的最佳聚类数量：
- en: '[PRE62]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'In the following plots, we see that the optimal number of clusters is six for
    the first two variables and seven for the third:'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下图中，我们可以看到前两个变量的最佳聚类数量为六，第三个为七：
- en: '![Figure 4.9 – The number of clusters versus the explained variation for the
    MedInc, HouseAge, and AveRooms variables, from top to bottom](img/B22396_04_9.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9 – 从上到下为MedInc、HouseAge和AveRooms变量的聚类数量与解释变异的关系](img/B22396_04_9.jpg)'
- en: Figure 4.9 – The number of clusters versus the explained variation for the MedInc,
    HouseAge, and AveRooms variables, from top to bottom
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9 – 从上到下为MedInc、HouseAge和AveRooms变量的聚类数量与解释变异的关系
- en: 'Let’s set up a discretizer that uses k-means clustering to create six partitions
    and returns the clusters as one-hot-encoded variables:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置一个使用k-means聚类创建六个分区并返回聚类作为独热编码变量的离散化器：
- en: '[PRE63]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Let’s fit the discretizer to the slice of the DataFrame that contains the variables
    to discretize so that it finds the clusters for each variable:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将离散化器拟合到包含要离散化变量的DataFrame切片，以便它为每个变量找到聚类：
- en: '[PRE64]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Note
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In this recipe, we sort the values of all three of the variables into six clusters.
    To discretize `MedInc` and `HouseAge` into six partitions and `AveRooms` into
    seven, we would set up one instance of the discretizer for each variable group
    and use the `ColumnTransformer()` to restrict the discretization to each group.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将所有三个变量的值排序到六个聚类中。要将`MedInc`和`HouseAge`离散化到六个分区，将`AveRooms`离散化到七个分区，我们需要为每个变量组设置一个离散化器实例，并使用`ColumnTransformer()`来限制离散化到每个组。
- en: 'Let’s inspect the cut points:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查切分点：
- en: '[PRE65]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Each array contains the cut points for the six clusters for `MedInc`, `HouseAge`,
    and `AveRooms`:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个数组包含`MedInc`、`HouseAge`和`AveRooms`六个聚类的切分点：
- en: '[PRE66]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Let’s obtain the discretized form of the variables in the train test sets:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从训练测试集中获取变量的离散化形式：
- en: '[PRE67]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'With `print(test_features)`, we can inspect the DataFrame that is returned
    by the discretizer. It contains 18 binary variables corresponding to the one-hot-encoded
    transformation of the six clusters returned for each of the three numerical variables:'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用 `print(test_features)`，我们可以检查离散化器返回的 DataFrame。它包含 18 个二进制变量，对应于每个三个数值变量返回的六个簇的一热编码转换：
- en: '[PRE68]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: You can concatenate the result to the original DataFrame using `pandas` and
    then drop the original numerical variables. Alternatively, use the `ColumnTransformer()`
    class to restrict the discretization to the selected variables and add the result
    to the data by setting `remainder` to `"passthrough"`.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 `pandas` 将结果连接到原始 DataFrame，然后删除原始数值变量。或者，使用 `ColumnTransformer()` 类将离散化限制为所选变量，并通过将
    `remainder` 设置为 `"passthrough"` 将结果添加到数据中。
- en: How it works...
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we performed discretization with k-means clustering. First,
    we identified the optimal number of clusters utilizing the elbow method by using
    Yellowbrick’s `KElbowVisualizer()`.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们使用 k-means 聚类进行了离散化。首先，我们通过使用 Yellowbrick 的 `KElbowVisualizer()` 利用肘部方法确定了最佳簇数量。
- en: To perform k-means discretization, we used scikit-learn’s `KBinsDiscretizer()`,
    setting `strategy` to `kmeans` and the number of clusters to six in the `n_bins`
    argument. With `fit()`, the transformer learned the cluster boundaries using the
    k-means algorithm. With `transform()`, it sorted the variable values to their
    corresponding cluster. We set `encode` to `"onehot-dense"`; hence, after the discretization,
    the transformer applied one-hot encoding to the clusters. We also set the output
    of the discretizer to `pandas`, and with that, the transformer returned the one-hot
    encoded version of the clustered variables as a DataFrame.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行 k-means 离散化，我们使用了 scikit-learn 的 `KBinsDiscretizer()`，将 `strategy` 设置为 `kmeans`，并在
    `n_bins` 参数中将簇的数量设置为六。使用 `fit()`，转换器通过 k-means 算法学习了簇边界。使用 `transform()`，它将变量值排序到相应的簇。我们将
    `encode` 设置为 `"onehot-dense"`；因此，在离散化后，转换器对簇应用了一热编码。我们还设置了离散化器的输出为 `pandas`，因此转换器返回了作为
    DataFrame 的聚类变量的一个热编码版本。
- en: See also
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: Discretization with k-means is described in the article found in *Palaniappan
    and Hong, Discretization of Continuous Valued Dimensions in OLAP Data Cube*s.
    International Journal of Computer Science and Network Security, VOL.8 No.11, November
    2008\. [http://paper.ijcsns.org/07_book/200811/20081117.pdf](http://paper.ijcsns.org/07_book/200811/20081117.pdf).
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 *Palaniappan 和 Hong, Discretization of Continuous Valued Dimensions in OLAP
    Data Cube* 文章中描述了使用 k-means 进行离散化。国际计算机科学和网络安全杂志，第 8 卷第 11 期，2008 年 11 月。[http://paper.ijcsns.org/07_book/200811/20081117.pdf](http://paper.ijcsns.org/07_book/200811/20081117.pdf)。
- en: To learn more about the elbow method, visit Yellowbrick’s documentation and
    references at [https://www.scikit-yb.org/en/latest/api/cluster/elbow.html](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html).
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要了解更多关于肘部方法的信息，请访问 Yellowbrick 的文档和参考资料：[https://www.scikit-yb.org/en/latest/api/cluster/elbow.html](https://www.scikit-yb.org/en/latest/api/cluster/elbow.html)。
- en: For other ways of determining the fit of k-means clustering, check out the additional
    visualizers in Yellowbrick at [https://www.scikit-yb.org/en/latest/api/cluster/index.html](https://www.scikit-yb.org/en/latest/api/cluster/index.html).
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要了解确定 k-means 聚类拟合的其他方法，请查看 Yellowbrick 中的其他可视化工具：[https://www.scikit-yb.org/en/latest/api/cluster/index.html](https://www.scikit-yb.org/en/latest/api/cluster/index.html)。
- en: Implementing feature binarization
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现特征二值化
- en: Some datasets contain sparse variables. Sparse variables are those where the
    majority of the values are 0\. The classical example of sparse variables are those
    derived from text data through the bag-of-words model, where each variable is
    a word and each value represents the number of times the word appears in a certain
    document. Given that a document contains a limited number of words, whereas the
    feature space contains the words that appear across all documents, most documents,
    that is, most rows, will show a value of 0 for most columns. However, words are
    not the sole example. If we think about house details data, the *number of saunas*
    variable will also be 0 for most houses. In summary, some variables have very
    skewed distributions, where most observations show the same value, usually 0,
    and only a few observations show different, usually higher, values.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据集包含稀疏变量。稀疏变量是指大多数值都是0的变量。稀疏变量的经典例子是通过词袋模型从文本数据中得到的，其中每个变量是一个单词，每个值代表单词在某个文档中出现的次数。鉴于一个文档包含有限数量的单词，而特征空间包含所有文档中出现的单词，大多数文档，即大多数行，对于大多数列将显示0值。然而，单词并不是唯一的例子。如果我们考虑房屋细节数据，*桑拿数量*变量对于大多数房屋也将是0。总之，一些变量具有非常偏斜的分布，其中大多数观测值显示相同的值，通常是0，而只有少数观测值显示不同的值，通常是更高的值。
- en: For a simpler representation of these sparse or highly skewed variables, we
    can binarize them by clipping all values greater than 1 to 1\. In fact, binarization
    is commonly performed on text count data, where we consider the presence or absence
    of a feature rather than a quantified number of occurrences of a word.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更简单地表示这些稀疏或高度偏斜的变量，我们可以通过将所有大于1的值裁剪为1来对它们进行二值化。实际上，二值化通常在文本计数数据上执行，我们考虑的是特征的缺失或存在，而不是单词出现次数的量化。
- en: In this recipe, we will perform binarization using `scikit-learn`.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将使用`scikit-learn`执行二值化。
- en: Getting ready
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use a dataset consisting of a bag of words, which is available in the
    UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Bag+of+Words).
    It is licensed under CC BY 4.0 ([https://creativecommons.org/licenses/by/4.0/legalcode](https://creativecommons.org/licenses/by/4.0/legalcode)).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个包含单词袋的数据集，该数据集可在 UCI 机器学习仓库（https://archive.ics.uci.edu/ml/datasets/Bag+of+Words）中找到。它受
    CC BY 4.0 许可（[https://creativecommons.org/licenses/by/4.0/legalcode](https://creativecommons.org/licenses/by/4.0/legalcode)）。
- en: 'I downloaded and prepared a small bag of words representing a simplified version
    of one of those datasets. You will find this dataset in the accompanying GitHub
    repository:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我下载并准备了一个小型的单词袋数据集，它代表了一个数据集的简化版本。您可以在附带的 GitHub 仓库中找到这个数据集：
- en: https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/tree/main/ch04-discretization
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/tree/main/ch04-discretization](https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Third-Edition/tree/main/ch04-discretization)'
- en: How to do it...
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let’s begin by importing the libraries and loading the data:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先导入库并加载数据：
- en: 'Let’s import the required Python libraries, classes, and datasets:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入所需的 Python 库、类和数据集：
- en: '[PRE69]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Let’s load the bag of words dataset, which contains words as columns and different
    texts as rows:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们加载数据集，该数据集包含单词作为列，不同的文本作为行：
- en: '[PRE70]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Let’s display histograms to visualize the sparsity of the variables:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们显示直方图以可视化变量的稀疏性：
- en: '[PRE71]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'In the following histograms, we can see that the different words appear zero
    times in most documents:'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下直方图中，我们可以看到不同的单词在大多数文档中出现的次数为零：
- en: "![Figure 4.10 – Histograms representing th\uFEFFe number of times each word\
    \ appears in a document](img/B22396_04_10.jpg)"
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.10 – 表示每个单词在文档中出现的次数的直方图](img/B22396_04_10.jpg)'
- en: Figure 4.10 – Histograms representing the number of times each word appears
    in a document
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 表示每个单词在文档中出现的次数的直方图
- en: 'Let’s set up `binarizer` to clip all values greater than 1 to 1 and return
    DataFrames as a result:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置`binarizer`以裁剪所有大于1的值到1，并返回结果为 DataFrames：
- en: '[PRE72]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Let’s binarize the variables:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们二值化变量：
- en: '[PRE73]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Now we can explore the distribution of the binarized variables by displaying
    the histograms as in *step 3*, or better, by creating bar plots.
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们可以通过显示直方图来探索二值化变量的分布，就像在*步骤 3*中那样，或者更好，通过创建条形图。
- en: 'Let’s create a bar plot with the number of observations per bin per variable:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个条形图，显示每个变量的每个箱中的观测数：
- en: '[PRE74]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'In the following plot, we can see the binarized variables, where most occurrences
    show the `0` value:'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在下面的图表中，我们可以看到二值化变量，其中大多数出现次数显示的是`0`值：
- en: "![Figure 4.11 – Bar plots containing the number of documents that eithe\uFEFF\
    r show each one of the words or not](img/B22396_04_11.jpg)"
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图4.11 – 包含显示或不显示每个单词的文档数量的条形图](img/B22396_04_11.jpg)'
- en: Figure 4.11 – Bar plots containing the number of documents that either show
    each one of the words or not
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11 – 包含显示或不显示每个单词的文档数量的条形图
- en: That’s it; now we have a simpler representation of the data.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样；现在我们有了数据的一个更简单的表示。
- en: How it works…
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we changed the representation of sparse variables to consider
    the presence or absence of an occurrence, which, in our case, is a word. The data
    consisted of a bag of words, where each variable (column) is a word, each row
    is a document, and the values represent the number of times the word appears in
    a document. Most words do not appear in most documents; therefore, most values
    in the data are 0\. We corroborated the sparsity of our data with histograms.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将稀疏变量的表示方式改为考虑出现的存在或不存在，在我们的案例中，这是一个单词。数据由一个词袋组成，其中每个变量（列）是一个单词，每行是一个文档，值表示单词在文档中出现的次数。大多数单词不会出现在大多数文档中；因此，数据中的大多数值都是0。我们通过直方图证实了数据的稀疏性。
- en: scikit-learn’s `Binarizer()` mapped values greater than the threshold, which,
    in our case, was 0, to the `1` value, while values less than or equal to the threshold
    were mapped to 0\. `Binarizer()` has the `fit()` and `transform()` methods, where
    `fit()` does not do anything and `transform()` binarizes the variables.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn的`Binarizer()`将大于阈值的值映射到`1`，在我们的案例中，这个阈值是0，而小于或等于阈值的值被映射到0。`Binarizer()`有`fit()`和`transform()`方法，其中`fit()`不做任何事情，而`transform()`对变量进行二值化。
- en: '`Binarizer()` modifies all variables in a dataset returning NumPy arrays by
    default. To return `pandas` DataFrames instead, we set the transform output to
    `pandas`.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '`Binarizer()`默认通过NumPy数组修改数据集中的所有变量。要返回`pandas`数据框，我们将转换输出设置为`pandas`。'
- en: Using decision trees for discretization
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用决策树进行离散化
- en: In all previous recipes in this chapter, we determined the number of intervals
    arbitrarily, and then the discretization algorithm would find the interval limits
    one way or another. Decision trees can find the interval limits and the optimal
    number of bins automatically.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的所有先前配方中，我们任意确定区间的数量，然后离散化算法会以某种方式找到区间界限。决策树可以自动找到区间界限和最优的箱数。
- en: Decision tree methods discretize continuous attributes during the learning process.
    At each node, a decision tree evaluates all possible values of a feature and selects
    the cut point that maximizes the class separation, or sample coherence, by utilizing
    a performance metric such as entropy or Gini impurity for classification, or the
    squared or absolute error for regression. As a result, the observations end up
    in certain leaves based on whether their feature values are greater or smaller
    than certain cut points.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树方法在学习过程中对连续属性进行离散化。在每个节点，决策树评估一个特征的所有可能值，并通过利用性能指标（如熵或基尼不纯度用于分类，或平方或绝对误差用于回归）选择最大化类别分离或样本一致性的切割点。因此，观察结果根据它们的特征值是否大于或小于某些切割点而最终落在某些叶子节点上。
- en: 'In the following figure, we can see the diagram of a decision tree that is
    trained to predict house prices based on the property’s average number of rooms:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图中，我们可以看到训练用来根据房产的平均房间数预测房价的决策树的图：
- en: '![Figure 4.12 – A diagram of a decision tree trained to predict house price
    based on the property’s average number of rooms](img/B22396_04_12.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![图4.12 – 基于房产平均房间数预测房价的决策树图](img/B22396_04_12.jpg)'
- en: Figure 4.12 – A diagram of a decision tree trained to predict house price based
    on the property’s average number of rooms
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 – 基于房产平均房间数预测房价的决策树图
- en: Based on this decision tree, houses with a smaller mean number of rooms than
    5.5 will go to the first leaf, houses with a mean number of rooms between 5.5
    and 6.37 will fall into the second leaf, houses with mean values between 6.37
    and 10.77 will end up in the third leaf, and houses with mean values greater than
    10.77 will land in the fourth leaf.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此决策树，平均房间数小于5.5的房屋将进入第一个叶子节点，平均房间数在5.5到6.37之间的房屋将进入第二个叶子节点，平均房间数在6.37到10.77之间的房屋将进入第三个叶子节点，平均房间数大于10.77的房屋将进入第四个叶子节点。
- en: As you see, by design, decision trees can find the set of cut points that partition
    a variable into intervals with good class coherence.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，按照设计，决策树可以找到将变量分割成具有良好类别一致性的区间的切割点集。
- en: In this recipe, we will perform decision tree-based discretization using Feature-engine.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用Feature-engine执行基于决策树的离散化。
- en: How to do it...
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let’s begin by importing some libraries and loading the data:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从导入一些库和加载数据开始：
- en: 'Let’s import the required Python libraries, classes, and datasets:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入所需的Python库、类和数据集：
- en: '[PRE75]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Let’s load the California housing dataset into a `pandas` DataFrame and then
    split it into train and test sets:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将加利福尼亚住房数据集加载到`pandas` DataFrame中，然后将其拆分为训练集和测试集：
- en: '[PRE76]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Let’s make a list with the names of the variables to discretize:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们创建一个包含要离散化变量名的列表：
- en: '[PRE77]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'If we execute `print(variables)`, we’ll see the following variable names: `[''MedInc''`,
    `''HouseAge''`, `''AveRooms''`, `''AveBedrms''`, `''``Population''`, `''AveOccup'']`.'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们执行 `print(variables)`，我们将看到以下变量名：`['MedInc'`, `'HouseAge'`, `'AveRooms'`,
    `'AveBedrms'`, `'Population'`, `'AveOccup']`。
- en: 'Let’s set up the transformer to discretize the variables from *step 3*. We
    want the transformer to optimize the hyperparameter’s maximum depth and minimum
    samples per leaf of each tree based on the negative mean square error metric using
    three-fold cross-validation. As the output of the discretization, we want the
    limits of the intervals:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置转换器来离散化第3步中的变量。我们希望转换器根据三折交叉验证的负均方误差指标优化每个树的超参数的最大深度和每个叶子的最小样本数。我们希望离散化的输出是区间的限制：
- en: '[PRE78]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Let’s fit the discretizer using the train set so that it finds the best decision
    trees for each of the variables:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用训练集来拟合离散化器，以便它为每个变量找到最佳的决策树：
- en: '[PRE79]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Note
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can inspect the limits of the found intervals for each variable in the `binner_dict_`
    attribute by executing `disc.binner_dict_`. Note how the discretizer appended
    minus and plus infinity to the limits to accommodate smaller and greater values
    than those observed in the training set.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过执行 `disc.binner_dict_` 来检查每个变量在`binner_dict_`属性中找到的区间限制。注意离散化器如何将负无穷和正无穷添加到限制中，以适应训练集中观察到的较小和较大的值。
- en: 'Let’s discretize the variables and then display the first five rows of the
    transformed training set:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们离散化变量，然后显示转换训练集的前五行：
- en: '[PRE80]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'In the following output, we can see the limits of the intervals to which each
    observation was allocated:'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下输出中，我们可以看到每个观测值分配的区间限制：
- en: '![Figure 4.13 – The first five rows of the transformed training set containing
    the discretized variables](img/B22396_04_13.jpg)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![图4.13 – 包含离散化变量的转换训练集的前五行](img/B22396_04_13.jpg)'
- en: Figure 4.13 – The first five rows of the transformed training set containing
    the discretized variables
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13 – 包含离散化变量的转换训练集的前五行
- en: Note
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you choose to return the interval limits and want to use these datasets to
    train machine learning models, you will need to follow up the discretization with
    one-hot encoding or ordinal encoding. Check the recipes in [*Chapter 2*](B22396_02.xhtml#_idTextAnchor182),
    *Encoding Categorical Variables*, for more details.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择返回区间限制并想使用这些数据集来训练机器学习模型，你需要对离散化进行后续的一热编码或序数编码。请参阅[*第2章*](B22396_02.xhtml#_idTextAnchor182)，“分类变量编码”，以获取更多详细信息。
- en: 'Instead of returning the interval limits, we can return the interval number
    to which each observation is allocated by setting up the transformer like this:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 而不是返回区间限制，我们可以通过设置转换器如下来返回每个观测值分配的区间编号：
- en: '[PRE81]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'We can now fit and then transform the training and testing sets:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以拟合并转换训练集和测试集：
- en: '[PRE82]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'If you now execute `train_t[variables].head()`, you will see integers as a
    result instead of the interval limits:'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你现在执行 `train_t[variables].head()`，你将看到整数作为结果而不是区间限制：
- en: '![Figure 4.14 – The first five rows of the transformed training set containing
    the discretized variables](img/B22396_04_14.jpg)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![图4.14 – 包含离散化变量的转换训练集的前五行](img/B22396_04_14.jpg)'
- en: Figure 4.14 – The first five rows of the transformed training set containing
    the discretized variables
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14 – 包含离散化变量的转换训练集的前五行
- en: 'To wrap up the recipe, we will make the discretizer return the predictions
    of the trees as replacement values for the discretized variables:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结这个菜谱，我们将使离散化器返回树的预测作为离散化变量的替换值：
- en: 'Let’s set up the transformer to return the predictions, then fit it to the
    training set, and finally transform both datasets:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置转换器以返回预测，然后将其拟合到训练集，并最终转换两个数据集：
- en: '[PRE83]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Let’s explore the number of unique values of the `AveRooms` variable before
    and after the discretization:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们探索 `AveRooms` 变量在离散化前后的唯一值数量：
- en: '[PRE84]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'In the following output, we can see that the predictions of the decision trees
    are also discrete or finite because the trees contain a finite number of end leaves;
    `7`, while the original variable contained more than 6000 different values:'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在以下输出中，我们可以看到决策树的预测也是离散的或有限的，因为树包含有限数量的终端叶子；`7`，而原始变量包含超过 6000 个不同的值：
- en: '[PRE85]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'To better understand the structure of the tree, we can capture it into a variable:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了更好地理解树的结构，我们可以将其捕获到一个变量中：
- en: '[PRE86]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: Note
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When we set the transformer to return integers or bin limits, we will obtain
    the bin limits in the `binner_dict_` attribute. If we set the transformer to return
    the tree predictions, `binner_dict_` will contain the trained tree for each variable.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将转换器设置为返回整数或区间限制时，我们将在 `binner_dict_` 属性中获得区间限制。如果我们设置转换器以返回树预测，`binner_dict_`
    将包含每个变量的训练树。
- en: 'Now, we can display the tree structure:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以显示树结构：
- en: '[PRE87]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'In the following figure, we can see the values used by the tree to allocate
    samples to the different end leaves based on the mean number of rooms:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下图中，我们可以看到树根据房间数量的平均值将样本分配到不同的终端叶子所使用的值：
- en: '![Figure 4.15 – The structure of the decision tree trained to discretize AveRooms](img/B22396_04_15.jpg)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.15 – 训练用于离散化 AveRooms 的决策树结构](img/B22396_04_15.jpg)'
- en: Figure 4.15 – The structure of the decision tree trained to discretize AveRooms
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15 – 训练用于离散化 AveRooms 的决策树结构
- en: 'To wrap up the recipe, we can plot the number of observations per bin for three
    of the variables:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了总结这个方法，我们可以绘制三个变量的每个区间的观察值数量：
- en: '[PRE88]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'We can see the number of observations per bin in the following output:'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以在以下输出中看到每个区间的观察值数量：
- en: "![Figure 4.16 – The proportion of observations \uFEFFper bin after discretizing\
    \ the variables with decision trees](img/B22396_04_16.jpg)"
  id: totrans-382
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.16 – 使用决策树离散化变量后的每个区间的观察值比例](img/B22396_04_16.jpg)'
- en: Figure 4.16 – The proportion of observations per bin after discretizing the
    variables with decision trees
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.16 – 使用决策树离散化变量后的每个区间的观察值比例
- en: As evidenced in the plots, discretization with decision trees returns a different
    fraction of observations at each node or bin.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，使用决策树进行离散化会在每个节点或区间返回不同的观察值比例。
- en: How it works...
  id: totrans-385
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'To perform discretization with decision trees, we used f`eature-engine`’s `Decision``     TreeDiscretiser()`. This transformer fitted a decision tree using each variable
    to discretize as input and optimized the hyperparameters of the model to find
    the best partitions based on a performance metric. It automatically found the
    optimal number of intervals, as well as their limits, returning either the limits,
    the bin number, or the predictions as a result.'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用决策树进行离散化，我们使用了 `feature-engine` 的 `DecisionTreeDiscretiser()`。这个转换器使用每个变量作为离散化的输入来拟合决策树，并优化模型的超参数以找到基于性能指标的最佳分区。它自动找到了最佳区间数量以及它们的限制，并返回限制、区间编号或预测作为结果。
- en: There’s more...
  id: totrans-387
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容...
- en: The implementation of `feature-engine` is inspired by the winning solution of
    the KDD 2009 data science competition. The winners created new features by obtaining
    predictions of decision trees based on continuous features. You can find more
    details in the *Winning the KDD Cup Orange Challenge with Ensemble Selection*
    article on *page 27* of the article series at [http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf](http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf).
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '`feature-engine` 的实现灵感来源于 KDD 2009 数据科学竞赛的获胜方案。获胜者通过基于连续特征获取决策树的预测来创建新特征。您可以在《使用集成选择赢得
    KDD Cup Orange 挑战赛》一文中找到更多详细信息，该文章系列位于 [http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf](http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf)
    的第 27 页。'
- en: 'For a review of discretization techniques, you might find the following articles
    useful:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回顾离散化技术，您可能会发现以下文章很有用：
- en: 'Dougherty et al, *Supervised and Unsupervised Discretization of Continuous
    Features, Machine Learning: Proceedings of the 12th International Conference*,
    1995, ([https://ai.stanford.edu/~ronnyk/disc.pdf](https://ai.stanford.edu/~ronnyk/disc.pdf)).'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dougherty 等人，*监督和非监督连续特征离散化，机器学习：第12届国际会议论文集*，1995年，([https://ai.stanford.edu/~ronnyk/disc.pdf](https://ai.stanford.edu/~ronnyk/disc.pdf))。
- en: 'Lu et al, *Discretization: An Enabling Technique, Data Mining, and Knowledge
    Discovery*, 6, 393–423, 2002, ([https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique](https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique)).'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lu 等人，*离散化：一种使能技术，数据挖掘与知识发现*，第6卷，第393–423页，2002年，([https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique](https://www.researchgate.net/publication/220451974_Discretization_An_Enabling_Technique))。
- en: 'Garcia et al, *A Survey of Discretization Techniques: Taxonomy and Empirical
    Analysis in Supervised Learning, IEEE Transactions on Knowledge in Data Engineering
    25 (4)*, 2013, ([https://ieeexplore.ieee.org/document/6152258](https://ieeexplore.ieee.org/document/6152258)).'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garcia 等人，*离散化技术综述：监督学习中的分类和实证分析，IEEE 知识数据工程杂志 25 (4)*，2013年，([https://ieeexplore.ieee.org/document/6152258](https://ieeexplore.ieee.org/document/6152258))。
