- en: Chapter 6. Filtering the Images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Filtering images using low-pass filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering images using a median filter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying directional filters to detect edges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing the Laplacian of an image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Filtering is one of the fundamental tasks in signal and image processing. It
    is a process aimed at selectively extracting certain aspects of an image that
    are considered to convey important information in the context of a given application.
    Filtering removes noise in images, extracts interesting visual features, allows
    image resampling, and so on. It finds its roots in the general **Signals and Systems**
    theory. We will not cover this theory in detail here. However, this chapter will
    present some of the important concepts related to filtering and will show you
    how filters can be used in image-processing applications. But first, let's begin
    with a brief explanation of the concept of frequency domain analysis.
  prefs: []
  type: TYPE_NORMAL
- en: When we look at an image, we observe how the different gray-levels (or colors)
    are distributed over the image. Images differ from each other because they have
    a different gray-level distribution. However, there exists another point of view
    under which an image can be analyzed. We can look at the gray-level variations
    that are present in an image. Some images contain large areas of almost constant
    intensity (for example, a blue sky) while in other images, the gray-level intensities
    vary rapidly over the image (for example, a busy scene crowded with many small
    objects). Therefore, observing the frequency of these variations in an image constitutes
    another way of characterizing an image. This point of view is referred to as the
    **frequency domain**, while characterizing an image by observing its gray-level
    distribution is referred to as the **spatial domain**.
  prefs: []
  type: TYPE_NORMAL
- en: The frequency domain analysis decomposes an image into its frequency content
    from the lowest to the highest frequencies. Areas where the image intensities
    vary slowly contain only low frequencies, while high frequencies are generated
    by rapid changes in intensities. Several well-known transformations exist, such
    as the Fourier transform or the Cosine transform, which can be used to explicitly
    show the frequency content of an image. Note that since an image is a two-dimensional
    entity, it is made of both vertical frequencies (variations in the vertical directions)
    and horizontal frequencies (variations in the horizontal directions).
  prefs: []
  type: TYPE_NORMAL
- en: Under the frequency domain analysis framework, a **filter** is an operation
    that amplifies certain bands of frequencies of an image while blocking (or reducing)
    other image frequency bands. A low-pass filter is, therefore, a filter that eliminates
    the high-frequency components of an image and reciprocally, a high-pass filter
    eliminates the low-pass components. This chapter will present some filters that
    are frequently used in image processing and will explain their effect when applied
    on an image.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering images using low-pass filters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this first recipe, we will present some very basic low-pass filters. In the
    introductory section of this chapter, we learned that the objective of such filters
    is to reduce the amplitude of the image variations. One simple way to achieve
    this goal is to replace each pixel by the average value of the pixels around it.
    By doing this, the rapid intensity variations will be smoothed out and thus replaced
    by a more gradual transition.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The objective of the `cv::blur` function is to smooth an image by replacing
    each pixel with the average pixel value computed over a rectangular neighborhood.
    This low-pass filter is applied as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This kind of filter is also called a box filter. Here, we applied it by using
    a `5x5` filter in order to make the filter''s effect more visible. Take a look
    at the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00074.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The result of the filter being applied on the preceding image is the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00075.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In some cases, it might be desirable to give more importance to the closer
    pixels in the neighborhood of a pixel. Therefore, it is possible to compute a
    weighted average in which nearby pixels are assigned a larger weight than ones
    that are further away. This can be achieved by using a weighted scheme that follows
    a Gaussian function (a "bell-shaped" function). The `cv::GaussianBlur` function
    applies such a filter and it is called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is then shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00076.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A filter is said to be linear if its application corresponds to replacing a
    pixel with a weighted sum of neighboring pixels. This is the case of the mean
    filter in which a pixel is replaced by the sum of all pixels in a rectangular
    neighborhood and divided by the size of this neighborhood (to get the average
    value). This is like multiplying each neighboring pixel by `1` over the total
    number of pixels and summing all of these values. The different weights of a filter
    can be represented using a matrix that shows the multiplying factors associated
    with each pixel position in the considered neighborhood. The central element of
    the matrix corresponds to the pixel on which the filter is currently applied.
    Such a matrix is sometimes called a **kernel** or a **mask**. For a `3x3` mean
    filter, the corresponding kernel would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1/9 | 1/9 | 1/9 |'
  prefs: []
  type: TYPE_TB
- en: '| 1/9 | 1/9 | 1/9 |'
  prefs: []
  type: TYPE_TB
- en: '| 1/9 | 1/9 | 1/9 |'
  prefs: []
  type: TYPE_TB
- en: The `cv::boxFilter` function filters an image with a square kernel made of many
    `1` only. It is similar to the mean filter but without dividing the result by
    the number of coefficients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Applying a linear filter then corresponds to moving a kernel over each pixel
    of an image and multiplying each corresponding pixel by its associated weight.
    Mathematically, this operation is called a **convolution** and can formally be
    written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00077.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding double summation aligns the current pixel at (x,y) with the center
    of the K kernel, which is assumed to be at coordinate (0,0).
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the output images produced in this recipe, it can be observed that
    the net effect of a low-pass filter is to blur or smooth the image. This is not
    surprising since this filter attenuates the high-frequency components that correspond
    to the rapid variations visible on an object's edge.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of a Gaussian filter, the weight associated with a pixel is proportional
    to its distance from the central pixel. Recall that the 1D Gaussian function has
    the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00078.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The normalizing coefficient A is chosen such that the different weights sum
    to one. The σ (sigma) value controls the width of the resulting Gaussian function.
    The greater this value is, the flatter the function will be. For example, if we
    compute the coefficients of the 1D Gaussian filter for the interval [-4, 0, 4]
    with σ = 0.5, we obtain the following coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For σ=1.5, these coefficients are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that these values were obtained by calling the `cv::getGaussianKernel`
    function with the appropriate σ value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The symmetrical bell shape of the Gaussian function makes it a good choice
    for filtering. Refer to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00079.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Pixels farther from the center have a lower weight, which makes the pixel-to-pixel
    transitions smoother. This contrasts with the flat mean filter where pixels far
    away can cause sudden changes in the current mean value. In terms of frequencies,
    this implies that the mean filter does not remove all the high frequency components.
  prefs: []
  type: TYPE_NORMAL
- en: To apply a 2D Gaussian filter on an image, one can simply apply a 1D Gaussian
    filter on the image lines first (to filter the horizontal frequencies), followed
    by the application of another 1D Gaussian filter on the image columns (to filter
    the vertical frequencies). This is possible because the Gaussian filter is a separable
    filter (that is, the 2D kernel can be decomposed into two 1D filters). The `cv::sepFilter2D`
    function can be used to apply a general separable filter. It is also possible
    to directly apply a 2D kernel using the `cv::filter2D` function. In general, separable
    filters are faster to compute than non-separable ones because they require less
    multiplication operations.
  prefs: []
  type: TYPE_NORMAL
- en: With OpenCV, the Gaussian filter to be applied on an image is specified by providing
    both the number of coefficients (the third parameter, which is an odd number)
    and the value of σ (the fourth parameter) to `cv::GaussianBlur`. You can also
    simply set the value of σ and let OpenCV determine the appropriate number of coefficients
    (you then input a value of `0` for the filter size). The opposite is also possible,
    where you input a size and a value of `0` for σ. The σ value that best fits the
    given size will be determined.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Low-pass filters are also used when an image is resized; this section explains
    why. The resizing of an image might also require interpolating pixel value; this
    aspect is also discussed in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Downsampling an image
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You might think that you can reduce the size of an image by simply eliminating
    some of the columns and rows of the image. Unfortunately, the resulting image
    will not look very nice. The following figure illustrates this fact by showing
    you a test image that is reduced by a factor of `4` with respect to its original
    size by simply keeping `1` of every `4` columns and rows. Note that to make the
    defects in this image more apparent, we zoom in on the image by displaying it
    with pixels that are two times larger (the next section explains how this can
    be done). Refer to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Downsampling an image](img/00080.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Clearly, one can see that the image quality has degraded. For example, the oblique
    edges of the castle's roof in the original image now appear as a staircase on
    the reduced image. Other jagged distortions are also visible on the textured parts
    of the image (the brick walls, for instance).
  prefs: []
  type: TYPE_NORMAL
- en: 'These undesirable artifacts are caused by a phenomenon called **spatial aliasing**
    that occurs when you try to include high-frequency components in an image that
    is too small to contain them. Indeed, smaller images (that is, images with fewer
    pixels) cannot represent fine textures and sharp edges as nicely as the higher
    resolution images (think of the difference between high-definition TV versus conventional
    TV). Since fine details in an image correspond to high frequencies, we need to
    remove these higher frequency components in an image before reducing its size.
    We learned in this recipe that this can be done through a low-pass filter. Consequently,
    to reduce the size of an image by `4` without adding annoying artifacts, you must
    first apply a low-pass filter to the original image before throwing away columns
    and rows. Here is how you would do this using OpenCV:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Downsampling an image](img/00081.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Of course, some of the fine details of the image have been lost, but globally,
    the visual quality of the image is better preserved than in the previous case.
  prefs: []
  type: TYPE_NORMAL
- en: 'A special OpenCV function also performs image reduction. This is the `cv::pyrDown`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The preceding function uses a `5x5` Gaussian filter to low-pass the image before
    reducing it by a factor of two. The reciprocal `cv::pyrUp` function that doubles
    the size of an image also exists. It is interesting to note that in this case,
    the upsampling is done by inserting the `0` values between every two columns and
    rows and then by applying the same `5x5` Gaussian filter (but with the coefficients
    multiplied by `4`) on the expanded image. Obviously, if you downsize an image
    and then upsize it, you will not recover the exact original image. What was lost
    during the downsizing process cannot be recovered. These two functions are used
    to create **image pyramids**. This is a data structure made of stacked versions
    of an image at different sizes (here, each level is 2 times smaller than the previous
    level, but the reduction factor can be less, for example, `1.2`) that is often
    built for efficient image analysis. For example, if you want to detect an object
    in an image, the detection can be first accomplished on the small image at the
    top of the pyramid, and as you locate the object of interest, you can refine the
    search by moving to the lower levels of the pyramid that contains the higher resolution
    versions of the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that there is also a more general `cv::resize` function that allows you
    to specify the size you want for the resulting image. You simply call it by specifying
    a new size that could be smaller or larger than the original image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also possible to specify resizing in terms of scale factors. In this
    case, an empty size instance is given as an argument followed by the desired scale
    factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: A last parameter allows you to select the interpolation method that is to be
    used in the resampling process. This is discussed in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Interpolating pixel values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When an image is resized by a factional factor, it becomes necessary to perform
    some pixel interpolation in order to produce new pixel values at locations that
    fall in between the existing ones. General image remapping, as discussed in the
    *Remapping an image* recipe of [Chapter 2](part0019_split_000.html#page "Chapter 2. Manipulating
    Pixels"), *Manipulating Pixels*, is another situation where pixel interpolation
    is required.
  prefs: []
  type: TYPE_NORMAL
- en: The most basic approach to perform interpolation is to use a **nearest neighbor
    strategy**. The new grid of pixels that must be produced is placed on top of the
    existing image, and each new pixel is assigned the value of its closest pixel
    in the original image. In the case of image upsampling (that is, when using a
    new grid denser than the original one), this implies that more than one pixel
    of the new grid will receive its value from the same original pixel.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we rescale the reduced image of the previous section by `3`
    using nearest neighbor interpolation (which is done by using the interpolation
    flag `cv::INTER_NEAREST`), we obtain the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interpolating pixel values](img/00082.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this case, the interpolation corresponds to simply multiplying the size
    of each pixel by `3` (this is how we produced the images of the previous section).
    A better approach consists of interpolating a new pixel value by combining the
    values of several neighboring pixels. Hence, we can linearly interpolate a pixel
    value by considering the four pixels around it, as illustrated by the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interpolating pixel values](img/00083.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This is done by first vertically interpolating two pixel values to the left-
    and right-hand side of the added pixel. Then, these two interpolated pixels (drawn
    in gray in the preceding figure) are used to horizontally interpolate the pixel
    value at the desired location. This bilinear interpolation scheme is the default
    approach used by `cv::resize` (that can also be explicitly specified by the flag
    `cv::INTER_LINEAR`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interpolating pixel values](img/00084.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There also exist other approaches that can produce superior results. With **bicubic
    interpolation**, a neighborhood of `4x4` pixels is considered to perform the interpolation.
    However, since the approach uses more pixels and implies the computation of cubic
    terms, it is slower than bilinear interpolation.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *There's more…* section of the *Scanning an image with neighbor access*
    recipe in [Chapter 2](part0019_split_000.html#page "Chapter 2. Manipulating Pixels"),
    *Manipulating Pixels*, introduces the `cv::filter2D` function. This function lets
    you apply a linear filter to an image by inputting the kernel of your choice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering images using a median filter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first recipe of this chapter introduced the concept of linear filters. Non-linear
    filters also exist and can be advantageously used in image processing. One such
    filter is the median filter that we present in this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since median filters are particularly useful in order to combat salt-and-pepper
    noise (or salt-only, in our case), we will use the image we created in the first
    recipe of [Chapter 2](part0019_split_000.html#page "Chapter 2. Manipulating Pixels"),
    *Manipulating Pixels*, and that is reproduced here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Filtering images using a median filter](img/00085.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The call to the median filtering function is done in a way that is similar
    to the other filters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00086.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since the median filter is not a linear filter, it cannot be represented by
    a kernel matrix. However, it also operates on a pixel's neighborhood in order
    to determine the output pixel value. The pixel and its neighborhood form a set
    of values and, as the name suggests, the median filter will simply compute the
    median value of this set, and the current pixel is then replaced with this median
    value (the median of a set is the value at the middle position when the set is
    sorted).
  prefs: []
  type: TYPE_NORMAL
- en: 'This explains why the filter is so efficient in eliminating the salt-and-pepper
    noise. Indeed, when an outlier black or white pixel is present in a given pixel
    neighborhood, it is never selected as the median value (rather, it is the maximal
    or minimal value), so it is always replaced by a neighboring value. In contrast,
    a simple mean filter would be greatly affected by such noise as it can be observed
    in the following image that represents the mean filtered version of our salt-and-pepper
    corrupted image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00087.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Clearly, the noisy pixels shifted the mean value of neighboring pixels. As a
    result, the noise is still visible even if it has been blurred by the mean filter.
  prefs: []
  type: TYPE_NORMAL
- en: The median filter also has the advantage of preserving the sharpness of the
    edges. However, it washes out the textures in uniform regions (for example, the
    trees in the background). Because of the visual impact it has on images, the median
    filter is often used to create special effects in photo-editing software tools.
    You should test it on a color image to see how it can produce *cartoon-like* images.
  prefs: []
  type: TYPE_NORMAL
- en: Applying directional filters to detect edges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first recipe of this chapter introduced the idea of linear filtering using
    kernel matrices. The filters that were used had the effect of blurring an image
    by removing or attenuating its high-frequency components. In this recipe, we will
    perform the opposite transformation, that is, amplifying the high-frequency content
    of an image. As a result, the high-pass filters introduced here will perform **edge
    detection**.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The filter that we will use here is called the **Sobel** filter. It is said
    to be a directional filter, because it only affects the vertical or the horizontal
    image frequencies depending on which kernel of the filter is used. OpenCV has
    a function that applies the **Sobel** operator on an image. The horizontal filter
    is called as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Vertical filtering is achieved by the following (and very similar to the horizontal
    filter) call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Several integer parameters are provided to the function, and these will be explained
    in the next section. Note that these have been chosen to produce an 8-bit image
    (`CV_8U`) representation of the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of the horizontal Sobel operator is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00088.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Since, as it will be seen in the next section, the kernels of the Sobel operator
    contain both positive and negative values, the result of the Sobel filter is generally
    computed in a 16-bit signed integer image (`CV_16S`). To make the results displayable
    as an 8-bit image, as shown in the preceding figure, we used a representation
    in which a zero value corresponds to gray-level 128\. Negative values are represented
    by darker pixels, while positive values are represented by brighter pixels. The
    vertical Sobel image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00089.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: If you are familiar with photo-editing software, the preceding images might
    remind you of the **image emboss** effect, and indeed, this image transformation
    is generally based on the use of directional filters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The two results (vertical and horizontal) can then be combined to obtain the
    norm of the Sobel filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The Sobel norm can be conveniently displayed in an image using the optional
    rescaling parameter of the `convertTo` method in order to obtain an image in which
    zero values correspond to white, and higher values are assigned darker gray shades:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The result can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00090.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Looking at this image, it is now clear why these kind of operators are called
    edge detectors. It is then possible to threshold this image in order to obtain
    a binary map that shows you the image contour. The following snippet creates the
    image that follows it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![How to do it...](img/00091.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Sobel operator is a classic edge-detection linear filter that is based
    on two simple `3x3` kernels that have the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '| -1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -2 | 0 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| -1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -1 | -2 | -1 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 2 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'If we view the image as a two-dimensional function, the Sobel operator can
    then be seen as a measure of the variation of the image in the vertical and horizontal
    directions. In mathematical terms, this measure is called a **gradient**, and
    it is defined as a 2D vector that is made from the function''s first derivatives
    in two orthogonal directions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00092.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Therefore, the Sobel operator gives you an approximation of the image gradient
    by differencing pixels in the horizontal and vertical directions. It operates
    on a window around the pixel of interest in order to reduce the influence of noise.
    The `cv::Sobel` function computes the result of the convolution of the image with
    a Sobel kernel. Its complete specification is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Therefore, you decide whether you wish to have the result written in an unsigned
    characters, a signed integer, or a floating point image. Of course, if the result
    falls outside of the domain of the image pixel, saturation will be applied. This
    is where the last two parameters can be useful. Before storing the result in the
    image, the result can be scaled (multiplied) by `alpha` and an offset, `beta`,
    can be added. This is how, in the previous section, we generated an image for
    which the Sobel value `0` was represented by the mid-gray level `128`. Each Sobel
    mask corresponds to a derivative in one direction. Therefore, two parameters are
    used to specify the kernel that will be applied, the order of the derivative in
    the `x`, and the `y` directions. For instance, the horizontal Sobel kernel is
    obtained by specifying `1` and `0` for the `xorder` and `yorder` parameters, and
    the vertical kernel will be generated with `0` and `1`. Other combinations are
    also possible, but these two are the ones that will be used most often (the case
    of second-order derivatives is discussed in the next recipe). Finally, it is also
    possible to use kernels of a size that is larger than `3x3`. Values `1`, `3`,
    `5`, and `7` are possible choices for the kernel size. A kernel of size 1 corresponds
    to a 1D Sobel filter (`1x3` or `3x1`). See the following *There's more…* section
    to learn why using a larger kernel might be useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the gradient is a 2D vector, it has a norm and a direction. The norm
    of the gradient vector tells you what the amplitude of the variation is, and it
    is normally computed as a Euclidean norm (also called **L2 norm**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00093.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'However, in image processing, this norm is often computed as the sum of the
    absolute values. This is called the **L1 norm**, and it gives values that are
    close to the L2 norm but at a lower computational cost. This is what we did in
    this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The gradient vector always points in the direction of the steepest variation.
    For an image, this means that the gradient direction will be orthogonal to the
    edge, pointing in the darker to brighter direction. Gradient angular direction
    is given by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00094.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Most often, for edge detection, only the norm is computed. However, if you
    require both the norm and the direction, then the following OpenCV function can
    be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: By default, the direction is computed in radians. Just add `true` as an additional
    argument in order to have them computed in degrees.
  prefs: []
  type: TYPE_NORMAL
- en: 'A binary edge map has been obtained by applying a threshold on the gradient
    magnitude. Choosing the right threshold is not an obvious task. If the threshold
    value is too low, too many (thick) edges will be retained, while if we select
    a more severe (higher) threshold, then broken edges will be obtained. As an illustration
    of this trade-off situation, compare the preceding binary edge map with the following,
    which is obtained using a higher threshold value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00095.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: One way to get the best of both lower and higher thresholds is to use the concept
    of hysteresis thresholding. This will be explained in the next chapter where we
    introduce the Canny operator.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Other gradient operators also exist. We present some of them in this section.
    It is also possible to apply a Gaussian smoothing filter before applying a derivative
    filter. This makes it less sensitive to noise, as explained in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient operators
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To estimate the gradient at a pixel location, the Prewitt operator defines
    the following kernels:'
  prefs: []
  type: TYPE_NORMAL
- en: '| -1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -1 | -1 | -1 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: 'The Roberts operator is based on these simple `2x2` kernels:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | -1 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| -1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'The Scharr operator is preferred when more accurate estimates of the gradient
    orientation are required:'
  prefs: []
  type: TYPE_NORMAL
- en: '| -3 | 0 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| -10 | 0 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| -3 | 0 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| -3 | -10 | -3 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 10 | 3 |'
  prefs: []
  type: TYPE_TB
- en: 'Note that it is possible to use the Scharr kernels with the `cv::Sobel` function
    by calling it with the `CV_SCHARR` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, equivalently, you can call the `cv::Scharr` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: All of these directional filters try to estimate the first-order derivative
    of the image function. Therefore, high values are obtained at areas where large
    intensity variations in the filter direction are present, while flat areas produce
    low values. This is why filters that compute image derivatives are high-pass filters.
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian derivatives
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Derivative filters are high-pass filters. As such, they tend to amplify noise
    and small highly-contrasted details in an image. In order to reduce the impact
    of these higher frequency elements, it is a good practice to first smooth the
    image before applying a derivative filter. You might think that this would be
    done in two steps, which are smoothing the image and then computing the derivative.
    However, a closer look at these operations reveals that it is possible to combine
    these two steps into one with a proper choice of the smoothing kernel. We learned
    previously that the convolution of an image with a filter can be expressed as
    a summation of terms. Interestingly, a well-known mathematical property is that
    the derivative of a summation of terms is equal to the summation of the terms'
    derivative.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequently, instead of applying the derivative on the result of the smoothing,
    it is possible to derivate the kernel and then convolute it with the image. Since
    the Gaussian kernel is continuously derivable, it represents a particularly appropriate
    choice. This is what is done when you call the `cv::sobel` function with different
    kernel sizes. The function will compute a Gaussian derivative kernel with different
    σ values. As an example, if we select the `7x7` Sobel filter (that is `kernel_size=7`)
    in the x direction, the following result is obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gaussian derivatives](img/00096.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: If you compare this image with the one shown earlier, it can be seen that many
    fine details have been removed, giving them more emphasis on the more significant
    edges. Note that we now have a band-pass filter, the higher frequencies being
    removed by the Gaussian filter and the lower frequencies being removed by the
    Sobel filter.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *Detecting image contours with the Canny operator* recipe in [Chapter 7](part0052_split_000.html#page
    "Chapter 7. Extracting Lines, Contours, and Components"), *Extracting Lines, Contours,
    and Components*, shows you how to obtain a binary edge map using two different
    threshold values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computing the Laplacian of an image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Laplacian is another high-pass linear filter that is based on the computation
    of the image derivatives. As it will be explained, it computes second-order derivatives
    to measure the curvature of the image function.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The OpenCV function, `cv::Laplacian`, computes the Laplacian of an image. It
    is very similar to the `cv::Sobel` function. In fact, it uses the same basic function,
    `cv::getDerivKernels`, in order to obtain its kernel matrix. The only difference
    is that there are no derivative order parameters since these ones are, by definition,
    second order derivatives.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this operator, we will create a simple class that will encapsulate some
    useful operations related to the Laplacian. The basic methods are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The computation of the Laplacian is done here on a floating point image. To
    get an image of the result, we perform a rescaling, as shown in the previous recipe.
    This rescaling is based on the Laplacian maximum absolute value, where value `0`
    is assigned gray-level `128`. A method of our class allows the following image
    representation to be obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Using this class, the Laplacian image computed from a `7x7` kernel is obtained
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting image is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/00097.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Formally, the Laplacian of a 2D function is defined as the sum of its second
    derivatives:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00098.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In its simplest form, it can be approximated by the following 3x3 kernel:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | -4 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: As for the Sobel operator, it is also possible to compute the Laplacian using
    larger kernels, and since this operator is even more sensitive to image noise,
    it is desirable to do so (unless computational efficiency is a concern). Since
    these larger kernels are computed using the second derivatives of the Gaussian
    function, the corresponding operator is often called **Laplacian of Gaussian**
    (**LoG**). Note that the kernel values of a Laplacian always sum up to `0`. This
    guarantees that the Laplacian will be zero in areas of constant intensities. Indeed,
    since the Laplacian measures the curvature of the image function, it should be
    equal to `0` on flat areas.
  prefs: []
  type: TYPE_NORMAL
- en: 'At first glance, the effect of the Laplacian might be difficult to interpret.
    From the definition of the kernel, it is clear that any isolated pixel value (that
    is, a value that''s very different from its neighbors) will be amplified by the
    operator. This is a consequence of the operator''s high sensitivity to noise.
    However, it is more interesting to look at the Laplacian values around an image
    edge. The presence of an edge in an image is the result of a rapid transition
    between areas of different gray-level intensities. Following the evolution of
    the image function along an edge (for example, caused by a transition from dark
    to bright), one can observe that the gray-level ascension necessarily implies
    a gradual transition from a positive curvature (when the intensity values start
    to rise) to a negative curvature (when the intensity is about to reach its high
    plateau). Consequently, a transition between a positive and a negative Laplacian
    value (or reciprocally) constitutes a good indicator of the presence of an edge.
    Another way to express this fact is to say that edges will be located at the **zero-crossings**
    of the Laplacian function. We will illustrate this idea by looking at the values
    of a Laplacian in a small window of our test image. We select one that corresponds
    to an edge created by the bottom part of the roof of one of the castle''s tower.
    A white box has been drawn in the following image to show you the exact location
    of this region of interest:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00099.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, looking at the Laplacian values (`7x7` kernel) inside this window, we
    have the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00100.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: If, as illustrated, you carefully follow the zero-crossings of the Laplacian
    (located between pixels of different signs), you obtain a curve that corresponds
    to the edge that is visible in the image window. In the preceding figure, we drew
    dotted lines along the zero-crossings that correspond to the edge of the tower
    that is visible in the selected image window. This implies that, in principle,
    you can even detect the image edges at sub-pixel accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the zero-crossing curves in a Laplacian image is a delicate task.
    However, a simplified algorithm can be used to detect the approximate zero-crossing
    locations. This one proceeds by first thresholding the Laplacian at `0` such that
    it obtains a partition between the positive and negative values. The contours
    between these two partitions then correspond to our zero-crossings. Therefore,
    we use a morphological operation to extract these contours, that is, we subtract
    the dilated image from the Laplacian image (this is the Beucher gradient presented
    in the *Detecting edges and corners using morphological filters* recipe in [Chapter
    5](part0040_split_000.html#page "Chapter 5. Transforming Images with Morphological
    Operations"), *Transforming Images with Morphological Operations*). This algorithm
    is implemented by the following method, which generates a binary image of zero-crossings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is the following binary map:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/00101.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the zero-crossings of the Laplacian detect all edges. No distinction
    is made between strong edges and weaker edges. We also mentioned that the Laplacian
    is very sensitive to noise. Finally, some of these edges are due to compression
    artifacts. All these factors explain why so many edges are detected by the operator.
    In practice, the Laplacian is only used in conjunction with other operators to
    detect edges (for example, edges can be declared at zero-crossing locations of
    strong gradient magnitude). We will also learn in [Chapter 8](part0058_split_000.html#page
    "Chapter 8. Detecting Interest Points"), *Detecting Interest Points*, that the
    Laplacian and other second-order operators are very useful in order to detect
    interest points at multiple scales.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Laplacian is a high-pass filter. It is possible to approximate it by using
    a combination of low-pass filters. But before that, let's have a word about image
    enhancement, which is a topic we already discussed in [Chapter 2](part0019_split_000.html#page
    "Chapter 2. Manipulating Pixels"), *Manipulating Pixels*.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing the contrast of an image using the Laplacian
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The contrast of an image can be enhanced by subtracting its Laplacian from
    it. This is what we did in the Scanning an image with neighbor access recipe of
    [Chapter 2](part0019_split_000.html#page "Chapter 2. Manipulating Pixels"), *Manipulating
    Pixels*, where we introduced the kernel:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 0 | -1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| -1 | 5 | -1 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | -1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: This is equal to 1 minus the Laplacian kernel (that is, the original image minus
    its Laplacian).
  prefs: []
  type: TYPE_NORMAL
- en: Difference of Gaussians
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Gaussian filter presented in the first recipe of this chapter extracts
    the low frequencies of an image. We learned that the range of frequencies that
    are filtered by a Gaussian filter depend on the parameter σ, which controls the
    width of the filter. Now, if we subtract the two images that result from the filtering
    of an image by two Gaussian filters of different bandwidths, then the resulting
    image will be composed of those higher frequencies that one filter has preserved,
    and not the other. This operation is called **Difference of Gaussians** (**DoG**)
    and is computed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, we also compute the zero-crossings of the DoG operator and we
    obtain the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Difference of Gaussians](img/00102.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In fact, it can be demonstrated that with the proper choice of σ values, DoG
    operators can constitute a good approximation of LoG filters. Also, if you compute
    a series of difference of Gaussians from consecutive pair values in an increasing
    sequence of σ values, you obtain a scale-space representation of the image. This
    multiscale representation is useful, for example, for scale-invariant image feature
    detection, as it will be explained in [Chapter 8](part0058_split_000.html#page
    "Chapter 8. Detecting Interest Points"), *Detecting Interest Points*.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Detecting scale-invariant features recipe in [Chapter 8](part0058_split_000.html#page
    "Chapter 8. Detecting Interest Points"), *Detecting Interest Points* uses the
    Laplacian and DoG for the detection of scale-invariant features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
