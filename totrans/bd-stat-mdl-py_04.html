<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer064">
<h1 class="chapter-number" id="_idParaDest-66"><a id="_idTextAnchor070"/>4</h1>
<h1 id="_idParaDest-67"><a id="_idTextAnchor071"/>Parametric Tests</h1>
<p>In the previous chapter, we introduced the concept of a hypothesis test and showed several applications of the z-test. The z-test is a type of hypothesis test in a family of hypothesis tests called parametric tests. Parametric tests are powerful hypothesis tests, but the application of parametric tests requires certain assumptions to be met by the data. While the z-test is a useful test, it is limited by the required assumptions. In this chapter, we will discuss several more parametric tests, which will expand our parametric tool set. More specifically, we will discuss the various applications of the t-test, how to perform tests when more than two subgroups of data are present, and the hypothesis test for Pearson’s correlation coefficient. We will complete the chapter with a discussion on power analysis for <span class="No-Break">parametric tests.</span></p>
<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
<ul>
<li>Assumptions of <span class="No-Break"><strong class="bold">parametric tests</strong></span></li>
<li><strong class="bold">T-test</strong>—a parametric <span class="No-Break">hypothesis test</span></li>
<li>Tests with more than two groups and <strong class="bold">analysis of </strong><span class="No-Break"><strong class="bold">variance</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ANOVA</strong></span><span class="No-Break">)</span></li>
<li><strong class="bold">Pearson’s </strong><span class="No-Break"><strong class="bold">correlation coefficient</strong></span></li>
<li><strong class="bold">Power </strong><span class="No-Break"><strong class="bold">analysis</strong></span><span class="No-Break"> examples</span></li>
</ul>
<h1 id="_idParaDest-68"><a id="_idTextAnchor072"/>Assumptions of parametric tests</h1>
<p>Parametric tests <a id="_idIndexMarker295"/>make assumptions about population data that require the statistics practitioner to perform analysis of data prior to modeling, especially when using sample data because the sample statistics are leveraged as estimates for the population parameters when the true population parameters are unknown. These are the three primary assumptions of parametric <span class="No-Break">hypothesis tests:</span></p>
<ul>
<li>Normally distributed <span class="No-Break">population data</span></li>
<li>Samples <span class="No-Break">are independent</span></li>
<li>Equal population variances (when comparing two or <span class="No-Break">more groups)</span></li>
</ul>
<p>In this <a id="_idIndexMarker296"/>chapter, we discuss the z-test, t-test, ANOVA, and Pearson’s correlation. These tests are used on continuous data. In addition to these assumptions, Pearson’s correlation requires data to contain paired samples. In other words, there must be an equal number of samples in each group being compared as Pearson’s correlation is based on <span class="No-Break">pairwise comparisons.</span></p>
<p>While these assumptions are ideal, there are many occasions where these cannot be ensured. Consequently, it is useful to understand there is some robustness to these assumptions, depending on <span class="No-Break">the test.</span></p>
<h2 id="_idParaDest-69"><a id="_idTextAnchor073"/>Normally distributed population data</h2>
<p>Because <a id="_idIndexMarker297"/>in parametric hypothesis tests we are interested in gaining inferences about population parameters, such as <a id="_idIndexMarker298"/>the mean or standard deviation, we must assume the parameter of choice is representative of the distribution and that it is safe to assume a central tendency in the data. We must also assume the statistic (parametric value taken from a sample or sampling distribution) is representative of its respective population parameter. Therefore, since we assume in parametric hypothesis tests that the population is normally distributed, the sample should also be normally distributed as well. Otherwise, it is not safe to assume the sample is representative of <span class="No-Break">the population.</span></p>
<p>Parametric hypothesis tests rely heavily on the mean and assume it is strongly representative of the data’s central point (all population data is centrally distributed around the mean). Consider where the means of two distributions are being compared to test if there is a statistically significant difference between them. If the distributions are skewed, the mean will not be the center point of the data and, consequently, cannot represent the distributions very well. Since this would be the case, inference obtained from a test comparing the means would not <span class="No-Break">be reliable.</span></p>
<h3>Robustness to normally distributed data</h3>
<p>Many<a id="_idIndexMarker299"/> hypothesis tests specify degrees of freedom when using samples to make estimates about populations. Degrees of freedom force models to assume there is extra variance in the distributions used than actually present. While the statistical parameters in the analysis remain the same, the assumed extra variance forces measures of central tendency closer. Stated differently, using degrees of freedom forces measures of central tendency to be more centrally representative of the distributions from which they are calculated. The reason for this is that it is assumed samples—while representative of their overall populations—represent their populations with a margin of error. Consequently, parametric hypothesis tests using degrees of freedom have some robustness to violations of the requirement for normally <span class="No-Break">distributed data.</span></p>
<p>In the plots shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.1</em>, we have a slightly skewed distribution. One applies degrees of freedom while the other does not. We can see the mean and median have the same distance between them whether degrees of freedom are used or not. However, the distribution using degrees of freedom takes on more errors (<span class="No-Break">more variance):</span></p>
<div>
<div class="IMG---Figure" id="_idContainer051">
<img alt="Figure 4.1 – Visualizing the influence of degrees of freedom" height="441" src="image/B18945_04_001.jpg" width="861"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – Visualizing the influence of degrees of freedom</p>
<p>When using a hypothesis test that considers the mean, we can see that the mean, while not centered (as is the median), approximates the center of the distribution much more closely, relative to all data points, when degrees of freedom are used. Since parametric hypothesis tests use the mean as the central point, this is important for the usefulness of the model as the mean is more representative of the central point of the data when degrees of freedom are used. This is a primary reason there is some robustness to normality. Some other robustness is in the statistical interpretation, such as in choosing the level of <a id="_idIndexMarker300"/>confidence; if a distribution is not perfectly normally distributed, it may be beneficial to use a 90% level of confidence rather than a 99% level of confidence, <span class="No-Break">for example.</span></p>
<h3>Testing for normally distributed data</h3>
<p>There are<a id="_idIndexMarker301"/> multiple methods for determining whether a distribution is normally distributed and thus can be used in<a id="_idIndexMarker302"/> parametric hypothesis testing. Generally, the level of adherence to normality is up to the discretion of the researcher. The methods in this section leave some margin for debate on normality based on visual inspection as well as levels of statistical <span class="No-Break">significance applied.</span></p>
<h4>Visual inspection</h4>
<p>The<a id="_idIndexMarker303"/> best tests to identify whether a distribution <a id="_idIndexMarker304"/>is normally distributed or not are based on visual inspection. We can use <strong class="bold">Quantile-Quantile</strong> (<strong class="bold">QQ</strong>) plots <a id="_idIndexMarker305"/>and histograms—among other tests—to visually inspect <span class="No-Break">the distributions.</span></p>
<p>In the following code snippet, we generate plots of the original data as well as the QQ plots using the <strong class="source-inline">scipy.stats</strong> module’s <span class="No-Break"><strong class="source-inline">probplot</strong></span><span class="No-Break"> function:</span></p>
<pre class="source-code">
import matplotlib.pyplot as plt
import scipy.stats as stats
import numpy as np
mu, sigma = 0, 1.1
normally_distributed = np.random.normal(mu, sigma, 1000)</pre>
<p>In <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.2</em>, we can see in the first column a histogram of exponentially distributed data and, beneath it, its QQ plot. As the points are very far from approximating adherence to the 45-degree red line, which represents a pure normal distribution, we can conclude the data is not normally distributed. By visually inspecting the data in the second column, we can see the histogram exhibits an approximately normally distributed dataset. This is backed up by the QQ plot below it, where the points mostly approximate the 45-degree red line. With respect to the tails of the QQ plot, these data points represent the density of skewness. We expect with a normally distributed dataset that the bulk of data points will tend toward the center of the red line. With the exponential distribution, we can see a heavy density toward the left, lower tail of the red line, and a sparse <a id="_idIndexMarker306"/>scattering of points toward the <a id="_idIndexMarker307"/>upper-right side of the line. The QQ plot can be read left to right, mirroring the spread seen in the histogram, where the smallest values appear on the left-hand side of the <em class="italic">x</em> axis and the largest on the <span class="No-Break">right-hand side:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer052">
<img alt="Figure 4.2 – Visually assessing normality with QQ and histogram plots" height="855" src="image/B18945_04_002.jpg" width="861"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – Visually assessing normality with QQ and histogram plots</p>
<p>Visual inspection of the QQ plots and histograms should be enough to help a researcher conclude whether the normality assumption has been violated or not. However, in cases where one might <a id="_idIndexMarker308"/>not want to perform visual inspection—such as when constructing a data science pipeline—there are alternative approaches that provide specific<a id="_idIndexMarker309"/> measurements of normality. Three of the most commonly used<a id="_idIndexMarker310"/> tests are<a id="_idIndexMarker311"/> the <strong class="bold">Kolmogorov-Smirnov</strong>, <strong class="bold">Anderson-Darling</strong>, and <span class="No-Break"><strong class="bold">Shapiro-Wilk</strong></span><span class="No-Break"> tests.</span></p>
<p>The<a id="_idIndexMarker312"/> Kolmogorov-Smirnov test focuses more on the centrality of the data. Consequently, however, the test has less power if there is a wide variance around the center of the data. Anderson-Darling focuses more on the tails of the data than the center and is more likely to identify non-conformity to normality if data is heavy-tailed with extreme outliers. These two tests perform well on large sample sizes but do not have as much power when sample sizes are lower. The third test we consider, Shapiro-Wilk, is more general than the Kolmogorov-Smirnov and Anderson-Darling tests and therefore more robust to small sample sizes. Based on these traits, it may be more useful to use Shapiro-Wilk tests in an automated pipeline. Alternatively, it may be better to lower the level of confidence for the test <span class="No-Break">being applied.</span></p>
<h4>Kolmogorov-Smirnov</h4>
<p>The <strong class="bold">Kolmogorov-Smirnov</strong> test <a id="_idIndexMarker313"/>can be <a id="_idIndexMarker314"/>used to test the null hypothesis that a  given sample distribution is normally distributed. This version of the Kolmogorov-Smirnov test is the one-sample goodness-of-fit test, which performs analysis against a benchmark cumulative density distribution. When running the <strong class="source-inline">kstest</strong> function in the <strong class="source-inline">scipy.stats</strong> module, using <strong class="source-inline">stats.norm.cdf</strong> (<strong class="source-inline">scipy</strong>’s cumulative density function) performs this one-sample version of the test. The two-sample version tests against a specified distribution to determine whether the two distributions match. In the two-sample case, the distribution to be tested must be provided as a <strong class="source-inline">numpy</strong> array instead of the <strong class="source-inline">stats.norm.cdf</strong> function used in the code snippet shown below <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.3</em>. However, this is outside of the scope of testing for normality, so we will not look <span class="No-Break">at this.</span></p>
<p>Kolmogorov-Smirnov measures a calculated test statistic against a table-based critical value (<strong class="source-inline">kstest</strong> calculates this internally). As with other hypothesis tests, if the test statistic is larger than the critical value, the null hypothesis that the given distribution is normally distributed can be rejected. This can also be assessed if the p-value is low enough to be significant. The test statistic is calculated as the absolute value of the maximum distance between all data points in the given distribution against the cumulative <span class="No-Break">density</span><span class="No-Break"><a id="_idIndexMarker315"/></span><span class="No-Break"> function.</span></p>
<p class="callout-heading">Kolmogorov-Smirnov special requirement</p>
<p class="callout">The Kolmogorov-Smirnov test requires data to be centered around zero and scaled to a standard deviation of one. All data must be transformed for the test, but inference can be applied to the pre-transformed distribution; the centered and scaled distribution does not need to be the distribution used in further statistical testing <span class="No-Break">or analysis.</span></p>
<p>In the<a id="_idIndexMarker316"/> following code snippet, we test to confirm whether a normally distributed dataset, <strong class="source-inline">normally_distributed</strong>, is normally distributed. The dataset has a mean of 0 and a standard deviation of 1. The output confirms the data is normally distributed. The plots in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.3</em> show the normally distributed distribution centered around a mean of 0 with a standard deviation of 1, and on the right of it is the exponentially transformed version of the <span class="No-Break">same distribution:</span></p>
<pre class="source-code">
from scipy import stats
import numpy as np
mu, sigma = 0, 1
normally_distributed = np.random.normal(mu, sigma, 1000)</pre>
<div>
<div class="IMG---Figure" id="_idContainer053">
<img alt="Figure 4.3 – Normally distributed and exponential data" height="448" src="image/B18945_04_003.jpg" width="861"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – Normally distributed and exponential data</p>
<p>Here, we<a id="_idIndexMarker317"/> run the <span class="No-Break">Kolmogorov-Smirnov </span><span class="No-Break"><a id="_idIndexMarker318"/></span><span class="No-Break">test:</span></p>
<pre class="source-code">
stats.kstest(normally_distributed,
             stats.norm.cdf)</pre>
<p>The <strong class="source-inline">statsmodels</strong> Kolmorogov-Smirnov test yielded the following results for <span class="No-Break">our data:</span></p>
<p><span class="No-Break"><strong class="source-inline">KstestResult(statistic=0.0191570377833315, pvalue=0.849436919292824)</strong></span></p>
<p>If we use the same data, but transform it exponentially to be right-skewed, the same test indicates the data is no longer <span class="No-Break">normally distributed:</span></p>
<pre class="source-code">
stats.kstest(np.exp(normally_distributed), stats.norm.cdf)</pre>
<p>The signficant p-value <span class="No-Break">confirms non-normality:</span></p>
<p><span class="No-Break"><strong class="source-inline">KstestResult(statistic=0.5375205782404135, pvalue=9.59979841227121e-271)</strong></span></p>
<p>Next, let us take a distribution of 1,000 samples with a mean of 100 and a standard deviation of 2. We need to center it to a mean of 0 with unit variance (standard deviation of 1). In the following code snippet, we generate the data, then perform the scaling and save it to the <span class="No-Break"><strong class="source-inline">normally_distributed_scaled</strong></span><span class="No-Break"> variable:</span></p>
<pre class="source-code">
mu, sigma = 100, 2
normally_distributed = np.random.normal(mu, sigma, 1000)
normally_distributed_scaled = (
    normally_distributed-normally_distributed.mean()) /
    normally_distributed.std()</pre>
<p>Now that <a id="_idIndexMarker319"/>the data is centered and scaled as required, we check it using the Kolmogorov-Smirnov test. As expected, the <a id="_idIndexMarker320"/>data is confirmed <span class="No-Break">normally distributed:</span></p>
<pre class="source-code">
stats.kstest(normally_distributed_scaled, stats.norm.cdf)</pre>
<p>This is <span class="No-Break">the output:</span></p>
<p><span class="No-Break"><strong class="source-inline">KstestResult(statistic=0.02597307287070466, pvalue=0.5016041053535877)</strong></span></p>
<h4>Anderson-Darling</h4>
<p>Similar to <a id="_idIndexMarker321"/>the Kolmogorov-Smirnov test, the <strong class="bold">Anderson-Darling</strong> test<a id="_idIndexMarker322"/> measures a given distribution against a normally distributed distribution. In <strong class="source-inline">scipy</strong>’s <strong class="source-inline">anderson</strong> test, we can test against other distributions, but the default argument specifying a normal distribution, <strong class="source-inline">dist="norm"</strong>, assumes a null hypothesis that the given distribution is statistically the same as a normally distributed distribution. For each distribution tested against, a different set of critical values must <span class="No-Break">be calculated.</span></p>
<p class="callout-heading">Anderson-Darling compared to Kolmogorov-Smirnov</p>
<p class="callout">Note that while both the Anderson-Darling and Kolmogorov-Smirnov tests use the cumulative density frequency distributions to test for normality, the Anderson-Darling test is different from the Kolmogorov-Smirnov test because it weights the variance in the tails of the cumulative density frequency distribution more than the middle. This is because the variance in the tails can be measured in smaller increments than in the middle of the distribution. Consequently, the Anderson-Darling test is more sensitive to tails than the Kolmogorov-Smirnov test. In line with the Kolmogorov-Smirnov test, a test statistic is calculated and measured against a critical value. If the test statistic is larger than the critical value, the null hypothesis that the given distribution is normally distributed can be rejected at the specified level <span class="No-Break">of significance.</span></p>
<p>Here, we are using the Anderson-Darling test to test a random normal probability distribution<a id="_idIndexMarker323"/> generated with a mean of 19 and a standard deviation of 1.7. We also test an exponentially<a id="_idIndexMarker324"/> transformed version of <span class="No-Break">this data:</span></p>
<pre class="source-code">
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
mu, sigma = 19, 1.7
normally_distributed = np.random.normal(mu, sigma, 1000)
not_normally_distributed = np.exp(normally_distributed);</pre>
<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.4</em> shows plots of <span class="No-Break">the data:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer054">
<img alt="Figure 4.4 – Normal distribution versus heavy-tailed exponential distribution" height="465" src="image/B18945_04_004.jpg" width="861"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.4 – Normal distribution versus heavy-tailed exponential distribution</p>
<p>In the code and output shown next, in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.5</em>, we can see the distribution is normally distributed at all levels of significance. Recall that the level of significance is the p-value (that is, a level of significance = 15.0 means a p-value of 0.15 or smaller <span class="No-Break">is significant):</span></p>
<pre class="source-code">
<strong class="source-inline">from scipy import stats</strong>
<strong class="source-inline">import pandas as pd</strong>
<strong class="source-inline">import numpy as np</strong>
<strong class="source-inline">def anderson_test(data):</strong>
<strong class="source-inline">    </strong><strong class="source-inline">data = np.array(data)</strong>
<strong class="source-inline">    test_statistic, critical_values, significance_levels = stats.anderson(normally_distributed, dist='norm')</strong>
<strong class="source-inline">    df_anderson = pd.DataFrame({'Test Statistic':np.repeat(test_statistic, len(critical_values)), 'Critical Value':critical_values, 'Significance Level': significance_levels})</strong>
<strong class="source-inline">    df_anderson.loc[df_anderson['Test Statistic'] &gt;= </strong><strong class="source-inline">df_anderson['Critical Value'], 'Normally Distributed'] = 'No'</strong>
<strong class="source-inline">    df_anderson.loc[df_anderson['Test Statistic'] &lt;df_anderson['Critical Value'], 'Normally Distributed'] = 'Yes'</strong>
<strong class="source-inline">    return df_anderson;</strong>
<strong class="source-inline">mu, sigma = 19, 1.7</strong>
<strong class="source-inline">normally_distributed = np.random.normal(mu, sigma, 1000)</strong>
<strong class="source-inline">anderson_test(normally_distributed)</strong></pre>
<p>Here, the data generated through the <strong class="source-inline">numpy</strong> <strong class="source-inline">random.normal</strong> function is tested with the Anderson-Darling method and confirmed to be <span class="No-Break">normally distributed:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-3">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Test statistic</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Critical value</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Significance level</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Normally distributed</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.191482344</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.574</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">15</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Yes</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.191482344</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.653</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">10</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Yes</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.191482344</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.784</span></p>
</td>
<td class="No-Table-Style">
<p>5</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Yes</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.191482344</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.914</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">2.5</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Yes</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.191482344</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">1.088</span></p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Yes</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 4.5 – Anderson-Darling results for normally distributed data</p>
<p>Here, we <a id="_idIndexMarker325"/>test an exponential<a id="_idIndexMarker326"/> transformation of the normally distributed data to check for normality. The data is exponentially distributed and should reject at all levels of significance. However, we see in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.6</em> that it has failed to reject at the 0.01 level of significance (99% confidence). Therefore, depending on the use case, it may be prudent to check all levels of significance, use a different test, or make a decision based on <span class="No-Break">multiple tests:</span></p>
<pre class="source-code">
<strong class="source-inline">not_normally_distributed = np.exp(normally_distributed)</strong>
<strong class="source-inline">anderson_test(not_normally_distributed)</strong></pre>
<p>Our Anderson-Darling test of non-normally distributed data outputs are as follows in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table002-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Test statistic</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Critical value</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Significance level</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Normally distributed</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.96277351</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.574</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">15</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">No</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.96277351</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.653</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">10</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">No</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.96277351</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.784</span></p>
</td>
<td class="No-Table-Style">
<p>5</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">No</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.96277351</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.914</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">2.5</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">No</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">0.96277351</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">1.088</span></p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Yes</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 4.6 – Anderson-Darling results for non-normally distributed data</p>
<h4>Shapiro-Wilk</h4>
<p>The <strong class="bold">Shapiro-Wilk</strong> test is a <a id="_idIndexMarker327"/>goodness-of-fit<a id="_idIndexMarker328"/> test that checks whether a given distribution is normally distributed. The test checks how closely a distribution of observed values centered on 0 and scaled to a unit variance of 1 approximates an observed centered and scaled standard normal distribution. This<a id="_idIndexMarker329"/> centering and scaling (called <strong class="bold">standardizing</strong>) are performed within the function in the <strong class="source-inline">scipy.stats shapiro</strong> module, so input data does not need to be altered prior to testing. The level of significance for this test in <strong class="source-inline">scipy</strong> <span class="No-Break">is 0.05.</span></p>
<p class="callout-heading">Shapiro-Wilk compared to Kolmogorov-Smirnov and Anderson-Darling</p>
<p class="callout">Shapiro-Wilk is ideal, compared to Kolmogorov-Smirnov and Anderson-Darling, for testing small sample sizes of roughly less than 50. However, one drawback is that since Shapiro-Wilk uses repeated sampling and testing for the calculated test statistic by applying Monte Carlo simulation, the law of large numbers poses a risk that as the sample size increases, there is an inherent increase in the risk of encountering a <em class="italic">type II</em> error (a loss of power) and failing to reject the null hypothesis, where the null hypothesis states the given distribution is <span class="No-Break">normally distributed.</span></p>
<p>Using the same distributions as in the Anderson-Darling test, we test with Shapiro-Wilk. We can see with the random normal distribution with a mean of 19 and a standard deviation of 1.7, the Shapiro-Wilk test has confirmed with a p-value of 0.99 that the null hypothesis that the input distribution is normally distributed should not <span class="No-Break">be rejected:</span></p>
<pre class="source-code">
mu, sigma = 19, 1.7
normally_distributed = np.random.normal(mu, sigma, 1000)
stats.shapiro(normally_distributed)</pre>
<p>This is <span class="No-Break">the output:</span></p>
<p><span class="No-Break"><strong class="source-inline">ShapiroResult(statistic=0.9993802905082703, pvalue=0.9900037050247192)</strong></span></p>
<p>When testing using the exponentially transformed version of the normally distributed data, we find a significant p-value (p = 0.0), indicating we have enough evidence to reject the null hypothesis <a id="_idIndexMarker330"/>and conclude the distribution is not <span class="No-Break">normally distributed:</span></p>
<pre class="source-code">
not_normally_distributed = np.exp(normally_distributed)
stats.shapiro(not_normally_distributed)</pre>
<p>This is <span class="No-Break">the output:</span></p>
<p><span class="No-Break"><strong class="source-inline">ShapiroResult(statistic=0.37320804595947266, pvalue=0.0)</strong></span></p>
<h3>Independent samples</h3>
<p>In <a id="_idIndexMarker331"/>parametric hypothesis testing, the independence of samples is another important assumption. Two effects can occur from non-independent sampling. One effect occurs when subgroup sampling is performed. The issue here is that responses in one subgroup of the population may be different than responses from another subgroup of the same population or even more similar to those of a different population. However, when sampling representative of the overall population is taken, this type of subgroup difference may not be very representative of <span class="No-Break">the population.</span></p>
<p>Another effect of non-independent sampling is when samples are taken close enough together in time that the occurrence of one precludes or excludes the occurrence of another. This is called serial (or <span class="No-Break">auto-) correlation.</span></p>
<p>Parametric tests are not typically robust to violations of this requirement as it has direct, categorical implications on the interpretability of test outcomes. With respect to subgroup sampling, this can be prevented through a well-structured sampling approach such as those outlined in <a href="B18945_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a><em class="italic">, Sampling and Generalization</em>. However, as regards the serial effect, we can test for autoregressive correlation (also called serial correlation) in <span class="No-Break">the data.</span></p>
<h3>Durbin-Watson</h3>
<p>One of the <a id="_idIndexMarker332"/>most common<a id="_idIndexMarker333"/> tests performed to assess a lack of independence in sampling is the first-order (also referred to as lag-one) autoregressive test called the <strong class="bold">Durbin-Watson</strong> test. <strong class="bold">Autoregressive</strong> means<a id="_idIndexMarker334"/> previous data points are used to predict the current data point. First-order means the last sampled data point (lag one) is the point most significantly correlated to the most recently sampled data point (lag zero) in a sequence of sampled data. In first-order autocorrelation, the correlation for each data point is strongest with the previous data point. The Durbin-Watson test does not test whether any value is correlated to the value before it, but instead if, overall, there is a strong enough relationship between each value and the value before it to conclude there is significant autocorrelation. In that sense, there is some robustness to non-independent sampling such that an accident or two may not completely invalidate a hypothesis test, but a consistent recurrence of this type of <span class="No-Break">violation will.</span></p>
<p>A Durbin-Watson <a id="_idIndexMarker335"/>value of 2 indicates no significant autocorrelation, a value between 0 and 2 represents positive (direct) autocorrelation, and a value between 2 and 4 represents negative (<span class="No-Break">inverse) autocorrelation.</span></p>
<p>In the following example, we have two distributions, each with 1,000 samples. The distribution on the left is a sinusoidal distribution that exhibits strong autoregressive correlation, and the distribution on the right is a set of randomly generated data displaying as white-noise variance (random points centered around a mean of 0). Using the <strong class="source-inline">durbin_watson()</strong> function from the <strong class="source-inline">statsmodels.stats</strong> module, we are able to confirm direct, positive lag-one autocorrelation in the sinusoidal pattern (a very small Durbin-Watson value) and a Durbin-Watson statistic of 2.1 with the random noise, indicating no autocorrelation. Therefore, in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.7</em>, the plot on the left is not composed of <a id="_idIndexMarker336"/>independent samples whereas the plot on the <span class="No-Break">right is:</span></p>
<pre class="source-code">
<strong class="source-inline">from statsmodels.stats.stattools import durbin_watson</strong>
<strong class="source-inline">import matplotlib.pyplot as plt</strong>
<strong class="source-inline">import numpy as np</strong>
<strong class="source-inline">mu, sigma = 0, 1.1</strong>
<strong class="source-inline">independent_samples = np.random.normal(mu, sigma, 1000)</strong>
<strong class="source-inline">correlated_samples = np.linspace(-np.pi, np.pi, num=1000)</strong>
<strong class="source-inline">fig, ax = plt.subplots(1,2, figsize=(10,5))</strong>
<strong class="source-inline">ax[0].plot(correlated_samples, np.sin(correlated_samples))</strong>
<strong class="source-inline">ax[0].set_title('Durbin Watson = {}'.format(</strong>
    <strong class="source-inline">durbin_watson(correlated_samples)))</strong>
<strong class="source-inline">ax[1].plot(independent_samples)</strong>
<strong class="source-inline">ax[1].set_title('Durbin Watson = {}'.format(</strong>
    <strong class="source-inline">durbin_watson(independent_samples)))</strong></pre>
<div>
<div class="IMG---Figure" id="_idContainer055">
<img alt="Figure 4.7 – Serially correlated and normally distributed sequence data" height="448" src="image/B18945_04_007.jpg" width="861"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.7 – Serially correlated and normally distributed sequence data</p>
<h2 id="_idParaDest-70"><a id="_idTextAnchor074"/>Equal population variance</h2>
<p>Similar to<a id="_idIndexMarker337"/> the assumption of normally distributed data, the assumption of equal population variance—also referred to as homogeneity of variance—is about the shape of the physical properties of the distributions being compared. Assuming <a id="_idIndexMarker338"/>equal population variance helps increase the power of a parametric test. This is because there is confidence when means are identified as being different; we also know the degree of potential distribution overlap. When a test has an intuition about the location of the full distributions—in effect, true knowledge of the effect size—power increases. Conversely, as variances diverge, <span class="No-Break">power decreases.</span></p>
<h3>Robustness to equal population variance</h3>
<p>While equal population variance is useful in parametric testing, modifications to these tests exist <a id="_idIndexMarker339"/>that help results be robust to deviance from equal variance. One prominent modified version of these tests uses the <strong class="bold">Welch-Satterthwaite</strong> adjustment<a id="_idIndexMarker340"/> to the degrees of freedom used. Because applying the same degree of freedom to each group when each group has a different variance would result in a misrepresentation of the data, the Welch-Satterthwaite adjustment accounts for variance differences when allocating degrees of freedom to parametric tests that assume equal variance. Two common tests that use the Welch-Satterthwaite adjustment are Welch’s t-test and Welch’s ANOVA test. When used on small samples, these tests may not be reliable, but when used on sample sizes large enough to have sufficient power, the results should be approximately the same as their <span class="No-Break">non-Welch counterparts.</span></p>
<h3>Testing for equal variance</h3>
<p>When <a id="_idIndexMarker341"/>testing for equal variance among distributions, we have two prominent tests: <strong class="bold">Levene’s test for equality of variances</strong> and <span class="No-Break"><strong class="bold">Fisher’s F-test</strong></span><span class="No-Break">.</span></p>
<h3>Levene’s test for equality of variances</h3>
<p>Levene’s test <a id="_idIndexMarker342"/>for equality of variances is useful when<a id="_idIndexMarker343"/> testing for homogeneity of variance of two or more groups. In the code snippet shown below <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.8</em>, we test with three distributions, each having a sample size of 100, a mean of 0, and standard deviations of 0.9, 1.1, and 2. <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.8</em> is a plot of the three distributions generated using the data output from the code above <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">.</span></p>
<pre class="source-code">
<strong class="source-inline">from scipy.stats import levene</strong>
<strong class="source-inline">np.random.seed(26)</strong>
<strong class="source-inline">mu1, sigma1, mu2, sigma2, mu3, sigma3 = 0,0.9,0,1.1,0,2</strong>
<strong class="source-inline">distro1, distro2, distro3 = pd.DataFrame(), pd.DataFrame(),</strong>
    <strong class="source-inline">pd.DataFrame()</strong>
<strong class="source-inline">distro1['x'] = np.random.normal(mu1, sigma1, 100)</strong>
<strong class="source-inline">distro2['x'] = np.random.normal(mu2, sigma2, 100)</strong>
<strong class="source-inline">distro3['x'] = np.random.normal(mu3, sigma3, 100)</strong></pre>
<p>We can see how their different standard deviations impact <span class="No-Break">their range.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer056">
<img alt="Figure 4.8 – Distributions for multiple equality of variance testing" height="319" src="image/B18945_04_008.jpg" width="861"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.8 – Distributions for multiple equality of variance testing</p>
<p>We can<a id="_idIndexMarker344"/> see the test is sensitive to violations of <a id="_idIndexMarker345"/>non-homogenous variance because the result of this is a statistically significant p-value indicating <span class="No-Break">non-homogenous variance:</span></p>
<pre class="source-code">
<strong class="source-inline">f_statistic, p_value = levene(distro1['x'], distro2['x'], distro3['x'])</strong>
<strong class="source-inline">if p_value &lt;= 0.05:</strong>
<strong class="source-inline">    print('The distributions do not have homogenous variance. P-value = %.4f, F-statistic = %.4f'%(p_value, f_statistic))</strong>
<strong class="source-inline">else:</strong>
<strong class="source-inline">    print('The distributions have homogenous variance.P-value = %.4f, F-statistic = %.4f'%(p_value, f_statistic))</strong></pre>
<p>This is <span class="No-Break">the output:</span></p>
<p><strong class="source-inline">The distributions do not have homogenous variance. P-value = </strong><span class="No-Break"><strong class="source-inline">0.0000</strong></span></p>
<h3>Fisher’s F-test</h3>
<p>Fisher’s F-test is <a id="_idIndexMarker346"/>useful when testing for homogeneity of variance <a id="_idIndexMarker347"/>for two groups at a time. This test compares a test statistic to a critical value to determine whether the variances are statistically the same or not. The calculated F-statistic is the variance of group one divided by the variance of group two. Group one is always the group with the larger variance. Using the preceding data, let us compare distribution 1 with distribution 3. Distribution 3 has a larger variance of 2, so that group’s variance will be the numerator when calculating the F-statistic. Since each group has a sample size of 100, their degrees of freedom for the table lookup will each be 99. However, since we will use the <strong class="source-inline">scipy</strong> Python package to compute the test, here, the table lookup is not needed as <strong class="source-inline">scipy</strong> does this for us with the <strong class="source-inline">f.cdf()</strong> function. In line with the results of the Levene test, the F-test indicates distribution 1 and distribution 3 do not have <span class="No-Break">homogenous variance:</span></p>
<pre class="source-code">
<strong class="source-inline">from scipy.stats import f</strong>
<strong class="source-inline">def f_test(inputA, inputB):</strong>
<strong class="source-inline">    group1 = np.array(inputA)</strong>
<strong class="source-inline">    group2 = np.array(inputB)</strong>
<strong class="source-inline">    if np.var(group1) &gt; np.var(group2):</strong>
<strong class="source-inline">        f_statistic = np.var(group1) / np.var(group2)</strong>
<strong class="source-inline">        numeratorDegreesOfFreedom = group1.shape[0] - 1</strong>
<strong class="source-inline">        denominatorDegreesOfFreedom = group2.shape[0] - 1</strong>
<strong class="source-inline">    else:</strong>
<strong class="source-inline">        f_statistic = np.var(group2)/np.var(group1)</strong>
<strong class="source-inline">        numeratorDegreesOfFreedom = group2.shape[0] - 1</strong>
<strong class="source-inline">        denominatorDegreesOfFreedom = group1.shape[0] - 1</strong>
<strong class="source-inline">    p_value = 1 - f.cdf(f_statistic,numeratorDegreesOfFreedom, denominatorDegreesOfFreedom)</strong>
<strong class="source-inline">    if p_value &lt;= 0.05:</strong>
<strong class="source-inline">        print('The distributions do not have homogenous variance. P-value = %.4f, </strong><strong class="source-inline">F-statistic = %.4f'%(p_value, f_statistic))</strong>
<strong class="source-inline">    else:</strong>
<strong class="source-inline">        print('The distributions have homogenous variance. P-value = %.4f, F-statistic = %.4f'%(p_value, f_statistic))</strong>
<strong class="source-inline">f_test(distro3['x'], distro1['x'])</strong></pre>
<p>This F-test <a id="_idIndexMarker348"/>output<a id="_idIndexMarker349"/> is <span class="No-Break">as follows:</span></p>
<p><strong class="source-inline">The distributions do not have homogenous variance. P-value = 0.0000, F-statistic = </strong><span class="No-Break"><strong class="source-inline">102622.9745</strong></span></p>
<h1 id="_idParaDest-71"><a id="_idTextAnchor075"/>T-test – a parametric hypothesis test</h1>
<p>In the last <a id="_idIndexMarker350"/>chapter, the z-test for means was applied when population standard <a id="_idIndexMarker351"/>deviations were known. However, in the real world, it is not easy (or virtually impossible) to obtain the population standard deviation. In this section, we will discuss another hypothesis test called the <strong class="bold">t-test</strong>, which is used when the population standard deviations are unknown. The mean and the standard deviation of a population are estimated by taking the mean and the standard deviation of sample data representative of <span class="No-Break">this population.</span></p>
<p>Broadly speaking, the method for the t-test for means is very similar to the one for the z-test for means, but the calculations for the test statistic and p-value are not the same as for the z-test. The test statistic is computed by the <span class="No-Break">following formula:</span></p>
<p><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Text">/</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>Here, <span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable"> </span> , <span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">s</span>, and <span class="_-----MathTools-_Math_Variable">n</span> are the sample mean, population mean, sample standard deviation, and sample size, respectively, which <a id="_idIndexMarker352"/>has a <span class="_-----MathTools-_Math_Variable">t</span><strong class="bold">-distribution</strong> when the sample data, <span class="_-----MathTools-_Math_Variable">x</span>, is normally distributed. The following code illustrates the standard normal distribution (blue curve) with 1,000 samples and t-distribution (green and red curves) with <a id="_idIndexMarker353"/>two <a id="_idIndexMarker354"/>sample sizes—3 and <span class="No-Break">16 samples:</span></p>
<pre class="source-code">
# libraries
import numpy as np
import scipy.stats as stats
# creating normal distribution
x =np.linspace(-5, 5, 1000) #create 1000 point from -5 to 5
y = stats.norm.pdf(x) # create probability density for each point x  - normal distribution
# creating Student t distributions for 2 sample sizes n =3 and n =15
degree_freedom1 = 2
t_dis1 = stats.t.pdf(x, degree_freedom1)
degree_freedom2 = 15
t_dis2 = stats.t.pdf(x, degree_freedom2)</pre>
<p>The following visuallization is for these 3 <span class="No-Break">distributions considered.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer057">
<img alt="Figure 4.9 – Normal and t-distributions" height="776" src="image/B18945_04_009.jpg" width="1264"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.9 – Normal and t-distributions</p>
<p>Observe that the<a id="_idIndexMarker355"/> three curves have similar symmetry and shapes but there is more variability (or, in other words, heavier tails) for a sample with a smaller size. Historically, researchers <a id="_idIndexMarker356"/>considered a sample standard deviation to represent the population when the sample size was greater than 30, that is, the red curve approximates the blue curve when <span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">&gt;</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">30</span>. It was also common to use the z-test if the sample distribution overlapped the standard normal distribution. This practice has some reasoning behind it because, previously, critical value tables were stored up to a sample size of 50, but nowadays, with the power of computation and the internet, the <em class="italic">t</em> values can be obtained easily with any <span class="No-Break">sample size.</span></p>
<h2 id="_idParaDest-72"><a id="_idTextAnchor076"/>T-test for means</h2>
<p>One-sample <a id="_idIndexMarker357"/>and two-sample t-tests related to a population mean or means of two populations where the population variances or population standard deviations are unknown will be considered in <span class="No-Break">this part.</span></p>
<p>To perform a t-test, the <a id="_idIndexMarker358"/>following assumptions need to <span class="No-Break">be satisfied:</span></p>
<p><strong class="bold">Normality</strong>: The sample is <span class="No-Break">normally distributed</span></p>
<p><strong class="bold">Independence</strong>: Observations are randomly selected from a population to form a sample or, in other<a id="_idIndexMarker359"/> words, they <span class="No-Break">are independent</span></p>
<p>Let us consider the one-sample t-test in the <span class="No-Break">following section.</span></p>
<h3>One-sample t-test</h3>
<p>Similar <a id="_idIndexMarker360"/>to the <a id="_idIndexMarker361"/>one-sample z-test, the null and alternative hypotheses need to be considered in order to perform the hypothesis test. Three null and alternative hypotheses corresponding to left-tailed, right-tailed, and two-tailed t-tests are presented <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">≥</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">≤</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">μ</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">0</span></span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">&lt;</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">&gt;</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">≠</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">μ</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">0</span></span></p>
<p>Next, the level of significance, <span class="_-----MathTools-_Math_Variable">α</span>, needs to be specified following the research purpose. There are two approaches: the p-value approach and the critical value approach. In the p-value approach, the rejection rule (reject <span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span>—the null hypothesis) is when the p-value is less than or equal to the specified level of significance chosen. In the critical value approach, the rejection rule is when the test statistic is less than or equal to the critical value <span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">α</span> for the left-tailed t-test, the test statistic is greater than or equal to <span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">α</span> for a right-tailed t-test, and the test statistic is less than or equal to <span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">α</span><span class="_-----MathTools-_Math_Text">/</span><span class="_-----MathTools-_Math_Number">2</span> or greater than or equal to <span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">α</span><span class="_-----MathTools-_Math_Text">/</span><span class="_-----MathTools-_Math_Number">2</span> for a two-tailed test. The last step is to interpret the statistical conclusion for the <span class="No-Break">hypothesis test.</span></p>
<p>To find the p-value based on the value of the student <span class="_-----MathTools-_Math_Variable">t</span> distribution, we can use the <span class="No-Break">following syntax:</span></p>
<pre class="source-code">
scipy.stats.t.sf(abs(x), df)</pre>
<p>Here, <strong class="source-inline">x</strong> is the test statistic and <strong class="source-inline">df</strong> is the degree of freedom (<strong class="source-inline">df</strong> = n-1 where <em class="italic">n</em> is the sample size) in <span class="No-Break">the formula.</span></p>
<p>For example, to find the p-value associated with a t-score of 1.9 with the degree of freedom 14 in a left-tailed test, this would be the <span class="No-Break">Python implementation:</span></p>
<pre class="source-code">
import scipy.stats
round(scipy.stats.t.sf(abs(1.9), df=14),4)</pre>
<p>The output would be 0.0391. If the level of significance <span class="_-----MathTools-_Math_Variable">α</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0.05</span>, then we reject the null hypothesis because the p-value is less than <span class="_-----MathTools-_Math_Variable">α</span><span class="_-----MathTools-_Math_Operator">.</span> For a right-tailed t-test, similar Python code as in the left-tailed t-test is implemented to find the p-value. For a two-tailed test, we need<a id="_idIndexMarker362"/> to multiply the value by 2, <span class="No-Break">as follows:</span></p>
<pre class="source-code">
scipy.stats.t.sf(abs(t), df)*2</pre>
<p>Here, <strong class="source-inline">t</strong> is the test statistic and <strong class="source-inline">df</strong> is the degree of freedom (<strong class="source-inline">df</strong> = n-1 where <em class="italic">n</em> is the <span class="No-Break">sample size).</span></p>
<p>To<a id="_idIndexMarker363"/> compute the critical value in Python, we use the <span class="No-Break">following syntax:</span></p>
<pre class="source-code">
scipy.stats.t.ppf(q, df)</pre>
<p>Here, <strong class="source-inline">q</strong> is the level of significance and <strong class="source-inline">df</strong> is the degree of freedom to be used in the formula. Here is the implementation of the code in Python for left-tailed, right-tailed, and <span class="No-Break">two-tailed tests:</span></p>
<pre class="source-code">
import scipy.stats as stats
alpha = 0.05 # level of significance
df= 15 # degree of freedom
#find t critical value for left-tailed test
print(f" The critical value is {stats.t.ppf(q= alpha, df =df)}")
#find t critical value for right-tailed test
print(f" The critical value is {stats.t.ppf(q= 1-alpha, df =df)}")
##find t critical value for two-tailed test
print(f" The critical values are {-stats.t.ppf(q= 1-alpha/2, df =df)} and {stats.t.ppf(q= 1-alpha/2, df =df)}")</pre>
<p>This is the output of the <span class="No-Break">preceding code:</span></p>
<ul>
<li>The critical value <span class="No-Break">is -1.7530503556925552</span></li>
<li>The critical value <span class="No-Break">is 1.7530503556925547</span></li>
<li>The critical values are -2.131449545559323 <span class="No-Break">and 2.131449545559323</span></li>
</ul>
<p>At the level <a id="_idIndexMarker364"/>of significance <span class="_-----MathTools-_Math_Variable">α</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0.05</span>, for the left-tailed test, the critical value is about -1.753. Since this is a left-tailed test, if the test statistic is less than or equal to this critical value, we reject the null hypothesis. Similarly, for the right-tailed test, if the test statistic is greater than or equal to 1.753, we reject the null hypothesis. For the two-tailed test, we reject the null hypothesis if the test statistic is greater than or equal to 2.1314 or less than or equal to -2.1314. Finally, we interpret the statistical conclusion for the <span class="No-Break">hypothesis testing.</span></p>
<p>Let us <a id="_idIndexMarker365"/>randomly choose 30 students from a high school and score their IQ. We would like to test the claim that the mean IQ score of the distribution of the students from this high school is higher than 100. This means that we will perform a right-tailed t-test. The IQ scores of 30 students are <span class="No-Break">given here:</span></p>
<pre class="source-code">
IQscores = [113, 107, 106, 115, 103, 103, 107, 102, 108, 107, 104, 104, 99, 102, 102, 105, 109, 97, 109, 103, 103, 100, 97, 107,116, 117, 105, 107, 104, 107]</pre>
<p>Before conducting the hypothesis testing, we will check normality and independence assumptions. The assumption of independence is satisfied if the sample is randomly selected from the population of high school students at this school. For normality, we will check the histogram and QQ plots of IQ <span class="No-Break">score data:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer058">
<img alt="Figure 4.10 – Visually assessing normality of student IQ scores" height="1030" src="image/B18945_04_010.jpg" width="1263"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.10 – Visually assessing normality of student IQ scores</p>
<p>There is little <a id="_idIndexMarker366"/>to no evidence from the histogram and QQ plot that the<a id="_idIndexMarker367"/> population IQ score distribution of the students at the high school is not normal. Since the distribution is assumed to be normal, we will proceed with <span class="No-Break">the t-test.</span></p>
<p>First, we define the null hypothesis and the <span class="No-Break">alternative hypothesis:</span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">≤</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">100</span></span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">&gt;</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">100</span></span></p>
<p>We choose the level of significance <span class="_-----MathTools-_Math_Variable">α</span>=0.05. You can calculate the test statistic by using its mathematical formula by hand or by implementing Python. For the critical value and p-value, the implemented code was shown in the previous part. Here, we will use another function from the <strong class="source-inline">scipy</strong> library to find the test statistic <span class="No-Break">and p-value:</span></p>
<pre class="source-code">
scipy.stats.ttest_1samp(data, popmean, alternative='greater')</pre>
<p>Here, the <span class="No-Break">following applies:</span></p>
<ul>
<li><strong class="source-inline">data</strong>: The observations from <span class="No-Break">the sample</span></li>
<li><strong class="source-inline">popmean</strong>: The expected value in the <span class="No-Break">null hypothesis</span></li>
<li><strong class="source-inline">alternative</strong>: <strong class="source-inline">'two-sided'</strong> for a two-tailed t-test, <strong class="source-inline">'less'</strong> for a left-tailed t-test, and <strong class="source-inline">'greater'</strong> for a <span class="No-Break">right-tailed t-test</span></li>
</ul>
<p>The <a id="_idIndexMarker368"/>Python code<a id="_idIndexMarker369"/> is implemented <span class="No-Break">as follows:</span></p>
<pre class="source-code">
import scipy.stats as stats
#perform one sample t-test
t_statistic, p_value = stats.ttest_1samp(IQscores, popmean =100, axis=0,  alternative='greater')
print(f"The test statistic is {t_statistic} and the corresponding p-value is {p_value}.")</pre>
<p>This is <span class="No-Break">the output:</span></p>
<p><strong class="source-inline">The test statistic is 6.159178830896832 and the corresponding p-value </strong><span class="No-Break"><strong class="source-inline">is 5.15076734562176e-07.</strong></span></p>
<p>Because the p-value &lt; 0.05 where 0.05 is the level of significance, we have enough evidence to reject the null hypothesis and conclude that the true mean IQ scores of the students from this school is higher <span class="No-Break">than 100.</span></p>
<p>In addition, with 95% confidence, the mean IQ score lies between 104.08 and 107.12. We can perform the calculation for the confidence interval in Python <span class="No-Break">as follows:</span></p>
<pre class="source-code">
IQmean = np.array(IQscores).mean() # sample mean
IQsd = np.array(IQscores).std() # sample standard deviation
sample_size = len(np.array(IQscores)) # sample size
df = sample_size-1 # degree of freedom
alpha = 0.05 # level of significance
t_crit = stats.t.ppf(q=1-alpha, df =df) # critical
confidence_interval = (IQmean-IQsd*t_crit/np.sqrt(sample_size), IQmean+IQsd*t_crit/np.sqrt(sample_size))</pre>
<p>The steps<a id="_idIndexMarker370"/> to <a id="_idIndexMarker371"/>perform a hypothesis test in Python using the left-tailed t-test are similar to those of the right-tailed and <span class="No-Break">two-tailed t-tests.</span></p>
<h2 id="_idParaDest-73"><a id="_idTextAnchor077"/>Two-sample t-test – pooled t-test</h2>
<p>Similar to <a id="_idIndexMarker372"/>what <a id="_idIndexMarker373"/>was covered in <a href="B18945_03.xhtml#_idTextAnchor055"><span class="No-Break"><em class="italic">Chapter 3</em></span></a><em class="italic">, Hypothesis Testing,</em> (two-sample z-test for means), the <a id="_idIndexMarker374"/>two-sample t-test for<a id="_idIndexMarker375"/> means has three forms for the null and alternative hypotheses. Some assumptions need to be <a id="_idIndexMarker376"/>satisfied before conducting the test, <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="bold">Normality</strong>: Two samples are drawn from their normally <span class="No-Break">distributed populations</span></li>
<li><strong class="bold">Independence</strong>: The observations of one sample are independent of <span class="No-Break">one another</span></li>
<li><strong class="bold">Homogeneity of variance</strong>: Both populations are assumed to have similar <span class="No-Break">standard deviations</span></li>
</ul>
<p>For normality, we use visual histograms and also QQ plots of the two samples and compare them. Let us assume independence is satisfied. In order to check equal standard deviations between the two samples, we could use visualization by observing their histograms and also use an F-test to have additional evidence if the visualization is inconclusive. This is a hypothesis test to check whether two sample variances <span class="No-Break">are equal.</span></p>
<p>Let us look at the IQ scores between two high schools, A and B. The following are the scores of 30 students from each school, <span class="No-Break">randomly selected:</span></p>
<pre class="source-code">
IQscoresA=[113, 107, 106, 115, 103, 103, 107, 102,108, 107,
            104, 104, 99, 102, 102, 105, 109, 97, 109, 103,
            103, 100, 97, 107, 116, 117, 105, 107, 104, 107]
IQscoresB = [102, 108, 110, 101, 98, 98, 97, 102, 102, 103,
             100, 99, 97, 97, 94, 100, 104, 98, 92, 104,
            98, 95, 92, 111, 102, 112, 100, 103, 103, 100]</pre>
<p>The histograms and QQ plots shown in <span class="No-Break">Figure 4</span>.11 are generated by the IQ <span class="No-Break">data above.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<img alt="Figure 4.11 – Assessing normality of two schools’ IQ scores" height="920" src="image/B18945_04_011.jpg" width="1205"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.11 – Assessing normality of two schools’ IQ scores</p>
<p>We can<a id="_idIndexMarker377"/> see that the normality assumption is satisfied. We also can <a id="_idIndexMarker378"/>assume by observing the histograms that the equal variance assumption is supported. Another F-test to check the equal variance assumption (if <span class="No-Break">necessary) follows:</span></p>
<pre class="source-code">
# F-test
import numpy as np
import scipy.stats as stats
IQscoresA = np.array(IQscoresA)
IQscoresB = np.array(IQscoresB)
f = np.var(IQscoresA, ddof=1)/np.var(IQscoresB, ddof=1) # F statistic
dfA = IQscoresA.size-1 #degrees of freedom A
dfB = IQscoresB.size-1 #degrees of freedom B
p = 1-stats.f.cdf(f, dfA, dfB) #p-value</pre>
<p>The output of <a id="_idIndexMarker379"/>the preceding code tells us the F-test statistic is 0.9963 and the corresponding p-value is 0.50394 &gt; 0.05 (0.05 is the level of significance), then we fail to reject the null hypothesis. This means that there is enough evidence to say that the standard deviations of these two samples <span class="No-Break">are equal.</span></p>
<p>We now define the null hypothesis and the <span class="No-Break">alternative hypothesis:</span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">A</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">μ</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">B</span></span><span class="No-Break">,</span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">A</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">≠</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">μ</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">B</span></span><span class="No-Break">.</span></p>
<p>We choose <a id="_idIndexMarker380"/>the level of significance <span class="_-----MathTools-_Math_Variable">α</span>=0.05. We use the <strong class="source-inline">statsmodels.stats.weightstats.ttest_ind</strong> function to conduct the t-test. The documentation can be found <span class="No-Break">here: </span><a href="https://www.statsmodels.org/dev/generated/statsmodels.stats.weightstats.ttest_ind.xhtml"><span class="No-Break">https://www.statsmodels.org/dev/generated/statsmodels.stats.weightstats.ttest_ind.xhtml</span></a><span class="No-Break">.</span></p>
<p>We can use this function to perform three forms of the alternate hypothesis with <strong class="source-inline">alternative='two-sided'</strong>, <strong class="source-inline">'larger'</strong>, or <strong class="source-inline">'smaller'</strong>. In the pooled-variance t-test, when the assumption for equal variances is satisfied, the test statistic is computed <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Base">‾</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">‾</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">____________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>Here, <span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Operator">and</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span> are sample means, population means, and sample sizes of two samples, 1 and 2 respectively, and the pooled standard deviation is <span class="No-Break">given here:</span></p>
<p><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">_______________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number">)</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">_______________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>The degree of freedom is <span class="No-Break">shown here:</span></p>
<p><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Variable">f</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Operator">.</span></span></p>
<p>Let’s go back to <span class="No-Break">the example:</span></p>
<pre class="source-code">
from statsmodels.stats.weightstats import ttest_ind as ttest
t_statistic, p_value, degree_freedom = ttest(IQscoresA,
    IQscoresB, alternative='two-sided', usevar='pooled')</pre>
<p>The output <a id="_idIndexMarker381"/>returns the test statistic 3.78 and the p-value 0.00037, and the<a id="_idIndexMarker382"/> degrees of freedom used in the t-test are 58 (each sample size has 30 observations, then the degrees of freedom are calculated as 30 + 30 - 2 = <span class="No-Break">58).</span></p>
<p>Because the p-value &lt;0.05, we reject the null hypothesis. There is sufficient evidence to suggest that there is a difference in mean IQ score between students at high schools A and B. To perform the confidence level, you can adapt the Python code in the last part of the <span class="No-Break">one-sample t-test.</span></p>
<p>Recall that in some situations, if the histograms and QQ plots show some evidence of skewness, we can consider testing the medians instead of the means for hypothesis testing. As shown in <a href="B18945_02.xhtml#_idTextAnchor029"><span class="No-Break"><em class="italic">Chapter 2</em></span></a><em class="italic">, Distributions of Data</em>, we can perform a data transformation (for example, log transformation) to obtain the normality assumption. After the transformation, the median of <strong class="source-inline">log(data)</strong> is equal to the mean of <strong class="source-inline">log(data)</strong>. This means that the test is performed on means of the <span class="No-Break">transformed data.</span></p>
<h2 id="_idParaDest-74"><a id="_idTextAnchor078"/>Two-sample t-test – Welch’s t-test</h2>
<p>This is a <a id="_idIndexMarker383"/>practical two-sample t-test when the data is normally distributed <a id="_idIndexMarker384"/>but the population standard deviations are <a id="_idIndexMarker385"/>unknown and unequal. We have the same assumption for normality as with a pooled t-test but we can relax the assumption for equal variance when performing Welch’s t-test. Let us consider the following example where we have two <span class="No-Break">sample datasets:</span></p>
<pre class="source-code">
sample1 = np.array([2,3,4,2,3,4,2,3,5,8,7,10])
sample2 = np.array([30,26,32,34,28,29,31,35,36,33,32,27])</pre>
<p>We assume the independence is satisfied, but we will check the normality and equal standard deviation assumptions for these two samples, <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer060">
<img alt="Figure 4.12 – Checking equal variance for Welch’s t-test" height="1012" src="image/B18945_04_012.jpg" width="1212"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.12 – Checking equal variance for Welch’s t-test</p>
<p>There is<a id="_idIndexMarker386"/> strong visual evidence against equal standard deviations <a id="_idIndexMarker387"/>by looking <a id="_idIndexMarker388"/>at the <em class="italic">x</em> axis scale of the histograms in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.12</em>. Let us assume the normality assumption is satisfied. In this case, a two-sample pooled t-test is not a good idea, but Welch’s t-test would suffice. The null and alternative hypotheses are <span class="No-Break">given here:</span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">μ</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">≠</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Variable">μ</span></span><span class="No-Break"><span class="_-----MathTools-_Math_Base"> </span></span><span class="No-Break"><span class="_-----MathTools-_Math_Number">2</span></span></p>
<p>We specify the level of significance 0.05. To calculate the test statistic and p-value, we implement the code <span class="No-Break">as follows:</span></p>
<pre class="source-code">
import scipy.stats as stats
t_statistic, p_value = stats.ttest_ind(sample1, sample2,
    equal_var = False)</pre>
<p>The test <a id="_idIndexMarker389"/>statistic is -22.47 and the p-value is &lt;0.05 (the level of significance). We reject <a id="_idIndexMarker390"/>the null hypothesis. There is <a id="_idIndexMarker391"/>strong evidence to suggest the mean of sample data 1 is different from the mean of sample <span class="No-Break">data 2.</span></p>
<h2 id="_idParaDest-75"><a id="_idTextAnchor079"/>Paired t-test</h2>
<p>The paired t-test<a id="_idIndexMarker392"/> is also known as a matched pairs or dependent t-test and is <a id="_idIndexMarker393"/>used in studies when each element in a sample is tested twice (pre-test and post-test or repeated measures) and when the researcher thinks that there are some similarities, such as family. The assumptions are set <span class="No-Break">out here:</span></p>
<ul>
<li>Differences are <span class="No-Break">normally distributed</span></li>
<li>Differences are independent between observations but dependent from one test to <span class="No-Break">another test</span></li>
</ul>
<p>The paired t-test is used in many studies, especially in medical reasoning tests related to pre- and post-treatments. Let’s go back to IQ test scores—a researcher recruits a number of students to see whether there is a score difference before and after a training section, as represented in the <span class="No-Break">following table:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table003-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Students</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Pre-training score</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Post-training score</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Differences</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>A</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">95</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">95</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>B</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">98</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">110</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">12</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>C</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">90</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">97</span></p>
</td>
<td class="No-Table-Style">
<p>7</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>D</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">115</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">112</span></p>
</td>
<td class="No-Table-Style">
<p>-3</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>E</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">112</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">117</span></p>
</td>
<td class="No-Table-Style">
<p>5</p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.13 – Pre-training and post-training scores</p>
<p>In this case, we should not use an independent two-sample t-test. The mean of the differences should be tested here. We can check the assumption about normal distribution by using<a id="_idIndexMarker394"/> histogram<a id="_idIndexMarker395"/> and QQ plots, <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer061">
<img alt="Figure 4.14 – Checking normality for the paired t-test" height="960" src="image/B18945_04_014.jpg" width="1201"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.14 – Checking normality for the paired t-test</p>
<p>Evidence for the data being normally distributed is more obvious by looking at the QQ plot than <span class="No-Break">the histogram.</span></p>
<p>The differences are assumed to be independent. The null and alternative hypotheses are <span class="No-Break">given here:</span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Variable">e</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">&gt;</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
<p><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span> denotes the difference between the pre-training score and the post-training score of each student. The null and alternative hypotheses can be rewritten <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
<p><span class="_-----MathTools-_Math_Variable">H</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">a</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">:</span><span class="_-----MathTools-_Math_Operator"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">&gt;</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
<p>Then, the test statistic is computed <span class="No-Break">like so:</span></p>
<p><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">√</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>Here, <span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">d</span><span class="_-----MathTools-_Math_Variable"> </span> is the <a id="_idIndexMarker396"/>sample mean of the differences and <span class="_-----MathTools-_Math_Variable">s</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">d</span> is the sample standard<a id="_idIndexMarker397"/> deviation of differences. In other words, a paired t-test is reduced to a one-sample t-test. However, we can use the following function in <span class="No-Break"><strong class="source-inline">scipy</strong></span><span class="No-Break"> directly:</span></p>
<p><strong class="source-inline">stats.ttest_rel(data_pos, data_pre, alternative = {'two-sided', '</strong><span class="No-Break"><strong class="source-inline">less', 'greater'})</strong></span></p>
<p>The alternative hypothesis corresponds to a left-tailed, right-tailed, or two-tailed test. Here is the Python implementation for the IQ test score <span class="No-Break">study example:</span></p>
<pre class="source-code">
from scipy import stats
IQ_pre = [95, 98, 90, 115, 112]
IQ_pos = [95, 110, 97, 112, 117]
t_statistic, p_value = stats.ttest_rel(IQ_pos, IQ_pre, alternative = 'greater')</pre>
<p>The test statistic is 1.594 and the p-value is 0.093. Therefore, given the p-value is &lt;0.05 and the level of significance <span class="_-----MathTools-_Math_Variable">α</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0.05</span><span class="_-----MathTools-_Math_Operator">,</span> we reject the null hypothesis. There is sufficient evidence to suggest that training has a significant effect on <span class="No-Break">IQ scores.</span></p>
<h1 id="_idParaDest-76"><a id="_idTextAnchor080"/>Tests with more than two groups and ANOVA</h1>
<p>In the previous chapter and previous sections, we covered tests between two groups. In this section, we will cover two methods for testing differences between groups, <span class="No-Break">as follows:</span></p>
<ul>
<li>Pairwise tests with the <span class="No-Break"><strong class="bold">Bonferroni correction</strong></span></li>
<li><span class="No-Break">ANOVA</span></li>
</ul>
<p>When testing for differences between more than two groups, we will have to use multiple tests, which will affect our <em class="italic">type I</em> error rate. There are several methods to control the error rate. We will see how to utilize the Bonferroni correction to control the <em class="italic">Type I</em> error rate. We will also discuss ANOVA in this section, which is used to test for a difference in means of <span class="No-Break">multiple groups.</span></p>
<h2 id="_idParaDest-77"><a id="_idTextAnchor081"/>Multiple tests for significance</h2>
<p>In the previous sections, we <a id="_idIndexMarker398"/>looked at making a comparison between two groups. In this section, we will consider how to perform tests when there are more than two groups present. Let’s again consider the factory example where we have several models (model A, model B, and model C) of machines on a factory floor, and these machines are used to perform the same operation in the factory. A plausible question of interest is: <em class="italic">Does one machine model have a higher mean output than the other two models?</em> To make this determination, we would need to do three tests comparing the difference in means of each model to the other models, testing that the difference in means is different than zero. These are the null hypotheses we would need <span class="No-Break">to test:</span></p>
<p><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Variable">A</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Variable">B</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
<p><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Variable">B</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Variable">C</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
<p><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Variable">A</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">o</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Variable">u</span><span class="_-----MathTools-_Math_Variable">t</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Variable">C</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
<p>When performing multiple tests, we will need to apply p-value corrections for our expected error rate. Recall that in <a href="B18945_03.xhtml#_idTextAnchor055"><span class="No-Break"><em class="italic">Chapter 3</em></span></a><em class="italic">, Hypothesis Testing</em>, we defined the expected error rate for a hypothesis test as <span class="_-----MathTools-_Math_Variable">α</span>. This is the rate at which we expect a <em class="italic">single</em> hypothesis test to result in a <em class="italic">Type I</em> error. In our example with factory machines, we are making three hypothesis tests, which means <em class="italic">we are three times more likely to see a Type I error</em>. While our example specifically considers multiple tests for differences in means, this applies to any type of hypothesis test. In these situations with multiple tests, we will generally define <a id="_idIndexMarker399"/>a <strong class="bold">familywise error rate</strong> (<strong class="bold">FWER</strong>) and apply p-value corrections to control for the FWER. The FWER is the probability of making a <em class="italic">Type I</em> error from a group of hypothesis tests. The error rate from tests within the group is <a id="_idIndexMarker400"/>the <strong class="bold">individual error rate</strong> (<strong class="bold">IER</strong>). We will define the IER and FWER <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="bold">IER</strong>: The expected <em class="italic">Type I</em> error rate for an individual <span class="No-Break">hypothesis test</span></li>
<li><strong class="bold">FWER</strong>: The <a id="_idIndexMarker401"/>expected <em class="italic">Type I</em> error rate for a group of <span class="No-Break">hypothesis tests</span></li>
</ul>
<p>We will discuss one method for p-value correction in this section to provide intuition for <span class="No-Break">the rationale.</span></p>
<h3>The Bonferroni correction</h3>
<p>One method<a id="_idIndexMarker402"/> for adjusting the p-value to control multiple hypothesis tests is the Bonferroni correction. The Bonferroni correction controls the FWER by uniformly reducing the significance level of each individual test in the family of tests. Given that we have <span class="_-----MathTools-_Math_Variable">m</span> tests in a family each with the p-value <span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span>, then the p-value correction is given <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">p</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">≤</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">α</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">m</span><span class="_-----MathTools-_Math_Variable"> </span></p>
<p>Taking our previous example of three models of machines, we have a family of three tests, making <span class="_-----MathTools-_Math_Variable">m</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span>. If we let FWER be 0.05, then, with the Bonferroni correction, the level of significance for the three individual tests <span class="No-Break">is this:</span></p>
<p><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0.05</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Number"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">0.0167</span></span></p>
<p>Thus, in this example, any of the individual tests would be required to have a p-value of 0.0167 to be <span class="No-Break">considered significant.</span></p>
<p class="callout-heading">Effects on Type I and Type II errors</p>
<p class="callout">As discussed, the Bonferroni correction reduces the significance levels of individual tests to control the <em class="italic">Type I</em> error rate at<a id="_idIndexMarker403"/> the family level. We should also consider how this change impacts <a id="_idIndexMarker404"/>the <em class="italic">Type II</em> error rate. In general, reducing the significance level of individual tests will increase the chance of making a <em class="italic">Type II</em> error for that test (as is done in the Bonferroni correction). While we have only discussed the Bonferroni correction in this section, there are other methods for p-value correction that provide different trade-offs. Check the documentation of <strong class="source-inline">multipletests</strong> in <strong class="source-inline">statsmodels</strong> to see a list of p-value corrections implemented <span class="No-Break">in </span><span class="No-Break"><strong class="source-inline">statsmodels</strong></span><span class="No-Break">.</span></p>
<p>Let’s take a look at an example using the miles per gallon (MPG) data from the <em class="italic">Auto MPG</em> dataset from the <em class="italic">UCI Machine Learning Repository</em>, which can be found at this link: <a href="https://archive.ics.uci.edu/ml/datasets/Auto+MPG">https://archive.ics.uci.edu/ml/datasets/Auto+MPG</a> [1]. This dataset contains various attributes, including <strong class="source-inline">origin</strong>, <strong class="source-inline">mpg</strong>, <strong class="source-inline">cylinders</strong>, and <strong class="source-inline">displacement</strong>, for vehicles manufactured between 1970 and 1982. We will show an abbreviated form of the analysis here; the full analysis is included in the notebook in the code repository for <span class="No-Break">this chapter.</span></p>
<p>For this<a id="_idIndexMarker405"/> example, we will use the <strong class="source-inline">mpg</strong> and <strong class="source-inline">origin</strong> variables, and test whether there is a difference in <strong class="source-inline">mpg</strong> from the different origins with a significance level of 0.01. The group means are shown in the following table (<strong class="source-inline">origin</strong> is an integer-encoded label in <span class="No-Break">this dataset).</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table004">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold">Vehicle </strong><span class="No-Break"><strong class="bold">origin</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="source-inline">origin</strong></span><span class="No-Break">)</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">MPG</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="source-inline">mpg</strong></span><span class="No-Break">)</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">20.0</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>2</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">27.9</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>3</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">30.5</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.15 – Vehicle MPG means for each origin group</p>
<p>Running a t-test to compare each mean, we get the <span class="No-Break">following p-values:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table005">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Null hypothesis</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Uncorrected p-value</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">7.946116336281346e-12</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">4.608511957238898e-19</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.0420926104552266</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.16 – Uncorrected p-values for t-tests on the difference between each group</p>
<p>Applying the Bonferroni correction to the p-values, we get the <span class="No-Break">following p-values:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table006">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Null hypothesis</strong></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold">Corrected </strong><span class="No-Break"><strong class="bold">p-value (Bonferroni)</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">2.38383490e-11</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">1.38255359e-18</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">3</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.126277831</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.17 – Corrected p-values for t-tests on the difference between each group</p>
<p>With the preceding p-values, reject the null hypothesis for a difference in the means of groups 1 and 2 and a<a id="_idIndexMarker406"/> difference in the means of groups 1 and 3, but fail to reject the null hypothesis for a difference in the means of groups 2 and 3 at our significance level <span class="No-Break">of 0.01.</span></p>
<p class="callout-heading">Other p-value correction methods</p>
<p class="callout">In this section, we only discussed one method for p-value correction—the Bonferroni correction—to provide intuition for the rationale of p-value corrections. However, there are other correction methods available that might be better suited for your problem. To see a list of p-value correction methods implemented within <strong class="source-inline">statsmodels</strong>, check the documentation <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">statsmodels.stats.multitest.multipletests</strong></span><span class="No-Break">.</span></p>
<h2 id="_idParaDest-78"><a id="_idTextAnchor082"/>ANOVA</h2>
<p>In the previous<a id="_idIndexMarker407"/> section on multiple tests for significance, we saw how to perform multiple tests to determine whether means differed between groups. When dealing with means of groups, a useful first task is to conduct an analysis of variance. ANOVA is a statistical test for determining whether there is a difference between means of several groups. The null hypothesis is there is no difference in means, and the alternative hypothesis is the means are not all equal. Since ANOVA tests for a difference in means, it is commonly used before testing for a difference in means with pairwise hypothesis tests. If the ANOVA null hypothesis fails to be rejected, then there is no need to perform the pairwise tests. However, if the ANOVA null hypothesis is rejected, then pairwise tests can be performed to determine which specific <span class="No-Break">means differ.</span></p>
<p class="callout-heading">ANOVA versus pairwise tests</p>
<p class="callout">While <a id="_idIndexMarker408"/>pairwise testing is a general procedure for testing for differences <a id="_idIndexMarker409"/>between groups, ANOVA can only be used to test for differences <span class="No-Break">in means.</span></p>
<p>In this example, we will again consider the MPG of vehicles from the <em class="italic">Auto MPG</em> dataset. Since we have already run pairwise tests and found a significant difference in the mean mpg of vehicles based on origin, we expect that ANOVA will provide a positive test result (reject the null hypothesis). Performing the ANOVA calculation, we get the following output. The small p-value suggests that we should reject the <span class="No-Break">null hypothesis:</span></p>
<pre class="source-code">
anova = anova_oneway(data.mpg, data.origin, use_var='equal')
print(anova)
# statistic = 98.54179491075868
# pvalue = 1.915486418412936e-35</pre>
<p>The ANOVA analysis <a id="_idIndexMarker410"/>shown here is abbreviated. For the full code, see the associated notebook in the code repository for <span class="No-Break">this chapter.</span></p>
<p>In this section, we covered methods for performing hypothesis tests for more than two groups of data. The first method was pairwise testing with p-value correction, which is a general method that can be used for any type of hypothesis test. The other method we covered was ANOVA, which is a specific test for differences in the means of groups. This is not a general method such as pairwise testing but can be used as a first step before performing pairwise tests for differences in means. In the next section, we cover another type of parametric test that can be used to determine whether two sets of data <span class="No-Break">are correlated.</span></p>
<h2 id="_idParaDest-79"><a id="_idTextAnchor083"/>Pearson’s correlation coefficient</h2>
<p><strong class="bold">Pearson’s correlation coefficient</strong>, also called Pearson’s <em class="italic">r</em> (or Pearson’s rho (<em class="italic">ρ</em>) when applied to population data) or the <strong class="bold">Pearson product-moment sample coefficient of correlation (PPMCC)</strong>, is a <a id="_idIndexMarker411"/>bivariate test that measures the linear correlation between two<a id="_idIndexMarker412"/> variables. The coefficient produces a value ranging from -1 to 1 where -1 is a strong, inverse correlation and 1 is a strong, direct correlation. A zero-valued coefficient indicates no correlation between the two variables. Weak correlation is generally considered to be correlation between +/- 0.1 and +/- 0.3, moderate correlation is between +/- 0.3 and +/- 0.5, and strong correlation is between +/- 0.5 to +/- <span class="No-Break">1.0.</span></p>
<p>This test<a id="_idIndexMarker413"/> is considered parametric but does not require assumptions of normal distribution or homogeneity of variance. It is, however, required that data be independently sampled (both randomly selected and without serial correlation), have finite variance—such as with a distribution that has a very heavy tail—and be of a continuous data type. The test does not indicate an input variable and a response variable; it is simply a measure of the linear relation between two variables. The test uses standardized covariance to derive correlation. Recall that standardization requires dividing a value by the <span class="No-Break">standard deviation.</span></p>
<p>The equation for the population Pearson’s coefficient, <span class="_-----MathTools-_Math_Variable">ρ</span>, is <span class="No-Break">shown here:</span></p>
<p><span class="_-----MathTools-_Math_Variable">ρ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>Here, <span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">y</span> is the population covariance, calculated <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">σ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">∑</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">μ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">_____________</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">N</span><span class="_-----MathTools-_Math_Variable"> </span></p>
<p>The equation for the sample Pearson’s coefficient, <em class="italic">r</em>, is <span class="No-Break">shown here:</span></p>
<p><span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span></p>
<p>Here, <span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">y</span> is the sample covariance, calculated <span class="No-Break">as follows:</span></p>
<p><span class="_-----MathTools-_Math_Variable">S</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">∑</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">x</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base">(</span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">)</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">____________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Number"> </span></p>
<p>In Python, we can perform this test using the <strong class="source-inline">scipy</strong> <strong class="source-inline">scipy.stats.pearsonr</strong> function. In the following code snippet, we generate two normally distributed datasets of random numbers using <strong class="source-inline">numpy</strong>. We want to test the hypothesis that there is a correlation between the two groups since there is some <span class="No-Break">significant overlap:</span></p>
<pre class="source-code">
<strong class="source-inline">from scipy.stats import pearsonr</strong>
<strong class="source-inline">import matplotlib.pyplot as plt</strong>
<strong class="source-inline">import scipy.stats as stats</strong>
<strong class="source-inline">import seaborn as sns</strong>
<strong class="source-inline">import pandas as pd</strong>
<strong class="source-inline">import numpy as np</strong>
<strong class="source-inline">mu1, sigma1 = 0, 1.1</strong>
<strong class="source-inline">normally_distributed_1 = np.random.normal(mu1, sigma1, 1000)</strong>
<strong class="source-inline">mu2, sigma2 = 0, 0.7</strong>
<strong class="source-inline">normally_distributed_2 = np.random.normal(mu2, sigma2,</strong>
    <strong class="source-inline">1000)</strong>
<strong class="source-inline">df_norm = pd.DataFrame({'Distribution':['Distribution 1' for i in range(len(normally_distributed_1))] + ['Distribution 2' for i in range(len(normally_distributed_2))], 'X':np.concatenate([normally_distributed_1, normally_distributed_2])})</strong></pre>
<p>In <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.18</em>, we <a id="_idIndexMarker414"/>can observe the overlapping variance of the two <span class="No-Break">correlated distributions:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer062">
<img alt="Figure 4.18 – Correlated distributions" height="566" src="image/B18945_04_018.jpg" width="1080"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.18 – Correlated distributions</p>
<p>In the plot <a id="_idIndexMarker415"/>shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.18</em>, we can see the overlap of the populations. Now, we want to test the correlation using the <strong class="source-inline">pearsonr()</strong> function, <span class="No-Break">as follows:</span></p>
<pre class="source-code">
<strong class="source-inline">p, r = pearsonr(df_norm.loc[df_norm['Distribution'] == 'Distribution 1', 'X'], df_norm.loc[df_norm['Distribution'] == 'Distribution 2', 'X'])</strong>
<strong class="source-inline">print("p-value = %.4f"%p)</strong>
<strong class="source-inline">print("Correlation coefficient = %.4f"%r)</strong></pre>
<p>The following output indicates that at a 0.05 level of significance, we have a 0.9327 level of correlation (p-value <span class="No-Break">is 0.0027):</span></p>
<p><strong class="source-inline">p-value = </strong><span class="No-Break"><strong class="source-inline">0.0027</strong></span></p>
<p><strong class="source-inline">Correlation coefficient = </strong><span class="No-Break"><strong class="source-inline">0.9327</strong></span></p>
<p>To frame the correlation differently, we could say the level of variance explained (<span class="_-----MathTools-_Math_Variable">r</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span>, also <a id="_idIndexMarker416"/>called <strong class="bold">goodness-of-fit</strong> or the <strong class="bold">coefficient of determination</strong>) in <a id="_idIndexMarker417"/>distribution 2 by distribution 1 is <span class="_-----MathTools-_Math_Number">0.9327</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">87</span><span class="_-----MathTools-_Math_Text">%</span>, assuming we know that distribution 2 is a response to distribution 1. Otherwise, we could simply say there is a correlation of 0.93 or an 87% level of variance explained in the relationship between the <span class="No-Break">two variables.</span></p>
<p>Now, let us look at the <em class="italic">Motor Trend Car Road Tests</em> dataset from R, which we import using the <strong class="source-inline">statsmodels datasets.get_rdataset</strong> function. Here, we have the first five rows, which have the variables for miles per gallon (<strong class="source-inline">mpg</strong>), number of cylinders (<strong class="source-inline">cyl</strong>), engine displacement (<strong class="source-inline">disp</strong>), horsepower (<strong class="source-inline">hp</strong>), rear-axle gear ratio (<strong class="source-inline">drat</strong>), weight (<strong class="source-inline">wt</strong>), minimum time to drive a quarter of a mile (<strong class="source-inline">qsec</strong>), engine shape (<strong class="source-inline">vs=0</strong> for v-shaped and <strong class="source-inline">vs=1</strong> for inline), transmission (<strong class="source-inline">am=0</strong> for automatic and <strong class="source-inline">am=1</strong> for manual), number <a id="_idIndexMarker418"/>of gears (<strong class="source-inline">gear</strong>), and number of carburetors (<strong class="source-inline">carb</strong>) (if not <span class="No-Break">fuel injected):</span></p>
<pre class="source-code">
<strong class="source-inline">import statsmodels.api as sm</strong>
<strong class="source-inline">df_cars = sm.datasets.get_rdataset("mtcars","datasets").data</strong></pre>
<p>In <span class="No-Break">Figure 4</span>.19, we can see the first five rows of the data set, which contains data suitable for Pearson's <span class="No-Break">correlation analysis.</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table007">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">mpg</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">cyl</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">disp</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">hp</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">drat</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">wt</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">qsec</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">Vs</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">am</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">gear</strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold">carb</strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">21</span></p>
</td>
<td class="No-Table-Style">
<p>6</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">160</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">110</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">3.9</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">2.62</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">16.46</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>4</p>
</td>
<td class="No-Table-Style">
<p>4</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">21</span></p>
</td>
<td class="No-Table-Style">
<p>6</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">160</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">110</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">3.9</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">2.875</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">17.02</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>4</p>
</td>
<td class="No-Table-Style">
<p>4</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">22.8</span></p>
</td>
<td class="No-Table-Style">
<p>4</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">108</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">93</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">3.85</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">2.32</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">18.61</span></p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>4</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">21.4</span></p>
</td>
<td class="No-Table-Style">
<p>6</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">258</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">110</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">3.08</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">3.215</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">19.44</span></p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>3</p>
</td>
<td class="No-Table-Style">
<p>1</p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">18.7</span></p>
</td>
<td class="No-Table-Style">
<p>8</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">360</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">175</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">3.15</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">3.44</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">17.02</span></p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>0</p>
</td>
<td class="No-Table-Style">
<p>3</p>
</td>
<td class="No-Table-Style">
<p>2</p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.19 – first five rows from the mtcars dataset</p>
<p>Using the dataset, we can plot a correlation matrix with the following code, which shows each pairwise correlation for all features in the dataset to see how they relate to <span class="No-Break">one another:</span></p>
<pre class="source-code">
<strong class="source-inline">sns.set_theme(style="white")</strong>
<strong class="source-inline">corr = df_cars.corr()</strong>
<strong class="source-inline">f, ax = plt.subplots(figsize=(15, 10))</strong>
<strong class="source-inline">cmap = sns.diverging_palette(250, 20, as_cmap=True)</strong>
<strong class="source-inline">sns.heatmap(corr, cmap=cmap, vmax=.4, center=0,</strong>
<strong class="source-inline">            square=True, linewidths=.5, annot=True)</strong></pre>
<p>Suppose we are curious about the variables most meaningful for quarter-mile time (<strong class="source-inline">qsec</strong>). In <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.20</em>, we can see by looking at the line for <strong class="source-inline">qsec</strong> that <strong class="source-inline">vs</strong> (v-shaped) is positively correlated at 0.74. Since this is a binary variable, we can assume, based on this dataset, that<a id="_idIndexMarker419"/> inline engines are faster than v-shaped engines. However, there are other covariates involved with significant correlation. For example, almost as strongly correlated with speed as engine shape is horsepower, such that as horsepower goes up, quarter-mile runtime <span class="No-Break">goes down:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer063">
<img alt="Figure 4.20 – Correlation matrix heatmap" height="945" src="image/B18945_04_020.jpg" width="1099"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.20 – Correlation matrix heatmap</p>
<p>A correlation matrix is useful for exploring the relationships between multiple variables at one time. It is also a useful tool <a id="_idIndexMarker420"/>for feature selection when building statistical <a id="_idIndexMarker421"/>and <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) models, such as <span class="No-Break">linear regression.</span></p>
<h2 id="_idParaDest-80"><a id="_idTextAnchor084"/>Power analysis examples</h2>
<p>Power analysis is<a id="_idIndexMarker422"/> a statistical method for identifying an appropriate sample size required for a hypothesis test to have sufficient power in preventing <em class="italic">Type II</em> errors – or failing to reject the null hypothesis when the null hypothesis should be rejected. Power analysis can also be used for identifying, based on sample size, a detectable effect size (or difference) between samples tested. In other words, based on a specific sample size and distribution, a power analysis can provide the analyst with a specific minimum difference the researcher may be able to reliably identify with a given test. In this section, we will demonstrate a power analysis using a <span class="No-Break">one-sample t-test.</span></p>
<h3>One-sample t-test</h3>
<p>Let’s <a id="_idIndexMarker423"/>assume a manufacturer sells a type of machine capable <a id="_idIndexMarker424"/>of producing 100,000 units per month with a standard deviation of 2,800 units. A company has bought a number of these machines and has found them to only be producing 90,000 units. The company wants to know how many of the machines are needed to determine with a high level of confidence the machines are not capable of producing 100,000 units. The following power analysis indicates that for a t-test, a sample of three machines is required to prevent, with an 85% probability, failing to identify a statistically significant difference in actual versus marketed machine performance when there <span class="No-Break">is one:</span></p>
<pre class="source-code">
<strong class="source-inline">from statsmodels.stats.power import TTestPower</strong>
<strong class="source-inline">import numpy as np</strong>
<strong class="source-inline"># Difference of distribution mean and the value to be assessed divided by the distribution standard deviation</strong>
<strong class="source-inline">effect_size = abs(100000-90000) / 2800</strong>
<strong class="source-inline">powersTT = TTestPower()</strong>
<strong class="source-inline">result = powersTT.solve_power(effect_size, nobs=3, alpha=0.05, alternative='two-sided')</strong>
<strong class="source-inline">print('Power based on sample size:{}'.format(round(result,2)))</strong>
<strong class="source-inline"># Power based on sample size: 0.85</strong></pre>
<h3>Additional power analysis example</h3>
<p>To <a id="_idIndexMarker425"/>see additional examples of power analysis in Python, please refer to this book’s GitHub repository. There, we have examples for additional t-tests and F-tests, which focus on analyzing variance between <span class="No-Break">sample groups.</span></p>
<h1 id="_idParaDest-81"><a id="_idTextAnchor085"/>Summary</h1>
<p>This chapter covered topics of parametric tests. Starting with the assumptions of parametric tests, we identified and applied methods for testing the violation of these assumptions and discussed scenarios where robustness can be assumed when the required assumptions are not met. We then looked at one of the most popular alternatives to the z-test, the t-test. We iterated through multiple applications of this test, covering one-sample and two-sample versions of this test using pooling, pairing, and Welch’s non-pooled version of the two-sample analysis. Next, we explored ANOVA techniques, where we looked at using data from multiple groups to identify statistically significant differences between them. This included one of the most popular adjustments to the p-value for when a high volume of groups is present—the Bonferroni correction, which helps prevent inflating the <em class="italic">Type I</em> error when performing multiple tests. We then looked at performing correlation analysis on continuous data using Pearson’s correlation coefficient and how to visualize correlation using a correlation matrix and accompanying heatmap. Finally, we briefly overviewed power analysis, with an example of performing this with a one-sample t-test. In the next chapter, we will discuss non-parametric hypothesis testing, including new tests in addition to those that pair with the parametric tests in this chapter for when assumptions cannot be <span class="No-Break">safely assumed.</span></p>
<h1 id="_idParaDest-82"><a id="_idTextAnchor086"/>References</h1>
<p>[1] <em class="italic">Dua, D.</em> and <em class="italic">Graff, C.</em> (<em class="italic">2019</em>). <em class="italic">UCI Machine Learning Repository</em> [<a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>]. <em class="italic">Irvine, CA: University of California, School of Information and </em><span class="No-Break"><em class="italic">Computer Science</em></span><span class="No-Break">.</span></p>
</div>
</div></body></html>