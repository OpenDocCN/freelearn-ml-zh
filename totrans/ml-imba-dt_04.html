<html><head></head><body>
		<div id="_idContainer078">
			<h1 id="_idParaDest-82" class="chapter-number"><a id="_idTextAnchor120"/>4</h1>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor121"/>Ensemble Methods</h1>
			<p><a id="_idTextAnchor122"/>Think of a top executive at a major company. They don’t make decisions on their own. Throughout the day, they need to make numerous critical decisions. How do they make those choices? Not alone, but by consulting <span class="No-Break">their advisors.</span></p>
			<p>Let’s say that an executive consults five different advisors from different departments, each proposing a slightly different solution based on their expertise, skills, and domain knowledge. To make the most effective decision, the executive combines the insights and opinions of all five advisors to create a hybrid solution that incorporates the best parts of each proposal. This <a id="_idIndexMarker259"/>scenario illustrates the concept of <strong class="bold">ensemble methods</strong>, where multiple weak classifiers are combined to create a stronger and more accurate classifier. By combining different approaches, ensemble methods can often achieve better performance than relying on a <span class="No-Break">single classifier.</span></p>
			<p>We can create a strong model through ensemble methods by combining the results from multiple weak classifiers. These weak classifiers, such as simplified decision trees, neural networks, or support vector machines, perform slightly better than random guessing. In contrast, a strong model, created by ensembling these weak classifiers, performs significantly better than random guessing. The weak classifiers can be fed different sources of information. There are two general approaches for building ensembles of models: bagging <span class="No-Break">and boosting.</span></p>
			<p>The problem with traditional ensemble methods is that they use classifiers that assume balanced data. Thus, they may not work very well with imbalanced datasets. So, we combine the popular machine learning ensembling methods with the techniques for dealing with imbalanced data that we studied in previous chapters. We are going to discuss those combinations in <span class="No-Break">this chapter.</span></p>
			<p>Here are the topics that will be covered in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Bagging techniques for <span class="No-Break">imbalanced data</span></li>
				<li>Boosting techniques for <span class="No-Break">imbalanced data</span></li>
				<li>Ensemble <span class="No-Break">of ensembles</span></li>
				<li>Model <span class="No-Break">performance comparison</span></li>
			</ul>
			<p>In <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.1</em>, we have categorized the various ensembling techniques that we will cover in <span class="No-Break">this chapter:</span></p>
			<div>
				<div id="_idContainer058" class="IMG---Figure">
					<img src="image/B17259_04_01.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – Overview of ensembling techniques</p>
			<p>By the end of this chapter, you will understand how to adapt ensemble models such as bagging and boosting to account for class imbalances <span class="No-Break">in datasets.</span></p>
			<h1 id="_idParaDest-84"><a id="_idTextAnchor123"/>Technical requirements</h1>
			<p><a id="_idTextAnchor124"/>The Python notebooks for this chapter are available on GitHub at <a href="https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter04">https://github.com/PacktPublishing/Machine-Learning-for-Imbalanced-Data/tree/master/chapter04</a>. As usual, you can open the GitHub notebook using Google Colab by clicking on the <strong class="bold">Open in Colab</strong> icon at the top of this chapter’s notebook or by launching it from <a href="https://colab.research.google.com">https://colab.research.google.com</a> using the GitHub URL of <span class="No-Break">the notebook.</span></p>
			<p>In this chapter, we will continue to use a synthetic dataset generated using the <strong class="source-inline">make_classification</strong> API, just as we did in the previous chapters. Toward the end of this chapter, we will test the methods we learned in this chapter on some real datasets. Our full dataset contains 90,000 examples with a 1:99 imbalance ratio. Here is what the training dataset <span class="No-Break">looks like:</span></p>
			<div>
				<div id="_idContainer059" class="IMG---Figure">
					<img src="image/B17259_04_02.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – Plot of a dataset with a 1:99 imbalance ratio</p>
			<p>With our imbalanced dataset ready to use, let’s look at the first ensembling method, <span class="No-Break">called bagging.</span></p>
			<h1 id="_idParaDest-85"><a id="_idTextAnchor125"/>Bagging techniques for imbalanced data</h1>
			<p>Imagine a business executive with thousands of confidential files regarding an important merger <a id="_idIndexMarker260"/>or acquisition. The analysts assigned to the case don’t have enough time to review all the files. Each can randomly select some files from the set and start reviewing them. Later, they can combine their insights in a meeting to <span class="No-Break">draw conclusions.</span></p>
			<p>This scenario <a id="_idIndexMarker261"/>is a metaphor for a process in machine learning called bagging [1], which is short for <strong class="bold">bootstrap aggregating</strong>. In bagging, much like the analysts in the previous scenario, we create several subsets of the original dataset, train a weak learner on each subset, and then aggregate <span class="No-Break">their predictions.</span></p>
			<p>Why use weak learners instead of strong learners? The rationale applies to both bagging and boosting methods (discussed later in this chapter). There are <span class="No-Break">several reasons:</span></p>
			<ul>
				<li><strong class="bold">Speed</strong>: Weak learners are computationally efficient and inexpensive <span class="No-Break">to execute.</span></li>
				<li><strong class="bold">Diversity</strong>: Weak learners are more likely to make different types of errors, which is advantageous when combining their predictions. Using strong learners could result in them all making the same type of error, leading to less <span class="No-Break">effective ensembles.</span></li>
				<li><strong class="bold">Overfitting</strong>: As a corollary to the previous point, the diversity in errors helps reduce the risk of overfitting in <span class="No-Break">the ensemble.</span></li>
				<li><strong class="bold">Interpretability</strong>: While the ensemble as a whole may not be easily interpretable, its individual components – often simpler models – are easier to understand <span class="No-Break">and interpret.</span></li>
			</ul>
			<p>Now, back to <a id="_idIndexMarker262"/>bagging. The first step of the algorithm is called <strong class="bold">bootstrapping</strong>. In this step, we make several subsets or smaller groups of data by randomly picking items from the main data. The data is picked with the possibility of picking the same item more than once (this process is called “random sampling with replacement”), so these smaller groups may have some items in common. Then, we train our classifiers on each of these <span class="No-Break">smaller groups.</span></p>
			<p>The second <a id="_idIndexMarker263"/>step is called <strong class="bold">aggregating</strong>. The test sample is passed to each classifier at the time of prediction. After this, we take the average or majority prediction as the <span class="No-Break">real answer.</span></p>
			<p>As shown in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.3</em>, the dataset is first sampled with replacement into three subsets. Then, separate classifiers are trained on each of the subsets. Finally, the results of the <a id="_idIndexMarker264"/>classifiers are combined at the time <span class="No-Break">of prediction:</span></p>
			<div>
				<div id="_idContainer060" class="IMG---Figure">
					<img src="image/B17259_04_03.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.3 – Demonstrating how bagging works</p>
			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.4</em> summarizes the bagging algorithm in a <span class="No-Break">pseudocode format:</span></p>
			<div>
				<div id="_idContainer061" class="IMG---Figure">
					<img src="image/B17259_04_04.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.4 – Bagging pseudocode</p>
			<p>We’ll train a bagging classifier model from <strong class="source-inline">sklearn</strong> on the dataset we created previously. Since it’s possible to provide a base estimator to <strong class="source-inline">BaggingClassifier</strong>, we’ll use <strong class="source-inline">DecisionTreeClassifier</strong> with the maximum depth of the trees <span class="No-Break">being </span><span class="No-Break"><strong class="source-inline">6</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
from sklearn.ensemble import BaggingClassifier
from sklearn.metrics import PrecisionRecallDisplay
clf = BaggingClassifier(\
    estimator=DecisionTreeClassifier(max_depth=6), random_state=0
).fit(X_train, y_train)</pre>			<p>Let’s <a id="_idIndexMarker265"/>plot the <span class="No-Break">decision boundary:</span></p>
			<pre class="source-code">
plot_decision_boundary(X_train, y_train, clf, 'BaggingClassifier')
plt.show()</pre>			<p>You may refer to the definition of <strong class="source-inline">plot_decision_boundary()</strong> in the corresponding notebook on GitHub. We use the <strong class="source-inline">DecisionBoundaryDisplay</strong> API from the <strong class="source-inline">sklearn.inspection</strong> module to plot the <span class="No-Break">decision boundary.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.5</em> shows the learned decision boundary on the <span class="No-Break">training data:</span></p>
			<div>
				<div id="_idContainer062" class="IMG---Figure">
					<img src="image/B17259_04_05.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.5 – The decision boundary of BaggingClassifier on the training data</p>
			<p>Let’s also <a id="_idIndexMarker266"/>note the baseline metric of average precision when using this model on our <span class="No-Break">test set:</span></p>
			<pre class="source-code">
PrecisionRecallDisplay.from_estimator(
    clf, X_test, y_test, ax = plt.gca(),name = "BaggingClassifier")</pre>			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.6</em> shows the resulting <span class="No-Break">PR curve:</span></p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/B17259_04_06.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.6 – Precision-recall curve of BaggingClassifier on the test data</p>
			<p>Here are some <span class="No-Break">other metrics:</span></p>
			<pre class="source-code">
Average Precision Score: 0.969
AUC-ROC Score: 0.999
F2-score: 0.891
Precision: 0.967
Recall: 0.874</pre>			<p>In this <a id="_idIndexMarker267"/>chapter, we will also consider the <strong class="bold">F2 score</strong> (Fbeta-score with beta=2.0), which proportionally combines precision and recall, giving more weight to recall and less weight <span class="No-Break">to precision.</span></p>
			<p>So, what problems may we face when using <strong class="source-inline">BaggingClassifier</strong> on an imbalanced dataset? An obvious thing could be that when bootstrapping, some subsets on which base classifiers get trained may have very few minority class examples or none at all. This would mean that each of the individual base classifiers is going to perform poorly on the minority class, and combining their performance would still <span class="No-Break">be poor.</span></p>
			<p>We can combine undersampling techniques with bagging (one such method is UnderBagging) or oversampling techniques with bagging (one such method is OverBagging) to get better results. We will discuss such <span class="No-Break">techniques nex<a id="_idTextAnchor126"/>t.</span></p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor127"/>UnderBagging</h2>
			<p>The UnderBagging [2] technique uses random undersampling at the time of bootstrapping (or selection of subsets). We choose the whole set of the minority class examples <a id="_idIndexMarker268"/>for each classifier and bootstrap with replacement as many examples from the majority class as there are <a id="_idIndexMarker269"/>minority class examples. The aggregation step remains the same as in bagging. We can choose any classifier, say a decision tree, <span class="No-Break">for training.</span></p>
			<p>There are variants of UnderBagging where resampling with replacement of the minority class can also be applied to obtain more <span class="No-Break">diverse ensembles.</span></p>
			<p>The flowchart in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.7</em> represents the main steps in the UnderBagging algorithm with three subsets of data. It involves creating multiple subsets of data, performing random undersampling for the majority class in each subset, training classifiers on each subset, and finally combining the predictions of <span class="No-Break">the classifiers<a id="_idTextAnchor128"/>:</span></p>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/B17259_04_07.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.7 – Demonstrating how the UnderBagging algorithm works</p>
			<p>The <strong class="source-inline">imbalanced-learn</strong> library provides an implementation for <strong class="source-inline">BalancedBaggingClassifier</strong>. By default, this classifier uses a decision tree as the base classifier and <strong class="source-inline">RandomUnderSampler</strong> as the sampler via the <strong class="source-inline">sampler</strong> parameter. <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.8</em> shows the decision boundary of the trained <span class="No-Break">UnderBagging model:</span></p>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/B17259_04_08.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.8 – The decision boundary of the UnderBagging classifier on the training data</p>
			<p class="callout-heading">🚀 Bagging classifier in production at Microsoft</p>
			<p class="callout">In a real-world <a id="_idIndexMarker270"/>application at Microsoft [3], the team faced a significant challenge in forecasting Live Site Incident escalations (previously mentioned in <a href="B17259_02.xhtml#_idTextAnchor042"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Oversampling Methods</em>). The dataset was highly imbalanced, making it difficult <a id="_idIndexMarker271"/>for standard classifiers to perform well. To tackle this issue, Microsoft employed ensemble methods, specifically <strong class="source-inline">BalancedBaggingClassifier</strong> from the <strong class="source-inline">imbalanced-learn</strong> library. They used UnderBagging, where each bootstrap sample is randomly undersampled to get a balanced class distribution. As we have just discussed, UnderBagging uses all minority class samples and a random selection of majority class samples to train <span class="No-Break">the model.</span></p>
			<p class="callout">Bagged classification delivered the best results during their evaluation and also proved to be more consistent after they tracked it over a few months. They were able to significantly improve their forecasting accuracy for <span class="No-Break">incident escalations.</span></p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor129"/>OverBagging</h2>
			<p>Instead of <a id="_idIndexMarker272"/>random undersampling of the majority class samples, the minority class is oversampled (with replacement) at the <a id="_idIndexMarker273"/>time of bootstrapping. This method is called OverBagging [2]. As a variant, both minority and majority class examples can be resampled with replacements to achieve an equal number of majority and minority <span class="No-Break">class examples.</span></p>
			<p>The flowchart in <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.9</em> represents the main steps in the OverBagging algorithm with three subsets of data. It involves creating multiple subsets of data, performing random oversampling for the minority class in each subset, training classifiers on each subset, and finally combining the predictions of <span class="No-Break">the classifier<a id="_idTextAnchor130"/>s:</span></p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/B17259_04_09.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.9 – Demonstrating how the OverBagging algorithm works</p>
			<p>For OverBagging, we can use the same <strong class="source-inline">BalancedBaggingClassifier</strong> with <strong class="source-inline">RandomOverSampler</strong> in the <span class="No-Break"><strong class="source-inline">sampler</strong></span><span class="No-Break"> parameter.</span></p>
			<p>We will see the following <span class="No-Break">decision boundary:</span></p>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B17259_04_10.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.10 – The decision boundary of the OverBagging classifier on the training data</p>
			<p>We will <a id="_idIndexMarker274"/>compare the performance <a id="_idIndexMarker275"/>metrics of these techniques after discussing the various <span class="No-Break">bagging techniques.</span></p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor131"/>SMOTEBagging</h2>
			<p>Can we use SMOTE at the time of bootstrapping instead of random oversampling of minority <a id="_idIndexMarker276"/>class examples? The answer is yes. The majority class will be bootstrapped with replacement, and the minority class will be sampled using SMOTE until a balancing ratio <span class="No-Break">is reached.</span></p>
			<p>The pseudocode <a id="_idIndexMarker277"/>for SMOTEBagging [2] is very similar to that for OverBagging, with the key difference being the use of the SMOTE algorithm instead of random oversampling to augment the minority <span class="No-Break">clas<a id="_idTextAnchor132"/>s data.</span></p>
			<p>Similar to OverBagging, we can implement <strong class="source-inline">SMOTEBagging</strong> using <span class="No-Break">the </span><span class="No-Break"><strong class="source-inline">BalancedBagging</strong></span><strong class="source-inline"> Classifier</strong> API with SMOTE as the <span class="No-Break"><strong class="source-inline">sampler</strong></span><span class="No-Break"> parameter.</span></p>
			<p>The decision boundary is not very different <span class="No-Break">from OverBagging:</span></p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B17259_04_11.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.11 – The decision boundary of the SMOTEBagging classifier on the training data</p>
			<p class="callout-heading">A note about random forest and how it is related to bagging</p>
			<p class="callout">Random <a id="_idIndexMarker278"/>forest [4] is another <a id="_idIndexMarker279"/>model that is based on the concept of bagging. The way the <strong class="source-inline">RandomForestClassifier</strong> and <strong class="source-inline">BaggingClassifier</strong> models from <strong class="source-inline">sklearn</strong> differ from each other is the fact that <strong class="source-inline">RandomForestClassifier</strong> considers a random subset of features while trying to decide the feature on which to split the nodes in the decision tree, while <strong class="source-inline">BaggingClassifier</strong> takes all <span class="No-Break">the features.</span></p>
			<p class="callout"><em class="italic">Table 4.1</em> highlights the difference between random forest and <span class="No-Break">bagging classifiers:</span></p>
			<table id="table001-4" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style"/>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">RandomForestClassifier</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">BaggingClassifier</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Base classifier</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Decision trees</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Any classifier.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Bootstrap sampling</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Take a subset <span class="No-Break">of features</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Yes (at <span class="No-Break">each node)</span></p>
						</td>
						<td class="No-Table-Style">
							<p>No, by default. We can use the <strong class="source-inline">max_features</strong> hyperparameter to take subsets <span class="No-Break">of features.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Works <span class="No-Break">best with?</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Any tabular data, but it shines with large <span class="No-Break">feature sets</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Any tabular data, but it’s best when the base classifier is <span class="No-Break">carefully chosen.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Handles missing values <span class="No-Break">and outliers</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes, inherently</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Depends on the <span class="No-Break">base classifier.</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 4.1 – RandomForestClassifier versus BaggingClassifier</p>
			<p>The <strong class="source-inline">imbalanced-learn</strong> library provides the <strong class="source-inline">BalancedRandomForestClassifier</strong> class to tackle the imbalanced datasets where <a id="_idIndexMarker280"/>each of the bootstraps is undersampled before the individual <a id="_idIndexMarker281"/>decision trees are trained. As an exercise, we encourage you to learn about <strong class="source-inline">BalancedRandomForestClassifier</strong>. See how it relates to the other techniques we just discussed. Also, try out the various sampling strategies and explore the parameters this <span class="No-Break">class offers.</span></p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor133"/>Comparative performance of bagging methods</h2>
			<p>Let’s <a id="_idIndexMarker282"/>compare the <a id="_idIndexMarker283"/>performance of various bagging methods using the same dataset we’ve employed so far. We’ll use the decision tree as a baseline and evaluate different techniques across several performance metrics. The highest values for each metric across all techniques are highlighted <span class="No-Break">in bold:</span></p>
			<table id="table002-2" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">TECHNIQUE</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">F2</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">PRECISION</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">RECALL</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">AVERAGE PRECISION</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">AUC-ROC</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">SMOTEBagging</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">0.928</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.754</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.985</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.977</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">OverBagging</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.888</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.612</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.976</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">UnderBagging</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.875</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.609</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.981</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.885</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.999</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Bagging</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.891</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.967</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.874</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.969</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Balanced <span class="No-Break">random forest</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.756</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.387</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.993</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.909</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.999</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Random forest</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.889</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">0.975</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.870</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">0.979</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Decision tree</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.893</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.960</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.878</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.930</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.981</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 4.2 – Performance comparison of various bagging techniques</p>
			<p>Here <a id="_idIndexMarker284"/>are some <a id="_idIndexMarker285"/>conclusions we can draw from <span class="No-Break"><em class="italic">Table 4.2</em></span><span class="No-Break">:</span></p>
			<ul>
				<li>For maximizing the F2 score, <strong class="bold">SMOTEBagging</strong> did <span class="No-Break">the best</span></li>
				<li>For high precision, <strong class="bold">bagging</strong> and <strong class="bold">random forest</strong> performed <span class="No-Break">exceptionally well</span></li>
				<li>For high recall, <strong class="bold">OverBagging</strong> and <strong class="bold">balanced random forest</strong> are <span class="No-Break">strong choices</span></li>
				<li>For general performance across all metrics, <strong class="bold">SMOTEBagging</strong> and <strong class="bold">bagging</strong> proved to be <span class="No-Break">solid options</span></li>
			</ul>
			<p>In conclusion, although ensemble approaches such as bagging and random forest establish <a id="_idIndexMarker286"/>robust benchmarks that are challenging to outperform, incorporating imbalanced learning strategies such as SMOTEBagging can lead to <span class="No-Break">notable gains.</span></p>
			<p>This <a id="_idIndexMarker287"/>concludes our discussion of bagging techniques. If bagging is the wisdom of the crowd, boosting is the master sculptor, refining the previous art with each stroke. We’ll try to understand how boosting works in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor134"/>Boosting techniques for imbalanced data</h1>
			<p>Imagine two friends doing group study to solve their mathematics assignment. The first student is <a id="_idIndexMarker288"/>strong in most topics but weak in two topics: complex numbers and triangles. So, the first student asks the second student to spend more time on these two topics. Then, while solving the assignments, they combine their answers. Since the first student knows most of the topics well, they decided to give more weight to his answers to the assignment questions. What these two students are doing is the key idea <span class="No-Break">behind boosting.</span></p>
			<p>In bagging, we noticed that we could train all the classifiers in parallel. These classifiers are trained on a subset of the data, and all of them have an equal say at the time <span class="No-Break">of prediction.</span></p>
			<p>In boosting, the classifiers are trained one after the other. While every classifier learns from the whole data, points in the dataset are assigned different weights based on their difficulty of classification. Classifiers are also assigned weights that tell us about their predictive power. While predicting new data, the weighted sum of the classifiers <span class="No-Break">is used.</span></p>
			<p>Boosting begins by training the first classifier on the whole dataset, with each data point assigned the same weight. In the second iteration, the data points that were misclassified in the first iteration are given more weight, and a second classifier is trained with these new weights. A weight is also assigned to the classifiers themselves based on their overall performance. This process continues through multiple iterations with different classifiers. <span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.12</em> illustrates this concept for a <span class="No-Break">two-class dataset<a id="_idTextAnchor135"/>:</span></p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B17259_04_12.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.12 – Boosting idea: (left) the decision boundary from the first classifier; (middle) the weights of misclassified data points are bumped up for the second classifier; (right) the decision boundary from the second classifier</p>
			<p>The kind <a id="_idIndexMarker289"/>of boosting we just described is called <strong class="bold">AdaBoost</strong>. There is another category of boosting algorithms called gradient boosting, where the main focus is on minimizing the residuals (the difference between the actual value and predicted output value) of the previous model, trying to <a id="_idIndexMarker290"/>correct the <a id="_idIndexMarker291"/>previous model’s mistakes. There are several popular <a id="_idIndexMarker292"/>gradient boosting implementations, such as <strong class="bold">XGBoost</strong>, <strong class="bold">LightGBM</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="bold">CatBoost</strong></span><span class="No-Break">.</span></p>
			<p>In this chapter, we will mostly focus on AdaBoost and modify it to account for data imbalance. However, swapping AdaBoost with XGBoost, for example, shouldn’t be <span class="No-Break">too difficult.</span></p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor136"/>AdaBoost</h2>
			<p>AdaBoost, short for <a id="_idIndexMarker293"/>adaptive boosting, is one <a id="_idIndexMarker294"/>of the earliest boosting methods based on decision trees. Decision trees are classifiers that are easy to <span class="No-Break">ensemble together:</span></p>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/B17259_04_13.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.13 – AdaBoost pseudocode</p>
			<p>The following <a id="_idIndexMarker295"/>code shows how to <a id="_idIndexMarker296"/>import the classifier from the <strong class="source-inline">sklearn</strong> library and train it on<a id="_idTextAnchor137"/> <span class="No-Break">the data:</span></p>
			<pre class="source-code">
from sklearn.ensemble import AdaBoostClassifier
clf = AdaBoostClassifier(
    random_state=0, estimator = DecisionTreeClassifier(max_depth=6)
).fit(X_train, y_train)</pre>			<p>Let’s plot what the decision boundary looks like after the model gets trained on <span class="No-Break">the data:</span></p>
			<pre class="source-code">
plot_decision_boundary(X_train, y_train, clf, 'AdaBoostClassifier')
plt.show()</pre>			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.14</em> shows the decision boundary of the model on the <span class="No-Break">training data:</span></p>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/B17259_04_14.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.14 – The decision boundary of AdaBoostClassifier on the training data</p>
			<p>We can <a id="_idIndexMarker297"/>make oversampling and undersampling <a id="_idIndexMarker298"/>an integral part of the boosting algorithm, similar to how we did for the bagging algorithm. We will discuss <span class="No-Break">that next.</span></p>
			<h2 id="_idParaDest-92"><a id="_idTextAnchor138"/>RUSBoost, SMOTEBoost, and RAMOBoost</h2>
			<p>As you <a id="_idIndexMarker299"/>might have guessed, we can combine AdaBoost with resampling <a id="_idIndexMarker300"/>techniques. Here is the <a id="_idIndexMarker301"/>main idea: at each boosting <a id="_idIndexMarker302"/>iteration, before training a classifier on the incorrect examples <a id="_idIndexMarker303"/>from the previous <a id="_idIndexMarker304"/>iteration, we sample the data (via some undersampling or oversampling variant). Here’s the <span class="No-Break">general pseudocode:</span></p>
			<ol>
				<li><strong class="bold">Input</strong>: The training data and some decision <span class="No-Break">tree classifiers.</span></li>
				<li><strong class="bold">Output</strong>: An <span class="No-Break">aggregated classifier.</span></li>
				<li>Initialize the equal weights for all the samples of the <span class="No-Break">training data.</span></li>
				<li>Repeat this for each decision <span class="No-Break">tree classifier:</span><ol><li class="upper-roman">Resample the data using a data <span class="No-Break">sampling method:</span><ol><li class="lower-roman">If the <a id="_idIndexMarker305"/>sampling method used is <strong class="bold">Random UnderSampling</strong> (<strong class="bold">RUS</strong>), the <a id="_idIndexMarker306"/>method is called <span class="No-Break"><strong class="bold">RUSBoost</strong></span><span class="No-Break"> [5].</span></li><li class="lower-roman">If the sampling method used is SMOTE, the method is called <span class="No-Break"><strong class="bold">SMOTEBoost</strong></span><span class="No-Break"> [6].</span></li><li class="lower-roman">In <strong class="bold">RAMOBoost</strong> (short for <strong class="bold">Ranked Minority Oversampling in Boosting</strong> [7]), oversampling of the minority class is done based on the weight <a id="_idIndexMarker307"/>of the minority class examples. If the weight of an example is more (because the model didn’t do well on that example in the previous iteration), then it’s oversampled more, and <span class="No-Break">vice versa.</span></li></ol></li><li class="upper-roman">Train a classifier on the resampled data, giving more importance to samples with higher weights based on <span class="No-Break">previous iterations.</span></li><li class="upper-roman">Compute the error for the classifier on the given data by comparing its predictions with the <span class="No-Break">actual outputs.</span></li><li class="upper-roman">Consider all the wrongly classified examples for the next iteration. Increase the weights of such wrongly <span class="No-Break">classified examples.</span></li></ol></li>
				<li>Combine all the decision tree classifiers into a final classifier, where the classifiers with smaller error values on the training data have a larger say in the <span class="No-Break">final prediction.</span></li>
			</ol>
			<p>In this pseudocode, <em class="italic">Step 4 (I)</em> is the only extra step we have added compared to the AdaBoost algorithm. Let’s discuss the pros and cons of <span class="No-Break">these techniques:</span></p>
			<ul>
				<li>In RUSBoost, as the <a id="_idIndexMarker308"/>data is reduced, we tend to have a faster <span class="No-Break">training time.</span></li>
				<li>SMOTEBoost <a id="_idIndexMarker309"/>produces synthetic samples from the minority class. Thus, it adds diversity to the data and may improve the classifier’s accuracy. However, it would increase the time to train and may not be scalable to very <span class="No-Break">large datasets.</span></li>
				<li>RAMOBoost <a id="_idIndexMarker310"/>gives preference to the samples near the class boundaries. This can improve performance in some cases. However, like SMOTEBoost, this method may increase the training time and cost and may cause overfitting of the <span class="No-Break">final model.</span></li>
			</ul>
			<p>The <strong class="source-inline">imbalanced-learn</strong> library provides the implementation <span class="No-Break">for </span><span class="No-Break"><strong class="source-inline">RUSBoostClassifier</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
from imblearn.ensemble import RUSBoostClassifier
rusboost_clf = RUSBoostClassifier(random_state=0, \
    estimator=DecisionTreeClassifier\
    (max_depth=6)).fit(X_train, y_train)</pre>			<p>Let’s examine the decision boundary of the <span class="No-Break">trained model:</span></p>
			<pre class="source-code">
plot_decision_boundary(
    X_train, y_train, rusboost_clf, 'RUSBoostClassifier')
plt.show()</pre>			<p>The resulting plot is <span class="No-Break">shown here:</span></p>
			<div>
				<div id="_idContainer072" class="IMG---Figure">
					<img src="image/B17259_04_15.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.15 – The decision boundary of RUSBoostClassifier on training data</p>
			<p>The <strong class="source-inline">imbalanced-learn</strong> library doesn’t have the implementations of RAMOBoost and SMOTEBoost yet (as of version 0.11.0). You can check the open source repository at <a href="https://github.com/dialnd/imbalanced-algorithms">https://github.com/dialnd/imbalanced-algorithms</a> for <span class="No-Break">reference implementations.</span></p>
			<p>Can we create multiple subsets of the majority class, train an ensemble from each of these subsets, and combine all weak classifiers in these ensembles into a final output? This approach will be explored in the next section, where we will utilize the ensemble o<a id="_idTextAnchor139"/>f <span class="No-Break">ensembles technique.</span></p>
			<h1 id="_idParaDest-93"><a id="_idTextAnchor140"/>Ensemble of ensembles</h1>
			<p>Can we combine boosting and bagging? As we saw earlier, in bagging, we create multiple subsets of data and then train classifiers on those datasets. We can treat AdaBoost <a id="_idIndexMarker311"/>as a classifier while doing bagging. The process is simple: first, we create the bags and then train different AdaBoost classifiers on each bag. Here, AdaBoost is an ensemble in itself. Thus, these models are called an <strong class="bold">ensemble </strong><span class="No-Break"><strong class="bold">of ensembles</strong></span><span class="No-Break">.</span></p>
			<p>On top of having an ensemble of ensembles, we can also do undersampling (or oversampling) at the time of bagging. This gives us the <strong class="bold">benefits of bagging</strong>, <strong class="bold">boosting</strong>, and <strong class="bold">random undersampling</strong> (or oversampling) in a single model. We will discuss one such algorithm in this section, called <strong class="bold">EasyEnsemble</strong>. Since random undersampling doesn’t have significant overhead, both algorithms have training times similar to any other algorithm with the same numb<a id="_idTextAnchor141"/>er of <span class="No-Break">weak classifiers.</span></p>
			<h2 id="_idParaDest-94"><a id="_idTextAnchor142"/>EasyEnsemble</h2>
			<p>The EasyEnsemble algorithm [8] generates balanced datasets from the original dataset and trains a <a id="_idIndexMarker312"/>different AdaBoost classifier on each of the balanced datasets. Later, it creates an aggregate classifier that makes predictions based on the majority votes of the <span class="No-Break">AdaBoost classifiers:</span></p>
			<div>
				<div id="_idContainer073" class="IMG---Figure">
					<img src="image/B17259_04_16.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.16 – EasyEnsemble pseudocode</p>
			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.17</em> summarizes the EasyEnsemble algorithm using three subsets of the <span class="No-Break">training data:</span></p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/B17259_04_17.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.17 – EasyEnsemble algorithm explained</p>
			<p>Instead of <a id="_idIndexMarker313"/>randomly undersampling the majority class examples, we can randomly oversample the minority class <span class="No-Break">examples too.</span></p>
			<p>The <strong class="source-inline">imbalanced-learn</strong> library provides the API for EasyEnsemble using <strong class="source-inline">EasyEnsembleClassifier</strong>. The <strong class="source-inline">EasyEnsembleClassifier</strong> API provides a <strong class="source-inline">base_estimator</strong> argument that can be used to set any classifier, with the default <span class="No-Break">be<a id="_idTextAnchor143"/>ing </span><span class="No-Break"><strong class="source-inline">AdaBoostClassifier</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
from imblearn.ensemble import EasyEnsembleClassifier
clf = EasyEnsembleClassifier(n_estimators=70,random_state=42).fit(X,y)</pre>			<p>Let’s plot the <span class="No-Break">decision boundary:</span></p>
			<pre class="source-code">
plot_decision_boundary(X, y, clf, 'EasyEnsembleClassifier')
plt.show()</pre>			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B17259_04_18.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.18 – The decision boundary of EasyEnsembleClassifier on the training data</p>
			<p>By default, EasyEnsemble uses <strong class="source-inline">AdaBoostClassifier</strong> as the base estimator. However, we can use any other estimator as well, such as <strong class="source-inline">XGBoostClassifier</strong>, or tune it in <a id="_idIndexMarker314"/>other ways, say by passing <span class="No-Break">another </span><span class="No-Break"><strong class="source-inline">sampling_strategy</strong></span><span class="No-Break">.</span></p>
			<p>This concludes our discussion of EasyEnsemble. Next, we will compare the various boosting methods that <span class="No-Break">we’ve studied.</span></p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor144"/>Comparative performance of boosting methods</h2>
			<p>Let’s <a id="_idIndexMarker315"/>compare the performance of the various boosting methods we’ve discussed. We use a decision <a id="_idIndexMarker316"/>tree as a baseline and RUSBoost, AdaBoost, XGBoost, and EasyEnsemble, along with two variants. By default, <strong class="source-inline">EasyEnsembleClassifier</strong> uses <strong class="source-inline">AdaBoostClassifier</strong> as a baseline estimator. We use XGBoost instead as the estimator in the second variant of <strong class="source-inline">EasyEnsembleClassifier</strong>; in the third variant, we use <strong class="source-inline">not majority</strong> for our <strong class="source-inline">sampling_strategy</strong>, along with the <span class="No-Break">XGBoost estimator:</span></p>
			<table id="table003-1" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Technique</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">F2 Score</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Precision</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Recall</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Average Precision</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">AUC-ROC</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>EasyEnsemble (<strong class="source-inline">estimator=XGBoost</strong> and <strong class="source-inline">sampling_strategy = </strong><span class="No-Break"><strong class="source-inline">not_majority</strong></span><span class="No-Break">)</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.885</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.933</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.874</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">0.978</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>EasyEnsemble (<span class="No-Break"><strong class="source-inline">estimator=XGBoost</strong></span><span class="No-Break">)</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.844</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.520</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">0.978</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.999</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">EasyEnsemble</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.844</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.519</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.940</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.999</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">RUSBoost</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.836</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.517</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.989</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.948</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">AdaBoost</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">0.907</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.938</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.900</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">0.978</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">XGBoost</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.885</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.933</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.874</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.968</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">1.000</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Decision Tree</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.893</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">0.960</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.878</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.930</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">0.981</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 4.3 – Performance comparison of various boosting techniques</p>
			<p>Here <a id="_idIndexMarker317"/>are some <a id="_idIndexMarker318"/>conclusions from <span class="No-Break"><em class="italic">Table 4.3</em></span><span class="No-Break">:</span></p>
			<ul>
				<li>For the highest F2 score, AdaBoost is the <span class="No-Break">best choice</span></li>
				<li>For high precision, the plain decision tree beats all <span class="No-Break">other techniques</span></li>
				<li>For perfect recall, EasyEnsemble (<strong class="source-inline">estimator=XGBoost</strong>) and EasyEnsemble <span class="No-Break">perform perfectly</span></li>
				<li>For overall balanced performance, AdaBoost and EasyEnsemble (<strong class="source-inline">estimator=XGBoost</strong> and <strong class="source-inline">sampling_strategy=not_majority</strong>) are <span class="No-Break">strong contenders</span></li>
				<li>The ensembling techniques such as RUSBoost and EasyEnsemble are specifically designed for handling data imbalance and improving recall compared to a baseline model such as the decision tree or <span class="No-Break">even AdaBoost</span></li>
			</ul>
			<p>Overall, the results indicate that while ensemble methods such as AdaBoost and XGBoost <a id="_idIndexMarker319"/>provide robust baselines that are hard to beat, leveraging imbalanced learning techniques <a id="_idIndexMarker320"/>can indeed modify the decision boundaries of the resulting classifiers, which can potentially help with improving the recall. The efficacy of these techniques, however, largely depends on the dataset and performance metric <span class="No-Break">under consideration.</span></p>
			<p>By wrapping up our journey through the ensemble of ensembles, we’ve added yet another powerful and dynamic tool to our machine <span class="No-Break">learning arsenal.</span></p>
			<h1 id="_idParaDest-96"><a id="_idTextAnchor145"/>Model performance comparison</h1>
			<p>The effectiveness of the techniques we’ve discussed so far can be highly dependent on the dataset they are applied to. In this section, we will conduct a comprehensive comparative <a id="_idIndexMarker321"/>analysis that compares the various techniques we have discussed so far while using the logistic regression model as a baseline. For a comprehensive review of the complete implementation, please consult the accompanying notebook available <span class="No-Break">on GitHub.</span></p>
			<p>The analysis spans four distinct datasets, each with its own characteristics <span class="No-Break">and challenges:</span></p>
			<ul>
				<li><strong class="bold">Synthetic data with Sep: 0.5</strong>: A simulated dataset with moderate separation between classes, serving as a baseline to understand algorithm performance in <span class="No-Break">simplified conditions.</span></li>
				<li><strong class="bold">Synthetic data with Sep: 0.9</strong>: Another synthetic dataset, but with a higher degree of separation, allowing us to examine how algorithms perform as class <span class="No-Break">distinguishability improves.</span></li>
				<li><strong class="bold">Thyroid sick dataset</strong>: A real-world dataset (available to import from <strong class="source-inline">imblearn</strong>) related to healthcare, chosen for its practical importance and the natural class imbalance often seen in <span class="No-Break">medical datasets.</span></li>
				<li><strong class="bold">Abalone 19 dataset</strong>: A challenging real-world dataset related to marine biology, with a high level of class imbalance (1:130). This can be imported from <strong class="source-inline">imblearn</strong> <span class="No-Break">as well.</span></li>
			</ul>
			<p>Our primary metric for evaluation is average precision, a summary measure that combines both precision and recall, thereby providing a balanced view of <span class="No-Break">algorithm performance.</span></p>
			<p>We’d like to <a id="_idIndexMarker322"/>emphasize that we are using the vanilla versions of the various ensemble models for comparison. With some additional effort in tuning the hyperparameters of these models, we could certainly enhance the performance of these implementations. We leave that as an exercise <span class="No-Break">for you.</span></p>
			<p>By comparing these diverse algorithms across a variety of datasets, this analysis aims to provide some valuable insights into the <span class="No-Break">following aspects:</span></p>
			<ul>
				<li>How conventional and specialized techniques stack up against <span class="No-Break">each other</span></li>
				<li>The dependency of algorithm effectiveness on <span class="No-Break">dataset characteristics</span></li>
				<li>The practical implications of choosing one algorithm over another in <span class="No-Break">different scenarios</span></li>
			</ul>
			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.19</em> compares the performance of various bagging and boosting techniques using the average precision score, while using the logistic regression model as a baseline, over two <span class="No-Break">synthetic datasets:</span></p>
			<div>
				<div id="_idContainer076" class="IMG---Figure">
					<img src="image/B17259_04_19.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.19 – Average precision scores on synthetic datasets</p>
			<p><span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.20</em> shows similar <a id="_idIndexMarker323"/>plots across two <span class="No-Break">real-world datasets:</span></p>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B17259_04_20.jpg" alt="" role="presentation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.20 – Average precision scores on the thyroid_sick and abalone_19 datasets</p>
			<p>Let’s analyze these results for each of <span class="No-Break">the datasets:</span></p>
			<ul>
				<li><strong class="bold">Synthetic data with Sep 0.5</strong> (<span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.19</em>, left): XGBoost and logistic regression performed the best in terms of average precision, scoring 0.30 and 0.27, respectively. Interestingly, ensemble methods designed specifically for imbalanced data, such as SMOTEBagging and OverBagging, perform comparably or even worse than conventional methods such as bagging. This suggests that specialized methods do not always guarantee an advantage in simpler <span class="No-Break">synthetic settings.</span></li>
				<li><strong class="bold">Synthetic data with Sep 0.9</strong> (<span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.19</em>, right): EasyEnsemble takes the lead on this dataset with an average precision score of 0.64, closely followed by logistic regression and XGBoost. This higher separation seems to allow EasyEnsemble to capitalize on its focus on balancing, leading to better performance. Other ensemble methods such as UnderBagging and OverBagging perform reasonably but do not surpass <span class="No-Break">the leaders.</span></li>
				<li><strong class="bold">Thyroid sick dataset</strong> (<span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.20</em>, left): In a real-world dataset focusing on thyroid sickness, XGBoost far outperforms all other methods with an average precision of 0.97. Other ensemble methods such as bagging, OverBagging, and SMOTEBagging <a id="_idIndexMarker324"/>also score high, suggesting that ensembles are particularly effective for this dataset. Interestingly, boosting and RUSBoost do not keep pace, indicating that not all boosting variants are <span class="No-Break">universally effective.</span></li>
				<li><strong class="bold">Abalone 19 dataset</strong> (<span class="No-Break"><em class="italic">Figure 4</em></span><em class="italic">.20</em>, right): For the Abalone 19 dataset, all methods perform relatively poorly, with XGBoost standing out with an average precision of 0.13. EasyEnsemble comes in second with a score of 0.09, while traditional methods such as logistic regression and bagging lag behind. This could indicate that the dataset is particularly challenging for most methods, and specialized imbalanced techniques can only make <span class="No-Break">marginal improvements.</span></li>
			</ul>
			<p>Here are some <span class="No-Break">overall insights:</span></p>
			<ul>
				<li>Conventional methods such as XGBoost and logistic regression often provide strong baselines that are difficult <span class="No-Break">to beat</span></li>
				<li>The efficacy of specialized imbalanced learning techniques can vary significantly, depending on the dataset and its <span class="No-Break">inherent complexities</span></li>
				<li>Ensemble methods generally perform well across various datasets, but their effectiveness can <span class="No-Break">be context-dependent</span></li>
				<li>The choice of performance metric – in this case, average precision – can significantly influence the evaluation, making it crucial to consider multiple metrics for a <span class="No-Break">comprehensive understanding</span></li>
			</ul>
			<p>We hope that this chapter has shown how you can incorporate sampling techniques with ensemble methods to achieve improved results, especially when dealing with <span class="No-Break">imbalanced data.</span></p>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor146"/>Summary</h1>
			<p>Ensemble methods in machine learning create strong classifiers by combining results from multiple weak classifiers using approaches such as bagging and boosting. However, these methods assume balanced data and may struggle with imbalanced datasets. Combining ensemble methods with sampling methods such as oversampling and undersampling leads to techniques such as UnderBagging, OverBagging, and SMOTEBagging, all of which can help address imbalanced <span class="No-Break">data issues.</span></p>
			<p>Ensembles of ensembles, such as EasyEnsemble, combine boosting and bagging techniques to create powerful classifiers for <span class="No-Break">imbalanced datasets.</span></p>
			<p>Ensemble-based imbalance learning techniques can be an excellent addition to your toolkit. The ones based on KNN, viz., SMOTEBoost, and RAMOBoost can be slow. However, the ensembles based on random undersampling and random oversampling are less costly. Also, boosting methods are found to sometimes work better than bagging methods in the case of imbalanced data. We can combine random sampling techniques with boosting to get better overall performance. As we emphasized previously, it’s empirical, and we have to try to know what would work best for <span class="No-Break">our data.</span></p>
			<p>In the next chapter, we will learn how to change the model to account for the imbalance in data and the various costs incurred by the model because of misclassifying the minority <span class="No-Break">class exam<a id="_idTextAnchor147"/>ples.</span></p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor148"/>Questions</h1>
			<ol>
				<li>Try using <strong class="source-inline">RUSBoostClassifier</strong> on the <strong class="source-inline">abalone_19</strong> dataset and compare the performance with other techniques from the <span class="No-Break">previous chapters.</span></li>
				<li>What is the difference between the <strong class="source-inline">BalancedRandomForestClassifier</strong> and <strong class="source-inline">BalancedBaggingClassifier</strong> classes in the <span class="No-Break"><strong class="source-inline">imbalanced-learn</strong></span><span class="No-Break"> lib<a id="_idTextAnchor149"/>rary?</span></li>
			</ol>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor150"/>References</h1>
			<ol>
				<li value="1">L. Breiman, <em class="italic">Bagging predictors</em>, Mach Learn, vol. 24, no. 2, pp. 123–140, Aug. 1996, doi: <span class="No-Break">10.1007/BF00058655, </span><a href="https://link.springer.com/content/pdf/10.1007/BF00058655.pdf"><span class="No-Break">https://link.springer.com/content/pdf/10.1007/BF00058655.pdf</span></a><span class="No-Break">.</span></li>
				<li>(The paper that introduced OverBagging, UnderBagging, and SMOTEBagging) S. Wang and X. Yao, <em class="italic">Diversity analysis on imbalanced data sets by using ensemble models</em>, in 2009 IEEE Symposium on Computational Intelligence and Data Mining, Nashville, TN, USA: IEEE, Mar. 2009, pp. 324–331. doi: <span class="No-Break">10.1109/CIDM.2009.4938667, </span><a href="https://www.cs.bham.ac.uk/~wangsu/documents/papers/CIDMShuo.pdf"><span class="No-Break">https://www.cs.bham.ac.uk/~wangsu/documents/papers/CIDMShuo.pdf</span></a><span class="No-Break">.</span></li>
				<li><em class="italic">Live Site Incident escalation forecast</em> (<span class="No-Break">2023), </span><a href="https://medium.com/data-science-at-microsoft/live-site-incident-escalation-forecast-566763a2178"><span class="No-Break">https://medium.com/data-science-at-microsoft/live-site-incident-escalation-forecast-566763a2178</span></a></li>
				<li>L. Breiman, <em class="italic">Random Forests</em>, Machine Learning, vol. 45, no. 1, pp. 5–32, 2001, doi: <span class="No-Break">10.1023/A:1010933404324, </span><a href="https://link.springer.com/content/pdf/10.1023/A:1010933404324.pdf"><span class="No-Break">https://link.springer.com/content/pdf/10.1023/A:1010933404324.pdf</span></a><span class="No-Break">.</span></li>
				<li>(The paper that introduced the RUSBoost algorithm) C. Seiffert, T. M. Khoshgoftaar, J. Van Hulse, and A. Napolitano, <em class="italic">RUSBoost: A Hybrid Approach to Alleviating Class Imbalance</em>, IEEE Trans. Syst., Man, Cybern. A, vol. 40, no. 1, pp. 185–197, Jan. 2010, doi: <span class="No-Break">10.1109/TSMCA.2009.2029559, </span><a href="https://www.researchgate.net/profile/Jason-Van-Hulse/publication/224608502_RUSBoost_A_Hybrid_Approach_to_Alleviating_Class_Imbalance/links/0912f50f4bec299a8c000000/RUSBoost-A-Hybrid-Approach-to-Alleviating-Class-Imbalance.pdf"><span class="No-Break">https://www.researchgate.net/profile/Jason-Van-Hulse/publication/224608502_RUSBoost_A_Hybrid_Approach_to_Alleviating_Class_Imbalance/links/0912f50f4bec299a8c000000/RUSBoost-A-Hybrid-Approach-to-Alleviating-Class-Imbalance.pdf</span></a><span class="No-Break">.</span></li>
				<li>(The paper that introduced the SMOTEBoost algorithm) N. V. Chawla, A. Lazarevic, L. O. Hall, and K. W. Bowyer, <em class="italic">SMOTEBoost: Improving Prediction of the Minority Class in Boosting</em>, in Knowledge Discovery in Databases: PKDD 2003, N. Lavrač, D. Gamberger, L. Todorovski, and H. Blockeel, Eds., in Lecture Notes in Computer Science, vol. 2838. Berlin, Heidelberg: Springer Berlin Heidelberg, 2003, pp. 107–119. doi: <span class="No-Break">10.1007/978-3-540-39804-2_12, </span><a href="https://www3.nd.edu/~dial/publications/chawla2003smoteboost.pdf"><span class="No-Break">https://www3.nd.edu/~dial/publications/chawla2003smoteboost.pdf</span></a><span class="No-Break">.</span></li>
				<li>(The paper that introduced RAMOBoost algorithm) Sheng Chen, Haibo He, and E. A. Garcia, <em class="italic">RAMOBoost: Ranked Minority Oversampling in Boosting</em>, IEEE Trans. Neural Netw., vol. 21, no. 10, pp. 1624–1642, Oct. 2010, doi: <span class="No-Break">10.1109/TNN.2010.2066988, </span><a href="https://ieeexplore.ieee.org/abstract/document/5559472"><span class="No-Break">https://ieeexplore.ieee.org/abstract/document/5559472</span></a><span class="No-Break">.</span></li>
				<li>(The paper that introduced EasyEnsemble) Xu-Ying Liu, Jianxin Wu, and Zhi-Hua Zhou, <em class="italic">Exploratory Undersampling for Class-Imbalance Learning</em>, IEEE Trans. Syst., Man, Cybern. B, vol. 39, no. 2, pp. 539–550, Apr. 2009, doi: <span class="No-Break">10.1109/TSMCB.2008.2007853, </span><a href="http://129.211.169.156/publication/tsmcb09.pdf"><span class="No-Break">http://129.211.169.156/publication/tsmcb09.pdf</span></a><span class="No-Break">.</span></li>
			</ol>
		</div>
	</body></html>