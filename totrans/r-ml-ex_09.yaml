- en: Chapter 8. Sentiment Analysis of Twitter Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。Twitter数据的情感分析
- en: '|   | *"He who molds the public sentiment... makes statutes and decisions possible
    or impossible to make."* |   |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '|   | *"他塑造了公众舆论...使得制定法律和决策成为可能或不可能。" |   |'
- en: '|   | --*Abraham Lincoln.* |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|   | --*亚伯拉罕·林肯* |'
- en: What people think matters not only to politicians and celebrities but also to
    most of us social beings. This need to know opinions about ourselves has affected
    people for a long time and is aptly summarized by the preceding famous quote.
    The opinion bug not only affects our own outlook, it affects the way we use products
    and services as well. As discussed while learning about market basket analysis
    and recommender engines (see [Chapter 3](part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis"),
    *Predicting Customer Shopping Trends with Market Basket Analysis* and [Chapter
    4](part0032_split_000.html#UGI01-973e731d75c2419489ee73e3a0cf4be8 "Chapter 4. Building
    a Product Recommendation System"), *Building a Product Recommendation System*
    respectively), our behavior can be approximated or predicted by observing the
    behavior of a group of people with similar characteristics such as price sensitivity,
    color preferences, brand loyalty, and so on. We also discussed in the earlier
    chapters that, for a long time, we have asked our friends and relatives for their
    opinions before making that next big purchase. While those opinions are important
    to us at an individual level, there are far more valuable insights we can derive
    from such information.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 人们的想法不仅对政治家和名人很重要，对我们大多数社会人也是如此。这种了解自己观点的需求影响了人们很长时间，并被前面的著名引言恰当地总结。意见的困扰不仅影响我们的观点，还影响我们使用产品和服务的方式。正如在学习市场篮子分析和推荐引擎时讨论的那样（参见[第3章](part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8
    "第3章。使用市场篮子分析预测客户购物趋势")，*使用市场篮子分析预测客户购物趋势*和[第4章](part0032_split_000.html#UGI01-973e731d75c2419489ee73e3a0cf4be8
    "第4章。构建产品推荐系统")，*构建产品推荐系统*分别），我们的行为可以通过观察具有类似特征（如价格敏感度、颜色偏好、品牌忠诚度等）的一组人的行为来近似或预测。我们在前面的章节中也讨论了，长期以来，我们在做出下一个重大购买决策之前，会向我们的朋友和亲戚征求他们的意见。虽然这些意见对我们个人来说很重要，但我们可以从这样的信息中得出更多有价值的见解。
- en: To say that the advent of the World Wide Web has simply accelerated and widened
    our circle would be an understatement. Without being repetitive, it is worth mentioning
    that the web has opened new doors for analyzing human behavior.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅说万维网的到来只是加速和扩大了我们的社交圈，这还不足以表达其影响。无需重复，值得一提的是，网络为分析人类行为开启了新的途径。
- en: In the previous chapter, social networks were the object of discussion. We not
    only used social networks as tools to derive insights but we also discussed the
    fact that these platforms satisfy our inherent curiosity about what others are
    thinking or doing. Social networks provide us all with a platform where we can
    voice our opinions and be heard. The *be heard* aspect of it is a little tricky
    to define and handle. For instance, our opinions and feedback (assuming they are
    genuine) about someone or something on these platforms will certainly be heard
    by the people in our circles (directly or indirectly), but they may or may not
    be heard by the people or organizations they are intended for. Nevertheless, such
    opinions or feedback do impact the people connected to them and their behavior
    from then on. This impact of opinions and our general curiosity about what people
    think, coupled with more such use cases, is the motivation for this chapter.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，社交网络是讨论的主题。我们不仅使用社交网络作为工具来获取洞察，还讨论了这些平台满足我们天生的好奇心，想知道别人在想什么或做什么。社交网络为我们提供了一个平台，我们可以表达自己的观点并被人听到。其中“被人听到”这一方面定义和操作起来有些棘手。例如，我们对这些平台上某人或某事的观点和反馈（假设它们是真实的）肯定会直接或间接地被我们圈子中的人听到，但它们可能或可能不会被它们旨在影响的人或组织听到。尽管如此，这样的观点或反馈确实会影响与之相关的人及其随后的行为。这种观点的影响以及我们对人们想法的一般好奇心，加上更多这样的用例，正是本章的动机。
- en: 'In this chapter, we will:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将：
- en: Learn about sentiment Analysis and its key concepts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解情感分析及其关键概念
- en: Look into the applications and challenges presented by sentiment analysis
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探讨情感分析的应用和挑战
- en: Understand the different approaches to perform opinion mining
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解执行意见挖掘的不同方法
- en: Apply the concepts of sentiment analysis on Twitter data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Twitter数据上应用情感分析的概念
- en: Understanding Sentiment Analysis
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解情感分析
- en: The fact that Internet-based companies and their CEOs feature as some of the
    most profitable entities in the global economy says a lot about how the world
    is being driven by technology and shaped by the Internet. Unlike any other medium,
    the Internet has become ubiquitous and has penetrated every aspect of our lives.
    It is no surprise that we are using and relying on the Internet and Internet-based
    solutions for advice and recommendations, apart from using it for many other purposes.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网公司及其首席执行官作为全球经济体中最有利可图的实体之一，这充分说明了世界是如何被技术和互联网所驱动的，以及是如何被塑造的。与其他任何媒介不同，互联网已经无处不在，渗透到我们生活的方方面面。我们使用和依赖互联网以及基于互联网的解决方案来获取建议和推荐，这并不奇怪，除了用于许多其他目的之外。
- en: As we saw in the previous chapters, the relationship between the Internet and
    domains such as e-commerce and financial institutions goes way too deep. But our
    use of and trust in the online world doesn't stop there. Be it about booking a
    table at the new restaurant in your neighborhood or deciding which movie to see
    tonight, we take help from the Internet to know what opinions others have, or
    what others have to share, before we make the final call. As we will see later,
    such decision aids are not just limited to the commerce platforms but also apply
    to many other domains.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前几章所看到的，互联网与电子商务和金融机构等领域的联系非常深远。但我们对在线世界的使用和信任并不仅限于此。无论是预订你邻里的新餐厅的桌子，还是决定今晚要看哪部电影，我们都会在做出最终决定之前，从互联网上获取他人的意见或分享的内容。正如我们稍后将看到的，这样的决策辅助工具不仅限于商业平台，还适用于许多其他领域。
- en: Opinion mining or sentiment analysis (as it is widely and interchangeably known)
    is the process of automatically identifying the subjectivity in text using natural
    language processing, text analytics, and computational linguistics. Sentiment
    analysis aims to identify the positive, negative, or neutral opinion, sentiment,
    or attitude of the speaker using said techniques. Sentiment analysis (henceforth
    used interchangeably with opinion mining) finds its application in areas from
    commerce to service domains across the world.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 意见挖掘或情感分析（正如它被广泛且可互换地称呼）是使用自然语言处理、文本分析和计算语言学自动识别文本中主观性的过程。情感分析旨在使用这些技术识别说话者的正面、负面或中性意见、情感或态度。情感分析（以下简称情感挖掘）在从商业到服务领域的全球范围内都有应用。
- en: Key concepts of sentiment analysis
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 情感分析的关键概念
- en: We will now examine the key terms and concepts related to sentiment analysis.
    These terms and concepts will help us formalize our discussions in the coming
    sections.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将探讨与情感分析相关的关键术语和概念。这些术语和概念将帮助我们使接下来的讨论更加规范化。
- en: Subjectivity
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主观性
- en: Opinions or sentiments are one's own expression of views and beliefs. Furthermore,
    subjectivity (or subjective text) expresses our sentiments about entities such
    as products, people, governments, and so on. For instance, a subjective sentence
    could be *I love to use Twitter*, which shows a person's love towards a particular
    social network, while an objective sentence would be *Twitter is a social network*.
    The second example simply states a fact. Sentiment analysis revolves around subjective
    texts or subjectivity classification. It is also important to understand that
    not all subjective texts express sentiment. For example, *I just created my Twitter
    account*.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 意见或情感是个人对观点和信念的表达。此外，主观性（或主观文本）表达了我们对于产品、人物、政府等实体的情感。例如，一个主观句子可能是“我喜欢使用Twitter”，这表明一个人对某个特定社交网络的喜爱，而一个客观句子则是“Twitter是一个社交网络”，第二个例子只是陈述了一个事实。情感分析围绕主观文本或主观性分类展开。同样重要的是要理解并非所有主观文本都表达情感。例如，“我刚创建了Twitter账户”。
- en: Sentiment polarity
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 情感极性
- en: Once we have a piece of text which is subjective in nature (and expresses some
    sentiment), the next task is to classify it into one of the sentiment classes
    of positive or negative (sometimes neutral is also considered). The task may also
    involve placing the text's sentiment on a continuous (or discrete) scale of polarities,
    thus defining the degree of positivity (or sentiment polarity). The sentiment
    polarity classification may deal with a different set of classes depending upon
    the context. For example, in a rating system for movies, sentiment polarities
    may be defined as liked versus disliked, or in a debate the views may be classified
    as for versus against.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有一段主观性（并表达某种情感）的文本，接下来的任务就是将其分类为正面或负面情感类别之一（有时也考虑中性）。这项任务还可能涉及将文本的情感放置在连续（或离散）的极性尺度上，从而定义积极程度（或情感极性）。情感极性分类可能根据上下文处理不同的类别。例如，在电影评分系统中，情感极性可能被定义为喜欢与不喜欢，或在辩论中观点可能被分类为支持与反对。
- en: Opinion summarization
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 意见总结
- en: Opinion classification or sentiment extraction from a piece of text is an important
    task in the process of sentiment analysis. This is often followed by a summarization
    of sentiments. To draw insights or conclusions from different texts related to
    the same topic (say, reviews of a given movie), it is important to aggregate (or
    summarize) the sentiments into a consumable form to draw conclusions (whether
    the movie is a blockbuster or a dud). This may involve the use of visualizations
    to infer the overall sentiment.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从一段文本中提取观点或情感是情感分析过程中的一个重要任务。这通常随后是对情感的总结。为了从与同一主题（例如，某部电影的评论）相关的不同文本中得出见解或结论，将情感汇总（或总结）成可消费的形式以得出结论（电影是票房大作还是失败之作）是很重要的。这可能涉及到使用可视化来推断整体情感。
- en: Feature extraction
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征提取
- en: 'As we have seen across the chapters, feature identification and extraction
    is what makes or breaks a machine learning algorithm. It is the most important
    factor after the data itself. Let us look at some of the feature sets utilized
    in solving the problem of sentiment analysis:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在各章节中看到的，特征识别和提取是使机器学习算法成功或失败的关键。它是在数据本身之后最重要的因素。让我们看看在解决情感分析问题中使用的某些特征集：
- en: '**TF-IDF**: Information Retrieval makes heavy use of **Term Frequency-Inverse**
    **Document Frequency** (**tf-idf**) to enable quick information retrieval and
    analysis. In the context of tf-idf, a piece of text is represented as a feature
    vector containing words as its constituents. Recent research has also shown that,
    in the context of sentiment analysis, the presence of a word improves the performance
    and accuracy as compared to the frequency of the word.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TF-IDF**：信息检索大量使用**词频-逆文档频率**（**tf-idf**）来实现快速的信息检索和分析。在tf-idf的上下文中，一段文本被表示为一个包含单词作为其组成部分的特征向量。最近的研究也表明，在情感分析的上下文中，与单词的频率相比，单词的存在可以提高性能和准确性。'
- en: Note
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Source**:'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**来源**：'
- en: Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. Thumbs up? Sentiment classification
    using machine learning techniques. In Proceedings of the Conference on **Empirical
    Methods in Natural Language Processing** (**EMNLP**), pages 79–86, 2002.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Bo Pang, Lillian Lee, 和 Shivakumar Vaithyanathan. Thumbs up? Sentiment classification
    using machine learning techniques. In Proceedings of the Conference on **Empirical
    Methods in Natural Language Processing** (**EMNLP**), pages 79–86, 2002.
- en: 'TF-IDF is given as: ![Feature extraction](img/00239.jpeg)'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: TF-IDF 表示为：![特征提取](img/00239.jpeg)
- en: Where,
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中，
- en: '`tf(t,d)` is the term frequency of term `t` in document `d`.'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`tf(t,d)` 是文档 `d` 中术语 `t` 的词频。'
- en: '`idf(t,D)` is the inverse document frequency for term `t` in document set `D`.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`idf(t,D)` 是文档集 `D` 中术语 `t` 的逆文档频率。'
- en: 'For example, we have the following screenshots of two documents with their
    terms and their corresponding frequencies:'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，我们有以下两个文档及其术语和相应频率的截图：
- en: '![Feature extraction](img/00240.jpeg)'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![特征提取](img/00240.jpeg)'
- en: 'In its simplest form, `TF-IDF` for the term `Twitter` can be given as:'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在其最简单的形式中，术语 `Twitter` 的 `TF-IDF` 可以表示为：
- en: '![Feature extraction](img/00241.jpeg)'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![特征提取](img/00241.jpeg)'
- en: Different weight schemes can be used for calculating `tfidf`; the preceding
    example uses log with base 10 to calculate `idf`.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用不同的权重方案来计算 `tfidf`；前面的例子使用以10为底的对数来计算 `idf`。
- en: '`n-Grams`: Computational linguistics and probability consider a text corpus
    as a contiguous sequence of terms, which may be phonemes, letters, words, and
    so on. The n-gram-based modeling techniques find their roots in information theory,
    where the likelihood of the next character or word is based upon the *n* previous
    terms. Depending upon the value of `n`, the feature vector or model is termed
    as unigram (for `n=1`), bigram (for `n=2`), trigram (for `n=3`), and so on. n-grams
    are particularly useful with out-of-vocabulary words and approximate matches.
    For example, considering a sequence of words, a sentence such as *A chapter on
    sentiment analysis* would have bigrams such as *a chapter*, *chapter on*, *on
    sentiment*, *sentiment analysis*, and so on.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n-Grams`：计算语言学和概率将文本语料库视为连续的术语序列，这些术语可以是音素、字母、单词等。基于n-gram的建模技术源于信息理论，其中下一个字符或单词的可能性基于前*n*个术语。根据`n`的值，特征向量或模型被称为单语（对于`n=1`）、双语（对于`n=2`）、三元语（对于`n=3`）等等。n-grams对于处理词汇表外的单词和近似匹配特别有用。例如，考虑一个单词序列，一个像*A
    chapter on sentiment analysis*这样的句子会有诸如*a chapter*、*chapter on*、*on sentiment*、*sentiment
    analysis*等双语。'
- en: Note
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Interesting work by Google on using n-grams: [http://googleresearch.blogspot.in/2006/08/all-our-n-gram-are-belong-to-you.html](http://googleresearch.blogspot.in/2006/08/all-our-n-gram-are-belong-to-you.html).'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Google关于使用n-grams的有趣工作：[http://googleresearch.blogspot.in/2006/08/all-our-n-gram-are-belong-to-you.html](http://googleresearch.blogspot.in/2006/08/all-our-n-gram-are-belong-to-you.html)。
- en: '**Parts of Speech** (**POS**): Understanding and making use of the underlying
    structure of the language for analysis has obvious advantages. POS are rules of
    language which are used to create sentences, paragraphs and documents. In its
    simplest form, adjectives are usually pretty good indicators of subjectivity (not
    always, though). A number of approaches make use of the polarity of adjectives
    while classifying subjective texts. Using phrases containing adjectives has been
    shown to improve performance even further. Research into using other parts of
    speech, such as verbs and nouns, along with adjectives has also shown positive
    results.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词性**（**POS**）：理解和利用语言的基本结构进行分析具有明显的优势。词性是用于创建句子、段落和文档的语言规则。在其最简单的形式中，形容词通常是主观性的良好指标（尽管并非总是如此）。许多方法在分类主观文本时利用了形容词的极性。使用包含形容词的短语已被证明可以进一步提高性能。对使用其他词性（如动词和名词）的研究，以及与形容词一起使用，也显示出积极的结果。'
- en: Note
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Reference**:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**参考文献**：'
- en: Peter Turney. Thumbs up or thumbs down? Semantic orientation applied to unsupervised
    classification of reviews. In Proceedings of the **Association for Computational
    Linguistics** (**ACL**), pages 417–424, 2002.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Peter Turney. Thumbs up or thumbs down? Semantic orientation applied to unsupervised
    classification of reviews. In Proceedings of the **Association for Computational
    Linguistics** (**ACL**), pages 417–424, 2002.
- en: 'The following example shows the parts of speech (adjectives, nouns, and so
    on) tagged in a sample sentence, for example, *We saw the yellow dog*:'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下示例显示了在样本句子中标记的词性（形容词、名词等），例如，*We saw the yellow dog*：
- en: '![Feature extraction](img/00242.jpeg)'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![特征提取](img/00242.jpeg)'
- en: 'Source: [http://www.nltk.org/](http://www.nltk.org/)'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 来源：[http://www.nltk.org/](http://www.nltk.org/)
- en: '**Negation**: In the case of sentiment analysis, negation plays an important
    role. For example, sentences such as *I like oranges* and *I don''t like oranges*
    differ only in the word *don''t*, but the negation term flips the polarity of
    sentences to opposite classes (positive and negative respectively). Negation may
    be used as a secondary feature set where the original feature vector is generated
    as is, but is flipped in polarity later on based on the negation term. There are
    other variants to this approach as well, and they show an improvement in the results
    as compared to approaches which do not take into account the effects of negation.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**否定**：在情感分析的情况下，否定起着重要的作用。例如，像*I like oranges*和*I don''t like oranges*这样的句子，它们之间的区别仅在于单词*don''t*，但否定词翻转了句子的极性到相反的类别（分别是正极和负极）。否定可以作为次要特征集使用，其中原始特征向量按原样生成，但后来根据否定词翻转极性。还有其他变体，与不考虑否定影响的方法相比，它们在结果上有所改进。'
- en: '**Topic specific features**: Topic plays an important role in setting the context.
    Since sentiment analysis is about the speaker''s opinion, the subjectivity is
    influenced by the topic being discussed. Extensive research has gone into analyzing
    the effects of and relationship between the topic and sentiment of the text corpus.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主题特定特征**：主题在设置上下文中起着重要作用。由于情感分析涉及说话者的观点，因此主观性受到所讨论主题的影响。在分析主题与文本语料库情感之间的关系方面进行了大量研究。'
- en: Note
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Reference**:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献**：'
- en: Tony Mullen and Nigel Collier. Sentiment analysis using support vector machines
    with diverse information sources. In Proceedings of the Conference on **Empirical**
    **Methods in Natural Language Processing** (**EMNLP**), pages 412–418, July 2004\.
    Poster paper.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Tony Mullen 和 Nigel Collier. 使用支持向量机和多种信息源进行情感分析。在自然语言处理实证方法会议（**EMNLP**）论文集中，第
    412–418 页，2004 年 7 月。海报论文。
- en: Approaches
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法
- en: Now that we have a basic understanding of the key concepts from the world of
    sentiment analysis, let us look at different approaches for tackling this problem.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对情感分析领域的核心概念有了基本的了解，让我们来看看解决这个问题的不同方法。
- en: 'Sentiment analysis is mostly performed at the following two levels of abstraction:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析主要在以下两个抽象级别上进行：
- en: '**Document level**: At this level of abstraction, the task is to analyze a
    given document to determine whether its overall sentiment is positive or negative
    (or neutral in certain cases). The basic assumption is that the whole document
    expresses opinions related to a single entity. For example, given a product review,
    the system analyzes it to determine whether the review is positive or negative.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档级别**：在这个抽象级别，任务是分析给定的文档，以确定其整体情感是积极、消极（或在某些情况下是中性的）。基本假设是整个文档表达了对单个实体的意见。例如，给定一个产品评论，系统会分析它以确定评论是积极的还是消极的。'
- en: '**Sentence level**: Sentence level analysis is a more granular form of sentiment
    analysis. This level of granularity counters the fact that not all sentences in
    a document are subjective and thus makes better use of subjectivity classification
    to determine the sentiment on a per sentence basis.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**句子级别**：句子级别分析是情感分析的一种更细粒度的形式。这种粒度级别抵消了这样一个事实，即文档中的所有句子并不都是主观的，因此更好地利用主观性分类来确定每句话的情感。'
- en: 'Pretty much like other machine learning techniques, sentiment analysis can
    also be tackled using supervised and unsupervised methods:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他机器学习技术类似，情感分析也可以使用监督和无监督方法来解决：
- en: '**Supervised Approach**: Research on sentiment analysis has been going on for
    quite some time. While the earlier research was constrained by the availability
    of labeled datasets and performed rather shallow analysis, modern day supervised
    learning approaches for sentiment analysis have seen a boost, both in terms of
    systems utilizing these techniques as well as the overall performance of such
    systems due to the availability of labeled datasets. Datasets such as WordNet,
    SentiWordNet, SenticNet, newswire, Epinions, and so on enormously assist researchers
    in improving supervised algorithms by providing datasets with polar words, documents
    classified into categories, user opinions, and so on. Algorithms such as **Naïve
    Bayes**, **Support Vector Machines** (**SVM**), as discussed in [Chapter 6](part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 6. Credit Risk Detection and Prediction – Predictive Analytics"), *Credit
    Risk Detection and Prediction – Predictive Analytics*, and **Maximum-Entropy-based**
    classification algorithms are classic examples of supervised learning approaches.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督方法**：情感分析的研究已经进行了很长时间。虽然早期研究受限于标记数据集的可用性，并且进行了相当浅的分析，但现代监督学习方法在情感分析方面取得了显著进展，无论是在利用这些技术的系统数量上，还是在由于标记数据集的可用性而导致的系统整体性能上。例如，WordNet、SentiWordNet、SenticNet、新闻稿、Epinions
    等数据集极大地帮助研究人员通过提供包含极性词汇、分类文档、用户意见等数据集来改进监督算法。**朴素贝叶斯**、**支持向量机**（**SVM**）等算法，如第
    6 章（part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8 "第 6 章. 信用风险检测和预测
    – 预测分析"）中讨论的，以及基于最大熵的分类算法，是监督学习方法的经典例子。'
- en: '**Unsupervised Approach**: Unsupervised algorithms for sentiment analysis usually
    begin with building or learning a sentiment lexicon and then determining the polarity
    of the text input. Lexicon generation has been done through techniques such as
    linguistic heuristics, bootstrapping, and so on. One famous approach was detailed
    by Turney in his 2002 paper where he describes unsupervised sentiment analysis
    using some fixed syntactic patterns which were based on POS.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督方法（Unsupervised Approach）**: 无监督情感分析算法通常从构建或学习情感词典开始，然后确定文本输入的极性。词典生成是通过诸如语言启发式、自举等技术完成的。Turney
    在他的2002年论文中详细描述了一种著名的方法，其中他使用一些基于词性（POS）的固定句法模式进行无监督情感分析。'
- en: Note
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**注意**:'
- en: '**Reference**:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**参考**:'
- en: '**Linguistic heuristics**: Vasileios Hatzivassiloglou and Kathleen McKeown.
    Predicting the semantic orientation of adjectives. In Proceedings of the Joint
    ACL/EACL Conference, pages 174–181, 1997.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**语言启发式（Linguistic heuristics）**: Vasileios Hatzivassiloglou 和 Kathleen McKeown.
    预测形容词的语义方向。在联合ACL/EACL会议论文集中，第174-181页，1997年。'
- en: '**Bootstrapping**: Ellen Riloff and Janyce Wiebe. Learning extraction patterns
    for subjective expressions. In Proceedings of the Conference on **Empirical Methods
    in Natural Language Processing** (**EMNLP**), 2003.'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**自举（Bootstrapping）**: Ellen Riloff 和 Janyce Wiebe. 学习主观表达式的提取模式。在自然语言处理实证方法会议（**EMNLP**）论文集中，2003年。'
- en: '**Turney**: Peter Turney. Thumbs up or thumbs down? Semantic orientation applied
    to unsupervised classification of reviews. In Proceedings of the **Association
    for Computational Linguistics** (**ACL**), pages 417–424, 2002.'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**Turney**: Peter Turney. 点赞还是踩？语义方向在无监督分类评论中的应用。在计算语言学协会（**ACL**）会议论文集中，第417-424页，2002年。'
- en: Applications
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**应用**:'
- en: 'As we have been discussing throughout, our reliance upon online opinions is
    something of a surprise. We knowingly or unknowingly check these opinions or are
    influenced by them before buying products, downloading software, selecting apps,
    or choosing a restaurant. Sentiment analysis or opinion mining finds its application
    in many areas; they can be summarized into the following broad categories:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们一直在讨论的，我们对在线意见的依赖是一种惊喜。在购买产品、下载软件、选择应用程序或选择餐厅之前，我们有意或无意地检查这些意见或受其影响。情感分析或意见挖掘在许多领域都有应用；它们可以概括为以下广泛类别：
- en: '**Online and Offline Commerce**: Customer preferences can make or break brands
    in an instant. For a product to be a hot seller, everything including pricing,
    packaging, and marketing has to be perfect. Customers form opinions about all
    aspects related to products, and thus affect their sales. It is not just the case
    with online commerce where customers check product reviews on multiple websites
    or blogs before making the actual purchase, but word of mouth and other such factors
    affect customer opinions in the world of offline commerce as well. Sentiment analysis
    thus forms an important factor which brands or companies track and analyze to
    be on top of the game. Analysis of social media content such as tweets, Facebook
    posts, blogs, and so on provide brands with an insight into how customers perceive
    their product. In certain cases, brands roll out specific marketing campaigns
    to set the general sentiment or hype about a product.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在线和离线商业（Online and Offline Commerce）**: 顾客的偏好可以在一瞬间决定品牌的命运。要使产品成为热销商品，包括定价、包装和营销在内的所有方面都必须完美无缺。顾客会对与产品相关的所有方面形成看法，从而影响其销售。这不仅适用于在线商业，顾客在购买前会在多个网站或博客上查看产品评论，而且口碑和其他类似因素也会影响离线商业中的顾客意见。因此，情感分析成为品牌或公司跟踪和分析以保持领先地位的重要因素。对社交媒体内容，如推文、Facebook帖子、博客等的分析为品牌提供了洞察顾客如何看待其产品的见解。在某些情况下，品牌会推出特定的营销活动来设定关于产品的普遍情绪或炒作。'
- en: '**Governance**: In a world where most activities have online counterparts,
    governments are no exceptions. There have been projects by various governments
    across the globe which have made use of sentiment analysis in matters of policy
    making and security (by analyzing and monitoring any increase in hostile or negative
    communications). Sentiment Analysis has also been used by analysts to determine
    or predict outcomes of elections as well. Tools such as *eRuleMaking* have sentiment
    analysis as a key component.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**治理（Governance）**: 在大多数活动都有在线对应物的世界中，政府也不例外。全球各国政府都开展了利用情感分析在政策制定和安全（通过分析和监控任何敌意或负面通信的增加）方面的问题的项目。分析人员还使用情感分析来确定或预测选举的结果。例如，*eRuleMaking*
    等工具将情感分析作为关键组成部分。'
- en: Apart from the aforementioned two categories, opinion mining acts as an augmenting
    technology in fields such as recommendation engines and general prediction systems.
    For example, opinion mining may be used in conjunction with recommender engines
    to exclude products from recommendation lists which have opinions or sentiments
    below certain thresholds. Sentiment analysis may also find innovative use in predicting
    whether an upcoming movie will be a blockbuster or not based on sentiments related
    to the star cast, production house, topic of the movie, and so on.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述两个类别之外，意见挖掘在推荐引擎和通用预测系统等领域的应用中充当一种增强技术。例如，意见挖掘可以与推荐引擎结合使用，排除那些意见或情感低于某些阈值的产品的推荐列表。情感分析也可能在预测即将上映的电影是否会成为票房炸弹方面找到创新的应用，这基于与明星阵容、制作公司、电影主题等相关联的情感。
- en: Challenges
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 挑战
- en: 'To understand the opinions and/or sentiments of others is an inherently difficult
    task. To be able to handle such a problem algorithmically is equally hard. The
    following are some of the challenges faced while performing Sentiment Analysis:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 理解他人的观点和/或情感是一个固有的困难任务。能够以算法方式处理这样的问题同样困难。以下是在执行情感分析时面临的一些挑战：
- en: '**Understanding and Modeling Natural Language Constructs**: Sentiment analysis
    is inherently a **natural language processing** (**NLP**) problem, albeit a restricted
    one. Even though sentiment analysis is a restricted form of NLP, involving classification
    into positive, negative or neutral, it still faces issues like coreference resolution,
    word sense disambiguation, and negation handling to name a few. Advancements in
    NLP, as well as Sentiment Analysis, in recent years have helped in overcoming
    these issues to a certain extent, yet there is a long way to travel before we
    will be able to model the rules of a natural language perfectly.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理解和建模自然语言结构**：情感分析本质上是一个自然语言处理（NLP）问题，尽管是受限的。尽管情感分析是一种受限的自然语言处理形式，涉及对积极、消极或中性的分类，但它仍然面临诸如指称消解、词义消歧和否定处理等问题。近年来，自然语言处理以及情感分析方面的进步在一定程度上帮助解决了这些问题，但在我们能够完美地模拟自然语言的规则之前，还有很长的路要走。'
- en: '**Sarcasm**: Sentiments can be expressed in pretty subtle ways. It is not just
    negative sentiments; positive sentiments can also be nicely disguised within sarcastic
    sentences. Since understanding sarcasm is a trick only a few can master, it is
    not easy to model sarcasm and identify sentiment correctly. For example, the comment
    *Such a simple to use product, you just need to read 300 pages from the manual*,
    contains only positive words yet has a negative flavor to it which is not easy
    to model.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**讽刺**：情感可以通过相当微妙的方式表达。这不仅仅是负面情感；积极的情感也可以在讽刺的句子中巧妙地隐藏。由于理解讽刺是一种只有少数人能够掌握的技巧，因此很难对讽刺进行建模并正确识别情感。例如，评论“这样一个简单易用的产品，你只需要阅读手册中的300页”，虽然只包含积极的词汇，但带有一种不易建模的负面味道。'
- en: '**Review and reviewer quality**: Opinions vary from person to person. Some
    of us may present our opinions very strongly while others may not. Another issue
    is that everyone has an opinion, whether they know about a subject or not. This
    creates a problem of review and reviewer quality, which may affect overall analysis.
    For example, a person who is a casual reader may not be the most apt person to
    ask for a review of a new book. Similarly, it may not be advisable to get a new
    author''s book reviewed by a critic. Both extremes may result in biased outcomes
    or incorrect insights.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评审和评审质量**：每个人的观点都不尽相同。我们中的一些人可能会非常强烈地表达自己的观点，而其他人可能不会。另一个问题是，无论是否了解某个主题，每个人都有自己的观点。这导致了评审和评审质量的问题，可能会影响整体分析。例如，一个普通读者可能不是最合适的人选来评审一本新书。同样，让一位新作者的书被评论家评审可能也不太合适。这两种极端情况可能会导致结果有偏见或得出错误的见解。'
- en: '**Opinion data size and skew**: The web has loads and loads of blogs and sites
    which provide users with a platform to voice and share opinions on everything
    possible on and beyond the planet. Still, the opinion data at a granular level
    is an issue. As we discussed in the previous chapter, the amount of data related
    to a particular context (say a brand or a person) is so limited that it affects
    the overall analysis. Moreover, the data available is sometimes skewed in favor
    of (or against) entities due to prejudices, incorrect facts, or rumors.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**意见数据规模和偏差**：网络上有大量的博客和网站为用户提供了一个平台，让他们可以就地球上以及更远的地方的任何可能的事情发表和分享意见。然而，在细粒度层面上，意见数据仍然是一个问题。正如我们在上一章讨论的那样，与特定上下文（比如一个品牌或一个人）相关的数据量非常有限，这影响了整体分析。此外，由于偏见、错误的事实或谣言，可用的数据有时会偏向（或反对）某些实体。'
- en: Sentiment analysis upon Tweets
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对推文的情感分析
- en: 'Now that we are equipped with the key terms and concepts from the world of
    Sentiment Analysis, let us put our theory to the test. We have seen some major
    application areas for Sentiment Analysis and the challenges faced, in general,
    to perform such analytics. In this section we will perform Sentiment Analysis
    categorized into:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经掌握了情感分析领域的核心术语和概念，让我们将我们的理论付诸实践。我们已经看到了情感分析的一些主要应用领域以及一般面临的挑战。在本节中，我们将进行情感分析，分为以下类别：
- en: '**Polarity analysis**: This will involve the scoring and aggregation of sentiment
    polarity using a labeled list of positive and negative words.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**极性分析**：这将涉及使用标记的正面和负面词汇列表对情感极性进行评分和汇总。'
- en: '**Classification-based analysis**: In this approach we will make use of R''s
    rich libraries to perform classification based on labeled tweets available for
    public usage. We will also discuss their performance and accuracy.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于分类的分析**：在这种方法中，我们将利用R丰富的库来执行基于可供公众使用的标记推文的分类。我们还将讨论它们的性能和准确性。'
- en: R has a very robust library for the extraction and manipulation of information
    from Twitter called `TwitteR`. As we saw in the previous chapter, we first need
    to create an application using Twitter's application management console before
    we can use TwitteR or any other library for sentiment analysis. For this chapter,
    we will be reusing the application from the previous chapter (keep your application
    keys and secrets handy). Also, in the coming sections, we will be utilizing our
    code from previous chapters in a more structured format to enable reuse and to
    follow `#bestCodingPractices`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: R有一个非常强大的库，名为`TwitteR`，用于从Twitter中提取和操作信息。正如我们在上一章所看到的，在我们能够使用`TwitteR`或任何其他用于情感分析的库之前，我们首先需要使用Twitter的应用程序管理控制台创建一个应用程序。对于本章，我们将重用上一章中的应用程序（请妥善保管您的应用程序密钥和密码）。此外，在接下来的章节中，我们将以前几章中的代码为基础，以更结构化的格式使用我们的代码，以便重用并遵循`#bestCodingPractices`。
- en: 'Before we begin our analysis, let us first restructure our existing code and
    write some helper functions, which will come in handy later on. As we know, data
    from Twitter can be extracted using search terms or from a user''s timeline. The
    following two helper functions help us to do exactly the same tasks in a reusable
    fashion:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始分析之前，让我们首先重构我们现有的代码并编写一些辅助函数，这些函数将在以后派上用场。正如我们所知，可以使用搜索词或从用户的时序中提取Twitter的数据。以下两个辅助函数帮助我们以可重用的方式完成相同的任务：
- en: '[PRE0]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The function `extractTweets` takes the `search` term and number of tweets to
    be extracted as inputs and returns the data in a data frame which contains text
    converted to UTF8 encoding. Similarly, the function `extractTimelineTweets` takes
    the username and number of tweets as inputs and returns data in a data frame with
    the text converted to UTF8 encoding. Therefore, the preceding two functions will
    help us to extract tweets multiple times (based on different `search` terms or
    users) without rewriting the same lines of code again and again.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`extractTweets`接受`search`词和要提取的推文数量作为输入，并返回一个包含转换为UTF8编码的文本的数据框。同样，函数`extractTimelineTweets`接受用户名和推文数量作为输入，并返回一个包含转换为UTF8编码的文本的数据框。因此，前两个函数将帮助我们多次提取推文（基于不同的`search`词或用户），而无需反复重写相同的代码行。
- en: 'Continuing with the same theme, we will write another helper function to clean
    and transform our data set. As we saw in the previous chapter, R''s `tm` library
    provides us with various utility functions to quickly clean and transform text
    corpus. In this function, we will make use of `tm_map` to transform our tweets:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 继续同一主题，我们将编写另一个辅助函数来清理和转换我们的数据集。正如我们在上一章中看到的，R 的 `tm` 库为我们提供了各种实用函数，可以快速清理和转换文本语料库。在这个函数中，我们将使用
    `tm_map` 来转换我们的推文：
- en: '[PRE1]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In addition to the usual transformations, such as stop word removal, change
    to lower case, punctuation removal, and so on, the function `transformTweets`
    tokenizes each tweet at word level and attaches the list of words in each tweet
    to the object. Also, the function returns the transformed tweets in a data frame
    for further manipulation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 除了常见的转换，例如去除停用词、转换为小写、去除标点符号等，函数 `transformTweets` 在单词级别对每条推文进行分词，并将每条推文中的单词列表附加到对象上。此外，该函数返回一个数据框中的转换后的推文，以便进行进一步的操作。
- en: Polarity analysis
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 极性分析
- en: Polarity, as discussed in the section *Key Concepts*, is the positive, negative
    or neutral classification of the piece of text in consideration. The class labels
    may change depending upon the context (liked versus disliked or favorable versus
    unfavorable). Polarity may also have a degree attached to it which places the
    analyzed text on a continuous (or discrete) scale of polarities (say from `-5`
    to `5`). This degree of polarity helps us analyze the extent (or degree) of positivity
    (or negativity) in the text. This is particularly useful in comparative studies
    as we have the opportunity to view analyzed text with reference to certain benchmarks.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如在 *关键概念* 部分所述，极性是对考虑中的文本片段的正、负或中性分类。类标签可能根据上下文（喜欢与不喜欢或有利与不利）而变化。极性也可能附有一个程度，将分析文本放置在极性（或离散）的连续（或离散）尺度上（例如从
    `-5` 到 `5`）。这种极性程度有助于我们分析文本中积极（或消极）的程度（或程度）。这在比较研究中特别有用，因为我们有机会参考某些基准来查看分析文本。
- en: 'In this section, we will analyze tweets and score each of them based on the
    polar words identified in each of the tweets. The simple and easy-to-code algorithm
    is outlined in the following steps:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将分析推文并根据每条推文中确定的极性词对它们进行评分。简单的易于编码的算法概述如下步骤：
- en: Extract tweets based on selected search terms or Twitter handles.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据选定的搜索词或推特用户名提取推文。
- en: Clean and transform tweets into a suitable format for ease of analysis. Tokenize
    tweets into a constituent list of words.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理和转换推文，使其适合分析，将推文分词成单词列表。
- en: Load the list of positive and negative words to be used for polar word identification.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载用于极性词识别的正面和负面词列表。
- en: For each tweet, count the number of positive and negative words that match the
    list of positive and negative words obtained in the preceding step 3.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每条推文，计算与前一步骤 3 中获得的正面和负面词列表匹配的正面和负面词的数量。
- en: Assign a polarity score to each tweet based on the difference between positive
    and negative matches in the preceding step.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据前一步中正负匹配的差异，为每条推文分配一个极性分数。
- en: 'The preceding steps are represented diagrammatically as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的步骤可以用以下图示表示：
- en: '![Polarity analysis](img/00243.jpeg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![极性分析](img/00243.jpeg)'
- en: Once each tweet in the dataset has been scored, we may aggregate the scores
    to understand the overall sentiment distribution related to the search terms or
    Twitter handle. Positive values define a positive sentiment; larger numbers denote
    a greater degree of positivity, and similarly for negative sentiments. A neutral
    stance is represented by a score of 0\. For example, *This car is amazingly fast
    and beautiful* has a greater degree of positivity than *This is a nice car*, though
    both are positive sentences.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据集中的每条推文都被评分，我们可以汇总这些评分来了解与搜索词或推特用户名相关的整体情感分布。正值定义了积极情感；更大的数字表示更积极的程度，对于消极情感也是如此。中立立场由分数为
    0 表示。例如，*这辆车速度惊人，非常漂亮* 的积极程度高于 *这是一辆好车*，尽管两者都是积极的句子。
- en: Let us use this algorithm to analyze sentiments using search terms and Twitter
    handles. As discussed previously, opinion mining has become essential, not just
    for brands but for governments as well. Every entity out there wants to gauge
    how its target audience feels about it and its initiatives, and governments are
    no exception. Of late, the Indian Government has been utilizing Twitter and other
    social media platforms effectively to reach its audience and make them aware about
    its initiatives and policies. One such initiative is the recently launched Make
    in India initiative. Consider a scenario where one is tasked with analyzing the
    effectiveness of and public opinion related to such an initiative. To analyze
    public opinion, which changes dynamically over time, Twitter would be a good choice.
    So, to analyze sentiments for the Make in India initiative, let us analyze some
    tweets.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个算法通过搜索词和Twitter用户名来分析情感。如前所述，情感挖掘不仅对品牌至关重要，对政府也是如此。每个实体都希望了解其目标受众对其及其倡议的看法，政府也不例外。最近，印度政府有效地利用了Twitter和其他社交媒体平台来接触其受众，并让他们了解其倡议和政策。其中一个这样的倡议是最近推出的“印度制造”倡议。考虑这样一个场景，一个人被要求分析此类倡议的有效性和公众意见。为了分析随时间动态变化的公众意见，Twitter是一个不错的选择。因此，为了分析“印度制造”倡议的情感，让我们分析一些推文。
- en: As previously outlined, we start by connecting to Twitter and extracting tweets
    related to the search term *Make In India*. This is followed by the preprocessing
    step, where we remove stop words, URLs, and so on to transform the tweets into
    a usable format. We also tokenize each tweet into a list of constituent words
    for use in the coming steps. Once our dataset is ready and in a consumable format,
    we load the precompiled list of positive and negative words. The list is available
    from [https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们首先连接到Twitter，提取与搜索词*印度制造*相关的推文。这之后是预处理步骤，其中我们删除停用词、URL等，将推文转换为可用的格式。我们还对每个推文进行分词，将其分解成构成词列表，用于后续步骤。一旦我们的数据集准备就绪，并以可消费的格式存在，我们就加载预编译的正面和负面词列表。该列表可在[https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)找到。
- en: 'We first write a reusable `analyzeTrendSentiments` function which takes the
    search term and number of tweets to be extracted as inputs. It makes use of the
    functions `extractTweets` and `transformTweets` to get the job done:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先编写一个可重用的`analyzeTrendSentiments`函数，该函数接受搜索词和要提取的推文数量作为输入。它利用`extractTweets`和`transformTweets`函数来完成工作：
- en: '[PRE2]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We then use the function `analyzeTrendSentiments` to get a data frame consisting
    of tweets scored using a precompiled list of polar words. We use `twitteR`, `ggplot2`,
    `stringr` and `tm` libraries as well:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`analyzeTrendSentiments`函数获取一个包含使用预编译的极性词列表评分的推文的DataFrame。我们同时使用`twitteR`、`ggplot2`、`stringr`和`tm`库：
- en: '[PRE3]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the last chapter, we learned and used different visualizations to grasp
    the insights hidden in our analysis. Continuing with the same thought process,
    we generate a histogram of aggregated scores. The visualization looks like this:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了使用不同的可视化来掌握分析中隐藏的洞察力。继续同样的思考过程，我们生成一个聚合得分的直方图。可视化看起来是这样的：
- en: '![Polarity analysis](img/00244.jpeg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![极性分析](img/00244.jpeg)'
- en: The histogram is easy to interpret. It shows the tweets distributed across a
    polarity scale on the *x*-axis and frequency of tweets on the *y*-axis. The results
    show a normal distribution with a general tilt towards the positive side. It seems
    the initiative is getting a positive response from its audience.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图易于解释。它在x轴上显示了推文在极性尺度上的分布，在y轴上显示了推文的频率。结果显示为正态分布，整体倾向于正方向。这似乎表明该倡议得到了其受众的积极反响。
- en: Going a bit deeper into the analysis itself, let us analyze the sentiments for
    the same search term and see how the opinions change over time.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析本身深入一些，让我们分析相同搜索词的情感，看看意见是如何随时间变化的。
- en: Note
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The tweets for this analysis were extracted on the day the initiative was launched
    as well as a day later. Your results may vary due to the dynamic nature of Twitter.
    You may observe a difference in outcomes across other examples in this chapter
    as well. We urge you to be creative and try out other trending topics while working
    through examples from this chapter.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 用于此分析的所有推文都是在该倡议启动当天以及之后一天提取的。由于推特动态性的特点，您可能会观察到结果有所不同。您可能会在本章的其他示例中观察到结果差异。我们敦促您发挥创意，在处理本章的示例时尝试其他热门话题。
- en: 'The output looks like this:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 输出看起来像这样：
- en: '![Polarity analysis](img/00245.jpeg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![极性分析](img/00245.jpeg)'
- en: The preceding two histograms show a shift in opinions over the course of two
    days. If you were following the news at the time, in one of the events for this
    initiative a sudden fire broke out and burnt the whole stage. The graph on top
    is based upon tweets after the fire broke out while the graph labeled **makeinindia_yday**
    refers to the tweets from the day before. Though the shift in sentiments isn't
    drastic, it is clearly visible that the shift has been more towards the positive
    side (some tweets are even hitting a score of 6+). Could this be because tweeple
    started praising the emergency teams and police for their quick action in preventing
    casualties? Well, it looks like Twitter isn't just about people ranting on random
    stuff!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个直方图显示了两天内观点的变化。如果你当时在关注新闻，在这个倡议的一个事件中突然发生了火灾，整个舞台被烧毁。顶部的图表是基于火灾发生后发布的推文，而标记为**makeinindia_yday**的图表则指的是前一天发布的推文。尽管情感的变化并不剧烈，但很明显，变化更多地偏向于正面（一些推文的得分甚至达到了6+）。这会不会是因为推文作者开始赞扬紧急救援队伍和警察的快速行动，防止了伤亡？嗯，看起来推特不仅仅是人们随意发泄的地方！
- en: Note
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**World leaders**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**世界领袖**'
- en: Twitter has caught the frenzy of celebrities and politicians alike. As a quick
    exercise, try analyzing tweets from the twitter handles of world leaders such
    as `@potus`, `@pmoindia`, and `@number10gov` to see what kind of opinions our
    leaders project through Twitter. Don't be surprised if their timelines are neutral...oops,
    diplomatic!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 推特吸引了名人和政治家的狂热。作为一个快速练习，尝试分析来自世界领袖的推特账号，如`@potus`、`@pmoindia`和`@number10gov`的推文，看看我们的领导人在推特上传达了什么样的观点。如果他们的时间线是中性的，请不要感到惊讶……哦，外交啊！
- en: '![Polarity analysis](img/00246.jpeg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![极性分析](img/00246.jpeg)'
- en: Classification-based algorithms
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于分类的算法
- en: A classification problem requires the labeling of input data into required classes
    based on some defined characteristics of each class (see [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machines Learn*, for details).
    In the case of sentiment analysis, the classes are positive and negative (or neutral
    in certain cases). We have learned about different classification algorithms and
    seen how they are used across domains to solve categorization and classification
    problems in the previous chapters, and sentiment analysis is yet another domain
    where these algorithms are highly useful.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 分类问题需要根据每个类别的定义特征对输入数据进行标记，以便将其归类到所需的类别中（有关详细信息，请参阅[第2章](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "第2章。让我们帮助机器学习")，*让我们帮助机器学习*）。在情感分析的情况下，类别是正面和负面（或在某些情况下是中性）。在前几章中，我们已经学习了不同的分类算法，并看到了它们如何被用于各个领域来解决分类和分类问题，而情感分析又是这些算法高度有用的另一个领域。
- en: In this section, we will perform opinion mining using classification algorithms
    such as SVM and boosting. We will also touch upon ensemble methods and see how
    they help to improve performance. Note that, for this section, we will concentrate
    only on the positive and negative polarities, but the approach is generic enough
    to be easily extended to include the neutral polarity as well.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用SVM和提升等分类算法进行观点挖掘。我们还将简要介绍集成方法，看看它们如何帮助提高性能。请注意，对于本节，我们将仅集中讨论正面和负面极性，但这种方法足够通用，可以轻松扩展以包括中性极性。
- en: Labeled dataset
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标记数据集
- en: Since this is a supervised learning approach, we require labeled data for training
    and testing the performance of our algorithms. For the purpose of this chapter,
    we will utilize a labeled dataset from [http://www.sentiment140.com/](http://www.sentiment140.com/).
    It contains tweets labeled as 0, 2, and 4 for negative, neutral and positive sentiments,
    respectively. There are various attributes such as `tweet ID`, `date`, `search
    query`, `username`, and the `tweet text`, apart from the sentiment label. For
    our case we will be considering only the tweet text and its corresponding label.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个监督学习方法，我们需要标记数据来训练和测试算法的性能。为了本章的目的，我们将利用来自[http://www.sentiment140.com/](http://www.sentiment140.com/)的标记数据集。它包含标记为0、2和4的推文，分别代表负面、中性和正面情感。除了情感标签之外，还有各种属性，如`tweet
    ID`、`date`、`search query`、`username`和`tweet text`。在我们的案例中，我们只考虑推文文本及其相应的标签。
- en: '![Labeled dataset](img/00247.jpeg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![标记数据集](img/00247.jpeg)'
- en: Note
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Another source of labeled tweets is available at [https://github.com/guyz/twitter-sentiment-dataset](https://github.com/guyz/twitter-sentiment-dataset).
    This source makes use of a python script to download around 5000 labeled tweets
    keeping Twitter API guidelines in mind.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个标记推文的来源是[https://github.com/guyz/twitter-sentiment-dataset](https://github.com/guyz/twitter-sentiment-dataset)。这个来源使用Python脚本下载大约5000条标记推文，同时考虑到Twitter
    API指南。
- en: Before we get into the algorithm-specific details, let us look into the labeled
    dataset and perform the initial steps of collecting and transforming our data
    into the required forms. We will make use of libraries such as `caret` and `RTextTools`
    for these steps.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入算法的特定细节之前，让我们先查看标记数据集，并执行收集和将我们的数据转换为所需形式的初始步骤。我们将使用`caret`和`RTextTools`等库来完成这些步骤。
- en: As mentioned previously, the dataset contains polarities labeled as 0, 2, and
    4 for negative, neutral, and positive. We will load the `csv` file in R and apply
    a quick transformation to change the labels to positive and negative. Once the
    polarities have been transformed into intelligible names, we will filter out the
    rows of data containing neutral sentiments. Also, we will keep only the columns
    for polarity and tweet text, and remove the rest.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，数据集包含标记为0、2和4的极性，分别代表负面、中性和正面。我们将使用R加载`csv`文件，并快速转换标签为正面和负面。一旦极性被转换为可理解的名字，我们将过滤掉包含中性情感的数据行。此外，我们只保留极性和推文文本的列，并删除其余部分。
- en: '[PRE4]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `tweets` object is now available as a matrix with each row representing
    a tweet, and with columns referring to polarity and tweet text. Before we transform
    this matrix into the formats required by the classification algorithms, we need
    to split our data into training and testing datasets (see [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let''s Help Machines Learn"), *Let''s Help Machines Learn*, for more
    on this). Since both the training and testing datasets should contain a good enough
    distribution of samples of all classes for the purposes of training and testing,
    we use the `createDataPartition` function available from the `caret` package.
    For our use case, we split our data into 70/30 training and testing datasets:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`tweets`对象现在作为一个矩阵可用，其中每一行代表一条推文，列则分别指代极性和推文文本。在我们将这个矩阵转换为分类算法所需的格式之前，我们需要将我们的数据分为训练集和测试集（参见[第2章](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "第2章。让我们帮助机器学习")，*让我们帮助机器学习*，了解更多相关信息）。由于训练集和测试集都应该包含足够好的所有类别的样本分布，以便进行训练和测试，我们使用`caret`包中提供的`createDataPartition`函数。对于我们的用例，我们将数据分为70/30的训练集和测试集：'
- en: '[PRE5]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We perform a quick check to see how our data is split across the positive and
    negative classes in our original dataset, and the training and testing datasets.
    You will see the result in the following screenshot:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们快速检查了原始数据集中正负类别以及训练集和测试集的数据分布情况，结果将在下面的屏幕截图中展示：
- en: '![Labeled dataset](img/00248.jpeg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![标记数据集](img/00248.jpeg)'
- en: As we can see, `createDataPartition` has done a nice job of maintaining a similar
    sentiment distribution across the training and testing datasets.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，`createDataPartition`在训练集和测试集之间保持了相似的极性分布。
- en: 'Next in the line of transformations is the Document Term Matrix transformation.
    As we have seen in [Chapter 7](part0059_split_000.html#1O8H61-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 7. Social Media Analysis – Analyzing Twitter Data"), *Social Media Analysis
    – Analyzing Twitter Data*, a document term matrix transforms a given dataset into
    rows representing the documents and columns of terms (words/sentences). Unlike
    the previous chapter, where we used the `tm` library''s `DocumentTermMatrix` function
    for transformation and applied various transformations using `tm_map`, for the
    current use case we will use the `create_matrix` function from the `RTextTools`
    library. This function is an abstraction over `tm`''s corresponding functions.
    We will also assign weights to each of the terms using `tfidf` as our feature.
    The `create_matrix` method also helps us take care of splitting sentences into
    words, stop words and number removal, and stemming them as well. Here''s how you
    do it:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是文档词矩阵转换。正如我们在[第7章](part0059_split_000.html#1O8H61-973e731d75c2419489ee73e3a0cf4be8
    "第7章. 社交媒体分析 – 分析Twitter数据"), *社交媒体分析 – 分析Twitter数据*中看到的，文档词矩阵将给定的数据集转换为表示文档的行和表示术语（单词/句子）的列。与上一章不同，我们使用了`tm`库的`DocumentTermMatrix`函数进行转换，并使用`tm_map`应用了各种转换，对于当前的使用案例，我们将使用`RTextTools`库中的`create_matrix`函数。这个函数是`tm`对应函数的抽象。我们还将使用`tfidf`作为特征为每个术语分配权重。`create_matrix`方法还帮助我们处理将句子拆分为单词、去除停用词和数字，以及词干提取。以下是操作步骤：
- en: '[PRE6]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `create_matrix` method in `RTextTools v1.4.2` has a small bug which prevents
    weight assignment when using `originalMatrix` option. The following small hack
    can be used to fix the issue till the library gets updated:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`RTextTools v1.4.2`中的`create_matrix`方法有一个小错误，使用`originalMatrix`选项时阻止了权重分配。以下这个小技巧可以用来修复问题，直到库更新：'
- en: '[PRE7]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Scroll to line 42 and update Acronym to acronym.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动到第42行，并将缩写更新为缩写。
- en: 'Check the following links for more details and alternate ways of handling this
    issue:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下链接以获取更多详细信息以及处理此问题的其他方法：
- en: '[https://github.com/timjurka/RTextTools/issues/4](https://github.com/timjurka/RTextTools/issues/4)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/timjurka/RTextTools/issues/4](https://github.com/timjurka/RTextTools/issues/4)'
- en: '[http://stackoverflow.com/questions/16630627/recreate-same-document-term-matrix-with-new-data](http://stackoverflow.com/questions/16630627/recreate-same-document-term-matrix-with-new-data)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://stackoverflow.com/questions/16630627/recreate-same-document-term-matrix-with-new-data](http://stackoverflow.com/questions/16630627/recreate-same-document-term-matrix-with-new-data)'
- en: Now that we have both the training and testing datasets in the `DocumentTermMatrix`
    format, we can proceed towards the classification algorithms and let our machines
    learn and build sentiment classifiers!
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了训练集和测试集，都是以`DocumentTermMatrix`格式，我们可以继续进行分类算法，让我们的机器学习并构建情感分类器！
- en: Support Vector Machines
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 支持向量机
- en: '**Support Vector** **Machines**, or **SVM** as they are commonly known, are
    one of the most versatile classes of supervised learning algorithms for classification.
    An SVM builds a model in such a way that the data points belonging to different
    classes are separated by a clear gap, which is optimized such that the distance
    of separation is the maximum possible. The samples on the margins are called the
    support vectors, which are separated by a hyperplane (see [Chapter 6](part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 6. Credit Risk Detection and Prediction – Predictive Analytics"), *Credit
    Risk Detection and Prediction – Predictive Analytics* for more details).'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**，或通常所说的**SVM**，是分类中最灵活的监督学习算法之一。SVM以这种方式构建模型，即不同类别的数据点被一个清晰的间隙分开，这个间隙被优化到最大可能的分离距离。边缘上的样本被称为支持向量，它们被一个超平面分开（详见[第6章](part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8
    "第6章. 信用风险检测与预测 – 预测分析"), *信用风险检测与预测 – 预测分析*了解更多细节）。'
- en: '[PRE8]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The confusion matrix generated as follows shows that the classifier has just
    *50% accuracy*, which is as bad as a coin toss, with no predictions for negative
    sentiments whatsoever! It seems like the classifier couldn't infer or learn much
    from the training dataset.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如下生成的混淆矩阵显示，分类器的准确率仅为**50**%，这和掷硬币一样糟糕，完全没有对负面情绪进行预测！看起来分类器无法从训练数据集中推断或学习到很多东西。
- en: '![Support Vector Machines](img/00249.jpeg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![支持向量机](img/00249.jpeg)'
- en: 'To build a better-performing model, we will now go under the hood and tweak
    some parameters. The `svm` implementation from `e1071` provides us with a wonderful
    utility called `tune` to obtain the optimized values of hyperparameters using
    a grid search over the given parameter ranges:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建性能更好的模型，我们现在将深入底层并调整一些参数。`e1071`中的`svm`实现提供了一个名为`tune`的出色实用工具，通过在给定的参数范围内进行网格搜索来获得超参数的优化值：
- en: '[PRE10]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE11]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The parameter-tuning results in optimized values for hyperparameters `cost`
    and `gamma` as `10` and `0.01`, respectively; the following plot confirms the
    same (darkest region corresponds to best values).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 参数调整导致超参数`cost`和`gamma`的优化值分别为`10`和`0.01`；以下图表证实了这一点（最暗的区域对应最佳值）。
- en: '![Support Vector Machines](img/00250.jpeg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![支持向量机](img/00250.jpeg)'
- en: 'The following snippet of code uses the best model to predict and prepare a
    confusion matrix, as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段使用最佳模型进行预测并准备混淆矩阵，如下所示：
- en: '[PRE12]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following confusion matrix shows the predictions from a much improved model.
    From a mere 50% accuracy to a comfortable 80% and above is a good leap. Let us
    check the ROC curves for this model to confirm that the accuracy is indeed good
    enough:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下混淆矩阵显示了从改进后的模型中得出的预测。从仅仅50%的准确率到舒适的80%以上是一个很大的飞跃。让我们检查此模型的ROC曲线，以确认准确率确实足够好：
- en: '![Support Vector Machines](img/00251.jpeg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![支持向量机](img/00251.jpeg)'
- en: 'To prepare the ROC curves, we will reuse our utility script `performance_plot_utils.R`
    from [Chapter 6](part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 6. Credit Risk Detection and Prediction – Predictive Analytics"), *Credit
    Risk Detection and Prediction – Predictive Analytics*, and pass the predictions
    from the optimized model to it:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备ROC曲线，我们将重用我们的实用脚本`performance_plot_utils.R`，来自[第6章](part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8
    "第6章。信用风险检测和预测 – 预测分析")，*信用风险检测和预测 – 预测分析*，并将优化模型的预测传递给它：
- en: '[PRE13]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The ROC curves also confirm a well-learned model with an AUC of 0.89\. We can
    therefore use this model to classify tweets into positive or negative classes.
    We encourage readers to try out ROC-based optimizations and observe if there are
    any further improvements in the model.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ROC曲线也证实了一个学习良好的模型，其AUC为0.89。因此，我们可以使用此模型将推文分类为正面或负面类别。我们鼓励读者尝试基于ROC的优化，并观察模型是否还有进一步的改进。
- en: Ensemble methods
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成学习方法
- en: Supervised Machine Learning algorithms, in a nutshell, are about learning the
    underlying functions or patterns which help us predict accurately (within certain
    bounds) based on historic data. Over the course of this book, we have come across
    many such algorithms and, although R makes it easy to code and test these, it
    is worth mentioning that learning a highly accurate function or pattern is not
    an easy task. Building highly complex models leads us to issues of overfitting
    and underfitting, to name a few. Amidst all this confusion, it is to be noted
    that it is always easy to learn simple rules and functions.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，监督式机器学习算法是关于学习底层函数或模式，这些函数或模式帮助我们根据历史数据准确预测（在一定的范围内）。在本书的整个过程中，我们遇到了许多这样的算法，尽管R使得编码和测试这些算法变得容易，但值得一提的是，学习一个高度准确的功能或模式并不是一件容易的事情。构建高度复杂的模型会导致过拟合和欠拟合等问题。在所有这些混乱中，值得注意的是，学习简单的规则和函数总是很容易的。
- en: 'For example, to classify an email as spam or not spam there are multiple rules
    which a machine learning algorithm would have to learn, rules such as:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，为了将一封电子邮件分类为垃圾邮件或非垃圾邮件，机器学习算法需要学习多个规则，例如：
- en: E-mails containing text such as *buy now* are spam
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含类似“现在购买”等文本的电子邮件是垃圾邮件
- en: E-mails containing more than five hyperlinks are spam
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含五个以上超链接的电子邮件是垃圾邮件
- en: E-mails from contacts in the address book are not spam
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 地址簿中的联系人发送的电子邮件不是垃圾邮件
- en: And many more such rules. Given a training dataset, say `T` of labeled emails,
    a machine learning algorithm (specifically a classification algorithm) will generate
    a classifier, `C`, which is a hypothesis of an underlying function or pattern.
    We then use this classifier `C` to predict the labels for new emails.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 以及许多类似的规则。给定一个训练数据集，比如说`T`个标记的电子邮件，机器学习算法（特别是分类算法）将生成一个分类器`C`，这是一个底层函数或模式的假设。然后我们使用这个分类器`C`来预测新电子邮件的标签。
- en: On the other hand, an ensemble of classifiers is defined as a set of classifiers
    whose outputs are combined in some way to classify new examples. The main discovery
    in the field of machine learning-based ensembles is that ensembles perform much
    better than the individual classifiers they are made of.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，分类器集成被定义为输出以某种方式组合以对新示例进行分类的分类器集合。在基于机器学习的集成领域的主要发现是，集成比它们所组成的单个分类器表现得更好。
- en: A necessary and sufficient condition for ensembles to be better than their constituents
    is that they should be *accurate* and *diverse*. A classifier is termed *accurate*
    if its predictions are better than random guessing (see weak learners ). While
    two classifiers are termed as *diverse* if they make different errors on the same
    data points.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 集成优于其组成部分的必要且充分条件是它们应该是*准确*和*多样*的。如果一个分类器的预测比随机猜测更好，则称其为*准确*（参见弱学习者）。而如果两个分类器在相同的数据点上做出不同的错误，则称它们为*多样*。
- en: We can define a **weak learner** as a learner whose predictions and decisions
    are at least better than random guessing. Weak learners are also termed as base
    learners or meta learners.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将**弱学习者**定义为预测和决策至少比随机猜测更好的学习者。弱学习者也被称为基学习器或元学习器。
- en: 'The following block diagram visualizes the concept of ensemble classifiers:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 以下框图可视化了集成分类器的概念：
- en: '![Ensemble methods](img/00253.jpeg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![集成方法](img/00253.jpeg)'
- en: As seen in the preceding block diagram, the training dataset is split into *n*
    datasets (the splitting or generation of such datasets is dependent upon the ensemble-ing
    methodology) upon which weak learners (the same or different weak learners, again,
    depends upon the ensemble methodology) build models. These models are then combined
    based on weighted or unweighted voting to prepare a final model, which is used
    for classification. The mathematical proofs of why ensembles work are fairly involved
    and beyond the scope of this book.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述框图所示，训练数据集被分成 *n* 个数据集（这种数据集的分割或生成取决于集成方法），弱学习器（相同的或不同的弱学习器，同样取决于集成方法）在这些数据集上建立模型。然后根据加权或无权投票将这些模型组合起来，以准备一个最终模型，该模型用于分类。集成为何有效力的数学证明相当复杂，超出了本书的范围。
- en: Boosting
  id: totrans-176
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提升法
- en: There are various ways of constructing ensemble classifiers (or regressors)
    and boosting is one of them. Boosting came out as an answer by Robert Schapire
    in his pioneering paper in 1990 entitled *The Strength of Weak Learnability*,
    where he elegantly describes the boosting ensemble while answering questions posed
    by Kearns and Valiant in their paper published in 1989, which talks about multiple
    weak learners that can create a single strong learner.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 构建集成分类器（或回归器）的方法有很多，提升法就是其中之一。提升法作为罗伯特·沙皮雷在1990年发表的开拓性论文《弱学习能力的力量》中的答案出现，这篇论文的标题是《弱学习能力的力量》，他在其中优雅地描述了提升集成，同时回答了凯尔斯和瓦利亚恩在1989年发表的论文中提出的问题，该论文讨论了能够创建单个强学习者的多个弱学习者。
- en: Note
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '*The Strength of Weak Learnability*: [http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf](http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf).'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '*《弱学习能力的力量》*：[http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf](http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf)。'
- en: '**Kearns and Valiant:** Cryptographic limitations on learning Boolean Learning
    and finite automata: [http://dl.acm.org/citation.cfm?id=73049](http://dl.acm.org/citation.cfm?id=73049)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**凯尔斯和瓦利亚恩**：关于学习布尔学习和有限自动机的密码学限制：[http://dl.acm.org/citation.cfm?id=73049](http://dl.acm.org/citation.cfm?id=73049)'
- en: 'The original algorithm for boosting was revised by Freund and Schapire, and
    termed as **AdaBoost** or **Adaptive** **Boosting**. This algorithm was practically
    implementable and empirically improves generalization performance. The algorithm
    can be mathematically presented as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 提升法的原始算法由弗里德和沙皮雷修订，并命名为**AdaBoost**或**自适应****提升法**。这个算法是实际可实现的，并且经验上提高了泛化性能。该算法可以如下数学表示：
- en: '![Boosting](img/00254.jpeg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![提升法](img/00254.jpeg)'
- en: 'Source: [https://www.cs.princeton.edu/picasso/mats/schapire02boosting_schapire.pdf](https://www.cs.princeton.edu/picasso/mats/schapire02boosting_schapire.pdf)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.cs.princeton.edu/picasso/mats/schapire02boosting_schapire.pdf](https://www.cs.princeton.edu/picasso/mats/schapire02boosting_schapire.pdf)
- en: 'Here:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这里：
- en: '**X** is the training set'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**X** 是训练集'
- en: '**Y** is the label set'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Y** 是标签集'
- en: '**D[t](i)** is the weight distribution on training example **i** on iteration
    **t**'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**D[t](i)** 是在第 **t** 次迭代中对训练示例 **i** 的权重分布'
- en: '**h[t]** is the classifier obtained in iteration **t**'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**h[t]** 是在第 **t** 次迭代中获得的分类器'
- en: '**α** is the strength parameter or weight of **h[t]**'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**α** 是强度参数或 **h[t]** 的权重'
- en: '**H** is the final or combined classifier.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H** 是最终的或组合分类器。'
- en: In simple words, boosting, in general, begins by initially assigning equal weights
    to all training examples. It then iterates over the hypothesis space to learn
    a hypothesis **h[t]** on the weighted examples. After each such hypothesis is
    learned, the weights are adjusted in such a manner that the weights of the examples
    that are correctly classified are reduced. This update to weights helps weak learners,
    in coming iterations, to concentrate more on wrongly classified data points. Finally,
    each of the learned hypotheses is then passed through a weighted voting to come
    up with a final model, **H**.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，提升（Boosting）通常从最初对所有训练样本分配相同的权重开始。然后，它在假设空间中迭代，以学习加权样本上的假设 **h[t]**。在每个这样的假设学习之后，权重以这种方式进行调整，即正确分类的样本的权重减少。这种权重的更新有助于弱学习者在后续迭代中更多地关注错误分类的数据点。最后，将每个学习的假设通过加权投票来得到最终的模型，**H**。
- en: Now that we have an overview of ensemble methods and boosting in general, let
    us use the boosting implementation available from the `RTextTools` library in
    R to classify tweets as positive or negative.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对集成方法和提升有了概述，让我们使用R中的 `RTextTools` 库提供的提升实现来对推文进行正面或负面分类。
- en: We will reuse the training-testing document term matrices `train.dtMatrix` and
    `test.dtMatrix`, and container objects `train.container` and `test.container`,
    which we created for the SVM-based classification.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重用为基于SVM的分类创建的训练-测试文档项矩阵 `train.dtMatrix` 和 `test.dtMatrix`，以及容器对象 `train.container`
    和 `test.container`。
- en: For building a classifier based on a boosting ensemble, `RTextTools` provides
    an easy-to-use utility function called `train_model`. It uses *LogitBoosting*
    internally to build a classifier. We use `500` iterations for building our boosting
    ensemble.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建基于提升集成的分类器，`RTextTools` 提供了一个易于使用的实用函数 `train_model`。它内部使用 *LogitBoosting*
    来构建分类器。我们为构建我们的提升集成使用 `500` 次迭代。
- en: '[PRE14]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We then prepare a confusion matrix to see how our classifier performs on the
    test dataset.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们准备一个混淆矩阵来查看我们的分类器在测试数据集上的表现。
- en: '[PRE15]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The following confusion matrix shows that our boosting-based classifier works
    with an accuracy of 78.5%, which is fairly good given the fact that we did not
    perform any performance tuning. Compare this to the initial iteration of SVM where
    we got a dismal accuracy of just over 50%.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的混淆矩阵显示，我们的基于提升的分类器以78.5%的准确率工作，考虑到我们没有进行任何性能调整，这是一个相当不错的成绩。将其与SVM的初始迭代进行比较，我们得到的准确率仅为50%多。
- en: '![Boosting](img/00255.jpeg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![提升](img/00255.jpeg)'
- en: As mentioned earlier, ensemble methods (specifically boosting) have improved
    generalized performance, that is, they help achieve close to 0 training errors
    without overfitting on the training data. To understand and evaluate our Boosting
    classifier on these parameters, we will use a model-evaluation technique called
    **Cross-validation**.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，集成方法（特别是提升）提高了泛化性能，也就是说，它们有助于在不过度拟合训练数据的情况下实现接近0的训练错误。为了理解和评估我们的提升分类器在这些参数上，我们将使用一种称为
    **交叉验证** 的模型评估技术。
- en: Cross-validation
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 交叉验证
- en: 'Cross-validation is a model-evaluation technique which is used to evaluate
    the generalization performance of a model. It is also termed **rotational estimation**.
    Cross-validation is a better measure to validate a model for generalization compared
    to residual methods because, for conventional validation techniques, the error
    (such as **Root** **Mean Square Error**/**RMSE**) for the training set and testing
    set does not properly represent the model''s performance. Cross-validation can
    be performed using:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是一种模型评估技术，用于评估模型的泛化性能。它也被称为 **旋转估计**。与残差方法相比，交叉验证是验证模型泛化性能的更好指标，因为对于传统的验证技术，训练集和测试集的错误（如
    **均方根误差**/**RMSE**）并不能正确地表示模型的表现。交叉验证可以通过以下方式执行：
- en: '**Holdout method**: The simplest cross-validation technique. Data is split
    into training and testing sets. The model is fitted on the training set, and then
    the testing set (which the model hasn''t seen so far) is used to calculate the
    mean absolute test error. This accumulated error is used to evaluate the model.
    This technique suffers from high variance due to its dependency on how the training-testing
    division was done.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保留法**：最简单的交叉验证技术。数据被分为训练集和测试集。模型在训练集上拟合，然后使用测试集（模型之前未见过）来计算平均绝对测试误差。这个累积误差用于评估模型。这种技术由于依赖于训练-测试划分的方式，因此具有高方差。'
- en: '**K-fold cross validation method**: This is an improvement over the holdout
    method. The dataset is divided into *k* subsets and then the holdout method is
    applied k times using *1* of the *k* subsets as test and the rest, *k-1*, as training
    sets. This method has a lower variance due to the fact that each data point gets
    to be in the test set once and in the training set *k-1* times. The disadvantage
    is that more computation time is required due to the number of iterations. An
    extreme form of K-fold cross validation is the Leave-Out One cross-validation
    method where all data points except one are used for training. The process is
    repeated *N* (size of dataset) times.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**K折交叉验证方法**：这是对保留法的一种改进。数据集被分为*k*个子集，然后使用*k*个子集中的一个作为测试集，其余的*k-1*个子集作为训练集，重复使用保留法*k*次。由于每个数据点至少有一次进入测试集，而有*k-1*次进入训练集，这种方法具有较低的方差。缺点是由于迭代次数较多，需要更多的计算时间。K折交叉验证的一种极端形式是留一法交叉验证，其中除了一个数据点外，所有数据点都用于训练。这个过程重复*N*（数据集大小）次。'
- en: 'We can easily perform K-fold cross validation on our boosting classifier using
    the `cross_validate` function. In general, 10-fold cross validation is used:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`cross_validate`函数轻松地在我们的提升分类器上执行K折交叉验证。通常使用10折交叉验证：
- en: '[PRE16]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The results show that the classifier has generalized well enough, and has an
    overall mean accuracy of 97.8%.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，分类器已经很好地泛化，整体平均准确率为97.8%。
- en: Boosting is one of the methods to construct ensemble classifiers based on weak
    learners. Methods such as bagging, bayes optimal classifier, bucketing, and stacking
    are some of the variants with their own pros and cons.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 提升法是构建基于弱学习者的集成分类器的一种方法。例如，袋装法、贝叶斯最优分类器、桶装法和堆叠法等都是一些具有各自优缺点的变体。
- en: Note
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Constructing ensembles**'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**构建集成**'
- en: '`RTextTools` is a robust library which provides functions such as `train_models`
    and `classify_models` to prepare ensembles by combining various base learners.
    It also provides tools for generating analysis for evaluating the performance
    of such ensembles in a very detailed manner. Check out the detailed explanation
    at [https://journal.r-project.org/archive/2013-1/collingwood-jurka-boydstun-etal.pdf](https://journal.r-project.org/archive/2013-1/collingwood-jurka-boydstun-etal.pdf).'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`RTextTools`是一个健壮的库，它提供了`train_models`和`classify_models`等函数，通过结合各种基学习器来准备集成。它还提供了生成分析的工具，以非常详细的方式评估此类集成的性能。请参阅[https://journal.r-project.org/archive/2013-1/collingwood-jurka-boydstun-etal.pdf](https://journal.r-project.org/archive/2013-1/collingwood-jurka-boydstun-etal.pdf)的详细说明。'
- en: Summary
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Twitter is a goldmine for data science, with interesting patterns and insights
    spread all across it. Its constant flow of user-generated content, coupled with
    unique, interest-based relationships, present opportunities to understand human
    dynamics up close. Sentiments Analysis is one such field where Twitter provides
    the right set of ingredients to understand what and how we present and share opinions
    about products, brands, people, and so on.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter是数据科学的一个宝库，其中有趣的模式和见解遍布其中。其用户生成内容的持续流动，加上基于兴趣的独特关系，为近距离理解人类动态提供了机会。情感分析就是这样一个领域，Twitter提供了理解我们如何表达和分享对产品、品牌、人物等观点的合适成分。
- en: Throughout this chapter, we have looked at the basics of Sentiment Analysis,
    key terms, and areas of application. We have also looked into the various challenges
    posed while performing sentiment analysis. We have looked at various commonly-used
    feature extraction methods such as tf-idf, Ngrams, POS, negation, and so on for
    performing sentiment analysis (or textual analysis in general). We have built
    on our code base from the previous chapter to streamline and structure utility
    functions for reuse. We have performed polarity analysis using Twitter search
    terms and have seen how public opinion about certain campaigns can be easily tracked
    and analyzed. We then moved on to supervised learning algorithms for classification,
    where we used SVM and Boosting to build sentiment classifiers using libraries
    such as `caret`, `RTextTools`, `ROCR`, `e1071` and so on. Before closing the final
    chapter we also briefly touched upon the highly researched and widely used field
    of ensemble methods, and also learned about cross-validation-based model evaluation.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了情感分析的基础、关键术语以及应用领域。我们还探讨了在执行情感分析时遇到的各项挑战。我们研究了各种常用的特征提取方法，如tf-idf、Ngrams、POS、否定等，用于执行情感分析（或一般文本分析）。我们基于上一章的代码库，对可重用的实用函数进行了简化和结构化。我们使用Twitter搜索词进行了极性分析，并看到了公众对某些活动的看法如何被轻松追踪和分析。然后，我们转向监督学习算法进行分类，其中我们使用了SVM和Boosting，利用`caret`、`RTextTools`、`ROCR`、`e1071`等库构建情感分类器。在结束最后一章之前，我们还简要介绍了高度研究和广泛使用的集成方法领域，以及基于交叉验证的模型评估。
- en: There are many other algorithms and analysis techniques which can be applied
    to extract even more interesting insights from Twitter and other sources on the
    Internet. Throughout this chapter (and this book), we have merely attempted to
    address the tip of a huge iceberg! Data science is not just about applying algorithms
    to solve a problem or derive insights. It requires creative thinking and a lot
    of due diligence apart from domain understanding, feature engineering, and collecting
    data to try and solve problems which are as yet unknown.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他算法和分析技术可以应用于从Twitter和其他互联网来源中提取更多有趣的见解。在本章（以及本书）中，我们仅仅尝试触及这个巨大冰山的一角！数据科学不仅仅是将算法应用于解决问题或得出见解。它需要创造性思维和大量的尽职调查，除了领域理解、特征工程和收集数据来尝试解决尚未知的问题之外。
- en: 'To sum up things, ponder upon this quote by Donald Rumsfeld:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，思考一下唐纳德·拉姆斯菲尔德的这句话：
- en: '*"There are known knowns. These are things we know that we know. There are
    known unknowns. That is to say, there are things that we know we don''t know.
    But there are also unknown unknowns. There are things we don''t know we don''t
    know."*'
  id: totrans-217
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*"已知已知的事物。这些是我们知道我们知道的。已知未知的事物。也就是说，有些事情我们知道我们不知道。但还有未知未知的事物。有些事情我们不知道我们不知道。"*'
- en: Data science is a journey of learning the knowns and exploring the unknown unknowns,
    and machine learning is a powerful tool to help accomplish it. `#KeepMining`!
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学是一个学习已知事物和探索未知未知事物的旅程，而机器学习是帮助实现这一目标的强大工具。`#KeepMining`！
