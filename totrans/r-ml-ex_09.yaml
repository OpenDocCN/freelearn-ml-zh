- en: Chapter 8. Sentiment Analysis of Twitter Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '|   | *"He who molds the public sentiment... makes statutes and decisions possible
    or impossible to make."* |   |'
  prefs: []
  type: TYPE_TB
- en: '|   | --*Abraham Lincoln.* |'
  prefs: []
  type: TYPE_TB
- en: What people think matters not only to politicians and celebrities but also to
    most of us social beings. This need to know opinions about ourselves has affected
    people for a long time and is aptly summarized by the preceding famous quote.
    The opinion bug not only affects our own outlook, it affects the way we use products
    and services as well. As discussed while learning about market basket analysis
    and recommender engines (see [Chapter 3](part0026_split_000.html#OPEK1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 3. Predicting Customer Shopping Trends with Market Basket Analysis"),
    *Predicting Customer Shopping Trends with Market Basket Analysis* and [Chapter
    4](part0032_split_000.html#UGI01-973e731d75c2419489ee73e3a0cf4be8 "Chapter 4. Building
    a Product Recommendation System"), *Building a Product Recommendation System*
    respectively), our behavior can be approximated or predicted by observing the
    behavior of a group of people with similar characteristics such as price sensitivity,
    color preferences, brand loyalty, and so on. We also discussed in the earlier
    chapters that, for a long time, we have asked our friends and relatives for their
    opinions before making that next big purchase. While those opinions are important
    to us at an individual level, there are far more valuable insights we can derive
    from such information.
  prefs: []
  type: TYPE_NORMAL
- en: To say that the advent of the World Wide Web has simply accelerated and widened
    our circle would be an understatement. Without being repetitive, it is worth mentioning
    that the web has opened new doors for analyzing human behavior.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, social networks were the object of discussion. We not
    only used social networks as tools to derive insights but we also discussed the
    fact that these platforms satisfy our inherent curiosity about what others are
    thinking or doing. Social networks provide us all with a platform where we can
    voice our opinions and be heard. The *be heard* aspect of it is a little tricky
    to define and handle. For instance, our opinions and feedback (assuming they are
    genuine) about someone or something on these platforms will certainly be heard
    by the people in our circles (directly or indirectly), but they may or may not
    be heard by the people or organizations they are intended for. Nevertheless, such
    opinions or feedback do impact the people connected to them and their behavior
    from then on. This impact of opinions and our general curiosity about what people
    think, coupled with more such use cases, is the motivation for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will:'
  prefs: []
  type: TYPE_NORMAL
- en: Learn about sentiment Analysis and its key concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Look into the applications and challenges presented by sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the different approaches to perform opinion mining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply the concepts of sentiment analysis on Twitter data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Sentiment Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fact that Internet-based companies and their CEOs feature as some of the
    most profitable entities in the global economy says a lot about how the world
    is being driven by technology and shaped by the Internet. Unlike any other medium,
    the Internet has become ubiquitous and has penetrated every aspect of our lives.
    It is no surprise that we are using and relying on the Internet and Internet-based
    solutions for advice and recommendations, apart from using it for many other purposes.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in the previous chapters, the relationship between the Internet and
    domains such as e-commerce and financial institutions goes way too deep. But our
    use of and trust in the online world doesn't stop there. Be it about booking a
    table at the new restaurant in your neighborhood or deciding which movie to see
    tonight, we take help from the Internet to know what opinions others have, or
    what others have to share, before we make the final call. As we will see later,
    such decision aids are not just limited to the commerce platforms but also apply
    to many other domains.
  prefs: []
  type: TYPE_NORMAL
- en: Opinion mining or sentiment analysis (as it is widely and interchangeably known)
    is the process of automatically identifying the subjectivity in text using natural
    language processing, text analytics, and computational linguistics. Sentiment
    analysis aims to identify the positive, negative, or neutral opinion, sentiment,
    or attitude of the speaker using said techniques. Sentiment analysis (henceforth
    used interchangeably with opinion mining) finds its application in areas from
    commerce to service domains across the world.
  prefs: []
  type: TYPE_NORMAL
- en: Key concepts of sentiment analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now examine the key terms and concepts related to sentiment analysis.
    These terms and concepts will help us formalize our discussions in the coming
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: Subjectivity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Opinions or sentiments are one's own expression of views and beliefs. Furthermore,
    subjectivity (or subjective text) expresses our sentiments about entities such
    as products, people, governments, and so on. For instance, a subjective sentence
    could be *I love to use Twitter*, which shows a person's love towards a particular
    social network, while an objective sentence would be *Twitter is a social network*.
    The second example simply states a fact. Sentiment analysis revolves around subjective
    texts or subjectivity classification. It is also important to understand that
    not all subjective texts express sentiment. For example, *I just created my Twitter
    account*.
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment polarity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once we have a piece of text which is subjective in nature (and expresses some
    sentiment), the next task is to classify it into one of the sentiment classes
    of positive or negative (sometimes neutral is also considered). The task may also
    involve placing the text's sentiment on a continuous (or discrete) scale of polarities,
    thus defining the degree of positivity (or sentiment polarity). The sentiment
    polarity classification may deal with a different set of classes depending upon
    the context. For example, in a rating system for movies, sentiment polarities
    may be defined as liked versus disliked, or in a debate the views may be classified
    as for versus against.
  prefs: []
  type: TYPE_NORMAL
- en: Opinion summarization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Opinion classification or sentiment extraction from a piece of text is an important
    task in the process of sentiment analysis. This is often followed by a summarization
    of sentiments. To draw insights or conclusions from different texts related to
    the same topic (say, reviews of a given movie), it is important to aggregate (or
    summarize) the sentiments into a consumable form to draw conclusions (whether
    the movie is a blockbuster or a dud). This may involve the use of visualizations
    to infer the overall sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: Feature extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we have seen across the chapters, feature identification and extraction
    is what makes or breaks a machine learning algorithm. It is the most important
    factor after the data itself. Let us look at some of the feature sets utilized
    in solving the problem of sentiment analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '**TF-IDF**: Information Retrieval makes heavy use of **Term Frequency-Inverse**
    **Document Frequency** (**tf-idf**) to enable quick information retrieval and
    analysis. In the context of tf-idf, a piece of text is represented as a feature
    vector containing words as its constituents. Recent research has also shown that,
    in the context of sentiment analysis, the presence of a word improves the performance
    and accuracy as compared to the frequency of the word.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Source**:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. Thumbs up? Sentiment classification
    using machine learning techniques. In Proceedings of the Conference on **Empirical
    Methods in Natural Language Processing** (**EMNLP**), pages 79–86, 2002.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'TF-IDF is given as: ![Feature extraction](img/00239.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Where,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`tf(t,d)` is the term frequency of term `t` in document `d`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`idf(t,D)` is the inverse document frequency for term `t` in document set `D`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For example, we have the following screenshots of two documents with their
    terms and their corresponding frequencies:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Feature extraction](img/00240.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'In its simplest form, `TF-IDF` for the term `Twitter` can be given as:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Feature extraction](img/00241.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Different weight schemes can be used for calculating `tfidf`; the preceding
    example uses log with base 10 to calculate `idf`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`n-Grams`: Computational linguistics and probability consider a text corpus
    as a contiguous sequence of terms, which may be phonemes, letters, words, and
    so on. The n-gram-based modeling techniques find their roots in information theory,
    where the likelihood of the next character or word is based upon the *n* previous
    terms. Depending upon the value of `n`, the feature vector or model is termed
    as unigram (for `n=1`), bigram (for `n=2`), trigram (for `n=3`), and so on. n-grams
    are particularly useful with out-of-vocabulary words and approximate matches.
    For example, considering a sequence of words, a sentence such as *A chapter on
    sentiment analysis* would have bigrams such as *a chapter*, *chapter on*, *on
    sentiment*, *sentiment analysis*, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Interesting work by Google on using n-grams: [http://googleresearch.blogspot.in/2006/08/all-our-n-gram-are-belong-to-you.html](http://googleresearch.blogspot.in/2006/08/all-our-n-gram-are-belong-to-you.html).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Parts of Speech** (**POS**): Understanding and making use of the underlying
    structure of the language for analysis has obvious advantages. POS are rules of
    language which are used to create sentences, paragraphs and documents. In its
    simplest form, adjectives are usually pretty good indicators of subjectivity (not
    always, though). A number of approaches make use of the polarity of adjectives
    while classifying subjective texts. Using phrases containing adjectives has been
    shown to improve performance even further. Research into using other parts of
    speech, such as verbs and nouns, along with adjectives has also shown positive
    results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Reference**:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Peter Turney. Thumbs up or thumbs down? Semantic orientation applied to unsupervised
    classification of reviews. In Proceedings of the **Association for Computational
    Linguistics** (**ACL**), pages 417–424, 2002.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The following example shows the parts of speech (adjectives, nouns, and so
    on) tagged in a sample sentence, for example, *We saw the yellow dog*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Feature extraction](img/00242.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Source: [http://www.nltk.org/](http://www.nltk.org/)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Negation**: In the case of sentiment analysis, negation plays an important
    role. For example, sentences such as *I like oranges* and *I don''t like oranges*
    differ only in the word *don''t*, but the negation term flips the polarity of
    sentences to opposite classes (positive and negative respectively). Negation may
    be used as a secondary feature set where the original feature vector is generated
    as is, but is flipped in polarity later on based on the negation term. There are
    other variants to this approach as well, and they show an improvement in the results
    as compared to approaches which do not take into account the effects of negation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Topic specific features**: Topic plays an important role in setting the context.
    Since sentiment analysis is about the speaker''s opinion, the subjectivity is
    influenced by the topic being discussed. Extensive research has gone into analyzing
    the effects of and relationship between the topic and sentiment of the text corpus.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Reference**:'
  prefs: []
  type: TYPE_NORMAL
- en: Tony Mullen and Nigel Collier. Sentiment analysis using support vector machines
    with diverse information sources. In Proceedings of the Conference on **Empirical**
    **Methods in Natural Language Processing** (**EMNLP**), pages 412–418, July 2004\.
    Poster paper.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a basic understanding of the key concepts from the world of
    sentiment analysis, let us look at different approaches for tackling this problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sentiment analysis is mostly performed at the following two levels of abstraction:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Document level**: At this level of abstraction, the task is to analyze a
    given document to determine whether its overall sentiment is positive or negative
    (or neutral in certain cases). The basic assumption is that the whole document
    expresses opinions related to a single entity. For example, given a product review,
    the system analyzes it to determine whether the review is positive or negative.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sentence level**: Sentence level analysis is a more granular form of sentiment
    analysis. This level of granularity counters the fact that not all sentences in
    a document are subjective and thus makes better use of subjectivity classification
    to determine the sentiment on a per sentence basis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pretty much like other machine learning techniques, sentiment analysis can
    also be tackled using supervised and unsupervised methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Supervised Approach**: Research on sentiment analysis has been going on for
    quite some time. While the earlier research was constrained by the availability
    of labeled datasets and performed rather shallow analysis, modern day supervised
    learning approaches for sentiment analysis have seen a boost, both in terms of
    systems utilizing these techniques as well as the overall performance of such
    systems due to the availability of labeled datasets. Datasets such as WordNet,
    SentiWordNet, SenticNet, newswire, Epinions, and so on enormously assist researchers
    in improving supervised algorithms by providing datasets with polar words, documents
    classified into categories, user opinions, and so on. Algorithms such as **Naïve
    Bayes**, **Support Vector Machines** (**SVM**), as discussed in [Chapter 6](part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 6. Credit Risk Detection and Prediction – Predictive Analytics"), *Credit
    Risk Detection and Prediction – Predictive Analytics*, and **Maximum-Entropy-based**
    classification algorithms are classic examples of supervised learning approaches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unsupervised Approach**: Unsupervised algorithms for sentiment analysis usually
    begin with building or learning a sentiment lexicon and then determining the polarity
    of the text input. Lexicon generation has been done through techniques such as
    linguistic heuristics, bootstrapping, and so on. One famous approach was detailed
    by Turney in his 2002 paper where he describes unsupervised sentiment analysis
    using some fixed syntactic patterns which were based on POS.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Reference**:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Linguistic heuristics**: Vasileios Hatzivassiloglou and Kathleen McKeown.
    Predicting the semantic orientation of adjectives. In Proceedings of the Joint
    ACL/EACL Conference, pages 174–181, 1997.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Bootstrapping**: Ellen Riloff and Janyce Wiebe. Learning extraction patterns
    for subjective expressions. In Proceedings of the Conference on **Empirical Methods
    in Natural Language Processing** (**EMNLP**), 2003.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Turney**: Peter Turney. Thumbs up or thumbs down? Semantic orientation applied
    to unsupervised classification of reviews. In Proceedings of the **Association
    for Computational Linguistics** (**ACL**), pages 417–424, 2002.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we have been discussing throughout, our reliance upon online opinions is
    something of a surprise. We knowingly or unknowingly check these opinions or are
    influenced by them before buying products, downloading software, selecting apps,
    or choosing a restaurant. Sentiment analysis or opinion mining finds its application
    in many areas; they can be summarized into the following broad categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Online and Offline Commerce**: Customer preferences can make or break brands
    in an instant. For a product to be a hot seller, everything including pricing,
    packaging, and marketing has to be perfect. Customers form opinions about all
    aspects related to products, and thus affect their sales. It is not just the case
    with online commerce where customers check product reviews on multiple websites
    or blogs before making the actual purchase, but word of mouth and other such factors
    affect customer opinions in the world of offline commerce as well. Sentiment analysis
    thus forms an important factor which brands or companies track and analyze to
    be on top of the game. Analysis of social media content such as tweets, Facebook
    posts, blogs, and so on provide brands with an insight into how customers perceive
    their product. In certain cases, brands roll out specific marketing campaigns
    to set the general sentiment or hype about a product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Governance**: In a world where most activities have online counterparts,
    governments are no exceptions. There have been projects by various governments
    across the globe which have made use of sentiment analysis in matters of policy
    making and security (by analyzing and monitoring any increase in hostile or negative
    communications). Sentiment Analysis has also been used by analysts to determine
    or predict outcomes of elections as well. Tools such as *eRuleMaking* have sentiment
    analysis as a key component.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apart from the aforementioned two categories, opinion mining acts as an augmenting
    technology in fields such as recommendation engines and general prediction systems.
    For example, opinion mining may be used in conjunction with recommender engines
    to exclude products from recommendation lists which have opinions or sentiments
    below certain thresholds. Sentiment analysis may also find innovative use in predicting
    whether an upcoming movie will be a blockbuster or not based on sentiments related
    to the star cast, production house, topic of the movie, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the opinions and/or sentiments of others is an inherently difficult
    task. To be able to handle such a problem algorithmically is equally hard. The
    following are some of the challenges faced while performing Sentiment Analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Understanding and Modeling Natural Language Constructs**: Sentiment analysis
    is inherently a **natural language processing** (**NLP**) problem, albeit a restricted
    one. Even though sentiment analysis is a restricted form of NLP, involving classification
    into positive, negative or neutral, it still faces issues like coreference resolution,
    word sense disambiguation, and negation handling to name a few. Advancements in
    NLP, as well as Sentiment Analysis, in recent years have helped in overcoming
    these issues to a certain extent, yet there is a long way to travel before we
    will be able to model the rules of a natural language perfectly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sarcasm**: Sentiments can be expressed in pretty subtle ways. It is not just
    negative sentiments; positive sentiments can also be nicely disguised within sarcastic
    sentences. Since understanding sarcasm is a trick only a few can master, it is
    not easy to model sarcasm and identify sentiment correctly. For example, the comment
    *Such a simple to use product, you just need to read 300 pages from the manual*,
    contains only positive words yet has a negative flavor to it which is not easy
    to model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Review and reviewer quality**: Opinions vary from person to person. Some
    of us may present our opinions very strongly while others may not. Another issue
    is that everyone has an opinion, whether they know about a subject or not. This
    creates a problem of review and reviewer quality, which may affect overall analysis.
    For example, a person who is a casual reader may not be the most apt person to
    ask for a review of a new book. Similarly, it may not be advisable to get a new
    author''s book reviewed by a critic. Both extremes may result in biased outcomes
    or incorrect insights.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Opinion data size and skew**: The web has loads and loads of blogs and sites
    which provide users with a platform to voice and share opinions on everything
    possible on and beyond the planet. Still, the opinion data at a granular level
    is an issue. As we discussed in the previous chapter, the amount of data related
    to a particular context (say a brand or a person) is so limited that it affects
    the overall analysis. Moreover, the data available is sometimes skewed in favor
    of (or against) entities due to prejudices, incorrect facts, or rumors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis upon Tweets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we are equipped with the key terms and concepts from the world of
    Sentiment Analysis, let us put our theory to the test. We have seen some major
    application areas for Sentiment Analysis and the challenges faced, in general,
    to perform such analytics. In this section we will perform Sentiment Analysis
    categorized into:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Polarity analysis**: This will involve the scoring and aggregation of sentiment
    polarity using a labeled list of positive and negative words.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Classification-based analysis**: In this approach we will make use of R''s
    rich libraries to perform classification based on labeled tweets available for
    public usage. We will also discuss their performance and accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: R has a very robust library for the extraction and manipulation of information
    from Twitter called `TwitteR`. As we saw in the previous chapter, we first need
    to create an application using Twitter's application management console before
    we can use TwitteR or any other library for sentiment analysis. For this chapter,
    we will be reusing the application from the previous chapter (keep your application
    keys and secrets handy). Also, in the coming sections, we will be utilizing our
    code from previous chapters in a more structured format to enable reuse and to
    follow `#bestCodingPractices`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we begin our analysis, let us first restructure our existing code and
    write some helper functions, which will come in handy later on. As we know, data
    from Twitter can be extracted using search terms or from a user''s timeline. The
    following two helper functions help us to do exactly the same tasks in a reusable
    fashion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The function `extractTweets` takes the `search` term and number of tweets to
    be extracted as inputs and returns the data in a data frame which contains text
    converted to UTF8 encoding. Similarly, the function `extractTimelineTweets` takes
    the username and number of tweets as inputs and returns data in a data frame with
    the text converted to UTF8 encoding. Therefore, the preceding two functions will
    help us to extract tweets multiple times (based on different `search` terms or
    users) without rewriting the same lines of code again and again.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing with the same theme, we will write another helper function to clean
    and transform our data set. As we saw in the previous chapter, R''s `tm` library
    provides us with various utility functions to quickly clean and transform text
    corpus. In this function, we will make use of `tm_map` to transform our tweets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In addition to the usual transformations, such as stop word removal, change
    to lower case, punctuation removal, and so on, the function `transformTweets`
    tokenizes each tweet at word level and attaches the list of words in each tweet
    to the object. Also, the function returns the transformed tweets in a data frame
    for further manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: Polarity analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Polarity, as discussed in the section *Key Concepts*, is the positive, negative
    or neutral classification of the piece of text in consideration. The class labels
    may change depending upon the context (liked versus disliked or favorable versus
    unfavorable). Polarity may also have a degree attached to it which places the
    analyzed text on a continuous (or discrete) scale of polarities (say from `-5`
    to `5`). This degree of polarity helps us analyze the extent (or degree) of positivity
    (or negativity) in the text. This is particularly useful in comparative studies
    as we have the opportunity to view analyzed text with reference to certain benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will analyze tweets and score each of them based on the
    polar words identified in each of the tweets. The simple and easy-to-code algorithm
    is outlined in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract tweets based on selected search terms or Twitter handles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clean and transform tweets into a suitable format for ease of analysis. Tokenize
    tweets into a constituent list of words.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load the list of positive and negative words to be used for polar word identification.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each tweet, count the number of positive and negative words that match the
    list of positive and negative words obtained in the preceding step 3.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign a polarity score to each tweet based on the difference between positive
    and negative matches in the preceding step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The preceding steps are represented diagrammatically as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Polarity analysis](img/00243.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Once each tweet in the dataset has been scored, we may aggregate the scores
    to understand the overall sentiment distribution related to the search terms or
    Twitter handle. Positive values define a positive sentiment; larger numbers denote
    a greater degree of positivity, and similarly for negative sentiments. A neutral
    stance is represented by a score of 0\. For example, *This car is amazingly fast
    and beautiful* has a greater degree of positivity than *This is a nice car*, though
    both are positive sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Let us use this algorithm to analyze sentiments using search terms and Twitter
    handles. As discussed previously, opinion mining has become essential, not just
    for brands but for governments as well. Every entity out there wants to gauge
    how its target audience feels about it and its initiatives, and governments are
    no exception. Of late, the Indian Government has been utilizing Twitter and other
    social media platforms effectively to reach its audience and make them aware about
    its initiatives and policies. One such initiative is the recently launched Make
    in India initiative. Consider a scenario where one is tasked with analyzing the
    effectiveness of and public opinion related to such an initiative. To analyze
    public opinion, which changes dynamically over time, Twitter would be a good choice.
    So, to analyze sentiments for the Make in India initiative, let us analyze some
    tweets.
  prefs: []
  type: TYPE_NORMAL
- en: As previously outlined, we start by connecting to Twitter and extracting tweets
    related to the search term *Make In India*. This is followed by the preprocessing
    step, where we remove stop words, URLs, and so on to transform the tweets into
    a usable format. We also tokenize each tweet into a list of constituent words
    for use in the coming steps. Once our dataset is ready and in a consumable format,
    we load the precompiled list of positive and negative words. The list is available
    from [https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'We first write a reusable `analyzeTrendSentiments` function which takes the
    search term and number of tweets to be extracted as inputs. It makes use of the
    functions `extractTweets` and `transformTweets` to get the job done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We then use the function `analyzeTrendSentiments` to get a data frame consisting
    of tweets scored using a precompiled list of polar words. We use `twitteR`, `ggplot2`,
    `stringr` and `tm` libraries as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In the last chapter, we learned and used different visualizations to grasp
    the insights hidden in our analysis. Continuing with the same thought process,
    we generate a histogram of aggregated scores. The visualization looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Polarity analysis](img/00244.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The histogram is easy to interpret. It shows the tweets distributed across a
    polarity scale on the *x*-axis and frequency of tweets on the *y*-axis. The results
    show a normal distribution with a general tilt towards the positive side. It seems
    the initiative is getting a positive response from its audience.
  prefs: []
  type: TYPE_NORMAL
- en: Going a bit deeper into the analysis itself, let us analyze the sentiments for
    the same search term and see how the opinions change over time.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The tweets for this analysis were extracted on the day the initiative was launched
    as well as a day later. Your results may vary due to the dynamic nature of Twitter.
    You may observe a difference in outcomes across other examples in this chapter
    as well. We urge you to be creative and try out other trending topics while working
    through examples from this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Polarity analysis](img/00245.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The preceding two histograms show a shift in opinions over the course of two
    days. If you were following the news at the time, in one of the events for this
    initiative a sudden fire broke out and burnt the whole stage. The graph on top
    is based upon tweets after the fire broke out while the graph labeled **makeinindia_yday**
    refers to the tweets from the day before. Though the shift in sentiments isn't
    drastic, it is clearly visible that the shift has been more towards the positive
    side (some tweets are even hitting a score of 6+). Could this be because tweeple
    started praising the emergency teams and police for their quick action in preventing
    casualties? Well, it looks like Twitter isn't just about people ranting on random
    stuff!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**World leaders**'
  prefs: []
  type: TYPE_NORMAL
- en: Twitter has caught the frenzy of celebrities and politicians alike. As a quick
    exercise, try analyzing tweets from the twitter handles of world leaders such
    as `@potus`, `@pmoindia`, and `@number10gov` to see what kind of opinions our
    leaders project through Twitter. Don't be surprised if their timelines are neutral...oops,
    diplomatic!
  prefs: []
  type: TYPE_NORMAL
- en: '![Polarity analysis](img/00246.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Classification-based algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A classification problem requires the labeling of input data into required classes
    based on some defined characteristics of each class (see [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let's Help Machines Learn"), *Let's Help Machines Learn*, for details).
    In the case of sentiment analysis, the classes are positive and negative (or neutral
    in certain cases). We have learned about different classification algorithms and
    seen how they are used across domains to solve categorization and classification
    problems in the previous chapters, and sentiment analysis is yet another domain
    where these algorithms are highly useful.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will perform opinion mining using classification algorithms
    such as SVM and boosting. We will also touch upon ensemble methods and see how
    they help to improve performance. Note that, for this section, we will concentrate
    only on the positive and negative polarities, but the approach is generic enough
    to be easily extended to include the neutral polarity as well.
  prefs: []
  type: TYPE_NORMAL
- en: Labeled dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since this is a supervised learning approach, we require labeled data for training
    and testing the performance of our algorithms. For the purpose of this chapter,
    we will utilize a labeled dataset from [http://www.sentiment140.com/](http://www.sentiment140.com/).
    It contains tweets labeled as 0, 2, and 4 for negative, neutral and positive sentiments,
    respectively. There are various attributes such as `tweet ID`, `date`, `search
    query`, `username`, and the `tweet text`, apart from the sentiment label. For
    our case we will be considering only the tweet text and its corresponding label.
  prefs: []
  type: TYPE_NORMAL
- en: '![Labeled dataset](img/00247.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another source of labeled tweets is available at [https://github.com/guyz/twitter-sentiment-dataset](https://github.com/guyz/twitter-sentiment-dataset).
    This source makes use of a python script to download around 5000 labeled tweets
    keeping Twitter API guidelines in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get into the algorithm-specific details, let us look into the labeled
    dataset and perform the initial steps of collecting and transforming our data
    into the required forms. We will make use of libraries such as `caret` and `RTextTools`
    for these steps.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, the dataset contains polarities labeled as 0, 2, and
    4 for negative, neutral, and positive. We will load the `csv` file in R and apply
    a quick transformation to change the labels to positive and negative. Once the
    polarities have been transformed into intelligible names, we will filter out the
    rows of data containing neutral sentiments. Also, we will keep only the columns
    for polarity and tweet text, and remove the rest.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `tweets` object is now available as a matrix with each row representing
    a tweet, and with columns referring to polarity and tweet text. Before we transform
    this matrix into the formats required by the classification algorithms, we need
    to split our data into training and testing datasets (see [Chapter 2](part0022_split_000.html#KVCC1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 2. Let''s Help Machines Learn"), *Let''s Help Machines Learn*, for more
    on this). Since both the training and testing datasets should contain a good enough
    distribution of samples of all classes for the purposes of training and testing,
    we use the `createDataPartition` function available from the `caret` package.
    For our use case, we split our data into 70/30 training and testing datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We perform a quick check to see how our data is split across the positive and
    negative classes in our original dataset, and the training and testing datasets.
    You will see the result in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Labeled dataset](img/00248.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, `createDataPartition` has done a nice job of maintaining a similar
    sentiment distribution across the training and testing datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next in the line of transformations is the Document Term Matrix transformation.
    As we have seen in [Chapter 7](part0059_split_000.html#1O8H61-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 7. Social Media Analysis – Analyzing Twitter Data"), *Social Media Analysis
    – Analyzing Twitter Data*, a document term matrix transforms a given dataset into
    rows representing the documents and columns of terms (words/sentences). Unlike
    the previous chapter, where we used the `tm` library''s `DocumentTermMatrix` function
    for transformation and applied various transformations using `tm_map`, for the
    current use case we will use the `create_matrix` function from the `RTextTools`
    library. This function is an abstraction over `tm`''s corresponding functions.
    We will also assign weights to each of the terms using `tfidf` as our feature.
    The `create_matrix` method also helps us take care of splitting sentences into
    words, stop words and number removal, and stemming them as well. Here''s how you
    do it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `create_matrix` method in `RTextTools v1.4.2` has a small bug which prevents
    weight assignment when using `originalMatrix` option. The following small hack
    can be used to fix the issue till the library gets updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Scroll to line 42 and update Acronym to acronym.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the following links for more details and alternate ways of handling this
    issue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/timjurka/RTextTools/issues/4](https://github.com/timjurka/RTextTools/issues/4)'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://stackoverflow.com/questions/16630627/recreate-same-document-term-matrix-with-new-data](http://stackoverflow.com/questions/16630627/recreate-same-document-term-matrix-with-new-data)'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have both the training and testing datasets in the `DocumentTermMatrix`
    format, we can proceed towards the classification algorithms and let our machines
    learn and build sentiment classifiers!
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Support Vector** **Machines**, or **SVM** as they are commonly known, are
    one of the most versatile classes of supervised learning algorithms for classification.
    An SVM builds a model in such a way that the data points belonging to different
    classes are separated by a clear gap, which is optimized such that the distance
    of separation is the maximum possible. The samples on the margins are called the
    support vectors, which are separated by a hyperplane (see [Chapter 6](part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 6. Credit Risk Detection and Prediction – Predictive Analytics"), *Credit
    Risk Detection and Prediction – Predictive Analytics* for more details).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The confusion matrix generated as follows shows that the classifier has just
    *50% accuracy*, which is as bad as a coin toss, with no predictions for negative
    sentiments whatsoever! It seems like the classifier couldn't infer or learn much
    from the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines](img/00249.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To build a better-performing model, we will now go under the hood and tweak
    some parameters. The `svm` implementation from `e1071` provides us with a wonderful
    utility called `tune` to obtain the optimized values of hyperparameters using
    a grid search over the given parameter ranges:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The parameter-tuning results in optimized values for hyperparameters `cost`
    and `gamma` as `10` and `0.01`, respectively; the following plot confirms the
    same (darkest region corresponds to best values).
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines](img/00250.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following snippet of code uses the best model to predict and prepare a
    confusion matrix, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following confusion matrix shows the predictions from a much improved model.
    From a mere 50% accuracy to a comfortable 80% and above is a good leap. Let us
    check the ROC curves for this model to confirm that the accuracy is indeed good
    enough:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines](img/00251.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To prepare the ROC curves, we will reuse our utility script `performance_plot_utils.R`
    from [Chapter 6](part0046_split_000.html#1BRPS1-973e731d75c2419489ee73e3a0cf4be8
    "Chapter 6. Credit Risk Detection and Prediction – Predictive Analytics"), *Credit
    Risk Detection and Prediction – Predictive Analytics*, and pass the predictions
    from the optimized model to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The ROC curves also confirm a well-learned model with an AUC of 0.89\. We can
    therefore use this model to classify tweets into positive or negative classes.
    We encourage readers to try out ROC-based optimizations and observe if there are
    any further improvements in the model.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Supervised Machine Learning algorithms, in a nutshell, are about learning the
    underlying functions or patterns which help us predict accurately (within certain
    bounds) based on historic data. Over the course of this book, we have come across
    many such algorithms and, although R makes it easy to code and test these, it
    is worth mentioning that learning a highly accurate function or pattern is not
    an easy task. Building highly complex models leads us to issues of overfitting
    and underfitting, to name a few. Amidst all this confusion, it is to be noted
    that it is always easy to learn simple rules and functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to classify an email as spam or not spam there are multiple rules
    which a machine learning algorithm would have to learn, rules such as:'
  prefs: []
  type: TYPE_NORMAL
- en: E-mails containing text such as *buy now* are spam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: E-mails containing more than five hyperlinks are spam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: E-mails from contacts in the address book are not spam
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And many more such rules. Given a training dataset, say `T` of labeled emails,
    a machine learning algorithm (specifically a classification algorithm) will generate
    a classifier, `C`, which is a hypothesis of an underlying function or pattern.
    We then use this classifier `C` to predict the labels for new emails.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, an ensemble of classifiers is defined as a set of classifiers
    whose outputs are combined in some way to classify new examples. The main discovery
    in the field of machine learning-based ensembles is that ensembles perform much
    better than the individual classifiers they are made of.
  prefs: []
  type: TYPE_NORMAL
- en: A necessary and sufficient condition for ensembles to be better than their constituents
    is that they should be *accurate* and *diverse*. A classifier is termed *accurate*
    if its predictions are better than random guessing (see weak learners ). While
    two classifiers are termed as *diverse* if they make different errors on the same
    data points.
  prefs: []
  type: TYPE_NORMAL
- en: We can define a **weak learner** as a learner whose predictions and decisions
    are at least better than random guessing. Weak learners are also termed as base
    learners or meta learners.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following block diagram visualizes the concept of ensemble classifiers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Ensemble methods](img/00253.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As seen in the preceding block diagram, the training dataset is split into *n*
    datasets (the splitting or generation of such datasets is dependent upon the ensemble-ing
    methodology) upon which weak learners (the same or different weak learners, again,
    depends upon the ensemble methodology) build models. These models are then combined
    based on weighted or unweighted voting to prepare a final model, which is used
    for classification. The mathematical proofs of why ensembles work are fairly involved
    and beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Boosting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are various ways of constructing ensemble classifiers (or regressors)
    and boosting is one of them. Boosting came out as an answer by Robert Schapire
    in his pioneering paper in 1990 entitled *The Strength of Weak Learnability*,
    where he elegantly describes the boosting ensemble while answering questions posed
    by Kearns and Valiant in their paper published in 1989, which talks about multiple
    weak learners that can create a single strong learner.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*The Strength of Weak Learnability*: [http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf](http://www.cs.princeton.edu/~schapire/papers/strengthofweak.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Kearns and Valiant:** Cryptographic limitations on learning Boolean Learning
    and finite automata: [http://dl.acm.org/citation.cfm?id=73049](http://dl.acm.org/citation.cfm?id=73049)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The original algorithm for boosting was revised by Freund and Schapire, and
    termed as **AdaBoost** or **Adaptive** **Boosting**. This algorithm was practically
    implementable and empirically improves generalization performance. The algorithm
    can be mathematically presented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Boosting](img/00254.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://www.cs.princeton.edu/picasso/mats/schapire02boosting_schapire.pdf](https://www.cs.princeton.edu/picasso/mats/schapire02boosting_schapire.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**X** is the training set'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Y** is the label set'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D[t](i)** is the weight distribution on training example **i** on iteration
    **t**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**h[t]** is the classifier obtained in iteration **t**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**α** is the strength parameter or weight of **h[t]**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**H** is the final or combined classifier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In simple words, boosting, in general, begins by initially assigning equal weights
    to all training examples. It then iterates over the hypothesis space to learn
    a hypothesis **h[t]** on the weighted examples. After each such hypothesis is
    learned, the weights are adjusted in such a manner that the weights of the examples
    that are correctly classified are reduced. This update to weights helps weak learners,
    in coming iterations, to concentrate more on wrongly classified data points. Finally,
    each of the learned hypotheses is then passed through a weighted voting to come
    up with a final model, **H**.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an overview of ensemble methods and boosting in general, let
    us use the boosting implementation available from the `RTextTools` library in
    R to classify tweets as positive or negative.
  prefs: []
  type: TYPE_NORMAL
- en: We will reuse the training-testing document term matrices `train.dtMatrix` and
    `test.dtMatrix`, and container objects `train.container` and `test.container`,
    which we created for the SVM-based classification.
  prefs: []
  type: TYPE_NORMAL
- en: For building a classifier based on a boosting ensemble, `RTextTools` provides
    an easy-to-use utility function called `train_model`. It uses *LogitBoosting*
    internally to build a classifier. We use `500` iterations for building our boosting
    ensemble.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We then prepare a confusion matrix to see how our classifier performs on the
    test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The following confusion matrix shows that our boosting-based classifier works
    with an accuracy of 78.5%, which is fairly good given the fact that we did not
    perform any performance tuning. Compare this to the initial iteration of SVM where
    we got a dismal accuracy of just over 50%.
  prefs: []
  type: TYPE_NORMAL
- en: '![Boosting](img/00255.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As mentioned earlier, ensemble methods (specifically boosting) have improved
    generalized performance, that is, they help achieve close to 0 training errors
    without overfitting on the training data. To understand and evaluate our Boosting
    classifier on these parameters, we will use a model-evaluation technique called
    **Cross-validation**.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-validation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Cross-validation is a model-evaluation technique which is used to evaluate
    the generalization performance of a model. It is also termed **rotational estimation**.
    Cross-validation is a better measure to validate a model for generalization compared
    to residual methods because, for conventional validation techniques, the error
    (such as **Root** **Mean Square Error**/**RMSE**) for the training set and testing
    set does not properly represent the model''s performance. Cross-validation can
    be performed using:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Holdout method**: The simplest cross-validation technique. Data is split
    into training and testing sets. The model is fitted on the training set, and then
    the testing set (which the model hasn''t seen so far) is used to calculate the
    mean absolute test error. This accumulated error is used to evaluate the model.
    This technique suffers from high variance due to its dependency on how the training-testing
    division was done.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**K-fold cross validation method**: This is an improvement over the holdout
    method. The dataset is divided into *k* subsets and then the holdout method is
    applied k times using *1* of the *k* subsets as test and the rest, *k-1*, as training
    sets. This method has a lower variance due to the fact that each data point gets
    to be in the test set once and in the training set *k-1* times. The disadvantage
    is that more computation time is required due to the number of iterations. An
    extreme form of K-fold cross validation is the Leave-Out One cross-validation
    method where all data points except one are used for training. The process is
    repeated *N* (size of dataset) times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can easily perform K-fold cross validation on our boosting classifier using
    the `cross_validate` function. In general, 10-fold cross validation is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The results show that the classifier has generalized well enough, and has an
    overall mean accuracy of 97.8%.
  prefs: []
  type: TYPE_NORMAL
- en: Boosting is one of the methods to construct ensemble classifiers based on weak
    learners. Methods such as bagging, bayes optimal classifier, bucketing, and stacking
    are some of the variants with their own pros and cons.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Constructing ensembles**'
  prefs: []
  type: TYPE_NORMAL
- en: '`RTextTools` is a robust library which provides functions such as `train_models`
    and `classify_models` to prepare ensembles by combining various base learners.
    It also provides tools for generating analysis for evaluating the performance
    of such ensembles in a very detailed manner. Check out the detailed explanation
    at [https://journal.r-project.org/archive/2013-1/collingwood-jurka-boydstun-etal.pdf](https://journal.r-project.org/archive/2013-1/collingwood-jurka-boydstun-etal.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Twitter is a goldmine for data science, with interesting patterns and insights
    spread all across it. Its constant flow of user-generated content, coupled with
    unique, interest-based relationships, present opportunities to understand human
    dynamics up close. Sentiments Analysis is one such field where Twitter provides
    the right set of ingredients to understand what and how we present and share opinions
    about products, brands, people, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, we have looked at the basics of Sentiment Analysis,
    key terms, and areas of application. We have also looked into the various challenges
    posed while performing sentiment analysis. We have looked at various commonly-used
    feature extraction methods such as tf-idf, Ngrams, POS, negation, and so on for
    performing sentiment analysis (or textual analysis in general). We have built
    on our code base from the previous chapter to streamline and structure utility
    functions for reuse. We have performed polarity analysis using Twitter search
    terms and have seen how public opinion about certain campaigns can be easily tracked
    and analyzed. We then moved on to supervised learning algorithms for classification,
    where we used SVM and Boosting to build sentiment classifiers using libraries
    such as `caret`, `RTextTools`, `ROCR`, `e1071` and so on. Before closing the final
    chapter we also briefly touched upon the highly researched and widely used field
    of ensemble methods, and also learned about cross-validation-based model evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: There are many other algorithms and analysis techniques which can be applied
    to extract even more interesting insights from Twitter and other sources on the
    Internet. Throughout this chapter (and this book), we have merely attempted to
    address the tip of a huge iceberg! Data science is not just about applying algorithms
    to solve a problem or derive insights. It requires creative thinking and a lot
    of due diligence apart from domain understanding, feature engineering, and collecting
    data to try and solve problems which are as yet unknown.
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up things, ponder upon this quote by Donald Rumsfeld:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"There are known knowns. These are things we know that we know. There are
    known unknowns. That is to say, there are things that we know we don''t know.
    But there are also unknown unknowns. There are things we don''t know we don''t
    know."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Data science is a journey of learning the knowns and exploring the unknown unknowns,
    and machine learning is a powerful tool to help accomplish it. `#KeepMining`!
  prefs: []
  type: TYPE_NORMAL
