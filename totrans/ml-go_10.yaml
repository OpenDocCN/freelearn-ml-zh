- en: Algorithms/Techniques Related to Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a few algorithms and techniques, related to the machine learning examples
    in this book, that we were not able to go into much detail about in the preceding
    chapters. We will address that here.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In multiple examples (including those in [Chapter 4](c5c610c4-4e25-4e09-9150-b25c4b69720e.xhtml),
    *Regression* and [Chapter 5](f0ffd10e-d2c4-41d7-8f26-95c05a30d818.xhtml)*, Classification*),
    we took advantage of an optimization technique called **gradient descent**. There
    are multiple variants of the gradient descent method, and, in general, you will
    see them pretty much everywhere in the machine learning world. Most prominently,
    they are utilized in the determination of optimal coefficients for algorithms
    such as linear or logistic regression, and thus, they often also play a role in
    more complicated techniques at least partially based on linear/logistic regression
    (such as neural networks).
  prefs: []
  type: TYPE_NORMAL
- en: The general idea of gradient descent methods is to determine a direction and
    magnitude of change in some parameters that will move you in the right direction
    to optimize some measure (such as error). Think about standing on some landscape.
    To move toward lower elevations, you need to take steps in the downward direction.
    This is basically what gradient descent is doing algorithmically when it is optimizing
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s gain some more intuition about this process by looking at so-called
    **Stochastic Gradient Descent** (**SGD**), which is an incremental kind of gradient
    descent. If you remember, we actually utilized SGD in our implementation of logistic
    regression in [Chapter 5](f0ffd10e-d2c4-41d7-8f26-95c05a30d818.xhtml), *Classification*.
    In that example, we implemented the training or fitting of our logistic regression
    parameters as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The loop under the `// Iteratively optimize the weights` comment implements
    SGD to optimize the logistic regression parameters. Let's pick apart this loop
    to determine what exactly is happening.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we calculate the output of our model with the current weights and the
    difference between our prediction and the ideal value (the actual observation,
    that is):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, according to SGD, we are going to calculate an update to our parameters
    (in this case `weights`) according to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9585b444-6017-4174-95fd-103c4941f2f9.png)'
  prefs: []
  type: TYPE_IMG
- en: The **gradient** is the mathematical gradient of the cost function in your problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'More detailed mathematical information about this quantity can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://mathworld.wolfram.com/Gradient.html](http://mathworld.wolfram.com/Gradient.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The update can then be applied to the parameters as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2a207315-7ebb-4ca5-824f-5794482733b1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the case of our logistic regression model, this works out to have the following
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This type of SGD is pretty widely used in machine learning. However, in some
    cases, this kind of gradient descent can lead to overfitting or getting stuck
    in local minimums/maximums (rather than finding the global optimum).
  prefs: []
  type: TYPE_NORMAL
- en: To address some of these issues, you can utilize a variant of gradient descent
    called **batch gradient descent**. In batch gradient descent, you calculate each
    of the parameter updates based on gradients in all of the training dataset, as
    opposed to a gradient for a particular observation or row of the dataset. This
    helps you prevent overfitting, but it can also be rather slow and have memory
    issues because you need to calculate gradient with respect to a whole dataset
    for each parameter. **Mini-batch** **gradient descent**, which is another variant,
    attempts to maintain some of the benefits of batch gradient descent while being
    more computationally tractable. In mini-batch gradient descent, the gradients
    are calculated on subsets of the training dataset rather than the whole training
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of logistic regression, you may see the use of gradient ascent or
    descent, where gradient ascent is the same thing as gradient descent except that
    it is applied to the negative of the cost function. The logistic cost function
    gives you both of these options as long as you are consistent. This is further
    discussed at [https://stats.stackexchange.com/questions/261573/using-gradient-ascent-instead-of-gradient-descent-for-logistic-regression](https://stats.stackexchange.com/questions/261573/using-gradient-ascent-instead-of-gradient-descent-for-logistic-regression).
  prefs: []
  type: TYPE_NORMAL
- en: 'Gradient descent methods are also already implemented by the gonum team in
    `gonum.org/v1/gonum/optimize`. See these docs for more information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://godoc.org/gonum.org/v1/gonum/optimize#GradientDescent](https://godoc.org/gonum.org/v1/gonum/optimize#GradientDescent)'
  prefs: []
  type: TYPE_NORMAL
- en: Entropy, information gain, and related methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 5](f0ffd10e-d2c4-41d7-8f26-95c05a30d818.xhtml), *Classification*,
    we explored decision tree methods in which models consisted of a tree of if/then
    statements. These if/then portions of the decision tree split the prediction logic
    based on one of the features of the training set. In an example where we were
    trying to classify medical patients into unhealthy or healthy categories, a decision
    tree might first split based on a gender feature, then based on an age feature,
    then based on a weight feature, and so on, eventually landing on healthy or unhealthy.
  prefs: []
  type: TYPE_NORMAL
- en: How does the algorithm choose which features to use first in the decision tree?
    In the preceding example, we could split on gender first, or weight first, and
    any other feature first. We need a way to arrange our splits in an optimal way,
    such that our model makes the best predictions that it can make.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many decision tree model implementations, including the one we used in [Chapter
    5](f0ffd10e-d2c4-41d7-8f26-95c05a30d818.xhtml), *Classification*, use a quantity
    called **entropy** and an analysis of **information gain** to build up decision
    trees. To illustrate this process, let''s consider an example. Assume that you
    have the following data about numbers of healthy people versus various characteristics
    of those people:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Healthy** | **Unhealthy** |'
  prefs: []
  type: TYPE_TB
- en: '| **Vegan Diet** | 5 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| **Vegetarian Diet** | 4 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| **Meat Eating Diet** | 3 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '|  | **Healthy** | **Unhealthy** |'
  prefs: []
  type: TYPE_TB
- en: '| **Age 40+** | 3 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| **Age < 40** | 9 | 2 |'
  prefs: []
  type: TYPE_TB
- en: Here, we have two features in our data, Diet and Age, and we would like to build
    a decision tree to predict if people are healthy or not based on Diet and Age.
    To do this, we need to decide whether we should split our decision tree first
    on Age or first on Diet. Notice that we also have a total of 12 healthy people
    and 7 unhealthy people represented in the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, we will calculate the overall or total entropy of the classes in
    our data. This is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0d24303f-5049-4827-8236-938d7f26a921.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *p[1]*, *p[2],* and so on, are the probabilities of a first category,
    a second category, and so on. In our particular case (because we have 12 healthy
    people and 7 unhealthy people), our total entropy is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4ce3e27c-05ed-47d1-bcf9-44a96c149cce.png)'
  prefs: []
  type: TYPE_IMG
- en: This *0.95* measure represents the homogeneity of our health data. It goes between
    0 and 1, with high values corresponding to less homogeneous data.
  prefs: []
  type: TYPE_NORMAL
- en: To determine whether we should split our tree first on Age or first on Diet,
    we will calculate which of these features gives us the most information gain.
    Simply put, we will find the feature that gives us the most homogeneity after
    splitting on that feature, as measured by the preceding entropy. This decrease
    in entropy is called **information gain**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The information gain for a certain feature in our example is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3158bf53-063b-4137-8163-579a8b5b2fea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, *E(Health, Feature)* is a second measure of entropy with respect to the
    given feature (*Age* or *Diet*). For Diet, this second measure would be calculated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5c8cb814-8e7c-4157-8b5f-7dea151e83fb.png)'
  prefs: []
  type: TYPE_IMG
- en: The quantities *p[40+]* and *p[<40]* are the probabilities of having an age
    of *40*+ or *<40* (8/19 and 11/19, respectively). The quantities *E(Health,40+)*
    and *E(Health,<40)* are the health entropies (as defined in the preceding formula)
    but only using the counts corresponding to those Age *40+* and Age *<40*, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: For our example data, the information gain for the Age feature comes out to
    *0.152* and the information gain for the Diet feature comes out to *0.079*. Thus,
    we would choose to split our decision tree on the Age feature first because it
    increases the overall homogeneity of our data the most.
  prefs: []
  type: TYPE_NORMAL
- en: You can find out more about building decision trees based on entropy at [http://www.saedsayad.com/decision_tree.htm](http://www.saedsayad.com/decision_tree.htm),
    and you can see an example implementation in Go at [https://github.com/sjwhitworth/golearn/blob/master/trees/entropy.go](https://github.com/sjwhitworth/golearn/blob/master/trees/entropy.go).
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 8](3e51d99f-2f6a-4d4b-876f-3b44f74b9a20.xhtml), *Neural Networks and
    Deep Learning*, included an example of a neural network built from scratch in
    Go. This neural network included an implementation of the backpropagation method
    to train neural networks, which can be found in almost any neural network code.
    We discussed some details in that chapter. However, this method is utilized so
    often that we wanted to go through it step by step here.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To train a neural network with backpropagation, we do the following for each
    of a series of epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: Feed the training data through the neural network to produce output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate an error between the expected output and the predicted output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on the error, calculate updates for the neural network weights and biases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Propagate these updates back into the network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As a reminder, our implementation of this procedure for a network with a single
    hidden layer looked like the following (where `wHidden` and `wOut` are our hidden
    layer and output layer weights and `bHidden` and `bOut` are our hidden layer and
    output layer biases):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Let's pick this implementation apart in detail to understand exactly what's
    happening.
  prefs: []
  type: TYPE_NORMAL
- en: 'The feed forward process that produces our output does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Multiplies the input data by the hidden layer weights, adds the hidden layer
    biases, and applies the sigmoid activation function to calculate the output of
    the hidden layer, `hiddenLayerActivations` (lines 112 to 120 in the preceding
    snippet).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiples the `hiddenLayerActivations` by the output layer weights, then adds
    the output layer biases, and applies the sigmoid activation function to calculate
    the `output` (lines 122 to 126).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notice that in the feed forward process, we are starting with the input data
    at the input layer and working our way forward through the hidden layer until
    we reach the output.
  prefs: []
  type: TYPE_NORMAL
- en: After the feed forward process, we need to calculate optimal updates to our
    weights and biases. As you might expect after going through the gradient descent
    portion of this Appendix, gradient descent is a perfect fit to find these weights
    and biases. Lines 129 through 144 in the preceding snippet implement SGD.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we need to apply these updates backward through the network in lines
    147 through 169\. This is the backward propagation of updates that gives backpropagation
    its name. There isn''t anything too special about this process, we just perform
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Apply the calculated updates to the output weights and biases (lines 147 to
    157).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the calculated updates to the hidden layer weights and biases (lines 159
    to 169).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notice how we start at the output and work our way back to the input applying
    the changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find a very detailed discussion of backpropagation, including mathematical
    proofs, here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://neuralnetworksanddeeplearning.com/chap2.html](http://neuralnetworksanddeeplearning.com/chap2.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation started to be widely utilized after a 1986 paper by David Rumelhart,
    Geoffrey Hinton, and Ronald Williams. Although the method is utilized across the
    industry in neural networks, Geoffrey Hinton recently came out to say that he
    is *deeply suspicious* of backpropagation and suggests that we need to work hard
    to find an alternative.
  prefs: []
  type: TYPE_NORMAL
