# *第11章*：超参数调整和自动机器学习

在前一章中，我们学习了如何训练**卷积神经网络**和复杂的**深度神经网络**。在训练这些模型时，我们经常面临各种参数的艰难选择，例如层数、滤波器维度、层的类型和顺序、正则化、批量大小、学习率、训练轮数等。这不仅适用于DNN，当我们需要选择正确的预处理步骤、特征、模型和模型参数时，统计机器学习方法也会出现同样的挑战。

在本章中，我们将探讨优化训练过程以移除机器学习（ML）中的一些非最佳人类选择。这将帮助您更快、更高效地训练更好的模型，而无需人工干预。首先，我们将探讨**超参数优化**（在Azure机器学习中也称为**HyperDrive**），这是一种优化ML过程中参数的标准技术。通过评估不同的超参数采样技术，例如随机采样、网格采样和贝叶斯优化，您将学习如何有效地在模型运行时间和模型性能之间进行权衡。

在本章的后半部分，我们将探讨通过使用**自动机器学习**自动化完整的端到端ML训练过程来进行模型优化。这个过程也常被称为**AutoML**。使用自动机器学习，我们可以在一个抽象的优化管道中优化预处理、特征工程、模型选择、超参数调整和模型堆叠。

Azure机器学习的一个好处是，参数优化（HyperDrive）和模型优化（自动机器学习）都支持相同的通用方式。这意味着我们可以将它们部署到自动扩展的训练集群中，将最佳模型或参数组合存储在磁盘上，然后在不离开笔记本环境的情况下将最佳模型部署到生产环境中。

本章将涵盖以下主题：

+   使用HyperDrive找到最佳模型参数

+   使用自动机器学习找到最佳模型

# 技术要求

在本章中，我们将使用以下Python库和版本来创建基于决策树的集成分类器：

+   `azureml-core 1.34.0`

+   `azureml-sdk 1.34.0`

与前几章类似，您可以使用本地Python解释器或Azure机器学习中的笔记本环境运行此代码。然而，所有脚本都需要在Azure机器学习训练集群中安排。

本章中的所有代码示例都可以在这个书的GitHub仓库中找到：[https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter11](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter11)。

# 使用HyperDrive寻找最佳模型参数

在机器学习中，我们通常处理参数模型或非参数模型。模型代表训练数据的分布，以对同一分布中的未见数据进行预测。虽然参数模型（如线性回归、逻辑回归和神经网络）通过使用学习到的参数集来表示训练数据分布，但非参数模型通过其他特征来描述训练数据分布，如决策树（所有基于树的分类器）、训练样本（k-最近邻）或加权的训练样本（支持向量机）。

**参数模型**，如线性或逻辑回归，通常由一个与训练数据无关的常数参数数量定义。这些模型对训练数据做出了强烈的假设，因此通常需要较少的训练样本。因此，训练和推理通常都非常快。

相比之下，对于**非参数模型**，如决策树或k-最近邻，特征的数量通常随着训练样本数量的增加而增加。虽然这些模型不对训练数据的分布做任何假设，但通常需要许多训练样本。这往往会导致训练速度慢和干扰性能慢。

术语**超参数**指的是用于配置和调整参数模型或非参数模型训练过程的全部参数。以下是一个神经网络中一些典型超参数的列表：

+   隐藏层的数量

+   每层的单元数量

+   批处理大小

+   过滤维度

+   学习率

+   正则化项

+   Dropout

+   损失度量

训练一个简单的机器学习模型所需的超参数数量和参数值是惊人的。你是否曾经发现自己手动调整训练过程中的参数，比如决策分类器中的分割数量或神经网络分类器中的单元数量？如果是这样，你并不孤单！然而，接受手动调整参数需要对该特定模型或模型配置有深厚的专业知识是非常重要的。然而，我们不可能成为每种统计建模、机器学习和优化的专家，以便手动调整所有可能的参数。鉴于参数选择数量巨大，尝试所有可能的组合是不切实际的，因此我们需要找到一种更好的方法来优化它们。

我们不仅不可能手动尝试所有不同的参数组合，而且在许多情况下，即使有专家知识，我们也无法预测超参数调整的结果。在这种情况下，我们可以开始寻找自动找到最佳参数集的方法。这个过程被称为**超参数调整**或**超参数搜索**。

超参数调整涉及自动测试模型针对不同超参数组合集的性能，并最终选择最佳的超参数组合。最佳性能的定义取决于选择的指标和验证方法。例如，使用f1分数指标的分层交叉验证将产生与k折交叉验证的准确度指标不同的最佳参数集。

我们在这本书中讨论超参数调整（以及稍后讨论的自动机器学习）的一个原因是，我们使用弹性云计算基础设施具有竞争优势。虽然在你笔记本电脑上按顺序训练数百个模型是困难的，但在云中使用廉价的自动扩展计算并行训练数千个模型则很容易。使用廉价的云存储，我们还可以持久化所有潜在的好模型以供后续分析。许多最近的机器学习论文表明，通过使用更多的计算能力或更好的参数选择，我们通常可以实现更好的结果。

在我们开始调整超参数之前，我们想提醒您基线模型的重要性。对于许多实际的机器学习任务，您应该能够使用单个基于树的集成分类器或具有默认参数的预训练神经网络实现良好的性能。如果情况不是这样，超参数调整不会神奇地输出顶级最佳模型的参数。在这种情况下，最好是先回到数据预处理和特征工程，构建一个更好的基线模型，然后再调整批量大小、隐藏单元数量或树的数量。

在超参数调整中需要避免的另一个问题是过拟合以及关注错误的表现指标或验证方法。与任何其他优化技术一样，超参数调整将产生给定损失函数或指标的最佳参数组合。因此，在开始超参数调整之前验证你的损失函数是至关重要的。

与机器学习中的大多数其他技术一样，有多种方法可以找到模型的最佳超参数。最流行的技术是网格搜索、随机搜索和贝叶斯优化。在本章中，我们将研究这三种方法，讨论它们的优缺点，并通过实际示例进行实验。

## 使用网格搜索对所有可能的参数组合进行采样

**网格搜索**（或**网格采样**）是一种通过测试多维参数网格的每个可能的参数组合来从参数网格中找到最佳超参数的流行技术。对于每个参数（连续或分类），我们需要定义所有应该测试的值或值范围。流行的机器学习库提供工具来有效地创建这些参数网格。

两个特性将网格搜索与其他超参数采样方法区分开来：

+   假设所有参数组合都是相互独立的，这意味着它们可以并行测试。因此，给定100种可能的参数组合，我们可以启动100个模型来并行测试所有组合。

+   通过测试所有可能的参数组合，我们可以确保我们寻找的是全局最优解，而不是局部最优解。

网格搜索对于只有少数超参数的小型机器学习模型工作得很好，但随着每个额外参数的增加，它会呈指数增长，因为它为参数网格添加了一个新的维度。

让我们看看如何使用Azure机器学习实现网格搜索。在Azure机器学习中，超参数调整功能位于`hyperdrive`包中。以下是我们要做的事情：

1.  创建一个网格采样配置

1.  定义一个主要指标来定义调整目标

1.  创建`hyperdrive`配置

1.  将`hyperdrive`配置作为实验提交到Azure机器学习

让我们更详细地看看这些步骤：

1.  首先，我们必须通过定义网格采样的参数选择和范围来创建网格采样配置，如下面的代码块所示：

    [PRE0]

在前面的代码中，我们使用离散的参数选择定义了一个参数网格，沿着三个参数维度——第一层的神经元数量、第二层的神经元数量和训练批次大小。

1.  参数名称格式化为命令行参数，因为它们将被作为参数传递给训练脚本。因此，我们需要确保训练脚本可以通过命令行参数配置参数。以下代码显示了在您的训练示例中这可能是什么样子：

    [PRE1]

使用网格采样，我们可以测试这些参数的所有可能组合。这将导致总共32次运行（*4 x 4 x 2*），理论上我们可以并行运行，因为训练运行和参数配置是相互独立的。在这种情况下，所需的总训练运行次数很明显，因为我们只使用离散的参数范围。稍后，我们将看到这并不适用于随机采样和贝叶斯优化。对于这些其他方法，我们从连续分布中进行采样，因此训练运行的次数不会有限制。我们还将看到，当参数选择不是独立时，并行运行的次数会影响优化过程。因此，让我们欣赏网格采样解决方案在少量离散参数上的简单性。

1.  接下来，我们需要定义一个度量标准，用于衡量每个参数组合的性能。这个度量标准可以是训练脚本记录的任何数值。请注意，这个度量标准不需要与损失函数相同——它可以是你想要用来比较不同参数对度的任何测量。看看下面的例子。在这里，我们决定最大化`accuracy`度量标准，并定义了以下参数：

    [PRE2]

在前面的代码中，我们选择了`accuracy`度量标准，这是我们想要最大化的。在这里，你可以看到我们只是简单地指定了任何度量名称作为字符串。为了使用此度量标准来评估超参数优化运行，训练脚本需要记录具有此确切名称的度量。我们已经在之前的章节中看到了这一点，其中我们为Azure Machine Learning运行发出了度量。

1.  我们必须使用相同的`primary_metric_name`度量名称来定义和记录一个可以被`hyperdrive`在训练脚本中评估的度量：

    [PRE3]

1.  在我们继续之前，回想一下之前章节中的脚本运行配置。类似于之前的章节，我们必须配置一个基于CPU的Azure Machine Learning训练集群，定义为`aml_cluster`，以及一个包含运行TensorFlow所需的所有相关包的环境`tf_env`：

    [PRE4]

1.  现在，我们可以初始化`hyperdrive`配置，它由估计器、采样网格、优化度量标准以及运行数和并发运行数组成：

    [PRE5]

在网格采样中，运行的次数应该与可能的参数组合数相对应。由于这是一个必需的属性，我们需要计算这个值并将其传递到这里。网格采样的最大并发运行数仅受你的Azure Machine Learning集群中节点数的限制。我们使用了一个四节点集群，因此我们将数字设置为`4`以最大化并发性。

1.  最后，我们可以将`hyperdrive`配置提交给一个实验，该实验将在指定的计算目标上执行所有并发子运行：

    [PRE6]

前面的代码片段将启动训练过程，如果需要，将构建和注册新的Docker镜像，初始化并扩展集群中的节点，并最终在集群上运行训练脚本。每个脚本将使用采样网格中唯一的参数组合进行参数化。下面的截图显示了生成的实验运行。我们可以通过点击前面代码片段返回的链接来访问这个页面：

![图11.1 – 网格采样概述](img/B17928_11_01.jpg)

图11.1 – 网格采样概述

在这里，我们可以看到采样策略的名称，它是**GRID**，以及配置的参数空间。这些参数将被作为命令行参数应用到训练脚本中。

如您可能已经猜到的，当你必须从一个多维网格中采样所有可能的参数组合时，并非一切都很完美。随着超参数数量的增加，网格的维度也会增加。并且每个参数维度都会增加一个数量级的参数配置，需要对其进行测试。别忘了，测试参数配置通常意味着在你的模型上执行训练、交叉验证和测试集预测，这可能需要大量的资源。

假设你想为五个参数寻找最佳参数组合，每个参数有 10 个不同的值。让我们假设以下情况：

+   我们正在测试 10^5 (*10 x 10 x 10 x 10 x 10*) 个参数组合。

+   一次训练运行只需 2 分钟。

+   我们正在进行四折交叉验证。

在这里，我们最终会有 555 天（*2min x 4 x 10^5 = 800,000min*）的累计训练时间。虽然你可以通过并行运行参数组合来减少总运行时间，但还有其他更适合大量参数的方法，例如随机抽样。让我们看看如何通过随机抽样参数配置来限制参数优化搜索所需的运行时间。

## 使用随机搜索测试随机组合

**随机搜索**是另一种流行的超参数抽样方法，类似于网格搜索。主要区别在于，它不是测试所有可能的参数组合，而是随机选择并测试几个组合。主要思想是，网格搜索通常采样对模型性能影响不大的参数配置。因此，我们浪费了大量时间追逐类似的不良解决方案，而我们本可以用这些时间尝试更多样化和可能更成功的参数配置。

当你处理大量的超参数（例如，超过 5 个）时，随机搜索会比网格搜索更快地找到一组好的超参数 – 然而，它可能不是最佳结果。即便如此，在许多情况下，使用随机搜索而不是网格搜索来提高预测性能，通过超参数调整进行权衡将是合理的。

在随机搜索中，参数通常是从连续分布中抽取的，而不是使用离散的参数选择。这导致定义参数网格的方式略有不同。我们不是为不同的值提供选择，而是可以为每个参数定义一个分布函数，以从连续范围内抽取随机值。

与网格搜索类似，如果参数组合是带替换抽取的，则所有参数组合都是独立的，这意味着它们可以被完全并行化。如果提供了一个包含 10,000 个不同参数配置的参数网格，我们就可以并行运行并测试所有模型。

让我们来看看 Azure Machine Learning 中的随机搜索：

1.  与所有其他超参数优化方法一样，我们在`hyperdrive`包中找到了随机采样方法。正如我们之前讨论的，我们现在可以为每个参数定义概率分布函数，例如`normal`和`uniform`，而不是只选择离散参数：

    [PRE7]

使用连续参数范围是随机采样中的唯一不同之处。由于可以从连续范围中采样无限数量的参数配置，我们需要一种方法来指定搜索的持续时间。我们可以使用`max_total_runs`和`max_duration_minutes`参数来定义预期的运行时间（以分钟为单位）或限制采样参数配置的数量。

1.  让我们测试25种不同的配置，并将超参数调整过程运行最长60分钟。我们必须设置以下参数：

    [PRE8]

1.  我们将重用之前定义的相同指标，即*准确率*。`hyperdrive`配置如下所示：

    [PRE9]

1.  与之前的示例类似，我们必须从作者运行时提交`hyperdrive`配置到Azure Machine Learning，这将安排所有优化运行在计算目标上：

    [PRE10]

随机采样是测试大量可调超参数或从连续范围中采样值的绝佳选择。然而，我们不是逐步优化参数配置，而是简单地随机尝试所有这些配置，并比较它们的性能。

在下一节中，我们将学习如何通过提前停止训练运行来更快地找到好的参数组合。在随后的章节*使用贝叶斯优化优化参数选择*中，我们将探讨在超参数调整中通过优化导航参数空间的一种更优雅的方法。

## 使用提前终止更快地收敛

网格和随机采样技术都会测试模型对参数选择的不足，因此会浪费宝贵的计算资源来拟合参数较差的模型到您的训练数据中。**提前终止**是一种在中间结果看起来比其他运行更差时提前停止训练的技术。这是加快昂贵超参数优化技术的绝佳解决方案。

通常，您应该始终尝试在使用网格或随机采样时使用提前终止。如果结果比一些现有运行差得多，那么训练所有参数组合就没有任何好处。

一旦我们理解了取消表现不佳的运行的想法，我们需要找到一种方法来指定何时应该取消运行的阈值——我们将这个阈值称为**终止策略**。Azure Machine Learning提供了最流行的终止策略，即**探索者**、**中位数停止**和**截断选择**。让我们来看看它们，并了解它们之间的区别。

在我们深入了解细节之前，让我们学习如何配置早期终止。在Azure Machine Learning中，我们可以使用两个全局属性对不同的早期终止策略进行参数化，即`evaluation_interval`和`delay_evaluation`。这些参数控制早期终止策略被测试的频率。以下是如何使用这些参数的示例：

[PRE11]

这两个参数的单位都是间隔。例如，当你训练一个神经网络时，一个间隔等于一个训练epoch。`delay_evaluation`参数控制我们在第一次测试早期终止策略之前需要等待多少个间隔。在先前的例子中，我们将其配置为`10`，这意味着我们等待10个epoch之后才测试早期终止策略。

然后，每个其他策略评估都使用`evaluation_interval`参数进行配置。它描述了需要经过多少次迭代才能进行下一次测试。在先前的例子中，我们将`evaluation_interval`设置为`1`，这也是默认值。这意味着我们在`delay_evaluation`间隔之后每隔一个间隔测试早期终止策略——在这里，每1次迭代。让我们更详细地看看三种终止策略。

### 中值终止策略

让我们从最简单的终止策略开始——**中值终止策略**。它不需要除了两个默认参数之外的其他参数，这两个参数控制策略何时以及多久应该被测试。中值终止策略会跟踪所有实验运行中主要指标的平均值。每当评估中值策略时，它都会测试当前指标是否高于所有运行实验的中位数，并停止那些低于中位数的运行。以下代码展示了如何为任何超参数调整脚本创建一个中值终止的早期终止策略：

[PRE12]

如我们所见，构建中值终止策略非常简单，因为它只由两个默认参数配置。由于其简单性，它是一种非常有效的方法，可以减少你的超参数优化脚本的运行时间。然后，使用`policy`参数将早期终止策略应用于`hyperdrive`配置文件。现在，让我们看看截断选择策略。

### 截断选择策略

与中值终止策略不同，`truncation_percentage`参数：

[PRE13]

在先前的例子中，我们将`truncation_percentage`值设置为`10`。这意味着每当早期终止策略执行时，它将终止表现最差的10%的运行。我们还必须将`evaluation_interval`值增加到`5`，因为我们不想像以下示例中那样在每个epoch结束时终止运行：

[PRE14]

这种早期终止策略在只有很少的训练资源可用，并且我们希望在每次评估早期终止策略时积极修剪运行数量时是有意义的。让我们看看最终的策略——bandit策略。

### Bandit策略

`slack_factor`或`slack_amount`参数。`slack_factor`参数描述了相对于最佳指标的相对偏差，而`slack_amount`参数描述了相对于最佳主要指标的绝对偏差。

让我们来看一个例子。在这里，我们将通过配置`slack_factor`参数为`0.2`并测试一个准确度值（*越大越好*）来配置`hyperdrive`。像之前一样，我们将`evaluation_interval`值设置为`5`，将`evaluation_delay`值设置为`10`个间隔：

[PRE15]

假设性能最佳的运行在10个epoch后产生了0.8的准确度，这是早期终止策略第一次被应用的时候。现在，所有性能比最佳指标差20%以上的运行都将被终止。我们可以通过以下函数计算从0.8准确度出发的相对偏差：

*0.8/(1 + 0.2) = 0.67*

因此，所有性能低于0.67的运行都将被早期终止策略取消。

### 带有终止策略的HyperDrive配置

要创建一个`hyperdrive`配置，我们需要使用`policy`参数传递早期终止策略。以下是一个使用网格搜索采样和之前定义的bandit策略的示例：

[PRE16]

Bandit策略是中值停止和截断选择策略之间的一种良好权衡，后者在许多情况下都表现良好。你可以放心，只有所有超参数配置中表现良好的子集将在多个间隔内运行和评估。

让我们将这个HyperDrive配置作为一个实验提交到Azure机器学习。我们可以使用之前章节中看到的`RunDetails`方法来输出关于超参数调整实验的附加信息，例如调度和参数信息、训练性能的可视化，以及显示参数维度的并行坐标图：

[PRE17]

如果你运行前面的代码，它将运行配置策略的超参数搜索。一旦实验开始运行，你将看到作为小部件中图表的指定指标，对于单个参数组合和迭代：

![图11.2 – HyperDrive – 运行的性能](img/B17928_11_02.jpg)

图11.2 – HyperDrive – 运行的性能

除了查看定义的指标外，你还可以选择其他可视化，显示采样参数，例如在并行坐标图上，或作为二维和三维散点图。在这里，你可以看到哪些参数组合产生了高模型准确度：

![图11.3 – HyperDrive – 结果的可视化](img/B17928_11_03.jpg)

图11.3 – HyperDrive – 结果的可视化

在本节中，你了解到将早期终止策略应用于你的超参数优化脚本是一种简单但极其有效的方法，可以减少表现不佳的训练运行次数。只需几行代码，我们就可以将训练运行的次数减少到最小，并且只完成那些产生有希望结果的任务。

重要提示

当你使用随机或网格采样进行超参数优化时，*始终*使用早期终止策略。

## 使用贝叶斯优化优化参数选择

在前面的例子中，我们评估了从网格或随机采样的不同参数配置，而没有进行任何优化或战略性的参数选择。这有一个好处，即所有配置都是独立的，并且可以并行评估。然而，想象一下使用ML模型帮助我们找到大型多维参数空间中最佳参数组合的情况。这正是**贝叶斯优化**在超参数调整领域所做的事情。

优化方法的工作是找到预定义目标函数的最优值（即最小值或最大值）。在超参数调整中，我们面临一个非常类似的问题：我们想要找到产生最佳预定义评估指标的参数配置。

那么，超参数搜索的优化是如何工作的呢？首先，我们必须定义一个超平面——一个多维网格，我们可以从中采样参数配置。在下面的图中，我们可以看到沿着*x*和*y*轴的两个参数的这样一个平面。*z*轴表示使用该特定位置的参数测试的模型的性能：

![图11.4 – Rastrigin函数](img/B17928_11_04.jpg)

图11.4 – Rastrigin函数

上述图显示了多维Rastrigin函数，作为一个极其难以优化的例子。在超参数调整中，我们经常面临类似的问题，即找到最优解是困难的——就像在Rastrigin函数中找到全局最小值一样。

然后，我们必须从这个平面上采样点并测试第一个（几个）参数配置。我们假设参数不是独立的，并且当使用相似的邻近参数时，模型将具有相似的性能。然而，每次评估只能得到真实模型性能的噪声值。利用这些假设，我们可以使用**高斯过程**将模型评估组合成一个多元连续高斯分布。接下来，我们可以计算在这个高斯上预期改进最高的点。这些点将产生新的样本，以便用我们的模型进行测试。

幸运的是，我们不必自己实现算法，许多机器学习库都提供了开箱即用的超参数优化算法。在Azure机器学习中，我们可以使用**贝叶斯采样方法**，这有助于我们选择好的参数配置来优化预定义的指标。

参数网格的定义与随机采样技术类似——即通过使用连续或离散的参数空间来定义所有参数值，如下面的代码块所示：

[PRE18]

在我们继续之前，我们需要记住一件事。贝叶斯采样技术试图根据先前测试的参数结果来预测性能良好的参数配置。这意味着参数选择和运行不再独立。我们不能同时并行运行所有实验，因为我们需要某些实验的结果来采样新的参数。因此，我们需要设置一个额外的参数来控制应该同时运行多少个训练运行。

我们可以使用`max_concurrent_runs`参数来实现这一点。为了使贝叶斯优化技术收敛，建议将此值设置为较小的值，例如，在2-10的范围内。让我们将此实验的值设置为4，并将总运行次数设置为100。这意味着我们正在使用25次迭代来应用贝叶斯优化方法，其中我们一次探索四个参数配置：

[PRE19]

让我们用贝叶斯采样来启动实验：

[PRE20]

不幸的是，由于所有参数选择都依赖于前一次迭代的输出，这种技术无法进一步并行化以更快地完成。然而，由于优化步骤，它通常在相对较短的时间内产生良好的结果。

贝叶斯优化或超参数调优的另一个缺点是，优化需要计算每个运行中定义的参数配置的结果，以确定新的参数选择。因此，我们不能与贝叶斯采样一起使用早期终止，因为训练将提前停止，这意味着无法计算准确的指标。

重要提示

对于贝叶斯优化等优化技术，早期终止不起作用，因为它需要计算最终测试分数来计算参数梯度。

一旦你尝试使用机器学习来优化机器学习模型，你可能已经考虑将这一步更进一步：为什么我们应该止步于优化超参数，为什么我们不应该优化模型选择、网络结构或模型堆叠？

这是一个完全合理的想法。没有人能够测试所有不同机器学习模型、不同参数配置和不同嵌套模型的变体。在下一节中，我们将做这件事，不仅优化参数，还将使用自动机器学习优化模型架构和预处理步骤。

# 使用自动化机器学习寻找最佳模型

**自动化机器学习**是一个令人兴奋的新趋势，许多（如果不是所有）云服务提供商都在追随。目标是向用户提供一种服务，该服务可以自动预处理您的数据，选择机器学习模型，并训练和优化模型以适应您的训练数据，从而优化指定的误差指标。这将创建和训练一个完全自动化的端到端机器学习管道，只需您的标记训练数据和目标指标作为输入。以下是自动化机器学习为您优化的步骤列表：

+   数据预处理

+   特征工程

+   模型选择

+   超参数调整

+   模型集成

虽然大多数经验丰富的机器学习工程师或数据科学家可能会对这种自动化方法的有效性非常谨慎，但它仍然有很多好处，将在本节中解释。如果您喜欢超参数调整的想法，那么您会发现自动化机器学习很有价值。

考虑自动化机器学习的一个好方法是，它在完整的端到端机器学习管道上执行超参数搜索，类似于贝叶斯优化，但参数空间要大得多。现在，这些参数是端到端机器学习管道中的单独步骤，应该实现自动化。自动化机器学习的优点在于，它不会像愚蠢地采样所有可能的参数选择那样，而是在实际训练模型之前，预测某些预处理步骤和模型在数据集上的表现。这个过程被称为**元学习**，并将帮助优化过程产生对管道的候选解决方案，而无需花费时间进行评估。

## 自动化机器学习的优势

让我们评估自动化机器学习的优势。如果我们看看我们之前提到的自动化步骤列表，每个步骤都需要经验丰富的数据科学家花费数天时间来探索、评估和微调。即使是选择正确的模型，例如用于基于梯度的树集成分类的LightGBM或XGBoost，也是非平凡的，因为它们需要对这些工具的经验和知识。此外，我们都知道这两个只是所有可能的分类模型选项的一个非常小的子集。如果我们看看超参数调整和模型堆叠，我们可以立即看出构建一个优秀的集成模型所需的工作量是非平凡的。

这不仅是一个知识或专业知识的问题，而且也非常耗时。自动化机器学习的目标是用自动化的最佳实践来替代手动步骤，应用持续改进的规则，并对每个可能的人类选择进行大量优化。它与超参数调整非常相似，但针对的是完整的端到端过程。通过使用优化而不是手动选择，机器将比人类更快、更准确地找到最佳参数。

我们还可以从另一个角度看待自动化机器学习，即作为 **机器学习即服务（MLaaS**） 产品：输入数据，输出模型（或预测端点）。到目前为止，你应该已经意识到，构建端到端机器学习管道的每一步都是一个彻底、复杂且耗时的任务。即使你可以使用贝叶斯优化选择正确的模型和调整参数，构建和运营此基础设施的成本也是显著的。在这种情况下，选择 MLaaS 将为你提供通常成本的一小部分机器学习基础设施。

自动化机器学习的想法之所以非常有趣，还有另一个原因。它将机器学习部分与你的数据拟合问题分开，让你专注于你最擅长的数据。类似于在云中使用托管服务（例如，托管数据库），这让你可以专注于实现业务逻辑而不是操作基础设施，自动化机器学习将允许你使用基于最佳实践和数据优化而不是特定机器学习算法的托管机器学习管道。

这也是为什么自动化机器学习仍然非常适合许多（成熟）公司的原因——它将预测问题简化为最重要的任务：

+   数据获取

+   数据清洗

+   数据标注

+   选择错误度量标准

我们不想评判任何人，但机器学习从业者往往喜欢跳过这些话题，直接进入有趣的环节，即特征工程、模型选择、参数化、堆叠和调整。因此，每个机器学习项目的良好开端是从自动化机器学习基线模型开始，因为它将迫使你只关注数据方面。在取得良好的初始分数后，你总是可以继续进行进一步的特征工程，并在需要时构建模型。

现在我们已经讨论了自动化机器学习趋势的合理性以及你可以在某种程度上从中受益，让我们深入探讨一些示例和代码。我们将查看 Azure 自动化机器学习（Azure 机器学习的一个产品）的不同功能，它应用于标准的端到端机器学习管道。

在我们深入代码之前，让我们先看看 Azure 自动化机器学习可以解决哪些问题。一般来说，在自动化机器学习中，我们可以选择 *分类*、*回归* 和 *时间序列预测*。正如我们从前几章所知，时间序列预测只是回归的一种变体，其中所有预测值都在未来。

因此，选择正确的机器学习任务之后的最重要的任务是选择应该优化的适当错误度量标准。以下列表显示了所有受支持的错误度量标准：

+   `accuracy`、`AUC_weighted`、`average_precision_score_weighted`、`norm_macro_recall` 和 `precision_score_weighted`

+   `spearman_correlation`, `normalized_root_mean_squared_error`, `r2_score`, 和 `normalized_mean_absolute_error`

您应该熟悉这些大多数指标，因为它们是最受欢迎的错误度量分类和回归的变体。

在支持的模型中，包括LogisticRegression, SGD, MultinomialNaiveBayes, SVM, KNN, Random Forest, ExtremeRandomTrees, LigthtGBM, GradientBoosting, DNN, Lasso, Arima, Prophet等。在云中托管服务的优点在于，这个列表很可能会在未来增长，并添加最新的最先进模型。然而，这个列表应该被视为仅为您提供的附加信息，因为自动机器学习的理念是模型会自动为您选择。然而，根据用户的偏好，可以为自动机器学习允许或拒绝列表中的单个模型。

考虑到所有这些，让我们看看一个使用自动机器学习的分类示例。

## 自动机器学习的一个分类示例

当您使用新技术时，总是好的退一步思考这项技术可能具备的能力。让我们使用相同的方法来了解自动预处理如何帮助我们在一个典型的机器学习项目中，以及其局限性在哪里。

自动机器学习非常适合将最佳实践转换应用于您的数据集：应用日期/时间转换，以及在应用线性回归时对数据进行归一化和标准化，处理缺失数据或删除低方差特征等。微软提供了一系列功能，预计未来会增长。

让我们回顾一下在[*第7章*](B17928_07_ePub.xhtml#_idTextAnchor112)中学习的内容，*使用NLP的高级特征提取*。虽然自动机器学习可以检测自由文本并将其转换为数值特征向量，但它无法理解您业务领域中的数据语义。因此，它能够转换您的文本数据，但如果您需要语义编码文本或分类数据，您必须自行实现。

另一点需要记住的是，自动机器学习不会尝试推断训练数据中不同特征维度之间的任何相关性。因此，如果您想将两个分类列合并为一个组合特征列（例如，使用one-hot-encoding，mean embedding等），那么您将必须自行实现这一点。

在自动机器学习中，有两个不同的预处理集 – 指定了`preprocess`参数。如果您之前使用过scikit-learn，那么以下大多数预处理技术应该相当熟悉：

+   `StandardScaler`: 归一化 – 减去平均值并将特征缩放到单位方差。

+   `MinMaxScaler`: 归一化 – 通过最小值和最大值缩放特征。

+   `MaxAbsScaler`：归一化 – 通过最大绝对值缩放特征。

+   `RobustScaler`：归一化 – 将特征缩放到分位数范围内。

+   `PCA`：基于PCA的线性降维。

+   `TruncatedSVD`：基于线性降维的截断**奇异值分解**（**SVD**）。与PCA不同，此估计量在事先不对数据进行中心化。

+   `SparseNormalizer`：归一化 – 独立归一化每个样本。

复杂的预处理被称为**特征化**。这些预处理步骤更为复杂，并在自动机器学习优化过程中执行各种任务。作为Azure自动机器学习的用户，您可以期待这个列表不断增长，并包括随着可用性而出现的新最先进转换。以下列表显示了各种特征化步骤：

+   **删除高基数或无方差特征**：删除高基数特征（例如，散列、ID或GUID）或无方差特征（例如，所有值缺失或所有行具有相同值）。

+   **填充缺失值**：对数值特征（均值填充）和分类特征（众数填充）进行缺失值填充。

+   **生成额外特征**：生成基于日期/时间的额外特征（例如，年、月、日、星期几、年中的日、季度、年中的周、小时、分钟和秒）和文本特征（基于n-gram的词频）。

+   **转换和编码**：使用单热编码（低基数）和单热哈希编码（高基数）对分类特征进行编码。将具有少量唯一值的数值特征转换为分类特征。

+   **词嵌入**：使用预训练的嵌入模型将文本转换为使用平均嵌入的聚合特征向量。

+   **目标编码**：对分类特征执行目标编码。

+   **文本目标编码**：使用词袋模型对文本特征执行目标编码。

+   **证据权重**：通过证据权重计算分类列与目标列的相关性，并为每个列和每个类别输出一个新特征。

+   **聚类距离**：在所有数值列上训练k-means聚类模型，并在输出每个列和每个簇的新特征之前计算每个特征到其质心的距离。

让我们从使用预处理的一个简单的自动机器学习分类任务开始。

我们将首先定义一个包含自动机器学习配置的字典。为了启用标准预处理，如缩放、归一化和PCA/SVD，我们需要将`preprocess`属性设置为`true`。对于高级预处理和特征工程，我们需要将`featurization`属性设置为`auto`。以下代码块显示了所有这些设置：

[PRE21]

使用此配置，我们现在可以使用`pandas`加载数据集。如下面的代码片段所示，我们正在加载`titanic`数据集，并将目标列指定为字符串。这个列在稍后配置自动机器学习时是必需的：

[PRE22]

重要提示

当你使用自动机器学习并且处于本地执行上下文时，你可以使用pandas DataFrame作为输入源。然而，当你在一个远程集群上执行训练过程时，你需要将数据包装在Azure机器学习数据集中。

每当我们使用黑盒分类器时，我们也应该保留一个测试集来验证模型的测试性能，以验证泛化能力。因此，我们必须将数据分成训练集和测试集：

[PRE23]

最后，我们可以将所有必需的参数提供给自动机器学习配置构造函数。在这个例子中，我们使用本地执行目标来训练自动机器学习实验。然而，我们也可以提供一个Azure机器学习数据集并将实验提交到我们的训练集群：

[PRE24]

让我们将自动机器学习配置作为实验提交到定义的计算目标，并等待完成。我们可以输出运行详情：

[PRE25]

与`HyperDriveConfig`类似，我们可以看到自动机器学习的`RunDetails`显示了关于你当前实验的大量有用信息。你不仅可以查看所有已安排和正在运行的模式，还可以获得训练模型及其训练性能的精美可视化。以下截图显示了自动机器学习实验的前14次运行的准确度：

![图11.5 – 自动机器学习 – 结果的可视化](img/B17928_11_05.jpg)

图11.5 – 自动机器学习 – 结果的可视化

最后，经过15分钟后，我们可以从自动机器学习运行中检索最佳ML管道。从现在起，我们将简单地称这个管道为**模型**，因为所有预处理步骤都打包在这个模型中，它本身就是一个操作管道。我们可以使用以下代码来检索管道：

[PRE26]

得到的拟合管道（称为`best_model`）现在可以像scikit-learn估计器一样使用。我们可以将其存储在磁盘上，将其注册到模型存储中，部署到*容器实例*，或者简单地评估测试集上的结果。我们将在[*第14章*](B17928_14_ePub.xhtml#_idTextAnchor217)中更详细地了解，*模型部署、端点和操作*。最后，我们想要评估最佳模型。为此，我们将使用之前从数据集中分离出的测试集，并在拟合模型上预测输出：

[PRE27]

在前面的代码中，我们使用了scikit-learn中的`accuracy_score`函数来计算最终模型的准确度。这些步骤就是你在使用自动预处理数据和拟合模型对数据集进行分类时需要执行的所有步骤。

# 摘要

在本章中，我们介绍了通过**HyperDrive**进行超参数优化和通过**自动机器学习**进行模型优化。这两种技术都可以帮助你高效地检索到适合你的机器学习任务的最佳模型。

**网格采样**与经典机器学习模型配合得很好，当可调整参数的数量固定时也是如此。离散参数网格上的所有值都会被评估。在**随机采样**中，我们可以为参数空间应用连续分布，并选择尽可能多的参数选择，以适应配置的训练时长。随机采样在大量参数上表现更好。这两种采样技术都可以/应该使用**早期停止标准**进行调整。

与随机和网格采样不同，**贝叶斯优化**通过探测模型性能来优化以下参数选择。这意味着每一组参数选择和由此产生的模型性能都会用来计算下一组最佳参数选择。因此，贝叶斯优化使用机器学习来优化你的机器学习模型的参数选择。由于底层高斯过程需要模型性能的结果，早期停止在贝叶斯优化中不起作用。

我们还了解到，自动机器学习是对完整端到端机器学习管道中贝叶斯优化的泛化。我们不仅选择超参数，还选择预处理、特征工程、模型选择和模型堆叠方法，并将它们一起优化。自动机器学习通过预测哪些模型会在你的数据上表现良好，而不是盲目地尝试所有可能的组合，从而加快了这个过程。这两种技术对于优秀的机器学习项目都是必不可少的；自动机器学习让你首先关注数据和标注，而超参数调整则让你优化特定模型。

在下一章中，我们将探讨训练深度神经网络（DNNs）的情况，其中数据或模型参数不再适合单个机器的内存，因此需要分布式学习。
