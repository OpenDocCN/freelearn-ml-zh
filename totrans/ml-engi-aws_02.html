<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer078">
<h1 class="chapter-number" id="_idParaDest-40"><a id="_idTextAnchor041"/><a id="_idTextAnchor042"/>2</h1>
<h1 id="_idParaDest-41"><a id="_idTextAnchor043"/>Deep Learning AMIs</h1>
<p>In the <em class="italic">Essential prerequisites</em> section of <a href="B18638_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to ML Engineering on AWS</em>, it probably took us about an hour or so to set up our Cloud9 environment. We had to spend a bit of time installing several packages, along with a few dependencies, before we were able to work on the actual <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) requirements. On top of this, we had to make <a id="_idIndexMarker109"/>sure that we were using the right versions for certain packages to avoid running into a variety of issues. If you think this is error-prone and tedious, imagine being given the assignment of preparing 20 ML environments for a team of data scientists! Let me repeat that… <em class="italic">TWENTY</em>! It would have taken us around 15 to 20 hours of doing the same thing over and over again. After a week of using the ML environments you prepared, the data scientists then requested that you also install the deep learning frameworks <strong class="bold">TensorFlow</strong>, <strong class="bold">PyTorch</strong>, and <strong class="bold">MXNet</strong> inside these environments since they’ll be testing different deep learning models using these ML frameworks. At this point, you may already be asking yourself, “<em class="italic">Is there a better way to do this?</em>“. The good news is that there are a variety of ways to handle these types of requirements in a more efficient manner. One of the possible solutions is to utilize <strong class="bold">Amazon Machine Images</strong> (<strong class="bold">AMIs</strong>), specifically the AWS <strong class="bold">Deep Learning AMIs</strong> (<strong class="bold">DLAMIs</strong>) to <a id="_idIndexMarker110"/>significantly speed up the process of preparing ML environments. When launching new instances, these AMIs would serve as pre-configured templates containing the relevant software and environment configuration.</p>
<p>Before the <strong class="bold">DLAMIs</strong> existed, ML engineers had to spend hours installing and configuring <a id="_idIndexMarker111"/>deep learning frameworks inside EC2 instances before they could run ML workloads in the AWS cloud. The process of manually preparing these ML environments from scratch is tedious and error-prone as well. Once the DLAMIs were made available, data scientists and ML engineers were able to run their ML experiments straight away using their preferred deep learning framework. </p>
<p>In this chapter, we will see how convenient it is to set up a GPU instance using a framework-specific Deep Learning AMI. We will then train a deep learning model using <strong class="bold">TensorFlow</strong> and <strong class="bold">Keras</strong> inside this environment. Once the training step is complete, we will evaluate the model using a test dataset. After that, we will perform the cleanup steps and terminate the EC2 instance. Toward the end of this chapter, we will also have a short discussion on how AWS pricing works for EC2 instances. This will help equip you with the knowledge required to manage the overall cost of running ML workloads inside these instances.</p>
<p>That said, we will cover the following topics in this chapter:</p>
<ul>
<li>Getting started with Deep Learning AMIs</li>
<li>Launching an EC2 instance using a Deep Learning AMI</li>
<li>Downloading the sample dataset</li>
<li>Training an ML model</li>
<li>Loading and evaluating the model</li>
<li>Cleaning up</li>
<li>Understanding how AWS pricing works for EC2 instances</li>
</ul>
<p>The hands-on solutions in this chapter will help you migrate any of your existing <strong class="bold">TensorFlow</strong>, <strong class="bold">PyTorch</strong>, and <strong class="bold">MXNet</strong> scripts and models to the AWS cloud. In addition to the cost discussions mentioned earlier, we will also talk about a few security guidelines and best practices to help us ensure that the environments we set up have a good starting security configuration. With these in mind, let’s get started!</p>
<h1 id="_idParaDest-42"><a id="_idTextAnchor044"/>Technical requirements</h1>
<p>Before we start, we must have a web browser (preferably Chrome or Firefox) and an AWS account to use for the hands-on solutions in this chapter. Make sure that you have access to the AWS account you used in <a href="B18638_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to ML Engineering on AWS</em>.</p>
<p>The Jupyter notebooks, source code, and other files used for each chapter are available in this book’s GitHub repository: <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS">https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS</a>.</p>
<h1 id="_idParaDest-43"><a id="_idTextAnchor045"/>Getting started with Deep Learning AMIs</h1>
<p>Before we talk about DLAMIs, we must have a good idea of what AMIs are. We can think of an AMI <a id="_idIndexMarker112"/>as the “DNA” of an organism. Using this analogy, the organism would correspond and map to one or more EC2 instances:</p>
<div>
<div class="IMG---Figure" id="_idContainer037">
<img alt="Figure 2.1 – Launching EC2 instances using Deep Learning AMIs " height="453" src="image/B18638_02_001.jpg" width="1104"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.1 – Launching EC2 instances using Deep Learning AMIs</p>
<p>If we were to launch two EC2 instances using the same AMI (similar to what is shown in <em class="italic">Figure 2.1</em>), both instances would have the same set of installed packages, frameworks, tools, and operating systems upon instance launch. Of course, not everything needs to be the same as these instances may have different instance types, different security groups, and other configurable properties.</p>
<p>AMIs allow engineers to easily launch EC2 instances in consistent environments without having to spend hours installing different packages and tools. In addition to the installation steps, these EC2 instances need to be configured and optimized before they can be used for specific workloads. Pre-built AMIs such as DLAMIs have popular deep learning frameworks such as <strong class="bold">TensorFlow</strong>, <strong class="bold">PyTorch</strong>, and <strong class="bold">MXNet</strong> pre-installed already. This means that data scientists, developers, and ML engineers may proceed with performing ML experiments and deployments without having to worry about the installation and setup process. </p>
<p>If we had to prepare 20 ML environments with these deep learning frameworks installed, I’m pretty sure that it would not take us 20 or more hours to do so. If we were to use DLAMIs, probably <a id="_idIndexMarker113"/>2 to 3 hours would be more than enough to get the job done. <em class="italic">You don’t believe me?</em> <em class="italic">In the next section, we will do just that!</em> Of course, we will only be preparing a single ML environment instead of 20. While working on the hands-on solutions in this chapter, you will notice a significant speed boost when setting up and configuring the prerequisites needed to run the ML experiments. </p>
<p class="callout-heading">Note</p>
<p class="callout">It is important to note that we have the option to build on top of existing AMIs and prepare our own custom AMIs. Then, we can use these custom AMIs when launching new EC2 instances.</p>
<h1 id="_idParaDest-44"><a id="_idTextAnchor046"/>Launching an EC2 instance using a Deep Learning AMI</h1>
<p>Launching an EC2 instance from a DLAMI is straightforward. Once we have an idea of which DLAMI to <a id="_idIndexMarker114"/>use, the rest of <a id="_idIndexMarker115"/>the steps would just be focused on configuring and launching the EC2 instance. The cool thing here is that we are not limited to launching a single instance from an existing image. During the configuration stage, before an instance is launched from an AMI, it is important to note that we can specify the desired value for the number of instances to be launched (for example, <strong class="source-inline">20</strong>). This would mean that instead of launching a single instance, we would launch 20 instances all at the same time instead.</p>
<div>
<div class="IMG---Figure" id="_idContainer038">
<img alt="Figure 2.2 – Steps to launch an EC2 instance using a DLAMI " height="195" src="image/B18638_02_002.jpg" width="1048"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.2 – Steps to launch an EC2 instance using a DLAMI</p>
<p>We will divide this section into four parts. As shown in the preceding diagram, we’ll start by locating the framework-specific Deep Learning AMI in the <strong class="bold">AMI Catalog</strong> – a repository that contains a variety of AMIs that can be used when launching EC2 instances. We <a id="_idIndexMarker116"/>will then launch and <a id="_idIndexMarker117"/>configure an EC2 instance using the selected DLAMI and choose a GPU instance type, <strong class="source-inline">p3.2xlarge</strong>, as the instance type. We’ll then configure the security settings, including the network security settings, to be used by the instance. Finally, we will launch the instance and connect to it from the browser using <strong class="bold">EC2 Instance Connect</strong>.</p>
<h2 id="_idParaDest-45"><a id="_idTextAnchor047"/>Locating the framework-specific DLAMI</h2>
<p>When looking <a id="_idIndexMarker118"/>for an AMI, the first place we should check is the <strong class="bold">AWS AMI Catalog</strong>. In the AMI Catalog, we should find a variety of DLAMIs. These DLAMIs <a id="_idIndexMarker119"/>can be categorized into either multi-framework DLAMIs or framework-specific DLAMIs. <em class="italic">What’s the difference?</em> Multi-framework DLAMIs include multiple frameworks in a single AMI such as <strong class="bold">TensorFlow</strong>, <strong class="bold">PyTorch</strong>, or <strong class="bold">MXNet</strong>. This allows for easy experimentation and exploration of several frameworks for developers, ML engineers, and data scientists. On the other hand, framework-specific DLAMIs are more optimized for production environments and support only a single framework. In this chapter, we will be working with the framework-specific (TensorFlow) Deep Learning AMI.</p>
<p>In the next set of steps, we will navigate to the AMI Catalog and use the framework-specific (TensorFlow) Deep Learning AMI to launch an instance:</p>
<ol>
<li>Navigate to the AWS Management Console and then type <strong class="source-inline">ec2</strong> in the search bar. Select <strong class="bold">EC2</strong> from the list of results:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer039">
<img alt="Figure 2.3 – Navigating to the EC2 console " height="475" src="image/B18638_02_003.jpg" width="1098"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.3 – Navigating to the EC2 console</p>
<p class="list-inset">We should see a list of matching results such as <strong class="bold">EC2</strong>, <strong class="bold">EC2 Image Builder</strong>, and <strong class="bold">AWS Compute Optimizer</strong>, similar to what is shown in <em class="italic">Figure 2.2</em>. From this list, we’ll <a id="_idIndexMarker120"/>choose the first one, which should redirect us to the EC2 console.</p>
<ol>
<li value="2">In the sidebar, locate and click <strong class="bold">AMI Catalog</strong> under <strong class="bold">Images</strong> to navigate to the <strong class="bold">EC2</strong> &gt; <strong class="bold">AMI Catalog</strong> page.</li>
<li>Next, type <strong class="source-inline">deep learning ami</strong> in the search bar within the <strong class="bold">AMI Catalog</strong> page. Make sure that you press <strong class="bold">Enter</strong> to search for relevant AMIs related to the search query:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer040">
<img alt="Figure 2.4 – Searching for the framework-specific Deep Learning AMI " height="554" src="image/B18638_02_004.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.4 – Searching for the framework-specific Deep Learning AMI</p>
<p class="list-inset">As shown in the preceding screenshot, we should have a couple of matching results under <strong class="bold">Quickstart AMIs</strong>. There should be matching results under <strong class="bold">AWS Marketplace AMIs</strong> and <strong class="bold">Community AMIs</strong> as well. Quickstart AMIs include the commonly used AMIs for key workloads such as the <strong class="bold">Amazon Linux 2</strong> AMI, the <strong class="bold">Ubuntu Server 20.04 LTS</strong> AMI, the <strong class="bold">Deep Learning AMI</strong> (Amazon Linux 2) AMI, and more. AWS Marketplace AMIs include several AMIs created by AWS, along <a id="_idIndexMarker121"/>with AMIs created by trusted third-party sources. These should include AMIs such as the <strong class="bold">OpenVPN Access Server</strong> AMI, the <strong class="bold">Kali Linux</strong> AMI, and the <strong class="bold">Splunk Enterprise</strong> AMI. All publicly available AMIs can be found under <strong class="bold">Community AMIs</strong>.</p>
<ol>
<li value="4">Scroll down the list of <strong class="bold">Quickstart AMIs</strong> and locate the framework-specific Deep Learning AMI, as shown in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer041">
<img alt="Figure 2.5 – Locating the TensorFlow DLAMI " height="454" src="image/B18638_02_005.jpg" width="1528"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.5 – Locating the TensorFlow DLAMI</p>
<p class="list-inset">Here, we are choosing the framework-specific (TensorFlow) Deep Learning AMI for <strong class="bold">Amazon Linux 2</strong> since we’ll be training an ML model using TensorFlow later in this chapter. Verify the selection by reading the name and description of the AMI. Then, click the <strong class="bold">Select</strong> button. </p>
<ol>
<li value="5">After you have clicked the <strong class="bold">Select</strong> button in the previous step, scroll up to the top of the page and click the <strong class="bold">Launch Instance with AMI</strong> button, as shown in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer042">
<img alt="Figure 2.6 – Launch Instance with AMI " height="309" src="image/B18638_02_006.jpg" width="973"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.6 – Launch Instance with AMI</p>
<p class="list-inset">As we <a id="_idIndexMarker122"/>can see, the <strong class="bold">Launch Instance with AMI</strong> button is just beside the <strong class="bold">Create Template with AMI</strong> button. </p>
<p class="callout-heading">Important Note</p>
<p class="callout">There are no additional costs associated with the usage of <strong class="bold">AWS Deep Learning AMIs</strong>. This <a id="_idIndexMarker123"/>means that we only need to consider the costs associated with the infrastructure resources created. However, the usage of other AMIs may not be free. For example, AMIs created by other companies (from the list available under <strong class="bold">AWS Marketplace AMIs</strong>) may have an additional charge per hour of use. That said, it is important to check for any additional charges on top of the infrastructure resources launched using these AMIs.</p>
<p class="list-inset">Clicking the <strong class="bold">Launch Instance with AMI</strong> button should redirect you to the <strong class="bold">Launch an instance</strong> page, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer043">
<img alt="Figure 2.7 – The Launch an instance page " height="1013" src="image/B18638_02_007.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.7 – The Launch an instance page</p>
<p class="list-inset">Since AWS regularly updates the experience of launching and managing resources in the console, you might see a few differences while you are performing the next set of steps. However, the desired final configuration will be the <a id="_idIndexMarker124"/>same, regardless of what the console looks like while you are working on this section.</p>
<ol>
<li value="6">Under <strong class="bold">Name and tags</strong>, specify <strong class="source-inline">MLE-CH02-DLAMI</strong> in the <strong class="bold">Name</strong> field.</li>
</ol>
<p>After setting the <strong class="bold">Name</strong> field’s value, the next step involves choosing the desired instance type for our EC2 instance. Before we proceed with selecting the desired instance type, we must have a quick discussion about what instances are available and which types of instances are suitable for large-scale ML workloads. </p>
<h2 id="_idParaDest-46"><a id="_idTextAnchor048"/>Choosing the instance type</h2>
<p>When performing <a id="_idIndexMarker125"/>deep learning experiments, data scientists and ML <a id="_idIndexMarker126"/>engineers generally prefer GPU instances over CPU instances. <strong class="bold">Graphics Processing Units</strong> (<strong class="bold">GPUs</strong>) help significantly speed up deep learning experiments since GPUs can be used to process multiple parallel computations at the same time. Since GPU instances are usually more expensive than CPU instances, data scientists and ML engineers use a combination of both types <a id="_idIndexMarker127"/>when dealing with ML requirements. For <a id="_idIndexMarker128"/>example, ML practitioners may limit the usage of GPU instances just for training deep learning models only. This means that CPU instances would be used instead for inference endpoints where the trained models are deployed. This would be sufficient in most cases, and this would be considered a very practical move once costs are taken into consideration.</p>
<div>
<div class="IMG---Figure" id="_idContainer044">
<img alt="Figure 2.8 – CPU instances versus GPU instances " height="541" src="image/B18638_02_008.jpg" width="1019"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.8 – CPU instances versus GPU instances</p>
<p>That said, we need to identify which instances fall under the group of GPU instances and which instances fall under the CPU instances umbrella. The preceding diagram shows some examples of GPU instances, including <strong class="source-inline">p3.2xlarge</strong>, <strong class="source-inline">dl1.24xlarge</strong>, <strong class="source-inline">g3.4xlarge</strong>, <strong class="source-inline">p2.8xlarge</strong>, and <strong class="source-inline">g4ad.8xlarge</strong>. There are other examples of GPU instance types not in this list, but you should be able to identify these just by checking the instance family. For example, we are sure that <strong class="source-inline">p3.8xlarge</strong> is a GPU instance type since it belongs to the same family as the <strong class="source-inline">p3.2xlarge</strong> instance type. </p>
<p>Now that we <a id="_idIndexMarker129"/>have a better idea of what CPU and GPU instances are, let’s proceed with locating and choosing <strong class="source-inline">p3.2xlarge</strong> from the list of options for our instance type:</p>
<ol>
<li value="1">Continuing where we left off in the <em class="italic">Locating the framework-specific DLAMI</em> section, let’s locate and click the <strong class="bold">Compare instance types</strong> link under the <strong class="bold">Instance type</strong> pane. This should redirect you to the <strong class="bold">Compare instance types</strong> page, as shown in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer045">
<img alt="Figure 2.9 – Compare instance types " height="698" src="image/B18638_02_009.jpg" width="1102"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.9 – Compare instance types</p>
<p class="list-inset">Here, we <a id="_idIndexMarker130"/>can see the different instance types, along with their corresponding specs and cost per hour. </p>
<ol>
<li value="2">Click the search field (with the <strong class="bold">Filter instance types</strong> placeholder text). This should open a drop-down list of options, as shown in the following screenshot: </li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer046">
<img alt="Figure 2.10 – Using the Filter instance types search field " height="434" src="image/B18638_02_010.jpg" width="859"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.10 – Using the Filter instance types search field</p>
<p class="list-inset">Locate and select <strong class="bold">GPUs</strong> from the list of options. This should open the <strong class="bold">Add filter for GPUs</strong> window.</p>
<ol>
<li value="3">In the <strong class="bold">Add filter for GPUs</strong> window, open the dropdown menu and select <strong class="bold">&gt;</strong> from the <a id="_idIndexMarker131"/>list of options available. Next, specify a value of <strong class="source-inline">0</strong> in the text field beside it. Click the <strong class="bold">Confirm</strong> button afterward.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">The filter we applied should limit the set of results to GPU instances. We should find several accelerated computing instance families such as <em class="italic">P3</em>, <em class="italic">P2</em>, <em class="italic">G5</em>, <em class="italic">G4dn</em>, and <em class="italic">G3</em>, to name a few. </p>
<ol>
<li value="4">Next, let’s click the <strong class="bold">Preferences</strong> button, as highlighted in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer047">
<img alt="Figure 2.11 – Opening the Preferences window " height="707" src="image/B18638_02_011.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.11 – Opening the Preferences window</p>
<p class="list-inset">This should <a id="_idIndexMarker132"/>open the <strong class="bold">Preferences</strong> window. Under <strong class="bold">Attribute columns</strong>, ensure that the <strong class="bold">GPUs</strong> radio button is toggled on, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer048">
<img alt="Figure 2.12 – Displaying the GPUs attribute column " height="561" src="image/B18638_02_012.jpg" width="1022"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.12 – Displaying the GPUs attribute column</p>
<p class="list-inset">Click the <strong class="bold">Confirm</strong> button afterward. This should update the table list display and show us the number of GPUs of each of the instance types in the list, as shown here:</p>
<div>
<div class="IMG---Figure" id="_idContainer049">
<img alt="Figure 2.13 – GPUs of each instance type " height="546" src="image/B18638_02_013.jpg" width="1083"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.13 – GPUs of each instance type</p>
<p class="list-inset">Here, we should see a pattern that the number of GPUs generally increases as the instance type becomes “larger” within the same instance family.</p>
<ol>
<li value="5">Locate and select the row corresponding to the <strong class="bold">p3.2xlarge</strong> instance type. Take note of the <a id="_idIndexMarker133"/>number of GPUs available, along with the cost per hour (on-demand Linux pricing) for the <strong class="bold">p3.2xlarge</strong> instance type.</li>
<li>Click the <strong class="bold">Select instance type</strong> button (located at the lower right portion of the screen) afterward.</li>
</ol>
<p>This should close the <strong class="bold">Compare instance types</strong> window and return you to the <strong class="bold">Launch an instance</strong> page.</p>
<h2 id="_idParaDest-47"><a id="_idTextAnchor049"/>Ensuring a default secure configuration</h2>
<p>When launching an EC2 <a id="_idIndexMarker134"/>instance, we need to manage the security configuration, which will affect how the instance will be accessed. This involves configuring the following:</p>
<ul>
<li><strong class="bold">Key pair</strong>: Files containing <a id="_idIndexMarker135"/>credentials used to securely access the instance (for example, using SSH)</li>
<li><strong class="bold">Virtual Private Cloud</strong> (<strong class="bold">VPC</strong>): A logically isolated virtual network that dictates how <a id="_idIndexMarker136"/>resources are accessed and how resources communicate with each other</li>
<li><strong class="bold">Security group</strong>: A virtual <a id="_idIndexMarker137"/>firewall that controls traffic going in and out of the EC2 instance using rules that filter the traffic based on the configured protocol and ports</li>
</ul>
<p>That said, let’s proceed with completing the remaining configuration parameters before we <a id="_idIndexMarker138"/>launch the EC2 instance:</p>
<ol>
<li value="1">Continuing where we left off in the <em class="italic">Choosing the instance type</em> section, let’s proceed with creating a new key pair. Under <strong class="bold">Key pair (login)</strong>, locate and click <strong class="bold">Create new key pair</strong>.</li>
<li>In the <strong class="bold">Create key pair</strong> window, specify a unique key pair name (for example, <strong class="source-inline">dlami-key</strong>) for <strong class="bold">Key pair name</strong>. Ensure that the following configuration holds as well:<ul><li><strong class="bold">Key pair type</strong>: <strong class="source-inline">RSA</strong></li>
<li><strong class="bold">Private key file format</strong>: <strong class="source-inline">.pem</strong></li>
</ul></li>
<li>Click the <strong class="bold">Create key pair</strong> button afterward. This should automatically download the <strong class="source-inline">.pem</strong> file to your local machine. Note that we won’t need this <strong class="source-inline">.pem</strong> file for the hands-on solutions in this chapter since we’ll be accessing the instance later using <strong class="bold">EC2 Instance Connect</strong> (through the browser).</li>
</ol>
<p class="callout-heading">Important Note</p>
<p class="callout">Never share the downloaded key file since this is used to access the instance via SSH. For production environments, consider hiding non-public instances inside a properly configured VPC as well. There’s a lot to discuss when it comes to securing our ML environments. We will talk about security in detail in <a href="B18638_09.xhtml#_idTextAnchor187"><em class="italic">Chapter 9</em></a>, <em class="italic">Security, Governance, and Compliance Strategies</em>.</p>
<ol>
<li value="4">Under <strong class="bold">Network settings</strong>, locate and click the <strong class="bold">Edit</strong> button (located at the top right of the pane). Make <a id="_idIndexMarker139"/>sure that the following configuration settings are applied:<ul><li><strong class="bold">VPC - required</strong>: <em class="italic">[Select default VPC]</em> <strong class="source-inline">vpc-xxxxxxxx (default)</strong></li>
<li><strong class="bold">Auto-assign public IP</strong>: <strong class="source-inline">Enable</strong></li>
<li><strong class="bold">Firewall (security groups)</strong>: <strong class="source-inline">Create security group</strong></li>
</ul></li>
<li>Under <strong class="bold">Inbound security group rules</strong> of <strong class="bold">Network settings</strong>, specify a set of security group rules, similar to what is configured in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer050">
<img alt="Figure 2.14 – Inbound security groups rules " height="802" src="image/B18638_02_014.jpg" width="908"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.14 – Inbound security groups rules</p>
<p class="list-inset">As you can see, we will be configuring the new security group with the following rules:</p>
<ul>
<li><strong class="bold">Type</strong>: <strong class="source-inline">SSH</strong>; <strong class="bold">Protocol</strong>: <strong class="source-inline">TCP</strong>; <strong class="bold">Port Range</strong>: <strong class="source-inline">22</strong>; <strong class="bold">Source type</strong>: <strong class="source-inline">Anywhere</strong> | <strong class="bold">Source</strong>: <strong class="source-inline">0.0.0.0/0</strong>; <strong class="bold">Description</strong>: <strong class="source-inline">SSH</strong> – allows any “computer” such as your local machine to connect to the EC2 instance via the <strong class="bold">Secure Shell</strong> (SSH) protocol over port 22</li>
<li><strong class="bold">Type</strong>: <strong class="source-inline">Custom TCP</strong>; <strong class="bold">Protocol</strong>: <strong class="source-inline">TCP</strong>; <strong class="bold">Port Range</strong>: <strong class="source-inline">6006</strong>; <strong class="bold">Source type</strong>: <strong class="source-inline">Anywhere</strong> | <strong class="bold">Source</strong>: <strong class="source-inline">0.0.0.0/0</strong>; <strong class="bold">Description</strong>: <strong class="source-inline">Tensorboard</strong> – allows <a id="_idIndexMarker140"/>any “computer” such as your local machine to access port 6006 of the EC2 instance (which may be running an application such as <strong class="bold">TensorBoard</strong>)</li>
<li><strong class="bold">Type</strong>: <strong class="source-inline">Custom TCP</strong>; <strong class="bold">Protocol</strong>: <strong class="source-inline">TCP</strong>; <strong class="bold">Port Range</strong>: <strong class="source-inline">8888</strong>; <strong class="bold">Source type</strong>: <strong class="source-inline">Anywhere</strong> | <strong class="bold">Source</strong>: <strong class="source-inline">0.0.0.0/0</strong>; <strong class="bold">Description</strong>: <strong class="source-inline">Jupyter</strong> – allows any “computer” such as your local machine to access port 8888 of the EC2 instance (which may be running an application such as the <strong class="bold">Jupyter Notebook</strong> app)</li>
</ul>
<p class="list-inset">You may proceed with the next step once you have configured the new security group with <strong class="bold">Security group name – required</strong> and <strong class="bold">Description – required</strong> and the relevant set of <strong class="bold">Inbound security group rules</strong>. </p>
<p class="callout-heading">Note</p>
<p class="callout">Note that this configuration needs to be reviewed and secured further once we need to prepare our setup for production use. For one, <strong class="bold">Source type</strong> for any of these security group rules should not have been set to <strong class="bold">Anywhere</strong> (<strong class="source-inline">0.0.0.0/0</strong>) since this configuration allows any computer or server to access our instance through the open ports. That said, we could have limited access to only the IP address of our local machine. In the meantime, the configuration we have should do the trick since we will delete the instance immediately once we have completed this chapter.</p>
<ol>
<li value="6">Locate and click the <strong class="bold">Add new volume</strong> button under <strong class="bold">Configure storage</strong>: </li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer051">
<img alt="Figure 2.15 – Configuring the storage settings " height="591" src="image/B18638_02_015.jpg" width="1431"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.15 – Configuring the storage settings</p>
<p class="list-inset">Specify <strong class="source-inline">35</strong> in the text field between <strong class="bold">1x</strong> and <strong class="bold">GiB</strong>. similar to what we have in the preceding <a id="_idIndexMarker141"/>screenshot.</p>
<p>There are a few more options we can configure and tweak (under <strong class="bold">Advanced Details</strong>) but we’ll leave the default values as-is. </p>
<h2 id="_idParaDest-48"><a id="_idTextAnchor050"/>Launching the instance and connecting to it using EC2 Instance Connect</h2>
<p>There are different ways to connect to an EC2 instance. Earlier, we configured the instance so <a id="_idIndexMarker142"/>that it can be accessed via SSH using a key file (for example, from the Terminal of your local machine). Another possible option is to use <strong class="bold">EC2 Instance Connect</strong> to access the instance through the browser. We can also access the instance via SSH using <strong class="bold">Session Manager</strong>. In this section, we’ll use EC2 Instance Connect to access our instance.</p>
<p>Continuing <a id="_idIndexMarker143"/>where we left off in the <em class="italic">Ensuring a default secure configuration</em> section, let’s proceed with launching the EC2 instance and access it from the browser: </p>
<ol>
<li value="1">Once you have configured the storage settings, locate and click the <strong class="bold">Launch instance</strong> button under the <strong class="bold">Summary</strong> pane (located at the right portion of the screen). Make sure that you terminate this instance within the hour it has been launched as the per-hour rate of these types of instances is a bit higher relative to other instance types. You may check the <em class="italic">Cleaning up</em> section of this chapter for more details.</li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">Make sure that the value specified in the <strong class="bold">Number of instances</strong> field is set to <strong class="source-inline">1</strong>. Technically, we can launch 20 instances all in one go by setting this value to <strong class="source-inline">20</strong>. However, we don’t want to do this as this would be very expensive and wasteful. For now, let’s stick to <strong class="source-inline">1</strong> as this should be more than enough to handle the deep learning experiments in this chapter.</p>
<ol>
<li value="2">You should <a id="_idIndexMarker144"/>see a success notification, along with the instance ID of the resource being launched, similar to what is shown in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer052">
<img alt="Figure 2.16 – Launch success notification " height="546" src="image/B18638_02_016.jpg" width="1174"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.16 – Launch success notification</p>
<p class="list-inset">Click the link containing the instance ID (<strong class="source-inline">i-xxxxxxxxxxxxxxxxx</strong>), as highlighted in the preceding screenshot, to navigate to the <strong class="bold">Instances</strong> page. You may click the <strong class="bold">refresh</strong> button (beside the <strong class="bold">Connect</strong> button) a few times while waiting for the EC2 instance (<strong class="source-inline">MLE-CH02-DLAMI</strong>) to appear in the list of instances.</p>
<p class="callout-heading">Note</p>
<p class="callout">Wait for a minute or two before proceeding with the next step. In case you experience an <strong class="source-inline">InsufficientInstanceCapacity</strong> error while launching the instance, feel free to use a different <strong class="source-inline">p3</strong> instance. To troubleshoot this further, you may also refer to <a href="https://aws.amazon.com/premiumsupport/knowledge-center/ec2-insufficient-capacity-errors/">https://aws.amazon.com/premiumsupport/knowledge-center/ec2-insufficient-capacity-errors/</a> for more information.</p>
<ol>
<li value="3">Select the <a id="_idIndexMarker145"/>instance by toggling the checkbox highlighted in the following screenshot. Click the <strong class="bold">Connect</strong> button afterward:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer053">
<img alt="Figure 2.17 – Connecting to the instance directly " height="249" src="image/B18638_02_017.jpg" width="1064"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.17 – Connecting to the instance directly</p>
<p class="list-inset">Here, we can <a id="_idIndexMarker146"/>see that there’s an option to connect directly to the instance using the browser.</p>
<ol>
<li value="4">In the <strong class="bold">EC2 Instance Connect</strong> tab, locate and copy the <strong class="bold">Public IP address</strong> value (<strong class="source-inline">AA.BB.CC.DD</strong>) to a text editor on your local machine. Note that you will get a different public IP address value. We will use this IP address value later in this chapter when accessing <strong class="bold">TensorBoard</strong> (the visualization toolkit of TensorFlow) and the <strong class="bold">Jupyter notebook</strong> application. Leave the <strong class="bold">User name</strong> value as-is (<strong class="source-inline">root</strong>) and then click <strong class="bold">Connect</strong>:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer054">
<img alt="Figure 2.18 – EC2 Instance Connect " height="501" src="image/B18638_02_018.jpg" width="860"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.18 – EC2 Instance Connect</p>
<p class="list-inset">This should <a id="_idIndexMarker147"/>open a new tab that will allow us to run terminal commands directly from the browser. If you are getting a <strong class="bold">There was a problem connecting to your instance</strong> error message, wait for about 2 to 3 minutes before refreshing the page or clicking the <strong class="bold">Retry</strong> button:</p>
<div>
<div class="IMG---Figure" id="_idContainer055">
<img alt="Figure 2.19 – EC2 Instance Connect terminal " height="556" src="image/B18638_02_019.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.19 – EC2 Instance Connect terminal</p>
<p class="list-inset">As we can see, <strong class="source-inline">TensorFlow 2.9.1</strong> and other utility libraries are installed in <strong class="source-inline">/usr/local/bin/python3.9</strong>. Note that you may get different TensorFlow and Python versions, depending <a id="_idIndexMarker148"/>on the version of the DLAMI you use to launch the instance. </p>
<p>Wasn’t that easy? At this point, we should now be able to perform deep learning experiments using TensorFlow without having to install additional tools and libraries inside the EC2 instance. </p>
<p class="callout-heading">Note</p>
<p class="callout">Note that this process of <a id="_idIndexMarker149"/>launching instances from AMIs can be further sped up using <strong class="bold">Launch Templates</strong>, which already specify instance configuration information such as the AMI ID, instance type, key pair, and security groups. We won’t cover the usage of Launch Templates in this book, so feel free to check the following link for more details: <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.xhtml">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.xhtml</a>.</p>
<h1 id="_idParaDest-49"><a id="_idTextAnchor051"/>Downloading the sample dataset</h1>
<p>In the succeeding sections of this chapter, we will work with a very simple synthetic dataset that <a id="_idIndexMarker150"/>contains only two columns – <em class="italic">x</em> and <em class="italic">y</em>. Here, <em class="italic">x</em> may represent an object’s relative position on the <em class="italic">X</em>-axis, while <em class="italic">y</em> may represent the same object’s position on the <em class="italic">Y</em>-axis. The following screenshot shows an example of what the data looks like:</p>
<div>
<div class="IMG---Figure" id="_idContainer056">
<img alt="Figure 2.20 – Sample dataset " height="314" src="image/B18638_02_020.jpg" width="961"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.20 – Sample dataset</p>
<p>ML is about finding patterns. With this dataset, we will build a model that tries to predict the value of <em class="italic">y</em> given the value of <em class="italic">x</em> later in this chapter. Once we’re able to build models with a simple example like this, it will be much easier to deal with more realistic datasets that contain more than two columns, similar to what we worked with in <a href="B18638_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to ML Engineering on AWS</em>.</p>
<p class="callout-heading">Note</p>
<p class="callout">In this book, we won’t limit ourselves to just tabular data and simple datasets. In <a href="B18638_06.xhtml#_idTextAnchor132"><em class="italic">Chapter 6</em></a>, <em class="italic">SageMaker Training and Debugging Solutions</em>, for example, we’ll work with labeled <a id="_idIndexMarker151"/>image data and build two image classification models using several capabilities and features of <strong class="bold">Amazon SageMaker</strong>. In <a href="B18638_07.xhtml#_idTextAnchor151"><em class="italic">Chapter 7</em></a>, <em class="italic">SageMaker Deployment Solutions</em>, we’ll work with text data and deploy a <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) model using a <a id="_idIndexMarker152"/>variety of deployment options.</p>
<p>That said, let’s <a id="_idIndexMarker153"/>continue where we left off in the <em class="italic">Launching the instance and connecting to it using EC2 Instance Connect</em> section and proceed with downloading the dataset we will use to train the deep learning model in this chapter:</p>
<ol>
<li value="1">In the <strong class="bold">EC2 Instance Connect</strong> window (or tab), run the following command to create the <strong class="source-inline">data</strong> directory:<pre class="source-code">mkdir -p <strong class="bold">data</strong></pre></li>
<li>Download the training, validation, and test datasets using the <strong class="source-inline">wget</strong> command:<pre class="source-code">wget <strong class="bold">https://bit.ly/3h1KBx2</strong> -O <strong class="bold">data/training_data.csv</strong></pre><pre class="source-code">wget <strong class="bold">https://bit.ly/3gXYM6v</strong> -O<strong class="bold"> data/validation_data.csv</strong></pre><pre class="source-code">wget <strong class="bold">https://bit.ly/35aKWem</strong> -O <strong class="bold">data/test_data.csv</strong></pre></li>
<li>Optionally, we can install the <strong class="source-inline">tree</strong> utility using the <strong class="source-inline">yum</strong> package management tool: <pre class="source-code">yum install <strong class="bold">tree</strong></pre></li>
</ol>
<p class="list-inset">If this is your first time encountering the <strong class="source-inline">tree</strong> command, it is used to list the directories <a id="_idIndexMarker154"/>and files in a tree-like structure.</p>
<p class="callout-heading">Note</p>
<p class="callout">It is also possible to create a custom AMI from an EC2 instance. If we were to create a custom AMI from the EC2 instance we are using right now, we would be able to launch new EC2 instances from the new custom AMI with the following installed already: (1) installed frameworks, libraries, and tools from the DLAMI, and (2) the <strong class="source-inline">tree</strong> utility we installed before the custom AMI was created. </p>
<ol>
<li value="4">Use the <strong class="source-inline">tree</strong> command to see the current set directories and files in the current directory:<pre class="source-code"><strong class="bold">tree</strong></pre></li>
</ol>
<p class="list-inset">This should yield a tree-like structure, similar to what is shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer057">
<img alt="Figure 2.21 – Results after using the tree command " height="248" src="image/B18638_02_021.jpg" width="1365"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.21 – Results after using the tree command</p>
<p class="list-inset">Here, we can see that we have successfully downloaded the CSV files using the <strong class="source-inline">wget</strong> command earlier.</p>
<ol>
<li value="5">Now, let’s verify and check the contents of one of the CSV files we have downloaded. Use the <strong class="source-inline">head</strong> command to see the first few rows of the <strong class="source-inline">training_data.csv</strong> file:<pre class="source-code">head <strong class="bold">data/training_data.csv</strong></pre></li>
</ol>
<p class="list-inset">This should give us rows of <em class="italic">(x,y) pairs</em>, similar to what is shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer058">
<img alt="Figure 2.22 – The first few rows of the training_data.csv file " height="420" src="image/B18638_02_022.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.22 – The first few rows of the training_data.csv file</p>
<p class="list-inset">You may <a id="_idIndexMarker155"/>check the contents of <strong class="source-inline">validation_data.csv</strong> and <strong class="source-inline">test_data.csv</strong> using the <strong class="source-inline">head</strong> command as well.</p>
<p class="callout-heading">Note</p>
<p class="callout">It is important to note that the first column in this example is the <em class="italic">y</em> column. Some ML practitioners follow a convention where the first column is used as the target column (the column containing the values we want to predict using the other columns of the dataset). When using certain algorithms such as the <strong class="bold">XGBoost</strong> and <strong class="bold">Linear Learner</strong> built-in algorithms of <strong class="bold">SageMaker</strong>, the first column is assumed to be the target column. If you are using your own custom scripts to load the data, you can follow any convention you would like since you have the freedom of how the data is loaded and interpreted from a file.</p>
<p>You have probably noticed by now that, so far in this book, we have been using clean and preprocessed datasets. In real ML projects, you’ll be dealing with raw data with a variety of issues <a id="_idIndexMarker156"/>such as missing values and duplicate rows. In <a href="B18638_05.xhtml#_idTextAnchor105"><em class="italic">Chapter 5</em></a>, <em class="italic">Pragmatic Data Processing and Analysis</em>, we’ll be working with a “dirtier” version of the <em class="italic">bookings</em> dataset and use a variety of AWS services and capabilities <a id="_idIndexMarker157"/>such as <strong class="bold">AWS Glue DataBrew</strong> and <strong class="bold">Amazon SageMaker Data Wrangler</strong> to <a id="_idIndexMarker158"/>analyze, clean, and process the data. In this chapter, however, we will work with a “clean” dataset since we need to focus on training a deep learning model using <strong class="bold">TensorFlow</strong> and <strong class="bold">Keras</strong>. That said, let’s proceed with generating a model that accepts <em class="italic">x</em> as the input and returns a predicted <em class="italic">y</em> value as the output.</p>
<h1 id="_idParaDest-50"><a id="_idTextAnchor052"/>Training an ML model</h1>
<p>In <a href="B18638_01.xhtml#_idTextAnchor017"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to ML Engineering on AWS</em>, we trained a binary classifier model that aims to <a id="_idIndexMarker159"/>predict if a hotel booking will be canceled or not using the available information. In this chapter, we will use the (intentionally simplified) dataset from <em class="italic">Downloading the Sample Dataset</em> and train a regression model that will predict the value of <em class="italic">y</em> (continuous variable) given the value of <em class="italic">x</em>. Instead of relying on ready-made AutoML tools and services, we will be working with a custom script instead:</p>
<div>
<div class="IMG---Figure" id="_idContainer059">
<img alt="Figure 2.23 – Model life cycle " height="360" src="image/B18638_02_023.jpg" width="1051"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.23 – Model life cycle</p>
<p>When writing a custom training script, we usually follow a sequence similar to what is shown in the preceding diagram. We start by defining and compiling a model. After that, we load the data and use it to train and evaluate the model. Finally, we serialize and save the model into a file. </p>
<p class="callout-heading">Note</p>
<p class="callout">What happens after the model has been saved? The model file can be used and loaded in an inference endpoint — a web server that uses a trained ML model to perform predictions (for example, predicted <em class="italic">y</em> values) given a set of input values (for example, input <em class="italic">x</em> values). In the <em class="italic">Loading and evaluating the model</em> section of this chapter, we’ll load the generated model file inside a Jupyter Notebook using the <strong class="source-inline">load_model()</strong> function from <strong class="source-inline">tf.keras.models</strong>. We’ll then use the <strong class="source-inline">predict()</strong> method to perform sample predictions using a provided test dataset.</p>
<p>In this chapter, we will work with a script file that uses <strong class="bold">TensorFlow</strong> and <strong class="bold">Keras</strong> to build a <strong class="bold">neural network</strong> model – an interconnected group of nodes that can learn complex patterns <a id="_idIndexMarker160"/>between inputs and outputs. As we will be working with neural networks and deep learning concepts in this book, we must have a basic understanding of the following concepts:</p>
<ul>
<li><strong class="bold">Neurons</strong>: These are the building blocks of neural networks that accept and process input values <a id="_idIndexMarker161"/>to produce output values. <em class="italic">How are the output values computed?</em> Each of the input values passing through the neuron is multiplied by the associated <strong class="bold">weight</strong> values <a id="_idIndexMarker162"/>and then a numerical value (also known as the <strong class="bold">bias</strong>) is added afterward. A non-linear <a id="_idIndexMarker163"/>function called the <strong class="bold">activation function</strong> is then applied to the resulting value, which would yield the output. This non-linear function helps neural networks learn complex patterns between the input values and the output values. We can see a representation of a neuron in the following diagram:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer060">
<img alt="Figure 2.24 – A representation of a neuron " height="431" src="image/B18638_02_024.jpg" width="999"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.24 – A representation of a neuron</p>
<p class="list-inset">Here, we can see that we can compute the value of <em class="italic">y</em> with a formula involving the <em class="italic">x</em> input values, the corresponding weight values, the bias, and the activation function. That said, we <a id="_idIndexMarker164"/>can think of a neuron as a “mathematical function” and a neural network as a “bunch of mathematical functions” trying to map input values with output values through the continuous update of weight and bias values.</p>
<ul>
<li><strong class="bold">Layers</strong>: Layers are <a id="_idIndexMarker165"/>composed of a group of neurons located at a specific location or depth in a neural network:</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer061">
<img alt="Figure 2.25 – An input layer, output layer, and multiple hidden layers " height="433" src="image/B18638_02_025.jpg" width="870"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.25 – An input layer, output layer, and multiple hidden layers</p>
<p class="list-inset">Here, we can see <a id="_idIndexMarker166"/>the different layers of a neural network. The <strong class="bold">input layer</strong> is the layer receiving <a id="_idIndexMarker167"/>the input values, while the <strong class="bold">output layer</strong> is the layer <a id="_idIndexMarker168"/>generating the output values. Between the input layer <a id="_idIndexMarker169"/>and the output layer are processing layers called <strong class="bold">hidden layers</strong>, which process and transform the data from the input layer to <a id="_idIndexMarker170"/>the output layer. (Neural networks with more than one or two hidden layers are generally called <strong class="bold">deep neural networks</strong>.)</p>
<ul>
<li><strong class="bold">Forward propagation</strong>: This <a id="_idIndexMarker171"/>refers to the forward flow of information from the input layer to the hidden layers and then to the output layers to generate the output values.</li>
<li><strong class="bold">Cost function</strong>: This function is used to compute how far off the predicted computed value is <a id="_idIndexMarker172"/>from the actual value. Given that the goal of training a neural network is to generate a predicted value as close as possible to the actual value, we should be aiming to look for a minimum value of the cost <a id="_idIndexMarker173"/>function (which represents the error of the model) using optimization algorithms such as <strong class="bold">Gradient Descent</strong>.</li>
<li><strong class="bold">Backpropagation</strong>: This is <a id="_idIndexMarker174"/>the process of adjusting the weights in a neural network based on the difference between the predicted values and the actual values (which involves calculating the <strong class="bold">gradients</strong> or making small updates to the weights in each layer):</li>
</ul>
<div>
<div class="IMG---Figure" id="_idContainer062">
<img alt="Figure 2.26 – Backpropagation " height="344" src="image/B18638_02_026.jpg" width="860"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.26 – Backpropagation</p>
<p class="list-inset">Here, we can see that <a id="_idIndexMarker175"/>backpropagation involves propagating the computed error backward from the output layer to the input layer (and updating the weights accordingly).</p>
<ul>
<li><strong class="bold">Learning rate</strong>: This influences the amount used to adjust the weights in the network concerning <a id="_idIndexMarker176"/>the loss gradient while training the neural network.</li>
<li><strong class="bold">Epoch</strong>: This is a training iteration that involves one forward and one backward propagation <a id="_idIndexMarker177"/>using the entire training dataset. After each training iteration, the weights of the neural network are updated, and the neural network is expected to perform better in mapping the set of input values into the set of output values.</li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">We won’t dive deep into the details of deep learning and neural networks in this book. If you are interested in learning more about these topics, there are several books available online: <a href="https://www.amazon.com/Neural-Network/s?k=Neural+Network">https://www.amazon.com/Neural-Network/s?k=Neural+Network</a>.</p>
<p>Now that we have a better idea of what neural networks are, we can proceed with training a neural <a id="_idIndexMarker178"/>network model. In the next set of steps, we will use a custom script to train a deep learning model with the data downloaded in the previous section:</p>
<ol>
<li value="1">First, let’s create a directory named <strong class="source-inline">logs</strong> using the <strong class="source-inline">mkdir</strong> command:<pre class="source-code">mkdir -p <strong class="bold">logs</strong></pre></li>
<li>Next, use the <strong class="source-inline">wget</strong> command to download the <strong class="source-inline">train.py</strong> file:<pre class="source-code">wget <strong class="bold">https://bit.ly/33D0iYC</strong> -O <strong class="bold">train.py</strong></pre></li>
<li>Use the <strong class="source-inline">tree</strong> command to quickly check what the file and directory structure looks like:<pre class="source-code"><strong class="bold">tree</strong></pre></li>
</ol>
<p class="list-inset">This should yield a tree-like structure, similar to what is shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer063">
<img alt="Figure 2.27 – Results after using the tree command " height="338" src="image/B18638_02_027.jpg" width="1462"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.27 – Results after using the tree command</p>
<p class="list-inset">Note that the data and log directories are at the same level as the <strong class="source-inline">train.py</strong> file.</p>
<ol>
<li value="4">Before running the <strong class="source-inline">train.py</strong> file, execute the following command:<pre class="source-code"><strong class="bold">for a in /sys/bus/pci/devices/*; do echo 0 | sudo tee -a $a/numa_node; done</strong></pre></li>
</ol>
<p class="list-inset">This will help us avoid the <strong class="bold">successful NUMA node read from SysFS had negative value (-1)</strong> warning message when listing the GPU devices later in this chapter.</p>
<ol>
<li value="5">Before running the downloaded <strong class="source-inline">train.py</strong> script, let’s check its contents by opening <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter02/train.py">https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter02/train.py</a> in a separate browser tab: </li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer064">
<img alt="Figure 2.28 – The train.py file " height="597" src="image/B18638_02_028.jpg" width="1026"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.28 – The train.py file</p>
<p class="list-inset">In the preceding <a id="_idIndexMarker179"/>screenshot, we can see that our <strong class="source-inline">train.py</strong> script does the following: </p>
<ul>
<li>(<strong class="bold">1</strong>) defines a sample neural network model using the <strong class="source-inline">prepare_model()</strong> function </li>
<li>(<strong class="bold">2</strong>) loads the training and validation data using the <strong class="source-inline">load_data()</strong> function</li>
<li>(<strong class="bold">3</strong>) prepares the <strong class="bold">TensorBoard</strong> callback object</li>
<li>(<strong class="bold">4</strong>) performs the training step using the <strong class="source-inline">fit()</strong> method and passes the <strong class="bold">TensorBoard</strong> callback object as the <strong class="source-inline">callback</strong> parameter value</li>
<li>(<strong class="bold">5</strong>) saves the model artifacts using the <strong class="source-inline">save()</strong> method</li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">It is important to note that the <strong class="source-inline">prepare_model()</strong> function in our <strong class="source-inline">train.py</strong> script performs both the <em class="italic">define model</em> and <em class="italic">compile model</em> steps. The neural network defined in this function is a sample sequential model with five layers. For more information, feel free to check out the implementation of the <strong class="source-inline">prepare_model()</strong> function at <a href="https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter02/train.py#L24">https://github.com/PacktPublishing/Machine-Learning-Engineering-on-AWS/blob/main/chapter02/train.py</a>.</p>
<ol>
<li value="6">Let’s start the training step by running the following in the EC2 Instance Connect terminal:<pre class="source-code">python3.9 <strong class="bold">train.py</strong></pre></li>
</ol>
<p class="list-inset">This should <a id="_idIndexMarker180"/>yield a set of logs, similar to what is shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer065">
<img alt="Figure 2.29 – train.py script logs " height="426" src="image/B18638_02_029.jpg" width="903"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.29 – train.py script logs</p>
<p class="list-inset">Note that the training step may take around 5 minutes to complete. Once the <strong class="source-inline">train.py</strong> script has finished executing, you may check the new files generated inside the <strong class="source-inline">logs</strong> and <strong class="source-inline">model</strong> directories using the <strong class="source-inline">tree</strong> command.</p>
<p class="callout-heading">Note</p>
<p class="callout">What’s happening here? Here, the <strong class="source-inline">fit()</strong> method of the model we defined in <strong class="source-inline">train.py</strong> is training the model with the number of epochs (iterations) set to <strong class="source-inline">500</strong>. For each iteration, we are updating the weights of the neural network to minimize the “error” between the actual values and the predicted values (for example, using cross-validation data).</p>
<ol>
<li value="7">Next, run the following command to run the <strong class="source-inline">tensorBoard</strong> application, which can help <a id="_idIndexMarker181"/>visualize and debug ML experiments:<pre class="source-code"><strong class="bold">tensorboard --logdir=logs --bind_all</strong></pre></li>
<li>Open a new browser tab and open <strong class="bold">TensorBoard</strong> by going to <strong class="source-inline">http://&lt;IP ADDRESS&gt;:6006</strong>. Replace <strong class="source-inline">&lt;IP ADDRESS&gt;</strong> with the public IP address we copied to our text editor in the <em class="italic">Launching an EC2 instance using a Deep Learning AMI</em> section:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer066">
<img alt="Figure 2.30 – TensorBoard " height="1143" src="image/B18638_02_030.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.30 – TensorBoard</p>
<p class="list-inset">This should load a web application, similar to what is shown in the preceding screenshot. We <a id="_idIndexMarker182"/>won’t dive deep into what we can do with TensorBoard, so feel free to check out <a href="https://www.tensorflow.org/tensorboard">https://www.tensorflow.org/tensorboard</a> for more information.</p>
<p class="callout-heading">Note</p>
<p class="callout">How do we interpret these charts? As shown in <em class="italic">Figure 2.30</em>,  the training and validation loss generally decrease over time. In the first chart (top), the <em class="italic">X</em>-axis corresponds to the epoch number, while the <em class="italic">Y</em>-axis shows the training and validation loss. It should be noted that in this chart, the train and validation “learning curves” are overlapping and both continue to decrease up to a certain point as the number of epochs or iterations increases. It should be noted that these types of charts help diagnose ML model performance, which would <a id="_idIndexMarker183"/>be useful in avoiding issues such as <strong class="bold">overfitting</strong> (where the trained <a id="_idIndexMarker184"/>model performs well on the training data but performs poorly on unseen data) and <strong class="bold">underfitting</strong> (where the trained model performs poorly on the training dataset and unseen data). We won’t discuss this in detail, so feel free to check other ML and deep learning resources available. </p>
<ol>
<li value="9">Navigate <a id="_idIndexMarker185"/>back to the <strong class="bold">EC2 Instance Content</strong> terminal and stop the running <strong class="bold">TensorBoard</strong> application process with <em class="italic">Ctrl</em> + <em class="italic">C</em>.</li>
</ol>
<p>At this point, we should have the artifacts of a trained model inside the <strong class="source-inline">model</strong> directory. In the next section, we will load and evaluate this model inside a Jupyter Notebook environment.</p>
<h1 id="_idParaDest-51"><a id="_idTextAnchor053"/>Loading and evaluating the model</h1>
<p>In the previous section, we trained our deep learning model using the terminal. When performing ML experiments, it is generally more convenient to use a web-based interactive environment such as the <strong class="bold">Jupyter Notebook</strong>. We can technically run all the succeeding code blocks in the terminal, but we will use the Jupyter Notebook instead for convenience.</p>
<p>In the next set of steps, we will launch the Jupyter Notebook from the command line. Then, we will run a <a id="_idIndexMarker186"/>couple of blocks of code to load and evaluate the ML model we trained in the previous section. Let’s get started:</p>
<ol>
<li value="1">Continuing where we left off in the <em class="italic">Training an ML model</em> section, let’s run the following command in the <strong class="bold">EC2 Instance Connect</strong> terminal:<pre class="source-code"><strong class="bold">jupyter notebook --allow-root --port 8888 --ip 0.0.0.0</strong></pre></li>
</ol>
<p class="list-inset">This should start the Jupyter Notebook and make it accessible through port <strong class="source-inline">8888</strong>:</p>
<div>
<div class="IMG---Figure" id="_idContainer067">
<img alt="Figure 2.31 – Jupyter Notebook token " height="393" src="image/B18638_02_031.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.31 – Jupyter Notebook token</p>
<p class="list-inset">Make sure that you copy the generated random token from the logs generated after running the <strong class="source-inline">jupyter notebook</strong> command. Refer to the preceding screenshot on where to get the generated token. </p>
<ol>
<li value="2">Open a new <a id="_idIndexMarker187"/>browser tab and open the <strong class="bold">Jupyter</strong> application by accessing <strong class="source-inline">http://&lt;IP ADDRESS&gt;:8888</strong>. Replace <strong class="source-inline">&lt;IP ADDRESS&gt;</strong> with the public IP address we copied to our text editor in the <em class="italic">Launching an EC2 instance using a Deep Learning AMI</em> section:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer068">
<img alt="Figure 2.32 – Accessing the Jupyter Notebook " height="791" src="image/B18638_02_032.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.32 – Accessing the Jupyter Notebook</p>
<p class="list-inset">Here, we can see that we are required to input a password or token before we can use the <strong class="bold">Jupyter Notebook</strong>. Simply input the token obtained from the logs generated in the previous step.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">Note that this setup is not ready for use in production environments. For more information on <a id="_idIndexMarker188"/>how to secure the Jupyter Notebook server, check out https://jupyter-notebook.readthedocs.io/en/stable/security.xhtml. We will also discuss a few strategies to improve the security of this setup in <a href="B18638_09.xhtml#_idTextAnchor187"><em class="italic">Chapter 9</em></a>, <em class="italic">Security, Governance, and Compliance Strategies</em>. </p>
<ol>
<li value="3">Create a new notebook by clicking <strong class="bold">New</strong> and selecting <strong class="bold">Python 3 (ipykernel)</strong> from the list of <a id="_idIndexMarker189"/>dropdown options, similar to what is shown in the following screenshot:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer069">
<img alt="Figure 2.33 – Creating a new Jupyter Notebook " height="353" src="image/B18638_02_033.jpg" width="1056"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.33 – Creating a new Jupyter Notebook</p>
<p class="list-inset">This should open a blank notebook where we can run our Python code.</p>
<ol>
<li value="4">Import <strong class="source-inline">tensorflow</strong> and then use <strong class="source-inline">list_physical_devices()</strong> to list the visible GPUs in our instance:<pre class="source-code">import tensorflow as tf</pre><pre class="source-code">tf.config.list_physical_devices('GPU')</pre></li>
</ol>
<p class="list-inset">This should return <a id="_idIndexMarker190"/>a list with a single <strong class="source-inline">PhysicalDevice</strong> object, similar to <strong class="source-inline">[PhysicalDevice(name='/physical_device:GPU:0',device_type='GPU')]</strong>.</p>
<p class="callout-heading">Note</p>
<p class="callout">Since we are using a <strong class="source-inline">p3.2xlarge</strong> instance, the preceding block of code returned a single visible GPU device. If we launched a <strong class="source-inline">p3.16xlarge</strong> instance, we should get 8 visible GPU devices instead. Note that we can significantly reduce the training time by utilizing multiple GPU devices <a id="_idIndexMarker191"/>at the same time through parallelism techniques such as <strong class="bold">data parallelism</strong> (where the same model is used in each GPU but trained with <a id="_idIndexMarker192"/>different chunks of the dataset) and <strong class="bold">model parallelism</strong> (where the model is divided into several parts equal to the number of GPUs). Of course, the ML experiment scripts need to be modified to utilize multiple GPUs. For more <a id="_idIndexMarker193"/>information on how to use a GPU in TensorFlow, feel free to check the following link for more details: <a href="https://www.tensorflow.org/guide/gpu">https://www.tensorflow.org/guide/gpu</a>.</p>
<ol>
<li value="5">Load the model using <strong class="source-inline">tf.keras.models.load_model()</strong>. Inspect the model using <strong class="source-inline">model.summary()</strong>:<pre class="source-code">model = tf.keras.models.<strong class="bold">load_model</strong>('model')</pre><pre class="source-code">model.<strong class="bold">summary</strong>()</pre></li>
</ol>
<p class="list-inset">This should <a id="_idIndexMarker194"/>yield a model summary, as shown in the following screenshot:</p>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> </p>
<div>
<div class="IMG---Figure" id="_idContainer070">
<img alt="Figure 2.34 – Model summary " height="459" src="image/B18638_02_034.jpg" width="1231"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.34 – Model summary</p>
<p class="list-inset">This model summary should reflect the properties of the model we prepared and trained in the <em class="italic">Training an ML model</em> section.</p>
<p class="callout-heading">Important Note</p>
<p class="callout">Make sure to load only ML models from trusted sources using the <strong class="source-inline">load_model()</strong> function (along with other similar functions). Attackers can easily prepare a model (with a malicious payload) that, when loaded, will give the attacker access to the server running the ML scripts (for example, through a <strong class="bold">reverse shell</strong>). For more information on this topic, you may check the author’s talk on how to hack and secure ML environments and systems: <a href="https://speakerdeck.com/arvslat/pycon-apac-2022-hacking-and-securing-machine-learning-environments-and-systems?slide=21">https://speakerdeck.com/arvslat/pycon-apac-2022-hacking-and-securing-machine-learning-environments-and-systems?slide=21</a>.</p>
<ol>
<li value="6">Define <a id="_idIndexMarker195"/>the <strong class="source-inline">load_data()</strong> function, which will return the values of a CSV file with the specified file location:<pre class="source-code"><strong class="bold">import</strong> numpy <strong class="bold">as</strong> np</pre><pre class="source-code"><strong class="bold">def load_data</strong>(training_data_location):</pre><pre class="source-code">    fo = open(training_data_location, "rb")</pre><pre class="source-code">    result = np.loadtxt(fo, delimiter=",")</pre><pre class="source-code">    </pre><pre class="source-code">    y = result[:, 0]</pre><pre class="source-code">    x = result[:, 1]</pre><pre class="source-code">    </pre><pre class="source-code">    <strong class="bold">return</strong> (x, y)</pre></li>
<li>Now, let’s test if the loaded model can perform predictions given as a set of input values. Load the test data using <strong class="source-inline">load_data()</strong> and perform a few sample predictions using <strong class="source-inline">model.predict()</strong>:<pre class="source-code">x, y = <strong class="bold">load_data</strong>("data/test_data.csv")</pre><pre class="source-code">predictions = model.<strong class="bold">predict</strong>(x[0:5])</pre><pre class="source-code">predictions</pre></li>
</ol>
<p class="list-inset">This should <a id="_idIndexMarker196"/>yield an array of floating-point values, similar to what is shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer071">
<img alt="Figure 2.35 – Prediction results " height="135" src="image/B18638_02_035.jpg" width="925"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.35 – Prediction results</p>
<p class="list-inset">Here, we have the array of predicted <em class="italic">y</em> target values that correspond to each of the five input <em class="italic">x</em> values. Note that these predicted <em class="italic">y</em> values are different from the actual <em class="italic">y</em> values loaded from the <strong class="source-inline">test_data.csv</strong> file.</p>
<ol>
<li value="8">Evaluate <a id="_idIndexMarker197"/>the loaded model using <strong class="source-inline">model.evaluate()</strong>:<pre class="source-code">results = model.evaluate(x, y, batch_size=128)</pre><pre class="source-code">results</pre></li>
</ol>
<p class="list-inset">This should give us a value similar to or close to <strong class="source-inline">2.705784797668457</strong>. If you are wondering what this number means, this is the numerical value corresponding to <em class="italic">how far</em> the predicted values are from the actual values: </p>
<div>
<div class="IMG---Figure" id="_idContainer072">
<img alt="Figure 2.36 – How model evaluation works " height="251" src="image/B18638_02_036.jpg" width="686"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.36 – How model evaluation works</p>
<p>Here, we <a id="_idIndexMarker198"/>can see an example of how model evaluation <a id="_idIndexMarker199"/>works for regression problems. First, evaluation <a id="_idIndexMarker200"/>metrics such as <strong class="bold">Root Mean Square Error</strong> (<strong class="bold">RMSE</strong>), <strong class="bold">Mean Square Error</strong> (<strong class="bold">MSE</strong>), and <strong class="bold">Mean Absolute Error</strong> (<strong class="bold">MAE</strong>) compute the differences <a id="_idIndexMarker201"/>between the actual and predicted values of <em class="italic">y</em> before computing for a single evaluation metric value. This means that a model with a lower RMSE value generally makes fewer mistakes compared to a model with a higher RMSE value.</p>
<p>At this point, you may decide to build a custom backend API utilizing the preceding blocks of code, along with Python web frameworks such as <strong class="bold">Flask</strong>, <strong class="bold">Pyramid</strong>, or <strong class="bold">Django</strong>. However, you may <a id="_idIndexMarker202"/>want to check other built-in solutions first, such as <strong class="bold">TensorFlow Serving</strong> (an ML model serving system for TensorFlow models), which is designed for production environments.</p>
<p>If you think about it, we have completed an entire ML experiment in the last couple of sections <em class="italic">without having to install any additional libraries, packages, or frameworks</em> (other than the optional <strong class="source-inline">tree</strong> utility). With that, you have learned how useful and powerful <strong class="bold">Deep Learning AMIs</strong> are! Again, if we had to set up 20 or more ML environments like this, it would take us maybe less than 2 hours to get everything set up and ready. </p>
<h1 id="_idParaDest-52"><a id="_idTextAnchor054"/>Cleaning up</h1>
<p>Now that we have <a id="_idIndexMarker203"/>completed an end-to-end ML experiment, it’s about time we perform the cleanup steps to help us manage costs:</p>
<ol>
<li value="1">Close the browser tab that contains the <strong class="bold">EC2 Instance Connect</strong> terminal session.</li>
<li>Navigate to the <strong class="bold">EC2 instance</strong> page of the instance we launched using the Deep Learning AMI. Click <strong class="bold">Instance state</strong> to open the list of dropdown options and then click <strong class="bold">Terminate instance</strong>:</li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer073">
<img alt="Figure 2.37 – Terminating the instance " height="381" src="image/B18638_02_037.jpg" width="860"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.37 – Terminating the instance</p>
<p class="list-inset">As we can see, there are other options available, such as <strong class="bold">Stop instance</strong> and <strong class="bold">Reboot instance</strong>. If you do not want to delete the instance yet, you may want to stop the instance instead and start it at a later date and time. Note that a stopped instance will incur costs since the attached EBS volume is not deleted when an EC2 instance is stopped. That said, it is preferable to terminate the instance and delete any attached EBS volume if there are no critical files stored in the EBS volume.</p>
<ol>
<li value="3">In the <strong class="bold">Terminate instance?</strong> window, click <strong class="bold">Terminate</strong>. This should delete the EC2 instance, along <a id="_idIndexMarker204"/>with the volume attached to it. </li>
</ol>
<p>Unused resources should be turned off, terminated, or deleted when no longer needed to manage and reduce costs. As our ML and ML engineering requirements need more resources, we will have to make use of several cost optimization strategies to manage costs. We will discuss some of these strategies in the next section.</p>
<h1 id="_idParaDest-53"><a id="_idTextAnchor055"/>Understanding how AWS pricing works for EC2 instances</h1>
<p>Before we end this <a id="_idIndexMarker205"/>chapter, we must have a <a id="_idIndexMarker206"/>good idea of how AWS pricing works when dealing with EC2 instances. We also need to understand how the architecture and setup affect the overall cost of running ML workloads in the cloud.</p>
<p>Let’s say that we initially have a single <strong class="source-inline">p2.xlarge</strong> instance running 24/7 for an entire month in the Oregon region. Inside this instance, the data science team regularly runs a script that trains a deep learning model using the preferred ML framework. This training script generally runs for about 3 hours twice every week. Given the unpredictable schedule <a id="_idIndexMarker207"/>of the availability of new data, it’s hard to <a id="_idIndexMarker208"/>know when the training script will be run to produce a new model. The resulting ML model then gets deployed immediately to a web API server, which serves as the inference endpoint within the same instance. <em class="italic">Given this information, how much would the setup cost?</em></p>
<div>
<div class="IMG---Figure" id="_idContainer074">
<img alt="Figure 2.38 – Approximate cost of running a p2.xlarge instance per month " height="485" src="image/B18638_02_038.jpg" width="956"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.38 – Approximate cost of running a p2.xlarge instance per month</p>
<p>Here, we can see that the total cost for this setup would be around at least <em class="italic">$648 per month</em>. <em class="italic">How were we able to get this number?</em> We start by looking for the on-demand cost per hour of running a <strong class="source-inline">p2.xlarge</strong> instance in the Oregon region (using the following link as a reference: <a href="https://aws.amazon.com/ec2/pricing/on-demand/">https://aws.amazon.com/ec2/pricing/on-demand/</a>). At the time <a id="_idIndexMarker209"/>of writing, the on-demand cost per hour of a <strong class="source-inline">p2.xlarge</strong> instance would be <em class="italic">$0.90 per hour</em> in the Oregon (<strong class="source-inline">us-west-2</strong>) region. Since we will be running this instance 24/7 for an entire month, we’ll have to compute the <em class="italic">estimated total number of hours per month</em>. Assuming that we have about 30 days per month, we should approximately have a total of <em class="italic">720 hours in a single month</em> – that is, <strong class="source-inline">24 hours per day x 30 days = 720 hours</strong>. </p>
<p>Note that we can also use <em class="italic">730.001 hours</em> as a more accurate value for the total number of hours per month. However, we’ll stick with 720 hours for now to simplify things a bit. The next step is to multiply the <em class="italic">cost per hour of running the EC2 instance</em> (<strong class="source-inline">$0.90 per hour</strong>) and the <em class="italic">total number of hours per month</em> (<strong class="source-inline">720 hours per month</strong>). This would give us the total cost of running the EC2 instance in a single month (<strong class="source-inline">$0.90 x 720 = $648</strong>).</p>
<p class="callout-heading">Note</p>
<p class="callout">To simplify the computations in this section, we will only consider the cost per hour of using the EC2 instances. In real life, we’ll need to take into account the costs associated with using other resources such as the EBS volumes, VPC resources (NAT gateway), and more. For a more <a id="_idIndexMarker210"/>accurate set of estimates, make sure to use the <strong class="bold">AWS Pricing Calculator</strong>: https://calculator.aws/.</p>
<p>After a while, the <a id="_idIndexMarker211"/>data science team decided to train <a id="_idIndexMarker212"/>another model inside the same instance where we are already running a training script and a web server (inference endpoint). Worried that they might encounter performance issues and bottlenecks while running the two training scripts at the same time, the team requested for the <strong class="source-inline">p2.xlarge</strong> instance to be upgraded to a <strong class="source-inline">p2.8xlarge</strong> instance. <em class="italic">Given this information, how much would the new setup cost?</em></p>
<div>
<div class="IMG---Figure" id="_idContainer075">
<img alt="Figure 2.39 – Approximate cost of running a p2.8xlarge instance per month " height="454" src="image/B18638_02_039.jpg" width="968"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.39 – Approximate cost of running a p2.8xlarge instance per month</p>
<p>Here, we can see that the total cost for this setup would be around at least <em class="italic">$5,184 per month</em>. <em class="italic">How were we able to get this number?</em> We must follow a similar set of steps as with the previous <a id="_idIndexMarker213"/>example and look for the on-demand <a id="_idIndexMarker214"/>cost per hour of running a <strong class="source-inline">p2.8xlarge</strong> instance. Here, we can see that the cost of running a <strong class="source-inline">p2.8xlarge</strong> instance (<em class="italic">$7.20 per hour</em>) is eight times the cost of running a <strong class="source-inline">p2.xlarge</strong> instance (<em class="italic">$0.90 per hour</em>). That said, we’re expecting the overall cost to be eight times as well compared to the original setup that we had earlier. After multiplying the <em class="italic">cost per hour of running the p2.8xlarge instance</em> (<strong class="source-inline">$7.20 per hour</strong>) and the <em class="italic">total number of hours per month</em> (<strong class="source-inline">720 hours per month</strong>), we should get the total cost of running the <strong class="source-inline">p2.8xlarge</strong> instance in a single month (<strong class="source-inline">$7.20 x 720 = $5,184</strong>).</p>
<h2 id="_idParaDest-54"><a id="_idTextAnchor056"/>Using multiple smaller instances to reduce the overall cost of running ML workloads</h2>
<p>At this point, you might be wondering if there is a better way to set things up to significantly <a id="_idIndexMarker215"/>lower the cost while running the same set of ML workloads. The good news is that there’s a variety of ways to improve what we have so far and reduce the cost from <em class="italic">$5,184 per month</em> to a much smaller value such as <em class="italic">$86.40 per month</em>! Note that this is also significantly smaller compared to the cost of running the original setup (<em class="italic">$648 per month</em>). <em class="italic">How do we do this?</em></p>
<p>The first thing we need to do is utilize multiple “smaller” instances instead of a single <strong class="source-inline">p2.8xlarge</strong> instance. One possible setup is to use a <strong class="source-inline">p2.xlarge</strong> instance (<em class="italic">$0.90 per hour</em>) for each of the training scripts. Since we are working with two training scripts, we’ll have a total of two <strong class="source-inline">p2.xlarge</strong> instances. In addition to this, we’ll be using an <strong class="source-inline">m6i.large</strong> instance (<em class="italic">$0.096 per hour</em>) to host the inference endpoint where the model is deployed. Since the training scripts are only expected to run when there’s new data available (approximately twice per week), we can have <strong class="source-inline">p2.xlarge</strong> instances running only when we need to run the training scripts. This means that if we have around <em class="italic">720 hours per month</em>, a <strong class="source-inline">p2.xlarge</strong> instance associated with one of the training scripts should only run for about <em class="italic">24 hours per month</em> in total (with the instance turned off the majority of the time).</p>
<p class="callout-heading">Note</p>
<p class="callout"><em class="italic">How did we get this number</em>? Since the training script is expected to run for about 3 hours twice every week, then the formula would be <strong class="source-inline">[3 hours per run] x [2 times per week] x [4 weeks]</strong>, which would yield a value of 24 hours. This means that each of the <strong class="source-inline">p2.xlarge</strong> instances would cost around <em class="italic">$21.60 per month</em> if these would only run for a total of about 24 hours in a single month. </p>
<p>Even if these <strong class="source-inline">p2.xlarge</strong> instances are turned off most of the time, our ML inference endpoint <a id="_idIndexMarker216"/>would still be running 24/7 in its dedicated <strong class="source-inline">m6i.large</strong> instance. The cost of running the <strong class="source-inline">m6i.large</strong> instance for an entire month would be around <em class="italic">$69.12 per month</em> (using the <strong class="source-inline">[$0.096 per hour] x [720 hours per month]</strong> formula):</p>
<div>
<div class="IMG---Figure" id="_idContainer076">
<img alt="Figure 2.40 – Using multiple smaller instances to reduce the overall cost " height="659" src="image/B18638_02_040.jpg" width="1184"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.40 – Using multiple smaller instances to reduce the overall cost</p>
<p>That said, we should be able to reduce the overall cost to around <em class="italic">$112.32 per month</em>, similar to what is shown in the preceding diagram. <em class="italic">How were we able to get this number</em>? We simply added the expected costs of running each instance in a month: <strong class="source-inline">$21.60 + $21.60 + $69.12 = $112.32</strong>.</p>
<h2 id="_idParaDest-55"><a id="_idTextAnchor057"/>Using spot instances to reduce the cost of running training jobs</h2>
<p>It is important to note that we can further decrease this cost by utilizing <strong class="bold">spot instances</strong> instead of on-demand instances for the <strong class="source-inline">p2.xlarge</strong> instances used to run the <a id="_idIndexMarker217"/>training scripts. With spot instances, we can reduce the cost of using a specific EC2 instance type by around 60% to 90% by utilizing the spare compute capacity available in AWS. This means that instead of paying <em class="italic">$0.90 per hour</em> when running <strong class="source-inline">p2.xlarge</strong> instances, we may only pay <em class="italic">$0.36 per hour</em>, assuming that we’ll have around 60% savings using spot instances. <em class="italic">What’s the catch when using spot instances?</em> When using spot instances, there’s a chance for the applications running inside these instances to be interrupted! This means that we should only run tasks (such as ML training jobs) that can be resumed after an unexpected interruption.</p>
<p class="callout-heading">Note</p>
<p class="callout">How did we get this number? 60% savings is equivalent to multiplying the on-demand cost per hour (<em class="italic">$0.90 per hour</em>) by 0.40. This would give us <strong class="source-inline">[$0.90 per hour] x [0.40] = [$0.36 per hour]</strong>.</p>
<p>Since interruptions are possible when using spot instances, it is not recommended that you use them for the 24/7 <strong class="source-inline">m6i.large</strong> instance where the web server (inference endpoint) is running:</p>
<div>
<div class="IMG---Figure" id="_idContainer077">
<img alt="Figure 2.41 – Using spot instances to reduce the cost of running training jobs " height="689" src="image/B18638_02_041.jpg" width="1185"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.41 – Using spot instances to reduce the cost of running training jobs</p>
<p>Once we’ve utilized spot instances for the <strong class="source-inline">p2.xlarge</strong> instances, we’ll be able to reduce the overall cost to around <em class="italic">$86.40 per month</em>, similar to what we have in the preceding <a id="_idIndexMarker218"/>diagram. Again, this final value excludes the other costs to simplify the computations a bit. However, as you can see, this value is significantly smaller than the cost of running a single <strong class="source-inline">p2.8xlarge</strong> instance (<em class="italic">$5,184 per month</em>).</p>
<p>Wasn’t that amazing?! We just changed the architecture a bit and we were able to reduce the cost from <em class="italic">$5,184 per month</em> to <em class="italic">$86.40 per month</em>! Note that there are other ways to optimize the overall costs of running ML workloads in the cloud (for example, utilizing <strong class="bold">Compute Savings Plans</strong>). What you learned in this section should be enough for now as we’ll continue with these types of discussions over the next few chapters of this book.</p>
<h1 id="_idParaDest-56"><a id="_idTextAnchor058"/>Summary</h1>
<p>In this chapter, we were able to launch an EC2 instance using a <strong class="bold">Deep Learning AMI</strong>. This allowed us to immediately have an environment where we can perform our ML experiments without worrying about the installation and setup steps. We then proceeded with using <strong class="bold">TensorFlow</strong> to train and evaluate our deep learning model to solve a regression problem. We wrapped up this chapter by having a short discussion on how AWS pricing works for EC2 instances. </p>
<p>In the next chapter, we will focus on how <strong class="bold">AWS Deep Learning Containers</strong> help significantly speed up the ML experimentation and deployment process.</p>
<h1 id="_idParaDest-57"><a id="_idTextAnchor059"/>Further reading</h1>
<p>We are only scratching the surface of what we can do with Deep Learning AMIs. In addition to the convenience of having preinstalled frameworks, DLAMIs make it easy for ML engineers to utilize other optimization solutions such as <strong class="bold">AWS Inferentia</strong>, <strong class="bold">AWS Neuron</strong>, <strong class="bold">distributed training</strong>, and <strong class="bold">Elastic Fabric Adapter</strong>. For more information, feel free to check out the following resources:</p>
<ul>
<li><em class="italic">What is the AWS Deep Learning AMI?</em> (<a href="https://docs.aws.amazon.com/dlami/latest/devguide/what-is-dlami.xhtml">https://docs.aws.amazon.com/dlami/latest/devguide/what-is-dlami.xhtml</a>)</li>
<li><em class="italic">How AWS Pricing Works</em> (<a href="https://docs.aws.amazon.com/whitepapers/latest/how-aws-pricing-works/how-aws-pricing-works.pdf">https://docs.aws.amazon.com/whitepapers/latest/how-aws-pricing-works/how-aws-pricing-works.pdf</a>)</li>
<li><em class="italic">Elastic Fabric Adapter</em> (<a href="https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-efa.xhtml">https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-efa.xhtml</a>)</li>
</ul>
</div>
</div>
</body></html>