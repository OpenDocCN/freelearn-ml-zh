<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer019">
<h1 class="chapter-number" id="_idParaDest-15"><a id="_idTextAnchor014"/>1</h1>
<h1 id="_idParaDest-16"><a id="_idTextAnchor015"/>Introducing Machine Learning</h1>
<p>Our journey starts with an introduction to machine learning and the fundamental concepts we’ll use throughout <span class="No-Break">this book.</span></p>
<p>We’ll start by providing an overview of machine learning from a software engineering perspective. Then, we’ll introduce the core concepts that are used in the field of machine learning and data science: models, datasets, learning paradigms, and other details. This introduction will include a practical example that clearly illustrates the machine learning <span class="No-Break">terms discussed.</span></p>
<p>We will also introduce decision trees, a crucially important machine learning algorithm that is our first step to <span class="No-Break">understanding LightGBM.</span></p>
<p>After completing this chapter, you will have established a solid foundation in machine learning and the practical application of machine <span class="No-Break">learning techniques.</span></p>
<p>The following main topics will be covered in <span class="No-Break">this chapter:</span></p>
<ul>
<li>What is <span class="No-Break">machine learning?</span></li>
<li>Introducing models, datasets, and <span class="No-Break">supervised learning</span></li>
<li>Decision <span class="No-Break">tree learning</span></li>
</ul>
<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/>Technical requirements</h1>
<p>This chapter includes examples of simple machine learning algorithms and introduces working with scikit-learn. You must install a Python environment with scikit-learn, NumPy, pandas, and Jupyter Notebook. The code for this chapter is available <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-1"><span class="No-Break">https://github.com/PacktPublishing/Practical-Machine-Learning-with-LightGBM-and-Python/tree/main/chapter-1</span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/>What is machine learning?</h1>
<p>Machine learning is a part of the broader artificial intelligence field that involves methods and techniques that allow computers to “learn” specific tasks without <span class="No-Break">explicit programming.</span></p>
<p>Machine learning is just <a id="_idIndexMarker000"/>another way to write programs, albeit automatically, from data. Abstractly, a program is a set of <em class="italic">instructions</em> that transforms <em class="italic">inputs</em> into specific <em class="italic">outputs</em>. A programmer’s job is to understand all the relevant inputs to a computer program and develop a set of instructions to produce the <span class="No-Break">correct outputs.</span></p>
<p>However, what if the inputs are beyond the <span class="No-Break">programmer’s understanding?</span></p>
<p>For example, let’s consider creating a program to forecast the total sales of a large retail store. The inputs to the program would be various factors that could affect sales. We could imagine factors such as historical sales figures, upcoming public holidays, stock availability, any special deals the store might be running, and even factors such as the weather forecast or proximity to <span class="No-Break">other stores.</span></p>
<p>In our store example, the traditional approach would be to break down the inputs into manageable, understandable (by a programmer) pieces, perhaps consult an expert in store sales forecasting, and then devise handcrafted rules and instructions to attempt to forecast <span class="No-Break">future sales.</span></p>
<p>While this approach is certainly possible, it is also brittle (in the sense that the program might have to undergo extensive changes regarding the input factors) and wholly based on the programmer’s (or domain expert’s) understanding of the problem. With potentially thousands of factors and billions of examples, this problem <span class="No-Break">becomes untenable.</span></p>
<p>Machine learning offers us an alternative to this approach. Instead of creating rules and instructions, we repeatedly show the computer examples of the tasks we need to accomplish and then get it to figure out how to solve <span class="No-Break">them automatically.</span></p>
<p>However, where we previously <a id="_idIndexMarker001"/>had a set of instructions, we now have a <strong class="bold">trained model</strong> instead of a <span class="No-Break">programmed one.</span></p>
<p>The key realization here, especially if you are coming from a software background, is that our machine learning program still functions like a regular program: it accepts input, has a way to process it, and produces output. Like all other software programs, machine learning software must be tested for correctness, integrated into other systems, deployed, monitored, and optimized. Collectively, this forms the field of <em class="italic">machine learning engineering</em>. We’ll cover all these aspects and more in <span class="No-Break">later chapters.</span></p>
<h2 id="_idParaDest-19"><a id="_idTextAnchor018"/>Machine learning paradigms</h2>
<p>Broadly speaking, machine learning has three main paradigms: supervised, unsupervised, and <span class="No-Break">reinforcement learning.</span></p>
<p>With <strong class="bold">supervised learning</strong>, the model is trained on labeled data: each instance in the dataset has <a id="_idIndexMarker002"/>its associated correct output, or label, for the <a id="_idIndexMarker003"/>input example. The model is expected to learn to predict the label for unseen <span class="No-Break">input examples.</span></p>
<p>With <strong class="bold">unsupervised learning</strong>, the <a id="_idIndexMarker004"/>examples in the dataset are <a id="_idIndexMarker005"/>unlabeled; in this case, the model is expected to discover patterns and relationships in the data. Examples of unsupervised approaches are clustering algorithms, anomaly detection, and dimensionality <span class="No-Break">reduction algorithms.</span></p>
<p>Finally, <strong class="bold">reinforcement learning</strong> entails a model, usually called an agent, interacting with a <a id="_idIndexMarker006"/>particular environment and learning by <a id="_idIndexMarker007"/>receiving penalties or rewards for specific actions. The goal is for the agent to perform actions that maximize its reward. Reinforcement learning is widely used in robotics, control systems, or training computers to <span class="No-Break">play games.</span></p>
<p>LightGBM and most other algorithms discussed later in this book are examples of supervised learning techniques and are the focus of <span class="No-Break">this book.</span></p>
<p>The following section dives deeper into the machine learning terminology we’ll use throughout this book and the details of the machine <span class="No-Break">learning process.</span></p>
<h1 id="_idParaDest-20"><a id="_idTextAnchor019"/>Introducing models, datasets, and supervised learning</h1>
<p>In the previous section, we introduced a model as a construct to replace a set of instructions that typically comprise a program to perform a specific task. This section covers models and other core machine learning concepts in <span class="No-Break">more detail.</span></p>
<h2 id="_idParaDest-21"><a id="_idTextAnchor020"/>Models</h2>
<p>More formally, a model is <a id="_idIndexMarker008"/>a mathematical or algorithmic representation of a specific process that performs a particular task. A machine learning model learns a particular task by being trained on a <strong class="bold">dataset</strong> using a <span class="No-Break"><strong class="bold">training algorithm</strong></span><span class="No-Break">.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">An alternative term for training is <strong class="bold">fit</strong>. Historically, fit stems from the statistical field. A model is said to “fit the data” when trained. We’ll use both terms interchangeably throughout <span class="No-Break">this book.</span></p>
<p>Many distinct types of models exist, all of which use different mathematical, statistical, or algorithmic techniques to model the training data. Examples of machine learning algorithms include linear regression, logistic regression, decision trees, support vector machines, and <span class="No-Break">neural networks.</span></p>
<p>A distinction is made between the model type and a trained instance of that model: the majority of machine learning models can be trained to perform various tasks. For example, decision trees (a model type) can be trained to forecast sales, recognize heart disease, and predict football match results. However, each of these tasks requires a different <em class="italic">instance</em> of a decision tree that has been trained on a <span class="No-Break">distinct dataset.</span></p>
<p>What a specific model does depends on the model’s <strong class="bold">parameters</strong>. Parameters are also sometimes called <strong class="bold">weights</strong>, which are technically particular types of <span class="No-Break">model parameters.</span></p>
<p>A <strong class="bold">training algorithm</strong> is an <a id="_idIndexMarker009"/>algorithm for finding the most appropriate model parameters for a <span class="No-Break">specific task.</span></p>
<p>We determine <a id="_idIndexMarker010"/>the quality of fit, or how well the model performs, using an <strong class="bold">objective function</strong>. This is a mathematical function that measures the difference between the predicted output and the actual output for a given input. The objective function quantifies the performance of a model. We may seek to minimize or maximize the objective function depending on the problem we are solving. The objective is often measured as an error we aim to minimize <span class="No-Break">during training.</span></p>
<p>We can summarize <a id="_idIndexMarker011"/>the model training process as follows: a training algorithm uses data from a dataset to optimize a model’s parameters for a particular task, as measured through an <span class="No-Break">objective function.</span></p>
<h2 id="_idParaDest-22"><a id="_idTextAnchor021"/>Hyperparameters</h2>
<p>While a model is composed of parameters, the training algorithm has parameters of its own called <strong class="bold">hyperparameters</strong>. A hyperparameter is a controllable value that influences the <a id="_idIndexMarker012"/>training process or algorithm. For example, consider finding the minimum of a parabola function: we could start by guessing a value and then take small steps in the direction that minimizes the function output. The step size would have to be chosen well: if our steps are too small, it will take a prohibitively long time to find the minimum. If the step size is too large, we may overshoot and miss the minimum and then continue oscillating (jumping back and forth) around <span class="No-Break">the minimum:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer014">
<img alt="Figure 1.1 – Effect of using a step size that is too large (left) and too small (right)" height="626" src="image/B16690_01_01.jpg" width="1179"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – Effect of using a step size that is too large (left) and too small (right)</p>
<p>In this example, the step size would be a hyperparameter of our minimization algorithm. The effect of the step size is illustrated in <span class="No-Break"><em class="italic">Figure 1</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">.</span></p>
<h2 id="_idParaDest-23"><a id="_idTextAnchor022"/>Datasets</h2>
<p>As explained previously, the machine learning model is trained using a dataset. Data is at the heart of <a id="_idIndexMarker013"/>the machine learning process, and data preparation is often the part of the process that takes up the <span class="No-Break">most time.</span></p>
<p>Throughout this book, we’ll work with <em class="italic">tabular</em> datasets. Tabular datasets are very common in the real world and consist of rows and columns. Rows are often called samples, examples, or observations, and columns are usually called features, variables, <span class="No-Break">or attributes.</span></p>
<p>Importantly, there is no restriction on the data type in a column. Features may be strings, numbers, Booleans, geospatial coordinates, or encoded formats such as audio, images, <span class="No-Break">or video.</span></p>
<p>Datasets are also rarely perfectly defined. Data may be incomplete, noisy, incorrect, inconsistent, and contain <span class="No-Break">various formats.</span></p>
<p>Therefore, <em class="italic">data preparation and cleaning</em> are essential parts of the machine <span class="No-Break">learning process.</span></p>
<p>Data preparation concerns processing the data to make it suitable for machine learning and typically consists of the <span class="No-Break">following steps:</span></p>
<ol>
<li><strong class="bold">Gathering and validation</strong>: Some datasets are initially too small or represent the problem poorly (the data is not representative of the actual data population it’s been sampled from). In these cases, the practitioner must collect more data, and validation must be done to ensure the data represents <span class="No-Break">the problem.</span></li>
<li><strong class="bold">Checking for systemic errors and bias</strong>: It is vital to check for and correct any systemic errors in the collection and validation process that may lead to bias in the dataset. In our sales example, a systemic collection error may be that data was only gathered from urban stores and excluded rural ones. A model trained on only urban store data will be biased in forecasting store sales, and we may expect poor performance when the model is used to predict sales for <span class="No-Break">rural stores.</span></li>
<li><strong class="bold">Cleaning the data</strong>: Any format or value range inconsistencies must be addressed. Any missing values also need to be handled in a way that does not <span class="No-Break">introduce bias.</span></li>
<li><strong class="bold">Feature engineering</strong>: Certain features may need to be transformed to ensure the machine learning model can learn from them, such as numerically encoding a sentence of words. Additionally, new features may need to be prepared from existing features to help the model <span class="No-Break">detect patterns.</span></li>
<li><strong class="bold">Normalizing and standardizing</strong>: The relative ranges of features must be normalized and <a id="_idIndexMarker014"/>standardized. Normalizing and standardizing ensure that no one feature has an outsized effect on the <span class="No-Break">overall prediction.</span></li>
<li><strong class="bold">Balancing the dataset</strong>: In cases where the dataset is imbalanced – that is, it contains many more examples of one class or prediction than another – the dataset needs to be balanced. Balancing is typically done by oversampling the minority examples to balance <span class="No-Break">the dataset.</span></li>
</ol>
<p>In <a href="B16690_06.xhtml#_idTextAnchor094"><span class="No-Break"><em class="italic">Chapter 6</em></span></a><em class="italic">, Solving Real-World Data Science Problems with LightGBM</em>, we’ll go through the entire data preparation process to show how the preceding steps are <span class="No-Break">applied practically.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">A good adage to remember is “garbage in, garbage out”. A model learns from any data given to it, including any flaws or biases contained in the data. When we train the model on garbage data, it results in a <span class="No-Break">garbage model.</span></p>
<p>One final concept to understand regarding datasets is the training, validation, and test datasets. We split our datasets into these three subsets after the data preparation step <span class="No-Break">is done:</span></p>
<ul>
<li>The <strong class="bold">training set</strong> is the most <a id="_idIndexMarker015"/>significant subset and typically consists <a id="_idIndexMarker016"/>of 60% to 80% of the data. This data is used to train <span class="No-Break">the model.</span></li>
<li>The <strong class="bold">validation set</strong> is separate <a id="_idIndexMarker017"/>from the training data and is <a id="_idIndexMarker018"/>used throughout the training process to evaluate the model. Having independent validation data ensures that the model is evaluated on data it has not seen before, also known as its generalization ability. Hyperparameter tuning, a process covered in detail in <a href="B16690_05.xhtml#_idTextAnchor083"><span class="No-Break"><em class="italic">Chapter 5</em></span></a><em class="italic">, LightGBM Parameter Optimization with Optuna</em>, also uses the <span class="No-Break">validation set.</span></li>
<li>Finally, the <strong class="bold">test set</strong> is an <a id="_idIndexMarker019"/>optional hold-out set, similar to the validation set. It is <a id="_idIndexMarker020"/>used at the end of the process to evaluate the model’s performance on data that was not part of the training or <span class="No-Break">tuning process.</span></li>
</ul>
<p>Another use of the validation set is to monitor whether the model is overfitting the data. Let’s discuss overfitting in <span class="No-Break">more detail.</span></p>
<h2 id="_idParaDest-24"><a id="_idTextAnchor023"/>Overfitting and generalization</h2>
<p>To understand overfitting, we must first define what we mean by model <strong class="bold">generalization</strong>. As stated <a id="_idIndexMarker021"/>previously, generalization is the model’s ability to accurately predict data it has not seen before. Compared to training accuracy, generalization accuracy is more significant as an estimate of model performance as this indicates how our model will perform in production. Generalization comes in two forms, <strong class="bold">interpolation </strong><span class="No-Break"><strong class="bold">and extrapolation</strong></span><span class="No-Break">:</span></p>
<ul>
<li>Interpolation refers <a id="_idIndexMarker022"/>to the model’s ability to predict a value between two known data points – stated another way, to generalize within the training data range. For example, let’s say we train our model with monthly data from January to July. When interpolating, we would ask the model to make a prediction on a particular day in April, a date within our <span class="No-Break">training range.</span></li>
<li>Extrapolation, as you <a id="_idIndexMarker023"/>might infer, is the model’s ability to predict values outside of the range defined by our training data. A typical example of extrapolation is forecasting – that is, predicting the future. In our previous example, if we ask the model to make a prediction in December, we expect it to extrapolate from the <span class="No-Break">training data.</span></li>
</ul>
<p>Of the two types of generalization, extrapolation is much more challenging and may require a specific type of model to achieve. However, in both cases, a model can overfit the data, losing its ability to interpolate or <span class="No-Break">extrapolate accurately.</span></p>
<p><strong class="bold">Overfitting</strong> is a phenomenon <a id="_idIndexMarker024"/>where the model fits the training data too closely and loses its ability to generalize to unseen data. Instead of learning the underlying pattern in the data, the model has memorized the training data. More technically, the model fits the <em class="italic">noise</em> contained in the training data. The term noise stems from the concept of data containing <em class="italic">signal</em> and <em class="italic">noise</em>. Signal refers to the underlying pattern or information captured in the data we are trying to predict. In contrast, noise refers to random or irrelevant variations of data points that mask <span class="No-Break">the signal.</span></p>
<p>For example, consider a dataset where we try to predict the rainfall for specific locations. The signal in the data would be the general trend of rainfall: rainfall increases in the winter or summer, or vice versa for other locations. The noise would be the slight variations in rainfall measurement for each month and location in <span class="No-Break">our dataset.</span></p>
<p>The following graph illustrates the phenomenon <span class="No-Break">of overfitting:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer015">
<img alt="Figure 1.2 – Graph showing overfitting. The model has overfitted and predicted the training data perfectly but has lost the ability to generalize to the actual signal" height="667" src="image/B16690_01_02.jpg" width="879"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – Graph showing overfitting. The model has overfitted and predicted the training data perfectly but has lost the ability to generalize to the actual signal</p>
<p>The preceding figure shows the difference between signal and noise: each data point was sampled <a id="_idIndexMarker025"/>from the actual signal. The data follows the general pattern of the signal, with slight, random variations. We can see how the model has overfitted the data: the model has fit the training data perfectly but at the cost of generalization. We can also see that if we use the model to <em class="italic">interpolate</em> by predicting a value for <span class="_-----MathTools-_Math_Number">4</span>, we get a result much higher than the actual signal (<span class="_-----MathTools-_Math_Number">6.72</span> versus <span class="_-----MathTools-_Math_Number">6.2</span>). Also shown is the model’s failure to <em class="italic">extrapolate</em>: the prediction for <span class="_-----MathTools-_Math_Number">12</span> is much lower than a forecast of the signal (<span class="_-----MathTools-_Math_Number">7.98</span> <span class="No-Break">versus </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">8.6</span></span><span class="No-Break">).</span></p>
<p>In reality, all real-world datasets contain noise. As data scientists, we aim to prepare the data to remove as much noise as possible, making the signal easier to detect. Data cleaning, normalization, feature selection, feature engineering, and regularization are techniques for removing noise from <span class="No-Break">the data.</span></p>
<p>Since all real-world data contains noise, overfitting is impossible to eliminate. The following conditions may lead <span class="No-Break">to overfitting:</span></p>
<ul>
<li><strong class="bold">An overly complex model</strong>: A model that is too complex for the amount of data we have utilizes additional complexity to memorize the noise in the data, leading <span class="No-Break">to overfitting</span></li>
<li><strong class="bold">Insufficient data</strong>: If we don’t have enough training data for the model we use, it’s similar to an overly complex model, which overfits <span class="No-Break">the data</span></li>
<li><strong class="bold">Too many features</strong>: A dataset with too many features likely contains irrelevant (noisy) features that reduce the <span class="No-Break">model’s generalization</span></li>
<li><strong class="bold">Overtraining</strong>: Training the model for too long allows it to memorize the noise in <span class="No-Break">the dataset</span></li>
</ul>
<p>As the validation set is a part of the training data that remains unseen by the model, we use the validation <a id="_idIndexMarker026"/>set to monitor for overfitting. We can recognize the point of overfitting by looking at the training and generalization errors over time. At the point of overfitting, the validation error increases. In contrast, the training error continues to improve: the model is fitting noise in the training data and losing its ability <span class="No-Break">to generalize.</span></p>
<p>Techniques that prevent overfitting usually aim to address the conditions that lead to overfitting we <a id="_idIndexMarker027"/>discussed previously. Here are some strategies to <span class="No-Break">avoid overfitting:</span></p>
<ul>
<li><strong class="bold">Early stopping</strong>: We can stop training when we see the validation error beginning <span class="No-Break">to increase.</span></li>
<li><strong class="bold">Simplifying the model</strong>: A less complex model with fewer parameters would be incapable of learning the noise in the training data, thereby <span class="No-Break">generalizing better.</span></li>
<li><strong class="bold">Get more data</strong>: Either collecting more data or augmenting data is an effective method for preventing overfitting by giving the model a better chance to learn the signal in the data instead of the noise in a <span class="No-Break">smaller dataset.</span></li>
<li><strong class="bold">Feature selection and dimensionality reduction</strong>: As some features might be irrelevant to the problem being solved, we can discard features we think are redundant or use techniques such as Principal Component Analysis to reduce the <span class="No-Break">dimensionality (features).</span></li>
<li><strong class="bold">Adding regularization</strong>: Smaller parameter values typically lead to better generalization, depending on the model (a neural network is an example of such a model). Regularization adds a penalty term to the objective function to discourage large <a id="_idIndexMarker028"/>parameter values. By driving the parameters to smaller (or zero) values, they contribute less to the prediction, effectively simplifying <span class="No-Break">the model.</span></li>
<li><strong class="bold">Ensemble methods</strong>: Combining the prediction from multiple, <em class="italic">weaker</em> models can lead to better generalization while also <span class="No-Break">improving performance.</span></li>
</ul>
<p>It’s important to note that <em class="italic">overfitting and the techniques to prevent overfitting are specific to our model</em>. Our goal should always be to minimize overfitting to ensure generalization to unseen data. Some strategies, such as regularization, might not work for specific models, while others might be more effective. There are also more bespoke strategies for models, an example of which we’ll see when we discuss overfitting in <span class="No-Break">decision trees.</span></p>
<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/>Supervised learning</h2>
<p>The store <a id="_idIndexMarker029"/>sales example is an instance of <strong class="bold">supervised learning</strong> – we have a dataset consisting of features and are training the model to predict <span class="No-Break">a target.</span></p>
<p>Supervised learning problems can be divided into two main types of problem categories: <strong class="bold">classification problems</strong> and <span class="No-Break"><strong class="bold">regression problems</strong></span><span class="No-Break">.</span></p>
<h3>Classification and regression</h3>
<p>With a <em class="italic">classification problem</em>, the label <a id="_idIndexMarker030"/>that needs to be predicted <a id="_idIndexMarker031"/>by the model is categorical or defines a class. Some examples of classes are <strong class="source-inline">spam</strong> or <strong class="source-inline">not spam</strong>, <strong class="source-inline">cat</strong> or <strong class="source-inline">dog</strong>, and <strong class="source-inline">diabetic</strong> or <strong class="source-inline">not diabetic</strong>. These are examples of binary classifications: there are only <span class="No-Break">two classes.</span></p>
<p>Multi-class classification is also possible; for example, email may be classified as <strong class="source-inline">Important</strong>, <strong class="source-inline">Promotional</strong>, <strong class="source-inline">Clutter</strong>, or <strong class="source-inline">Spam</strong>; images of clouds could be classified as <strong class="source-inline">Cirro</strong>, <strong class="source-inline">Cumulo</strong>, <strong class="source-inline">Strato</strong>, <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">Nimbo</strong></span><span class="No-Break">.</span></p>
<p>With <em class="italic">regression problems</em>, the goal is to predict a continuous, numerical value. Examples <a id="_idIndexMarker032"/>include predicting revenue, sales, temperature, house <a id="_idIndexMarker033"/>prices, and <span class="No-Break">crowd size.</span></p>
<p>A big part of the <em class="italic">art</em> of machine learning is correctly defining or transcribing a problem as a classification or regression problem (or perhaps unsupervised or reinforcement). Later chapters will cover multiple end-to-end case studies of both types <span class="No-Break">of problems.</span></p>
<h2 id="_idParaDest-26"><a id="_idTextAnchor025"/>Model performance metrics</h2>
<p>Let’s briefly discuss how we measure our model’s performance. Model performance refers to the <a id="_idIndexMarker034"/>ability of a machine learning model to make accurate predictions or generate meaningful outputs based on the given inputs. An evaluation metric quantifies how well a model generalizes to new, unseen data. High model performance indicates that the model has learned the underlying patterns in the data effectively and can make accurate predictions on data it has not seen before. We can measure the model’s performance relative to the known targets when working with supervised learning problems (either classification or <span class="No-Break">regression problems).</span></p>
<p>Importantly, how we measure the model’s performance on classification tasks and regression tasks differs. scikit-learn has many built-in metrics functions ready for use with either a cla<a href="https://scikit-learn.org/stable/modules/model_evaluation.xhtml">ssification or regression problem (https://scikit-learn.org/s</a>table/modules/model_evaluation.xhtml). Let’s review the most common <span class="No-Break">of these.</span></p>
<p>Classification metrics <a id="_idIndexMarker035"/>can be defined in terms of positive and negative predictions made by the model. The following definitions can be used to calculate <span class="No-Break">classification metrics:</span></p>
<ul>
<li><strong class="bold">True positive</strong> (<strong class="bold">TP</strong>): A positive instance is correctly classified <span class="No-Break">as positive</span></li>
<li><strong class="bold">True negative</strong> (<strong class="bold">TN</strong>): A negative instance is correctly classified <span class="No-Break">as negative</span></li>
<li><strong class="bold">False positive</strong> (<strong class="bold">FP</strong>): A negative instance is incorrectly classified <span class="No-Break">as positive</span></li>
<li><strong class="bold">False negative</strong> (<strong class="bold">FN</strong>): A positive instance is incorrectly classified <span class="No-Break">as negative</span></li>
</ul>
<p>Given these definitions, the most common <em class="italic">classification</em> metrics are <span class="No-Break">as follows:</span></p>
<ul>
<li><strong class="bold">Accuracy</strong>: Accuracy <a id="_idIndexMarker036"/>is the most straightforward classification metric. Accuracy is the number of correct predictions divided by the total number of predictions. However, accuracy is susceptible to an imbalance in the data. For example, suppose we have an email dataset with 8 examples of spam and 2 examples of non-spam, and our model predicts only spam. In that case, the model has an accuracy of 80%, even though it never correctly <a id="_idIndexMarker037"/>classified non-spam emails. Mathematically, we can define accuracy <span class="No-Break">as follows:</span><p class="list-inset"><span class="_-----MathTools-_Math_Variable">Accuracy</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TN</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">______________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FP</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TN</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FN</span><span class="_-----MathTools-_Math_Variable"> </span></p></li>
<li><strong class="bold">Precision</strong>: The precision score is one way of getting a more nuanced understanding <a id="_idIndexMarker038"/>of the classification performance. Precision is the ratio between the true positive prediction (correctly predicted) and all positive predictions (true positive and false positive). In other words, the precision score indicates how precise the model is in predicting positives. In our spam emails example, a model predicting only spam is not very precise (as it classifies all non-spam emails as spam) and has a lower precision score. The following formula can be used to <span class="No-Break">calculate precision:</span><p class="list-inset"><span class="_-----MathTools-_Math_Variable">Precision</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FP</span><span class="_-----MathTools-_Math_Variable"> </span></p></li>
<li><strong class="bold">Recall</strong>: The recall <a id="_idIndexMarker039"/>score is the counterpoint to the precision score. The recall score measures how effectively the model finds (or recalls) all true positive cases. The recall is calculated as the ratio between true positive predictions and all positive instances (true positive and false negative). In our spam example, a model predicting only spam has perfect recall (it can find all the spam). We can calculate recall <span class="No-Break">like so:</span><p class="list-inset"><span class="_-----MathTools-_Math_Variable">Recall</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FN</span><span class="_-----MathTools-_Math_Variable"> </span></p></li>
<li><strong class="bold">F1 score</strong>: Finally, we <a id="_idIndexMarker040"/>have the F1 score. The F1 score is calculated as the harmonic mean between precision and recall. The F1 score balances precision and recall, giving us a singular value that summarizes the classifier’s performance. The following formula can be used to calculate the <span class="No-Break">F1 score:</span><p class="list-inset"><span class="_-----MathTools-_Math_Variable">F</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Precision</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Recall</span><span class="_-----MathTools-_Math_Variable">  </span><span class="_-----MathTools-_Math_Base">_______________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Variable">Precision</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">Recall</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base">____________</span><span class="_-----MathTools-_Math_Base">  </span><span class="_-----MathTools-_Math_Number">2</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">×</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">TP</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FP</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">FN</span><span class="_-----MathTools-_Math_Variable"> </span></p></li>
</ul>
<p>The preceding classification metrics are the most common, but there are many more. Even though the F1 score is commonly used in classification problems (as it summarizes precision and recall), choosing the best metric is specific to the problem you are solving. Often, it might be the case that a specific metric is required, but other times, you must choose based on experience and your understanding of the data. We will look at examples of different metrics later in <span class="No-Break">this book.</span></p>
<p>The following are common <span class="No-Break"><em class="italic">regression</em></span><span class="No-Break"> metrics:</span></p>
<ul>
<li><strong class="bold">Mean squared error</strong> (<strong class="bold">MSE</strong>): The MSE is calculated as the average of the squared <a id="_idIndexMarker041"/>differences between predicted and actual values. The MSE is commonly used because of one crucial mathematical property: the MSE is <em class="italic">differentiable</em> and is therefore appropriate for use with gradient-based learning methods. However, since the difference is squared, the MSE penalizes large errors more heavily than small errors, which may or may not be appropriate to the problem <span class="No-Break">being solved.</span></li>
<li><strong class="bold">Mean absolute error</strong> (<strong class="bold">MAE</strong>): Instead of squaring the differences, the MAE is calculated <a id="_idIndexMarker042"/>as the average of the absolute differences between predicted and actual values. By avoiding the square of errors, the MAE is more robust against the magnitude of errors and less sensitive to outliers than the MSE. However, the MAE is not differentiable and, therefore, can’t be used with gradient-based <span class="No-Break">learning methods.</span></li>
</ul>
<p>As with the classification metrics, choosing the most appropriate regression metric is specific to the problem you are trying <span class="No-Break">to solve.</span></p>
<p class="callout-heading">Metrics versus objectives</p>
<p class="callout">We defined <a id="_idIndexMarker043"/>training a model as finding the most appropriate <a id="_idIndexMarker044"/>parameters to minimize an <em class="italic">objective function</em>. It’s important to note that the objective function and metrics used for a specific problem may differ. A good example is decision trees, where a measure of impurity (entropy) is used as the objective function when building a tree. However, we still calculate the metrics explained previously to determine the tree’s performance on <span class="No-Break">the data.</span></p>
<p>With our understanding of basic metrics in place, we can conclude our introduction to machine learning concepts. Now, let’s review the terms and concepts we’ve discussed using <span class="No-Break">an example.</span></p>
<h2 id="_idParaDest-27"><a id="_idTextAnchor026"/>A modeling example</h2>
<p>Consider the <a id="_idIndexMarker045"/>following data of sales by month, <span class="No-Break">in thousands:</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-1">
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Jan</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Feb</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Mar</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Apr</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">May</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Jun</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">4,140</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">4,850</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">7,340</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">6,890</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">8,270</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">10,060</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Jul</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Aug</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Sept</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Oct</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Nov</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">Dec</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">8,110</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">11,670</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">10,450</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">11,540</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">13,400</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">14,420</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 1.1 – Sample sales data, by month, in thousands</p>
<p>This problem is straightforward: there is only one feature, the month, and the target is the number of sales. Therefore, this is an example of a supervised <span class="No-Break">regression problem.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">You might have noticed that this is an example of a time series problem: time is the primary variable. Time series can also be predicted using more advanced time series-specific algorithms such as ANOVA, but we’ll use a simple algorithm for illustration purposes in <span class="No-Break">this section.</span></p>
<p>We can plot our data as a graph of sales per month to understand <span class="No-Break">it better:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer016">
<img alt="Figure 1.3 – Graph showing store sales by month" height="692" src="image/B16690_01_03.jpg" width="907"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – Graph showing store sales by month</p>
<p>Here, we’re using <a id="_idIndexMarker046"/>a straight-line model, also known as simple linear regression, to model our sales data. The definition of a straight line is given by the <span class="No-Break">following formula:</span></p>
<p><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">mx</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">+</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">c</span></p>
<p>Here, <span class="_-----MathTools-_Math_Variable">m</span><span class="_-----MathTools-_Math_Space"> </span>is the line’s slope and <span class="_-----MathTools-_Math_Variable">c</span> is the Y-intercept. In machine learning, the straight line is the model, and <span class="_-----MathTools-_Math_Variable">m</span> and <span class="_-----MathTools-_Math_Variable">c</span> are the <span class="No-Break">model parameters.</span></p>
<p>To find the best parameters, we must measure how well our model fits the data for a particular set of parameters – that is, the error in our outputs. We will use the MAE as <span class="No-Break">our metric:</span></p>
<p><span class="_-----MathTools-_Math_Variable">MAE</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">∑</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">i</span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Number">1</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">|</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">ˆ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">−</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Base">|</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">_</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">n</span><span class="_-----MathTools-_Math_Variable"> </span></p>
<p>Here, <span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Base">ˆ</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Variable">y</span><span class="_-----MathTools-_Math_Variable"> </span> is the predicted output, <span class="_-----MathTools-_Math_Variable">y</span> is the actual output, and <span class="_-----MathTools-_Math_Variable">n</span> is the number of predictions. We calculate the MAE by making a prediction for each of our inputs and then calculating the MAE based on <span class="No-Break">the formula.</span></p>
<h3>Fitting the model</h3>
<p>Now, let’s fit our linear model to our data. Our process for fitting the line is iterative, and we start this <a id="_idIndexMarker047"/>process by guessing values for <span class="_-----MathTools-_Math_Variable">m</span> and <span class="_-----MathTools-_Math_Variable">c</span> and then iterating from there. For example, let’s consider <span class="_-----MathTools-_Math_Variable">m</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Number">0.1</span><span class="_-----MathTools-_Math_Operator">,</span><span class="_-----MathTools-_Math_Space"> </span><span class="_-----MathTools-_Math_Variable_v-normal">c</span><span class="_-----MathTools-_Math_Base"> </span><span class="_-----MathTools-_Math_Operator">=</span><span class="_-----MathTools-_Math_Base"> </span><span class="No-Break"><span class="_-----MathTools-_Math_Number">4</span></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer017">
<img alt="Figure 1.4 – Graph showing the prediction of a linear model with m = 0.1 and c = 4" height="696" src="image/B16690_01_04.jpg" width="946"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – Graph showing the prediction of a linear model with m = 0.1 and c = 4</p>
<p>With these parameters, we achieve an error <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">4,610</strong></span><span class="No-Break">.</span></p>
<p>Our guess is far too low, but that’s okay; we can now update the parameters to attempt to improve the error. In reality, updating the model parameters is done algorithmically using a training algorithm such as gradient descent. We’ll discuss gradient descent in <a href="B16690_02.xhtml#_idTextAnchor036"><span class="No-Break"><em class="italic">Chapter 2</em></span></a><em class="italic">, Ensemble Learning – Bagging </em><span class="No-Break"><em class="italic">and Boosting</em></span><span class="No-Break">.</span></p>
<p>In this example, we’ll use our understanding of straight lines and intuition to update the parameters for each iteration manually. Our line is too shallow, and the intercept is too low; therefore, we must increase both values. We can control the updates we make each iteration by choosing a <em class="italic">step size</em>. We must update the <span class="_-----MathTools-_Math_Variable">m</span> and <span class="_-----MathTools-_Math_Variable">c</span> values with each iteration by adding the step size. The results, for a step size of 0.1, is shown in <span class="No-Break"><em class="italic">Table 1.2</em></span><span class="No-Break">.</span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table002">
<colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break">Guess#</span></p>
</td>
<td class="No-Table-Style">
<p><span class="_-----MathTools-_Math_Variable">m</span></p>
</td>
<td class="No-Table-Style">
<p><span class="_-----MathTools-_Math_Variable">c</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="_-----MathTools-_Math_Variable">MAE</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>1</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.1</span></p>
</td>
<td class="No-Table-Style">
<p>4</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">4.61</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>2</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.2</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">4.1</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">3.89</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>3</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.3</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">4.2</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">3.17</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>4</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.3</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">4.3</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">2.5</span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p>5</p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">0.4</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">4.4</span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break">1.83</span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 1.2 – Step wise guessing of the slope (<span class="_-----MathTools-_Math_Variable_v-bold-italic">m</span>) and y-intercept (<span class="_-----MathTools-_Math_Variable_v-bold-italic">c</span>) for a straight line to fit our data. The quality of fit is measured using the MAE</p>
<p>In our example, the <em class="italic">step size</em> is a <em class="italic">hyperparameter</em> of our <span class="No-Break">training process.</span></p>
<p>We end up <a id="_idIndexMarker048"/>with an error of <em class="italic">1.83</em>, which means, on average, our predictions are wrong by less <span class="No-Break">than </span><span class="No-Break"><em class="italic">2,000</em></span><span class="No-Break">.</span></p>
<p>Now, let’s see how we can solve this problem <span class="No-Break">using scikit-learn.</span></p>
<h3>Linear regression with scikit-learn</h3>
<p>Instead of manually modeling, we can use scikit-learn to build a linear regression model. As this is <a id="_idIndexMarker049"/>our first example, we’ll walk through the <a id="_idIndexMarker050"/>code line by line and explain <span class="No-Break">what’s happening.</span></p>
<p>To start with, we <a id="_idIndexMarker051"/>must import the Python tools we are going <span class="No-Break">to use:</span></p>
<pre class="source-code">
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error</pre>
<p>There are three sets of imports: we import <strong class="source-inline">numpy</strong> and <strong class="source-inline">pandas</strong> first. Importing NumPy and pandas is a widely used way to start all your data science notebooks. Also, note the short names <strong class="source-inline">np</strong> and <strong class="source-inline">pd</strong>, which are the standard conventions when working with <strong class="source-inline">numpy</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">pandas</strong></span><span class="No-Break">.</span></p>
<p>Next, we import a few standard plotting libraries we will use to plot some graphs: <strong class="source-inline">pyplot</strong> from <strong class="source-inline">matplotlib</strong> and <strong class="source-inline">seaborn</strong>. Matplotlib is a widely used plotting library that we access <a id="_idIndexMarker052"/>via the pyplot python interface. <strong class="bold">Seaborn</strong> is another visualization tool built on top of Matplotlib, which makes it easier to draw <span class="No-Break">professional-looking graphs.</span></p>
<p>Finally, we get <a id="_idIndexMarker053"/>to our scikit-learn imports. In Python <a id="_idIndexMarker054"/>code, the scikit-learn library is called <strong class="source-inline">sklearn</strong>. From its <strong class="source-inline">linear_model</strong> package, we import <strong class="source-inline">LinearRegression</strong>. scikit-learn <a id="_idIndexMarker055"/>implements a wide variety of predefined metrics, and here, we will be <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">mean_absolute_error</strong></span><span class="No-Break">.</span></p>
<p>Now, we are ready to set up <span class="No-Break">our data:</span></p>
<pre class="source-code">
months = np.array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])
sales = np.array([4.14,  4.85,  7.34,  6.89,  8.27, 10.06,  8.11, 11.67, 10.45, 11.54, 13.4 , 14.42])
df = pd.DataFrame({"month": months, "sales": sales})</pre>
<p>Here, we define a new <strong class="source-inline">numpy</strong> array for the months and the corresponding sales, and to make them easier to work with, we gather both arrays into a new <span class="No-Break"><strong class="source-inline">pandas</strong></span><span class="No-Break"> DataFrame.</span></p>
<p>With the data in place, we get to the interesting part of the code: modeling using scikit-learn. The code <span class="No-Break">is straightforward:</span></p>
<pre class="source-code">
model = LinearRegression()
model = model.fit(df[["month"]], df[["sales"]])</pre>
<p>First, we create our model by constructing an instance of <strong class="source-inline">LinearRegression</strong>. We then fit our model using <strong class="source-inline">model.fit</strong> and passing in the month and sales data from our DataFrame. These two lines are all that’s required to fit a model, and as we’ll see in later chapters, even complicated models use the same recipe to instantiate and train <span class="No-Break">a model.</span></p>
<p>We can now calculate our <em class="italic">MAE</em> by creating predictions for our data and passing the predictions and actual targets to the <span class="No-Break">metric function:</span></p>
<pre class="source-code">
predicted_sales = model.predict(df[["month"]])
mean_absolute_error(predicted_sales, df[["sales"]])</pre>
<p>We get an error of <em class="italic">0.74</em>, which is slightly lower than our guesswork. We can also examine the model’s coefficient and intercept (<em class="italic">m</em> and <em class="italic">c</em> <span class="No-Break">from earlier):</span></p>
<pre class="source-code">
print(f"Gradient: ${model.coef_}")
print(f"Intercept: ${model.intercept_}")</pre>
<p>scikit-learn <a id="_idIndexMarker056"/>has fitted a model with a coefficient of <em class="italic">0.85</em> and an intercept of <em class="italic">3.68</em>. We were in the right neighborhood with our guesses, but it might have taken us some time to get to the <span class="No-Break">optimal values.</span></p>
<p>That concludes <a id="_idIndexMarker057"/>our introduction to scikit-learn and <a id="_idIndexMarker058"/>the basics of modeling and machine learning. In our toy example, we did not split our data into separate datasets, optimize our model’s hyperparameters, or apply any techniques to ensure our model does not overfit. In the next section, we’ll look at classification and regression examples, where we’ll apply these and other <span class="No-Break">best practices.</span></p>
<h1 id="_idParaDest-28"><a id="_idTextAnchor027"/>Decision tree learning</h1>
<p>This section introduces decision tree learning, a machine learning algorithm essential to understanding <a id="_idIndexMarker059"/>LightGBM. We’ll work through an example of how to build decision trees using scikit-learn. This section will also provide some mathematical definitions for building decision trees; understanding these definitions is not critical, but it will help us understand our discussion of the decision <span class="No-Break">tree hyperparameters.</span></p>
<p>Decision trees are tree-based learners that function by asking successive questions about the data to determine the result. A path is followed down the tree, making decisions about the input using one or more features. The path terminates at a leaf node, which represents the predicted class or value. Decision trees can be used for classification <span class="No-Break">or regression.</span></p>
<p>The following <a id="_idIndexMarker060"/>is an illustration of a decision tree fit on the <span class="No-Break">Iris dataset:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer018">
<img alt="Figure 1.5 – A decision tree modeling the Iris dataset" height="1163" src="image/B16690_01_05.jpg" width="1500"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5 – A decision tree modeling the Iris dataset</p>
<p>The Iris dataset is a classification dataset where Iris flower sepal and petal dimensions are used to predict the type of Iris flower. Each non-leaf node uses one or more features to narrow down the samples in the dataset: the root node starts with all 150 samples and then splits them based on petal width, &lt;= 0.8. We continue down the tree, with each node splitting the samples further until we reach a leaf node that contains the predicted class (versicolor, virginica, <span class="No-Break">or setosa).</span></p>
<p>Compared to other models, decision trees have <span class="No-Break">many advantages:</span></p>
<ul>
<li><strong class="bold">Features may be numeric or categorical</strong>: Samples can be split using either numerical <a id="_idIndexMarker061"/>features (by splitting a range) or categorical ones without us having to <span class="No-Break">encode either.</span></li>
<li><strong class="bold">Reduced need for data preparation</strong>: Decision splits are not sensitive to data ranges or size. Many other models (for example, neural networks) require data to be normalized to <span class="No-Break">unit ranges.</span></li>
<li><strong class="bold">Interpretability</strong>: As shown previously, it’s straightforward to interpret the predictions made by a tree. Interpretability is valuable in contexts where a prediction must be explained <span class="No-Break">to decision-makers.</span></li>
</ul>
<p>These are just some of the advantages of using tree-based models. However, we also need to be aware of some of the disadvantages associated with <span class="No-Break">decision trees:</span></p>
<ul>
<li><strong class="bold">Overfitting</strong>: Decision trees are very prone to overfitting. Setting the correct hyperparameters <a id="_idIndexMarker062"/>is essential when fitting decision trees. Overfitting in decision trees will be discussed in <span class="No-Break">detail later.</span></li>
<li><strong class="bold">Poor extrapolation</strong>: Decision trees are poor at extrapolation since their predictions are not continuous and are effectively bounded by the <span class="No-Break">training data.</span></li>
<li><strong class="bold">Unbalanced data</strong>: When fitting a tree on unbalanced data, the high-frequency classes dominate the predictions. Data needs to be prepared to <span class="No-Break">remove imbalances.</span></li>
</ul>
<p>A more detailed discussion of the advantages and disadvantages of decision trees is available <span class="No-Break">at </span><a href="https://scikit-learn.org/stable/modules/tree.xhtml"><span class="No-Break">https://scikit-learn.org/stable/modules/tree.xhtml</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-29"><a id="_idTextAnchor028"/>Entropy and information gain</h2>
<p>First, we need a rudimentary understanding of entropy and information gain before we look at an <a id="_idIndexMarker063"/>algorithm for building (or fitting) a <span class="No-Break">decision tree.</span></p>
<p>Entropy can be considered a way to measure the disorder or randomness of a system. Entropy measures how surprising the result of a specific input or event might be. Consider a well-shuffled deck of cards: drawing from the top of the deck could give us any of the cards in the deck (a surprising result each time); therefore, we can say that a shuffled deck of <a id="_idIndexMarker064"/>cards has <strong class="bold">high entropy</strong>. Drawing cards from the top of an ordered deck is unsurprising; we know which cards come next. Therefore, an ordered deck <a id="_idIndexMarker065"/>of cards has <strong class="bold">low entropy</strong>. Another way to interpret entropy is the impurity of the dataset: a low-entropy dataset (neatly ordered) has less impurity than a <span class="No-Break">high-entropy dataset.</span></p>
<p>Information gain, in turn, is the amount of information gained when modifying or observing <a id="_idIndexMarker066"/>the underlying data. Information gain involves reducing entropy from before the observation. In our deck of cards example, we might take a shuffled deck of cards and split it into four smaller decks by suit (spades, hearts, diamonds, and clubs). If we draw from the smaller decks, the outcome is less of a surprise: we know that the next card is from the same suit. By splitting the deck by suit, we have reduced the entropy of the smaller decks. Splitting the deck of cards on a feature (the suit) is very similar to how the splits in a decision tree work; each division seeks to maximize the information gain – that is, they minimize the entropy after <span class="No-Break">the split.</span></p>
<p>In decision trees, there are two common ways of measuring information gain or the loss <span class="No-Break">of impurity:</span></p>
<ul>
<li>The <span class="No-Break">Gini index</span></li>
<li>Log loss <span class="No-Break">or entropy</span></li>
</ul>
<p>A detailed explanation of each is available <span class="No-Break">at </span><a href="https://scikit-learn.org/stable/modules/tree.xhtml#classification-criteria"><span class="No-Break">https://scikit-learn.org/stable/modules/tree.xhtml#classification-criteria</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-30"><a id="_idTextAnchor029"/>Building a decision tree using C4.5</h2>
<p>C4.5 is an <a id="_idIndexMarker067"/>algorithm for building a decision tree <a id="_idIndexMarker068"/>from a dataset [1]. The algorithm is recursive and starts with the following <span class="No-Break">base cases:</span></p>
<ol>
<li>If all the samples in a sub-dataset are of the same class, create a leaf node in the tree that chooses <span class="No-Break">that class.</span></li>
<li>If no information can be gained by splitting using any of the features (the dataset can’t be divided any further), create a leaf node that predicts the most frequent class contained in <span class="No-Break">the sub-dataset.</span></li>
<li>If a minimum threshold of samples is reached in a sub-dataset, create a leaf node that predicts the most frequent class contained in <span class="No-Break">the sub-dataset.</span></li>
</ol>
<p>Then, we can apply <span class="No-Break">the algorithm:</span></p>
<ol>
<li>Check for any of the three base cases and stop splitting if any applies to <span class="No-Break">the dataset.</span></li>
<li>For each feature or attribute of the dataset, calculate the information gained by splitting the dataset on <span class="No-Break">that feature.</span></li>
<li>Create a decision node by splitting the dataset on the feature with the highest <span class="No-Break">information gain.</span></li>
<li>Split the dataset into two sub-datasets based on the decision node and recursively reply to the algorithm on <span class="No-Break">each sub-dataset.</span></li>
</ol>
<p>Once the <a id="_idIndexMarker069"/>tree has been built, pruning is applied. During <a id="_idIndexMarker070"/>pruning, decision nodes with a relatively lower information gain than other tree nodes are removed. Removing nodes avoids overfitting the training data and improves the tree’s <span class="No-Break">generalization ability.</span></p>
<h3>Classification and Regression Tree</h3>
<p>You may have noticed that in the preceding explanations, we only used classes to split datasets <a id="_idIndexMarker071"/>using decision nodes; this is not by chance, as the canonical C4.5 algorithm only supports classification trees. <strong class="bold">Classification and Regression Tree</strong> (<strong class="bold">CART</strong>) extends C4.5 to support numerical target variables – that is, regression problems [2]. With CART, decision nodes can also split continuous numerical input variables to support regression, typically using a threshold (for example, x &lt;= <span class="_-----MathTools-_Math_Number">0.3</span>). When reaching a leaf node, the mean or median of the remaining numerical range is generally taken as the <span class="No-Break">predicted value.</span></p>
<p>When building classification trees, only impurity is used to determine splits. However, with regression trees, impurity is combined with other criteria to calculate <span class="No-Break">optimal splits:</span></p>
<ul>
<li>The MSE (<span class="No-Break">or MAE)</span></li>
<li>Half <span class="No-Break">Poisson Deviance</span></li>
</ul>
<p>A detailed mathematical explanation of each is available <span class="No-Break">at </span><a href="https://scikit-learn.org/stable/modules/tree.xhtml#regression-criteria"><span class="No-Break">https://scikit-learn.org/stable/modules/tree.xhtml#regression-criteria</span></a><span class="No-Break">.</span></p>
<p>scikit-learn uses an optimized version of CART to build <span class="No-Break">decision trees.</span></p>
<h2 id="_idParaDest-31"><a id="_idTextAnchor030"/>Overfitting in decision trees</h2>
<p>One of the most significant disadvantages of decision trees is that they are prone to overfitting. Without proper hyperparameter choices, C4.5 and other training algorithms create overly <a id="_idIndexMarker072"/>complex and deep trees that fit the training data almost exactly. Managing overfitting is a crucial part of building decision trees. Here are some strategies to <span class="No-Break">avoid overfitting:</span></p>
<ul>
<li><strong class="bold">Pruning</strong>: As mentioned previously, we can remove branches that do not contribute much information gain; this reduces the tree’s complexity and <span class="No-Break">improves generalization.</span></li>
<li><strong class="bold">Maximum depth</strong>: Limiting the depth of the tree also avoids overly complex trees and <span class="No-Break">avoids overfitting.</span></li>
<li><strong class="bold">Maximum number of leaf nodes</strong>: Similar to restricting depth, limiting the number of leaf nodes avoids overly specific branches and <span class="No-Break">improves generalization.</span></li>
<li><strong class="bold">Minimum samples per leaf</strong>: Setting a minimum limit on the number of samples a leaf may contain (stopping splitting when the sub-dataset is of the minimum size) also avoids overly specific <span class="No-Break">leaf nodes.</span></li>
<li><strong class="bold">Ensemble methods</strong>: Ensemble learning is a technique that combines multiple models to improve the prediction over an individual model. Averaging the prediction of multiple models can also <span class="No-Break">reduce overfitting.</span></li>
</ul>
<p>These strategies can be applied by setting the appropriate hyperparameters. Now that we understand how to build decision trees and strategies for overfitting, let’s look at building decision trees <span class="No-Break">in scikit-learn.</span></p>
<h2 id="_idParaDest-32"><a id="_idTextAnchor031"/>Building decision trees with scikit-learn</h2>
<p>It is time to examine how we may use decision trees by training classification and regression trees <span class="No-Break">using scikit-learn.</span></p>
<p>For these <a id="_idIndexMarker073"/>examples, we’ll use the toy datasets included in scikit-learn. These datasets are small compared to real-world data but are easy to work with, allowing us to focus on the <span class="No-Break">decision trees.</span></p>
<h3>Classifying breast cancer</h3>
<p>We’ll use <a id="_idIndexMarker074"/>the Breast Cancer dataset (https://scikit-learn.org/stable/datasets/toy_dataset.xhtml#breast-cancer-dataset) for our classification example. This dataset consists of features that have been calculated from the images of fine needle aspirated breast masses, and the task is to predict whether the mass is malignant <span class="No-Break">or benign.</span></p>
<p>Using scikit-learn, we can solve this classification problem with five lines <span class="No-Break">of code:</span></p>
<pre class="source-code">
dataset = datasets.load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, random_state=157)
model = DecisionTreeClassifier(random_state=157, max_depth=3, min_samples_split=2)
model = model.fit(X_train, y_train)
f1_score(y_test, model.predict(X_test))</pre>
<p>First, we load the dataset using <strong class="source-inline">load_breast_cancer</strong>. Then, we split our dataset into training and test sets using <strong class="source-inline">train_test_split</strong>; by default, 25% of the data is used for the test set. Like before, we instantiate our <strong class="source-inline">DecisionTreeClassifier</strong> model and train it on the training set using <strong class="source-inline">model.fit</strong>. The two hyperparameters we pass through when instantiating the model are notable: <strong class="source-inline">max_depth</strong> and <strong class="source-inline">min_samples_split</strong>. Both parameters control overfitting and will be discussed in more detail in the next section. We also specify <strong class="source-inline">random_state</strong> for both the train-test split and the model. By fixing the random state, we ensure the outcome is repeatable (otherwise, a new random state is created by scikit-learn for <span class="No-Break">every execution).</span></p>
<p>Finally, we measure the performance using <strong class="source-inline">f1_score</strong>. Our model achieves an F1 score of <span class="_-----MathTools-_Math_Number">0.94</span> and <a id="_idIndexMarker075"/>an accuracy of 93.7%. F1 scores are out of 1.0, so we may conclude that the model does very well. If we break down our predictions, the model missed the prediction on only 9 of the 143 samples in the test set: 7 false positives and 2 <span class="No-Break">false negatives.</span></p>
<h3>Predicting diabetes progression</h3>
<p>To illustrate solving a regression problem with decision trees, we’ll use the Diabetes dataset (<a href="https://scikit-learn.org/stable/datasets/toy_dataset.xhtml#diabetes-dataset">https://scikit-learn.org/stable/datasets/toy_dataset.xhtml#diabetes-dataset</a>). This dataset has 10 features (age, sex, body mass index, and others), and the model <a id="_idIndexMarker076"/>is tasked with predicting a quantitative measure of disease progression after <span class="No-Break">1 year.</span></p>
<p>We can use the following code to build and evaluate a <span class="No-Break">regression model:</span></p>
<pre class="source-code">
dataset = datasets.load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, random_state=157)
model = DecisionTreeRegressor(random_state=157, max_depth=3, min_samples_split=2)
model = model.fit(X_train, y_train)
mean_absolute_error(y_test, model.predict(X_test))</pre>
<p>Our model achieves an MAE of <span class="_-----MathTools-_Math_Number">45.28</span>. The code is almost identical to our classification example: instead of a classifier, we use <strong class="source-inline">DecisionTreeRegressor</strong> as our model and calculate <strong class="source-inline">mean_absolute_error</strong> instead of the F1 score. The consistency in the API for solving various problems with different types of models in scikit-learn is by design and <a id="_idIndexMarker077"/>illustrates a fundamental truth in machine learning work: even though data, models, and metrics change, <em class="italic">the overall process for building machine learning models remains the same</em>. In the coming chapters, we’ll expand on this general methodology and leverage the process’ consistency when building machine <span class="No-Break">learning pipelines.</span></p>
<h2 id="_idParaDest-33"><a id="_idTextAnchor032"/>Decision tree hyperparameters</h2>
<p>We used some decision tree hyperparameters in the preceding classification and regression <a id="_idIndexMarker078"/>examples to control overfitting. This section will look <a id="_idTextAnchor033"/>at the most critical decision tree hyperparameters provided <span class="No-Break">by scikit-learn:</span></p>
<ul>
<li><strong class="source-inline">max_depth</strong>: The maximum depth the tree is allowed to reach. Deeper trees allow more splits, resulting in more complex trees <span class="No-Break">and overfitting.</span></li>
<li><strong class="source-inline">min_samples_split</strong>: The minimum number of samples required to split a node. Nodes containing only a few samples overfit the data, whereas having a larger minimum <span class="No-Break">improves generalization.</span></li>
<li><strong class="source-inline">min_samples_leaf</strong>: The minimum number of samples allowed in leaf nodes. Like the minimum samples in a split, increasing the value leads to less complex trees, <span class="No-Break">reducing overfitting.</span></li>
<li><strong class="source-inline">max_leaf_nodes</strong>: The maximum number of lead nodes to allow. Fewer leaf nodes reduce the tree size and, therefore, the complexity, which may <span class="No-Break">improve generalization.</span></li>
<li><strong class="source-inline">max_features</strong>: The maximum features to consider when determining a split. Discarding some features reduces noise in the data, which improves overfitting. Features are chosen <span class="No-Break">at random.</span></li>
<li><strong class="source-inline">criterion</strong>: The impurity measure to use when determining a split, either <strong class="source-inline">gini</strong> <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">entropy/log_loss</strong></span><span class="No-Break">.</span></li>
</ul>
<p>As you may have noticed, most decision tree hyperparameters involve controlling overfitting by controlling the complexity of the tree. These parameters provide multiple ways of doing so, and finding the best combination of parameters and their values is non-trivial. Finding <a id="_idIndexMarker079"/>the best hyperparameters is called <strong class="bold">hyperparameter tuning</strong> and will <a id="_idIndexMarker080"/>be covered extensively later in <span class="No-Break">this book.</span></p>
<p>A complete list of the hyperparameters can be found at the <span class="No-Break">following places:</span></p>
<ul>
<li><span class="No-Break">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.xhtml#sklearn-tree-decisiontreeclassifier</span></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.xhtml#sklearn.tree.DecisionTreeRegressor"><span class="No-Break">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.xhtml#sklearn.tree.DecisionTreeRegressor</span></a></li>
</ul>
<p>Now, let’s summarize the key takeaways from <span class="No-Break">this chapter.</span></p>
<h1 id="_idParaDest-34"><a id="_idTextAnchor034"/>Summary</h1>
<p>In this chapter, we introduced machine learning as a method of creating software by learning to perform a task from a corpus of data instead of relying on programming the instructions by hand. We introduced the core concepts of machine learning with a focus on supervised learning and illustrated their applications through examples <span class="No-Break">with scikit-learn.</span></p>
<p>We also introduced decision trees as a machine learning algorithm and discussed their strengths and weaknesses, as well as how to control overfitting using hyperparameters. We concluded this chapter with examples of how to solve classification and regression problems using decision trees <span class="No-Break">in scikit-learn.</span></p>
<p>This chapter has given us a foundational understanding of machine learning, enabling us to dive deeper into the data science process and the <span class="No-Break">LightGBM library.</span></p>
<p>The next chapter will focus on ensemble learning in decision trees, a technique where the predictions of multiple decision trees are combined to improve the overall performance. Boosting, particularly gradient boosting, will be covered <span class="No-Break">in detail.</span></p>
<h1 id="_idParaDest-35"><a id="_idTextAnchor035"/>References</h1>
<table class="No-Table-Style" id="table003">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><em class="italic">[</em><span class="No-Break"><em class="italic">1]</em></span></p>
</td>
<td class="No-Table-Style">
<p><em class="italic">J. R. Quinlan, C4.5: Programs for machine learning, </em><span class="No-Break"><em class="italic">Elsevier, 2014.</em></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><em class="italic">[</em><span class="No-Break"><em class="italic">2]</em></span></p>
</td>
<td class="No-Table-Style">
<p><em class="italic">R. J. Lewis, An introduction to classification and regression tree (CART) analysis, in Annual meeting of the Society For Academic Emergency Medicine in San Francisco, </em><span class="No-Break"><em class="italic">California, 2000.</em></span></p>
</td>
</tr>
</tbody>
</table>
</div>
</div></body></html>