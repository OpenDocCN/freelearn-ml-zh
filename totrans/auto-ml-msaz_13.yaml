- en: '*Chapter 10*: Creating End-to-End AutoML Solutions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have created **machine learning** (**ML**) pipelines, you can learn
    how to use them in other Azure products outside of the **Azure Machine Learning**
    **Service** (**AMLS**). Perhaps the most useful is Azure Data Factory.
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Data Factory** (**ADF**) is Azure''s premier code-free data orchestration
    tool. You can use ADF to pull data from on-premise sources into the Azure cloud,
    to run ML pipelines, and push data out of Azure by creating an **Azure Data Factory
    pipeline** (**ADF pipeline**). ADF pipelines are an integral part of creating
    end-to-end ML solutions and are the end goal of any non-real-time AutoML project.'
  prefs: []
  type: TYPE_NORMAL
- en: You will begin this chapter by learning how to connect AMLS to ADF. Once you
    have accomplished this task, you will learn how to schedule an ML pipeline using
    the parallel pipeline you created in [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129),
    *Implementing a Batch Scoring Solution*.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you will learn how to pull data from your local machine and load it into
    the Azure cloud using ADF. Finally, you will pull everything you have together
    to create an end-to-end AutoML solution, creating an ADF pipeline for scoring
    incoming data, and another ADF pipeline for retraining AutoML models.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to integrate AMLS with ADF to create
    ADF pipelines and be able to fashion complete end-to-end AutoML solutions, from
    ingesting and scoring data, to retraining ML models. This is an invaluable, in-demand
    skillset that will set you apart from your peers.
  prefs: []
  type: TYPE_NORMAL
- en: If you're already a trained data scientist, you will acquire software engineering
    skills that are rare in your field. If you're a trained engineer, you will learn
    how to incorporate ML into a familiar field you already understand.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Connecting AMLS to ADF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scheduling a machine learning pipeline in ADF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transferring data using ADF
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating an end-to-end scoring solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating an end-to-end training solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will create an ADF resource and use the ML pipeline objects
    you created in [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129), *Implementing
    a Batch Scoring Solution*. As such, you will need a working internet connection,
    an Azure account, and access to your AMLS workspace.
  prefs: []
  type: TYPE_NORMAL
- en: With your Azure account, you will also need permissions to create a service
    principal in Azure Active Directory. If you're using a personal Azure account,
    you should have this access. If you're using a work account, speak with your Azure
    administrator for this level of permission.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the prerequisites for the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Have access to the internet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have a web browser, preferably Google Chrome or Microsoft Edge Chromium
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have a Microsoft Azure account
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have created an AMLS workspace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have created the `compute-cluster` compute cluster in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand how to navigate to the Jupyter environment from an Azure compute
    instance as demonstrated in [*Chapter 4*](B16595_04_ePub.xhtml#_idTextAnchor056),
    *Building an AutoML Regression Solution*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have trained and registered the `Iris-Multi-Classification-AutoML` ML model
    in [*Chapter 5*](B16595_05_ePub.xhtml#_idTextAnchor068), *Building an AutoML Classification
    Solution*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have created all three of the ML pipelines in [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129),
    *Implementing a Batch Scoring Solution*. The three ML pipelines are *Iris-Scoring-Pipeline*,
    *Iris-Parallel-Scoring-Pipeline*, and *Iris-AutoML-Training-Pipeline*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have necessary permissions to create service principals in Azure Active Directory.
    If you're using a personal account, you will have these permissions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The code for this chapter is available here: [https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter10](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/tree/master/Chapter10).'
  prefs: []
  type: TYPE_NORMAL
- en: Connecting AMLS to ADF
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ADF is a code-free data orchestration and transformation tool. With it, you
    can create ADF pipelines that can copy data into Azure, transform data, run ML
    pipelines, and push data back onto certain on-premise databases and file shares.
    It's incredibly easy to make and schedule ADF pipelines using ADF's code-free
    pipeline editing tool. As you create an ADF pipeline with the drag and drop interface,
    you're actually writing JSON code, which ADF uses to execute jobs.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Synapse Analytics**, Microsoft Azure''s premier data warehousing and
    integrated analytics service, also has a feature nearly identical to ADF pipelines:
    **Azure Synapse pipelines**. Anything that you do in this chapter with ADF pipelines
    you can also achieve with Azure Synapse pipelines using a very similar interface.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you will create an ADF resource and connect it to AMLS. You
    will do this using a **linked service**, an object similar to a connection string
    that ADF requires to connect to other Azure and non-Azure services and data stores.
    Linked services require authentication, and AMLS requires service principal authentication.
  prefs: []
  type: TYPE_NORMAL
- en: A **service principal** is a security identity that Azure uses to grant permissions
    across Azure resources. Once you grant your service principal access to both ADF
    and AMLS, it's easy to connect them together and start running ML pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an ADF
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An ADF can be created by using the GUI or using Azure PowerShell through the
    Azure **Command Line Interface** (**CLI**) that you used in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*. **PowerShell** is a series
    of cmdlets for managing Azure resources through the CLI. Here, you will first
    learn how to create an ADF resource using the Azure portal GUI. Then, you will
    learn how to create an ADF resource through PowerShell.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create an ADF resource using the GUI, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the Azure portal at [https://portal.azure.com](https://portal.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Create a resource** in the top-left corner.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the search box, type in `Data Factory` and click **Data Factory** from the
    drop-down box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Create**, the blue box in the top-left corner under **Data Factory**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now fill out the **Data Factory creation** form. Begin by selecting the same
    **Resource group** that holds your AMLS workspace. If you used the suggested **Resource
    group** in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023), *Getting Started
    with Azure Machine Learning Service*, this will be **auto-ml-example-resource-group**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the same Azure **Region** that holds your AMLS workspace. If you used
    the suggested Azure **Region** in [*Chapter 2*](B16595_02_ePub.xhtml#_idTextAnchor023),
    *Getting Started with Azure Machine Learning Service*, this will be **North Central
    US**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give your ADF a name in the `automl-adf` followed by a number string. The following
    screenshot shows what your completed settings should look like. Leave **Version**
    as **V2**:![Figure 10.1 – Data factory settings](img/Figure_10.1_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.1 – Data factory settings
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **Git configuration** tab and check the **Configure Git later** box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Review + create** and hit **Create**. Your data factory is now created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Another way to create an ADF resource is through PowerShell. Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the Azure portal at [https://portal.azure.com](https://portal.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the computer screen icon at the top right of your screen as shown in the
    following screenshot. When you hover over the icon, the words **Cloud Shell**
    will appear:![Figure 10.2 – Navigating to PowerShell ](img/Figure_10.2_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.2 – Navigating to PowerShell
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select **PowerShell** from the drop-down box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`ResourceGroupName` sets your resource group. `Set-AzDataFactoryV2` sets your
    version, while `location` sets your Azure region. `Name` gives your ADF a name.
    Your data factory has now been created.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now that you have created an ADF, the next step is to create a service principal
    and give it access to both your ADF and AMLS workspace. This will grant ADF access
    to use ML pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a service principal and granting access
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Service principals are security identities that Azure uses to grant Azure resources
    access to other Azure resources. You can use service principal authentication
    across many areas of Azure, including AMLS. In order to connect AMLS to ADF, however,
    a service principal is required. To create one using the Azure portal, you must
    first navigate to **Azure Active Directory**, Azure''s premier identity and authentication
    service, by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the Azure portal at [https://portal.azure.com](https://portal.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Search for `Azure Active Directory` in the top search bar and click **Azure
    Active Directory** under the **Services** heading.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **App registrations** on the left-hand side of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **New registration** at the top left of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give the service principal a name, `adf-service-principal`, and click **Register**.
    Leave all other settings as is.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will now be taken to a page with all of the information about your service
    principal. Copy **Application (client) ID** and paste it in Notepad or a similar
    text editor. You will need this ID later.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Certificates & secrets** on the left-hand side of the screen. This will
    let you create a password for your service principal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **New client secret**. *Secret* is another word for a password in Azure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give the secret a name, `ADF-Secret`, and set it so that it never expires as
    shown in *Figure 10.3*. Click **Add**:![Figure 10.3 – Naming your service principal
    secret ](img/Figure_10.3_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.3 – Naming your service principal secret
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Copy the **Value** field of your secret. This is your password and you will
    only be able to see it for a short time before it disappears. Once it vanishes,
    you will never be able to see it again. Paste it into Notepad or a similar text
    editor, as you will need it later when creating your ADF linked service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With your service principal created, you must now grant it access to both AMLS
    and ADF. Navigate to the front page of the Azure portal at [https://portal.azure.com](https://portal.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open your AMLS resource by clicking the **Machine Learning** icon near the top
    of your screen under **Azure Services**. You should see it if you have recently
    used AMLS, as shown in *Figure 10.4*:![Figure 10.4 – Azure services panel ](img/Figure_10.4_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.4 – Azure services panel
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the name of your AMLS workspace to access the resource.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Access Control (IAM)** on the left-hand panel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Add role assignments**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select `adf-service-principal` and click it as shown in *Figure 10.5*. Then,
    click **Save**:![Figure 10.5 – Granting permission to your service principal ](img/Figure_10.5_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.5 – Granting permission to your service principal
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have now granted your service principal access to AMLS. Now, you must do
    the same thing for ADF. Begin by navigating to the front page of the Azure portal
    by clicking **Home** in the top-left corner of your screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Data factories** icon at the top of your screen under **Azure Services**.
    If you have used ADF lately, you will see this icon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the name of the data factory you made to open up the resource.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat *steps 14-16* for ADF. These steps are identical to AMLS. You have now
    granted your service principal access to both ADF and AMLS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating an ADF resource through the Azure CLI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can also create a service principal and grant it access to ADF and AMLS
    through the Azure CLI with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up the Azure CLI by clicking the computer screen icon at the top right
    of your screen and select **Bash** from the drop-down menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Type in the following code to create your service principal, assigning it a
    name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Copy both the `appid` and `password` fields. You will never see the value for
    your password again, so make sure to copy it. This maps to **Application (client)
    ID** and the secret.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the following code to grant your service principal access to all resources
    in the resource group containing both AMLS and ADF. Change to match your resource
    group if necessary. Use `assignee` to pass in your service principal application
    ID. Use `role` to pass in the correct level of access, in this case, `resource-group`
    to assign access to the correct **Resource group**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With your service principal created and granted access to the appropriate resources,
    your next step is to open ADF and create the linked service. Make sure you have
    Notepad open as you will need both the service principal ID as well as the secret
    you created. Having these readily available will make the next set of steps easy.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a linked service to connect ADF with AMLS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Moving forward, now you''ll get a chance to open up ADF and get used to its
    interface. ADF is designed largely as a code-free platform, but everything you
    create is also written as JSON files under the hood. To link ADF with AMLS, follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the Azure portal at [https://portal.azure.com](https://portal.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Data factories** icon at the top of your screen under **Azure Services**.
    If you have used ADF lately, you will see this icon. If not, use the search bar
    at the top of your screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the name of the data factory you made that starts with the name `autol-adf`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Author & Monitor** in the middle of the screen. You should now see the
    ADF user interface, shown in *Figure 10.6*:![Figure 10.6 – ADF UI ](img/Figure_10.6_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.6 – ADF UI
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the toolbox icon on the left-hand side. When you hover over the icon for
    a few seconds, the word **Manage** will appear to indicate the section you're
    navigating to.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Linked Services** under **Connections** in the top-left corner.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Create linked service**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Compute** and select **Azure Machine Learning** as shown in *Figure
    10.7*:![Figure 10.7 – Create an Azure ML linked service ](img/Figure_10.7_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.7 – Create an Azure ML linked service
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Continue**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now it's time to fill out the linked service creation form. Begin by giving
    your linked service a name such as `AMLS Linked Service`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **AutoResolveIntegrationRuntime** from the dropdown under **Connect via
    integration runtime**. An **integration runtime** is simply the compute that ADF
    uses under the hood to move data and run your jobs. The **Azure integration runtime**
    (**Azure IR**) is a serverless, elastic compute fully managed by ADF.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select your Azure subscription from the drop-down box under **Azure subscription**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select your AMLS workspace from the drop-down box under **Azure Machine Learning
    workspace name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste your service principal application (client) ID into the **Service principal
    ID** textbox. You copied this ID into a text editor earlier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste your service principal secret into the **Service principal key** textbox.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Test connection**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the result of the test is **Connection successful**, click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your linked service has been created. Hover over your new linked service and
    click the **{ }** icon to view the underlying JSON code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You have successfully connected your ADF to AMLS. In this short section, you
    have learned a lot. Not only have you learned how to create an ADF, but you have
    also learned how to create service principals, grant access, and create linked
    services. With this infrastructure created, you can now learn how to easily run
    and schedule ML pipelines inside of an ADF pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling a machine learning pipeline in ADF
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Perhaps ADF's best feature is its ease of use. By clicking and dragging objects
    across a screen, you can easily orchestrate a flow of seamless data ingestion,
    transformation, and ML through an ADF pipeline. Moreover, with a few more clicks,
    you can schedule that ADF pipeline to run whenever you want. Gaining this skill
    will enable you to create code-free data orchestration runs quickly and easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you will schedule and run the simplest ML pipeline you created in [*Chapter
    9*](B16595_09_ePub.xhtml#_idTextAnchor129), *Implementing a Batch Scoring Solution*,
    the `Iris-Scoring-Pipeline`. To do so, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to your ADF resource and click **Author & Monitor**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the pen icon on the left-hand side. When you hover over this icon, the
    word **Author** will appear to indicate which section you're navigating to.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the blue cross icon next to the search box under **Factory Resources**
    in the top-left corner. When you hover over this icon, the words **Add new resource**
    will appear.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Pipeline** from the resulting dropdown as shown in *Figure 10.8*:![Figure
    10.8 – Creating your first ADF pipeline ](img/Figure_10.8_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.8 – Creating your first ADF pipeline
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Machine Learning** under **Activities** in the center-left of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click and drag the blue flask icon onto the canvas as shown in *Figure 10.9*.
    This is the **Machine Learning Executive Pipeline** activity:![Figure 10.9 – Machine
    Learning Execute Pipeline activity ](img/Figure_10.9_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.9 – Machine Learning Execute Pipeline activity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click `Execute Iris Scoring Pipeline`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Settings** underneath the canvas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **AMLS Linked Service** from the first drop-down box to connect your
    linked service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Iris-Scoring-Pipeline** from the **Machine Learning pipeline name**
    drop-down box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select a pipeline ID from the **Machine Learning pipeline ID** drop-down box.
    There should only be one pipeline ID unless you published multiple ML pipelines
    with the same name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the abacus icon in the top right-hand corner to open the `pipeline1` to
    `Iris Scoring Pipeline`. Spaces are allowed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Publish All** near the top left of your screen. Then, click **Publish**
    in the bottom right-hand corner to create your ADF pipeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important tip
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In order to save your work in ADF, you need to publish your changes. Make sure
    you publish multiple times as you're developing new ADF pipelines.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To schedule your newly created ADF pipeline, click **Add trigger** near the
    top of your screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **New/Edit** from the resulting dropdown.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Choose Trigger** dropdown and select **+ New**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Like the AML Python SDK, there are multiple types of triggers within ADF. Execute
    **schedule-based triggers** on a timetable. Execute **event-based triggers** when
    a file is created or deleted in an Azure blob container.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Tumbling window triggers** are similar to schedule-based triggers, but they
    are more advanced and have options such as retrying failed runs and backfilling
    past time periods. For this exercise, create a simple schedule-based trigger.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Give your trigger a name such as `Once Monthly`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Schedule** under **Type**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pick a start date and the appropriate time zone from the respective drop-down
    boxes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under `1` and select **Month** from the drop-down box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **OK** twice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click **Publish All** near the top left of your screen, followed by **Publish**
    in the bottom right-hand corner. You are now finished. Your completed ADF pipeline
    should look something like *Figure 10.10*. To see the JSON code, click the **{
    }** icon at the top right-hand side of your screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Your first completed ADF pipeline ](img/Figure_10.10_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.10 – Your first completed ADF pipeline
  prefs: []
  type: TYPE_NORMAL
- en: While you have created and scheduled your first ADF pipeline, it does not mean
    much. After all, while this ADF pipeline will trigger your ML pipeline on a monthly
    basis, you still need to automate the ingestion of new data. Thankfully, data
    ingestion is where ADF excels. You will see just how easy transferring data is
    using ADF in the next section. No matter where the data lies, ADF can pull it
    in.
  prefs: []
  type: TYPE_NORMAL
- en: Transferring data using ADF
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Moving data from on-premise to the cloud and from the cloud to on-premise is
    a key skill for any data engineer or data scientist. ADF accomplishes this task
    with the **Copy data** activity. This is ADF's most basic and most powerful function.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, first, you will download a **self-hosted integration runtime**
    (**SHIR**) to your local machine, allowing your computer to serve as a compute
    resource to load data into Azure. Then, you will create a linked service for your
    **Azure storage account** and your local PC.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you will download a file from the GitHub repository and save it to your
    PC. Finally, you will create a **Copy data** activity in ADF that will take data
    from your PC and put it into the same Azure blob container that's connected to
    your AML datastore.
  prefs: []
  type: TYPE_NORMAL
- en: Going through these exercises will give you the data engineering skills that
    will allow you to create an end-to-end solution in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Installing a self-hosted integration runtime
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before you can copy data into Azure, you first need to install a SHIR on your
    local machine. Begin with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to your ADF resource and click **Author & Monitor**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the toolbox icon on the left-hand side. When you hover over this icon,
    the word **Manage** will appear to indicate which section you're navigating to.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Integration runtimes** under **Connections**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **+New** at the top center of your screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Azure, Self-Hosted** and click **Continue** as shown in *Figure 10.11*:![Figure
    10.11 – Selecting the right integration runtime to install a SHIR ](img/Figure_10.11_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.11 – Selecting the right integration runtime to install a SHIR
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select **Self-Hosted** and click **Continue**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give your new SHIR a name, `IntegrationRuntime`, and click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the next screen, you will see two options to install the SHIR. Choose **Option
    1: Express setup** by clicking **Click here to launch the express setup for this
    computer**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you are using your work machine, ask your IT security organization for permission
    before installing the SHIR. It does open up a connection between your machine
    and the public-facing Azure cloud.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This will download the SHIR installation file to your compute. Open the file
    and click **Yes**. Installation should take between 5 and 10 minutes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the installation is finished, click **Close**. Your SHIR should now appear
    as shown in *Figure 10.12*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Self-hosted integration runtime ](img/Figure_10.12_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.12 – Self-hosted integration runtime
  prefs: []
  type: TYPE_NORMAL
- en: With an SHIR installed on your local machine, you're now able to move data from
    your PC directly into Azure using ADF. Just as you created a linked service for
    AMLS, next you will create a linked service for Azure Blob storage.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Azure Blob storage linked service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create a linked service connecting ADF to **Azure Blob storage**, follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click **Linked services** under **Connections** in the top-left corner of your
    screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **+New** at the top center of your screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Azure Blob Storage** and click **Continue** to see the linked service
    creation form.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give your linked service a name such as `AMLSDatastoreLink`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **AutoResolveIntegrationRuntime**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select your Azure subscription from the drop-down box under **Azure subscription**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select your storage account from the drop-down box under `automlexamplew` followed
    by a string of numbers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Test connection**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If your test was successful, click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Download `Iris_Scoring_Data_for_ADF.csv` from the GitHub repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Chapter10/Iris_Scoring_Data_for_ADF.csv](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Chapter10/Iris_Scoring_Data_for_ADF.csv)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a folder on your PC called `Iris`. Move `Iris_Scoring_Data_for_ADF.csv`
    there.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating a linked service to your PC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, it''s time to create a linked service to your PC. This linked service
    will make use of your SHIR. Use the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click **Linked Services** and **+New** as you did to create the other linked
    services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **File**, select **File System**, and click **Continue** to see the linked
    service creation form.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give your linked service a name such as `LocalPCLink`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select your SHIR from the drop-down box under **Connect via integration runtime**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under `Iris` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill in the username and password that you use to log into your PC. To find
    your username, search for **System Information** in your PC's search bar and click
    it; your user name can be found under **System Summary**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Test connection**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If your test was successful, click **Create**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating an ADF pipeline to copy data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With an SHIR, Azure Blob storage linked service, and a linked service connecting
    to your local PC, you are now ready to build an ADF pipeline using the **Copy
    data** activity with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click the pen icon on the left-hand side of your ADF.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the blue cross icon next to the search box under **Factory Resources**
    in the top-left corner. When you hover over this icon, the words **Add new resource**
    will appear.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Copy Data tool** from the resulting dropdown as shown in *Figure 10.13*:![Figure
    10.13 – Copy Data tool ](img/Figure_10.13_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.13 – Copy Data tool
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Under `Copy Iris Data to Azure` and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You now have to select your source datastore. Select the linked service to your
    PC, **LocalPCLink**, and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the data you wish to transfer into Azure by clicking `Iris_Scoring_Data_for_ADF.csv`,
    and clicking **Choose**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **File format settings**, check the box for **First row as header** and
    click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You now have to select your destination datastore. Select the linked service
    to your Azure storage account, **AMLSDatastoreLink**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under `Input_Folder/Iris_Scoring_Data.csv` and click `Iris_Scoring_Data.csv`
    in a folder called `Input_Folder`. The folder will be created if it does not exist.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **File format settings**, check the box for **Add header to file** and
    click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next** under **Settings** without changing any of the defaults.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next** under **Summary**. Your ADF pipeline will now be created and
    run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Finish**. You will now be transported to the main ADF pipeline authoring
    tool.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click `Copy Iris Data to Azure` under **Pipelines**. You will notice that your
    **Copy data** activity will be poorly named.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click your activity and rename it `Copy Iris Data from PC` as shown in *Figure
    10.14*:![Figure 10.14 – Finished ADF pipeline with the Copy data activity ](img/Figure_10.14_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.14 – Finished ADF pipeline with the Copy data activity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Save your change to the pipeline by clicking **Publish All** and then **Publish**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You have now successfully transferred data from your PC into Azure using ADF.
    This is a foundational skill for data engineering and allows you to transfer all
    sorts of data into the cloud. Like the ADF pipeline you created in the previous
    section for executing ML pipelines, you can schedule this to run on any time schedule
    you wish.
  prefs: []
  type: TYPE_NORMAL
- en: We are now going to bring together all of the skills you have learned in this
    chapter to write a truly productionalizable ADF pipeline. This pipeline will ingest
    data from your computer, score it, and then write results back to your local machine.
    Even though it's not a trivial task by any means, you will be able to churn out
    pipeline after pipeline by the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Automating an end-to-end scoring solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ultimately, the end goal of any AutoML project is to create an automated scoring
    solution. Data gets pulled in from a source, scored automatically using the model
    you trained, and the results get stored in a location of your choice. By combining
    everything you've learned in the previous three sections, you can accomplish this
    task easily.
  prefs: []
  type: TYPE_NORMAL
- en: You will begin this section by opening up AMLS, creating a new dataset, and
    slightly altering your existing `Iris-Scoring-Pipeline`. Then, after republishing
    your pipeline with a new name, you will combine it with the **Copy data** activity
    you created to load data into Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you will create another Copy Data activity to transfer your results from
    Azure to your PC and schedule the job to run once a week on Mondays. This is a
    very common pattern in ML, and it's one you can accomplish without any code at
    all using ADF.
  prefs: []
  type: TYPE_NORMAL
- en: Editing an ML pipeline to score new data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, you need to create a new ML pipeline by editing `Iris-Scoring-Pipeline`
    you created in [*Chapter 9*](B16595_09_ePub.xhtml#_idTextAnchor129), *Implementing
    a Batch Scoring Solution*, with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Access your AML studio at [https://ml.azure.com](https://ml.azure.com).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the GUI to create a new dataset as you did in [*Chapter 3*](B16595_03_ePub.xhtml#_idTextAnchor044),
    *Training Your First AutoML Model*. Begin by clicking **Datasets** under **Assets**
    on the left-hand panel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After clicking `Iris Local Scoring Data`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select `Iris_Data.csv` in `Input_Folder`. This is the data you copied over from
    your PC.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finish creating the dataset, making sure to set the option under the **Column
    headers** dropdown to **Use headers from the first file** in order to pull in
    column names.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With your dataset created, navigate to your `machine-learning-pipeline` Python
    notebook in Jupyter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **File** at the top left and select **Make a Copy** from the drop-down
    box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename your copied notebook to `machine-learning-pipeline-local-scoring`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete the cells that make `Iris` data and register it as a dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Rename your Python script from `Iris_Scoring.py` to `Iris_Scoring_Local.py`
    in the first line of your script that writes the file as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In `Iris_Scoring_Local.py`, retrieve your `Iris Local Scoring Data` dataset
    instead of the `Iris Scoring` dataset as shown in the following line of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When configuring your ML pipeline step, replace `Iris_Scoring.py` with `Iris_Scoring_Local.py`
    as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In `Iris_Scoring_Local.py`, retrieve your `Iris Local Scoring Data` dataset
    instead of the `Iris Scoring` dataset in the following line of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Rename your published pipeline from `Iris-Scoring-Pipeline` to `Iris-Local-Scoring-Pipeline`
    in the following lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run all cells in your notebook to create your new ML pipeline, `Iris-Local-Scoring-Pipeline`.
    This will take a few minutes. You have now created an ML pipeline that scores
    data loaded into Azure from your PC.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating an ADF pipeline to run your ML pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With a new ML pipeline created, you are now ready to create a new ADF pipeline
    that automates the end-to-end scoring process using these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up ADF and click the pen icon on the left-hand side to open the ADF pipeline
    authoring tool.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click `Copy Iris Data to Azure` and select **Clone** from the drop-down box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename your new pipeline to `End-to-End Iris Scoring`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click `Copy Iris Data from PC` activity by clicking the green square, holding
    your mouse button so an arrow appears, and connecting the arrow to your **Machine
    Learning Execute Pipeline** activity as shown in *Figure 10.15*:![Figure 10.15
    – Connecting activities in an ADF pipeline](img/Figure_10.15_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.15 – Connecting activities in an ADF pipeline
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Configure your `Score Iris Data` by selecting the activity and opening the `Iris-Scoring-Local-Pipeline`
    and select the only **Machine Learning pipeline ID** that appears in the drop-down
    box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Publish All** and **Publish** to save your work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Move & transform** under **Activities** and drag a new Copy Data activity
    onto your canvas. Connect it to the end of your ADF pipeline.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After selecting the new activity, click `Copy Results to PC`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Source** and click **+New** to begin the creation of a new input data
    file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Azure Blob Storage** as your source destination and **DelimitedText**
    as your file format. Click **Continue**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill out the ADF dataset creation form. Name this object `ScoringResults`. Select
    `Iris_Predictions.csv` in `Output_Folder` on your AML datastore. When finished,
    the form should match *Figure 10.16*. Click **OK**:![Figure 10.16 – ADF dataset
    creation form ](img/Figure_10.16_B16595.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Figure 10.16 – ADF dataset creation form
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Sink** and click **+New** to begin the creation of a new output data
    file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Azure Blob Storage** as your source destination and **DelimitedText**
    as your file format. Click **Continue**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **File,** select **File system**, and click **Continue**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **DelimitedText** as your file format. Click **Continue**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill out the ADF dataset creation form. Name this object `ScoringLocalOutput`.
    Select **LocalPCLink** as your linked service. Check the box for **First row as
    header**. Click **OK**. This will save your file in the same folder on your PC
    as your input data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Sink** and click **Open**. This will open a new tab where you can edit
    the destination data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edit `Iris_Scoring_Results.csv` as the filename.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Publish All** and **Publish** to save your work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adding a trigger to your ADF pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The last step in creating an ADF pipeline is adding a trigger to automate pipeline
    runs:'
  prefs: []
  type: TYPE_NORMAL
- en: Next, add a trigger as you did earlier in the chapter. Click **Add trigger**
    and select **New/Edit**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Choose trigger** and select **+New**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name your trigger `Monday Trigger` and set it to run once a week on Mondays
    at 11:00 A.M. Make sure you set your time zone to your local time zone. Click
    **OK** twice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click **Publish All** and **Publish** to save your work. Test your new ADF
    pipeline by clicking **Trigger (1)** and **Trigger Now**. Your pipeline should
    run successfully as shown in *Figure 10.17*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.17 – Successful end-to-end scoring pipeline ](img/Figure_10.17_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.17 – Successful end-to-end scoring pipeline
  prefs: []
  type: TYPE_NORMAL
- en: You have now created a fully automated AutoML scoring solution that will pull
    in data from your local PC every Monday at 11:00 A.M. and produce a scoring file.
    In a real situation, this solution would pull data from a database that gets updated
    on a routine basis.
  prefs: []
  type: TYPE_NORMAL
- en: This technique is applicable to any ML project; you can use custom trained models,
    vision models, AutoML models, or any other type of ML model. This pattern is reusable
    for any batch scoring scenario, and it is the most common deployment scenario
    across all industries. Practice it.
  prefs: []
  type: TYPE_NORMAL
- en: With an automated scoring solution in your toolkit, your final task is to craft
    an automated training solution. ML models, for many reasons, often need to be
    retrained and should be retrained when new data becomes available. By using the
    same techniques and patterns you used in this section, this will be an easy task.
  prefs: []
  type: TYPE_NORMAL
- en: Automating an end-to-end training solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Like any other ML model, once an AutoML model is deployed and runs for a few
    months, it can benefit from being retrained. There are many reasons for this,
    in order of importance:'
  prefs: []
  type: TYPE_NORMAL
- en: ML models break if the pattern between your input data and target column changes.
    This often happens due to extraneous factors such as changes in consumer behavior.
    When the pattern breaks, you need to retrain your model to retain performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML models perform better the more relevant data you feed them. Therefore, as
    your data grows, you should periodically retrain models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retraining models on a consistent basis means that they're less likely to break
    if patterns change slowly over time. Consequently, it's best practice to retrain
    as data is acquired.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, you are going to put your skills to the test. You will be given
    a set of instructions similar to when you created an end-to-end scoring solution.
    However, this time, there will be significantly less guidance. If you find yourself
    lost, carefully reread the instructions throughout this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a pipeline to copy data into Azure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, you need to create an ADF pipeline to copy data from your PC into Azure:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download `Iris_Training_Data_for_ADF.csv` from the GitHub repository and put
    it in your `Iris` folder on your PC:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Chapter10/Iris_Training_Data_for_ADF.csv](https://github.com/PacktPublishing/Automated-Machine-Learning-with-Microsoft-Azure/blob/master/Chapter10/Iris_Training_Data_for_ADF.csv)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a new ADF pipeline called `End-to-End Iris Training`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Within the pipeline, create a `Copy Iris Training Data from PC` where you copy
    `Iris_Training_Data_for_ADF.csv` into `Input_Folder` on your Azure storage account.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Refer to the `Copy Iris Data from PC` activity you created in the *Automating
    an end-to-end scoring solution* section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run this pipeline once to move data into Azure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Editing an ML pipeline to train with new data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, copy and edit the `automl-training-pipeline` you created in [*Chapter
    9*](B16595_09_ePub.xhtml#_idTextAnchor129), *Implementing a Batch Scoring Solution*:'
  prefs: []
  type: TYPE_NORMAL
- en: Open AMLS and create a new dataset called `Iris Local Training Data`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open your Jupyter notebook called `automl-training-pipeline`. Make a copy and
    rename it `automl-local-training-pipeline`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replace the `Iris Training` dataset with the `Iris Local Training Data` dataset
    within the ML pipeline. Run and publish the ML pipeline with the name `Iris-AutoML-Training-Local-Pipeline`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adding a Machine Learning Execute Pipeline activity to your ADF pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, you''ll add an activity to your ADF pipeline to execute the ML pipeline
    you just created as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: In ADF, add a `Retrain Iris Model`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a trigger called `Tuesday Trigger` to your **End-to-End Iris Training**
    pipeline. Schedule this trigger to run every Tuesday at 6:00 A.M. local time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Publish your changes to save your work. Your finished pipeline should be a
    two-step process resembling *Figure 10.18*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.18 – Completed retraining pipeline ](img/Figure_10.18_B16595.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.18 – Completed retraining pipeline
  prefs: []
  type: TYPE_NORMAL
- en: That's it! You've created a solution that will automatically retrain models
    on a weekly basis with new data. In the real world, this would be pulling from
    a database that is routinely updated instead of from your local PC.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that your ML pipeline for training automatically registers models,
    and your ML pipeline for scoring automatically reuses the latest version of your
    ML model. As such, there's no need to manually update either of the pipelines
    from this point on.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Automating ML solutions in an end-to-end fashion is no easy task and if you've
    made it this far, feel proud. Most modern data science organizations can easily
    train models. Very few can implement reliable, automated, end-to-end solutions
    as you have done in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: You should now feel confident in your ability to design end-to-end AutoML solutions.
    You can train models with AutoML and create ML pipelines to score data and retrain
    models. You can easily ingest data into Azure and transfer it out of Azure with
    ADF. Furthermore, you can tie everything together and create ADF pipelines that
    seamlessly ingest data, score data, train data, and push results to wherever you'd
    like. You can now create end-to-end ML solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B16595_11_ePub.xhtml#_idTextAnchor172), *Implementing a Real-Time
    Scoring Solution*, will cement your ML knowledge by teaching you how to score
    data in real time using Azure Kubernetes Service within AMLS. Adding real-time
    scoring to your batch-scoring skillset will make you a more complete applied ML
    expert, able to tackle a wide variety of problems.'
  prefs: []
  type: TYPE_NORMAL
