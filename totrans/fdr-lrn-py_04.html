<html><head></head><body>
		<div id="_idContainer043">
			<h1 id="_idParaDest-81" class="chapter-number"><a id="_idTextAnchor085"/>4</h1>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor086"/>Federated Learning Server Implementation with Python</h1>
			<p>The server-side implementation of a <strong class="bold">federated learning</strong> (<strong class="bold">FL</strong>) system is critical for realizing authentic FL-enabled applications. We have discussed the basic system architecture and flow in the previous chapter. In this chapter, more hands-on implementation will be discussed so that you can create a simple server and aggregator of the FL system that various <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) applications can be connected to and tested on. </p>
			<p>This chapter describes an actual implementation aspect of FL server-side components discussed in <a href="B18369_03.xhtml#_idTextAnchor058"><em class="italic">Chapter 3</em></a>, <em class="italic">Workings of the Federated Learning System</em>. Based on the understanding of how the entire process of the FL system works, you will be able to go one step further to make it happen with example code provided here and on GitHub. Once you understand the basic implementation principles using the example code, it is a fun aspect to be able enhance the FL server functionalities based on your own design.</p>
			<p>In this chapter, we’re going to cover the following topics:</p>
			<ul>
				<li>Main software components of the aggregator</li>
				<li>Implementing FL server-side functionalities</li>
				<li>Maintaining models for aggregation with the state manager</li>
				<li>Aggregating local models</li>
				<li>Running the FL server</li>
				<li>Implementing and running the database server</li>
				<li>Potential enhancements to the FL server</li>
			</ul>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor087"/>Technical requirements</h1>
			<p>All the code files introduced in this chapter can be found on GitHub here: <a href="https://github.com/tie-set/simple-fl">https://github.com/tie-set/simple-fl</a>. </p>
			<p class="callout-heading">Important note</p>
			<p class="callout">You can use the code files for personal or educational purposes. However, please note that we will not support deployments for commercial use and will not be responsible for any errors, issues, or damages caused by using the code.</p>
			<h1 id="_idParaDest-84"><a id="_idTextAnchor088"/>Main software components of the aggregator  and database</h1>
			<p>The architecture <a id="_idIndexMarker264"/>of an aggregator with the FL server was introduced in the previous chapter. Here, we will introduce the code that realizes the basic functionalities of an FL system. The aggregator and database-side Python-based software components are listed in the <strong class="source-inline">aggregator</strong> directory of <strong class="source-inline">fl_main</strong>, as well as <strong class="source-inline">lib/util</strong> and <strong class="source-inline">pseudodb</strong> folders, as in <em class="italic">Figure 4.1</em>:</p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B18369_04_01.jpg" alt="Figure 4.1 – Python software components for the aggregator as well as internal libraries and pseudo database &#13;&#10;"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – Python software components for the aggregator as well as internal libraries and pseudo database </p>
			<p>The following is a brief description of the Python code files in the aggregator.</p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor089"/>Aggregator-side codes</h2>
			<p>In this section, we<a id="_idIndexMarker265"/> will touch on the<a id="_idIndexMarker266"/> main Python files of the aggregator-side related to the FL server thread, FL state manager, and model aggregation itself. These aggregator-side code files are found in the <strong class="source-inline">aggregator</strong> folder. The code in the repo only captures the model aggregation perspective, not the entire engineering aspects of creating a thorough FL platform.</p>
			<h3>FL server code (server_th.py)</h3>
			<p>This is the <a id="_idIndexMarker267"/>main code that realizes <a id="_idIndexMarker268"/>the whole basic flow of the FL process from the communication processes between an aggregator itself, agents, and a database to coordinating agent participation and the aggregation of the ML models. It also initializes the global cluster model sent from the first connected agent. It manages receiving local models and the cluster model synthesis routine in which the cluster global model is formed after collecting enough local models.</p>
			<h3>FL state manager (state_manager.py)</h3>
			<p>The state <a id="_idIndexMarker269"/>manager <a id="_idIndexMarker270"/>buffers the local model and cluster model data that is needed for aggregation processes. The buffers will be filled out when the aggregator receives local models from the agents and cleared when proceeding to the next round of the FL process. The checking function of the aggregation criteria is also defined in this file.</p>
			<h3>Aggregation code (aggregation.py)</h3>
			<p>The <a id="_idIndexMarker271"/>aggregation<a id="_idIndexMarker272"/> Python code will list the basic algorithms for aggregating the model. In the code example used here in this chapter, we will only introduce the averaging method called <strong class="bold">federated averaging</strong> (<strong class="bold">FedAvg</strong>), which<a id="_idIndexMarker273"/> averages the weights of the collected local models considering local dataset sizes to generate a cluster global model.</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor090"/>lib/util codes </h2>
			<p>The Python<a id="_idIndexMarker274"/> files for the internal <a id="_idIndexMarker275"/>libraries (<strong class="source-inline">communication_handler.py</strong>, <strong class="source-inline">data_struc.py</strong>, <strong class="source-inline">helpers.py</strong>, <strong class="source-inline">messengers.py</strong>, and <strong class="source-inline">states.py</strong>) will be explained in the <em class="italic">Appendix</em>, <em class="italic">Exploring Internal Libraries</em>.</p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor091"/>Database-side code</h2>
			<p>Database-side code consists of the pseudo database and the SQLite database Python code files that can be found in the <strong class="source-inline">pseudodb</strong> folder. The pseudo database code is hosting a server to receive messages from the aggregator and purse them to process as the ML model data that can be utilized for the FL process.</p>
			<h3>Pseudo database code (pseudo_db.py)</h3>
			<p>The function of pseudo database Python code is to accept the messages related to the local and global cluster models from the aggregator and push the information to the database. It also saves the ML model binary files in the local file system.</p>
			<h3>SQLite database code (sqlite_db.py)</h3>
			<p>The SQLite database Python code creates an actual SQLite database at the specified path. It also has the function to insert data entries related to the local and global cluster models into the database.</p>
			<p>Now that the aggregator and database-side software components are defined, let's move on to the configuration of the aggregator.</p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor092"/>Toward the configuration of the aggregator</h2>
			<p>The following <a id="_idIndexMarker276"/>code is an example of the aggregator-side configuration parameters defined in the <strong class="source-inline">config_aggregator.json</strong> file, which can be found in the <strong class="source-inline">setups</strong> folder:</p>
			<pre class="source-code">
{
    "aggr_ip": "localhost",
    "db_ip": "localhost",
    "reg_socket": "8765",
    "exch_socket": "7890",
    "recv_socket": "4321",
    "db_socket": "9017",
    "round_interval": 5,
    "aggregation_threshold": 1.0,
    "polling": 1
}</pre>
			<p>The parameters include the aggregator’s IP (the FL server’s IP), the database server’s IP, and the various port numbers of the database and agents. The round interval is the time of the interval at which the criteria of aggregation are checked and the aggregation threshold defines the percentage of collected local ML models needed to start the aggregation process. The polling flag is related to whether to utilize the <strong class="source-inline">polling</strong> method for communications between the aggregator and agents or not.</p>
			<p>Now that we have covered the concept of the configuration file for the aggregator side, let’s move on to how the code is designed and implemented.</p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor093"/>Implementing FL server-side functionalities</h1>
			<p>In this section, we <a id="_idIndexMarker277"/>will explain how you can implement the very first version of an aggregator with an FL server system using the actual code examples, which are in <strong class="source-inline">server_th.py</strong> in the <strong class="source-inline">aggregator</strong> directory. In this way, you will understand the core functionalities of the FL server system and how they are implemented so that you can further enhance a lot more functionalities on your own. Therefore, we will only cover the important and core functionalities that are critical to conducting a simple FL process. The potential enhancements will be listed in the later section of this chapter, <em class="italic">Potential enhancements to the FL server</em>.</p>
			<p><strong class="source-inline">server_th.py</strong> handles all the aspects of basic functionalities related to the FL server side, so let’s look into that in the following section. </p>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor094"/>Importing libraries for the FL server</h2>
			<p>The FL server-side<a id="_idIndexMarker278"/> code starts with importing the necessary libraries. In particular, <strong class="source-inline">lib.util</strong> handles the basic supporting functionalities to make the implementation of FL easy. The details of the code can be found in the GitHub repository.</p>
			<p>The server code imports <strong class="source-inline">StateManager</strong> and <strong class="source-inline">Aggregator</strong> for the FL processes. The code about the state manager and aggregation will be discussed in later sections in this chapter about <em class="italic">Maintaining models for aggregation with the state manager </em>and<em class="italic"> Aggregating local models. </em></p>
			<p>Here is the code for importing the necessary libraries:</p>
			<pre class="source-code">
import asyncio, logging, time, numpy as np
from typing import List, Dict, Any
from fl_main.lib.util.communication_handler import init_fl_server, send, send_websocket, receive 
from fl_main.lib.util.data_struc import convert_LDict_to_Dict
from fl_main.lib.util.helpers import read_config, set_config_file
from fl_main.lib.util.messengers import generate_db_push_message, generate_ack_message, generate_cluster_model_dist_message, generate_agent_participation_confirmation_message
from fl_main.lib.util.states import ParticipateMSGLocation, ModelUpMSGLocation, PollingMSGLocation, ModelType, AgentMsgType
from .state_manager import StateManager
from .aggregation import Aggregator</pre>
			<p>After we import <a id="_idIndexMarker279"/>the necessary libraries, let us move on to designing an FL <strong class="source-inline">Server</strong> class.</p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor095"/>Defining the FL Server class </h2>
			<p>In practice, it is <a id="_idIndexMarker280"/>wise to define the <strong class="source-inline">Server</strong> class, using which you can create an instance of the FL server that has the functionalities discussed in <a href="B18369_03.xhtml#_idTextAnchor058"><em class="italic">Chapter 3</em></a>, <em class="italic">Workings of the Federated Learning System</em>, as follows:</p>
			<pre class="source-code">
class Server:
    """
    FL Server class defining the functionalities of 
    agent registration, global model synthesis, and
    handling mechanisms of messages by agents. 
    """</pre>
			<p>Again, the <strong class="source-inline">server</strong> class primarily provides the functionalities of agent registration and global model synthesis and handles the mechanisms of uploaded local models and polling messages sent from agents. It also serves as the interface between the aggregator and database and between the aggregator and agents.</p>
			<p>The FL server class functionality is now clear – next is initializing and configuring the server.</p>
			<h2 id="_idParaDest-92"><a id="_idTextAnchor096"/>Initializing the FL server </h2>
			<p>The<a id="_idIndexMarker281"/> following code inside the <strong class="source-inline">__init__</strong> constructor is an example of the initialization process of the <strong class="source-inline">Server</strong> instance:</p>
			<pre class="source-code">
def __init__(self):
    config_file = set_config_file("aggregator")
    self.config = read_config(config_file)
    self.sm = StateManager()
    self.agg = Aggregator(self.sm)
    self.aggr_ip = self.config['aggr_ip']
    self.reg_socket = self.config['reg_socket']
    self.recv_socket = self.config['recv_socket']
    self.exch_socket = self.config['exch_socket']
    self.db_ip = self.config['db_ip']
    self.db_socket = self.config['db_socket']
    self.round_interval = self.config['round_interval']
    self.is_polling = bool(self.config['polling'])
    self.sm.agg_threshold = 
                     self.config['aggregation_threshold']</pre>
			<p>Then, <strong class="source-inline">self.config</strong> stores the information from the <strong class="source-inline">config_aggregator.json</strong> file discussed in the preceding code block. </p>
			<p><strong class="source-inline">self.sm</strong> and <strong class="source-inline">self.agg</strong> have instances of the state manager class and aggregator class discussed as follows, respectively.</p>
			<p><strong class="source-inline">self.aggr_ip</strong> reads an IP address from the aggregator’s configuration file.</p>
			<p>Then, <strong class="source-inline">reg_socket</strong> and <strong class="source-inline">recv_socket</strong> will be set up, where <strong class="source-inline">reg_socket</strong> is used for agents to register themselves together with an aggregator IP address stored as <strong class="source-inline">self.aggr_ip</strong>, and <strong class="source-inline">recv_socket</strong> is used for receiving local models from agents, together with an aggregator IP address stored as <strong class="source-inline">self.aggr_ip</strong>. Both <strong class="source-inline">reg_socket</strong> and <strong class="source-inline">recv_socket</strong> in this example code can be read from the aggregator’s configuration file.</p>
			<p>The <strong class="source-inline">exch_socket</strong> is the port number used to send the global model back to the agent together with the agent IP address, which is initialized with the configuration parameter in the initialization process.</p>
			<p>The information to get connected to the database server will then be configured, where <strong class="source-inline">dp_ip</strong> and <strong class="source-inline">db_socket</strong> will be the IP address and the port number of the database server, respectively, all read from the <strong class="source-inline">config_aggregator.json</strong> file.</p>
			<p><strong class="source-inline">round_interval</strong> is an interval time to check whether the aggregation criteria for starting the model aggregation process are met or not.</p>
			<p>The <strong class="source-inline">is_polling</strong> flag is related to whether to use the <strong class="source-inline">polling</strong> method from the agents or not. The polling flag must be the same as the one used in the agent-side configuration file.</p>
			<p><strong class="source-inline">agg_threshold</strong> is also the percentage over the number of collected local models that is used in the <strong class="source-inline">ready_for_local_aggregation</strong> function where if the percentage of the collected models is equal to or more than <strong class="source-inline">agg_threshold</strong>, the FL server starts the aggregation process of the local models.</p>
			<p>Both <strong class="source-inline">self.round_interval</strong> and <strong class="source-inline">self.agg_threshold</strong> are read from the configuration file in this example code too.</p>
			<p>Now that the<a id="_idIndexMarker282"/> configuration has been set up, we will talk about how to register agents that are trying to participate in the FL process.</p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor097"/>Registration function of agents </h2>
			<p>In this <a id="_idIndexMarker283"/>section, the simplified and asynchronous <strong class="source-inline">register</strong> function is described to receive the participation message specifying the model structures and return socket information for future model exchanges. It also sends the welcome message back to the agent as a response. </p>
			<p>The registration process of agents is described in the following example code:</p>
			<pre class="source-code">
async def register(self, websocket: str, path):        
    msg = await receive(websocket)
    es = self._get_exch_socket(msg)
    agent_nm = msg[int(ParticipateMSGLocation.agent_name)]
    agent_id = msg[int(ParticipateMSGLocation.agent_id)]
    ip = msg[int(ParticipateMSGLocation.agent_ip)]
    id, es = self.sm.add_agent(agent_nm, agent_id, ip, es)
    if self.sm.round == 0:
        await self._initialize_fl(msg)
    await self._send_updated_global_model( \
        websocket, id, es)</pre>
			<p>In this example code, the received message from an agent, defined here as <strong class="source-inline">msg</strong>, is decoded by the <strong class="source-inline">receive</strong> function imported from the <strong class="source-inline">communication_handler</strong> code.</p>
			<p>In particular, the <strong class="source-inline">self.sm.add_agent(agent_name, agent_id, addr, es)</strong> function takes the agent name, agent ID, agent IP address, and the <strong class="source-inline">exch_socket</strong> number included in the <strong class="source-inline">msg</strong> message in order to accept the messages from this agent, even if the agent is temporarily disconnected and then connected again.</p>
			<p>After that, the registration function checks whether it should move on to the process of initial models or not, depending on the FL round that is tracked with <strong class="source-inline">self.sm.round</strong>. If the FL process is not happening yet, that is, if <strong class="source-inline">self.sm.round</strong> is <strong class="source-inline">0</strong>, it calls the <strong class="source-inline">_initialize_fl(msg)</strong> function in order to initialize the FL process.</p>
			<p>Then, the FL server sends the updated global model back to the agent by calling the <strong class="source-inline">_send_updated_global_model(websocket, id, es)</strong> function. The function takes the WebSocket, agent ID, and <strong class="source-inline">exch_socket</strong> as parameters and creates a reply<a id="_idIndexMarker284"/> message to the agent to notify it whether the participation message has been accepted or not. </p>
			<p>The registration process of agents with the FL server is simplified in this example code here. In a production environment, all the system information from the agent will be pushed to the database so that an agent that loses the connection to the FL server can be recovered anytime by reconnecting to the FL server.</p>
			<p>Usually, if the FL server is installed in the cloud and agents are connected to the FL server from their local environment, this push-back mechanism from the aggregator to agents will not work because of security settings such as firewalls. We do not discuss the topic of security issues in this book in detail, so you are encouraged to use the <strong class="source-inline">polling</strong> method implemented in the <strong class="source-inline">simple-fl</strong> code to communicate between the <a id="_idIndexMarker285"/>cloud-based aggregator and local agents.</p>
			<h3>Getting socket information to push the global model back to agents</h3>
			<p>The following<a id="_idIndexMarker286"/> function <a id="_idIndexMarker287"/>called <strong class="source-inline">_get_exch_socket</strong> takes a<a id="_idIndexMarker288"/> participation <a id="_idIndexMarker289"/>message from the agent and decides which port to use to reach out to the agent depending on the simulation flag in the message:</p>
			<pre class="source-code">
def _get_exch_socket(self, msg):
    if msg[int(ParticipateMSGLocation.sim_flag)]:
        es = msg[int(ParticipateMSGLocation.exch_socket)]
    else:
        es = self.exch_socket
    return es</pre>
			<p>We support a simulation run in this implementation exercise by which you can run all the FL system components of a database, aggregator, and multiple agents in one machine.</p>
			<h3>Initializing the FL process if necessary</h3>
			<p>The<a id="_idIndexMarker290"/> asynchronous <strong class="source-inline">_initialize_fl</strong> function is for initializing an FL process that is only called when the round of FL is <strong class="source-inline">0</strong>. The following is the code to do so:</p>
			<pre class="source-code">
async def _initialize_fl(self, msg):
    agent_id = msg[int(ParticipateMSGLocation.agent_id)]
    model_id = msg[int(ParticipateMSGLocation.model_id)]
    gene_time = msg[int(ParticipateMSGLocation.gene_time)]
    lmodels = msg[int(ParticipateMSGLocation.lmodels)] 
    perf_val = msg[int(ParticipateMSGLocation.meta_data)]
    init_flag = \
        bool(msg[int(ParticipateMSGLocation.init_flag)])
    self.sm.initialize_model_info(lmodels, init_flag)
    await self._push_local_models( \
        agent_id, model_id, lmodels, gene_time, perf_val)
    self.sm.increment_round()</pre>
			<p>After extracting the agent ID (<strong class="source-inline">agent_id</strong>), the model ID (<strong class="source-inline">model_id</strong>), local models from an agent (<strong class="source-inline">lmodels</strong>), the generated time of the model (<strong class="source-inline">gene_time</strong>), the performance data (<strong class="source-inline">perf_val</strong>), and the value of <strong class="source-inline">init_flag</strong> from the received message, the <strong class="source-inline">initialize_model_info</strong> function of the state manager code is called, which is explained in a later section of this chapter. </p>
			<p>This function then pushes the local model to the database by calling the <strong class="source-inline">_push_local_models</strong> function, which is also described in this section. You can refer to<a id="_idIndexMarker291"/> the <em class="italic">Functions to push the local and global models to the database</em> section.</p>
			<p>After that, the round is incremented to proceed to the first round in FL.</p>
			<h3>Confirming agent participation with an updated global model </h3>
			<p>After <a id="_idIndexMarker292"/>initializing <a id="_idIndexMarker293"/>the (cluster) global model, the global models need to be sent to the agent connected to the aggregator through this registration process. The asynchronous <strong class="source-inline">_send_updated_global_model</strong> function as follows handles the process of sending the global models to the agent by taking the WebSocket information, agent ID, and the port to use to reach out to the agent as parameters. The following code block describes the procedure:</p>
			<pre class="source-code">
async def _send_updated_global_model( \
                   self, websocket, agent_id, exch_socket):
    model_id = self.sm.cluster_model_ids[-1]
    cluster_models = \
       convert_LDict_to_Dict(self.sm.cluster_models)
    reply = generate_agent_participation_confirm_message(
       self.sm.id, model_id, cluster_models, self.sm.round,
       agent_id, exch_socket, self.recv_socket)
    await send_websocket(reply, websocket)</pre>
			<p>If the FL process has already started, that is, the <strong class="source-inline">self.sm.round</strong> is more than 0 already, we get the cluster models from their buffer and convert them into a dictionary format with the <strong class="source-inline">convert_LDict_to_Dict</strong> library function.</p>
			<p>Then, the reply message is packaged using the <strong class="source-inline">generate_</strong> <strong class="source-inline">agent_participation_confirm_message</strong> function and sent to the agent that just connected or reconnected to the aggregator by calling the <strong class="source-inline">send_websocket(reply, websocket)</strong> function. Please also refer to the <em class="italic">Functions to send the global models to the agents</em> section.</p>
			<p>Now that <a id="_idIndexMarker294"/>we <a id="_idIndexMarker295"/>understand the agents’ registration process, let’s move on to the implementation of handling the local ML models and polling messages.</p>
			<h2 id="_idParaDest-94"><a id="_idTextAnchor098"/>The server for handling messages from local agents </h2>
			<p>The <a id="_idIndexMarker296"/>asynchronous <strong class="source-inline">receive_msg_from_agent</strong> process<a id="_idIndexMarker297"/> at the FL server is constantly running to receive local model updates and to push them to the database and the memory buffer temporally saving local models. It also responds to the polling messages from the local agents. The following code explains this functionality:</p>
			<pre class="source-code">
async def receive_msg_from_agent(self, websocket, path):
    msg = await receive(websocket)
    if msg[int(ModelUpMSGLocation.msg_type)] == \
                                       AgentMsgType.update:
        await self._process_lmodel_upload(msg)
    elif msg[int(PollingMSGLocation.msg_type)] == \
                                      AgentMsgType.polling:
        await self._process_polling(msg, websocket)  </pre>
			<p>We will then look into the two functions called by the <strong class="source-inline">receive_msg_from_agent</strong> function as <a id="_idIndexMarker298"/>shown in the <a id="_idIndexMarker299"/>preceding code blocks, which are the <strong class="source-inline">_process_lmodel_upload</strong> and <strong class="source-inline">_process_polling</strong> functions.</p>
			<h3>Processing a model upload by local agents</h3>
			<p>The <a id="_idIndexMarker300"/>asynchronous <strong class="source-inline">_process_lmodel_upload</strong> function deals<a id="_idIndexMarker301"/> with the <strong class="source-inline">AgentMsgType.update</strong> message. The following code block is about the function related to receiving the local ML models and putting them into the buffer in the state manager:</p>
			<pre class="source-code">
async def _process_lmodel_upload(self, msg):
    lmodels = msg[int(ModelUpMSGLocation.lmodels)]
    agent_id = msg[int(ModelUpMSGLocation.agent_id)]
    model_id = msg[int(ModelUpMSGLocation.model_id)]
    gene_time = msg[int(ModelUpMSGLocation.gene_time)]
    perf_val = msg[int(ModelUpMSGLocation.meta_data)]
    await self._push_local_models( \ 
        agent_id, model_id, lmodels, gene_time, perf_val)
    self.sm.buffer_local_models( \ 
        lmodels, participate=False, meta_data=perf_val)</pre>
			<p>First, it extracts the agent ID (<strong class="source-inline">agent_id</strong>), the model ID (<strong class="source-inline">model_id</strong>), local models from an agent (<strong class="source-inline">lmodels</strong>), the generated time of the model (<strong class="source-inline">gene_time</strong>), and the performance data (<strong class="source-inline">perf_val</strong>) from the received message, and then calls the <strong class="source-inline">_push_local_models</strong> function to push the local models to the database.</p>
			<p>The <strong class="source-inline">buffer_local_models</strong> function is then called to save the local models (<strong class="source-inline">lmodels</strong>) in the memory buffer. The <strong class="source-inline">buffer_local_models</strong> function is described in the <em class="italic">Maintaining models for aggregation with the state manager</em> section. </p>
			<h3>Processing polling by agents</h3>
			<p>The following<a id="_idIndexMarker302"/> asynchronous <strong class="source-inline">_process_polling</strong> function<a id="_idIndexMarker303"/> deals with the <strong class="source-inline">AgentMsgType.polling</strong> message:</p>
			<pre class="source-code">
async def _process_polling(self, msg, websocket):
    if self.sm.round &gt; \
                   int(msg[int(PollingMSGLocation.round)]):
        model_id = self.sm.cluster_model_ids[-1]
        cluster_models = \
            convert_LDict_to_Dict(self.sm.cluster_models)
        msg = generate_cluster_model_dist_message( \
            self.sm.id, model_id, self.sm.round, \
            cluster_models)
        await send_websocket(msg, websocket)
    else:
        msg = generate_ack_message()
        await send_websocket(msg, websocket)  </pre>
			<p>If the FL round (<strong class="source-inline">self.sm.round</strong>) is greater than the local FL round included in the received message that is maintained by the local agent itself, it means that the model aggregation is done during the period between the time when the agent polled to the aggregator last time and now. </p>
			<p>In this case, <strong class="source-inline">cluster_models</strong> that are converted into a dictionary format are packaged into a response message by <strong class="source-inline">generate_cluster_model_dist_message</strong> and sent back to the agent via the <strong class="source-inline">send_websocket</strong> function.</p>
			<p>Otherwise, the aggregator just returns the <em class="italic">ACK</em> message to the agent, generated by the <strong class="source-inline">generate_ack_message</strong> function.</p>
			<p>Now we are ready to aggregate the local models received from the agents, so let us look into the model aggregation routine.</p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor099"/>The global model synthesis routine</h2>
			<p>The global <a id="_idIndexMarker304"/>model synthesis <a id="_idIndexMarker305"/>routine process designed in <strong class="source-inline">async def model_synthesis_routine(self)</strong> in the FL server periodically checks the number of stored models and executes global model synthesis if there are enough local models collected to meet the aggregation threshold. </p>
			<p>The following code describes the model synthesis routine process that periodically checks the aggregation criteria and executes model synthesis:</p>
			<pre class="source-code">
async def model_synthesis_routine(self):
    while True:
        await asyncio.sleep(self.round_interval)
        if self.sm.ready_for_local_aggregation():  
            self.agg.aggregate_local_models()
            await self._push_cluster_models()
            if self.is_polling == False:
                await self._send_cluster_models_to_all()
            self.sm.increment_round()</pre>
			<p>This process is asynchronous, running with a <strong class="source-inline">while</strong> loop.</p>
			<p>In particular, once the criteria set by <strong class="source-inline">ready_for_local_aggregation</strong> (explained in the <em class="italic">Maintaining models for aggregation with the state manager</em> section) are met, the <strong class="source-inline">aggregate_local_models</strong> function imported from the <strong class="source-inline">aggregator.py</strong> file is called, where this function averages the weights of the collected local models based on <strong class="source-inline">FedAvg</strong>. Further explanation of the <strong class="source-inline">aggregate_local_models</strong> function can be found in the <em class="italic">Aggregating local models</em> section.</p>
			<p>Then, <strong class="source-inline">await self._push_cluster_models()</strong> is called to push the aggregated cluster global model to the database. </p>
			<p><strong class="source-inline">await self._send_cluster_models_to_all()</strong> is for sending the updated global model to all the agents connected to the aggregator if the <strong class="source-inline">polling</strong> method is not used.</p>
			<p>Last but not least, the FL round is incremented by <strong class="source-inline">self.sm.increment_round()</strong>.</p>
			<p>Once the cluster global model is generated, the models need to be sent to the connected <a id="_idIndexMarker306"/>agents with <a id="_idIndexMarker307"/>the functions described in the following section.</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor100"/>Functions to send the global models to the agents </h2>
			<p>The<a id="_idIndexMarker308"/> functionality<a id="_idIndexMarker309"/> of sending global models to the connected agents is dealt with by the <strong class="source-inline">_send_cluster_models_to_all</strong> function. This is an asynchronous function to send out cluster global models to all agents under this aggregator as follows:</p>
			<pre class="source-code">
async def _send_cluster_models_to_all(self):
    model_id = self.sm.cluster_model_ids[-1]
    cluster_models = \
        convert_LDict_to_Dict(self.sm.cluster_models)
    msg = generate_cluster_model_dist_message( \
        self.sm.id, model_id, self.sm.round, \
        cluster_models)
    for agent in self.sm.agent_set:
        await send(msg, agent['agent_ip'], agent['socket'])</pre>
			<p>After getting the cluster models’ information, it creates the message including the cluster models, round, model ID, and aggregator ID information using the <strong class="source-inline">generate_cluster_model_dist_message</strong> function and calls the <strong class="source-inline">send</strong> function from the <strong class="source-inline">communication_handler</strong> libraries to send the global models to all the agents in the <strong class="source-inline">agent_set</strong> registered through the agent participation process.</p>
			<p>Sending the cluster global models to the connected agents has now been explained. Next, we explain<a id="_idIndexMarker310"/> how to push the local and cluster models to the database.</p>
			<h2 id="_idParaDest-97"><a id="_idTextAnchor101"/>Functions to push the local and global models to the database </h2>
			<p>The <strong class="source-inline">_push_local_models</strong> and <strong class="source-inline">_push_cluster_models</strong> functions are both called internally to push and send the local models and cluster global models to the database. </p>
			<h3>Pushing local models to the database</h3>
			<p>Here is <a id="_idIndexMarker311"/>the <strong class="source-inline">_push_local_models</strong> function <a id="_idIndexMarker312"/>for pushing a given set of local models to the database:</p>
			<pre class="source-code">
async def _push_local_models(self, agent_id: str, \
        model_id: str, local_models: Dict[str, np.array], \
        gene_time: float, performance: Dict[str, float]) \
        -&gt; List[Any]:
    return await self._push_models(
        agent_id, ModelType.local, local_models, \
        model_id, gene_time, performance)</pre>
			<p>The <strong class="source-inline">_push_local_models</strong> function takes parameters such as the agent ID, local models, the model ID, the generated time of the model, and the performance data, and returns a response message if there is one.</p>
			<h3>Pushing cluster models to the database</h3>
			<p>The<a id="_idIndexMarker313"/> following <strong class="source-inline">_push_cluster_models</strong> function <a id="_idIndexMarker314"/>is for pushing the cluster global models to the database:</p>
			<pre class="source-code">
async def _push_cluster_models(self) -&gt; List[Any]:
    model_id = self.sm.cluster_model_ids[-1] 
    models = convert_LDict_to_Dict(self.sm.cluster_models)
    meta_dict = dict({ \
        "num_samples" : self.sm.own_cluster_num_samples})
    return await self._push_models( \
        self.sm.id, ModelType.cluster, models, model_id, \
        time.time(), meta_dict)</pre>
			<p><strong class="source-inline">_push_cluster_models</strong> in this code does not take any parameters, as those parameters can be obtained from the instance information and buffered memory data of the state manager. For example, <strong class="source-inline">self.sm.cluster_model_ids[-1]</strong> obtains the ID of the latest cluster model, and <strong class="source-inline">self.sm.cluster_models</strong> stores the latest cluster model itself, which is converted into <strong class="source-inline">models</strong> with a dictionary format to be sent <a id="_idIndexMarker315"/>to the <a id="_idIndexMarker316"/>database. It also creates <strong class="source-inline">mata_dict</strong> to store the number of samples.</p>
			<h3>Pushing ML models to the database</h3>
			<p>Both the <a id="_idIndexMarker317"/>preceding<a id="_idIndexMarker318"/> functions call the <strong class="source-inline">_push_models</strong> function as follows:</p>
			<pre class="source-code">
async def _push_models(
    self, component_id: str, model_type: ModelType,
    models: Dict[str, np.array], model_id: str,
    gene_time: float, performance_dict: Dict[str, float])
    -&gt; List[Any]:
    msg = generate_db_push_message(component_id, \
        self.sm.round, model_type, models, model_id, \
        gene_time, performance_dict)
    resp = await send(msg, self.db_ip, self.db_socket)
    return resp</pre>
			<p>In this code example, the <strong class="source-inline">_push_models</strong> function takes parameters such as <strong class="source-inline">component_id</strong> (the ID of the aggregator or agent), <strong class="source-inline">model_type</strong>, such as local or cluster model, <strong class="source-inline">models</strong> themselves, <strong class="source-inline">model_id</strong>,  <strong class="source-inline">gene_time</strong> (the time the model is created), and <strong class="source-inline">performance_dict</strong> as the performance metrics of the models. Then, the message to be sent to the database (using the <strong class="source-inline">send</strong> function) is created by the <strong class="source-inline">generate_db_push_message</strong> function, taking these parameters together with the FL round information. It returns a response message from the database.</p>
			<p>Now that we have explained all the core functionalities related to the FL server, let us look into the <a id="_idIndexMarker319"/>role of <a id="_idIndexMarker320"/>the state manager, which maintains all the models needed for the aggregation process.</p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor102"/>Maintaining models for aggregation with the  state manager</h1>
			<p>In this section, we <a id="_idIndexMarker321"/>will explain <strong class="source-inline">state_manager.py,</strong> which handles maintaining the models and necessary volatile information related to the aggregation of local models.</p>
			<h2 id="_idParaDest-99"><a id="_idTextAnchor103"/>Importing the libraries of the state manager </h2>
			<p>This code imports<a id="_idIndexMarker322"/> the<a id="_idIndexMarker323"/> following. The internal libraries for <strong class="source-inline">data_struc</strong>, <strong class="source-inline">helpers</strong>, and <strong class="source-inline">states</strong> are introduced in the <em class="italic">Appendix</em>, <em class="italic">Exploring Internal Libraries</em>:</p>
			<pre class="source-code">
import numpy as np
import logging
import time
from typing import Dict, Any
from fl_main.lib.util.data_struc import LimitedDict
from fl_main.lib.util.helpers import generate_id, generate_model_id
from fl_main.lib.util.states import IDPrefix</pre>
			<p>After importing the necessary libraries, let’s define the state manager class.</p>
			<h2 id="_idParaDest-100"><a id="_idTextAnchor104"/>Defining the state manager class</h2>
			<p>The state <a id="_idIndexMarker324"/>manager<a id="_idIndexMarker325"/> class (<strong class="source-inline">Class StateManager</strong>), as seen in <strong class="source-inline">state_manager.py</strong>, is defined in the following code:</p>
			<pre class="source-code">
class StateManager:
    """
    StateManager instance keeps the state of an aggregator.
    Functions are listed with this indentation.
    """</pre>
			<p>This keeps track of the state information of an aggregator. The volatile state of an aggregator and agents should also be stored, such as local models, agents’ info connected to the aggregator, cluster models generated by the aggregation process, and the current round number.</p>
			<p>After defining the state manager, let us move on to initializing the state manager. </p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor105"/>Initializing the state manager</h2>
			<p>In the <strong class="source-inline">__init__</strong> constructor, the<a id="_idIndexMarker326"/> information<a id="_idIndexMarker327"/> related to the FL process is <a id="_idIndexMarker328"/>configured. The following code is an example of how to construct the state manager: </p>
			<pre class="source-code">
def __init__(self):
    self.id = generate_id()
    self.agent_set = list()
    self.mnames = list()
    self.round = 0
    self.local_model_buffers = LimitedDict(self.mnames)
    self.local_model_num_samples = list()
    self.cluster_models = LimitedDict(self.mnames)
    self.cluster_model_ids = list()
    self.initialized = False
    self.agg_threshold = 1.0</pre>
			<p>The ID of the <strong class="source-inline">self.id</strong> aggregator can be generated randomly using the <strong class="source-inline">generate_id()</strong> function from the <strong class="source-inline">util.helpers</strong> library.</p>
			<p><strong class="source-inline">self.agent_set</strong> is a set of agents connected to the aggregator where the format of the set is a collection of dictionary information, related to agents in this case.</p>
			<p><strong class="source-inline">self.mnames</strong> stores the names of each layer of the ML models to be aggregated in a list format.</p>
			<p><strong class="source-inline">self.round</strong> is initialized to be <strong class="source-inline">0</strong> so that the round of FL is initialized. </p>
			<p><strong class="source-inline">local_model_buffers</strong> is a list of local models collected by agents stored in the memory <a id="_idIndexMarker329"/>space. <strong class="source-inline">local_model_buffers</strong> accepts the local models sent from the agents for <a id="_idIndexMarker330"/>each FL round, and once the round is completed by the aggregation process, this buffer is cleared and starts accepting the next round’s local models.</p>
			<p><strong class="source-inline">self.local_model_num_samples</strong> is a list that stores the number of data samples for the models that are collected in the buffer.</p>
			<p><strong class="source-inline">self.cluster_models</strong> is a collection of global cluster models in the <strong class="source-inline">LimitedDict</strong> format, and <strong class="source-inline">self.cluster_model_ids</strong> is a list of IDs of cluster models. </p>
			<p><strong class="source-inline">self.initialized</strong> becomes <strong class="source-inline">True</strong> once the initial global model is set and is <strong class="source-inline">False</strong> otherwise.</p>
			<p><strong class="source-inline">self.agg_threshold</strong> is initialized to be <strong class="source-inline">1.0</strong>, which is overwritten by the value specified in the <strong class="source-inline">config_aggregator.json</strong> file.</p>
			<p>After initializing the state manager, let us investigate initializing a global model next.</p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor106"/>Initializing a global model</h2>
			<p>The <a id="_idIndexMarker331"/>following <strong class="source-inline">initialize_model_info</strong> function <a id="_idIndexMarker332"/>sets up the initial global <a id="_idIndexMarker333"/>model to be used by the other agents:</p>
			<pre class="source-code">
def initialize_model_info(self, lmodels, \
                          init_weights_flag):
    for key in lmodels.keys():
        self.mnames.append(key)
    self.local_model_buffers = LimitedDict(self.mnames)
    self.cluster_models = LimitedDict(self.mnames)
    self.clear_lmodel_buffers()
    if init_weights_flag:
        self.initialize_models(lmodels, \
                            weight_keep=init_weights_flag)
    else:
        self.initialize_models(lmodels, weight_keep=False)</pre>
			<p>It fills up the model names (<strong class="source-inline">self.mnames</strong>) extracted from the local models (<strong class="source-inline">lmodels</strong>) sent from an initial agent. Together with the model names, <strong class="source-inline">local_model_buffers</strong> and <strong class="source-inline">cluster_models</strong> are re-initialized too. After clearing the local model buffers, it calls the <strong class="source-inline">initialize_models</strong> function.</p>
			<p>The following <strong class="source-inline">initialize_models</strong> function initializes the structure of neural networks (<strong class="source-inline">numpy.array</strong>) based on the initial base models received as parameters of models<a id="_idIndexMarker334"/> with a dictionary format (<strong class="source-inline">str</strong> or <strong class="source-inline">np.array</strong>):</p>
			<pre class="source-code">
def initialize_models(self, models: Dict[str, np.array], \
                                weight_keep: bool = False):
    self.clear_saved_models()
    for mname in self.mnames:
        if weight_keep:
            m = models[mname]
        else:
            m = np.zeros_like(models[mname])
        self.cluster_models[mname].append(m)
        id = generate_model_id(IDPrefix.aggregator, \
                 self.id, time.time())
        self.cluster_model_ids.append(id)
        self.initialized = True</pre>
			<p>For each layer of the model, defined here as model names, this function fills out the model parameters. Depending on the <strong class="source-inline">weight_keep</strong> flag, the model is initialized with zeros or parameters that are received. This way, the initial cluster global model is constructed together with the randomized model ID. If an agent sends a different ML model than the model architecture defined here, the aggregator rejects the acceptance of the model or gives an error message to the agent. Nothing is returned.</p>
			<p>So, we have<a id="_idIndexMarker335"/> covered<a id="_idIndexMarker336"/> initializing the global model. In the following section, we will explain the core part of the FL process, which is checking aggregation criteria.</p>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor107"/>Checking the aggregation criteria</h2>
			<p>The<a id="_idIndexMarker337"/> following <a id="_idIndexMarker338"/>code, called <strong class="source-inline">ready_for_local_aggregation</strong>, is for <a id="_idIndexMarker339"/>checking the aggregation criteria:</p>
			<pre class="source-code">
def ready_for_local_aggregation(self) -&gt; bool:
    if len(self.mnames) == 0:
            return False
    num_agents = int(self.agg_threshold * \
                                       len(self.agent_set))
    if num_agents == 0: num_agents = 1
    num_collected_lmodels = \
        len(self.local_model_buffers[self.mnames[0]])
    if num_collected_lmodels &gt;= num_agents:
        return True
    else:
        return False            </pre>
			<p>This <strong class="source-inline">ready_for_local_aggregation</strong> function returns a <strong class="source-inline">bool</strong> value to identify whether the aggregator can start the aggregation process. It returns <strong class="source-inline">True</strong> if it satisfies the aggregation criteria (such as collecting enough local models to aggregate) and <strong class="source-inline">False</strong> otherwise. The aggregation threshold, <strong class="source-inline">agg_threshold</strong>, is configured<a id="_idIndexMarker340"/> in <a id="_idIndexMarker341"/>the <strong class="source-inline">config_aggregator.json</strong> file.</p>
			<p>The following section is about buffering the local models that are used for the aggregation process.</p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor108"/>Buffering the local models</h2>
			<p>The following <a id="_idIndexMarker342"/>code<a id="_idIndexMarker343"/> on <strong class="source-inline">buffer_local_models</strong> stores local models from an agent in the local model buffer: </p>
			<pre class="source-code">
def buffer_local_models(self, models: Dict[str, np.array], 
        participate=False, meta_data: Dict[Any, Any] = {}):
    if not participate:  
        for key, model in models.items():
            self.local_model_buffers[key].append(model)
        try:
            num_samples = meta_data["num_samples"]
        except:
            num_samples = 1
        self.local_model_num_samples.append( \
                int(num_samples))
    else:  
        pass
    if not self.initialized:
        self.initialize_models(models)</pre>
			<p>The parameters include the local <strong class="source-inline">models</strong> formatted as a dictionary as well as meta-information such as the number of samples.</p>
			<p>First, this function checks whether the local model sent from an agent is either the initial model or not by checking the participation flag. If it is an initial model, it calls the <strong class="source-inline">initialize_model</strong> function, as shown in the preceding code block.</p>
			<p>Otherwise, for each layer of the model defined with model names, it stores the <strong class="source-inline">numpy</strong> array in the <strong class="source-inline">self.local_model_buffers</strong>. The <strong class="source-inline">key</strong> is the model name and <strong class="source-inline">model</strong> mentioned in the preceding code are the actual parameters of the model. Optionally, it can accept the number of samples or data sources that the agent has used for the retraining process and push it to the <strong class="source-inline">self.</strong> <strong class="source-inline">local_model_num_samples</strong> buffer.</p>
			<p>This function is called when the FL server receives the local models from an agent during the <strong class="source-inline">receive_msg_from_agent</strong> routine.</p>
			<p>With that, the local model buffer has been explained. Next, we will explain how to clear the saved<a id="_idIndexMarker344"/> models <a id="_idIndexMarker345"/>so that aggregation can continue without having to store unnecessary models in the buffer.</p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor109"/>Clearing the saved models</h2>
			<p>The <a id="_idIndexMarker346"/>following <strong class="source-inline">clear_saved_models</strong> function clears all cluster models stored in this <a id="_idIndexMarker347"/>round:</p>
			<pre class="source-code">
def clear_saved_models(self):
    for mname in self.mnames:
        self.cluster_models[mname].clear()</pre>
			<p>This function is called when initializing the FL process at the very beginning and the cluster global model is emptied to start a fresh FL round again.  </p>
			<p>The following function, the <strong class="source-inline">clear_lmodel_buffers</strong> function, clears all the buffered local models to prepare for the next FL round: </p>
			<pre class="source-code">
def clear_lmodel_buffers(self):
    for mname in self.mnames:
        self.local_model_buffers[mname].clear()
    self.local_model_num_samples = list()</pre>
			<p>Clearing the local models in <strong class="source-inline">local_model_buffers</strong> is critical when proceeding to the next FL round. Without this process, the models to be aggregated are mixed up with the non-relevant models from other rounds, and eventually, the performance <a id="_idIndexMarker348"/>of the<a id="_idIndexMarker349"/> FL is sometimes degraded.</p>
			<p>Next, we will explain the basic framework of adding agents during the FL process.</p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor110"/>Adding agents</h2>
			<p>This <strong class="source-inline">add_agent</strong> function<a id="_idIndexMarker350"/> deals<a id="_idIndexMarker351"/> with brief agent registration using system memory:</p>
			<pre class="source-code">
def add_agent(self, agent_name: str, agent_id: str, \
                               agent_ip: str, socket: str):
    for agent in self.agent_set:
        if agent_name == agent['agent_name']:
            return agent['agent_id'], agent['socket']
    agent = {
        'agent_name': agent_name,
        'agent_id': agent_id,
        'agent_ip': agent_ip,
        'socket': socket
    }
    self.agent_set.append(agent)
    return agent_id, socket</pre>
			<p>This function just adds agent-related information to the <strong class="source-inline">self.agent_set</strong> list. The agent information includes the agent name, agent ID, agent IP address, and the <strong class="source-inline">socket</strong> number to reach out to the agent. The <strong class="source-inline">socket</strong> number can be used when sending the cluster global model to the agent connected to the aggregator and when the <strong class="source-inline">push</strong> method is used for communication between an aggregator and an agent. This function is only called during the agent registration process and returns the agent ID and the <strong class="source-inline">socket</strong> number.</p>
			<p>If the agent is already registered, which means there is already an agent with the same name in <strong class="source-inline">agent_set</strong>, it returns the agent ID and the <strong class="source-inline">socket</strong> number of the existing agent.</p>
			<p>Again, this <strong class="source-inline">push</strong> communication method from an aggregator to agents does not work under certain security circumstances. It is recommended to use the <strong class="source-inline">polling</strong> method that the agents use to constantly check whether the aggregator has an updated global model or not.</p>
			<p>The agent <a id="_idIndexMarker352"/>registration<a id="_idIndexMarker353"/> mechanism can be expanded using a database, which will give you better management of the distributed systems.</p>
			<p>Next, we will touch on incrementing the FL round.</p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor111"/>Incrementing the FL round</h2>
			<p>The <strong class="source-inline">increment_round</strong> function<a id="_idIndexMarker354"/> just <a id="_idIndexMarker355"/>increments the round number precisely managed by the state manager: </p>
			<pre class="source-code">
def increment_round(self):
    self.round += 1</pre>
			<p>Incrementing rounds is a critical part of the FL process for supporting the continuous learning operation. This function is only called after registering the initial global model or after each model aggregation process.</p>
			<p>Now that we understand how the FL works with the state manager, in the following section, we will talk about the model aggregation framework.</p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor112"/>Aggregating local models</h1>
			<p>The <strong class="source-inline">aggregation.py</strong> code<a id="_idIndexMarker356"/> handles aggregating local models with a bunch of aggregation algorithms. In the code example, we only support <strong class="bold">FedAvg</strong>, as discussed in the following sections.</p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor113"/>Importing the libraries for the aggregator</h2>
			<p>The <strong class="source-inline">aggregation.py</strong> code<a id="_idIndexMarker357"/> imports the following: </p>
			<pre class="source-code">
import logging
import time
import numpy as np
from typing import List
from .state_manager import StateManager
from fl_main.lib.util.helpers import generate_model_id
from fl_main.lib.util.states import IDPrefix</pre>
			<p>The imported state manager’s role and functionalities are discussed in the <em class="italic">Maintaining models for aggregation with the state manager</em> section, and the <strong class="source-inline">helpers</strong> and <strong class="source-inline">states</strong> libraries are introduced in the <em class="italic">Appendix</em>, <em class="italic">Exploring Internal Libraries. </em></p>
			<p>After importing the necessary libraries, let’s define the aggregator class.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor114"/>Defining and initializing the aggregator class</h2>
			<p>The following <a id="_idIndexMarker358"/>code for <strong class="source-inline">class Aggregator</strong> defines the core process of the aggregator, which provides a set of mathematical functions for computing the aggregated models:</p>
			<pre class="source-code">
class Aggregator:
    """
    Aggregator class instance provides a set of 
    mathematical functions to compute aggregated models.
    """</pre>
			<p>The following <strong class="source-inline">__init__</strong> function just sets up the state manager of the aggregator to access the model buffers:</p>
			<pre class="source-code">
def __init__(self, sm: StateManager):
    self.sm = sm</pre>
			<p>Once the <a id="_idIndexMarker359"/>aggregator class is defined and initialized, let’s look at the actual FedAvg algorithm implementation.</p>
			<h2 id="_idParaDest-111"><a id="_idTextAnchor115"/>Defining the aggregate_local_models function </h2>
			<p>The following <a id="_idIndexMarker360"/> <strong class="source-inline">aggregate_local_models</strong> function is the code for aggregating the local models:</p>
			<pre class="source-code">
def aggregate_local_models(self):
    for mname in self.sm.mnames:
        self.sm.cluster_models[mname][0] \
            = self._average_aggregate( \
                self.sm.local_model_buffers[mname], \
                self.sm.local_model_num_samples)
    self.sm.own_cluster_num_samples = \
        sum(self.sm.local_model_num_samples)
    id = generate_model_id( \
        IDPrefix.aggregator, self.sm.id, time.time())
    self.sm.cluster_model_ids.append(id)
    self.sm.clear_lmodel_buffers()</pre>
			<p>This function can be called after the aggregation criteria are satisfied, such as the aggregation threshold defined in the <strong class="source-inline">config_aggregator.json</strong> file. The aggregation process uses local ML models buffered in the memory of the state manager. Those local ML models are sent from the registered agents. For each layer of the models defined by <strong class="source-inline">mname</strong>, the weights of the model are averaged by the <strong class="source-inline">_average_aggregate</strong> function as follows to realize FedAvg. After averaging the model parameters of all the layers, <strong class="source-inline">cluster_models</strong> is updated, which is sent to all the agents. </p>
			<p>Then, the local<a id="_idIndexMarker361"/> model buffer is cleared to be ready for the next round of the FL process.</p>
			<h2 id="_idParaDest-112"><a id="_idTextAnchor116"/>The FedAvg function</h2>
			<p>The following<a id="_idIndexMarker362"/> function, <strong class="source-inline">_average_aggregate</strong>, called by the preceding <strong class="source-inline">aggregate_local_models</strong> function, is the code that realizes the <strong class="source-inline">FedAvg</strong> aggregation method:</p>
			<pre class="source-code">
def _average_aggregate(self, buffer: List[np.array], 
                       num_samples: List[int]) -&gt; np.array:
    denominator = sum(num_samples)
    model = float(num_samples[0])/denominator * buffer[0]
    for i in range(1, len(buffer)):
        model += float(num_samples[i]) / 
                                    denominator * buffer[i]
    return model</pre>
			<p>In the <strong class="source-inline">_average_aggregate</strong> function, the computation is simple enough that, for each buffer of the given list of ML models, it takes averaged parameters for the models. The basics of model aggregation are discussed in <a href="B18369_03.xhtml#_idTextAnchor058"><em class="italic">Chapter 3</em></a>, <em class="italic">Workings of the Federated Learning System</em>. It returns the  weighted aggregated models with <strong class="source-inline">np.array</strong>.</p>
			<p>Now that we have covered all the essential functionalities of the FL server and aggregator, next, we will talk about how to run the FL server itself.</p>
			<h1 id="_idParaDest-113"><a id="_idTextAnchor117"/>Running the FL server</h1>
			<p>Here is an<a id="_idIndexMarker363"/> example of running the FL server. In order to run the FL server, you will just execute the following code:</p>
			<pre class="source-code">
if __name__ == "__main__":
    s = Server()
    init_fl_server(s.register, 
                   s.receive_msg_from_agent, 
                   s.model_synthesis_routine(), 
                   s.aggr_ip, s.reg_socket, s.recv_socket)</pre>
			<p>The <strong class="source-inline">register</strong>, <strong class="source-inline">receive_msg_from_agnet</strong>, and <strong class="source-inline">model_synthesis_routine</strong> functions of the instance of the FL server are for starting the registration process of the agents, receiving messages from the agents, and starting the model synthesis process to create a global model, which are all started using the <strong class="source-inline">init_fl_server</strong> function from the <strong class="source-inline">communication_handler</strong> libraries. </p>
			<p>We have covered <a id="_idIndexMarker364"/>all the core modules of the aggregator with the FL server. They can work with the database server, which will be discussed in the following section.</p>
			<h1 id="_idParaDest-114"><a id="_idTextAnchor118"/>Implementing and running the database server</h1>
			<p>The database<a id="_idIndexMarker365"/> server <a id="_idIndexMarker366"/>can be hosted either on the same machine as the aggregator server or separately from the aggregator server. Whether the database server is hosted on the same machine or not, the code introduced here is still applicable to both cases. The database-related code is found in the <strong class="source-inline">fl_main/pseudodb</strong> folder of the GitHub repository provided alongside this book.</p>
			<h2 id="_idParaDest-115"><a id="_idTextAnchor119"/>Toward the configuration of the database</h2>
			<p>The following <a id="_idIndexMarker367"/>code is an example of the database-side configuration parameters saved as <strong class="source-inline">config_db.json</strong>:</p>
			<pre class="source-code">
{
    "db_ip": "localhost",
    "db_socket": "9017",
    "db_name": "sample_data",
    "db_data_path": "./db",
    "db_model_path": "./db/models"
}</pre>
			<p>In particular, <strong class="source-inline">db_data_path</strong> is the location of the SQLite database and <strong class="source-inline">db_model_path</strong> is the location of the ML model binary files. The <strong class="source-inline">config_db.json</strong> file <a id="_idIndexMarker368"/>can be found in the <strong class="source-inline">setup</strong> folder.</p>
			<p>Next, let’s define the database server and import the necessary libraries. </p>
			<h2 id="_idParaDest-116"><a id="_idTextAnchor120"/>Defining the database server </h2>
			<p>The main<a id="_idIndexMarker369"/> functionality of the <strong class="source-inline">pseudo_db.py</strong> code is accepting messages that contain local and cluster global models. </p>
			<h3>Importing the libraries for the pseudo database </h3>
			<p>First, the <strong class="source-inline">pseudo_db.py</strong> code<a id="_idIndexMarker370"/> imports <a id="_idIndexMarker371"/>the following:</p>
			<pre class="source-code">
import pickle, logging, time, os
from typing import Any, List
from .sqlite_db import SQLiteDBHandler
from fl_main.lib.util.helpers import generate_id, read_config, set_config_file
from fl_main.lib.util.states import DBMsgType, DBPushMsgLocation, ModelType
from fl_main.lib.util.communication_handler import init_db_server, send_websocket, receive</pre>
			<p>It imports the basic general libraries as well as <strong class="source-inline">SQLiteDBHandler</strong> (discussed later in the <em class="italic">Defining the database with SQLite </em>section) and the functions from the <strong class="source-inline">lib/util</strong> libraries that are discussed in the <em class="italic">Appendix</em>, <em class="italic">Exploring Internal Libraries</em>.</p>
			<h3>Defining the PseudoDB class</h3>
			<p>The <strong class="source-inline">PseudoDB</strong> class <a id="_idIndexMarker372"/>is then defined to <a id="_idIndexMarker373"/>create an instance that receives models and their data from an aggregator and pushes them to an actual database (SQLite, in this case):</p>
			<pre class="source-code">
class PseudoDB:
    """
    PseudoDB class instance receives models and their data
    from an aggregator, and pushes them to database
    """</pre>
			<p>Now, let us move on to initializing the instance of <strong class="source-inline">PseudoDB</strong>.</p>
			<h3>Initializing PseudoDB</h3>
			<p>Then, the<a id="_idIndexMarker374"/> initialization process, <strong class="source-inline">__init__</strong>, is <a id="_idIndexMarker375"/>defined as follows:</p>
			<pre class="source-code">
def __init__(self):
    self.id = generate_id()
    self.config = read_config(set_config_file("db"))
    self.db_ip = self.config['db_ip']
    self.db_socket = self.config['db_socket']
    self.data_path = self.config['db_data_path']
    if not os.path.exists(self.data_path):
        os.makedirs(self.data_path)
    self.db_file = \
        f'{self.data_path}/model_data{time.time()}.db'
    self.dbhandler = SQLiteDBHandler(self.db_file)
    self.dbhandler.initialize_DB()
    self.db_model_path = self.config['db_model_path']
    if not os.path.exists(self.db_model_path):
        os.makedirs(self.db_model_path)</pre>
			<p>The initialization process generates the ID of the instance and sets up various parameters such as the database socket (<strong class="source-inline">db_socket</strong>), the database IP address (<strong class="source-inline">db_ip</strong>), the path to the database (<strong class="source-inline">data_path</strong>), and the database file (<strong class="source-inline">db_file</strong>), all configured from <strong class="source-inline">config_db.json</strong>.</p>
			<p><strong class="source-inline">dbhandler</strong> stores the instance of <strong class="source-inline">SQLiteDBHandler</strong> and calls the <strong class="source-inline">initialize_DB</strong> function to create an SQLite database. </p>
			<p>Folders for <strong class="source-inline">data_path</strong> and <strong class="source-inline">db_model_path</strong> are created if they do not already exist.</p>
			<p>After the initialization process of <strong class="source-inline">PseudoDB</strong>, we need to design the communication module that accepts the messages from the aggregators. We again use WebSocket for communicating with an aggregator and start this module as a server to accept and respond to<a id="_idIndexMarker376"/> messages from an aggregator. In<a id="_idIndexMarker377"/> this design, we do not push messages from the database server to an aggregator or agents in order to make the FL mechanism simpler.</p>
			<h3>Handling messages from the aggregator</h3>
			<p>The following <a id="_idIndexMarker378"/>code for the <strong class="source-inline">async def handler</strong> function, which<a id="_idIndexMarker379"/> takes <strong class="source-inline">websocket</strong> as a parameter, receives messages from the aggregator and returns the requested information:</p>
			<pre class="source-code">
async def handler(self, websocket, path):
    msg = await receive(websocket)
    msg_type = msg[DBPushMsgLocation.msg_type]
    reply = list()
    if msg_type == DBMsgType.push:
        self._push_all_data_to_db(msg)
        reply.append('confirmation')
    else:
        raise TypeError(f'Undefined DB Message Type: \
                                              {msg_type}.')
    await send_websocket(reply, websocket)</pre>
			<p>In the <strong class="source-inline">handler</strong> function, once it decodes the received message from an aggregator, the <strong class="source-inline">handler</strong> function checks whether the message type is <strong class="source-inline">push</strong> or not. If so, it tries to push the local or cluster models to the database by calling the _<strong class="source-inline">push_all_data_to_db</strong> function. Otherwise, it will show an error message. The confirmation message about pushing the models to the database can then be sent back to the aggregator.</p>
			<p>Here, we only<a id="_idIndexMarker380"/> defined the type of the <strong class="source-inline">push</strong> message, but <a id="_idIndexMarker381"/>you can define as many types as possible, together with the enhancement of the database schema and design.</p>
			<h3>Pushing all the data to the database</h3>
			<p>The <a id="_idIndexMarker382"/>following code for <strong class="source-inline">_push_all_data_to_db</strong> pushes the models’ information to the database:</p>
			<pre class="source-code">
def _push_all_data_to_db(self, msg: List[Any]):
    pm = self._parse_message(msg)
    self.dbhandler.insert_an_entry(*pm)
    model_id = msg[int(DBPushMsgLocation.model_id)]
    models = msg[int(DBPushMsgLocation.models)]
    fname = f'{self.db_model_path}/{model_id}.binaryfile'
    with open(fname, 'wb') as f:
        pickle.dump(models, f)</pre>
			<p>The models’ information is extracted by the <strong class="source-inline">_parse_message</strong> function and passed to the <strong class="source-inline">_insert_an_entry</strong> function. Then, the actual models are saved in the local server filesystems, where the filename of the models and the path are defined by <strong class="source-inline">db_model_path</strong> and <strong class="source-inline">fname</strong> here.</p>
			<h3>Parsing the message</h3>
			<p>The <strong class="source-inline">_parse_message</strong> function<a id="_idIndexMarker383"/> just extracts the<a id="_idIndexMarker384"/> parameters from the received message:</p>
			<pre class="source-code">
def _parse_message(self, msg: List[Any]):
    component_id = msg[int(DBPushMsgLocation.component_id)]
    r = msg[int(DBPushMsgLocation.round)]
    mt = msg[int(DBPushMsgLocation.model_type)]
    model_id = msg[int(DBPushMsgLocation.model_id)]
    gene_time = msg[int(DBPushMsgLocation.gene_time)]
    meta_data = msg[int(DBPushMsgLocation.meta_data)]
    local_prfmc = 0.0
    if mt == ModelType.local:
        try: local_prfmc = meta_data["accuracy"]
        except: pass
    num_samples = 0
    try: num_samples = meta_data["num_samples"]
    except: pass
    return component_id, r, mt, model_id, gene_time, \
                                   local_prfmc, num_samples</pre>
			<p>This function parses the received message into parameters related to agent ID or aggregator ID (<strong class="source-inline">component_id</strong>), round number (<strong class="source-inline">r</strong>), message type (<strong class="source-inline">mt</strong>), <strong class="source-inline">model_id</strong>, time of generation of the models (<strong class="source-inline">gene_time</strong>), and performance data as a dictionary format (<strong class="source-inline">meta_data</strong>). The local performance data, <strong class="source-inline">local_prfmc</strong>, is extracted when the model type is local. The amount of sample data used at the local device is also extracted from <strong class="source-inline">meta_dect</strong>. All these extracted parameters are returned at<a id="_idIndexMarker385"/> the end.</p>
			<p>In the following section, we will explain the database implementation using the SQLite framework.</p>
			<h2 id="_idParaDest-117"><a id="_idTextAnchor121"/>efining the database with SQLite</h2>
			<p>The <strong class="source-inline">sqlite_db.py</strong> code<a id="_idIndexMarker386"/> creates the SQLite database and deals with storing and retrieving data from the database.</p>
			<h3>Importing libraries for the SQLite database</h3>
			<p><strong class="source-inline">sqlite_db.py</strong> imports <a id="_idIndexMarker387"/>the basic general libraries and <strong class="source-inline">ModelType</strong> as follows:</p>
			<pre class="source-code">
import sqlite3
import datetime
import logging
from fl_main.lib.util.states import ModelType</pre>
			<p>The <strong class="source-inline">ModelType</strong> from <strong class="source-inline">lib/util</strong> defines the type of the models: local models and (global) cluster models.</p>
			<h3>Defining and initializing the SQLiteDBHandler class</h3>
			<p>Then, the<a id="_idIndexMarker388"/> following code related to the <strong class="source-inline">SQLiteDBHandler</strong> class <a id="_idIndexMarker389"/>creates and initializes the SQLite database and inserts models into the SQLite database:</p>
			<pre class="source-code">
class SQLiteDBHandler:
    """
    SQLiteDB Handler class that creates and initialize
    SQLite DB, and inserts models to the SQLiteDB
    """</pre>
			<p>The initialization is very simple – just setting the <strong class="source-inline">db_file</strong> parameter passed from the <strong class="source-inline">PseudoDB</strong> instance to <strong class="source-inline">self.db_file</strong>:</p>
			<pre class="source-code">
def __init__(self, db_file):
    self.db_file = db_file</pre>
			<h3>Initializing the database</h3>
			<p>In the<a id="_idIndexMarker390"/> following <strong class="source-inline">initialize_DB</strong> function, the database tables are defined with local and cluster models using SQLite (<strong class="source-inline">sqlite3</strong>):</p>
			<pre class="source-code">
def initialize_DB(self):
    conn = sqlite3.connect(f'{self.db_file}')
    c = conn.cursor()
    c.execute('''CREATE TABLE local_models(model_id, \
        generation_time, agent_id, round, performance, \
        num_samples)''')
    c.execute('''CREATE TABLE cluster_models(model_id, \
        generation_time, aggregator_id, round, \
        num_samples)''')
    conn.commit()
    conn.close()</pre>
			<p>The tables are simplified in this example so that you can easily follow the uploaded local models an<a id="_idTextAnchor122"/>d their performance as well as the global models created by an aggregator. </p>
			<p>The <strong class="source-inline">local_models</strong> table has a model ID (<strong class="source-inline">model_id</strong>), the time the model is generated (<strong class="source-inline">generation_time</strong>), an agent ID uploaded of the local model (<strong class="source-inline">agent_id</strong>), round information (<strong class="source-inline">round</strong>), the performance data of the local model (<strong class="source-inline">performance</strong>), and the number of samples used for FedAvg aggregation (<strong class="source-inline">num_samples</strong>).</p>
			<p><strong class="source-inline">cluster_models</strong> has a model ID (<strong class="source-inline">model_id</strong>), the time the model is generated (<strong class="source-inline">generation_time</strong>), an aggregator ID (<strong class="source-inline">aggregator_id</strong>), round information (<strong class="source-inline">round</strong>), and the number of samples (<strong class="source-inline">num_samples</strong>).</p>
			<h3>Inserting an entry into the database</h3>
			<p>The following<a id="_idIndexMarker391"/> code for <strong class="source-inline">insert_an_entry</strong> inserts the data received as parameters using <strong class="source-inline">sqlite3</strong> libraries:</p>
			<pre class="source-code">
def insert_an_entry(self, component_id: str, r: int, mt: \
    ModelType, model_id: str, gtime: float, local_prfmc: \
    float, num_samples: int):
    conn = sqlite3.connect(self.db_file)
    c = conn.cursor()
    t = datetime.datetime.fromtimestamp(gtime)
    gene_time = t.strftime('%m/%d/%Y %H:%M:%S')
    if mt == ModelType.local:
        c.execute('''INSERT INTO local_models VALUES \
        (?, ?, ?, ?, ?, ?);''', (model_id, gene_time, \
        component_id, r, local_prfmc, num_samples))
    elif mt == ModelType.cluster:
        c.execute('''INSERT INTO cluster_models VALUES \
        (?, ?, ?, ?, ?);''', (model_id, gene_time, \
        component_id, r, num_samples))
    conn.commit()
    conn.close()</pre>
			<p>This function takes<a id="_idIndexMarker392"/> the parameters of <strong class="source-inline">component_id</strong> (agent ID or aggregator ID), round number (<strong class="source-inline">r</strong>), message type (<strong class="source-inline">mt</strong>), model ID (<strong class="source-inline">model_id</strong>), the time the model is generated (<strong class="source-inline">gtime</strong>), the local model’s performance data (<strong class="source-inline">local_prfmc</strong>), and the number of samples (<strong class="source-inline">num_samples</strong>) to insert an entry with the <strong class="source-inline">execute</strong> function of the SQLite library.</p>
			<p>If the model type is <em class="italic">local</em>, the information of the models is inserted into the <strong class="source-inline">local_models</strong> table. If the model type is <em class="italic">cluster</em>, the information of the models is inserted into the <strong class="source-inline">cluster_models</strong> table. </p>
			<p>Other functions, such as updating and deleting data from the database, are not implemented in this example code and it’s up to you to write those additional functions.</p>
			<p>In the following section, we will explain how to run the database server.</p>
			<h2 id="_idParaDest-118"><a id="_idTextAnchor123"/>Running the database server</h2>
			<p>Here is the code for <a id="_idIndexMarker393"/>running the database server with the SQLite database:</p>
			<pre class="source-code">
if __name__ == "__main__":
    pdb = PseudoDB()
    init_db_server(pdb.handler, pdb.db_ip, pdb.db_socket)</pre>
			<p>The instance of <strong class="source-inline">PseudoDB</strong> class is created as <strong class="source-inline">pdb</strong>. The <strong class="source-inline">pdb.handler</strong>, the database’s IP address (<strong class="source-inline">pdb.db_ip</strong>), and the database socket (<strong class="source-inline">pdb.db_socket</strong>) are used to start the process of receiving local and cluster models from an aggregator enabled by <strong class="source-inline">init_db_server</strong> from the <strong class="source-inline">communication_handler</strong> library in the <strong class="source-inline">util/lib</strong> folder.</p>
			<p>Now, we understand how to implement and run the database server. The database tables and schema discussed here are minimally designed so that we can understand the fundamentals of the FL server’s procedure. In the following section, we will discuss potential enhancements to the FL server.</p>
			<h1 id="_idParaDest-119"><a id="_idTextAnchor124"/>Potential enhancements to the FL server</h1>
			<p>Here are some <a id="_idIndexMarker394"/>of the key potential enhancements to the FL server discussed in this chapter.</p>
			<h2 id="_idParaDest-120"><a id="_idTextAnchor125"/>Redesigning the database </h2>
			<p>The database was<a id="_idIndexMarker395"/> intentionally designed with minimal table information in this book and needs to be extended, such as by having tables of the aggregator itself, agents, the initial base model, and the project info, among other things, in the database. For example, the FL system described here in this chapter does not support the termination and restart of the server and agent processes. Thus, the FL server implementation is not complete, as it loses most of the information when any of the systems is stopped or failed.</p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor126"/>Automating the registry of an initial model</h2>
			<p>In order to<a id="_idIndexMarker396"/> simplify the explanation of the process of registering the initial model, we defined the layers of the ML models using model names. This registration of the model in the system can be automated so that just loading a certain ML model, such as PyTorch or Keras models, with file extensions such as <strong class="source-inline">.pt/.pth</strong> and <strong class="source-inline">.h5</strong>, will be enough for the users of the FL systems to start the process.</p>
			<h2 id="_idParaDest-122"><a id="_idTextAnchor127"/>Performance metrics for local and global models</h2>
			<p>Again, to <a id="_idIndexMarker397"/>simplify<a id="_idIndexMarker398"/> the explanation of the <a id="_idIndexMarker399"/>FL server and the database-side functionalities, an accuracy value is just used as one of the performance criteria of the models. Usually, ML applications have many more metrics to keep track of as performance data and they needs to be enhanced together with the database and communications protocol design.</p>
			<h2 id="_idParaDest-123"><a id="_idTextAnchor128"/>Fine-tuned aggregation</h2>
			<p>In order to simplify<a id="_idIndexMarker400"/> the process of <a id="_idIndexMarker401"/>aggregating the local models, we just used FedAvg, a weighted averaging method. The number of samples can dynamically change depending on the local environment, and that aspect is enhanced by you. There are also a variety of model aggregation methods, which will be explained in <a href="B18369_07.xhtml#_idTextAnchor176"><em class="italic">Chapter 7</em></a>, <em class="italic">Model Aggregation</em>, of this book so that you can accommodate the best aggregation method depending on the ML applications to be created and integrated into the FL system.</p>
			<h1 id="_idParaDest-124"><a id="_idTextAnchor129"/>Summary</h1>
			<p>In this chapter, the basics and principles of FL server-side implementation were explained with actual code examples. Having followed the contents of this chapter, you should now be able to construct the FL server-side functionalities with model aggregation mechanisms. </p>
			<p>The server-side components that were introduced here involve basic communications and the registration of the agents and initial models, managing state information used for the aggregation, and the aggregation mechanisms for creating the global cluster models. In addition, we discussed the implementation of the database to just store the information of the ML models. The code was simplified so that you were able to understand the principles of server-side functionalities. Further enhancements to many other aspects of constructing a more sustainable, resilient, and scalable FL system are up to you. </p>
			<p>In the next chapter, we will discuss the principle of implementing the functionalities of the FL client and agent. The client side needs to provide some well-designed APIs for the ML applications for plugin use. Therefore, the chapter will discuss the FL client's core functionalities and libraries as well as the library integration into the very simple ML applications to enable the whole FL process. </p>
		</div>
	</body></html>