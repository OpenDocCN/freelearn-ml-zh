- en: '*Chapter 1:*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: R for Advanced Analytics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Explain advanced R programming constructs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Print the summary statistics of a real-world dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read data from CSV, text, and JSON files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write R markdown files for code reproducibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explain R data structures such as data.frame, data.table, lists, arrays, and
    matrices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement the cbind, rbind, merge, reshape, aggregate, and apply functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use packages such as dplyr, plyr, caret, tm, and many more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create visualizations using ggplot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will set the foundation for programming with R and understand
    the various syntax and data structures for advanced analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: R was one of the early programming languages developed for statistical computing
    and data analysis with good support for visualization. With the rise of data science,
    R emerged as an undoubted choice of programming language among many data science
    practitioners. Since R was open-source and extremely powerful in building sophisticated
    statistical models, it quickly found adoption in both industry and academia.
  prefs: []
  type: TYPE_NORMAL
- en: Tools and software such as SAS and SPSS were only affordable by large corporations,
    and traditional programming languages such as C/C++ and Java were not suitable
    for performing complex data analysis and building model. Hence, the need for a
    much more straightforward, comprehensive, community-driven, cross-platform compatible,
    and flexible programming language was a necessity.
  prefs: []
  type: TYPE_NORMAL
- en: Though Python programming language is increasingly becoming popular in recent
    times because of its industry-wide adoption and robust production-grade implementation,
    R is still the choice of programming language for quick prototyping of advanced
    machine learning models. R has one of the most populous collection of packages
    (a collection of functions/methods for accomplishing a complicated procedure,
    which otherwise requires a lot of time and effort to implement). At the time of
    writing this book, the **Comprehensive R Archive Network** (**CRAN**), a network
    of FTP and web servers around the world that store identical, up-to-date, versions
    of code and documentation for R, has more than 13,000 packages.
  prefs: []
  type: TYPE_NORMAL
- en: While there are numerous books and online resources on learning the fundamentals
    of R, in this chapter, we will limit the scope only to cover the important topics
    in R programming that will be used extensively in many data science projects.
    We will use a real-world dataset from the UCI Machine Learning Repository to demonstrate
    the concepts. The material in this chapter will be useful for learners who are
    new to R Programming. The upcoming chapters in supervised learning concepts will
    borrow many of the implementations from this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Real-World Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are plenty of open datasets available online these days. The following
    are some popular sources of open datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Kaggle**: A platform for hosting data science competitions. The official
    website is [https://www.kaggle.com/](https://www.kaggle.com/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**UCI Machine Learning Repository**: A collection of databases, domain theories,
    and data generators that are used by the machine learning community for the empirical
    analysis of machine learning algorithms. You can visit the official page via navigating
    to [https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)
    URL.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**data.gov.in**: Open Indian government data platform, which is available at
    [https://data.gov.in/](https://data.gov.in/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**World Bank Open Data**: Free and open access to global development data,
    which can be accessed from [https://data.worldbank.org/](https://data.worldbank.org/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increasingly, many private and public organizations are willing to make their
    data available for public access. However, it is restricted to only complex datasets
    where the organization is looking for solutions to their data science problem
    through crowd-sourcing platforms such as Kaggle. There is no substitute for learning
    from data acquired internally in the organization as part of a job that offers
    all kinds of challenges in processing and analyzing.
  prefs: []
  type: TYPE_NORMAL
- en: Significant learning opportunity and challenge concerning data processing comes
    from the public data sources as well, as not all the data from these sources are
    clean and in a standard format. JSON, Excel, and XML are some other formats used
    along with CSV, though CSV is predominant. Each format needs a separate encoding
    and decoding method and hence a reader package in R. In our next section, we will
    discuss various data formats and how to process the available data in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout this chapter and in many others, we will use the direct marketing
    campaigns (phone calls) of a Portuguese banking institution dataset from UCI Machine
    Learning Repository. ([https://archive.ics.uci.edu/ml/datasets/bank+marketing](https://archive.ics.uci.edu/ml/datasets/bank+marketing)).
    The following table describes the fields in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1: Portuguese banking institution dataset from UCI Machine Learning
    Repository (Part 1)'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_01_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.1: Portuguese banking institution dataset from UCI Machine Learning
    Repository (Part 1)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Figure 1.2: Portuguese banking institution dataset from UCI Machine Learning
    Repository (Part 2)](img/C12624_01_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.2: Portuguese banking institution dataset from UCI Machine Learning
    Repository (Part 2)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the following exercise, we will download the `bank.zip` dataset as a ZIP
    file and unzip it using the `unzip` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1: Using the unzip Method for Unzipping a Downloaded File'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will write an R script to download the Portuguese Bank
    Direct Campaign dataset from UCI Machine Learning Repository and extract the content
    of the ZIP file in a given folder using the `unzip` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Preform these steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: First, open R Studio on your system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, set the working directory of your choice using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: R codes in this book are implemented using the R version 3.2.2.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Download the ZIP file containing the datasets using the `download.file()` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, before we unzip the file in the working directory using the `unzip()`
    method, we need to choose a file and save its file path in R (for Windows) or
    specify the complete path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the folder where the ZIP file is unzipped:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, unzip the ZIP file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.3: Unzipping the bank.zip file'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_01_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.3: Unzipping the bank.zip file'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Reading Data from Various Data Formats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Data from digital systems is generated in various forms: browsing history on
    an e-commerce website, clickstream data, the purchase history of a customer, social
    media interactions, footfalls in a retail store, images from satellite and drones,
    and numerous other formats and types of data. We are living in an exciting time
    when technology is significantly changing lives, and enterprises are leveraging
    it to create their next data strategy to make better decisions.'
  prefs: []
  type: TYPE_NORMAL
- en: It is not enough to be able to collect a huge amount of different types of data;
    we also need to leverage value out of it. A CCTV footage captured throughout a
    day will help the law and order teams of the government in improving the real-time
    surveillance of public places. The challenge remains in how we will process a
    large volume of heterogeneous data formats within a single system.
  prefs: []
  type: TYPE_NORMAL
- en: Transaction data in the **Customer Relationship Management** (**CRM**) application
    would mostly be tabular and feed in social media is mostly text, audio, video,
    and images.
  prefs: []
  type: TYPE_NORMAL
- en: We can categorize the data formats as structured—tabular data such as CSV and
    database tables; unstructured—textual data such as tweets, FB posts, and word
    documents; and semi-structured. Unlike textual, which is hard for machines to
    process and understand, semi-structured provides associated metadata, which makes
    it easy for computers to process it. It's popularly used with many web applications
    for data exchange, and JSON is an example of the semi-structured data format.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will see how to load, process, and transform various data
    formats in R. Within the scope of this book, we will work with CSV, text, and
    JSON data.
  prefs: []
  type: TYPE_NORMAL
- en: CSV Files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CSV files are the most common type of data storage and exchange formats for
    structured data. R provides a method called `read.csv()` for reading data from
    a CSV file. It will read the data into a `data.frame` (more about it in the next
    section). There are many arguments that the method takes; the two required arguments
    are a path to the `filename` and `sep`, which specifies the character that separates
    the column values. The `summary()` method describes the six summary statistics,
    **min**, **first quartile**, **median**, **mean**, **third quartile**, and **max**.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, we'll read a CSV file and summarize its column.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 2: Reading a CSV File and Summarizing its Column'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will read the previously extracted CSV file and use the
    `summary` function to print the min, max, mean, median, 1st quartile, and 3rd
    quartile values of numeric variables and count the categories of the categorical
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Carry out these steps to read a CSV file and later summarize its columns:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, use the `read.csv` method and load the `bank-full.csv` into a DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the summary of the DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: JSON
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: JSON is the next most commonly used data format for sharing and storing data.
    It is unlike CSV files, which only deal with rows and columns of data where each
    has a definite number of columns. For example, in the e-commerce data of the customers,
    each row could be representing a customer with their information stored in separate
    columns. For a customer, if a column has no value, the field is stored as NULL.
  prefs: []
  type: TYPE_NORMAL
- en: JSON provides an added flexibility of having a varying number of fields for
    each customer. This type of flexibility relieves the developer from the burden
    of maintaining a schema as we have in traditional relational databases, wherein
    the same customer data might be spread across multiple tables to optimize for
    storage and querying time.
  prefs: []
  type: TYPE_NORMAL
- en: JSON is more of a key-value store type of storage, where all we care about is
    the keys (such as the name, age, and DOB) and their corresponding values. While
    this sounds flexible, proper care has to be taken, otherwise manageability might
    at times, go out of control. Fortunately, with the advent of big data technologies
    in recent days, many document stores (a subclass of the key-value store), popularly
    also known as **NoSQL** databases, are available for storing, retrieving, and
    processing data in such formats.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, the JSON file has data for cardamom (spices and condiments)
    cultivation district-wise in Tamil Nadu, India, for the year 2015-16\. The keys
    include **area** (hectare), **production** (in quintals), and **productivity**
    (average yield per hectare).
  prefs: []
  type: TYPE_NORMAL
- en: The `jsonlite` package provides an implementation to read and convert a JSON
    file into DataFrame, which makes the analysis simpler. The `fromJSON` method reads
    a JSON file, and if the `flatten` argument in the `fromJSON` function is set to
    `TRUE`, it gives a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 3: Reading a JSON file and Storing the Data in DataFrame'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will read a JSON file and store the data in the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the data from [https://data.gov.in/catalog/area-production-productivity-spices-condiments-district-wise-tamil-nadu-year-2015-16](https://data.gov.in/catalog/area-production-productivity-spices-condiments-district-wise-tamil-nadu-year-2015-16).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, use the following command to install the packages required for the system
    of read the JSON file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, read the JSON file using the `fromJSON` method, as illustrated here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The second element in the list contains the DataFrame with crop production
    value. Retrieve it from `json_data` and store as a DataFrame named `crop_production`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, use the following command to rename the columns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, print the top six rows using the `head()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unstructured data is the language of the web. All the social media, blogs, web
    pages, and many other sources of information are textual and untidy to extract
    any meaningful information. An increasing amount of research work is coming out
    from the **Natural Language Processing** (**NLP**) field, wherein computers are
    becoming better in understanding not only the meaning of the word but also the
    context in which it's used in a sentence. The rise of computer chatbot, which
    responds to a human query, is the most sophisticated form of understanding textual
    information.
  prefs: []
  type: TYPE_NORMAL
- en: In R, we will use the `tm` text mining package to show how to read, process,
    and retrieve meaningful information from text data. We will use a small sample
    of the **Amazon Food Review** dataset in Kaggle ([https://www.kaggle.com/snap/amazon-fine-food-reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews))
    for the exercise in this section.
  prefs: []
  type: TYPE_NORMAL
- en: In the `tm` package, collections of text documents are called `tm` package is
    `VCorpus` (`VCorpus` object, we can use the `inspect()` method. The following
    exercise uses the `lapply` method for looping through the first two reviews and
    casting the text as a character. You will learn more about the `apply` family
    of function in the *The Apply Family of Functions* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4: Reading a CSV File with Text Column and Storing the Data in VCorpus'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will read a CSV file with the text column and store the
    data in VCorpus.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s load the text mining package from the R into the system to read
    the text file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, read the first top 10 reviews from the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To store the text column in `VCorpus`, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To inspect the structure of first two reviews, execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using `lapply`, cast the first review as character and print:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will revisit the `review_corpus` dataset in a later section to show how to
    convert the unstructured textual information to structured tabular data.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from CSV, Text, and JSON, there are numerous other data formats depending
    upon the source of data and its usage. R has a rich collection of libraries that
    helps with many formats. R can import not only the standard formats (apart from
    the previous three) such as HTML tables and XML but also formats specific to an
    analytical tool such as SAS and SPSS. This democratization led to a significant
    migration of industry experts who were earlier working in the propriety tools
    (costly and often found with only the large corporations) to open source analytical
    programming languages such as R and Python.
  prefs: []
  type: TYPE_NORMAL
- en: Write R Markdown Files for Code Reproducibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The considerable success of analytics is a result of the way the information
    and knowledge network around the subject started to spread. More open source communities
    emerged, developers were happily sharing their work with the outer world, and
    many data projects were becoming reproducible. This change meant that work started
    by one person was soon getting adapted, improvised, and modified in many different
    forms by a community of people before it got adopted in an entirely different
    domain than the one from where it initially emerged. Imagine every research work
    that gets published in conference submitting a collection of code and data that
    is easily reproducible along with their research paper. This change is accelerating
    the pace at which an idea meets reality, and innovation will start to boom.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's see how to create such reproducible work in a single file that we
    call the **R Markdown** file. In the following activity, we will demonstrate how
    to create a new R Markdown file in RStudio. A detailed intro to R Markdown could
    be found at [https://rmarkdown.rstudio.com/lesson-1.html](https://rmarkdown.rstudio.com/lesson-1.html).
  prefs: []
  type: TYPE_NORMAL
- en: In the next activity, you will recreate the code shown in *Exercise 4*, *Reading
    a CSV File with Text Column and Storing the Data in VCorpus*, into an R Markdown.
    Observe in *Figure 4.2* that you have just written the explanation and the code
    in R Markdown, and when the **Knit to Word** action is performed, it interweaves
    the explanation, code, and its output neatly into a word document.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1: Create an R Markdown File to Read a CSV File and Write a Summary
    of Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this activity, we will create a R Markdown file to read a CSV file and print
    a small summary of the data in a word file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the activity:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open RStudio and navigate to the **R Markdown** option:![Figure 1.4: Creating
    a new R Markdown file in Rstudio](img/C12624_01_04.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 1.4: Creating a new R Markdown file in Rstudio'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Provide the **Title** and **Author** name for the document and select the **Default
    Output Format** as **Word**:![Figure 1.5: Using the read.csv method to read the
    data'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/C12624_01_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.5: Using the read.csv method to read the data'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Use the `read.csv()` method to read the `bank-full.csv` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, print the summary into a word file using the `summary` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.6: Final output after using the summary method](img/C12624_01_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.6: Final output after using the summary method'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found at page 438.
  prefs: []
  type: TYPE_NORMAL
- en: Data Structures in R
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In any programming language, data structures are the fundamental units of storing
    information and making it ready for further processing. Depending on the type
    of data, various forms of data structures are available for **storing** and **processing**.
    Each of the data structures explained in the next section has its characteristic
    features and applicability.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will explore each of it and how to use it with our data.
  prefs: []
  type: TYPE_NORMAL
- en: Vector
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`c()` method, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We can extract the second value in the vector by specifying the index in square
    brackets next to the vector name. Let''s review the following code where we subset
    the value in the second index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The collection of string concatenated with the `c()` method is a vector. It
    can store a homogenous collection of characters, integers, or floating point values.
    While trying to store an integer with character, an implicit type cast will happen,
    which will convert all the values to character.
  prefs: []
  type: TYPE_NORMAL
- en: Caution
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Note that it might not be the expected behavior every time. Caution is required,
    especially when the data is not clean. It may otherwise cause errors that are
    harder to find than the usual programming errors.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Matrix** is the higher dimension data structure used for storing *n*-dimensional
    data. It is suitable for storing tabular data. Similar to vector, the matrix also
    allows only homogenous collection of data in its rows and columns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code generates 16 random numbers drawn from a binomial distribution
    with a parameter, number of trials `(size) = 100`, and success probability equal
    to `0.4`. The `rbinom()` method in R is useful for generating such random numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to store `r_number` as a matrix, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Let's extend the text mining example we took in *Exercise 4*, *Reading a CSV
    File with Text Column and Storing the Data in VCorpus*, to understand the usage
    of matrix in text mining.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following two reviews. Use the `lapply` to type cast the first
    review to `as.character` and print:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now, in the following exercise, we will transform the data to remove stopwords,
    whitespaces, and punctuations from these two paragraphs. We will then perform
    stemming (both *looking* and *looked* will be reduced to look). Also, for consistency,
    convert all the text into lowercase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 5: Performing Transformation on the Data to Make it Available for
    the Analysis'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will perform the transformation on the data to make it
    available for further analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, use the following commands to convert all the characters in the data
    to lowercase:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, remove the stopwords from the data, such as, `a`, `the`, `an`, and many
    more:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Remove extra whitespaces between words using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Perform the stemming process, which will only keep the root of the word. For
    example, `looking` and `looked` will become `look`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have the text processed and cleaned up, we can create a document
    matrix that stores merely the frequency of the occurrence of distinct words in
    the two reviews. We will demonstrate how to count each word contained in the review.
    Each row of the matrix represents one review, and the columns are distinct words.
    Most of the values are zero because not all the words will be present in each
    review. In this example, we have a sparsity of 49%, which means only 51% of the
    matrix contains non-zero values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create `as.matrix()` method again. The matrix contains two documents (reviews)
    and 37 unique words. The count of a particular word in a document is retrieved
    by specifying the row and column index or name in the matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, store the results in a matrix using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To find the dimension of the matrix, that is, 2 documents and 37 words, use
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, print a subset of the matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, count the word `product` in document 1 using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: List
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While vector and matrix both are useful structures to be used in various computations
    in a program, it might not be sufficient for storing a real-world dataset, which
    most often contains data of mix types, like a customer table in CRM application
    has the customer name and age together in two columns. The list offers a structure
    to allow for storing two different types of data together.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, along with generating 16 random numbers, we have
    used the `sample()` method to generate 16 characters from the English alphabet.
    The `list` method stores both the integers and characters together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 6: Using the List Method for Storing Integers and Characters Together'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will use the `list` method to store randomly generated
    numbers and characters. The random numbers will be generated using the `rbinom`
    function, and the random characters will be selected from English alphabets A-Z.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, generate 16 random numbers drawn from a binomial distribution with parameter
    size equals `100` and the probability of success equals `0.4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, select 16 alphabets from English `LETTERS` without repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Put `r_numbers` and `r_characters` into a single list. The `list()` function
    will create the data structure list with `r_numbers` and `r_characters`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the following step, we will see a list with the integer and character vectors
    stored together.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s store and retrieve integer and character vectors from a list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, retrieve values in the character vector using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, retrieve the first value in the character vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Though this solves the requirement of storing heterogeneous data types together,
    its still doesn't put any integrity checks on the relationship between the values
    in the two vectors. If we would like to assign every *letter* to one *integer*.
    In the previous output, `V` represents `48`, `C` represents `53`, and so on.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A list is not robust to handle such one-to-one mapping. Consider the following
    code, instead of `16` characters, if we generate 18 random characters, and it
    still allows for storing it in a list. The last two characters have no associated
    mapping with the integer now.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, generate 16 random numbers drawn from a binomial distribution with parameter
    size equal to `100` and probability of success equal to `0.4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select any 18 alphabets from English `LETTERS` without repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Place `r_numbers` and `r_characters` into a single list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Activity 2: Create a List of Two Matrices and Access the Values'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this activity, you will create two matrices and retrieve a few values using
    the index of the matrix. You will also perform operations such as multiplication
    and subtraction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Create two matrices of size `10 x 4` and `4 x 5` by randomly generated numbers
    from a binomial distribution (use `rbinom` method). Call the matrix `mat_A` and
    `mat_B`, respectively.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, store the two matrices in a list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the list, access the row 4 and column 2 of `mat_A` and store it in variable
    `A`, and access row 2 and column 1 of `mat_B` and store it in variable `B`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiply the `A` and `B` matrices and subtract from row 2 and column 1 of `mat_A`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found at page 440.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: DataFrame
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the limitation of vector, matrix, and list, a data structure suitable for
    real-world datasets was a much-needed requirement for data science practitioners.
    DataFrames are an elegant way of storing and retrieving tabular data. We have
    already seen how DataFrame handles the rows and columns of data in *Exercise 3*,
    *Reading a JSON File and Storing the Data in DataFrame*. DataFrames will be extensively
    used throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7: Performing Integrity Checks Using DataFrame'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's revisit *step 6* of *Exercise 6*, *Using the List Method for Storing Integers
    and Characters Together*, where we discussed the integrity check when we attempted
    to store two unequal length vectors in a list and will see how DataFrame handles
    it differently. We will, once again, generate random numbers (`r_numbers`) and
    random characters (`r_characters`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, generate 16 random numbers drawn from a binomial distribution with parameter
    size equal to `100` and probability of success equal to `0.4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select any 18 alphabets from English `LETTERS` without repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Put `r_numbers` and `r_characters` into a single DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, the error in the previous output shows that the last two LETTERS,
    that is, `P` and `Q`, have no mapping with a corresponding random `INTEGER` generated
    using the binomial distribution.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Accessing any particular row and column in the DataFrame is similar to the matrix.
    We will show many tricks and techniques to best use the power of indexing in the
    DataFrame, which also includes some of the filtering options.
  prefs: []
  type: TYPE_NORMAL
- en: Every row in a DataFrame is a result of the tightly coupled collection of columns.
    Each column clearly defines the relationship each row of data has with every other
    one. If there is no corresponding value available in a column, it will be filled
    with NA. For example, a customer in a CRM application might not have filled their
    marital status, whereas a few other customers filled it. So, it becomes essential
    during application design to specify which columns are mandatory and which are
    optional.
  prefs: []
  type: TYPE_NORMAL
- en: Data Table
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the growing adaption of DataFrame came a time when its limitations started
    to surface. Particularly with large datasets, DataFrame performs poorly. In the
    complex analysis, we often create many intermediate DataFrames to store the results.
    However, R is built on an in-memory computation architecture, and it heavily depends
    on RAM. Unlike disk space, RAM is limited to either 4 or 8 GB in many standard
    desktops and laptops. DataFrame is not built efficiently to manage the memory
    during the computation, which often results in `out of memory error`, especially
    when working with large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to handle this issue, `data.table` inherited the `data.frame` functionality
    and offers fast and memory-efficient version for the following task on top of
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: File reader and writer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equi, non-equi, rolling, range, and interval joins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient memory management makes the development fast and reduces the latency
    between operations. The following exercise shows the significant difference `data.table`
    makes in computation time as compared to `data.frame`. First, we read the complete
    `fread()` method, which is one of the fast reading methods from `data.table`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 8: Exploring the File Read Operation'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will only show file read operations. You are encouraged
    to test the other functionalities ([https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html))
    and compare the data table capabilities over DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, load the data table package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Read the dataset using the `fread()` method of the `data.table` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, read the same CSV file using the `read.csv()` method of base package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Observe that `3.78` seconds elapsed for reading it through the `fread()` method,
    while the `read.csv` function took `4.91` seconds. The execution speed is almost
    *30%* faster. As the size of the data increasing, this difference is even more
    significant.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous output, the `user` time is the time spent by the current R session,
    and `system` time is the time spent by the operating system to complete the process.
    It's possible that you may get a different value after executing the `system.time`
    method even if you use the same dataset. It depends a lot on how busy your CPU
    was at the time of running the method. However, we should read the output of the
    `system.time` method relative to the comparison we are carrying out and not relative
    to the absolute values.
  prefs: []
  type: TYPE_NORMAL
- en: When the size of the dataset is too large, we have too many intermediate operations
    to get to the final output. However, keep in mind that `data.table` is not the
    magic wand that allows us to deal with a dataset of any size in R. The size of
    RAM still plays a significant role, and `data.table` is no substitute for distributed
    and parallel processing big data systems. However, even for the smaller dataset,
    the usage of `data.table` has shown much better performance than `data.frames`.
  prefs: []
  type: TYPE_NORMAL
- en: Data Processing and Transformation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have seen different ways to read and store data. Now, let's focus
    on the kind of data processing and transformation required to perform data analysis
    and draw insights or build models. Data in its raw form is hardly of any use,
    so it becomes essential to process it to make it suitable for any useful purpose.
    This section focuses on many methods in R that have widespread usage during data
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: cbind
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As the name suggests, it combines two or more vector, matrix, DataFrame, or
    table by column. `cbind` is useful when we have more than one vector, matrix,
    or DataFrame that need to be combined into one for analysis or visualization.
    The output of `cbind` varies based on the input data. The following exercise provides
    a few examples of `cbind`, which combines two vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 9: Exploring the cbind Function'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will implement the `cbind` function to combine two DataFrame
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate 16 random numbers drawn from a binomial distribution with parameter
    size equal to `100` and probability of success equal to `0.4`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, print the `r_numbers` values using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select any 16 alphabets from English `LETTERS` without repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, print the `r_characters` values using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Combine `r_numbers` and `r_characters` using `cbind`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the class (type of data structure) we obtain after using `cbind`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Observe a warning message in the output of `cbind` in the 5th step of this
    exercise:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The error means that the lengths of `r_numbers` and `r_characters` are not same
    (16 and 18, respectively). Note that the `cbind()` method, unlike `as.data.frame()`,
    doesn't throw an error. Instead, it automatically performs what is known as `r_numbers`
    `38` and `48` are recycled from the top to fill the 17th and 18th index.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider that we write the following command instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'It will now throw an error as we had shown earlier in the DataFrame section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: One needs to be careful by always checking for the dimensions and the class
    of data. Otherwise, it may lead to unwanted results. When we give two vectors,
    it creates a matrix by default on doing a `cbind`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Since we are not setting any seed value, the output of sample and `rbinom` will
    differ in each execution of the code.
  prefs: []
  type: TYPE_NORMAL
- en: rbind
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`rbind` is like `cbind`, but it combines by row instead of column. For `rbind`
    to work, the number of columns should be equal in both the DataFrames. It is useful
    in cases when we want to append an additional set of observations with an existing
    dataset where all the columns of the original dataset are the same and are in
    the same order. Let''s explore `rbind` in the following exercise.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 10: Exploring the rbind Function'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will combine two DataFrames using the `rbind` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate 16 random numbers drawn from a binomial distribution with parameter
    size equal to `100` and probability of success equal to 0.4:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, print the `r_numbers` values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select any 16 alphabets from English `LETTERS` without repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, print the `r_characters` using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, use the `rbind` method to print the combined value of `r_numbers`
    and `r_characters`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: From the last step, observe that the `rbind` function concatenates (binds) the
    `r_numbers` and `r_characters` as two rows of data, unlike `cbind`, where it was
    stacked in two columns. Except for the output, all the other rules of `cbind`
    apply to `rbind` as well.
  prefs: []
  type: TYPE_NORMAL
- en: The merge Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `merge()` function in R is particularly useful when there is more than one
    DataFrame to join using a common column (what we call a **primary key** in the
    database world). Merge has two different implementations for the DataFrame and
    data table, which behave mostly in the same way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 11: Exploring the merge Function'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will generate two DataFrames, that is, `df_one` and `df_two`,
    such that the `r_numbers` column uniquely identifies each row in each of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '**First DataFrame**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `set.seed()` method to ensure that the same random numbers are generated
    every time the code is run:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, generate any 16 random numbers between 1 to 30 without repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Generate any 16 characters from the English alphabet with repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Combine `r_numbers` and `r_characters` into one DataFrame named `df_one`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Second DataFrame**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `set.seed()` method for preserving the same random numbers over multiple
    runs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, generate any 16 random numbers between 1 to 30 without repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, generate any 16 characters from the English alphabet with repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Combine `r_numbers` and `r_characters` into one DataFrame named `df_two`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once we create the `df_one` and `df_two` DataFrames using the `cbind()` function,
    we are ready to perform some merge (will use the word JOIN, which means the same
    as `merge()`).
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's see how different type of joins give different results.
  prefs: []
  type: TYPE_NORMAL
- en: In the world of databases, JOINs are used to combine two or more than two tables
    using a common primary key. In databases, we use Structured Query Language (SQL)
    to perform the JOINs. In R, the `merge()` function helps us with the same functionality
    as SQL offers in databases. Also, instead of tables, we have DataFrames here,
    which is again a table with rows and columns of data.
  prefs: []
  type: TYPE_NORMAL
- en: Inner Join
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In *Exercise 11*, *Exploring the merge Function*, we created two DataFrames:
    `df_one` and `df_ two`. We will now join the two DataFrames using `26` (row number
    `7`) in the `r_numbers` column is common between the two DataFrames, where the
    corresponding character in the `r_characters` column is `R` in `df_one` and character
    `O` in `df_two`. In the output, `X` corresponds to the `df_one` DataFrame and
    `Y` correspond to the `df_two` DataFrame.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To merge the `df_one` and `df_two` DataFrames using the `r_numbers` column,
    use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Left Join
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`df_one` in the `r_numbers` column and adds `<NA>` as a value wherever the
    corresponding value in `df_two` is not found. For example, for `r_number = 2`,
    there is no value in `df_two`, whereas for `r_number = 26`, values in `df_one`
    and `df_two`, for the `r_characters` column is `R` and `O`, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To merge the `df_one` and `df_two` DataFrames using the `r_numbers` column,
    use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: Right Join
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`r_character` columns of `df_one` are `<NA>` wherever a match is not found.
    Again, `r_numbers = 26` is the only match.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To merge the `df_one` and `df_two` DataFrames using the `r_numbers` column,
    use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: Full Join
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike Left and Right Join, `r_numbers` column from both the DataFrames and
    adds `<NA>` in the `r_characters` column from the respective DataFrame. Observe
    that only the `r_number = 26` row has values from both the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'To merge the `df_one` and `df_two` DataFrames using the `r_numbers` column,
    use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: The reshape Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data is known to be in a `reshape` function is used often to convert between
    wide and long formats for a variety of operations to make the data useful for
    computation or analysis. In many visualizations, we use `reshape()` to convert
    wide format to long and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the Iris dataset. This dataset contains variables named `Sepal.Length`,
    `Sepal.Width`, `Petal.Length`, and `Petal.Width`, whose measurements are given
    in centimeters, for 50 flowers from each of 3 species of Iris, namely *setosa*,
    *versicolor*, and *virginica*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12: Exploring the reshape Function'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will explore the reshape function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, print the top five rows of the iris dataset using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the previous command is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create a variable called `Type` based on the following condition. When
    `Sepal.Width > 2` and `Sepal Width <= 3`, we will assign `TYPE 1` or `TYPE 2`.
    The type column is for demo purpose only and has no particular logic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Store the `Type`, `Sepal.Width`, and `Species` columns in the `df_iris` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, reshape `df_iris` into wide DataFrame using the following `reshape` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get a warning while running the `reshape` command, saying as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This warning means there were multiple values for `Type 1` and `Type 2` for
    the three species, so the reshape has picked the first occurrence of each of the
    species. In this case, the `1`, `51`, and `101` row numbers. We will now see how
    we could handle this transformation better in the `aggregate` function.
  prefs: []
  type: TYPE_NORMAL
- en: The aggregate Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Aggregation is a useful method for computing statistics such as count, averages,
    standard deviations, and quartiles, and it also allows for writing a custom function.
    In the following code, the formula (formula is a name of the data structure in
    R, not a mathematical equation) for each Iris species computes the mean of the
    numeric measures sepal and petal width and length. The first of the aggregate
    function argument is a formula that takes species and all the other measurements
    to compute the mean from all the observations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the previous command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: The Apply Family of Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If one has to debate on a few powerful features of R programming, the `apply`
    family of functions, would find a mention. It is used commonly to avoid using
    looping structures such as `for` and `while` even though they are available in
    R.
  prefs: []
  type: TYPE_NORMAL
- en: First, it's slow to run `for` loops in R and second, the implementation of the
    `apply` functions in R is based on efficient programming languages such as C/C++,
    which makes it extremely fast to loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many functions in the `apply` family. Depending on the structure
    of the input and output required, we select the appropriate function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`apply()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lapply()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sapply()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vapply()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mapply()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rapply()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tapply()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will discuss a few in this section.
  prefs: []
  type: TYPE_NORMAL
- en: The apply Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `apply()` function takes an array, including a matrix, as input and returns
    a vector, array, or list of values obtained by applying a function to margins
    of an array or matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 13: Implementing the apply Function'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will count the number of vowels in each column of a 100
    x 100 matrix of random letters from the English alphabet. The `MARGIN = 1` function
    will scan each row, and `MARGIN = 2` will specify the column. The same function
    will the count vowels in each row.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a 100 x 100 matrix of random letters (`ncol` is the number of columns
    and `nrow` is the number of rows) using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create a function named `c_vowel` to count the number of vowels in a given
    array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, use the `apply` function to run through each column of the matrix, and
    use the `c_vowel` function as illustrated here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The lapply Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `lapply` function looks similar to `apply()`, with a difference that it
    takes input as a *list* and returns a *list* as output. After rewriting our previous
    example in the following exercise, the output of class function shows that the
    output is a list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 14: Implementing the lapply Function'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will take a list of vectors and count the number of vowels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a list with two vector of random letters, each of size 100:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `lapply` function to run through on list `a` and `b`, and the `c_vowel`
    function to count the number of vowels from the list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the class (type) of the output. The `class()` function provides the type
    of data structure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The sapply Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `sapply` function is just a wrapper on the `lapply` function, where the
    output is a vector or matrix instead of a list. In the following code, observe
    the type of the output after applying `sapply` difference. The output returns
    a vector of integers, as we can check with the `class()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'To print the class of the output, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the previous command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: The tapply Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Apply a function to each cell of a ragged array, that is, to each (non-empty)
    group of values given by a unique combination of the levels of certain factors.
    The `tapply` function is quite useful when it comes to working on a subset level
    of data. For example, in our `aggregate` function, if we were to get an aggregate
    like standard deviation for the type of Iris species, we could use `tapply`. The
    following code shows how to use the `tapply` function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, calculate the standard deviation of sepal length for each Iris species:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, calculate the standard deviation of sepal width for each of the Iris
    species:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the previous command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's explore some popular and useful R packages that might be of value
    while building complex data processing methods, machine learning models, or data
    visualization.
  prefs: []
  type: TYPE_NORMAL
- en: Useful Packages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While there are more than thirteen thousand packages in the CRAN repository,
    some of the packages have a unique place and utility for some major functionality.
    So far, we saw many examples of data manipulations such as join, aggregate, reshaping,
    and sub-setting. The R packages we will discuss next will provide a plethora of
    functions, providing a wide range of data processing and transformation capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The dplyr Package
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `dplyr` package helps in the most common data manipulation challenges through
    five different methods, namely, `mutate()`, `select()`, `filter()`, `summarise()`,
    and `arrange()`. Let's revisit our direct marketing campaigns (phone calls) of
    a Portuguese banking institution dataset from UCI Machine Learning Repository
    to test out all these methods.
  prefs: []
  type: TYPE_NORMAL
- en: The `%>%` symbol in the following exercise is called **chain operator**. The
    output of the one operation is sent to the next one without explicitly creating
    a new variable. Such a chaining operation is storage efficient and makes the readability
    of the code easy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 15: Implementing the dplyr Package'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we are interested in knowing the average bank balance of people
    doing blue-collar jobs by their marital status. Use the functions from the `dplyr`
    package to get the answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `bank-full.csv` file into the `df_bank_detail` object using the
    `read.csv()` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, load the `dplyr` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select (filter) all the observations where the `job` column contains the value
    `blue-collar` and then group by the martial status to generate the summary statistic,
    `mean`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s find out the bank balance of customers with secondary education and
    default as `yes`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Much of complex analysis is done with ease. Note that the `mutate()` method
    helps in creating custom columns with certain calculation or logic.
  prefs: []
  type: TYPE_NORMAL
- en: The tidyr Package
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `tidyr` package has three essential functions—`gather()`, `separate()`,
    and `spread()`—for cleaning messy data.
  prefs: []
  type: TYPE_NORMAL
- en: The `gather()` function converts **wide** DataFrame to long by taking multiple
    columns and gathering them into key-value pairs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 16: Implementing the tidyr Package'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will explore the `tidyr` package and the functions associated
    with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `tidyr` library using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, set the `seed` to 100 using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an `r_name` object and store the 5 person names in it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For the `r_food_A` object, generate 16 random numbers between 1 to 30 without
    repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similarly, for the `r_food_B` object, generate 16 random numbers between 1
    to 30 without repetition:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create and print the data from the DataFrame using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `gather()` method from the `tidyr` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `spread()` function works the other way around of `gather()`, that is,
    it takes a long format and converts it into wide format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `separate()` function is useful in places where columns are a combination
    of values and is used for making it a key column for other purposes. We can separate
    out the key if it has a common separator character:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Activity 3: Create a DataFrame with Five Summary Statistics for All Numeric
    Variables from Bank Data Using dplyr and tidyr'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This activity will make you accustomed to selecting all numeric fields from
    the bank data and produce the summary statistics on numeric variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract all numeric variables from bank data using `select()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the `summarise_all()` method, compute min, 1st quartile, 3rd quartile,
    median, mean, max, and standard deviation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: You can learn more about the `summarise_all` function at [https://www.rdocumentation.org/packages/dplyr/versions/0.5.0/topics/summarise_all](https://www.rdocumentation.org/packages/dplyr/versions/0.5.0/topics/summarise_all).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Store the result in a DataFrame of wide format named `df_wide`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, to convert wide format to deep, use the gather, separate, and spread functions
    of the `tidyr` package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The final output should have one row for each variable and one column each of
    min, 1st quartile, 3rd quartile, median, mean, max, and standard deviation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you complete the activity, you should have the final output as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 440.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The plyr Package
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'What we saw with the `apply` functions could be done through the `plyr` package
    on a much bigger scale and robustness. The `plyr` package provides the ability
    to split the dataset into subsets, apply a common function to each subset, and
    combine the results into a single output. The advantage of using `plyr` over the
    `apply` function is features like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Speed of code execution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallelization of processing using `foreach` loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for list, DataFrame, and matrices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Better debugging of errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the function names in `plyr` are clearly defined based on input and output.
    For example, if an input is a DataFrame and output is list, the function name
    would be `dlply`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure from the *The Split-Apply-Combine Strategy for Data Analysis*
    paper displays all the different `plyr` functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7: Functions in the plyr packages'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_01_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.7: Functions in the plyr packages'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The `_` means the output will be discarded.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 17: Exploring the plyr Package'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will see how split-apply-combine makes things simple with
    the flexibility of controlling the input and output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `plyr` package using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, use the slightly tweaked version of the `c_vowel` function we created
    in the earlier example in *Exercise 13*, *Exploring the apply Function*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the `seed` to `101`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Store the value in the `r_characters` object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '`Input = DataFrame to output = list`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `dlply()` function and print the split in the row format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '`Input = data.frame to output = array`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can simply replace dlply with the `daply()` function and print the split
    in the column format as an array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: '`Input = DataFrame to output = DataFrame`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `ddply()` function and print the split:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In steps 5, 6, and 7, observe how we created a list, array, and data as an output
    for DataFrame input. All we must do is use a different function from `plyr`. This
    makes it easy to type cast between many possible combinations.
  prefs: []
  type: TYPE_NORMAL
- en: The caret Package
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `caret` package is particularly useful for building a predictive model,
    and it provides a structure for seamlessly following the entire process of building
    a predictive model. Starting from splitting data to training and testing dataset
    and variable importance estimation, we will extensively use the `caret` package
    in our chapters on regression and classification. In summary, `caret` provides
    tools for:'
  prefs: []
  type: TYPE_NORMAL
- en: Data splitting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pre-processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature selection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model tuning using resampling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variable importance estimation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will revisit the caret package with examples in *Chapter 4*, *Regression*,
    and *Chapter 5*, *Classification*.
  prefs: []
  type: TYPE_NORMAL
- en: Data Visualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An essential part of what we call `ggplot2`, a powerful package in R. Just like
    `dplyr` and `plyr`, `ggplot2` is built on the **Grammar of Graphics**, which is
    a tool that enables us to describe the components of a graphic concisely.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Good grammar will allow us to gain insight into the composition of complicated
    graphics and reveal unexpected connections between seemingly different graphics.
  prefs: []
  type: TYPE_NORMAL
- en: (Cox 1978) [Cox, D. R. (1978), "Some Remarks on the Role in Statistics of Graphical
    Methods," Applied Statistics, 27 (1), 4–9\. [3,26].
  prefs: []
  type: TYPE_NORMAL
- en: Scatterplot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A scatterplot is a type of plot or mathematical diagram using Cartesian coordinates
    to display values for typically two variables for a set of data. If the points
    are color-coded, an additional variable can be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is the most common type of chart and is extremely useful in spotting patterns
    in the data, especially between two variables. We will use our bank data again
    to do some EDA. Let''s use the Portuguese bank direct campaign dataset for the
    visualizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: '`ggplot` works in a layered way of stacking different elements of the plot.
    In the following example of this section, in the first layer, we provide the data
    to the `ggplot()` method and then map it with aesthetic details like *x* and *y*-axis,
    in the example, the `age` and `balance` values, respectively. Finally, to be able
    to identify some reasoning associated with few high bank balances, we added a
    color based on the type of job.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following command to plot the scatterplot of age and balance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 1.8: Scatterplot of age and balance.'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_01_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.8: Scatterplot of age and balance.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: From *Figure 1.8*, the distribution of bank balance with age looks much normal,
    with middle age showing a high bank balance whereas youngsters and old people
    are on the lower side of the spectrum.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, some outlier values seem to be coming from management and retired
    professionals.
  prefs: []
  type: TYPE_NORMAL
- en: In data visualization, it's always tempting to see a graph and jump to a conclusion.
    A data visual is for consuming the data better and not for drawing causal inference.
    Usually, an interpretation by an analyst is always vetted by a business. Graphs
    that are aesthetically pleasing often tempt you to put it into presentation deck.
    So, next time a beautiful chart gets into your presentation deck, carefully analyze
    what you are going to say.
  prefs: []
  type: TYPE_NORMAL
- en: Scatter Plot between Age and Balance split by Marital Status
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will draw three scatter plots in a single plot between age
    and balance split by marital status (one for each single, divorced, and married
    individuals).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you could split the distribution by marital status. The patterns seem
    to be consistent among the single, married, and divorced individuals. We used
    a method called `facet_wrap()` as the third layer in `ggplot`. It takes a `marital`
    variable as a formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 1.9: Scatter plot between age and balance split by marital status'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_01_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.9: Scatter plot between age and balance split by marital status'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Line Charts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A line chart or line graph is a type of chart that displays information as a
    series of data points called **markers** connected by straight line segments.
  prefs: []
  type: TYPE_NORMAL
- en: '`ggplot` uses an elegant `geom()` method, which helps in quickly switching
    between two visual objects. In the previous example, we saw `geom_point()` for
    the scatterplot. In line charts, the observations are connected by a line in the
    order of the variable on the *x*-axis. The shaded area surrounding the line represents
    the *95%* confidence interval, that is, there is 95% confidence that the actual
    regression line lies within the shaded area. We will discuss more on this idea
    in *Chapter 4*, *Regression*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following plot, we show the line chart of age and bank balance for single,
    married, and divorced individuals. It is not clear whether there is some trend,
    but one can see the pattern among the three categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 1.10: Line graph of age and balance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_01_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.10: Line graph of age and balance'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Histogram
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A histogram is a visualization consisting of rectangles whose area is proportional
    to the frequency of a variable and whose width is equal to the class interval.
  prefs: []
  type: TYPE_NORMAL
- en: The height of the bar in a histogram represents the number of observations in
    each group. In the following example, we are counting the number of observations
    for each type of job and marital status. **y** is a binary variable checking whether
    the client subscribed a term deposit or not (**yes**, **no**) as a response to
    the campaign call.
  prefs: []
  type: TYPE_NORMAL
- en: 'It looks like blue-collar individuals are responding to the campaign calls
    the least, and individuals in management jobs are subscribing to the term deposit
    the most:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 1.11: Histogram of count and job'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_01_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.11: Histogram of count and job'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Boxplot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A boxplot is a standardized way of displaying the distribution of data based
    on a five number summary (minimum, first quartile (Q1), median, third quartile
    (Q3), and maximum). Probably, boxplot is the only chart that encapsulates much
    information in a beautiful looking representation compared to any other charts.
    Observe the summary of the `age` variable by each `job` type. The five summary
    statistics, that is, min, first quartile, median, mean, third quartile, and max,
    are described succinctly by a boxplot.
  prefs: []
  type: TYPE_NORMAL
- en: 'The 25th and 75th percentiles, in the first and third quartiles, are shown
    by lower and upper hinges, respectively. The upper whisper, which extends from
    the hinges to the maximum value, is within an IQR of 1.5 *, from the hinge. This
    is where the IQR is the inter-quartile range or distance between the two quartiles.
    This is similar in case of the lower hinge. All the points that are outside the
    hinges are called **outliers**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following boxplot, we are looking at the summary of age with respect
    to each job type. The size of the box that is set to `varwidth = TRUE` in `geom_boxplot`
    shows the number of observations in the particular job type. The wider the box,
    the larger the number of observations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 1.12: Boxplot of age and job'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C12624_01_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.12: Boxplot of age and job'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we visited some basics of R programming data types, data structures,
    and important functions and packages. We described vectors, matrix, list, DataFrame,
    and data tables as different forms of storing data. In the data processing and
    transformation space, we explore the `cbind`, `rbind`, `merge`, `reshape`, `aggregate`,
    and `apply` family of functions.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed the most important packages in R such as `dplyr`, `tidyr`,
    and `plyr`. In the end, the `ggplot2` data visualization package was used to demonstrate
    various types of visualization and how to draw insights from them.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will use all that you have learned in this chapter for
    performing Exploratory Data Analysis (EDA). In EDA, data transformation and visualization
    you learned here will be useful for drawing inferences from data.
  prefs: []
  type: TYPE_NORMAL
