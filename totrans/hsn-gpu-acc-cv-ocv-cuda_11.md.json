["```py\nimport pycuda.driver as drv\nimport pycuda.autoinit\nfrom pycuda.compiler import SourceModule\n\nmod = SourceModule(\"\"\"\n  #include <stdio.h>\n\n  __global__ void myfirst_kernel()\n  {\n    printf(\"Hello,PyCUDA!!!\");\n  }\n\"\"\")\n\nfunction = mod.get_function(\"myfirst_kernel\")\nfunction(block=(1,1,1))\n```", "```py\nkernel (parameters for kernel,block=(tx,ty,tz) , grid=(bx,by,bz))\n```", "```py\nimport pycuda.driver as drv\nimport pycuda.autoinit\ndrv.init()\nprint(\"%d device(s) found.\" % drv.Device.count())\nfor i in range(drv.Device.count()):\n  dev = drv.Device(i)\n  print(\"Device #%d: %s\" % (i, dev.name()))\n  print(\" Compute Capability: %d.%d\" % dev.compute_capability())\n  print(\" Total Memory: %s GB\" % (dev.total_memory()//(1024*1024*1024)))\n\n  attributes = [(str(prop), value) \n    for prop, value in list(dev.get_attributes().items())]\n    attributes.sort()\n    n=0\n\n    for prop, value in attributes:\n      print(\" %s: %s \" % (prop, value),end=\" \")\n      n = n+1\n      if(n%2 == 0):\n        print(\" \")\n```", "```py\n\nimport pycuda.driver as drv\nimport pycuda.autoinit\nfrom pycuda.compiler import SourceModule\n\nmod = SourceModule(\"\"\"\n  #include <stdio.h>\n  __global__ void myfirst_kernel()\n  {\n    printf(\"I am in block no: %d \\\\n\", blockIdx.x);\n  }\n\"\"\")\n\nfunction = mod.get_function(\"myfirst_kernel\")\nfunction(grid=(4,1),block=(1,1,1))\n```", "```py\nimport pycuda.autoinit\nimport pycuda.driver as drv\nimport numpy\nfrom pycuda.compiler import SourceModule\nmod = SourceModule(\"\"\"\n\n  __global__ void add_num(float *d_result, float *d_a, float *d_b)\n  {\n     const int i = threadIdx.x; \n     d_result[i] = d_a[i] + d_b[i];\n  }\n\"\"\")\n\n```", "```py\n\nadd_num = mod.get_function(\"add_num\")\n\nh_a = numpy.random.randn(1).astype(numpy.float32)\nh_b = numpy.random.randn(1).astype(numpy.float32)\n\nh_result = numpy.zeros_like(h_a)\nd_a = drv.mem_alloc(h_a.nbytes)\nd_b = drv.mem_alloc(h_b.nbytes)\nd_result = drv.mem_alloc(h_result.nbytes)\ndrv.memcpy_htod(d_a,h_a)\ndrv.memcpy_htod(d_b,h_b)\n\nadd_num(\n  d_result, d_a, d_b,\n  block=(1,1,1), grid=(1,1))\ndrv.memcpy_dtoh(h_result,d_result)\nprint(\"Addition on GPU:\")\nprint(h_a[0],\"+\", h_b[0] , \"=\" , h_result[0])\n```", "```py\nimport pycuda.autoinit\nimport pycuda.driver as drv\nimport numpy\nN = 10\nfrom pycuda.compiler import SourceModule\nmod = SourceModule(\"\"\"\n\n  __global__ void add_num(float *d_result, float *d_a, float *d_b)\n {\n    const int i = threadIdx.x; \n    d_result[i] = d_a[i] + d_b[i];\n }\n\"\"\")\nadd_num = mod.get_function(\"add_num\")\nh_a = numpy.random.randn(N).astype(numpy.float32)\nh_b = numpy.random.randn(N).astype(numpy.float32)\nh_result = numpy.zeros_like(h_a)\nadd_num(\n  drv.Out(h_result), drv.In(h_a), drv.In(h_b),\n  block=(N,1,1), grid=(1,1))\nprint(\"Addition on GPU:\")\nfor i in range(0,N):\n  print(h_a[i],\"+\", h_b[i] , \"=\" , h_result[i])\n```", "```py\nimport pycuda.driver as drv\nstart = drv.Event()\nend=drv.Event()\n#Start Time\nstart.record()\n#The kernel code for which time is to be measured\n#End Time\nend.record()\nend.synchronize()\n#Measure time difference\nsecs = start.time_till(end)*1e-3\n```", "```py\nimport pycuda.autoinit\nimport pycuda.driver as drv\nimport numpy\nimport time\nimport math\n\nfrom pycuda.compiler import SourceModule\nN = 1000000\nmod = SourceModule(\"\"\"\n\n__global__ void add_num(float *d_result, float *d_a, float *d_b,int N)\n{\n int tid = threadIdx.x + blockIdx.x * blockDim.x; \n  while (tid < N)\n  {\n    d_result[tid] = d_a[tid] + d_b[tid];\n    tid = tid + blockDim.x * gridDim.x;\n  }\n}\n\"\"\")\n```", "```py\nstart = drv.Event()end=drv.Event()\nadd_num = mod.get_function(\"add_num\")\n\nh_a = numpy.random.randn(N).astype(numpy.float32)\nh_b = numpy.random.randn(N).astype(numpy.float32)\n\nh_result = numpy.zeros_like(h_a)\nh_result1 = numpy.zeros_like(h_a)\nn_blocks = math.ceil((N/1024))\nstart.record()\nadd_num(\n  drv.Out(h_result), drv.In(h_a), drv.In(h_b),numpy.uint32(N),\n  block=(1024,1,1), grid=(n_blocks,1))\nend.record()\nend.synchronize()\nsecs = start.time_till(end)*1e-3\nprint(\"Addition of %d element of GPU\"%N)\nprint(\"%fs\" % (secs))\n```", "```py\nstart = time.time()\nfor i in range(0,N):\n    h_result1[i] = h_a[i] +h_b[i]\nend = time.time()\nprint(\"Addition of %d element of CPU\"%N)\nprint(end-start,\"s\")\n```", "```py\nimport pycuda.driver as drv\nimport pycuda.autoinit \nfrom pycuda.compiler import SourceModule\nimport numpy\nmod = SourceModule(\"\"\"\n  __global__ void square(float *d_a)\n  {\n    int idx = threadIdx.x + threadIdx.y*5;\n    d_a[idx] = d_a[idx]*d_a[idx];\n  }\n\"\"\")\n```", "```py\nstart = drv.Event()\nend=drv.Event()\nh_a = numpy.random.randint(1,5,(5, 5))\nh_a = h_a.astype(numpy.float32)\nh_b=h_a.copy()\n\nstart.record()\n\nd_a = drv.mem_alloc(h_a.size * h_a.dtype.itemsize)\ndrv.memcpy_htod(d_a, h_a)\n\nsquare = mod.get_function(\"square\")\nsquare(d_a, block=(5, 5, 1), grid=(1, 1), shared=0)\n\nh_result = numpy.empty_like(h_a)\ndrv.memcpy_dtoh(h_result, d_a)\nend.record()\nend.synchronize()\nsecs = start.time_till(end)*1e-3\nprint(\"Time of Squaring on GPU without inout\")\nprint(\"%fs\" % (secs))\nprint(\"original array:\")\nprint(h_a)\nprint(\"Square with kernel:\")\nprint(h_result)\n```", "```py\nstart.record()\nstart.synchronize()\n\nsquare(drv.InOut(h_a), block=(5, 5, 1))\n\nend.record()\nend.synchronize()\n\nprint(\"Square with InOut:\")\nprint(h_a)\nsecs = start.time_till(end)*1e-3\nprint(\"Time of Squaring on GPU with inout\")\nprint(\"%fs\" % (secs))\n```", "```py\nimport pycuda.gpuarray as gpuarray\nimport numpy\nimport pycuda.driver as drv\n\nstart = drv.Event()\nend=drv.Event()\nstart.record()\nstart.synchronize()\n\nh_b = numpy.random.randint(1,5,(5, 5))\nd_b = gpuarray.to_gpu(h_b.astype(numpy.float32))\nh_result = (d_b**2).get()\nend.record()\nend.synchronize()\n\nprint(\"original array:\")\nprint(h_b)\nprint(\"doubled with gpuarray:\")\nprint(h_result)\nsecs = start.time_till(end)*1e-3\nprint(\"Time of Squaring on GPU with gpuarray\")\nprint(\"%fs\" % (secs))\n```", "```py\nimport pycuda.gpuarray as gpuarray\nimport pycuda.driver as drv\nimport numpy\nimport time\nimport pycuda.autoinit\nn=100\nh_a=numpy.float32(numpy.random.randint(1,5,(1,n)))\nh_b=numpy.float32(numpy.random.randint(1,5,(1,n)))\n\nstart=time.time()\nh_result=numpy.sum(h_a*h_b)\n\n#print(numpy.dot(a,b))\nend=time.time()-start\nprint(\"Answer of Dot Product using numpy\")\nprint(h_result)\nprint(\"Time taken for Dot Product using numpy\")\nprint(end,\"s\")\n```", "```py\nd_a = gpuarray.to_gpu(h_a)\nd_b = gpuarray.to_gpu(h_b)\n\nstart1 = drv.Event()\nend1=drv.Event()\nstart1.record()\n\nd_result = gpuarray.dot(d_a,d_b)\nend1.record()\nend1.synchronize()\nsecs = start1.time_till(end1)*1e-3\nprint(\"Answer of Dot Product on GPU\")\nprint(d_result.get())\nprint(\"Time taken for Dot Product on GPU\")\nprint(\"%fs\" % (secs))\nif(h_result==d_result.get()):\n  print(\"The computed dor product is correct\")\n```", "```py\n\nimport numpy as np\nfrom pycuda import driver\nfrom pycuda.compiler import SourceModule\nimport pycuda.autoinit\nMATRIX_SIZE = 3 \n\nmatrix_mul_kernel = \"\"\"\n__global__ void Matrix_Mul_Kernel(float *d_a, float *d_b, float *d_c)\n{\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  float value = 0;\n\n  for (int i = 0; i < %(MATRIX_SIZE)s; ++i) {\n    float d_a_element = d_a[ty * %(MATRIX_SIZE)s + i];\n    float d_b_element = d_b[i * %(MATRIX_SIZE)s + tx];\n    value += d_a_element * d_b_element;\n }\n\n   d_c[ty * %(MATRIX_SIZE)s + tx] = value;\n } \"\"\"\n\nmatrix_mul = matrix_mul_kernel % {'MATRIX_SIZE': MATRIX_SIZE}\n\nmod = SourceModule(matrix_mul)\n```", "```py\n\nh_a = np.random.randint(1,5,(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\nh_b = np.random.randint(1,5,(MATRIX_SIZE, MATRIX_SIZE)).astype(np.float32)\n\nd_a = gpuarray.to_gpu(h_a) \nd_b = gpuarray.to_gpu(h_b)\nd_c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n\nmatrixmul = mod.get_function(\"Matrix_Mul_Kernel\")\n\nmatrixmul(d_a, d_b,d_c_gpu, \n  block = (MATRIX_SIZE, MATRIX_SIZE, 1),\n)\nprint(\"*\" * 100)\nprint(\"Matrix A:\")\nprint(d_a.get())\n\nprint(\"*\" * 100)\nprint(\"Matrix B:\")\nprint(d_b.get())\n\nprint(\"*\" * 100)\nprint(\"Matrix C:\")\nprint(d_c_gpu.get())\n\n  # compute on the CPU to verify GPU computation\nh_c_cpu = np.dot(h_a, h_b)\nif h_c_cpu == d_c_gpu.get() :\n    print(\"The computed matrix multiplication is correct\")\n```", "```py\nimport pycuda.gpuarray as gpuarray\nimport pycuda.driver as drv\nfrom pycuda.elementwise import ElementwiseKernel\nfrom pycuda.curandom import rand as curand\nadd = ElementwiseKernel(\n  \"float *d_a, float *d_b, float *d_c\",\n  \"d_c[i] = d_a[i] + d_b[i]\",\n  \"add\")\n\n```", "```py\n\nn = 1000000\nd_a = curand(n)\nd_b = curand(n)\nd_c = gpuarray.empty_like(d_a)\nstart = drv.Event()\nend=drv.Event()\nstart.record()\nadd(d_a, d_b, d_c)\nend.record()\nend.synchronize()\nsecs = start.time_till(end)*1e-3\nprint(\"Addition of %d element of GPU\"%shape)\nprint(\"%fs\" % (secs))\n# check the result\nif d_c == (d_a + d_b):\n  print(\"The sum computed on GPU is correct\")\n```", "```py\nimport pycuda.gpuarray as gpuarray\nimport pycuda.driver as drv\nimport numpy\nfrom pycuda.reduction import ReductionKernel\nimport pycuda.autoinit\nn=5\nstart = drv.Event()\nend=drv.Event()\nstart.record()\nd_a = gpuarray.arange(n,dtype= numpy.uint32)\nd_b = gpuarray.arange(n,dtype= numpy.uint32)\nkernel = ReductionKernel(numpy.uint32,neutral=\"0\",reduce_expr=\"a+b\",map_expr=\"d_a[i]*d_b[i]\",arguments=\"int *d_a,int *d_b\")\nd_result = kernel(d_a,d_b).get()\nend.record()\nend.synchronize()\nsecs = start.time_till(end)*1e-3\nprint(\"Vector A\")\nprint(d_a)\nprint(\"Vector B\")\nprint(d_b)\nprint(\"The computed dot product using reduction:\")\nprint(d_result)\nprint(\"Dot Product on GPU\")\nprint(\"%fs\" % (secs))\n```", "```py\nInput Vector\n[7 5 9 2 9]\nScan Operation for cumulative sum\n[7,7+5,7+5+9,7+5+9+2,7+2+9+2+7]\n```", "```py\n\nimport pycuda.gpuarray as gpuarray\nimport pycuda.driver as drv\nimport numpy\nfrom pycuda.scan import InclusiveScanKernel\nimport pycuda.autoinit\nn=10\nstart = drv.Event()\nend=drv.Event()\nstart.record()\nkernel = InclusiveScanKernel(numpy.uint32,\"a+b\")\nh_a = numpy.random.randint(1,10,n).astype(numpy.int32)\nd_a = gpuarray.to_gpu(h_a)\nkernel(d_a)\nend.record()\nend.synchronize()\nsecs = start.time_till(end)*1e-3\nassert(d_a.get() == numpy.cumsum(h_a,axis=0)).all()\nprint(\"The input data:\")\nprint(h_a)\nprint(\"The computed cumulative sum using Scan:\")\nprint(d_a.get())\nprint(\"Cumulative Sum on GPU\")\nprint(\"%fs\" % (secs))\n```"]