<html><head></head><body>
<div id="_idContainer155">
<h1 class="chapter-number" id="_idParaDest-268"><a id="_idTextAnchor447"/><span class="koboSpan" id="kobo.1.1">17</span></h1>
<h1 id="_idParaDest-269"><a id="_idTextAnchor448"/><span class="koboSpan" id="kobo.2.1">Human-in-the-Loop Machine Learning</span></h1>
<p><span class="koboSpan" id="kobo.3.1">Machine learning modeling is more than just machine learning developers and engineers sitting behind their computers to build and revise components of a machine learning life cycle. </span><span class="koboSpan" id="kobo.3.2">Incorporating feedback from domain experts, or even the non-expert crowd, is key in bringing more reliable and application-oriented models to production. </span><span class="koboSpan" id="kobo.3.3">This concept, which is called human-in-the-loop machine learning, is about benefiting from human intelligence and expert knowledge in different stages of a life cycle to further improve the performance and reliability of </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">our models.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">In this chapter, we will cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.7.1">Humans in the machine learning </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">life cycle</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.9.1">Human-in-the-loop modeling</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.10.1">By the end of this chapter, you will know about the benefits and challenges of incorporating human intelligence in your machine learning </span><span class="No-Break"><span class="koboSpan" id="kobo.11.1">modeling projects.</span></span></p>
<h1 id="_idParaDest-270"><a id="_idTextAnchor449"/><span class="koboSpan" id="kobo.12.1">Humans in the machine learning life cycle</span></h1>
<p><span class="koboSpan" id="kobo.13.1">Developing</span><a id="_idIndexMarker911"/><span class="koboSpan" id="kobo.14.1"> and improving different components of a machine learning life cycle to bring a reliable and high-performance model to production is a collaborative effort that can benefit from expert and non-expert human feedback (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.15.1">Figure 17</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.16.1">.1</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">):</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer154">
<span class="koboSpan" id="kobo.18.1"><img alt="Figure 17.1 – Human﻿s in the machine learning life cycle" src="image/B16369_17_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.19.1">Figure 17.1 – Humans in the machine learning life cycle</span></p>
<p><span class="koboSpan" id="kobo.20.1">For </span><a id="_idIndexMarker912"/><span class="koboSpan" id="kobo.21.1">example, a radiologist can help in annotating radiological images while most people with good vision capabilities can easily label cat and dog images. </span><span class="koboSpan" id="kobo.21.2">But incorporating human feedback is not limited to data annotation at the beginning of a </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">life cycle.</span></span></p>
<p><span class="koboSpan" id="kobo.23.1">We can benefit from human intelligence and expertise to improve data preparation, feature engineering, and representation learning aspects of a life cycle, as well as model training and testing, and eventually model deployment and monitoring. </span><span class="koboSpan" id="kobo.23.2">In each of these stages, human feedback can be incorporated either passively or actively, which allows us to bring a better model </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">into production.</span></span></p>
<p><span class="koboSpan" id="kobo.25.1">Passive human-in-the-loop</span><a id="_idIndexMarker913"/><span class="koboSpan" id="kobo.26.1"> is about collecting feedback and information from experts and non-experts and benefitting from that the next time we revise components of the corresponding machine learning modeling system. </span><span class="koboSpan" id="kobo.26.2">In this process, the feedback and extra information help in identifying opportunities for improving the components of the life cycle and identifying data and concept drift to bring a better model into production. </span><span class="koboSpan" id="kobo.26.3">In active human-in-the-loop machine learning, the infrastructure and one or all of the life cycle components need to be designed in a way that the extra human-in-the-loop information and data can be actively and continuously incorporated to improve data analysis </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">and </span></span><span class="No-Break"><a id="_idIndexMarker914"/></span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">modeling.</span></span></p>
<p><span class="koboSpan" id="kobo.29.1">First, we will review expert feedback collection and how to effectively benefit from it in improving </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">our model</span><a id="_idTextAnchor450"/><span class="koboSpan" id="kobo.31.1">s.</span></span></p>
<h2 id="_idParaDest-271"><a id="_idTextAnchor451"/><span class="koboSpan" id="kobo.32.1">Expert feedback collection</span></h2>
<p><span class="koboSpan" id="kobo.33.1">The </span><a id="_idIndexMarker915"/><span class="koboSpan" id="kobo.34.1">ultimate goal of building a piece of technology on top of one or multiple machine learning modes is to provide a tool for users, experts, or non-experts for a specific objective, such as healthcare image classification, stock price prediction, credit risk estimation, and product recommendation in platforms such as Amazon. </span><span class="koboSpan" id="kobo.34.2">For example, we can collect feedback for data annotation or later in the production stage for drift detection. </span><span class="koboSpan" id="kobo.34.3">We can then use this feedback to improve our models. </span><span class="koboSpan" id="kobo.34.4">However, this feedback could extend beyond the purposes of just data annotation or identifying data and </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">concept drift.</span></span></p>
<p><span class="koboSpan" id="kobo.36.1">We can incorporate expert feedback for four major purposes: data generation and annotation, data filtering, model selection, and model monitoring. </span><span class="koboSpan" id="kobo.36.2">Expert feedback collection for annotation and monitoring is generally similar to non-expert data collection except for the fact that in some applications, expertise is of necessity, such as in classifying </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">radiological images.</span></span></p>
<p><span class="koboSpan" id="kobo.38.1">For model selection, we can use expert feedback to not need to rely exclusively on the performance measures we use for model performance assessment and, consequently, select the best model, but to detect red flags according to wrong predictions or rely on explainability information for our models, such as if features that contribute the most in terms of predictions are of </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">lowest relevance.</span></span></p>
<p><span class="koboSpan" id="kobo.40.1">We can also benefit from experts’ feedback in monitoring our models. </span><span class="koboSpan" id="kobo.40.2">Drift detection, as discussed in </span><a href="B16369_11.xhtml#_idTextAnchor300"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.41.1">Chapter 11</span></em></span></a><span class="koboSpan" id="kobo.42.1">, </span><em class="italic"><span class="koboSpan" id="kobo.43.1">Avoiding and Detecting Data and Concept Drifts</span></em><span class="koboSpan" id="kobo.44.1">, is crucial to ensure the reliability of our models in production. </span><span class="koboSpan" id="kobo.44.2">In many applications, users of our models could be experts in specific domains, such as healthcare and drug discovery. </span><span class="koboSpan" id="kobo.44.3">In such cases, we need to make sure we continuously collect their feedback and use this to detect and eliminate drifts in </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">our models.</span></span></p>
<p><span class="koboSpan" id="kobo.46.1">Collecting </span><a id="_idIndexMarker916"/><span class="koboSpan" id="kobo.47.1">feedback from experts as users of our machine learning models should not be limited to getting their binary response of “good” versus “bad.” </span><span class="koboSpan" id="kobo.47.2">We need to provide enough information about our models and their predictions and ask experts to provide their feedback, </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">as follows:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.49.1">Provide sufficient information</span></strong><span class="koboSpan" id="kobo.50.1">: When asking for feedback from expert users of our models, we need to provide sufficient information to get better and more relevant feedback. </span><span class="koboSpan" id="kobo.50.2">For example, in addition to the performance of our model in testing and production, or wrong and correct predictions for a specific set of data points, we can also provide explainability information on how the model came up with its decision for those data points. </span><span class="koboSpan" id="kobo.50.3">This type of information could help the users provide better feedback that will help us in improving </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">our models.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.52.1">Don’t ask for translations</span></strong><span class="koboSpan" id="kobo.53.1">: Many of the users of our models might have limited statistical and machine learning modeling knowledge. </span><span class="koboSpan" id="kobo.53.2">So, asking them to convert their opinions and ideas into technical terms would limit efficient feedback collection. </span><span class="koboSpan" id="kobo.53.3">You need to provide sufficient information and ask for their feedback and have a back-and-forth conversation to convert their insights into actionable items for </span><span class="No-Break"><span class="koboSpan" id="kobo.54.1">model improvement.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.55.1">Design for automated feedback collection</span></strong><span class="koboSpan" id="kobo.56.1">: Although it is better to not ask for translations, as pointed out earlier, you can move toward more automated feedback collection using clear and detailed questions and proper infrastructure design to collect the feedback and incorporate it into your models. </span><span class="koboSpan" id="kobo.56.2">For example, you can use machine learning explainability and ask whether the most informative features used by the model for predicting the output of a specific set of data points are relevant to the task </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">or not.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.58.1">Human-in-the-loop has its own challenges, such as in preserving privacy when third-party companies are needed to monitor models and pipelines, or when there would be specific legal barriers in sharing data coming from collaborators and business partners with others in our teams and organizations. </span><span class="koboSpan" id="kobo.58.2">We need to keep these challenges in mind when we’re designing so that we can benefit from human feedback in our machine learning </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">life cycles.</span></span></p>
<p><span class="koboSpan" id="kobo.60.1">Although </span><a id="_idIndexMarker917"/><span class="koboSpan" id="kobo.61.1">we can collect feedback in different stages of the machine learning life cycle to improve our models, there are techniques such as active learning (which we will cover next) that can help us bring a better model with lower cost </span><span class="No-Break"><span class="koboSpan" id="kobo.62.1">into produc</span><a id="_idTextAnchor452"/><span class="koboSpan" id="kobo.63.1">tion.</span></span></p>
<h1 id="_idParaDest-272"><a id="_idTextAnchor453"/><span class="koboSpan" id="kobo.64.1">Human-in-the-loop modeling</span></h1>
<p><span class="koboSpan" id="kobo.65.1">Despite more high-quality </span><a id="_idIndexMarker918"/><span class="koboSpan" id="kobo.66.1">annotated data points being more valuable, the cost of annotating data, specifically when domain expertise is of necessity, could be very high. </span><span class="koboSpan" id="kobo.66.2">Active learning is a strategy that helps us in generating and labeling data to improve the performance of our models at a lower</span><a id="_idTextAnchor454"/><span class="koboSpan" id="kobo.67.1"> cost. </span><span class="koboSpan" id="kobo.67.2">In an active learning setting, we aim to benefit from a model with a limited amount of data and iteratively select new data points to be labeled, or their continuous value identified, with the aim of achieving higher performance (Wu et al., 2022; Ren et al., 2021; Burbidge et al., 2007). </span><span class="koboSpan" id="kobo.67.3">The model queries new instances to be annotated by experts or non-experts, or their labels or continuous values are identified via any computational or experimental technique. </span><span class="koboSpan" id="kobo.67.4">However, instead of the instances being selected randomly, there are techniques for new instance selection to help us in achieving better models with a lower number of instances and iterations (</span><em class="italic"><span class="koboSpan" id="kobo.68.1">Table 17.1</span></em><span class="koboSpan" id="kobo.69.1">). </span><span class="koboSpan" id="kobo.69.2">Each of these techniques has its advantages and disadvantages. </span><span class="koboSpan" id="kobo.69.3">For example, </span><em class="italic"><span class="koboSpan" id="kobo.70.1">uncertainty sampling</span></em><span class="koboSpan" id="kobo.71.1"> is simple but its effect on performance might be limited if uncertainty in the predicted output of instances is not highly correlated with </span><span class="No-Break"><span class="koboSpan" id="kobo.72.1">model error:</span></span></p>
<table class="No-Table-Style" id="table001-12">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.73.1">Data-Centric</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.74.1">Model-Centric</span></strong></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.75.1">Uncertainty sampling</span></strong></span></p>
<p><span class="koboSpan" id="kobo.76.1">Selecting instances with the most uncertainty (in inference), which could be instances closest to the decision boundary in </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">classification problems</span></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.78.1">Expected </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.79.1">model change</span></strong></span></p>
<p><span class="koboSpan" id="kobo.80.1">Selecting instances that know their labels results in the biggest impact on the </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">current model</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.82.1">Density-weighted </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.83.1">uncertainty sampling</span></strong></span></p>
<p><span class="koboSpan" id="kobo.84.1">Selecting instances that not only have the highest uncertainty but also are representative of many other data points that rely on the density of data in </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">feature space</span></span></p>
</td>
<td class="No-Table-Style">
<p><strong class="bold"><span class="koboSpan" id="kobo.86.1">Estimation of </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.87.1">error reduction</span></strong></span></p>
<p><span class="koboSpan" id="kobo.88.1">Selecting instances that know their labels would result in the biggest future </span><span class="No-Break"><span class="koboSpan" id="kobo.89.1">error reduction</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.90.1">Query-by-committee</span></strong></span></p>
<p><span class="koboSpan" id="kobo.91.1">Multiple models (the committee) get trained and instances with the highest disagreement in their prediction </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">get selected</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.93.1">Variance reduction</span></strong></span></p>
<p><span class="koboSpan" id="kobo.94.1">Selecting instances that know their labels would result in the most reduction in the model’s uncertainty about </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">its parameters</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.96.1">Table 17.1 – Active learning techniques for instance election to be annotated in each step</span></p>
<p><span class="koboSpan" id="kobo.97.1">In this chapter, we focused on introducing concepts and techniques behind human-in-the-loop. </span><span class="koboSpan" id="kobo.97.2">However, there are Python libraries such</span><a id="_idIndexMarker919"/><span class="koboSpan" id="kobo.98.1"> as </span><strong class="source-inline"><span class="koboSpan" id="kobo.99.1">modAL</span></strong><span class="koboSpan" id="kobo.100.1"> (</span><a href="https://modal-python.readthedocs.io/en/latest/"><span class="koboSpan" id="kobo.101.1">https://modal-python.readthedocs.io/en/latest/</span></a><span class="koboSpan" id="kobo.102.1">) that can help you in implementing some of these techniques in your projects to bring human feedback into your machine learning </span><span class="No-Break"><span class="koboSpan" id="kobo.103.1">life cycle.</span></span><a id="_idTextAnchor455"/></p>
<h1 id="_idParaDest-273"><a id="_idTextAnchor456"/><span class="koboSpan" id="kobo.104.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.105.1">In this chapter, you learned about some of the important concepts in human-in-the-loop machine learning, which can help you in better establishing collaboration between you and your team with experts or non-experts so that you can incorporate their feedback into your machine learning </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">modeling projects.</span></span></p>
<p><span class="koboSpan" id="kobo.107.1">This was the last chapter of this book. </span><span class="koboSpan" id="kobo.107.2">I hope you learned enough about different approaches to improve your machine learning models and build better ones so that you can start your journey toward becoming an expert in </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">this domain.</span></span><a id="_idTextAnchor457"/></p>
<h1 id="_idParaDest-274"><a id="_idTextAnchor458"/><span class="koboSpan" id="kobo.109.1">Questions</span></h1>
<ol>
<li><span class="koboSpan" id="kobo.110.1">Is human-in-the-loop machine learning limited to data annotation </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">and labeling?</span></span></li>
<li><span class="koboSpan" id="kobo.112.1">What is the difference between uncertainty sampling and density-weighted uncertainty sampling in selecting instances in each step of an active </span><span class="No-Break"><span class="koboSpan" id="kobo.113.1">learning process?</span></span><a id="_idTextAnchor459"/></li>
</ol>
<h1 id="_idParaDest-275"><a id="_idTextAnchor460"/><span class="koboSpan" id="kobo.114.1">References</span></h1>
<ul>
<li><span class="koboSpan" id="kobo.115.1">Amershi, Saleema, et al. </span><em class="italic"><span class="koboSpan" id="kobo.116.1">Power to the people: The role of humans in interactive machine learning</span></em><span class="koboSpan" id="kobo.117.1">. </span><span class="koboSpan" id="kobo.117.2">Ai Magazine 35.4 (</span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">2014): 105-120.</span></span></li>
<li><span class="koboSpan" id="kobo.119.1">Wu, Xingjiao, et al. </span><em class="italic"><span class="koboSpan" id="kobo.120.1">A survey of human-in-the-loop for machine learning</span></em><span class="koboSpan" id="kobo.121.1">. </span><span class="koboSpan" id="kobo.121.2">Future Generation Computer Systems 135 (</span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">2022): 364-381.</span></span></li>
<li><span class="koboSpan" id="kobo.123.1">Ren, Pengzhen, et al. </span><em class="italic"><span class="koboSpan" id="kobo.124.1">A survey of deep active learning</span></em><span class="koboSpan" id="kobo.125.1">. </span><span class="koboSpan" id="kobo.125.2">ACM computing surveys (CSUR) 54.9 (</span><span class="No-Break"><span class="koboSpan" id="kobo.126.1">2021): 1-40.</span></span></li>
<li><span class="koboSpan" id="kobo.127.1">Burbidge, Robert, Jem J. </span><span class="koboSpan" id="kobo.127.2">Rowland, and Ross D. </span><span class="koboSpan" id="kobo.127.3">King. </span><em class="italic"><span class="koboSpan" id="kobo.128.1">Active learning for regression based on query by committee</span></em><span class="koboSpan" id="kobo.129.1">. </span><span class="koboSpan" id="kobo.129.2">Intelligent Data Engineering and Automated Learning-IDEAL 2007: 8th International Conference, Birmingham, UK, December 16-19, 2007. </span><span class="koboSpan" id="kobo.129.3">Proceedings 8. </span><span class="koboSpan" id="kobo.129.4">Springer Berlin </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">Heidelberg, 2007.</span></span></li>
<li><span class="koboSpan" id="kobo.131.1">Cai, Wenbin, Ya Zhang, and Jun Zhou. </span><em class="italic"><span class="koboSpan" id="kobo.132.1">Maximizing expected model change for active learning in regression</span></em><span class="koboSpan" id="kobo.133.1">. </span><span class="koboSpan" id="kobo.133.2">2013 IEEE 13th international conference on data mining. </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">IEEE, 2013.</span></span></li>
<li><span class="koboSpan" id="kobo.135.1">Roy, Nicholas, and Andrew McCallum. </span><em class="italic"><span class="koboSpan" id="kobo.136.1">Toward optimal active learning through monte carlo estimation of error reduction</span></em><span class="koboSpan" id="kobo.137.1">. </span><span class="koboSpan" id="kobo.137.2">ICML, Williamstown 2 (</span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">2001): 441-448.</span></span></li>
<li><span class="koboSpan" id="kobo.139.1">Donmez, Pinar, Jaime G. </span><span class="koboSpan" id="kobo.139.2">Carbonell, and Paul N. </span><span class="koboSpan" id="kobo.139.3">Bennett. </span><em class="italic"><span class="koboSpan" id="kobo.140.1">Dual strategy active learning</span></em><span class="koboSpan" id="kobo.141.1">. </span><span class="koboSpan" id="kobo.141.2">Machine Learning: ECML 2007: 18th European Conference on Machine Learning, Warsaw, Poland, September 17-21, 2007. </span><span class="koboSpan" id="kobo.141.3">Proceedings 18. </span><span class="koboSpan" id="kobo.141.4">Springer Berlin </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">Heidelberg, 2007.</span></span></li>
</ul>
</div>


<div id="_idContainer156">
<h1 id="_idParaDest-276"><a id="_idTextAnchor461"/><span class="koboSpan" id="kobo.1.1">Assessments</span></h1>
<h1 id="_idParaDest-277"><em class="italic"><a id="_idTextAnchor462"/></em><a href="B16369_01.xhtml#_idTextAnchor015"><em class="italic"><span class="koboSpan" id="kobo.2.1">Chapter 1</span></em></a><span class="koboSpan" id="kobo.3.1"> – Beyond Code Debugging</span></h1>
<ol>
<li><span class="koboSpan" id="kobo.4.1">Yes – here is an example that was provided in </span><span class="No-Break"><span class="koboSpan" id="kobo.5.1">this chapter:</span></span><pre class="source-code"><span class="koboSpan" id="kobo.6.1">
def odd_counter(num_list: list):    """    :param num_list: list of integers to be checked for identifying odd numbers    :return: return an integer as the number of odd numbers in the input list    """    odd_count = 0    for num in num_list:        if (num % 2) == 0:            print("{} is even".format(num))        else:            print("{} is even".format(num))        odd_count += 1    return odd_countnum_list = [1, 2, 5, 8, 9]print(odd_counter(num_list))</span></pre></li> <li><span class="koboSpan" id="kobo.7.1">Here are </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">their definitions:</span></span><ul><li><strong class="source-inline"><span class="koboSpan" id="kobo.9.1">AttributeError</span></strong><span class="koboSpan" id="kobo.10.1">: This type of error is raised when an attribute is used for an object that it is not defined for. </span><span class="koboSpan" id="kobo.10.2">For example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.11.1">isnull</span></strong><span class="koboSpan" id="kobo.12.1"> is not defined for a list. </span><span class="koboSpan" id="kobo.12.2">So, </span><strong class="source-inline"><span class="koboSpan" id="kobo.13.1">my_list. </span><span class="koboSpan" id="kobo.13.2">isnull()</span></strong><span class="koboSpan" id="kobo.14.1"> results </span><span class="No-Break"><span class="koboSpan" id="kobo.15.1">in </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.16.1">AttributeError</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.17.1">.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.18.1">NameError</span></strong><span class="koboSpan" id="kobo.19.1">: This error is raised when you try to call a function, class, or other names and modules that are not defined in your code. </span><span class="koboSpan" id="kobo.19.2">For example, if you haven’t defined a </span><strong class="source-inline"><span class="koboSpan" id="kobo.20.1">neural_ network</span></strong><span class="koboSpan" id="kobo.21.1"> class in your code but call it in your code as </span><strong class="source-inline"><span class="koboSpan" id="kobo.22.1">neural_network()</span></strong><span class="koboSpan" id="kobo.23.1">, you will get a </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.24.1">NameError</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.25.1"> message.</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.26.1">Higher dimensionality makes a sparser feature space and could reduce the confidence of the model in identifying generalizable decision boundaries in a </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">classification setting.</span></span></li>
<li><span class="koboSpan" id="kobo.28.1">When you get an error message in Python, it usually provides you with the necessary information to find the issue. </span><span class="koboSpan" id="kobo.28.2">This information creates a report-like message about the lines of your code that the error occurred in, the types of errors, and the function or class calls that resulted in such errors. </span><span class="koboSpan" id="kobo.28.3">This report-like message is called a </span><strong class="bold"><span class="koboSpan" id="kobo.29.1">traceback</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.30.1">in Python.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.31.1">Incremental programming</span></strong><span class="koboSpan" id="kobo.32.1">: Writing code for every small component, then testing it and writing test codes using PyTest, for example, could help you avoid issues with each function or class you wrote. </span><span class="koboSpan" id="kobo.32.2">It also helps you ensure the outputs of one module that feed another module as its input </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">are compatible.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.34.1">Logging</span></strong><span class="koboSpan" id="kobo.35.1">: When you develop functions and classes in Python, you can benefit from logging to log information, errors, and other kinds of messages to help you in identifying potential sources of issues when you get an </span><span class="No-Break"><span class="koboSpan" id="kobo.36.1">error message.</span></span></p>
<ol>
<li value="6"><span class="koboSpan" id="kobo.37.1">For example, if you use experts, such as radiologists, to annotate medical images for a cancer diagnosis, then the confidence on the label of images could be different. </span><span class="koboSpan" id="kobo.37.2">And these confidences could be considered in the modeling phase either in the data collection process, such as by asking more experts to annotate the same images, or in the modeling process, such as by assigning a weight to each image based on the confidence in labeling. </span><span class="koboSpan" id="kobo.37.3">The features of your data could also have different qualities. </span><span class="koboSpan" id="kobo.37.4">For example, you might have highly sparse features that have mostly zero values across the data points or features that might have different levels of confidence. </span><span class="koboSpan" id="kobo.37.5">For example, a measurement feature will have lower confidence if you use a measurement tape to capture millimeter differences between the sizes of objects, such as dice, compared to using the same tape to capture differences between bigger objects, such </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">as furniture.</span></span></li>
<li><span class="koboSpan" id="kobo.39.1">You can control underfitting and overfitting by controlling </span><span class="No-Break"><span class="koboSpan" id="kobo.40.1">model complexity.</span></span></li>
<li><span class="koboSpan" id="kobo.41.1">Yes, it is possible. </span><span class="koboSpan" id="kobo.41.2">The data that’s used for training and testing machine learning models could become out of date. </span><span class="koboSpan" id="kobo.41.3">For example, the changes in the trends of the clothing market could make predictions of a model for clothing </span><span class="No-Break"><span class="koboSpan" id="kobo.42.1">recommendation unreliable.</span></span></li>
<li><span class="koboSpan" id="kobo.43.1">By playing with model hyperparameters alone, you can’t develop the best possible model. </span><span class="koboSpan" id="kobo.43.2">In the same way, by increasing the quality and quantity of your data and keeping your model hyperparameters the same, you also can’t achieve the best performance possible. </span><span class="koboSpan" id="kobo.43.3">So, data and hyperparameters work hand </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">in hand.</span></span></li>
</ol>
<h1 id="_idParaDest-278"><em class="italic"><a id="_idTextAnchor463"/></em><a href="B16369_02.xhtml#_idTextAnchor076"><em class="italic"><span class="koboSpan" id="kobo.45.1">Chapter 2</span></em></a><span class="koboSpan" id="kobo.46.1"> – Machine Learning Life Cycle</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.47.1">Examples of cleaning processes are filling in missing values in your data and </span><span class="No-Break"><span class="koboSpan" id="kobo.48.1">removing outliers.</span></span></li>
<li><span class="koboSpan" id="kobo.49.1">One-hot encoding generates a new feature for each category of categorical features. </span><span class="koboSpan" id="kobo.49.2">Label encoding keeps the same features and just replaces each category with a number assigned to </span><span class="No-Break"><span class="koboSpan" id="kobo.50.1">that category.</span></span></li>
<li><span class="koboSpan" id="kobo.51.1">The simplest way of detecting outliers is by using quantiles of the distribution of variable values. </span><span class="koboSpan" id="kobo.51.2">Data points that are beyond the upper and lower bounds are considered outliers. </span><span class="koboSpan" id="kobo.51.3">The lower and upper bounds can be calculated as </span><em class="italic"><span class="koboSpan" id="kobo.52.1">Q1-a.IQR </span></em><span class="koboSpan" id="kobo.53.1">and </span><em class="italic"><span class="koboSpan" id="kobo.54.1">Q3+a.IQR</span></em><span class="koboSpan" id="kobo.55.1">, where </span><em class="italic"><span class="koboSpan" id="kobo.56.1">a</span></em><span class="koboSpan" id="kobo.57.1"> can be a real value between 1.5 and 3. </span><span class="koboSpan" id="kobo.57.2">The common value of </span><em class="italic"><span class="koboSpan" id="kobo.58.1">a</span></em><span class="koboSpan" id="kobo.59.1"> that is also used by default in drawing a boxplot is 1.5, but having higher values makes the process of outlier identification less stringent and lets fewer data points be detected </span><span class="No-Break"><span class="koboSpan" id="kobo.60.1">as outliers.</span></span></li>
<li><span class="koboSpan" id="kobo.61.1">If you want to deploy a model in doctors’ personal computers in hospitals to be used directly by clinicians, you need to consider all difficulties and planning needed to set up the proper production environment and all the software dependencies. </span><span class="koboSpan" id="kobo.61.2">You also need to make sure their local system has the necessary hardware requirements. </span><span class="koboSpan" id="kobo.61.3">These are not among the considerations if you want to deploy a model behind chatbots in a </span><span class="No-Break"><span class="koboSpan" id="kobo.62.1">banking system.</span></span></li>
</ol>
<h1 id="_idParaDest-279"><em class="italic"><a id="_idTextAnchor464"/></em><a href="B16369_03.xhtml#_idTextAnchor119"><em class="italic"><span class="koboSpan" id="kobo.63.1">Chapter 3</span></em></a><span class="koboSpan" id="kobo.64.1"> – Debugging toward Responsible AI</span></h1>
<ol>
<li value="1"><strong class="bold"><span class="koboSpan" id="kobo.65.1">Data collection bias</span></strong><span class="koboSpan" id="kobo.66.1">: Data that is collected could have biases such as gender bias, as in Amazon’s applicant sorting examples, race bias, as in COMPAS, socioeconomic biases, as in hospitalization examples, or other kinds </span><span class="No-Break"><span class="koboSpan" id="kobo.67.1">of biases.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.68.1">Sampling bias</span></strong><span class="koboSpan" id="kobo.69.1">: Another source of data bias could be in the process of sampling data points or sampling the population in the data collection stage of the life cycle. </span><span class="koboSpan" id="kobo.69.2">For example, in sampling students to fill in a survey, our sampling process could be biased toward girls or boys, rich or poor student families, or high- versus </span><span class="No-Break"><span class="koboSpan" id="kobo.70.1">low-grade students.</span></span></p>
<ol>
<li value="2"><strong class="bold"><span class="koboSpan" id="kobo.71.1">Perfect-knowledge white-box attacks</span></strong><span class="koboSpan" id="kobo.72.1">: The attacker knows everything about </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1">the system.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.74.1">Zero-knowledge black-box attacks</span></strong><span class="koboSpan" id="kobo.75.1">: The attacker doesn’t have any knowledge of the system itself but collects information through predictions of the model </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">in production.</span></span></p>
<ol>
<li value="3"><span class="koboSpan" id="kobo.77.1">The encryption process transforms the information, data, or algorithm into a new (that is, encrypted) form. </span><span class="koboSpan" id="kobo.77.2">The encrypted data can be decrypted (that is, become human-readable or machine understandable) if the individual has access to the encryption key (that is, a password-style key necessary for the decryption process). </span><span class="koboSpan" id="kobo.77.3">In this way, getting access to the data and algorithm without the encryption key will be almost impossible or </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">very difficult.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.79.1">Differential privacy</span></strong><span class="koboSpan" id="kobo.80.1"> tries to ensure that the removal or addition of individual data points does not affect the outcome of modeling. </span><span class="koboSpan" id="kobo.80.2">It attempts to learn from patterns within groups of data points. </span><span class="koboSpan" id="kobo.80.3">For example, by adding random noise from a normal distribution, it tries to make the features of individual data points obscure. </span><span class="koboSpan" id="kobo.80.4">The effect of noise in learning could be eliminated based on the law of large numbers if a large number of data points will </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">be accessible.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.82.1">Federated learning </span></strong><span class="koboSpan" id="kobo.83.1">relies on the idea of decentralizing learning, data analysis, and inference, thus allowing the user’s data to be kept within individual devices or </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">local databases.</span></span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.85.1">Transparency helps in building trust in users and could potentially increase the number of users that trust and use </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1">your models.</span></span></li>
</ol>
<h1 id="_idParaDest-280"><em class="italic"><a id="_idTextAnchor465"/></em><a href="B16369_04.xhtml#_idTextAnchor159"><em class="italic"><span class="koboSpan" id="kobo.87.1">Chapter 4</span></em></a><span class="koboSpan" id="kobo.88.1"> – Detecting Performance and Efficiency Issues in Machine Learning Models</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.89.1">In a primary diagnostic test, with more accurate follow-up tests, we want to make sure we do not lose any patients with the disease we are testing for. </span><span class="koboSpan" id="kobo.89.2">So, we need to aim to decrease false negatives, while trying to decrease false positives at the same time. </span><span class="koboSpan" id="kobo.89.3">So, we can aim to maximize </span><strong class="bold"><span class="koboSpan" id="kobo.90.1">recall </span></strong><span class="koboSpan" id="kobo.91.1">while controlling for </span><strong class="bold"><span class="koboSpan" id="kobo.92.1">precision </span></strong><span class="No-Break"><span class="koboSpan" id="kobo.93.1">and </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.94.1">specificity</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.96.1">In such cases, you want to make sure you have the </span><strong class="bold"><span class="koboSpan" id="kobo.97.1">precision </span></strong><span class="koboSpan" id="kobo.98.1">to control risks and suggest good investment opportunities. </span><span class="koboSpan" id="kobo.98.2">This might result in a lower </span><strong class="bold"><span class="koboSpan" id="kobo.99.1">recall</span></strong><span class="koboSpan" id="kobo.100.1">, which is okay as a bad investment could result in a significant loss of capital for individual investors. </span><span class="koboSpan" id="kobo.100.2">Here, we don’t want to consider the details of investment risk management and want to have a high-level understanding of how to select a good performance measure. </span><span class="koboSpan" id="kobo.100.3">If you are an expert in this field, consider your knowledge and select a good performance measure that satisfies the requirements you are </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1">aware of.</span></span></li>
<li><span class="koboSpan" id="kobo.102.1">ROC-AUC is a summary measure. </span><span class="koboSpan" id="kobo.102.2">Two models with the same ROC-AUCs could have different predictions for individual </span><span class="No-Break"><span class="koboSpan" id="kobo.103.1">data points.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.104.1">MCC </span></strong><span class="koboSpan" id="kobo.105.1">focuses on predicted labels, while </span><strong class="bold"><span class="koboSpan" id="kobo.106.1">log-loss </span></strong><span class="koboSpan" id="kobo.107.1">cares about predicted probabilities for the tested data points. </span><span class="koboSpan" id="kobo.107.2">So, a lower </span><strong class="bold"><span class="koboSpan" id="kobo.108.1">log-loss </span></strong><span class="koboSpan" id="kobo.109.1">does not necessarily result in a </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">lower </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.111.1">MCC</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.113.1">Not necessarily. </span><em class="italic"><span class="koboSpan" id="kobo.114.1">R</span></em><span class="superscript"><span class="koboSpan" id="kobo.115.1">2</span></span><span class="koboSpan" id="kobo.116.1"> doesn’t take into account data dimensionality (that is, the number of features, inputs, or independent variables). </span><span class="koboSpan" id="kobo.116.2">A model with more features could result in a higher </span><em class="italic"><span class="koboSpan" id="kobo.117.1">R</span></em><span class="superscript"><span class="koboSpan" id="kobo.118.1">2</span></span><span class="koboSpan" id="kobo.119.1">, while it might not necessarily be a </span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">better model.</span></span></li>
<li><span class="koboSpan" id="kobo.121.1">It depends on the performance measure and test data used for assessing the generalizability of the model. </span><span class="koboSpan" id="kobo.121.2">We need to use the right performance measure for our objective in production, and use a set of data points for model testing that will be more reflective of unseen data </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">in production.</span></span></li>
</ol>
<h1 id="_idParaDest-281"><em class="italic"><a id="_idTextAnchor466"/></em><a href="B16369_05.xhtml#_idTextAnchor183"><em class="italic"><span class="koboSpan" id="kobo.123.1">Chapter 5</span></em></a><span class="koboSpan" id="kobo.124.1"> – Improving the Performance of Machine Learning Models</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.125.1">Adding more training data points could help to reduce variance while adding more features could help to reduce bias. </span><span class="koboSpan" id="kobo.125.2">However, there is no guarantee of a reduction of variance through the addition of new data points or whether new features will be helpful in </span><span class="No-Break"><span class="koboSpan" id="kobo.126.1">reducing variance.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.127.1">Assigning weights during optimization</span></strong><span class="koboSpan" id="kobo.128.1">: You can assign a weight to each data point, according to the confidence of class labels, when training machine </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">learning models.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.130.1">Ensemble learning</span></strong><span class="koboSpan" id="kobo.131.1">: If you consider a distribution of the quality or confidence score of each data point, then you can build different models using data points from each part of this distribution and then combine the predictions of the models for example using their </span><span class="No-Break"><span class="koboSpan" id="kobo.132.1">weighted average.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.133.1">Transfer learning</span></strong><span class="koboSpan" id="kobo.134.1">: You can train a model on a large dataset with different levels of label confidence (see </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.135.1">Figure 5</span></em></span><em class="italic"><span class="koboSpan" id="kobo.136.1">.3</span></em><span class="koboSpan" id="kobo.137.1">), excluding very low-confidence data and then fine-tune it on the very high-confidence part of </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">your dataset.</span></span></p>
<ol>
<li value="2"><span class="koboSpan" id="kobo.139.1">By increasing confidence in identifying the decision boundary, in a classification setting, where the minority class </span><span class="No-Break"><span class="koboSpan" id="kobo.140.1">is sparse.</span></span></li>
<li><span class="koboSpan" id="kobo.141.1">If we use Borderline-SMOTE, the new synthetically generated data points would be close to the majority-class data points, which helps in identifying a generalizable </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">decision boundary.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.143.1">In DSMOTE, </span><strong class="bold"><span class="koboSpan" id="kobo.144.1">DBSCAN </span></strong><span class="koboSpan" id="kobo.145.1">is used to divide data points of the minority class into three groups of core samples, borderline samples, and noise (that is, outlying) samples, and then the core and borderline samples only get used </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">for oversampling.</span></span></p>
<ol>
<li value="4"><span class="koboSpan" id="kobo.147.1">Searching over the whole possible combinations of hyperparameters is not necessary, as explained in </span><span class="No-Break"><span class="koboSpan" id="kobo.148.1">this chapter.</span></span></li>
<li><span class="koboSpan" id="kobo.149.1">Yes, L1 regularization can eliminate the contribution of features to the </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">regularization process.</span></span></li>
<li><span class="koboSpan" id="kobo.151.1">Yes, it </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">is possible.</span></span></li>
</ol>
<h1 id="_idParaDest-282"><em class="italic"><a id="_idTextAnchor467"/></em><a href="B16369_06.xhtml#_idTextAnchor201"><em class="italic"><span class="koboSpan" id="kobo.153.1">Chapter 6</span></em></a><span class="koboSpan" id="kobo.154.1"> – Interpretability and Explainability in Machine Learning Modeling</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.155.1">Explainability can help improve performance, such as by reducing the sensitivity of models to small feature value changes, increasing data efficiency in model training, trying to help in proper reasoning in models, and avoiding </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">spurious correlations.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.157.1">Local explainability</span></strong><span class="koboSpan" id="kobo.158.1"> helps us understand the behavior of a model close to a data point in feature space. </span><span class="koboSpan" id="kobo.158.2">Although these models meet local fidelity criteria, features that have been identified to be locally important might not be globally important, and </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">vice versa.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.160.1">Global explainability </span></strong><span class="koboSpan" id="kobo.161.1">techniques try to go beyond local explainability and provide global explanations to </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">the models.</span></span></p>
<ol>
<li value="3"><span class="koboSpan" id="kobo.163.1">Linear models, although interpretable, usually have low performance. </span><span class="koboSpan" id="kobo.163.2">Instead, we could benefit from more complex models, with higher performance, and use explainability techniques to understand how the model comes up with </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">its predictions.</span></span></li>
<li><span class="koboSpan" id="kobo.165.1">Yes, it does. </span><span class="koboSpan" id="kobo.165.2">Explainability techniques could help us understand what models are major contributors to predictions for one set of </span><span class="No-Break"><span class="koboSpan" id="kobo.166.1">data points.</span></span></li>
<li><span class="koboSpan" id="kobo.167.1">SHAP can determine how each feature contributes to a model’s prediction. </span><span class="koboSpan" id="kobo.167.2">As features work cooperatively in determining the decision boundaries of classification models and eventually affecting model predictions, SHAP tries to first identify the marginal contribution of each feature and then provide Shapely values as an estimate of each feature in cooperation with the whole feature set to predict </span><span class="No-Break"><span class="koboSpan" id="kobo.168.1">a model.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.169.1">LIME is an alternative to SHAP for </span><strong class="bold"><span class="koboSpan" id="kobo.170.1">local explainability </span></strong><span class="koboSpan" id="kobo.171.1">that explains the predictions of any classifier or regressor, in a model-agnostic way, by approximating a model locally with an </span><span class="No-Break"><span class="koboSpan" id="kobo.172.1">interpretable model.</span></span></p>
<ol>
<li value="6"><span class="koboSpan" id="kobo.173.1">Counterfactual examples, or explanations, help us identify what needs to be changed in an instance to change the outcome of a classification model. </span><span class="koboSpan" id="kobo.173.2">These counterfactuals could help in identifying actionable paths in many applications, such as finance, retail, marketing, recruiting, and healthcare. </span><span class="koboSpan" id="kobo.173.3">For example, we can use them to suggest to a bank customer how they can change the rejection to their </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">loan application.</span></span></li>
<li><span class="koboSpan" id="kobo.175.1">As presented in the </span><em class="italic"><span class="koboSpan" id="kobo.176.1">Counterfactual generation using Diverse Counterfactual Explanations (DiCE)</span></em><span class="koboSpan" id="kobo.177.1"> section, not all counterfactuals are feasible according to the definition and meaning of each feature. </span><span class="koboSpan" id="kobo.177.2">For example, if we want to suggest to a 30-year-old individual to change their outcome, suggesting that they need to wait until they get to their 50s is not an effective and actionable suggestion. </span><span class="koboSpan" id="kobo.177.3">Also, suggesting a change of </span><strong class="source-inline"><span class="koboSpan" id="kobo.178.1">hours_per_week</span></strong><span class="koboSpan" id="kobo.179.1"> of work from 38 to &gt;80 is </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">not feasible.</span></span></li>
</ol>
<h1 id="_idParaDest-283"><em class="italic"><a id="_idTextAnchor468"/></em><a href="B16369_07.xhtml#_idTextAnchor218"><em class="italic"><span class="koboSpan" id="kobo.181.1">Chapter 7</span></em></a><span class="koboSpan" id="kobo.182.1"> – Decreasing Bias and Achieving Fairness</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.183.1">No. </span><span class="koboSpan" id="kobo.183.2">There might be proxies in our models for sensitive attributes, but not in </span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">our models.</span></span></li>
<li><span class="koboSpan" id="kobo.185.1">Salary and income (in some countries), occupation, a history of a </span><span class="No-Break"><span class="koboSpan" id="kobo.186.1">felony charge.</span></span></li>
<li><span class="koboSpan" id="kobo.187.1">Not necessarily. </span><span class="koboSpan" id="kobo.187.2">Satisfying fairness according to </span><strong class="bold"><span class="koboSpan" id="kobo.188.1">demographic parity</span></strong><span class="koboSpan" id="kobo.189.1"> wouldn’t necessarily result in a model being fair according to </span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.190.1">equalized odds</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.192.1">Demographic parity</span></strong><span class="koboSpan" id="kobo.193.1"> is a group fairness definition to ensure that a model’s predictions are not dependent on a given sensitive attribute, such as ethnicity </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">or sex.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.195.1">Equalized odds</span></strong><span class="koboSpan" id="kobo.196.1"> is satisfied when a given prediction is independent of the group of a given sensitive attribute and the </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">real output.</span></span></p>
<ol>
<li value="5"><span class="koboSpan" id="kobo.198.1">Not necessarily. </span><span class="koboSpan" id="kobo.198.2">For example, there could be feature proxies for </span><strong class="source-inline"><span class="koboSpan" id="kobo.199.1">'sex'</span></strong><span class="koboSpan" id="kobo.200.1"> among top contributors to </span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">model predictions.</span></span></li>
<li><span class="koboSpan" id="kobo.202.1">We can use explainability techniques to identify potential biases in our models and then plan to improve them toward fairness. </span><span class="koboSpan" id="kobo.202.2">For example, we can identify fairness issues between male and </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">female groups.</span></span></li>
</ol>
<h1 id="_idParaDest-284"><em class="italic"><a id="_idTextAnchor469"/></em><a href="B16369_08.xhtml#_idTextAnchor243"><em class="italic"><span class="koboSpan" id="kobo.204.1">Chapter 8</span></em></a><span class="koboSpan" id="kobo.205.1"> – Controlling Risks Using Test-Driven Development</span></h1>
<ol>
<li value="1"><strong class="source-inline"><span class="koboSpan" id="kobo.206.1">pytest</span></strong><span class="koboSpan" id="kobo.207.1"> is a simple-to-use Python library you can use to design unit tests. </span><span class="koboSpan" id="kobo.207.2">The designed tests can then be simply used to test changes in your code and control risks of potential mistakes throughout the development process and future changes in </span><span class="No-Break"><span class="koboSpan" id="kobo.208.1">your code.</span></span></li>
<li><span class="koboSpan" id="kobo.209.1">In programming for data analysis and machine learning modeling, we need to use data that is in different variables or data objects, comes from a file in your local machine or the cloud, is queried from a database, or comes from a URL to our tests. </span><span class="koboSpan" id="kobo.209.2">Fixtures help us in these processes by removing the need to repeat the same code across our tests. </span><span class="koboSpan" id="kobo.209.3">Attaching a fixture function to a test will run it and return data to the test before each test runs. </span><span class="koboSpan" id="kobo.209.4">We can use the examples provided on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.210.1">pytest</span></strong><span class="koboSpan" id="kobo.211.1"> documentation page for </span><span class="No-Break"><span class="koboSpan" id="kobo.212.1">fixtures (</span></span><a href="https://docs.pytest.org/en/7.1.x/how-to/fixtures.html"><span class="No-Break"><span class="koboSpan" id="kobo.213.1">https://docs.pytest.org/en/7.1.x/how-to/fixtures.html</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.214.1">).</span></span></li>
<li><span class="koboSpan" id="kobo.215.1">Differential testing attempts to check two versions of a piece of software, as base and test versions, on the same input and compare the outputs. </span><span class="koboSpan" id="kobo.215.2">This process helps identify whether the outputs are the same and identify unexpected differences. </span><span class="koboSpan" id="kobo.215.3">In differential testing, the base version is already verified and considered as the approved version while the test version needs to be checked against the base version in producing the </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">correct output.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.217.1">mlflow</span></strong><span class="koboSpan" id="kobo.218.1"> is a widely used machine learning experiment tracking library that we can use in Python. </span><span class="koboSpan" id="kobo.218.2">Keeping track of our machine learning experiments will help us to reduce the risks of invalid conclusions and selecting unreliable models. </span><span class="koboSpan" id="kobo.218.3">Experiment tracking in machine learning is about saving information about the experiments, such as the data that has been used, the testing performance and the metric used for performance assessment, and the algorithms and the hyperparameters used </span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">for modeling.</span></span></li>
</ol>
<h1 id="_idParaDest-285"><em class="italic"><a id="_idTextAnchor470"/></em><a href="B16369_09.xhtml#_idTextAnchor261"><em class="italic"><span class="koboSpan" id="kobo.220.1">Chapter 9</span></em></a><span class="koboSpan" id="kobo.221.1"> – Testing and Debugging for Production</span></h1>
<ol>
<li value="1"><strong class="bold"><span class="koboSpan" id="kobo.222.1">Data drift</span></strong><span class="koboSpan" id="kobo.223.1">: Data drift happens if the characteristics and meaning of features or independent variables in production differ from the modeling stage. </span><span class="koboSpan" id="kobo.223.2">Imagine you used a third-party tool to generate a score for the health or financial situation of people. </span><span class="koboSpan" id="kobo.223.3">The algorithm behind that tool could change over time, and its range and meaning will not be the same when your model gets used in production. </span><span class="koboSpan" id="kobo.223.4">If you have not updated your model accordingly, then your model will not work as expected as the meaning of the value of the features will not be the same between the data used for training and the user data </span><span class="No-Break"><span class="koboSpan" id="kobo.224.1">after deployment.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.225.1">Concept drift</span></strong><span class="koboSpan" id="kobo.226.1">: Concept drift is about any change in the definition of output variables. </span><span class="koboSpan" id="kobo.226.2">For example, real decision boundaries between training data and production could be different because of concept drift, meaning the effort in training might result in a decision boundary far from reality </span><span class="No-Break"><span class="koboSpan" id="kobo.227.1">in production.</span></span></p>
<ol>
<li value="2"><strong class="bold"><span class="koboSpan" id="kobo.228.1">Model assertions</span></strong><span class="koboSpan" id="kobo.229.1"> can help you detect issues early on, such as input data drift or other unexpected behaviors that might affect the model’s performance. </span><span class="koboSpan" id="kobo.229.2">We can consider model assertions as a set of rules that get checked during the model’s training, validation, or even during deployment to ensure that the model’s predictions meet the predefined conditions. </span><span class="koboSpan" id="kobo.229.3">Model assertions can help us in many ways, such as detecting and diagnosing issues with the model or input data, allowing us to address them before they impact the </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">model’s performance.</span></span></li>
<li><span class="koboSpan" id="kobo.231.1">Here are some examples of the components of </span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">integration testing:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.233.1">Testing data pipelines</span></strong><span class="koboSpan" id="kobo.234.1">: We need to evaluate that the data preprocessing components before model training, such as data wrangling, are consistent between the training and </span><span class="No-Break"><span class="koboSpan" id="kobo.235.1">deployment stages.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.236.1">Testing APIs</span></strong><span class="koboSpan" id="kobo.237.1">: If our machine learning model is exposed through an API, we can test the API endpoints to ensure they handle requests and </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">responses correctly.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.239.1">Testing model deployment</span></strong><span class="koboSpan" id="kobo.240.1">: We can use integration testing to assess the model’s deployment process, whether it’s deployed as a standalone service, within a container, or embedded in an application. </span><span class="koboSpan" id="kobo.240.2">This process helps us ensure that the deployment environment provides the necessary resources, such as CPU, memory, and storage, and that the model can be updated </span><span class="No-Break"><span class="koboSpan" id="kobo.241.1">if needed.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.242.1">Testing interactions with other components</span></strong><span class="koboSpan" id="kobo.243.1">: We need to verify that our machine learning model works seamlessly with databases, user interfaces, or third-party services. </span><span class="koboSpan" id="kobo.243.2">This may include testing how the model’s predictions are stored, displayed, or used within </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">the application.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.245.1">Testing end-to-end functionality</span></strong><span class="koboSpan" id="kobo.246.1">: We can use end-to-end tests that simulate real-world scenarios and user interactions to validate that the model’s predictions are accurate, reliable, and useful in the context of the </span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">overall application.</span></span></li></ul></li>
<li><span class="koboSpan" id="kobo.248.1">IaC and configuration management tools such as Chef, Puppet, and Ansible can be used to automate the deployment, configuration, and management of software and hardware infrastructures. </span><span class="koboSpan" id="kobo.248.2">These tools could help us ensure consistency and reliability across different environments. </span><span class="koboSpan" id="kobo.248.3">First, we need to define two important terminologies, client and server, before describing what these IaC tools are </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">for us:</span></span><ul><li><strong class="bold"><span class="koboSpan" id="kobo.250.1">Chef</span></strong><span class="koboSpan" id="kobo.251.1"> (</span><a href="https://www.chef.io/products/chef-infrastructure-management"><span class="koboSpan" id="kobo.252.1">https://www.chef.io/products/chef-infrastructure-management</span></a><span class="koboSpan" id="kobo.253.1">): Chef is an open source configuration management tool that relies on a client-server model, where the Chef server stores the desired configuration, and the Chef client applies it to </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">the nodes.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.255.1">Puppet</span></strong><span class="koboSpan" id="kobo.256.1"> (</span><a href="https://www.puppet.com/"><span class="koboSpan" id="kobo.257.1">https://www.puppet.com/</span></a><span class="koboSpan" id="kobo.258.1">): Puppet is another open source configuration management tool that works in a client-server model or as a standalone application. </span><span class="koboSpan" id="kobo.258.2">Puppet enforces desired configurations across nodes by periodically pulling them from the Puppet </span><span class="No-Break"><span class="koboSpan" id="kobo.259.1">master server.</span></span></li><li><strong class="bold"><span class="koboSpan" id="kobo.260.1">Ansible</span></strong><span class="koboSpan" id="kobo.261.1"> (</span><a href="https://www.ansible.com/"><span class="koboSpan" id="kobo.262.1">https://www.ansible.com/</span></a><span class="koboSpan" id="kobo.263.1">): Ansible is an open source and easy-to-use configuration management, orchestration, and automation tool that employs an agentless architecture to communicate and apply configurations </span><span class="No-Break"><span class="koboSpan" id="kobo.264.1">to nodes.</span></span></li></ul></li>
</ol>
<h1 id="_idParaDest-286"><em class="italic"><a id="_idTextAnchor471"/></em><a href="B16369_10.xhtml#_idTextAnchor286"><em class="italic"><span class="koboSpan" id="kobo.265.1">Chapter 10</span></em></a><span class="koboSpan" id="kobo.266.1"> – Versioning and Reproducible Machine Learning Modeling</span></h1>
<ol>
<li value="1"><strong class="bold"><span class="koboSpan" id="kobo.267.1">MLflow</span></strong><span class="koboSpan" id="kobo.268.1">: We introduced MLflow for experiment tracking and model monitoring in previous chapters, but you can also use it for data </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">versioning (</span></span><a href="https://mlflow.org/"><span class="No-Break"><span class="koboSpan" id="kobo.270.1">https://mlflow.org/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.271.1">).</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.272.1">DVC</span></strong><span class="koboSpan" id="kobo.273.1">: An open source version control system for managing data, code, and ML models. </span><span class="koboSpan" id="kobo.273.2">It is designed to handle large datasets and integrates with </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">Git (</span></span><a href="https://dvc.org/"><span class="No-Break"><span class="koboSpan" id="kobo.275.1">https://dvc.org/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.276.1">).</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.277.1">Pachyderm</span></strong><span class="koboSpan" id="kobo.278.1">: A data versioning platform that provides reproducibility, provenance, and scalability in machine learning </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">workflows (</span></span><a href="https://www.pachyderm.com/"><span class="No-Break"><span class="koboSpan" id="kobo.280.1">https://www.pachyderm.com/</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.281.1">).</span></span></p>
<ol>
<li value="2"><span class="koboSpan" id="kobo.282.1">No. </span><span class="koboSpan" id="kobo.282.2">Different versions of the same data file could be stored with the same name and restored and retrieved </span><span class="No-Break"><span class="koboSpan" id="kobo.283.1">when needed.</span></span></li>
<li><span class="koboSpan" id="kobo.284.1">A simple change of the random state when splitting data into training and test sets or during model initialization could result in different parameter values and performances for training and </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">evaluation sets.</span></span></li>
</ol>
<h1 id="_idParaDest-287"><em class="italic"><a id="_idTextAnchor472"/></em><a href="B16369_11.xhtml#_idTextAnchor300"><em class="italic"><span class="koboSpan" id="kobo.286.1">Chapter 11</span></em></a><span class="koboSpan" id="kobo.287.1"> – Avoiding and Detecting Data and Concept Drifts</span></h1>
<ol>
<li value="1"><strong class="bold"><span class="koboSpan" id="kobo.288.1">Magnitude</span></strong><span class="koboSpan" id="kobo.289.1">: We might face different magnitudes of difference in the data distribution resulting in drift in our machine learning models. </span><span class="koboSpan" id="kobo.289.2">Small changes in the data distribution may be difficult to detect, while large changes may be </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">more noticeable.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.291.1">Frequency</span></strong><span class="koboSpan" id="kobo.292.1">: Drifts might occur in </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">different frequencies.</span></span></p>
<ol>
<li value="2"><span class="koboSpan" id="kobo.294.1">The Kolmogorov–Smirnov test can be used for data </span><span class="No-Break"><span class="koboSpan" id="kobo.295.1">drift detection.</span></span></li>
</ol>
<h1 id="_idParaDest-288"><em class="italic"><a id="_idTextAnchor473"/></em><a href="B16369_12.xhtml#_idTextAnchor320"><em class="italic"><span class="koboSpan" id="kobo.296.1">Chapter 12</span></em></a><span class="koboSpan" id="kobo.297.1"> – Going Beyond ML Debugging with Deep Learning</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.298.1">Yes, in the forward pass, parameters that are already calculated get used for output generation; then, the difference between the real and predicted output gets used in the backpropagation process to update </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">the weights.</span></span></li>
<li><span class="koboSpan" id="kobo.300.1">In stochastic gradient descent, one data point is used per iteration to optimize and update the model weights, while in mini-batch gradient descent, a mini-batch (small subset) of data points </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">gets used.</span></span></li>
<li><span class="koboSpan" id="kobo.302.1">Each batch or mini-batch is a small subset of data points in the training set that gets used to calculate the loss and update the model’s weights. </span><span class="koboSpan" id="kobo.302.2">In each epoch, multiple batches get iterated to cover all </span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">training data.</span></span></li>
<li><span class="koboSpan" id="kobo.304.1">The sigmoid and softmax functions are commonly used in output layers to transform the scores of the output neurons to values of between zero and one for classification models. </span><span class="koboSpan" id="kobo.304.2">This is called the probability </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">of predictions.</span></span></li>
</ol>
<h1 id="_idParaDest-289"><em class="italic"><a id="_idTextAnchor474"/></em><a href="B16369_13.xhtml#_idTextAnchor342"><em class="italic"><span class="koboSpan" id="kobo.306.1">Chapter 13</span></em></a><span class="koboSpan" id="kobo.307.1"> – Advanced Deep Learning Techniques</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.308.1">CNNs can be used for image classification or segmentation – for example, for radiological images to identify malignancies (tumor regions). </span><span class="koboSpan" id="kobo.308.2">On the other hand, GNNs can be used in social and </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">biological networks.</span></span></li>
<li><span class="koboSpan" id="kobo.310.1">Yes, </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">it does.</span></span></li>
<li><span class="koboSpan" id="kobo.312.1">It might result in </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">more mistakes.</span></span></li>
<li><span class="koboSpan" id="kobo.314.1">To handle this challenge, a common ID, such as 0, gets used before or after IDs of tokens of words in each sequence of words or sentences in a process </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">called padding.</span></span></li>
<li><span class="koboSpan" id="kobo.316.1">The classes we build for CNNs and GNNs have similar </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">code structures.</span></span></li>
<li><span class="koboSpan" id="kobo.318.1">Edge features help you include some vital information, depending on the application. </span><span class="koboSpan" id="kobo.318.2">For example, in chemistry, you can determine the type of chemical bond as an edge feature, while the nodes could be the atoms in </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">the graphs.</span></span></li>
</ol>
<h1 id="_idParaDest-290"><em class="italic"><a id="_idTextAnchor475"/></em><a href="B16369_14.xhtml#_idTextAnchor379"><em class="italic"><span class="koboSpan" id="kobo.320.1">Chapter 14</span></em></a><span class="koboSpan" id="kobo.321.1"> – Introduction to Recent Advancements in Machine Learning</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.322.1">Transformer-based text generation, VAEs, </span><span class="No-Break"><span class="koboSpan" id="kobo.323.1">and GANs.</span></span></li>
<li><span class="koboSpan" id="kobo.324.1">Different versions of LLaMA </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">and GPT.</span></span></li>
<li><span class="koboSpan" id="kobo.326.1">The generator, which could be a neural network architecture for generating desired data types, such as images, generates images aiming to fool the discriminator into recognizing the generated data as real data. </span><span class="koboSpan" id="kobo.326.2">The discriminator learns to remain good at recognizing generated data compared to </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">real data.</span></span></li>
<li><span class="koboSpan" id="kobo.328.1">You can improve your prompting by being specific about the question and specifying for whom the data is </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">being generated.</span></span></li>
<li><span class="koboSpan" id="kobo.330.1">In RLHF, the reward is calculated based on the feedback of humans, either experts or non-experts, depending on the problem. </span><span class="koboSpan" id="kobo.330.2">But the reward is not like a predefined mathematical formula considering the complexity of problems such as language modeling. </span><span class="koboSpan" id="kobo.330.3">The feedback provided by humans results in improving the model step </span><span class="No-Break"><span class="koboSpan" id="kobo.331.1">by step.</span></span></li>
<li><span class="koboSpan" id="kobo.332.1">The idea of contrastive learning is to learn representations that result in similar data points being closer to each other compared to dissimilar </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1">data points.</span></span></li>
</ol>
<h1 id="_idParaDest-291"><em class="italic"><a id="_idTextAnchor476"/></em><a href="B16369_15.xhtml#_idTextAnchor406"><em class="italic"><span class="koboSpan" id="kobo.334.1">Chapter 15</span></em></a><span class="koboSpan" id="kobo.335.1"> – Correlation versus Causality</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.336.1">Yes. </span><span class="koboSpan" id="kobo.336.2">You can have features that are highly correlated with the output in supervised learning that </span><span class="No-Break"><span class="koboSpan" id="kobo.337.1">aren’t causal.</span></span></li>
<li><span class="koboSpan" id="kobo.338.1">One way to establish causality is to conduct experiments, as in </span><strong class="bold"><span class="koboSpan" id="kobo.339.1">experimental design</span></strong><span class="koboSpan" id="kobo.340.1">, where we measure the effect of changes in the causal feature on the target variable. </span><span class="koboSpan" id="kobo.340.2">However, such experimental studies may not always be feasible or ethical. </span><span class="koboSpan" id="kobo.340.3">In </span><strong class="bold"><span class="koboSpan" id="kobo.341.1">observational studies</span></strong><span class="koboSpan" id="kobo.342.1">, we use observational data, instead of controlled experiments, and try to identify causal relationships by controlling </span><span class="No-Break"><span class="koboSpan" id="kobo.343.1">confounding variables.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.344.1">Instrumental variables</span></strong><span class="koboSpan" id="kobo.345.1"> is used in causal aim to overcome a common problem in observational studies where the treatment and outcome variables are jointly determined by other variables, or confounders, that are not included in the model. </span><span class="koboSpan" id="kobo.345.2">This approach starts with identifying an instrument that is correlated with the treatment variable and uncorrelated with the outcome variable, except through its effect on the </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">treatment variable.</span></span></li>
<li><span class="koboSpan" id="kobo.347.1">The directions, from a feature to the outcome, don’t necessarily mean causality. </span><span class="koboSpan" id="kobo.347.2">But </span><em class="italic"><span class="koboSpan" id="kobo.348.1">Bayesian</span></em><span class="koboSpan" id="kobo.349.1"> networks can be used for estimating the causal effects of variables on the outcome while controlling the </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">confounding variables.</span></span></li>
</ol>
<h1 id="_idParaDest-292"><em class="italic"><a id="_idTextAnchor477"/></em><a href="B16369_16.xhtml#_idTextAnchor429"><em class="italic"><span class="koboSpan" id="kobo.351.1">Chapter 16</span></em></a><span class="koboSpan" id="kobo.352.1"> – Security and Privacy in Machine Learning</span></h1>
<ol>
<li value="1"><strong class="bold"><span class="koboSpan" id="kobo.353.1">Advanced Encryption Standard</span></strong><span class="koboSpan" id="kobo.354.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.355.1">AES</span></strong><span class="koboSpan" id="kobo.356.1">): AES is one of the strongest encryption algorithms that protects data. </span><span class="koboSpan" id="kobo.356.2">AES accepts different key sizes: 128, 192, or </span><span class="No-Break"><span class="koboSpan" id="kobo.357.1">256 bits.</span></span></li>
</ol>
<p><strong class="bold"><span class="koboSpan" id="kobo.358.1">Triple Data Encryption Standard</span></strong><span class="koboSpan" id="kobo.359.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.360.1">DES</span></strong><span class="koboSpan" id="kobo.361.1">): Triple DES is an encryption method that uses a 56-bit key to encrypt </span><span class="No-Break"><span class="koboSpan" id="kobo.362.1">data blocks.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.363.1">Blowfish</span></strong><span class="koboSpan" id="kobo.364.1">: Blowfish is a symmetric-key encryption technique used as an alternative to the DES encryption algorithm. </span><span class="koboSpan" id="kobo.364.2">Blowfish is fast and highly effective for data encryption. </span><span class="koboSpan" id="kobo.364.3">It splits data, for example, strings and messages, into blocks of 64 bits and encrypts </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">them individually.</span></span></p>
<ol>
<li value="2"><span class="koboSpan" id="kobo.366.1"> We can use a model for inference on encrypted data without the need </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">for decryption.</span></span></li>
<li><span class="koboSpan" id="kobo.368.1">The objective of </span><strong class="bold"><span class="koboSpan" id="kobo.369.1">differential privacy</span></strong><span class="koboSpan" id="kobo.370.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.371.1">DP</span></strong><span class="koboSpan" id="kobo.372.1">) is to ensure that the removal or addition of individual data points does not affect the outcome of the modeling. </span><span class="koboSpan" id="kobo.372.2">For example, by adding random noise to a normal distribution, it tries to make the features of individual data </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">points obscure.</span></span></li>
<li><span class="koboSpan" id="kobo.374.1">The challenge of using FL or DP in practice goes beyond programming or infrastructure design. </span><span class="koboSpan" id="kobo.374.2">In spite of this great alternative to storing user data locally, there are still ethical, legal, and business challenges when benefitting from FL in </span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">different applications.</span></span></li>
</ol>
<h1 id="_idParaDest-293"><em class="italic"><a id="_idTextAnchor478"/></em><a href="B16369_17.xhtml#_idTextAnchor447"><em class="italic"><span class="koboSpan" id="kobo.376.1">Chapter 17</span></em></a><span class="koboSpan" id="kobo.377.1"> – Human-in-the-Loop Machine Learning</span></h1>
<ol>
<li value="1"><span class="koboSpan" id="kobo.378.1">No. </span><span class="koboSpan" id="kobo.378.2">For example, you can bring human experts into the loop through </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.379.1">active learning</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.380.1">.</span></span></li>
<li><span class="koboSpan" id="kobo.381.1">In </span><strong class="bold"><span class="koboSpan" id="kobo.382.1">uncertainty sampling</span></strong><span class="koboSpan" id="kobo.383.1">, data points get selected solely based on uncertainty in inference. </span><span class="koboSpan" id="kobo.383.2">But in </span><strong class="bold"><span class="koboSpan" id="kobo.384.1">density-weighted uncertainty sampling</span></strong><span class="koboSpan" id="kobo.385.1">, instances get selected not only based on their highest uncertainty but also to be representative of the many other data points that rely on the density of data in the </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1">feature space.</span></span></li>
</ol>
</div>
</body></html>