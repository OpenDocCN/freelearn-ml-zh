<html><head></head><body>
<div id="_idContainer127" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-210"><a id="_idTextAnchor219" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1.1">10</span></h1>
<h1 id="_idParaDest-211" class="calibre5"><a id="_idTextAnchor220" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.2.1">Preserving Privacy in Large Language Models</span></h1>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.3.1">Large language models</span></strong><span class="kobospan" id="kobo.4.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.5.1">LLMs</span></strong><span class="kobospan" id="kobo.6.1">) have emerged as a transformative technology in the field of artificial intelligence (AI), enabling advanced </span><strong class="bold"><span class="kobospan" id="kobo.7.1">natural language processing</span></strong><span class="kobospan" id="kobo.8.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.9.1">NLP</span></strong><span class="kobospan" id="kobo.10.1">) tasks and generative capabilities. </span><span class="kobospan" id="kobo.10.2">These models, such as OpenAI’s GPT-3.5 and Meta’s Llama 2 have shown remarkable proficiency in generating human-like text and demonstrating a deep understanding of language patterns. </span><span class="kobospan" id="kobo.10.3">In this chapter, you will learn about closed source and open source LLMs at a high level, privacy issues with these LLMs, and </span><strong class="bold"><span class="kobospan" id="kobo.11.1">state-of-the-art</span></strong><span class="kobospan" id="kobo.12.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.13.1">SOTA</span></strong><span class="kobospan" id="kobo.14.1">) research in privacy-preserving technologies </span><span><span class="kobospan" id="kobo.15.1">for LLMs.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.16.1">We will cover the following </span><span><span class="kobospan" id="kobo.17.1">main topics:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.18.1">Key concepts/terms used </span><span><span class="kobospan" id="kobo.19.1">in LLMs</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.20.1">Prompt engineering: Sentence translation using ChatGPT (closed source LLM) as well as using open </span><span><span class="kobospan" id="kobo.21.1">source LLMs</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.22.1">Comparison of open source LLMs and closed </span><span><span class="kobospan" id="kobo.23.1">source LLMs</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.24.1">AI standards and terminology </span><span><span class="kobospan" id="kobo.25.1">of attacks</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.26.1">National Institute of Standards and Technology</span></strong><span class="kobospan" id="kobo.27.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.28.1">NIST</span></strong><span class="kobospan" id="kobo.29.1">) Trustworthy and </span><span><span class="kobospan" id="kobo.30.1">Responsible AI</span></span></li><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.31.1">Open Worldwide Application Security Project</span></strong><span class="kobospan" id="kobo.32.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.33.1">OWASP</span></strong><span class="kobospan" id="kobo.34.1">) Top </span><span><span class="kobospan" id="kobo.35.1">10 LLMs</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.36.1">Privacy attacks </span><span><span class="kobospan" id="kobo.37.1">on LLMs</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.38.1">Real-world incidents of privacy leaks </span><span><span class="kobospan" id="kobo.39.1">in LLMs</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.40.1">Membership inference attacks against </span><span><span class="kobospan" id="kobo.41.1">generative models</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.42.1">Extracting training data </span><span><span class="kobospan" id="kobo.43.1">from LLMs</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.44.1">Prompt </span><span><span class="kobospan" id="kobo.45.1">injection attacks</span></span></li></ul></li>
<li class="calibre11"><span class="kobospan" id="kobo.46.1">Privacy-preserving technologies </span><span><span class="kobospan" id="kobo.47.1">for LLMs</span></span><ul class="calibre16"><li class="calibre11"><span class="kobospan" id="kobo.48.1">Text attacks on </span><strong class="bold"><span class="kobospan" id="kobo.49.1">machine learning</span></strong><span class="kobospan" id="kobo.50.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.51.1">ML</span></strong><span class="kobospan" id="kobo.52.1">) and </span><strong class="bold"><span class="kobospan" id="kobo.53.1">generative </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.54.1">AI</span></strong></span><span><span class="kobospan" id="kobo.55.1"> (</span></span><span><strong class="bold"><span class="kobospan" id="kobo.56.1">GenAI</span></strong></span><span><span class="kobospan" id="kobo.57.1">)</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.58.1">Training LLMs using differential privacy with </span><span><span class="kobospan" id="kobo.59.1">private transformer</span></span></li><li class="calibre11"><span class="kobospan" id="kobo.60.1">SOTA research on </span><span><span class="kobospan" id="kobo.61.1">privacy-preserving LLMs</span></span></li></ul></li>
</ul>
<h1 id="_idParaDest-212" class="calibre5"><a id="_idTextAnchor221" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.62.1">Key concepts/terms used in LLMs</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.63.1">LLMs are a complex field of NLP, and there are several terms associated </span><span><span class="kobospan" id="kobo.64.1">with them.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.65.1">Some key terms and concepts used in the context of LLMs are </span><span><span class="kobospan" id="kobo.66.1">the following:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.67.1">Transformer architecture</span></strong><span class="kobospan" id="kobo.68.1">: The foundational architecture for most LLMs, known for its self-attention mechanism, which allows the model to weigh the importance of different words in </span><span><span class="kobospan" id="kobo.69.1">a sentence.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.70.1">Pre-training</span></strong><span class="kobospan" id="kobo.71.1">: The initial phase in which the LLM is trained on a massive corpus of text data from the internet to learn language patterns and context. </span><span class="kobospan" id="kobo.71.2">This pre-trained model is often referred to as the “</span><span><span class="kobospan" id="kobo.72.1">base model.”</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.73.1">Fine-tuning</span></strong><span class="kobospan" id="kobo.74.1">: The subsequent phase where the pre-trained model is adapted to perform specific NLP tasks, such as text classification, translation, summarization, or question answering. </span><span class="kobospan" id="kobo.74.2">Fine-tuning helps the model specialize in </span><span><span class="kobospan" id="kobo.75.1">these tasks.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.76.1">Parameters</span></strong><span class="kobospan" id="kobo.77.1">: These are the trainable components of the LLM, represented by numerical values. </span><span class="kobospan" id="kobo.77.2">The number of parameters is a key factor in determining the size and capability of </span><span><span class="kobospan" id="kobo.78.1">an LLM.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.79.1">Attention mechanism</span></strong><span class="kobospan" id="kobo.80.1">: A core component of the transformer architecture, it enables the model to focus on different parts of the input sequence when processing it, improving </span><span><span class="kobospan" id="kobo.81.1">contextual understanding.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.82.1">Self-attention</span></strong><span class="kobospan" id="kobo.83.1">: A specific type of attention where the model assigns weights to different words in a sentence based on their relevance to each other, allowing it to capture dependencies between words. </span><span class="kobospan" id="kobo.83.2">Most transformers are built based on the research paper from Google, </span><em class="italic"><span class="kobospan" id="kobo.84.1">Attention Is All You </span></em><span><em class="italic"><span class="kobospan" id="kobo.85.1">Need</span></em></span><span><span class="kobospan" id="kobo.86.1"> (</span></span><a href="https://arxiv.org/abs/1706.03762" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.87.1">https://arxiv.org/abs/1706.03762</span></span></a><span><span class="kobospan" id="kobo.88.1">).</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.89.1">Embeddings</span></strong><span class="kobospan" id="kobo.90.1">: Word embeddings or token embeddings are vector representations of words or tokens in a continuous space. </span><span class="kobospan" id="kobo.90.2">These embeddings capture semantic relationships </span><span><span class="kobospan" id="kobo.91.1">between words.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.92.1">Contextual embeddings</span></strong><span class="kobospan" id="kobo.93.1">: Unlike static word embeddings, these embeddings change based on the context of the sentence, allowing LLMs to understand the meaning of words in different contexts. </span><span class="kobospan" id="kobo.93.2">Positional embeddings and rotary position embeddings come under the category of </span><span><span class="kobospan" id="kobo.94.1">contextual embeddings.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.95.1">Tokenization</span></strong><span class="kobospan" id="kobo.96.1">: The process of breaking down text into individual tokens (words or subwords) for input into the model. </span><span class="kobospan" id="kobo.96.2">LLMs use tokenizers to perform </span><span><span class="kobospan" id="kobo.97.1">this task.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.98.1">Decoding</span></strong><span class="kobospan" id="kobo.99.1">: The process of converting model-generated representations (usually logits or token IDs) into human-readable text. </span><span class="kobospan" id="kobo.99.2">Decoding is necessary to produce the </span><span><span class="kobospan" id="kobo.100.1">final output.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.101.1">Transfer learning (TL)</span></strong><span class="kobospan" id="kobo.102.1">: The concept of transferring knowledge gained from one task or domain to another. </span><span class="kobospan" id="kobo.102.2">LLMs often benefit from TL, as they are pre-trained on a broad range of text before fine-tuning for </span><span><span class="kobospan" id="kobo.103.1">specific tasks.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.104.1">Prompt engineering</span></strong><span class="kobospan" id="kobo.105.1">: The process of designing input prompts or instructions that guide the LLM to generate the desired output. </span><span class="kobospan" id="kobo.105.2">Crafting effective prompts is crucial in controlling the </span><span><span class="kobospan" id="kobo.106.1">model’s behavior:</span></span></li>
</ul>
<div class="calibre2">
<div class="img---figure" id="_idContainer121">
<span class="kobospan" id="kobo.107.1"><img alt="Figure 10.1 – Simple prompt flow" src="image/B16573_10_01.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.108.1">Figure 10.1 – Simple prompt flow</span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.109.1">Zero-shot learning</span></strong><span class="kobospan" id="kobo.110.1">: A</span><a id="_idIndexMarker958" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.111.1"> type of TL where a model is asked to perform a task for which it was not explicitly fine-tuned. </span><span class="kobospan" id="kobo.111.2">LLMs are capable of zero-shot learning to </span><span><span class="kobospan" id="kobo.112.1">some extent.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.113.1">Few-shot learning</span></strong><span class="kobospan" id="kobo.114.1">: Like</span><a id="_idIndexMarker959" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.115.1"> zero-shot learning, but the model is provided with a limited number of examples for a new task </span><span><span class="kobospan" id="kobo.116.1">during fine-tuning.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.117.1">Chain of Thought (CoT)</span></strong><span class="kobospan" id="kobo.118.1">: CoT </span><a id="_idIndexMarker960" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.119.1">prompting is a technique that guides LLMs to follow a reasoning process when dealing with hard problems. </span><span class="kobospan" id="kobo.119.2">This is done by showing the model a few examples where the step-by-step reasoning is clearly </span><span><span class="kobospan" id="kobo.120.1">laid out.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.121.1">Tree of Thoughts (ToT)</span></strong><span class="kobospan" id="kobo.122.1">: ToT </span><a id="_idIndexMarker961" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.123.1">prompting breaks a problem into a sequence of smaller steps—or </span><em class="italic"><span class="kobospan" id="kobo.124.1">thoughts</span></em><span class="kobospan" id="kobo.125.1">—that are solved individually. </span><span class="kobospan" id="kobo.125.2">This approach does not constrain the model to output these steps all at once. </span><span class="kobospan" id="kobo.125.3">Rather, each thought is generated or solved independently and passed to the next step for solving </span><span><span class="kobospan" id="kobo.126.1">the problem.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.127.1">Graph of Thoughts (GoT)</span></strong><span class="kobospan" id="kobo.128.1">: It </span><a id="_idIndexMarker962" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.129.1">conceptualizes the data generated by an LLM as a graph, where each node symbolizes a unit of information, commonly known as “LLM thoughts.” </span><span class="kobospan" id="kobo.129.2">The connections between these nodes represent the dependencies or associations among distinct units </span><span><span class="kobospan" id="kobo.130.1">of thought.</span></span></li>
</ul>
<h2 id="_idParaDest-213" class="calibre7"><a id="_idTextAnchor222" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.131.1">Prompt example using ChatGPT (closed source LLM)</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.132.1">Let’s try an </span><a id="_idIndexMarker963" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.133.1">example using ChatGPT (</span><a href="https://chat.openai.com/" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.134.1">https://chat.openai.com/</span></a><span class="kobospan" id="kobo.135.1">) and ask questions to translate a sentence from English </span><span><span class="kobospan" id="kobo.136.1">to German.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.137.1">In this case, the question is called a prompt, and the response from ChatGPT (LLM) is called </span><span><span class="kobospan" id="kobo.138.1">a completion/result:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer122">
<span class="kobospan" id="kobo.139.1"><img alt="Figure 10.2 – Simple prompt request and completion" src="image/B16573_10_02.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.140.1">Figure 10.2 – Simple prompt request and completion</span></p>
<h2 id="_idParaDest-214" class="calibre7"><a id="_idTextAnchor223" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.141.1">Prompt example using open source LLMs</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.142.1">Let’s try an</span><a id="_idIndexMarker964" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.143.1"> example using open source LLMs programmatically </span><span><span class="kobospan" id="kobo.144.1">using Python.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.145.1">This code snippet demonstrates how to use the Google FLAN-T5 model for translation from English to German. </span><span class="kobospan" id="kobo.145.2">It utilizes the Hugging Face </span><strong class="source-inline"><span class="kobospan" id="kobo.146.1">Transformers</span></strong><span class="kobospan" id="kobo.147.1"> library, specifically the </span><strong class="source-inline"><span class="kobospan" id="kobo.148.1">T5Tokenizer</span></strong><span class="kobospan" id="kobo.149.1"> and </span><span><strong class="source-inline"><span class="kobospan" id="kobo.150.1">T5ForConditionalGeneration</span></strong></span><span><span class="kobospan" id="kobo.151.1"> classes.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.152.1">Ensure</span><a id="_idIndexMarker965" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.153.1"> that you have the Hugging Face Transformers library installed and that you have access to the </span><strong class="source-inline"><span class="kobospan" id="kobo.154.1">"google/flan-t5-large"</span></strong><span class="kobospan" id="kobo.155.1"> model for this code to run successfully. </span><span class="kobospan" id="kobo.155.2">Follow the next steps to implement </span><span><span class="kobospan" id="kobo.156.1">this example:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.157.1">Install the library using the </span><span><span class="kobospan" id="kobo.158.1">following command:</span></span><pre class="source-code">
<strong class="bold1"><span class="kobospan1" id="kobo.159.1">pip install transformers</span></strong></pre></li>
<li class="calibre11"><span class="kobospan" id="kobo.160.1">Additionally, you need to download the model using </span><strong class="source-inline1"><span class="kobospan" id="kobo.161.1">transformers.AutoModel.from_pretrained("google/flan-t5-large")</span></strong><span class="kobospan" id="kobo.162.1"> if you </span><span><span class="kobospan" id="kobo.163.1">haven’t already.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.164.1">Import the necessary classes from the Transformers library, namely </span><strong class="source-inline1"><span class="kobospan" id="kobo.165.1">T5Tokenizer</span></strong> <span><span class="kobospan" id="kobo.166.1">and </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.167.1">T5ForConditionalGeneration</span></strong></span><span><span class="kobospan" id="kobo.168.1">.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.169.1">Initialize the T5 tokenizer and model with the pre-trained </span><strong class="source-inline1"><span class="kobospan" id="kobo.170.1">"google/flan-t5-large"</span></strong><span class="kobospan" id="kobo.171.1"> model. </span><span class="kobospan" id="kobo.171.2">This model is designed for </span><span><span class="kobospan" id="kobo.172.1">translation tasks.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.173.1">Define the input text you want to translate from English to German, which is </span><strong class="source-inline1"><span class="kobospan" id="kobo.174.1">"translate English to German: How old </span></strong><span><strong class="source-inline1"><span class="kobospan" id="kobo.175.1">are you?"</span></strong></span><span><span class="kobospan" id="kobo.176.1">.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.177.1">Tokenize the input text using the tokenizer, and convert it into PyTorch tensors. </span><span class="kobospan" id="kobo.177.2">This step prepares the text for input to </span><span><span class="kobospan" id="kobo.178.1">the model.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.179.1">Generate the translation using the T5 model by passing the tokenized input to the model’s </span><strong class="source-inline1"><span class="kobospan" id="kobo.180.1">generate</span></strong><span class="kobospan" id="kobo.181.1"> method. </span><span class="kobospan" id="kobo.181.2">The translation output is stored in the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.182.1">outputs</span></strong></span><span><span class="kobospan" id="kobo.183.1"> variable.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.184.1">Decode the generated output using the tokenizer’s </span><strong class="source-inline1"><span class="kobospan" id="kobo.185.1">decode</span></strong><span class="kobospan" id="kobo.186.1"> method, and print the translated text, which will be the German translation of the </span><span><span class="kobospan" id="kobo.187.1">input text.</span></span></li>
</ol>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.188.1">Source code: Ex_LLM_Opensource.ipynb</span></em><span class="kobospan" id="kobo.189.1">The following is a detailed source code of </span><span><span class="kobospan" id="kobo.190.1">the example:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.191.1">
!pip install transformers
from transformers import T5Tokenizer,
T5ForConditionalGeneration
tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-large")
model =
T5ForConditionalGeneration.from_pretrained("google/flan-t5-large")
input_text = "translate English to German: How old are you?"
</span><span class="kobospan1" id="kobo.191.2">input_ids = tokenizer(input_text, return_tensors="pt").input_ids
outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer123">
<span class="kobospan" id="kobo.192.1"><img alt="Figure 10.3 – T5 model weights, tokenizer and config downloads" src="image/B16573_10_03.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.193.1">Figure 10.3 – T5 model weights, tokenizer and config downloads</span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.194.1">
input_text = "Who is the prime minister of India?"
</span><span class="kobospan1" id="kobo.194.2">input_ids = tokenizer(input_text, return_tensors="pt").input_ids
outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.195.1">This results in the </span><span><span class="kobospan" id="kobo.196.1">following output</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.197.1">
&lt;pad&gt; narendra modi&lt;/s&gt;</span></pre>
<h2 id="_idParaDest-215" class="calibre7"><a id="_idTextAnchor224" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.198.1">Comparison of open source LLMs and closed source LLMs</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.199.1">Open source </span><a id="_idIndexMarker966" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.200.1">and closed source LLMs represent </span><a id="_idIndexMarker967" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.201.1">two different approaches to the development and availability </span><span><span class="kobospan" id="kobo.202.1">of LLMs.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.203.1">Open source LLMs</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.204.1">Let’s look at some</span><a id="_idIndexMarker968" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.205.1"> of the attributes of open </span><span><span class="kobospan" id="kobo.206.1">source LLMs:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.207.1">Accessibility</span></strong><span class="kobospan" id="kobo.208.1">: Open source LLMs are publicly accessible, and their architecture and parameters can be examined, modified, and shared by the community. </span><span class="kobospan" id="kobo.208.2">This transparency fosters collaboration </span><span><span class="kobospan" id="kobo.209.1">and innovation.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.210.1">Community contributions</span></strong><span class="kobospan" id="kobo.211.1">: They often benefit from contributions and enhancements from a diverse community of researchers and developers, leading to rapid improvements and addressing </span><span><span class="kobospan" id="kobo.212.1">potential biases.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.213.1">Customization</span></strong><span class="kobospan" id="kobo.214.1">: Users have the freedom to fine-tune and adapt open source LLMs for specific tasks, languages, or domains, making them highly flexible </span><span><span class="kobospan" id="kobo.215.1">and versatile.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.216.1">Cost-efficiency</span></strong><span class="kobospan" id="kobo.217.1">: Typically, open source LLMs are free to use, which can be particularly advantageous for researchers, start-ups, </span><span><span class="kobospan" id="kobo.218.1">and developers.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.219.1">Hardware infrastructure</span></strong><span class="kobospan" id="kobo.220.1">: Open source models need to be hosted on GPUs for inferencing, and associated costs need to </span><span><span class="kobospan" id="kobo.221.1">be owned.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.222.1">Security</span></strong><span class="kobospan" id="kobo.223.1">: Open source LLMs may have security vulnerabilities or the underlying software versions, so addressing</span><a id="_idIndexMarker969" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.224.1"> these security vulnerabilities (</span><strong class="bold"><span class="kobospan" id="kobo.225.1">Common Vulnerabilities and Exposures</span></strong><span class="kobospan" id="kobo.226.1">, or </span><strong class="bold"><span class="kobospan" id="kobo.227.1">CVEs</span></strong><span class="kobospan" id="kobo.228.1">) needs to be managed on </span><span><span class="kobospan" id="kobo.229.1">its own.</span></span></li>
</ul>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.230.1">Examples</span></em><span class="kobospan" id="kobo.231.1">: Google’s FLAN-T5, Meta’s Llama models, GPT-3, and Hugging Face transformers are open source and </span><span><span class="kobospan" id="kobo.232.1">widely accessible.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.233.1">Closed source LLMs</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.234.1">Now, let’s turn </span><a id="_idIndexMarker970" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.235.1">our attention to the </span><a id="_idIndexMarker971" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.236.1">attributes of closed </span><span><span class="kobospan" id="kobo.237.1">source LLMs:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.238.1">Proprietary</span></strong><span class="kobospan" id="kobo.239.1">: Closed source LLMs are developed and owned by organizations or companies, and their architecture and parameters are not </span><span><span class="kobospan" id="kobo.240.1">publicly disclosed</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.241.1">Control</span></strong><span class="kobospan" id="kobo.242.1">: Developers of </span><a id="_idIndexMarker972" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.243.1">closed source LLMs retain control over their models, algorithms, and </span><strong class="bold"><span class="kobospan" id="kobo.244.1">intellectual property</span></strong><span class="kobospan" id="kobo.245.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.246.1">IP</span></strong><span class="kobospan" id="kobo.247.1">), allowing them to protect </span><span><span class="kobospan" id="kobo.248.1">their innovations</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.249.1">Limited customization</span></strong><span class="kobospan" id="kobo.250.1">: Users of closed source LLMs may have limited options for fine-tuning or adapting the model to specific needs, as the source code is not </span><span><span class="kobospan" id="kobo.251.1">openly available</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.252.1">Costs</span></strong><span class="kobospan" id="kobo.253.1">: Closed source LLMs often come with licensing fees or usage costs, which can be a significant factor for some users </span><span><span class="kobospan" id="kobo.254.1">or organizations</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.255.1">Hardware infrastructure</span></strong><span class="kobospan" id="kobo.256.1">: Closed source models are deployed in GPUs by the vendors, and </span><a id="_idIndexMarker973" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.257.1">they provide the APIs to access either through REST or gRPC, so infra costs are owned by the providers (in the case of GPT-4 or GPT-3.x, OpenAI and Microsoft will own the </span><span><span class="kobospan" id="kobo.258.1">hosted versions)</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.259.1">Security</span></strong><span class="kobospan" id="kobo.260.1">: Closed source LLMs may have security vulnerabilities in the underlying software versions, so LLM providers will address these security vulnerabilities (CVEs), and it is a black box for the users who make use </span><span><span class="kobospan" id="kobo.261.1">of these.</span></span></li>
</ul>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.262.1">Examples</span></em><span class="kobospan" id="kobo.263.1">: Commercial </span><a id="_idIndexMarker974" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.264.1">language models such as GPT-3.5 or GPT-4 models and proprietary models used by tech companies may be </span><span><span class="kobospan" id="kobo.265.1">closed source.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.266.1">The choice between open source and closed source LLMs depends on factors such as budget, data privacy concerns, customization needs, and the level of </span><span><span class="kobospan" id="kobo.267.1">control required.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.268.1">Open source LLMs offer accessibility, collaboration, and cost savings but may require more technical expertise for customization. </span><span class="kobospan" id="kobo.268.2">Closed source LLMs provide IP protection and may come with specialized support and features, but at the cost of limited transparency and potential </span><span><span class="kobospan" id="kobo.269.1">licensing fees.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.270.1">Organizations and developers should carefully consider their specific requirements when choosing between these </span><span><span class="kobospan" id="kobo.271.1">two approaches.</span></span></p>
<h1 id="_idParaDest-216" class="calibre5"><a id="_idTextAnchor225" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.272.1">AI standards and terminology of attacks</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.273.1">In the following section, we</span><a id="_idIndexMarker975" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.274.1"> will go through some AI standards and terminology </span><span><span class="kobospan" id="kobo.275.1">of attacks.</span></span></p>
<h2 id="_idParaDest-217" class="calibre7"><a id="_idTextAnchor226" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.276.1">NIST</span></h2>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.277.1">NIST Trustworthy and Responsible AI</span></em><span class="kobospan" id="kobo.278.1"> released a paper on taxonomy and terminologies</span><a id="_idIndexMarker976" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.279.1"> used in AI with respect to attacks and mitigations. </span><span class="kobospan" id="kobo.279.2">It </span><a id="_idIndexMarker977" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.280.1">covers both predictive AI (traditional ML) </span><span><span class="kobospan" id="kobo.281.1">and GenAI.</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer124">
<span class="kobospan" id="kobo.282.1"><img alt="Figure 10.4 – Taxonomy of attacks on Generative AI systems" src="image/B16573_10_04.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.283.1">Figure 10.4 – Taxonomy of attacks on Generative AI systems</span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.284.1">Image source: “</span></em><span class="kobospan" id="kobo.285.1">Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations</span><em class="italic"><span class="kobospan" id="kobo.286.1"> ” paper from </span></em><span><em class="italic"><span class="kobospan" id="kobo.287.1">NIST. </span></em></span><a href="https://doi.org/10.6028/NIST.AI.100-2e2023" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.288.1">https://doi.org/10.6028/NIST.AI.100-2e2023</span></span></a></p>
<h2 id="_idParaDest-218" class="calibre7"><a id="_idTextAnchor227" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.289.1">OWASP Top 10 for LLM applications</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.290.1">The </span><em class="italic"><span class="kobospan" id="kobo.291.1">OWASP Top 10 for Large Language Model Applications</span></em><span class="kobospan" id="kobo.292.1"> project aims to educate</span><a id="_idIndexMarker978" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.293.1"> developers, designers, architects, managers, and </span><a id="_idIndexMarker979" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.294.1">organizations about the potential security risks when deploying and managing LLMs. </span><span class="kobospan" id="kobo.294.2">The OWASP Top 10 for LLM applications are </span><span><span class="kobospan" id="kobo.295.1">as follows.</span></span></p>
<ul class="calibre10">
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.296.1">LLM01: </span></em><span><em class="italic"><span class="kobospan" id="kobo.297.1">Prompt Injection</span></em></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.298.1">LLM02: Insecure </span></em><span><em class="italic"><span class="kobospan" id="kobo.299.1">Output Handling</span></em></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.300.1">LLM03: Training </span></em><span><em class="italic"><span class="kobospan" id="kobo.301.1">Data Poisoning</span></em></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.302.1">LLM04: Model Denial </span></em><span><em class="italic"><span class="kobospan" id="kobo.303.1">of Service</span></em></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.304.1">LLM05: Supply </span></em><span><em class="italic"><span class="kobospan" id="kobo.305.1">Chain Vulnerabilities</span></em></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.306.1">LLM06: Sensitive </span></em><span><em class="italic"><span class="kobospan" id="kobo.307.1">Information Disclosure</span></em></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.308.1">LLM07: Insecure </span></em><span><em class="italic"><span class="kobospan" id="kobo.309.1">Plugin Design</span></em></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.310.1">LLM08: </span></em><span><em class="italic"><span class="kobospan" id="kobo.311.1">Excessive Agency</span></em></span></li>
<li class="calibre11"><span><em class="italic"><span class="kobospan" id="kobo.312.1">LLM09: Overreliance</span></em></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.313.1">LLM10: </span></em><span><em class="italic"><span class="kobospan" id="kobo.314.1">Model Theft</span></em></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.315.1">The detailed vulnerabilities and how to detect each vulnerability and possible solutions are documented </span><span><span class="kobospan" id="kobo.316.1">at </span></span><a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v1_1.pdf" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.317.1">https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v1_1.pdf</span></span></a><span><span class="kobospan" id="kobo.318.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.319.1">In the next section, we will cover in more detail privacy attacks </span><span><span class="kobospan" id="kobo.320.1">on LLMs/GenAI.</span></span></p>
<h1 id="_idParaDest-219" class="calibre5"><a id="_idTextAnchor228" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.321.1">Privacy attacks on LLMs</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.322.1">In recent years, LLMs have </span><a id="_idIndexMarker980" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.323.1">revolutionized </span><strong class="bold"><span class="kobospan" id="kobo.324.1">natural language understanding</span></strong><span class="kobospan" id="kobo.325.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.326.1">NLU</span></strong><span class="kobospan" id="kobo.327.1">) and </span><strong class="bold"><span class="kobospan" id="kobo.328.1">natural language generation</span></strong><span class="kobospan" id="kobo.329.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.330.1">NLG</span></strong><span class="kobospan" id="kobo.331.1">), powering</span><a id="_idIndexMarker981" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.332.1"> a wide range of applications from chatbots and virtual assistants to content recommendation systems and language translation </span><a id="_idIndexMarker982" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.333.1">services. </span><span class="kobospan" id="kobo.333.2">However, the rapid advancement of these models has raised significant concerns about privacy and security. </span><span class="kobospan" id="kobo.333.3">LLM </span><a id="_idIndexMarker983" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.334.1">applications have the potential to expose sensitive data, proprietary algorithms, or other confidential information through their output. </span><span class="kobospan" id="kobo.334.2">This could lead to unauthorized access to sensitive data, IP, privacy infringements, and other security violations. </span><span class="kobospan" id="kobo.334.3">As LLMs become increasingly prevalent in our digital landscape, there is a growing need for effective strategies to protect sensitive information and uphold </span><span><span class="kobospan" id="kobo.335.1">user privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.336.1">As discussed in the earlier chapters, ML models are susceptible to privacy attacks, and there’s no exception for GenAI models (</span><span><span class="kobospan" id="kobo.337.1">LLMs) either.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.338.1">The following two recent articles provide details of privacy issues in enterprises with respect </span><span><span class="kobospan" id="kobo.339.1">to GenAI:</span></span></p>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.340.1">Cyberhaven’s survey</span></strong><span class="kobospan" id="kobo.341.1">: As per the article from Cyberhaven (</span><a href="https://www.cyberhaven.com/blog/4-2-of-workers-have-pasted-company-data-into-chatgpt/" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.342.1">https://www.cyberhaven.com/blog/4-2-of-workers-have-pasted-company-data-into-chatgpt/</span></a><span class="kobospan" id="kobo.343.1">), the potential risks of data leaks when employees paste company data into chatbots such as</span><a id="_idIndexMarker984" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.344.1"> OpenAI’s GPT-3. </span><span class="kobospan" id="kobo.344.2">The company conducted a survey of 2,000 workers in the US and the UK and found that 4.2% of them had pasted company data into chatbots. </span><span class="kobospan" id="kobo.344.3">While chatbots such as GPT-3 are designed to forget information after the conversation ends, the risk lies in the fact that these chatbots could potentially remember and replicate sensitive information during the conversation. </span><span class="kobospan" id="kobo.344.4">The article also mentions that if a hacker gains control of the chatbot during the conversation, they could access sensitive data. </span><span class="kobospan" id="kobo.344.5">The article emphasizes the need for companies to have clear policies about what data can be shared with chatbots and to educate employees about potential risks. </span><span class="kobospan" id="kobo.344.6">It also suggests that companies should implement </span><strong class="bold"><span class="kobospan" id="kobo.345.1">data loss prevention</span></strong><span class="kobospan" id="kobo.346.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.347.1">DLP</span></strong><span class="kobospan" id="kobo.348.1">) solutions</span><a id="_idIndexMarker985" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.349.1"> to automatically block sensitive data from being shared with chatbots. </span><span class="kobospan" id="kobo.349.2">It concludes by stating that while AI chatbots have many benefits, companies need to be aware of potential security and privacy risks and take appropriate measures to protect </span><span><span class="kobospan" id="kobo.350.1">sensitive data.</span></span></p>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.351.1">Samsung’s IP leak</span></strong><span class="kobospan" id="kobo.352.1">: As per</span><a id="_idIndexMarker986" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.353.1"> the article at </span><a href="https://techcrunch.com/2023/05/02/samsung-bans-use-of-generative-ai-tools-like-chatgpt-after-april-internal-data-leak/" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.354.1">https://techcrunch.com/2023/05/02/samsung-bans-use-of-generative-ai-tools-like-chatgpt-after-april-internal-data-leak/</span></a><span class="kobospan" id="kobo.355.1">, Samsung employees unintentionally disclosed confidential information while using ChatGPT for work-related tasks, highlighting potential privacy and security risks. </span><span class="kobospan" id="kobo.355.2">Samsung’s semiconductor division permitted engineers to employ ChatGPT for source code checks and other duties. </span><span class="kobospan" id="kobo.355.3">However, </span><em class="italic"><span class="kobospan" id="kobo.356.1">The Economist</span></em><span class="kobospan" id="kobo.357.1"> in Korea reported three separate incidents where sensitive data was inadvertently exposed </span><span><span class="kobospan" id="kobo.358.1">to ChatGPT.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.359.1">In one incident, an employee copied confidential source code into a chat to identify errors. </span><span class="kobospan" id="kobo.359.2">Another employee shared code and requested optimization. </span><span class="kobospan" id="kobo.359.3">A third employee shared a meeting recording for transcription into presentation notes. </span><span class="kobospan" id="kobo.359.4">This data is now accessible </span><span><span class="kobospan" id="kobo.360.1">to ChatGPT.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.361.1">Samsung has responded promptly by limiting ChatGPT’s upload capacity to 1,024 bytes per user and initiating investigations into those responsible for the data breaches. </span><span class="kobospan" id="kobo.361.2">Moreover, Samsung is considering developing an in-house AI chatbot to bolster data security and privacy going forward. </span><span class="kobospan" id="kobo.361.3">However, it’s improbable that Samsung can retrieve the leaked data due to ChatGPT’s data policy, which employs data for model training unless users explicitly opt out. </span><span class="kobospan" id="kobo.361.4">The ChatGPT usage guide explicitly warns against sharing sensitive information </span><span><span class="kobospan" id="kobo.362.1">during conversations.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.363.1">These incidents illustrate real-world scenarios that privacy experts have long been wary of, such as sharing confidential legal or medical documents for text analysis or summarization, which could be utilized to refine the model. </span><span class="kobospan" id="kobo.363.2">Privacy experts caution that this may potentially</span><a id="_idIndexMarker987" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.364.1"> contravene </span><strong class="bold"><span class="kobospan" id="kobo.365.1">General Data Protection Regulation</span></strong><span class="kobospan" id="kobo.366.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.367.1">GDPR</span></strong><span class="kobospan" id="kobo.368.1">) compliance, resulting in </span><span><span class="kobospan" id="kobo.369.1">regulatory consequences.</span></span></p>
<h2 id="_idParaDest-220" class="calibre7"><a id="_idTextAnchor229" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.370.1">Membership inference attacks against generative models</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.371.1">We learned</span><a id="_idIndexMarker988" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.372.1"> about membership inference attacks on ML models in </span><a href="B16573_04.xhtml#_idTextAnchor079" class="pcalibre1 calibre6 pcalibre"><span><em class="italic"><span class="kobospan" id="kobo.373.1">Chapter 4</span></em></span></a><span class="kobospan" id="kobo.374.1">. </span><span class="kobospan" id="kobo.374.2">GenAI models also are susceptible to membership inference attacks along a </span><span><span class="kobospan" id="kobo.375.1">similar line:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.376.1">Generative models aim to estimate the fundamental distribution of a dataset, enabling the creation of lifelike samples based on </span><span><span class="kobospan" id="kobo.377.1">that distribution.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.378.1">When presented with a data point, the adversary discerns whether it was utilized in training </span><span><span class="kobospan" id="kobo.379.1">the model.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.380.1">These attacks are based on both white-box and black-box access to the target model, against several SOTA </span><span><span class="kobospan" id="kobo.381.1">generative models</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.382.1">Let’s go through </span><span><span class="kobospan" id="kobo.383.1">an example.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.384.1">This example</span><a id="_idIndexMarker989" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.385.1"> provides a basic membership inference attack against a generative model using PyTorch. </span><span class="kobospan" id="kobo.385.2">The attack aims to determine if a specific data point was part of the generative model’s training dataset. </span><span class="kobospan" id="kobo.385.3">It includes the </span><span><span class="kobospan" id="kobo.386.1">following components:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.387.1">Sample GenAI model </span><a id="_idIndexMarker990" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.388.1">using a </span><strong class="bold"><span class="kobospan" id="kobo.389.1">variational </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.390.1">autoencoder</span></strong></span><span><span class="kobospan" id="kobo.391.1"> (</span></span><span><strong class="bold"><span class="kobospan" id="kobo.392.1">VAE</span></strong></span><span><span class="kobospan" id="kobo.393.1">):</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.394.1">VAE</span></strong><span class="kobospan" id="kobo.395.1">: A simple </span><a id="_idIndexMarker991" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.396.1">VAE is used as the generative model. </span><span class="kobospan" id="kobo.396.2">The VAE is capable of encoding and decoding binary </span><span><span class="kobospan" id="kobo.397.1">data points.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.398.1">Adversary model</span></strong><span class="kobospan" id="kobo.399.1">: An adversary model is implemented as </span><span><span class="kobospan" id="kobo.400.1">a two-layer</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.401.1">feedforward neural network</span></strong><span class="kobospan" id="kobo.402.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.403.1">FNN</span></strong><span class="kobospan" id="kobo.404.1">): This model is trained to predict whether a given data point was a member of the </span><span><span class="kobospan" id="kobo.405.1">training dataset.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.406.1">Synthetic data</span></strong><span class="kobospan" id="kobo.407.1">: Synthetic binary data is generated for demonstration purposes. </span><span class="kobospan" id="kobo.407.2">In practice, you would replace this with your </span><span><span class="kobospan" id="kobo.408.1">actual dataset.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.409.1">Training process</span></strong><span class="kobospan" id="kobo.410.1">: The VAE and the adversary model are trained independently. </span><span class="kobospan" id="kobo.410.2">The VAE learns to encode and decode data, while the adversary model learns to </span><span><span class="kobospan" id="kobo.411.1">predict membership.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.412.1">Membership inference attack</span></strong><span class="kobospan" id="kobo.413.1">: The membership inference attack function takes a target data point, encodes it using the VAE, and then uses the adversary model to predict </span><a id="_idIndexMarker992" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.414.1">whether the target data point is a member or non-member of the </span><span><span class="kobospan" id="kobo.415.1">training dataset.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.416.1">Source </span><a id="_idIndexMarker993" class="pcalibre1 calibre6 pcalibre"/><span><span class="kobospan" id="kobo.417.1">code components:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.418.1">SampleGenModel class</span></strong><span class="kobospan" id="kobo.419.1">: Defines the architecture of </span><span><span class="kobospan" id="kobo.420.1">the VAE</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.421.1">Adversary class</span></strong><span class="kobospan" id="kobo.422.1">: Defines the architecture of the </span><span><span class="kobospan" id="kobo.423.1">adversary model</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.424.1">Data generation</span></strong><span class="kobospan" id="kobo.425.1">: Generates synthetic binary data for training </span><span><span class="kobospan" id="kobo.426.1">and testing</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.427.1">Training</span></strong><span class="kobospan" id="kobo.428.1">: Training loops for the VAE-based </span><strong class="source-inline1"><span class="kobospan" id="kobo.429.1">SampleGenModel</span></strong><span class="kobospan" id="kobo.430.1"> class and the </span><span><span class="kobospan" id="kobo.431.1">adversary model</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.432.1">Membership inference attack</span></strong><span class="kobospan" id="kobo.433.1">: The function for conducting the membership </span><span><span class="kobospan" id="kobo.434.1">inference attack</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.435.1">Main execution</span></strong><span class="kobospan" id="kobo.436.1">: Initializes the VAE and the adversary model and performs an attack on a target </span><span><span class="kobospan" id="kobo.437.1">data point</span></span></li>
</ul>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.438.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.439.1">code: MemberShipInference_LLM.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.440.1">
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
# Define a simple  generative model
class SampleGenModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, latent_dim):
        super(SampleGenModel, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, latent_dim * 2)
# Two times latent_dim for mean and log-variance
        )
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
            nn.Sigmoid()
        )
    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std
    def forward(self, x):
        x = self.encoder(x)
        mu, log_var = x[:, :latent_dim], x[:, latent_dim:]
        z = self.reparameterize(mu, log_var)
        reconstructed = self.decoder(z)
        return reconstructed, mu, log_var
# Generate synthetic data for demonstration
num_samples = 1000
data_dim = 20
data = torch.tensor(np.random.randint(2, size=(num_samples, data_dim)), dtype=torch.float32)
print(data)
# Initialize the SampleGenModel
input_dim = data_dim
hidden_dim = 64
latent_dim = 16
vae = SampleGenModel(input_dim, hidden_dim, latent_dim)
# Define an adversary model (a simple feedforward neural network)
class Adversary(nn.Module):
    def __init__(self, input_dim):
        super(Adversary, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )
    def forward(self, x):
        return self.fc(x)
# Train the SampleGenModel
# Train the adversary model
adversary = Adversary(latent_dim)
optimizer = optim.Adam(adversary.parameters(), lr=0.001)
criterion = nn.BCELoss()
# Prepare target data for the membership inference attack
target_data_point = torch.tensor(np.random.randint(2, size=data_dim), dtype=torch.float32)
# Membership inference attack function
def membership_inference_attack(vae, adversary, target_data_point):
# Encode the target data point using the VAE
    with torch.no_grad():
        target_data_point = target_data_point.unsqueeze(0)  # Add batch dimension
        reconstructed, mu, log_var = vae(target_data_point)
# Use the adversary to predict membership
    prediction = adversary(mu)
# If the prediction is close to 1, the target data point is likely a member
    if prediction.item() &gt; 0.5:
        return "Member"
    else:
        return "Non-Member"
# Perform the membership inference attack
result = membership_inference_attack(vae, adversary, target_data_point)
# Output the result
print("Membership Inference Result:", result)</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.441.1">This </span><a id="_idIndexMarker994" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.442.1">results in the </span><span><span class="kobospan" id="kobo.443.1">following output:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.444.1">
tensor([[0., 0., 1.,  ..., 1., 0., 1.],
        [0., 1., 1.,  ..., 0., 0., 1.],
        [1., 0., 1.,  ..., 1., 0., 1.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 1., 0.,  ..., 0., 1., 1.],
        [1., 0., 1.,  ..., 0., 0., 0.]])
Membership Inference Result: Member</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.445.1">Membership</span><a id="_idIndexMarker995" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.446.1"> inference attacks are more complex in practice, and this code serves as a basic demonstration. </span><span class="kobospan" id="kobo.446.2">Implement privacy and security measures when deploying generative models to protect against such attacks. </span><span class="kobospan" id="kobo.446.3">We will cover in detail how to protect GenAI models in a privacy-preserving manner in the </span><span><span class="kobospan" id="kobo.447.1">next section.</span></span></p>
<h2 id="_idParaDest-221" class="calibre7"><a id="_idTextAnchor230" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.448.1">Extracting training data attack from generative models</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.449.1">Extracting training data</span><a id="_idIndexMarker996" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.450.1"> from LLMs can be a challenging task because the training data is not typically available directly from the model. </span><span class="kobospan" id="kobo.450.2">Instead, LLMs are pre-trained on vast datasets from the internet. </span><span class="kobospan" id="kobo.450.3">If we have a specific LLM in mind and want to extract training data related to it, we may need access to the original data sources used for pre-training, which may not be </span><span><span class="kobospan" id="kobo.451.1">publicly available.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.452.1">Here’s a sample Python code snippet that demonstrates how we can extract text data from a pre-trained Hugging Face Transformers model, such as GPT-2. </span><span class="kobospan" id="kobo.452.2">Keep in mind that this code is for illustrative purposes and won’t retrieve the actual training data but rather generates text samples from </span><span><span class="kobospan" id="kobo.453.1">the model:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.454.1">In this code, we do </span><span><span class="kobospan" id="kobo.455.1">the following:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.456.1">We load a pre-trained GPT-2 model and tokenizer from the Hugging Face Transformers library. </span><span class="kobospan" id="kobo.456.2">You can choose other models based on </span><span><span class="kobospan" id="kobo.457.1">your requirements.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.458.1">We define a prompt, which serves as the starting point for generating text. </span><span class="kobospan" id="kobo.458.2">You can change the prompt to suit </span><span><span class="kobospan" id="kobo.459.1">your needs.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.460.1">We specify the number of text samples (</span><strong class="source-inline1"><span class="kobospan" id="kobo.461.1">num_samples</span></strong><span class="kobospan" id="kobo.462.1">) to generate from </span><span><span class="kobospan" id="kobo.463.1">the model.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.464.1">Inside the loop, we encode the prompt using the tokenizer and generate text sequences using the model. </span><span class="kobospan" id="kobo.464.2">We decode the output to obtain </span><span><span class="kobospan" id="kobo.465.1">human-readable text.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.466.1">Please note </span><a id="_idIndexMarker997" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.467.1">that the generated text is not actual training data used for the model but rather synthetic text produced by the model based on the provided prompt. </span><span class="kobospan" id="kobo.467.2">To access the actual training data used to train LLMs, you would need access to the original data sources, which are typically large and diverse </span><span><span class="kobospan" id="kobo.468.1">web corpora.</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.469.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.470.1">code: Training_Data_Extraction_Gen_AI.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.471.1">
!pip install torch
!pip install transformers
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer
# Load a pretrained GPT-2 model and tokenizer
model_name = "gpt2"
# You can choose other pretrained models as well
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
# Generate text samples from the model
prompt = "Once upon a time"
num_samples = 5
for _ in range(num_samples):
    input_ids = tokenizer.encode(prompt, return_tensors="pt")
    output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2)
    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
    print("Generated Text:\n", generated_text)
    print("="*80)</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer125">
<span class="kobospan" id="kobo.472.1"><img alt="Figure 10.5 – GPT2 model weights, tokenizer and config downloads" src="image/B16573_10_05.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.473.1">Figure 10.5 – GPT2 model weights, tokenizer and config downloads</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.474.1">Researchers</span><a id="_idIndexMarker998" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.475.1"> from Google, Apple, OpenAI, Harvard, UC Berkeley, Northeastern University and Stanford demonstrated an attack on GPT-2, a language model trained on scrapes of the public internet, and were able to extract hundreds of verbatim text sequences from the model’s training data. </span><span class="kobospan" id="kobo.475.2">These</span><a id="_idIndexMarker999" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.476.1"> extracted examples included (public) </span><strong class="bold"><span class="kobospan" id="kobo.477.1">personally identifiable information</span></strong><span class="kobospan" id="kobo.478.1"> or </span><strong class="bold"><span class="kobospan" id="kobo.479.1">PII</span></strong><span class="kobospan" id="kobo.480.1"> (names, phone numbers, and email addresses):</span><span> </span><a href="https://arxiv.org/pdf/2012.07805.pdf" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.481.1">https://arxiv.org/pdf/2012.07805.pdf</span></span></a><span><span class="kobospan" id="kobo.482.1">.</span></span></p>
<h2 id="_idParaDest-222" class="calibre7"><a id="_idTextAnchor231" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.483.1">Prompt injection attacks</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.484.1">A </span><a id="_idIndexMarker1000" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.485.1">prompt injection attack, also known as data or command injection, is a type of security vulnerability that happens when an attacker can influence the prompts or commands sent to a data processing system such as an LLM. </span><span class="kobospan" id="kobo.485.2">These attacks potentially allow attackers to manipulate the actions of the system or extract sensitive or </span><span><span class="kobospan" id="kobo.486.1">private data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.487.1">In the context of an LLM, prompt injection attacks could involve an attacker providing a crafted input designed to trick the model into providing information it has been trained on, which could potentially include sensitive or confidential information if the training data was not properly anonymized or scrubbed. </span><span class="kobospan" id="kobo.487.2">Moreover, an attacker could inject malicious prompts to make the model produce outputs that inflict harm, such as generating offensive, defamatory, or illegal content. </span><span class="kobospan" id="kobo.487.3">This could be used for spear phishing, spreading disinformation, defaming individuals or entities, and many other </span><span><span class="kobospan" id="kobo.488.1">nefarious purposes.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.489.1">LangChain (</span><a href="https://www.langchain.com/" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.490.1">https://www.langchain.com/</span></a><span class="kobospan" id="kobo.491.1">) is </span><a id="_idIndexMarker1001" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.492.1">one of the open source frameworks that provides tools to build LLM applications. </span><span class="kobospan" id="kobo.492.2">In August 2023, the NVIDIA AI Red Team identified three vulnerabilities in LangChain through prompt injection; they are listed </span><span><span class="kobospan" id="kobo.493.1">as follows:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.494.1">CVE-2023-29374</span></em><span class="kobospan" id="kobo.495.1">: In LangChain through 0.0.131, the </span><strong class="source-inline1"><span class="kobospan" id="kobo.496.1">LLMMathChain</span></strong><span class="kobospan" id="kobo.497.1"> chain allows prompt injection attacks that can execute arbitrary code via the Python </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.498.1">exec</span></strong></span><span><span class="kobospan" id="kobo.499.1"> method</span></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.500.1">CVE-2023-32786</span></em><span class="kobospan" id="kobo.501.1">: In Langchain through 0.0.155, prompt injection allows an attacker to force the service to retrieve data from an arbitrary URL, essentially providing </span><strong class="bold"><span class="kobospan" id="kobo.502.1">server-side request forgery</span></strong><span class="kobospan" id="kobo.503.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.504.1">SSRF</span></strong><span class="kobospan" id="kobo.505.1">) and potentially injecting content</span><a id="_idIndexMarker1002" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.506.1"> into </span><span><span class="kobospan" id="kobo.507.1">downstream tasks</span></span></li>
<li class="calibre11"><em class="italic"><span class="kobospan" id="kobo.508.1">CVE-2023-36189</span></em><span class="kobospan" id="kobo.509.1">: SQL injection vulnerability in LangChain before v0.0.247 allows a remote attacker to obtain sensitive information via the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.510.1">SQLDatabaseChain </span></strong></span><span><span class="kobospan" id="kobo.511.1">component</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.512.1">Currently, the</span><a id="_idIndexMarker1003" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.513.1"> extent to which LLMs are vulnerable to these attacks isn’t fully understood. </span><span class="kobospan" id="kobo.513.2">It’s also worth mentioning that these models are designed not to directly recall any specifics about their training data, including documents or sources they were trained on, and they generally don’t have the ability to access or retrieve personal data unless they’ve been explicitly programmed to do so, or they’ve been trained on data that contains sensitive personal information. </span><span class="kobospan" id="kobo.513.3">Nonetheless, it’s always crucial to approach the use of LLMs, or any AI system, with robust security </span><a id="_idIndexMarker1004" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.514.1">measures and an understanding of </span><span><span class="kobospan" id="kobo.515.1">potential risks.</span></span></p>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.516.1">Example: PromptInjection.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.517.1">
class SimpleModel:
    def __init__(self):
        self.data={
            'Unique ID':'123-45-6789',
            'email':'example@example.com',
            'password':'mypassword'
        }
    def generate_text(self,prompt):
        return self.data.get(prompt,'Sorry,I don\'t have the data')
model=SimpleModel()
## Normal Request
print(model.generate_text('favorite_color'))
## Malicious request , simulating an attempt to a prompt injection attack
print(model.generate_text('Unique ID'))</span></pre>
<p class="calibre3"><strong class="source-inline"><span class="kobospan" id="kobo.518.1">This results in the </span></strong><span><strong class="source-inline"><span class="kobospan" id="kobo.519.1">following output.</span></strong></span></p>
<pre class="console"><span class="kobospan1" id="kobo.520.1">
Sorry,I don't have the data
123-45-6789</span></pre>
<h1 id="_idParaDest-223" class="calibre5"><a id="_idTextAnchor232" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.521.1">Privacy-preserving technologies for LLMs</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.522.1">Differential</span><a id="_idIndexMarker1005" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.523.1"> privacy </span><a id="_idIndexMarker1006" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.524.1">is one of the privacy-preserving technologies that can be used for LLMs </span><span><span class="kobospan" id="kobo.525.1">as well.</span></span></p>
<h2 id="_idParaDest-224" class="calibre7"><a id="_idTextAnchor233" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.526.1">Text attacks on ML models and LLMs</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.527.1">TextAttack </span><a id="_idIndexMarker1007" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.528.1">stands as a Python</span><a id="_idIndexMarker1008" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.529.1"> framework designed for conducting adversarial attacks, adversarial training, and data augmentation within the field of NLP. </span><span class="kobospan" id="kobo.529.2">This versatile tool streamlines the process of exploring NLP model robustness, offering a seamless, rapid, and user-friendly experience. </span><span class="kobospan" id="kobo.529.3">Furthermore, it proves invaluable for NLP model training, adversarial training, and data augmentation purposes. </span><span class="kobospan" id="kobo.529.4">TextAttack offers various components tailored for typical NLP tasks, including sentence encoding, grammar checking, and word replacement, which can also be </span><span><span class="kobospan" id="kobo.530.1">utilized independently.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.531.1">Instructions on</span><a id="_idIndexMarker1009" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.532.1"> how to install the TextAttack package can be found at this GitHub URL:  </span><a href="https://github.com/QData/TextAttack" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.533.1">https://github.com/QData/TextAttack</span></span></a><span><span class="kobospan" id="kobo.534.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.535.1">Install TextAttack framework using </span><strong class="source-inline"><span class="kobospan" id="kobo.536.1">pip install</span></strong><span class="kobospan" id="kobo.537.1"> in the </span><span><span class="kobospan" id="kobo.538.1">following way:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.539.1">
!pip install textattack</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.540.1">TextAttack provides various recipes to attack on NLP modules. </span><span class="kobospan" id="kobo.540.2">The following example utilizes various libraries and components to perform adversarial attacks on NLP models using the </span><span><span class="kobospan" id="kobo.541.1">TextAttack framework.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.542.1">Here are the high-level steps</span><a id="_idIndexMarker1010" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.543.1"> in the implementation of </span><span><span class="kobospan" id="kobo.544.1">this example:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.545.1">Importing libraries</span></strong><span class="kobospan" id="kobo.546.1">: Import the necessary libraries, including </span><strong class="source-inline1"><span class="kobospan" id="kobo.547.1">transformers</span></strong><span class="kobospan" id="kobo.548.1"> from Hugging Face, </span><strong class="source-inline1"><span class="kobospan" id="kobo.549.1">torch</span></strong><span class="kobospan" id="kobo.550.1"> for PyTorch, </span><strong class="source-inline1"><span class="kobospan" id="kobo.551.1">math</span></strong><span class="kobospan" id="kobo.552.1">, </span><strong class="source-inline1"><span class="kobospan" id="kobo.553.1">textattack</span></strong><span class="kobospan" id="kobo.554.1">, </span><span><span class="kobospan" id="kobo.555.1">and </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.556.1">random</span></strong></span><span><span class="kobospan" id="kobo.557.1">.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.558.1">Environment setup</span></strong><span class="kobospan" id="kobo.559.1">: It sets the </span><strong class="source-inline1"><span class="kobospan" id="kobo.560.1">CUDA_VISIBLE_DEVICES</span></strong><span class="kobospan" id="kobo.561.1"> environment variable to an empty string, essentially disabling GPU usage. </span><span class="kobospan" id="kobo.561.2">It specifies the device to be used as </span><strong class="source-inline1"><span class="kobospan" id="kobo.562.1">"cpu"</span></strong><span class="kobospan" id="kobo.563.1"> for </span><span><span class="kobospan" id="kobo.564.1">PyTorch operations.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.565.1">Model definition</span></strong><span class="kobospan" id="kobo.566.1">: Defines a custom PyTorch model called </span><strong class="source-inline1"><span class="kobospan" id="kobo.567.1">Model</span></strong><span class="kobospan" id="kobo.568.1">. </span><span class="kobospan" id="kobo.568.2">This model uses </span><strong class="bold"><span class="kobospan" id="kobo.569.1">Bidirectional Encoder Representations from Transformers</span></strong><span class="kobospan" id="kobo.570.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.571.1">BERT</span></strong><span class="kobospan" id="kobo.572.1">) for NLP tasks. </span><span class="kobospan" id="kobo.572.2">The </span><a id="_idIndexMarker1011" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.573.1">model loads the pre-trained </span><strong class="source-inline1"><span class="kobospan" id="kobo.574.1">'bert-base-uncased'</span></strong><span class="kobospan" id="kobo.575.1"> BERT model from Hugging Face’s Transformers library. </span><span class="kobospan" id="kobo.575.2">It includes a dropout layer and a linear layer </span><span><span class="kobospan" id="kobo.576.1">for classification.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.577.1">Initialization </span><a id="_idIndexMarker1012" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.578.1">of model </span><span><span class="kobospan" id="kobo.579.1">and tokenization:</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.580.1">Model initialization</span></strong><span class="kobospan" id="kobo.581.1">: An instance of the </span><strong class="source-inline1"><span class="kobospan" id="kobo.582.1">Model</span></strong><span class="kobospan" id="kobo.583.1"> class is created and moved to the </span><a id="_idIndexMarker1013" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.584.1">CPU for evaluation. </span><span class="kobospan" id="kobo.584.2">The model is set to evaluation mode </span><span><span class="kobospan" id="kobo.585.1">using </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.586.1">model.eval()</span></strong></span><span><span class="kobospan" id="kobo.587.1">.</span></span></li><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.588.1">Tokenizer initialization</span></strong><span class="kobospan" id="kobo.589.1">: Initializes a BERT tokenizer (</span><strong class="source-inline1"><span class="kobospan" id="kobo.590.1">BertTokenizer</span></strong><span class="kobospan" id="kobo.591.1">) for </span><span><span class="kobospan" id="kobo.592.1">tokenizing text.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.593.1">Custom model wrapper</span></strong><span class="kobospan" id="kobo.594.1">: Defines a custom model wrapper class called </span><strong class="source-inline1"><span class="kobospan" id="kobo.595.1">CustomWrapper</span></strong><span class="kobospan" id="kobo.596.1"> that wraps the PyTorch model. </span><span class="kobospan" id="kobo.596.2">This wrapper allows the model to be used with the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.597.1">TextAttack</span></strong></span><span><span class="kobospan" id="kobo.598.1"> library.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.599.1">Utilizes the TextAttack library to build an attack using the </span><strong class="source-inline1"><span class="kobospan" id="kobo.600.1">TextFoolerJin2019</span></strong><span class="kobospan" id="kobo.601.1"> recipe. </span><span class="kobospan" id="kobo.601.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.602.1">CustomWrapper</span></strong><span class="kobospan" id="kobo.603.1"> instance is passed to </span><span><span class="kobospan" id="kobo.604.1">the attack:</span></span><ul class="calibre16"><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.605.1">Dataset</span></strong><span class="kobospan" id="kobo.606.1">: Defines a list called </span><strong class="source-inline1"><span class="kobospan" id="kobo.607.1">dataset</span></strong><span class="kobospan" id="kobo.608.1">, containing text samples and corresponding labels. </span><span class="kobospan" id="kobo.608.2">These samples are examples of performing </span><span><span class="kobospan" id="kobo.609.1">adversarial attacks.</span></span></li><li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.610.1">Attack execution</span></strong><span class="kobospan" id="kobo.611.1">: Creates an </span><strong class="source-inline1"><span class="kobospan" id="kobo.612.1">Attacker</span></strong><span class="kobospan" id="kobo.613.1"> instance, specifying the attack, dataset, and other attack parameters. </span><span class="kobospan" id="kobo.613.2">Finally, the </span><strong class="source-inline1"><span class="kobospan" id="kobo.614.1">attack_dataset()</span></strong><span class="kobospan" id="kobo.615.1"> method is called on the attacker to perform adversarial attacks on </span><span><span class="kobospan" id="kobo.616.1">the dataset.</span></span></li></ul></li>
</ol>
<p class="calibre3"><span class="kobospan" id="kobo.617.1">Overall, this</span><a id="_idIndexMarker1014" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.618.1"> code</span><a id="_idIndexMarker1015" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.619.1"> sets up a PyTorch model, initializes an attack using the TextAttack library, and then applies this attack to a dataset of text samples for the purpose of evaluating the robustness of the </span><span><span class="kobospan" id="kobo.620.1">NLP model.</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.621.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.622.1">code: Privacy_attacks_LLMs.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.623.1">
import pandas as pd
import os
from transformers import BertTokenizer, BertModel
from torch import nn
import torch
import math
import textattack
import random
#from train_bert import Model
os.environ["CUDA_VISIBLE_DEVICES"] = ""
#torch.cuda.is_available = lambda : False
textattack.shared.utils.device = "cpu"
class Model(torch.nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.bert_model = BertModel.from_pretrained('bert-base-uncased')
        #self.bert_model.parallelize()
        self.drop = torch.nn.Dropout(p=0.1)
        self.l1 = torch.nn.Linear(768,2)
    def forward(self, text):
        tokenized_text = tokenizer(text , max_length=512, truncation=True, return_tensors='pt').input_ids#.to('cuda:3')
        text_rep = self.drop(self.bert_model(tokenized_text).pooler_output)
        out = self.l1(text_rep)
        print(out)
        return out.squeeze().tolist()
model = Model()
model.load_state_dict(torch.load('bert-base-uncased'))
model = model.to('cpu')
model.eval()
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
class CustomWrapper(textattack.models.wrappers.ModelWrapper):
    def __init__(self, model):
        self.model = model#.to('cuda:3')
        self.model.eval()
    def __call__(self, list_of_texts):
        results = []
        self.model.requires_grad = False
        for text in list_of_texts:
          results.append(self.model(text))
        return results
class_model = CustomWrapper(model)
from textattack.datasets import Dataset
from textattack.attack_recipes.textfooler_jin_2019 import TextFoolerJin2019
from textattack import Attacker, AttackArgs
attack = TextFoolerJin2019.build(class_model)
attack#.cuda_()
dataset = [
    ["This film is a masterpiece! </span><span class="kobospan1" id="kobo.623.2">The story is incredibly moving, and the performances are outstanding. </span><span class="kobospan1" id="kobo.623.3">It's a true classic.", 1],
    ["The Godfather is a cinematic gem. </span><span class="kobospan1" id="kobo.623.4">The storytelling and performances are top-notch. </span><span class="kobospan1" id="kobo.623.5">A true classic in every sense.", 1],
    ["The Emoji Movie is a complete disappointment. </span><span class="kobospan1" id="kobo.623.6">The plot is weak, and it feels like one big advertisement. </span><span class="kobospan1" id="kobo.623.7">A waste of time.", 0],
    ["Mind-bending and visually stunning! </span><span class="kobospan1" id="kobo.623.8">Inception keeps you guessing from start to finish. </span><span class="kobospan1" id="kobo.623.9">Christopher Nolan at his best.", 1],
    ["Twilight is a guilty pleasure for some, but the acting and dialogue are cringe-worthy. </span><span class="kobospan1" id="kobo.623.10">Not a cinematic masterpiece.", 0],
    ["Forrest Gump is a heartwarming journey through history. </span><span class="kobospan1" id="kobo.623.11">Tom Hanks delivers an unforgettable performance.", 1],
    ["Explosions and CGI can't make up for the lackluster story in Transformers: The Last Knight. </span><span class="kobospan1" id="kobo.623.12">Disappointing.", 0],
    ["The Dark Knight is a dark and gripping superhero film. </span><span class="kobospan1" id="kobo.623.13">Heath Ledger's Joker is iconic. </span><span class="kobospan1" id="kobo.623.14">A must-see.", 1],
    ["Avatar is visually breathtaking, but the story is somewhat predictable. </span><span class="kobospan1" id="kobo.623.15">Still, it's a cinematic experience.", 1],
    ["The Room is so bad that it's almost good. </span><span class="kobospan1" id="kobo.623.16">The unintentional humor makes it a cult classic.", 1]
]
random.shuffle(dataset)
attacker = Attacker(attack, textattack.datasets.Dataset(dataset[:10]), AttackArgs(num_examples=10))
attacker.attack_dataset()</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.624.1">This results in the </span><span><span class="kobospan" id="kobo.625.1">following output:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.626.1">
+-------------------------------+--------+
| Attack Results                |        |
+-------------------------------+--------+
| Number of successful attacks: | 1      |
| Number of failed attacks:     | 2      |
| Number of skipped attacks:    | 7      |
| Original accuracy:            | 30.0%  |
| Accuracy under attack:        | 20.0%  |
| Attack success rate:          | 33.33% |
| Average perturbed word %:     | 40.91% |
| Average num. </span><span class="kobospan1" id="kobo.626.2">words per input: | 17.3   |
| Avg num queries:              | 213.33 |
+-------------------------------+--------+</span></pre>
<p class="calibre3"><span class="kobospan" id="kobo.627.1">In a similar</span><a id="_idIndexMarker1016" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.628.1"> way, the GPT-2 model also</span><a id="_idIndexMarker1017" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.629.1"> can be explored for NLP attacks (for the complete source code, refer to the GitHub repo </span><span><span class="kobospan" id="kobo.630.1">at </span></span><a href="https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter10/Privacy_attacks_LLMs.ipynb" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.631.1">https://github.com/PacktPublishing/Privacy-Preserving-Machine-Learning/blob/main/Chapter10/Privacy_attacks_LLMs.ipynb</span></span></a><span><span class="kobospan" id="kobo.632.1">):</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.633.1">
class ClassificationModel(nn.Module):
    def __init__(self, model, pos_prompt, neg_prompt):
        super(ClassificationModel, self).__init__()
        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
        self.model = GPT2LMHeadModel.from_pretrained(model)
        self.model.eval()
        self.pos_prompt = pos_prompt
        self.neg_prompt = neg_prompt
    def score(self, prompt, sentence, model):
        tokenized_prompt = self.tokenizer.encode(prompt , max_length=1024, truncation=True, return_tensors='pt').to('cpu')
        tokenized_all = self.tokenizer.encode(prompt + ' ' + sentence, max_length=1024, truncation=True, return_tensors='pt').to('cpu')
        loss1=model(tokenized_all, labels=tokenized_all).loss
        loss2 = model(tokenized_prompt, labels=tokenized_prompt).loss*len(tokenized_prompt[0])/len(tokenized_all[0])
        loss = loss1-loss2
        return math.exp(loss)
    def forward(self, sentence):
        pos = 0
        neg = 0
        for prompt in self.pos_prompt:
             pos += self.score(prompt, sentence, self.model)#.cpu()
        for prompt in self.neg_prompt:
             neg += self.score(prompt, sentence, self.model)#.cpu()
        result = torch.FloatTensor([5000-neg/10.0e+52, 5000-pos/10.0e+52])
        result = torch.softmax(result, 0)
        if abs(result[0].item()+result[1].item()-1) &gt;= 1e-6:
            print('detected something')
            result = torch.FloatTensor([1,0])
        return torch.softmax(result, 0)
model = ClassificationModel('gpt2', ['Positive:'], ['Negative:'])
class_model = CustomWrapper(model)
attacker = Attacker(attack, textattack.datasets.Dataset(dataset[:10]), AttackArgs(num_examples=10))</span></pre>
<p class="calibre3"><span><strong class="source-inline"><span class="kobospan" id="kobo.634.1">attacker.attack_dataset()</span></strong></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.635.1">This results</span><a id="_idIndexMarker1018" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.636.1"> in the </span><span><span class="kobospan" id="kobo.637.1">following output:</span></span></p>
<pre class="console"><span class="kobospan1" id="kobo.638.1">
-------------------------------+-------+
| Attack Results                |       |
+-------------------------------+-------+
| Number of successful attacks: | 0     |
| Number of failed attacks:     | 3     |
| Number of skipped attacks:    | 7     |
| Original accuracy:            | 30.0% |
| Accuracy under attack:        | 30.0% |
| Attack success rate:          | 0.0%  |
| Average perturbed word %:     | nan%  |
| Average num. </span><span class="kobospan1" id="kobo.638.2">words per input: | 17.3  |
| Avg num queries:              | 250.0 |
+-------------------------------+-------+</span></pre>
<h2 id="_idParaDest-225" class="calibre7"><a id="_idTextAnchor234" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.639.1">Private transformers – training LLMs using differential privacy</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.640.1">The complete source </span><a id="_idIndexMarker1019" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.641.1">code for this section can be found at  </span><a href="https://github.com/lxuechen/private-transformers" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.642.1">https://github.com/lxuechen/private-transformers</span></span></a><span><span class="kobospan" id="kobo.643.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.644.1">Xuechen Li, Florian Tramer, Percy Liang, Tatsunori Hashimoto et al. </span><span class="kobospan" id="kobo.644.2">provided private transformers to train LLMs using </span><span><span class="kobospan" id="kobo.645.1">differential privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.646.1">They modified the </span><a id="_idIndexMarker1020" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.647.1">Opacus framework, integrated it with Hugging Face’s </span><strong class="source-inline"><span class="kobospan" id="kobo.648.1">transformers</span></strong><span class="kobospan" id="kobo.649.1"> library, and provided a </span><strong class="bold"><span class="kobospan" id="kobo.650.1">privacy engine</span></strong><span class="kobospan" id="kobo.651.1"> to </span><a id="_idIndexMarker1021" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.652.1">train the LLMs in a privacy-preserving manner. </span><span class="kobospan" id="kobo.652.2">Using this code base, they successfully fine-tuned exceptionally large pre-trained models, achieving some of the most impressive differentially private NLP results to date. </span><span class="kobospan" id="kobo.652.3">In fact, certain models have exhibited performance comparable to robust non-private baseline approaches. </span><span class="kobospan" id="kobo.652.4">This provides compelling empirical support for the notion that highly effective differentially private NLP models can be constructed even with relatively modest datasets. </span><span class="kobospan" id="kobo.652.5">Furthermore, support for the ghost-clipping technique enables the private training of large transformers with significantly reduced memory requirements. </span><span class="kobospan" id="kobo.652.6">In many instances, the memory footprint is nearly as lightweight as non-private training, with only a modest increase in runtime overhead. </span><span class="kobospan" id="kobo.652.7">Private transformers currently support the following </span><span><span class="kobospan" id="kobo.653.1">LLMs only:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.654.1">OpenAIGPTLMHeadModel</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.655.1">OpenAIGPTDoubleHeadsModel</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.656.1">GPT2LMHeadModel</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.657.1">GPT2DoubleHeadsModel</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.658.1">BertForSequenceClassification</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.659.1">RobertaForSequenceClassification</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.660.1">AlbertForSequenceClassification</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.661.1">BartForConditionalGeneration</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.662.1">T5ForConditionalGeneration</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.663.1">OPTForCausalLM</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.664.1">ViTForImageClassification</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.665.1">DeiTForImageClassification</span></strong></span></li>
<li class="calibre11"><span><strong class="source-inline1"><span class="kobospan" id="kobo.666.1">BeitForImageClassification</span></strong></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.667.1">Privately training</span><a id="_idIndexMarker1022" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.668.1"> Hugging Face transformers </span><a id="_idIndexMarker1023" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.669.1">simply consists of </span><span><span class="kobospan" id="kobo.670.1">four steps:</span></span></p>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.671.1">Create your favorite transformer model and optimizer; attach this optimizer to a </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.672.1">PrivacyEngine</span></strong></span><span><span class="kobospan" id="kobo.673.1"> instance.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.674.1">Compute a per-example loss (1-D tensor) for a mini-batch </span><span><span class="kobospan" id="kobo.675.1">of data.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.676.1">Pass the loss to </span><strong class="source-inline1"><span class="kobospan" id="kobo.677.1">optimizer.step</span></strong><span class="kobospan" id="kobo.678.1"> or </span><strong class="source-inline1"><span class="kobospan" id="kobo.679.1">optimizer.virtual_step</span></strong><span class="kobospan" id="kobo.680.1"> as a </span><span><span class="kobospan" id="kobo.681.1">keyword argument.</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.682.1">Repeat from </span><span><em class="italic"><span class="kobospan" id="kobo.683.1">step 2</span></em></span><span><span class="kobospan" id="kobo.684.1">.</span></span></li>
</ol>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.685.1">Example</span></em></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.686.1">The code shown next is designed for training a language model with privacy-preserving features. </span><span class="kobospan" id="kobo.686.2">It utilizes the Hugging Face Transformers library and PyTorch. </span><span class="kobospan" id="kobo.686.3">Next are the detailed steps </span><span><span class="kobospan" id="kobo.687.1">to implement.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.688.1">The following things are covered in the steps </span><span><span class="kobospan" id="kobo.689.1">outlined next:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.690.1">Libraries </span><span><span class="kobospan" id="kobo.691.1">and imports</span></span></li>
<li class="calibre11"><span><span class="kobospan" id="kobo.692.1">Dataset class</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.693.1">Loading data from a </span><span><span class="kobospan" id="kobo.694.1">text file</span></span></li>
<li class="calibre11"><span><span class="kobospan" id="kobo.695.1">Forward step</span></span></li>
<li class="calibre11"><span><span class="kobospan" id="kobo.696.1">Training function</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.697.1">Running </span><span><span class="kobospan" id="kobo.698.1">the training</span></span></li>
</ul>
<ol class="calibre15">
<li class="calibre11"><span class="kobospan" id="kobo.699.1">Importing </span><a id="_idIndexMarker1024" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.700.1">the necessary</span><a id="_idIndexMarker1025" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.701.1"> libraries and modules. </span><span class="kobospan" id="kobo.701.2">These include </span><span><span class="kobospan" id="kobo.702.1">the following:</span></span><ul class="calibre16"><li class="calibre11"><strong class="source-inline1"><span class="kobospan" id="kobo.703.1">tqdm</span></strong><span class="kobospan" id="kobo.704.1">: A library for displaying progress bars </span><span><span class="kobospan" id="kobo.705.1">during training.</span></span></li><li class="calibre11"><strong class="source-inline1"><span class="kobospan" id="kobo.706.1">transformers</span></strong><span class="kobospan" id="kobo.707.1">: A library for working with </span><span><span class="kobospan" id="kobo.708.1">transformer-based models.</span></span></li><li class="calibre11"><strong class="source-inline1"><span class="kobospan" id="kobo.709.1">torch</span></strong><span class="kobospan" id="kobo.710.1">: The PyTorch library for </span><strong class="bold"><span class="kobospan" id="kobo.711.1">deep </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.712.1">learning</span></strong></span><span><span class="kobospan" id="kobo.713.1"> (</span></span><span><strong class="bold"><span class="kobospan" id="kobo.714.1">DL</span></strong></span><span><span class="kobospan" id="kobo.715.1">).</span></span></li><li class="calibre11"><strong class="source-inline1"><span class="kobospan" id="kobo.716.1">GPT2Tokenizer</span></strong><span class="kobospan" id="kobo.717.1"> and </span><strong class="source-inline1"><span class="kobospan" id="kobo.718.1">GPT2LMHeadModel</span></strong><span class="kobospan" id="kobo.719.1"> from </span><strong class="source-inline1"><span class="kobospan" id="kobo.720.1">transformers</span></strong><span class="kobospan" id="kobo.721.1">: These classes provide access to the GPT-2 model </span><span><span class="kobospan" id="kobo.722.1">and tokenizer.</span></span></li><li class="calibre11"><strong class="source-inline1"><span class="kobospan" id="kobo.723.1">PrivacyEngine</span></strong><span class="kobospan" id="kobo.724.1"> from </span><strong class="source-inline1"><span class="kobospan" id="kobo.725.1">private_transformers</span></strong><span class="kobospan" id="kobo.726.1">: A custom privacy engine for training the model with </span><span><span class="kobospan" id="kobo.727.1">privacy constraints.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.728.1">Dataset class</span></strong><span class="kobospan" id="kobo.729.1">: A custom </span><strong class="source-inline1"><span class="kobospan" id="kobo.730.1">Dataset</span></strong><span class="kobospan" id="kobo.731.1"> class is defined to handle the training data. </span><span class="kobospan" id="kobo.731.2">This class has the </span><span><span class="kobospan" id="kobo.732.1">following methods:</span></span><ul class="calibre16"><li class="calibre11"><strong class="source-inline1"><span class="kobospan" id="kobo.733.1">__init__(self, texts, labels, eos_token)</span></strong><span class="kobospan" id="kobo.734.1">: Initializes the dataset with texts, labels, and</span><a id="_idIndexMarker1026" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.735.1"> an </span><strong class="bold"><span class="kobospan" id="kobo.736.1">end-of-sequence</span></strong><span class="kobospan" id="kobo.737.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.738.1">EOS</span></strong><span class="kobospan" id="kobo.739.1">) </span><span><span class="kobospan" id="kobo.740.1">token (</span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.741.1">eos_token</span></strong></span><span><span class="kobospan" id="kobo.742.1">).</span></span></li><li class="calibre11"><strong class="source-inline1"><span class="kobospan" id="kobo.743.1">__len__(self)</span></strong><span class="kobospan" id="kobo.744.1">: Returns the length of </span><span><span class="kobospan" id="kobo.745.1">the dataset.</span></span></li><li class="calibre11"><strong class="source-inline1"><span class="kobospan" id="kobo.746.1">__getitem__(self, index)</span></strong><span class="kobospan" id="kobo.747.1">: Retrieves a specific text and its corresponding label at the </span><span><span class="kobospan" id="kobo.748.1">given index.</span></span></li></ul></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.749.1">Loading data from a text file</span></strong><span class="kobospan" id="kobo.750.1">: The </span><strong class="source-inline1"><span class="kobospan" id="kobo.751.1">get_data_from_txt(path)</span></strong><span class="kobospan" id="kobo.752.1"> function is used to load text data and labels from a text file. </span><span class="kobospan" id="kobo.752.2">Each line in the file contains a label</span><a id="_idIndexMarker1027" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.753.1"> followed by a text. </span><span class="kobospan" id="kobo.753.2">This function reads the file, extracts the labels and texts, and returns them </span><span><span class="kobospan" id="kobo.754.1">as lists.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.755.1">Forward step</span></strong><span class="kobospan" id="kobo.756.1">: The </span><strong class="source-inline1"><span class="kobospan" id="kobo.757.1">forward_step(correct_texts, wrong_texts, tokenizer, model, mismatch_loss, mismatch_weight)</span></strong><span class="kobospan" id="kobo.758.1"> function performs a forward step during training. </span><span class="kobospan" id="kobo.758.2">It takes a list of correct and incorrect texts, a tokenizer, the model, and parameters for mismatch loss and mismatch weight. </span><span class="kobospan" id="kobo.758.3">It tokenizes the texts, calculates the language modeling loss, and applies mismatch loss if specified. </span><span class="kobospan" id="kobo.758.4">The result is a </span><span><span class="kobospan" id="kobo.759.1">loss tensor.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.760.1">Training function</span></strong><span class="kobospan" id="kobo.761.1">: The </span><strong class="source-inline1"><span class="kobospan" id="kobo.762.1">train_llm(args_model_out, return_results, train_data, train_loader)</span></strong><span class="kobospan" id="kobo.763.1"> function trains the language model. </span><span class="kobospan" id="kobo.763.2">It initializes the GPT-2 model, tokenizer, optimizer, and privacy engine. </span><span class="kobospan" id="kobo.763.3">A privacy budget (epsilon) value of </span><strong class="source-inline1"><span class="kobospan" id="kobo.764.1">0.5</span></strong><span class="kobospan" id="kobo.765.1"> is used in this example, but it can be changed to the desired privacy budget. </span><span class="kobospan" id="kobo.765.2">It then iterates over training epochs, processing data in batches and calculating losses. </span><span class="kobospan" id="kobo.765.3">The model is saved at the end of </span><span><span class="kobospan" id="kobo.766.1">each epoch.</span></span></li>
<li class="calibre11"><strong class="bold"><span class="kobospan" id="kobo.767.1">Running the training</span></strong><span class="kobospan" id="kobo.768.1">: At the end of the code, a sample dataset is loaded from a text file, and the training process is initiated using the </span><strong class="source-inline1"><span class="kobospan" id="kobo.769.1">train_llm()</span></strong><span class="kobospan" id="kobo.770.1"> function. </span><span class="kobospan" id="kobo.770.2">The function takes parameters such as the output path for saving the model, whether to return results, the training data, and the </span><span><span class="kobospan" id="kobo.771.1">data loader.</span></span></li>
</ol>
<p class="calibre3"><span class="kobospan" id="kobo.772.1">All the preceding </span><a id="_idIndexMarker1028" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.773.1">six steps are implemented in the following </span><span><span class="kobospan" id="kobo.774.1">code snippet:</span></span></p>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.775.1">Source </span></em><span><em class="italic"><span class="kobospan" id="kobo.776.1">code: Privacy_Transformer.ipynb</span></em></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.777.1">
!pip install transformers
!pip install git+</span><a href="https://github.com/lxuechen/private-transformers.git" class="pcalibre pcalibre1 calibre19"><span class="kobospan1" id="kobo.778.1">https://github.com/lxuechen/private-transformers.git</span></a><span class="kobospan1" id="kobo.779.1">
!pip install tqdm
from tqdm import tqdm
import transformers
import torch
from transformers import GPT2Tokenizer, GPT2LMHeadModel
from private_transformers import PrivacyEngine
class Dataset(torch.utils.data.Dataset):
    def __init__(self, texts, labels, eos_token):
       self.texts = texts
       self.y = labels
       self.eos_token = eos_token
    def __len__(self):
        return len(self.texts)
    def __getitem__(self, index):
        text = self.texts[index] + ' ' + self.eos_token
        label = self.y[index]
        return text, label
def get_data_from_txt(path: str):
    texts = []
    labels = []
    with open(path, 'r') as f:
        for line in f:
            texts.append(' '.join(line.split(' ')[1:]).replace('\n', ''))
            labels.append(int(line.split(' ')[0]))
    return texts, labels
def forward_step(texts,tokenizer, model):
    tokenized_texts = tokenizer(texts, truncation=True, max_length=500, return_tensors='pt', padding=True).input_ids.to('cpu')
    lm_loss = model(tokenized_texts, labels=tokenized_texts).loss.unsqueeze(dim=0)
    return lm_loss
def train_llm(train_data, train_loader, ):
    model = GPT2LMHeadModel.from_pretrained("gpt2")
    #model.parallelize()
    model.train()
    tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
    tokenizer.pad_token = tokenizer.eos_token
    optimizer = torch.optim.Adam(model.parameters(),lr = 8e-6)
    args_epochs=2
    print(args_epochs)
    epsilon=0.5
    privacy_engine = PrivacyEngine(
            model,
            batch_size=1,
            sample_size=10,
            epochs=args_epochs,
            max_grad_norm=0.1,
            target_epsilon=epsilon,
        )
    privacy_engine.attach(optimizer)
    for epoch in range(args_epochs):
        total_loss = 0
        for texts, labels in tqdm(train_loader):
            lm_loss = forward_step(texts,tokenizer, model)
            optimizer.step(loss=lm_loss)
            total_loss += lm_loss.item()
    return model
train_texts, train_labels = get_data_from_txt('imdb_train.txt')
train_texts = train_texts[0:100]
train_labels =train_labels[0:100]
train_data = Dataset(train_texts, train_labels, '&lt;|endoftext|&gt;')
train_loader = torch.utils.data.DataLoader(train_data, shuffle=False, batch_size=1)
pmodel = train_llm(train_data,train_loader)
print(pmodel)
Output of this program as follows:
2
0.5
training epoch 0</span></pre>
<div class="calibre2">
<div class="img---figure" id="_idContainer126">
<span class="kobospan" id="kobo.780.1"><img alt="Figure 10.6 Training Loss and Model Parameters" src="image/B16573_10_06.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.781.1">Figure 10.6 Training Loss and Model Parameters</span></p>
<h2 id="_idParaDest-226" class="calibre7"><a id="_idTextAnchor235" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.782.1">STOA – Privacy-preserving technologies for LLMs</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.783.1">The following </span><a id="_idIndexMarker1029" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.784.1">section provides high-level SOTA research </span><a id="_idIndexMarker1030" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.785.1">work on privacy-preserving technologies for LLMs. </span><span class="kobospan" id="kobo.785.2">This is not an exhaustive list but details current trends in </span><span><span class="kobospan" id="kobo.786.1">the research.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.787.1">Prompts – Privacy: “Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models” </span><em class="italic"><span class="kobospan" id="kobo.788.1">Research article</span></em><span class="kobospan" id="kobo.789.1">: </span><a href="https://arxiv.org/pdf/2305.15594.pdf" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.790.1">https://arxiv.org/pdf/2305.15594.pdf</span></a></h3>
<p class="calibre3"><span class="kobospan" id="kobo.791.1">Large Language Models (LLMs) are adept at understanding contextual information; however, concerns</span><a id="_idIndexMarker1031" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.792.1"> arise regarding the privacy implications associated with the data contained within prompts. </span><span class="kobospan" id="kobo.792.2">This study validates these concerns by demonstrating a simple yet highly effective membership inference attack on the data used for LLM prompts. </span><span class="kobospan" id="kobo.792.3">To address this vulnerability, one option is to move away from prompting and instead focus on fine-tuning LLMs using established algorithms for private gradient descent. </span><span class="kobospan" id="kobo.792.4">However, this approach sacrifices the practicality and efficiency provided by the prompting method. </span><span class="kobospan" id="kobo.792.5">Therefore, the authors propose a new solution: private prompt learning. </span><span class="kobospan" id="kobo.792.6">They first show the feasibility of obtaining soft prompts privately through gradient descent on downstream data. </span><span class="kobospan" id="kobo.792.7">However, the challenge lies in handling discrete prompts. </span><span class="kobospan" id="kobo.792.8">To overcome this, a process is devised where an ensemble of LLMs is engaged with various prompts, similar to a group of diverse parrots. </span><span class="kobospan" id="kobo.792.9">A noisy vote among these LLMs privately transfers the collective knowledge of the ensemble into a single public prompt. </span><span class="kobospan" id="kobo.792.10">Their results demonstrate that LLMs prompted using their private algorithms closely approach the performance of their non-private counterparts. </span><span class="kobospan" id="kobo.792.11">For example, when using GPT-3 as the base model, they achieve a downstream accuracy of 92.7% on the sst2 dataset with (ε = 0.147, δ = 10-6)-differential privacy, compared to 95.2% for the </span><span><span class="kobospan" id="kobo.793.1">non-private baseline.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.794.1">Prompts – Privacy: LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers</span></h3>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.795.1">Research </span></em><span><em class="italic"><span class="kobospan" id="kobo.796.1">article</span></em></span><span><span class="kobospan" id="kobo.797.1">: </span></span><a href="https://arxiv.org/abs/2305.18396" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.798.1">https://arxiv.org/abs/2305.18396</span></span></a></p>
<p class="calibre3"><span class="kobospan" id="kobo.799.1">In this study, scholars</span><a id="_idIndexMarker1032" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.800.1"> illustrated that replacing computationally and communication-intensive functions within the transformer framework with privacy-computing-compatible approximations markedly reduced the expenses linked to private inference, with only slight impacts on model effectiveness. </span><span class="kobospan" id="kobo.800.2">Contrasting with the state-of-the-art Iron framework (</span><em class="italic"><span class="kobospan" id="kobo.801.1">NeurIPS 2022</span></em><span class="kobospan" id="kobo.802.1">), their model inference process tailored for privacy-computing demonstrated a fivefold increase in computational speed and an 80% decrease in communication overhead, while preserving almost identical </span><span><span class="kobospan" id="kobo.803.1">accuracy levels.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.804.1">Differentially private attention computation</span></h3>
<h3 class="calibre9"><em class="italic"><span class="kobospan" id="kobo.805.1">Research article</span></em><span class="kobospan" id="kobo.806.1">: </span><a href="https://arxiv.org/abs/2305.04701" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.807.1">https://arxiv.org/abs/2305.04701</span></a></h3>
<p class="calibre3"><span class="kobospan" id="kobo.808.1">The </span><a id="_idIndexMarker1033" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.809.1">attention mechanism plays a crucial role in LLMs, enabling them to selectively focus on various segments of input text. </span><span class="kobospan" id="kobo.809.2">Computing the attention matrix is a well-recognized and substantial task in the LLM computation process. </span><span class="kobospan" id="kobo.809.3">Consequently, determining how to offer verifiable privacy guarantees for the computation of the attention matrix is a significant research avenue. </span><span class="kobospan" id="kobo.809.4">One natural mathematical concept for quantifying privacy, as found in theoretical computer science graduate textbooks, is </span><span><span class="kobospan" id="kobo.810.1">differential privacy.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.811.1">In this study, inspired by the work of Vyas, Kakade, and Barak (2023), researchers present a provable outcome that demonstrates how to differentially privately approximate the attention matrix. </span><span class="kobospan" id="kobo.811.2">From a technical perspective, the results draw upon pioneering research in the realm of differential privacy as established by Alabi, Kothari, Tankala, Venkat, and </span><span><span class="kobospan" id="kobo.812.1">Zhang (2022).</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.813.1">Differentially private decoding in LLMs</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.814.1">Research </span><span><span class="kobospan" id="kobo.815.1">article: </span></span><a href="https://arxiv.org/abs/2205.13621" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.816.1">https://arxiv.org/abs/2205.13621</span></span></a></p>
<p class="calibre3"><span class="kobospan" id="kobo.817.1">Researchers</span><a id="_idIndexMarker1034" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.818.1"> presented a straightforward, easily interpretable, and computationally efficient perturbation technique designed for implementation during the decoding phase of a pre-trained model. </span><span class="kobospan" id="kobo.818.2">This perturbation mechanism is model-agnostic and compatible with any LLM. </span><span class="kobospan" id="kobo.818.3">Their work includes a theoretical analysis demonstrating the differential privacy properties of the proposed mechanism, along with experimental results illustrating the trade-off between privacy </span><span><span class="kobospan" id="kobo.819.1">and utility.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.820.1">Differentially private model compression</span></h3>
<p class="calibre3"><em class="italic"><span class="kobospan" id="kobo.821.1">Research </span></em><span><em class="italic"><span class="kobospan" id="kobo.822.1">article</span></em></span><span><span class="kobospan" id="kobo.823.1">: </span></span><a href="https://arxiv.org/abs/2206.01838" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.824.1">https://arxiv.org/abs/2206.01838</span></span></a></p>
<p class="calibre3"><span class="kobospan" id="kobo.825.1">Large</span><a id="_idIndexMarker1035" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.826.1"> pre-trained LLMs have demonstrated the ability to undergo fine-tuning on private data, achieving performance levels comparable to non-private models across numerous downstream NLP) tasks while ensuring differential privacy. </span><span class="kobospan" id="kobo.826.2">However, these models, comprising hundreds of millions of parameters, often incur prohibitively high inference costs. </span><span class="kobospan" id="kobo.826.3">Therefore, in practical applications, LLMs are frequently subjected to compression before deployment. </span><span class="kobospan" id="kobo.826.4">Researchers embark on the exploration of differentially private model compression and propose frameworks capable of achieving 50% sparsity levels while retaining </span><a id="_idIndexMarker1036" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.827.1">nearly full performance. </span><span class="kobospan" id="kobo.827.2">Their study includes practical demonstrations of standard </span><strong class="bold"><span class="kobospan" id="kobo.828.1">General Language Understanding Evaluation</span></strong><span class="kobospan" id="kobo.829.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.830.1">GLUE</span></strong><span class="kobospan" id="kobo.831.1">) benchmarks using BERT models, thus establishing benchmarks for future research in </span><span><span class="kobospan" id="kobo.832.1">this field.</span></span></p>
<h1 id="_idParaDest-227" class="calibre5"><a id="_idTextAnchor236" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.833.1">Summary</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.834.1">In conclusion, this chapter has provided an in-depth exploration into the world of Language Models (LLMs) and the critical considerations surrounding their use, particularly focusing on privacy and security aspects. </span><span class="kobospan" id="kobo.834.2">We have covered key concepts such as prompt engineering and compared open-source versus closed-source LLMs. </span><span class="kobospan" id="kobo.834.3">Additionally, we delved into AI standards and terminology of attacks, highlighting NIST’s guidelines and the OWASP Top 10 </span><span><span class="kobospan" id="kobo.835.1">LLMs vulnerabilities.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.836.1">Furthermore, we discussed various privacy attacks on LLMs, including real-world incidents of privacy leaks, membership inference attacks, and prompt injection attacks. </span><span class="kobospan" id="kobo.836.2">These examples underscore the importance of robust privacy-preserving technologies in LLMs. </span><span class="kobospan" id="kobo.836.3">We examined techniques like training LLMs using Differential Privacy with Private Transformer to mitigate privacy risks while maintaining </span><span><span class="kobospan" id="kobo.837.1">model performance.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.838.1">Overall, this chapter aims to empower readers with the knowledge and tools necessary to navigate the complexities of LLMs while safeguarding user privacy and ensuring responsible AI deployment. </span><span class="kobospan" id="kobo.838.2">As the field continues to evolve, it becomes increasingly crucial to stay informed and proactive in addressing privacy concerns in LLMs. </span><span class="kobospan" id="kobo.838.3">By understanding the nuances of prompt engineering, AI standards, privacy attacks, and privacy-preserving technologies, stakeholders can make informed decisions to promote trustworthy and responsible use of LLMs in </span><span><span class="kobospan" id="kobo.839.1">various applications.</span></span></p>
</div>
</body></html>