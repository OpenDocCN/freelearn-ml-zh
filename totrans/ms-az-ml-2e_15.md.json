["```py\nfrom azureml.train.hyperdrive import HyperDriveConfig\nhyperdrive_run_config = HyperDriveConfig(\n    estimator=estimator,\n    hyperparameter_sampling=param_sampling, \n    primary_metric_name=\"accuracy\", \n    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n    max_total_runs=100,\n    max_concurrent_runs=4)\nfrom azureml.core.experiment import Experiment\nexperiment = Experiment(workspace, experiment_name)\nhyperdrive_run = experiment.submit(hyperdrive_run_config)\n```", "```py\n-- explicitly use 3 reducers\n-- set mapred.reduce.tasks=3;\ncreate table xgb_softmax_model as\nselect \n  train_xgboost(features, label, \n    '-objective multi:softmax -num_class 10 -num_round 10') \n    as (model_id, model)\nfrom (\n  select features, (label - 1) as label\n  from data_train\n  cluster by rand(43) -- shuffle data to reducers\n) data;\n```", "```py\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n    .appName(\"Distributed Training\") \\\n    .master(\"local\") \\\n    .getOrCreate()\n# read the input data\ndf = spark.read.parquet(\"data/\")\n# define your training function\nfrom sklearn.ensemble import RandomForestClassifier\ndef train_model(data):\n    clf = RandomForestClassifier(n_estimators=10)\n    return clf.fit(data['train_x'], data['train_y'])\n# split your data into partitions and train models\nnum_models = 100\nmodels = df.rdd.repartition(num_models) \\\n  .mapPartitions(train_model) \\\n  .collect()\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nclass ParallelModel(nn.Module):\n    def __init__(self):\n        super(ParallelModel, self).__init__()\n        self.net1 = torch.nn.Linear(10, 10).to('cuda:0')\n        self.relu = torch.nn.ReLU()\n        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')\n    def forward(self, x):\n        x = self.relu(self.net1(x.to('cuda:0')))\n        return self.net2(x.to('cuda:1'))\n```", "```py\nmodel = ParallelModel()\nloss_fn = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\noptimizer.zero_grad()\noutputs = model(torch.randn(20, 10))\nlabels = torch.randn(20, 5).to('cuda:1')\nloss_fn(outputs, labels).backward()\noptimizer.step()\n```", "```py\n    import horovod.keras as hvd\n    hvd.init()\n    ```", "```py\n    from tensorflow.keras import backend as K\n    import tensorflow as tf\n    # pin GPU to be used to process local rank.\n    # one GPU per process\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.visible_device_list = str(hvd.local_rank())\n    K.set_session(tf.Session(config=config))\n    ```", "```py\n    # standard model and data\n    batch_size = 10\n    epochs = 100\n    model = load_model(...)\n    x_train, y_train = load_train_data(...)\n    x_test, y_test = load_test_data(...)\n    ```", "```py\n    from tensorflow.keras.optimizers import Adadelta\n    # adjust learning rate based on number of GPUs\n    opt = Adadelta(1.0 * hvd.size())\n    # add Horovod Distributed Optimizer\n    opt = hvd.DistributedOptimizer(opt)\n    ```", "```py\n    model.compile(loss=keras.losses.categorical_crossentropy,\n                  optimizer=opt, \n                  metrics=['accuracy'])\n    callbacks = [\n      hvd.callbacks.BroadcastGlobalVariablesCallback(0)\n    ]\n    model.fit(x_train,\n              y_train,\n              batch_size=batch_size,\n              callbacks=callbacks,\n              epochs=epochs,\n              verbose=1 if hvd.rank() == 0 else 0,\n              validation_data=(x_test, y_test))\n    score = model.evaluate(x_test, y_test)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n    ```", "```py\n    horovodrun -np 8 -H server1:4,server2:4 python train.py\n    ```", "```py\nhr = HorovodRunner(np=2)\ndef train():\n    # Perform your training here..\n    import horovod.keras as hvd\n    hvd.init()\n    ...\nhr.run(train)\n```", "```py\nfrom azureml.core import ScriptRunConfig\nfrom azureml.core.runconfig import MpiConfiguration\nrun_config = get_run_config(aml_cluster, [\n    'numpy', 'pandas', 'scikit-learn', 'joblib',\n    'tensorflow', 'horovod'])\ndistr_config = MpiConfiguration(process_count_per_node=1,\n                                node_count=2)\nsrc = ScriptRunConfig(source_directory=script_folder,\n                      script='train.py',\n                      run_config=run_config,\n                      arguments=script_params\n                      distributed_job_config=distr_config)\n```", "```py\nrun = experiment.submit(src)\n```"]