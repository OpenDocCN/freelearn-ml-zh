<html><head></head><body>
<div id="_idContainer036">
<h1 class="chapter-number" id="_idParaDest-66"><a id="_idTextAnchor065"/><span class="koboSpan" id="kobo.1.1">4</span></h1>
<h1 id="_idParaDest-67"><a id="_idTextAnchor066"/><span class="koboSpan" id="kobo.2.1">Describe Core Machine Learning Concepts</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In the previous chapters, you were introduced to some basic </span><strong class="bold"><span class="koboSpan" id="kobo.4.1">machine learning</span></strong><span class="koboSpan" id="kobo.5.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.6.1">ML</span></strong><span class="koboSpan" id="kobo.7.1">) concepts, including various models and scenarios where a particular type of model might be useful. </span><span class="koboSpan" id="kobo.7.2">In this chapter, we’re going to explore concepts surrounding the actual data used </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">in ML.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">The objectives and skills we’ll cover in this chapter include </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.11.1">Identify features and labels in a dataset for </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">machine learning</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Describe how training and validation datasets are used in </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">machine learning</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.15.1">By the end of this chapter, you should be able to clearly articulate the terminology </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">surrounding ML.</span></span></p>
<h1 id="_idParaDest-68"><a id="_idTextAnchor067"/><span class="koboSpan" id="kobo.17.1">Identify features and labels in a dataset for machine learning</span></h1>
<p><span class="koboSpan" id="kobo.18.1">As you learned in </span><a href="B22207_03.xhtml#_idTextAnchor042"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.19.1">Chapter 3</span></em></span></a><span class="koboSpan" id="kobo.20.1">, </span><em class="italic"><span class="koboSpan" id="kobo.21.1">Identify Common Machine Learning Techniques</span></em><span class="koboSpan" id="kobo.22.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.23.1">features</span></strong><span class="koboSpan" id="kobo.24.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.25.1">labels</span></strong><span class="koboSpan" id="kobo.26.1"> are two fundamental concepts that define the data you work with when training </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">ML models.</span></span></p>
<p><span class="koboSpan" id="kobo.28.1">Features are </span><a id="_idIndexMarker240"/><span class="koboSpan" id="kobo.29.1">individual measurable</span><a id="_idIndexMarker241"/><span class="koboSpan" id="kobo.30.1"> properties or characteristics of whatever is being observed. </span><span class="koboSpan" id="kobo.30.2">In ML models, features are used as input variables. </span><span class="koboSpan" id="kobo.30.3">These are the data points that you use to make predictions. </span><span class="koboSpan" id="kobo.30.4">For example, if you’re trying to predict the price of a house, the features might include the number of bedrooms, the size of the house in square feet, the neighborhood it’s in, how close it is to a fire station, or what the local property tax rates are. </span><span class="koboSpan" id="kobo.30.5">Features are represented by independent variables in your dataset that you believe will help you make accurate predictions about your </span><span class="No-Break"><span class="koboSpan" id="kobo.31.1">target variable.</span></span></p>
<p><span class="koboSpan" id="kobo.32.1">Labels, on the</span><a id="_idIndexMarker242"/><span class="koboSpan" id="kobo.33.1"> other hand, are the output you’re trying to predict </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">or classify.</span></span></p>
<p><span class="koboSpan" id="kobo.35.1">In </span><strong class="bold"><span class="koboSpan" id="kobo.36.1">supervised learning</span></strong><span class="koboSpan" id="kobo.37.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.38.1">SL</span></strong><span class="koboSpan" id="kobo.39.1">), each training </span><a id="_idIndexMarker243"/><span class="koboSpan" id="kobo.40.1">example includes a label. </span><span class="koboSpan" id="kobo.40.2">Continuing with the house pricing example, the label would be the actual selling price of </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">the house.</span></span></p>
<p><span class="koboSpan" id="kobo.42.1">In classification tasks, labels are the categories assigned to data points. </span><span class="koboSpan" id="kobo.42.2">For instance, in an ML model trained to identify whether an email is spam or not, the labels might be “</span><strong class="source-inline"><span class="koboSpan" id="kobo.43.1">spam</span></strong><span class="koboSpan" id="kobo.44.1">” and “</span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.45.1">not spam</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.46.1">.”</span></span></p>
<p><span class="koboSpan" id="kobo.47.1">In this section, we’ll dive a little </span><a id="_idIndexMarker244"/><span class="koboSpan" id="kobo.48.1">deeper into working with features and labels in </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">your datasets.</span></span></p>
<h2 id="_idParaDest-69"><a id="_idTextAnchor068"/><span class="koboSpan" id="kobo.50.1">Identifying features in a dataset</span></h2>
<p><span class="koboSpan" id="kobo.51.1">Identifying features in an ML dataset involves </span><a id="_idIndexMarker245"/><span class="koboSpan" id="kobo.52.1">understanding variables that can be used to predict the outcome (target variable). </span><span class="koboSpan" id="kobo.52.2">There are many things you can do to narrow down what’s important for your </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">ML model.</span></span></p>
<p><span class="koboSpan" id="kobo.54.1"> Let’s go through them in </span><span class="No-Break"><span class="koboSpan" id="kobo.55.1">this section.</span></span></p>
<h3><span class="koboSpan" id="kobo.56.1">Understanding the problem domain</span></h3>
<p><span class="koboSpan" id="kobo.57.1">Begin by understanding the domain or </span><a id="_idIndexMarker246"/><span class="koboSpan" id="kobo.58.1">context of the problem. </span><span class="koboSpan" id="kobo.58.2">This involves researching the subject area to understand what factors might influence the outcome. </span><span class="koboSpan" id="kobo.58.3">For example, if you are working on a project to predict house prices, potential features could include the size of the house, the number of bedrooms, the number of bathrooms, the year it was built, the location, distance to fire stations, number of public libraries in the area, and statistics on the local </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">school system.</span></span></p>
<p><span class="koboSpan" id="kobo.60.1">When working through this step, it would likely be helpful to speak with domain experts to understand important variables. </span><span class="koboSpan" id="kobo.60.2">You could also look for existing literature, research, or studies to identify common predictors or variables used in </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">similar problems.</span></span></p>
<h3><span class="koboSpan" id="kobo.62.1">Collecting data</span></h3>
<p><span class="koboSpan" id="kobo.63.1">Gather your data from </span><a id="_idIndexMarker247"/><span class="koboSpan" id="kobo.64.1">relevant sources. </span><span class="koboSpan" id="kobo.64.2">This could include databases, reports, files, external APIs connected to industry data sources, or direct measurements. </span><span class="koboSpan" id="kobo.64.3">The data you collect will consist of various attributes or variables. </span><span class="koboSpan" id="kobo.64.4">You should work to ensure that the data collected is relevant to the problem domain and includes variables identified in your research of the </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">subject matter.</span></span></p>
<p><span class="koboSpan" id="kobo.66.1">For example, if you’re working on a model that’s going to predict housing prices, you’d likely look at data sources such as recent sale prices of houses in a particular zip code. </span><span class="koboSpan" id="kobo.66.2">Since you’d identified other features such as school system ratings and the distances to fire stations and libraries, you’d </span><a id="_idIndexMarker248"/><span class="koboSpan" id="kobo.67.1">need to get that data as well—which would likely be from different data sources. </span><span class="koboSpan" id="kobo.67.2">You’d need to plot the distance from each house to the nearest library and fire station and add the dataset that you’ll be training a </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1">model with.</span></span></p>
<h3><span class="koboSpan" id="kobo.69.1">Exploring the data</span></h3>
<p><span class="koboSpan" id="kobo.70.1">Perform </span><strong class="bold"><span class="koboSpan" id="kobo.71.1">exploratory data analysis</span></strong><span class="koboSpan" id="kobo.72.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.73.1">EDA</span></strong><span class="koboSpan" id="kobo.74.1">) to get a</span><a id="_idIndexMarker249"/><span class="koboSpan" id="kobo.75.1"> feel for the data. </span><span class="koboSpan" id="kobo.75.2">This can include summarizing the statistics of the </span><a id="_idIndexMarker250"/><span class="koboSpan" id="kobo.76.1">data, visualizing distributions and relationships between variables, and identifying any patterns or anomalies. </span><span class="koboSpan" id="kobo.76.2">Tools such as histograms, scatter plots, and correlation matrices can be useful here. </span><span class="koboSpan" id="kobo.76.3">You should also use statistical summaries (such as mean, median, mode, and standard deviation) to understand the distribution of each variable and identify areas where you </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">have outliers.</span></span></p>
<p><span class="koboSpan" id="kobo.78.1">Here’s an example of a </span><span class="No-Break"><span class="koboSpan" id="kobo.79.1">scatter plot:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer033">
<span class="koboSpan" id="kobo.80.1"><img alt="Figure 4.1 – Scatter plot showing the relationship between housing price and square footage" src="image/B22207_04_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.81.1">Figure 4.1 – Scatter plot showing the relationship between housing price and square footage</span></p>
<h3><span class="koboSpan" id="kobo.82.1">Selecting relevant variables</span></h3>
<p><span class="koboSpan" id="kobo.83.1">Not all variables in your dataset</span><a id="_idIndexMarker251"/><span class="koboSpan" id="kobo.84.1"> may be relevant or necessary for predicting the outcome. </span><span class="koboSpan" id="kobo.84.2">Select variables that are likely to influence the target variable based on your domain knowledge and initial data exploration. </span><span class="koboSpan" id="kobo.84.3">Variables that show a correlation with the target variable are often good candidates </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">for features.</span></span></p>
<p><span class="koboSpan" id="kobo.86.1">When identifying variables, it’s important to consider the practical significance of variables in addition to their statistical significance. </span><span class="koboSpan" id="kobo.86.2">For example, going back to the housing example, you may have learned that a house’s proximity to a library may not have a very big impact. </span><span class="koboSpan" id="kobo.86.3">During the EDA, you also may discover other variables that may seem important, such as proximity to a shopping center or the number of closets and </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">storage areas.</span></span></p>
<p><span class="koboSpan" id="kobo.88.1">After reviewing your preliminary data, you may discover that you have missing attributes or values or that some data may be irrelevant to the problem context. </span><span class="koboSpan" id="kobo.88.2">Consider discarding that data since it may reduce the effectiveness of your model. </span><span class="koboSpan" id="kobo.88.3">Continue iterating until you settle in on </span><span class="No-Break"><span class="koboSpan" id="kobo.89.1">relevant features.</span></span></p>
<h3><span class="koboSpan" id="kobo.90.1">Feature engineering</span></h3>
<p><span class="koboSpan" id="kobo.91.1">This involves creating new features from existing ones through various techniques such as binning, aggregation, and combination of attributes. </span><span class="koboSpan" id="kobo.91.2">For example, from a dataset containing dates, you might extract </span><a id="_idIndexMarker252"/><span class="koboSpan" id="kobo.92.1">features such as the day of the week, the month, or the year. </span><span class="koboSpan" id="kobo.92.2">Or, you may decide to collapse or combine multiple date ranges into </span><span class="No-Break"><span class="koboSpan" id="kobo.93.1">fewer features.</span></span></p>
<p><span class="koboSpan" id="kobo.94.1">In the house pricing example, you may decide to aggregate data by month or week instead of having individual house prices by day. </span><span class="koboSpan" id="kobo.94.2">This may reduce some noise and help focus on trends </span><span class="No-Break"><span class="koboSpan" id="kobo.95.1">more easily.</span></span></p>
<p><span class="koboSpan" id="kobo.96.1">Advanced techniques, such as polynomial features, can help capture non-linear relationships. </span><span class="koboSpan" id="kobo.96.2">In a house, a non-linear example might be the relationship between the number of bathrooms and closets. </span><span class="koboSpan" id="kobo.96.3">One method of creating a polynomial feature would be by multiplying two unrelated features together. </span><span class="koboSpan" id="kobo.96.4">In this example, you could multiply the number of bathrooms and closets: a house that has 3 bathrooms and 7 closets could have a new feature with a value </span><span class="No-Break"><span class="koboSpan" id="kobo.97.1">of 21.</span></span></p>
<p><span class="koboSpan" id="kobo.98.1">Feature engineering can also involve transforming variables, such as scaling or normalizing, to make them more suitable for ML models. </span><span class="koboSpan" id="kobo.98.2">For example, you may decide to round housing prices to the nearest $25,000 or group houses by the number of bedrooms, such as 0-2, 3-4, 5-6, and 7+. </span><span class="koboSpan" id="kobo.98.3">Each of these techniques can be used to help streamline the data and help produce a clearer set </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">of predictions.</span></span></p>
<h3><span class="koboSpan" id="kobo.100.1">Handling missing values</span></h3>
<p><span class="koboSpan" id="kobo.101.1">Decide how to handle missing data in</span><a id="_idIndexMarker253"/><span class="koboSpan" id="kobo.102.1"> your potential features. </span><span class="koboSpan" id="kobo.102.2">You might fill in missing values with the mean or median (imputation), discard them, or use a model to predict and fill them. </span><span class="koboSpan" id="kobo.102.3">Be sure to consider the reasons for missing data to determine if it’s random </span><span class="No-Break"><span class="koboSpan" id="kobo.103.1">or not.</span></span></p>
<h3><span class="koboSpan" id="kobo.104.1">Removing irrelevant or redundant features</span></h3>
<p><span class="koboSpan" id="kobo.105.1">Eliminate features that are irrelevant to the </span><a id="_idIndexMarker254"/><span class="koboSpan" id="kobo.106.1">outcome or that duplicate information contained in other features. </span><span class="koboSpan" id="kobo.106.2">Redundant or irrelevant features can introduce noise and lead to overfitting. </span><span class="koboSpan" id="kobo.106.3">As you develop the model, you may discover that you need to remove features to help refine the model to produce </span><span class="No-Break"><span class="koboSpan" id="kobo.107.1">better results.</span></span></p>
<h3><span class="koboSpan" id="kobo.108.1">Consulting with experts</span></h3>
<p><span class="koboSpan" id="kobo.109.1">If possible, consult with domain experts to</span><a id="_idIndexMarker255"/><span class="koboSpan" id="kobo.110.1"> validate your selection of features and data sources. </span><span class="koboSpan" id="kobo.110.2">They might provide insights into which variables are most influential or suggest additional variables that you hadn’t considered, as well as indicate any known biases for your data </span><span class="No-Break"><span class="koboSpan" id="kobo.111.1">source selections.</span></span></p>
<h3><span class="koboSpan" id="kobo.112.1">Using feature selection techniques</span></h3>
<p><span class="koboSpan" id="kobo.113.1">There are automated feature selection techniques such as </span><strong class="bold"><span class="koboSpan" id="kobo.114.1">forward selection</span></strong><span class="koboSpan" id="kobo.115.1">, </span><strong class="bold"><span class="koboSpan" id="kobo.116.1">backward elimination</span></strong><span class="koboSpan" id="kobo.117.1">, and </span><strong class="bold"><span class="koboSpan" id="kobo.118.1">recursive feature elimination</span></strong><span class="koboSpan" id="kobo.119.1"> that can help identify the most important features based on statistical tests or </span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">model performance:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.121.1">Forward selection</span></strong><span class="koboSpan" id="kobo.122.1">: Forward selection is</span><a id="_idIndexMarker256"/><span class="koboSpan" id="kobo.123.1"> a feature selection technique used to build a model by iteratively adding one feature at a time, starting with the most significant or </span><a id="_idIndexMarker257"/><span class="koboSpan" id="kobo.124.1">promising feature. </span><span class="koboSpan" id="kobo.124.2">The process continues until a stopping criterion is met, such as reaching a predetermined number of features or until the addition of new features no longer improves the model’s performance significantly. </span><span class="koboSpan" id="kobo.124.3">For example, with our house pricing example, this might mean starting with overall square footage as the most promising feature that has an impact on the price of a house, and then in the next iteration, add the number </span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">of bedrooms.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.126.1">Backward elimination</span></strong><span class="koboSpan" id="kobo.127.1">: This is simply the opposite process of forward selection. </span><span class="koboSpan" id="kobo.127.2">Instead of adding features</span><a id="_idIndexMarker258"/><span class="koboSpan" id="kobo.128.1"> until the model doesn’t change, you start with all of the features to train a model and take out features until the stopping criterion is met—such as the number of features remaining or until the removal of features no longer improves </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">the model.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.130.1">Recursive feature elimination</span></strong><span class="koboSpan" id="kobo.131.1">: Similar to</span><a id="_idIndexMarker259"/><span class="koboSpan" id="kobo.132.1"> backward elimination, recursive feature elimination is a process that starts with a full set of features and then removes them. </span><span class="koboSpan" id="kobo.132.2">Whereas </span><a id="_idIndexMarker260"/><span class="koboSpan" id="kobo.133.1">backward elimination simply removes the least significant features, recursive feature elimination removes features based on their importance and interaction with </span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">other features.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.135.1">You’ll want to temper any automated feature selection tools with domain knowledge, expert insight, and data understanding to ensure you’re choosing the most appropriate set </span><span class="No-Break"><span class="koboSpan" id="kobo.136.1">of features.</span></span></p>
<p><span class="koboSpan" id="kobo.137.1">Remember—model development is </span><a id="_idIndexMarker261"/><span class="koboSpan" id="kobo.138.1">an iterative process. </span><span class="koboSpan" id="kobo.138.2">As you build and develop your models, you might discover that some features are more important than others or that some can be removed without decreasing model performance (in regard </span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">to accuracy).</span></span></p>
<h2 id="_idParaDest-70"><a id="_idTextAnchor069"/><span class="koboSpan" id="kobo.140.1">Identifying labels in a dataset</span></h2>
<p><span class="koboSpan" id="kobo.141.1">Identifying labels in an ML dataset</span><a id="_idIndexMarker262"/><span class="koboSpan" id="kobo.142.1"> involves understanding the outcome or target variable that your model aims to predict. </span><span class="koboSpan" id="kobo.142.2">Here’s how you can identify labels in </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">a dataset.</span></span></p>
<h3><span class="koboSpan" id="kobo.144.1">Defining the objective</span></h3>
<p><span class="koboSpan" id="kobo.145.1">Start by clearly defining the objective </span><a id="_idIndexMarker263"/><span class="koboSpan" id="kobo.146.1">of your ML project. </span><span class="koboSpan" id="kobo.146.2">Are you trying to predict a continuous value (regression), classify data into categories (classification), or identify groups of similar instances (clustering)? </span><span class="koboSpan" id="kobo.146.3">Your objective will guide what your label </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">should be.</span></span></p>
<p><span class="koboSpan" id="kobo.148.1">Understanding </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">the data</span></span></p>
<p><span class="koboSpan" id="kobo.150.1">Examine your dataset and understand </span><a id="_idIndexMarker264"/><span class="koboSpan" id="kobo.151.1">each variable. </span><span class="koboSpan" id="kobo.151.2">In SL, the label is the variable that is being predicted, which could be the outcome of an event, the classification category, or the future value of </span><span class="No-Break"><span class="koboSpan" id="kobo.152.1">a series.</span></span></p>
<h3><span class="koboSpan" id="kobo.153.1">Identifying the target variable</span></h3>
<p><span class="koboSpan" id="kobo.154.1">In most datasets used for SL, there is</span><a id="_idIndexMarker265"/><span class="koboSpan" id="kobo.155.1"> usually a specific column that serves as the target variable (label). </span><span class="koboSpan" id="kobo.155.2">This could be a column indicating “Yes” or “No” for a binary classification problem, a numerical value for a regression problem, or category labels for a multiclass </span><span class="No-Break"><span class="koboSpan" id="kobo.156.1">classification problem.</span></span></p>
<h3><span class="koboSpan" id="kobo.157.1">Consulting domain experts</span></h3>
<p><span class="koboSpan" id="kobo.158.1">If it’s not clear which variable should be</span><a id="_idIndexMarker266"/><span class="koboSpan" id="kobo.159.1"> used as the label, consult with domain experts or stakeholders of your ML project. </span><span class="koboSpan" id="kobo.159.2">They can provide insights into what predictions would be most valuable based on the dataset, business outcomes, and </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">research objectives.</span></span></p>
<h3><span class="koboSpan" id="kobo.161.1">Exploring the data</span></h3>
<p><span class="koboSpan" id="kobo.162.1">Use EDA to better understand</span><a id="_idIndexMarker267"/><span class="koboSpan" id="kobo.163.1"> potential labels. </span><span class="koboSpan" id="kobo.163.2">For instance, if you’re working with a dataset where the objective is to predict whether an email is spam or not, the label could be a column indicating “spam” or “not spam.” </span><span class="koboSpan" id="kobo.163.3">Look for a column or other output with categorical or binary data that fits the problem you are trying </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">to solve.</span></span></p>
<h3><span class="koboSpan" id="kobo.165.1">Checking data documentation</span></h3>
<p><span class="koboSpan" id="kobo.166.1">If your dataset comes with </span><a id="_idIndexMarker268"/><span class="koboSpan" id="kobo.167.1">documentation or a </span><strong class="bold"><span class="koboSpan" id="kobo.168.1">data dictionary</span></strong><span class="koboSpan" id="kobo.169.1">, review this material to understand the role of each</span><a id="_idIndexMarker269"/><span class="koboSpan" id="kobo.170.1"> variable. </span><span class="koboSpan" id="kobo.170.2">Often, the documentation will explicitly state which column is the target variable (label) for prediction. </span><span class="koboSpan" id="kobo.170.3">If the documentation doesn’t identify the label, it may provide insights about existing fields or column names to help you determine </span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">a label.</span></span></p>
<p><span class="koboSpan" id="kobo.172.1">Look for pre-labeled data; in some cases, especially in SL tasks, datasets are already labeled. </span><span class="koboSpan" id="kobo.172.2">This means that for each record, there is an accompanying label that has been previously determined. </span><span class="koboSpan" id="kobo.172.3">This is common in datasets used for training models, where the goal is to learn the relationship between input features </span><span class="No-Break"><span class="koboSpan" id="kobo.173.1">and labels.</span></span></p>
<h3><span class="koboSpan" id="kobo.174.1">Considering the problem type</span></h3>
<p><span class="koboSpan" id="kobo.175.1">The nature of your label depends on the type of problem you are trying to use ML </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">to solve.</span></span></p>
<p><span class="koboSpan" id="kobo.177.1">For classification, labels are categorical</span><a id="_idIndexMarker270"/><span class="koboSpan" id="kobo.178.1"> and represent different classes (for example, “spam” or “not spam” for binary classification dealing with whether an email is junk mail or not; “cat,” “dog,” and “bird” for multiclass classification identifying animals </span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">from pictures).</span></span></p>
<p><span class="koboSpan" id="kobo.180.1">For regression, labels are continuous values (such as house prices </span><span class="No-Break"><span class="koboSpan" id="kobo.181.1">or temperatures).</span></span></p>
<p><span class="koboSpan" id="kobo.182.1">For clustering (an </span><strong class="bold"><span class="koboSpan" id="kobo.183.1">unsupervised learning</span></strong><span class="koboSpan" id="kobo.184.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.185.1">UL</span></strong><span class="koboSpan" id="kobo.186.1">) task), labels are not provided, and the goal is to discover them</span><a id="_idIndexMarker271"/><span class="koboSpan" id="kobo.187.1"> through the grouping of similar </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">data points.</span></span></p>
<h3><span class="koboSpan" id="kobo.189.1">Cleaning the data</span></h3>
<p><span class="koboSpan" id="kobo.190.1">Ensure your label data is clean</span><a id="_idIndexMarker272"/><span class="koboSpan" id="kobo.191.1"> and consistent. </span><span class="koboSpan" id="kobo.191.2">This might involve correcting mislabeling, handling missing values, and ensuring labels are in a format that can be used for modeling (for example, converting strings to </span><span class="No-Break"><span class="koboSpan" id="kobo.192.1">numerical categories).</span></span></p>
<p><span class="koboSpan" id="kobo.193.1">As you develop your model, you may need to revisit and re-evaluate your choice of labels (just as you may need to revisit your choice of features). </span><span class="koboSpan" id="kobo.193.2">The effectiveness of your model in predicting these labels will help you understand if you have identified the correct labels or if adjustments </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">are needed.</span></span></p>
<h1 id="_idParaDest-71"><a id="_idTextAnchor070"/><span class="koboSpan" id="kobo.195.1">Describe how training and validation datasets are used in machine learning</span></h1>
<p><span class="koboSpan" id="kobo.196.1">In ML, </span><strong class="bold"><span class="koboSpan" id="kobo.197.1">training</span></strong><span class="koboSpan" id="kobo.198.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.199.1">validation</span></strong><span class="koboSpan" id="kobo.200.1"> sets are subsets of your overall dataset used during the model development phase. </span><span class="koboSpan" id="kobo.200.2">Their roles are</span><a id="_idIndexMarker273"/><span class="koboSpan" id="kobo.201.1"> distinct but complementary, aimed at creating a model that is able to make accurate predictions about new, </span><span class="No-Break"><span class="koboSpan" id="kobo.202.1">unseen </span></span><span class="No-Break"><a id="_idIndexMarker274"/></span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">data.</span></span></p>
<p><span class="koboSpan" id="kobo.204.1">You may recall seeing the concepts of training and validation sets in </span><a href="B22207_03.xhtml#_idTextAnchor042"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.205.1">Chapter 3</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.206.1">, Identify Common Machine Learning Techniques</span></em><span class="koboSpan" id="kobo.207.1"> when we discussed dividing the dataset into sections—a subset that would be used to train the model, and a “held back” or “reserved” part of the data that we could use to test the predictions. </span><span class="koboSpan" id="kobo.207.2">These are the training and validation </span><span class="No-Break"><span class="koboSpan" id="kobo.208.1">sets, respectively.</span></span></p>
<h2 id="_idParaDest-72"><a id="_idTextAnchor071"/><span class="koboSpan" id="kobo.209.1">Training set</span></h2>
<p><span class="koboSpan" id="kobo.210.1">This is the data on which the ML model is trained. </span><span class="koboSpan" id="kobo.210.2">The model learns to make predictions or decisions based on this data. </span><span class="koboSpan" id="kobo.210.3">The training set is used to fit the parameters of the model, such as the </span><a id="_idIndexMarker275"/><span class="koboSpan" id="kobo.211.1">weights in a </span><strong class="bold"><span class="koboSpan" id="kobo.212.1">neural network</span></strong><span class="koboSpan" id="kobo.213.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.214.1">NN</span></strong><span class="koboSpan" id="kobo.215.1">) or the coefficients in </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">linear regression.</span></span></p>
<p><span class="koboSpan" id="kobo.217.1">The training set in ML is the actual dataset used to train the model. </span><span class="koboSpan" id="kobo.217.2">Training involves adjusting the model’s parameters to minimize errors, typically through a process known as learning. </span><span class="koboSpan" id="kobo.217.3">The size and </span><a id="_idIndexMarker276"/><span class="koboSpan" id="kobo.218.1">quality of the training set can significantly influence the performance of the ML model. </span><span class="koboSpan" id="kobo.218.2">A larger training set provides more examples from which the model can learn, potentially leading to better generalization when the model is used to make predictions on new data. </span><span class="koboSpan" id="kobo.218.3">However, the data must also be representative of the real-world scenario the model will be applied to, encompassing a broad range of examples </span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">and variations.</span></span></p>
<p><span class="koboSpan" id="kobo.220.1">During the training phase, the model iteratively adjusts its parameters to reduce the difference between the predicted output and the actual output, as defined by a specific mathematical loss function. </span><span class="koboSpan" id="kobo.220.2">This process can vary depending on the type of model and learning algorithm. </span><span class="koboSpan" id="kobo.220.3">For instance, in SL, each example in the training set includes both the input features and the corresponding target label. </span><span class="koboSpan" id="kobo.220.4">The model uses these pairs to learn underlying patterns in the data. </span><span class="koboSpan" id="kobo.220.5">In UL, where there are no labels, the model tries to learn the underlying structure of the data based on the input </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">features alone.</span></span></p>
<p><span class="koboSpan" id="kobo.222.1">The effectiveness of the training process (in both SL and UL) is largely dependent on the quality of the training data, the volume of data in the training set, the relevance of the features selected, and the suitability of the model for the problem at hand. </span><span class="koboSpan" id="kobo.222.2">If possible, training on actual data (as opposed to synthetic data) is preferred, as it helps the model learn about natural outliers and variances. </span><span class="koboSpan" id="kobo.222.3">Sometimes, however, due to privacy or other responsible </span><strong class="bold"><span class="koboSpan" id="kobo.223.1">artificial intelligence</span></strong><span class="koboSpan" id="kobo.224.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.225.1">AI</span></strong><span class="koboSpan" id="kobo.226.1">) development </span><a id="_idIndexMarker277"/><span class="koboSpan" id="kobo.227.1">principles, actual data may not </span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">be available.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.229.1">Generating your own training data</span></p>
<p class="callout"><span class="koboSpan" id="kobo.230.1">You may also want to consider asking a </span><strong class="bold"><span class="koboSpan" id="kobo.231.1">generative AI</span></strong><span class="koboSpan" id="kobo.232.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.233.1">GenAI</span></strong><span class="koboSpan" id="kobo.234.1">) model to create training data for you. </span><span class="koboSpan" id="kobo.234.2">This may be</span><a id="_idIndexMarker278"/><span class="koboSpan" id="kobo.235.1"> useful in helping you understand relationships between features or protecting privacy if a potential dataset contains personal information. </span><span class="koboSpan" id="kobo.235.2">However, training data generated by an AI model can also amplify any bias in the data that was used to train the generative model, leading to skewed or unrealistic training data. </span><span class="koboSpan" id="kobo.235.3">In either case, when using GenAI, you’ll need to take precautions to ensure that the data is representative of what you’re trying </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">to achieve.</span></span></p>
<p><span class="koboSpan" id="kobo.237.1">Typically, the training set constitutes a larger portion of the entire dataset, often ranging from 60% to 80%. </span><span class="koboSpan" id="kobo.237.2">The aim is to</span><a id="_idIndexMarker279"/><span class="koboSpan" id="kobo.238.1"> provide the model with a diverse and comprehensive set of examples that mirror the real-world scenarios in which it will </span><span class="No-Break"><span class="koboSpan" id="kobo.239.1">be applied.</span></span></p>
<p><span class="koboSpan" id="kobo.240.1">If you’re asking yourself, “How do I know if the model is trained well enough?” </span><span class="koboSpan" id="kobo.240.2">or “How will I know when I’m done training?” </span><span class="koboSpan" id="kobo.240.3">that’s where validation sets </span><span class="No-Break"><span class="koboSpan" id="kobo.241.1">come in.</span></span></p>
<h2 id="_idParaDest-73"><a id="_idTextAnchor072"/><span class="koboSpan" id="kobo.242.1">Validation set</span></h2>
<p><span class="koboSpan" id="kobo.243.1">This subset of the dataset is used to provide an unbiased evaluation of a model fit on the training dataset while tuning the</span><a id="_idIndexMarker280"/><span class="koboSpan" id="kobo.244.1"> model’s </span><strong class="bold"><span class="koboSpan" id="kobo.245.1">hyperparameters</span></strong><span class="koboSpan" id="kobo.246.1"> (settings or configurations that are not learned from the data) that the model is unable to adjust automatically. </span><span class="koboSpan" id="kobo.246.2">The validation</span><a id="_idIndexMarker281"/><span class="koboSpan" id="kobo.247.1"> set acts as a proxy for the test set since it is not used for training the model and hence can help in estimating how well the model has generalized to unseen data. </span><span class="koboSpan" id="kobo.247.2">Typically, the validation set might be about 20% to 30% of the </span><span class="No-Break"><span class="koboSpan" id="kobo.248.1">entire dataset.</span></span></p>
<p><span class="koboSpan" id="kobo.249.1">It is crucial to</span><a id="_idIndexMarker282"/><span class="koboSpan" id="kobo.250.1"> avoid </span><strong class="bold"><span class="koboSpan" id="kobo.251.1">overfitting</span></strong><span class="koboSpan" id="kobo.252.1"> (sometimes referred to as </span><strong class="bold"><span class="koboSpan" id="kobo.253.1">overtraining</span></strong><span class="koboSpan" id="kobo.254.1">), a situation where the model performs well on the training data but poorly </span><a id="_idIndexMarker283"/><span class="koboSpan" id="kobo.255.1">on new, </span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">unseen data.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.257.1">What’s a hyperparameter?</span></p>
<p class="callout"><span class="koboSpan" id="kobo.258.1">An ML model</span><a id="_idIndexMarker284"/><span class="koboSpan" id="kobo.259.1"> hyperparameter is a configuration setting that is external to the model and influences its learning process. </span><span class="koboSpan" id="kobo.259.2">Unlike model parameters, which are learned from the training data, hyperparameters are predefined by the user and affect aspects such as model complexity, regularization, and optimization. </span><span class="koboSpan" id="kobo.259.3">Examples include the learning rate in gradient descent, the depth of a decision tree, or the number of hidden layers in an NN. </span><span class="koboSpan" id="kobo.259.4">Hyperparameter tuning is crucial for optimizing model performance. </span><span class="koboSpan" id="kobo.259.5">Don’t worry, though—from the perspective of the </span><em class="italic"><span class="koboSpan" id="kobo.260.1">AI-900</span></em><span class="koboSpan" id="kobo.261.1"> exam, the important concept is that hyperparameters are external to </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">the model.</span></span></p>
<p><span class="koboSpan" id="kobo.263.1">Using a validation set helps detect issues</span><a id="_idIndexMarker285"/><span class="koboSpan" id="kobo.264.1"> such as </span><strong class="bold"><span class="koboSpan" id="kobo.265.1">overfitting</span></strong><span class="koboSpan" id="kobo.266.1">. </span><span class="koboSpan" id="kobo.266.2">Overfitting happens when a model learns noise or random fluctuations in the training data instead of actual underlying patterns. </span><span class="koboSpan" id="kobo.266.3">By evaluating the model on the validation set, you can identify when overfitting is occurring and take steps to mitigate it, such as simplifying the model, applying regularization techniques, or obtaining more </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">training data.</span></span></p>
<p><span class="koboSpan" id="kobo.268.1">Additionally, the validation set allows for the comparison of different models and configurations in a controlled manner. </span><span class="koboSpan" id="kobo.268.2">After the model has been trained on the training set, its performance on the validation set provides an unbiased evaluation. </span><span class="koboSpan" id="kobo.268.3">Only after the model has been optimized and selected based on its performance on the validation set should it be tested on the test set to assess its generalization capabilities to new, unseen data. </span><span class="koboSpan" id="kobo.268.4">This approach ensures that the final evaluation of the model is based on data that has not been used during the training or validation phases, providing a more accurate measure of its predictive performance and </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">generalization ability.</span></span></p>
<p><span class="koboSpan" id="kobo.270.1">The process usually involves</span><a id="_idIndexMarker286"/><span class="koboSpan" id="kobo.271.1"> training the model on the training set and then evaluating its performance on the validation set. </span><span class="koboSpan" id="kobo.271.2">Based on this evaluation, adjustments can be made to the model’s configuration. </span><span class="koboSpan" id="kobo.271.3">Once the model performs satisfactorily on the validation set, it can then be tested on a separate test set to further evaluate its performance in a completely unseen data scenario. </span><span class="koboSpan" id="kobo.271.4">This practice helps ensure that the model is not just memorizing the training data but actually learning patterns that </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">are generalizable.</span></span></p>
<h1 id="_idParaDest-74"><a id="_idTextAnchor073"/><span class="koboSpan" id="kobo.273.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.274.1">This chapter expanded on concepts relating to data in regard to ML. </span><span class="koboSpan" id="kobo.274.2">You learned about techniques for identifying features and labels in datasets as well as techniques for ensuring data is suitable for learning. </span><span class="koboSpan" id="kobo.274.3">You learned about the concepts and purposes of both the training set and validation set </span><span class="No-Break"><span class="koboSpan" id="kobo.275.1">as well.</span></span></p>
<p><span class="koboSpan" id="kobo.276.1">In the next chapter, we’ll dive a little deeper into Azure Machine Learning concepts </span><span class="No-Break"><span class="koboSpan" id="kobo.277.1">and capabilities.</span></span></p>
<h1 id="_idParaDest-75"><a id="_idTextAnchor074"/><span class="koboSpan" id="kobo.278.1">Exam Readiness Drill – Chapter Review Questions</span></h1>
<p><span class="koboSpan" id="kobo.279.1">Apart from a solid understanding of key concepts, being able to think quickly under time pressure is a skill that will help you ace your certification exam. </span><span class="koboSpan" id="kobo.279.2">That is why working on these skills early on in your learning journey </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">is key.</span></span></p>
<p><span class="koboSpan" id="kobo.281.1">Chapter review questions are designed to improve your test-taking skills progressively with each chapter you learn and review your understanding of key concepts in the chapter at the same time. </span><span class="koboSpan" id="kobo.281.2">You’ll find these at the end of </span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">each chapter.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.283.1">Before you proceed</span></p>
<p class="callout"><span class="koboSpan" id="kobo.284.1">If you don't have a Packt Library subscription or you haven't purchased this book from the Packt store, you will need to unlock the online resources to access the exam readiness drills. </span><span class="koboSpan" id="kobo.284.2">Unlocking is free and needs to be done only once. </span><span class="koboSpan" id="kobo.284.3">To learn how to do that, head over to the chapter titled </span><a href="B22207_12.xhtml#_idTextAnchor228"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.285.1">Chapter 12</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.286.1">, Accessing the </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.287.1">Online Resources</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.288.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.289.1">To open the Chapter Review Questions for this chapter, perform the </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">following steps:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.291.1">Click the link – </span><a href="https://packt.link/AI-900_CH04"><span class="No-Break"><span class="koboSpan" id="kobo.292.1">https://packt.link/AI-900_CH04</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.293.1">.</span></span><p class="list-inset"><span class="koboSpan" id="kobo.294.1">Alternatively, you can scan the following QR code (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.295.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.296.1">.2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">):</span></span></p></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer034">
<span class="koboSpan" id="kobo.298.1"><img alt="Figure 4.2 – QR code that opens Chapter Review Questions for logged-in users" src="image/B22207_04_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.299.1">Figure 4.2 – QR code that opens Chapter Review Questions for logged-in users</span></p>
<ol>
<li value="2"><span class="koboSpan" id="kobo.300.1">Once you log in, you’ll see a page similar to the one shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.301.1">Figure 4</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.302.1">.3</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.303.1">:</span></span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer035">
<span class="koboSpan" id="kobo.304.1"><img alt="Figure 4.3 – Chapter Review Questions for Chapter 4" src="image/B22207_04_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.305.1">Figure 4.3 – Chapter Review Questions for Chapter 4</span></p>
<ol>
<li value="3"><span class="koboSpan" id="kobo.306.1">Once ready, start the following practice drills, re-attempting the quiz </span><span class="No-Break"><span class="koboSpan" id="kobo.307.1">multiple times.</span></span></li>
</ol>
<h2 id="_idParaDest-76"><a id="_idTextAnchor075"/><span class="koboSpan" id="kobo.308.1">Exam Readiness Drill</span></h2>
<p><span class="koboSpan" id="kobo.309.1">For the first three attempts, don’t worry about the </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">time limit.</span></span></p>
<h3><span class="koboSpan" id="kobo.311.1">ATTEMPT 1</span></h3>
<p><span class="koboSpan" id="kobo.312.1">The first time, aim for at least </span><strong class="bold"><span class="koboSpan" id="kobo.313.1">40%</span></strong><span class="koboSpan" id="kobo.314.1">. </span><span class="koboSpan" id="kobo.314.2">Look at the answers you got wrong and read the relevant sections in the chapter again to fix your </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">learning gaps.</span></span></p>
<h3><span class="koboSpan" id="kobo.316.1">ATTEMPT 2</span></h3>
<p><span class="koboSpan" id="kobo.317.1">The second time, aim for at least </span><strong class="bold"><span class="koboSpan" id="kobo.318.1">60%</span></strong><span class="koboSpan" id="kobo.319.1">. </span><span class="koboSpan" id="kobo.319.2">Look at the answers you got wrong and read the relevant sections in the chapter again to fix any remaining </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">learning gaps.</span></span></p>
<h3><span class="koboSpan" id="kobo.321.1">ATTEMPT 3</span></h3>
<p><span class="koboSpan" id="kobo.322.1">The third time, aim for at least </span><strong class="bold"><span class="koboSpan" id="kobo.323.1">75%</span></strong><span class="koboSpan" id="kobo.324.1">. </span><span class="koboSpan" id="kobo.324.2">Once you score 75% or more, you start working on </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">your timing.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.326.1">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.327.1">You may take more than </span><strong class="bold"><span class="koboSpan" id="kobo.328.1">three</span></strong><span class="koboSpan" id="kobo.329.1"> attempts to reach 75%. </span><span class="koboSpan" id="kobo.329.2">That’s okay. </span><span class="koboSpan" id="kobo.329.3">Just review the relevant sections in the chapter till you </span><span class="No-Break"><span class="koboSpan" id="kobo.330.1">get there.</span></span></p>
<h2 id="_idParaDest-77"><a id="_idTextAnchor076"/><span class="koboSpan" id="kobo.331.1">Working On Timing</span></h2>
<p><span class="koboSpan" id="kobo.332.1">Your aim is to keep the score the same while trying to answer these questions as quickly as possible. </span><span class="koboSpan" id="kobo.332.2">Here’s an example of how your next attempts should </span><span class="No-Break"><span class="koboSpan" id="kobo.333.1">look like:</span></span></p>
<table class="No-Table-Style _idGenTablePara-1" id="table001-3">
<colgroup>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.334.1">Attempt</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.335.1">Score</span></strong></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.336.1">Time Taken</span></strong></span></p>
</td>
</tr>
</thead>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.337.1">Attempt 5</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.338.1">77%</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.339.1">21 mins </span><span class="No-Break"><span class="koboSpan" id="kobo.340.1">30 seconds</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.341.1">Attempt 6</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.342.1">78%</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.343.1">18 mins </span><span class="No-Break"><span class="koboSpan" id="kobo.344.1">34 seconds</span></span></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.345.1">Attempt 7</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="No-Break"><span class="koboSpan" id="kobo.346.1">76%</span></span></p>
</td>
<td class="No-Table-Style">
<p><span class="koboSpan" id="kobo.347.1">14 mins </span><span class="No-Break"><span class="koboSpan" id="kobo.348.1">44 seconds</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.349.1">Table 4.1 – Sample timing practice drills on the online platform</span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.350.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.351.1">The time limits shown in the above table are just examples. </span><span class="koboSpan" id="kobo.351.2">Set your own time limits with each attempt based on the time limit of the quiz on </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">the website.</span></span></p>
<p><span class="koboSpan" id="kobo.353.1">With each new attempt, your score should stay above </span><strong class="bold"><span class="koboSpan" id="kobo.354.1">75%</span></strong><span class="koboSpan" id="kobo.355.1"> while your “time taken” to complete should “decrease”. </span><span class="koboSpan" id="kobo.355.2">Repeat as many attempts as you want till you feel confident dealing with the </span><span class="No-Break"><span class="koboSpan" id="kobo.356.1">time pressure.</span></span></p>
</div>
</body></html>