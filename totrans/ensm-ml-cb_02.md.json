["```py\nTotal Error = Bias ^ 2 + Variance + Irreducible Error\n```", "```py\n# import required packages\nimport os\nimport pandas as pd\n\n# Set working directory as per your need\nos.chdir(\".../.../Chapter 2\")\nos.getcwd()\n```", "```py\ndf_cryotherapydata = pd.read_csv(\"Cryotherapy.csv\")\n```", "```py\ndf_cryotherapydata.head(5)\n```", "```py\n# Import required libraries\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\n```", "```py\n# We create train & test sample from our dataset\nfrom sklearn.cross_validation import train_test_split\n\n# create feature & response sets\nfeature_columns = ['sex', 'age', 'Time', 'Number_of_Warts', 'Type', 'Area']\nX = df_cryotherapydata[feature_columns]\nY = df_cryotherapydata['Result_of_Treatment']\n\n# Create train & test sets\nX_train, X_test, Y_train, Y_test = \\\ntrain_test_split(X, Y, test_size=0.20, random_state=1)\n```", "```py\n# create the sub models\nestimators = []\n\ndt_model = DecisionTreeClassifier(random_state=1)\nestimators.append(('DecisionTree', dt_model))\n\nsvm_model = SVC(random_state=1)\nestimators.append(('SupportVector', svm_model))\n\nlogit_model = LogisticRegression(random_state=1)\nestimators.append(('Logistic Regression', logit_model))\n```", "```py\nfrom sklearn.metrics import accuracy_score\n\nfor each_estimator in (dt_model, svm_model, logit_model):\n    each_estimator.fit(X_train, Y_train)\n    Y_pred = each_estimator.predict(X_test)\n    print(each_estimator.__class__.__name__, accuracy_score(Y_test, Y_pred))\n```", "```py\n#Using VotingClassifier() to build ensemble model with Hard Voting\nensemble_model = VotingClassifier(estimators=estimators, voting='hard')\n\nensemble_model.fit(X_train,Y_train)\npredicted_labels = ensemble_model.predict(X_test) \n\nprint(\"Classifier Accuracy using Hard Voting: \", accuracy_score(Y_test, predicted_labels))\n```", "```py\n# create the sub models\nestimators = []\n\ndt_model = DecisionTreeClassifier(random_state=1)\nestimators.append(('DecisionTree', dt_model))\n\nsvm_model = SVC(random_state=1, probability=True)\nestimators.append(('SupportVector', svm_model))\n\nlogit_model = LogisticRegression(random_state=1)\nestimators.append(('Logistic Regression', logit_model))\n\nfor each_estimator in (dt_model, svm_model, logit_model):\n    each_estimator.fit(X_train, Y_train)\n    Y_pred = each_estimator.predict(X_test)\n    print(each_estimator.__class__.__name__, accuracy_score(Y_test, Y_pred))\n\n# Using VotingClassifier() to build ensemble model with Soft Voting\nensemble_model = VotingClassifier(estimators=estimators, voting='soft')\nensemble_model.fit(X_train,Y_train)\npredicted_labels = ensemble_model.predict(X_test) \nprint(\"Classifier Accuracy using Soft Voting: \", accuracy_score(Y_test, predicted_labels))\n```", "```py\ndf_winedata = pd.read_csv(\"whitewines.csv\")\n```", "```py\ndf_winedata.head(5)\n```", "```py\n# Import required libraries\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\n```", "```py\n# Create feature and response variable set\nfrom sklearn.cross_validation import train_test_split\n\n# create feature & response variables\nfeature_columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar','chlorides', 'free sulfur dioxide', 'total sulfur dioxide','density', 'pH', 'sulphates', 'alcohol']\nX = df_winedata[feature_columns]\nY = df_winedata['quality']\n```", "```py\n# Create train & test sets\nX_train, X_test, Y_train, Y_test = \\\ntrain_test_split(X, Y, test_size=0.20, random_state=1)\n```", "```py\n# Build base learners\nlinreg_model = LinearRegression()\nsvr_model = SVR()\nregressiontree_model = DecisionTreeRegressor()\n\n# Fitting the model\nlinreg_model.fit(X_train, Y_train)\nsvr_model.fit(X_train, Y_train)\nregressiontree_model.fit(X_train, Y_train)\n```", "```py\nlinreg_predictions = linreg_model.predict(X_test)\nsvr_predictions = svr_model.predict(X_test)\nregtree_predictions = regressiontree_model.predict(X_test)\n```", "```py\n# We divide the summation of the predictions by 3 i.e. number of base learners \naverage_predictions=(linreg_predictions + svr_predictions + regtree_predictions)/3\n```", "```py\ndf_cancerdata = pd.read_csv(\"wisc_bc_data.csv\")\n```", "```py\ndf_cancerdata.head(5)\n```", "```py\n# Import required libraries\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n```", "```py\n# Create feature and response variable set\n# We create train & test sample from our dataset\nfrom sklearn.cross_validation import train_test_split\n\n# create feature & response variables\nX = df_cancerdata.iloc[:,2:32]\nY = df_cancerdata['diagnosis']\n```", "```py\n# Create train & test sets\nX_train, X_test, Y_train, Y_test = \\\ntrain_test_split(X, Y, test_size=0.20, random_state=1)\n```", "```py\n# create the sub models\nestimators = []\n\ndt_model = DecisionTreeClassifier()\nestimators.append(('DecisionTree', dt_model))\n\nsvm_model = SVC(probability=True)\nestimators.append(('SupportVector', svm_model))\n\nlogit_model = LogisticRegression()\nestimators.append(('Logistic Regression', logit_model))\n```", "```py\ndt_model.fit(X_train, Y_train)\nsvm_model.fit(X_train, Y_train)\nlogit_model.fit(X_train, Y_train)\n```", "```py\ndt_predictions = dt_model.predict_proba(X_test)\nsvm_predictions = svm_model.predict_proba(X_test)\nlogit_predictions = logit_model.predict_proba(X_test)\n```", "```py\nweighted_average_predictions=(dt_predictions * 0.3 + svm_predictions * 0.4 + logit_predictions * 0.3)\n```"]