<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis">
<head>
  <meta charset="UTF-8"/>
  <title>Object Detection in Images using Deep Neural Networks</title>
  <link type="text/css" rel="stylesheet" media="all" href="style.css"/>
  <link type="text/css" rel="stylesheet" media="all" href="core.css"/>
</head>
<body>
  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Object Detection in Images using Deep Neural Networks</h1>
            </header>

            <article>
                
<p>We used basic neural networks in <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks</em> with Neural Networks. Research in neural networks is creating some of the most advanced and accurate classification algorithms in many areas. The differences between the concepts introduced in this chapter, versus those introduced in <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks</em> is around&#160;<em>complexity</em>. In this chapter, we look at deep neural networks, those with many hidden layers, and also at more complex layer types for dealing with specific types of information, such as images.</p>
<p>These advances have come on the back of improvements in computational power, allowing us to train larger and more complex networks. However, the advances are much more than simply throwing more computational power at the problem. New algorithms and layer types have drastically improved performance, outside computational power. The cost is that these new classifiers need more data to learn from than other data mining classifiers.</p>
<p>In this chapter, we will look at determining what object is represented in an image. The pixel values will be used as input, and the neural network will then automatically find useful combinations of pixels to form higher-level features. These will then be used for the actual classification.</p>
<p>Overall, in this chapter, we will examine the following:</p>
<ul>
<li>Classifying objects in images</li>
<li>Different types of deep neural networks</li>
<li><span>The TensorFlow and Keras</span><span>&#160;libraries to build and train neural networks</span></li>
<li><span>Using a GPU to improve the speed of the algorithms</span></li>
<li>Using cloud-based services for added horse-power for data mining</li>
</ul>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Object classification</h1>
            </header>

            <article>
                
<p>Computer vision is becoming an important part of future technology. For example, we will have access to self-driving cars in the very near future - car manufacturers are scheduled to be releasing self-driving models in 2017 and are already partially self-driving. In order to achieve this, the car's computer needs to be able to see around it; identify obstacles, other traffic, and weather conditions; and then use that to plan a safe journey.</p>
<p>While we can easily detect whether there is an obstacle, for example using radar, it is also important we know what that object is. If it is an animal on the road, we can stop and let it move out of the way; if it is a building, this strategy won't work very well!</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Use cases</h1>
            </header>

            <article>
                
<p>Computer vision is used in many scenarios. Following are some examples where they applications is very important.</p>
<ul>
<li>Online map websites, such as Google Maps, use computer vision for a number of reasons. One reason is to automatically blur any faces that they find, in order to give some privacy to the people being photographed as part of their Street View feature.</li>
<li>Face detection is also used in many industries. Modern cameras automatically detect faces, as a means to improve the quality of photos taken (the user most often wants to focus on a visible face). Face detection can also be used for identification. For example, Facebook automatically recognises people in photos, allowing for easy tagging of friends.</li>
<li>As we stated before, autonomous vehicles are highly dependent on computer vision to recognise their path and avoid obstacles. Computer vision is one of the key problems that is being addressed not only in research into autonomous vehicles, not just for consumer use, but also in mining and other industries.</li>
<li>Other industries are using computer vision too, including warehouses examining goods automatically for defects.</li>
<li>The space industry is also using computer vision, helping to automate the collection of data. This is critical for effective use of spacecraft, as sending a signal from Earth to a rover on Mars can take a long time and is not possible at certain times (for instance, when the two planets are not facing each other). As we start dealing with space-based vehicles more frequently, and from a greater distance, increasing the autonomy of these spacecraft is absolutely necessary and computer vision is a key part of this.The following picture shows the Mars rover designed and used by NASA; it made significant use of computer vision to identify its surroundings on a strange, inhospitable planet.</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="401" width="501" class=" image-border" src="images/B06162_11_03.jpg"/></div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Application scenario</h1>
            </header>

            <article>
                
<p>In this chapter, we will build a system that will take an image as an input and give a prediction on what the object in it is. We will take on the role of a vision system for a car, looking around at any obstacles in the way or on the side of the road. Images are of the following form:</p>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="images/B06162_11_01.png"/></div>
<p>This dataset comes from a popular dataset called CIFAR-10. It contains 60,000 images that are 32 pixels wide and 32 pixels high, with each pixel having a red-green-blue (RGB) value. The dataset is already split into training and testing, although we will not use the testing dataset until after we complete our training.</p>
<div class="packt_tip">The CIFAR-10 dataset is available for download at&#160;<a href="http://www.cs.toronto.edu/~kriz/cifar.html">http://www.cs.toronto.edu/~kriz/cifar.html</a><br/>
Download the python version, which has already been converted to NumPy arrays.</div>
<p>Opening a new Jupyter Notebook, we can see what the data looks like. First, we set up the data filenames. We will only worry about the first batch to start with, and scale up to the full dataset size towards the end;</p>
<pre>import os<br/>data_folder = os.path.join(os.path.expanduser("~"), "Data", "cifar-10-batches-py") <br/>batch1_filename = os.path.join(data_folder, "data_batch_1")
</pre>
<p>Next, we create a function that can read the data stored in the batches. The batches have been saved using pickle, which is a python library to save objects. Usually, we can just call <kbd>pickle.load(file)</kbd> on the file to get the object. However, there is a small issue with this data: it was saved in Python 2, but we need to open it in Python 3. In order to address this, we set the encoding to <kbd>latin</kbd> (even though we are opening it in byte mode):</p>
<pre>import pickle<br/># Bugfix thanks to: http://stackoverflow.com/questions/11305790/pickle-incompatability-of-numpy-arrays-between-python-2-and-3 <br/>def unpickle(filename): <br/>    with open(filename, 'rb') as fo: <br/>        return pickle.load(fo, encoding='latin1')
</pre>
<p>Using this function, we can now load the batch dataset:</p>
<pre>batch1 = unpickle(batch1_filename)
</pre>
<p>This batch is a dictionary containing the actual data in NumPy arrays, the corresponding labels and filenames, and a note to say which batch it is (this is training batch 1 of 5, for instance).</p>
<p>We can extract an image by using its index in the batch's data key:</p>
<pre>image_index = 100 <br/>image = batch1['data'][image_index]
</pre>
<p>The image array is a NumPy array with 3,072 entries, from 0 to 255. Each value is the red, green, or blue intensity at a specific location in the image.</p>
<p>The images are in a different format than what matplotlib usually uses (to display images), so to show the image we first need to reshape the array and rotate the matrix. This doesn't matter so much to train our neural network (we will define our network in a way that fits with the data), but we do need to convert it for <span class="packt_screen">matplotlib's</span> sake:</p>
<pre>image = image.reshape((32,32, 3), order='F') <br/>import numpy as np <br/>image = np.rot90(image, -1)
</pre>
<p>Now we can show the image using matplotlib:</p>
<pre>%matplotlib inline<br/><br/>from matplotlib import pyplot as plt <br/>plt.imshow(image)
</pre>
<p>The resulting image, a boat, is displayed:</p>
<div class="CDPAlignCenter CDPAlign"><img height="217" width="215" class=" image-border" src="images/B06162_11_02.png"/></div>
<p>The resolution of this image is quite poor—it is only 32 pixels wide and 32 pixels high. Despite that, most people will look at the image and see a boat. Can we get a computer to do the same?</p>
<p>You can change the image index to show different images, getting a feel for the dataset's properties.</p>
<p>The aim of our project, in this chapter, is to build a classification system that can take an image like this and predict what the object in it is. Before we do that though, we will take a detour to learn about the classifier we are going to use: <strong>Deep neural networks</strong>.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Deep neural networks</h1>
            </header>

            <article>
                
<p>The neural networks we used in <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks</em>, have some fantastic <em>theoretical</em> properties. For example, only a single hidden layer is needed to learn any mapping (although the size of the middle layer may need to be very, very big). Neural networks were a very active area of research in the 1970s and 1980s due to this theoretical perfection. However several issues caused them to fall out of favor, particularly compared to other classification algorithms such as support vector machines. A few of the major ones are listed here:</p>
<ul>
<li>One of the main issues was that the computational power needed to run many neural networks was more than other algorithms and more than what many people had access to.</li>
<li>Another issue was training the networks. While the back propagation algorithm has been known about for some time, it has issues with larger networks, requiring a very large amount of training before the weights settle.</li>
</ul>
<div class="packt_infobox">Each of these issues has been addressed in recent times, leading to a resurgence in popularity of neural networks. Computational power is now much more easily available than 30 years ago, and advances in algorithms for training mean that we can now readily use that power.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Intuition</h1>
            </header>

            <article>
                
<p>The aspect that differentiates <strong>deep neural networks</strong> from the more basic neural network we saw in <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks</em>, is size.</p>
<div class="packt_infobox">A neural network is considered deep when it has two or more hidden layers. In practice, a deep neural network is often much larger, both in the number of nodes in each layer and also the number of layers. While some of the research of the mid -2000s focused on very large numbers of layers, smarter algorithms are reducing the actual number of layers needed.</div>
<p>The size is one differentiator, but new layer types and neural network structures are assisting in creating deep neural networks for specific areas. We have already seen a feed-forward neural network composed of <strong>dense layers</strong>. This means we have a series of layers, in order, where each neuron from one layer is attached to each neuron from another layer. Other types include:</p>
<ul>
<li><strong>Convolutional Neural Networks</strong> (<strong>CNN</strong>) for image analysis. In this case, a small segment of the image is taken as a single input, and that input is passed onto a pooling layer to combine these outputs. This helps with issues such as rotation and translation of images. We will use these networks in this chapter.</li>
<li><strong>Recurrent Neural Networks</strong> (<strong>RNN</strong>) for text and time-series analysis. In this case, the previous state of the neural network is remembered&#160;and used to alter the current output. Think of the preceding word in a sentence modifying the output for the current word in the phrase: <em>United States</em>. One of the most popular types is an LSTM recurrent network, standing for <strong>Long-Short Term Memory</strong>.</li>
<li><strong>Autoencoders</strong>, which learn a mapping from the input, through a hidden layer (usually with fewer nodes), back to the input. This finds a compression of the input data, and this layer can be reused in other neural networks, reducing the amount of labelled training data needed.</li>
</ul>
<p>There are many, many more types of neural networks. Research into applications and theory of deep neural networks is finding more and more&#160;forms of neural networks every month. Some are designed for general purpose learning, some for specific tasks. Further, there are multiple ways to combine layers, tweak parameters, and otherwise alter the learning strategy. For example, <strong>dropout layers</strong> randomly reduce some weights to zero during training, forcing all parts of the neural network to learn good weights.</p>
<p>Despite all these differences, a&#160;neural network is usually designed to take very basic features as inputs—in the case of computer vision, it is simple pixel values. As that data is combined and pushed through the network, these basic features combine into more complex features. Sometimes, these features have little meaning to humans, but they represent the aspects of the sample that the computer looks for to make its classification.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Implementing deep neural networks</h1>
            </header>

            <article>
                
<div class="packt_infobox">Implementing these deep neural networks can be quite challenging due to their size. A bad implementation will take significantly longer to run than a good one, and may not even run at all due to memory usage.</div>
<p>A basic implementation of a neural network might start by creating a node class and collecting a set of these into a layer class. Each node is then connected to a node in the next layer using an instance of an <em>Edge</em> class. This type of implementation, a class-based one, is good to show how networks operate but&#160;too inefficient for larger networks. Neural networks simply have too many moving parts for this strategy to be efficient.</p>
<div class="packt_infobox">Instead, most neural networks operations can be expressed as mathematical expressions on matrices. The weights of the connections between one network layer and the next can be represented as a matrix of values, where the rows represent nodes in the first layer and the columns represent the nodes in the second layer (the transpose of this matrix is used sometimes too). The value is the weight of the edge between one layer and the next. A network can then be defined as a set of these weight matrices. In addition to the nodes, we add a bias term to each layer, which is basically a node that is always on and connected to each neuron in the next layer.</div>
<p>This insight allows us to use matrix operations to build, train, and use neural networks, as opposed to creating a class-based implementation. These mathematical operations are great, as many great libraries of highly optimised code have been written that we can use to perform these computations as efficiently as we can.</p>
<p>The scikit-learn implementation that we used in <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks</em>, does contain some features for building neural networks&#160;but lacks several recent advances in the field. For larger and more customised networks, though, we need a library that gives us a bit more power. We will use the <strong>Keras</strong> library instead to create our deep neural network.</p>
<p>In this chapter, we will start by implementing a basic neural network with Keras and then (nearly) replicate our experiment in <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks</em>, on predicting which letter is in an image. Finally, we will use a much more complex convolution neural network to perform image classification on the CIFAR dataset, which will also include running this on GPUs rather than CPUs to improve the performance.</p>
<p>Keras is a high-level interface to using a graph-computation library for implementing deep neural networks. G<span>raph-computation</span> libraries outline a series of operations and then later compute the values. These are great for matrix operations&#160;because they can be used to represent data flows, distribute those data flows across multiple systems and perform other optimisations. Keras can use either of two graph-computation libraries under the hood. The first is called <strong>Theano</strong>, which is a little older and has a strong following (and was used in the first edition of this book), and the second is <strong>TensorFlow</strong>, released recently by Google and is the library that powers much of their deep learning. Ultimately, you can use either library in this chapter.&#160;</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">An Introduction to TensorFlow</h1>
            </header>

            <article>
                
<p>TensorFlow is a graph computation library designed by engineers at Google, and is starting to power many of Google's recent advances in <strong>deep learning</strong> and <strong>artificial intelligence</strong>.</p>
<p>A graph computation library has two steps. They are listed below:</p>
<ol>
<li>Defining the sequence (or more complex graphs) of operations that take the input data, operate on it, and convert to outputs.</li>
<li>Compute on the graph obtained from step 1 with a given input.</li>
</ol>
<p>Many programmers don't use this type of programming day-to-day, but most of them interact with a related system that does. Relational databases, specifically SQL-based ones, use a similar concept called the declarative paradigm. While a programmer might define a <kbd>SELECT</kbd> query on a database with a <kbd>WHERE</kbd> clause, the database interprets that and creates an optimised query based on a number of factors, such as whether the <kbd>WHERE</kbd> clause is applied to a primary key, the format the data is stored in, and other factors. The programmer defines what they want and the system determines how to do it.</p>
<div class="packt_infobox">You can install TensorFlow using Anaconda: <span class="packt_screen">conda install tensorflow</span><br/>
For more options, Google has a detailed installation page at&#160;<a href="https://www.tensorflow.org/get_started/os_setup">https://www.tensorflow.org/get_started/os_setup</a>&#160;</div>
<p>Using TensorFlow, we can define many types of functions working on scalars, arrays, and matrices, as well as other mathematical expressions. For instance, we can create a graph that computes the values of a given quadratic equation:</p>
<pre>import tensorflow as tf<br/><br/># Define the parameters of the equation as constant values<br/>a = tf.constant(5.0)<br/>b = tf.constant(4.5)<br/>c = tf.constant(3.0)<br/><br/># Define the variable x, which lets its value be changed<br/>x = tf.Variable(0., name='x')  # Default of 0.0<br/><br/># Define the output y, which is an operation on a, b, c and x<br/>y = (a * x ** 2) + (b * x) + c
</pre>
<p>This <em>y</em> object is a Tensor object. It does not yet have a value as this hasn't been computed. All we have done is create a graph that states:</p>
<p><em>When we do compute <span class="packt_screen">y</span>,&#160;first&#160;take the square the value of <span class="packt_screen">x</span> and multiply it by <span class="packt_screen">a</span>, add <span class="packt_screen">b</span> times <span class="packt_screen">x</span> to it, and then add <span class="packt_screen">c</span> to the result.</em></p>
<p>The graph itself can be viewed through TensorFlow. Here is some code to visualise this graph within a Jupyter Notebook, courtesy of &#160;StackOverflow user Yaroslav Bulatov (see this answer:&#160;<a href="http://stackoverflow.com/a/38192374/307363">http://stackoverflow.com/a/38192374/307363</a>):</p>
<pre>from IPython.display import clear_output, Image, display, HTML<br/><br/>def strip_consts(graph_def, max_const_size=32):<br/>    """Strip large constant values from graph_def."""<br/>    strip_def = tf.GraphDef()<br/>    for n0 in graph_def.node:<br/>        n = strip_def.node.add() <br/>        n.MergeFrom(n0)<br/>        if n.op == 'Const':<br/>            tensor = n.attr['value'].tensor<br/>            size = len(tensor.tensor_content)<br/>            if size &gt; max_const_size:<br/>                tensor.tensor_content = "&lt;stripped %d bytes&gt;"%size<br/>    return strip_def<br/><br/>def show_graph(graph_def, max_const_size=32):<br/>    """Visualize TensorFlow graph."""<br/>    if hasattr(graph_def, 'as_graph_def'):<br/>        graph_def = graph_def.as_graph_def()<br/>    strip_def = strip_consts(graph_def, max_const_size=max_const_size)<br/>    code = """<br/>        &lt;script&gt;<br/>          function load() {{<br/>            document.getElementById("{id}").pbtxt = {data};<br/>          }}<br/>        &lt;/script&gt;<br/>        &lt;link rel="import" href="https://tensorboard.appspot.com/tf-graph-basic.build.html" onload=load()&gt;<br/>        &lt;div style="height:600px"&gt;<br/>          &lt;tf-graph-basic id="{id}"&gt;&lt;/tf-graph-basic&gt;<br/>        &lt;/div&gt;<br/>    """.format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))<br/><br/>    iframe = """<br/>        &lt;iframe seamless style="width:1200px;height:620px;border:0" srcdoc="{}"&gt;&lt;/iframe&gt;<br/>    """.format(code.replace('"', '&amp;quot;'))<br/>    display(HTML(iframe))
</pre>
<p>We can then perform the actual visualisation using this code in a new cell:</p>
<pre>show_graph(tf.get_default_graph().as_graph_def())
</pre>
<p>The results show how these operations are linked in a directed graph. The visualisation platform is called <strong>TensorBoard</strong>, which comes with TensorFlow:</p>
<div class="CDPAlignCenter CDPAlign"><img class=" image-border" src="images/B06162_11_04.png"/></div>
<p>When we want to compute a value for <span class="packt_screen">y</span>, we need to pass a value for <span class="packt_screen">x</span> through the other nodes in the graph, these are called <span class="packt_screen">OpNodes</span> in the above graph, short for <em>Operation Node</em>.</p>
<p>To this point, we have defined the graph itself. The next step is to compute the values. We can do this a number of ways, especially considering <span class="packt_screen">x</span> is a <span class="packt_screen">Variable</span>. To compute <span class="packt_screen">y</span>, using the current value of <span class="packt_screen">x</span>, we create a TensorFlow Session object and then ask it to run <span class="packt_screen">y</span>:</p>
<pre>model = tf.global_variables_initializer()<br/>with tf.Session() as session:<br/>    session.run(model)<br/>    result = session.run(y)<br/>print(result)
</pre>
<p>The first line initialises the variables. TensorFlow lets you specify scopes of operations and namespaces. At this point, we are just using the global namespace, and this function is a handy shortcut to initialise that scope properly, which can be thought of as a step needed for TensorFlow to compile the graph.</p>
<p>The second creates a new session that will run the model itself. The result from&#160;<kbd>tf.global_variables_initializer()</kbd> is itself an operation on the graph, and must be executed to happen. The next line actually runs the variable <span class="packt_screen">y</span>, which computes the necessary <span class="packt_screen">OpNodes</span> needed to compute the value of <span class="packt_screen">y</span>. In our case, that is all of the nodes but it is possible that larger graphs might not need all nodes computed - TensorFlow will do just enough work to get the answer and no more.</p>
<div class="packt_tip">If you get an error that <kbd>global_variables_initializer</kbd> is not defined, replace it with <kbd>initialize_all_variables</kbd> - the interface was recently changed.</div>
<p>Printing the result gives us our value of 3.</p>
<p>We can also do other operations, such as change the value of <span class="packt_screen">x</span>. For instance, we can create an assign operation, which assigns a new value to an existing Variable. In this example, we change the value of <span class="packt_screen">x</span> to 10&#160;and then compute y, which results in 548.</p>
<pre>model = tf.global_variables_initializer()<br/>with tf.Session() as session:<br/>    session.run(model)<br/>    session.run(x.assign(10))<br/>    result = session.run(y)<br/>print(result)
</pre>
<p>While this simple example may not seem much more powerful than what we can already do with Python, TensorFlow (and Theano) have large amounts of distribution options for computing larger networks over many computers and optimisations for doing it efficiently. Both libraries also contain extra tools for saving and loading networks, including values, which lets us save models created in these libraries.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Using Keras</h1>
            </header>

            <article>
                
<p>TensorFlow is not a library to directly build neural networks. In a similar way, NumPy is not a library to perform data mining; it just does the heavy lifting and is generally used from another library.&#160;TensorFlow contains a built-in library, referred to as TensorFlow Learn to build networks and perform data mining. Other libraries, such as Keras, are also built with this in mind&#160;and use TensorFlow in the backend.</p>
<p>Keras implements a number of modern types of neural network layers and the building blocks for building them. In this chapter, we will use convolution layers which are designed to mimic the way in which human vision works. They use small collections of connected neurons that analyse only a segment of the input values - in this case, an image. This allows the network to deal with standard alterations such as dealing with translations of images. In the case of vision-based experiments, an example of an alteration dealt with by convolution layers is translating the image.</p>
<div class="packt_infobox">In contrast, a traditional neural network is often heavily connected—all neurons from one layer connect to all neurons in the next layer. This is referred to as a dense layer.</div>
<p>The standard model for neural networks in Keras is a <strong>Sequential</strong> model, which is created by passing a list of layers. The input (<span class="packt_screen">X_train</span>) is given to the first layer, and its output given to the next layer and so on, in a standard feed-forward configuration.</p>
<p>Building a neural network in Keras is significantly easier than building it using just TensorFlow. Unless you are doing highly customised modifications to the neural network structure, I strongly recommend using Keras.</p>
<p>To show the basics of using Keras for neural networks, we will implement a basic network to lean on the Iris dataset, which we saw in <a href="lrn-dtmn-py-2e_ch01.html">Chapter 1</a><em>, Getting Started with Data Mining</em>. The Iris dataset is great for testing new algorithms, even complex ones such as deep neural networks.</p>
<p>First, open a new Jupyter Notebook. We will come back to the Notebook with the CIFAR data, later in the chapter.</p>
<p>Next, we load the dataset:</p>
<pre>import numpy as np<br/>from sklearn.datasets import load_iris <br/>iris = load_iris() <br/>X = iris.data.astype(np.float32) <br/>y_true = iris.target.astype(np.int32)
</pre>
<p>When dealing with libraries like TensorFlow, it is best to be quite explicit about data types. While Python will happily convert from one numerical data type to another implicitly, libraries like TensorFlow are wrappers around lower-level code (in this case, C++). These libraries are not able to always convert between numerical data types.</p>
<p>Our output is currently a single array of categorical values (0, 1 or 2 depending on the class). Neural networks&#160;<em>can&#160;</em>be developed to output data in this format, but the <em>normal convention</em> is for the neural network to have <em>n</em> outputs, where <em>n</em> in the number of classes. Due to this, we use one-hot encoding to convert our categorical <span class="packt_screen">y</span> into a one-hot encoded <kbd>y_onehot</kbd>:</p>
<pre>from sklearn.preprocessing import OneHotEncoder<br/><br/>y_onehot = OneHotEncoder().fit_transform(y_true.reshape(-1, 1))<br/>y_onehot = y_onehot.astype(np.int64).todense()
</pre>
<p>We then split into training and testing datasets:</p>
<pre>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, random_state=14)
</pre>
<p>Next, we build our network by creating the different layers. Our dataset contains four input variables and three output classes. This gives us the size of the first and last layer, but not the layers in between. Playing around with this figure will give different results, and it is worth trailing different values to see what happens. We will create a small network to start with, with the following dimensions:</p>
<pre>input_layer_size, hidden_layer_size, output_layer_size = 4, 6, 3
</pre>
<p>Next, we create our hidden layer and our output layer (the input layer is implicit). For this example we will use Dense layers:</p>
<pre>from keras.layers import Dense<br/>hidden_layer = Dense(output_dim=hidden_layer_size, input_dim=input_layer_size, activation='relu')<br/>output_layer = Dense(output_layer_size, activation='sigmoid')
</pre>
<p>I encourage you to play with the activation value, and see how that affects the results. The values here are great defaults if you have no further information about your problem. That is, use <kbd>relu</kbd> for hidden layers, and <kbd>sigmoid</kbd> for the output layer.</p>
<p>We then combine the layers into a Sequential model:</p>
<pre>from keras.models import Sequential<br/>model = Sequential(layers=[hidden_layer, output_layer])
</pre>
<p>One necessary step from here is to compile the network, which creates the graph. In the compile step, we were&#160;given information on how the network will be trained and evaluated. The values here define what exactly it is that the neural network is trying to train to reduce, in the case below, it is the mean squared error between the output neurons and their expected values. The choice of optimizer largely affects how efficiently it can do this, often with a trade-off between speed and memory usage.</p>
<pre>model.compile(loss='mean_squared_error',<br/>              optimizer='adam',<br/>              metrics=['accuracy'])
</pre>
<p>We then train our model using the <kbd>fit</kbd> function. Keras models return a history object from <kbd>fit()</kbd>, that allows us see the data at a fine-grained level.</p>
<pre>history = model.fit(X_train, y_train)
</pre>
<p>You will get quite a lot of output. The neural network will train 10 epochs, which are training cycles of taking the training data, running it through the neural network, updating the weights and evaluating the results. If you investigate the history object (try <kbd>print(history.history)</kbd>) you will see the loss function's score after each of these epochs (lower is better). Also included is the accuracy, where higher is better. You will probably also notice that it hasn't really improved that much.&#160;</p>
<p>We can plot out the history object using <kbd>matplotlib</kbd>:</p>
<pre>import seaborn as sns<br/>from matplotlib import pyplot as plt<br/><br/>plt.plot(history.epoch, history.history['loss'])<br/>plt.xlabel("Epoch")<br/>plt.ylabel("Loss")
</pre>
<div class="CDPAlignCenter CDPAlign"><img height="481" width="482" class=" image-border" src="images/B06162_11_05.png"/></div>
<p>While the training loss is decreasing, it is not decreasing much. This is one issue with neural networks - they train slowly. By default, the fit function will only perform 10 epochs, which is nowhere near enough for nearly any application. To see this,&#160;use the neural network to predict the test set and run a classification report:</p>
<pre>from sklearn.metrics import classification_report<br/>y_pred = model.predict_classes(X_test)<br/>print(classification_report(y_true=y_test.argmax(axis=1), y_pred=y_pred))
</pre>
<p>The results are quite poor, with an overall f1-score of 0.07, and the classifier only predicting class 2 for all instances. At first, it might seem that neural networks are not that great but let's have a look at what happens when we train for 1000 epochs:</p>
<pre>history = model.fit(X_train, y_train, nb_epoch=1000, verbose=False)
</pre>
<p>Visualizing the loss per epoch again, a very useful visualization when running iterative algorithms like neural networks,&#160;using the above code shows a very different story:</p>
<p><img class=" image-border" src="images/B06162_11_06.png"/></p>
<p>Finally, we perform a classification report again to see the results:</p>
<pre>y_pred = model.predict_classes(X_test)<br/>print(classification_report(y_true=y_test.argmax(axis=1), y_pred=y_pred))
</pre>
<p>Perfect.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Convolutional Neural Networks</h1>
            </header>

            <article>
                
<p>To get started with image analysis with Keras, we are going to reimplement the example we used in <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks</em>, to predict which letter was represented in an image. We will recreate the dense neural network we used in <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks</em>. To start with, we need to enter our dataset building code again in our notebook. For a description of what this code does, refer to <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks&#160;</em>(<em>remember to update the file location of the Coval font</em>):</p>
<pre>import numpy as np <br/>from PIL import Image, ImageDraw, ImageFont <br/>from skimage import transform as tf
</pre>
<pre>def create_captcha(text, shear=0, size=(100, 30), scale=1):<br/>    im = Image.new("L", size, "black")<br/>    draw = ImageDraw.Draw(im)<br/>    font = ImageFont.truetype(r"bretan/Coval-Black.otf", 22) <br/>    draw.text((0, 0), text, fill=1, font=font)<br/>    image = np.array(im)<br/>    affine_tf = tf.AffineTransform(shear=shear)<br/>    image = tf.warp(image, affine_tf)<br/>    image = image / image.max()<br/>    shape = image.shape<br/>    # Apply scale<br/>    shapex, shapey = (shape[0] * scale, shape[1] * scale)<br/>    image = tf.resize(image, (shapex, shapey))<br/>    return image
</pre>
<pre>from skimage.measure import label, regionprops<br/>from skimage.filters import threshold_otsu<br/>from skimage.morphology import closing, square<br/><br/>def segment_image(image):<br/>    # label will find subimages of connected non-black pixels<br/>    labeled_image = label(image&gt;0.2, connectivity=1, background=0)<br/>    subimages = []<br/>    # regionprops splits up the subimages<br/>    for region in regionprops(labeled_image):<br/>        # Extract the subimage<br/>        start_x, start_y, end_x, end_y = region.bbox<br/>        subimages.append(image[start_x:end_x,start_y:end_y])<br/>    if len(subimages) == 0:<br/>        # No subimages found, so return the entire image<br/>        return [image,]<br/>    return subimages<br/><br/>
</pre>
<pre>from sklearn.utils import check_random_state<br/>random_state = check_random_state(14) <br/>letters = list("ABCDEFGHIJKLMNOPQRSTUVWXYZ")<br/>assert len(letters) == 26<br/>shear_values = np.arange(0, 0.8, 0.05)<br/>scale_values = np.arange(0.9, 1.1, 0.1)
</pre>
<pre>def generate_sample(random_state=None): <br/>    random_state = check_random_state(random_state) <br/>    letter = random_state.choice(letters) <br/>    shear = random_state.choice(shear_values)<br/>    scale = random_state.choice(scale_values)<br/>    return create_captcha(letter, shear=shear, size=(30, 30), scale=scale), letters.index(letter)
</pre>
<pre>dataset, targets = zip(*(generate_sample(random_state) for i in range(1000)))<br/>dataset = np.array([tf.resize(segment_image(sample)[0], (20, 20)) for sample in dataset])<br/>dataset = np.array(dataset, dtype='float') <br/>targets = np.array(targets)
</pre>
<pre>from sklearn.preprocessing import OneHotEncoder <br/>onehot = OneHotEncoder() <br/>y = onehot.fit_transform(targets.reshape(targets.shape[0],1))<br/>y = y.todense()<br/><br/>X = dataset.reshape((dataset.shape[0], dataset.shape[1] * dataset.shape[2]))<br/><br/>from sklearn.model_selection import train_test_split <br/>X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9)
</pre>
<p>After rerunning all of this code, you'll have a dataset similar to <a href="lrn-dtmn-py-2e_ch08.html">Chapter 8</a><em>, Beating CAPTCHAs with Neural Networks</em>&#160;experiment. Next, instead of using scikit-learn to do our neural network, we will use Keras.</p>
<p>First, we create our two <strong>Dense</strong> layers and combine them in a <strong>Sequential</strong> model. I've chosen to put 100 neurons in the hidden layer.</p>
<pre>from keras.layers import Dense<br/>from keras.models import Sequential<br/>hidden_layer = Dense(100, input_dim=X_train.shape[1])<br/>output_layer = Dense(y_train.shape[1])<br/># Create the model<br/>model = Sequential(layers=[hidden_layer, output_layer])<br/>model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
</pre>
<p>Then, we fit the model. As before, you will want to have quite a larger number of epochs. I've used 1000 again, if you want better results, you can increase this number.</p>
<pre>model.fit(X_train, y_train, nb_epoch=1000, verbose=False)<br/>y_pred = model.predict(X_test)
</pre>
<p>You can also collect the resulting history object, like we did with the Iris example, to investigate the training further.</p>
<pre>from sklearn.metrics import classification_report<br/>print(classification_report(y_pred=y_pred.argmax(axis=1),<br/>y_true=y_test.argmax(axis=1)))
</pre>
<p>Again, perfect.</p>
<div class="packt_tip">At least, it was on my machine but your results may differ slightly.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">GPU optimization</h1>
            </header>

            <article>
                
<p>Neural networks can grow quite large in size. This has some implications for memory use; however, efficient structures such as sparse matrices mean that we don't generally run into problems fitting a neural network in memory.</p>
<div class="packt_infobox">The main issue when neural networks grow large is that they take a very long time to compute. In addition, some datasets and neural networks will need to run many epochs of training to get a good fit for the dataset.</div>
<p>The neural network we will train in this chapter takes more than 8 minutes per epoch on my reasonably powerful computer, and we expect to run dozens, potentially hundreds, of epochs. Some larger networks can take hours to train a single epoch. To get the best performance, you may be considering thousands of training cycles.</p>
<p>The scale of neural networks leads to long training times.</p>
<p>One positive is that neural networks are, at their core, full of floating point operations. There are also a large number of operations that can be performed in parallel, as neural network training is composed of mainly matrix operations. These factors mean that computing on GPUs is an attractive option to speed up this training.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">When to use GPUs for computation</h1>
            </header>

            <article>
                
<p>GPUs were originally designed to render graphics for display. These graphics are represented using matrices and mathematical equations on those matrices, which are then converted into the pixels that we see on our screen. This process involves lots of computation in parallel. While modern CPUs may have a number of cores (your computer may have 2, 4, or even 16—or more!), GPUs have thousands of small cores designed specifically for graphics.</p>
<p>A CPU is&#160;better for sequential tasks, as the cores tend to be individually faster and tasks such as accessing the computer's memory are more efficient. It is also, honestly, easier to just let the CPU do the heavy lifting. Almost every machine learning library defaults to using the CPU, and there is extra work involved before you can use the GPU for computing. The benefits can be quite significant.</p>
<p>GPUs are therefore better suited for tasks in which there are lots of small operations on numbers that can be performed at the same time. Many machine learning tasks are like this, lending themselves to efficiency improvements through the use of a GPU.</p>
<p>Getting your code to run on a GPU can be a frustrating experience. It depends greatly on what type of GPU you have, how it is configured, your operating system, and whether you are prepared to make some low-level changes to your computer.</p>
<div class="packt_tip packt_infobox">Luckily, Keras will automatically use a GPU for operations, if the operation suits and a GPU can be found (and if you use TensorFlow as the backend). However, you still need to setup your computer such that the GPU can be found by Keras and TensorFlow.</div>
<p>There are three main avenues to take:</p>
<ul>
<li>The first is to look at your computer, search for tools and drivers for your GPU and operating system, explore some of the many tutorials out there, and find one that fits your scenario. Whether this works depends on what your system is like. That said, this scenario is much easier than it was a few years ago, with better tools and drivers available to perform GPU-enabled computation.</li>
<li>The second avenue is to choose a system, find good documentation on setting it up&#160;and buy a system to match. This will work better, but can be fairly expensive—in most modern computers, the GPU is one of the most expensive parts. This is especially true if you want to get great performance out of the system—you'll need a really good GPU, which can be very expensive. If you are a business (or have larger amounts of money to spend), you can buy high-end GPUs specifically for deep learning and talk more directly to vendors to ensure you get the right hardware.</li>
<li>The third avenue is to use a virtual machine, which is already configured for such a purpose. For example, Altoros Systems has created such a system that runs on Amazon's Web Services. The system will cost you money to run, but the price is much less than that of a new computer. Depending on your location, the exact system you get and how much you use it, you are probably looking at less than $1 an hour, and often much, much less. If you use spot instances in Amazon's Web Services, you can run them for just a few cents per hour (although, you will need to develop your code to run on spot instances separately).</li>
</ul>
<div class="packt_tip">If you aren't able to afford the running costs of a virtual machine, I recommend that you look into the first avenue, with your current system. You may also be able to pick up a good second-hand GPU from family or a friend who constantly updates their computer (gamer friends are great for this!).</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Running our code on a GPU</h1>
            </header>

            <article>
                
<p>We are going to take the third avenue in this chapter and create a virtual machine based on Altoros Systems' base system. This will run on an Amazon's EC2 service. There are many other Web services to use, and the procedure will be slightly different for each. In this section, I'll outline the procedure for Amazon.</p>
<p>If you want to use your own computer and have it configured to run GPU-enabled computation, feel free to skip this section.</p>
<div class="packt_tip">You can get more information on how this was set up, see&#160;<a href="https://aws.amazon.com/marketplace/pp/B01H1VWUOY?qid=1485755720051&amp;sr=0-1&amp;ref_=srh_res_product_title">https://aws.amazon.com/marketplace/pp/B01H1VWUOY?qid=1485755720051&amp;sr=0-1&amp;ref_=srh_res_product_title</a>&#160;</div>
<ol>
<li>To start with, go to the AWS console at: <a href="https://console.aws.amazon.com/console/home?region=us-east-1">https://console.aws.amazon.com/console/home?region=us-east-1</a></li>
<li>Log in with your Amazon account. If you don't have one, you will be prompted to create one, which you will need to do in order to continue.</li>
<li>Next, go to the EC2 service console at:&#160;<a href="https://console.aws.amazon.com/ec2/v2/home?region=us-east-1.">https://console.aws.amazon.com/ec2/v2/home?region=us-east-1.</a></li>
<li>Click on <span class="packt_screen">Launch Instance</span> and choose N. California as your location in the drop-down menu at the top-right.</li>
</ol>
<ol start="5">
<li>Click on <span class="packt_screen">Community AMIs</span> and search for <span class="packt_screen">Ubuntu x64 AMI with TensorFlow (GPU)</span>, which is the machine created by&#160;<span>Altoros Systems.</span> Then, click on <span class="packt_screen">Select</span>. On the next screen, choose <span class="packt_screen">g2.2xlarge</span> as the machine type and click on <span class="packt_screen">Review and Launch</span>. On the next screen, click on <span class="packt_screen">Launch</span>.</li>
<li>At this point, you will be charged, so please remember to shut down your machines when you are done with them. You can go to the EC2 service, select the machine, and stop it. You won't be charged for machines that are not running.</li>
<li>You'll be prompted with some information on how to connect to your instance. If you haven't used AWS before, you will probably need to create a new key pair to securely connect to your instance. In this case, give your key pair a name, download the pemfile, and store it in a safe place—if lost, you will not be able to connect to your instance again!</li>
<li>Click on <span class="packt_screen">Connect</span> for information on using the <span class="packt_screen">pem</span> file to connect to your instance. The most likely scenario is that you will use ssh with the following command:</li>
</ol>
<pre>ssh -i &lt;certificante_name&gt;.pem ubuntu@&lt;server_ip_address&gt;
</pre>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Setting up the environment</h1>
            </header>

            <article>
                
<p>Next, we need to get our code onto the machine. There are many ways to get this file onto your computer, but one of the easiest is to just copy-and-paste the contents.</p>
<p>To start with, open the Jupyter Notebook we used before (on your computer, not on the Amazon Virtual Machine). On the Notebook itself is a menu. Click on <span class="packt_screen">File</span> and then <span class="packt_screen">Download as</span>. Select <span class="packt_screen">Python</span> and save it to your computer. This procedure downloads the code in the Jupyter Notebook as a python script that you can run from the command line.</p>
<p>Open this file (on some systems, you may need to right-click and open with a text editor). Select all of the contents and copy them to your clipboard.</p>
<p>On the Amazon Virtual Machine, move to the home directory and open <span class="packt_screen">nano</span> with a new filename:</p>
<pre><strong>$ cd~/</strong>
</pre>
<pre><strong>$ nano chapter11script.py</strong>
</pre>
<p>The nano program will open, which is a command-line text editor.</p>
<p>With this program open, paste the contents of your clipboard into this file. On some systems, you may need to use a file option of the ssh program, rather than pressing Ctrl+ V to paste.</p>
<p>In nano, press Ctrl+ O to save the file on the disk and then Ctrl+ X to exit the program.</p>
<p>You'll also need the font file. The easiest way to do this is to download it again from the original location. To do this, enter the following:</p>
<pre><strong>$ wget http://openfontlibrary.org/assets/downloads/bretan/680bc56bbeeca95353ede363a3744fdf/bretan.zip</strong>
</pre>
<pre><strong>$ sudo apt-get install unzip</strong>
</pre>
<pre><strong>$ unzip -p bretan.zip</strong>
</pre>
<p>While still in the virtual machine, you can run the program with the following command:</p>
<pre><strong>$ python chapter11script.py</strong>
</pre>
<p>The program will run through as it would in the Jupyter Notebook and the results will print to the command line.</p>
<p>The results should be the same as before, but the actual training and testing of the neural network will be much faster. Note that it won't be that much faster in the other aspects of the program—we didn't write the CAPTCHA dataset creation to use a GPU, so we will not obtain a speedup there.</p>
<div class="packt_tip">You may wish to shut down the Amazon virtual machine to save some money; we will be using it at the end of this chapter to run our main experiment, but will be developing the code on your main computer first.</div>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Application</h1>
            </header>

            <article>
                
<p>Back on your main computer now, open the first Jupyter Notebook we created in this chapter—the one that we loaded the CIFAR dataset with. In this major experiment, we will take the CIFAR dataset, create a deep convolution neural network, and then run it on our GPU-based virtual machine.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Getting the data</h1>
            </header>

            <article>
                
<p>To start with, we will take our CIFAR images and create a dataset with them. Unlike previously, we are going to preserve the pixel structure—that is, in rows and columns. First, load all the batches into a list:</p>
<pre>import os<br/>import numpy as np <br/><br/>data_folder = os.path.join(os.path.expanduser("~"), "Data", "cifar-10-batches-py")<br/><br/>batches = [] <br/>for i in range(1, 6):<br/>    batch_filename = os.path.join(data_folder, "data_batch_{}".format(i))<br/>    batches.append(unpickle(batch_filename)) <br/>    break
</pre>
<p>The last line, the break, is to test the code—this will drastically reduce the number of training examples, allowing you to quickly see if your code is working. I'll prompt you later to remove this line&#160;after you have tested that the code works.</p>
<p>Next, create a dataset by stacking these batches on top of each other. We use NumPy's <span class="packt_screen">vstack</span>, which can be visualised as adding rows to the end of the array:</p>
<pre>X = np.vstack([batch['data'] for batch in batches])
</pre>
<p>We then normalise the dataset to the range 0 to 1 and then force the type to be a 32-bit float (this is the only datatype the GPU-enabled virtual machine can run with):</p>
<pre>X = np.array(X) / X.max() <br/>X = X.astype(np.float32)
</pre>
<p>We then do the same with the classes, except we perform a <span class="packt_screen">hstack</span>, which is similar to adding columns to the end of the array. We could then use the <span class="packt_screen">OneHotEncoder</span> to turn this into a one-hot array. I'll show an alternate method here using a utility function present in Keras, but the result is the same either way:</p>
<pre>from keras.utils import np_utils<br/>y = np.hstack(batch['labels'] for batch in batches).flatten()<br/>nb_classes = len(np.unique(y))<br/>y = np_utils.to_categorical(y, nb_classes)
</pre>
<p>Next, we split the dataset into training and testing sets:</p>
<pre>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
</pre>
<p>Next, we reshape the arrays to preserve the original data structure. The original data was 32-by-32-pixel images, with 3 values per pixel (for the red, green, and blue values). While standard feed-forward neural networks only take a single array of input data (see the CAPTCHA example), Convolutional Neural Networks are built for images&#160;and accept 3-dimensional image data (2-D image, and another dimension containing colour depth).</p>
<pre>X_train = X_train.reshape(-1, 3, 32, 32)<br/>X_test = X_test.reshape(-1, 3, 32, 32)<br/>n_samples, d, h, w = X_train.shape  # Obtain dataset dimensions<br/># Convert to floats and ensure data is normalised.<br/>X_train = X_train.astype('float32')<br/>X_test = X_test.astype('float32')
</pre>
<p>We now have a familiar training and testing dataset, along with the target classes for each. We can now build the classifier.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Creating the neural network</h1>
            </header>

            <article>
                
<p>We will now build the convolutional neural network. I have performed some tinkering and found a layout that works well, but feel free to experiment with more layers (or fewer), layers of different types and different sizes. Smaller networks train faster, but larger networks can achieve better results.</p>
<p>First, we create the layers of our neural network:</p>
<pre>from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D<br/>conv1 = Convolution2D(32, 3, 3, input_shape=(d, h, w), activation='relu')<br/>pool1 = MaxPooling2D()<br/>conv2 = Convolution2D(64, 2, 2, activation='relu')<br/>pool2 = MaxPooling2D()<br/>conv3 = Convolution2D(128, 2, 2, activation='relu')<br/>pool3 = MaxPooling2D()<br/>flatten = Flatten()<br/>hidden4 = Dense(500, activation='relu')<br/>hidden5 = Dense(500, activation='relu')<br/>output = Dense(nb_classes, activation='softmax')<br/>layers = [conv1, pool1,<br/>          conv2, pool2,<br/>          conv3, pool3,<br/>          flatten, hidden4, hidden5,<br/>          output]
</pre>
<p>We use dense layers for the last three layers as per a normal feed-forward neural network, but before that, we use convolution layers combined with pooling layers. We have three sets of these.</p>
<p>For each pair of&#160;<span class="packt_screen">Convolution2D</span> and <span class="packt_screen">MaxPooling2D</span> layers, the following happens:</p>
<ol>
<li>The <span class="packt_screen">Convolution2D</span> network fetches patches of the input data. These are passed through a filter, a matrix transformation akin to the kernel operator Support Vector Machines use. A filter is a smaller matrix, of size <span class="packt_screen">k</span> by <span class="packt_screen">n</span> (specified as 3x3 in the&#160;Convolution2D initialiser above) that is applied to each&#160;<span class="packt_screen">k</span> <span>by</span> <span class="packt_screen">n</span> pattern found in the image. The result is a convolved feature.</li>
<li>The <span class="packt_screen">MaxPooling2D</span> layer takes the results from the&#160;<span><span class="packt_screen">Convolution2D</span> layer and finds the maximum value for each convolved feature.</span></li>
</ol>
<p>While this does discard lots of information, this actually helps for image detection. If the object of an image is a few pixels to the right, a standard neural network will consider it a completely new image. In contrast, the convolution layer will find it&#160;and report almost the same output (depending, of course, on a wide variety of other factors).</p>
<p>After passing through these pairs layers, the features that go into the dense part of the network are meta-features that represent abstract concepts of the image, rather than specific qualities. Often these can be visualised, resulting in features like <em>a little bit of a line pointing up</em>.</p>
<p>Next, we put these layers together to build our neural network and train it. This training will take substantially longer than previous training. I recommend starting with 10 epochs, make sure the code works all the way through, and then rerun with 100 epochs. Also, once you have confirmed that the code works and you get predictions out, go back and remove the <kbd>break</kbd> line we put in when creating the dataset (it is in the batches loop). This will allow the code to train on all of the samples, not just the first batch.</p>
<pre>model = Sequential(layers=layers)<br/>model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])<br/>import tensorflow as tf<br/>history = model.fit(X_train, y_train, nb_epoch=25, verbose=True,<br/>validation_data=(X_test, y_test),batch_size=1000))
</pre>
<p>Finally, we can predict with the network and evaluate.</p>
<pre>y_pred = model.predict(X_test)<br/>from sklearn.metrics import classification_report<br/>print(classification_report(y_pred=y_pred.argmax(axis=1),<br/> y_true=y_test.argmax(axis=1)))
</pre>
<p>After running for 100 epochs, it is still not quite perfect in this case, but still an excellent result. If you have the time (say, overnight), try running the code for 1000 epochs. There is an increase in accuracy but a diminishing return on time invested. A (not so) good rule of thumb is that to halve the error, you need to double the training time.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Putting it all together</h1>
            </header>

            <article>
                
<p>Now that we have our network code working, we can train it with our training dataset on the remote machine. If you used your local machine to run the neural network, you can skip this section.</p>
<p>We need to upload the script to our virtual machine. As with before, click on <span class="packt_screen">File| Download</span> as, Python, and save the script somewhere on your computer. Launch and connect to the virtual machine and upload the script as you did earlier (I called my script <kbd>chapter11cifar.py</kbd>—if you named yours differently, just update the following code).</p>
<p>The next thing we need is for the dataset to be on the virtual machine. The easiest way to do this is to go to the virtual machine and type:</p>
<pre><strong>$ wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</strong>
</pre>
<p>This will download the dataset. Once that has downloaded, you can extract the data to the Data folder by first creating that folder and then unzipping the data there:</p>
<pre><strong>$ mkdir Data</strong>
</pre>
<pre><strong>$ tar -zxf cifar-10-python.tar.gz -C Data</strong>
</pre>
<p>Finally, we can run our example with the following:</p>
<pre><strong>$ python3 chapter11cifar.py</strong>
</pre>
<p>The first thing you'll notice is a drastic speedup. On my home computer, each epoch took over 100 seconds to run. On the GPU-enabled virtual machine, each epoch takes just 16 seconds! If we tried running 100 epochs on my computer, it would take nearly three hours, compared to just 26 minutes on the virtual machine.</p>
<p>This drastic speedup makes trialing different models much faster. Often with trialing machine learning algorithms, the computational complexity of a single algorithm doesn't matter too much. An algorithm might take a few seconds, minutes, or hours to run. If you are only running one model, it is unlikely that this training time will matter too much—especially as prediction, as with most machine learning algorithms, &#160;is quite quick and that is where a machine learning model is mostly used.</p>
<p>However, when you have many parameters to run, you will suddenly need to train thousands of models with slightly different parameters—suddenly, these speed increases matter much more.</p>
<p>After 100 epochs of training, taking a whole 26 minutes, you will get a printout of the final result:</p>
<pre><strong>0.8497</strong>
</pre>
<p>Not too bad! We can increase the number of epochs of training to improve this further or we might try changing the parameters instead; perhaps, more hidden nodes, more convolution layers, or an additional dense layer. There are other types of layers in Keras that could be tried too; although generally, convolution layers are better for vision.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>


  <div id="sbo-rt-content"><section>

            <header>
                <h1 class="header-title">Summary</h1>
            </header>

            <article>
                
<p>In this chapter, we looked at using deep neural networks, specifically convolution networks, in order to perform computer vision. We did this through the Keras package, which uses Tensorflow or Theano as its computation backend. The networks were relatively easy to build with Kera's helper functions.</p>
<p>The convolution networks were designed for computer vision, so it shouldn't be a surprise that the result was quite accurate. The final result shows that computer vision is indeed an effective application using today's algorithms and computational power.</p>
<p>We also used a GPU-enabled virtual machine to drastically speed up the process, by a factor of almost 10 for my machine. If you need extra power to run some of these algorithms, virtual machines by cloud providers can be an effective way to do this (usually for less than a dollar per hour)—just remember to turn them off when you are done!</p>
<p>To extend the work in this chapter, try play with the structure of the network to increase the accuracy further than what we obtained here. Another method that can be used to improve the accuracy is to create more data, either by taking your own pictures (slow) or by modifying the existing ones (much faster). To do the modification, you can flip images upside down, rotate, shear and so on. Keras has a function for doing this that is quite useful. See the documentation at <a href="https://keras.io/preprocessing/image/">https://keras.io/preprocessing/image/</a></p>
<p>Another area worth investigating is variations in neural network structure, more nodes, fewer nodes, more layers and so on. Also experiment with different activation types, different layer types and different combinations.</p>
<p>This chapter's focus was on a very complex algorithm. Convolution networks take a long time to train and have many parameters to train. Ultimately, the size of the data was small in comparison; although it was a large dataset, we can load it all in memory without even using sparse matrices. In the next chapter, we go for a much simpler algorithm, but a much, much larger dataset that can't fit in memory. This is the basis of Big Data and it underpins applications of data mining in many large industries such as mining and social networks.</p>


            </article>

            <footer style="margin-top: 5em;">
                
            </footer>

        </section>
    </div>
</body>
</html>