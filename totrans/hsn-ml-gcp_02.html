<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Google Compute Engine</h1>
                </header>
            
            <article>
                
<p>The core service of <strong><span>Google Cloud Platform</span></strong> (<strong>GCP</strong>) is <strong>Google Compute Engine</strong> (<strong>GCE</strong>). The GCE allows you to launch spin up <strong>virtual machines</strong> (<strong>VMs</strong>) with the right operating system, size, RAM, and appropriate number of CPUs or GPUs for your needs. It is an equivalent of AWS EC2. With GCE, we dive into the core of GCP.</p>
<p>In this chapter, you will learn how to:</p>
<ul>
<li>Create VM instances on GCE that are adapted to your projects.</li>
<li>Use Google's command-line tools to manage your VMs.</li>
<li>Set up a Python data science stack on a GCE VM with <kbd>conda</kbd> and <kbd>scikit-learn</kbd>.</li>
<li>Access your VM via a password-protected Jupyter Notebook. And we'll cover more advanced topics related to images, snapshots, pre-emptibles VMs, startup script, and IPs.</li>
</ul>
<p>By the end of this chapter, you will be able to create and fully manage your VM both via the online console and the command-line tools, as well as implement a data science workflow and a Jupyter Notebook workspace.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Google Compute Engine</h1>
                </header>
            
            <article>
                
<p>Simply put, GCE is a service that lets you create and run VMs on Google infrastructure. The GCE allows you to launch spin up VMs with the right operating system, size, RAM, and the appropriate number of CPUs or GPUs for your needs. It is the equivalent of AWS EC2.</p>
<p>The GCE was announced on June 28, 2012, at Google I/O 2012 and made available to the general public on May 15, 2013. Compared to AWS EC2, an equivalent product, the GCE is a rather new service:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e183a41b-0cad-4ecf-ac95-e751055a9c16.png"/></div>
<p>The following extracts from the release notes timeline illustrate the rapid evolution of the GCE service from a simple contender to a fully fledged player in the Cloud computing domain:</p>
<ul>
<li>May 15, 2013: GCE is available for everyone.</li>
<li>August 6, 2013: GCE launches load balancing.</li>
<li>December 3, 2013: GCE is announced as being production ready.<span> </span><em>Users can now feel confident using Compute Engine to support mission-critical workloads with 24/7 support and a 99.95% monthly SLA</em>.</li>
<li>June 25, 2014: <strong>Solid-State Drives</strong> (<strong>SSD</strong>) persistent disks are now available in general availability and open to all users and projects.</li>
<li>September 08, 2015: Pre-emptible instances are now generally available to all users and projects.</li>
<li>March 30, 2016: Persistent disks larger than 10 TB are generally available.</li>
<li>July 1, 2016: Shutdown scripts are now generally available to use with compute engine instances.</li>
<li>September 21, 2017: NVIDIA® Tesla® K80 GPUs are now generally available.</li>
<li>September 26, 2017: Billing increments for GCE VM instances are reduced from per-minute increments to per-second increments.</li>
<li>The most recent news at the time of writing this is the launch in beta of a staggering 96-vCPUs machine types.</li>
</ul>
<p>In the past four years, Google has been steadily improving and developing its GCE offer at a rapid pace by:</p>
<ul>
<li>Expanding regions</li>
<li>Adding more powerful machines and Intel CPU platforms</li>
<li>Adding roles and features</li>
<li>Steadily releasing new public images for Windows, Suse, CentOS, Debian, Ubuntu, RHEL, or CoreOS</li>
</ul>
<p>As the timeline illustrates, the GCE service is a young and dynamic service that embraces the evolution of its customers needs and anticipates them with bold new offers. It reflects Google's drive to become a leader in the Cloud computing business and potentially offset Amazon's lead in Cloud computing.</p>
<p>Before we launch our first GCE VM, let's cover a few important concepts.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">VMs, disks, images, and snapshots</h1>
                </header>
            
            <article>
                
<p>A VM is an on-demand virtual server that you spin up for your needs. It is geographically located in one of Google's data centers, but you only choose the region and zone, not the precise location. Although you share some of the infrastructure resources with other users, this sharing is transparent to you.</p>
<p>A<span> </span>VM<span> </span>requires a<span> </span>persistent disk<span> </span>to run on and an operating system such as a Windows or Linux distribution to boot on. Although very much abstracted in a cloud computing context, a GCE disk would refer to a physical drive that the computer can boot on.</p>
<p>An<span> </span>image<span> </span>exists on top of a<span> </span>persistent disk, and includes the operating system necessary to launch the instance. A typical use of an image is to enable sharing a VM setup across many different VMs. An image consists of an operating system and boot loader and can be used to boot an instance.</p>
<p>A<span> </span><strong>snapshot</strong><span> </span>is a reflection of the content of a VM at a given time. A snapshot is mostly used for instant backups. Snapshots are stored as diffs, relative to the previous one, while images are not.</p>
<p>Images<span> </span>and<span> </span>snapshots<span> </span>are quite similar. It's possible to activate an instance using a snapshot or an image.</p>
<p>When you launch a new<span> </span>instance, GCE starts by attaching a<span> </span>persistent disk<span> </span>to your<span> </span>VM. This provides the disk space and gives the instance the root filesystem it needs to boot up. The disk uses the image you have chosen and installs the OS associated with that image. Public images are provided by Google with specific OS while private images are your own images.</p>
<p>By taking snapshots of an image, you can copy data from existing persistent disks to new persistent disks. Snapshots are meant for creating instant backups.</p>
<p>From the Google Shell, you can access and manage all your resources and files.</p>
<p>For example, let's list all our existing instances by typing:</p>
<div>
<div class="scroll-view">
<div class="lines">
<div>
<pre class="line"><strong><span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text">$ gcloud compute instances list</span></span></span></strong></pre>
<p class="line"><span>We see our newly created sparrow instance.</span></p>
</div>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a VM</h1>
                </header>
            
            <article>
                
<p>Let's now create our first VM instance using the web console.</p>
<p>Go to the GCE console,<span> </span><a href="https://console.cloud.google.com/">https://console.cloud.google.com/</a>. Select the project we created in the previous chapter (or create one if you don't have one yet), and in the menu on the left, click on <span class="packt_screen">Compute Engine</span>. Since you don't have a VM yet, you are greeted by the following message. Click on <span class="packt_screen">Create</span> as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d0d2a021-5406-4ab0-b29e-764f6527d6e7.png" style=""/></div>
<p>For this first VM, we will choose a small one and resize it as we go along.</p>
<p>There are several things you need to decide on at this point:</p>
<ul>
<li>
<p>The name of your instance. I will call mine <strong>sparrow</strong>. This name does not have to be unique across GCP. Feel free to name yours as you like.</p>
</li>
<li>
<p>The region and the zone. It's often better to choose the zone closest to you to reduce latency. However, GCP services often open in the US first and become available <span>only </span>after a while in other parts of the world. Different zones may also have different rules and regulations. For instance, Europe offers stronger data related privacy laws than the US. Choose the zone as you see fit. It will always be possible to change the zone later.</p>
</li>
<li>
<p>Selecting the right<span> </span>machine<span> </span>type is important. At time of writing this book, different machines are grouped in categories as small, standard, high CPU and high RAM:</p>
<ul style="padding-left: 1px">
<li>
<p><span><strong>Small</strong>: Shared CPUs and limited RAM</span></p>
</li>
<li>
<p><span><strong>Standard VMs</strong>: 3.75 GB of RAM</span></p>
</li>
<li>
<p><span><strong>High-memory VMs</strong>: 13 GB RAM</span></p>
</li>
<li><strong>High-CPU VMs</strong>: 1.8 GB</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">The small category is perfect to get started with and build some hands-on experience with the platform. For more intense projects, you may want more more computational power or more memory.</p>
<div class="packt_infobox">Note that free-trial accounts are limited to eight CPUs.</div>
<p style="padding-left: 60px">It is also possible to customize the machine you need by setting the number of CPUs or memory per CPU you want. This is also where you choose the number of GPUs to have on your machine, as shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/097b1ed2-0dbd-49e9-a47a-7e6ac40912a4.png" style=""/></div>
<ul>
<li>Finally, you need to choose the<span> </span>OS<span> </span>for your VM. The Debian Linux distribution is offered by default. You have a choice among several OSes: Windows, CentOS, Suse, CoreOS, and Ubuntu. Although Ubuntu is often the most popular choice, there is actually little difference between Debian and Ubuntu and we will go with the default Debian distribution. If you're more familiar with the Ubuntu distribution, go for it. It should not cause any problems in this chapter.</li>
</ul>
<div class="packt_infobox">Ubuntu or Debian?<strong> </strong>Debian is one of the first Linux distributions with a first stable release in 1996. Ubuntu started as a fork, a branched out version of Debian in 2004. The two distributions are very similar, with Ubuntu being more user friendly and having a better desktop/UI experience. Debian is usually preferred for servers, a massive package library, with a strong focus on stability and open-licensed software. A stable version of Debian is released approximately every two years. The Ubuntu release cycle is six months. Ubuntu takes the unstable branch of Debian, makes customization especially in terms of the UI, and releases it. For our work, there should be close to no difference between either distribution and we will use Debian for our VMs.</div>
<p>Leave all the rest of parameters to their default choices. We will come back to HTTPs traffic, disks, networking, and <kbd>ssh</kbd> keys in a few pages.</p>
<p>One very useful feature in the web console that lowers the learning curve to mastering the GCP is the two links at the bottom of the VM creation page, <span class="packt_screen">Equivalent Rest or command line</span>, as shown in the following image:<span> </span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1a1844f3-3d0a-4c89-bda1-6b2f5475795b.png" style="width:17.00em;height:2.25em;"/> </div>
<p>The<span> </span><span class="packt_screen">command line</span><span> </span>link exists on multiple pages of the web console. It is a very useful feature to quickly learn the right syntax and parameters of the GCP command line tools.</p>
<p>Our VM is now created, up and running!</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a40c0e77-6c49-4865-b19e-bb64a8c7cb95.png"/></div>
<p>Now that we have a brand new shiny VM, how do we access it? That nicely leads us to the Google Shell.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Google Shell</h1>
                </header>
            
            <article>
                
<p>The Google Shell is Google's smart way of giving you a standalone terminal in your browser to access and manage your resources.</p>
<p>You activate the Google Shell by clicking on the<span> </span><span class="packt_screen">&gt;_</span><span> </span>icon in the upper right part of the console page:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5e055b57-d27d-470c-bf22-ec2588696e4d.png" style=""/></div>
<p>The browser window splits into half and the lower part is <span>now </span>a shell terminal:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/4b9953b4-413a-4b27-83cd-6b20c51c1755.png" style=""/></div>
<p>This terminal runs on an f1-micro GCE VM with a Debian operating system. It is created on a per user and per session basis. It persists when your Cloud Shell session is active and is deleted after 20 minutes of inactivity. The instance runs on a persistent disk with 5 GB storage. Both the disk and the image are available at no extra cost. Although the instance is not persistent across sessions, its associated disk is persistent across sessions. Everything you create via the Google Shell will be available as you've left it at the beginning of your next session. This includes all the files you store, the software you install and the configuration files you edit (<kbd>.bashrc</kbd> and <kbd>.vimrc</kbd> for instance). This disk is private and cannot be accessed by other users. And, finally, the Google Shell instance comes pre-installed with the Google Cloud SDK and other popular developer tools such as VIM.</p>
<p>Some of the commands you run via the web console will be memorized in your Google Shell VM. For instance, the SQL queries you run on a Google SQL instance, will show up in a <kbd>.mysql_history</kbd> file in your user's <kbd>$HOME</kbd> folder. More info on the Google Shell can be found in the <kbd>README-cloudshell.txt</kbd> in your <kbd>$HOME</kbd> folder.</p>
<p>From the Google Shell, you can access and manage all your resources and files. For example, let's list all our existing instances by typing:</p>
<pre><strong>$ gcloud compute instances list</strong></pre>
<p>We see our newly created sparrow instance:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ba21c51e-c467-4278-a800-0d0c1e6fbfbb.png"/></div>
<p>To access the VM you just created, type in:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute ssh sparrow</span></span></span></strong></pre>
<p>This will run through the creation of the necessary <kbd>ssh</kbd> keys. And you are now no longer on the Google's Cloud Shell VM instance but on the sparrow VM. To check which OS and version we're running in our sparrow instance, we run:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ lsb_release -d</span></span></span></strong></pre>
<p>On the sparrow machine, I have Debian GNU/Linux 9 (stretch), while on the Google Shell VM,<span> it's </span>Debian GNU/Linux 8 (jessie). Which tells me that the Google Shell is not yet on the most recent version of the Debian distribution. You may, of course, see different results.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Google Cloud Platform SDK</h1>
                </header>
            
            <article>
                
<p>GCP offers several standalone <strong>command-line interfaces</strong> (<strong>CLIs</strong>) to manage and interact with your GCP resources,<span> </span><kbd>gcloud</kbd><span> </span>being the main one. All secondary command-line tools are installed via<span> </span><kbd>gcloud</kbd>. At time of writing this, the command-line tools are:</p>
<ul>
<li><kbd>gcloud</kbd>: The main CLI to manage your GCP resources and projects: authentication, local configuration, developer workflow, and interactions with the GCP APIs. The following services can be handled via the <kbd>gcloud</kbd> CLI: app engine, auth, compute engine, container, DataFlow, Dataproc, machine learning, SQL databases as well as deployment of Cloud resources, Iam setup, and logging with Stackdriver and web resources such as DNS, Domains, or Firebase.</li>
</ul>
<p>Gcloud also takes care of other command-line tools:</p>
<ul>
<li><kbd>gsutil</kbd>: This is the CLI for Google Storage. You use <kbd>gsutil</kbd> to create and delete buckets, upload, download and move files around, set permissions, and so forth.</li>
<li><kbd>bq</kbd>: This is the CLI for interacting with BigQuery.</li>
<li><kbd>datalab</kbd>: The Datalab CLI.</li>
</ul>
<p>All these CLI tools are Python scripts and require Python 2.7 installed on your system.</p>
<p>To install <kbd>gcloud</kbd>, the best way is to follow the instructions on the Cloud DSK page at<span> </span><a href="https://cloud.google.com/sdk/downloads">https://cloud.google.com/sdk/downloads</a>. Download the right package and run the appropriate commands for your machine. The install will guide you through the creation of <kbd>ssh</kbd> keys. It will install three files in your <kbd>~/.ssh</kbd> folder. Your public and private <kbd>ssh</kbd> keys (that is, <kbd>google_compute_engine.pub</kbd> and <kbd>google_compute_engine</kbd>) and the list of know hosts (<kbd>google_compute_known_hosts</kbd>).</p>
<p>You can verify that <kbd>gcloud</kbd> is properly installed by running<span> </span><kbd>gcloud version</kbd><span> </span>in the terminal. Your output will be similar to:</p>
<pre>Google Cloud SDK 173.0.0<br/>core 2017.09.25<br/>gsutil 4.27</pre>
<p>As we can see, <kbd>gcloud</kbd> is not a one-size-fits-all tool. <kbd>gcloud</kbd> comes loaded with components. They can either be other standalone CLIs such as <kbd>gsutils</kbd>, <kbd>bq</kbd><span>,</span> <kbd>datalab</kbd> or <kbd>gcloud</kbd> extensions (<kbd>app-engine-python</kbd>), as well as Alpha and Beta release levels. To see which components are installed in your <kbd>gcloud</kbd>, run:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud components list</span></span></span></strong></pre>
<p>You will obtain the following result:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/42154b10-241f-48e4-9c48-89d7a0f1745c.png"/></div>
<p>To install or remove components in your current SDK version (173.0.0), use this:</p>
<pre><strong>$ gcloud components install COMPONENT_ID <br/>$ gcloud components remove COMPONENT_ID</strong></pre>
<p>To update your SDK installation to the latest version (175.0.0), run:</p>
<pre><strong>$ gcloud components update</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gcloud</h1>
                </header>
            
            <article>
                
<p>Let's go through a few commands to get a feel for the syntax of the <kbd>gcloud</kbd> CLI:</p>
<ul>
<li>To list all your projects, use:</li>
</ul>
<pre style="padding-left: 60px"><strong>$ gcloud projects list</strong></pre>
<ul>
<li>To list all your instances in the<span> </span><kbd>packt-gcp</kbd><span> </span>project, use:</li>
</ul>
<pre style="padding-left: 60px"><strong>$ gcloud compute instances list --project packt-gcp</strong></pre>
<p>The global generic syntax of the <kbd>gcloud</kbd> that also applies the other CLI tools is:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud GROUP | COMMAND parameters</span></span></span></strong></pre>
<p>Where<span> </span><kbd>GROUP</kbd><span> </span>is a service or an account element and<span> </span><kbd>COMMAND</kbd><span> </span>is the command to send to the<span> </span><kbd>GROUP</kbd>. For instance in<span> </span><kbd>gcloud projects list</kbd>,<span> </span><kbd>projects</kbd><span> </span>is the <kbd>GROUP</kbd>, an element of your account and<span> </span><kbd>list</kbd><span> </span>is the <kbd>COMMAND</kbd>. In<span> </span><kbd>gcloud compute instances list --project packt-gcp</kbd><span>, </span>the <kbd>GROUP</kbd> is<span> </span><kbd>compute</kbd>, followed by a sub-group<span> </span><kbd>instances</kbd>, and the <kbd>COMMAND</kbd> is<span> </span><kbd>list</kbd><span> </span>while<span> </span><kbd>--project packt-gcp</kbd><span> </span>are the required parameters.</p>
<p>gcloud parameters include account settings (keys and region for instance), CLI settings (verbosity, format, or specific configuration) as well as arguments required by the commands. For example, to start our instance, we need to specify two parameters—the region and the instance ID:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute instances start sparrow  --project packt-gcp --zone us-east1-d</span></span></span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gcloud config</h1>
                </header>
            
            <article>
                
<p>To avoid having to specify the zone or other parameters, you can set them in the <kbd>config</kbd> with:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud config set compute/zone us-east1-d</span></span></span></strong></pre>
<p>And to unset them in the <kbd>config</kbd>, you can use the following:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud config unset compute/zone</span></span></span></strong></pre>
<p>For a list of all the different settings available in the <kbd>config</kbd>, run<span> </span><kbd>gcloud config set --help</kbd>.</p>
<p>The zone and region can be also stored in the environment variable <kbd>CLOUDSDK_COMPUTE_ZONE</kbd> and <kbd>CLOUDSDK_COMPUTE_REGION</kbd>. Environment variables override default properties that you set with the <kbd>gcloud</kbd> <kbd>config</kbd> commands, but do not override explicit flags like <kbd>--zone</kbd> or <kbd>--region</kbd>.</p>
<p>To set the environment variable <kbd>CLOUDSDK_COMPUTE_ZONE</kbd>, run or add this line to your <kbd>.bashrc</kbd>:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ export CLOUDSDK_COMPUTE_ZONE=us-east1-c</span></span></span></strong></pre>
<p>For more details, see<span> </span><a href="https://cloud.google.com/compute/docs/gcloud-compute/#set_default_zone_and_region_in_your_local_client">https://cloud.google.com/compute/docs/gcloud-compute/#set_default_zone_and_region_in_your_local_client</a>.<a href="https://cloud.google.com/compute/docs/gcloud-compute/#set_default_zone_and_region_in_your_local_client"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Accessing your instance with gcloud</h1>
                </header>
            
            <article>
                
<p>There are two important things you want to do from the start:</p>
<ul>
<li>Accessing the instance</li>
<li>Moving files between your instance and another machine. To do <kbd>ssh</kbd> into your instance, run:</li>
</ul>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute ssh &lt;instance_name&gt;</span></span></span></strong></pre>
<p style="padding-left: 60px">In our case:</p>
<pre style="padding-left: 60px"><strong>$ gcloud compute ssh sparrow</strong></pre>
<p>The first time you access your instance from your local system, the platform will<span> </span>propagate<span> </span>your keys to the instance, which may take a few minutes. Once connected, you can verify that your local public key (<kbd>cat ~/.ssh/google_compute_engine.pub</kbd>) is included in the list of <kbd>authorized_keys</kbd> on your instance (<kbd>cat ~/.ssh/authorized_keys</kbd>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Transferring files with gcloud</h1>
                </header>
            
            <article>
                
<p>Transferring files back and forth from your machine (or any other location) and your instance is done via Gcloud's version of the <kbd>.csp</kbd> command:</p>
<ul>
<li>To send a local file to your instance <kbd>$HOME</kbd> folder:</li>
</ul>
<pre style="padding-left: 60px"><strong>$ gcloud compute scp ~/LOCAL-FILE<span> </span>:~/</strong></pre>
<ul>
<li>For instance, to send a file titled <kbd>hello_world.txt</kbd> to sparrow, you would run this:</li>
</ul>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute scp ~/hello_world.txt  sparrow:~/</span></span></span></strong></pre>
<ul>
<li>Similarly, to download a file from the instance to your local machine <kbd>$HOME</kbd> folder:</li>
</ul>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute scp  &lt;instance-name&gt;:~/REMOTE-FILE ~/</span></span></span></strong></pre>
<p>We will explore the <kbd>gsutil</kbd> and <kbd>bq</kbd> command-line tools in the next chapter and the Datalab CLI in <a href="862553c5-4bb7-4a5c-b7bd-03f0eb8d413e.xhtml" target="_blank">Chapter 4</a>, <em>Querying Your data with BigQuery</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Managing the VM</h1>
                </header>
            
            <article>
                
<p>There are several operations that you will want to do as you start working with a VM on Google Compute, such as starting instances, stopping instances, resizing and modifying disks, and taking snapshots. We go over the most important ones:</p>
<ol>
<li>Start and shut down the VM:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ gcloud compute instances start sparrow --project packt-gcp </strong><br/><strong>$ gcloud compute instances stop sparrow --project packt-gcp</strong></pre>
<ol start="2">
<li>Check the VM status:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ gcloud compute instances list --project packt-gcp</strong></pre>
<p>The instance we started with is an f1-micro with not-enough CPU, RAM, or disk space for a real-world data science project. We want to change the underlying machine and augment its disk space. But, before that, we should take a snapshot of our current machine as a backup. If anything goes wrong, we'll be able to restore the instance from the snapshot:</p>
<ol>
<li><span>Taking a snapshot of a VM:</span></li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>$ gcloud compute disks snapshot [DISK_NAME]</strong></pre>
<ol start="2">
<li>In our case, let's call our disk<span> </span><kbd>sparrow-backup</kbd><span> </span>as we run:</li>
</ol>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute disks snapshot sparrow-backup --project packt-gcp</span></span></span></strong></pre>
<ol start="3">
<li>Changing the machine type, you first need to stop your instance with<span> </span><kbd>$ gcloud compute instances stop sparrow --project packt-gcp</kbd><span>. Once that's done, changing the machine type is doable with the generic command:</span></li>
</ol>
<pre style="padding-left: 60px"><strong>$ gcloud compute instances set-machine-type INSTANCE --machine-type MACHINE-TYPE</strong></pre>
<ol start="4">
<li>In our case, if we want to change the type to <kbd>n1-standard-1</kbd> (3.75 GB memory and 1 vCPU), we should run this:</li>
</ol>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute instances set-machine-type sparrow --machine-type n1-standard-1</span></span></span></strong></pre>
<ol start="5">
<li>While we're at it, we would also like to resize the underlying disk from 10 GB to 100 GB:</li>
</ol>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute disks resize sparrow --size 100</span></span></span></strong></pre>
<ol start="6">
<li>Another important setting is to make sure that the disk will not be deleted when the instance is deleted:</li>
</ol>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute instances set-disk-auto-delete</span></span></span></strong></pre>
<p style="padding-left: 60px">This is an important parameter that can also be set in the compute engine console by unselecting <span class="packt_screen">Delete boot disk when instance is deleted</span> when creating or editing an instance:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f08c0a52-e038-4c69-9f7a-30c0f9c36661.png" style=""/></div>
<ol start="7">
<li>Instance configuration: The entire instance configuration is available via <kbd>$ gcloud</kbd> <span>compute instances describe sparrow.</span></li>
<li>Creating the right VM from scratch: in this all these parameters are available when you create a VM from scratch. Running the following command will create a new<span> </span><kbd>n1-standard-1</kbd> <span>instance named</span> <kbd>hummingbird</kbd> <span>in the</span> <kbd>europe-west1-c</kbd> <span>zone, when running on</span> Ubuntu 17.04<span>, with a</span> 100 GB <span>disk also named</span> <kbd>hummingbird</kbd><span>. Note that this instance is</span> pre-emptible <span>(</span><kbd>--preemptible</kbd><span>) and the disk will persist once the instance is deleted (</span><kbd>--no-boot-disk-auto-delete</kbd><span>):</span></li>
</ol>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute --project packt-gcp instances create hummingbird \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--zone europe-west1-c --machine-type n1-standard-1 \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--image ubuntu-1704-zesty-v20171011 --image-project ubuntu-os-cloud \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--boot-disk-size 100  --boot-disk-type "pd-standard"  \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--boot-disk-device-name hummingbird \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--preemptible --no-boot-disk-auto-delete</span></span></span></strong></pre>
<p>We can verify that we now have two instances in our project:</p>
<p>To keep our resources under control, we should delete this new instance with:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute instances stop hummingbird --zone europe-west1-c  --project packt-gcp</span></span></span></strong></pre>
<p>Note that if you have set up a different zone as default either in the <kbd>config</kbd> setup or as an environment variable, you need to specify the zone of the instance before you can delete it; otherwise, a <kbd>resource not found</kbd> error message will be generated.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IPs</h1>
                </header>
            
            <article>
                
<p>You must have noticed the presence of an internal and an external IP associated with our VMs. Each GCP project comes with a <strong>Virtual Private Cloud</strong> (<strong>VPC</strong>) network, which is automatically created with the project. A VPC is basically a private and isolated virtual network partition that enables your resources to talk to each other within a given project, while allowing control of external access to the VPC. Upon creation, each instance gets an internal IP address <span>assigned </span>to allow other resources within the project's VPC to communicate with the instance. To communicate with entities outside the VPC, including connections with the internet, the instance requires an external IP address.</p>
<p>IP addresses, both internal and external, can be ephemeral or static. Ephemeral IP addresses remain associated with the instance <span>only</span><span> </span><span>as long as the instance is running. When the instance stops or is terminated, the IP address is released in the global GCP pool of IP addresses. For an instance to have a stable IP address, the IP address needs to become static. Static addresses generate extra costs.</span></p>
<p>Changing the nature of an IP address from ephemeral to static can be done via the console. Stop the VM and edit it. In the <span class="packt_screen">Network interface</span> section, select the right type for the internal and external IPs of the VM:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/05cdf268-94bc-4386-b5a4-f6db44cbd2a2.png" style=""/></div>
<p>The management of IPs and VPCs is accessible from the VPC network console at<span> </span><a href="https://console.cloud.google.com/networking/networks/list">https://console.cloud.google.com/networking/networks/list</a>.<a href="https://console.cloud.google.com/networking/networks/list"/></p>
<p>You can create a new static IP address and then attach it to your instance directly from the <span class="packt_screen">External IP addresses</span> page:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/fa901139-ba02-475f-9b00-eb1939e74e62.png" style=""/></div>
<p>Click on <span class="packt_screen">Reserve a static address</span>, select regional for region type, set the region to your instance's region, and attach it to your sparrow instance:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c67cd3a2-8491-4dcd-b03d-c4aeb9176d5d.png" style=""/></div>
<p>The command-line equivalent of creating a static IP and adding it to the instance is:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute --project=packt-gcp addresses create sparrow-notebook --region=us-east1<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute --project=packt-gcp instances add-access-config sparrow --zone=us-east1-d --address=IP_OF_THE_NEWLY_CREATED_STATIC_ADDRESS</span></span></span></strong></pre>
<p>As static IPs are billed even when not used, it is important to release them when no longer needed.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up a data science stack on the VM</h1>
                </header>
            
            <article>
                
<p>So, <span>now </span>we have a VM running and we're able to send files to it, connect to it, and modify it. Everything is ready for us to set it up for data science!</p>
<p>We will install the Python Miniconda stack from continuum, much smaller than the full Conda distribution. Do SSH into your instance.</p>
<ol>
<li>Install the mini <kbd>sudo apt-get update sudo apt-get install bzip2 wget</kbd><span> from </span><a href="https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh">https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh</a><span> using the following command:</span></li>
</ol>
<pre style="padding-left: 60px"><strong>bash Miniconda2-latest-Linux-x86_64.sh</strong></pre>
<ol start="2">
<li>And then install the Python stack with <kbd>conda</kbd>:</li>
</ol>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ conda install scikit-learn pandas jupyter ipython</span></span></span></strong></pre>
<p style="padding-left: 60px">Don't forget to do this:</p>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ source .bashrc</span></span></span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">BOX the ipython console</h1>
                </header>
            
            <article>
                
<p>To launch a Jupyter Notebook in your instance and access it over the Web, you need to promote the ephemeral external IP address provided by default to your VM to a static external IP.</p>
<p>You also need to make sure that your instance is accepting HTTP and HTTPS traffic. For that, go to your VM page, edit it, and check the following checkboxes:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6ba3f1e3-fea0-41eb-ac82-cad5527409a6.png" style=""/></div>
<p>Since your Jupyter Notebook is open to all traffic on the web, you password-protect it:</p>
<ol>
<li>
<p>Generate a configuration:</p>
</li>
</ol>
<pre style="padding-left: 60px"><strong>$ jupyter notebook --generate-config</strong></pre>
<ol start="2">
<li>And add a password with:</li>
</ol>
<pre style="padding-left: 60px"><strong>$ jupyter notebook password</strong></pre>
<p style="padding-left: 60px">More info on how to protect your public Notebook, including using <kbd>ssh</kbd> keys and adding encryption, is available at<span> </span><a href="http://jupyter-notebook.readthedocs.io/en/latest/public_server.html">http://jupyter-notebook.readthedocs.io/en/latest/public_server.html</a>.<a href="http://jupyter-notebook.readthedocs.io/en/latest/public_server.html"/></p>
<ol start="3">
<li>Launch your Jupyter Notebook with:</li>
</ol>
<pre class="line" style="padding-left: 60px"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser &amp;</span></span></span></strong></pre>
<p style="padding-left: 60px">This generates a token and the following message:</p>
<pre style="padding-left: 60px">The Jupyter Notebook is running at:<span> </span>http://0.0.0.0:8888/?token=7b1deb1b1467a3b3c9c23946e2f2efa12d9dc2c258353660<br/>and access it in your browser via<span> </span>http://104.196.129.173:8888/?token=7b1deb1b1467a3b3c9c23946e2f2efa12d9dc2c258353660</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Troubleshooting</h1>
                </header>
            
            <article>
                
<p>There is an alternative solution if you encounter problems in accessing your Notebook. The idea is to launch the Jupyter Notebook with IP <kbd>0.0.0.0</kbd>, without having to set up a static IP first:</p>
<pre class="line"><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser</span></span></span></pre>
<p>This will generate a token. Do SSH into another terminal, adding the following flags <kbd>--ssh-flag="-L" --ssh-flag="2222:localhost:8888"</kbd>:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute ssh sparrow --ssh-flag="-L" --ssh-flag="2222:localhost:8888"</span></span></span></strong></pre>
<p>This is how it associates the URL <kbd>localhost:2222</kbd> with the Jupyter Notebook URL <kbd>localhost:8888</kbd>. You can then access your Notebook at<span> </span><kbd>http://localhost:2222</kbd>. You also need to enter the token you were given a moment ago.</p>
<p>This alternative was given by the comments on this blog post by Jeff Delaney,<span> </span><em>Running a Python Jupyter Notebook on Google Cloud Engine</em><span>: </span><a href="https://jeffdelaney.me/blog/running-jupyter-notebook-google-cloud-platform/">https://jeffdelaney.me/blog/running-jupyter-notebook-google-cloud-platform/</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding GPUs to instances</h1>
                </header>
            
            <article>
                
<p>Check and request for an increase in your quotas for GPUs:</p>
<ul>
<li>Search for GPU. If you have 0 in your allocated quotas, select the type of GPU and region and click on edit the quotas. Fill in the request form<span> (</span><a href="https://console.cloud.google.com/iam-admin/quotas?project=packt-gcp">https://console.cloud.google.com/iam-admin/quotas?project=packt-gcp</a>).</li>
</ul>
<p>There are several restrictions when it comes to using GPUs on Google Compute. GPUs are not available in shared or pre-emptible machines. GPU instances are terminated for regular (weekly) maintenance events. See<span> </span><a href="https://cloud.google.com/compute/docs/gpus/">https://cloud.google.com/compute/docs/gpus/</a><span> </span>for up-to-date information on the restrictions. See also<span> </span><a href="https://cloud.google.com/compute/docs/gpus#introduction">https://cloud.google.com/compute/docs/gpus#introduction</a><span> </span>to learn what machine types are available based on your desired GPU count.</p>
<p>To create a VM with GPU from the console:</p>
<ol>
<li>Go to the VM console and click on <span class="packt_screen">Create Instance</span></li>
<li>Select a zone that is GPU compatible</li>
<li>Click on customize the machine type and again on the GPUs link</li>
<li>Select the <span class="packt_screen">Number of GPUs</span> and the associated type you require:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2926c6ff-6316-4560-aa7e-95df0b25f364.png" style=""/></div>
<p>Similarly you can create a GPU-enabled instance with <kbd>gcloud</kbd> with the following command:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute instances create [INSTANCE_NAME] \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--machine-type [MACHINE_TYPE] --zone [ZONE] \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--accelerator type=[ACCELERATOR_TYPE],count=[ACCELERATOR_COUNT] \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--image-family [IMAGE_FAMILY] --image-project [IMAGE_PROJECT] \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--maintenance-policy TERMINATE --restart-on-failure \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--metadata startup-script='[STARTUP_SCRIPT]'</span></span></span></strong></pre>
<p>Where <kbd>--accelerator type= specifies</kbd> the type of GPU and <kbd>count=</kbd> specifies the number of GPUs.</p>
<p>For instance, this command will create an Ubuntu 1604 instance with one NVIDIA® Tesla® K80 GPU and two vCPUs in the <kbd>us-east1-d</kbd> zone. The startup-script metadata instructs the instance to install the CUDA toolkit with its recommended driver version:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute instances create gpu-instance-1 \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--machine-type n1-standard-2 --zone us-east1-d \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--accelerator type=nvidia-tesla-k80,count=1 \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--image-family ubuntu-1604-lts --image-project ubuntu-os-cloud \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--maintenance-policy TERMINATE --restart-on-failure \<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>--metadata startup-script='#!/bin/bash<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>echo "Checking for CUDA and installing."<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span># Check for CUDA and try to install.</span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>if ! dpkg-query -W cud<br/>a-8-0; then<br/></span></span></span><span class="syntax--text syntax--plain"><span>  </span><span class="syntax--meta syntax--paragraph syntax--text"><span>curl -O </span><span class="syntax--markup syntax--underline syntax--link syntax--http syntax--hyperlink"><span>http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb<br/></span></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>  dpkg -i ./cuda-repo-ubuntu1604_8.0.61-1_amd64.deb<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>  apt-get update<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>  apt-get install cuda-8-0 -y<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>fi'</span></span></span></strong></pre>
<p>The startup script installs the right CUDA driver for the Ubuntu. For other drivers and operating systems, follow the instructions at<span> </span><a href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a>.</p>
<p>Once the driver has finished installing, you can verify that it is properly installed:</p>
<ol>
<li>Do <kbd>ssh</kbd> into your instance</li>
<li>Type <kbd>nvidia-smi</kbd> to see your driver version and how much GPU memory you have</li>
</ol>
<p>The command <kbd>nvcc --version</kbd> shows the current CUDA version.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Startup scripts and stop scripts</h1>
                </header>
            
            <article>
                
<p>Startup scripts allow you to run a script when starting up or creating an instance. For instance, to always install <kbd>miniconda</kbd> and related data science packages when creating a new instance, simply write the following script in a file on your local machine:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>#! /bin/bash<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>apt-get install bzip2<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>wget </span><span class="syntax--markup syntax--underline syntax--link syntax--https syntax--hyperlink"><span>https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh<br/></span></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>sudo bash Miniconda2-latest-Linux-x86_64.sh<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>conda install scikit-learn<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>conda install pandas<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>conda install jupyter<br/></span></span></span><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>conda install ipython</span></span></span></strong></pre>
<p>Then as you start the new instance, supply the <kbd>--metadata-from-file</kbd> flag, followed by <kbd>startup-script=PATH/TO/FILE</kbd>, where <kbd>PATH/TO/FILE</kbd> is a relative path to the startup script:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute instances create example-instance --metadata-from-file startup-script=examples/scripts/install.sh</span></span></span></strong></pre>
<p>You can also use a startup script in extension in the command line or from a file stored in Google Storage. For more on startup scripts, visit <a href="https://cloud.google.com/compute/docs/startupscript">https://cloud.google.com/compute/docs/startupscript</a>.</p>
<p>Stop scripts are scripts that are automatically run when an instance is terminated or restarted. Similar to startup scripts, you can associate a stop script with an instance at creation by adding the <kbd>--metadata-from-file flag</kbd>, followed by <kbd>shutdown-script=PATH/TO/FILE</kbd>:</p>
<pre class="line"><strong><span class="syntax--text syntax--plain"><span class="syntax--meta syntax--paragraph syntax--text"><span>$ gcloud compute instances create example-instance --metadata-from-file shutdown-script=examples/scripts/shutdown.sh</span></span></span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Resources and further reading</h1>
                </header>
            
            <article>
                
<p>The following are a few interesting articles on setting TensorFlow on GCE:</p>
<ul>
<li><strong>Running distributed TensorFlow on Compute Engine</strong>:<span> </span><a href="https://cloud.google.com/solutions/running-distributed-tensorflow-on-compute-engine">https://cloud.google.com/solutions/running-distributed-tensorflow-on-compute-engine</a></li>
<li><strong>Jupyter + TensorFlow + Nvidia GPU + Docker + GCE</strong>:<span> </span><a href="https://medium.com/google-cloud/jupyter-tensorflow-nvidia-gpu-docker-google-compute-engine-4a146f085f17">https://medium.com/google-cloud/jupyter-tensorflow-nvidia-gpu-docker-google-compute-engine-4a146f085f17</a></li>
<li><strong>Using a GPU and TensorFlow on GCP</strong>:<span> </span><a href="https://medium.com/google-cloud/using-a-gpu-tensorflow-on-google-cloud-platform-1a2458f42b0">https://medium.com/google-cloud/using-a-gpu-tensorflow-on-google-cloud-platform-1a2458f42b0</a></li>
<li><strong>Running Jupyter Notebooks on GPU on Google Cloud</strong>:<span> </span><a href="https://medium.com/google-cloud/running-jupyter-notebooks-on-gpu-on-google-cloud-d44f57d22dbd">https://medium.com/google-cloud/running-jupyter-notebooks-on-gpu-on-google-cloud-d44f57d22dbd</a></li>
</ul>
<p>Some docker-related resources:</p>
<ul>
<li><strong>Docker config to create machines on GCE</strong>:<span> </span><a href="https://docs.docker.com/machine/drivers/gce/">https://docs.docker.com/machine/drivers/gce/</a></li>
<li><strong>Logging with stackcriver</strong>:<span> </span><a href="https://medium.com/google-cloud/how-to-log-your-application-on-google-compute-engine-6600d81e70e3">https://medium.com/google-cloud/how-to-log-your-application-on-google-compute-engine-6600d81e70e3</a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>The GCE is a GCP core service, offering a wide variety of scalable VMs based on different OSes. The multiplicity of available OSes, the range of machines with CPUs, GPUs, small to huge disk space, and RAM make the GCE a powerful Cloud environment adapted to a wide variety of projects and contexts.</p>
<p>In this chapter you learned:</p>
<ul>
<li><span>How to c</span>reate, launch, back up, modify, and access multiple VMs</li>
<li>The different parameters and variables related to a VM</li>
<li><span>How to a</span>ccess and use the Google Shell</li>
<li><span>How to u</span>se the <kbd>gcloud</kbd> CLI to carry out the same operations in the GCP</li>
<li><span>How to i</span>nstall a data science Python stack</li>
<li><span>How to </span>launch a Jupyter Notebook</li>
</ul>
<p>There are many more possibilities offered by the power and flexibility of the GCE that we haven't covered. Hopefully, by the end of this chapter, you should feel comfortable working with instances that are appropriate for your projects in a data-focused context.</p>
<p>In the next chapter, we will learn how to store data on the GCP with Google Storage and Google SQL.</p>


            </article>

            
        </section>
    </body></html>