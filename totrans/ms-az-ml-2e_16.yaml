- en: '*Chapter 13*: Building a Recommendation Engine in Azure'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed distributed training methods for ML models,
    and you learned how to train distributed ML models efficiently in Azure. In this
    chapter, we will dive into traditional and modern recommendation engines, which
    often combine technologies and techniques covered in the previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will take a quick look at the different types of recommendation engines,
    what data is needed for each type, and what can be recommended using these different
    approaches. This will help you understand when to choose from non-personalized,
    content-based, or rating-based recommenders.
  prefs: []
  type: TYPE_NORMAL
- en: After this, we will dive into content-based recommendations, namely item-item
    and user-user recommenders, based on feature vectors and similarity. You will
    learn about cosine distance to measure the similarity between feature vectors
    and feature engineering techniques to avoid common pitfalls while building content-based
    recommendation engines.
  prefs: []
  type: TYPE_NORMAL
- en: Subsequently, we will discuss rating-based recommendations that can be used
    once enough user-item interaction data has been collected. You will learn the
    difference between implicit and explicit ratings, develop your own implicit metric
    function, and think about the recency of user ratings.
  prefs: []
  type: TYPE_NORMAL
- en: In the section following this, we will combine content- and rating-based recommenders
    into a single hybrid recommender and learn about state-of-the-art techniques for
    modern recommendation engines. You will implement two recommenders using Azure
    Machine Learning, one using Python and one using Azure Machine Learning designer
    – the graphical UI of Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: In the last section, we will look into an online recommender system as a service
    using reinforcement learning – Azure Personalizer. Having understood both content-
    and rating-based methods, you will learn how to improve your recommendations on
    the fly using a fitness function and online learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to recommendation engines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A content-based recommender system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborative filtering – a rating-based recommender system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining content and ratings in hybrid recommendation engines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic optimization through reinforcement learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will use the following Python libraries and versions to
    create content- and rating-based recommendation engines, as well as hybrid and
    online recommenders:'
  prefs: []
  type: TYPE_NORMAL
- en: '`azureml-core 1.34.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`azureml-sdk 1.34.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numpy 1.19.5`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scipy 1.7.1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pandas 1.3.2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`scikit-learn 0.24.2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lightgbm 3.2.1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pyspark 3.2.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`azure-cognitiveservices-personalizer 0.1.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similar to previous chapters, you can run this code using either a local Python
    interpreter or a notebook environment hosted in Azure Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: For the Matchbox recommender example, you need to use Azure Machine Learning
    designer in your Azure Machine Learning workspace. For Azure Personalizer, you
    need to set up an Azure Personalizer resource in the Azure portal.
  prefs: []
  type: TYPE_NORMAL
- en: 'All code examples in this chapter can be found in the GitHub repository for
    this book: [https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter13](https://github.com/PacktPublishing/Mastering-Azure-Machine-Learning-Second-Edition/tree/main/chapter13).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to recommendation engines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In today's digital world, recommendation engines are ubiquitous among many industries.
    Many online businesses, such as streaming, shopping, news, and social media, rely
    at their core on recommending the most relevant articles, news, and items to their
    users. How often have you clicked on a suggested video on YouTube, scrolled through
    your Facebook feed, listened to a personalized playlist on Spotify, or clicked
    on a recommended item on Amazon?
  prefs: []
  type: TYPE_NORMAL
- en: If you ask yourself what the term *relevant* means for the different services
    and industries, you are on the right track. In order to recommend relevant information
    to the user, we need to first define a relevancy metric, and a way to describe
    and compare different items and their similarity. These two properties are the
    key to understanding the different recommendation engines. We will learn more
    about this in the following sections of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: While the purpose of a recommendation engine is clear to most people, the different
    approaches are usually not. Hence, in order to better understand this, in this
    chapter, we will compare the different types of recommender systems and give some
    examples of them that you might have seen in your daily life. It's also worth
    mentioning that many services implement more than one of these approaches to produce
    great recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest recommendation engines and methods are *non-personalized* recommendations.
    They are often used to show global interest (for example, Twitter global trends,
    popular Netflix shows, and a news website's front page) or trends where no user
    data is available. A good example is the recommendations of any streaming service
    that appear when you register and log into the service for the first time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you log into a web service and start using it moderately, you are usually
    confronted with *content-based recommendations*. Content-based recommenders look
    for similar items or items of similar users, based on the item and user profile
    features. User profile items can contain many personality-based or socio-demographic
    traits including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Age
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gender
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nationality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Country of residence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mother tongue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Imagine logging into Amazon without having bought anything there yet. Most recommended
    items will be similar to the ones you just viewed or the ones matching your demographics
    and location.
  prefs: []
  type: TYPE_NORMAL
- en: Once enough interaction data is available, you will start seeing *rating-based
    recommendations*, a method that is also called collaborative filtering. In rating-based
    recommenders, the users' interactions with items are transformed into explicit
    or implicit ratings. Based on these ratings, recommendations are made based on
    similar recommendations given by other users. Rating a movie on Netflix is an
    explicit rating, while watching a full 20-minute documentary on YouTube is an
    implicit rating. Therefore, a user will be shown movies liked by other people
    who also liked the movie that you just rated. And similarly, YouTube will show
    videos watched by other users who also watched the video you just saw.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft provides many different implementations for popular recommendation
    engines in their GitHub repository at [https://github.com/Microsoft/Recommenders/](https://github.com/Microsoft/Recommenders/).
    This makes it easy to get started, pick the right algorithm, and implement, train,
    and deploy a recommendation engine on Azure.
  prefs: []
  type: TYPE_NORMAL
- en: The next natural step is to combine both content- and rating-based recommenders
    into a single *hybrid recommendation engine* that can deal with both user ratings
    and cold-start users, who are users without ratings. The benefit of this approach
    is that both recommender systems are optimized together and create a combined
    recommendation. Azure Machine Learning Studio (classic) and Azure Machine Learning
    designer provide the building blocks to train and deploy the Matchbox recommender,
    an online Bayesian hybrid recommendation engine built by Microsoft Research.
  prefs: []
  type: TYPE_NORMAL
- en: Another exciting new development in the past year was the introduction of hybrid
    online recommender optimization based on reinforcement learning. By providing
    a fitness function for the user rating, the algorithm can continuously learn to
    optimize this function. In the last section of this chapter, we will take a look
    at Azure Personalizer, a reinforcement learning-based recommendation engine as
    a service.
  prefs: []
  type: TYPE_NORMAL
- en: Let's dive right into the methods discussed and develop some example solutions
    for scalable recommendation engines in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: A content-based recommender system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We first start with content-based recommendations, as they are the most similar
    to what we previously discussed in this book. The term *content* refers to the
    usage of only an item's or user's content information in the shape of a (numeric)
    feature vector. The way to arrive at a feature vector from an item (an article
    in a web shop) or a user (a browser session in a web service) is through data
    mining, data pre-processing, and feature engineering – skills you learned in the
    previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using users'' and items'' feature vectors, we can divide content-based recommendations
    into roughly two approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Item-item similarity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-user similarity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hence, recommendations are based on the similarity of items or the similarity
    of users. Both approaches work great in cases where little to no interaction data
    between user and items is available (for example, a user with no purchase history
    on Amazon, no search history on YouTube, or no movies yet watched on Netflix –
    the so-called cold-start problem).
  prefs: []
  type: TYPE_NORMAL
- en: You will always have to deal with the cold-start problem the moment you decide
    to roll out recommendations or the moment a new user starts using your service.
    In both cases, you don't have sufficient user-item interactions (so-called ratings)
    available and need to recommend items based on content only.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the first approach, we design a system that recommends similar items to
    the one a user currently interacts with. When a user looks at an item, the recommender
    returns the most similar items. The item similarity is based on the similarity
    of the item''s feature vectors – we will see in the subsequent section how to
    compute this similarity. This approach can be used when no or little user interaction
    data is available. *Figure 13.1* visualizes this approach of recommending similar
    items based on content features and a single user interaction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – Finding similar products using a content-based recommendation
    ](img/B17928_13_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – Finding similar products using a content-based recommendation
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a playlist on Spotify will yield a box with recommended songs at the
    bottom, as shown in *Figure 13.2*. We can see that the recommended songs are based
    on the songs in the playlist; hence, it is similar content:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2 – Spotify''s recommended songs ](img/B17928_13_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – Spotify's recommended songs
  prefs: []
  type: TYPE_NORMAL
- en: We can see songs listed that are similar to the ones in the playlist – similar
    in terms of genre, style, artists, and many more features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Clicking on a product on Amazon will yield a box with related products at the
    bottom of the page, as shown in *Figure 13.3*. Again, similar products mean it
    is a content-based recommendation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – Amazon''s recommended products ](img/B17928_13_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – Amazon's recommended products
  prefs: []
  type: TYPE_NORMAL
- en: This recommendation has nothing to do with your previous shopping experience
    and can be displayed even when no user-purchase history is found.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the second approach, the system recommends similar users based on a user
    profile. From those similar users, we can then select the favorite items and present
    them as a recommendation. Please note that in digital systems, the user profile
    can be implicitly defined via location (for example, through an IP address), language,
    demographic, and device fingerprinting. This technique can be used when user-item
    interaction data is available from other users but not for the current user. *Figure
    13.4* visualizes this recommendation of the purchases of a similar user based
    on content features:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – Finding similar users using a content-based recommendation
    ](img/B17928_13_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – Finding similar users using a content-based recommendation
  prefs: []
  type: TYPE_NORMAL
- en: From a user's perspective, it is usually hard to distinguish between this kind
    of recommendation and a non-personalized recommendation (for example, the top
    products in your location for your demographic or your language – all properties
    that can be extracted from your browser's fingerprint).
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the similarity between items
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The crucial part of training a content-based recommendation engine is to specify
    a metric that can measure and rank the similarity between two items. A popular
    choice is to use the **cosine similarity** or **cosine distance** between the
    items'' feature vectors to measure the similarity between two items. The *cosine
    similarity* is computed as the cosine of the angle between two vectors where a
    vector is an observation in the dataset. The *cosine distance* is computed as
    1 minus the cosine similarity. *Figure 13.5* shows two numeric feature vectors
    and the cosine distance between the feature vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.5 – Cosine distance ](img/B17928_13_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.5 – Cosine distance
  prefs: []
  type: TYPE_NORMAL
- en: We can see in the figure that if both vectors are the same, the cosine distance
    between the two vectors is 0\. On the other hand, the cosine similarity yields
    1 when both vectors are pointing in the same direction, and 0 when both vectors
    are orthogonal to each other; hence, there is no similarity between the observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are unsure, you can always compute the cosine distance or similarity
    between two feature vectors using the following code (make sure that your DataFrame
    (`df`) has no additional `id` column and all columns are numeric):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Looking at the preceding snippet, I recommend you pick a few rows from your
    dataset, estimate their similarity (1 if they are the same or 0 if they are completely
    different), and then compute the cosine similarity using the aforementioned approach.
    If your guess and the computed approach are very different and you don't understand
    the reason, you'd better go back to data pre-processing and feature engineering.
    In the next section, you will learn the most common mistakes in feature engineering
    for recommender systems.
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering for content-based recommenders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Training a content-based recommendation engine is very similar to training a
    classical ML model. For end-to-end ML pipelines, all the steps, such as data preparation,
    training, validation, optimization, and deployment, are the same and use very
    similar or even the same tools and libraries as any traditional embedding, clustering,
    regression, or classification technique.
  prefs: []
  type: TYPE_NORMAL
- en: As for most other ML algorithms, great feature engineering is the key to good
    results from a recommendation engine. The difficulty for clustering-based recommenders
    is that most embeddings and similarity metrics only work in numeric space. While
    other techniques, such as tree-based classifiers, give you more freedom in the
    structure of input data, many clustering techniques require numeric features.
  prefs: []
  type: TYPE_NORMAL
- en: Another important factor for training content-based recommenders is the semantic
    meaning of categorical features. Therefore, you most likely want to use advanced
    natural language processingmethods to embed categorical features into numerical
    space to capture this semantic meaning and provide it for the recommendation engine.
    The reason for the effect of categorical features in recommendation systems is
    based on the way similarity is measured.
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in the previous section, a similarity is often expressed/measured
    as the cosine similarity and, hence, computing the cosine between two feature
    vectors. Therefore, even if there is only a single different character between
    two categorical values, those categorical values would yield a similarity of 0
    using one-hot encoding – although they are semantically very similar. Using simple
    label encoding, the results are even less obvious. With label encoding, the resulting
    similarity is now not only 0 but a non-interpretable value different from 0.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we recommend semantic embedding of nominal/textual variables in order
    to capture their semantic meaning in numeric space and avoid common pitfalls,
    with categorical embeddings leaking into the similarity metric.
  prefs: []
  type: TYPE_NORMAL
- en: In general, there are two possible ways to implement content-based recommenders.
    If you are looking for a pure similarity, you can use any non-supervised embedding
    and clustering technique for finding similar items or users. The second possibility
    is to implement the recommender as a regression or classification technique. With
    this, you can predict a discrete or continuous value of relevance for all items,
    only considering item features or combinations of an item and user features. We
    will take a look at an example method in the subsequent section.
  prefs: []
  type: TYPE_NORMAL
- en: Content-based recommendations using gradient boosted trees
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For our content-based model, we will use the *Criteo dataset* to predict the
    **Click-Through Rate** (**CTR**) per article, based on article features. We will
    use the predicted CTR to recommend articles with the highest predicted CTR. As
    you can see, it's very simple to formulate a content-based recommendation engine
    as a standard classification or regression problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we will use a gradient-boosted tree regressor from LightGBM.
    The model to predict the CTR is very similar to any regression model previously
    trained in this book. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we define the parameters for the LightGBM model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we define the training and test set as LightGBM datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using this information, we can now train the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can evaluate the model performance by predicting the CTR and computing
    the area under the ROC curve as an error metric:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Great! You have learned to create recommendations based on item similarities.
    However, these recommendations have a poor diversity and will only recommend similar
    items. Therefore, they can be used when no user-item interaction data is available
    but will perform poorly once the user is active on your service. A better recommendation
    engine would recommend a variety of different items to help users explore and
    discover new and unrelated items they might like. This is exactly what we will
    do with collaborative filtering in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering – a rating-based recommender system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By recommending only similar items or items from similar users, your users might
    get bored of the recommendations provided due to the lack of diversity and variety.
    Once a user starts interacting with a service (for example, watching videos on
    YouTube, reading and liking posts on Facebook, or rating movies on Netflix), we
    want to provide them with great personalized recommendations and relevant content
    to keep them happy and engaged. A great way to do so is to provide a good mix
    of similar content and new content to explore and discover.
  prefs: []
  type: TYPE_NORMAL
- en: 'Collaborative filtering is a popular approach for providing such diverse recommendations
    by comparing user-item interactions, finding other users who interact with similar
    items, and recommending items that those users also interacted with. It''s almost
    as if you were to build many custom stereotypes and recommend other items consumed
    from by same stereotype. *Figure 13.6* illustrates this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.6 – Finding similar user ratings using collaborative filtering
    ](img/B17928_13_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.6 – Finding similar user ratings using collaborative filtering
  prefs: []
  type: TYPE_NORMAL
- en: As the person on the left buys similar items to the person on the right, we
    can recommend a new item to the person on the left that the person on the right
    bought. In this case, the user-item interaction is a person buying a product.
    However, in recommender language, we speak about ratings as a term summarizing
    all possible interactions between a user and an item. Let's look at building such
    a rating function (also called a feedback function).
  prefs: []
  type: TYPE_NORMAL
- en: 'One great example of amazing rating-based recommendations are the personalized
    recommended playlists in Spotify, as shown in *Figure 13.7*. In contrast to the
    previous Spotify recommendation at the bottom of each playlist, these recommendations
    are personalized based on my interaction history and feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Spotify''s rating-based song recommendation ](img/B17928_13_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.7 – Spotify's rating-based song recommendation
  prefs: []
  type: TYPE_NORMAL
- en: These playlists contain songs similar to the ones I listened to and that are
    also listened to by other people with my taste. Another nifty extension is that
    the song recommendations are categorized by genre into these six playlists.
  prefs: []
  type: TYPE_NORMAL
- en: What is a rating? Explicit feedback versus implicit feedback
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **feedback function** (or rating) quantifies the interaction between a user
    and an item. We differentiate between two types of feedback – explicit ratings
    (or non-observable feedback) and implicit ratings (or directly observable feedback).
    An **explicit rating** would be leaving a five-star review of a product on Amazon,
    whereas an **implicit rating** is buying the said product. While the former is
    a biased decision of the user, the latter can be objectively observed and evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: The most obvious form of rating is to explicitly ask the user for feedback –
    for example, to rate a certain movie, song, article, or the helpfulness of a support
    document. This is the method most people think about when first implementing recommendations
    engines. In the case of an explicit rating, we cannot directly observe the user's
    sentiment but must rely on the user's ability to quantify their sentiment with
    a rating, such as rating a movie on an ordinal scale from one to five.
  prefs: []
  type: TYPE_NORMAL
- en: There are many problems with explicit ratings – especially on ordinal scales
    (for example, stars from one to five) – that we should consider when building
    our feedback function. Most people will have a bias when rating items on an ordinal
    scale – for example, some users might rate a movie 3/5 if they are unsatisfied
    and 5/5 if they liked the movie, while other users might rate 1/5 for a bad movie,
    3/5 for a good one, and only very rarely 5/5 for an exceptional one.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the ordinal scales either need to be normalized across users or you'll
    need to use a binary scale (such as thumbs up/thumbs down) to collect binary feedback.
    Binary feedback is usually much easier to handle, as we can remove the user bias
    from the feedback function, simplify the error metric, and therefore provide better
    recommendations. Many popular streaming services nowadays collect binary (thumbs
    up/thumbs down, star/unstar, and so on) feedback.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a little snippet to help normalize user ratings. It applies a normalization
    across each group of user ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Another popular way to train recommender systems is to build an implicit feedback
    function based on the direct observation of an implicit user rating. This has
    the benefit that the user feedback is unbiased. Common implicit ratings include
    the user adding an item to the cart, the user buying the item, the user scrolling
    to the end of the article, and the user watching the full video to the end.
  prefs: []
  type: TYPE_NORMAL
- en: One additional problem to consider is that the way a user interacts with items
    will change over time. This could be due to a user's habit due to consuming more
    and more items on the service or changing user preferences. Recommending a video
    to you that you once liked in your childhood might not be helpful to another adult.
    Similar to this user drift, the popularity of items will also change over time.
    Recommending the song *Somebody That I Used to Know* to a user today might not
    lead to the same CTR as in 2011\. Therefore, we also must model time and account
    for temporal drift in our item ratings and feedback function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The time drift of explicit or implicit ratings can be modeled using exponential
    time decay on the numeric rating. Depending on the business rules, we can, for
    example, use explicit ratings with a binary scale [1, -1] and exponentially decay
    these ratings with a half-life time of 1 year. Hence, after 1 year, a rating of
    1 becomes 0.5; after 2 years, it becomes 0.25, and so on. Here is a snippet to
    exponentially decay your ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We learned that the choice of a proper feedback function matters greatly and
    is as important for designing a rating-based recommendation engine as feature
    engineering is for content-based recommenders.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the missing ratings to make a recommendation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By collecting user-item ratings, we generate a sparse user-item-rating matrix
    that looks similar to *Figure 13.8*. However, in order to make a recommendation,
    we first need to fill the unknown ratings displayed red in the diagram. Collaborative
    filtering is about filling the blank rows or columns of the user-item-ratings
    matrix, depending on the prediction use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.8 – The user-item-ratings matrix ](img/B17928_13_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.8 – The user-item-ratings matrix
  prefs: []
  type: TYPE_NORMAL
- en: To recommend the best movie for Alice, we only need to compute the first row
    of the rating matrix, whereas to compute the best candidates for Terminator, we
    only need to compute the last column of the matrix. It is important to know that
    we don't have to compute the whole matrix all the time, which helps to significantly
    improve the recommendation performance.
  prefs: []
  type: TYPE_NORMAL
- en: You can also probably already guess that this matrix will get really, really
    large as the number of users and/or items grows. Therefore, we need an efficient
    parallelizable algorithm for computing the blank ratings in order to make a recommendation.
    The most popular method to solve this problem is to use matrix factorization and,
    hence, decompose the matrix into a product of two lower dimensional matrices.
    These two matrices and their dimensions can be interpreted as user trait and item
    trait matrices; by way of analogy, the dimension refers to the number of different
    distinct traits – the so-called latent representation.
  prefs: []
  type: TYPE_NORMAL
- en: Once the latent representation is known, we can fill the missing ratings by
    multiplying the correct rows and columns from the latent trait matrices. A recommendation
    can then be made by using the top *n* highest computed ratings. But that's enough
    of the theory – let's look at an example using the `PySpark`. Apart from the method,
    everything else in the pipeline is the same as in a standard ML pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to all previous pipelines, we also compute a training and testing set
    for validating the model performance using a grouped selection algorithm (for
    example, `LeavePGroupsOut` and `GroupShuffleSplit`), performing training, optimizing
    the hyperparameters, validating the model test performance, and eventually, stacking
    multiple models together. As in many other methods, most models are trained using
    gradient descent. We can also use a standard regression loss function, such as
    the **RMSE**, to compute the fit of our recommendations on the test set. Let's
    dive into the example.
  prefs: []
  type: TYPE_NORMAL
- en: Scalable recommendations using ALS factorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To train a large collaborative filtering model using matrix factorization, we
    need an algorithm that is easily distributable. The ALS algorithm of the Spark
    `MLlib` package is an excellent choice – however, many other algorithms for factorizing
    matrices are available, such as *Bayesian personalized ranking*, FastAI's *EmbeddingDotBias*,
    or *neural collaborative filtering*.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: A summary of example applications using the preceding methods can be found on
    Microsoft's GitHub repository at [https://github.com/Microsoft/Recommenders](https://github.com/Microsoft/Recommenders).
  prefs: []
  type: TYPE_NORMAL
- en: 'By using Spark, or more precisely PySpark – the Python bindings for Spark and
    its libraries – we can take advantage of the distributed computing framework of
    Spark. While it''s possible to run Spark on a single-node, single-core process
    locally, it can be easily distributed to a cluster with hundreds and thousands
    of nodes. Hence, it is a good choice, as your code automatically becomes scalable
    if your input data scales and exceeds the memory limits of a single node:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first create and parametrize an ALS estimator in PySpark using `MLlib`,
    the standard ML library of Spark. We will find `ALS` in the recommendation package
    of `MLlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code, we initialize the `ALS` estimator and define the number
    of iterations for gradient descent optimization, the rank of the latent trait
    matrices, and the L2 regularization constant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we fit the model using this estimator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'That''s all we have to do. Once the model is successfully trained, we can now
    predict the ratings for the test set by calling the `transform` method on the
    trained model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To compute the performance of the recommendations, we use a regression evaluator
    and the `rmse` metric as a scoring function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To compute the `rmse` score, we simply call the `evaluate` method on the `scoring`
    object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Congratulations! You successfully implemented a rating-based recommendation
    engine with a collaborative filtering approach by factorizing the user-item-ratings
    matrix. Have you realized that this approach is similar to finding the eigenvectors
    of a matrix and that they can be interpreted as user stereotypes (or user tastes,
    traits, and so on)? While this approach is great for creating diverse recommendations,
    it requires the availability of (many) user-item ratings. Therefore, it would
    work great in a service with a lot of user interaction and poorly with completely
    new users (the cold-start problem).
  prefs: []
  type: TYPE_NORMAL
- en: Combining content and ratings in hybrid recommendation engines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instead of seeing rating-based recommenders as a successor to content-based
    recommenders, you should consider them as a different recommender after having
    acquired enough user-item interaction data to provide rating-only recommendations.
    In most practical cases, a recommendation engine will exist for both approaches
    – either as two distinct algorithms or a single hybrid model. In this section,
    we will look into training such a hybrid model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build a state-of-the-art recommender using the **Matchbox recommender**,
    open Azure Machine Learning designer and add the building blocks for the Matchbox
    recommender to the canvas, as shown in the following diagram. As we can see, the
    recommender can now take ratings and user and item features as input to create
    a hybrid recommendation model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.9 – The Matchbox recommender in Azure Machine Learning designer
    ](img/B17928_13_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.9 – The Matchbox recommender in Azure Machine Learning designer
  prefs: []
  type: TYPE_NORMAL
- en: In order to configure the Matchbox recommender, we need to configure the number
    of traits and, hence, the dimensions of the latent space matrices. We set this
    value to 10\. Similar to the content-based recommender, instead of feeding raw
    unprocessed feature vectors into the recommender, we should pre-process the data
    and encode categorical variables using advanced NLP techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have built the recommendation engine in Azure Machine Learning designer,
    you simply press **Run** to train the model. You can also pull-request input and
    output blocks to the canvas to deploy this model as a web service.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, the Matchbox recommender is only available through the graphical
    interface. However, you can use other hybrid models, such as Extreme Deep Factorization
    Machines and Wide and Deep, to train hybrid recommenders from Python.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid recommenders are very powerful, as they help avoid the cold-start problem
    but refine recommendations based on ratings once a user provides item ratings.
    However, the additional ratings are only used to refine predictions, and similar
    to all previous techniques, hybrid recommenders have to be trained before being
    deployed.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will take a look at recommenders that can be deployed
    without any user ratings and trained online while users interact with items –
    recommenders based on reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic optimization through reinforcement learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can improve your recommendations by providing online training techniques,
    which will retrain your recommender systems after every user-item interaction.
    By replacing the feedback function with a reward function and adding a reinforcement
    learning model, we can now make recommendations, make decisions, and optimize
    choices that optimize the reward function.
  prefs: []
  type: TYPE_NORMAL
- en: This is a fantastic new approach to training recommender models. The Azure Personalizer
    service offers exactly this functionality – to make and optimize decisions and
    choices by providing contextual features and a reward function to the user. Azure
    Personalizer uses contextual bandits, an approach to reinforcement learning that
    is framed around making decisions or choices between discrete actions in a given
    context.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Under the hood, Azure Personalizer uses the Vowpal Wabbit ([https://github.com/VowpalWabbit/vowpal_wabbit/wiki](https://github.com/VowpalWabbit/vowpal_wabbit/wiki))
    learning system from Microsoft Research to provide high-throughput and low-latency
    optimization for the recommendation system.
  prefs: []
  type: TYPE_NORMAL
- en: From a developer's perspective, Azure Personalizer is quite easy to use. The
    basic recommender API consists of two main requests, the rank request and the
    reward request. During the rank request, we send the user features of the current
    user, plus all possible item features, to the API which returns a ranking of those
    items and an event ID in the response.
  prefs: []
  type: TYPE_NORMAL
- en: Using this response, we can present the items to the user who will then interact
    with these items. Whenever the user creates implicit feedback (for example, they
    click on an item or scroll to the end of the item), we make a second call to the
    service, this time to the reward API. In this request, we only send the event
    ID and the reward (a numeric value) to the service. This will trigger another
    training iteration using the new reward and the previously submitted user and
    item features. Hence, with each iteration and each service call, we optimize the
    performance of the recommendation engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Personalizer SDKs are available for many different languages and are
    mainly wrappers around the official REST API. In order to install the Python SDK,
    run the following command in your shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now, go to the Azure portal and deploy an instance of Azure Personalizer from
    your portal and configure the **Rewards** and **Exploration** settings, as discussed
    in the following paragraphs.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: You can find more information about Azure Personalizer configurations in the
    official documentation at [https://docs.microsoft.com/en-us/azure/cognitive-services/personalizer/how-to-settings](https://docs.microsoft.com/en-us/azure/cognitive-services/personalizer/how-to-settings).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to configure how long the algorithm should wait to collect
    rewards for a certain event, as shown in *Figure 13.10*. Up to this time, rewards
    are collected and aggregated by the reward aggregation function. You can also
    define the model update frequency, which allows you to train your model frequently
    when requiring recommendations for quick-changing user behaviors. It makes sense
    to set the reward time and model update frequency to the same value – for example,
    10 minutes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.10 – Rewards settings ](img/B17928_13_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.10 – Rewards settings
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding figure, we can also select the aggregation function for rewards
    collected on the same event during the reward wait time. The possible options
    are **Earliest** and **Sum** – hence, using only the first reward or a sum of
    all rewards in the reward period.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Exploration** setting makes the algorithm explore alternative patterns
    over time, which is very helpful in discovering a diverse set of items through
    exploration. It can be set through the percentage of rank calls used for exploration,
    as shown in *Figure 13.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.11 – Exploration settings ](img/B17928_13_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.11 – Exploration settings
  prefs: []
  type: TYPE_NORMAL
- en: Hence, in 20% of the calls, the model won't return the highest ranked item but
    will randomly explore new items and their rewards. It sounds reasonable that the
    value for exploration should be greater than 0% to let the reinforcement algorithm
    try variations of items over time and set lower than 100% to avoid making the
    algorithm completely random.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s embed a recommendation engine in your application using Python:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s grab your resource key, open a Python environment, and start implementing
    the rank and reward calls. First, we define the API URLs for both calls:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we create a unique `eventid` function and an object containing the user
    features of the current user and the item features of all possible actions. Once
    the request is constructed, we can send it to the rank API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The response contains the ranking of the possible items/actions and a probability
    value, as well as the winning item under the `rewardActionId` property:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s parse `rewardActionId` from `response` – this contains the winning item
    and, hence, the recommended action for the user:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using this ranking, we can return the winning item to the user based on `rewardActionId`.
    We now give the user some time to interact with the item. Finally, we use this
    ID to return the tracked implicit feedback as a reward value to the reward API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: That's all you need to embed a fully online self-training recommendation engine
    in your application using Python and Azure Personalizer. It's that simple. As
    previously mentioned, other SDKs that wrap the API calls are available for many
    other languages.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: A demo of Personalizer to test the reward function, as well as the request and
    response of the service, can be found at [https://personalizationdemo.azurewebsites.net/](https://personalizationdemo.azurewebsites.net/).
  prefs: []
  type: TYPE_NORMAL
- en: Detailed up-to-date examples for other languages are provided on GitHub at [https://github.com/Azure-Samples/cognitive-services-personalizer-samples](https://github.com/Azure-Samples/cognitive-services-personalizer-samples).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the need for different types of recommendation
    engines, from non-personalized ones to rating- and content-based ones, as well
    as hybrid models.
  prefs: []
  type: TYPE_NORMAL
- en: We learned that content-based recommendation engines use feature vectors and
    cosine similarity to compute similar items and users based on content alone. This
    allows us to make recommendations via *k-means clustering* or *tree-based regression*
    models. One important consideration is the embedding of categorical data, which,
    if possible, should use semantic embedding to avoid confusing similarities based
    on one-hot or label encodings.
  prefs: []
  type: TYPE_NORMAL
- en: Rating-based recommendations or collaborative filtering methods rely on user-item
    interactions, so-called ratings, or feedback. While explicit feedback is the most
    obvious possibility for collecting user ratings through ordinal or binary scales,
    we need to make sure that those ratings are properly normalized.
  prefs: []
  type: TYPE_NORMAL
- en: Another possibility is to directly observe the feedback through implicit ratings
    – for example, a user bought a product, clicked on an article, scrolled a page
    until the end, or watched a whole video until the end. However, these ratings
    will also be affected by user preference drift over time, as well as item popularity
    over time. To avoid this, you can use exponential time decay to decrease ratings
    over time.
  prefs: []
  type: TYPE_NORMAL
- en: Rating-based methods are great for providing diverse recommendations but require
    a lot of existing ratings for a good performance. Hence, they are often combined
    with content-based recommendations to fight this cold-start problem. Therefore,
    popular state-of-the-art recommendation models often combine both methods in a
    single hybrid model, of which the *Matchbox recommender* is one such example.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you learned about the possibility of using reinforcement learning to
    optimize the recommender's feedback function on the fly. *Azure Personalizer*
    is a service that can be used to create hybrid online recommenders.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look into deploying our trained models as batch
    or real-time scoring systems directly from the Azure Machine Learning service.
  prefs: []
  type: TYPE_NORMAL
