<html><head></head><body>
		<div id="_idContainer088">
			<h1 id="_idParaDest-75"><em class="italic"><a id="_idTextAnchor075"/>Chapter 5</em>: Predicting Boolean Values Using Binary Logistic Regression</h1>
			<p>Binary logistic regression is one of the most widely used <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) algorithms to predict the classification of future events and behaviors. It's used in different industries and contexts. Some variables that can be predicted with this technique are the propensity to buy a product and the probability of getting positive or negative feedback from customers for a specific service.</p>
			<p>Most digital native companies offer their services in subscription mode. In streaming video services, telco operators, and pay TVs, the binary logistic regression technique is widely used to predict the probability of churn of a customer. Predicting this kind of information is fundamental to target marketing campaigns and special offers to customers with the highest propensity to buy and increase revenue.</p>
			<p>In this chapter, we'll see all the stages necessary to implement a binary logistic regression model leveraging BigQuery ML.</p>
			<p>Using the BigQuery ML SQL language, we'll go through the following topics:</p>
			<ul>
				<li>Introducing the business scenario</li>
				<li>Discovering binary logistic regression</li>
				<li>Exploring and understanding the dataset</li>
				<li>Training the binary logistic regression model</li>
				<li>Evaluating the binary logistic regression model</li>
				<li>Using the binary logistic regression model </li>
				<li>Drawing business conclusions</li>
			</ul>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor076"/>Technical requirements</h1>
			<p>This chapter requires access to a web browser and the possibility to leverage the following:</p>
			<ul>
				<li>A GCP account to access Google Cloud Console</li>
				<li>A GCP project to host the BigQuery datasets</li>
			</ul>
			<p>Now that we're ready with the technical requirements, let's dive into the analysis and development of our BigQuery ML binary logistic regression model.</p>
			<p>Check out the following video to see the Code in Action: <a href="https://bit.ly/2QXCGHM">https://bit.ly/2QXCGHM</a></p>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor077"/>Introducing the business scenario</h1>
			<p>In this section, we'll introduce <a id="_idIndexMarker275"/>the business scenario that will be tackled with binary logistic regression.</p>
			<p>Let's take an example wherein you are a taxi driver who is passionate about ML. You're currently working in Chicago and your goal is to provide an additional tool to all your colleagues to understand the probability of getting a tip from your customers.</p>
			<p>Getting a tip from a customer is very important for taxi drivers to increase their income. Predicting the probability of getting a tip can be useful to, for example, know when to reserve a particularly gentle treatment for a specific subset of customers.</p>
			<p>In the following photo, you can see a taxi in Chicago:</p>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/B16722_05_001.jpg" alt="Figure 5.1 – Taxi in Chicago&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.1 – Taxi in Chicago</p>
			<p>The city of Chicago has <a id="_idIndexMarker276"/>collected information about most of the taxi trips that have occurred since 2013. This dataset is available in the BigQuery public datasets marketplace (<a href="https://console.cloud.google.com/marketplace/details/city-of-chicago-public-data/chicago-taxi-trips">https://console.cloud.google.com/marketplace/details/city-of-chicago-public-data/chicago-taxi-trips</a>) and can be easily accessed and used.</p>
			<p>Your goal is to leverage the available information about taxi trips, such as the payment type, the miles traveled, the fare, and the name of the taxi company, to predict whether a taxi driver will receive a tip at the <a id="_idIndexMarker277"/>end of the taxi ride.</p>
			<p>Now that we've explained and understood the business scenario, let's take a look at the ML technique that we can use to predict whether a specific event will happen or not.</p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor078"/>Discovering binary logistic regression</h1>
			<p>In this section, we'll learn what <strong class="bold">binary logistic regression</strong> is and we'll understand the use cases that can be tackled with this ML algorithm.</p>
			<p><strong class="bold">Logistic regression</strong> is a <a id="_idIndexMarker278"/>classification ML technique that can be used to predict a categorical variable. We can apply <strong class="bold">binary logistic regression</strong> when the variable <a id="_idIndexMarker279"/>to predict is binary and can assume only two values, such as true or false, yes or no, or 1 or 0.</p>
			<p>In order to predict one of the two labels, this ML algorithm <a id="_idIndexMarker280"/>calculates the probability of two different outcomes and allows us to choose a probability threshold to get the final classification of the binary variable.</p>
			<p>Since this is an algorithm based on a regression technique, the prediction of the label is based on a set of independent variables called features that are used to predict the dependent variable, called a label.</p>
			<p>This ML technique can be used to answer relevant business questions across different industries, such as the following:</p>
			<ul>
				<li>Will this customer buy my product?</li>
				<li>Is my customer satisfied with my service?</li>
				<li>Will my customer unsubscribe from my service in the next months?</li>
				<li>Will this student pass the next exam?</li>
				<li>Will this person develop diabetes in the next year?</li>
			</ul>
			<p>In our business scenario, the possibility of getting a tip at the end of a taxi ride can be predicted by leveraging binary logistic regression. In fact, we're interested in predicting whether a certain event will happen or not. If the taxi driver will get a tip, the binary categorical variable will be valued with 1, otherwise 0.</p>
			<p>Training a binary logistic regression model means trying to find the values of the coefficients that can be used in the equation between the input variables, called features, and the binary output variable, called the label.</p>
			<p>After the training, we'll leverage a <strong class="bold">confusion matrix</strong> to evaluate the performance of our <a id="_idIndexMarker281"/>binary logistic regression model. In this matrix, the rows represent the predicted value of the label while the columns are used to store the actual values.</p>
			<p>The following figure <a id="_idIndexMarker282"/>represents a confusion matrix that is used to evaluate the performances of the binary logistic regression:</p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B16722_05_Table_01.jpg" alt="Figure 5.2 – Confusion matrix&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.2 – Confusion matrix</p>
			<p>This matrix allows us to visualize the performance of an ML algorithm, comparing the right predictions with the wrong ones.</p>
			<p>From the numbers that will be presented in the confusion matrix, we can extract a fundamental performance indicator for <a id="_idIndexMarker283"/>logistic regression models: the <strong class="bold">Area Under the Curve</strong> (<strong class="bold">AUC</strong>) and the <strong class="bold">Receiver Operating Characteristic</strong> (<strong class="bold">ROC</strong>). The <strong class="bold">ROC</strong> is a curve that <a id="_idIndexMarker284"/>helps us in measuring the performance of a classification scenario with various thresholds. Basically, it tells us the capability of our ML model in predicting the right class.</p>
			<p>The <strong class="bold">ROC</strong> curve is a graph plotted using the following two parameters:</p>
			<ul>
				<li><strong class="bold">False positive rate</strong> on the <a id="_idIndexMarker285"/>abscissa axis. This parameter is calculated as the ratio between the <a id="_idIndexMarker286"/>number of <strong class="bold">false positives</strong> and the <a id="_idIndexMarker287"/>sum of <strong class="bold">false positives</strong> and <strong class="bold">true negatives</strong>.</li>
				<li><strong class="bold">True positive rate</strong> on the <a id="_idIndexMarker288"/>ordinate axis. This parameter is also called the <strong class="bold">recall</strong> of the <a id="_idIndexMarker289"/>model. It is calculated as the ratio <a id="_idIndexMarker290"/>between <strong class="bold">true positives</strong> and the <a id="_idIndexMarker291"/>sum of <strong class="bold">true positives</strong> and <strong class="bold">false negatives</strong>.</li>
			</ul>
			<p>If the <strong class="bold">area under the curve</strong>, called the <strong class="bold">AUC</strong>, is high and close to 1, the <a id="_idIndexMarker292"/>model is more likely to be able to predict the right label.</p>
			<p>We've learned about the basics of binary logistic regression; now it's time to take a look at the dataset that we'll use to build our ML model.</p>
			<h1 id="_idParaDest-79"><a id="_idTextAnchor079"/>Exploring and understanding the dataset</h1>
			<p>As we learned in <a href="B16722_04_Final_ASB_ePub.xhtml#_idTextAnchor061"><em class="italic">Chapter 4</em></a>, <em class="italic">Predicting Numerical Values with Linear Regression</em>, before diving into the ML implementation, it's necessary to analyze the data available for our use case. We need to begin by having a clear understanding of the data that can be used for our business scenario.</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor080"/>Understanding the data</h2>
			<p>To start <a id="_idIndexMarker293"/>exploring the data, we need to do the following:</p>
			<ol>
				<li value="1">Log in to Google Cloud Console and access the <strong class="bold">BigQuery</strong> user interface from the navigation menu.</li>
				<li>Create a new dataset in the project that we created in <a href="B16722_02_Final_ASB_ePub.xhtml#_idTextAnchor039"><em class="italic">Chapter 2</em></a>, <em class="italic">Setting Up Your GCP and BigQuery Environment</em>. For this use case, we'll create the <strong class="source-inline">05_chicago_taxi</strong> dataset with the default options.</li>
				<li>Open the <strong class="source-inline">bigquery-public-data</strong> GCP project that hosts all the BigQuery public datasets and browse the items until you find the <strong class="source-inline">chicago_taxi_trips</strong> dataset. In this public dataset, we can see only one BigQuery table: <strong class="source-inline">taxi_trips</strong>. This table contains all the information about the taxi rides that happened in the city of Chicago and we'll use it to train and test our ML model:<div id="_idContainer076" class="IMG---Figure"><img src="image/B16722_05_003.jpg" alt="Figure 5.3 – The chicago_taxi_trips dataset contains only one table: taxi_trips&#13;&#10;"/></div><p class="figure-caption">Figure 5.3 – The chicago_taxi_trips dataset contains only one table: taxi_trips</p></li>
				<li>Let's click on the table named <strong class="bold">taxi_trips</strong> in the BigQuery navigation menu to access the schema of the table.<p>Each field is well described and also the names of the columns seem self-explanatory.</p><p>The table <a id="_idIndexMarker294"/>contains the <strong class="source-inline">tips</strong> column, represented with the numeric <strong class="source-inline">FLOAT</strong> format. Apparently, this might seem like a problem because our ML model is only able to predict Boolean values. This situation can easily be overcome by transforming the numeric value into a binary value by applying the following rule: if the value of <strong class="source-inline">tips</strong> is greater than 0, the label is 1, otherwise it's 0.</p><p>We can leverage all the other columns in the table as <strong class="bold">features</strong> of our ML model. The duration of the taxi ride could be a good feature because during longer rides, the taxi driver has more time to familiarize themselves with the customer than during short trips of just some minutes. The pick-up and drop-off locations can impact the tip because, as we can imagine, some areas are more profitable than others. For example, an area of the city with a lot of businesses and offices of large <a id="_idIndexMarker295"/>companies can increase the probability of getting a tip.</p><p>The payment type used to pay for the taxi ride is another important factor in our analysis. When you need to pay a taxi driver with electronic payment, it's usually easier to give a tip simply by <a id="_idIndexMarker296"/>pressing a button on the <strong class="bold">Point of Sale</strong> (<strong class="bold">POS</strong>) device.</p><p>Furthermore, the name of the taxi company could be another important feature to consider. Some taxi companies can offer a better experience to customers in terms of services, professionalism of the drivers, and comfort of the cars. All these ingredients can influence a customer in giving a tip to the taxi driver.</p><p>From a schema perspective, this table includes a lot of useful information that can be used to develop our binary logistic regression model. Let's proceed with our analysis, deepening our understanding of the data.</p></li>
				<li>As a next step, let's take a look at how many records we have in the table and whether they're enough for our purposes. In the <strong class="bold">Details</strong> tab, we can notice that the table contains more than 194 million records. We can be confident in building our ML model with this amount of data:<div id="_idContainer077" class="IMG---Figure"><img src="image/B16722_05_004.jpg" alt="Figure 5.4 – The Details tab on the taxi_trips table shows the number of records &#13;&#10;and the table size in terms of GB&#13;&#10;"/></div><p class="figure-caption">Figure 5.4 – The Details tab on the taxi_trips table shows the number of records and the table size in terms of GB</p></li>
				<li>Now, let's take a look at the <a id="_idIndexMarker297"/>actual data in the <strong class="source-inline">taxi_trips</strong> table:<p class="source-code">SELECT *</p><p class="source-code">FROM</p><p class="source-code">  `bigquery-public-data.chicago_taxi_trips.taxi_trips`</p><p class="source-code">LIMIT 10;</p><p>The query shows all the fields of the table filtering on the first 10 rows. The <strong class="source-inline">LIMIT 10</strong> clause is used to limit the number of records in the result set and returns a random selection of rows from the table.</p></li>
				<li>After getting a preview of the table content, we can analyze the time frame of our dataset:<p class="source-code">SELECT MIN(trip_start_timestamp),  MAX(trip_start_timestamp)</p><p class="source-code">FROM</p><p class="source-code">  `bigquery-public-data.chicago_taxi_trips.taxi_trips`;</p><p>The query extracts the minimum and maximum values of the <strong class="source-inline">trip_start_timestamp</strong> field to have a clear understanding of the period over which the data is collected.</p><p>In the following screenshot, you <a id="_idIndexMarker298"/>can view the result of the query execution:</p><div id="_idContainer078" class="IMG---Figure"><img src="image/B16722_05_005.jpg" alt="Figure 5.5 – The query returns the minimum and maximum values of the trip_start_timestamp field&#13;&#10;"/></div><p class="figure-caption">Figure 5.5 – The query returns the minimum and maximum values of the trip_start_timestamp field</p><p>At the time of writing this book, the minimum value is represented by 1 January 2013, while the maximum value is 1 October 2020.</p></li>
				<li>Then, we can apply a data quality check on the <strong class="source-inline">tips</strong> field on which our label will be based. In fact, if the <strong class="source-inline">tips</strong> column is greater than 0, we can assume that the taxi driver got a tip from the customer:<p class="source-code">SELECT COUNT(*)</p><p class="source-code">FROM</p><p class="source-code">  `bigquery-public-data.chicago_taxi_trips.taxi_trips`</p><p class="source-code">WHERE</p><p class="source-code">        tips IS NULL;</p><p>In the following screenshot, you can see the result of the query:</p></li>
			</ol>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B16722_05_006.jpg" alt="Figure 5.6 – The query returns the 4,784 records with the tips field empty&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.6 – The query returns the 4,784 records with the tips field empty</p>
			<p>Executing the <strong class="source-inline">SELECT COUNT(*)</strong> query, we <a id="_idIndexMarker299"/>can notice that there are 4,784 records where the <strong class="source-inline">tips</strong> field is empty. We'll take into consideration this aspect during the creation of the ML model, filtering these rows.</p>
			<p>In this section, we've analyzed the dataset that we can leverage in order to build our ML model, so now let's start segmenting it into three different sets: training, evaluation, and classification.</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor081"/>Segmenting the dataset</h2>
			<p>Before implementing our <a id="_idIndexMarker300"/>binary logistic regression model, let's segment our dataset according to the main stages of the ML development: training, evaluation, and use:</p>
			<ol>
				<li value="1">To understand how the <a id="_idIndexMarker301"/>data is distributed across the years and months, we can use the following query statement:<p class="source-code">SELECT     EXTRACT (YEAR FROM trip_start_timestamp) year,</p><p class="source-code">           EXTRACT (MONTH FROM trip_start_timestamp) month,</p><p class="source-code">           COUNT(*) total</p><p class="source-code">FROM</p><p class="source-code">          `bigquery-public-data.chicago_taxi_trips.taxi_trips`</p><p class="source-code">WHERE </p><p class="source-code">           tips IS NOT NULL AND</p><p class="source-code">           trip_seconds IS NOT NULL AND</p><p class="source-code">           trip_miles IS NOT NULL AND</p><p class="source-code">           fare IS NOT NULL AND</p><p class="source-code">           tolls IS NOT NULL AND</p><p class="source-code">           pickup_location IS NOT NULL AND</p><p class="source-code">           dropoff_location IS NOT NULL AND</p><p class="source-code">           pickup_latitude IS NOT NULL AND</p><p class="source-code">           pickup_longitude IS NOT NULL AND</p><p class="source-code">           dropoff_latitude IS NOT NULL AND</p><p class="source-code">           dropoff_longitude IS NOT NULL AND</p><p class="source-code">           company IS NOT NULL AND</p><p class="source-code">           trip_miles &gt; 1 AND</p><p class="source-code">           trip_seconds &gt; 180</p><p class="source-code">GROUP BY</p><p class="source-code">          year, month</p><p class="source-code">ORDER BY</p><p class="source-code">           year, month ASC;</p><p>The <strong class="source-inline">SELECT</strong> statement extracts the information about the year and month when the taxi rides occurred and for each month counts the total number of rides. This aggregation is possible by the <strong class="source-inline">GROUP BY</strong> clause at the end of the query.</p><p>The query extracts the <a id="_idIndexMarker302"/>records from the <strong class="source-inline">taxi_trips</strong> table but applies some important filters. All the records with an empty <strong class="source-inline">tips</strong> field are excluded as well as all the rows with the potential features equal to <strong class="source-inline">NULL</strong>.</p><p>In order to exclude outliers and possible incorrect measurements, we've decided to keep only the taxi rides with a duration greater than 3 minutes and longer than a mile.</p><p>Thanks to the <strong class="source-inline">ORDER BY</strong> clause, the results are ascendingly ordered:</p><div id="_idContainer080" class="IMG---Figure"><img src="image/B16722_05_007.jpg" alt="Figure 5.7 – The query returns the distribution of the records in the taxi_trips table&#13;&#10;"/></div><p class="figure-caption">Figure 5.7 – The query returns the distribution of the records in the taxi_trips table</p><p>Focusing on the <a id="_idIndexMarker303"/>most recent months, we can immediately notice a drop in the numbers in April 2020. This sudden decrease is probably caused by the restrictions introduced to manage the COVID-19 pandemic. To avoid any impact of this event on our analysis, let's focus our implementation only on the year 2019. We'll split our dataset using a time frame that starts from January 2019 up to October 2019.</p></li>
				<li>Let's create a table that <a id="_idIndexMarker304"/>contains the rows that will be used to train our BigQuery ML model. For this use case, we'll select only the taxi rides that occurred from January 2019 until August 2019 inclusive:<p class="source-code">CREATE OR REPLACE TABLE `05_chicago_taxi.training_table` AS</p><p class="source-code">    SELECT *</p><p class="source-code">    FROM</p><p class="source-code">          `bigquery-public-data.chicago_taxi_trips.taxi_trips`</p><p class="source-code">    WHERE</p><p class="source-code">           tips IS NOT NULL AND</p><p class="source-code">           trip_seconds IS NOT NULL AND</p><p class="source-code">           trip_miles IS NOT NULL AND</p><p class="source-code">           fare IS NOT NULL AND</p><p class="source-code">           tolls IS NOT NULL AND</p><p class="source-code">           pickup_location IS NOT NULL AND</p><p class="source-code">           dropoff_location IS NOT NULL AND</p><p class="source-code">           pickup_latitude IS NOT NULL AND</p><p class="source-code">           pickup_longitude IS NOT NULL AND</p><p class="source-code">           dropoff_latitude IS NOT NULL AND</p><p class="source-code">           dropoff_longitude IS NOT NULL AND</p><p class="source-code">           company IS NOT NULL AND</p><p class="source-code">           trip_miles &gt; 1 AND</p><p class="source-code">           trip_seconds &gt; 180 AND</p><p class="source-code">           EXTRACT (YEAR FROM trip_start_timestamp) = 2019 AND</p><p class="source-code">           (EXTRACT (MONTH FROM trip_start_timestamp) &gt;=1 AND EXTRACT (MONTH FROM trip_start_timestamp)&lt;=8);</p><p>As we can notice from the <strong class="source-inline">CREATE TABLE</strong> statement, the query filters all the rows with empty features and labels that could cause issues during the implementation of the ML model.</p></li>
				<li>After that, we create <a id="_idIndexMarker305"/>another table dedicated to the records that will be used to evaluate our ML model:<p class="source-code">CREATE OR REPLACE TABLE `05_chicago_taxi.evaluation_table` AS</p><p class="source-code">    SELECT *</p><p class="source-code">    FROM</p><p class="source-code">          `bigquery-public-data.chicago_taxi_trips.taxi_trips`</p><p class="source-code">    WHERE</p><p class="source-code">           tips IS NOT NULL AND</p><p class="source-code">           trip_seconds IS NOT NULL AND</p><p class="source-code">           trip_miles IS NOT NULL AND</p><p class="source-code">           fare IS NOT NULL AND</p><p class="source-code">           tolls IS NOT NULL AND</p><p class="source-code">           pickup_location IS NOT NULL AND</p><p class="source-code">           dropoff_location IS NOT NULL AND</p><p class="source-code">           pickup_latitude IS NOT NULL AND</p><p class="source-code">           pickup_longitude IS NOT NULL AND</p><p class="source-code">           dropoff_latitude IS NOT NULL AND</p><p class="source-code">           dropoff_longitude IS NOT NULL AND</p><p class="source-code">           company IS NOT NULL AND</p><p class="source-code">           trip_miles &gt; 1 AND</p><p class="source-code">           trip_seconds &gt; 180 AND</p><p class="source-code">           EXTRACT (YEAR FROM trip_start_timestamp) = 2019 AND</p><p class="source-code">           EXTRACT (MONTH FROM trip_start_timestamp) = 09;</p><p>The only difference, compared to <a id="_idIndexMarker306"/>the table that contains the training data, is in the month that we've selected to create this table. In this case, we've chosen to include the records related to the month of September of 2019.</p></li>
				<li>The last preparatory step is based on the creation of the table that we'll use to test our binary logistic regression model. Let's create <strong class="source-inline">classification_table</strong> as specified in the following SQL statement:<p class="source-code">CREATE OR REPLACE TABLE `05_chicago_taxi.classification_table` AS</p><p class="source-code">    SELECT *</p><p class="source-code">    FROM</p><p class="source-code">          `bigquery-public-data.chicago_taxi_trips.taxi_trips`</p><p class="source-code">    WHERE</p><p class="source-code">           tips IS NOT NULL AND</p><p class="source-code">           trip_seconds IS NOT NULL AND</p><p class="source-code">           trip_miles IS NOT NULL AND</p><p class="source-code">           fare IS NOT NULL AND</p><p class="source-code">           tolls IS NOT NULL AND</p><p class="source-code">           pickup_location IS NOT NULL AND</p><p class="source-code">           dropoff_location IS NOT NULL AND</p><p class="source-code">           pickup_latitude IS NOT NULL AND</p><p class="source-code">           pickup_longitude IS NOT NULL AND</p><p class="source-code">           dropoff_latitude IS NOT NULL AND</p><p class="source-code">           dropoff_longitude IS NOT NULL AND</p><p class="source-code">           company IS NOT NULL AND</p><p class="source-code">           trip_miles &gt; 1 AND</p><p class="source-code">           trip_seconds &gt; 180 AND</p><p class="source-code">           EXTRACT (YEAR FROM trip_start_timestamp) = 2019 AND</p><p class="source-code">           EXTRACT (MONTH FROM trip_start_timestamp) = 10;</p><p>Thanks to the <a id="_idIndexMarker307"/>selection and the filters that we've applied in this query, our set will contain only the records related to October 2019. We can also notice that all the other filters remain unchanged and uniform across the three datasets: training, evaluation, and classification.</p></li>
			</ol>
			<p>Now that we've divided our dataset into three parts. Let's start the actual training of the binary logistic regression ML model.</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor082"/>Training the binary logistic regression model</h1>
			<p>As we already did in <a href="B16722_04_Final_ASB_ePub.xhtml#_idTextAnchor061"><em class="italic">Chapter 4</em></a>, <em class="italic">Predicting Numerical Values with Linear Regression</em>, we'll adopt an <a id="_idIndexMarker308"/>incremental approach in trying to improve the performance of our ML model at each attempt:</p>
			<ol>
				<li value="1">Let's start training our first ML model, <strong class="source-inline">binary_classification_version_1</strong>:<p class="source-code">CREATE OR REPLACE MODEL `05_chicago_taxi.binary_classification_version_1`</p><p class="source-code">OPTIONS</p><p class="source-code">  (model_type='logistic_reg', labels = ['will_get_tip']) AS</p><p class="source-code">    SELECT</p><p class="source-code">        trip_seconds,</p><p class="source-code">        IF(tips&gt;0,1,0) AS will_get_tip</p><p class="source-code">    FROM  `05_chicago_taxi.training_table`;</p><p>In this BigQuery ML statement, we can see the <strong class="source-inline">CREATE OR REPLACE MODEL</strong> keywords used to start the training of the model. These keywords are followed by the identifier of the ML model. After the identifier, we can notice the <strong class="source-inline">OPTIONS</strong> clause. As our options, we've chosen to train the model with a <strong class="source-inline">logistic_reg</strong> algorithm and to use the <strong class="source-inline">will_get_tip</strong> field as the target label.</p><p>The <strong class="source-inline">SELECT</strong> statement <a id="_idIndexMarker309"/>points out that the <strong class="source-inline">will_get_tip</strong> label is valued with <strong class="source-inline">1</strong> if the value of the <strong class="source-inline">tips</strong> field is greater than 0, otherwise with <strong class="source-inline">0</strong>. In the <strong class="source-inline">SELECT</strong> statement, we've also included the only feature that we're using for our first attempt: <strong class="source-inline">trip_seconds</strong>. This feature represents the duration expressed in seconds of the taxi ride.</p><p>Finally, the <strong class="source-inline">SELECT</strong> statement is based on the table that we've created to perform the training of the model: <strong class="source-inline">05_chicago_taxi.training_table</strong>.</p></li>
				<li>At the end of the training, we can access the ML model from the BigQuery navigation menu to have a look at the performance of the model. Selecting the <strong class="bold">Evaluation</strong> tab, we can see the <strong class="bold">ROC AUC</strong> value. In this case, we can see we haven't achieved great results because it is not close to 1; it's <strong class="bold">0.5696</strong>:<div id="_idContainer081" class="IMG---Figure"><img src="image/B16722_05_008.jpg" alt="Figure 5.8 – The Evaluation tab shows the ROC AUC value related to the trained ML model&#13;&#10;"/></div><p class="figure-caption">Figure 5.8 – The Evaluation tab shows the ROC AUC value related to the trained ML model</p><p>In the same tab, we <a id="_idIndexMarker310"/>can also see the ROC curve:</p><div id="_idContainer082" class="IMG---Figure"><img src="image/B16722_05_009.jpg" alt="Figure 5.9 – In the Evaluation tab, it is also possible to graphically analyze the ROC curve and see the blue area under the ROC curve&#13;&#10;"/></div><p class="figure-caption">Figure 5.9 – In the Evaluation tab, it is also possible to graphically analyze the ROC curve and see the blue area under the ROC curve</p><p>As we can see from the preceding diagram, the ROC curve, which expresses the rate between the true positive and the false positive, is not close to 1. The blue area under the curve is about 50% of the entire square.</p><p>As shown in the following screenshot, we <a id="_idIndexMarker311"/>can also leverage the confusion matrix in the same tab to experiment with the outcome of the ML model according to different thresholds:</p><div id="_idContainer083" class="IMG---Figure"><img src="image/B16722_05_010.jpg" alt="Figure 5.10 – In the Evaluation tab, it is also possible to see the confusion matrix of the classification model&#13;&#10;"/></div><p class="figure-caption">Figure 5.10 – In the Evaluation tab, it is also possible to see the confusion matrix of the classification model</p></li>
				<li>Let's try to improve our ML model by adding features that can be useful to predict the probability of getting a tip. We'll introduce the fare of the taxi ride, any tolls paid during the ride, and the name of the taxi company as new features:<p class="source-code">CREATE OR REPLACE MODEL `05_chicago_taxi.binary_classification_version_2`</p><p class="source-code">OPTIONS</p><p class="source-code">  (model_type='logistic_reg', labels = ['will_get_tip']) AS</p><p class="source-code">    SELECT</p><p class="source-code">        trip_seconds,</p><p class="source-code">        fare,</p><p class="source-code">        tolls,</p><p class="source-code">        company,</p><p class="source-code">        IF(tips&gt;0,1,0) AS will_get_tip</p><p class="source-code">    FROM  `05_chicago_taxi.training_table`;</p><p>The <strong class="source-inline">CREATE OR REPLACE MODEL</strong> part is similar to the previous one but includes the new features previously mentioned. Despite adding the new fields, the improvement in terms of <strong class="bold">ROC AUC</strong> is not significant. In fact, with this attempt, we have achieved a value of <strong class="bold">0.5902</strong>.</p></li>
				<li>It's time to <a id="_idIndexMarker312"/>introduce a feature that can be extremely helpful for the development of our ML model. The next ML model, <strong class="source-inline">binary_classification_version_3</strong>, will introduce the payment type used by the customer to pay the taxi driver:<p class="source-code">CREATE OR REPLACE MODEL `05_chicago_taxi.binary_classification_version_3`</p><p class="source-code">OPTIONS</p><p class="source-code">  (model_type='logistic_reg', labels = ['will_get_tip']) AS</p><p class="source-code">    SELECT</p><p class="source-code">        trip_seconds,</p><p class="source-code">        fare,</p><p class="source-code">        tolls,</p><p class="source-code">        company,</p><p class="source-code">        payment_type,</p><p class="source-code">        IF(tips&gt;0,1,0) AS will_get_tip</p><p class="source-code">    FROM  `05_chicago_taxi.training_table`; </p><p>After the training of this ML model, we can immediately notice a huge increase in the value of <strong class="bold">ROC AUC</strong>. Adding the payment method as a feature to our model, we have achieved a value of <strong class="bold">0.9809</strong>. This is very close to 1 and represents a significant improvement in the performance of our binary logistic regression model.</p></li>
				<li>The result that we've achieved with the <strong class="source-inline">binary_classification_version_3</strong> ML model in the preceding code block is already a <a id="_idIndexMarker313"/>great result. Let's see whether it's possible to further improve our classification model by leveraging the information about the pick-up and drop-off locations of the taxi trip:<p class="source-code">CREATE OR REPLACE MODEL `05_chicago_taxi.binary_classification_version_4`</p><p class="source-code">OPTIONS</p><p class="source-code">  (model_type='logistic_reg', labels = ['will_get_tip']) AS</p><p class="source-code">    SELECT</p><p class="source-code">        trip_seconds,</p><p class="source-code">        fare,</p><p class="source-code">        tolls,</p><p class="source-code">        company,</p><p class="source-code">        payment_type,</p><p class="source-code">        pickup_location,</p><p class="source-code">        dropoff_location,</p><p class="source-code">        IF(tips&gt;0,1,0) AS will_get_tip</p><p class="source-code">    FROM  `05_chicago_taxi.training_table`; </p><p>The query is very similar to the other training statements but introduces two more features: <strong class="source-inline">pickup_location</strong> and <strong class="source-inline">dropoff_location</strong>. The two fields represent the area where the taxi ride started and ended.</p><p>After the <a id="_idIndexMarker314"/>training of the ML model, we can immediately appreciate that we've further improved the performances of our classification model. This is clearly visible from the <strong class="bold">ROC AUC</strong> value, which is <strong class="bold">0.9827</strong>.</p><p>Looking at the <strong class="bold">Confusion matrix</strong>, we can choose the best threshold that gives us the right balance between true positive and true negative predictions.</p><p>The threshold value influences the ratio between the True Positive Rate and the False Positive Rate. Finding the best threshold means to find a value that maximize the True Positive Rate and minimize the False Positive Rate.</p><p>In the following screenshot, you can see the confusion matrix and the <strong class="bold">Positive class threshold</strong> slider:</p></li>
			</ol>
			<p class="figure-caption"> </p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B16722_05_011.jpg" alt="Figure 5.11 – The confusion matrix shows excellent performances in terms of &#13;&#10;predicted labels versus the actual ones&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.11 – The confusion matrix shows excellent performances in terms of predicted labels versus the actual ones</p>
			<p>All the other key performance indicators, such as the precision, recall, and accuracy, are very high and close to the maximum of 1.</p>
			<p>From a graphical perspective, we can appreciate the excellent quality of our ML model. In fact, the <a id="_idIndexMarker315"/>blue area under the ROC curve is very close to 1 and covers almost the entire area of the square. The following screenshot shows the ROC curve of the last ML model and shows that our ML model has achieved an excellent result:</p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B16722_05_012.jpg" alt="Figure 5.12 – The area under the ROC curve is very close to 1 and to filling in the entire square&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.12 – The area under the ROC curve is very close to 1 and to filling in the entire square</p>
			<p>In this section, we've trained some binary logistic regression ML models leveraging the features available in our dataset. To proceed with the evaluation stage, we choose to pick up the <strong class="source-inline">binary_classification_version_4</strong> model, which showed the best performance. Now, let's see how to start the evaluation phase.</p>
			<h1 id="_idParaDest-83"><a id="_idTextAnchor083"/>Evaluating the binary logistic regression model</h1>
			<p>To evaluate our BigQuery ML model, we'll use the <strong class="source-inline">ML.EVALUATE</strong> function and the table that we've expressly <a id="_idIndexMarker316"/>created as the evaluation dataset.</p>
			<p>The following query will tell us whether the model is suffering from overfitting or is also able to perform well on new data:</p>
			<p class="source-code">SELECT</p>
			<p class="source-code">  roc_auc,</p>
			<p class="source-code">  CASE</p>
			<p class="source-code">    WHEN roc_auc &gt; .9 THEN 'EXCELLENT'</p>
			<p class="source-code">    WHEN roc_auc &gt; .8 THEN 'VERY GOOD'</p>
			<p class="source-code">    WHEN roc_auc &gt; .7 THEN 'GOOD'</p>
			<p class="source-code">    WHEN roc_auc &gt; .6 THEN 'FINE'</p>
			<p class="source-code">    WHEN roc_auc &gt; .5 THEN 'NEEDS IMPROVEMENTS'</p>
			<p class="source-code">  ELSE</p>
			<p class="source-code">  'POOR'</p>
			<p class="source-code">END</p>
			<p class="source-code">  AS model_quality</p>
			<p class="source-code">FROM </p>
			<p class="source-code">  ML.EVALUATE(MODEL `05_chicago_taxi.binary_classification_version_5`,</p>
			<p class="source-code">    (</p>
			<p class="source-code">    SELECT</p>
			<p class="source-code">        trip_seconds,</p>
			<p class="source-code">        fare,</p>
			<p class="source-code">        tolls,</p>
			<p class="source-code">        company,</p>
			<p class="source-code">        payment_type,</p>
			<p class="source-code">        pickup_location,</p>
			<p class="source-code">        dropoff_location,</p>
			<p class="source-code">        IF(tips&gt;0,1,0) AS will_get_tip</p>
			<p class="source-code">     FROM `05_chicago_taxi.evaluation_table`));</p>
			<p>The <strong class="source-inline">SELECT</strong> statement extracts the <strong class="source-inline">roc_auc</strong> value returned by the <strong class="source-inline">ML.EVALUATE</strong> function and also provides a clear description of the quality of the model, starting from <strong class="source-inline">'POOR'</strong> and going up to the <strong class="source-inline">'EXCELLENT'</strong> grade, passing through some intermediate stages such as <strong class="source-inline">'NEEDS IMPROVEMENTS'</strong> and <strong class="source-inline">'GOOD'</strong>.</p>
			<p>Executing the query, we can <a id="_idIndexMarker317"/>see that the score is very high, and the result is <strong class="source-inline">EXCELLENT</strong>:</p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B16722_05_013.jpg" alt="Figure 5.13 – The evaluation stage returns an EXCELLENT quality result of our BigQuery ML model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.13 – The evaluation stage returns an EXCELLENT quality result of our BigQuery ML model</p>
			<p>Now that we've evaluated our ML model, let's see how we can apply it to other records to get the predictions.</p>
			<h1 id="_idParaDest-84"><a id="_idTextAnchor084"/>Using the binary logistic regression model</h1>
			<p>In this section, we'll use the <a id="_idIndexMarker318"/>ML model to predict the probability of getting a tip from our customers.</p>
			<p>To test our BigQuery ML model, we'll use the <strong class="source-inline">ML.PREDICT</strong> function on the <strong class="source-inline">classification_table</strong> table:</p>
			<p class="source-code">SELECT predicted_will_get_tip, predicted_will_get_tip_probs, will_get_tip actual</p>
			<p class="source-code">FROM</p>
			<p class="source-code">  ML.PREDICT(MODEL`05_chicago_taxi.binary_classification_version_5`,</p>
			<p class="source-code">    (</p>
			<p class="source-code">      SELECT</p>
			<p class="source-code">        trip_seconds,</p>
			<p class="source-code">        fare,</p>
			<p class="source-code">        tolls,</p>
			<p class="source-code">        company,</p>
			<p class="source-code">        payment_type,</p>
			<p class="source-code">        pickup_location,</p>
			<p class="source-code">        dropoff_location,</p>
			<p class="source-code">        IF(tips&gt;0,1,0) AS will_get_tip</p>
			<p class="source-code">       FROM `05_chicago_taxi.classification_table`));</p>
			<p>The query is <a id="_idIndexMarker319"/>composed of a <strong class="source-inline">SELECT</strong> statement that extracts the actual and predicted values of the <strong class="source-inline">will_get_tip</strong> field. If not specified, <strong class="source-inline">ML.PREDICT</strong> will use the value <strong class="source-inline">0.5</strong> as the default threshold.</p>
			<p>The output of the query shows the following columns:</p>
			<ul>
				<li>The predicted label in the first column</li>
				<li>The calculated probabilities for each label in the second and third columns</li>
				<li>The actual value extracted from <strong class="source-inline">classification_table</strong> as the last column</li>
			</ul>
			<p>In the following screenshot, you can see the result of the query execution:</p>
			<div>
				<div id="_idContainer087" class="IMG---Figure">
					<img src="image/B16722_05_014.jpg" alt="Figure 5.14 – The output of the query shows the predicted label compared with the actual one&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.14 – The output of the query shows the predicted label compared with the actual one</p>
			<p>Now that we've tested <a id="_idIndexMarker320"/>our BigQuery ML model, let's make some final considerations about the possibility of predicting whether a customer will give a tip to the taxi driver according to the information that we have about the taxi ride.</p>
			<h1 id="_idParaDest-85"><a id="_idTextAnchor085"/>Drawing business conclusions</h1>
			<p>In this section, we'll use our ML model, and we'll <a id="_idIndexMarker321"/>understand how many times the BigQuery ML model is able to predict the actual outcome.</p>
			<p>Using the default threshold of <strong class="source-inline">0.5</strong>, let's see how many times the ML model is able to correctly identify when a driver will get a tip:</p>
			<p class="source-code">SELECT COUNT(*)</p>
			<p class="source-code">FROM (</p>
			<p class="source-code">      SELECT predicted_will_get_tip, predicted_will_get_tip_probs, will_get_tip actual_tip</p>
			<p class="source-code">      FROM</p>
			<p class="source-code">        ML.PREDICT(MODEL`05_chicago_taxi.binary_classification_version_5`,</p>
			<p class="source-code">          (</p>
			<p class="source-code">            SELECT</p>
			<p class="source-code">              trip_seconds,</p>
			<p class="source-code">              fare,</p>
			<p class="source-code">              tolls,</p>
			<p class="source-code">              company,</p>
			<p class="source-code">              payment_type,</p>
			<p class="source-code">              pickup_location,</p>
			<p class="source-code">              dropoff_location,</p>
			<p class="source-code">              IF(tips&gt;0,1,0) AS will_get_tip</p>
			<p class="source-code">             FROM `05_chicago_taxi.classification_table`)))</p>
			<p class="source-code">WHERE</p>
			<p class="source-code">       predicted_will_get_tip =  actual_tip;</p>
			<p>To calculate this value, we've introduced the <strong class="source-inline">WHERE</strong> clause, filtering only the rows where the predicted value is equal to the actual one.</p>
			<p><strong class="source-inline">SELECT COUNT</strong> returns a <a id="_idIndexMarker322"/>value of 727,462 predictions corresponding with the predicted value being equal to the actual one.</p>
			<p>On a total of 744,058 rows, we can say that our model with a standard threshold of 0.5 predicts the right outcome in 97.76% of cases.</p>
			<p>Since we've created a very effective binary logistic regression model leveraging BigQuery ML, we're now confident with providing insights and suggestions to our taxi drivers. Knowing in advance the probability of getting a tip, they can behave differently according to the probability of getting a tip from the customer they're serving.</p>
			<h1 id="_idParaDest-86"><a id="_idTextAnchor086"/>Summary</h1>
			<p>In this chapter, we implemented a binary logistic regression model. We introduced the business scenario based on the data collected by the city of Chicago about taxi services. After that, we learned how the binary logistic regression technique can be used to predict binary values.</p>
			<p>In order to build an effective model, we performed a detailed analysis of the data, and then segmented the dataset according to our needs into three tables: one to host training data, the second for evaluation, and the last one to apply our classification model.</p>
			<p>During the training phase of the BigQuery ML model, we constantly improved the performances of the ML model based on the confusion matrix and the ROC AUC value.</p>
			<p>After that, we evaluated the best ML model on a new set of records to verify the absence of overfitting and gain more confidence in the good quality of our binary logistic regression model.</p>
			<p>Finally, we applied our ML model to the last subset of records to predict the probability of getting a tip or not from the customer at the end of each taxi ride. We discovered that our ML model is able to correctly predict the customer's behavior in more than 97% of cases.</p>
			<p>In the next chapter, we'll go through multiclass logistic regression and we'll learn how to apply this algorithm to classify trees into different species according to their characteristics.</p>
			<h1 id="_idParaDest-87"><a id="_idTextAnchor087"/>Further resources</h1>
			<ul>
				<li><strong class="bold">Chicago Taxi Trips public dataset</strong>: <a href="https://console.cloud.google.com/marketplace/details/city-of-chicago-public-data/chicago-taxi-trips">https://console.cloud.google.com/marketplace/details/city-of-chicago-public-data/chicago-taxi-trips</a></li>
				<li><strong class="bold">Chicago Open Data</strong>: <a href="https://data.cityofchicago.org/">https://data.cityofchicago.org/</a></li>
				<li><strong class="bold">BigQuery ML CREATE MODEL</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create</a></li>
				<li><strong class="bold">BigQuery ML EVALUATE MODEL</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate</a></li>
				<li><strong class="bold">BigQuery ML PREDICT</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict">https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict</a></li>
				<li><strong class="bold">BigQuery ML binary logistic regression example</strong>: <a href="https://cloud.google.com/bigquery-ml/docs/logistic-regression-prediction">https://cloud.google.com/bigquery-ml/docs/logistic-regression-prediction</a></li>
			</ul>
		</div>
	</body></html>