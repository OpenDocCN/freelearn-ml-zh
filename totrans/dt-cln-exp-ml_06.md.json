["```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    nls97 = pd.read_csv(\"data/nls97b.csv\")\n    nls97.set_index(\"personid\", inplace=True)\n    ```", "```py\n    feature_cols = ['satverbal','satmath','gpascience',\n      'gpaenglish','gpamath','gpaoverall']\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(nls97[feature_cols],\\\n      nls97[['wageincome']], test_size=0.3, \\\n      random_state=0)\n    ```", "```py\n    nls97.shape[0]\n    8984\n    X_train.info()\n    <class 'pandas.core.frame.DataFrame'>\n    Int64Index: 6288 entries, 574974 to 370933\n    Data columns (total 6 columns):\n     #   Column        Non-Null Count     Dtype\n    ---  ------        --------------   -------\n     0   satverbal      1001 non-null   float64\n     1   satmath      1001 non-null   float64\n     2   gpascience     3998 non-null   float64\n     3   gpaenglish     4078 non-null   float64\n     4   gpamath        4056 non-null   float64\n     5   gpaoverall     4223 non-null   float64\n    dtypes: float64(6)\n    memory usage: 343.9 KB\n    y_train.info()\n    <class 'pandas.core.frame.DataFrame'>\n    Int64Index: 6288 entries, 574974 to 370933\n    Data columns (total 1 columns):\n     #   Column        Non-Null Count    Dtype\n    ---  ------        --------------  -------\n     0   wageincome    3599 non-null   float64\n    dtypes: float64(1)\n    memory usage: 98.2 KB\n    ```", "```py\n    X_test.info()\n    <class 'pandas.core.frame.DataFrame'>\n    Int64Index: 2696 entries, 363170 to 629736\n    Data columns (total 6 columns):\n     #   Column        Non-Null Count    Dtype\n    ---  ------        --------------  -------  \n     0   satverbal      405 non-null   float64\n     1   satmath        406 non-null   float64\n     2   gpascience    1686 non-null   float64\n     3   gpaenglish    1720 non-null   float64\n     4   gpamath       1710 non-null   float64\n     5   gpaoverall    1781 non-null   float64\n    dtypes: float64(6)\n    memory usage: 147.4 KB\n    y_test.info()\n    <class 'pandas.core.frame.DataFrame'>\n    Int64Index: 2696 entries, 363170 to 629736\n    Data columns (total 1 columns):\n     #   Column          Non-Null Count    Dtype\n    ---  ------          --------------  -------  \n     0   wageincome      1492 non-null   float64\n    dtypes: float64(1)\n    memory usage: 42.1 KB\n    ```", "```py\n    import pandas as pd\n    import feature_engine.selection as fesel\n    from sklearn.model_selection import train_test_split\n    nls97 = pd.read_csv(\"data/nls97b.csv\")\n    nls97.set_index(\"personid\", inplace=True)\n    ltpoland = pd.read_csv(\"data/ltpoland.csv\")\n    ltpoland.set_index(\"station\", inplace=True)\n    ltpoland.dropna(inplace=True)\n    ```", "```py\n    feature_cols = ['satverbal','satmath','gpascience',\n      'gpaenglish','gpamath','gpaoverall']\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(nls97[feature_cols],\\\n      nls97[['wageincome']], test_size=0.3, \\\n      random_state=0)\n    ```", "```py\n    X_train.corr()\n              satverbal  satmath  gpascience  gpaenglish \\\n    satverbal     1.000    0.729       0.439      0.444  \n    satmath       0.729    1.000       0.480      0.430\n    gpascience    0.439    0.480       1.000      0.672\n    gpaenglish    0.444    0.430       0.672      1.000\n    gpamath       0.375    0.518       0.606      0.600\n    gpaoverall    0.421    0.485       0.793      0.844\n                gpamath   gpaoverall  \n    satverbal     0.375        0.421  \n    satmath       0.518        0.485  \n    gpascience    0.606        0.793  \n    gpaenglish    0.600        0.844  \n    gpamath       1.000        0.750  \n    gpaoverall    0.750        1.000  \n    ```", "```py\n    tr = fesel.DropCorrelatedFeatures(variables=None, method='pearson', threshold=0.75)\n    tr.fit(X_train)\n    X_train_tr = tr.transform(X_train)\n    X_test_tr = tr.transform(X_test)\n    X_train_tr.info()\n    <class 'pandas.core.frame.DataFrame'>\n    Int64Index: 6288 entries, 574974 to 370933\n    Data columns (total 5 columns):\n     #   Column       Non-Null Count     Dtype\n    ---  ------        --------------  -------  \n     0   satverbal     1001 non-null   float64\n     1   satmath       1001 non-null   float64\n     2   gpascience    3998 non-null   float64\n     3   gpaenglish    4078 non-null   float64\n     4   gpamath       4056 non-null   float64\n    dtypes: float64(5)\n    memory usage: 294.8 KB\n    ```", "```py\n    feature_cols = ['year','month','latabs', \n      'latitude','elevation', 'longitude','country']\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(ltpoland[feature_cols],\\\n      ltpoland[['temperature']], test_size=0.3, \\\n      random_state=0)\n    X_train.sample(5, random_state=99)\n             year  month  latabs  latitude  elevation  longitude country\n    station  \n    SIEDLCE   2019   11    52    52    152    22    Poland\n    OKECIE    2019    6    52    52    110    21    Poland\n    BALICE    2019    1    50    50    241    20    Poland\n    BALICE    2019    7    50    50    241    20    Poland\n    BIALYSTOK 2019   11    53    53    151    23    Poland\n    X_train.year.value_counts()\n    2019    84\n    Name: year, dtype: int64\n    X_train.country.value_counts()\n    Poland    84\n    Name: country, dtype: int64\n    (X_train.latitude!=X_train.latabs).sum()\n    0\n    ```", "```py\n    tr = fesel.DropConstantFeatures()\n    tr.fit(X_train)\n    X_train_tr = tr.transform(X_train)\n    X_test_tr = tr.transform(X_test)\n    X_train_tr.head()\n\n             month  latabs  latitude  elevation  longitude\n    station                                                 \n    OKECIE       1      52        52        110         21\n    LAWICA       8      52        52         94         17\n    LEBA        11      55        55          2         18\n    SIEDLCE     10      52        52        152         22\n    BIALYSTOK   11      53        53        151         23\n    ```", "```py\n    tr = fesel.DropDuplicateFeatures()\n    tr.fit(X_train_tr)\n    X_train_tr = tr.transform(X_train_tr)\n    X_train_tr.head()\n               month   latabs   elevation   longitude\n    station                                       \n    OKECIE         1       52         110          21\n    LAWICA         8       52          94          17\n    LEBA          11       55           2          18\n    SIEDLCE       10       52         152          22\n    BIALYSTOK     11       53         151          23\n    ```", "```py\n    import pandas as pd\n    from feature_engine.encoding import OneHotEncoder\n    from sklearn.preprocessing import OrdinalEncoder\n    from sklearn.model_selection import train_test_split\n    nls97 = pd.read_csv(\"data/nls97b.csv\")\n    nls97.set_index(\"personid\", inplace=True)\n    ```", "```py\n    feature_cols =['gender','maritalstatus','colenroct99']\n    nls97demo = nls97[['wageincome'] + feature_cols].dropna()\n    X_demo_train, X_demo_test, y_demo_train, y_demo_test=\\\n      train_test_split(nls97demo[feature_cols],\\\n      nls97demo[['wageincome']], test_size=0.3, \\\n      random_state=0)\n    ```", "```py\n    pd.get_dummies(X_demo_train, \\\n      columns=['gender','maritalstatus']).head(2).T\n    personid                    736081          832734\n    colenroct99                 1.Not enrolled  1.Not enrolled\n    gender_Female               1               0\n    gender_Male                 0               1\n    maritalstatus_Divorced      0               0\n    maritalstatus_Married       1               0\n    maritalstatus_Never-married 0               1\n    maritalstatus_Separated     0               0\n    maritalstatus_Widowed       0               0\n    ```", "```py\n    pd.get_dummies(X_demo_train, \\\n      columns=['gender','maritalstatus'],\n      drop_first=True).head(2).T\n    personid                      736081          832734\n    colenroct99                  1\\. Not enrolled  1\\. Not enrolled\n    gender_Male                  0                1\n    maritalstatus_Married        1                0\n    maritalstatus_Never-married  0                1\n    maritalstatus_Separated      0                0\n    maritalstatus_Widowed        0                0\n    ```", "```py\n    ohe = OneHotEncoder(drop_last=True,\n      variables=['gender','maritalstatus'])\n    ohe.fit(X_demo_train)\n    X_demo_train_ohe = ohe.transform(X_demo_train)\n    X_demo_test_ohe = ohe.transform(X_demo_test)\n    X_demo_train_ohe.filter(regex='gen|mar', axis=\"columns\").head(2).T\n    personid                     736081          832734\n    gender_Female                1               0\n    maritalstatus_Married        1               0\n    maritalstatus_Never-married  0               1\n    maritalstatus_Divorced       0               0\n    maritalstatus_Separated      0               0\n    ```", "```py\n    X_demo_train.colenroct99.unique()\n    array(['1\\. Not enrolled', '2\\. 2-year college ', \n           '3\\. 4-year college'], dtype=object)\n    X_demo_train.head()\n                gender   maritalstatus   colenroct99\n    personid                                           \n    736081      Female   Married         1\\. Not enrolled\n    832734      Male     Never-married   1\\. Not enrolled\n    453537      Male     Married         1\\. Not enrolled\n    322059      Female   Divorced        1\\. Not enrolled\n    324323      Female   Married         2\\. 2-year college\n    ```", "```py\n    oe = OrdinalEncoder(categories=\\\n      [X_demo_train.colenroct99.unique()])\n    colenr_enc = \\\n      pd.DataFrame(oe.fit_transform(X_demo_train[['colenroct99']]),\n        columns=['colenroct99'], index=X_demo_train.index)\n    X_demo_train_enc = \\\n      X_demo_train[['gender','maritalstatus']].\\\n      join(colenr_enc)\n    ```", "```py\n    X_demo_train_enc.head()\n                 gender       maritalstatus    colenroct99\n    personid                                    \n    736081       Female       Married          0\n    832734       Male         Never-married    0\n    453537       Male         Married          0\n    322059       Female       Divorced         0\n    324323       Female       Married          1\n    X_demo_train.colenroct99.value_counts().sort_index()\n    1\\. Not enrolled        3050\n    2\\. 2-year college       142\n    3\\. 4-year college       350\n    Name: colenroct99, dtype: int64\n    X_demo_train_enc.colenroct99.value_counts().sort_index()\n    0       3050\n    1       142\n    2       350\n    Name: colenroct99, dtype: int64\n    ```", "```py\n    import pandas as pd\n    from feature_engine.encoding import OneHotEncoder\n    from category_encoders.hashing import HashingEncoder\n    from sklearn.model_selection import train_test_split\n    covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n    feature_cols = ['location','population',\n        'aged_65_older','diabetes_prevalence','region']\n    covidtotals = covidtotals[['total_cases'] + feature_cols].dropna()\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(covidtotals[feature_cols],\\\n      covidtotals[['total_cases']], test_size=0.3, \n      random_state=0)\n    ```", "```py\nX_train.region.value_counts()\nEastern Europe  16\nEast Asia  12\nWestern Europe  12\nWest Africa  11\nWest Asia  10\nEast Africa  10\nSouth America  7\nSouth Asia  7\nCentral Africa  7\nSouthern Africa  7\nOceania / Aus  6\nCaribbean  6\nCentral Asia  5\nNorth Africa  4\nNorth America  3\nCentral America  3\nName: region, dtype: int64\n```", "```py\n    ohe = OneHotEncoder(top_categories=6, variables=['region'])\n    covidtotals_ohe = ohe.fit_transform(covidtotals)\n    covidtotals_ohe.filter(regex='location|region',\n      axis=\"columns\").sample(5, random_state=99).T\n              97      173      92         187        104\n    Location  Israel  Senegal  Indonesia  Sri Lanka  Kenya\n    region_Eastern Europe  0      0      0      0      0\n    region_Western Europe  0      0      0      0      0\n    region_West Africa     0      1      0      0      0\n    region_East Asia       0      0      1      0      0\n    region_West Asia       1      0      0      0      0\n    region_East Africa     0      0      0      0      1\n    ```", "```py\nX_train['region2'] = X_train.region\n```", "```py\nhe = HashingEncoder(cols=['region'], n_components=6)\n```", "```py\nX_train_enc = he.fit_transform(X_train)\n```", "```py\nX_train_enc.\\\n```", "```py\n groupby(['col_0','col_1','col_2','col_3','col_4',\n```", "```py\n   'col_5','region2']).\\\n```", "```py\n    size().reset_index().rename(columns={0:'count'})\n```", "```py\n  col_0 col_1 col_2 col_3 col_4 col_5 region2         count\n```", "```py\n0   0     0     0     0     0     1   Caribbean       6\n```", "```py\n1   0     0     0     0     0     1   Central Africa  7\n```", "```py\n2   0     0     0     0     0     1   East Africa     10\n```", "```py\n3   0     0     0     0     0     1   North Africa    4\n```", "```py\n4   0     0     0     0     1     0   Central America 3\n```", "```py\n5   0     0     0     0     1     0   Eastern Europe  16\n```", "```py\n6   0     0     0     0     1     0   North America   3\n```", "```py\n7   0     0     0     0     1     0   Oceania / Aus   6\n```", "```py\n8   0     0     0     0     1     0   Southern Africa 7\n```", "```py\n9   0     0     0     0     1     0   West Asia       10\n```", "```py\n10  0     0     0     0     1     0   Western Europe  12\n```", "```py\n11  0     0     0     1     0     0   Central Asia    5\n```", "```py\n12  0     0     0     1     0     0   East Asia       12\n```", "```py\n13  0     0     0     1     0     0   South Asia      7\n```", "```py\n14  0     0     1     0     0     0   West Africa     11\n```", "```py\n15  1     0     0     0     0     0   South America   7\n```", "```py\n    import pandas as pd\n    from feature_engine import transformation as vt\n    from sklearn.model_selection import train_test_split\n    import matplotlib.pyplot as plt\n    from scipy import stats\n    covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n    feature_cols = ['location','population',\n        'aged_65_older','diabetes_prevalence','region']\n    covidtotals = covidtotals[['total_cases'] + feature_cols].dropna()\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(covidtotals[feature_cols],\\\n      covidtotals[['total_cases']], test_size=0.3, \\\n      random_state=0)\n    ```", "```py\n    y_train.total_cases.skew()\n    6.313169268923333\n    plt.hist(y_train.total_cases)\n    plt.title(\"Total COVID Cases  (in millions)\")\n    plt.xlabel('Cases')\n    plt.ylabel(\"Number of Countries\")\n    plt.show()\n    ```", "```py\n    tf = vt.LogTransformer(variables = ['total_cases'])\n    y_train_tf = tf.fit_transform(y_train)\n    y_train_tf.total_cases.skew()\n    -1.3872728024141519\n    plt.hist(y_train_tf.total_cases)\n    plt.title(\"Total COVID Cases (log transformation)\")\n    plt.xlabel('Cases')\n    plt.ylabel(\"Number of Countries\")\n    plt.show()\n    ```", "```py\n    tf = vt.BoxCoxTransformer(variables = ['total_cases'])\n    y_train_tf = tf.fit_transform(y_train)\n    y_train_tf.total_cases.skew()\n    0.07333475786753735\n    plt.hist(y_train_tf.total_cases)\n    plt.title(\"Total COVID Cases (Box-Cox transformation)\")\n    plt.xlabel('Cases')\n    plt.ylabel(\"Number of Countries\")\n    plt.show()\n    ```", "```py\nstats.boxcox(y_train.total_cases)[1]\n```", "```py\n0.10435377585681517\n```", "```py\n    import pandas as pd\n    from feature_engine.discretisation import EqualFrequencyDiscretiser as efd\n    from feature_engine.discretisation import EqualWidthDiscretiser as ewd\n    from sklearn.preprocessing import KBinsDiscretizer\n    from sklearn.model_selection import train_test_split\n    covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n    feature_cols = ['location','population',\n        'aged_65_older','diabetes_prevalence','region']\n    covidtotals = covidtotals[['total_cases'] + feature_cols].dropna()\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(covidtotals[feature_cols],\\\n      covidtotals[['total_cases']], test_size=0.3, random_state=0)\n    ```", "```py\n    y_train['total_cases_group'] = pd.qcut(y_train.total_cases, q=10, labels=[0,1,2,3,4,5,6,7,8,9])\n    y_train.total_cases_group.value_counts().sort_index()\n    0   13\n    1   13\n    2   12\n    3   13\n    4   12\n    5   13\n    6   12\n    7   13\n    8   12\n    9   13\n    Name: total_cases_group, dtype: int64\n    ```", "```py\n    def runtransform(bt, dftrain, dftest):\n      bt.fit(dftrain)\n      train_bins = bt.transform(dftrain)\n      test_bins = bt.transform(dftest)\n      return train_bins, test_bins\n    ```", "```py\n    y_train.drop(['total_cases_group'], axis=1, inplace=True)\n    bintransformer = efd(q=10, variables=['total_cases'])\n    y_train_bins, y_test_bins = runtransform(bintransformer, y_train, y_test)\n    y_train_bins.total_cases.value_counts().sort_index()\n    0  13\n    1  13\n    2  12\n    3  13\n    4  12\n    5  13\n    6  12\n    7  13\n    8  12\n    9  13\n    Name: total_cases, dtype: int64\n    ```", "```py\n    bintransformer = ewd(bins=10, variables=['total_cases'])\n    y_train_bins, y_test_bins = runtransform(bintransformer, y_train, y_test)\n    y_train_bins.total_cases.value_counts().sort_index()\n    0  119\n    1  4\n    5  1\n    9  2\n    Name: total_cases, dtype: int64\n    ```", "```py\n    pd.options.display.float_format = '{:,.0f}'.format\n    y_train_bins = y_train_bins.\\\n      rename(columns={'total_cases':'total_cases_group'}).\\\n      join(y_train)\n    y_train_bins.groupby(\"total_cases_group\")[\"total_cases\"].agg(['min','max'])\n      min  max\n    total_cases_group       \n    0  1           3,304,135\n    1  3,740,567   5,856,682\n    5  18,909,037  18,909,037\n    9  30,709,557  33,770,444\n    ```", "```py\n    kbins = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='kmeans')\n    y_train_bins = \\\n      pd.DataFrame(kbins.fit_transform(y_train),\n      columns=['total_cases'])\n    y_train_bins.total_cases.value_counts().sort_index()\n    0  49\n    1  24\n    2  23\n    3  11\n    4  6\n    5  6\n    6  4\n    7  1\n    8  1\n    9  1\n    Name: total_cases, dtype: int64\n    ```", "```py\n    y_train.total_cases.agg(['skew','kurtosis'])\n    skew          6.313\n    kurtosis     41.553\n    Name: total_cases, dtype: float64\n    y_train_bins.total_cases.agg(['skew','kurtosis'])\n    skew            1.439\n    kurtosis        1.923\n    Name: total_cases, dtype: float64\n    ```", "```py\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n    covidtotals = pd.read_csv(\"data/covidtotals.csv\")\n    feature_cols = ['population','total_deaths',\n        'aged_65_older','diabetes_prevalence']\n    covidtotals = covidtotals[['total_cases'] + feature_cols].dropna()\n    X_train, X_test, y_train, y_test =  \\\n      train_test_split(covidtotals[feature_cols],\\\n      covidtotals[['total_cases']], test_size=0.3, random_state=0)\n    ```", "```py\n    scaler = MinMaxScaler()\n    X_train_mms = pd.DataFrame(scaler.fit_transform(X_train),\n      columns=X_train.columns, index=X_train.index)\n    X_train_mms.describe()\n         population total_deaths aged_65_older diabetes_prevalence\n    count  123.00      123.00        123.00        123.00\n    mean   0.04        0.04          0.30          0.41\n    std    0.13        0.14          0.24          0.23\n    min    0.00        0.00          0.00          0.00\n    25%    0.00        0.00          0.10          0.26\n    50%    0.01        0.00          0.22          0.37\n    75%    0.02        0.02          0.51          0.54\n    max    1.00        1.00          1.00          1.00\n    ```", "```py\n    scaler = StandardScaler()\n    X_train_ss = pd.DataFrame(scaler.fit_transform(X_train),\n      columns=X_train.columns, index=X_train.index)\n    X_train_ss.describe()\n           population  total_deaths  aged_65_older  diabetes_prevalence\n    count  123.00      123.00        123.00       123.00\n    mean  -0.00       -0.00         -0.00        -0.00\n    std    1.00        1.00          1.00         1.00\n    min   -0.29       -0.32         -1.24        -1.84\n    25%   -0.27       -0.31         -0.84        -0.69\n    50%   -0.24       -0.29         -0.34        -0.18\n    75%   -0.11       -0.18          0.87         0.59\n    max    7.58        6.75          2.93         2.63\n    ```", "```py\n    scaler = RobustScaler()\n    X_train_rs = pd.DataFrame(\n      scaler.fit_transform(X_train),\n      columns=X_train.columns, index=X_train.index)\n    X_train_rs.describe()\n         population total_deaths aged_65_older diabetes_prevalence\n    count  123.00      123.00      123.00      123.00\n    mean   1.47        2.22        0.20        0.14\n    std    6.24        7.65        0.59        0.79\n    min   -0.35       -0.19       -0.53       -1.30\n    25%   -0.24       -0.15       -0.30       -0.40\n    50%    0.00        0.00        0.00        0.00\n    75%    0.76        0.85        0.70        0.60\n    max    48.59       53.64       1.91        2.20\n    ```"]