["```py\nCascadeClassifier face_cascade;\nface_cascade.load(\"haarcascade_frontalface_default.xml\");\n```", "```py\nMat img, img_gray;\nimg = imread(imgPath[i], CV_LOAD_IMAGE_COLOR);\ncvtColor(img, img_gray, CV_RGB2GRAY);\nequalizeHist(img_gray, img_gray);\n```", "```py\nvector<Rect> faces;\nface_cascade.detectMultiScale( img_gray, faces, 1.1, 3 );\n```", "```py\nint bbox[4] = { faces[i].x, faces[i].y, faces[i].x + faces[i].width, faces[i].y + faces[i].height };\n```", "```py\n    git clone http://github.com/uricamic/flandmark\n\n    ```", "```py\n    #include \"msvc-compat.h\"\n    ```", "```py\n    #include <stdint.h>\n    ```", "```py\n    #include \"msvc-compat.h\"\n    #include <cv.h> \n    #include <cvaux.h>\n    ```", "```py\n    #include <stdint.h>\n    #include \"opencv2/opencv.hpp\"\n    #include \"opencv2/objdetect/objdetect.hpp\"\n    #include \"opencv2/highgui/highgui.hpp\"\n    #include \"opencv2/imgproc/imgproc.hpp\"\n    #include <iostream>\n    #include <stdio.h>\n    using namespace std;\n    using namespace cv;\n    ```", "```py\n    add_subdirectory(libflandmark)\n    include_directories(\"${PROJECT_SOURCE_DIR}/libflandmark\")\n    ```", "```py\n    #include \"flandmark_detector.h\"\n    ```", "```py\nFLANDMARK_Model * model = flandmark_init(\"flandmark_model.dat\");\n```", "```py\nint num_of_landmark = model->data.options.M;\ndouble *points = new double[2 * num_of_landmark];\n```", "```py\nint bbox[4] = { faces[i].x, faces[i].y, faces[i].x + faces[i].width, faces[i].y + faces[i].height };\nflandmark_detect(new IplImage(img_gray), bbox, model, points);\n```", "```py\nfor(int j = 0 ; j < num_of_landmark; j++){\n  Point landmark = Point((int)points[2 * j], (int)points[2* j + 1]);\n  circle(img, landmark, 4, Scalar(255, 255, 255), -1);\n}\n```", "```py\nPoint centerLeft = Point( (int) (points[2 * 6] + points[2 * 2]) / 2, (int) (points[2 * 6 + 1] + points[2 * 2 + 1]) / 2 );\n```", "```py\nint widthLeft = abs(points[2 * 6] - points[2 * 2]);\n```", "```py\nPoint centerRight = Point( (int) (points[2 * 1] + points[2 * 5]) / 2, (int) (points[2 * 1 + 1] + points[2 * 5 + 1]) / 2 );\nint widthRight = abs(points[2 * 1] - points[2 * 5]);\n```", "```py\nint widthFace = (centerLeft.x + widthLeft) - (centerRight.x - widthRight);\nint heightFace = widthFace * 1.2;\n```", "```py\nMat face = img(Rect( centerRight.x - widthFace/4  , centerRight.y - heightFace/4, widthFace, heightFace ));\n```", "```py\n    mkdir build && cd build && cmake .. && make\n\n    ```", "```py\n    ./facial_components -src <input_folder> -dest <out_folder>\n\n    ```", "```py\nMat extractFeature(Mat face, string feature_name);\n```", "```py\nMat extractFeature(Mat img, string feature_name){\n    Mat descriptors;\n    if(feature_name.compare(\"brisk\") == 0){\n        descriptors = extractBrisk(img);\n    } else if(feature_name.compare(\"kaze\") == 0){\n        descriptors = extractKaze(img);\n    } else if(feature_name.compare(\"sift\") == 0){\n        descriptors = extractSift(img);\n    } else if(feature_name.compare(\"dense-sift\") == 0){\n        descriptors = extractDenseSift(img);\n    } else if(feature_name.compare(\"daisy\") == 0){\n        descriptors = extractDaisy(img);\n    }\n    return descriptors;\n}\n```", "```py\nMat extractSift(Mat img){\n    Mat descriptors;\n    vector<KeyPoint> keypoints;\n\n    Ptr<Feature2D> sift = xfeatures2d::SIFT::create();\n    sift->detect(img, keypoints, Mat());\n    sift->compute(img, keypoints, descriptors);\n\n    return descriptors;\n}\n```", "```py\nMat extractSurf(Mat img){\n    Mat descriptors;\n    vector<KeyPoint> keypoints;\n\n    Ptr<Feature2D> surf = xfeatures2d::SURF::create();\n    surf->detect(img, keypoints, Mat());\n    surf->compute(img, keypoints, descriptors);\n\n    return descriptors;\n}\n```", "```py\nMat extractDaisy(Mat img){\n    Mat descriptors;\n    vector<KeyPoint> keypoints;\n\n    Ptr<FeatureDetector> surf = xfeatures2d::SURF::create();\n    surf->detect(img, keypoints, Mat());\n    Ptr<DescriptorExtractor> daisy = xfeatures2d::DAISY::create();\n    daisy->compute(img, keypoints, descriptors);\n\n    return descriptors;\n}\n```", "```py\nMat extractDenseSift(Mat img){\n    Mat descriptors;\n    vector<KeyPoint> keypoints;\n\n    Ptr<Feature2D> sift = xfeatures2d::SIFT::create();\n createDenseKeyPoints(keypoints, img);\n    sift->compute(img, keypoints, descriptors);\n\n    return descriptors;\n}\n```", "```py\nvoid createDenseFeature(vector<KeyPoint> &keypoints, Mat image, float initFeatureScale=1.f, int featureScaleLevels=1,\n                                    float featureScaleMul=0.1f,\n                                    int initXyStep=6, int initImgBound=0,\n                                    bool varyXyStepWithScale=true,\n                                    bool varyImgBoundWithScale=false){\n    float curScale = static_cast<float>(initFeatureScale);\n    int curStep = initXyStep;\n    int curBound = initImgBound;\n    for( int curLevel = 0; curLevel < featureScaleLevels; curLevel++ )\n    {\n        for( int x = curBound; x < image.cols - curBound; x += curStep )\n        {\n            for( int y = curBound; y < image.rows - curBound; y += curStep )\n            {\n                keypoints.push_back( KeyPoint(static_cast<float>(x), static_cast<float>(y), curScale) );\n            }\n        }\n        curScale = static_cast<float>(curScale * featureScaleMul);\n        if( varyXyStepWithScale ) curStep = static_cast<int>( curStep * featureScaleMul + 0.5f );\n        if( varyImgBoundWithScale ) curBound = static_cast<int>( curBound * featureScaleMul + 0.5f );\n    }\n}\n```", "```py\nMat extractBrisk(Mat img){\n    Mat descriptors;\n    vector<KeyPoint> keypoints;\n\n    Ptr<DescriptorExtractor> brisk = BRISK::create();\n    brisk->detect(img, keypoints, Mat());\n    brisk->compute(img, keypoints, descriptors);\n\n    return descriptors;\n}\n```", "```py\nMat extractKaze(Mat img){\n    Mat descriptors;\n    vector<KeyPoint> keypoints;\n\n    Ptr<DescriptorExtractor> kaze = KAZE::create();\n    kaze->detect(img, keypoints, Mat());\n    kaze->compute(img, keypoints, descriptors);\n\n    return descriptors;\n}\n```", "```py\nMat rawFeatureData = Mat::zeros(num_of_feature, image_feature_size, CV_32FC1);\n```", "```py\nint cur_idx = 0;\nfor(int i = 0 ; i < features_vector.size(); i++){\n    features_vector[i].copyTo(rawFeatureData.rowRange(cur_idx, cur_idx + features_vector[i].rows));\n    cur_idx += features_vector[i].rows;\n}\n```", "```py\nMat labels, centers;\nkmeans(rawFeatureData, k, labels, TermCriteria( TermCriteria::EPS+TermCriteria::COUNT, 100, 1.0), 3, KMEANS_PP_CENTERS, centers);\n```", "```py\ndouble kmeans(InputArray data, int K, InputOutputArray bestLabels, TermCriteria criteria, int attempts, int flags, OutputArray centers=noArray())\n```", "```py\nPCA pca(featureDataOverBins, cv::Mat(), CV_PCA_DATA_AS_ROW, 0.90);\n```", "```py\nfor(int i = 0 ; i < num_of_image; i++){\n    Mat feature = pca.project(featureDataOverBins.row(i));\n    // save the feature in FileStorage\n}\n```", "```py\nint feature_size = pca.eigenvectors.rows;\n```", "```py\n    mkdir build && cd build && cmake .. && make\n\n    ```", "```py\n    ./feature_extraction  -feature <feature_name> -src <input_folder> -dest <output_folder>\n\n    ```", "```py\nPtr<ml::SVM> svm = ml::SVM::create();\n```", "```py\nsvm->setType(SVM::C_SVC);\nsvm->setKernel(SVM::RBF);\n```", "```py\nPtr<ml::TrainData> trainData = ml::TrainData::create(train_features, ml::SampleTypes::ROW_SAMPLE, labels);\n```", "```py\n    Mat train_labels = Mat::zeros( labels.rows, 1, CV_32S);\n    for(int i = 0 ; i < labels.rows; i ++){\n        train_labels.at<unsigned int>(i, 0) = labels.at<int>(i, 0);\n    }\n    ```", "```py\nsvm->trainAuto(trainData);\n```", "```py\nfloat predict = svm->predict(sample);\n```", "```py\nMat layers = Mat(3, 1, CV_32S);\n```", "```py\nlayers.row(0) = Scalar(feature_size);\nlayers.row(1) = Scalar(20);\nlayers.row(2) = Scalar(num_of_labels);\n```", "```py\nPtr<ml::ANN_MLP> mlp = ml::ANN_MLP::create();\nmlp->setLayerSizes(layers);\n```", "```py\nmlp->setTrainMethod(ml::ANN_MLP::BACKPROP);\nmlp->setActivationFunction(ml::ANN_MLP::SIGMOID_SYM, 0, 0);\nmlp->setTermCriteria(TermCriteria(TermCriteria::EPS+TermCriteria::COUNT, 100000, 0.00001f));\n```", "```py\nPtr<ml::TrainData> trainData = ml::TrainData::create(train_features, ml::SampleTypes::ROW_SAMPLE, train_labels);\n```", "```py\n    Mat train_labels = Mat::zeros( labels.rows, num_of_label, CV_32FC1);\n    for(int i = 0 ; i < labels.rows; i ++){\n        int idx = labels.at<int>(i, 0);\n        train_labels.at<float>(i, idx) = 1.0f;\n    }\n    ```", "```py\nmlp->train(trainData);\n```", "```py\nMat response(1, num_of_labels, CV_32FC1);\n```", "```py\nmlp->predict(sample, response);\n```", "```py\nPtr<ml::KNearest> knn = ml::KNearest::create();\nPtr<ml::TrainData> trainData = ml::TrainData::create(train_features, ml::SampleTypes::ROW_SAMPLE, labels);\nknn->train(trainData);\n```", "```py\nMat predictedLabels;\nknn->findNearest(sample, K, predictedLabels);\n```", "```py\nfloat prediction = bestLabels.at<float>(0,0);\n```", "```py\nPtr<ml::NormalBayesClassifier> bayes = ml::NormalBayesClassifier::create();\nPtr<ml::TrainData> trainData = ml::TrainData::create(train_features, ml::SampleTypes::ROW_SAMPLE, labels);\nbayes->train(trainData);\n```", "```py\n    Mat output, outputProb;\n    ```", "```py\n    bayes->predictProb(sample, output, outputProb);\n    ```", "```py\n    unsigned int label = output.at<unsigned int>(0, 0);\n    ```", "```py\n    mkdir build && cd build && cmake .. && make\n\n    ```", "```py\n    ./train -algo <algorithm_name> -src <input_features> -dest <output_folder>\n\n    ```", "```py\ngit clone https://github.com/Itseez/opencv.git --depth=1\n\n```", "```py\ngit clone https://github.com/Itseez/opencv_contrib --depth=1\n\n```", "```py\ncd opencv\nmkdir build\ncd build\n\n```", "```py\ncmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/ ..\nmake -j4\nmake install\n\n```"]