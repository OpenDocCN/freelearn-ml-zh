- en: Chapter 4. Understanding Regression Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Fitting a linear regression model with lm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarizing linear model fits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using linear regression to predict unknown values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating a diagnostic plot of a fitted model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fitting a polynomial regression model with lm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fitting a robust linear regression model with rlm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Studying a case of linear regression on SLID data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the Gaussian model for generalized linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the Poisson model for generalized linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the Binomial model for generalized linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fitting a generalized additive model to data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing a generalized additive model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagnosing a generalized additive model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regression is a supervised learning method, which is employed to model and analyze
    the relationship between a dependent (response) variable and one or more independent
    (predictor) variables. One can use regression to build a prediction model, which
    can first be used to find the best fitted model with minimum squared errors of
    the fitted values. The fitted model can then be further applied to data for continuous
    value predictions.
  prefs: []
  type: TYPE_NORMAL
- en: There are many types of regression. If there is only one predictor variable,
    and the relationship between the response variable and independent variable is
    linear, we can apply a linear model. However, if there is more than one predictor
    variable, a multiple linear regression method should be used. When the relationship
    is nonlinear, one can use a nonlinear model to model the relationship between
    the predictor and response variables.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we introduce how to fit a linear model into data with the `lm`
    function. Next, for distribution in other than the normal Gaussian model (for
    example, Poisson or Binomial), we use the `glm` function with an appropriate link
    function correspondent to the data distribution. Finally, we cover how to fit
    a generalized additive model into data using the `gam` function.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting a linear regression model with lm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The simplest model in regression is linear regression, which is best used when
    there is only one predictor variable, and the relationship between the response
    variable and the independent variable is linear. In R, we can fit a linear model
    to data with the `lm` function.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to prepare data with one predictor and response variable, and with a
    linear relationship between the two variables.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to perform linear regression with `lm`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You should install the `car` package and load its library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'From the package, you can load the `Quartet` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can use the `str` function to display the structure of the `Quartet` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Draw a scatter plot of the x and y variables with `plot`, and append a fitted
    line through the `lm` and `abline` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00078.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: A simple regression plot fitted by lm
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To view the fit model, execute the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The regression model has the `response ~ terms` form, where `response` is the
    response vector, and `terms` is a series of terms that specifies a predictor.
    We can illustrate a simple regression model in the formula *y=α+βx*, where *α*
    is the intercept while the slope, *β*, describes the change in *y* when *x* changes.
    By using the least squares method, we can estimate ![How it works...](img/00079.jpeg)
    and ![How it works...](img/00080.jpeg) (where ![How it works...](img/00081.jpeg)
    indicates the mean value of *y* and ![How it works...](img/00082.jpeg) denotes
    the mean value of *x*).
  prefs: []
  type: TYPE_NORMAL
- en: To perform linear regression, we first prepare the data that has a linear relationship
    between the predictor variable and response variable. In this example, we load
    Anscombe's quartet dataset from the package car. Within the dataset, the *x* and
    *y1* variables have a linear relationship, and we prepare a scatter plot of these
    variables. To generate the regression line, we use the lm function to generate
    a model of the two variables. Further, we use `abline` to plot a regression line
    on the plot. As per the previous screenshot, the regression line illustrates the
    linear relationship of *x* and *y1* variables. We can see that the coefficient
    of the fitted model shows the intercept equals 3.0001 and coefficient equals 0.5001\.
    As a result, we can use the intercept and coefficient to infer the response value.
    For example, we can infer the response value when *x* at 3 is equal to *4.5103
    (3 * 0.5001 + 3.0001)*.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Besides the `lm` function, you can also use the `lsfit` function to perform
    simple linear regression. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![There''s more...](img/00083.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: A simple regression fitted by the lsfit function.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing linear model fits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `summary` function can be used to obtain the formatted coefficient, standard
    errors, degree of freedom, and other summarized information of a fitted model.
    This recipe introduces how to obtain overall information on a model through the
    use of the `summary` function.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to have completed the previous recipe by computing the linear model
    of the *x* and *y1* variables from the quartet, and have the fitted model assigned
    to the `lmfit` variable.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following step to summarize linear model fits:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Compute a detailed summary of the fitted model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `summary` function is a generic function used to produce summary statistics.
    In this case, it computes and returns a list of the summary statistics of the
    fitted linear model. Here, it will output information such as residuals, coefficient
    standard error R-squared, f-statistic, and a degree of freedom. In the `Call`
    section, the function called to generate the fitted model is displayed. In the
    `Residuals` section, it provides a quick summary (min, 1Q, median, 3Q, max) of
    the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: In the `Coefficients` section, each coefficient is a Gaussian random variable.
    Within this section, `Estimate` represents the mean distribution of the variable;
    `Std.Error` displays the standard error of the variable; the `t` value is `Estimate`
    divided by `Std.Error` and the `p` value indicates the probability of getting
    a value larger than the `t` value. In this sample, the `p` value of both intercepts
    (0.002573) and x (0.00217) have a 95 percent level of confidence.
  prefs: []
  type: TYPE_NORMAL
- en: Residual standard error outputs the standard deviation of residuals, while the
    degree of freedom indicates the differences between the observation in training
    samples and the number used in the model. Multiple R-squared is obtained by dividing
    the sum of squares. One can use R-squared to measure how close the data is to
    fit into the regression line. Mostly, the higher the R-squared, the better the
    model fits your data. However, it does not necessarily indicate whether the regression
    model is adequate. This means you might get a good model with a low R-squared
    or you can have a bad model with a high R-squared. Since multiple R-squared ignore
    a degree of freedom, the calculated score is biased. To make the calculation fair,
    an adjusted R-squared (0.6295) uses an unbiased estimate, and will be slightly
    less than multiple R-squared (0.6665). F-statistic is retrieved by performing
    an f-test on the model. A `p` value equal to 0.00217 (< 0.05) rejects the null
    hypothesis (no linear correlation between variables) and indicates that the observed
    `F` is greater than the critical `F` value. In other words, the result shows that
    there is a significant positive linear correlation between the variables.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For more information on the parameters used for obtaining a summary of the
    fitted model, you can use the `help` function or `?` to view the help page:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Alternatively, you can use the following functions to display the properties
    of the model:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Using linear regression to predict unknown values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With a fitted regression model, we can apply the model to predict unknown values.
    For regression models, we can express the precision of prediction with a prediction
    interval and a confidence interval. In the following recipe, we introduce how
    to predict unknown values under these two measurements.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to have completed the previous recipe by computing the linear model
    of the x and y1 variables from the `quartet` dataset.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to predict values with linear regression:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fit a linear model with the `x` and `y1` variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign values to be predicted into `newdata`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute the prediction result using the confidence interval with `level` set
    as `0.95`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Compute the prediction result using this prediction interval:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We first build a linear fitted model with `x` and `y1` variables. Next, we assign
    values to be predicted into a data frame, `newdata`. It is important to note that
    the generated model is in the form of `y1 ~ x`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we compute the prediction result using a confidence interval by specifying
    `confidence` in the argument interval. From the output of row 1, we get fitted
    `y1` of the `x=3` input, which equals to `4.500364`, and a 95 percent confidence
    interval (set 0.95 in the `level` argument) of the `y1` mean for `x=3` is between
    `2.691375` and `6.309352`. In addition to this, row 2 and 3 give the prediction
    result of `y1` with an input of `x=6` and `x=15`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we compute the prediction result using a prediction interval by specifying
    `prediction` in the argument interval. From the output of row 1, we can see fitted
    `y1` of the `x=3` input equals to `4.500364`, and a 95 percent prediction interval
    of `y1` for `x=3` is between `1.169022` and `7.831705`. Row 2 and 3 output the
    prediction result of `y1` with an input of `x=6` and `x=15`.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For those who are interested in the differences between prediction intervals
    and confidence intervals, you can refer to the Wikipedia entry *contrast with
    confidence intervals* at [http://en.wikipedia.org/wiki/Prediction_interval#Contrast_with_confidence_intervals](http://en.wikipedia.org/wiki/Prediction_interval#Contrast_with_confidence_intervals).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating a diagnostic plot of a fitted model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Diagnostics are methods to evaluate assumptions of the regression, which can
    be used to determine whether a fitted model adequately represents the data. In
    the following recipe, we introduce how to diagnose a regression model through
    the use of a diagnostic plot.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to have completed the previous recipe by computing a linear model of
    the x and y1 variables from the quartet, and have the model assigned to the `lmfit`
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following step to generate a diagnostic plot of the fitted model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Plot the diagnostic plot of the regression model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00084.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Diagnostic plots of the regression model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The plot function generates four diagnostic plots of a regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: The upper-left plot shows residuals versus fitted values. Within the plot, residuals
    represent the vertical distance from a point to the regression line. If all points
    fall exactly on the regression line, all residuals will fall exactly on the dotted
    gray line. The red line within the plot is a smooth curve with regard to residuals,
    and if all the dots fall exactly on the regression line, the position of the red
    line should exactly match the dotted gray line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The upper-right shows the normal of residuals. This plot verifies the assumption
    that residuals were normally distributed. Thus, if the residuals were normally
    distributed, they should lie exactly on the gray dash line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Scale-Location** plot on the bottom-left is used to measure the square
    root of the standardized residuals against the fitted value. Therefore, if all
    dots lie on the regression line, the value of *y* should be close to zero. Since
    it is assumed that the variance of residuals does not change the distribution
    substantially, if the assumption is correct, the red line should be relatively
    flat.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bottom-right plot shows standardized residuals versus leverage. The leverage
    is a measurement of how each data point influences the regression. It is a measurement
    of the distance from the centroid of regression and level of isolation (measured
    by whether it has neighbors). Also, you can find the contour of Cook's distance,
    which is affected by high leverage and large residuals. You can use this to measure
    how regression would change if a single point is deleted. The red line is smooth
    with regard to standardized residuals. For a perfect fit regression, the red line
    should be close to the dashed line with no points over 0.5 in Cook's distance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To see more of the diagnostic plot function, you can use the `help` function
    to access further information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to discover whether there are points with large Cook''s distance,
    one can use the `cooks.distance` function to compute the Cook''s distance of each
    point, and analyze the distribution of distance through visualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![There''s more...](img/00085.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: A plot of Cook's distance
  prefs: []
  type: TYPE_NORMAL
- en: In this case, where the point on index 3 shows greater Cook's distance than
    other points, one can investigate whether this point might be an outlier.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting a polynomial regression model with lm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some predictor variables and response variables may have a non-linear relationship,
    and their relationship can be modeled as an *nth* order polynomial. In this recipe,
    we introduce how to deal with polynomial regression using the `lm` and `poly`
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prepare the dataset that includes a relationship between the predictor and response
    variable that can be modeled as an *nth* order polynomial. In this recipe, we
    will continue to use the `Quartet` dataset from the `car` package.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to fit the polynomial regression model with `lm`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we make a scatter plot of the `x` and `y2` variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00086.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Scatter plot of variables x and y2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can apply the `poly` function by specifying `2` in the argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00087.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: A quardratic fit example of the regression plot of variables x and y2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can illustrate the second order polynomial regression model in formula, ![How
    it works](img/00088.jpeg), where *α* is the intercept while *β*, illustrates regression
    coefficients.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot (step 1), the scatter plot of the `x` and `y2` variables
    does not fit in a linear relationship, but shows a concave downward curve (or
    convex upward) with the turning point at x=11\. In order to model the nonlinear
    relationship, we apply the `poly` function with an argument of 2 to fit the independent
    `x` variable and the dependent `y2` variable. The red line in the screenshot shows
    that the model perfectly fits the data.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can also fit a second order polynomial model with an independent variable
    equal to the formula of the combined first order `x` variable and the second order
    `x` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Fitting a robust linear regression model with rlm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An outlier in the dataset will move the regression line away from the mainstream.
    Apart from removing it, we can apply a robust linear regression to fit datasets
    containing outliers. In this recipe, we introduce how to apply `rlm` to perform
    robust linear regression to datasets containing outliers.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prepare the dataset that contains an outlier that may move the regression line
    away from the mainstream. Here, we use the `Quartet` dataset loaded from the previous
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to fit the robust linear regression model with
    `rlm`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a scatter plot of the `x` variable against `y3`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00089.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Scatter plot of variables x and y3
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, you should import the `MASS` library first. Then, you can apply the `rlm`
    function to fit the model, and visualize the fitted line with the `abline` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00090.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Robust linear regression to variables x and y3
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As per the preceding screenshot (step 1), you may encounter datasets that include
    outliers away from the mainstream. To remove the effect of an outlier, we demonstrate
    how to apply a robust linear regression (`rlm`) to fit the data. In the second
    screenshot (step 2), the robust regression line ignores the outlier and matches
    the mainstream.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To see the effect of how an outlier can move the regression line away from
    the mainstream, you may replace the `rlm` function used in this recipe to `lm`,
    and replot the graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![There''s more...](img/00091.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Linear regression on variables x and y3
  prefs: []
  type: TYPE_NORMAL
- en: It is obvious that outlier (x=13) moves the regression line away from the mainstream.
  prefs: []
  type: TYPE_NORMAL
- en: Studying a case of linear regression on SLID data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To summarize the contents of the previous section, we explore more complex data
    with linear regression. In this recipe, we demonstrate how to apply linear regression
    to analyze the **Survey of Labor and Income Dynamics** (**SLID**) dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Check whether the `car` library is installed and loaded, as it is required to
    access thedataset SLID.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to perform linear regression on SLID data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the `str` function to get an overview of the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'First, we visualize the variable wages against language, age, education, and
    sex:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00092.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Plot of wages against multiple combinations
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then, we can use `lm` to fit the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can examine the summary of the fitted model through the `summary` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Drop the `language` attribute, and refit the model with the `lm` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can then draw a diagnostic plot of `lmfit`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00093.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Diagnostic plot of fitted model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we take the log of wages and replot the diagnostic plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00094.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Diagnostic plot of adjusted fitted model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, you can diagnose the multi-colinearity of the regression model using
    the `vif` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, you can install and load the `lmtest` package and diagnose the heteroscedasticity
    of the regression model with the `bptest` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, you can install and load the `rms` package. Then, you can correct
    standard errors with `robcov`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe demonstrates how to conduct linear regression analysis on the SLID
    dataset. First, we load the SLID data and display its structure through the use
    of the `str` function. From the structure of the data, we know that there are
    four independent variables that will affect the wages of the dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we explore the relationship of each independent variable to the dependent
    variable, `wages`, through visualization; the visualization result is shown in
    the preceding screenshot (step 2). In the upper-left section of this screenshot,
    you can find the box plot of three different languages against wages; the correlation
    between the languages and wages is not obvious. The upper-right section of the
    screenshot shows that the age appears to have a positive relationship with the
    dependent variable, `wages`. In the bottom-left of the screenshot, it is shown
    that education also appears to have a positive relationship with wages. Finally,
    the box plot in the bottom-right section of the screenshot shows that the wages
    of males are slightly higher than females.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we fit all the attributes except for `wages` to the model as predictor
    variables. By summarizing the model, it is shown that education, age, and sex
    show a significance (*p-value < 0.05*). As a result, we drop the insignificant
    `language` attribute (which has a p-value greater than 0.05) and fit the three
    independent variables (education, sex, and age) with regard to the dependent variable
    (`wages`) in the linear model. This accordingly raises the f-statistic from 336.8
    to 565.3.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we generate the diagnostic plot of the fitted model. Within the diagnostic
    plot, all the four plots indicate that the regression model follows the regression
    assumption. However, from residuals versus fitted and scale-location plot, residuals
    of smaller fitted values are biased toward the regression model. Since wages range
    over several orders of magnitude, to induce the symmetry, we apply a log transformation
    to wages and refit the data into a regression model. The red line of residuals
    versus fitted values plot and the Scale-Location plot are now closer to the gray
    dashed line.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we would like to test whether multi-colinearity exists in the model. Multi-colinearity
    takes place when a predictor is highly correlated with others. If multi-colinearity
    exists in the model, you might see some variables have a high R-squared value
    but are shown as variables insignificant. To detect multi-colinearity, we can
    calculate the variance inflation and generalized variance inflation factors for
    linear and generalized linear models with the `vif` function. If multi-colinearity
    exists, we should find predictors with the square root of variance inflation factor
    above 2\. Then, we may remove redundant predictors or use a principal component
    analysis to transform predictors to a smaller set of uncorrelated components.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we would like to test whether **heteroscedasticity** exists in the
    model. Before discussing the definition of heteroscedasticity, we first have to
    know that in classic assumptions, the ordinary regression model assumes that the
    variance of the error is constant or homogeneous across observations. On the contrary,
    heteroscedasticity means that the variance is unequal across observations. As
    a result, heteroscedasticity may be biased toward the standard errors of our estimates
    and, therefore, mislead the testing of the hypothes. To detect and test heteroscedasticity,
    we can perform the **Breusch-Pagan** test for heteroscedasticity with the `bptest`
    function within the `lmtest` package. In this case, the p-value shows 2.206e-06
    (<0.5), which rejects the null hypothesis of homoscedasticity (no heteroscedasticity).
    Here, it implies that the standard errors of the parameter estimates are incorrect.
    However, we can use robust standard errors to correct the standard error (do not
    remove the heteroscedasticity) and increase the significance of truly significant
    parameters with `robcov` from the `rms` package. However, since it only takes
    the fitted model from the `rms` series as an input, we have to fit the ordinary
    least squares model beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For more information about the SLID dataset, you can use the `help` function
    to view the related documentation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Applying the Gaussian model for generalized linear regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Generalized linear model** (**GLM**) is a generalization of linear regression,
    which can include a link function to make a linear prediction. As a default setting,
    the family object for `glm` is Gaussian, which makes the `glm` function perform
    exactly the same as `lm`. In this recipe, we first demonstrate how to fit the
    model into the data using the `glm` function, and then show that `glm` with a
    Gaussian model performs exactly the same as `lm`.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Check whether the `car` library is installed and loaded as we require the SLID
    dataset from this package.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to fit a generalized linear regression model with
    the Gaussian model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fit the independent variables, `age`, `sex`, and `education`, and dependent
    variable wages to `glm`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the independent variables, `age`, `sex`, and `education`, and the dependent
    variable wages to `lm`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `anova` to compare the two fitted models:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `glm` function fits a model to the data in a similar fashion to the `lm`
    function. The only difference is that you can specify a different link function
    in the parameter, `family` (you may use `?family` in the console to find different
    types of link functions). In this recipe, we first input the independent variables,
    `age`, `sex`, and `education`, and the dependent `wages` variable to the `glm`
    function, and assign the built model to `lmfit1`. You can use the built model
    for further prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Next, to determine whether `glm` with a Gaussian model is exactly the same as
    `lm`, we fit the independent variables, `age`, `sex`, and `education`, and the
    dependent variable, `wages`, to the `lm` model. By applying the `summary` function
    to the two different models, it reveals that the residuals and coefficients of
    the two output summaries are exactly the same.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we further compare the two fitted models with the `anova` function.
    The result of the `anova` function shows that the two models are similar, with
    the same **residual degrees of freedom** (**Res.DF**) and **residual sum of squares**
    (**RSS Df**).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a comparison of generalized linear models with linear models, you can refer
    to *Venables, W. N., & Ripley, B. D. (2002). Modern applied statistics with S.
    Springer*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the Poisson model for generalized linear regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generalized linear models allow response variables that have error distribution
    models other than a normal distribution (Gaussian). In this recipe, we demonstrate
    how to apply Poisson as a family object within `glm` with regard to count data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The prerequisite of this task is to prepare the count data, with all the input
    data values as integers.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to fit the generalized linear regression model
    with the Poisson model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `warpbreaks` data, and use `head` to view the first few lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We apply Poisson as a family object for the independent variable, `tension`,
    and the dependent variable, `breaks`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Under the assumption of a Poisson distribution, the count data can be fitted
    to a log-linear model. In this recipe, we first loaded a sample count data from
    the `warpbreaks` dataset, which contained data regarding the number of warp breaks
    per loom. Next, we applied the `glm` function with breaks as a dependent variable,
    `tension` as an independent variable, and Poisson as a family object. Finally,
    we viewed the fitted log-linear model with the summary function.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To understand more on how a Poisson model is related to count data, you can
    refer to *Cameron, A. C., & Trivedi, P. K. (2013). Regression analysis of count
    data (No. 53). Cambridge university press.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the Binomial model for generalized linear regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a binary dependent variable, one may apply a binomial model as the family
    object in the `glm` function.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The prerequisite of this task is to prepare a binary dependent variable. Here,
    we use the `vs` variable (V engine or straight engine) as the dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to fit a generalized linear regression model with
    the Binomial model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we examine the first six elements of `vs` within `mtcars`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We apply the `glm` function with `binomial` as the family object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within the binary data, each observation of the response value is coded as either
    `0` or `1`. Fitting into the regression model of the binary data requires a binomial
    distribution function. In this example, we first load the binary dependent variable,
    `vs`, from the `mtcars` dataset. The `vs` is suitable for the binomial model as
    it contains binary data. Next, we fit the model into the binary data using the
    `glm` function by specifying `binomial` as the family object. Last, by referring
    to the summary, we can obtain the description of the fitted model.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you specify the family object in parameters only, you will use the default
    link to fit the model. However, to use an alternative link function, you can add
    a link argument. For example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you would like to know how many alternative links you can use, please refer
    to the family document via the help function:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Fitting a generalized additive model to data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Generalized additive model** (**GAM**), which is used to fit generalized
    additive models, can be viewed as a semiparametric extension of GLM. While GLM
    holds the assumption that there is a linear relationship between dependent and
    independent variables, GAM fits the model on account of the local behavior of
    data. As a result, GAM has the ability to deal with highly nonlinear relationships
    between dependent and independent variables. In the following recipe, we introduce
    how to fit regression using a generalized additive model.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to prepare a data frame containing variables, where one of the variables
    is a response variable and the others may be predictor variables.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to fit a generalized additive model into data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, load the `mgcv` package, which contains the `gam` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, install the `MASS` package and load the `Boston` dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Fit the regression using `gam`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get the summary information of the fitted model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GAM is designed to maximize the prediction of a dependent variable, `y`, from
    various distributions by estimating the nonparametric functions of the predictors
    that link to the dependent variable through a link function. The notion of GAM
    is ![How it works](img/00095.jpeg), where an exponential family, *E*, is specified
    for *y*, along with the `g` link function; `f` denotes the link function of predictors.
  prefs: []
  type: TYPE_NORMAL
- en: The `gam` function is contained in the `mgcv` package, so, install this package
    first and load it into an R session. Next, load the Boston dataset (*Housing Values
    in the Suburbs of Boston*) from the `MASS` package. From the dataset, we use `dis`
    (the weighted mean of the distance to five Boston employment centers) as the dependent
    variable, and `nox` (nitrogen oxide concentration) as the independent variable,
    and then input them into the `gam` function to generate a fitted model.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to `glm`, `gam` allows users to summarize the `gam` fit. From the summary,
    one can find the parametric parameter, significance of smoothed terms, and other
    useful information.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Apart from `gam`, the `mgcv` package provides another generalized additive
    model, `bam`, for large datasets. The `bam` package is very similar to `gam`,
    but uses less memory and is relatively more efficient. Please use the `help` function
    for more information on this model:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For more information about generalized additive models in R, please refer to
    *Wood, S. (2006). Generalized additive models: an introduction with R. CRC press*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing a generalized additive model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we demonstrate how to add a `gam` fitted regression line to
    a scatter plot. In addition, we visualize the gam fit using the `plot` function.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Complete the previous recipe by assigning a `gam` fitted model to the `fit`
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to visualize the generalized additive model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a scatter plot using the `nox` and `dis` variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00096.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Scatter plot of variable nox against dis
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Add the regression to the scatter plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00097.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Fitted regression of gam on a scatter plot
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Alternatively, you can plot the fitted model using the `plot` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00098.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Plot of fitted gam
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To visualize the fitted regression, we first generate a scatter plot using the
    `dis` and `nox` variables. Then, we generate the sequence of *x*-axis, and respond
    *y* through the use of the `predict` function on the fitted model, `fit`. Finally,
    we use the `lines` function to add the regression line to the scatter plot.
  prefs: []
  type: TYPE_NORMAL
- en: Besides using the lines to add fitted regression lines on the scatter plot,
    `gam` has a `plot` function to visualize the fitted regression lines containing
    the confidence region. To shade the confidence region, we assign `shade = TRUE`
    within the function.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `vis.gam` function is used to produce perspective or contour plot views
    of the `gam` model predictions. It is helpful to observe how response variables
    interact with two predictor variables. The following is an example of a contour
    plot on the `Boston` dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '![There''s more...](img/00099.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: A sample contour plot produced by vis.gam
  prefs: []
  type: TYPE_NORMAL
- en: Diagnosing a generalized additive model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GAM also provides diagnostic information about the fitting procedure and results
    of the generalized additive model. In this recipe, we demonstrate how to plot
    diagnostic plots through the `gam.check` function.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensure that the previous recipe is completed with the `gam` fitted model assigned
    to the `fit` variable.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following step to diagnose the generalized additive model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate the diagnostic plot using `gam.check` on the fitted model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/00100.jpeg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Diagnostic plot of fitted gam
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `gam.check` function first produces the smoothing parameter estimation convergence
    information. In this example, the smoothing parameter, **GCV/UBRE** (**Generalized
    Cross Validation/ Unbiased Risk Estimator**) score converges after seven iterations.
    The mean absolute gradient of the GCV/UBRE function at the minimum is 8.79622e-06
    and the estimated rank is `10`. The dimension check is to test whether the basis
    dimension for a smooth function is adequate. From this example, the low p-value
    indicates that the k is set too low. One may adjust the dimension choice for smooth
    by specifying the argument, k, by fitting `gam` to the data.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to providing information regarding smoothing parameter estimation
    convergence, the function returns four diagnostic plots. The upper-left section
    of the plot in the screenshot shows a **quantile-comparison** plot. This plot
    is useful to identify outliers and heavy tails. The upper-right section of the
    plot shows residuals versus linear predictors, which are useful in finding nonconstant
    error variances. The bottom-left section of the plot shows a histogram of the
    residuals, which is helpful in detecting non-normality. The bottom-right section
    shows response versus the fitted value.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can access the `help` function for more information on `gam.check`. In
    particular, this includes a detailed illustration of smoothing parameter estimation
    convergence and four returned plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, more information for `choose.k` can be accessed by the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
