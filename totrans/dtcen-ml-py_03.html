<html><head></head><body>
<div id="_idContainer025">
<h1 class="chapter-number" id="_idParaDest-44"><a id="_idTextAnchor043"/><span class="koboSpan" id="kobo.1.1">3</span></h1>
<h1 id="_idParaDest-45"><a id="_idTextAnchor044"/><span class="koboSpan" id="kobo.2.1">Principles of Data-Centric ML</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In this chapter, you will learn the key principles of data-centric ML. </span><span class="koboSpan" id="kobo.3.2">We’ll cover the foundational principles of data-centricity in this chapter to provide a high-level structure and framework to work through and refer to throughout the rest of this book. </span><span class="koboSpan" id="kobo.3.3">These principles will give you important context – or the </span><em class="italic"><span class="koboSpan" id="kobo.4.1">why</span></em><span class="koboSpan" id="kobo.5.1"> – before we dive into the specific techniques and approaches associated with each principle in the following chapters – or </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">the </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.7.1">what</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.9.1">As you read through the principles, remember that data-centric ML is an extension – and not a replacement – of a model-centric approach. </span><span class="koboSpan" id="kobo.9.2">Essentially, model-centric and data-centric techniques work together to glean the most value from </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">your efforts.</span></span></p>
<p><span class="koboSpan" id="kobo.11.1">By the end of this chapter, you will have a good understanding of each of the principles and how they work together to form a framework </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">for data-centricity.</span></span></p>
<p><span class="koboSpan" id="kobo.13.1">In this chapter, we’ll cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.15.1">Principle 1 – data should be the center of </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">ML development</span></span></li>
<li><span class="koboSpan" id="kobo.17.1">Principle 2 – leverage annotators and </span><strong class="bold"><span class="koboSpan" id="kobo.18.1">subject-matter experts</span></strong><span class="koboSpan" id="kobo.19.1"> (</span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.20.1">SMEs</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">) effectively</span></span></li>
<li><span class="koboSpan" id="kobo.22.1">Principle 3 – use ML to improve </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">your data</span></span></li>
<li><span class="koboSpan" id="kobo.24.1">Principle 4 – follow ethical, responsible, and well-governed </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">ML practices</span></span></li>
</ul>
<h1 id="_idParaDest-46"><a id="_idTextAnchor045"/><span class="koboSpan" id="kobo.26.1">Sometimes, all you need is the right data</span></h1>
<p><span class="koboSpan" id="kobo.27.1">A few years ago, I (Jonas) was leading a team of data scientists tasked with an interesting but challenging problem. </span><span class="koboSpan" id="kobo.27.2">The financial services business we worked for attracted many new online visitors wanting to open new accounts with us through the company’s website. </span><span class="koboSpan" id="kobo.27.3">However, a significant number of potential customers couldn’t complete the account opening process for unknown reasons, which is why the company turned to its data scientists </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">for help.</span></span></p>
<p><span class="koboSpan" id="kobo.29.1">This problem of unopened accounts and lost customers was multifaceted, but we were determined to find every needle in the haystack. </span><span class="koboSpan" id="kobo.29.2">The account opening process was rather straightforward, designed to make it easy for someone to open a new account in less than 10 minutes with no support. </span><span class="koboSpan" id="kobo.29.3">For the customer, the steps were </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">as follows:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.31.1">Enter </span><span class="No-Break"><span class="koboSpan" id="kobo.32.1">personal details.</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.33.1">Verify identity.</span></span></li>
<li><span class="koboSpan" id="kobo.34.1">Verify </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">contact details.</span></span></li>
<li><span class="koboSpan" id="kobo.36.1">Accept the terms and conditions and open </span><span class="No-Break"><span class="koboSpan" id="kobo.37.1">an account.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.38.1">This process worked most of the time, but things were going wrong in </span><em class="italic"><span class="koboSpan" id="kobo.39.1">steps 2</span></em><span class="koboSpan" id="kobo.40.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.41.1">3</span></em><span class="koboSpan" id="kobo.42.1"> for a significant proportion of applicants. </span><span class="koboSpan" id="kobo.42.2">If someone’s identity couldn’t be verified online (</span><em class="italic"><span class="koboSpan" id="kobo.43.1">step 2</span></em><span class="koboSpan" id="kobo.44.1">), the individual would have to be verified in person, which was an obvious detractor for many, and it caused a </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">significant drop-off.</span></span></p>
<p><span class="koboSpan" id="kobo.46.1">The problems arising in </span><em class="italic"><span class="koboSpan" id="kobo.47.1">step 3</span></em><span class="koboSpan" id="kobo.48.1"> were less obvious. </span><span class="koboSpan" id="kobo.48.2">About 10% of users would quit their journey at this point, even though most of the hard work had already been done. </span><span class="koboSpan" id="kobo.48.3">Why would someone go through this whole process and then decide not to proceed </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">after all?</span></span></p>
<p><span class="koboSpan" id="kobo.50.1">We collected all the relevant data points we could get our hands on, but unfortunately, we didn’t have a very deep dataset to work on because the account opening process was so simple and these were new customers. </span><span class="koboSpan" id="kobo.50.2">We profiled our dataset and used various supervised and unsupervised ML techniques to tease out any behaviors that correlated with accounts not opening, but nothing stuck out in </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">our analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.52.1">We decided to dig deeper. </span><span class="koboSpan" id="kobo.52.2">Since these clients shared their contact information, we could match their phone numbers with our phone call records and obtain the recorded conversations with matching phone numbers. </span><span class="koboSpan" id="kobo.52.3">We pulled out hundreds of call recordings and started </span><span class="No-Break"><span class="koboSpan" id="kobo.53.1">listening in.</span></span></p>
<p><span class="koboSpan" id="kobo.54.1">Soon after, a clear pattern emerged: “I clicked the </span><strong class="bold"><span class="koboSpan" id="kobo.55.1">Verify contact details</span></strong><span class="koboSpan" id="kobo.56.1"> button, but never received a verification code,” said one recorded caller. </span><span class="koboSpan" id="kobo.56.2">“I’ve waited for 10 minutes, but the code hasn’t come through yet,” said another. </span><span class="koboSpan" id="kobo.56.3">Users weren’t getting through because they weren’t sent the final verification code as a text message – even when it was resent by call center agents. </span><span class="koboSpan" id="kobo.56.4">But this wasn’t the case for all new users, so what was going wrong for this </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">particular group?</span></span></p>
<p><span class="koboSpan" id="kobo.58.1">As we continued to listen to call recordings, another faint signal emerged: “I shouldn’t have come back,” said one user. </span><span class="koboSpan" id="kobo.58.2">“Your systems haven’t gotten any better since the last time I was here,” </span><span class="No-Break"><span class="koboSpan" id="kobo.59.1">said another.</span></span></p>
<p><span class="koboSpan" id="kobo.60.1">We had a look at closed customer accounts and sure enough, these people had been customers of ours in the past. </span><span class="koboSpan" id="kobo.60.2">The issue was simply that the enterprise system was treating these users as existing customers and therefore not sending out the required text messages, no matter how many times it was prompted by users or staff. </span><span class="koboSpan" id="kobo.60.3">The issue was occurring around 200 times a week, meaning the business was missing out on 10,000 new customers a year. </span><span class="koboSpan" id="kobo.60.4">Why didn’t anyone pick up on this </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">issue earlier?</span></span></p>
<p><span class="koboSpan" id="kobo.62.1">Only a proportion of the 200 occurrences would generate a call, and with hundreds of call center staff on duty throughout the week, it seemed like a rare glitch that only happened now and then. </span><span class="koboSpan" id="kobo.62.2">No one individual could see the issue because it was too infrequent and impossible for our models to flag. </span><span class="koboSpan" id="kobo.62.3">After all, the initial dataset had too much noise and not </span><span class="No-Break"><span class="koboSpan" id="kobo.63.1">enough signal.</span></span></p>
<p><span class="koboSpan" id="kobo.64.1">We only got to the bottom of it and found our needle in the haystack because we followed the four principles of data-centricity discussed in this chapter. </span><span class="koboSpan" id="kobo.64.2">Let’s explore each of these principles in </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">more detail.</span></span></p>
<h1 id="_idParaDest-47"><a id="_idTextAnchor046"/><span class="koboSpan" id="kobo.66.1">Principle 1 – data should be the center of ML development</span></h1>
<p><span class="koboSpan" id="kobo.67.1">As we discussed in </span><a href="B19297_02.xhtml#_idTextAnchor028"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.68.1">Chapter </span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.69.1">2</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.70.1">, From Model-Centric to Data-Centric – ML’s Evolution,</span></em><span class="koboSpan" id="kobo.71.1"> the </span><a id="_idIndexMarker067"/><span class="koboSpan" id="kobo.72.1">predominant model-centric approach is lacking in several ways: computing and storage have been commoditized, algorithms have become practically automated and highly data-dependent, models are accessible but less malleable, and deep learning and AutoML tools are available everywhere. </span><span class="koboSpan" id="kobo.72.2">But the data? </span><span class="koboSpan" id="kobo.72.3">Well, that’s still </span><span class="No-Break"><span class="koboSpan" id="kobo.73.1">the wildcard.</span></span></p>
<p><span class="koboSpan" id="kobo.74.1">Rather than relying on powerful computing and storage environments and sophisticated algorithms that demand excess amounts of data to give us the incremental uplift in model accuracy, a better approach is to be driven by data – specifically, by the data that is available and relevant to the problem </span><span class="No-Break"><span class="koboSpan" id="kobo.75.1">at hand.</span></span></p>
<p><span class="koboSpan" id="kobo.76.1">Data is unique to every company, problem, and situation, and the data-centric paradigm recognizes this by putting the spotlight and development efforts on the data before the model. </span><span class="koboSpan" id="kobo.76.2">Data is no longer a static asset that can be collected at the beginning and forgotten about; it is now a unique commodity that needs to be leveraged to its full potential to make better predictions. </span><span class="koboSpan" id="kobo.76.3">We will argue that in many cases, a company’s proprietary data is its only truly unique competitive advantage – so long as </span><span class="No-Break"><span class="koboSpan" id="kobo.77.1">it’s leveraged.</span></span></p>
<p><span class="koboSpan" id="kobo.78.1">By focusing</span><a id="_idIndexMarker068"/><span class="koboSpan" id="kobo.79.1"> on the data, data-centricity helps companies distinguish themselves from their competitors. </span><span class="koboSpan" id="kobo.79.2">Most companies have access to the same algorithms and plenty of computing and storage, but the data they use and the insights they gain from that data can give them a decisive edge over </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">the competition.</span></span></p>
<p><span class="koboSpan" id="kobo.81.1">In our observation, focusing on data quality also brings substantial benefits to an organization besides getting better data. </span><span class="koboSpan" id="kobo.81.2">Focusing on data quality means going beyond simple data refinement because quality data is a critical component of </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">business operations.</span></span></p>
<p><span class="koboSpan" id="kobo.83.1">For data quality to improve, there is typically a need to digitize and automate processes and to create strong accountability for process adherence. </span><span class="koboSpan" id="kobo.83.2">Strong data governance processes will assign ownership, stewardship, and accountability for data quality, which, in turn, relies on data collection standards and processes to be followed, measured, </span><span class="No-Break"><span class="koboSpan" id="kobo.84.1">and managed.</span></span></p>
<p><span class="koboSpan" id="kobo.85.1">Data quality is often a symptom of the quality of underlying processes and adherence to these processes. </span><span class="koboSpan" id="kobo.85.2">If an organization is good at collecting high-quality data, it is also likely to have good processes more generally. </span><span class="koboSpan" id="kobo.85.3">As companies improve data collection, they drive better accountability, accuracy, reliability, and overall consistency in their operations. </span><span class="koboSpan" id="kobo.85.4">Hence, focusing on data quality can have far-reaching consequences beyond improved data integrity and reliability. </span><span class="koboSpan" id="kobo.85.5">It is an essential driver of </span><span class="No-Break"><span class="koboSpan" id="kobo.86.1">operational excellence.</span></span></p>
<p><span class="koboSpan" id="kobo.87.1">If we think back to the example of missing verification codes discussed at the beginning of this chapter, no amount of model selection, parameter tuning, or feature engineering on the existing dataset would have revealed the root cause of </span><span class="No-Break"><span class="koboSpan" id="kobo.88.1">the problem.</span></span></p>
<p><span class="koboSpan" id="kobo.89.1">This issue could only be discovered and solved by collecting the right data for the problem at hand. </span><span class="koboSpan" id="kobo.89.2">In this case, the missing data points were </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">as follows:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.91.1">Verification codes weren’t </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">being received</span></span></li>
<li><span class="koboSpan" id="kobo.93.1">This was only the case for previous customers who returned to open a </span><span class="No-Break"><span class="koboSpan" id="kobo.94.1">new account</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.95.1">The </span><a id="_idIndexMarker069"/><span class="koboSpan" id="kobo.96.1">discovery of the verification code issue resulted in two key changes to the way the business operated. </span><span class="koboSpan" id="kobo.96.2">Firstly, the IT department fixed the code responsible for triggering verification codes being sent, which, all else being equal, resulted in a substantial uplift in new account openings. </span><span class="koboSpan" id="kobo.96.3">Secondly, the call center team established a central process for logging client tech issues, no matter how small, so we could discover </span><em class="italic"><span class="koboSpan" id="kobo.97.1">the tip of the iceberg</span></em><span class="koboSpan" id="kobo.98.1"> of any new system issues. </span><span class="koboSpan" id="kobo.98.2">In other words, it was now accepted culture that collecting high-quality data is central to improving </span><span class="No-Break"><span class="koboSpan" id="kobo.99.1">operational processes.</span></span></p>
<p><span class="koboSpan" id="kobo.100.1">This was a mindset shift for frontline staff in two ways. </span><span class="koboSpan" id="kobo.100.2">Firstly, there was a newfound appreciation for data as a powerful asset that could be aggregated and analyzed to understand the bigger picture of their work. </span><span class="koboSpan" id="kobo.100.3">Secondly, frontline teams now felt empowered: if I do my bit to capture and call out important issues, there is a chance we can </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1">fix them.</span></span></p>
<p><span class="koboSpan" id="kobo.102.1">Our data scientists also gained a different appreciation for data collection and curation as a key part of </span><em class="italic"><span class="koboSpan" id="kobo.103.1">their</span></em><span class="koboSpan" id="kobo.104.1"> role. </span><span class="koboSpan" id="kobo.104.2">Seeing the impact they could have by walking in the shoes of customers and frontline staff created a profound shift in the way the team solved problems. </span><span class="koboSpan" id="kobo.104.3">Rather than accepting data (quality) as given, data engineering now permeated all steps of the model development and </span><span class="No-Break"><span class="koboSpan" id="kobo.105.1">deployment process.</span></span></p>
<h2 id="_idParaDest-48"><a id="_idTextAnchor047"/><span class="koboSpan" id="kobo.106.1">A checklist for data-centricity</span></h2>
<p><span class="koboSpan" id="kobo.107.1">To stay </span><a id="_idIndexMarker070"/><span class="koboSpan" id="kobo.108.1">true to the first principle of data-centric ML, it is incredibly valuable to have a checklist of data-focused tasks to complete as you work through an ML project. </span><span class="koboSpan" id="kobo.108.2">Here is our checklist, spread across the five steps in the model development </span><span class="No-Break"><span class="koboSpan" id="kobo.109.1">life cycle.</span></span></p>
<h3><span class="koboSpan" id="kobo.110.1">Step 1 – identify the business problem, scope the project, and define the data needs</span></h3>
<p><span class="koboSpan" id="kobo.111.1">The first part of </span><a id="_idIndexMarker071"/><span class="koboSpan" id="kobo.112.1">any ML project </span><a id="_idIndexMarker072"/><span class="koboSpan" id="kobo.113.1">should always be to clearly define the problem you’re trying to solve; this should be done in collaboration with key stakeholders such as end users and SMEs. </span><span class="koboSpan" id="kobo.113.2">Identifying data gaps will be a lot easier when you have a clear definition of the problem you’re solving, and what success looks like when the problem has </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">been solved.</span></span></p>
<p><span class="koboSpan" id="kobo.115.1">A strong </span><a id="_idIndexMarker073"/><span class="koboSpan" id="kobo.116.1">modeling dataset contains both </span><em class="italic"><span class="koboSpan" id="kobo.117.1">content</span></em><span class="koboSpan" id="kobo.118.1"> and </span><em class="italic"><span class="koboSpan" id="kobo.119.1">context</span></em><span class="koboSpan" id="kobo.120.1">. </span><span class="koboSpan" id="kobo.120.2">Content is a specific object, event, or status you’re measuring and context describes the circumstances in which the object, event, or status occurred. </span><span class="koboSpan" id="kobo.120.3">In our previous missing verification code example, the content is the </span><em class="italic"><span class="koboSpan" id="kobo.121.1">(missing) verification code</span></em><span class="koboSpan" id="kobo.122.1"> and the context is </span><em class="italic"><span class="koboSpan" id="kobo.123.1">for former, </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.124.1">returning customers</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.125.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.126.1">A critical element in defining the project scope is outlining the process you’re trying to model. </span><span class="koboSpan" id="kobo.126.2">We do this by getting relevant end users and SMEs in a room with data scientists for as long as it takes to map out the process or situation underlying the business problem. </span><span class="koboSpan" id="kobo.126.3">This allows all participants to get a deep understanding of the content and context of the problem, while also identifying important data points needed for the </span><span class="No-Break"><span class="koboSpan" id="kobo.127.1">model build.</span></span></p>
<p><span class="koboSpan" id="kobo.128.1">Here is a checklist of questions to consider during </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">this step:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.130.1">Have we clearly defined the problem we’re trying </span><span class="No-Break"><span class="koboSpan" id="kobo.131.1">to solve?</span></span></li>
<li><span class="koboSpan" id="kobo.132.1">Is it the right problem to solve in the </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">first place?</span></span></li>
<li><span class="koboSpan" id="kobo.134.1">What outcomes are we looking to achieve by solving </span><span class="No-Break"><span class="koboSpan" id="kobo.135.1">the problem?</span></span></li>
<li><span class="koboSpan" id="kobo.136.1">Have we mapped out the key parts of the problem </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">with SMEs?</span></span></li>
<li><span class="koboSpan" id="kobo.138.1">What are the critical steps or moments in the process according to SMEs, and does our data capture </span><span class="No-Break"><span class="koboSpan" id="kobo.139.1">these appropriately?</span></span></li>
<li><span class="koboSpan" id="kobo.140.1">Do our data points contain both </span><em class="italic"><span class="koboSpan" id="kobo.141.1">content</span></em> <span class="No-Break"><span class="koboSpan" id="kobo.142.1">and </span></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.143.1">context</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">?</span></span></li>
<li><span class="koboSpan" id="kobo.145.1">What biases could arise from the solution that we need to look out </span><span class="No-Break"><span class="koboSpan" id="kobo.146.1">for later?</span></span></li>
<li><span class="koboSpan" id="kobo.147.1">Will any groups or segments be treated unfairly as a result of these biases? </span><span class="koboSpan" id="kobo.147.2">How can we identify these during the validation phase (</span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.148.1">step 4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">)?</span></span></li>
<li><span class="koboSpan" id="kobo.150.1">Is it legal and ethical to use all features in </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">our dataset?</span></span></li>
<li><span class="koboSpan" id="kobo.152.1">Will the outputs be internally or </span><span class="No-Break"><span class="koboSpan" id="kobo.153.1">externally audited?</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.154.1">Step 2 – prepare and label data</span></h3>
<p><span class="koboSpan" id="kobo.155.1">For many data scientists, data preparation is a dreaded task. </span><span class="koboSpan" id="kobo.155.2">We certainly agree that data preparation can </span><a id="_idIndexMarker074"/><span class="koboSpan" id="kobo.156.1">be both repetitive and time-consuming, but as proponents of data-centric ML, we encourage you to embrace it as the most important part of </span><span class="No-Break"><span class="koboSpan" id="kobo.157.1">the job.</span></span></p>
<p><span class="koboSpan" id="kobo.158.1">Data preparation</span><a id="_idIndexMarker075"/><span class="koboSpan" id="kobo.159.1"> involves collecting, cleaning, structuring, enhancing, and augmenting your input data to increase the signal and reduce noise in the dataset. </span><span class="koboSpan" id="kobo.159.2">These tasks can be both technically challenging and rewarding – especially when you start seeing those AUC scores increase. </span><span class="koboSpan" id="kobo.159.3">By now, you are aware that this part of the process is likely to give you very powerful modeling outcomes if you put in the right kind </span><span class="No-Break"><span class="koboSpan" id="kobo.160.1">of effort.</span></span></p>
<p><span class="koboSpan" id="kobo.161.1">The following checklist is useful for guiding you through the data preparation process. </span><span class="koboSpan" id="kobo.161.2">We will teach you how to do these tasks in plenty of detail throughout the rest of </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">this book.</span></span></p>
<p><span class="koboSpan" id="kobo.163.1">Here are the </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">checklist questions:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.165.1">Have we performed a technical validation of data quality? </span><span class="koboSpan" id="kobo.165.2">(See </span><a href="B19297_05.xhtml#_idTextAnchor070"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.166.1">Chapter 5</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.167.1">, Techniques for </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.168.1">Data Cleaning</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">.)</span></span></li>
<li><span class="koboSpan" id="kobo.170.1">Can we enhance the strength of our dataset by cleaning it? </span><span class="koboSpan" id="kobo.170.2">(See </span><a href="B19297_05.xhtml#_idTextAnchor070"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.171.1">Chapter 5</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.172.1">, Techniques for </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.173.1">Data Cleaning</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">.)</span></span></li>
<li><span class="koboSpan" id="kobo.175.1">Do we need to collect additional data or enhance the quality of the existing dataset using human labelers? </span><span class="koboSpan" id="kobo.175.2">(See </span><a href="B19297_04.xhtml#_idTextAnchor056"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.176.1">Chapter 4</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.177.1">, Data Labeling Is a </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.178.1">Collaborative Process</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.179.1">.)</span></span></li>
<li><span class="koboSpan" id="kobo.180.1">Do we need to define specific labeling rules and train SMEs? </span><span class="koboSpan" id="kobo.180.2">(See </span><a href="B19297_04.xhtml#_idTextAnchor056"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.181.1">Chapter 4</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.182.1">, Data Labeling Is a </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.183.1">Collaborative Process</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.184.1">.)</span></span></li>
<li><span class="koboSpan" id="kobo.185.1">Can we improve data quality or impute missing values using programmatic labeling? </span><span class="koboSpan" id="kobo.185.2">(See </span><a href="B19297_06.xhtml#_idTextAnchor089"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.186.1">Chapter 6</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.187.1">, Techniques for Programmatic Labeling in </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.188.1">Machine Learning</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.189.1">.)</span></span></li>
<li><span class="koboSpan" id="kobo.190.1">Should we use synthetic data to augment or enhance certain classes in the data? </span><span class="koboSpan" id="kobo.190.2">(See </span><a href="B19297_07.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.191.1">Chapter 7</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.192.1">, Using Synthetic Data in Data-Centric </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.193.1">Machine Learning</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">.)</span></span></li>
<li><span class="koboSpan" id="kobo.195.1">Do we need to preserve the privacy of individuals in the dataset? </span><span class="koboSpan" id="kobo.195.2">(See </span><a href="B19297_07.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.196.1">Chapter 7</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.197.1">, Using Synthetic Data in Data-Centric </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.198.1">Machine Learning</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">.)</span></span></li>
<li><span class="koboSpan" id="kobo.200.1">Does our dataset contain biased classes and do we need to adjust these? </span><span class="koboSpan" id="kobo.200.2">(See </span><a href="B19297_08.xhtml#_idTextAnchor125"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.201.1">Chapter 8</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.202.1">, Techniques for Identifying and </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.203.1">Removing Bias</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">.)</span></span></li>
<li><span class="koboSpan" id="kobo.205.1">Does our dataset contain enough of the right kinds of rare events? </span><span class="koboSpan" id="kobo.205.2">Do we need to add more or remove outliers? </span><span class="koboSpan" id="kobo.205.3">(See </span><a href="B19297_09.xhtml#_idTextAnchor141"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.206.1">Chapter 9</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.207.1">, Dealing with Edge Cases and Rare Events in </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.208.1">Machine Learning</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">.)</span></span></li>
<li><span class="koboSpan" id="kobo.210.1">Can we engineer new features from the </span><span class="No-Break"><span class="koboSpan" id="kobo.211.1">existing dataset?</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.212.1">Step 3 – train the model</span></h3>
<p><span class="koboSpan" id="kobo.213.1">The</span><a id="_idIndexMarker076"/><span class="koboSpan" id="kobo.214.1"> model training phase is where data-centric and model-centric ML principles come together to create synergy. </span><span class="koboSpan" id="kobo.214.2">Again, it is important to highlight that you should not discard everything you already know about how to build and enhance ML models based on a model-centric approach. </span><span class="koboSpan" id="kobo.214.3">Data-centricity simply gives you an additional set of tools in your toolbox and allows you to amplify the impact of </span><span class="No-Break"><span class="koboSpan" id="kobo.215.1">your models.</span></span></p>
<p><span class="koboSpan" id="kobo.216.1">Feature selection is an important part of this synergistic process because it filters out features that aren’t useful (and in the worst case, problematic) for your model. </span><span class="koboSpan" id="kobo.216.2">Generally speaking, it is desirable to have fewer attributes contributing to your model because it reduces unwanted noise and makes the model easier </span><span class="No-Break"><span class="koboSpan" id="kobo.217.1">to explain.</span></span></p>
<p><span class="koboSpan" id="kobo.218.1">It is important to consider feature selection as part of the model selection process because a model and its input data go hand in hand to produce predictions. </span><span class="koboSpan" id="kobo.218.2">They are intrinsically linked to each other. </span><span class="koboSpan" id="kobo.218.3">Practically speaking, this means you should pick the features </span><em class="italic"><span class="koboSpan" id="kobo.219.1">with</span></em><span class="koboSpan" id="kobo.220.1"> the model and not use a static dataset of pre-selected features to choose </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">between models.</span></span></p>
<p><span class="koboSpan" id="kobo.222.1">Here are the </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">checklist questions:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.224.1">Do you suspect your data to be dirty (for example, wrong labels, missing values, meaningless patterns, or </span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">irrelevant outputs)?</span></span></li>
<li><span class="koboSpan" id="kobo.226.1">Can we improve model accuracy by improving the quality of the dataset? </span><span class="koboSpan" id="kobo.226.2">The long list of data-centric techniques outlined in this book is designed to help you with </span><span class="No-Break"><span class="koboSpan" id="kobo.227.1">this task!</span></span></li>
<li><span class="koboSpan" id="kobo.228.1">Do our engineered features suggest any relationships in the data that require us to collect additional data (features </span><span class="No-Break"><span class="koboSpan" id="kobo.229.1">or observations)?</span></span></li>
<li><span class="koboSpan" id="kobo.230.1">Do our (engineered) features suggest any relationships in the data that we should verify with SMEs? </span><span class="koboSpan" id="kobo.230.2">Rather than assuming our new features are correct, any influential correlations should be cross-checked with SMEs to ensure their relevance and validity within the context of </span><span class="No-Break"><span class="koboSpan" id="kobo.231.1">the solution.</span></span></li>
<li><span class="koboSpan" id="kobo.232.1">Can we reduce the number of features in our model without losing predictive power? </span><span class="koboSpan" id="kobo.232.2">By applying dimensionality reduction techniques or feature selection methods, we </span><a id="_idIndexMarker077"/><span class="koboSpan" id="kobo.233.1">may be able to decrease the number of features in our model without significantly compromising its </span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">predictive accuracy.</span></span></li>
</ul>
<h3><span class="koboSpan" id="kobo.235.1">Step 4 – evaluate performance, fairness, and bias</span></h3>
<p><span class="koboSpan" id="kobo.236.1">The data-centric </span><a id="_idIndexMarker078"/><span class="koboSpan" id="kobo.237.1">approach to ML puts a strong emphasis on detecting bias and fairness issues during model evaluation. </span><span class="koboSpan" id="kobo.237.2">To validate the accuracy of an ML model, you should still start with traditional validation tasks such as splitting data into training and testing sets, performing cross-validation, and producing confusion matrices. </span><span class="koboSpan" id="kobo.237.3">The following checklist assumes that you will already be doing these tasks, using standard performance evaluation using metrics such as accuracy, precision, recall, F1 score, </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">and more.</span></span></p>
<p><span class="koboSpan" id="kobo.239.1">Bias detection is </span><a id="_idIndexMarker079"/><span class="koboSpan" id="kobo.240.1">an important tool for uncovering potential unfairness and discrimination in ML models. </span><span class="koboSpan" id="kobo.240.2">This can be done by creating confusion matrices for each subgroup separately to compare false positive and false negative rates across groups, and assessing demographic parity (equal representation) and equal opportunity (equal true positive rate) or equal odds (equal false positive rate) across groups. </span><span class="koboSpan" id="kobo.240.3">Disparities between subgroups, such as those related to gender or race, are common examples of sources of bias </span><span class="No-Break"><span class="koboSpan" id="kobo.241.1">or unfairness.</span></span></p>
<p><span class="koboSpan" id="kobo.242.1">Here are the </span><span class="No-Break"><span class="koboSpan" id="kobo.243.1">checklist questions:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.244.1">Can we improve model performance by improving data quality or collecting </span><span class="No-Break"><span class="koboSpan" id="kobo.245.1">new features?</span></span></li>
<li><span class="koboSpan" id="kobo.246.1">Can we detect any bias or unfairness toward particular groups </span><span class="No-Break"><span class="koboSpan" id="kobo.247.1">or segments?</span></span></li>
<li><span class="koboSpan" id="kobo.248.1">Are there any large correlations between sensitive attributes and predictions made by </span><span class="No-Break"><span class="koboSpan" id="kobo.249.1">the model?</span></span></li>
<li><span class="koboSpan" id="kobo.250.1">How does the model perform on unseen data concerning fairness </span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">and bias?</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.252.1">We’ll cover techniques for identifying and removing bias in </span><a href="B19297_08.xhtml#_idTextAnchor125"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.253.1">Chapter 8</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.254.1">, Techniques for Identifying and </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.255.1">Removing Bias</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.256.1">.</span></span></p>
<h3><span class="koboSpan" id="kobo.257.1">Step 5 – deploy and monitor</span></h3>
<p><span class="koboSpan" id="kobo.258.1">Effective monitoring of ML models also relies on data-centric principles. </span><span class="koboSpan" id="kobo.258.2">When monitoring model</span><a id="_idIndexMarker080"/><span class="koboSpan" id="kobo.259.1"> performance, it is important to include data quality, data coverage, data relevance, and labeling </span><span class="No-Break"><span class="koboSpan" id="kobo.260.1">consistency metrics.</span></span></p>
<p><span class="koboSpan" id="kobo.261.1">Data quality refers to the accuracy, completeness, and consistency of data, while data coverage refers to having enough data points to make confident predictions in the first place. </span><span class="koboSpan" id="kobo.261.2">Data relevance ensures that the data used to train the model is suitable for the task. </span><span class="koboSpan" id="kobo.261.3">Finally, data labeling consistency ensures that the data points used for training the model have </span><span class="No-Break"><span class="koboSpan" id="kobo.262.1">correct labels.</span></span></p>
<p><span class="koboSpan" id="kobo.263.1">Several techniques </span><a id="_idIndexMarker081"/><span class="koboSpan" id="kobo.264.1">and tools can help data scientists monitor ML models effectively. </span><span class="koboSpan" id="kobo.264.2">For example, data drift detection helps detect changes in data characteristics, such as mean, variance, and distribution. </span><span class="koboSpan" id="kobo.264.3">Similarly, outlier detection helps identify data points that differ significantly from the common distribution. </span><span class="koboSpan" id="kobo.264.4">Also, bias detection techniques help identify and correct instances of bias in </span><span class="No-Break"><span class="koboSpan" id="kobo.265.1">ML models.</span></span></p>
<p><span class="koboSpan" id="kobo.266.1">In addition to relying on reporting and metrics to monitor ML models, it is crucial to understand that monitoring is an ongoing process that requires the involvement of stakeholders beyond the data science team. </span><span class="koboSpan" id="kobo.266.2">Stakeholders may include SMEs, business owners, and end users. </span><span class="koboSpan" id="kobo.266.3">These stakeholders should collaborate to evaluate the model’s performance, interpret the results, and identify any issues that need to </span><span class="No-Break"><span class="koboSpan" id="kobo.267.1">be addressed.</span></span></p>
<p><span class="koboSpan" id="kobo.268.1">Here are the </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">checklist questions:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.270.1">Are the data sources used in the model automated, consistent, </span><span class="No-Break"><span class="koboSpan" id="kobo.271.1">and reliable?</span></span></li>
<li><span class="koboSpan" id="kobo.272.1">Have we designed a monitoring and reporting plan that captures failures, biases, </span><span class="No-Break"><span class="koboSpan" id="kobo.273.1">and drift?</span></span></li>
<li><span class="koboSpan" id="kobo.274.1">Does our monitoring quantify data quality, data coverage, data relevance, and </span><span class="No-Break"><span class="koboSpan" id="kobo.275.1">labeling consistency?</span></span></li>
<li><span class="koboSpan" id="kobo.276.1">Have we set up a mechanism for end users to provide continuous feedback on </span><span class="No-Break"><span class="koboSpan" id="kobo.277.1">model performance?</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.278.1">Our checklist questions are designed to make you think about data quality, and the impacts thereof, at each step in the model development process. </span><span class="koboSpan" id="kobo.278.2">In other words, they are an addition to – and not a replacement for – more model-centric </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">development tasks.</span></span></p>
<p><span class="koboSpan" id="kobo.280.1">Data-centricity requires a mindset shift from “I’ll build the best model with this data” to “How can we make the best dataset to solve this particular problem?” </span><span class="koboSpan" id="kobo.280.2">To do that, we need the whole organization involved in a coordinated effort. </span><span class="koboSpan" id="kobo.280.3">This brings us to the second principle of </span><span class="No-Break"><span class="koboSpan" id="kobo.281.1">data-centric ML.</span></span></p>
<h1 id="_idParaDest-49"><a id="_idTextAnchor048"/><span class="koboSpan" id="kobo.282.1">Principle 2 – leverage annotators and SMEs effectively</span></h1>
<p><span class="koboSpan" id="kobo.283.1">No matter </span><a id="_idIndexMarker082"/><span class="koboSpan" id="kobo.284.1">where we are in the AI hype cycle when you read this, it is unlikely that AI and ML development has evolved past the point where human input and labeling </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">are needed.</span></span></p>
<p><span class="koboSpan" id="kobo.286.1">In recent years, we have experienced a large increase in the sophistication of AI technologies, especially in the field of generative AI. </span><span class="koboSpan" id="kobo.286.2">Despite this, it remains a fact that even the most powerful and revolutionary AI technologies, such as ChatGPT, rely on small armies of human labelers to refine and advance </span><span class="No-Break"><span class="koboSpan" id="kobo.287.1">their capabilities.</span></span></p>
<p><span class="koboSpan" id="kobo.288.1">These individuals review and annotate data samples, which are then fed back into the model to improve its understanding of natural language and context. </span><span class="koboSpan" id="kobo.288.2">Some of the key methodologies and techniques that are employed by human labelers include </span><span class="No-Break"><span class="koboSpan" id="kobo.289.1">the following:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.290.1">Domain expertise</span></strong><span class="koboSpan" id="kobo.291.1">: Labelers </span><a id="_idIndexMarker083"/><span class="koboSpan" id="kobo.292.1">with subject matter expertise can provide valuable insights and annotations that help the model better comprehend specific topics </span><span class="No-Break"><span class="koboSpan" id="kobo.293.1">and domains.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.294.1">Active learning</span></strong><span class="koboSpan" id="kobo.295.1">: This </span><a id="_idIndexMarker084"/><span class="koboSpan" id="kobo.296.1">approach involves prioritizing data samples that the model finds ambiguous or challenging, enabling labelers to focus on areas where their input can have the </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">greatest impact.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.298.1">Diversity of perspectives</span></strong><span class="koboSpan" id="kobo.299.1">: By </span><a id="_idIndexMarker085"/><span class="koboSpan" id="kobo.300.1">involving labelers from diverse backgrounds and with varied experiences, the model can be exposed to a broader range of linguistic nuances, cultural contexts, and perspectives, improving its </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">overall performance.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.302.1">Quality control</span></strong><span class="koboSpan" id="kobo.303.1">: Regular </span><a id="_idIndexMarker086"/><span class="koboSpan" id="kobo.304.1">audits and evaluations of labeler output can help ensure consistent annotation quality and adherence to guidelines, which is essential for effective </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">model training.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.306.1">In short, human annotators</span><a id="_idIndexMarker087"/><span class="koboSpan" id="kobo.307.1"> are integral to ML, and the quality of our models depends on our ability to train, organize, and collaborate with these annotators. </span><span class="koboSpan" id="kobo.307.2">Broadly speaking, there are three ways to leverage SMEs in the ML </span><span class="No-Break"><span class="koboSpan" id="kobo.308.1">development process:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.309.1">As direct labelers of </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">data points</span></span></li>
<li><span class="koboSpan" id="kobo.311.1">As verifiers of output quality and detectors of undesired outputs such as </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">toxic content</span></span></li>
<li><span class="koboSpan" id="kobo.313.1">As knowledge experts who can help us codify </span><span class="No-Break"><span class="koboSpan" id="kobo.314.1">labeling rules</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.315.1">Leveraging SMEs effectively</span><a id="_idIndexMarker088"/><span class="koboSpan" id="kobo.316.1"> requires a mindset shift from just creating labeling rules for annotators (although this is still important) to using the combined strengths of SMEs and data scientists to cover the problem space through well-defined </span><span class="No-Break"><span class="koboSpan" id="kobo.317.1">labeling rules.</span></span></p>
<p><span class="koboSpan" id="kobo.318.1">Our experience is that following this approach gives us much more than robust labeling functions. </span><span class="koboSpan" id="kobo.318.2">It helps us track down ambiguous examples and sharpen model performance, but just as importantly, it allows data scientists and SMEs to collaborate. </span><span class="koboSpan" id="kobo.318.3">As data scientists learn about the subject matter and SMEs learn how data science works, it creates a flywheel effect leading to new ideas, insights, </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">and knowledge.</span></span></p>
<p><span class="koboSpan" id="kobo.320.1">Let’s explore each of the three human labeling approaches in </span><span class="No-Break"><span class="koboSpan" id="kobo.321.1">more detail.</span></span></p>
<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/><span class="koboSpan" id="kobo.322.1">Direct labeling with human annotators</span></h2>
<p><span class="koboSpan" id="kobo.323.1">The</span><a id="_idIndexMarker089"/><span class="koboSpan" id="kobo.324.1"> primary benefit of human-annotated data is its accuracy. </span><span class="koboSpan" id="kobo.324.2">Humans can recognize patterns and subjectivity in ways that computers cannot. </span><span class="koboSpan" id="kobo.324.3">This means that the labels assigned to the data may be more accurate than those generated by automated processes. </span><span class="koboSpan" id="kobo.324.4">Additionally, humans can provide context to the data that would otherwise be lost in an </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">automated process.</span></span></p>
<p><span class="koboSpan" id="kobo.326.1">Human-annotated data also offers greater flexibility than automated processes. </span><span class="koboSpan" id="kobo.326.2">Annotators can customize their labeling process according to specific needs or requirements, allowing them to tailor the annotations to fit their project’s goals. </span><span class="koboSpan" id="kobo.326.3">This makes it easier for machines to interpret the data accurately </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">and quickly.</span></span></p>
<p><span class="koboSpan" id="kobo.328.1">Finally, human-annotated data can be cost-effective compared to other methods of labeling. </span><span class="koboSpan" id="kobo.328.2">This is mainly true when datasets are small- </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">to medium-sized.</span></span></p>
<p><span class="koboSpan" id="kobo.330.1">Small </span><a id="_idIndexMarker090"/><span class="koboSpan" id="kobo.331.1">datasets might consist of a few hundred to a few thousand observations, often manageable by a small team of human annotators. </span><span class="koboSpan" id="kobo.331.2">Medium-sized datasets may have tens of thousands of observations. </span><span class="koboSpan" id="kobo.331.3">While still possible to manually label, the complexity and time required start to increase, making it less </span><span class="No-Break"><span class="koboSpan" id="kobo.332.1">economically viable.</span></span></p>
<p><span class="koboSpan" id="kobo.333.1">When faced with larger datasets, manual annotation can become repetitive and prone to mistakes due to the sheer volume and potential complexity of the data. </span><span class="koboSpan" id="kobo.333.2">At this scale, the intricacies in the data could also increase, requiring a more nuanced understanding that may be challenging for human annotators to </span><span class="No-Break"><span class="koboSpan" id="kobo.334.1">maintain consistently.</span></span></p>
<p><span class="koboSpan" id="kobo.335.1">For larger or more complex datasets, we recommend going down the path of programmatic labeling, which we’ll discuss next. </span><span class="koboSpan" id="kobo.335.2">Interestingly, a hybrid approach can also be effective, where a subset of the large dataset is manually labeled to serve as training data for the programmatic labeling algorithm. </span><span class="koboSpan" id="kobo.335.3">This way, you can leverage the accuracy of human annotation and the scalability of ML, ensuring high-quality labels, even for </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">large datasets.</span></span></p>
<p><span class="koboSpan" id="kobo.337.1">Think back to the story of the missing verification codes we outlined at the beginning of this chapter. </span><span class="koboSpan" id="kobo.337.2">Once we had isolated the phone calls that were related to the yet-to-be-discovered issue, we chose to manually listen to hundreds of calls rather than use ML techniques to pick up </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">themes. </span><span class="koboSpan" id="kobo.338.2">Why?</span></span></p>
<p><span class="koboSpan" id="kobo.339.1">Because we wanted to make sure we understood the </span><em class="italic"><span class="koboSpan" id="kobo.340.1">content</span></em><span class="koboSpan" id="kobo.341.1"> and the </span><em class="italic"><span class="koboSpan" id="kobo.342.1">context</span></em><span class="koboSpan" id="kobo.343.1"> of these interactions and a human was just more likely to do that job well. </span><span class="koboSpan" id="kobo.343.2">At the same time, we were only listening to a few hundred calls, not millions, so human annotation was the most cost-effective way to find the signal in the noise and pinpoint our </span><span class="No-Break"><span class="koboSpan" id="kobo.344.1">needle-in-the-haystack issue.</span></span></p>
<p><span class="koboSpan" id="kobo.345.1">While labeling by humans is an essential part of the data-centric approach, there are several pitfalls and mistakes to avoid when using human labelers. </span><span class="koboSpan" id="kobo.345.2">In </span><a href="B19297_04.xhtml#_idTextAnchor056"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.346.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.347.1">,</span><em class="italic"><span class="koboSpan" id="kobo.348.1"> Data Labeling Is a Collaborative Process</span></em><span class="koboSpan" id="kobo.349.1">, we will teach you how to get the most out of SMEs and human annotators while managing the </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">potential downsides.</span></span></p>
<h2 id="_idParaDest-51"><a id="_idTextAnchor050"/><span class="koboSpan" id="kobo.351.1">Verifying output quality with human annotators</span></h2>
<p><span class="koboSpan" id="kobo.352.1">As mentioned</span><a id="_idIndexMarker091"/><span class="koboSpan" id="kobo.353.1"> previously, even very sophisticated AI solutions such as ChatGPT are heavily reliant on human annotators to guide algorithms to the optimal outcome. </span><span class="koboSpan" id="kobo.353.2">ChatGPT has been built on a mix of supervised learning and a </span><a id="_idIndexMarker092"/><span class="koboSpan" id="kobo.354.1">technique called </span><strong class="bold"><span class="koboSpan" id="kobo.355.1">reinforcement learning from human </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.356.1">feedback</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.357.1"> (</span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.358.1">RLHF</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.359.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.360.1">Reinforcement learning is an area of ML where an agent learns to make decisions by interacting with an environment. </span><span class="koboSpan" id="kobo.360.2">The agent’s objective is to select actions that maximize the cumulative reward over time. </span><span class="koboSpan" id="kobo.360.3">However, defining a suitable reward function for complex tasks can </span><span class="No-Break"><span class="koboSpan" id="kobo.361.1">be challenging.</span></span></p>
<p><span class="koboSpan" id="kobo.362.1">That’s where human feedback comes into play. </span><span class="koboSpan" id="kobo.362.2">In RLHF, an AI agent learns from rewards and penalties provided by humans, rather than a predefined reward function. </span><span class="koboSpan" id="kobo.362.3">This approach combines the power of ML algorithms with the intuition, experience, and knowledge of </span><span class="No-Break"><span class="koboSpan" id="kobo.363.1">human experts.</span></span></p>
<p><span class="koboSpan" id="kobo.364.1">The process involves the </span><span class="No-Break"><span class="koboSpan" id="kobo.365.1">following steps:</span></span></p>
<ol>
<li><span class="koboSpan" id="kobo.366.1">The AI agent interacts with the environment and </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">takes action.</span></span></li>
<li><span class="koboSpan" id="kobo.368.1">Human observers assess the agent’s actions and provide feedback in the form of rewards </span><span class="No-Break"><span class="koboSpan" id="kobo.369.1">or penalties.</span></span></li>
<li><span class="koboSpan" id="kobo.370.1">The agent uses this feedback to update its learning and improve its decision-making </span><span class="No-Break"><span class="koboSpan" id="kobo.371.1">over time.</span></span></li>
</ol>
<p><span class="koboSpan" id="kobo.372.1">Through these interactions, the AI agent learns to perform complex tasks by incorporating </span><span class="No-Break"><span class="koboSpan" id="kobo.373.1">human guidance.</span></span></p>
<p><span class="koboSpan" id="kobo.374.1">There are several benefits to using RLHF. </span><span class="koboSpan" id="kobo.374.2">Primarily, human feedback allows the AI agent to learn from the wealth of knowledge and experience that humans possess. </span><span class="koboSpan" id="kobo.374.3">This approach enables agents to learn complex behaviors that may be difficult to achieve with traditional algorithms. </span><span class="koboSpan" id="kobo.374.4">At the same time, the learning process can be tailored to specific needs or goals by adjusting the feedback provided by </span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">human experts.</span></span></p>
<p><span class="koboSpan" id="kobo.376.1">The drawbacks of having humans in the loop are that humans can make mistakes or provide inconsistent feedback, which may affect the agent’s learning. </span><span class="koboSpan" id="kobo.376.2">Furthermore, training an AI agent using human feedback can be a slow process, as it requires continuous input from human experts. </span><span class="koboSpan" id="kobo.376.3">In other words, it tends to be labor intensive and potentially costly as a result. </span><span class="koboSpan" id="kobo.376.4">For this reason, it’s important to develop an upfront estimate of the human and financial resources required for such a project to ensure </span><span class="No-Break"><span class="koboSpan" id="kobo.377.1">its viability.</span></span></p>
<p><span class="koboSpan" id="kobo.378.1">It’s important </span><a id="_idIndexMarker093"/><span class="koboSpan" id="kobo.379.1">to note that SMEs can be incredibly valuable contributors to almost any ML exercise. </span><span class="koboSpan" id="kobo.379.2">For example, we often use SMEs to help us review the outputs of our models because it allows us to discover new contexts in the problem space that should become features in the </span><span class="No-Break"><span class="koboSpan" id="kobo.380.1">training data.</span></span></p>
<p><span class="koboSpan" id="kobo.381.1">In the example of missing verification codes, we discovered the root of the problem by first developing a deep knowledge of the specific failure point by interviewing call center staff (one type of SME) and listening to call recordings (becoming SMEs ourselves). </span><span class="koboSpan" id="kobo.381.2">Once we had narrowed down the possible issue, we dug into the inner workings of the core system with our colleagues from the IT department (another type of SME) to verify </span><span class="No-Break"><span class="koboSpan" id="kobo.382.1">the glitch.</span></span></p>
<p><span class="koboSpan" id="kobo.383.1">This approach is not the same as reinforcement learning, but it highlights the value of involving SMEs throughout the whole development process, even if it requires </span><span class="No-Break"><span class="koboSpan" id="kobo.384.1">manual input.</span></span></p>
<h2 id="_idParaDest-52"><a id="_idTextAnchor051"/><span class="koboSpan" id="kobo.385.1">Codifying labeling rules with programmatic labeling</span></h2>
<p><span class="koboSpan" id="kobo.386.1">The </span><a id="_idIndexMarker094"/><span class="koboSpan" id="kobo.387.1">traditional method of labeling using human annotators is sometimes a bottleneck in the process that can prevent us from creating high-quality training sets in a way that is both efficient and cost-effective. </span><span class="koboSpan" id="kobo.387.2">This is typically an issue when we’re dealing with large datasets. </span><span class="koboSpan" id="kobo.387.3">Time- and cost-efficient training has become increasingly important as ML models become more complex and datasets </span><span class="No-Break"><span class="koboSpan" id="kobo.388.1">become larger.</span></span></p>
<p><span class="koboSpan" id="kobo.389.1">Enter</span><a id="_idIndexMarker095"/><span class="koboSpan" id="kobo.390.1"> programmatic labeling. </span><span class="koboSpan" id="kobo.390.2">At its core, programmatic labeling is a process of automatically assigning labels to data points based on predefined rules or algorithms. </span><span class="koboSpan" id="kobo.390.3">The main advantage of programmatic labeling over manual labeling is that it can be done much faster and more accurately than manual labeling – once there is a robust labeling function in place. </span><span class="koboSpan" id="kobo.390.4">This makes it ideal for large datasets where manual labeling would take too long or be </span><span class="No-Break"><span class="koboSpan" id="kobo.391.1">too costly.</span></span></p>
<p><span class="koboSpan" id="kobo.392.1">The process of programmatic labeling begins with defining the labels that need to be assigned to each data point. </span><span class="koboSpan" id="kobo.392.2">This can be done manually by SMEs or through automated methods such </span><a id="_idIndexMarker096"/><span class="koboSpan" id="kobo.393.1">as </span><strong class="bold"><span class="koboSpan" id="kobo.394.1">natural language processing</span></strong><span class="koboSpan" id="kobo.395.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.396.1">NLP</span></strong><span class="koboSpan" id="kobo.397.1">) algorithms or rule-based systems. </span><span class="koboSpan" id="kobo.397.2">Once the labels have been defined, they can then be applied to the data points using either supervised or unsupervised </span><span class="No-Break"><span class="koboSpan" id="kobo.398.1">learning algorithms.</span></span></p>
<p><span class="koboSpan" id="kobo.399.1">The </span><a id="_idIndexMarker097"/><span class="koboSpan" id="kobo.400.1">main benefits of </span><a id="_idIndexMarker098"/><span class="koboSpan" id="kobo.401.1">programmatic labeling are </span><span class="No-Break"><span class="koboSpan" id="kobo.402.1">as follows:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.403.1">Scalability</span></strong><span class="koboSpan" id="kobo.404.1">: Programmatic labeling can handle large volumes of data more efficiently than manual labeling, enabling faster model training </span><span class="No-Break"><span class="koboSpan" id="kobo.405.1">and iteration</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.406.1">Consistency</span></strong><span class="koboSpan" id="kobo.407.1">: Automated labeling methods ensure a consistent application of rules and criteria across the entire dataset, reducing variability and potential errors that may arise from </span><span class="No-Break"><span class="koboSpan" id="kobo.408.1">human subjectivity</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.409.1">Cost-effectiveness</span></strong><span class="koboSpan" id="kobo.410.1">: By automating the labeling process, organizations can save on the time and resources required to train, manage, and compensate </span><span class="No-Break"><span class="koboSpan" id="kobo.411.1">human labelers</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.412.1">Speed</span></strong><span class="koboSpan" id="kobo.413.1">: Programmatic labeling can process and annotate data much more quickly than manual labeling, accelerating the overall </span><span class="No-Break"><span class="koboSpan" id="kobo.414.1">ML pipeline</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.415.1">Reduced human error</span></strong><span class="koboSpan" id="kobo.416.1">: Automation minimizes the risk of human error and inconsistencies that can be introduced during </span><span class="No-Break"><span class="koboSpan" id="kobo.417.1">manual labeling</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.418.1">Reproducibility</span></strong><span class="koboSpan" id="kobo.419.1">: The automated labeling process is easily replicable, ensuring that results can be reproduced and verified across different datasets </span><span class="No-Break"><span class="koboSpan" id="kobo.420.1">and projects</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.421.1">Adaptability</span></strong><span class="koboSpan" id="kobo.422.1">: Programmatic labeling algorithms can be fine-tuned and updated as needed to accommodate changing requirements, new data sources, or evolving </span><span class="No-Break"><span class="koboSpan" id="kobo.423.1">project goals</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.424.1">24/7 availability</span></strong><span class="koboSpan" id="kobo.425.1">: Unlike human labelers, programmatic labeling can operate continuously without breaks or downtime, allowing for uninterrupted progress in </span><span class="No-Break"><span class="koboSpan" id="kobo.426.1">ML projects</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.427.1">We will show you how to use specific programmatic labeling techniques in </span><a href="B19297_06.xhtml#_idTextAnchor089"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.428.1">Chapter 6</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.429.1">, Techniques for Programmatic Labeling in </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.430.1">Machine Learning</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.431.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.432.1">Programmatic labeling techniques are often all that’s required to lift the quality of your data. </span><span class="koboSpan" id="kobo.432.2">However, in some cases, relationships between features are too complex for rules-based algorithms to do the job. </span><span class="koboSpan" id="kobo.432.3">This brings us to the third principle of </span><span class="No-Break"><span class="koboSpan" id="kobo.433.1">data-centric ML.</span></span></p>
<h1 id="_idParaDest-53"><a id="_idTextAnchor052"/><span class="koboSpan" id="kobo.434.1">Principle 3 – use ML to improve your data</span></h1>
<p><span class="koboSpan" id="kobo.435.1">Just as we can </span><a id="_idIndexMarker099"/><span class="koboSpan" id="kobo.436.1">use a programmatic or algorithmic approach to label our data, we can also use ML to identify data points that may be wrong or ambiguous. </span><span class="koboSpan" id="kobo.436.2">By leveraging developments in explainability, error analysis, and semi-supervised approaches, we can create new labels and find data points to improve </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">or discard.</span></span></p>
<p><span class="koboSpan" id="kobo.438.1">Here are some practical steps to generate better input data </span><span class="No-Break"><span class="koboSpan" id="kobo.439.1">with ML:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.440.1">Toss out noisy examples</span></strong><span class="koboSpan" id="kobo.441.1">: Sometimes, more data is not always better. </span><span class="koboSpan" id="kobo.441.2">Noisy data can lead to inaccurate predictions. </span><span class="koboSpan" id="kobo.441.3">By removing noisy examples, we can improve the quality of our input data. </span><span class="koboSpan" id="kobo.441.4">For instance, if you’re analyzing customer reviews and some reviews are filled with random characters or irrelevant information, those can be considered as “noisy” </span><span class="No-Break"><span class="koboSpan" id="kobo.442.1">and removed.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.443.1">Use techniques to focus on a subset of data to improve</span></strong><span class="koboSpan" id="kobo.444.1">: Not all data has the same value. </span><span class="koboSpan" id="kobo.444.2">We can focus on a subset of data to improve the quality of our input data. </span><span class="koboSpan" id="kobo.444.3">For example, if you’re analyzing sales data, you might focus on the subset of data from your most profitable region to get the most return on your efforts, all else </span><span class="No-Break"><span class="koboSpan" id="kobo.445.1">being equal.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.446.1">Expand available label data by leveraging ML generalization from expert input</span></strong><span class="koboSpan" id="kobo.447.1">: ML can be used to expand the available label data by using expert input to achieve similar precision and greater coverage. </span><span class="koboSpan" id="kobo.447.2">An expert in bird species, for</span><a id="_idIndexMarker100"/><span class="koboSpan" id="kobo.448.1"> example, could provide input on a limited set of images, and ML could use this to accurately label a larger set </span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">of images.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.450.1">Use semi-supervised approaches</span></strong><span class="koboSpan" id="kobo.451.1">: Semi-supervised approaches, including weak learning and active learning, can be used to identify data points that require SME review. </span><span class="koboSpan" id="kobo.451.2">For example, you might use active learning to identify customer emails that need to be reviewed by a human for </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">sentiment analysis.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.453.1">Use explainability</span></strong><span class="koboSpan" id="kobo.454.1">: Explainability is essential in identifying patterns in data and ensuring that models make sense. </span><span class="koboSpan" id="kobo.454.2">Complex models require a model-specific or model-agnostic approach to explainability, including local and global methods and SHAP values. </span><span class="koboSpan" id="kobo.454.3">For example, using SHAP values can help you understand why your model predicted a certain outcome in a loan approval process, ensuring the decision-making is transparent </span><span class="No-Break"><span class="koboSpan" id="kobo.455.1">and explainable.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.456.1">Use error analysis</span></strong><span class="koboSpan" id="kobo.457.1">: Error analysis can help identify patterns in data where models are making mistakes, helping to improve the quality of our input data. </span><span class="koboSpan" id="kobo.457.2">For instance, if your model is incorrectly identifying cats as something else in image recognition, error analysis can help you figure out where and why it’s making </span><span class="No-Break"><span class="koboSpan" id="kobo.458.1">these mistakes.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.459.1">The techniques required to perform these steps will be outlined throughout the subsequent chapters of </span><span class="No-Break"><span class="koboSpan" id="kobo.460.1">this book.</span></span></p>
<p><span class="koboSpan" id="kobo.461.1">By applying these steps in production, we can identify performance drifts in labeling functions or models. </span><span class="koboSpan" id="kobo.461.2">Additionally, we can identify data points that require human review, leading to better quality input data and improved </span><span class="No-Break"><span class="koboSpan" id="kobo.462.1">prediction accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.463.1">The use </span><a id="_idIndexMarker101"/><span class="koboSpan" id="kobo.464.1">of ML to improve input data quality is a fundamental shift in the traditional approach to ML. </span><span class="koboSpan" id="kobo.464.2">It requires a mindset shift from using ML models to make the best prediction to using ML to identify the data points that are not helping model performance. </span><span class="koboSpan" id="kobo.464.3">After all, the goal of data-centric ML is to increase signal and reduce noise in our </span><span class="No-Break"><span class="koboSpan" id="kobo.465.1">input data.</span></span></p>
<p><span class="koboSpan" id="kobo.466.1">Embracing a data-centric approach also provides us with a unique opportunity to collect and refine data in a manner that is inherently aligned with ethical, responsible, and well-governed ML practices. </span><span class="koboSpan" id="kobo.466.2">This shift in focus allows us to design our data strategies not just around performance enhancement but also around principles of fairness, transparency, </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">and accountability.</span></span></p>
<p><span class="koboSpan" id="kobo.468.1">As we proceed, we will explore how this approach can help us to embed ethics at the very core of our data collection and refinement processes. </span><span class="koboSpan" id="kobo.468.2">This way, we can ensure that improved data quality goes hand in hand with maintaining the integrity and trustworthiness of our </span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">ML applications.</span></span></p>
<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/><span class="koboSpan" id="kobo.470.1">Principle 4 – follow ethical, responsible, and well-governed ML practices</span></h1>
<p><span class="koboSpan" id="kobo.471.1">Ethical and responsible ML practices</span><a id="_idIndexMarker102"/><span class="koboSpan" id="kobo.472.1"> become increasingly important as data-centricity allows us to tackle more high-stakes challenges. </span><span class="koboSpan" id="kobo.472.2">This requires you to consider factors such as transparency, fairness, and accountability when designing algorithms so that they do not discriminate against certain groups or individuals. </span><span class="koboSpan" id="kobo.472.3">Additionally, those responsible for implementing these systems must be aware of how they work and understand their limitations so that they can make informed decisions about </span><span class="No-Break"><span class="koboSpan" id="kobo.473.1">their use.</span></span></p>
<p><span class="koboSpan" id="kobo.474.1">Unfortunately, ethical and responsible ML practices are generally not as developed as they should be. </span><span class="koboSpan" id="kobo.474.2">In 2021, the IBM Institute for Business Value and Oxford Economics conducted a study</span><span class="superscript"><span class="koboSpan" id="kobo.475.1">1</span></span><span class="koboSpan" id="kobo.476.1"> where 75% of executives ranked AI ethics as important; however, fewer than 20% of executives strongly agreed that their organizations’ practices aligned with their declared principles </span><span class="No-Break"><span class="koboSpan" id="kobo.477.1">and values.</span></span></p>
<p><span class="koboSpan" id="kobo.478.1">As practitioners of data-centric ML, we need to consider that the term </span><em class="italic"><span class="koboSpan" id="kobo.479.1">data quality</span></em><span class="koboSpan" id="kobo.480.1"> is much broader than the objective accuracy of individual data points. </span><span class="koboSpan" id="kobo.480.2">High-quality data should also allow us to identify and monitor potential ethical issues throughout the ML development process </span><span class="No-Break"><span class="koboSpan" id="kobo.481.1">and beyond.</span></span></p>
<p><span class="koboSpan" id="kobo.482.1">AI ethics and responsibility is not just a tick-box exercise, but a potential source of differentiation. </span><span class="koboSpan" id="kobo.482.2">Organizations that pay attention to AI ethics are more likely to be trusted by their customers, while organizations that overlook it are likely to suffer customer backlash and </span><span class="No-Break"><span class="koboSpan" id="kobo.483.1">reputational damage</span></span><span class="No-Break"><span class="superscript"><span class="koboSpan" id="kobo.484.1">2</span></span></span><span class="No-Break"><span class="koboSpan" id="kobo.485.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.486.1">The story of the UK’s 2020 </span><em class="italic"><span class="koboSpan" id="kobo.487.1">school grading fiasco</span></em><span class="koboSpan" id="kobo.488.1"> highlights what can happen when you ignore ethical considerations while using ML in high-stakes environments. </span><span class="koboSpan" id="kobo.488.2">During the COVID-19 pandemic, students across the UK were unable to sit their exams because of lockdowns. </span><span class="koboSpan" id="kobo.488.3">Instead, an algorithm was used to grade students’ exam results, resulting in a significant number of students receiving lower grades than they deserved. </span><span class="koboSpan" id="kobo.488.4">This caused uproar among students, teachers, and the academic community as it was seen as unfair </span><span class="No-Break"><span class="koboSpan" id="kobo.489.1">and unjust.</span></span></p>
<p><span class="koboSpan" id="kobo.490.1">The algorithm used by Ofqual, the UK regulator responsible for regulating qualifications, exams, and assessments, was designed to standardize grades across different schools to make them comparable. </span><span class="koboSpan" id="kobo.490.2">It considered factors such as prior attainment and school performance. </span><span class="koboSpan" id="kobo.490.3">However, it did not consider individual student performance or teacher assessments, which resulted in many students receiving lower grades than they </span><span class="No-Break"><span class="koboSpan" id="kobo.491.1">should have.</span></span></p>
<p><span class="koboSpan" id="kobo.492.1">Instead, the model favored students from private institutions and wealthy areas, significantly impacting high-performing individuals from public, state-funded schools. </span><span class="koboSpan" id="kobo.492.2">Consequently, numerous students lost their university admissions due to the lowered exam scores. </span><span class="koboSpan" id="kobo.492.3">This caused a great deal of distress among the students who had worked hard for their exams only to be let down by an algorithm that did not accurately reflect their abilities. </span><span class="koboSpan" id="kobo.492.4">In the end, the grades awarded by the algorithm were canceled, and replaced by a fairer but more manual </span><span class="No-Break"><span class="koboSpan" id="kobo.493.1">grading approach.</span></span></p>
<p><span class="koboSpan" id="kobo.494.1">To avoid </span><a id="_idIndexMarker103"/><span class="koboSpan" id="kobo.495.1">similar incidents such as the UK grading disaster from occurring in the future, AI systems must be designed with ethical considerations in mind from the outset. </span><span class="koboSpan" id="kobo.495.2">Overall, this incident highlights some of the ethical issues associated with AI systems and demonstrates why it is important for us to consider these issues when designing and implementing them. </span><span class="koboSpan" id="kobo.495.3">It also serves as a reminder that we must ensure these systems are transparent, fair, and accountable if we want them to be effective tools for decision-making in </span><span class="No-Break"><span class="koboSpan" id="kobo.496.1">our society.</span></span></p>
<p><span class="koboSpan" id="kobo.497.1">We will be discussing specific ways to deal with ambiguity in labeling in </span><a href="B19297_04.xhtml#_idTextAnchor056"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.498.1">Chapter 4</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.499.1">, Data Labeling Is a Collaborative Process</span></em><span class="koboSpan" id="kobo.500.1"> and show you a range of techniques for identifying and removing bias in </span><a href="B19297_08.xhtml#_idTextAnchor125"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.501.1">Chapter 8</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.502.1">, Techniques for Identifying and </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.503.1">Removing Bias</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.504.1">.</span></span></p>
<h1 id="_idParaDest-55"><a id="_idTextAnchor054"/><span class="koboSpan" id="kobo.505.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.506.1">In this chapter, we outlined the four principles of data-centric ML. </span><span class="koboSpan" id="kobo.506.2">By following these principles, you will be able to create ML models that are based on high-quality data that has been enhanced, cross-checked, and verified by humans, labeling functions, and </span><span class="No-Break"><span class="koboSpan" id="kobo.507.1">ML techniques.</span></span></p>
<p><span class="koboSpan" id="kobo.508.1">This allows us to get more signals out of our data, which, in turn, increases our ability to build powerful models on small or large datasets. </span><span class="koboSpan" id="kobo.508.2">Lastly, we can capture ethical considerations throughout the development life cycle, which ultimately ensures we’re using our powers </span><span class="No-Break"><span class="koboSpan" id="kobo.509.1">for good.</span></span></p>
<p><span class="koboSpan" id="kobo.510.1">In the next chapter, we’ll explore specific ways you can structure, optimize, and govern the process of using human annotators for your </span><span class="No-Break"><span class="koboSpan" id="kobo.511.1">ML projects.</span></span></p>
<h1 id="_idParaDest-56"><a id="_idTextAnchor055"/><span class="koboSpan" id="kobo.512.1">References</span></h1>
<ol>
<li><a href="https://www.ibm.com/thought-leadership/institute-business-value/en-us/report/ai-ethics-in-action"><span class="koboSpan" id="kobo.513.1">https://www.ibm.com/thought-leadership/institute-business-value/en-us/report/ai-ethics-in-action</span></a><span class="koboSpan" id="kobo.514.1">, accessed on 1 </span><span class="No-Break"><span class="koboSpan" id="kobo.515.1">June 2023</span></span></li>
<li><a href="https://www.capgemini.com/insights/expert-perspectives/decoding-trust-and-ethics-in-ai-for-business-outcomes/"><span class="koboSpan" id="kobo.516.1">https://www.capgemini.com/insights/expert-perspectives/decoding-trust-and-ethics-in-ai-for-business-outcomes/</span></a><span class="koboSpan" id="kobo.517.1">, accessed on 1 </span><span class="No-Break"><span class="koboSpan" id="kobo.518.1">June 2023</span></span></li>
</ol>
</div>
</body></html>