<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Microbenchmarking and Activation Functions</h1>
                </header>
            
            <article>
                
<p>In this chapter we are going to learn the following:</p>
<ul>
<li>What microbenchmarking is</li>
<li>How to apply it to your code</li>
<li>What activation functions are</li>
<li>How to plot and benchmark activation functions</li>
</ul>
<p>Every developer needs to have a good benchmarking tool at their disposal. Qualitative benchmarks are everywhere; you hear everyday, <em>We decreased this by 10% and increased that by 25%</em>. Remember the old adage, <em>When you hear a number thrown out, 98.4 percent of the time that number is false</em>? By the way, I just made up that number as well. When you hear a quote like that, ask that person to prove it and what do you get? Task manager perhaps? As data scientists, we don't need qualitative results; we need quantitative results that can be proven and consistently replicated. Reproducible results are incredibly important, not only for consistency but also for credibility and accuracy. And that's where microbenchmarking comes in to play.</p>
<p>We are going to use the irreplaceable <kbd>BenchmarkDotNet</kbd> library, which you can find here: <a href="https://github.com/dotnet/BenchmarkDotNet">https://github.com/dotnet/BenchmarkDotNet</a>.</p>
<p>If you are not already using this library, you need to drop what you are doing right now and install it. I consider it one of the most irreplaceable frameworks you can use, and I consider it in terms of importance, right up there with unit and integration testing.</p>
<p>To show you just how valuable this tool is, we are going to plot several activation functions and compare their runtimes. As part of this, we will consider <strong>warmup</strong>, <strong>legacy</strong> and <strong>RyuJIT</strong>, <strong>cold starting</strong>, and more aspects of a program execution. In the end, we will have a quantitative set of results that prove the exact measurements of our functions. If, say in release 2.0, we see that something is running slower, we can rerun the benchmarks and compare.</p>
<p>I would strongly recommend that this be integrated into your continuous integration/continuous build process so that at each release, you have benchmark numbers to compare. And that's not just our code. I have created massive CI/CD systems that encompassed a huge number of programs, microservices, environments, and build and deploy steps. We would also <span>regularly </span>benchmark certain .NET library functions that we use all the time to verify; in between .NET framework releases, nothing has changed.</p>
<p>In this chapter, we are going to have two samples. The first is an activation function viewer; it will plot each activation function so that you can see how it looks. You can find this as part of what I consider one of the most valuable open source programs, <strong>SharpNEAT</strong>, by Mr. Colin Green. This package is absolutely incredible, and there's not a day that goes by when I don't use it. I have created new UIs on top of it as well as advanced versions to work with my requirements, and it's as flexible a tool as you can find. I work daily with researching the integration of mirror and canonical neurons into extendable substrates, and tools such as SharpNEAT are incredible. A future advanced book will be highlighting SharpNEAT much more, so get familiar with it now! This first sample application is available with the latest SharpNEAT package, which can be found at <a href="https://github.com/colgreen/sharpneat">https://github.com/colgreen/sharpneat</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Visual activation function plotting</h1>
                </header>
            
            <article>
                
<p>Here is a plot of local and global minimum being plotted from a custom version of SharpNEAT. It is absolutely amazing what you can do with this product in the realm of neural networks and advanced machine learning!</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5e1b0cd5-63fd-4651-8f0e-96b9b2fb805a.png" style=""/></div>
<p>As I mentioned, we are going to plot and then benchmark several activation functions. We hear this term <strong>activation functions</strong> everywhere, but do we really know what it means? Let's start by giving a quick explanation just in case you are not familiar.</p>
<p>An activation function is used to decide whether a neuron has been activated or not. Some people like to replace the word <strong>activated</strong> with <strong>fired</strong>. Whatever flips your pickle! Either way, it's what finally determines whether something is on or off, fired or not, activated or not.</p>
<p>Let's start by showing you what a plot of a single activation function looks like:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/25824019-1323-4dd5-bc88-242fec67a72d.png"/></div>
<p>This is what the <strong>Logistic Steep</strong> approximation and <strong>Swish activation</strong> function look like when they are plotted individually, as there are many types of activation functions, here's what all of our activation functions are going to look like when they are plotted together:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7c96dcb6-1fe0-4351-a348-8c4f8696d16a.png"/></div>
<p>At this point you may be wondering, <em>Why do we even care what the plots look like?</em> Great question. We care because you are going to use these quite a bit once you progress into neural networks and beyond. It's very handy to be able to know whether your activation function will place the value of your neuron in on or off state, and what range it will keep or need the values in. You will no doubt encounter and/or use activation functions in your career as a machine learning developer, and knowing the difference between a <kbd>TanH</kbd> and a <kbd>LeakyReLU</kbd> activation function is very important.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Plotting all functions</h1>
                </header>
            
            <article>
                
<p>The plotting of all the activation functions is done within a single function, remarkably titled <kbd>PlotAllFunctions</kbd>:</p>
<pre>private void PlotAllFunctions()<br/>{<br/>// First, clear out any old GraphPane's from the MasterPane<br/>collection MasterPane master = zed.MasterPane;<br/>master.PaneList.Clear();<br/>// Display the MasterPane Title, and set the <br/>  outer margin to 10 points<br/>master.Title.IsVisible = true;<br/>master.Margin.All = 10;<br/>// Plot multiple functions arranged on a master pane.<br/>PlotOnMasterPane(Functions.LogisticApproximantSteep,<br/>  "Logistic Steep (Approximant)");<br/>PlotOnMasterPane(Functions.LogisticFunctionSteep,<br/>  "Logistic Steep (Function)");<br/>PlotOnMasterPane(Functions.SoftSign, "Soft Sign");<br/>PlotOnMasterPane(Functions.PolynomialApproximant,<br/>  "Polynomial Approximant");<br/>PlotOnMasterPane(Functions.QuadraticSigmoid,<br/>  "Quadratic Sigmoid");<br/>PlotOnMasterPane(Functions.ReLU, "ReLU");<br/>PlotOnMasterPane(Functions.LeakyReLU, "Leaky ReLU");<br/>PlotOnMasterPane(Functions.LeakyReLUShifted,<br/>  "Leaky ReLU (Shifted)");<br/>PlotOnMasterPane(Functions.SReLU, "S-Shaped ReLU");<br/>PlotOnMasterPane(Functions.SReLUShifted,<br/>  "S-Shaped ReLU (Shifted)");<br/>PlotOnMasterPane(Functions.ArcTan, "ArcTan");<br/>PlotOnMasterPane(Functions.TanH, "TanH");<br/>PlotOnMasterPane(Functions.ArcSinH, "ArcSinH");<br/>PlotOnMasterPane(Functions.ScaledELU, <br/>  "Scaled Exponential Linear Unit");<br/>// Refigure the axis ranges for the GraphPanes.<br/>  zed.AxisChange();<br/>// Layout the GraphPanes using a default Pane Layout.<br/>using (Graphics g = this.CreateGraphics()) {<br/>  master.SetLayout(g, PaneLayout.<strong>SquareColPreferred</strong>);<br/>}</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The main Plot function</h1>
                </header>
            
            <article>
                
<p>Behind the scenes, the <kbd>Plot</kbd> function is what is responsible for executing and plotting each function:</p>
<pre>private void Plot(Func&lt;double, double&gt; fn, string fnName, <br/>  Color graphColor, GraphPane gpane = null)<br/>{<br/>  const double <strong>xmin</strong> = -2.0;<br/>  const double <strong>xmax</strong> = 2.0;<br/>  const int <strong>resolution</strong> = 2000;<br/>  zed.IsShowPointValues = true;<br/>  zed.PointValueFormat = "e";<br/>  var pane = gpane ?? zed.GraphPane;<br/>  pane.XAxis.MajorGrid.IsVisible = true;<br/>  pane.YAxis.MajorGrid.IsVisible = true;<br/>  pane.Title.Text = fnName;<br/>  pane.YAxis.Title.Text = string.Empty;<br/>  pane.XAxis.Title.Text = string.Empty;<br/>  double[] xarr = new double[<strong>resolution</strong>];<br/>  double[] yarr = new double[<strong>resolution</strong>];<br/>  double incr = (<strong>xmax</strong> - <strong>xmin</strong>) / <strong>resolution</strong>;<br/>  double <strong>x</strong> = <strong>xmin</strong>;<br/>for(int <strong>i</strong>=0; <strong>i</strong> &lt; <strong>resolution</strong>; <strong>i</strong>++, <strong>x</strong>+=incr)<br/>{<br/>  xarr[<strong>i</strong>] = <strong>x</strong>;<br/>  yarr[<strong>i</strong>] = fn(<strong>x</strong>);<br/>}<br/>PointPairList list1 = new PointPairList(xarr, yarr);<br/>LineItem li = pane.AddCurve(string.Empty, list1, graphColor,<br/>  SymbolType.<strong>None</strong>);<br/>li.Symbol.Fill = new Fill(Color.White);<br/>pane.Chart.Fill = new Fill(Color.White, <br/>  Color.LightGoldenrodYellow, 45.0F);<br/>}</pre>
<p>The main point of interest within this code is highlighted in yellow. This is where the activation function that we passed in is executed and its value used for the <em>y</em> axis plot value. The famous <strong>ZedGraph</strong> open source plotting package is used for all graph plotting. Once each function is executed, the respective plot will be made.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Benchmarking</h1>
                </header>
            
            <article>
                
<p><kbd>BenchmarkDotNet</kbd> produces several reports, one of which is an HTML report similar to what you see here:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ec9f37e5-485d-4bd9-8ef2-4038279fb496.png" style=""/></div>
<p>The Excel report provides the details of every parameter that was used in running the program and is your most extensive source of information. In many cases, most of these parameters will use the default values and be more than you need, but at least you will have the choice to remove what you will:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5c10d791-352d-4762-b01a-5a1cb00b301f.png"/></div>
<p>We'll describe some of these parameters in our next section when we review the source code for creating what you see before:</p>
<pre>static void Main(string[] args)<br/>{<br/>var config = ManualConfig.Create(DefaultConfig.Instance);<br/>// Set up an results exporter.<br/>// Note. By default results files will be located in <br/>  .BenchmarkDotNet.Artifactsresults directory.<br/>config.Add(new CsvExporter(CsvSeparator.<strong>CurrentCulture</strong>,<br/>  new BenchmarkDotNet.Reports.SummaryStyle<br/>{<br/>  PrintUnitsInHeader = true,<br/>  PrintUnitsInContent = false,<br/>  TimeUnit = TimeUnit.Microsecond,<br/>  SizeUnit = BenchmarkDotNet.Columns.SizeUnit.KB<br/>}));<br/>// Legacy JITter tests.<br/>config.Add(new Job(EnvMode.LegacyJitX64, <br/>  EnvMode.Clr, RunMode.Short)<br/>{<br/>  Env = { Runtime = Runtime.Clr, Platform = Platform.<strong>X64</strong> },<br/>    Run = { LaunchCount = 1, WarmupCount = 1, <br/>    TargetCount = 1, RunStrategy =<br/>    BenchmarkDotNet.Engines.RunStrategy.<strong>Throughput</strong> },<br/>  Accuracy = { RemoveOutliers = true }<br/>}.WithGcAllowVeryLargeObjects(true));<br/>// RyuJIT tests.<br/>config.Add(new Job(EnvMode.RyuJitX64, EnvMode.Clr,<br/>  RunMode.Short)<br/>{<br/>  Env = { Runtime = Runtime.Clr, Platform = Platform.<strong>X64</strong> },<br/>    Run = { LaunchCount = 1, WarmupCount = 1, <br/>    TargetCount = 1, RunStrategy = <br/>    BenchmarkDotNet.Engines.RunStrategy.<strong>Throughput</strong> }, <br/>  Accuracy = { RemoveOutliers = true }<br/>}.WithGcAllowVeryLargeObjects(true));<br/>// Uncomment to allow benchmarking of non-optimized assemblies.<br/>//config.Add(JitOptimizationsValidator.DontFailOnError);<br/>// Run benchmarks.<br/>var summary = BenchmarkRunner.Run&lt;FunctionBenchmarks&gt;(config);<br/>}</pre>
<p>Let's dissect this code a bit more.</p>
<p>To begin with, we'll create a manual configuration object that will hold our configuration parameters used for benchmarking:</p>
<pre>var config = ManualConfig.Create(DefaultConfig.Instance);</pre>
<p>Next, we'll set up an exporter to hold the parameters we will use for exporting our results. We will export our results to a <kbd>.csv</kbd> file using a timing of microseconds and size in kilobytes:</p>
<pre>config.Add(new CsvExporter(CsvSeparator.<strong>CurrentCulture</strong>,<br/>  new BenchmarkDotNet.Reports.SummaryStyle<br/>{<br/>  PrintUnitsInHeader = true,<br/>  PrintUnitsInContent = false,<br/>  TimeUnit = TimeUnit.Microsecond,<br/>  SizeUnit = BenchmarkDotNet.Columns.SizeUnit.KB<br/>}));</pre>
<p>Next, we'll create a benchmark job that will handle the measurements of the <kbd>LegacyJitX64</kbd> on the x64 architecture. You can feel free to change this and any other parameter to experiment with or include whatever results you need or want for your test scenario. In our case, we will be using the x64 platform; a <kbd>LaunchCount</kbd>, <kbd>WarmupCount</kbd>, and <kbd>TargetCount</kbd> of <kbd>1</kbd>; and <kbd>RunStrategy</kbd> of <kbd>Throughput</kbd>. We will also do the same for RyuJIT but we won't show the code here:</p>
<pre>config.Add(new Job(EnvMode.LegacyJitX64, EnvMode.Clr,<br/> RunMode.Short)<br/>{<br/>  Env = { Runtime = Runtime.Clr, Platform = Platform.<strong>X64</strong> },<br/>    Run = { LaunchCount = 1, WarmupCount = 1, TargetCount = 1,<br/>    RunStrategy = <strong>Throughput</strong> },<br/>    Accuracy = { RemoveOutliers = true }<br/>}.WithGcAllowVeryLargeObjects(true));</pre>
<p>Finally, we will run <kbd>BenchmarkRunner</kbd> to perform our tests:</p>
<pre>// Run benchmarks.<br/>var summary = BenchmarkRunner.Run&lt;FunctionBenchmarks&gt;(config);</pre>
<p><kbd>BenchmarkDotNet</kbd> will run as a DOS command-line application, and the following is an example of the preceding code executing:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/28a6f0cd-5d8e-4b78-8b07-7dc8ce300724.png"/></div>
<p>Let's take a look at one example of an activation function being plotted:</p>
<pre>[Benchmark]<br/>public double LogisticFunctionSteepDouble()<br/>{<br/>  double <strong>a</strong> = 0.0;<br/>  for(int <strong>i</strong>=0; <strong>i</strong>&lt;<strong>__loops</strong>; <strong>i</strong>++)<br/>  {<br/><strong>    a</strong> = Functions.LogisticFunctionSteep(_x[<strong>i</strong> % _x.Length]);<br/>  }<br/>  return <strong>a</strong>;<br/>}</pre>
<p>You will notice the <kbd>[Benchmark]</kbd> attribute being used. This indicates to <kbd>BenchmarkDotNet</kbd> that this will be a test that needs to be benchmarked. Internally, it calls the following function:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1adf0073-45d7-40cc-b866-71f13c747239.png" style=""/></div>
<p class="mce-root CDPAlignLeft CDPAlign">For the <kbd>LogisticFunctionSteep</kbd> function, the implementation, like most activation functions, is simple (assuming you know the formula). In this case we are not plotting the activation function but rather benchmarking it. You will notice that the function takes and returns <kbd>double</kbd>. We have also benchmarked the identical function by using and returning <kbd>float</kbd> variables, so we are benchmarking the difference between the function using <kbd>double</kbd> and <kbd>float</kbd>. Hence, people can see that sometimes the performance impact is more than they may think:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c3dca76d-77f9-493f-b81c-2306673f2fd8.png" style=""/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter we learned about applying microbenchmarking to your code. We also saw how to plot and benchmark activation functions as well as use microbenchmarking with that as well. You now have one of the most powerful benchmarking libraries which you can add to all your code. In the next chapter, we are going to dive into Intuitive Deep Learning and show you one of the most powerful frameworks for machine learning testing available to a C# developer.</p>


            </article>

            
        </section>
    </body></html>