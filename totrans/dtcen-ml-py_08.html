<html><head></head><body>
<div id="_idContainer113">
<h1 class="chapter-number" id="_idParaDest-117"><a id="_idTextAnchor125"/><span class="koboSpan" id="kobo.1.1">8</span></h1>
<h1 id="_idParaDest-118"><a id="_idTextAnchor126"/><span class="koboSpan" id="kobo.2.1">Techniques for Identifying and Removing Bias</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In the realm of data-centric machine learning, the pursuit of unbiased and fair models is paramount. </span><span class="koboSpan" id="kobo.3.2">The consequences of biased algorithms can range from poor performance to ethically questionable decisions. </span><span class="koboSpan" id="kobo.3.3">It is important to recognize that bias can manifest at two key stages of the machine learning pipeline: data and model. </span><span class="koboSpan" id="kobo.3.4">While model-centric approaches have garnered significant attention in recent years, this chapter sheds light on the equally crucial data-centric strategies that are </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">often overlooked.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">In this chapter, we will explore the intricacies of bias in machine learning, emphasizing why data-centricity is a fundamental aspect of bias mitigation. </span><span class="koboSpan" id="kobo.5.2">We will explore real-world examples from finance, human resources, and healthcare, where the failure to address bias has had or could have </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">far-reaching implications.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">In this chapter, we’ll cover the </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">following topics:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.9.1">The </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">bias conundrum</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">Types </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">of bias</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">The </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">data-centric imperative</span></span></li>
<li><span class="No-Break"><span class="koboSpan" id="kobo.15.1">Case study</span></span></li>
</ul>
<h1 id="_idParaDest-119"><a id="_idTextAnchor127"/><span class="koboSpan" id="kobo.16.1">The bias conundrum</span></h1>
<p><span class="koboSpan" id="kobo.17.1">Bias in </span><a id="_idIndexMarker582"/><span class="koboSpan" id="kobo.18.1">machine learning is not a novel concern. </span><span class="koboSpan" id="kobo.18.2">It is deeply rooted in the data we collect and the algorithms we design. </span><span class="koboSpan" id="kobo.18.3">Bias can arise from historical disparities, societal prejudices, and even the human decisions made during data collection and annotation. </span><span class="koboSpan" id="kobo.18.4">Ignoring bias, or addressing it solely through model-centric techniques, can lead to </span><span class="No-Break"><span class="koboSpan" id="kobo.19.1">detrimental outcomes.</span></span></p>
<p><span class="koboSpan" id="kobo.20.1">Consider the following scenarios, which illustrate the multifaceted nature </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">of bias:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.22.1">Bias in finance</span></strong><span class="koboSpan" id="kobo.23.1">: In</span><a id="_idIndexMarker583"/><span class="koboSpan" id="kobo.24.1"> the financial sector, machine learning models play a pivotal role in credit scoring, fraud detection, and investment recommendations. </span><span class="koboSpan" id="kobo.24.2">However, if historical lending practices favor certain demographic groups over others, these biases can seep into the data used to train models. </span><span class="koboSpan" id="kobo.24.3">As a result, marginalized communities may face unfair lending practices, perpetuating </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">socioeconomic inequalities.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.26.1">Bias in human resources</span></strong><span class="koboSpan" id="kobo.27.1">: The use of AI in human resources has gained momentum for</span><a id="_idIndexMarker584"/><span class="koboSpan" id="kobo.28.1"> recruitment, employee performance assessment, and even salary negotiations. </span><span class="koboSpan" id="kobo.28.2">If job postings or historical hiring data are biased toward specific genders, ethnicities, or backgrounds, the AI systems can inadvertently perpetuate discrimination, leading to a lack of diversity and inclusion in </span><span class="No-Break"><span class="koboSpan" id="kobo.29.1">the workplace.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.30.1">Bias in healthcare</span></strong><span class="koboSpan" id="kobo.31.1">: In </span><a id="_idIndexMarker585"/><span class="koboSpan" id="kobo.32.1">healthcare, diagnostic algorithms are relied upon for disease detection and treatment recommendations. </span><span class="koboSpan" id="kobo.32.2">If training data predominantly represents certain demographics, individuals from underrepresented groups may receive suboptimal care or face delayed diagnoses. </span><span class="koboSpan" id="kobo.32.3">The implications can be life-altering, underscoring the need for equitable </span><span class="No-Break"><span class="koboSpan" id="kobo.33.1">healthcare AI.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.34.1">Now that we have covered areas where bias can arise, in the next section, we will cover the types of bias prevalent in </span><span class="No-Break"><span class="koboSpan" id="kobo.35.1">machine learning.</span></span></p>
<h1 id="_idParaDest-120"><a id="_idTextAnchor128"/><span class="koboSpan" id="kobo.36.1">Types of bias</span></h1>
<p><span class="koboSpan" id="kobo.37.1">In machine learning, there are generally five categories of bias that warrant attention. </span><span class="koboSpan" id="kobo.37.2">Although the list provided isn't exhaustive, these categories represent the most prevalent types of bias, each of which can be </span><span class="No-Break"><span class="koboSpan" id="kobo.38.1">further subdivided.</span></span></p>
<h2 id="_idParaDest-121"><a id="_idTextAnchor129"/><span class="koboSpan" id="kobo.39.1">Easy to identify bias</span></h2>
<p><span class="koboSpan" id="kobo.40.1">Some types of bias can be easy to identify using active monitoring and by conducting analysis. </span><span class="koboSpan" id="kobo.40.2">These include </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">the following.</span></span></p>
<h3><span class="koboSpan" id="kobo.42.1">Reporting bias</span></h3>
<p><span class="koboSpan" id="kobo.43.1">This type of bias</span><a id="_idIndexMarker586"/><span class="koboSpan" id="kobo.44.1"> occurs when the data producers, data annotators, or data capturers miss out on important elements, which results in data not being representative of the real world. </span><span class="koboSpan" id="kobo.44.2">For instance, a healthcare business might be interested in patients’ sentiments toward a health program; however, the data annotators may decide to focus on negative and positive sentiments, and sentiments that were neutral may be underrepresented. </span><span class="koboSpan" id="kobo.44.3">A model trained on such data will be good at identifying positive and negative sentiments but may fail to accurately predict neutral sentiments. </span><span class="koboSpan" id="kobo.44.4">This type of bias can be identified with active monitoring, where predictions on live data show drift from predictions on training data. </span><span class="koboSpan" id="kobo.44.5">To reduce reporting bias, it is important to articulate data points needed for the problem at the beginning phase of ML system design. </span><span class="koboSpan" id="kobo.44.6">It is also important to ensure that data used for training represents </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">real-life data.</span></span></p>
<h3><span class="koboSpan" id="kobo.46.1">Automation bias</span></h3>
<p><span class="koboSpan" id="kobo.47.1">This </span><a id="_idIndexMarker587"/><span class="koboSpan" id="kobo.48.1">type of bias occurs due to relying on automated ways of data collection and assuming data capture is not error-prone. </span><span class="koboSpan" id="kobo.48.2">As AI is becoming better, reliance on humans has significantly reduced, and hence it is often assumed that if an automated system is put in place, then it will magically solve all problems. </span><span class="koboSpan" id="kobo.48.3">Using active monitoring can help identify this type of bias, where the model accuracy is highly poor on real-life data. </span><span class="koboSpan" id="kobo.48.4">Another way of identifying this is by using humans to annotate labels and measure human performance versus algorithmic performance. </span><span class="koboSpan" id="kobo.48.5">As covered in </span><a href="B19297_06.xhtml#_idTextAnchor089"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.49.1">Chapter 6</span></em></span></a><em class="italic"><span class="koboSpan" id="kobo.50.1">, Techniques for Programmatic Labeling in Machine Learning</span></em><span class="koboSpan" id="kobo.51.1"> systems fail and can lead to missing data or inaccurate data. </span><span class="koboSpan" id="kobo.51.2">AI is as good as the data it was trained on. </span><span class="koboSpan" id="kobo.51.3">One of the key principles of data-centricity is to keep humans in the loop; hence, when building automated systems, we should ensure the data generated represents real-world scenarios and data is diverse rather than overrepresented </span><span class="No-Break"><span class="koboSpan" id="kobo.52.1">or underrepresented.</span></span></p>
<h3><span class="koboSpan" id="kobo.53.1">Selection bias</span></h3>
<p><span class="koboSpan" id="kobo.54.1">This </span><a id="_idIndexMarker588"/><span class="koboSpan" id="kobo.55.1">type of bias occurs when data selected for training the model is not representative of real-life data. </span><span class="koboSpan" id="kobo.55.2">This bias can take </span><span class="No-Break"><span class="koboSpan" id="kobo.56.1">multiple forms:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.57.1">Coverage bias</span></strong><span class="koboSpan" id="kobo.58.1">: This bias </span><a id="_idIndexMarker589"/><span class="koboSpan" id="kobo.59.1">can occur when data is not collected in a representative manner. </span><span class="koboSpan" id="kobo.59.2">This can happen when the business and practitioners are focused on outcomes, and ignore data points that do not contribute to the outcome. </span><span class="koboSpan" id="kobo.59.3">In healthcare, insurance companies may want to predict hospital admissions; however, data on people churning on insurance</span><a id="_idIndexMarker590"/><span class="koboSpan" id="kobo.60.1"> companies and using competitive insurance products, or data on people not claiming benefits to go into the hospital may not be readily available and, as a result, these groups of people may not be represented well in the </span><span class="No-Break"><span class="koboSpan" id="kobo.61.1">training data.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.62.1">Participation bias</span></strong><span class="koboSpan" id="kobo.63.1">: This bias can occur due to participants opting out of data collection</span><a id="_idIndexMarker591"/><span class="koboSpan" id="kobo.64.1"> processes, leading to one group being overrepresented over another group. </span><span class="koboSpan" id="kobo.64.2">For example, a model is trained to predict churn using survey data, where 80% of people who have moved to a new competitor are unlikely to respond to the survey, and their data is highly underrepresented in </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">the sample.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.66.1">Sampling bias</span></strong><span class="koboSpan" id="kobo.67.1">: This</span><a id="_idIndexMarker592"/><span class="koboSpan" id="kobo.68.1"> bias can occur when data collectors do not use proper randomization methods in data collection processes. </span><span class="koboSpan" id="kobo.68.2">For example, a model is trained to predict health scores based on survey data; instead of targeting the population at random, the surveyors chose 80% of people who are highly engaged with their health and are more likely to respond, compared to the rest of the responders. </span><span class="koboSpan" id="kobo.68.3">In the health industry, people who are more engaged with their health are likely to have a better health score than people who are less engaged, thus leading to a biased model toward </span><span class="No-Break"><span class="koboSpan" id="kobo.69.1">healthy people.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.70.1">Selection biases</span><a id="_idIndexMarker593"/><span class="koboSpan" id="kobo.71.1"> are difficult to identify; however, if drift is noted frequently in the data and highly frequent retraining is done to ensure the model quality does not degrade, then it will be a good time to investigate and check whether the data captured represents real-life data. </span><span class="koboSpan" id="kobo.71.2">Two types of analysis in regression modeling can help to identify this bias. </span><span class="koboSpan" id="kobo.71.3">One is conducting bivariate analysis, where a sensitive variable can be represented on the </span><em class="italic"><span class="koboSpan" id="kobo.72.1">x</span></em><span class="koboSpan" id="kobo.73.1"> axis and the target variable can be put on the </span><em class="italic"><span class="koboSpan" id="kobo.74.1">y</span></em><span class="koboSpan" id="kobo.75.1"> axis. </span><span class="koboSpan" id="kobo.75.2">If there is a strong association between the two variables, then it is important to evaluate the difference in the association metric at training time and post-scoring time. </span><span class="koboSpan" id="kobo.75.3">If the difference is significant, it is quite possible that the data used for training is not representative of real life. </span><span class="koboSpan" id="kobo.75.4">The second technique is to use multivariate analysis by comparing the possible outcomes when data is not fully represented and when data is fully represented. </span><span class="koboSpan" id="kobo.75.5">This can be done by separating the subgroups into data points that were included and the ones that were excluded at training time. </span><span class="koboSpan" id="kobo.75.6">We can run a multi-regression model by creating an independent variable group by labeling group 1 for data included and group 2 for data not included. </span><span class="koboSpan" id="kobo.75.7">We will add this new variable as a feature to the model training and then compare whether there is a significant difference in outcome between groups 1 and 2. </span><span class="koboSpan" id="kobo.75.8">If there is a difference, then the data collection </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">was biased.</span></span></p>
<p><span class="koboSpan" id="kobo.77.1">In classification examples, we can use false positive rates and/or false negative rates across sensitive subgroups to see whether these are vastly different. </span><span class="koboSpan" id="kobo.77.2">If they are, data is likely to be biased toward one or a couple of subgroups. </span><span class="koboSpan" id="kobo.77.3">Another metric that can be used to check whether bias persists is demographic parity, which is a probability comparison of the likelihood of selection from one subgroup over another. </span><span class="koboSpan" id="kobo.77.4">If the ratio of probabilities between the higher selection subgroup and the lower selection subgroup is below 0.8, it is quite likely data is biased and does not have enough representative samples. </span><span class="koboSpan" id="kobo.77.5">It is recommended to check multiple metrics to understand bias in the data and </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">the algorithm.</span></span></p>
<p><span class="koboSpan" id="kobo.79.1">To treat such biases, it is recommended, when collecting data, to use techniques such as stratified sampling to ensure that different groups are represented proportionally in the dataset. </span><span class="koboSpan" id="kobo.79.2">Now that we have covered types of bias that are easy to identify, in the next section, we will cover some types of bias that are difficult </span><span class="No-Break"><span class="koboSpan" id="kobo.80.1">to identify.</span></span></p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor130"/><span class="koboSpan" id="kobo.81.1">Difficult to identify bias</span></h2>
<p><span class="koboSpan" id="kobo.82.1">Some types of bias can be challenging because they are biases that individuals may not be consciously aware of. </span><span class="koboSpan" id="kobo.82.2">These biases often operate at a subconscious level and can influence perceptions, attitudes, and behaviors. </span><span class="koboSpan" id="kobo.82.3">In order to capture these, organizations and individuals need processes and training to ensure these biases are not present in the workspace. </span><span class="koboSpan" id="kobo.82.4">Once it has been identified that there was bias in the data collection process or data labeling process, then sensitive labels can be defined to measure and check whether the model is free from bias or whether there is an acceptable level of bias in the model. </span><span class="koboSpan" id="kobo.82.5">Some of these biases are </span><span class="No-Break"><span class="koboSpan" id="kobo.83.1">described next.</span></span></p>
<h3><span class="koboSpan" id="kobo.84.1">Group attribution bias</span></h3>
<p><span class="koboSpan" id="kobo.85.1">This type of </span><a id="_idIndexMarker594"/><span class="koboSpan" id="kobo.86.1">bias occurs when attribution is done for the entire data based on some data points. </span><span class="koboSpan" id="kobo.86.2">This usually occurs when the data creators have preconceived biases about the types of attributes present in the data. </span><span class="koboSpan" id="kobo.86.3">This type of bias can take </span><span class="No-Break"><span class="koboSpan" id="kobo.87.1">two forms:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.88.1">In-group bias</span></strong><span class="koboSpan" id="kobo.89.1">: This </span><a id="_idIndexMarker595"/><span class="koboSpan" id="kobo.90.1">is a preconceived bias where associated data points resonate with the data creator, hence those data points get a favorable outcome – for example, if a data engineering manager is designing a resume selection algorithm where they believe someone doing a Udacity nanodegree is qualified for </span><span class="No-Break"><span class="koboSpan" id="kobo.91.1">the role.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.92.1">Out-group homogeneity bias</span></strong><span class="koboSpan" id="kobo.93.1">: This is a preconceived bias where data points do not </span><a id="_idIndexMarker596"/><span class="koboSpan" id="kobo.94.1">resonate with the data creator, hence those</span><a id="_idIndexMarker597"/><span class="koboSpan" id="kobo.95.1"> data points get a negative outcome – for example, if a data engineering manager is designing a resume selection algorithm where they believe someone not doing a Udacity nanodegree is not qualified for </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">the role.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.97.1">Let’s move on to another type of bias that is difficult </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">to identify.</span></span></p>
<h3><span class="koboSpan" id="kobo.99.1">Implicit bias</span></h3>
<p><span class="koboSpan" id="kobo.100.1">This</span><a id="_idIndexMarker598"/><span class="koboSpan" id="kobo.101.1"> type of bias occurs when data creators make assumptions about the data based on their own mental models and personal experiences. </span><span class="koboSpan" id="kobo.101.2">For example, a sentiment analysis model trained on airline food service review data is likely to associate the word “okay” with neutral sentiment. </span><span class="koboSpan" id="kobo.101.3">However, some regions of the world use the word “okay” to signify a </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">positive sentiment.</span></span></p>
<p><span class="koboSpan" id="kobo.103.1">Bias in machine learning can take many forms; hence, we categorize these biases into two main types, </span><strong class="bold"><span class="koboSpan" id="kobo.104.1">easy to identify</span></strong><span class="koboSpan" id="kobo.105.1"> biases and </span><strong class="bold"><span class="koboSpan" id="kobo.106.1">difficult to identify</span></strong><span class="koboSpan" id="kobo.107.1"> biases. </span><span class="koboSpan" id="kobo.107.2">Practitioners are known to take a model-centric approach to treat these biases, where modifying the algorithm or using bias-friendly algorithms has been considered acceptable practice. </span><span class="koboSpan" id="kobo.107.3">In the next section, we will take an alternative view to the model-centric approach: the </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">data-centric approach.</span></span></p>
<h1 id="_idParaDest-123"><a id="_idTextAnchor131"/><span class="koboSpan" id="kobo.109.1">The data-centric imperative</span></h1>
<p><span class="koboSpan" id="kobo.110.1">Addressing</span><a id="_idIndexMarker599"/><span class="koboSpan" id="kobo.111.1"> bias in machine learning necessitates a holistic approach, with data-centric strategies complementing model-centric techniques. </span><span class="koboSpan" id="kobo.111.2">Data-centricity involves taking proactive steps to curate, clean, and enhance the dataset itself, thus minimizing the bias that models can inherit. </span><span class="koboSpan" id="kobo.111.3">By embracing data-centric practices, organizations can foster fairness, accountability, and </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">ethical AI.</span></span></p>
<p><span class="koboSpan" id="kobo.113.1">In the </span><a id="_idIndexMarker600"/><span class="koboSpan" id="kobo.114.1">remainder of this chapter, we will explore a spectrum of data-centric strategies that empower machine learning practitioners to reduce bias. </span><span class="koboSpan" id="kobo.114.2">These include data resampling, augmentation, cleansing, feature selection, and more. </span><span class="koboSpan" id="kobo.114.3">Real-world examples will illustrate the tangible impact of these strategies in the domains of finance, human resources, </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">and healthcare.</span></span></p>
<p><span class="koboSpan" id="kobo.116.1">If data is fairly and accurately captured or created, then it is quite likely algorithms will be mostly free from bias. </span><span class="koboSpan" id="kobo.116.2">However, the techniques we will cover in this chapter are post-data creation, where ML practitioners have to work with </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">provided data.</span></span></p>
<p><span class="koboSpan" id="kobo.118.1">In the following subsections, we will discuss some data-centric strategies for reducing bias in machine learning without changing the algorithm. </span><span class="koboSpan" id="kobo.118.2">These can be referred to as data </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">debiasing techniques.</span></span></p>
<h2 id="_idParaDest-124"><a id="_idTextAnchor132"/><span class="koboSpan" id="kobo.120.1">Sampling methods</span></h2>
<p><span class="koboSpan" id="kobo.121.1">Sampling methods</span><a id="_idIndexMarker601"/><span class="koboSpan" id="kobo.122.1"> such as undersampling</span><a id="_idIndexMarker602"/><span class="koboSpan" id="kobo.123.1"> and oversampling address class imbalances. </span><span class="koboSpan" id="kobo.123.2">Undersampling reduces majority class instances, whereas oversampling augments minority class examples. </span><span class="koboSpan" id="kobo.123.3">Integrating both mitigates overfitting and information loss, balancing class representation effectively. </span><span class="koboSpan" id="kobo.123.4">These methods can be combined with outlier treatment and Shapley values to further sample the data where harder-to-classify or harder-to-estimate data points can be removed or introduced to enhance the fairness metrics. </span><span class="koboSpan" id="kobo.123.5">These techniques are </span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">covered next.</span></span></p>
<h3><span class="koboSpan" id="kobo.125.1">Undersampling</span></h3>
<p><span class="koboSpan" id="kobo.126.1">In undersampling, we </span><a id="_idIndexMarker603"/><span class="koboSpan" id="kobo.127.1">remove random or strategic </span><a id="_idIndexMarker604"/><span class="koboSpan" id="kobo.128.1">subsets of overrepresented data points to balance class distributions – deleting data points from overrepresented classes where examples are difficult to classify or at random is a commonly used technique. </span><span class="koboSpan" id="kobo.128.2">We can also use outlier removal for </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">regression tasks.</span></span></p>
<h3><span class="koboSpan" id="kobo.130.1">Oversampling</span></h3>
<p><span class="koboSpan" id="kobo.131.1">In oversampling, we add random or strategic subsets of underrepresented data points to provide </span><a id="_idIndexMarker605"/><span class="koboSpan" id="kobo.132.1">more examples to the algorithm. </span><span class="koboSpan" id="kobo.132.2">We can duplicate or generate synthetic data points for underrepresented classes to balance class distributions. </span><span class="koboSpan" id="kobo.132.3">We can use techniques such as the </span><strong class="bold"><span class="koboSpan" id="kobo.133.1">Synthetic Minority Oversampling Technique</span></strong><span class="koboSpan" id="kobo.134.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.135.1">SMOTE</span></strong><span class="koboSpan" id="kobo.136.1">) and random oversampling for classification tasks. </span><span class="koboSpan" id="kobo.136.2">Alternatively, we can utilize outlier or edge case addition/removal for </span><span class="No-Break"><span class="koboSpan" id="kobo.137.1">regression tasks.</span></span></p>
<h3><span class="koboSpan" id="kobo.138.1">Combination of undersampling and oversampling</span></h3>
<p><span class="koboSpan" id="kobo.139.1">These </span><a id="_idIndexMarker606"/><span class="koboSpan" id="kobo.140.1">cover techniques such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.141.1">SMOTEENN</span></strong><span class="koboSpan" id="kobo.142.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.143.1">SMOTETomek</span></strong><span class="koboSpan" id="kobo.144.1">, where </span><strong class="source-inline"><span class="koboSpan" id="kobo.145.1">SMOTE</span></strong><span class="koboSpan" id="kobo.146.1"> is utilized to oversample the minority class. </span><span class="koboSpan" id="kobo.146.2">Techniques such as </span><strong class="bold"><span class="koboSpan" id="kobo.147.1">Edited Nearest Neighbors</span></strong><span class="koboSpan" id="kobo.148.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.149.1">ENN</span></strong><span class="koboSpan" id="kobo.150.1">) or Tomek Links are used to remove the examples that are difficult to classify or agree on using nearest neighbors, as these points are close to the boundary and there is no </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">clear separation.</span></span></p>
<h3><span class="koboSpan" id="kobo.152.1">Anomaly detection for oversampling and undersampling the data</span></h3>
<p><span class="koboSpan" id="kobo.153.1">This </span><a id="_idIndexMarker607"/><span class="koboSpan" id="kobo.154.1">covers using an anomaly detection technique to identify data points that are edge cases, and then these points can be reintroduced multiple times or removed so the model can get a better signal or become </span><span class="No-Break"><span class="koboSpan" id="kobo.155.1">more generalized.</span></span></p>
<h3><span class="koboSpan" id="kobo.156.1">Use of Shapley values for oversampling and undersampling data</span></h3>
<p><span class="koboSpan" id="kobo.157.1">This </span><a id="_idIndexMarker608"/><span class="koboSpan" id="kobo.158.1">covers using Shapley values to oversample or undersample data. </span><span class="koboSpan" id="kobo.158.2">Shapley values quantify feature importance by assessing each feature’s contribution to a model’s prediction. </span><span class="koboSpan" id="kobo.158.3">High Shapley values highlight influential features. </span><span class="koboSpan" id="kobo.158.4">Removing instances with high Shapley values but wrong predictions might enhance model accuracy by reducing outliers. </span><span class="koboSpan" id="kobo.158.5">Oversampling instances with high Shapley values and correct predictions can reinforce the model’s understanding of crucial patterns, potentially </span><span class="No-Break"><span class="koboSpan" id="kobo.159.1">improving performance.</span></span></p>
<h2 id="_idParaDest-125"><a id="_idTextAnchor133"/><span class="koboSpan" id="kobo.160.1">Other data-centric techniques</span></h2>
<p><span class="koboSpan" id="kobo.161.1">Besides sampling methods, there </span><a id="_idIndexMarker609"/><span class="koboSpan" id="kobo.162.1">are other</span><a id="_idIndexMarker610"/><span class="koboSpan" id="kobo.163.1"> data-centric techniques that can be used to reduce bias, some of which have been covered in previous chapters, and some we will utilize in the case study. </span><span class="koboSpan" id="kobo.163.2">The three main ones are </span><span class="No-Break"><span class="koboSpan" id="kobo.164.1">described next.</span></span></p>
<h3><span class="koboSpan" id="kobo.165.1">Data cleansing</span></h3>
<p><span class="koboSpan" id="kobo.166.1">This includes </span><a id="_idIndexMarker611"/><span class="koboSpan" id="kobo.167.1">removing missing data, where the inclusion of missing data can lead to unfair outcomes. </span><span class="koboSpan" id="kobo.167.2">These techniques were covered in </span><a href="B19297_05.xhtml#_idTextAnchor070"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.168.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.169.1">, </span><em class="italic"><span class="koboSpan" id="kobo.170.1">Techniques for Data Cleaning</span></em><span class="koboSpan" id="kobo.171.1">, where missing data was classified as “missing not </span><span class="No-Break"><span class="koboSpan" id="kobo.172.1">at random.”</span></span></p>
<h3><span class="koboSpan" id="kobo.173.1">Feature selection</span></h3>
<p><span class="koboSpan" id="kobo.174.1">This includes</span><a id="_idIndexMarker612"/><span class="koboSpan" id="kobo.175.1"> selecting specific features or eliminating features that will reduce bias. </span><span class="koboSpan" id="kobo.175.2">This may mean identifying a variable that is highly associated with a sensitive variable and outcome label, and removing such indirect variables or removing </span><span class="No-Break"><span class="koboSpan" id="kobo.176.1">sensitive variables.</span></span></p>
<h3><span class="koboSpan" id="kobo.177.1">Feature engineering</span></h3>
<p><span class="koboSpan" id="kobo.178.1">Feature engineering</span><a id="_idIndexMarker613"/><span class="koboSpan" id="kobo.179.1"> offers potent tools to mitigate model bias. </span><span class="koboSpan" id="kobo.179.2">Techniques such as re-encoding sensitive attributes, creating interaction terms, or introducing proxy variables enable models to learn without direct access to sensitive information. </span><span class="koboSpan" id="kobo.179.3">Feature selection and dimensionality reduction methods trim irrelevant or redundant features, fostering fairer and more robust models. </span><span class="koboSpan" id="kobo.179.4">Additionally, generating synthetic features or utilizing domain-specific knowledge helps improve models with a better understanding of data, aiding in fairer decision-making while improving overall model performance and reducing bias. </span><span class="koboSpan" id="kobo.179.5">We will create a synthetic variable, “Interest,” in the example to show how the model is biased toward one subgroup </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">over another.</span></span></p>
<p><span class="koboSpan" id="kobo.181.1">Now that we have covered data-centric methods, in the next section, we will describe the problem statement, and walk through examples of how we can identify and reduce bias in </span><span class="No-Break"><span class="koboSpan" id="kobo.182.1">real life.</span></span></p>
<h1 id="_idParaDest-126"><a id="_idTextAnchor134"/><span class="koboSpan" id="kobo.183.1">Case study</span></h1>
<p><span class="koboSpan" id="kobo.184.1">The challenge at </span><a id="_idIndexMarker614"/><span class="koboSpan" id="kobo.185.1">hand centers on uncovering and addressing potential bias within a dataset pertaining to credit card defaults in Taiwan. </span><span class="koboSpan" id="kobo.185.2">Acquired from the UC Irvine Machine Learning Repository (</span><a href="https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients"><span class="koboSpan" id="kobo.186.1">https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients</span></a><span class="koboSpan" id="kobo.187.1">), this dataset comprises information from 30,000 credit card clients over a six-month span, including demographic factors such as gender, marital status, and education. </span><span class="koboSpan" id="kobo.187.2">The key concern is whether these demographic features introduce bias into a decision tree classifier trained on all available features, with a specific focus on gender-related bias. </span><span class="koboSpan" id="kobo.187.3">The overarching objective of this example is to not only identify but also mitigate any biased outcomes through the application of data-centric techniques. </span><span class="koboSpan" id="kobo.187.4">By reevaluating the algorithm’s performance using fairness metrics, the example aims to shed light on the real-world implications of bias in financial decision-making, particularly how these biases can impact individuals based on gender and other demographic factors, potentially leading to unequal treatment in credit assessments and financial opportunities. </span><span class="koboSpan" id="kobo.187.5">Addressing and rectifying such biases is crucial for promoting fairness and equity in </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">financial systems.</span></span></p>
<p><span class="koboSpan" id="kobo.189.1">We will use two key metrics to check the fairness of </span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">the algorithm:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.191.1">Equalized odds difference</span></strong><span class="koboSpan" id="kobo.192.1">: This </span><a id="_idIndexMarker615"/><span class="koboSpan" id="kobo.193.1">metric compares the false negative rate and false positive rate across the sensitive variables, then takes the maximum difference between the false negative rate and false positive rate. </span><span class="koboSpan" id="kobo.193.2">For instance, on the test set, the false positive rate among men and women is 0.3 and 0.2 (difference of 0.1), whereas the false negative rate among men and women is 0.15 and 0.12 (difference of 0.03). </span><span class="koboSpan" id="kobo.193.3">Since the difference is larger on the false positive rate, the equalized odds will </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">be 0.1.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.195.1">Demographic parity ratio</span></strong><span class="koboSpan" id="kobo.196.1">: This metric measures whether the predictions made by a model are independent of a sensitive variable, such as race, gender, or age. </span><span class="koboSpan" id="kobo.196.2">Given this is a ratio, it measures the ratio of a lower selection rate to that of a higher selection rate. </span><span class="koboSpan" id="kobo.196.3">A ratio of 1 means that demographic parity is achieved, whereas below 0.8 usually means that the algorithm is highly biased toward one group of individuals over </span><span class="No-Break"><span class="koboSpan" id="kobo.197.1">the others.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.198.1">The following is a description of the features in </span><span class="No-Break"><span class="koboSpan" id="kobo.199.1">the dataset:</span></span></p>
<ul>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.200.1">Independent variables</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.201.1">:</span></span><ul><li><strong class="source-inline"><span class="koboSpan" id="kobo.202.1">LIMIT_BAL</span></strong><span class="koboSpan" id="kobo.203.1">: Amount of the given credit in NT dollars, including both the individual consumer credit and their family (</span><span class="No-Break"><span class="koboSpan" id="kobo.204.1">supplementary) credit.</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.205.1">Sex</span></strong><span class="koboSpan" id="kobo.206.1">: Gender (1 = male; 2 = </span><span class="No-Break"><span class="koboSpan" id="kobo.207.1">female).</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.208.1">Education X3</span></strong><span class="koboSpan" id="kobo.209.1">: Education (1 = graduate school; 2 = university; 3 = high school; 4 = </span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">others)</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.211.1">Marriage X4</span></strong><span class="koboSpan" id="kobo.212.1">: Marital status (1 = married; 2 = single; 3 = </span><span class="No-Break"><span class="koboSpan" id="kobo.213.1">others)</span></span></li><li><strong class="source-inline"><span class="koboSpan" id="kobo.214.1">Age X5</span></strong><span class="koboSpan" id="kobo.215.1">: Age of the person </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">in years</span></span></li><li><span class="koboSpan" id="kobo.217.1">PAY_0- PAY_5; X6 - X11: History of past payments, which includes the past monthly payment</span><a id="_idIndexMarker616"/><span class="koboSpan" id="kobo.218.1"> records (from April to September 2005), where PAY_0X6 = the repayment status in September, PAY_2; X7 = the repayment status in August 2005; ... </span><span class="koboSpan" id="kobo.218.2">PAY_6; X11 = the repayment status in April 2005. </span><span class="koboSpan" id="kobo.218.3">The measurement scale for the repayment status is -1 = amount paid duly; 1 = payment delay for 1 month; 2 = payment delay for 2 months; ... </span><span class="koboSpan" id="kobo.218.4">; 8 = payment delay for 8 months; 9 = payment delay for 9 months, and </span><span class="No-Break"><span class="koboSpan" id="kobo.219.1">so on.</span></span></li><li><span class="koboSpan" id="kobo.220.1">BILL_AMT1 . </span><span class="koboSpan" id="kobo.220.2">BILL_AMT6; X12-X17: Bill statement amount (in Taiwan dollars). </span><span class="koboSpan" id="kobo.220.3">BILL_AMT1;X12 means the amount on the credit card statement as of September 2005, while BILL_AMT6;X17 means the amount on the credit card statement as of </span><span class="No-Break"><span class="koboSpan" id="kobo.221.1">April 2005.</span></span></li><li><span class="koboSpan" id="kobo.222.1">PAY_AMT1-PAY_AMT6; X18-X23: Amount of payments made based on the previous month's bill statement. </span><span class="koboSpan" id="kobo.222.2">PAY_AMT1;X18 means amount paid in September 2005, while PAY_AMT6;X23 means amount paid on </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">April 2005.</span></span></li></ul></li>
<li><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.224.1">Target variable</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.225.1">:</span></span><ul><li><strong class="source-inline"><span class="koboSpan" id="kobo.226.1">default payment next month</span></strong><span class="koboSpan" id="kobo.227.1">: Whether a person defaulted on the next month’s payment (Yes = 1, No = 0), </span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">in 2005</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.229.1">To import the dataset, you need to install </span><strong class="source-inline"><span class="koboSpan" id="kobo.230.1">pandas</span></strong><span class="koboSpan" id="kobo.231.1">. </span><span class="koboSpan" id="kobo.231.2">We will also use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.232.1">os</span></strong><span class="koboSpan" id="kobo.233.1"> library to navigate the path and store the dataset. </span><span class="koboSpan" id="kobo.233.2">This library is native to Python. </span><span class="koboSpan" id="kobo.233.3">We will call the </span><strong class="source-inline"><span class="koboSpan" id="kobo.234.1">loan_dataset.csv</span></strong><span class="koboSpan" id="kobo.235.1"> file and save it in the same directory, from where we will run </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">this example:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.237.1">
import pandas as pd
import os
FILENAME = "./loan_dataset.csv"
DATA_URL = "http://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls"</span></pre> <p><span class="koboSpan" id="kobo.238.1">The file takes </span><a id="_idIndexMarker617"/><span class="koboSpan" id="kobo.239.1">a couple of seconds to a minute based on internet speed, so when we run this example for the first time, the file will be stored locally. </span><span class="koboSpan" id="kobo.239.2">However, on the subsequent runs, with the help of the </span><strong class="source-inline"><span class="koboSpan" id="kobo.240.1">os</span></strong><span class="koboSpan" id="kobo.241.1"> library, we will check that the file exists, else download it. </span><span class="koboSpan" id="kobo.241.2">We will rename two variables: </span><strong class="source-inline"><span class="koboSpan" id="kobo.242.1">PAY_0</span></strong><span class="koboSpan" id="kobo.243.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.244.1">PAY_1</span></strong><span class="koboSpan" id="kobo.245.1">, and also </span><strong class="source-inline"><span class="koboSpan" id="kobo.246.1">default payment next month</span></strong><span class="koboSpan" id="kobo.247.1"> to </span><strong class="source-inline"><span class="koboSpan" id="kobo.248.1">default</span></strong><span class="koboSpan" id="kobo.249.1">. </span><span class="koboSpan" id="kobo.249.2">We don’t believe the </span><strong class="source-inline"><span class="koboSpan" id="kobo.250.1">ID</span></strong><span class="koboSpan" id="kobo.251.1"> column will be useful for machine learning, hence we will </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">drop it:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.253.1">
if not os.path.exists(FILENAME):
    data = (
        pd.read_excel(io=DATA_URL, header=1)
        .drop(columns=["ID"])
        .rename(
            columns={"PAY_0": "PAY_1", "default payment next month": "default"}
        )
    )
    data.to_csv(FILENAME, sep=",", encoding="utf-8", index=False)</span></pre> <p><span class="koboSpan" id="kobo.254.1">Now, we load the file from the local directory into a DataFrame called </span><strong class="source-inline"><span class="koboSpan" id="kobo.255.1">dataset</span></strong><span class="koboSpan" id="kobo.256.1">. </span><span class="koboSpan" id="kobo.256.2">There are 30,000 rows and 24 columns including the </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">target variable:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.258.1">
dataset = pd.read_csv(FILENAME, sep=",", encoding="utf-8")
dataset.shape
(30000, 24)</span></pre> <p><span class="koboSpan" id="kobo.259.1">Next, we run the </span><strong class="source-inline"><span class="koboSpan" id="kobo.260.1">dataset.info()</span></strong><span class="koboSpan" id="kobo.261.1"> method to check whether there are any missing values</span><a id="_idIndexMarker618"/><span class="koboSpan" id="kobo.262.1"> or wrongly </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">encoded columns:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer091">
<span class="koboSpan" id="kobo.264.1"><img alt="Figure 8.1 – Output of the dataset.info() method" src="image/B19297_08_1.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.265.1">Figure 8.1 – Output of the dataset.info() method</span></p>
<p><span class="koboSpan" id="kobo.266.1">We don’t have any missing data; however, three categorical columns (</span><strong class="source-inline"><span class="koboSpan" id="kobo.267.1">SEX</span></strong><span class="koboSpan" id="kobo.268.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.269.1">EDUCATION</span></strong><span class="koboSpan" id="kobo.270.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.271.1">MARRIAGE</span></strong><span class="koboSpan" id="kobo.272.1">) have integer data types, which we may have to convert to strings. </span><span class="koboSpan" id="kobo.272.2">Since values in </span><strong class="source-inline"><span class="koboSpan" id="kobo.273.1">SEX</span></strong><span class="koboSpan" id="kobo.274.1"> might be ordinal, we will first remap them to </span><strong class="source-inline"><span class="koboSpan" id="kobo.275.1">1</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.276.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.277.1">0</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.278.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.279.1">
cat_colums = ['EDUCATION', 'MARRIAGE']
for col in cat_colums:
    dataset[col] = dataset[col].astype("category")
dataset['SEX'] = dataset['SEX'].map({1: 1, 2:0})</span></pre> <p><span class="koboSpan" id="kobo.280.1">If we rerun </span><strong class="source-inline"><span class="koboSpan" id="kobo.281.1">dataset.info()</span></strong><span class="koboSpan" id="kobo.282.1">, we will see that the data type for the three columns is now </span><strong class="source-inline"><span class="koboSpan" id="kobo.283.1">category</span></strong><span class="koboSpan" id="kobo.284.1">; we can now one-hot encode them. </span><span class="koboSpan" id="kobo.284.2">We exclude </span><strong class="source-inline"><span class="koboSpan" id="kobo.285.1">SEX</span></strong><span class="koboSpan" id="kobo.286.1"> from one-hot encoding since a person is either a male or female (in this dataset) and that information can be captured in one column. </span><span class="koboSpan" id="kobo.286.2">We will also extract </span><strong class="source-inline"><span class="koboSpan" id="kobo.287.1">SEX</span></strong><span class="koboSpan" id="kobo.288.1"> and store it in another variable, </span><strong class="source-inline"><span class="koboSpan" id="kobo.289.1">A</span></strong><span class="koboSpan" id="kobo.290.1">, and separate the target variable and independent features. </span><span class="koboSpan" id="kobo.290.2">Next, we create a </span><a id="_idIndexMarker619"/><span class="koboSpan" id="kobo.291.1">mapping for values in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.292.1">SEX</span></strong><span class="koboSpan" id="kobo.293.1"> feature to be used for analysis and visualization, to help interpret the results, so </span><strong class="source-inline"><span class="koboSpan" id="kobo.294.1">1</span></strong><span class="koboSpan" id="kobo.295.1"> will be mapped to </span><strong class="source-inline"><span class="koboSpan" id="kobo.296.1">male</span></strong><span class="koboSpan" id="kobo.297.1"> values and </span><strong class="source-inline"><span class="koboSpan" id="kobo.298.1">0</span></strong><span class="koboSpan" id="kobo.299.1"> will be mapped to </span><strong class="source-inline"><span class="koboSpan" id="kobo.300.1">female</span></strong><span class="koboSpan" id="kobo.301.1"> values. </span><span class="koboSpan" id="kobo.301.2">We store this mapping in the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.302.1">A_str</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.303.1"> variable:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.304.1">
Y, A = dataset.loc[:, "default"], dataset.loc[:, "SEX"]
X = pd.get_dummies(dataset.drop(columns=["default","SEX"]))
X["SEX"] = A.copy()
A_str = A.map({1: "male", 0: "female"})</span></pre> <p><span class="koboSpan" id="kobo.305.1">Next, let’s load all the </span><span class="No-Break"><span class="koboSpan" id="kobo.306.1">required libraries.</span></span></p>
<h2 id="_idParaDest-127"><a id="_idTextAnchor135"/><span class="koboSpan" id="kobo.307.1">Loading the libraries</span></h2>
<p><span class="koboSpan" id="kobo.308.1">To run </span><a id="_idIndexMarker620"/><span class="koboSpan" id="kobo.309.1">the example, you will need the following </span><span class="No-Break"><span class="koboSpan" id="kobo.310.1">additional libraries:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.311.1">sklearn</span></strong><span class="koboSpan" id="kobo.312.1"> (scikit-learn) for data preprocessing and fitting </span><span class="No-Break"><span class="koboSpan" id="kobo.313.1">the models</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.314.1">numpy</span></strong><span class="koboSpan" id="kobo.315.1"> to calculate some metrics and do some </span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">data wrangling</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.317.1">imblearn</span></strong><span class="koboSpan" id="kobo.318.1"> for over </span><span class="No-Break"><span class="koboSpan" id="kobo.319.1">and undersampling</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.320.1">fairlearn</span></strong><span class="koboSpan" id="kobo.321.1"> to calculate bias and </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">fairness scores</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.323.1">shap</span></strong><span class="koboSpan" id="kobo.324.1"> to visualize the interpretations of </span><span class="No-Break"><span class="koboSpan" id="kobo.325.1">the model</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.326.1">We load all the libraries at </span><span class="No-Break"><span class="koboSpan" id="kobo.327.1">the start:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.328.1">
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.combine import SMOTEENN, SMOTETomek
from sklearn.ensemble import IsolationForest
from imblearn.pipeline import make_pipeline
from imblearn.under_sampling import AllKNN, InstanceHardnessThreshold, RepeatedEditedNearestNeighbours, TomekLinks, EditedNearestNeighbours
from sklearn.metrics import balanced_accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.pipeline import Pipeline
from fairlearn.metrics import MetricFrame, equalized_odds_difference, demographic_parity_ratio
import numpy as np
import shap</span></pre> <p><span class="koboSpan" id="kobo.329.1">Next, we </span><a id="_idIndexMarker621"/><span class="koboSpan" id="kobo.330.1">split the dataset into </span><strong class="source-inline"><span class="koboSpan" id="kobo.331.1">train</span></strong><span class="koboSpan" id="kobo.332.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.333.1">test</span></strong><span class="koboSpan" id="kobo.334.1">, using </span><strong class="source-inline"><span class="koboSpan" id="kobo.335.1">train_test_split</span></strong><span class="koboSpan" id="kobo.336.1">, and assign 20% of the data to test. </span><span class="koboSpan" id="kobo.336.2">We also split </span><strong class="source-inline"><span class="koboSpan" id="kobo.337.1">A_str</span></strong><span class="koboSpan" id="kobo.338.1"> into </span><strong class="source-inline"><span class="koboSpan" id="kobo.339.1">A_train</span></strong><span class="koboSpan" id="kobo.340.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.341.1">A_test</span></strong><span class="koboSpan" id="kobo.342.1">, so we can calculate fairness scores on </span><span class="No-Break"><span class="koboSpan" id="kobo.343.1">test data:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.344.1">
X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(X,
                 Y,
                 A_str,
                 test_size=0.2,
                 stratify=Y,
                 random_state=42)</span></pre> <p><span class="koboSpan" id="kobo.345.1">Next, we create the decision tree classifier pipeline and train the algorithm with the </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">sensitive features:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.347.1">
d_tree_params = {
    "min_samples_leaf": 10,
    "random_state": 42
}
estimator = Pipeline(steps=[
    ("classifier", DecisionTreeClassifier(**d_tree_params))
])
estimator.fit(X_train, y_train)</span></pre> <p><span class="koboSpan" id="kobo.348.1">Next, we </span><a id="_idIndexMarker622"/><span class="koboSpan" id="kobo.349.1">calculate the ROC score and extract the predictions. </span><span class="koboSpan" id="kobo.349.2">We also visualize the </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">confusion matrix:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.351.1">
y_pred_proba = estimator.predict_proba(X_test)[:, 1]
y_pred = estimator.predict(X_test)
print(f"Roc score is : {roc_auc_score(y_test, y_pred_proba)}")
cm = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=estimator.classes_)
cm.plot()
Roc score is : 0.6875636482794665</span></pre> <p><span class="koboSpan" id="kobo.352.1">The code generates the following </span><span class="No-Break"><span class="koboSpan" id="kobo.353.1">confusion matrix:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer092">
<span class="koboSpan" id="kobo.354.1"><img alt="Figure 8.2 – Output confusion matrix" src="image/B19297_08_2.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.355.1">Figure 8.2 – Output confusion matrix</span></p>
<p><span class="koboSpan" id="kobo.356.1">In order to </span><a id="_idIndexMarker623"/><span class="koboSpan" id="kobo.357.1">check whether the algorithm is fair or not, we will first calculate false positive and false negative rates, and then compare those across male and female cohorts on the test dataset to see whether there are big differences between the </span><span class="No-Break"><span class="koboSpan" id="kobo.358.1">two cohorts.</span></span></p>
<p><span class="koboSpan" id="kobo.359.1">In the following code block, we have created two functions to calculate a false positive rate and a false negative rate. </span><span class="koboSpan" id="kobo.359.2">We have further created a dictionary of fairness metrics, in which we use the false positive rate and false negative rate, alongside a balanced accuracy metric from scikit-learn. </span><span class="koboSpan" id="kobo.359.3">We have then created a list of fairness metrics and stored them in a variable for </span><span class="No-Break"><span class="koboSpan" id="kobo.360.1">easy access:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.361.1">
def false_positive_rate(y_true, y_pred):
    """Compute the standard error for the false positive rate estimate."""
</span><span class="koboSpan" id="kobo.361.2">    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    return fp/(fp+tn)
def false_negative_rate(y_true, y_pred):
    """Compute the standard error for the false positive rate estimate."""
</span><span class="koboSpan" id="kobo.361.3">    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    return fn/(tp+fn)
fairness_metrics = {
    "balanced_accuracy": balanced_accuracy_score,
    "false_positive_rate": false_positive_rate,
    "false_negative_rate": false_negative_rate,
}
metrics_to_report = list(fairness_metrics.keys())</span></pre> <p><span class="koboSpan" id="kobo.362.1">We have also </span><a id="_idIndexMarker624"/><span class="koboSpan" id="kobo.363.1">created a function to report the differences between male and female cohorts on the fairness metrics. </span><span class="koboSpan" id="kobo.363.2">We first create a DataFrame called </span><strong class="source-inline"><span class="koboSpan" id="kobo.364.1">metricframe</span></strong><span class="koboSpan" id="kobo.365.1"> using the convenience function from </span><strong class="source-inline"><span class="koboSpan" id="kobo.366.1">fairlearn</span></strong><span class="koboSpan" id="kobo.367.1"> called </span><strong class="source-inline"><span class="koboSpan" id="kobo.368.1">MetricFrame</span></strong><span class="koboSpan" id="kobo.369.1">. </span><span class="koboSpan" id="kobo.369.2">It takes in true labels, predictions, and sensitive feature values, along with a dictionary of metrics to report on. </span><span class="koboSpan" id="kobo.369.3">We then leverage the </span><strong class="source-inline"><span class="koboSpan" id="kobo.370.1">.by_group</span></strong><span class="koboSpan" id="kobo.371.1"> property to report on fairness metrics for each cohort. </span><span class="koboSpan" id="kobo.371.2">Within the function, we also report on </span><strong class="source-inline"><span class="koboSpan" id="kobo.372.1">equalised_odds_difference</span></strong><span class="koboSpan" id="kobo.373.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.374.1">demographic_parity_ratio</span></strong><span class="koboSpan" id="kobo.375.1"> from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.376.1">fairlearn</span></strong><span class="koboSpan" id="kobo.377.1"> library to understand the overall fairness of </span><span class="No-Break"><span class="koboSpan" id="kobo.378.1">the model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.379.1">
def calculate_fairness_metrics(y_test, y_pred, A_test, metrics=fairness_metrics):
    """Function to calculate fairness metrics"""
    metricframe = MetricFrame(
        metrics=fairness_metrics,
        y_true=y_test,
        y_pred=y_pred,
        sensitive_features=A_test,
    )
    print(metricframe.by_group[metrics_to_report])
    print("\n *diff*")
    print(metricframe.difference()[metrics_to_report])
    print("\n *final_metrics*")
    print(metricframe.overall[metrics_to_report])
    equalized_odds = equalized_odds_difference(
        y_test, y_pred, sensitive_features=A_test
    )
    print("\n *equalized_odds*")
    print(equalized_odds)
    dpr= demographic_parity_ratio(y_test, y_pred, sensitive_features=A_test)
    print("\n *demographic_parity_ratio*")
    print(dpr)</span></pre> <p><span class="koboSpan" id="kobo.380.1">We now </span><a id="_idIndexMarker625"/><span class="koboSpan" id="kobo.381.1">run the function and calculate the fairness scores. </span><span class="koboSpan" id="kobo.381.2">It is evident that the model is quite similar in male and female cohorts since false positive rates and false negative rates are similar among the cohorts. </span><span class="koboSpan" id="kobo.381.3">Since the difference in the false positive rate is larger than the false negative rate, the equalized odds difference is the same as the difference between the false positive rate of the two groups. </span><span class="koboSpan" id="kobo.381.4">We can also see that the demographic parity ratio is above 0.8, which means that both cohorts are quite likely to get selected for a</span><a id="_idIndexMarker626"/> <span class="No-Break"><span class="koboSpan" id="kobo.382.1">positive outcome:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.383.1">
calculate_fairness_metrics_unmitigated = calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <p><span class="koboSpan" id="kobo.384.1">This will display the </span><span class="No-Break"><span class="koboSpan" id="kobo.385.1">following output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer093">
<span class="koboSpan" id="kobo.386.1"><img alt="Figure 8.3 – Fairness scores" src="image/B19297_08_3.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.387.1">Figure 8.3 – Fairness scores</span></p>
<p><span class="koboSpan" id="kobo.388.1">To illustrate bias in the dataset, we may need to generate a synthetic variable that correlates with a real-world scenario where, based on history, a cohort is treated more unfairly. </span><span class="koboSpan" id="kobo.388.2">First, we compare the default rate across males and females in the training dataset. </span><span class="koboSpan" id="kobo.388.3">We then add the </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">synthetic noise:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.390.1">
for val in dataset.SEX.unique():
    print(f"{('male' if val == 1 else 'female')} default rate is: ")
    print(dataset[dataset.SEX == val]['default'].mean())
    print()
female default rate is:
0.20776280918727916
male default rate is: 0.2416722745625841</span></pre> <p><span class="koboSpan" id="kobo.391.1">Given that the male default is higher than the female, we can replicate a biased scenario where applicants with lower default rates will have lower interest rates, but applicants with higher default rates will have higher interest rates imposed by the bank. </span><span class="koboSpan" id="kobo.391.2">Let’s assume the bank managers believe males are more likely to default, and instead of generalizing the scenario, the bank decides to charge higher interest rates </span><span class="No-Break"><span class="koboSpan" id="kobo.392.1">to males.</span></span></p>
<p><span class="koboSpan" id="kobo.393.1">To mimic </span><a id="_idIndexMarker627"/><span class="koboSpan" id="kobo.394.1">this scenario, we will introduce a new feature, </span><strong class="source-inline"><span class="koboSpan" id="kobo.395.1">Interest_rate</span></strong><span class="koboSpan" id="kobo.396.1">, following a Gaussian distribution. </span><span class="koboSpan" id="kobo.396.2">The mean will be 0 where someone hasn’t defaulted, but will be 2 times 1 where someone has defaulted. </span><span class="koboSpan" id="kobo.396.3">We also set the standard deviation to 2 for males and 1 </span><span class="No-Break"><span class="koboSpan" id="kobo.397.1">for females.</span></span></p>
<p><span class="koboSpan" id="kobo.398.1">To generate the synthetic Gaussian distribution, we use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.399.1">numpy.random.normal</span></strong><span class="koboSpan" id="kobo.400.1"> method, with a seed of </span><strong class="source-inline"><span class="koboSpan" id="kobo.401.1">42</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.402.1">for reproducibility:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.403.1">
np.random.seed(42)
X.loc[:, 'Interest_rate'] = np.random.normal(loc=2*Y, scale=A.map({1:2, 0:1}))
print("Maximum interest rate for men who defaulted vs women who defaulted")
print(X[(X.SEX == 1) &amp; (Y == 1)]["Interest_rate"].max(), X[(X.SEX == 0) &amp; (Y == 1)]["Interest_rate"].max())
print()
print("Maximum interest rate for men who did not default vs women that did not default")
print(X[(X.SEX == 1) &amp; (Y == 0)]["Interest_rate"].max(), X[(X.SEX == 0) &amp; (Y == 0)]["Interest_rate"].max())
Maximum interest rate for men who defaulted vs women who defaulted
9.852475412872653 6.479084251025757
Maximum interest rate for men who did not default vs women that did not default
6.857820956016427 3.852731490654721</span></pre> <p><span class="koboSpan" id="kobo.404.1">Now that we </span><a id="_idIndexMarker628"/><span class="koboSpan" id="kobo.405.1">have added the noise, we retrain the algorithm with the interest variable and recalculate the fairness metrics. </span><span class="koboSpan" id="kobo.405.2">We first split the data, then retrain and recalculate the fairness metrics. </span><span class="koboSpan" id="kobo.405.3">We resplit the data into </span><strong class="source-inline"><span class="koboSpan" id="kobo.406.1">train</span></strong><span class="koboSpan" id="kobo.407.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.408.1">test</span></strong><span class="koboSpan" id="kobo.409.1">, as shown previously, and retrain the algorithm. </span><span class="koboSpan" id="kobo.409.2">Once retrained, we calculate </span><span class="No-Break"><span class="koboSpan" id="kobo.410.1">the impact.</span></span></p>
<p><span class="koboSpan" id="kobo.411.1">We can see, in the following code, that by adding the synthetic interest variable, we have improved the </span><span class="No-Break"><span class="koboSpan" id="kobo.412.1">ROC metric:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.413.1">
y_pred_proba = estimator.predict_proba(X_test)[:, 1]
y_pred = estimator.predict(X_test)
roc_auc_score(y_test, y_pred_proba)
0.8465698909107798</span></pre> <p><span class="koboSpan" id="kobo.414.1">It is clear from the following output that we now have a more biased algorithm, based on equalized odds. </span><span class="koboSpan" id="kobo.414.2">The false negative rate is quite high in males, which means that more males who are unlikely to pay back to the bank are likely to be given a loan, and if this model was productionized, this could result in </span><span class="No-Break"><span class="koboSpan" id="kobo.415.1">unfair outcomes:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.416.1">
calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <p><span class="koboSpan" id="kobo.417.1">This will print the </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">following information:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer094">
<span class="koboSpan" id="kobo.419.1"><img alt="Figure 8.4 – Fairness scores" src="image/B19297_08_4.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.420.1">Figure 8.4 – Fairness scores</span></p>
<p><span class="koboSpan" id="kobo.421.1">To reduce the</span><a id="_idIndexMarker629"/><span class="koboSpan" id="kobo.422.1"> bias, we will apply the first data-centric debiasing technique under the feature selection by removing the sensitive variable from the algorithm. </span><span class="koboSpan" id="kobo.422.2">This can be done by retraining the algorithm without the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.423.1">SEX</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.424.1"> variable.</span></span></p>
<p><span class="koboSpan" id="kobo.425.1">Given that the dataset is biased toward one gender due to a higher variation in interest rates, it is recommended in the real world that data engineers and data scientists work with domain experts and data producers to reduce this bias in the dataset. </span><span class="koboSpan" id="kobo.425.2">For instance, instead of using </span><strong class="source-inline"><span class="koboSpan" id="kobo.426.1">SEX</span></strong><span class="koboSpan" id="kobo.427.1"> to determine the interest rate, other features could be used, such as payment history, credit history, and income. </span><span class="koboSpan" id="kobo.427.2">In the training step, we can drop the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.428.1">SEX</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.429.1"> variable:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.430.1">
estimator.fit(X_train.drop(['SEX'], axis=1), y_train)
Pipeline(steps=[('classifier',
                 DecisionTreeClassifier(min_samples_leaf=10, random_state=42))])</span></pre> <p><span class="koboSpan" id="kobo.431.1">From the following output, we can see that by removing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.432.1">SEX</span></strong><span class="koboSpan" id="kobo.433.1"> variable, the ROC score has dropped from 0.846 </span><span class="No-Break"><span class="koboSpan" id="kobo.434.1">to 0.839:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.435.1">
estimator.fit(X_train.drop(['SEX'], axis=1), y_train)
y_pred_proba = estimator.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]
y_pred = estimator.predict(X_test.drop(['SEX'], axis=1))
roc_auc_score(y_test, y_pred_proba)
0.8392395442658211</span></pre> <p><span class="koboSpan" id="kobo.436.1">Looking at the </span><a id="_idIndexMarker630"/><span class="koboSpan" id="kobo.437.1">following fairness metrics, it is obvious that when the outcome is biased based on the cohort of data, removing the variable from the training can debias the algorithm. </span><span class="koboSpan" id="kobo.437.2">The false negative rate in </span><strong class="source-inline"><span class="koboSpan" id="kobo.438.1">male</span></strong><span class="koboSpan" id="kobo.439.1"> has decreased, whereas, in </span><strong class="source-inline"><span class="koboSpan" id="kobo.440.1">female</span></strong><span class="koboSpan" id="kobo.441.1">, it has increased; however, the algorithm is more fair compared to when the </span><strong class="source-inline"><span class="koboSpan" id="kobo.442.1">SEX</span></strong><span class="koboSpan" id="kobo.443.1"> variable was used. </span><span class="koboSpan" id="kobo.443.2">The equalized odds have dropped from 0.18 to 0.07, but the demographic parity ratio has reduced, which means one group has more chance of getting a loan than </span><span class="No-Break"><span class="koboSpan" id="kobo.444.1">the other:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.445.1">
calculate_fairness_metrics_mitigated_v1 = calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <p><span class="koboSpan" id="kobo.446.1">The output is </span><span class="No-Break"><span class="koboSpan" id="kobo.447.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer095">
<span class="koboSpan" id="kobo.448.1"><img alt="Figure 8.5 – Fairness metrics" src="image/B19297_08_5.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.449.1">Figure 8.5 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.450.1">Next, we will show you how to apply </span><a id="_idIndexMarker631"/><span class="koboSpan" id="kobo.451.1">undersampling techniques to ensure the outcome variable </span><span class="No-Break"><span class="koboSpan" id="kobo.452.1">is balanced.</span></span></p>
<h2 id="_idParaDest-128"><a id="_idTextAnchor136"/><span class="koboSpan" id="kobo.453.1">AllKNN undersampling method</span></h2>
<p><span class="koboSpan" id="kobo.454.1">We will start</span><a id="_idIndexMarker632"/><span class="koboSpan" id="kobo.455.1"> with the AllKNN algorithm from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.456.1">imblearn</span></strong><span class="koboSpan" id="kobo.457.1"> package, and then try the instant hardness algorithm. </span><span class="koboSpan" id="kobo.457.2">Since the algorithms use KNN under the hood, which is a distance-based measure, we need to ensure that we scale the features using the scikit-learn </span><strong class="source-inline"><span class="koboSpan" id="kobo.458.1">StandardScaler</span></strong><span class="koboSpan" id="kobo.459.1"> method. </span><span class="koboSpan" id="kobo.459.2">We will first scale the variables, then run the sampling algorithm, and then train the decision tree. </span><span class="koboSpan" id="kobo.459.3">We will run the algorithm with 5 k cross-validation, and ensure the function returns the model trained. </span><span class="koboSpan" id="kobo.459.4">Cross-validation will be scored on </span><strong class="source-inline"><span class="koboSpan" id="kobo.460.1">roc_auc</span></strong><span class="koboSpan" id="kobo.461.1"> and </span><span class="No-Break"><span class="koboSpan" id="kobo.462.1">balanced accuracy.</span></span></p>
<p><span class="koboSpan" id="kobo.463.1">We will first try an undersampling technique, </span><strong class="source-inline"><span class="koboSpan" id="kobo.464.1">AllKNN</span></strong><span class="koboSpan" id="kobo.465.1">, from </span><strong class="source-inline"><span class="koboSpan" id="kobo.466.1">imblearn</span></strong><span class="koboSpan" id="kobo.467.1">. </span><span class="koboSpan" id="kobo.467.2">This algorithm does not aim at balancing majority and minority classes; however, it removes instances that are harder to classify from the majority class. </span><span class="koboSpan" id="kobo.467.3">It does that iteratively where, first, the model is trained on the entire dataset. </span><span class="koboSpan" id="kobo.467.4">Then, in the prediction step of the majority class, if a disagreement occurs between any of the neighbors about the predicted outcome, the data point is removed from the majority class. </span><span class="koboSpan" id="kobo.467.5">In the first iteration, a 1-KNN model is trained and some samples are removed, and then in the next iteration, a 2-KNN model is trained, and in the following iteration, a 3-KNN model is trained. </span><span class="koboSpan" id="kobo.467.6">Usually, the algorithm (by default) will </span><a id="_idIndexMarker633"/><span class="koboSpan" id="kobo.468.1">end at the 3-KNN iteration; however, the practitioner can choose more iterations, and the algorithm will not stop until the number of samples between the majority and minority class becomes the same or a maximum number of iterations is reached – whichever </span><span class="No-Break"><span class="koboSpan" id="kobo.469.1">happens earlier.</span></span></p>
<p><span class="koboSpan" id="kobo.470.1">Let’s first define the scaler and </span><span class="No-Break"><span class="koboSpan" id="kobo.471.1">sampler method:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.472.1">
scaler = StandardScaler()
sampler_method = AllKNN(n_jobs=-1)</span></pre> <p><span class="koboSpan" id="kobo.473.1">Next, we create a pipeline object and pass the scaler, sampler, and estimator to </span><span class="No-Break"><span class="koboSpan" id="kobo.474.1">the pipeline:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.475.1">
sampler_pipeline = make_pipeline(
    scaler,
    sampler_method,
    estimator)</span></pre> <p><span class="koboSpan" id="kobo.476.1">Then we pass the training data and run the cross-validation. </span><span class="koboSpan" id="kobo.476.2">We set the cross-validation method to return the estimator (pipeline) by setting </span><strong class="source-inline"><span class="koboSpan" id="kobo.477.1">return_estimator=True</span></strong><span class="koboSpan" id="kobo.478.1">, so that we can use it to make predictions on the </span><span class="No-Break"><span class="koboSpan" id="kobo.479.1">test data:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.480.1">
cv_results = cross_validate(sampler_pipeline,
                            X_train.drop(['SEX'], axis=1),
                            y_train, scoring=['roc_auc','balanced_accuracy'],
                            return_estimator=True)</span></pre> <p><span class="koboSpan" id="kobo.481.1">Next, we print the mean and standard deviation of ROC and balanced accuracy from the cross-validation step, returned from prediction results in each step, where at each step, four folds were used on training and the prediction was made on the </span><span class="No-Break"><span class="koboSpan" id="kobo.482.1">fifth fold:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.483.1">
print(f"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}")
print(f"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}")
Validation roc auc : 0.853 +/- 0.006
Validation balanced acc : 0.802 +/- 0.005</span></pre> <p><span class="koboSpan" id="kobo.484.1">We can see that by removing</span><a id="_idIndexMarker634"/><span class="koboSpan" id="kobo.485.1"> hard examples using the undersampling technique, </span><strong class="source-inline"><span class="koboSpan" id="kobo.486.1">roc_auc</span></strong><span class="koboSpan" id="kobo.487.1"> on </span><strong class="source-inline"><span class="koboSpan" id="kobo.488.1">test</span></strong><span class="koboSpan" id="kobo.489.1"> data bumped from 0.839 in the previous step </span><span class="No-Break"><span class="koboSpan" id="kobo.490.1">to 0.85:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.491.1">
model = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)
y_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]
y_pred = model.predict(X_test.drop(['SEX'],axis=1))
roc_auc_score(y_test, y_pred_proba)
0.8537904984477683</span></pre> <p><span class="koboSpan" id="kobo.492.1">Next, we calculate the fairness metrics. </span><span class="koboSpan" id="kobo.492.2">Although the false negative rate has decreased for both males and females, the false positive rate has increased, and the equalized odds difference has also increased from the previous step. </span><span class="koboSpan" id="kobo.492.3">This might be because cases with male samples that were difficult to classify have </span><span class="No-Break"><span class="koboSpan" id="kobo.493.1">been removed:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.494.1">
calculate_fairness_metrics_mitigated_v2 = calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <div>
<div class="IMG---Figure" id="_idContainer096">
<span class="koboSpan" id="kobo.495.1"><img alt="Figure 8.6 – Fairness metrics" src="image/B19297_08_6.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.496.1">Figure 8.6 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.497.1">We will now explore </span><a id="_idIndexMarker635"/><span class="koboSpan" id="kobo.498.1">the impact on the fairness metrics by introducing </span><span class="No-Break"><span class="koboSpan" id="kobo.499.1">hard cases.</span></span></p>
<h2 id="_idParaDest-129"><a id="_idTextAnchor137"/><span class="koboSpan" id="kobo.500.1">Instance hardness undersampling method</span></h2>
<p><span class="koboSpan" id="kobo.501.1">As the</span><a id="_idIndexMarker636"/><span class="koboSpan" id="kobo.502.1"> name suggests, the instance hardness method focuses on samples that are harder to classify, which are usually at the boundary or overlap with other classes. </span><span class="koboSpan" id="kobo.502.2">Usually, this depends on the algorithm used (as some algorithms are better at some hard cases than others) and the level of overlap between the classes. </span><span class="koboSpan" id="kobo.502.3">For such samples, the learning algorithm will usually show the low probability prediction on the hard cases, which means the lower the probability, the higher the instance hardness. </span><span class="koboSpan" id="kobo.502.4">Under the hood, the method has the capability to retain the right number of samples, based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.503.1">class imbalance.</span></span></p>
<p><span class="koboSpan" id="kobo.504.1">In the first step, we will define the algorithm, and the algorithm will be passed on to the instance hardness step. </span><span class="koboSpan" id="kobo.504.2">We will then define the instance hardness undersampling method, with </span><span class="No-Break"><span class="koboSpan" id="kobo.505.1">three-fold cross-validation.</span></span></p>
<p><span class="koboSpan" id="kobo.506.1">Next, we create the decision tree estimator. </span><span class="koboSpan" id="kobo.506.2">Finally, we combine the steps in the pipeline with scaling the dataset, then undersampling the data, and finally, training the model. </span><span class="koboSpan" id="kobo.506.3">When</span><a id="_idIndexMarker637"/><span class="koboSpan" id="kobo.507.1"> the pipeline is defined, we run the cross-validation similar to the </span><span class="No-Break"><span class="koboSpan" id="kobo.508.1">previous pipeline:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.509.1">
d_tree_params = {
    "min_samples_leaf": 10,
    "random_state": 42
}
d_tree = DecisionTreeClassifier(**d_tree_params)
sampler_method = InstanceHardnessThreshold(
    estimator=d_tree,
    sampling_strategy='auto',
    random_state=42,
    n_jobs=-1,
    cv=3)
estimator = Pipeline(steps=[
    ("classifier", DecisionTreeClassifier(**d_tree_params))
])
sampler_pipeline = make_pipeline(
    scaler,
    sampler_method,
    estimator)
cv_results = cross_validate(sampler_pipeline, X_train.drop(['SEX'], axis=1), y_train, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)</span></pre> <p><span class="koboSpan" id="kobo.510.1">Both </span><strong class="source-inline"><span class="koboSpan" id="kobo.511.1">AllKNN</span></strong><span class="koboSpan" id="kobo.512.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.513.1">InstanceHardness</span></strong><span class="koboSpan" id="kobo.514.1"> returned similar </span><span class="No-Break"><span class="koboSpan" id="kobo.515.1">cross-validation results:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.516.1">
print(f"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}")
print(f"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}")
Validation roc auc : 0.853 +/- 0.005
Validation balanced acc : 0.807 +/- 0.007</span></pre> <p><span class="koboSpan" id="kobo.517.1">The ROC slightly </span><a id="_idIndexMarker638"/><span class="koboSpan" id="kobo.518.1">bumped from 0.85 to 0.854 on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.519.1">test</span></strong><span class="koboSpan" id="kobo.520.1"> data when using the instance </span><span class="No-Break"><span class="koboSpan" id="kobo.521.1">hardness method:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.522.1">
model = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)
y_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]
y_pred = model.predict(X_test.drop(['SEX'],axis=1))
roc_auc_score(y_test, y_pred_proba)
0.8549627959428299</span></pre> <p><span class="koboSpan" id="kobo.523.1">The fairness metrics are quite similar to the previous undersampling technique, and probably due to similar reasons, where, by removing difficult cases, the model is unable to deal with predicting difficult </span><strong class="source-inline"><span class="koboSpan" id="kobo.524.1">male</span></strong><span class="koboSpan" id="kobo.525.1"> cases. </span><span class="koboSpan" id="kobo.525.2">However, in both undersampling methods, the equalized odds have increased, compared to the feature selection step. </span><span class="koboSpan" id="kobo.525.3">Also, the demographic parity ratio is still under 0.8, which means one subclass of gender is more likely to be selected over another when </span><span class="No-Break"><span class="koboSpan" id="kobo.526.1">predicting </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.527.1">default</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.529.1">
calculate_fairness_metrics_mitigated_v3 = calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <div>
<div class="IMG---Figure" id="_idContainer097">
<span class="koboSpan" id="kobo.530.1"><img alt="Figure 8.7 – Fairness metrics" src="image/B19297_08_7.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.531.1">Figure 8.7 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.532.1">Next, let’s look at </span><a id="_idIndexMarker639"/><span class="No-Break"><span class="koboSpan" id="kobo.533.1">oversampling methods.</span></span></p>
<h2 id="_idParaDest-130"><a id="_idTextAnchor138"/><span class="koboSpan" id="kobo.534.1">Oversampling methods</span></h2>
<p><span class="koboSpan" id="kobo.535.1">Another</span><a id="_idIndexMarker640"/><span class="koboSpan" id="kobo.536.1"> way of improving </span><a id="_idIndexMarker641"/><span class="koboSpan" id="kobo.537.1">model performance and fairness metrics is by introducing additional examples. </span><span class="koboSpan" id="kobo.537.2">The next two oversampling techniques, </span><strong class="source-inline"><span class="koboSpan" id="kobo.538.1">SMOTE</span></strong><span class="koboSpan" id="kobo.539.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.540.1">ADASYN</span></strong><span class="koboSpan" id="kobo.541.1">, were introduced in </span><a href="B19297_07.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.542.1">Chapter 7</span></em></span></a><span class="koboSpan" id="kobo.543.1">, </span><em class="italic"><span class="koboSpan" id="kobo.544.1">Using Synthetic Data in Data-Centric Machine Learning</span></em><span class="koboSpan" id="kobo.545.1">, hence we will not cover the details behind the algorithm. </span><span class="koboSpan" id="kobo.545.2">We will use these techniques in the context of improving fairness metrics by adding additional examples, in the hope that the model is able to learn better with additional </span><span class="No-Break"><span class="koboSpan" id="kobo.546.1">data points.</span></span></p>
<p><span class="koboSpan" id="kobo.547.1">For each of the methods, we will first scale the dataset, add additional minority class examples, and then</span><a id="_idIndexMarker642"/><span class="koboSpan" id="kobo.548.1"> train the model. </span><span class="koboSpan" id="kobo.548.2">We will print the cross-validation scores and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.549.1">test</span></strong><span class="koboSpan" id="kobo.550.1"> ROC score, as well as </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1">fairness metrics.</span></span></p>
<h3><span class="koboSpan" id="kobo.552.1">SMOTE</span></h3>
<p><span class="koboSpan" id="kobo.553.1">Given that </span><a id="_idIndexMarker643"/><span class="koboSpan" id="kobo.554.1">we used this algorithm in </span><a href="B19297_07.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.555.1">Chapter 7</span></em></span></a><span class="koboSpan" id="kobo.556.1">, </span><em class="italic"><span class="koboSpan" id="kobo.557.1">Using Synthetic Data in Data-Centric Machine Learning</span></em><span class="koboSpan" id="kobo.558.1">, we will dive straight into </span><span class="No-Break"><span class="koboSpan" id="kobo.559.1">the code:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.560.1">
estimator = Pipeline(steps=[
    ("classifier", DecisionTreeClassifier(**d_tree_params))
])
sampler_method = SMOTE(random_state=42)
sampler_pipeline = make_pipeline(
    scaler,
    sampler_method,
    estimator)
cv_results = cross_validate(sampler_pipeline, X_train.drop(['SEX'], axis=1), y_train, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)
print(f"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}")
print(f"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}")
model = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)
y_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]
y_pred = model.predict(X_test.drop(['SEX'],axis=1))
roc_auc_score(y_test, y_pred_proba)
Validation roc auc : 0.829 +/- 0.009
Validation balanced acc : 0.758 +/- 0.012
0.8393191272926885</span></pre> <p><span class="koboSpan" id="kobo.561.1">The validation</span><a id="_idIndexMarker644"/><span class="koboSpan" id="kobo.562.1"> metrics and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.563.1">test</span></strong><span class="koboSpan" id="kobo.564.1"> ROC score show poorer results compared to the undersampling methods covered previously. </span><span class="koboSpan" id="kobo.564.2">In the next step, we explore the </span><span class="No-Break"><span class="koboSpan" id="kobo.565.1">fairness metrics:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.566.1">
calculate_fairness_metrics_mitigated_v4 = calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <div>
<div class="IMG---Figure" id="_idContainer098">
<span class="koboSpan" id="kobo.567.1"><img alt="Figure 8.8 – Fairness metrics" src="image/B19297_08_8.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.568.1">Figure 8.8 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.569.1">The fairness</span><a id="_idIndexMarker645"/><span class="koboSpan" id="kobo.570.1"> metrics are better in comparison with the undersampling methods – that is, the difference between false positive and false negative rates is reduced between men and women and, based on the demographic parity ratio, the model is more likely to select both types of gender applicants for loan default. </span><span class="koboSpan" id="kobo.570.2">In the next section, we will use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.571.1">ADASYN</span></strong><span class="koboSpan" id="kobo.572.1"> algorithm and compare it with </span><strong class="source-inline"><span class="koboSpan" id="kobo.573.1">SMOTE</span></strong><span class="koboSpan" id="kobo.574.1"> and other </span><span class="No-Break"><span class="koboSpan" id="kobo.575.1">undersampling methods.</span></span></p>
<h3><span class="koboSpan" id="kobo.576.1">ADASYN</span></h3>
<p><span class="koboSpan" id="kobo.577.1">Similarly </span><a id="_idIndexMarker646"/><span class="koboSpan" id="kobo.578.1">to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.579.1">SMOTE</span></strong><span class="koboSpan" id="kobo.580.1"> method, we covered </span><strong class="source-inline"><span class="koboSpan" id="kobo.581.1">ADASYN</span></strong><span class="koboSpan" id="kobo.582.1"> in </span><a href="B19297_07.xhtml#_idTextAnchor111"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.583.1">Chapter 7</span></em></span></a><span class="koboSpan" id="kobo.584.1">, </span><em class="italic"><span class="koboSpan" id="kobo.585.1">Using Synthetic Data in Data-Centric Machine Learning</span></em><span class="koboSpan" id="kobo.586.1">, hence we will dive straight into the code, in which we oversample the </span><span class="No-Break"><span class="koboSpan" id="kobo.587.1">minority class:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.588.1">
sampler_method = ADASYN(random_state=42)
sampler_pipeline = make_pipeline(
    scaler,
    sampler_method,
    estimator)
cv_results = cross_validate(sampler_pipeline, X_train.drop(['SEX'], axis=1), y_train, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)
print(f"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}")
print(f"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}")
model = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)
y_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]
y_pred = model.predict(X_test.drop(['SEX'],axis=1))
roc_auc_score(y_test, y_pred_proba)
Validation roc auc : 0.823 +/- 0.004
Validation balanced acc : 0.757 +/- 0.006
0.816654655300673</span></pre> <p><span class="koboSpan" id="kobo.589.1">The validation </span><a id="_idIndexMarker647"/><span class="koboSpan" id="kobo.590.1">metrics and </span><strong class="source-inline"><span class="koboSpan" id="kobo.591.1">test</span></strong><span class="koboSpan" id="kobo.592.1"> ROC score are slightly below the </span><strong class="source-inline"><span class="koboSpan" id="kobo.593.1">SMOTE</span></strong><span class="koboSpan" id="kobo.594.1"> results and undersampling methods. </span><span class="koboSpan" id="kobo.594.2">Now, let’s review the </span><span class="No-Break"><span class="koboSpan" id="kobo.595.1">fairness metrics:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.596.1">
calculate_fairness_metrics_mitigated_v5 = calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <div>
<div class="IMG---Figure" id="_idContainer099">
<span class="koboSpan" id="kobo.597.1"><img alt="Figure 8.9 – Fairness metrics" src="image/B19297_08_9.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.598.1">Figure 8.9 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.599.1">The equalized </span><a id="_idIndexMarker648"/><span class="koboSpan" id="kobo.600.1">odds are slightly higher for </span><strong class="source-inline"><span class="koboSpan" id="kobo.601.1">ADASYN</span></strong><span class="koboSpan" id="kobo.602.1">, whereas demographic parity is slightly better when compared to </span><strong class="source-inline"><span class="koboSpan" id="kobo.603.1">SMOTE</span></strong><span class="koboSpan" id="kobo.604.1">, and both oversampling techniques guarantee higher fairness over undersampling methods, but slightly poorer </span><span class="No-Break"><span class="koboSpan" id="kobo.605.1">ROC performance.</span></span></p>
<p><span class="koboSpan" id="kobo.606.1">We have now seen that, despite balancing the classes, model fairness is compromised, and it is mostly </span><strong class="source-inline"><span class="koboSpan" id="kobo.607.1">male</span></strong><span class="koboSpan" id="kobo.608.1"> examples where the model is making more errors. </span><span class="koboSpan" id="kobo.608.2">So, in the next section, we will randomly introduce some additional </span><strong class="source-inline"><span class="koboSpan" id="kobo.609.1">male</span></strong><span class="koboSpan" id="kobo.610.1"> examples where the model is misclassifying </span><span class="No-Break"><span class="koboSpan" id="kobo.611.1">positive cases.</span></span></p>
<h3><span class="koboSpan" id="kobo.612.1">Oversampling plus misclassified examples at random</span></h3>
<p><span class="koboSpan" id="kobo.613.1">We will first </span><a id="_idIndexMarker649"/><span class="koboSpan" id="kobo.614.1">balance the dataset using </span><strong class="source-inline"><span class="koboSpan" id="kobo.615.1">ADASYN</span></strong><span class="koboSpan" id="kobo.616.1"> and avoid undersampling techniques since we want to retain hard cases that are difficult to classify. </span><span class="koboSpan" id="kobo.616.2">We then train the model and identify </span><strong class="source-inline"><span class="koboSpan" id="kobo.617.1">male</span></strong><span class="koboSpan" id="kobo.618.1"> cases that the model believes should be positive but wrongly classifies as negative. </span><span class="koboSpan" id="kobo.618.2">We then randomly select 10% of these cases, add them back to the training dataset, and retrain the model with the </span><span class="No-Break"><span class="koboSpan" id="kobo.619.1">same algorithm.</span></span></p>
<p><span class="koboSpan" id="kobo.620.1">At the end, we review the model metrics and fairness metrics on the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.621.1">test</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.622.1"> data.</span></span></p>
<p><span class="koboSpan" id="kobo.623.1">We utilize oversampling and reintroduce misclassified data points at random. </span><span class="koboSpan" id="kobo.623.2">Let’s run the pipeline with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.624.1">ADASYN</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.625.1">oversampling method:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.626.1">
sampler_method = ADASYN(random_state=42)
sampler_pipeline = make_pipeline(
    scaler,
    sampler_method,
    estimator)
cv_results = cross_validate(sampler_pipeline, X_train.drop(['SEX'], axis=1), y_train, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)
model = sampler_pipeline.fit( X_train.drop(['SEX'], axis=1), y_train)</span></pre> <p><span class="koboSpan" id="kobo.627.1">Next, we identify the examples from the training dataset where the model is making errors on the male population – that is, examples where the model predicts false negatives. </span><span class="koboSpan" id="kobo.627.2">We first subset the data associated with males and then run predictions over </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">this data:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.629.1">
X_train_males = X_train[X_train.SEX == 1].copy()
X_train_males["predictions"] = model.predict(X_train_males.drop(['SEX'], axis=1))
X_train_males['y_true'] = y_train.filter(X_train_males.index)</span></pre> <p><span class="koboSpan" id="kobo.630.1">Then we subset this data where the </span><strong class="source-inline"><span class="koboSpan" id="kobo.631.1">true</span></strong><span class="koboSpan" id="kobo.632.1"> label is </span><strong class="source-inline"><span class="koboSpan" id="kobo.633.1">1</span></strong><span class="koboSpan" id="kobo.634.1"> but model predictions </span><span class="No-Break"><span class="koboSpan" id="kobo.635.1">are </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.636.1">0</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.637.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.638.1">
X_train_male_false_negatives = X_train_males[(X_train_males.y_true == 1) &amp; (X_train_males.predictions == 0)]</span></pre> <p><span class="koboSpan" id="kobo.639.1">We randomly select 10% of the values and add them to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.640.1">X_train</span></strong><span class="koboSpan" id="kobo.641.1"> dataset. </span><span class="koboSpan" id="kobo.641.2">We leverage the </span><strong class="source-inline"><span class="koboSpan" id="kobo.642.1">.sample</span></strong><span class="koboSpan" id="kobo.643.1"> method, and this random selection is done </span><span class="No-Break"><span class="koboSpan" id="kobo.644.1">with replacement:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.645.1">
X_train_sample = X_train_male_false_negatives[X_train.columns].sample(frac=0.1, replace=True, random_state=42, axis=0)
y_train_sample = X_train_male_false_negatives['y_true'].sample(frac=0.1, replace=True, random_state=42, axis=0)</span></pre> <p><span class="koboSpan" id="kobo.646.1">Next, we</span><a id="_idIndexMarker650"/><span class="koboSpan" id="kobo.647.1"> add this 10% to </span><strong class="source-inline"><span class="koboSpan" id="kobo.648.1">X_train</span></strong><span class="koboSpan" id="kobo.649.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.650.1">y_train</span></strong><span class="koboSpan" id="kobo.651.1"> and create a </span><span class="No-Break"><span class="koboSpan" id="kobo.652.1">new dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.653.1">
X_train_with_male_samples = pd.concat([X_train, X_train_sample], axis=0, ignore_index=True)
y_train_with_male_samples = pd.concat([y_train, y_train_sample], axis=0, ignore_index=True)</span></pre> <p><span class="koboSpan" id="kobo.654.1">Then, we train the algorithm on this new dataset and print out the validation metrics and the </span><strong class="source-inline"><span class="koboSpan" id="kobo.655.1">test</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.656.1">ROC score:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.657.1">
cv_results = cross_validate(sampler_pipeline, X_train_with_male_samples.drop(['SEX'], axis=1), y_train_with_male_samples, scoring=['roc_auc','balanced_accuracy'], return_estimator=True)
print(f"Validation roc auc : {cv_results['test_roc_auc'].mean():.3f} +/- {cv_results['test_roc_auc'].std():.3f}")
print(f"Validation balanced acc : {cv_results['test_balanced_accuracy'].mean():.3f} +/- {cv_results['test_balanced_accuracy'].std():.3f}")
model = sampler_pipeline.fit(X_train_with_male_samples.drop(['SEX'], axis=1), y_train_with_male_samples)
y_pred_proba = model.predict_proba(X_test.drop(['SEX'],axis=1))[:, 1]
y_pred = model.predict(X_test.drop(['SEX'],axis=1))
roc_auc_score(y_test, y_pred_proba)
Validation roc auc : 0.824 +/- 0.005
Validation balanced acc : 0.754 +/- 0.005
0.8201623558253082</span></pre> <p><span class="koboSpan" id="kobo.658.1">Compared to the </span><a id="_idIndexMarker651"/><span class="koboSpan" id="kobo.659.1">oversampling section, the validation metrics are quite similar, as is the </span><strong class="source-inline"><span class="koboSpan" id="kobo.660.1">test</span></strong><span class="koboSpan" id="kobo.661.1"> ROC score. </span><span class="koboSpan" id="kobo.661.2">Next, we review the fairness metrics to check whether they </span><span class="No-Break"><span class="koboSpan" id="kobo.662.1">have improved:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.663.1">
calculate_fairness_metrics_mitigated_v6 = calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <div>
<div class="IMG---Figure" id="_idContainer100">
<span class="koboSpan" id="kobo.664.1"><img alt="Figure 8.10 – Fairness metrics" src="image/B19297_08_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.665.1">Figure 8.10 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.666.1">By adding </span><a id="_idIndexMarker652"/><span class="koboSpan" id="kobo.667.1">some false negative </span><strong class="source-inline"><span class="koboSpan" id="kobo.668.1">male</span></strong><span class="koboSpan" id="kobo.669.1"> examples, we can see that the equalized odds have improved slightly to 0.098 and the demographic ratio has also improved, increasing to 0.85. </span><span class="koboSpan" id="kobo.669.2">We believe that even better results can be achieved if we add false positive examples and false negative examples and combine these with undersampling and </span><span class="No-Break"><span class="koboSpan" id="kobo.670.1">oversampling techniques.</span></span></p>
<p><span class="koboSpan" id="kobo.671.1">To demonstrate this, we will iterate over four undersampling techniques (</span><strong class="source-inline"><span class="koboSpan" id="kobo.672.1">AllKNN</span></strong><span class="koboSpan" id="kobo.673.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.674.1">RepeatedEditedNearestNeighbours</span></strong><span class="koboSpan" id="kobo.675.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.676.1">InstanceHardnessThreshold</span></strong><span class="koboSpan" id="kobo.677.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.678.1">Tomek</span></strong><span class="koboSpan" id="kobo.679.1">), two oversampling techniques (</span><strong class="source-inline"><span class="koboSpan" id="kobo.680.1">SMOTE</span></strong><span class="koboSpan" id="kobo.681.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.682.1">ADASYN</span></strong><span class="koboSpan" id="kobo.683.1">), and two combinations of over and undersampling techniques (</span><strong class="source-inline"><span class="koboSpan" id="kobo.684.1">SMOTEENN</span></strong><span class="koboSpan" id="kobo.685.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.686.1">SMOTETomek</span></strong><span class="koboSpan" id="kobo.687.1">). </span><span class="koboSpan" id="kobo.687.2">How these algorithms work is outside the scope of this example. </span><span class="koboSpan" id="kobo.687.3">Instead, the goal is to demonstrate how these data techniques can lead to better selection and a generalized model with slightly poorer performance, but </span><span class="No-Break"><span class="koboSpan" id="kobo.688.1">higher fairness.</span></span></p>
<p><span class="koboSpan" id="kobo.689.1">We will now develop a mechanism where we first train the algorithm and then add false positive examples and false negative examples. </span><span class="koboSpan" id="kobo.689.2">Once the examples are added, we run the pipeline by sampling the dataset, using the previous algorithms. </span><span class="koboSpan" id="kobo.689.3">We'll record fairness outcomes and the ROC score to find the technique that best fosters a balance between fairness and performance in </span><span class="No-Break"><span class="koboSpan" id="kobo.690.1">our algorithm.</span></span></p>
<p><span class="koboSpan" id="kobo.691.1">We will first </span><a id="_idIndexMarker653"/><span class="koboSpan" id="kobo.692.1">create a dictionary with a configuration of each of the aforementioned sampling techniques so we can iterate over it. </span><span class="koboSpan" id="kobo.692.2">We can call this AutoML for the </span><span class="No-Break"><span class="koboSpan" id="kobo.693.1">sampling technique:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.694.1">
methods = {
    "all_knn": AllKNN(n_jobs=-1),
    "renn": RepeatedEditedNearestNeighbours(n_jobs=-1),
    "iht": InstanceHardnessThreshold(
        estimator=DecisionTreeClassifier(**d_tree_params),
        random_state=42,
        n_jobs=-1,
        cv=3),
    "tomek": TomekLinks(n_jobs=-1),
    "adasyn" : ADASYN(random_state=42),
    "smote" : SMOTE(random_state=42),
    "smoteenn": SMOTEENN(random_state=42,
                         smote=SMOTE(random_state=42),
                         enn=EditedNearestNeighbours(n_jobs=-1)
                        ),
    "smotetomek": SMOTETomek(random_state=42,
                             smote=SMOTE(random_state=42),
                             tomek=TomekLinks(n_jobs=-1)
                            )
          }</span></pre> <p><span class="koboSpan" id="kobo.695.1">Next, we create two functions that take the training dataset, model, column, and its subset value </span><a id="_idIndexMarker654"/><span class="koboSpan" id="kobo.696.1">to help create random samples. </span><span class="koboSpan" id="kobo.696.2">The following function will sample </span><span class="No-Break"><span class="koboSpan" id="kobo.697.1">false positives:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.698.1">
def sample_false_positives(X_train, y_train, estimator, perc=0.1, subset_col="SEX", subset_col_value=1, with_replace=True):
    """Function to sample false positives"""
    X_train = X_train.copy()
    y_train = y_train.copy()
    X_train_subset = X_train[X_train[subset_col] == subset_col_value].copy()
    y_train_subset = y_train.filter(X_train_subset.index).copy()
    X_train_subset["predictions"] = estimator.predict(X_train_subset.drop([subset_col], axis=1))
    X_train_subset['y_true'] = y_train_subset.values
    X_train_subset_false_positives = X_train_subset[(X_train_subset.y_true == 0) &amp; (X_train_subset.predictions == 1)]
    X_train_sample = X_train_subset_false_positives[X_train.columns].sample(frac=perc, replace=with_replace, random_state=42, axis=0)
    y_train_sample = X_train_subset_false_positives['y_true'].sample(frac=perc, replace=with_replace, random_state=42, axis=0)
    X_train_sample = pd.concat([X_train, X_train_sample], axis=0, ignore_index=True)
    y_train_sample = pd.concat([y_train, y_train_sample], axis=0, ignore_index=True)
    return X_train_sample, y_train_sample</span></pre> <p><span class="koboSpan" id="kobo.699.1">And this function samples false negatives. </span><span class="koboSpan" id="kobo.699.2">By default, both methods will add 10% random examples </span><span class="No-Break"><span class="koboSpan" id="kobo.700.1">with replacement:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.701.1">
def sample_false_negatives(X_train, y_train, estimator, perc=0.1, subset_col="SEX", subset_col_value=1, with_replace=True):
    """Function to sample false positives"""
    X_train = X_train.copy()
    y_train = y_train.copy()
    X_train_subset = X_train[X_train[subset_col] == subset_col_value].copy()
    y_train_subset = y_train.filter(X_train_subset.index).copy()
    X_train_subset["predictions"] = estimator.predict(X_train_subset.drop([subset_col], axis=1))
    X_train_subset['y_true'] = y_train_subset.values
    X_train_subset_false_negatives = X_train_subset[(X_train_subset.y_true == 1) &amp; (X_train_subset.predictions == 0)]
    X_train_sample = X_train_subset_false_negatives[X_train.columns].sample(frac=perc, replace=with_replace, random_state=42, axis=0)
    y_train_sample = X_train_subset_false_negatives['y_true'].sample(frac=perc, replace=with_replace, random_state=42, axis=0)
    X_train_sample = pd.concat([X_train, X_train_sample], axis=0, ignore_index=True)
    y_train_sample = pd.concat([y_train, y_train_sample], axis=0, ignore_index=True)
    return X_train_sample, y_train_sample</span></pre> <p><span class="koboSpan" id="kobo.702.1">Next, we </span><a id="_idIndexMarker655"/><span class="koboSpan" id="kobo.703.1">create a function that calculates test metrics post-data improvements. </span><span class="koboSpan" id="kobo.703.2">The function takes the test data and estimator and returns model metrics and </span><span class="No-Break"><span class="koboSpan" id="kobo.704.1">fairness metrics:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.705.1">
def calculate_metrics(estimator, X_test, y_test, A_test):
    """Function to calculate metrics"""
    y_pred_proba = estimator.predict_proba(X_test)[:, 1]
    y_pred = model.predict(X_test)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)
    equalized_odds = equalized_odds_difference(
        y_test, y_pred, sensitive_features=A_test
    )
    dpr = demographic_parity_ratio(y_test, y_pred, sensitive_features=A_test)
    return roc_auc, balanced_accuracy, equalized_odds, dpr</span></pre> <p><span class="koboSpan" id="kobo.706.1">Next, we </span><a id="_idIndexMarker656"/><span class="koboSpan" id="kobo.707.1">create a pipeline that will sample the dataset and then create random false positive </span><strong class="source-inline"><span class="koboSpan" id="kobo.708.1">male</span></strong><span class="koboSpan" id="kobo.709.1"> and false negative </span><strong class="source-inline"><span class="koboSpan" id="kobo.710.1">male</span></strong><span class="koboSpan" id="kobo.711.1"> examples. </span><span class="koboSpan" id="kobo.711.2">We then combine these into the training data, one at a time, and retrain the same algorithm. </span><span class="koboSpan" id="kobo.711.3">We then calculate the metrics and store them in a list called </span><strong class="source-inline"><span class="koboSpan" id="kobo.712.1">results</span></strong><span class="koboSpan" id="kobo.713.1"> with columns. </span><span class="koboSpan" id="kobo.713.2">Each iteration adds false negative and false positive examples with model performance and fairness metrics. </span><span class="koboSpan" id="kobo.713.3">We then use this list to compare the results </span><span class="No-Break"><span class="koboSpan" id="kobo.714.1">across algorithms.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.715.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.716.1">The code for creating the pipeline is pretty lengthy. </span><span class="koboSpan" id="kobo.716.2">Please refer to GitHub for the full </span><span class="No-Break"><span class="koboSpan" id="kobo.717.1">code: </span></span><a href="https://github.com/PacktPublishing/Data-Centric-Machine-Learning-with-Python/tree/main/Chapter%208%20-%20Techniques%20for%20identifying%20and%20removing%20bias"><span class="No-Break"><span class="koboSpan" id="kobo.718.1">https://github.com/PacktPublishing/Data-Centric-Machine-Learning-with-Python/tree/main/Chapter%208%20-%20Techniques%20for%20identifying%20and%20removing%20bias</span></span></a></p>
<p><span class="koboSpan" id="kobo.719.1">Next, we create a DataFrame called </span><strong class="source-inline"><span class="koboSpan" id="kobo.720.1">df</span></strong><span class="koboSpan" id="kobo.721.1"> and add all the </span><strong class="source-inline"><span class="koboSpan" id="kobo.722.1">test</span></strong><span class="koboSpan" id="kobo.723.1"> metrics so we can compare which method reaped the best model performance and </span><span class="No-Break"><span class="koboSpan" id="kobo.724.1">fairness metrics:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.725.1">
df = pd.DataFrame(data=results,
                  columns=["method", "sample",
                           "test_roc_auc", "test_balanced_accuracy",
                           "equalized_odds",
                           "demographic_parity_ratio",
                           "validation_roc_auc",
                           "validation_balanced_accuracy"]
                 )</span></pre> <p><span class="koboSpan" id="kobo.726.1">Let’s sort the DataFrame based on </span><span class="No-Break"><span class="koboSpan" id="kobo.727.1">equalized odds:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.728.1">
df.sort_values(by="equalized_odds")</span></pre> <p><span class="koboSpan" id="kobo.729.1">We can see that when the dataset was sampled with Tomek Links, where difficult cases were removed from the boundary and combined with additional false positive </span><strong class="source-inline"><span class="koboSpan" id="kobo.730.1">male</span></strong><span class="koboSpan" id="kobo.731.1"> training samples, this resulted in the best equalized odds of 0.075; however, a demographic parity of 0.8 was not achieved. </span><span class="koboSpan" id="kobo.731.2">When the SMOTETomek technique was used in combination </span><a id="_idIndexMarker657"/><span class="koboSpan" id="kobo.732.1">with false negative </span><strong class="source-inline"><span class="koboSpan" id="kobo.733.1">male</span></strong><span class="koboSpan" id="kobo.734.1"> examples, the model achieved a 0.088 equalized odds ratio, which was the best among the sampling methods, and the model also achieved a high demographic </span><span class="No-Break"><span class="koboSpan" id="kobo.735.1">parity ratio.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer101">
<span class="koboSpan" id="kobo.736.1"><img alt="Figure 8.11 – Resulting output dataset" src="image/B19297_08_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.737.1">Figure 8.11 – Resulting output dataset</span></p>
<h3><span class="koboSpan" id="kobo.738.1">Oversampling with anomalies</span></h3>
<p><span class="koboSpan" id="kobo.739.1">In the </span><a id="_idIndexMarker658"/><span class="koboSpan" id="kobo.740.1">previous steps, we learned that by adding poorly classified examples to the training dataset, we were able to improve model fairness. </span><span class="koboSpan" id="kobo.740.2">In the next step, instead of choosing samples at random, we will utilize an algorithm that identifies anomalies and then we add these anomalies to the training dataset as an </span><span class="No-Break"><span class="koboSpan" id="kobo.741.1">oversampling mechanism.</span></span></p>
<p><span class="koboSpan" id="kobo.742.1">First, we create a pipeline to oversample the </span><span class="No-Break"><span class="koboSpan" id="kobo.743.1">minority class:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.744.1">
X_train_scaled = pd.DataFrame()
scaler = StandardScaler()
sampler = SMOTETomek(random_state=42,
                     smote=SMOTE(random_state=42),
                     tomek=TomekLinks(n_jobs=-1)
                    )</span></pre> <p><span class="koboSpan" id="kobo.745.1">Next, we </span><a id="_idIndexMarker659"/><span class="koboSpan" id="kobo.746.1">extract the oversampled data. </span><span class="koboSpan" id="kobo.746.2">There is no reason why undersampling or no sampling could not have been chosen. </span><span class="koboSpan" id="kobo.746.3">Once the oversampled data is extracted, we then scale it back to the original </span><span class="No-Break"><span class="koboSpan" id="kobo.747.1">feature space:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.748.1">
columns = X_train.drop(['SEX'], axis=1).columns
X_train_scaled[columns] = scaler.fit_transform(X_train.drop(['SEX'], axis=1))
X_train_resample, y_train_resample = sampler.fit_resample(X_train_scaled, y_train)
X_train_resample[columns] = scaler.inverse_transform(X_train_resample)</span></pre> <p><span class="koboSpan" id="kobo.749.1">Next, we train the isolation forest to identify 10% of anomalies. </span><span class="koboSpan" id="kobo.749.2">To do that, we set the contamination to </span><strong class="source-inline"><span class="koboSpan" id="kobo.750.1">0.1</span></strong><span class="koboSpan" id="kobo.751.1">. </span><span class="koboSpan" id="kobo.751.2">We then fit the model on resampled data, and run prediction on this data. </span><span class="koboSpan" id="kobo.751.3">We store the results in a column called </span><strong class="source-inline"><span class="koboSpan" id="kobo.752.1">IF_anomaly</span></strong><span class="koboSpan" id="kobo.753.1"> and add it to the resampled dataset. </span><span class="koboSpan" id="kobo.753.2">We then extract these anomalies, as isolation forest labels with a value </span><span class="No-Break"><span class="koboSpan" id="kobo.754.1">of </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.755.1">-1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.756.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.757.1">
anomaly_model = IsolationForest(contamination=float(.1), random_state=42, n_jobs=-1)
anomaly_model.fit(X_train_resample)
X_train_resample['IF_anomaly'] = anomaly_model.predict(X_train_resample)
X_train_resample['default'] = y_train_resample
X_train_additional_samples = X_train_resample[X_train_resample.IF_anomaly == -1]
X_train_additional_samples.drop(['IF_anomaly'], axis=1, inplace=True)</span></pre> <p><span class="koboSpan" id="kobo.758.1">Next, we add these additional data points to the original dataset and train the decision tree model. </span><span class="koboSpan" id="kobo.758.2">Once the model is fitted, we calculate the ROC score on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.759.1">test</span></strong><span class="koboSpan" id="kobo.760.1"> data. </span><span class="koboSpan" id="kobo.760.2">We can see that this </span><span class="No-Break"><span class="koboSpan" id="kobo.761.1">is 0.82:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.762.1">
X_train_clean = X_train_resample[X_train_resample.IF_anomaly != -1]
y_train_clean = X_train_clean.default
estimator.fit(X_train_clean.drop(['IF_anomaly', 'default'], axis=1), y_train_clean)
y_pred_proba = estimator.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]
y_pred = estimator.predict(X_test.drop(['SEX'], axis=1))
roc_auc_score(y_test, y_pred_proba)
0.8248481592937735</span></pre> <p><span class="koboSpan" id="kobo.763.1">Next, we</span><a id="_idIndexMarker660"/><span class="koboSpan" id="kobo.764.1"> calculate the fairness metrics. </span><span class="koboSpan" id="kobo.764.2">Based on the following results, we can say that the model trained in the previous section produced better fairness and demographic parity </span><span class="No-Break"><span class="koboSpan" id="kobo.765.1">ratio scores:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer102">
<span class="koboSpan" id="kobo.766.1"><img alt="Figure 8.12 – Fairness metrics" src="image/B19297_08_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.767.1">Figure 8.12 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.768.1">Now that we </span><a id="_idIndexMarker661"/><span class="koboSpan" id="kobo.769.1">have utilized various examples of undersampling and oversampling data, including reintroducing random misclassified examples and anomalies, in the next section, we will utilize an advanced technique, where we will be more selective with which examples to add and which examples to remove, to further reduce bias in </span><span class="No-Break"><span class="koboSpan" id="kobo.770.1">the algorithm.</span></span></p>
<h2 id="_idParaDest-131"><a id="_idTextAnchor139"/><span class="koboSpan" id="kobo.771.1">Shapley values to detect bias, oversample, and undersample data</span></h2>
<p><span class="koboSpan" id="kobo.772.1">In this </span><a id="_idIndexMarker662"/><span class="koboSpan" id="kobo.773.1">section, we will utilize Shapley values to identify examples where the model struggles to make the correct prediction. </span><span class="koboSpan" id="kobo.773.2">We will use the impact score to either add, eliminate, or use a combination of both to improve the </span><span class="No-Break"><span class="koboSpan" id="kobo.774.1">fairness metrics.</span></span></p>
<p><strong class="bold"><span class="koboSpan" id="kobo.775.1">SHAP</span></strong><span class="koboSpan" id="kobo.776.1"> (which stands for </span><strong class="bold"><span class="koboSpan" id="kobo.777.1">Shapley Additive exPlanations</span></strong><span class="koboSpan" id="kobo.778.1">) is a model-agnostic approach </span><a id="_idIndexMarker663"/><span class="koboSpan" id="kobo.779.1">in machine learning that is built on the principles of game theory. </span><span class="koboSpan" id="kobo.779.2">It helps study the importance of the feature and the feature interaction on the final outcome by assigning it a score, similar to how it would be done in a game where each player’s contribution at a given time is calculated in the output of </span><span class="No-Break"><span class="koboSpan" id="kobo.780.1">the score.</span></span></p>
<p><span class="koboSpan" id="kobo.781.1">Shapley values</span><a id="_idIndexMarker664"/><span class="koboSpan" id="kobo.782.1"> can help provide global importance (the overall impact of the feature on all the predictions), but also local importance (the impact of each feature on a single outcome). </span><span class="koboSpan" id="kobo.782.2">It can also help understand the direction of impact – that is, whether a feature has a positive impact or a </span><span class="No-Break"><span class="koboSpan" id="kobo.783.1">negative impact.</span></span></p>
<p><span class="koboSpan" id="kobo.784.1">Hence, there </span><a id="_idIndexMarker665"/><span class="koboSpan" id="kobo.785.1">are a lot of use cases for Shapley values in machine learning, such as bias detection, local and global model debugging, model auditing, and </span><span class="No-Break"><span class="koboSpan" id="kobo.786.1">model interpretability.</span></span></p>
<p><span class="koboSpan" id="kobo.787.1">We use Shapley values in this section to understand the model and feature impacts on the outcomes. </span><span class="koboSpan" id="kobo.787.2">We leverage the impacts of these features and identify where the model is likely to make the most mistakes. </span><span class="koboSpan" id="kobo.787.3">We then apply two techniques: one to remove these rows from the data and the other to oversample the data with </span><span class="No-Break"><span class="koboSpan" id="kobo.788.1">these rows.</span></span></p>
<p><span class="koboSpan" id="kobo.789.1">First, we import SHAP and then train the decision tree model on the oversampled dataset. </span><span class="koboSpan" id="kobo.789.2">At the end of the step, we have a model and oversampled </span><strong class="source-inline"><span class="koboSpan" id="kobo.790.1">X</span></strong><span class="koboSpan" id="kobo.791.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.792.1">y</span></strong><span class="koboSpan" id="kobo.793.1"> samples. </span><span class="koboSpan" id="kobo.793.2">We include the </span><strong class="source-inline"><span class="koboSpan" id="kobo.794.1">SEX</span></strong><span class="koboSpan" id="kobo.795.1"> variable in the training data to see whether Shapley values can help us detect bias. </span><span class="koboSpan" id="kobo.795.2">First, we need to resplit the data into </span><strong class="source-inline"><span class="koboSpan" id="kobo.796.1">train</span></strong><span class="koboSpan" id="kobo.797.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.798.1">test</span></strong><span class="koboSpan" id="kobo.799.1"> sets, as done in the </span><span class="No-Break"><span class="koboSpan" id="kobo.800.1">previous sections:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.801.1">
model = DecisionTreeClassifier(**d_tree_params)
model.fit(X_train, y_train)
DecisionTreeClassifier(min_samples_leaf=10, random_state=42)</span></pre> <p><span class="koboSpan" id="kobo.802.1">Next, we define the SHAP tree explainer, by providing the decision tree model and then extract the Shapley values for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.803.1">train</span></strong><span class="koboSpan" id="kobo.804.1"> set using the </span><strong class="source-inline"><span class="koboSpan" id="kobo.805.1">.</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.806.1">shap_values</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.807.1"> method:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.808.1">
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_train)</span></pre> <p><span class="koboSpan" id="kobo.809.1">Let’s extract the first row of Shapley values, for class 0. </span><span class="koboSpan" id="kobo.809.2">The array contains the contribution of each feature value to decide the final output. </span><span class="koboSpan" id="kobo.809.3">Positive values mean the corresponding features have a positive impact on predicting the output as class 0, while negative values negatively contribute toward predicting </span><span class="No-Break"><span class="koboSpan" id="kobo.810.1">class 0:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.811.1">
shap_values[0][0]</span></pre> <p><span class="koboSpan" id="kobo.812.1">This will print out the </span><span class="No-Break"><span class="koboSpan" id="kobo.813.1">following array:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer103">
<span class="koboSpan" id="kobo.814.1"><img alt="Figure 8.13 – Resulting output array" src="image/B19297_08_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.815.1">Figure 8.13 – Resulting output array</span></p>
<p><span class="koboSpan" id="kobo.816.1">Next, we </span><a id="_idIndexMarker666"/><span class="koboSpan" id="kobo.817.1">generate a summary plot for class </span><span class="No-Break"><span class="koboSpan" id="kobo.818.1">label 0:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.819.1">
shap.summary_plot(shap_values[0], X_train)</span></pre> <p><span class="koboSpan" id="kobo.820.1">This will generate the </span><span class="No-Break"><span class="koboSpan" id="kobo.821.1">following plot:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer104">
<span class="koboSpan" id="kobo.822.1"><img alt="Figure 8.14 – SHAP values" src="image/B19297_08_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.823.1">Figure 8.14 – SHAP values</span></p>
<p><span class="koboSpan" id="kobo.824.1">The red </span><a id="_idIndexMarker667"/><span class="koboSpan" id="kobo.825.1">dots represent the high value of a feature while the blue dots represent the low value of the corresponding feature. </span><span class="koboSpan" id="kobo.825.2">The </span><em class="italic"><span class="koboSpan" id="kobo.826.1">x</span></em><span class="koboSpan" id="kobo.827.1"> axis denotes the Shapley value, where the positive value means the data point has a positive impact in predicting class 0, whereas the negative value means the data point for the corresponding feature negatively affects the prediction for class 0. </span><span class="koboSpan" id="kobo.827.2">If we look at </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.828.1">Figure 8</span></em></span><em class="italic"><span class="koboSpan" id="kobo.829.1">.13,</span></em><span class="koboSpan" id="kobo.830.1"> it is quite evident that high interest rates and male customers negatively affect the prediction of class 0. </span><span class="koboSpan" id="kobo.830.2">Shapley values do indicate a model bias toward </span><span class="No-Break"><span class="koboSpan" id="kobo.831.1">male customers.</span></span></p>
<p><span class="koboSpan" id="kobo.832.1">Next, we generate a summary plot for class </span><span class="No-Break"><span class="koboSpan" id="kobo.833.1">label 1:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.834.1">
shap.summary_plot(shap_values[1], X_train)</span></pre> <p><span class="koboSpan" id="kobo.835.1">This will generate the following </span><span class="No-Break"><span class="koboSpan" id="kobo.836.1">summary plot:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer105">
<span class="koboSpan" id="kobo.837.1"><img alt="Figure 8.15 – SHAP summary plot" src="image/B19297_08_15.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.838.1">Figure 8.15 – SHAP summary plot</span></p>
<p><span class="koboSpan" id="kobo.839.1">In comparison</span><a id="_idIndexMarker668"/><span class="koboSpan" id="kobo.840.1"> with the summary plot for class 0, high interest rates and male customers positively impact defaulting on the loan – that is, if you are a male and previously had a higher interest rate, you are likely to default on </span><span class="No-Break"><span class="koboSpan" id="kobo.841.1">the loan.</span></span></p>
<p><span class="koboSpan" id="kobo.842.1">We previously learned that by removing the </span><strong class="source-inline"><span class="koboSpan" id="kobo.843.1">SEX</span></strong><span class="koboSpan" id="kobo.844.1"> feature from model training, the model becomes fairer, and Shapley values are clearly indicated using summary plots. </span><span class="koboSpan" id="kobo.844.2">Now, we extract the Shapley values by training the new model without the </span><strong class="source-inline"><span class="koboSpan" id="kobo.845.1">SEX</span></strong><span class="koboSpan" id="kobo.846.1"> feature. </span><span class="koboSpan" id="kobo.846.2">We then score the training data to first identify all the rows corresponding to false negatives </span><a id="_idIndexMarker669"/><span class="koboSpan" id="kobo.847.1">and false positives. </span><span class="koboSpan" id="kobo.847.2">We then calculate the sum of Shapley values for each row where the model made errors, and then hold out the ones with the lowest impact. </span><span class="koboSpan" id="kobo.847.3">We run two experiments: first, we undersample the training dataset and calculate fairness metrics, and second, we oversample the training dataset to give a better signal to the model and recalculate </span><span class="No-Break"><span class="koboSpan" id="kobo.848.1">fairness metrics.</span></span></p>
<p><span class="koboSpan" id="kobo.849.1">First, let’s train the model without the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.850.1">SEX</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.851.1"> feature:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.852.1">
model = DecisionTreeClassifier(**d_tree_params)
X_train_samples = X_train.drop(['SEX'], axis=1).copy()
y_train_samples = y_train.copy()
model.fit(X_train_samples, y_train_samples)</span></pre> <p><span class="koboSpan" id="kobo.853.1">Next, we extract </span><span class="No-Break"><span class="koboSpan" id="kobo.854.1">Shapley values:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.855.1">
explainer = shap.Explainer(model)
shap_values = explainer.shap_values(X_train_samples)</span></pre> <p><span class="koboSpan" id="kobo.856.1">We score the training data, calculate predictions, and store these </span><span class="No-Break"><span class="koboSpan" id="kobo.857.1">in </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.858.1">Y_pred</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.859.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.860.1">
Y_pred = model.predict(X_train_samples)</span></pre> <p><span class="koboSpan" id="kobo.861.1">Then we will check the sum of the Shapley value for class 0 and class 1 at index 0, and print the corresponding prediction and </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.862.1">true</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.863.1"> value:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.864.1">
print(f"Shapley value for first value in the dataset for class 0 : {sum(shap_values[0][0])}")
print(f"Shapley value for first value in the dataset for class 1 : {sum(shap_values[1][0])}")
print(f"Prediction of first value is {Y_pred[0]}")
print(f"Actual prediction is {y_train_samples[0]}")
Shapley value for first value in the dataset for class 0 : -0.07290931372549389
Shapley value for first value in the dataset for class 1 : 0.07290931372548978
Prediction of first value is 0
Actual prediction is 1</span></pre> <p><span class="koboSpan" id="kobo.865.1">The model </span><a id="_idIndexMarker670"/><span class="koboSpan" id="kobo.866.1">predicted </span><strong class="source-inline"><span class="koboSpan" id="kobo.867.1">0</span></strong><span class="koboSpan" id="kobo.868.1">. </span><span class="koboSpan" id="kobo.868.2">Next, we extract the Shapley values where the model made a mistake. </span><span class="koboSpan" id="kobo.868.3">For that, we use the list comprehension with zip functionality. </span><span class="koboSpan" id="kobo.868.4">The first value of the array will be the index location of the data point so we know which Shapley value is associated with which row. </span><span class="koboSpan" id="kobo.868.5">The next values are in order of prediction, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.869.1">true</span></strong><span class="koboSpan" id="kobo.870.1"> value, the sum of Shapley values for the row for class 0, and the sum of Shapley values for class 1. </span><span class="koboSpan" id="kobo.870.2">Once we have extracted those, we create a DataFrame and store the values in </span><strong class="source-inline"><span class="koboSpan" id="kobo.871.1">df</span></strong><span class="koboSpan" id="kobo.872.1">, and we sample through the DataFrame to see five values. </span><span class="koboSpan" id="kobo.872.2">We use a random seed </span><span class="No-Break"><span class="koboSpan" id="kobo.873.1">for reproducibility:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.874.1">
data = [(index, pred, actual, sum(s0), sum(s1)) for
        index, (pred, actual, s0, s1) in
        enumerate(zip(Y_pred, y_train_samples, shap_values[0], shap_values[1]))
        if pred != actual]
df = pd.DataFrame(data=data, columns=["index", "predictions","actuals", "shap_class_0", "shap_class_1"])
df.sample(5, random_state=42)</span></pre> <p><span class="koboSpan" id="kobo.875.1">This generate the </span><span class="No-Break"><span class="koboSpan" id="kobo.876.1">following output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer106">
<span class="koboSpan" id="kobo.877.1"><img alt="Figure 8.16 – DataFrame displaying the Shapley values that made a mistake" src="image/B19297_08_16.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.878.1">Figure 8.16 – DataFrame displaying the Shapley values that made a mistake</span></p>
<p><span class="koboSpan" id="kobo.879.1">For index </span><strong class="source-inline"><span class="koboSpan" id="kobo.880.1">7915</span></strong><span class="koboSpan" id="kobo.881.1">, the Shapley values are close, meaning feature contributions to the model prediction are closer to </span><strong class="source-inline"><span class="koboSpan" id="kobo.882.1">0</span></strong><span class="koboSpan" id="kobo.883.1"> for each class, whereas for index </span><strong class="source-inline"><span class="koboSpan" id="kobo.884.1">4255</span></strong><span class="koboSpan" id="kobo.885.1">, the Shapley values are far apart from </span><strong class="source-inline"><span class="koboSpan" id="kobo.886.1">0</span></strong><span class="koboSpan" id="kobo.887.1"> and features are discriminatory in predicting </span><span class="No-Break"><span class="koboSpan" id="kobo.888.1">each class.</span></span></p>
<p><span class="koboSpan" id="kobo.889.1">Given that we </span><a id="_idIndexMarker671"/><span class="koboSpan" id="kobo.890.1">can extract the SHAP impact of features for each class, we want to know the rows where the Shapley value impact is highest so we can eliminate such data points from training; where the impact is low and quite close to the boundary, we can oversample </span><span class="No-Break"><span class="koboSpan" id="kobo.891.1">the data.</span></span></p>
<p><span class="koboSpan" id="kobo.892.1">Looking at the force plots for index </span><strong class="source-inline"><span class="koboSpan" id="kobo.893.1">4255</span></strong><span class="koboSpan" id="kobo.894.1">, for the expected class </span><strong class="source-inline"><span class="koboSpan" id="kobo.895.1">0</span></strong><span class="koboSpan" id="kobo.896.1">, the model is likely to predict </span><strong class="source-inline"><span class="koboSpan" id="kobo.897.1">1</span></strong><span class="koboSpan" id="kobo.898.1">, given that </span><strong class="source-inline"><span class="koboSpan" id="kobo.899.1">f(x)</span></strong><span class="koboSpan" id="kobo.900.1"> is quite low, and the model wrongly predicts </span><strong class="source-inline"><span class="koboSpan" id="kobo.901.1">1</span></strong><span class="koboSpan" id="kobo.902.1">, whereas the force plot for the expected class </span><strong class="source-inline"><span class="koboSpan" id="kobo.903.1">1</span></strong><span class="koboSpan" id="kobo.904.1"> shows an </span><strong class="source-inline"><span class="koboSpan" id="kobo.905.1">f(x)</span></strong><span class="koboSpan" id="kobo.906.1"> value of </span><strong class="source-inline"><span class="koboSpan" id="kobo.907.1">0.7</span></strong><span class="koboSpan" id="kobo.908.1">. </span><span class="koboSpan" id="kobo.908.2">Such data points can be eliminated from </span><span class="No-Break"><span class="koboSpan" id="kobo.909.1">the dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.910.1">
shap.force_plot(explainer.expected_value[0], shap_values[0][4255,:], X_train_samples.iloc[4255, :], matplotlib=True)</span></pre> <p><span class="koboSpan" id="kobo.911.1">This will generate the </span><span class="No-Break"><span class="koboSpan" id="kobo.912.1">following plot:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer107">
<span class="koboSpan" id="kobo.913.1"><img alt="Figure 8.17 – Force plot for class 0" src="image/B19297_08_17.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.914.1">Figure 8.17 – Force plot for class 0</span></p>
<p><span class="koboSpan" id="kobo.915.1">Let’s look at the force plot for </span><span class="No-Break"><span class="koboSpan" id="kobo.916.1">class </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.917.1">1</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.918.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.919.1">
shap.force_plot(explainer.expected_value[1], shap_values[1][4255,:], X_train_samples.iloc[4255, :], matplotlib=True)</span></pre> <p><span class="koboSpan" id="kobo.920.1">This will display the </span><span class="No-Break"><span class="koboSpan" id="kobo.921.1">following output:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer108">
<span class="koboSpan" id="kobo.922.1"><img alt="Figure 8.18 – Force plot for class 1" src="image/B19297_08_18.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.923.1">Figure 8.18 – Force plot for class 1</span></p>
<p><span class="koboSpan" id="kobo.924.1">Now, we</span><a id="_idIndexMarker672"/><span class="koboSpan" id="kobo.925.1"> calculate the Shapley impact of row index </span><strong class="source-inline"><span class="koboSpan" id="kobo.926.1">4255</span></strong><span class="koboSpan" id="kobo.927.1"> since it’s a false positive prediction. </span><span class="koboSpan" id="kobo.927.2">The row index is at the </span><strong class="source-inline"><span class="koboSpan" id="kobo.928.1">422</span></strong><span class="koboSpan" id="kobo.929.1"> location in the DataFrame. </span><span class="koboSpan" id="kobo.929.2">We take the absolute value of the Shapley impact and, where the Shapley impact is highest and the prediction is wrong, those values can be eliminated to improve </span><span class="No-Break"><span class="koboSpan" id="kobo.930.1">model performance:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.931.1">
index = 422
shap_impact = abs(df['shap_class_0'][index])
print(shap_impact)
0.4787916666666662</span></pre> <p><span class="koboSpan" id="kobo.932.1">Next, we create a function that calculates the Shapley impact. </span><span class="koboSpan" id="kobo.932.2">We are interested in those rows where a single feature has a minimum of </span><strong class="source-inline"><span class="koboSpan" id="kobo.933.1">0.2</span></strong><span class="koboSpan" id="kobo.934.1"> Shapley impact. </span><span class="koboSpan" id="kobo.934.2">First, we get the absolute impact of each feature in an array, and then we extract the maximum value. </span><span class="koboSpan" id="kobo.934.3">If the maximum value is greater than </span><strong class="source-inline"><span class="koboSpan" id="kobo.935.1">0.2</span></strong><span class="koboSpan" id="kobo.936.1">, we proceed with that row. </span><span class="koboSpan" id="kobo.936.2">Next, we check where the prediction doesn’t match the actual value, and for such rows, we extract the </span><span class="No-Break"><span class="koboSpan" id="kobo.937.1">SHAP impact:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.938.1">
def get_shapley_impact(shap_value, threshold=0.2):
    """Calculate Shapley impact"""
    shap_value_impacts = np.abs(shap_value)
    if np.max(shap_value_impacts) &gt;= threshold:
        return np.abs(np.sum(shap_value))</span></pre> <p><span class="koboSpan" id="kobo.939.1">We create a holdout dataset, where </span><strong class="source-inline"><span class="koboSpan" id="kobo.940.1">X_train</span></strong><span class="koboSpan" id="kobo.941.1"> will be further divided into training and validation datasets. </span><span class="koboSpan" id="kobo.941.2">We leverage 80% for training and 20% </span><span class="No-Break"><span class="koboSpan" id="kobo.942.1">for validation:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.943.1">
X_train_sample, X_val, y_train_sample, y_val, A_train_sample, A_val = train_test_split(X_train,
                   y_train,
                   A_train,
                   test_size=0.2,
                   stratify=y_train,
                   random_state=42)</span></pre> <p><span class="koboSpan" id="kobo.944.1">Then we resample the dataset using </span><strong class="source-inline"><span class="koboSpan" id="kobo.945.1">SMOTETomek</span></strong><span class="koboSpan" id="kobo.946.1">, which was the best sampling method for fairness and performance, and performed by adding difficult examples back to the dataset. </span><span class="koboSpan" id="kobo.946.2">Once the dataset is resampled, we train the standard decision tree as in the previous steps, and calculate the ROC score on the holdout </span><span class="No-Break"><span class="koboSpan" id="kobo.947.1">validation dataset:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.948.1">
model = DecisionTreeClassifier(**d_tree_params)
scaler = StandardScaler()
sampler = SMOTETomek(random_state=42,
                     smote=SMOTE(random_state=42),
                     tomek=TomekLinks(n_jobs=-1)
                    )
columns = X_train_sample.columns
X_train_scaled = pd.DataFrame()
X_train_scaled[columns] = scaler.fit_transform(X_train_sample[columns])
X_train_resampled, y_train_resampled = sampler_method.fit_resample(X_train_scaled, y_train_sample)
X_train_resampled[columns] = scaler.inverse_transform(X_train_resampled)
A_train_resampled = X_train_resampled['SEX'].copy()
model.fit(X_train_resampled.drop(['SEX'], axis=1), y_train_resampled)
Y_pred = model.predict(X_train_resampled.drop(['SEX'], axis=1))
y_val_pred = model.predict_proba(X_val.drop(['SEX'], axis=1))[: ,1]
val_roc = roc_auc_score(y_val, y_val_pred)
print(f"Validation roc auc : {val_roc}")
Validation roc auc : 0.8275769341994823</span></pre> <p><span class="koboSpan" id="kobo.949.1">We </span><a id="_idIndexMarker673"/><span class="koboSpan" id="kobo.950.1">calculate the fairness and performance metrics on the testing dataset. </span><span class="koboSpan" id="kobo.950.2">The equalized odds are high but the demographic parity ratio is within the </span><span class="No-Break"><span class="koboSpan" id="kobo.951.1">accepted range:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.952.1">
y_pred_proba = model.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]
y_pred = model.predict(X_test.drop(['SEX'], axis=1))
print(f"Roc: {roc_auc_score(y_test, y_pred_proba)}")
Roc: 0.8258396009334518</span></pre> <p><span class="koboSpan" id="kobo.953.1">Next, we calculate the </span><span class="No-Break"><span class="koboSpan" id="kobo.954.1">fairness metrics:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.955.1">
calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <p><span class="koboSpan" id="kobo.956.1">This will print out the </span><span class="No-Break"><span class="koboSpan" id="kobo.957.1">following metrics:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer109">
<span class="koboSpan" id="kobo.958.1"><img alt="Figure 8.19 – Fairness metrics" src="image/B19297_08_19.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.959.1">Figure 8.19 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.960.1">We extract</span><a id="_idIndexMarker674"/><span class="koboSpan" id="kobo.961.1"> the Shapley values using the SHAP explainer. </span><span class="koboSpan" id="kobo.961.2">We have ensured that the </span><strong class="source-inline"><span class="koboSpan" id="kobo.962.1">SEX</span></strong><span class="koboSpan" id="kobo.963.1"> feature </span><span class="No-Break"><span class="koboSpan" id="kobo.964.1">is removed:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.965.1">
explainer = shap.Explainer(model)
columns = X_train_resampled.drop(['SEX'], axis=1).columns
shap_values = explainer.shap_values(X_train_resampled[columns])</span></pre> <p><span class="koboSpan" id="kobo.966.1">The fairness metrics demonstrate that the gap between false negative rates is higher between the subclass of men and women, hence we focus on reducing false negative cases for males using </span><span class="No-Break"><span class="koboSpan" id="kobo.967.1">Shapley values.</span></span></p>
<p><span class="koboSpan" id="kobo.968.1">In the next step, we extract Shapley values where the model predicts class </span><strong class="source-inline"><span class="koboSpan" id="kobo.969.1">0,</span></strong><span class="koboSpan" id="kobo.970.1"> but the </span><strong class="source-inline"><span class="koboSpan" id="kobo.971.1">true</span></strong><span class="koboSpan" id="kobo.972.1"> value is </span><strong class="source-inline"><span class="koboSpan" id="kobo.973.1">1</span></strong><span class="koboSpan" id="kobo.974.1">. </span><span class="koboSpan" id="kobo.974.2">Hence, we are interested in Shapley values for class </span><strong class="source-inline"><span class="koboSpan" id="kobo.975.1">1</span></strong><span class="koboSpan" id="kobo.976.1">, as a high SHAP impact for class </span><strong class="source-inline"><span class="koboSpan" id="kobo.977.1">1</span></strong><span class="koboSpan" id="kobo.978.1"> where the model made an error could be a data point that the model is unable to make a correct </span><span class="No-Break"><span class="koboSpan" id="kobo.979.1">prediction on:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.980.1">
shapley_impact_false_negative = [(i, get_shapley_impact(s), y, p, a)
                                for s, i, y, p, a
                                in zip(shap_values[1], X_train_resampled.index, y_train_resampled, Y_pred, A_train_resampled)
                                 if y == 1 and p == 0 and a == 1]</span></pre> <p><span class="koboSpan" id="kobo.981.1">We are also </span><a id="_idIndexMarker675"/><span class="koboSpan" id="kobo.982.1">interested in those data points where both Shapley values and model prediction agree with the actual values. </span><span class="koboSpan" id="kobo.982.2">Hence, we focus on those data points where the model rightly predicts class </span><strong class="source-inline"><span class="koboSpan" id="kobo.983.1">0</span></strong><span class="koboSpan" id="kobo.984.1"> for </span><strong class="source-inline"><span class="koboSpan" id="kobo.985.1">male</span></strong><span class="koboSpan" id="kobo.986.1"> data points. </span><span class="koboSpan" id="kobo.986.2">Once we have extracted those, we focus on high-impact Shapley values for class </span><strong class="source-inline"><span class="koboSpan" id="kobo.987.1">0</span></strong><span class="koboSpan" id="kobo.988.1"> so we can oversample the dataset with those, such that the model can get a better signal for such </span><span class="No-Break"><span class="koboSpan" id="kobo.989.1">data points:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.990.1">
shapley_impact_true_negative = [(i, get_shapley_impact(s), y, p, a)
                                for s, i, y, p, a
                                in zip(shap_values[0], X_train_resampled.index, y_train_resampled, Y_pred, A_train_resampled)
                                 if y == 0 and p == 0 and a == 1]</span></pre> <p><span class="koboSpan" id="kobo.991.1">Next, we sort the false negative Shapley values so we can extract the high-impact </span><span class="No-Break"><span class="koboSpan" id="kobo.992.1">data points:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.993.1">
shapley_impact_false_negative_sorted = sorted([i for i in shapley_impact_false_negative if i[1] is not None], key=lambda x: x[1], reverse=True)</span></pre> <p><span class="koboSpan" id="kobo.994.1">Similar to the preceding, we are interested in true negative high-impact Shapley values, so we sort the list according to high-impact </span><span class="No-Break"><span class="koboSpan" id="kobo.995.1">Shapley values:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.996.1">
shapley_impact_true_negative_sorted =  sorted([i for i in shapley_impact_true_negative if i[1] is not None], key=lambda x: x[1], reverse=True)</span></pre> <p><span class="koboSpan" id="kobo.997.1">Now that we have extracted and sorted the Shapley values for false negative and true negative </span><strong class="source-inline"><span class="koboSpan" id="kobo.998.1">male</span></strong><span class="koboSpan" id="kobo.999.1"> data points, we pick the top 100 data points to eliminate from the false negative list and pick the top 100 data points from the true negative list to add back to the training data. </span><span class="koboSpan" id="kobo.999.2">The top 100 data points from the true negative list will be shuffled and only 50 data points from there will be added at random with a replacement strategy. </span><span class="koboSpan" id="kobo.999.3">We </span><a id="_idIndexMarker676"/><span class="koboSpan" id="kobo.1000.1">encourage practitioners to try another ratio for shuffling. </span><span class="koboSpan" id="kobo.1000.2">Once the data points are identified for elimination and reintroduction to the final training set, we update the training data. </span><span class="koboSpan" id="kobo.1000.3">These are named </span><strong class="source-inline"><span class="koboSpan" id="kobo.1001.1">X_train_final</span></strong> <span class="No-Break"><span class="koboSpan" id="kobo.1002.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1003.1">y_train_final</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1004.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1005.1">
data_points_to_eliminate = [i[0] for i in shapley_impact_false_negative_sorted[0:100]]
data_points_to_add = [i[0] for i in shapley_impact_true_negative_sorted[0:100]]
X_train_added = X_train_resampled[columns].iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)
y_train_added = y_train_resampled.iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)
X_train_reduced = X_train_resampled[columns].drop(data_points_to_eliminate)
y_train_reduced = y_train_resampled.drop(data_points_to_eliminate)
X_train_final = pd.concat([X_train_reduced, X_train_added], axis=0, ignore_index=True)
y_train_final = pd.concat([y_train_reduced, y_train_added], axis=0, ignore_index=True)</span></pre> <p><span class="koboSpan" id="kobo.1006.1">Next, we train the updated training data and calculate fairness metrics and performance metrics on the </span><strong class="source-inline"><span class="koboSpan" id="kobo.1007.1">test</span></strong><span class="koboSpan" id="kobo.1008.1"> data. </span><span class="koboSpan" id="kobo.1008.2">It is evident that the gap between false negative rates has reduced, the equalized odds ratio has improved to 0.082, and the ROC score has slightly improved from the previous step, from 0.825 </span><span class="No-Break"><span class="koboSpan" id="kobo.1009.1">to 0.826:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1010.1">
estimator = DecisionTreeClassifier(**d_tree_params)
model = estimator.fit(X_train_final, y_train_final)
y_pred_proba = model.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]
y_pred = model.predict(X_test.drop(['SEX'], axis=1))
print(f"Roc: {roc_auc_score(y_test, y_pred_proba)}")
Roc: 0.8262453372973797</span></pre> <p><span class="koboSpan" id="kobo.1011.1">We recalculate the </span><span class="No-Break"><span class="koboSpan" id="kobo.1012.1">fairness metrics:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1013.1">
calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <p><span class="koboSpan" id="kobo.1014.1">The output is </span><span class="No-Break"><span class="koboSpan" id="kobo.1015.1">as follows:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer110">
<span class="koboSpan" id="kobo.1016.1"><img alt="Figure 8.20 – Fairness metrics" src="image/B19297_08_20.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1017.1">Figure 8.20 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.1018.1">Now that we have </span><a id="_idIndexMarker677"/><span class="koboSpan" id="kobo.1019.1">determined that by using Shapley values we can identify data points that are difficult to classify and easy to classify, we can build an automatic mechanism to iterate over the data points such that we can reach a better fairness score </span><span class="No-Break"><span class="koboSpan" id="kobo.1020.1">than previously.</span></span></p>
<p><span class="koboSpan" id="kobo.1021.1">Next, we create a range of percentages to iterate so we can leverage and sort through the top data points as a percentage of top data points to eliminate and reintroduce. </span><span class="koboSpan" id="kobo.1021.2">We will leverage the NumPy </span><strong class="source-inline"><span class="koboSpan" id="kobo.1022.1">linspace</span></strong><span class="koboSpan" id="kobo.1023.1"> method to create a list of percentage values to iterate. </span><span class="koboSpan" id="kobo.1023.2">We choose 10 values from </span><strong class="source-inline"><span class="koboSpan" id="kobo.1024.1">0.05</span></strong><span class="koboSpan" id="kobo.1025.1"> through </span><strong class="source-inline"><span class="koboSpan" id="kobo.1026.1">0.5</span></strong><span class="koboSpan" id="kobo.1027.1"> (5 to 50 percent). </span><span class="koboSpan" id="kobo.1027.2">We call this </span><span class="No-Break"><span class="koboSpan" id="kobo.1028.1">list </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.1029.1">perc_points_to_eliminate</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.1030.1">:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1031.1">
perc_points_to_eliminate = np.linspace(0.05,0.5,10)
perc_points_to_eliminate
array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ])</span></pre> <p><span class="koboSpan" id="kobo.1032.1">We iterate through these percentages and repeat the preceding step where we eliminated some values and reintroduced some values. </span><span class="koboSpan" id="kobo.1032.2">However, this time, instead of 100, we use percentages to remove the top percent of data points or introduce the top percent of </span><span class="No-Break"><span class="koboSpan" id="kobo.1033.1">data points.</span></span></p>
<p><span class="koboSpan" id="kobo.1034.1">We also </span><a id="_idIndexMarker678"/><span class="koboSpan" id="kobo.1035.1">create an empty list of data so, for each iteration, we capture the percentage of data points eliminated or reintroduced, false negative and false positive rates on test data, equalized odds ratio, and demographic </span><span class="No-Break"><span class="koboSpan" id="kobo.1036.1">parity ratio.</span></span></p>
<p><span class="koboSpan" id="kobo.1037.1">Once we have iterated over all the values – 10*10 iterations, we store them in a DataFrame to see how many data points need to be removed and how many added to lead to the best </span><span class="No-Break"><span class="koboSpan" id="kobo.1038.1">fairness metrics:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1039.1">
fn_examples = len(shapley_impact_false_negative)
tn_examples = len(shapley_impact_true_negative)
model = DecisionTreeClassifier(**d_tree_params)
data = []
for fnp in perc_points_to_eliminate:
    data_points_to_eliminate = [idx[0] for idx in shapley_impact_false_negative_sorted[0:(round(fn_examples*fnp))]]
    for tnp in perc_points_to_eliminate:
        data_points_to_add = [idx[0] for idx in shapley_impact_true_negative_sorted[0:(round(tn_examples*tnp))]]
        X_train_added = X_train_resampled[columns].iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)
        y_train_added = y_train_resampled.iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)
        X_train_reduced = X_train_resampled[columns].drop(data_points_to_eliminate)
        y_train_reduced = y_train_resampled.drop(data_points_to_eliminate)
        X_train_final = pd.concat([X_train_reduced, X_train_added], axis=0, ignore_index=True)
        y_train_final = pd.concat([y_train_reduced, y_train_added], axis=0, ignore_index=True)
        model.fit(X_train_final, y_train_final)
        y_pred = model.predict(X_test.drop(['SEX'], axis=1))
        fpr = false_positive_rate(y_test, y_pred)
        fnr = false_negative_rate(y_test, y_pred)
        equalized_odds_mitigated = equalized_odds_difference(
            y_test, y_pred, sensitive_features=A_test
        )
        demographic_parity_ratio_mitigated = demographic_parity_ratio(y_test, y_pred, sensitive_features=A_test)
        data.append((fnp,
                     tnp,
                     fpr,
                     fnr,
                     equalized_odds_mitigated,
                     demographic_parity_ratio_mitigated
                    ))</span></pre> <p><span class="koboSpan" id="kobo.1040.1">Next, we </span><a id="_idIndexMarker679"/><span class="koboSpan" id="kobo.1041.1">create a DataFrame called </span><strong class="source-inline"><span class="koboSpan" id="kobo.1042.1">df_shapley</span></strong><span class="koboSpan" id="kobo.1043.1"> for the metadata for each iteration and sort it by equalized </span><span class="No-Break"><span class="koboSpan" id="kobo.1044.1">odds ratio:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1045.1">
columns = ["perc_false_negative_removed",
          "perc_true_negative_added",
          "false_positive_rate",
          "false_negative_rate",
          "equalized_odds_mitigated",
          "demographic_parity_ratio_mitigated"]
df_shapley = pd.DataFrame(data=data, columns=columns)
df_shapley.sort_values(by="equalized_odds_mitigated")</span></pre> <p><span class="koboSpan" id="kobo.1046.1">This will output the </span><span class="No-Break"><span class="koboSpan" id="kobo.1047.1">following DataFrame:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer111">
<span class="koboSpan" id="kobo.1048.1"><img alt="Figure  8.21 – The df_shapley DataFrame after sorting" src="image/B19297_08_21.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1049.1">Figure 8.21 – The df_shapley DataFrame after sorting</span></p>
<p><span class="koboSpan" id="kobo.1050.1">It’s evident that when the top 25% of false negative data points are removed and 30% of the top true negative data points are reintroduced, the model can achieve an equalized odds ratio of 0.074 with an optimum demographic parity ratio score </span><span class="No-Break"><span class="koboSpan" id="kobo.1051.1">of 0.85.</span></span></p>
<p><span class="koboSpan" id="kobo.1052.1">Finally, we</span><a id="_idIndexMarker680"/><span class="koboSpan" id="kobo.1053.1"> extract the top percentages and train the </span><span class="No-Break"><span class="koboSpan" id="kobo.1054.1">final model:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1055.1">
top_values = df_shapley.sort_values(by="equalized_odds_mitigated").values[0]
perc_false_negative_removed = top_values[0]
perc_true_negative_added = top_values[1]
columns = X_train_resampled.drop(['SEX'], axis=1).columns
data_points_to_eliminate = [i[0] for i in shapley_impact_false_negative_sorted[0:(round(fn_examples*perc_false_negative_removed))]]
data_points_to_add = [i[0] for i in shapley_impact_true_negative_sorted[0:(round(tn_examples*perc_true_negative_added))]]
X_train_added = X_train_resampled[columns].iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)
y_train_added = y_train_resampled.iloc[data_points_to_add].sample(frac=0.5, replace=True, random_state=42, axis=0)
X_train_reduced = X_train_resampled[columns].drop(data_points_to_eliminate)
y_train_reduced = y_train_resampled.drop(data_points_to_eliminate)
X_train_final = pd.concat([X_train_reduced, X_train_added], axis=0, ignore_index=True)
y_train_final = pd.concat([y_train_reduced, y_train_added], axis=0, ignore_index=True)</span></pre> <p><span class="koboSpan" id="kobo.1056.1">We train</span><a id="_idIndexMarker681"/><span class="koboSpan" id="kobo.1057.1"> the model and calculate the fairness and model metrics. </span><span class="koboSpan" id="kobo.1057.2">We can see that the false negative rate for </span><strong class="source-inline"><span class="koboSpan" id="kobo.1058.1">female</span></strong><span class="koboSpan" id="kobo.1059.1"> has increased but the gap between </span><strong class="source-inline"><span class="koboSpan" id="kobo.1060.1">male</span></strong><span class="koboSpan" id="kobo.1061.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.1062.1">female</span></strong><span class="koboSpan" id="kobo.1063.1"> has reduced, and the false positive rate for </span><strong class="source-inline"><span class="koboSpan" id="kobo.1064.1">male</span></strong><span class="koboSpan" id="kobo.1065.1"> has reduced. </span><span class="koboSpan" id="kobo.1065.2">The ROC score achieved is 0.82, but the model is much fairer based on two </span><span class="No-Break"><span class="koboSpan" id="kobo.1066.1">fairness metrics:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1067.1">
estimator = DecisionTreeClassifier(**d_tree_params)
model = estimator.fit(X_train_final, y_train_final)
y_pred_proba = model.predict_proba(X_test.drop(['SEX'], axis=1))[:, 1]
y_pred = model.predict(X_test.drop(['SEX'], axis=1))
print(f"Roc: {roc_auc_score(y_test, y_pred_proba)}")
Roc: 0.820911097453972</span></pre> <p><span class="koboSpan" id="kobo.1068.1">Finally, we calculate the </span><span class="No-Break"><span class="koboSpan" id="kobo.1069.1">fairness metrics.</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.1070.1">
calculate_fairness_metrics(y_test, y_pred, A_test)</span></pre> <p><span class="koboSpan" id="kobo.1071.1">This will print out </span><span class="No-Break"><span class="koboSpan" id="kobo.1072.1">the following:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer112">
<span class="koboSpan" id="kobo.1073.1"><img alt="Figure 8.22 – Fairness metrics" src="image/B19297_08_22.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.1074.1">Figure 8.22 – Fairness metrics</span></p>
<p><span class="koboSpan" id="kobo.1075.1">Now that we</span><a id="_idIndexMarker682"/><span class="koboSpan" id="kobo.1076.1"> have explored different data-centric techniques for reducing bias by improving data quality, we encourage you to experiment with the previous techniques and try a combination of these. </span><span class="koboSpan" id="kobo.1076.2">Once you have exhausted these data-centric approaches, we encourage you use some model-centric approaches, such as utilizing algorithms that are fairness aware and trying ensembling methods, AutoML, or iterating through your own list </span><span class="No-Break"><span class="koboSpan" id="kobo.1077.1">of algorithms.</span></span></p>
<h1 id="_idParaDest-132"><a id="_idTextAnchor140"/><span class="koboSpan" id="kobo.1078.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.1079.1">This chapter provided an extensive exploration of the pervasive challenge of bias in machine learning. </span><span class="koboSpan" id="kobo.1079.2">It started by explaining various forms of bias inherent in machine learning models and examined their impact on different industries. </span><span class="koboSpan" id="kobo.1079.3">The emphasis was on recognizing, monitoring, and mitigating bias, underscoring the importance of collecting data with minimal selection and </span><span class="No-Break"><span class="koboSpan" id="kobo.1080.1">sampling bias.</span></span></p>
<p><span class="koboSpan" id="kobo.1081.1">The central theme advocated a data-centric imperative over a model-centric one in addressing bias. </span><span class="koboSpan" id="kobo.1081.2">Techniques such as oversampling, undersampling, feature selection enhancement, and anomaly detection were explored for bias rectification. </span><span class="koboSpan" id="kobo.1081.3">Shapley values play a crucial role in bias identification, emphasizing the removal of examples with misaligned high Shapley values and the reintroduction of data points with replacement to improve ratios. </span><span class="koboSpan" id="kobo.1081.4">Stratification of misclassified examples based on sensitive variables such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.1082.1">SEX</span></strong><span class="koboSpan" id="kobo.1083.1"> was outlined for targeted </span><span class="No-Break"><span class="koboSpan" id="kobo.1084.1">bias correction.</span></span></p>
<p><span class="koboSpan" id="kobo.1085.1">The chapter concluded by highlighting the significance of refining and balancing datasets concerning sensitive variables as a foundational step. </span><span class="koboSpan" id="kobo.1085.2">It suggested progressing toward model-centric approaches, such as ensembling and fairness algorithms, once the dataset itself has been improved. </span><span class="koboSpan" id="kobo.1085.3">These subsequent model-centric strategies aim to enhance both performance and fairness metrics, establishing a foundation for more generalized and equitable </span><span class="No-Break"><span class="koboSpan" id="kobo.1086.1">AI models.</span></span></p>
<p><span class="koboSpan" id="kobo.1087.1">This comprehensive approach strives to create a balanced dataset as a precursor to applying model-centric techniques, promoting performance and fairness in </span><span class="No-Break"><span class="koboSpan" id="kobo.1088.1">AI systems.</span></span></p>
</div>
</body></html>