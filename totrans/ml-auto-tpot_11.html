<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer215">
			<h1 id="_idParaDest-92"><em class="italic"><a id="_idTextAnchor093"/>Chapter 8</em>: TPOT Model Deployment</h1>
			<p>In this chapter, you'll learn how to deploy any automated machine learning model, both to localhost and the cloud. You'll learn why the deployment step is necessary if you aim to make machine learning-powered software. It's assumed you know how to train basic regression and classification models with TPOT. Knowledge of the topics of the last couple of chapters (Dask and neural networks) isn't required, as we won't deal with those here.</p>
			<p>Throughout the chapter, you'll learn how easy it is to wrap your models in an API and expose their predictive capabilities to other users that aren't necessarily data scientists. You'll also learn which cloud providers are the best to get you started entirely for free.</p>
			<p>This chapter will cover the following topics:</p>
			<ul>
				<li>Why do we need model deployment?</li>
				<li>Introducing <strong class="source-inline">Flask</strong> and <strong class="source-inline">Flask-RESTful</strong></li>
				<li>Best practices for deploying automated models</li>
				<li>Deploying machine learning models to localhost</li>
				<li>Deploying machine learning models to the cloud</li>
			</ul>
			<h1 id="_idParaDest-93"><a id="_idTextAnchor094"/>Technical requirements</h1>
			<p>As briefly said earlier, you need to know how to build basic machine learning models with TPOT. Don't worry if you don't feel too comfortable with the library yet, as we'll develop the model from scratch. If you're entirely new to TPOT, please refer to <a href="B16954_02_Final_SK_ePub.xhtml#_idTextAnchor036"><em class="italic">Chapter 2</em></a>, <em class="italic">Deep Dive into TPOT</em>, <a href="B16954_03_Final_SK_ePub.xhtml#_idTextAnchor051"><em class="italic">Chapter 3</em></a>, <em class="italic">Exploring Regression with TPOT</em>, and <a href="B16954_04_Final_SK_ePub.xhtml#_idTextAnchor058"><em class="italic">Chapter 4</em></a>, <em class="italic">Exploring Classification with TPOT</em>.</p>
			<p>This chapter will be quite code-heavy, so you can refer to the official GitHub repository if you get stuck: <a href="https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter08">https://github.com/PacktPublishing/Machine-Learning-Automation-with-TPOT/tree/main/Chapter08</a>.</p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor095"/>Why do we need model deployment?</h1>
			<p>If you're already going through the hassle of training and optimizing machine learning models, why don't you take it a step further and deploy it so everyone can use it?</p>
			<p>Maybe you <a id="_idIndexMarker445"/>want to have the model's predictive capabilities available in a web application. Perhaps you're a mobile app developer who wants to bring machine learning to Android and iOS. The options are endless and different, but all of them share one similarity – the need to be deployed. </p>
			<p>Now, machine learning model deployment has nothing to do with machine learning. The aim is to write a simple REST API (preferably in Python, since that's the language used throughout the book) and expose any form of endpoint that calls a <strong class="source-inline">predict()</strong> function to the world. You want parameters sent to your application in JSON format, and then to use them as inputs to your model. Once the prediction is made, you can simply return it to the user.</p>
			<p>Yes, that's all there is to machine learning model deployment. Of course, things could get more technical, but keeping things simple will get us 95% of the way, and you can always explore further to squeeze that extra 5%.</p>
			<p>When it comes to the technical side of model deployment, Python provides you with a bunch of options. You can use either <strong class="source-inline">Flask</strong> and <strong class="source-inline">Flask-RESTful</strong>, <strong class="source-inline">FastAPI</strong>, <strong class="source-inline">Django</strong>, or <strong class="source-inline">Pyramid</strong>. There are other options, sure, but their "market share" is more or less negligible. You'll use the first option in this chapter, starting from the next section.</p>
			<p>The section that follows aims to introduce you to the libraries with a couple of basic hands-on examples. We'll dive into machine learning afterward.</p>
			<h1 id="_idParaDest-95"><a id="_idTextAnchor096"/>Introducing Flask and Flask-RESTful</h1>
			<p><strong class="source-inline">Flask</strong> is a lightweight framework for building web applications. It enables you to start simple and <a id="_idIndexMarker446"/>scale when needed. <strong class="source-inline">Flask-RESTful</strong> is an extension for <strong class="source-inline">Flask</strong> that allows you to build REST APIs in no time. </p>
			<p>To get started <a id="_idIndexMarker447"/>with these two, you'll need to install them. You can execute the following line from the terminal:</p>
			<p class="source-code">&gt; pip install flask flask-restful</p>
			<p>And that's all you need to get started. Let's explore the basics of <strong class="source-inline">Flask</strong> first:</p>
			<ol>
				<li>Believe it or not, you'll need only seven lines of code to create your first web application with <strong class="source-inline">Flask</strong>. It won't do anything useful, but it's still a step in the right direction. <p>To start, you'll need to import the library and create an application instance. You'll then have to make a function that returns what you want to be displayed on the website and decorate the function with an <strong class="source-inline">@app.route(route_url)</strong> decorator. Keep in mind that you should replace <strong class="source-inline">route_url</strong> with the URL string at which the function should display the result. If you pass in a forward slash (<strong class="source-inline">/</strong>), the results will be displayed on the root page – but more about that in a bit.</p><p>Finally, you'll have <a id="_idIndexMarker448"/>to make the Python file runnable with an <strong class="source-inline">if __name__ == '__main__'</strong> check. The application will run on localhost on port <strong class="source-inline">8000</strong>.</p><p>Refer to <a id="_idIndexMarker449"/>the following code snippet for your first <strong class="source-inline">Flask</strong> application:</p><p class="source-code">from flask import Flask </p><p class="source-code">app = Flask(__name__)</p><p class="source-code">@app.route('/')</p><p class="source-code">def root():</p><p class="source-code">    return 'Your first Flask app!'</p><p class="source-code">if __name__ == '__main__':</p><p class="source-code">    app.run(host='0.0.0.0', port=8000)</p><p>To run the application, you'll have to execute the Python file from the terminal. The file is named <strong class="source-inline">flask_basics.py</strong> on my machine, so to run it, please execute the following:</p><p class="source-code"><strong class="bold">&gt; python flask_basics.py</strong></p><p>If you did everything correctly, you'll see the following message displayed in your terminal window:</p><div id="_idContainer165" class="IMG---Figure"><img src="Images/B16954_08_1.jpg" alt="Figure 8.1 – Running your first Flask application&#13;&#10;" width="587" height="111"/></div><p class="figure-caption">Figure 8.1 – Running your first Flask application</p><p>From the <strong class="source-inline">Running on http://0.0.0.0:8000/</strong> message, you can see where the application <a id="_idIndexMarker450"/>is running, ergo which URL you need to visit to see your <a id="_idIndexMarker451"/>application. Just so you know, the <strong class="source-inline">0.0.0.0</strong> part can be replaced with <strong class="source-inline">localhost</strong>.</p><p>Once there, you'll see the following displayed, indicating that everything worked properly:</p><div id="_idContainer166" class="IMG---Figure"><img src="Images/B16954_08_2.jpg" alt="Figure 8.2 – Your first Flask application&#13;&#10;" width="393" height="122"/></div><p class="figure-caption">Figure 8.2 – Your first Flask application</p><p>And that's how easy it is to build your first web application with <strong class="source-inline">Flask</strong>. You'll learn how to make something a bit more complex next.</p></li>
				<li>By now, you know how to build the simplest application with <strong class="source-inline">Flask</strong> – but that's not why you're here. We want to make APIs instead of apps, and that's a bit of a different story. The difference between them is quite obvious – APIs don't come with a user interface (except for the documentation page), whereas web apps do. APIs are just a service. As it turns out, you can build APIs with <strong class="source-inline">Flask</strong> out of the box. We'll explore how to do so and explain why it isn't the best option.<p>To start, create a new Python file. This file will be referenced as <strong class="source-inline">flask_basics2.py</strong>. Inside it, we'll have a single route for two possible API call types. Both have the task of adding two numbers and returning the results, but they do so differently. Let's list the differences:</p><p>a) <strong class="source-inline">/adding</strong> (GET) relies on the logic implemented earlier. To be more precise, a GET request is <a id="_idIndexMarker452"/>made when the endpoint is called. The only difference <a id="_idIndexMarker453"/>is that this time, the parameters are passed in the URL. For example, calling <strong class="source-inline">/adding?num1=3&amp;num2=5</strong> should display <strong class="source-inline">8</strong> onscreen. The parameter values are extracted directly from the URL. You'll see this in action, so everything will be clear immediately.</p><p>b) <strong class="source-inline">/adding</strong> (POST) is quite similar to the first endpoint but makes a POST request instead. This is a more secure communication method, as parameter values aren't passed in the URL directly but in the request body instead. This endpoint returns the summation as JSON, so you'll need to wrap the results inside the <strong class="source-inline">flask.jsonify()</strong> function.</p><p>Both functions aim to complete an identical task – sum two numbers and return the result. Here's one example of how you might implement this logic:</p><p class="source-code">from flask import Flask, request, jsonify</p><p class="source-code">app = Flask(__name__)</p><p class="source-code">@app.route('/adding')</p><p class="source-code">def add_get():</p><p class="source-code">    num1 = int(request.args.get('num1'))</p><p class="source-code">    num2 = int(request.args.get('num2'))</p><p class="source-code">    return f'&lt;h3&gt;{num1} + {num2} = {num1 + num2}&lt;/h3&gt;'</p><p class="source-code">@app.route('/adding', methods=['POST'])</p><p class="source-code">def add_post():</p><p class="source-code">    data = request.get_json()</p><p class="source-code">    num1 = data['num1']</p><p class="source-code">    num2 = data['num2']</p><p class="source-code">    return jsonify({'result': num1 + num2})</p><p class="source-code">if __name__ == '__main__':</p><p class="source-code">    app.run(host='0.0.0.0', port=8000)</p><p>As you can see, the <strong class="source-inline">add_get()</strong> function returns a string formatted as HTML. You can return <a id="_idIndexMarker454"/>entire HTML documents if you want, but that's not something <a id="_idIndexMarker455"/>that interests us now, so we won't look further into it.</p><p>To run the application, you'll have to execute the Python file from the terminal. The file is named <strong class="source-inline">flask_basics2.py</strong> on my machine, so to run it, please execute the following:</p><p class="source-code"><strong class="bold">&gt; python flask_basics2.py</strong></p><p>The API will now run, and you can see both endpoints. Let's take a look at <strong class="source-inline">/adding</strong> for GET first:</p><div id="_idContainer167" class="IMG---Figure"><img src="Images/B16954_08_3.jpg" alt="Figure 8.3 – The GET endpoint without parameter values&#13;&#10;" width="984" height="178"/></div><p class="figure-caption">Figure 8.3 – The GET endpoint without parameter values</p><p>As you can see, calling the endpoint but failing to provide parameter values will result in an error. There's a way around this, but we're not too interested in GET methods in this chapter, so we'll leave it as is.</p><p>We could <a id="_idIndexMarker456"/>continue testing the API from the browser, but there's a better option – Postman. This <a id="_idIndexMarker457"/>is a free application designed for API testing. You can download it from here: <a href="https://www.postman.com">https://www.postman.com</a>. The installation is straightforward – simply download the <a id="_idIndexMarker458"/>installation file corresponding to your OS, specify the install location, and agree to the license terms. Don't feel obligated to change anything; just leave every setting as is by default.</p><p>Once installed, let's open the Postman app and enter the following URL: <strong class="source-inline">http://localhost:8000/adding?num1=3&amp;num2=5</strong>. The <strong class="bold">Params</strong> tab will immediately populate, and after that, you're ready to send the request.</p><p>You should see the following output almost immediately:</p><div id="_idContainer168" class="IMG---Figure"><img src="Images/B16954_08_4.jpg" alt="Figure 8.4 – The GET endpoint with parameter values&#13;&#10;" width="653" height="481"/></div><p class="figure-caption">Figure 8.4 – The GET endpoint with parameter values</p><p>As you can see, the result is formatted as HTML. We've deliberately returned an HTML tag <a id="_idIndexMarker459"/>here so there's a difference between the GET and POST responses. POST is <a id="_idIndexMarker460"/>preferable for this type of task because it allows you to play with the returned numbers more easily, and we'll explore it next.</p><p>Unlike GET, you can't make POST requests through the browser. Postman (or any other tool) is mandatory. Once the app is open, you'll need to change the request type from GET to POST, enter the URL, <strong class="source-inline">http://localhost:8000/adding</strong>, and under <strong class="bold">Body</strong>, select the <strong class="bold">Raw</strong> option and <strong class="bold">JSON</strong> as the data format. Inside, you'll enter the parameters as specified in the following figure:</p><p>Once done, you can click on the <strong class="bold">Send</strong> button to submit the request.</p><div id="_idContainer169" class="IMG---Figure"><img src="Images/B16954_08_5.jpg" alt="Figure 8.5 – The POST endpoint with parameters (Postman)&#13;&#10;" width="624" height="400"/></div><p class="figure-caption">Figure 8.5 – The POST endpoint with parameters (Postman)</p><p>And that's how you can test your API endpoints through Postman.</p><p>In reality, that's <a id="_idIndexMarker461"/>not the approach you'll go with. Postman is excellent <a id="_idIndexMarker462"/>for testing your APIs, but what if you need to work with the response somehow? Sure, it's a simple number now, but we'll be predicting machine learning models in a couple of pages. If that's the case, sending requests through programming languages such as Python is the only viable solution.</p><p>You can use the following code snippet to send requests through Python and capture the response:</p><p class="source-code">import requests</p><p class="source-code">req = requests.post(</p><p class="source-code">    url='http://localhost:8000/adding',</p><p class="source-code">    json={'num1': 3, 'num2': 5}</p><p class="source-code">)</p><p class="source-code">res = req.content</p><p class="source-code">print(res)</p><p>If you were to run this code now, here's what you would see as the output: </p><div id="_idContainer170" class="IMG---Figure"><img src="Images/B16954_08_6.jpg" alt="Figure 8.6 – The POST endpoint with parameters (Python)&#13;&#10;" width="208" height="28"/></div><p class="figure-caption">Figure 8.6 – The POST endpoint with parameters (Python)</p><p>This is essentially <a id="_idIndexMarker463"/>a string, so some conversion to JSON will be mandatory <a id="_idIndexMarker464"/>before you can work with the returned value. More on that later, in <a href="B16954_09_Final_SK_ePub.xhtml#_idTextAnchor102"><em class="italic">Chapter 9</em></a>, <em class="italic">Using the Deployed TPOT Model in Production</em>.</p><p>So far, you've seen how the <strong class="source-inline">Flask</strong> library can be used to develop both web applications and web services (APIs). It's a good first option, but there's a better approach if you're only interested in building APIs – <strong class="source-inline">Flask-RESTful</strong>. Let's explore it next.</p></li>
				<li>You already have <strong class="source-inline">Flask-RESTful</strong> installed. The syntax when using it is a bit different. It uses the <strong class="bold">Object-Oriented Programming</strong> (<strong class="bold">OOP</strong>) paradigm for declaring <a id="_idIndexMarker465"/>endpoints. In a nutshell, you'll need as many classes as there are distinct endpoints. Each endpoint class can contain one or multiple methods, such as <strong class="source-inline">get()</strong>, <strong class="source-inline">post()</strong>, and <strong class="source-inline">put()</strong>, which represent what happens when a request of a particular type is made.<p>All API classes inherit from the <strong class="source-inline">Flask-RESTful.Resource</strong> class and each endpoint must be manually bound to a specific URL string via the <strong class="source-inline">add_resource()</strong> method.</p><p>To summarize, we'll have the <strong class="source-inline">Add</strong> class, which has two methods: <strong class="source-inline">get()</strong> and <strong class="source-inline">post()</strong>. All of the logic inside these methods is identical to what we had earlier, with a <a id="_idIndexMarker466"/>single exception – we won't return HTML anywhere.</p><p>Here's <a id="_idIndexMarker467"/>the entire code snippet:</p><p class="source-code">from flask import Flask, request, jsonify</p><p class="source-code">from flask_restful import Resource, Api </p><p class="source-code">app = Flask(__name__)</p><p class="source-code">api = Api(app)</p><p class="source-code">class Adding(Resource):</p><p class="source-code">    @staticmethod</p><p class="source-code">    def get():</p><p class="source-code">        num1 = int(request.args.get('num1'))</p><p class="source-code">        num2 = int(request.args.get('num2'))</p><p class="source-code">        return num1 + num2</p><p class="source-code">    @staticmethod</p><p class="source-code">    def post():</p><p class="source-code">        data = request.get_json()</p><p class="source-code">        num1 = data['num1']</p><p class="source-code">        num2 = data['num2']</p><p class="source-code">        return jsonify({'result': num1 + num2})</p><p class="source-code">api.add_resource(Adding, '/adding')</p><p class="source-code">if __name__ == '__main__':</p><p class="source-code">    app.run(host='0.0.0.0', port=8000)</p><p>Everything inside the <strong class="source-inline">Adding</strong> class is available on the <strong class="source-inline">/adding</strong> endpoint.</p><p>As you <a id="_idIndexMarker468"/>can see, the API will run on a different port, just to easily <a id="_idIndexMarker469"/>distinguish between this API and the previous one.</p><p>If you were to open <strong class="source-inline">http://localhost:8000/adding</strong> now, you'd see the following message:</p></li>
			</ol>
			<div>
				<div id="_idContainer171" class="IMG---Figure">
					<img src="Images/B16954_08_7.jpg" alt="Figure 8.7 – Flask-RESTful GET without parameters&#13;&#10;" width="383" height="119"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.7 – Flask-RESTful GET without parameters</p>
			<p>We now have the same error as with the default <strong class="source-inline">Flask</strong> API, and the reason is that no parameter values were given in the URL. If you were to change it and call <strong class="source-inline">http://localhost:8000/adding?num1=5&amp;num2=10</strong>, you'd see the following in your browser window:</p>
			<div>
				<div id="_idContainer172" class="IMG---Figure">
					<img src="Images/B16954_08_8.jpg" alt="Figure 8.8 – Flask-RESTful GET with parameters&#13;&#10;" width="412" height="122"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.8 – Flask-RESTful GET with parameters</p>
			<p>As mentioned <a id="_idIndexMarker470"/>earlier, communicating with an API straight from the browser is <a id="_idIndexMarker471"/>not considered to be a good practice, but you can still do it with GET request types. You're better off using a tool such as Postman, and you already know how to do so.</p>
			<p>As for the POST method, you can call the same URL as previously, <strong class="source-inline">http://localhost:8000/adding</strong>, and pass the parameters as JSON in the request body. Here's how you can do so with Postman:</p>
			<div>
				<div id="_idContainer173" class="IMG---Figure">
					<img src="Images/B16954_08_9.jpg" alt="Figure 8.9 – Flask-RESTful POST with Postman&#13;&#10;" width="622" height="422"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.9 – Flask-RESTful POST with Postman</p>
			<p>You can do the same through Python, but you should already know how to do so by now.</p>
			<p>You now <a id="_idIndexMarker472"/>know the basics of REST API development with Python, <strong class="source-inline">Flask</strong>, and <strong class="source-inline">Flask-RESTful</strong>. This was a relatively quick, hands-on section that served as a primer <a id="_idIndexMarker473"/>for what's about to follow. In the next section, we'll go over a couple of best practices for deploying machine learning models, and in the last two sections, we'll explore how you can train and deploy models to localhost and the cloud, respectively.</p>
			<h1 id="_idParaDest-96"><a id="_idTextAnchor097"/>Best practices for deploying automated models</h1>
			<p>The deployment <a id="_idIndexMarker474"/>of automated models is more or less identical to the deployment of your normal machine learning models. It boils down to training the model first and then saving the model in some format. In the case of normal machine learning models, you could easily save the model to a <strong class="source-inline">.model</strong> or <strong class="source-inline">.h5</strong> file. There's no reason not to do the same with TPOT models.</p>
			<p>If you remember from previous chapters, TPOT can export the best pipeline to a Python file so this pipeline can be used to train the model if it isn't trained already, and the model can be saved afterward. If the model is already trained, only the prediction is obtained.</p>
			<p>The check <a id="_idIndexMarker475"/>for whether a model has been trained or not can be made by checking whether a file exists or not. If a model file exists, we can assume the model was trained, so we can load it and make a prediction. Otherwise, the model should be trained and saved first, and only then can the prediction be made.</p>
			<p>It's also a good idea to use a POST request type when connecting to a machine learning API. It's a better option than GET because parameter values aren't passed directly in the URL. As you might know, parameter values can be sensitive, so it's a good idea to hide them whenever possible.</p>
			<p>For example, maybe you need to authenticate with the API before making predictions. It's easy to understand why sending your username and password credentials directly in a URL isn't a good idea. POST has you covered, and the rest of the chapter will make good use of it.</p>
			<p>In a nutshell, you should always check whether the model is trained before making predictions and train it if required. The other take-home point is that POST is better than GET in our case. You now know a couple of basic best practices for deploying machine learning models. In the next section, we will train and deploy the model to localhost.</p>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor098"/>Deploying machine learning models to localhost</h1>
			<p>We'll have to train a model before we can deploy it. You already know everything about training <a id="_idIndexMarker476"/>with TPOT, so we won't <a id="_idIndexMarker477"/>spend too much time here. The goal is to train a simple Iris classifier and export the predictive functionality somehow. Let's go through the process step by step:</p>
			<ol>
				<li value="1">As always, the first step is to load in the libraries and the dataset. You can use the following piece of code to do so:<p class="source-code">import pandas as pd</p><p class="source-code">df = pd.read_csv('data/iris.csv')</p><p class="source-code">df.head()</p><p>This is what the first few rows look like:</p><div id="_idContainer174" class="IMG---Figure"><img src="Images/B16954_08_10.jpg" alt="Figure 8.10 – The first few rows of the Iris dataset&#13;&#10;" width="858" height="312"/></div><p class="figure-caption">Figure 8.10 – The first few rows of the Iris dataset</p></li>
				<li>The next <a id="_idIndexMarker478"/>step is to separate <a id="_idIndexMarker479"/>the features from the target variable. This time, we won't split the dataset into training and testing subsets, as we don't intend to evaluate the model's performance. In other words, we know the model performs well, and now we want to retrain it on the entire dataset. Also, string values in the target variables will be remapped to their integer representation as follows:<p>a) Setosa – 0</p><p>b) Virginica – 1 </p><p>c) Versicolor – 2</p><p>The following lines of code do everything that was described:</p><p class="source-code">X = df.drop('species', axis=1)</p><p class="source-code">y = df['species']</p><p class="source-code">y = y.replace({'setosa': 0, 'virginica': 1, 'versicolor': 2})</p><p class="source-code">y</p><p>Here's what the target variable looks like now:</p><div id="_idContainer175" class="IMG---Figure"><img src="Images/B16954_08_11.jpg" alt="Figure 8.11 – The target variable after value remapping&#13;&#10;" width="652" height="363"/></div><p class="figure-caption">Figure 8.11 – The target variable after value remapping</p></li>
				<li>Next stop – model training. We'll train the model with TPOT for 15 minutes. This part <a id="_idIndexMarker480"/>should be familiar to you, as <a id="_idIndexMarker481"/>we're not using any parameters that weren't used or described in previous chapters.<p>The following piece of code will train the model on the entire dataset:</p><p class="source-code">from tpot import TPOTClassifier</p><p class="source-code">clf = TPOTClassifier(</p><p class="source-code">    scoring='accuracy',</p><p class="source-code">    max_time_mins=15,</p><p class="source-code">    random_state=42,</p><p class="source-code">    verbosity=2</p><p class="source-code">)</p><p class="source-code">clf.fit(X, y)</p><p>You'll see many outputs during the training process, but it shouldn't take too long to achieve 100% accuracy, as shown in the following figure:</p><div id="_idContainer176" class="IMG---Figure"><img src="Images/B16954_08_12.jpg" alt="Figure 8.12 – TPOT training process&#13;&#10;" width="1036" height="579"/></div><p class="figure-caption">Figure 8.12 – TPOT training process</p><p>How <a id="_idIndexMarker482"/>many generations will <a id="_idIndexMarker483"/>pass in the 15-minute time frame depends on your hardware, but once finished, you should see something similar to this:</p><div id="_idContainer177" class="IMG---Figure"><img src="Images/B16954_08_13.jpg" alt="Figure 8.13 – TPOT output after training&#13;&#10;" width="1372" height="309"/></div><p class="figure-caption">Figure 8.13 – TPOT output after training</p></li>
				<li>Once the training process is complete, you'll have access to the <strong class="source-inline">fitted_pipeline_</strong> property:<p class="source-code">clf.fitted_pipeline_</p><p>It's a pipeline object that can be exported for later use. Here's what it should look like (keep in mind that you could see something different on your machine):</p><div id="_idContainer178" class="IMG---Figure"><img src="Images/B16954_08_14.jpg" alt="Figure 8.14 – TPOT fitted pipeline&#13;&#10;" width="1231" height="342"/></div><p class="figure-caption">Figure 8.14 – TPOT fitted pipeline</p></li>
				<li>To <a id="_idIndexMarker484"/>demonstrate how this <a id="_idIndexMarker485"/>pipeline works, please take a look at the following code snippet. It calls the <strong class="source-inline">predict()</strong> function of the <strong class="source-inline">fitted_pipeline_</strong> property with a 2D array of input data, representing a single flower species:<p class="source-code">clf.fitted_pipeline_.predict([[5.1, 3.5, 0.2, 3.4]])</p><p>The results are displayed in the following figure:</p><div id="_idContainer179" class="IMG---Figure"><img src="Images/B16954_08_15.jpg" alt="Figure 8.15 – TPOT prediction&#13;&#10;" width="159" height="36"/></div><p class="figure-caption">Figure 8.15 – TPOT prediction</p><p>Remember our remapping strategy from a couple of pages ago? <strong class="source-inline">0</strong> indicates that this species was classified as <strong class="source-inline">setosa</strong>.</p></li>
				<li>The final step we have to do is save the predictive capabilities of this model to a file. The <strong class="source-inline">joblib</strong> library makes this step easy to do, as you just have to call the <strong class="source-inline">dump()</strong> function to save the model and the <strong class="source-inline">load()</strong> function to load the model.<p>Here's a quick demonstration. The goal is to save the <strong class="source-inline">fitted_pipeline_</strong> property to a file called <strong class="source-inline">iris.model</strong>. You can use the following code to do so:</p><p class="source-code">import joblib</p><p class="source-code">joblib.dump(clf.fitted_pipeline_, 'iris.model')</p><p>And that's all there is to it! You'll see the following output once the model is saved to a file:</p></li>
			</ol>
			<div>
				<div id="_idContainer180" class="IMG---Figure">
					<img src="Images/B16954_08_16.jpg" alt="Figure 8.16 – Saving TPOT models&#13;&#10;" width="1026" height="34"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.16 – Saving TPOT models</p>
			<p>Just to <a id="_idIndexMarker486"/>verify that the model <a id="_idIndexMarker487"/>will still work, you can use the <strong class="source-inline">load()</strong> function to load the model in a new variable:</p>
			<p class="source-code">loaded_model = joblib.load('iris.model')</p>
			<p class="source-code">loaded_model.predict([[5.1, 3.5, 0.2, 3.4]])</p>
			<p>The output of the preceding code is shown in the following figure:</p>
			<div>
				<div id="_idContainer181" class="IMG---Figure">
					<img src="Images/B16954_08_17.jpg" alt="Figure 8.17 – Prediction of a saved model&#13;&#10;" width="995" height="33"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.17 – Prediction of a saved model</p>
			<p>And that's how easy it is to save machine learning models for later use. We now have everything needed to deploy this model, so let's do that next.</p>
			<p>The model deployment process will be quite similar to what we've done previously with <strong class="source-inline">Flask</strong> and <strong class="source-inline">Flask-RESTful</strong>. Before proceeding to the step-by-step guide, you should create a directory for your API with the following directory/file structure:</p>
			<div>
				<div id="_idContainer182" class="IMG---Figure">
					<img src="Images/B16954_08_18.jpg" alt="Figure 8.18 – API directory structure&#13;&#10;" width="746" height="107"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.18 – API directory structure</p>
			<p>As you can see, the root folder is called <strong class="source-inline">api</strong> and it has two Python files inside – <strong class="source-inline">app.py</strong> and <strong class="source-inline">helpers.py</strong>. The folder also has another folder for storing the model trained previously.</p>
			<p>Let's build <a id="_idIndexMarker488"/>the API one step at a time next:</p>
			<ol>
				<li value="1">Let's start <a id="_idIndexMarker489"/>with the <strong class="source-inline">helpers.py</strong> file. The goal of this Python file is to remove all calculations and data operations from <strong class="source-inline">app.py</strong>. The ladder is used only to declare and manage the API itself, and everything else is performed elsewhere.<p>The <strong class="source-inline">helpers.py</strong> file will have two functions – <strong class="source-inline">int_to_species(in_species)</strong> and <strong class="source-inline">predict_single(model, X)</strong>. </p><p>The goal of the first function is to reverse our previously declared mappings and to return the actual flower species name given the integer representation. Here's a concrete list of strings returned when given the integer input:</p><p>a) 0 – <strong class="source-inline">setosa</strong></p><p>b) 1 – <strong class="source-inline">virginica</strong></p><p>c) 2 – <strong class="source-inline">versicolor</strong></p><p>If some other number is passed, an empty string is returned. You can find the code for this function as follows:</p><p class="source-code">def int_to_species(in_species):</p><p class="source-code">    if in_species == 0:</p><p class="source-code">        return 'setosa'</p><p class="source-code">    if in_species == 1:</p><p class="source-code">        return 'virginica'</p><p class="source-code">    if in_species == 2:</p><p class="source-code">        return 'versicolor'</p><p>On to the <strong class="source-inline">predict_single(model, X)</strong> function now. It aims to return a prediction and its probability given the model and a list of input values. The function also makes the following checks:</p><p>a) Is <strong class="source-inline">X</strong> a list? If not, raise an exception.</p><p>b) Does <strong class="source-inline">X</strong> have four items (sepal length, sepal width, petal length, and petal width)? If not, raise an exception.</p><p>These <a id="_idIndexMarker490"/>checks are required <a id="_idIndexMarker491"/>because we don't want bad or misformatted data going in our model and crashing the API.</p><p>If all of the checks pass, the prediction and probability are returned to the user as a dictionary, alongside the entered data for each parameter. Here's how to implement this function:</p><p class="source-code">def predict_single(model, X):</p><p class="source-code">    if type(X) is not list:</p><p class="source-code">        raise Exception('X must be of list data type!')</p><p class="source-code">    if len(X) != 4:</p><p class="source-code">        raise Exception('X must contain 4 values - \</p><p class="source-code">sepal_length, sepal_width, petal_length, petal_width')</p><p class="source-code">    prediction = model.predict([X])[0]</p><p class="source-code">    prediction_probability =\</p><p class="source-code">model.predict_proba([X])[0][prediction]</p><p class="source-code">    return {</p><p class="source-code">        'In_SepalLength': X[0],</p><p class="source-code">        'In_SepalWidth': X[1],</p><p class="source-code">        'In_PetalLength': X[2],</p><p class="source-code">        'In_PetalWidth': X[3],</p><p class="source-code">        'Prediction': int_to_species(prediction),</p><p class="source-code">        'Probability': prediction_probability</p><p class="source-code">    }</p><p>Here's <a id="_idIndexMarker492"/>one example of calling the <strong class="source-inline">predict_single()</strong> function:</p><p class="source-code">predict_single(</p><p class="source-code">    model=joblib.load('api/model/iris.model'), </p><p class="source-code">    X=[5.1, 3.5, 0.2, 3.4]</p><p class="source-code">)</p><p>The <a id="_idIndexMarker493"/>results are shown in the following figure:</p><div id="_idContainer183" class="IMG---Figure"><img src="Images/B16954_08_19.jpg" alt="Figure 8.19 – Results of calling the predict_single() function&#13;&#10;" width="546" height="100"/></div><p class="figure-caption">Figure 8.19 – Results of calling the predict_single() function</p></li>
				<li>On to <strong class="source-inline">app.py</strong> now. If you have been following along from the beginning of this chapter, coding out this file will be a piece of cake. The goal is to have the model loaded at all times and to trigger the <strong class="source-inline">post()</strong> method of the <strong class="source-inline">PredictSpecies</strong> class when a <strong class="source-inline">/predict</strong> endpoint is called. You'll have to implement both the class and the method yourself.<p>The user has to pass input data as JSON. To be more precise, every flower measurement value is passed separately, so the user will have to specify values for four parameters in total.</p><p>If everything <a id="_idIndexMarker494"/>goes well, the <strong class="source-inline">predict_single()</strong> function from <strong class="source-inline">helpers.py</strong> is called, and the results are returned to the user.</p><p>Let's take <a id="_idIndexMarker495"/>a look at the implementation of <strong class="source-inline">app.py</strong>:</p><p class="source-code">import joblib </p><p class="source-code">import warnings</p><p class="source-code">from flask import Flask, request, jsonify</p><p class="source-code">from flask_restful import Resource, Api</p><p class="source-code">from helpers import predict_single</p><p class="source-code">warnings.filterwarnings('ignore')</p><p class="source-code">app = Flask(__name__)</p><p class="source-code">api = Api(app)</p><p class="source-code">model = joblib.load('model/iris.model')</p><p class="source-code">class PredictSpecies(Resource):</p><p class="source-code">    @staticmethod</p><p class="source-code">    def post():</p><p class="source-code">        user_input = request.get_json()</p><p class="source-code">        sl = user_input['SepalLength']</p><p class="source-code">        sw = user_input['SepalWidth']</p><p class="source-code">        pl = user_input['PetalLength']</p><p class="source-code">        pw = user_input['PetalWidth']</p><p class="source-code">        prediction =\</p><p class="source-code">predict_single(model=model, X=[sl, sw, pl, pw])</p><p class="source-code">        return jsonify(prediction)</p><p class="source-code">api.add_resource(PredictSpecies, '/predict')</p><p class="source-code">if __name__ == '__main__':</p><p class="source-code">    app.run(host='0.0.0.0', port=8000)</p></li>
				<li>You now <a id="_idIndexMarker496"/>have everything <a id="_idIndexMarker497"/>needed to run the API. You can do so the same way that you did with the previous APIs, and that is by executing the following line in the terminal:<p class="source-code"><strong class="bold">&gt; python app.py</strong></p><p>If everything went well, you'll get the following message:</p><div id="_idContainer184" class="IMG---Figure"><img src="Images/B16954_08_20.jpg" alt="Figure 8.20 – Running the API&#13;&#10;" width="679" height="117"/></div><p class="figure-caption">Figure 8.20 – Running the API</p></li>
				<li>The API is now running on <strong class="source-inline">http://localhost:8000</strong>. We'll use the Postman application to test the API.<p>Here's <a id="_idIndexMarker498"/>the first example:</p></li>
			</ol>
			<div>
				<div id="_idContainer185" class="IMG---Figure">
					<img src="Images/B16954_08_21.jpg" alt="Figure 8.21 – API testing example 1&#13;&#10;" width="670" height="533"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.21 – API testing example 1</p>
			<p>As you <a id="_idIndexMarker499"/>can see, the model is 100% confident that this species belongs to the <strong class="source-inline">setosa</strong> class. Let's try another one:</p>
			<div>
				<div id="_idContainer186" class="IMG---Figure">
					<img src="Images/B16954_08_22.jpg" alt="Figure 8.22 – API testing example 2&#13;&#10;" width="620" height="532"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.22 – API testing example 2</p>
			<p>This has <a id="_idIndexMarker500"/>an identical confidence <a id="_idIndexMarker501"/>level but a different prediction class. Let's mix things up a beat and pass values a bit different than anything in the training set:</p>
			<div>
				<div id="_idContainer187" class="IMG---Figure">
					<img src="Images/B16954_08_23.jpg" alt="Figure 8.23 – API testing example 3&#13;&#10;" width="624" height="534"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.23 – API testing example 3</p>
			<p>As you can see, the model isn't 100% confident this time, as the input data is a lot different from the data seen at training.</p>
			<p>And there <a id="_idIndexMarker502"/>you have it – TPOT model <a id="_idIndexMarker503"/>deployment to localhost! The only thing left to do in this chapter is to bring the model to the cloud and make it accessible from anywhere. Let's do that next.</p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor099"/>Deploying machine learning models to the cloud</h1>
			<p>Cloud <a id="_idIndexMarker504"/>deployment of machine learning <a id="_idIndexMarker505"/>models means creating a cloud virtual machine, transferring our API to it, and running it. It's a tedious process that gets easier with repetition since a lot of steps are involved. If you follow every step precisely from this section, everything will work fine. Just make sure not to miss any minor details:</p>
			<ol>
				<li value="1">To start, head over to <a href="https://portal.aws.amazon.com/billing/signup#/start">https://portal.aws.amazon.com/billing/signup#/start</a> and create an account (assuming you don't already have one). Here's what the website currently looks like (as of February 2021):<div id="_idContainer188" class="IMG---Figure"><img src="Images/B16954_08_24.jpg" alt="Figure 8.24 – AWS registration website&#13;&#10;" width="730" height="691"/></div><p class="figure-caption">Figure 8.24 – AWS registration website</p><p>The registration <a id="_idIndexMarker506"/>process will <a id="_idIndexMarker507"/>take some time, and you will have to enter your credit card information. Don't worry; we'll create entirely free virtual machine instances so you won't be charged a dime.</p></li>
				<li>Once the registration process is complete, click on the <strong class="bold">Launch a virtual machine With EC2</strong> option:<div id="_idContainer189" class="IMG---Figure"><img src="Images/B16954_08_25.jpg" alt="Figure 8.25 – EC2 virtual machine creation&#13;&#10;" width="926" height="350"/></div><p class="figure-caption">Figure 8.25 – EC2 virtual machine creation</p><p>We'll create an Ubuntu 20.04 instance. If it's not immediately visible, type <strong class="source-inline">ubuntu</strong> in the search bar:</p><div id="_idContainer190" class="IMG---Figure"><img src="Images/B16954_08_26.jpg" alt="Figure 8.26 – Ubuntu Server 20.04&#13;&#10;" width="1194" height="286"/></div><p class="figure-caption">Figure 8.26 – Ubuntu Server 20.04</p><p>Once <a id="_idIndexMarker508"/>you click on <strong class="bold">Select</strong>, you'll <a id="_idIndexMarker509"/>have to specify the type. Make sure to select the free version if you don't want to get charged:</p><div id="_idContainer191" class="IMG---Figure"><img src="Images/B16954_08_27.jpg" alt="Figure 2.27 – Ubuntu instance type&#13;&#10;" width="1159" height="389"/></div><p class="figure-caption">Figure 2.27 – Ubuntu instance type</p><p>Next, click on the <strong class="bold">Review and Launch</strong> button. You'll be taken to the following screen:</p><div id="_idContainer192" class="IMG---Figure"><img src="Images/B16954_08_28.jpg" alt="Figure 2.28 – Ubuntu instance confirmation&#13;&#10;" width="1150" height="469"/></div><p class="figure-caption">Figure 2.28 – Ubuntu instance confirmation</p><p>Once <a id="_idIndexMarker510"/>you click on <strong class="bold">Launch</strong>, the <a id="_idIndexMarker511"/>following window will appear. Make sure to select the identical options, but the key pair name is up to you:</p><div id="_idContainer193" class="IMG---Figure"><img src="Images/B16954_08_29.jpg" alt="Figure 8.29 – Ubuntu key pair&#13;&#10;" width="939" height="455"/></div><p class="figure-caption">Figure 8.29 – Ubuntu key pair</p><p>Click on the <strong class="bold">Download Key Pair</strong> button after you enter the details. After the download is complete, you'll be able to click on the <strong class="bold">Launch Instances</strong> button:</p><div id="_idContainer194" class="IMG---Figure"><img src="Images/B16954_08_30.jpg" alt="Figure 8.30 – Launching the Ubuntu instance&#13;&#10;" width="1242" height="317"/></div><p class="figure-caption">Figure 8.30 – Launching the Ubuntu instance</p><p>Finally, after <a id="_idIndexMarker512"/>everything is done, you <a id="_idIndexMarker513"/>can click on the <strong class="bold">View Instances</strong> button:</p><div id="_idContainer195" class="IMG---Figure"><img src="Images/B16954_08_31.jpg" alt="Figure 8.31 – View Instances&#13;&#10;" width="260" height="82"/></div><p class="figure-caption">Figure 8.31 – View Instances</p><p>You will be presented with your created instance immediately. It might take some time before you see that the instance is running, so please be patient:</p><div id="_idContainer196" class="IMG---Figure"><img src="Images/B16954_08_32.jpg" alt="Figure 8.32 – Running instance&#13;&#10;" width="1142" height="228"/></div><p class="figure-caption">Figure 8.32 – Running instance</p></li>
				<li>To obtain the connection parameter, click on the instance row and select the <strong class="bold">Actions</strong> | <strong class="bold">Connect</strong> option, as shown:<div id="_idContainer197" class="IMG---Figure"><img src="Images/B16954_08_33.jpg" alt="Figure 8.33 – Obtaining instance connection parameters&#13;&#10;" width="1117" height="267"/></div><p class="figure-caption">Figure 8.33 – Obtaining instance connection parameters</p><p>On the <a id="_idIndexMarker514"/>screen that follows, you'll <a id="_idIndexMarker515"/>see the instance name and dedicated IP address. Here's what it should look like:</p><div id="_idContainer198" class="IMG---Figure"><img src="Images/B16954_08_34.jpg" alt="Figure 8.34 – Instance connection parameters&#13;&#10;" width="895" height="505"/></div><p class="figure-caption">Figure 8.34 – Instance connection parameters</p><p>You now have almost everything needed to connect to the instance and transfer the API code. The last piece of the puzzle is the conversion of the key pair <strong class="source-inline">.pem</strong> file to a <strong class="source-inline">.ppk</strong> file. If you're on Windows, this conversion can be made by downloading <a id="_idIndexMarker516"/>the <em class="italic">PuTTYgen</em> app: <a href="https://www.puttygen.com">https://www.puttygen.com</a>. If you're on Mac, you can install it directly through Homebrew:</p><p class="source-code"><strong class="bold">&gt; brew install putty</strong></p><p>Once installed, execute the following terminal command to make the conversion:</p><p class="source-code"><strong class="bold">&gt; puttygen TPOT_Book_KeyPair.pem -o TPOT_Book_PrivateKey.ppk</strong></p><p>Once the <a id="_idIndexMarker517"/>conversion is made, you can open a file transfer tool <a id="_idIndexMarker518"/>such as <em class="italic">FileZilla</em> (<a href="https://filezilla-project.org">https://filezilla-project.org</a>) and <a id="_idIndexMarker519"/>establish a connection as shown:</p><div id="_idContainer199" class="IMG---Figure"><img src="Images/B16954_08_35.jpg" alt="Figure 8.35 – FileZilla connection&#13;&#10;" width="730" height="650"/></div><p class="figure-caption">Figure 8.35 – FileZilla connection</p><p>Just make sure to point to the <strong class="source-inline">.ppk</strong> file in the <strong class="bold">Key file</strong> option. After the <strong class="bold">Connect</strong> button is pressed, you'll see the following:</p><div id="_idContainer200" class="IMG---Figure"><img src="Images/B16954_08_36.jpg" alt="Figure 8.36 – FileZilla host key&#13;&#10;" width="1013" height="447"/></div><p class="figure-caption">Figure 8.36 – FileZilla host key</p><p>Just <a id="_idIndexMarker520"/>press <strong class="bold">OK</strong> and you're good <a id="_idIndexMarker521"/>to go. The connection was successful, as visible from the following figure:</p><div id="_idContainer201" class="IMG---Figure"><img src="Images/B16954_08_37.jpg" alt="Figure 8.37 – FileZilla successful connection&#13;&#10;" width="1303" height="466"/></div><p class="figure-caption">Figure 8.37 – FileZilla successful connection</p><p>You can now drag the <strong class="bold">api</strong> folder to the <strong class="bold">ubuntu</strong> folder on the remote virtual machine, as shown here:</p><div id="_idContainer202" class="IMG---Figure"><img src="Images/B16954_08_38.jpg" alt="Figure 8.38 – Transferring API data to a remote virtual machine&#13;&#10;" width="721" height="304"/></div><p class="figure-caption">Figure 8.38 – Transferring API data to a remote virtual machine</p><p>Before further configuring and starting the API, let's explore how you can obtain the connection through the terminal.</p></li>
				<li>Open up <a id="_idIndexMarker522"/>a new terminal window <a id="_idIndexMarker523"/>right where your <strong class="source-inline">.pem</strong> file is stored. Once there, execute the following command to change the permission:<p class="source-code"><strong class="bold">&gt; chmod 400 TPOT_Book_KeyPair.pem</strong></p><p>Now you have everything needed to establish a secure connection. The following command establishes a connection on my machine:</p><p class="source-code"><strong class="bold">&gt; ssh -i "TPOT_Book_KeyPair.pem" ubuntu@ec2-18-220-113-224.us-east-2.compute.amazonaws.com</strong></p><p>Please make sure to replace <strong class="source-inline">TPOT_Book_KeyPair.pem</strong> with your filename and also make sure to write your instance name after <strong class="source-inline">ubuntu@</strong>. If you did everything correctly, you should see the following in your terminal:</p><div id="_idContainer203" class="IMG---Figure"><img src="Images/B16954_08_39.jpg" alt="Figure 8.39 – Accessing the Ubuntu virtual machine through the terminal&#13;&#10;" width="535" height="80"/></div><p class="figure-caption">Figure 8.39 – Accessing the Ubuntu virtual machine through the terminal</p><p>As you can see, the <strong class="source-inline">/api</strong> folder is visible to use from the virtual machine. </p><p>While we're here, let's configure our Python environment. We need to install <strong class="source-inline">pip</strong>, but to do so, we first have to update the Linux repositories. The following command does both:</p><p class="source-code"><strong class="bold">&gt; sudo apt-get update &amp;&amp; sudo apt-get install python3-pip</strong></p><p>Finally, let's install every required library. Here's the command for doing so within a virtual environment:</p><p class="source-code"><strong class="bold">&gt; pip3 install virtualenv</strong></p><p class="source-code"><strong class="bold">&gt; virtualenv tpotapi_env</strong></p><p class="source-code"><strong class="bold">&gt; source tpotapi_env/bin/activate</strong></p><p class="source-code"><strong class="bold">&gt; pip3 install joblib flask flask-restful sklearn tpot</strong></p><p>There are a few steps you still need to complete before starting the API, such as managing security.</p></li>
				<li>If you <a id="_idIndexMarker524"/>were to run the API now, no errors <a id="_idIndexMarker525"/>would be raised, but you wouldn't be able to access the API in any way. That's because we need to "fix" a couple of permissions first. Put simply, our API needs to be accessible from anywhere, and it isn't by default.<p>To start, navigate to <strong class="bold">Network &amp; Security</strong> | <strong class="bold">Security Groups</strong> on the sidebar:</p><div id="_idContainer204" class="IMG---Figure"><img src="Images/B16954_08_40.jpg" alt="Figure 8.40 – Security Groups&#13;&#10;" width="190" height="180"/></div><p class="figure-caption">Figure 8.40 – Security Groups</p><p>You should see the <strong class="bold">Create security group</strong> button in the top-right corner of the browser window:</p><div id="_idContainer205" class="IMG---Figure"><img src="Images/B16954_08_41.jpg" alt="Figure 8.41 – The Create security group button&#13;&#10;" width="590" height="41"/></div><p class="figure-caption">Figure 8.41 – The Create security group button</p><p>Once the <a id="_idIndexMarker526"/>new window pops up, you'll <a id="_idIndexMarker527"/>have to specify a couple of things. The <strong class="bold">Security group name</strong> and <strong class="bold">Description</strong> fields are entirely arbitrary. On the other hand, the <strong class="bold">Inbound rules</strong> group isn't arbitrary. You'll have to add a new rule with the following options:</p><p>a) <strong class="bold">Type</strong>: <strong class="bold">All traffic</strong></p><p>b) <strong class="bold">Source</strong>: <strong class="bold">Anywhere</strong></p><p>Refer to the following figure for more information:</p><div id="_idContainer206" class="IMG---Figure"><img src="Images/B16954_08_42.jpg" alt="Figure 8.42 – Creating a security group&#13;&#10;" width="1025" height="528"/></div><p class="figure-caption">Figure 8.42 – Creating a security group</p><p>After specifying the correct values, you have to scroll down to the end of the screen and click on the <strong class="bold">Create security group</strong> option:</p><div id="_idContainer207" class="IMG---Figure"><img src="Images/B16954_08_43.jpg" alt="Figure 8.43 – Verifying a security group&#13;&#10;" width="741" height="50"/></div><p class="figure-caption">Figure 8.43 – Verifying a security group</p><p>We're not done yet. The next step is to go to the <strong class="bold">Network &amp; Security</strong> | <strong class="bold">Network Interfaces</strong> option on the sidebar:</p><div id="_idContainer208" class="IMG---Figure"><img src="Images/B16954_08_44.jpg" alt="Figure 8.44 – The Network Interfaces option&#13;&#10;" width="648" height="286"/></div><p class="figure-caption">Figure 8.44 – The Network Interfaces option</p><p>Once <a id="_idIndexMarker528"/>there, right-click the only <a id="_idIndexMarker529"/>available network interface (assuming this is your first time in the AWS console) and select the <strong class="bold">Change security groups</strong> option:</p><div id="_idContainer209" class="IMG---Figure"><img src="Images/B16954_08_45.jpg" alt="Figure 8.45 – Changing security groups&#13;&#10;" width="820" height="399"/></div><p class="figure-caption">Figure 8.45 – Changing security groups</p><p>The whole point of this is to assign the "access from anywhere" rule to our virtual machine. Once a window pops up, select the previously declared security group from the dropdown of options:</p><div id="_idContainer210" class="IMG---Figure"><img src="Images/B16954_08_46.jpg" alt="Figure 8.46 – Selecting the security group&#13;&#10;" width="575" height="152"/></div><p class="figure-caption">Figure 8.46 – Selecting the security group</p><p>Once <a id="_idIndexMarker530"/>added, click on the <strong class="bold">Save</strong> button <a id="_idIndexMarker531"/>to save this association:</p><div id="_idContainer211" class="IMG---Figure"><img src="Images/B16954_08_47.jpg" alt="Figure 8.47 – Saving security associations&#13;&#10;" width="818" height="239"/></div><p class="figure-caption">Figure 8.47 – Saving security associations</p></li>
				<li>Configuring our virtual machine was quite a lengthy process, but you can now finally start the <strong class="source-inline">Flask</strong> application (REST API). To do so, navigate to the <strong class="source-inline">/api</strong> folder and execute the following:<p class="source-code"><strong class="bold">&gt; python3 app.py</strong></p><p>You should see the following, by now a familiar message:</p><div id="_idContainer212" class="IMG---Figure"><img src="Images/B16954_08_48.jpg" alt="Figure 8.48 – Starting the REST API through the terminal&#13;&#10;" width="1508" height="292"/></div><p class="figure-caption">Figure 8.48 – Starting the REST API through the terminal</p><p>And that's it! The API is now running, and we can test whether it works properly.</p></li>
				<li>Before <a id="_idIndexMarker532"/>making a request through Postman, we first need to find the complete URL for our remote virtual machine. You can <a id="_idIndexMarker533"/>find yours by right-clicking the instance under <strong class="bold">Instances</strong> and clicking on the <strong class="bold">Connect</strong> option. There, you'll see the <strong class="bold">SSH client</strong> tab:</li>
			</ol>
			<div>
				<div id="_idContainer213" class="IMG---Figure">
					<img src="Images/B16954_08_49.jpg" alt="Figure 8.49 – Virtual machine URL&#13;&#10;" width="705" height="433"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.49 – Virtual machine URL</p>
			<p>Now we know the complete URL: <strong class="source-inline">http://ec2-18-220-113-224.us-east-2.compute.amazonaws.com:8000/predict</strong>. The procedure from now is identical to as it was on localhost, as visible in the following figure:</p>
			<div>
				<div id="_idContainer214" class="IMG---Figure">
					<img src="Images/B16954_08_50.jpg" alt="Figure 8.50 – Testing our deployed API&#13;&#10;" width="1242" height="1055"/>
				</div>
			</div>
			<p class="figure-caption">Figure 8.50 – Testing our deployed API</p>
			<p>As you <a id="_idIndexMarker534"/>can see, the connection <a id="_idIndexMarker535"/>went through, and the API returned a response just as it did with the locally deployed version. </p>
			<p>And there you have it – the complete procedure for deploying machine learning models to an AWS virtual machine. The process can be quite tedious to do and even tricky if this is your first time. It will get easier as you deploy more and more machine learning models, as the procedure is identical.</p>
			<p>You could play around with the permissions if you don't want your API to be accessible from anywhere by anyone, but that's beyond the scope of this book. This chapter is more <a id="_idIndexMarker536"/>or less over – great work! What <a id="_idIndexMarker537"/>follows is a summary of everything learned and then yet another interesting, hands-on chapter.</p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor100"/>Summary</h1>
			<p>This chapter was the longest one so far and quite intensive with the hands-on tasks. You've hopefully managed to follow along and learned how machine learning models built with TPOT can be deployed – both locally and to the cloud.</p>
			<p>You are now capable of deploying any sort of machine learning model built with Python. Besides, you also know how to deploy basic Python web applications, provided that you have the necessary knowledge of frontend technologies, such as HTML, CSS, and JavaScript. We didn't dive into this area, as it's beyond the scope of this book.</p>
			<p>In the following chapter, <a href="B16954_09_Final_SK_ePub.xhtml#_idTextAnchor102"><em class="italic">Chapter 9</em></a>, <em class="italic">Using the Deployed TPOT Model in Production</em>, you'll learn how to build a basic application around this REST API. To be more precise, you'll learn how to make a simple and decent-looking web interface that predicts flower species based on the input data. But before that, you'll practice making a request to our API with Python.</p>
			<p>As always, feel free to study model deployment in more detail, as AWS isn't the only option. There are many cloud providers that offer some sort of a free tier, and AWS is just a single fish in the pond. </p>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor101"/>Question</h1>
			<ol>
				<li value="1">Why do we need (and want) model deployment?</li>
				<li>What's the role of REST APIs in model deployment? </li>
				<li>Name a couple of Python libraries that can be used to deploy machine learning models.</li>
				<li>What's the difference between the GET and POST request types?</li>
				<li>What's the general idea behind the <strong class="source-inline">joblib</strong> library in Python?</li>
				<li>Explain in your own words what a virtual machine is.</li>
				<li>Which free tool can be used to test REST APIs?</li>
			</ol>
		</div>
	</div></body></html>