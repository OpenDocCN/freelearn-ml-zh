- en: '*Chapter 8*: Training Models with MLflow'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn about creating production-ready training jobs
    with MLflow. In the bigger scope of things, we will focus on how to move from
    the training jobs in the notebook environment that we looked at in the early chapters
    to a standardized format and blueprint to create training jobs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will look at the following sections in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating your training project with MLflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the training job
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying the model in the Model Registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Docker image for your training job
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's time to add to the pyStock **machine learning** (**ML**) platform training
    infrastructure to take **proof-of-concept** models created in the workbench developed
    in [*Chapter 3*](B16783_03_Final_SB_epub.xhtml#_idTextAnchor066), *Your Data Science
    Workbench to a Production Environment*.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will be developing a training project that runs periodically
    or when triggered by a dataset arrival. The main output of the training project
    is a new model that is generated as output and registered in the Model Registry
    with different details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an overview of the training workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Training workflow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0014.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 – Training workflow
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 8.1* describes at a high level the general process, whereby a training
    dataset arrives and a training job kicks in. The training job produces a model
    that is finally evaluated and deployed in the Model Registry. Systems upstream
    are now able to deploy inference **application programming interfaces** (**APIs**)
    or batch jobs with the newly deployed model.'
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following prerequisites:'
  prefs: []
  type: TYPE_NORMAL
- en: The latest version of Docker installed on your machine. If you don't already
    have it installed, please follow the instructions at [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of Docker Compose installed—please follow the instructions
    at [https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to Git in the command line, and installed as described at [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a Bash terminal (Linux or Windows).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to a browser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3.5+ installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The latest version of your ML library installed locally as described in [*Chapter
    4*](B16783_04_Final_SB_epub.xhtml#_idTextAnchor081), *Experiment Management in
    MLflow*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating your training project with MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You receive a specification from a data scientist based on the **XGBoost** model
    being ready to move from a **proof-of-concept** to a production phase.
  prefs: []
  type: TYPE_NORMAL
- en: We can review the original Jupyter notebook from which the model was registered
    initially by the data scientist, which is a starting point to start creating an
    ML engineering pipeline. After initial prototyping and training in the notebook,
    they are ready to move to production.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some companies go directly to productionize the notebooks themselves and this
    is definitely a possibility, but it becomes impossible for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: It's hard to version notebooks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's hard to unit-test the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's unreliable for long-running tests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these three distinct phases, we ensure reproducibility of the training
    data-generation process and visibility and clear separation of the different steps
    of the process.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by organizing our MLflow project into steps and creating placeholders
    for each of the components of the pipeline, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start a new folder in your local machine and name this `pystock-training`.
    Add the `MLProject` file, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following `conda.yaml` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can add now a sample `main.py` file to the folder to ensure that the basic
    structure of the project is working, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Test the basic structure by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This command will build your project based on the environment created by your
    `conda.yaml` file and run the basic project you just created. It should error
    out, as we need to add the missing files.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: At this stage, we have the basic blocks of the MLflow project of the data pipeline
    that we will be building in this chapter. You will next fill in the Python file
    to train the data.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the training job
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use the training data produced in the previous chapter. The assumption
    here is that an independent job populates the data pipeline in a specific folder.
    In the book's GitHub repository, you can look at the data in https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter08/psystock-training/data/training/data.csv.
  prefs: []
  type: TYPE_NORMAL
- en: We will now create a `train_model.py` file that will be responsible for loading
    the training data to fit and produce a model. Test predictions will be produced
    and persisted in the environment so that other steps of the workflow can use the
    data to evaluate the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The file produced in this section is available at the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter08/psystock-training/train_model.py[:](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Mlflow/blob/master/chapter_8/psytock-training/train_model.py  )
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start by importing the relevant packages. In this case, we will need
    `pandas` to handle the data, `xgboost` to run the training algorithm, and—obviously—m`lflow`
    to track and log the data run. Here is the code you''ll need to do this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, you should add a function to execute the split of the data relying on
    `train_test_split` from `sklearn`. Our chosen split is 33/67% for testing and
    training data respectively. We specify the `random_state` parameter in order to
    make the process reproducible, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This function returns the train and test dataset and the targets for each dataset.
    We rely on the `xgboost` matrix `xgb.Dmatrix` data format to efficiently load
    the training and testing data and feed the `xgboost.train` method. The code is
    illustrated in the following snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We also use this moment to produce test predictions using the `model.predict`
    method. Some data transformation is executed to discretize the probability of
    the stock going up or down and transform it into `0` (not going up) or `1` (going
    up), as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As a last step, we will persist the test predictions on the `result` variable.
    We drop the index so that the saved `pandas` DataFrame doesn''t include the index
    when running the `result.to_csv` command, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can look at your MLflow **user interface** (**UI**) by running the following
    command to see the metrics logged:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should be able to look at your MLflow UI, available to view in the following
    screenshot, where you can see the persisted model and the different model information
    of the just-trained model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Training model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0025.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Training model
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, we have our model saved and persisted on the artifacts of our
    MLflow installation. We will next add a new step to our workflow to produce the
    metrics of the model just produced.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now move on to collect evaluation metrics for our model, to add to the
    metadata of the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will work on the `evaluate_model.py` file. You can follow along by working
    in an empty file or by going to https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/blob/master/Chapter08/psystock-training/evaluate_model.py.
    Proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the relevant packages—`pandas` and `mlflow—f`or reading and running
    the steps, respectively. We will rely on importing a selection of model-evaluation
    metrics available in `sklearn` for classification algorithms, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At this stage, we have imported all the functions we need for the metrics we
    need to extract in the next section.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, you should add a `classification_metrics` function to generate metrics
    based on a `df` parameter. The assumption is that the DataFrame has two columns:
    `y_pred`, which is the target predicted by the training model, and `y_test`, which
    is the target present on the training data file. Here is the code you will need:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The preceding function produces a `metrics` dictionary based on the predicted
    values and the test predictions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'After creating this function that generates the metrics, we need to use `start_run`,
    whereby we basically read the prediction test file and run the metrics. We post
    all the metrics in `mlflow.log_metrics` method to log a dictionary of multiple
    metrics at the same time. The code is illustrated in the following snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can look again at the MLflow UI, where we can see the different metrics
    just persisted. You can view the output here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Training model metrics persisted'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0035.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.3 – Training model metrics persisted
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, we have a model evaluation for our training job, providing metrics
    and information to model implementers/deployers. We will now move on to the last
    step of the training process, which is to register the model in the MLflow Model
    Registry so that it can be deployed in production.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the model in the Model Registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, you should add the `register_model.py` function to register the model
    in the Model Registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is as simple as executing the `mlflow.register_model` method with the
    **Uniform Resource Identifier** (**URI**) of the model and the name of the model.
    Basically, a model will be created if it doesn''t already exist. If it''s already
    in the registry, a new version will be added, allowing the deployment tools to
    look at the models and trace the training jobs and metrics. It also allows a decision
    to be made as to whether to promote the model to production or not. The code you''ll
    need is illustrated in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following screenshot, the registered model is presented, and we can
    change state and move into staging or production, depending on our workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Registered model'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/image0045.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.4 – Registered model
  prefs: []
  type: TYPE_NORMAL
- en: After having registered our model, we will now move on to prepare a Docker image
    of our training job that can be used in a public cloud environment or in a Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Docker image for your training job
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A Docker image is, in many contexts, the most critical deliverable of a model
    developer to a more specialized systems infrastructure team in production for
    a training job. The project is contained in the following folder of the repository:
    https://github.com/PacktPublishing/Machine-Learning-Engineering-with-MLflow/tree/master/Chapter08/psystock-training-docker.
    In the following steps, we will produce a ready-to-deploy Docker image of the
    code produced:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You need to set up a Docker file in the root folder of the project, as shown
    in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will start by building and training the image by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can run your image, specifying your tracking server `$TRACKING_SERVER_URI`
    value to reach [http://host.docker.internal:5000](http://host.docker.internal:5000),
    as illustrated in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At this stage, we have concluded all the steps of our complete training workflow.
    In the next chapter, we will proceed to deploy the different components of the
    platform in production environments, leveraging all the MLflow projects created
    so far.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced the concepts and different features in terms
    of using MLflow to create production training processes.
  prefs: []
  type: TYPE_NORMAL
- en: We started by setting up the basic blocks of the MLflow training project and
    followed along throughout the chapter to, in sequence, train a model, evaluate
    a trained model, and register a trained model. We also delved into the creation
    of a ready-to-use image for your training job.
  prefs: []
  type: TYPE_NORMAL
- en: This was an important component of the architecture, and it will allow us to
    build an end-to-end production system for our ML system in production. In the
    next chapter, we will deploy different components and illustrate the deployment
    process of models.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to further your knowledge, you can consult the official documentation
    at the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.mlflow.org/docs/latest/projects.html](https://www.mlflow.org/docs/latest/projects.html)'
  prefs: []
  type: TYPE_NORMAL
