- en: Using ONNX with ML.NET
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have completed our deep dive into using TensorFlow with a **Windows
    Presentation Foundation** (**WPF**) application and ML.NET, it is now time to
    dive into using **Open Neural Network eXchange** (**ONNX**) with ML.NET. Specifically,
    in this final chapter, we will review what ONNX is, in addition to creating a
    new example application with a pre-trained ONNX model called **YOLO**. This application
    will build on the previous chapter and show the bounding boxes of the objects
    that the model detects. In addition, we will close out the chapter with suggestions
    on improving the example, for it to either become a production-grade application
    or be integrated into a production application.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down ONNX and YOLO
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating the ONNX object detection application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring additional production application enhancements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breaking down ONNX and YOLO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned in [Chapter 1](b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml), *Getting
    Started with Machine Learning and ML.NET,* the ONNX standard is widely regarded
    within the industry as a truly universal format across machine learning frameworks.
    In the next two sections, we will review what ONNX provides, in addition to the
    YOLO model that will drive our example in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing ONNX
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**ONNX** was created as a way for a less locked-down and free-flowing process
    when working with either pre-trained models or training models across frameworks.
    By providing an open format for frameworks to export to, ONNX allows interoperability,
    and thereby promotes experimentation that would have otherwise been prohibitive
    due to the nature of proprietary formats being used in almost every framework.'
  prefs: []
  type: TYPE_NORMAL
- en: Currently, supported frameworks include TensorFlow, XGBoost, and PyTorch—in
    addition to ML.NET, of course.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to deep dive into ONNX further, please check out their website: [https://onnx.ai/index.h](https://onnx.ai/index.html)[tml](https://onnx.ai/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: The YOLO ONNX model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building on the work that was performed in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml),
    *TensorFlow with ML.NET*, in which we used the pre-trained Inception model, in
    this chapter, we are going to use the pre-trained YOLO model. This model provides
    very fast and accurate object detection, meaning it can find multiple objects
    within an image with a certain level of confidence. This differs from the last
    chapter's model that provided a pure image classification, such as water or food.
  prefs: []
  type: TYPE_NORMAL
- en: 'To help visualize the difference between the two models, take the previous
    chapter''s TensorFlow model that classified water, and compare that to this chapter''s
    object detection of a car, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1ab6cee-dd3b-4f28-88ee-079e9a8547ff.png)'
  prefs: []
  type: TYPE_IMG
- en: Object detection within images (and video) has been increasing in demand due
    to the significantly increased amount of images on the internet and the need for
    security. Imagine a crowded environment such as a football stadium, in particular
    by the front gates. Security guards patrol and monitor this area; however, like
    you, they are only human and can only glance at so many people with a certain
    level of accuracy. Applying object detection with machine learning in real time
    to pick up on weapons or large bags could then be used to alert the security guards
    to go after a suspect.
  prefs: []
  type: TYPE_NORMAL
- en: The YOLO model itself comes in two main forms—a tiny and a full model. For the
    scope of this example, we will be using the smaller of the models (~60 MB) that
    can classify 20 objects found within an image. The tiny model is comprised of
    nine convolutional layers and six max-pooling layers. The full model can classify
    thousands of objects and, given the proper hardware (namely, **graphics processing
    units** (**GPUs**)), can run faster than real-time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram depicts how the YOLO model works (and neural networks,
    to a degree):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72db35ce-7a4d-42ef-a52b-8b60d333a7a8.png)'
  prefs: []
  type: TYPE_IMG
- en: Effectively, the image (or images) is converted to 3 x 416 x 416 images. The
    3 component represents the **Red-Green-Blue** (**RGB**) values. The 416 values
    represent the width and height of the resized image. This input layer is then
    inputted into the hidden layers of the model. For the Tiny YOLO v2 model that
    we are using in this chapter, there are a total of 15 layers before outputting
    the layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'To deep dive further into the YOLO model, please read this paper: [https://arxiv.org/pdf/1612.08242.pdf](https://arxiv.org/pdf/1612.08242.pdf).'
  prefs: []
  type: TYPE_NORMAL
- en: Creating the ONNX object detection application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned earlier, the application we will be creating is an object detection
    application using a pre-trained ONNX model. Using the application we developed
    in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml), *Using TensorFlow
    with ML.NET* as a starting point, we will add in support for bounding boxes overlaid
    on top of the image when the model categorizes objects of which it is aware. The
    usefulness of this to the general public is in the various applications image
    object detection provides. Imagine that you are working on a project for the police
    or intelligence community, where they have images or videos and want to detect
    weapons. Utilizing the YOLO model with ML.NET, as we are going to show, would
    make that process very easy.
  prefs: []
  type: TYPE_NORMAL
- en: As with previous chapters, the completed project code, pre-trained model, and
    project files can be downloaded here: [https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter13](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter13).
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the project architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building on the project architecture and code we created in previous chapters,
    the architecture we will be reviewing is enhanced to be more structured and usable
    by an end user.
  prefs: []
  type: TYPE_NORMAL
- en: 'As in some of the previous chapters, the following two additional NuGet packages
    are required if you want to utilize an ONNX model and perform object detection:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Microsoft.ML.ImageAnalytics`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Microsoft.ML.OnnxTransformer`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These NuGet packages are already referenced in the included sample code. Version
    1.3.1 of these packages is used in both the included example on GitHub and throughout
    this chapter's deep dive.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, you will find the Visual Studio Solution Explorer
    view of the project. There are several new additions to the solution, to facilitate
    the production use case we are targeting. We will review in detail each of the
    new files in the following solution screenshot later on in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bda2449a-5aa4-4ac5-acf2-adb328a47f44.png)'
  prefs: []
  type: TYPE_IMG
- en: Due to a current ML.NET limitation as of this writing, ONNX support is only
    provided for scoring using a pre-existing model. The pre-trained model included
    in this example can be found in the `assets/model` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Diving into the code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this application, as noted in the previous section, we are building on top
    of the work completed in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml), *Using
    TensorFlow with ML.NET*. While the **user interface** (**UI**) has not changed
    much, the underlying code to run an ONNX model has. For each file changed—as in
    previous chapters—we will review the changes made and the reasoning behind the
    changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Classes that were changed or added are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`DimensionsBase`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BoundingBoxDimensions`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`YoloBoundingBox`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MainWindow.xaml`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ImageClassificationPredictor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MainWindowViewModel`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is one additional file, with the `YoloOutputParser` class contained within.
    This class is derived from the **Massachusetts Institute of Technology** (**MIT**)
    licensed interface for the `TinyYOLO` ONNX model. Due to the length of this class,
    we will not review it; however, the code does read easily, and if you wish to
    step through a prediction, the flow will be easy to follow.
  prefs: []
  type: TYPE_NORMAL
- en: The DimensionsBase class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `DimensionsBase` class contains the coordinates along with the `Height`
    and `Width` properties, as illustrated in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This base class is used by both the `YoloOutputParser` and `BoundingBoxDimensions` classes
    to reduce code duplication.
  prefs: []
  type: TYPE_NORMAL
- en: The YoloBoundingBox class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `YoloBoundingBox` class provides the container class for what is used to
    populate our bounding boxes when generating them for the overlay, as illustrated
    in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, also defined in this same class file is our `BoundingBoxDimensions`
    class, as shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Again, this inheritance is used to reduce code duplication.
  prefs: []
  type: TYPE_NORMAL
- en: The MainWindow.xaml file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The **Extensible Application Markup Language** (**XAML**) view of our application
    has been simplified to just the button and the image controls, as illustrated
    in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, due to the nature of the bounding boxes and images you may select,
    the window has defaulted to `Maximized`, as can be seen in the following code
    block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: With the XAML changes behind us, let us now dive into the revised `ImageClassificationPredictor`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: The ImageClassificationPredictor class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `ImageClassificationPredictor` class, much like that of [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml),
    *Using TensorFlow with ML.NET*, contains the methods to run our image prediction.
    In this chapter, we will need to make several additional class objects to support
    the running of an ONNX model, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we define the `ImageNetSettings` struct that defines the height and
    width of our network. The YOLO model requires the use of 416 pixels by 416 pixels,
    as illustrated in the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the `TinyYoloModelSettings` struct to be used with the ONNX
    model, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike the previous chapter, where the TensorFlow model was imported and then
    exported as an ML.NET model on the first run, ONNX, as of this writing, does not
    support that path. So, we must load the ONNX model in the `Initialize` method
    every time, as illustrated in the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we modify the `Predict` method extensively to support the `YoloParser`
    call, calling the `DrawBoundingBox` method to overlay the bounding boxes, and
    then returning the bytes of the updated image, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: For brevity, the `DrawBoundingBox` method is not shown here. At a high level,
    the original image is loaded into memory, and the model's bounding boxes are then
    drawn on top of the image, along with the label and confidence. This updated image
    is then converted to a byte array and returned.
  prefs: []
  type: TYPE_NORMAL
- en: The MainWindowViewModel class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Inside the `MainWindowViewModel` class, there are a couple of changes to be
    made due to the nature of the example. We look at them here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the `LoadImageBytes` method now simply takes the parsed image bytes
    and converts them to an `Image` object, like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we modify the `Classify` method to call the `LoadImageBytes` method
    upon successfully running the model, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: With the changes in place for the `Classify` method, that concludes the code
    changes required for this chapter's example. Now, let us run the application!
  prefs: []
  type: TYPE_NORMAL
- en: Running the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To run the application, the process is identical to the sample application
    in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml), *Using TensorFlow
    with ML.NET*. To run the application from within Visual Studio, simply click the
    *play* icon found in the toolbar, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5fe7e40a-4da8-4dc1-8700-6fd1782f74bd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After launching the application, just as in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml),
    *Using TensorFlow with ML.NET*, select an image file, and the model will run.
    For example, I selected an image I took on a vacation to Germany (note the car''s
    bounding boxes), shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be4ac682-f556-4270-a7e6-6dbf82838d48.png)'
  prefs: []
  type: TYPE_IMG
- en: Feel free to try selecting images you have on your hard drive to see the confidence
    level of the detection and how well the bounding boxes are formed around the objects.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring additional production application enhancements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have completed our deep dive, there are a couple of additional elements
    to further enhance the application. A few ideas are discussed in the upcoming
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As noted previously, the importance of logging cannot be stressed enough within
    desktop applications. Logging utilizing NLog ([https://nlog-project.org/](https://nlog-project.org/))
    or a similar open-source project is highly recommended as your application complexity
    increases. This will allow you to log to a file, console, or third-party logging
    solution such as Loggly, at varying levels. For instance, if you deploy this application
    to a customer, breaking down the error level to at least Debug, Warning, and Error
    will be helpful when debugging issues remotely.
  prefs: []
  type: TYPE_NORMAL
- en: Image scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you might have noticed, with images that are quite large (those exceeding
    your screen resolution), the text labeling of the bounding boxes and resizing
    within the image preview is not as easy to read as for, say, a 640 x 480 image.
    One area of improvement here would be to provide hover-over capabilities, resizing
    the image to the dimensions of the window or increasing the font size dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing the full YOLO model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition, another area of improvement for this sample would be to use the
    full YOLO model within an application. As previously noted with the Tiny YOLO
    model used within the example application, only 20 labels are provided. In a production
    application or one in which you wish to build on, using the larger, more complex
    model would be a good choice.
  prefs: []
  type: TYPE_NORMAL
- en: You can download the full YOLO model here: [https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3](https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the course of this chapter, we have deep dived into what goes into the
    ONNX format and what it offers to the community. In addition, we also created
    a brand new detection engine using the pre-trained Tiny YOLO model in ML.NET.
  prefs: []
  type: TYPE_NORMAL
- en: And with that, this concludes your deep dive into ML.NET. Between the first
    page of this book and this one, you have hopefully grown to understand the power
    that ML.NET offers in a very straightforward feature-rich abstraction. With ML.NET
    constantly evolving (much like .NET), there will be no doubt about the evolution
    of ML.NET's feature sets and deployment targets, ranging from embedded **Internet
    of Things** (**IoT**) devices to mobile devices. I hope this book was beneficial
    for your deep dive into ML.NET and machine learning. In addition, I hope that
    as you approach problems in the future, you will first think about whether the
    problem would benefit from utilizing ML.NET to solve the problem more efficiently
    and, potentially, better overall. Given the world's data continually growing at
    exponential rates, the necessity for using non-brute-force/traditional approaches
    will only continue to grow, therefore the skills garnered from this book should
    help you for years to come.
  prefs: []
  type: TYPE_NORMAL
