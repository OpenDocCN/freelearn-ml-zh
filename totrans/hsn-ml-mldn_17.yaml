- en: Using ONNX with ML.NET
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 ML.NET 与 ONNX
- en: Now that we have completed our deep dive into using TensorFlow with a **Windows
    Presentation Foundation** (**WPF**) application and ML.NET, it is now time to
    dive into using **Open Neural Network eXchange** (**ONNX**) with ML.NET. Specifically,
    in this final chapter, we will review what ONNX is, in addition to creating a
    new example application with a pre-trained ONNX model called **YOLO**. This application
    will build on the previous chapter and show the bounding boxes of the objects
    that the model detects. In addition, we will close out the chapter with suggestions
    on improving the example, for it to either become a production-grade application
    or be integrated into a production application.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了使用 TensorFlow 和 ML.NET 的深入探索，现在是时候深入使用 **Open Neural Network eXchange**（**ONNX**）与
    ML.NET 的结合了。具体来说，在本章的最后一部分，我们将回顾 ONNX 是什么，以及创建一个名为 **YOLO** 的预训练 ONNX 模型的新示例应用程序。这个应用程序将基于上一章的内容，并显示模型检测到的对象的边界框。此外，我们将在本章结束时提出改进示例的建议，使其成为生产级应用程序或集成到生产应用程序中。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Breaking down ONNX and YOLO
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解构 ONNX 和 YOLO
- en: Creating the ONNX object detection application
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 ONNX 物体检测应用程序
- en: Exploring additional production application enhancements
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索额外的生产应用增强功能
- en: Breaking down ONNX and YOLO
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解构 ONNX 和 YOLO
- en: As mentioned in [Chapter 1](b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml), *Getting
    Started with Machine Learning and ML.NET,* the ONNX standard is widely regarded
    within the industry as a truly universal format across machine learning frameworks.
    In the next two sections, we will review what ONNX provides, in addition to the
    YOLO model that will drive our example in this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [第 1 章](b8d873e1-9234-4f11-ad94-76df5ffbb228.xhtml) 中所述，*使用 ML.NET 开始机器学习之旅*，ONNX
    标准在业界被广泛认为是一个真正通用的格式，适用于各种机器学习框架。在接下来的两节中，我们将回顾 ONNX 提供的内容，以及将在本章示例中驱动的 YOLO 模型。
- en: Introducing ONNX
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 ONNX
- en: '**ONNX** was created as a way for a less locked-down and free-flowing process
    when working with either pre-trained models or training models across frameworks.
    By providing an open format for frameworks to export to, ONNX allows interoperability,
    and thereby promotes experimentation that would have otherwise been prohibitive
    due to the nature of proprietary formats being used in almost every framework.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**ONNX** 的创建是为了在处理预训练模型或跨框架训练模型时提供一个更开放和自由流动的过程。通过为框架提供一个开放的导出格式，ONNX 允许互操作性，从而促进了由于几乎每个框架中使用的专有格式的性质而可能难以进行的实验。'
- en: Currently, supported frameworks include TensorFlow, XGBoost, and PyTorch—in
    addition to ML.NET, of course.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，支持的平台包括 TensorFlow、XGBoost 和 PyTorch——当然，还包括 ML.NET。
- en: If you want to deep dive into ONNX further, please check out their website: [https://onnx.ai/index.h](https://onnx.ai/index.html)[tml](https://onnx.ai/index.html).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想进一步深入了解 ONNX，请访问他们的网站：[https://onnx.ai/index.h](https://onnx.ai/index.html)[tml](https://onnx.ai/index.html)。
- en: The YOLO ONNX model
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YOLO ONNX 模型
- en: Building on the work that was performed in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml),
    *TensorFlow with ML.NET*, in which we used the pre-trained Inception model, in
    this chapter, we are going to use the pre-trained YOLO model. This model provides
    very fast and accurate object detection, meaning it can find multiple objects
    within an image with a certain level of confidence. This differs from the last
    chapter's model that provided a pure image classification, such as water or food.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 [第 12 章](049e90c4-05b0-466d-af93-d56df861a843.xhtml) 中进行的操作，*使用 ML.NET 的
    TensorFlow*，其中我们使用了预训练的 Inception 模型，在本章中，我们将使用预训练的 YOLO 模型。这个模型提供了非常快速和准确的对象检测，这意味着它可以在图像中找到多个对象，并具有一定的置信度。这与上一章提供的纯图像分类模型不同，例如水或食物。
- en: 'To help visualize the difference between the two models, take the previous
    chapter''s TensorFlow model that classified water, and compare that to this chapter''s
    object detection of a car, as illustrated in the following screenshot:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助可视化两种模型之间的差异，可以将上一章的 TensorFlow 模型（用于分类水）与本章的汽车对象检测进行比较，如下面的截图所示：
- en: '![](img/d1ab6cee-dd3b-4f28-88ee-079e9a8547ff.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d1ab6cee-dd3b-4f28-88ee-079e9a8547ff.png)'
- en: Object detection within images (and video) has been increasing in demand due
    to the significantly increased amount of images on the internet and the need for
    security. Imagine a crowded environment such as a football stadium, in particular
    by the front gates. Security guards patrol and monitor this area; however, like
    you, they are only human and can only glance at so many people with a certain
    level of accuracy. Applying object detection with machine learning in real time
    to pick up on weapons or large bags could then be used to alert the security guards
    to go after a suspect.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于互联网上图像数量的显著增加以及安全需求，图像（和视频）中的目标检测需求不断增加。想象一下拥挤的环境，比如足球场，尤其是前门附近。保安巡逻并监控这个区域；然而，就像你一样，他们也是凡人，只能以一定程度的准确性瞥见那么多人。将机器学习中的目标检测实时应用于检测武器或大包，然后可以用来提醒保安追捕嫌疑人。
- en: The YOLO model itself comes in two main forms—a tiny and a full model. For the
    scope of this example, we will be using the smaller of the models (~60 MB) that
    can classify 20 objects found within an image. The tiny model is comprised of
    nine convolutional layers and six max-pooling layers. The full model can classify
    thousands of objects and, given the proper hardware (namely, **graphics processing
    units** (**GPUs**)), can run faster than real-time.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO模型本身有两种主要形式——小型和完整模型。在本例的范围内，我们将使用较小的模型（约60 MB），它可以对图像中发现的20个对象进行分类。小型模型由九个卷积层和六个最大池化层组成。完整模型可以分类数千个对象，并且，在适当的硬件（特别是**图形处理单元**（**GPU**））的支持下，可以比实时运行得更快。
- en: 'The following diagram depicts how the YOLO model works (and neural networks,
    to a degree):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了YOLO模型的工作原理（以及在一定程度上，神经网络）：
- en: '![](img/72db35ce-7a4d-42ef-a52b-8b60d333a7a8.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/72db35ce-7a4d-42ef-a52b-8b60d333a7a8.png)'
- en: Effectively, the image (or images) is converted to 3 x 416 x 416 images. The
    3 component represents the **Red-Green-Blue** (**RGB**) values. The 416 values
    represent the width and height of the resized image. This input layer is then
    inputted into the hidden layers of the model. For the Tiny YOLO v2 model that
    we are using in this chapter, there are a total of 15 layers before outputting
    the layer.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，图像（或图像）被转换为3 x 416 x 416的图像。3个组件代表**红-绿-蓝**（**RGB**）值。416个值代表调整大小后的图像的宽度和高度。这个输入层随后被输入到模型的隐藏层。对于我们在本章中使用的Tiny
    YOLO v2模型，在输出层之前共有15层。
- en: 'To deep dive further into the YOLO model, please read this paper: [https://arxiv.org/pdf/1612.08242.pdf](https://arxiv.org/pdf/1612.08242.pdf).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解YOLO模型，请阅读这篇论文：[https://arxiv.org/pdf/1612.08242.pdf](https://arxiv.org/pdf/1612.08242.pdf)。
- en: Creating the ONNX object detection application
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建ONNX目标检测应用程序
- en: As mentioned earlier, the application we will be creating is an object detection
    application using a pre-trained ONNX model. Using the application we developed
    in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml), *Using TensorFlow
    with ML.NET* as a starting point, we will add in support for bounding boxes overlaid
    on top of the image when the model categorizes objects of which it is aware. The
    usefulness of this to the general public is in the various applications image
    object detection provides. Imagine that you are working on a project for the police
    or intelligence community, where they have images or videos and want to detect
    weapons. Utilizing the YOLO model with ML.NET, as we are going to show, would
    make that process very easy.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将创建的应用程序是一个使用预训练ONNX模型的目标检测应用程序。以我们在第12章中开发的应用程序为起点，即*使用ML.NET与TensorFlow*，我们将添加对模型分类已知对象时图像上叠加的边界框的支持。这种对公众的实用性在于图像目标检测提供的各种应用。想象一下，你正在为警察或情报社区的项目工作，他们有图像或视频，并希望检测武器。正如我们将展示的，利用YOLO模型与ML.NET将使这个过程变得非常简单。
- en: As with previous chapters, the completed project code, pre-trained model, and
    project files can be downloaded here: [https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter13](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter13).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 与前几章一样，完整的项目代码、预训练模型和项目文件可以在此处下载：[https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter13](https://github.com/PacktPublishing/Hands-On-Machine-Learning-With-ML.NET/tree/master/chapter13)。
- en: Exploring the project architecture
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索项目架构
- en: Building on the project architecture and code we created in previous chapters,
    the architecture we will be reviewing is enhanced to be more structured and usable
    by an end user.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中创建的项目架构和代码的基础上，我们将审查的架构得到了增强，使其更加结构化和便于最终用户使用。
- en: 'As in some of the previous chapters, the following two additional NuGet packages
    are required if you want to utilize an ONNX model and perform object detection:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如同一些前几章一样，如果您想利用 ONNX 模型进行对象检测，以下两个额外的 NuGet 包是必需的：
- en: '`Microsoft.ML.ImageAnalytics`'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Microsoft.ML.ImageAnalytics`'
- en: '`Microsoft.ML.OnnxTransformer`'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Microsoft.ML.OnnxTransformer`'
- en: These NuGet packages are already referenced in the included sample code. Version
    1.3.1 of these packages is used in both the included example on GitHub and throughout
    this chapter's deep dive.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 NuGet 包已在包含的示例代码中引用。这些包的 1.3.1 版本在 GitHub 中的示例和本章的深入探讨中均使用。
- en: 'In the following screenshot, you will find the Visual Studio Solution Explorer
    view of the project. There are several new additions to the solution, to facilitate
    the production use case we are targeting. We will review in detail each of the
    new files in the following solution screenshot later on in this chapter:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的屏幕截图中，您将找到项目的 Visual Studio 解决方案资源管理器视图。解决方案中添加了几个新内容，以方便我们针对的生产用例。我们将在本章后面的部分详细审查以下解决方案截图中的每个新文件：
- en: '![](img/bda2449a-5aa4-4ac5-acf2-adb328a47f44.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bda2449a-5aa4-4ac5-acf2-adb328a47f44.png)'
- en: Due to a current ML.NET limitation as of this writing, ONNX support is only
    provided for scoring using a pre-existing model. The pre-trained model included
    in this example can be found in the `assets/model` folder.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于当前 ML.NET 的限制，截至本文撰写时，ONNX 支持仅限于使用预存模型进行评分。本例中包含的预训练模型可在 `assets/model` 文件夹中找到。
- en: Diving into the code
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入代码
- en: For this application, as noted in the previous section, we are building on top
    of the work completed in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml), *Using
    TensorFlow with ML.NET*. While the **user interface** (**UI**) has not changed
    much, the underlying code to run an ONNX model has. For each file changed—as in
    previous chapters—we will review the changes made and the reasoning behind the
    changes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，对于这个应用程序，我们正在构建在 [第 12 章](049e90c4-05b0-466d-af93-d56df861a843.xhtml) 完成的作品之上，*使用
    TensorFlow 与 ML.NET*。虽然 **用户界面**（**UI**） 没有太大变化，但运行 ONNX 模型的底层代码已经改变。对于每个更改的文件——就像前几章一样——我们将审查所做的更改及其背后的原因。
- en: 'Classes that were changed or added are as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 已更改或添加的类如下：
- en: '`DimensionsBase`'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DimensionsBase`'
- en: '`BoundingBoxDimensions`'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BoundingBoxDimensions`'
- en: '`YoloBoundingBox`'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`YoloBoundingBox`'
- en: '`MainWindow.xaml`'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MainWindow.xaml`'
- en: '`ImageClassificationPredictor`'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ImageClassificationPredictor`'
- en: '`MainWindowViewModel`'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MainWindowViewModel`'
- en: There is one additional file, with the `YoloOutputParser` class contained within.
    This class is derived from the **Massachusetts Institute of Technology** (**MIT**)
    licensed interface for the `TinyYOLO` ONNX model. Due to the length of this class,
    we will not review it; however, the code does read easily, and if you wish to
    step through a prediction, the flow will be easy to follow.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个额外的文件，其中包含 `YoloOutputParser` 类。这个类是从 **麻省理工学院**（**MIT**）许可的接口派生出来的，用于 `TinyYOLO`
    ONNX 模型。由于这个类的长度，我们不会对其进行审查；然而，代码易于阅读，如果您想逐步进行预测，流程将很容易跟随。
- en: The DimensionsBase class
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`DimensionsBase` 类'
- en: 'The `DimensionsBase` class contains the coordinates along with the `Height`
    and `Width` properties, as illustrated in the following code block:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`DimensionsBase` 类包含坐标以及 `Height` 和 `Width` 属性，如下面的代码块所示：'
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This base class is used by both the `YoloOutputParser` and `BoundingBoxDimensions` classes
    to reduce code duplication.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基类被 `YoloOutputParser` 和 `BoundingBoxDimensions` 类使用，以减少代码重复。
- en: The YoloBoundingBox class
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YoloBoundingBox 类
- en: 'The `YoloBoundingBox` class provides the container class for what is used to
    populate our bounding boxes when generating them for the overlay, as illustrated
    in the following code block:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`YoloBoundingBox` 类提供了用于在生成叠加时填充边界框的容器类，如下面的代码块所示：'
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In addition, also defined in this same class file is our `BoundingBoxDimensions`
    class, as shown in the following code block:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在同一个类文件中定义了我们的 `BoundingBoxDimensions` 类，如下面的代码块所示：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Again, this inheritance is used to reduce code duplication.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这种继承用于减少代码重复。
- en: The MainWindow.xaml file
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MainWindow.xaml 文件
- en: 'The **Extensible Application Markup Language** (**XAML**) view of our application
    has been simplified to just the button and the image controls, as illustrated
    in the following code block:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用程序的**可扩展应用程序标记语言**（**XAML**）视图已被简化为仅包含按钮和图像控件，如下面的代码块所示：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In addition, due to the nature of the bounding boxes and images you may select,
    the window has defaulted to `Maximized`, as can be seen in the following code
    block:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于所选定的外接矩形和图像的性质，窗口默认设置为`最大化`，如下面的代码块所示：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: With the XAML changes behind us, let us now dive into the revised `ImageClassificationPredictor`
    class.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在XAML更改完成后，现在让我们深入探讨修订后的`ImageClassificationPredictor`类。
- en: The ImageClassificationPredictor class
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ImageClassificationPredictor类
- en: 'The `ImageClassificationPredictor` class, much like that of [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml),
    *Using TensorFlow with ML.NET*, contains the methods to run our image prediction.
    In this chapter, we will need to make several additional class objects to support
    the running of an ONNX model, as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`ImageClassificationPredictor`类，与[第12章](049e90c4-05b0-466d-af93-d56df861a843.xhtml)中提到的类似，即*使用ML.NET与TensorFlow结合使用*，其中包含了运行图像预测的方法。在本章中，我们需要创建几个额外的类对象来支持ONNX模型的运行，具体如下：'
- en: 'First, we define the `ImageNetSettings` struct that defines the height and
    width of our network. The YOLO model requires the use of 416 pixels by 416 pixels,
    as illustrated in the following code block:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们定义`ImageNetSettings`结构体，它定义了网络的宽度和高度。YOLO模型需要使用416像素×416像素，如下面的代码块所示：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we define the `TinyYoloModelSettings` struct to be used with the ONNX
    model, as follows:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义`TinyYoloModelSettings`结构体，用于与ONNX模型一起使用，如下所示：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Unlike the previous chapter, where the TensorFlow model was imported and then
    exported as an ML.NET model on the first run, ONNX, as of this writing, does not
    support that path. So, we must load the ONNX model in the `Initialize` method
    every time, as illustrated in the following code block:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与前一章不同，在前一章中，TensorFlow模型在第一次运行时被导入并导出为ML.NET模型，但截至本文写作时，ONNX不支持该路径。因此，我们必须在`Initialize`方法中每次都加载ONNX模型，如下面的代码块所示：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we modify the `Predict` method extensively to support the `YoloParser`
    call, calling the `DrawBoundingBox` method to overlay the bounding boxes, and
    then returning the bytes of the updated image, as follows:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们广泛修改`Predict`方法以支持`YoloParser`调用，调用`DrawBoundingBox`方法来叠加外接矩形，然后返回更新后的图像的字节，如下所示：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For brevity, the `DrawBoundingBox` method is not shown here. At a high level,
    the original image is loaded into memory, and the model's bounding boxes are then
    drawn on top of the image, along with the label and confidence. This updated image
    is then converted to a byte array and returned.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，这里没有展示`DrawBoundingBox`方法。从高层次来看，原始图像被加载到内存中，然后模型的外接矩形被绘制在图像上，包括标签和置信度。然后，这个更新后的图像被转换为字节数组并返回。
- en: The MainWindowViewModel class
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MainWindowViewModel类
- en: 'Inside the `MainWindowViewModel` class, there are a couple of changes to be
    made due to the nature of the example. We look at them here:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在`MainWindowViewModel`类内部，由于示例的性质，需要进行一些更改。我们在这里看看它们：
- en: 'First, the `LoadImageBytes` method now simply takes the parsed image bytes
    and converts them to an `Image` object, like this:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，`LoadImageBytes`方法现在只需将解析后的图像字节转换为`Image`对象，如下所示：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Lastly, we modify the `Classify` method to call the `LoadImageBytes` method
    upon successfully running the model, as follows:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们修改`Classify`方法，在成功运行模型后调用`LoadImageBytes`方法，如下所示：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With the changes in place for the `Classify` method, that concludes the code
    changes required for this chapter's example. Now, let us run the application!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 针对`Classify`方法的更改已经实施，这标志着本章示例所需的代码更改已经完成。现在，让我们运行应用程序吧！
- en: Running the application
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行应用程序
- en: 'To run the application, the process is identical to the sample application
    in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml), *Using TensorFlow
    with ML.NET*. To run the application from within Visual Studio, simply click the
    *play* icon found in the toolbar, as illustrated in the following screenshot:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 运行应用程序的过程与[第12章](049e90c4-05b0-466d-af93-d56df861a843.xhtml)中的示例应用程序相同，即*使用ML.NET与TensorFlow结合使用*。要从Visual
    Studio内部运行应用程序，只需单击工具栏中的*播放*图标，如图下所示：
- en: '![](img/5fe7e40a-4da8-4dc1-8700-6fd1782f74bd.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5fe7e40a-4da8-4dc1-8700-6fd1782f74bd.png)'
- en: 'After launching the application, just as in [Chapter 12](049e90c4-05b0-466d-af93-d56df861a843.xhtml),
    *Using TensorFlow with ML.NET*, select an image file, and the model will run.
    For example, I selected an image I took on a vacation to Germany (note the car''s
    bounding boxes), shown in the following screenshot:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 启动应用程序后，就像在第12章[使用TensorFlow与ML.NET](049e90c4-05b0-466d-af93-d56df861a843.xhtml)中一样，选择一个图像文件，模型就会运行。例如，我选择了一张我在德国度假时拍摄的图片（注意汽车边界框），如下面的截图所示：
- en: '![](img/be4ac682-f556-4270-a7e6-6dbf82838d48.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/be4ac682-f556-4270-a7e6-6dbf82838d48.png)'
- en: Feel free to try selecting images you have on your hard drive to see the confidence
    level of the detection and how well the bounding boxes are formed around the objects.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 随意尝试选择您硬盘上的图像，以查看检测的置信水平和边界框围绕对象的形成情况。
- en: Exploring additional production application enhancements
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索额外的生产应用增强
- en: Now that we have completed our deep dive, there are a couple of additional elements
    to further enhance the application. A few ideas are discussed in the upcoming
    sections.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了深入探讨，还有一些额外的元素可以进一步增强应用程序。一些想法将在接下来的章节中讨论。
- en: Logging
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录
- en: As noted previously, the importance of logging cannot be stressed enough within
    desktop applications. Logging utilizing NLog ([https://nlog-project.org/](https://nlog-project.org/))
    or a similar open-source project is highly recommended as your application complexity
    increases. This will allow you to log to a file, console, or third-party logging
    solution such as Loggly, at varying levels. For instance, if you deploy this application
    to a customer, breaking down the error level to at least Debug, Warning, and Error
    will be helpful when debugging issues remotely.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在桌面应用程序中强调日志记录的重要性是至关重要的。随着应用程序复杂性的增加，强烈建议使用NLog ([https://nlog-project.org/](https://nlog-project.org/))或类似的开源项目进行日志记录。这将允许您以不同的级别将日志记录到文件、控制台或第三方日志解决方案，如Loggly。例如，如果您将此应用程序部署给客户，将错误级别至少分解为调试、警告和错误，将有助于远程调试问题。
- en: Image scaling
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像缩放
- en: As you might have noticed, with images that are quite large (those exceeding
    your screen resolution), the text labeling of the bounding boxes and resizing
    within the image preview is not as easy to read as for, say, a 640 x 480 image.
    One area of improvement here would be to provide hover-over capabilities, resizing
    the image to the dimensions of the window or increasing the font size dynamically.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已注意到，对于相当大的图像（那些超出您的屏幕分辨率），在图像预览中对边界框进行文本标注和调整大小并不像640 x 480这样的图像那样容易阅读。在此方面的一个改进点可能是提供悬停功能，将图像调整到窗口的尺寸或动态增加字体大小。
- en: Utilizing the full YOLO model
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用完整的YOLO模型
- en: In addition, another area of improvement for this sample would be to use the
    full YOLO model within an application. As previously noted with the Tiny YOLO
    model used within the example application, only 20 labels are provided. In a production
    application or one in which you wish to build on, using the larger, more complex
    model would be a good choice.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于此示例的另一个改进点是在应用程序中使用完整的YOLO模型。正如之前在示例应用程序中使用的Tiny YOLO模型一样，只提供了20个标签。在生产应用程序或您希望构建的应用程序中，使用更大、更复杂的模型是一个不错的选择。
- en: You can download the full YOLO model here: [https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3](https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处下载完整的YOLO模型：[https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3](https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/yolov3)。
- en: Summary
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Over the course of this chapter, we have deep dived into what goes into the
    ONNX format and what it offers to the community. In addition, we also created
    a brand new detection engine using the pre-trained Tiny YOLO model in ML.NET.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的整个过程中，我们深入探讨了ONNX格式的内容以及它为社区提供的功能。此外，我们还使用ML.NET中的预训练Tiny YOLO模型创建了一个全新的检测引擎。
- en: And with that, this concludes your deep dive into ML.NET. Between the first
    page of this book and this one, you have hopefully grown to understand the power
    that ML.NET offers in a very straightforward feature-rich abstraction. With ML.NET
    constantly evolving (much like .NET), there will be no doubt about the evolution
    of ML.NET's feature sets and deployment targets, ranging from embedded **Internet
    of Things** (**IoT**) devices to mobile devices. I hope this book was beneficial
    for your deep dive into ML.NET and machine learning. In addition, I hope that
    as you approach problems in the future, you will first think about whether the
    problem would benefit from utilizing ML.NET to solve the problem more efficiently
    and, potentially, better overall. Given the world's data continually growing at
    exponential rates, the necessity for using non-brute-force/traditional approaches
    will only continue to grow, therefore the skills garnered from this book should
    help you for years to come.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 伴随着这一点，您对 ML.NET 的深入研究也就此结束。从这本书的第一页到这一页，您可能已经逐渐了解到 ML.NET 提供的非常直接且功能丰富的抽象能力。由于
    ML.NET（就像 .NET 一样）不断进化，ML.NET 的功能集和部署目标的发展也将毫无疑问，从嵌入式 **物联网**（**IoT**）设备到移动设备。我希望这本书对您深入理解
    ML.NET 和机器学习有所帮助。此外，我希望在您未来遇到问题时，您首先会考虑这个问题是否可以通过利用 ML.NET 来更高效甚至更好地解决问题。鉴于世界上的数据持续以指数级增长，使用非暴力/传统方法的需求只会继续增长，因此，从这本书中获得的知识和技能将帮助您多年。
