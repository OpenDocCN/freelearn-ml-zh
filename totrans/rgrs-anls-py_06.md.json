["```py\nIn: import pandas as pd\nfrom sklearn.datasets import load_boston\nboston = load_boston() \ndataset = pd.DataFrame(boston.data, columns=boston.feature_names)\ndataset['target'] = boston.target\nobservations = len(dataset)\nvariables = dataset.columns[:-1]\nX = dataset.ix[:,:-1]\ny = dataset['target'].values\n```", "```py\nIn: from sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=101)\nprint (\"Train dataset sample size: %i\" % len(X_train))\nprint (\"Test dataset sample size: %i\" % len(X_test))\n\nOut:   Train dataset sample size: 354\nTest dataset sample size: 152\n```", "```py\nIn: X_train, X_out_sample, y_train, y_out_sample = \\\ntrain_test_split(X, y, test_size=0.40, random_state=101)\nX_validation, X_test, y_validation, y_test = \\\ntrain_test_split(X_out_sample, y_out_sample, test_size=0.50, random_state=101)\nprint (\"Train dataset sample size: %i\" % len(X_train))\nprint (\"Validation dataset sample size: %i\" % len(X_validation))\nprint (\"Test dataset sample size: %i\" % len(X_test))\nOut:   Train dataset sample size: 303\nValidation dataset sample size: 101\nTest dataset sample size: 102\n```", "```py\nIn: from sklearn.cross_validation import cross_val_score, \\\nKFold, StratifiedKFold\nfrom sklearn.metrics import make_scorer\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\ndef RMSE(y_true, y_pred):\n    return np.sum((y_true -y_pred)**2)\nlm = LinearRegression()\ncv_iterator = KFold(n=len(X), n_folds=10, shuffle=True,\\ random_state=101)\nedges = np.histogram(y, bins=5)[1]\nbinning = np.digitize(y, edges)\nstratified_cv_iterator = StratifiedKFold(binning, n_folds=10,\\ shuffle=True, random_state=101)\n\nsecond_order=PolynomialFeatures(degree=2, interaction_only=False)\nthird_order=PolynomialFeatures(degree=3, interaction_only=True)\n\nover_param_X = second_order.fit_transform(X)\nextra_over_param_X = third_order.fit_transform(X)\ncv_score = cross_val_score(lm, over_param_X, y, cv=cv_iterator,\\ scoring='mean_squared_error', n_jobs=1)\n```", "```py\nIn: print (cv_score)\n\nOut: [-10.79792467 -19.21944292  -8.39077691 -14.79808458 -10.90565129  -7.08445784 -12.8788423  -16.80309722 -32.40034131 -13.66625192]\n```", "```py\nIn: print ('Cv score: mean %0.3f std %0.3f' % (np.mean(np.abs(cv_score)), np.std(cv_score)))\nOut: Cv score: mean 14.694 std 6.855\n```", "```py\nIn:cv_score = cross_val_score(lm, over_param_X, y,\\\ncv=stratified_cv_iterator, scoring='mean_squared_error', \\\nn_jobs=1)\nprint ('Cv score: mean %0.3f std %0.3f' % \\\n       (np.mean(np.abs(cv_score)), np.std(cv_score)))\nOut: Cv score: mean 13.584 std 5.226\n```", "```py\nIn: import random\ndef Bootstrap(n, n_iter=3, random_state=None):\n      \"\"\"\n      Random sampling with replacement cross-validation generator.\n      For each iter a sample bootstrap of the indexes [0, n) is\n      generated and the function returns the obtained sample\n      and a list of all the excluded indexes.\n      \"\"\"\n      if random_state:\n          random.seed(random_state)\n      for j in range(n_iter):\n          bs = [random.randint(0, n-1) for i in range(n)]\n          out_bs = list({i for i in range(n)} - set(bs))\n          yield bs, out_bs\n\nboot = Bootstrap(n=10, n_iter=5, random_state=101)\nfor train_idx, validation_idx in boot:\nprint (train_idx, validation_idx)\n```", "```py\nIn: import numpy as np\nboot = Bootstrap(n=len(X), n_iter=10, random_state=101)\nlm = LinearRegression()\nbootstrapped_coef = np.zeros((10,13))\nfor k, (train_idx, validation_idx) in enumerate(boot):\n       lm.fit(X.ix[train_idx,:],y[train_idx])\n       bootstrapped_coef[k,:] = lm.coef_\n```", "```py\nIn: print(bootstrapped_coef[:,10])\n\nOutput: [-1.04150741 -0.93651754 -1.09205904 -1.10422447 -0.9982515\n-0.79789273 -0.89421685 -0.92320895 -1.0276369  -0.79189224]\n```", "```py\nIn: print(bootstrapped_coef[:,6])\n\nOut: [-0.01930727  0.00053026 -0.00026774  0.00607945  0.02225979 -0.00089469  0.01922754  0.02164681  0.01243348 -0.02693115]\n```", "```py\nIn: from sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=3)\nlm = LinearRegression()\nlm.fit(X_train,y_train)\nprint ('Train (cases, features) = %s' % str(X_train.shape))\nprint ('Test  (cases, features) = %s' % str(X_test.shape))\nprint ('In-sample  mean squared error %0.3f' % mean_squared_error(\n        y_train,lm.predict(X_train)))\nprint ('Out-sample mean squared error %0.3f' % mean_squared_error(\n        y_test,lm.predict(X_test)))\n\nOut:   Train (cases, features) = (354, 13)\nTest  (cases, features) = (152, 13)\nIn-sample  mean squared error 22.420\nOut-sample mean squared error 22.440\n```", "```py\nIn: from sklearn.preprocessing import PolynomialFeatures\nsecond_order=PolynomialFeatures(degree=2, interaction_only=False)\nthird_order=PolynomialFeatures(degree=3, interaction_only=True)\n```", "```py\nIn: lm.fit(second_order.fit_transform(X_train),y_train)\nprint ('(cases, features) = %s' % str(second_order.fit_transform(\n            X_train).shape))\nprint ('In-sample  mean squared error %0.3f' %\nmean_squared_error(y_train,lm.predict(second_order.fit_transform(\n            X_train))))\nprint ('Out-sample mean squared error %0.3f' %\nmean_squared_error(y_test,lm.predict(second_order.fit_transform(\n            X_test))))\nOut:   (cases, features) = (354, 105)\nIn-sample  mean squared error 5.522\nOut-sample mean squared error 12.034\n```", "```py\nIn: lm.fit(third_order.fit_transform(X_train), y_train)\nprint ('(cases, features) = %s' % str(third_order.fit_transform(\n            X_train).shape))\nprint ('In-sample  mean squared error %0.3f' %\nmean_squared_error(y_train,lm.predict(third_order.fit_transform(\n            X_train))))\nprint ('Out-sample mean squared error %0.3f' %\nmean_squared_error(y_test,lm.predict(third_order.fit_transform(\n            X_test))))\n\nOut:   (cases, features) = (354, 378)\nIn-sample  mean squared error 0.438\nOut-sample mean squared error 85777.890\n```", "```py\nIn: try:\nimport urllib.request as urllib2\n  except:\n    import urllib2\n  import numpy as np\n  train_data = 'https://archive.ics.uci.edu/ml/machine-learning-databases/madelon/MADELON/madelon_train.data'\n  validation_data = 'https://archive.ics.uci.edu/ml/machine-learning-databases/madelon/MADELON/madelon_valid.data'\ntrain_response = 'https://archive.ics.uci.edu/ml/machine-learning-databases/madelon/MADELON/madelon_train.labels'\n  validation_response = 'https://archive.ics.uci.edu/ml/machine-learning-databases/madelon/madelon_valid.labels'\ntry:\n      Xt = np.loadtxt(urllib2.urlopen(train_data))\n      yt = np.loadtxt(urllib2.urlopen(train_response))\n      Xv = np.loadtxt(urllib2.urlopen(validation_data))\n      yv = np.loadtxt(urllib2.urlopen(validation_response))\nexcept:\n    # In case downloading the data doesn't works, \n# just manually download the files into the working directory\n      Xt = np.loadtxt('madelon_train.data')\n      yt = np.loadtxt('madelon_train.labels')\n      Xv = np.loadtxt('madelon_valid.data')\n      yv = np.loadtxt('madelon_valid.labels')\n```", "```py\nIn: print ('Training set: %i observations %i feature' % (Xt.shape))\n  print ('Validation set: %i observations %i feature' % (Xv.shape))\nOut:  Training set: 2000 observations 500 feature\n    Validation set: 600 observations 500 feature \n```", "```py\nIn:from scipy.stats import describe\n  print (describe(Xt))\n```", "```py\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n%matplotlib inline\n\ndef visualize_correlation_matrix(data, hurdle = 0.0):\n    R = np.corrcoef(data, rowvar=0)\n    R[np.where(np.abs(R)<hurdle)] = 0.0\n    heatmap = plt.pcolor(R, cmap=mpl.cm.coolwarm, alpha=0.8)\n    heatmap.axes.set_frame_on(False)\n    plt.xticks(rotation=90)\n    plt.tick_params(axis='both', which='both', bottom='off',\\\n                  top='off', left = 'off',right = 'off')\n    plt.colorbar()\n    plt.show()\n\nvisualize_correlation_matrix(Xt[:,100:150], hurdle=0.0)\n```", "```py\nIn: from sklearn.cross_validation import cross_val_score\n  from sklearn.linear_model import LogisticRegression\n  logit = LogisticRegression()\n  logit.fit(Xt,yt)\n\n  from sklearn.metrics import roc_auc_score\n  print ('Training area under the curve: %0.3f' % \\roc_auc_score(yt,logit.predict_proba(Xt)[:,1]))\n  print ('Validation area under the curve: %0.3f' % \\roc_auc_score(yv,logit.predict_proba(Xv)[:,1]))\n\nOut:   Training area under the curve: 0.824\n    Validation area under the curve: 0.602\n```", "```py\nIn addition, if interpreting your model is a valuable addition, you really should remove non-useful variables, striving for the simplest possible form of your linear model as dictated by Occam's razor, a commonplace practice in science, favoring simpler solutions against more complex ones when their difference in performance is not marked.\n```", "```py\nIn: from sklearn.feature_selection import SelectPercentile, f_classif\nselector = SelectPercentile(f_classif, percentile=50)\nselector.fit(Xt,yt)\nvariable_filter = selector.get_support()\n```", "```py\nIn: plt.hist(selector.scores_, bins=50, histtype='bar')\nplt.grid()\nplt.show()\n```", "```py\n  In: variable_filter = selector.scores_ > 10\n  print (\"Number of filtered variables: %i\" % \\ np.sum(variable_filter))\n  from sklearn.preprocessing import PolynomialFeatures\n  interactions = PolynomialFeatures(degree=2, interaction_only=True)\n  Xs = interactions.fit_transform(Xt[:,variable_filter])\n  print (\"Number of variables and interactions: %i\" % Xs.shape[1])\n\nOut:   Number of filtered variables: 13\nNumber of variables and interactions: 92\n```", "```py\nIn: logit.fit(Xs,yt)\nXvs = interactions.fit_transform(Xv[:,variable_filter])\n print ('Validation area Under the Curve ' + \\\n        'before recursive \\ selection:   %0.3f' % \\\n        roc_auc_score(yv,logit.predict_proba(Xvs)[:,1]))\n\nOut:   Validation area Under the Curve before \nrecursive selection: 0.808\n```", "```py\nIn: from sklearn.feature_selection import RFECV\nfrom sklearn.cross_validation import KFold\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = \\\n    train_test_split(X, y, test_size=0.30, random_state=1)\n\nlm = LinearRegression()\ncv_iterator = KFold(\n    n=len(X_train), n_folds=10, shuffle=True, random_state=101)\nrecursive_selector = RFECV(estimator=lm, step=1, cv=cv_iterator, scoring='mean_squared_error')\nrecursive_selector.fit(second_order.fit_transform(X_train),\ny_train)\nprint ('Initial number of features : %i' % \n       second_order.fit_transform(X_train).shape[1])\nprint ('Optimal number of features : %i' % \n       recursive_selector.n_features_)\n\nOut:   Initial number of features : 105\nOptimal number of features : 52\n```", "```py\nIn: essential_X_train = recursive_selector.transform(\n    second_order.fit_transform(X_train))\nessential_X_test  = recursive_selector.transform(\n    second_order.fit_transform(X_test))\nlm.fit(essential_X_train, y_train)\nprint ('cases = %i features = %i' % essential_X_test.shape)\nprint ('In-sample  mean squared error %0.3f' % \\ \nmean_squared_error(y_train,lm.predict(essential_X_train)))\nprint ('Out-sample mean squared error %0.3f' % \\\nmean_squared_error(y_test,lm.predict(essential_X_test)))\n\nOut:   cases = 152 features = 52\nIn-sample  mean squared error 7.834\nOut-sample mean squared error 11.523\n```", "```py\nIn: edges = np.histogram(y, bins=5)[1]\nbinning = np.digitize(y, edges)\nstratified_cv_iterator = StratifiedKFold(binning, n_folds=10, shuffle=True, random_state=101)\nessential_X = recursive_selector.transform(\n    second_order.fit_transform(X))\ncv_score = cross_val_score(\n    lm, essential_X, y, cv=stratified_cv_iterator, \n    scoring='mean_squared_error', n_jobs=1)\nprint ('Cv score: mean %0.3f std %0.3f' % (np.mean(np.abs(cv_score)), np.std(cv_score)))\n\nOut: Cv score: mean 11.400 std 3.779\n```", "```py\nIn: from sklearn.linear_model import Ridge\nridge = Ridge(normalize=True)\nridge.fit(second_order.fit_transform(X), y)\nlm.fit(second_order.fit_transform(X), y)\n```", "```py\nIn: print ('Average coefficient: Non regularized = %0.3f Ridge = \\\n%0.3f' % (np.mean(lm.coef_), np.mean(ridge.coef_)))\nprint ('Min coefficient: Non regularized = %0.3f Ridge = %0.3f' \\\n% (np.min(lm.coef_), np.min(ridge.coef_)))\nprint ('Max coefficient: Non regularized = %0.3f Ridge = %0.3f' \\\n% (np.max(lm.coef_), np.max(ridge.coef_)))\n\nOut:   Average coefficient: Non regularized = 1.376 Ridge = -0.027\nMin coefficient: Non regularized = -40.040 Ridge = -2.013\nMax coefficient: Non regularized = 142.329 Ridge = 1.181\n```", "```py\nIn: from sklearn.grid_search import GridSearchCV\nedges = np.histogram(y, bins=5)[1]\nbinning = np.digitize(y, edges)\nstratified_cv_iterator = StratifiedKFold(\n    binning, n_folds=10,shuffle=True, random_state=101)\nsearch = GridSearchCV(\n    param_grid={'alpha':np.logspace(-4,2,7)},\n    estimator=ridge, scoring ='mean_squared_error', \n    n_jobs=1, refit=True, cv=stratified_cv_iterator)\nsearch.fit(second_order.fit_transform(X), y)\nprint ('Best alpha: %0.5f' % search.best_params_['alpha'])\nprint ('Best CV mean squared error: %0.3f' % np.abs(\n        search.best_score_))\n\nOut:  Best alpha: 0.00100\nBest CV mean squared error: 11.883\n```", "```py\nIn: search.grid_scores_\nOut: \n[mean: -12.45899, std: 5.32834, params: {'alpha': 0.0001},\n mean: -11.88307, std: 4.92960, params: {'alpha': 0.001},\n mean: -12.64747, std: 4.66278, params: {'alpha': 0.01},\n mean: -16.83243, std: 5.28501, params: {'alpha': 0.1},\n mean: -22.91860, std: 5.95064, params: {'alpha': 1.0},\n mean: -37.81253, std: 8.63064, params: {'alpha': 10.0},\n mean: -66.65745, std: 10.35740, params: {'alpha': 100.0}]\n```", "```py\nIn: from sklearn.grid_search import RandomizedSearchCV\nfrom scipy.stats import expon\nnp.random.seed(101)\nsearch_func=RandomizedSearchCV(\n    estimator=ridge, n_jobs=1, iid=False, refit=True, n_iter=10,\n    param_distributions={'alpha':np.logspace(-4,2,100)}, \n    scoring='mean_squared_error', cv=stratified_cv_iterator)\n\nsearch_func.fit(second_order.fit_transform(X), y)\nprint ('Best alpha: %0.5f' % search_func.best_params_['alpha'])\nprint ('Best CV mean squared error: %0.3f' % np.abs(\n        search_func.best_score_))\n\nOut:  Best alpha: 0.00046\nBest CV mean squared error: 11.790\n```", "```py\nIn: from sklearn.linear_model import Lasso\nlasso = Lasso(alpha=1.0, normalize=True, max_iter=10**5)\n#The following comment shows an example of L1 logistic regression\n#lr_l1 = LogisticRegression(C=1.0, penalty='l1', tol=0.01)\n```", "```py\nIn: from sklearn.grid_search import RandomizedSearchCV\nfrom scipy.stats import expon\nnp.random.seed(101)\nsearch_func=RandomizedSearchCV(\n    estimator=lasso, n_jobs=1, iid=False, refit=True, n_iter=15,\n    param_distributions={'alpha':np.logspace(-5,2,100)}, \n    scoring='mean_squared_error', cv=stratified_cv_iterator)\n\nsearch_func.fit(second_order.fit_transform(X), y)\nprint ('Best alpha: %0.5f' % search_func.best_params_['alpha'])\nprint ('Best CV mean squared error: %0.3f' % np.abs(\n        search_func.best_score_))\n\nOut:  Best alpha: 0.00006\nBest CV mean squared error: 12.235\n```", "```py\nIn: print ('Zero value coefficients: %i out of %i' % \\\n(np.sum(~(search_func.best_estimator_.coef_==0.0)),\nlen(search_func.best_estimator_.coef_)))\n\nOut:  Zero value coefficients: 85 out of 105\n```", "```py\nIn: from sklearn.linear_model import ElasticNet\nelasticnet = ElasticNet(alpha=1.0, l1_ratio=0.15, normalize=True, max_iter=10**6, random_state=101)\n  from sklearn.grid_search import RandomizedSearchCV\n  from scipy.stats import expon\n  np.random.seed(101)\n  search_func=RandomizedSearchCV(estimator=elasticnet, param_distributions={'alpha':np.logspace(-5,2,100), 'l1_ratio':np.arange(0.0, 1.01, 0.05)}, n_iter=30, scoring='mean_squared_error', n_jobs=1, iid=False, \nrefit=True, cv=stratified_cv_iterator)\nsearch_func.fit(second_order.fit_transform(X), y)\nprint ('Best alpha: %0.5f' % search_func.best_params_['alpha'])\nprint ('Best l1_ratio: %0.5f' % \\ search_func.best_params_['l1_ratio'])\nprint ('Best CV mean squared error: %0.3f' % \\ np.abs(search_func.best_score_))\n\nOut:  Best alpha: 0.00002\nBest l1_ratio: 0.60000\nBest CV mean squared error: 11.900\n```", "```py\nIn: print ('Zero value coefficients: %i out of %i' % (np.sum(~(search_func.best_estimator_.coef_==0.0)), len(search_func.best_estimator_.coef_))) \n\nOut:   Zero value coefficients: 102 out of 105\n```", "```py\nIn: from sklearn.cross_validation import cross_val_score\n  from sklearn.linear_model import RandomizedLogisticRegression\n  from sklearn.preprocessing import PolynomialFeatures\n  from sklearn.pipeline import make_pipeline\n  threshold = 0.03 # empirically found value\n  stability_selection = RandomizedLogisticRegression(n_resampling=300, n_jobs=1,\n    random_state=101, scaling=0.15, \n    sample_fraction=0.50, selection_threshold=threshold)\n  interactions = PolynomialFeatures(degree=4, interaction_only=True)\n  model = make_pipeline(stability_selection, interactions, logit)\n  model.fit(Xt,yt)\n```", "```py\nIn: print ('Number of features picked by stability selection: %i' % \\ np.sum(model.steps[0][1].all_scores_ >= threshold))\n\nOut: Number of features picked by stability selection: 19\n```", "```py\nIn: from sklearn.metrics import roc_auc_score\nprint ('Area Under the Curve: %0.3f' % roc_auc_score(\n            yv,model.predict_proba(Xv)[:,1]))\n\nOut: Area Under the Curve: 0.885\n```"]