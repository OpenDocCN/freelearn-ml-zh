- en: 'Chapter 4: Visualizing Data with Python'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Regardless of the field of work you operate in, the career path you''ve chosen,
    or the specific project you are working on, the ability to effectively communicate
    information to others will always be useful. In fact, exactly one hundred years
    ago, in 1921, Frederick R. Barnard first said something which has become a phrase
    you have probably heard countless times: *A picture is worth a thousand words*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With the many new technologies that have emerged in the realm of machine learning
    in recent years, the amount of data being structured, processed, and analyzed
    has grown exponentially. The ability to take data in its raw form and translate
    it to a meaningful and communicative diagram is one of the most sought-after skill
    sets in the industry today. Most decisions made in large companies and corporations
    are generally data-driven, and the best way to start a conversation about an area
    you care about is to create a meaningful visualization about it. Consider the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: The human brain is able to process visualizations 60,000 times faster than text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nearly 90% of all information processed by the human brain is done visually.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizations are 30 times more likely to be read than even simple text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizations are not always about driving a conversation or convincing an
    opposing party to agree on something – they are often used as a means to investigate
    and explore data for the purposes of uncovering hidden insights. In almost every
    machine learning project you undertake, a significant amount of effort will be
    devoted to exploring data to uncover its hidden **features** through a process
    known as **Exploratory Data Analysis** (**EDA**). EDA is normally done prior to
    any type of machine learning project in order to better understand the data, its
    features, and its limits. One of the best ways to explore data in this fashion
    is in a visual form, allowing you to uncover much more than the numerical values
    alone.
  prefs: []
  type: TYPE_NORMAL
- en: Over the course of the following chapter, we will look over some useful steps
    to follow to develop a robust visual for a given dataset. We will also explore
    some of the most common visualization libraries used in the **Python** community
    today. Finally, we will explore several datasets and learn how to develop some
    of the most common visualizations for them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Within this chapter, we will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the six steps of data visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Commonly used visualization libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tutorial – visualizing data in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will apply our understanding of Python and `pip` installer
    demonstrated in [*Chapter 2*](B17761_02_Final_JM_ePub.xhtml#_idTextAnchor023),
    *Introducing Python and the Command Line*. Recall that the process of installing
    a library is done via the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: So, now that we are set up, let's begin!
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the six steps of data visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When it comes to effectively communicating key trends in your data, the method
    in which it is presented will always be important. When presenting any type of
    data to an audience, there are two main considerations: first, selecting the correct
    segment of data for the argument; second, selecting the most effective visualization
    for the argument. When working on a new visualization, there are six steps you
    can follow to help guide you:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Acquire**: Obtain the data from its source.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Understand**: Learn about the data and understand its categories and features.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`NaN` values, and corrupt entries.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mine**: Identify patterns or engineer new features.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Condense**: Isolate the most useful features.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Represent**: Select a representation for these features.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's look at each step in detail.
  prefs: []
  type: TYPE_NORMAL
- en: The first step is to *acquire* your data from its source. This source may be
    a simple CSV file, a relational database, or even a **NoSQL** database.
  prefs: []
  type: TYPE_NORMAL
- en: Second, it is important to *understand* the context of the data as well as its
    content. As a data scientist, your objective is to place yourself in the shoes
    of your stakeholders and understand their data as best you can. Often, a simple
    conversation with a **Subject Matter Expert** (**SME**) can save you hours by
    highlighting facts about the data that you otherwise would not have known.
  prefs: []
  type: TYPE_NORMAL
- en: Third, *filtering* your data will always be crucial. Most real-world applications
    of data science rarely involve ready-to-use datasets. Often, data in its raw form
    will be the main data source, and it is up to data scientists and developers to
    ensure that any missing values and corrupt entries are taken care of. Data scientists
    often refer to this step as **preprocessing**, and we will explore this in more
    detail in [*Chapter 5*](B17761_05_Final_JM_ePub.xhtml#_idTextAnchor082), *Understanding
    Machine Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: With the data preprocessed, our next objective is to *mine* the data in an attempt
    to identify patterns or engineer new features. In simple datasets, values can
    often be quickly visualized as either increasing or decreasing, allowing us to
    easily understand the trend. In multidimensional datasets, these trends are often
    more difficult to uncover. For example, a time-series graph may show you an increasing
    *trend*, however, the first derivative of this graph may expose *trends* relating
    to *seasonality*.
  prefs: []
  type: TYPE_NORMAL
- en: Once a trend of interest is identified, the data representing that trend is
    often *isolated* from the rest of the data. And finally, this trend is *represented*
    using a visualization that complements it.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand that these steps are by no means hard rules, but
    they should be thought of as useful guidelines to assist you in generating effective
    visualizations. Not every visualization will require every step! In fact, some
    visualizations may require other steps, perhaps sometimes in a different order.
    We will go through a number of these steps to generate some visualizations later
    in the *Tutorial – Visualizing data in Python* section within this chapter. When
    we do, try to recall these steps and see if you can identify them.
  prefs: []
  type: TYPE_NORMAL
- en: Before we begin generating some interesting visuals, let's talk about some of
    the libraries we will need.
  prefs: []
  type: TYPE_NORMAL
- en: Commonly used visualization libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are countless **visualization libraries** available in Python, and more
    are being published every day. Visualization libraries can be divided into two
    main categories: **static visualization** libraries and **interactive visualization**
    libraries. Static visualizations are images consisting of plotted values that
    cannot be clicked by the user. On the other hand, interactive visualizations are
    not just images but representations that can be clicked on, reshaped, moved around,
    and scaled in a particular direction. Static visualizations are often destined
    for email communications, printed publications, or slide decks, as they are visualizations
    that you do not intend others to change. However, interactive visualizations are
    generally destined for dashboards and websites (such as **AWS** or **Heroku**)
    in anticipation of users interacting with them and exploring the data as permitted.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following open source libraries are currently some of the most popular
    in the industry. Each of them has its own advantages and disadvantages, which
    are detailed in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – A list of the most common visualization libraries in Python
    ](img/B17761_04_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – A list of the most common visualization libraries in Python
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know about visualization libraries, let's move on to the next section!
  prefs: []
  type: TYPE_NORMAL
- en: Tutorial – visualizing data in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the course of this tutorial, we will be retrieving a few different datasets
    from a range of sources and exploring them through various kinds of visualizations.
    To create these visuals, we will implement many of the visualization steps in
    conjunction with some of the open source visualization libraries. Let's get started!
  prefs: []
  type: TYPE_NORMAL
- en: Getting data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recall that, in [*Chapter 3*](B17761_03_Final_JM_ePub.xhtml#_idTextAnchor050),
    *Getting Started with SQL and Relational Databases*, we used AWS to create and
    deploy a database to the cloud, allowing us to query data using `sqlalchemy`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s query that dataset directly from `endpoint`, `username`, and `password`
    values generated in the previous chapter. Go ahead and list these as variables
    in Python:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the variables populated with your respective parameters, we can now query
    this data using `sqlalchemy`. Since we are interested in the dataset as a whole,
    we can simply run a `SELECT * FROM dataset_toxicity_sd` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Alternatively, you can simply import the same dataset as a CSV file using the
    `read_csv()` function:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can take a quick look at the dataset to understand its content using the
    `head()` function. Recall that we can choose to reduce the columns by specifying
    the names of the ones we are interested in by using double square brackets (`[[]]`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This gives us the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.2 – A DataFrame representation of selected columns from the toxicity
    dataset ](img/B17761_04_002.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.2 – A DataFrame representation of selected columns from the toxicity
    dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you recall, there are quite a few columns within this dataset, ranging from
    general data such as the primary key (`ID`) to the structure (`smiles`) and the
    toxicity (`toxic`). In addition, there are many features that describe and represent
    the dataset, ranging from the total polar surface area (`TPSA`) all the way to
    lipophilicity (`LogP`).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can also get a sense of some of the general statistics behind this dataset
    – such as the maximum, minimum, and averages relating to each column – by using
    the `describe()` function in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This results in the following table:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.3 – Some general statistics of selected columns from the toxicity
    dataset ](img/B17761_04_003.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.3 – Some general statistics of selected columns from the toxicity dataset
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Immediately, we notice that the `FormalCharge` and `LogP`) having negative values.
    So, this real-world dataset is quite diverse and spread out.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Before we can explore the dataset further, we will need to ensure that there
    are no missing values. To do this, we can run a quick check using the `isna()`
    function provided by the `pandas` library. We can chain this with the `sum()`
    function to get a sum of all of the missing values for each column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result is shown in *Figure 4.4*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.4 – The list of missing values within the DataFrame ](img/B17761_04_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 – The list of missing values within the DataFrame
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, there are no missing values from this particular dataset, so we
    are free to move forward with creating a few plots and visuals.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '`dropna()` function. Another option is to replace any missing value with a
    common value using the `fillna()` or `replace()` functions. Finally, you can also
    replace missing values with the mean of all the other values using the `mean()`
    function. The method you select will be highly dependent on the identity and meaning
    of the column.'
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing data with bar plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Bar plots** or **bar charts** are often used to describe *categorical data*
    in which the lengths or heights of the bars are proportional to the values of
    the categories they represent. Bar plots provide a visual estimate of the central
    tendency of a dataset with the uncertainty of the estimate represented by error
    bars.'
  prefs: []
  type: TYPE_NORMAL
- en: So, let's create our first bar plot. We will be using the `seaborn` library
    for this particular task. There are a number of different ways to style your graphs.
    For the purposes of this tutorial, we will use the `darkgrid` style from `seaborn`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s plot the `TPSA` feature relative to the `FormalCharge` feature to get
    a sense of the relationship between them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Our initial results are shown in *Figure 4.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – A bar plot of the TPSA and FormalCharge features ](img/B17761_04_005.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 – A bar plot of the TPSA and FormalCharge features
  prefs: []
  type: TYPE_NORMAL
- en: 'Immediately, we can see an interesting relationship between the two, in the
    sense that the `TPSA` feature tends to increase when the absolute value of `FormalCharge`
    is further away from zero. If you are following along with the provided `HDonors`)
    instead of `TPSA`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the subsequent output in *Figure 4.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – A bar plot of the HDonors and FormalCharge features ](img/B17761_04_006.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 – A bar plot of the HDonors and FormalCharge features
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking a look at the plot, we do not see as strong a relationship between the
    two variables. The highest and lowest formal charges do in fact show higher hydrogen
    donors. Let''s compare this to `HAcceptors` – a similar feature in this dataset.
    We could either plot this feature individually, as we did with the hydrogen donors,
    or we could combine them both into one diagram. We can do this by *isolating*
    the features of interest (do you remember the name of this step?) and then *reshaping*
    the dataset. DataFrames within Python are often **reshaped** using four common
    functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Four of the most common DataFrame reshaping functions ](img/B17761_04_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 – Four of the most common DataFrame reshaping functions
  prefs: []
  type: TYPE_NORMAL
- en: Each of these functions serves to reshape the data in a specific way. The `pivot()`
    function is often used to reshape a DataFrame organized by its index. The `stack()`
    function is often used with multi-index DataFrames – this allows you to *stack*
    your data, making the table *long and narrow* instead of *wide and short*. The
    `melt()` function is similar to the `stack()` function in the sense that it also
    *stacks* your data, but the difference between them is that `stack()` will insert
    the compressed columns into the inner index, whereas `melt()` will create a new
    column called `Variable`. Finally, `unstack()` is simply the opposite of `stack()`,
    in the sense that data is converted from *long* to *wide*.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the purposes of comparing the hydrogen donors and acceptors, we will be
    using the `melt()` function, which you can see in *Figure 4.8*. Note that two
    new columns are created in the process: `Variable` and `Value`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 – A graphical representation of the melt() function ](img/B17761_04_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 – A graphical representation of the melt() function
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we create a variable called `df_iso` to represent the isolated DataFrame,
    and then we use the `melt()` function to *melt* its data and assign it to a new
    variable called `df_melt`. We can also print the shape of the data to prove to
    ourselves that the columns *stack* correctly if they exactly *double* in length.
    Recall that you can also check the data using the `head()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, with the data ordered correctly, we can go ahead and plot this data,
    specifying the x-axis as `FormalCharge`, and the y-axis as `value`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon executing this line of code, we will get the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9 – A bar plot of two features relative to FormalCharge ](img/B17761_04_009.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 – A bar plot of two features relative to FormalCharge
  prefs: []
  type: TYPE_NORMAL
- en: As you begin to explore the many functions and classes within the `seaborn`
    library, referring to the documentation as you write your code can help you to
    debug errors and also uncover new functionality that you may not have known about.
    You can view the Seaborn documentation at [https://seaborn.pydata.org/api.html](https://seaborn.pydata.org/api.html).
  prefs: []
  type: TYPE_NORMAL
- en: Working with distributions and histograms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`40`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the output of this code in *Figure 4.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10 – A histogram of molecular weight with a bin size of 40 ](img/B17761_04_010.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.10 – A histogram of molecular weight with a bin size of 40
  prefs: []
  type: TYPE_NORMAL
- en: 'As you explore more visualization methods in Python, you will notice that most
    libraries offer a number of quick functions that have already been developed and
    optimized to perform a specific task. We could go through the same process of
    reshaping our data for each feature and iterate through them to plot a histogram
    for each of the features, or we could simply use the `hist()` function for them
    collectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The subsequent output can be seen in *Figure 4.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – A series of histograms for various features automated using
    the hist() function ](img/B17761_04_011.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.11 – A series of histograms for various features automated using the
    hist() function
  prefs: []
  type: TYPE_NORMAL
- en: 'Histograms can also be overlayed in order to showcase two features on the same
    plot. When doing this, we would need to give the plots a degree of transparency
    by using the `alpha` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the output of the preceding command in *Figure 4.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.12 – An overlay of two histograms where their opacity was reduced
    ](img/B17761_04_012.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.12 – An overlay of two histograms where their opacity was reduced
  prefs: []
  type: TYPE_NORMAL
- en: Histograms are wonderful ways to summarize and visualize data in large quantities,
    especially when the functionality is as easy as using the `hist()` function. You
    will find that most libraries – such as `pandas` and `numpy` – have numerous functions
    with similar functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing features with scatter plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Scatter plots** are representations based on *Cartesian coordinates* that
    allow for visualizations to be created in both two- and three-dimensional spaces.
    Scatter plots consist of an x-axis and a y-axis and are normally accompanied by
    an additional feature that allows for separation within the data. Scatter plots
    are best used when accompanied by a third feature that can be represented either
    by color or shape, depending on the data type available. Let''s look at a simple
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll take a look at an example of a simple scatter plot showing `TPSA` relative
    to the `HeavyAtoms` feature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output for the preceding code can be seen in *Figure 4.13*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.13 – A scatter plot of the TPSA and HeavyAtoms features ](img/B17761_04_013.png.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.13 – A scatter plot of the TPSA and HeavyAtoms features
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Immediately, we notice that there is some dependency between the two features,
    as shown by the slight positive correlation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We can take a look at a third feature, such as `MolWt`, by changing the color
    and size using the `hue` and `size` arguments, respectively. This gives us the
    ability to plot three or four features on the same graph, giving us an excellent
    interpretation of the dataset. We can see some trending among `TPSA` relative
    to `HeavyAtoms`, and increasing `MolWt`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the preceding code can be seen in *Figure 4.14*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.14 – A scatter plot of two features, with a third represented by
    size and color ](img/B17761_04_014.png.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.14 – A scatter plot of two features, with a third represented by size
    and color
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As an alternative to 2D scatter plots, we can use 3D scatter plots to introduce
    another feature in the form of a new dimension. We can take advantage of the `Plotly`
    library to implement some 3D functionality. To do this, we can define a `fig`
    object using the `scatter_3d` function, and subsequently, we define the source
    of our data and the axes of interest:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of this code will result in *Figure 4.15*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.15 – A 3D scatter plot of three features, colored by toxicity ](img/B17761_04_015.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.15 – A 3D scatter plot of three features, colored by toxicity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Instead of adding more features, we can add some more elements to the scatter
    plot to help interpret the two features on the x and y coordinates. We noticed
    earlier that there was a slight correlation within the dataset that seems ripe
    for exploration. It would be interesting to see if this correlation holds true
    for both toxic and non-toxic compounds. We can get a sense of the correlation
    using the `lmplot()` function, which allows us to graphically represent the correlation
    as a *linear regression* within the scatter plot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The subsequent output can be seen in *Figure 4.16*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.16 – A scatter plot of two features and their associated correlations
    ](img/B17761_04_016.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.16 – A scatter plot of two features and their associated correlations
  prefs: []
  type: TYPE_NORMAL
- en: Scatter plots are great ways to portray data relationships and begin to understand
    any dependencies or correlations they may have. Plotting regressions or lines
    of best fit can give you some insight into any possible relationships. We will
    explore this in greater detail in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying correlations with heat maps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have established a correlation between two molecular features within
    our dataset, let''s investigate to see if there are any others. We can easily
    go through each set of features, plot them, and look at their respective regressions
    to determine whether or not a correlation may exist. In Python, automating whenever
    possible is advised, and luckily for us, this task has already been automated!
    So, let''s take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the `pairplot()` function will take your dataset as input and return
    a figure of all the scatter plots for all of the features within your dataset.
    To fit the figure within the confines of this page, only the most interesting
    features were selected. However, I challenge you to run the code in the provided
    Jupyter notebook to see if there are any other interesting trends:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The results are presented in the form of numerous smaller graphs, as shown
    in *Figure 4.17*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.17 – A pairplot() graphic of the toxicity dataset for selected features
    ](img/B17761_04_017.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.17 – A pairplot() graphic of the toxicity dataset for selected features
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Alternatively, we can capture the *Pearson correlation* for each of the feature
    pairs using the `corr()` function in conjunction with the DataFrame itself:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can review these correlations as a DataFrame in *Figure 4.18*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.18 – A DataFrame showing the correlations between selected features
    ](img/B17761_04_018.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.18 – A DataFrame showing the correlations between selected features
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For a more visually appealing result, we can *wrap* our data within a `heatmap()`
    function and apply a color map to show dark colors for strong correlations and
    light colors for weaker ones:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Some of the code we have written so far has become a little complicated as
    we begin to *chain* multiple functions together. To provide some clarity of the
    syntax and structure, let''s take a closer look at the following function. We
    begin by calling the main `heatmap` class within the `seaborn` library (recall
    that we give this the alias `sns`). We then add our dataset, containing the sliced
    set of the features of interest. We then apply the correlation function to get
    the respective correlations, and finally add some additional arguments to style
    and color the plot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.19 – A heat map showing the correlation between selected features
    ](img/B17761_04_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.19 – A heat map showing the correlation between selected features
  prefs: []
  type: TYPE_NORMAL
- en: Identifying correlations within datasets will always be useful, regardless of
    whether you are analyzing data or preparing a predictive model. You will find
    that `corr()` and many of its derivatives are commonly used in the machine learning
    space.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying sequential and time-series plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The datasets and features we have explored so far have all been provided in
    a *structured* and *tabular* form, existing as rows and columns within DataFrames.
    These rows are fully independent of each other. This is not always the case in
    all datasets, and *dependence* (especially *time-based dependence*) is sometimes
    a factor we need to consider. For example, take a **Fast All** (**FASTA**) sequence
    – that is, a text-based format often used in the realm of bioinformatics for representing
    nucleotide or amino acid sequences via letter codes. In molecular biology and
    genetics, a parameter known as **Guanine-Cytosine** (**GC**) **content** is a
    metric used to determine the percent of nitrogenous bases within DNA or RNA molecules.
    Let''s explore plotting this sequential data using a FASTA file for COVID-19 data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin the process by importing the dataset using the `wget` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we can calculate the GC content using the `Biopython` (also called `Bio`)
    library – one of the most commonly utilized Python libraries in the computational
    molecular biology space. The documentation and tutorials for the `Biopython` library
    can be found at [http://biopython.org/DIST/docs/tutorial/Tutorial.html](http://biopython.org/DIST/docs/tutorial/Tutorial.html).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will then parse the file using the `SeqIO` and `GC` classes and write the
    results to the `gc_values_covid` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Please note that the path to the file in the preceding code may change depending
    on which directory the file was saved in.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, we can go ahead and plot the results using either `pylab` or `matplotlib`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The subsequent output can be seen in *Figure 4.20*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.20 – A plot showing the GC content of the COVID-19 sequence ](img/B17761_04_020.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.20 – A plot showing the GC content of the COVID-19 sequence
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are many non-time-based sequential datasets such as `text`, `images`,
    and `audio`, there are also time-based datasets such as `stock prices` and `manufacturing
    processes`. Within the laboratory space, there are many pieces of equipment that
    also utilize time series-based approaches, such as those relating to chromatography.
    For example, take `time-series` dataset and overlay `Temperature` and `Pressure`
    together over time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this code can be seen in *Figure 4.21*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.21 – A time-series plot showing the temperature and pressure of
    a failed LCMS run ](img/B17761_04_021.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.21 – A time-series plot showing the temperature and pressure of a failed
    LCMS run
  prefs: []
  type: TYPE_NORMAL
- en: We notice that within the first 5 minutes of this graph, the temperature and
    pressure parameters are increasing quite quickly. A dip of some sort occurs within
    the 6.5-minute range, and the system keeps increasing for a moment, then both
    parameters begin to plummet downward and level out at their respective ranges.
    This is an example of an instrument failure, and it is a situation that a finely
    tuned machine learning model would be able to detect relative to its successful
    counterpart. We will explore the development of this anomaly detection model in
    greater detail in [*Chapter 7*](B17761_07_Final_JM_ePub.xhtml#_idTextAnchor101),
    *Supervised Machine Learning*.
  prefs: []
  type: TYPE_NORMAL
- en: Emphasizing flows with Sankey diagrams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A popular form of visualization in data science is the **Sankey diagram** –
    made famous by Minard''s classic depiction of Napoleon''s army during the invasion
    of Russia. The main purpose of a Sankey diagram is to visualize a magnitude in
    terms of its proportional width on a flow diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.22 – A Sankey diagram by Charles Joseph Minard depicting Napoleon''s
    march to Russia ](img/B17761_04_022.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.22 – A Sankey diagram by Charles Joseph Minard depicting Napoleon's
    march to Russia
  prefs: []
  type: TYPE_NORMAL
- en: 'Sankey diagrams are often used to depict many applications across various sectors.
    Biotechnology and health sector applications of Sankey diagrams include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Depictions of drug candidates during clinical trials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Process flow diagrams for synthetic molecules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Process flow diagrams for microbial fermentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Project flow diagrams and success rates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Financial diagrams depicting costs within an organization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s visualize a simple example of a company''s drug candidate pipeline.
    We''ll take the total number of candidates, their classification by phase, and
    finally, their designation by modality as small or large molecules. We can take
    advantage of the `Plotly` library to assist us with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This segment of code is quite long and complex – let''s try to break this down.
    The `figure` object consists of several arguments we need to take into account.
    The first is `pad`, which describes the spacing between the *nodes* of the visualization.
    The second describes the `thickness` value of the node''s bars. The third sets
    the `color` and `width` values of the lines. The fourth contains the `label` names
    of the nodes. And finally, we arrive at the data, which has been structured in
    a slightly different way to how we are accustomed. In this case, the dataset is
    divided into a `source` array (or origin), the `target` array, and the `value`
    array associated with it. Starting on the left-hand side, we see that the first
    value of `source` is node `0`, which goes to the `target` of node `1`, with a
    `value` of `15`. Reading the process in this fashion makes the flow of the data
    a little clearer to the user or developer. Finally, we can go ahead and plot the
    image using `show()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram displays the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.23 – A Sankey diagram representing a company''s pipeline ](img/B17761_04_023.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.23 – A Sankey diagram representing a company's pipeline
  prefs: []
  type: TYPE_NORMAL
- en: Sankey diagrams are a great way to show the flow or transfer of information
    over time or by category. In the preceding example, we looked at its application
    in terms of small and large molecules within a pipeline. Let's now take a look
    at how we can visualize these molecules.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing small molecules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When it comes to small molecules, there are a number of ways we can visualize
    them using various software platforms and online services. Luckily, there exists
    an excellent library commonly utilized for `rdkit` library can be installed using
    `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We can parse the DataFrame we imported earlier in this tutorial and extract
    a sample `smiles` string via indexing. We can then create a molecule object using
    the `MolFromSmiles()` function within the `Chem` class of `rdkit` using the `smiles`
    string as the single argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this variable can be seen in *Figure 4.24*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.24 – A representation of a small molecule ](img/B17761_04_024.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.24 – A representation of a small molecule
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check the structure of another molecule by looking at a different index
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, our output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.25 – A representation of a small molecule ](img/B17761_04_025.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.25 – A representation of a small molecule
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to rendering print-ready depictions of small molecules, the `rdkit`
    library also supports a wide variety of functions related to the analysis, prediction,
    and calculation of small molecule properties. In addition, the library also supports
    the use of charge calculations, as well as similarity maps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code can be seen in *Figure 4.26*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.26 – A representation of a small molecule''s charge ](img/B17761_04_026.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.26 – A representation of a small molecule's charge
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have gained an idea of how we can use RDKit to represent small molecules,
    let's look at an application of this for large molecules instead.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing large molecules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a number of Python libraries designed for the visualization, simulation,
    and analysis of large molecules for the purposes of research and development.
    Currently, one of the most common libraries is `py3Dmol`. Exclusively used for
    the purposes of 3D visualization within a Jupyter Notebook setting, this library
    allows for the creation of publication-ready visuals of 3D proteins. The library
    can be easily downloaded using the `pip` framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the time of writing, the world is still in the midst of dealing with the
    COVID-19 virus that originated in Wuhan, China and spread throughout the world.
    On July 8, 2020, a 1.7 Å resolution structure of the *SARS-CoV-2 3CL* protease
    was released in the `pdb = 6XMK`. Let''s go ahead and use this protein as an example
    in the following visualizations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can begin the development of this visual using the `py3dmol` library and
    querying the protein structure directly within the following function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the library imported, a new variable object called `lm` can be specified
    using the `view` class in `py3Dmol`. This function takes three main arguments.
    The first is the identity of the protein of interest, namely `6xmk`. The second
    and third arguments are the width and height of the display window, respectively.
    For more information about PDB files, visit the `stick` argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upon executing this line of code, we get the following image of the molecule:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.27 – A representation of a large molecule or protein in ball-stick
    form ](img/B17761_04_027.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.27 – A representation of a large molecule or protein in ball-stick
    form
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Notice that we added a `stick` argument that displayed the last structure.
    We can change this argument to `cartoon` to see a cartoon representation of this
    protein based on its *secondary structure*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When executing this line of code, we get the following image of the molecule:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.28 – A representation of a large molecule or protein''s secondary
    structure ](img/B17761_04_028.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 4.28 – A representation of a large molecule or protein's secondary structure
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'There are a number of other changes and arguments that can be added to custom
    fit this visualization to a user''s particular aims. One of these changes is the
    addition of a **Van der Waals surface**, which allows for the illustration of
    the area through which a molecular interaction might occur. We will add this surface
    to only one of the two chains on this protein:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can see the output of this code in *Figure 4.29*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.29 – A representation of a large molecule or protein''s secondary
    structure with a Van der Waals surface on one of the chains](img/B17761_04_029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.29 – A representation of a large molecule or protein's secondary structure
    with a Van der Waals surface on one of the chains
  prefs: []
  type: TYPE_NORMAL
- en: The study of large molecules, or **biologics**, have shown tremendous growth
    in the biotechnology sector in recent years. Within this chapter, we briefly introduced
    one of the many methods used to visualize these complex molecules – an important
    first step for any bioinformatics project.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Visualizations can be useful, powerful, and convincing tools to help illustrate
    points and drive conversations in specific directions. To create a proper visualization,
    there are certain steps and techniques that need to be taken to ensure your diagram
    is correct and effective.
  prefs: []
  type: TYPE_NORMAL
- en: Within this chapter, we explored the six main steps to follow when creating
    a proper visualization. We also explored many different methods and libraries
    within the scope of Python to help you create and style visuals for your specific
    aims. We explored some of the more basic visuals, such as bar plots, histograms,
    and scatter plots to analyze a few features at a time. We also explored more complex
    visualizations such as pair plots, heat maps, Sankey diagrams, and molecular representations,
    with which we can explore many more features.
  prefs: []
  type: TYPE_NORMAL
- en: We also touched on the concept of *correlation* and how certain features can
    have relationships with others – a concept we will cover in greater detail as
    we turn our attention to **machine learning** in the next chapter.
  prefs: []
  type: TYPE_NORMAL
