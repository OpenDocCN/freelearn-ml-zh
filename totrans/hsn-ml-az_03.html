<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Cognitive Services</h1>
                </header>
            
            <article>
                
<p>Cognitive Services are a set of pre-trained APIs from Microsoft that allow developers to develop applications that use AI without having to build ML models. With their support for edge deployment, developers can build applications that use powerful AI algorithms to interpret, listen, speak, and see on devices such as a drone. </p>
<p>There are five main categories of APIs:</p>
<ul>
<li>Vision</li>
<li>Language</li>
<li>Speech</li>
<li>Knowledge</li>
<li>Search</li>
</ul>
<p>Many of these APIs are now customizable to meet the specific needs of companies and their customers. In this chapter, we will look at an overview of each service category and go through a number of examples.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Cognitive Services for Vision APIs</h1>
                </header>
            
            <article>
                
<p>The Vision APIs help you to add image analysis capabilities to your AI application. At the time of writing, there are five Vision APIs included with Cognitive Services:</p>
<ul>
<li>Computer Vision</li>
<li>Face</li>
<li>Content Moderator</li>
<li>Video Indexer</li>
<li>Custom Vision</li>
</ul>
<p><span>We will be learning about the first two APIs in this chapter. We will leave the rest for you to explore on your own.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The Computer Vision API</h1>
                </header>
            
            <article>
                
<p>This API provides tags for images based on various recognizable objects, living beings, actions, and scenery. After uploading an image or specifying an image's URL, the algorithm of the Computer Vision API comes up with tags that it identified in the image. This might include the main subject, the setting (indoor or outdoor), furniture, tools, plants, animals, accessories, and gadgets.</p>
<p>Let's take a look at an example image:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/94bf3272-5611-4377-bab1-90b4814d7d32.png" style="width:31.33em;height:21.58em;" width="640" height="440"/></p>
<p>We send this to the API and get the output in JSON format. This will show us the tags and the confidence that is associated with each tag:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td style="width: 10%">
<p><strong>Tags</strong></p>
</td>
<td style="width: 89.1736%">
<p><kbd>[</kbd></p>
<p><kbd>{ "name": "bench", "confidence": 0.999963641 ...</kbd></p></td></tr></tbody></table></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Face API</h1>
                </header>
            
            <article>
                
<p>Let's now look at the next API in the Vision category, the Face API.</p>
<p>This can be used to detect human faces and compare similar ones. It will also indicate facial attributes, including age, emotion, gender, and hair color.</p>
<p>Let's take a look at an example image: </p>
<div class="CDPAlignCenter"><img src="Images/1284b5ac-51c4-4ff5-bf5e-138cb2f4cdbe.png" style="width:21.00em;height:17.25em;" width="585" height="480"/></div>
<div><span>If we send this input image to the API, we get the following output in JSON</span> format:</div>
<pre>//output omitted<br/>"faceAttributes": {<br/>      "hair": {<br/>        "bald": 0.01,<br/>        "invisible": false,<br/>        "hairColor": [<br/>          {<br/>            "color": "blond",<br/>            "confidence": 1.0<br/>          },<br/>          {<br/>            "color": "brown",<br/>            "confidence": 0.87<br/>          },<br/>        //omitted<br/>        ]<br/>      },<br/>      "smile": 0.018,<br/>      "headPose": {<br/>        "pitch": 0.0,<br/>        "roll": 3.2,<br/>        "yaw": -23.3<br/>      },<br/>      "gender": "female",<br/>      "age": 24.4,<br/>      "facialHair": {<br/>        "moustache": 0.0,<br/>        "beard": 0.0,<br/>        "sideburns": 0.0<br/>      },<br/>      "glasses": "NoGlasses",      "makeup": {<br/>        "eyeMakeup": true,<br/>        "lipMakeup": true<br/>      },<br/>      "emotion": {<br/>        "anger": 0.001,<br/>        "contempt": 0.002,<br/>        "disgust": 0.002,<br/>        "fear": 0.0,<br/>        "happiness": 0.018,<br/>        "neutral": 0.969,<br/>        "sadness": 0.006,<br/>        "surprise": 0.002<br/>      },<br/>//output omitted</pre>
<p>To try out the Face API <span>quickly</span><span>, you can go to the following URL:</span> <a href="https://azure.microsoft.com/en-us/services/cognitive-services/face/">https://azure.microsoft.com/en-us/services/cognitive-services/face/</a>.</p>
<p>Just like the Computer Vision API, you can call the Face API using Python or any other language. The steps for creating the Face API resource are similar to the Computer Vision API, except that you must search for Face API in the portal, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/4fcf4e0a-f0da-48a6-91ef-e6190e96e2b4.png" width="1712" height="588"/></p>
<p class="mce-root"/>
<div class="packt_infobox">For more information about the remaining Vision APIs, you can go to the following URL: <a href="https://azure.microsoft.com/en-us/services/cognitive-services/directory/vision/">https://azure.microsoft.com/en-us/services/cognitive-services/directory/vision/</a>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Cognitive Services for Language APIs</h1>
                </header>
            
            <article>
                
<p>Language APIs allow us to add text analysis, translation, and other capabilities to our AI applications. At the time of writing, Cognitive Services provide five language APIs:</p>
<ul>
<li>
<p>Text Analytics</p>
</li>
<li>
<p>Translator Text</p>
</li>
<li>
<p>Bing Spell Check</p>
</li>
<li>
<p>Content Moderator</p>
</li>
<li>
<p>Language Understanding</p>
</li>
</ul>
<p><span>In this chapter, we will just look at the first API. We'll leave the others for you to explore on your own.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Text Analytics</h1>
                </header>
            
            <article>
                
<p>The Text Analytics API can be used to detect sentiment, key phrases, entities, and language from your text. The following is an example that sends an input text to the API and gets the following output in JSON format. The text was as follows: <kbd>I am excited about using AI offerings by Microsoft</kbd>:</p>
<pre class="mce-root">{  "languageDetection": {    "documents": [      {        "id": "fe2529ff-073e-4355-86fa-b927d1b62a23",        "detectedLanguages": [          {            "name": "English",            "iso6391Name": "en",            "score": 1.0          }        ]      }    ],    "errors": []  },  "keyPhrases": {    "documents": [      {        "id": "fe2529ff-073e-4355-86fa-b927d1b62a23",        "keyPhrases": [          "Microsoft's offerings",          "AI space"        ]      }    ],    "errors": []  },  "sentiment": {    "documents": [      {        "id": "fe2529ff-073e-4355-86fa-b927d1b62a23",        "score": 0.93527746200561523      }    ],    "errors": []  },  "entities": {    "documents": [      {        "id": "fe2529ff-073e-4355-86fa-b927d1b62a23",        "entities": [          {            "name": "Microsoft",            "matches": [              {                "text": "Microsoft's",                "offset": 25,                "length": 11              }            ],            "wikipediaLanguage": "en",            "wikipediaId": "Microsoft",            "wikipediaUrl": "https://en.wikipedia.org/wiki/Microsoft",            "bingId": "a093e9b9-90f5-a3d5-c4b8-5855e1b01f85"          },          {            "name": "Ai Space",            "matches": [              {                "text": "AI space",                "offset": 50,                "length": 8              }            ],            "wikipediaLanguage": "en",            "wikipediaId": "Ai Space",            "wikipediaUrl": "https://en.wikipedia.org/wiki/Ai_Space",            "bingId": "2d055fa3-b3cc-e9f6-776a-77b6ed7f341f"          }        ]      }    ],    "errors": []  }}</pre>
<p>To try out the Text Analytics API <span>quickly</span><span>, go to the following URL:</span> <a href="https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/">https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/</a>.</p>
<p>As an AI developer, you can use any language to call the API. In this example, we will look at how to call the API using Python. A similar approach can be used for other programming languages:</p>
<ol>
<li>
<p>Create a Text Analytics API Cognitive Services resource from the Azure portal: <a href="https://portal.azure.com">https://portal.azure.com</a>.</p>
</li>
<li>
<p>Navigate to the API, as shown in the following screenshot. Click on <span class="packt_screen">Create a resource</span>, then <span class="packt_screen">AI + Machine Learning</span>, and then <span class="packt_screen">Text Analytics</span>:</p>
</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/eb446d3f-89a7-439b-8105-129a78e5c63e.png" style="width:55.33em;height:53.42em;" width="1715" height="1657"/></div>
<ol start="3">
<li>Alternatively, you can search for <kbd>Text Analytics</kbd> in the Azure portal:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/dd3d3083-be95-43a5-9920-5e62c9fc17d9.png" style="width:57.50em;height:23.00em;" width="1706" height="683"/></div>
<ol start="4">
<li>Provide a name for your service and then select an appropriate Azure subscription, a location, and a pricing tier (either free or paid). You will also need to create a new resource group or select an existing one:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/69614c31-8086-4d34-ad23-6abd60da9b80.png" style="width:33.33em;height:51.92em;" width="851" height="1326"/></div>
<ol start="5">
<li>It will take less than a minute to create the API. Once it is created, you will see the <span class="packt_screen">Quick Start</span> page, which has links to the API keys and its documentation. You will need the API keys to access the API from your Python (or any other language)<span> </span>code, or the code for whichever language you are using. Once you create the API, you will see the following screen:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/967b3f1f-b46c-424a-ac80-e6338d28bfd8.png" style="width:48.42em;height:30.33em;" width="2550" height="1597"/></div>
<ol start="6">
<li>Use your favorite Python editor and call the API using the following sample code:</li>
</ol>
<pre style="padding-left: 60px"># Replace &lt;Subscription Key&gt; with your valid subscription's api access key.<br/>subscription_key = "&lt;Access Key&gt;"<br/>assert subscription_key<br/><br/># Replace the base url with what you see as Endpoint in the portal’s Overview section under your api<br/>text_analytics_base_url = "https://westus2.api.cognitive.microsoft.com/text/analytics/v2.0/"<br/>sentiment_api_url = text_analytics_base_url + "sentiment"<br/><br/># Send the text you want the api to analyze<br/># You can send multiple texts<br/>documents = {'documents' : [<br/>  {'id': '1', 'text': 'I am excited about using AI offerings by Microsoft.'},<br/>]}<br/><br/>import requests<br/># Get sentiment of text<br/>headers   = {"Ocp-Apim-Subscription-Key": subscription_key}<br/>response  = requests.post(sentiment_api_url, headers=headers, json=documents)<br/>sentiments = response.json()<br/>print(sentiments)<br/><br/># Get the language of text<br/>language_api_url = text_analytics_base_url + "languages"<br/>response  = requests.post(language_api_url, headers=headers, json=documents)<br/>languages = response.json()<br/>print(languages)<br/><br/># Get key phrases from text<br/>key_phrase_api_url = text_analytics_base_url + "keyPhrases"<br/>response  = requests.post(key_phrase_api_url, headers=headers, json=documents)<br/>key_phrases = response.json()<br/>print(key_phrases)<br/><br/># Get well-known entities<br/>entity_linking_api_url = text_analytics_base_url + "entities"<br/>response  = requests.post(entity_linking_api_url, headers=headers, json=documents)<br/>entities = response.json()<br/>print(entities)</pre>
<ol start="7">
<li>When you run the preceding code, you will see an output that looks as follows:</li>
</ol>
<pre style="padding-left: 60px"><br/>{'documents': [{'id': '1', 'score': 0.9388835430145264}], 'errors': []}{'documents': [{'detectedLanguages': [{'iso6391Name': 'en', 'name': 'English', 'score': 1.0}], 'id': '1'}], 'errors': []}<br/>{'documents': [{'keyPhrases': ['AI offerings', 'Microsoft'], 'id': '1'}], 'errors': []}<br/>{'documents': [{'id': '1', 'entities': [{'name': 'Microsoft', 'wikipediaId': 'Microsoft', 'matches': [{'offset': 41, 'length': 9, 'text': 'Microsoft'}], 'bingId': 'a093e9b9-90f5-a3d5-c4b8-5855e1b01f85', 'wikipediaUrl': 'https://en.wikipedia.org/wiki/Microsoft', 'wikipediaLanguage': 'en'}, {'name': 'Artificial intelligence', 'wikipediaId': 'Artificial intelligence', 'matches': [{'offset': 25, 'length': 2, 'text': 'AI'}], 'bingId': '9d99fb44-edac-0e03-1579-19d8d8591a49',<br/>'wikipediaUrl': 'https://en.wikipedia.org/wiki/Artificial_intelligence', 'wikipediaLanguage': 'en'}]}], 'errors': []}</pre>
<p style="padding-left: 90px">A sentiment score of 0.93 indicates a positive sentiment. The API detected English as the language, and two key phrases and entities.</p>
<ol start="8">
<li>Each transaction equates to one API call. The portal will show details that you can monitor, such as total calls, errors, latency, and data in/out. In the preceding example, we called four different APIs: <kbd>sentiment</kbd>, <kbd>languages</kbd>, <kbd>keyPhrases</kbd>, and <kbd>entities</kbd>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="Images/de19e7f5-f855-4d9c-ae59-716784706177.png" width="1379" height="809"/></div>
<div class="packt_tip">To find more information about the remaining Language APIs, you can go to the following URL: <a href="https://azure.microsoft.com/en-us/services/cognitive-services/directory/lang/">https://azure.microsoft.com/en-us/services/cognitive-services/directory/lang/</a>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Cognitive Services for Speech APIs</h1>
                </header>
            
            <article>
                
<p>The Speech APIs help you to add various capabilities related to speech-to-text and text-to-speech operations to your AI application.</p>
<p>At the time of writing, Cognitive Services provide four Speech APIs:</p>
<ul>
<li>
<p>Speech to Text</p>
</li>
<li>
<p>Text to Speech</p>
</li>
<li>
<p>Speaker Recognition</p>
</li>
<li>
<p>Speech Translation</p>
</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Speech to Text</h1>
                </header>
            
            <article>
                
<p>The Speech to Text API can help convert spoken audio to text. The audio can either be real-time audio or audio that is being streamed from a recording. You can find more information at <a href="https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/">https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/</a>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Cognitive Services for Knowledge APIs</h1>
                </header>
            
            <article>
                
<p>The Knowledge APIs help parse through complex information and map it in a way that makes it easy to consume, based on natural language processing.</p>
<p>At the time of writing, there is one Knowledge API-based service: <span>QnA Maker.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">QnA Maker</h1>
                </header>
            
            <article>
                
<p>This API allows you to extract questions and answers <span>quickly</span><span> </span><span>from</span> <span>text that is in the form of FAQs</span> <span>by parsing it intelligently. Once this information is available, it can be used to create a question-and-answer bot. You can find more information at <a href="https://azure.microsoft.com/en-us/services/cognitive-services/qna-maker/">https://azure.microsoft.com/en-us/services/cognitive-services/qna-maker/</a>.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Cognitive Services for Search APIs</h1>
                </header>
            
            <article>
                
<p>The Search APIs help you search different types of content without having to develop complex search algorithms.</p>
<p>At the time of writing, Cognitive Services provides eight APIs:</p>
<ul>
<li>
<p>Bing Web Search</p>
</li>
<li>
<p>Bing Custom Search</p>
</li>
<li>
<p>Bing Video Search</p>
</li>
<li>
<p>Bing Image Search</p>
</li>
<li>
<p>Bing Visual Search</p>
</li>
<li>
<p>Bing Entity Search</p>
</li>
<li>
<p>Bing News Search</p>
</li>
<li>
<p>Bing Autosuggest</p>
</li>
</ul>
<p>In this chapter, we will discuss one API, Bing Visual Search, and leave you to explore the remaining APIs on your own.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Bing Visual Search</h1>
                </header>
            
            <article>
                
<p>The Bing Visual Search API allows users to identify entities and text within images. This means that they can carry out a range of actions, including deriving information from an image and finding similar images, products, and objects in a range of categories, including fashion, landmarks, flowers, celebrities, and others. Bing Visual Search can extract information from business cards and can be customized for specific domains.</p>
<p>The following screenshot shows an example of an input image that was sent to the API. <span>We then received an output in JSON form, which could be parsed and displayed on the web page, as shown on the right-hand side of the screenshot: </span></p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/791a3ce7-50bc-4da4-806d-2befcfe70b1e.png" width="1360" height="594"/></div>
<p>To try out this API or to call the API, programmatically, you can go to the following URL: <a href="https://azure.microsoft.com/en-us/services/cognitive-services/bing-visual-search/">https://azure.microsoft.com/en-us/services/cognitive-services/bing-visual-search/</a> . It also contains the API reference documentation.</p>
<div class="packt_tip">For the remaining Search APIs, you can go to the following URL: <a href="https://azure.microsoft.com/en-us/services/cognitive-services/directory/search/">https://azure.microsoft.com/en-us/services/cognitive-services/directory/search/</a>.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have learned how to use Cognitive Services to develop AI applications <span>quickly</span><span>. In the next</span> c<span>hapter, we will learn about the Bot Framework, which is used to build bots.</span></p>




            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Reference</h1>
                </header>
            
            <article>
                
<ul>
<li>All Cognitive Services can be accessed from the following URL: <a href="https://azure.microsoft.com/en-us/services/cognitive-services/">https://azure.microsoft.com/en-us/services/cognitive-services/</a></li>
</ul>


            </article>

            
        </section>
    </div>



  </body></html>