- en: '15'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '15'
- en: Building a CNN Model for CIFAR-10 with ChatGPT
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 ChatGPT 构建 CIFAR-10 的 CNN 模型
- en: Introduction
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: Having explored the depths of the **Multi-Layer Perceptron** (**MLP**) in our
    previous chapter with the Fashion-MNIST dataset, we now pivot to a more intricate
    and visually complex challenge. This chapter marks our transition from the primarily
    tabular, grayscale world of Fashion-MNIST to the colorful and diverse realm of
    the CIFAR-10 dataset. Here, we elevate our focus to **Convolutional Neural Networks**
    (**CNNs**), a class of deep neural networks that are revolutionizing the way we
    approach image classification tasks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们上一章中通过 Fashion-MNIST 数据集深入探讨了多层感知器（**Multi-Layer Perceptron**，**MLP**）之后，我们现在转向一个更复杂和视觉上更复杂的挑战。本章标志着我们从主要基于表格、灰度世界的
    Fashion-MNIST 转向色彩丰富和多样化的 CIFAR-10 数据集。在这里，我们将重点提升到 **卷积神经网络**（**Convolutional
    Neural Networks**，**CNNs**），这是一类正在改变我们处理图像分类任务方式的深度神经网络。
- en: Our journey through the MLP chapter provided a strong foundation for understanding
    the basics of neural networks and their application in classifying simpler, grayscale
    images. Now, we step into a more advanced territory where CNNs reign supreme.
    The CIFAR-10 dataset, with its array of 32x32 color images across 10 different
    classes, presents a unique set of challenges that MLPs are not best suited to
    address. This is where CNNs, with their ability to capture spatial and textural
    patterns in images, come into play.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 MLP 章节中的旅程为我们理解神经网络的基本原理及其在分类简单灰度图像中的应用奠定了坚实的基础。现在，我们进入了一个更高级的领域，在这里 CNNs
    占据主导地位。CIFAR-10 数据集包含 10 个不同类别中 32x32 彩色图像的阵列，为 MLPs 提供了一系列独特的挑战，MLPs 并不适合解决这些问题。这就是
    CNNs 发挥作用的地方，它们能够捕捉图像中的空间和纹理模式。
- en: As we transition from MLPs to CNNs, we carry forward the insights and knowledge
    gained, applying them to a more complex dataset that closely mimics real-world
    scenarios. The CIFAR-10 dataset not only tests the limits of image classification
    models but also serves as an excellent platform for us to explore the advanced
    capabilities of CNNs.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们从多层感知器（MLPs）过渡到 CNNs，我们将所获得的见解和知识应用于更复杂的数据集，这些数据集更接近现实世界场景。CIFAR-10 数据集不仅测试了图像分类模型的极限，而且为我们探索
    CNNs 的高级功能提供了一个极好的平台。
- en: This chapter aims to build upon what we learned about neural networks and guide
    you through the nuances of CNNs. We will delve into why CNNs are the preferred
    choice for image data, how they differ from MLPs in handling color and texture,
    and what makes them so effective in classifying images from the CIFAR-10 dataset.
    Prepare to embark on a journey that takes you from the fundamentals to the more
    sophisticated aspects of CNNs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在基于我们对神经网络的知识，并引导你了解卷积神经网络（CNNs）的细微差别。我们将深入探讨为什么 CNNs 是图像数据的优选选择，它们在处理颜色和纹理方面与
    MLPs 的不同之处，以及是什么使得它们在从 CIFAR-10 数据集中对图像进行分类时如此有效。准备好开始一段旅程，带你从基础到 CNNs 更为复杂方面的深入探索。
- en: Business problem
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 商业问题
- en: The CIFAR-10 dataset presents a business challenge to companies seeking to enhance
    image recognition capabilities for various objects and optimize decision-making
    processes based on visual data. A multitude of industries, such as e-commerce,
    autonomous driving, and surveillance, can benefit from accurate object classification
    and detection. By harnessing machine learning algorithms, businesses aim to improve
    efficiency, enhance their user experience, and streamline operations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10 数据集为寻求增强各种对象图像识别能力并基于视觉数据优化决策过程的公司提出了一个商业挑战。众多行业，如电子商务、自动驾驶和监控，都可以从准确的对象分类和检测中受益。通过利用机器学习算法，企业旨在提高效率、提升用户体验并简化运营流程。
- en: Problem and data domain
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题与数据领域
- en: In this context, we will utilize CNNs to tackle the object recognition task
    using the CIFAR-10 dataset. CNNs are particularly effective for image-related
    problems due to their ability to automatically learn hierarchical features from
    raw pixel data. By training a CNN model on the CIFAR-10 dataset, we aim to develop
    a robust system capable of accurately classifying objects into one of the ten
    predefined categories. This model can be applied in various domains, such as image-based
    search engines, automated surveillance systems, and quality control in manufacturing.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，我们将利用卷积神经网络（CNNs）来处理使用 CIFAR-10 数据集的对象识别任务。由于 CNNs 能够从原始像素数据中自动学习层次化特征，它们在处理与图像相关的问题上特别有效。通过在
    CIFAR-10 数据集上训练 CNN 模型，我们的目标是开发一个能够准确地将对象分类到十个预定义类别之一的鲁棒系统。该模型可以应用于多个领域，例如基于图像的搜索引擎、自动监控系统以及制造业的质量控制。
- en: Dataset overview
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集概述
- en: The CIFAR-10 dataset comprises 60,000 color images, divided into 10 classes,
    with 6,000 images per class. Each image has dimensions of 32x32 pixels and is
    represented in RGB format. The dataset is split into a training set of 50,000
    images and a test set of 10,000 images.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10数据集包含60,000张彩色图像，分为10个类别，每个类别有6,000张图像。每张图像的尺寸为32x32像素，并以RGB格式表示。数据集分为包含50,000张图像的训练集和包含10,000张图像的测试集。
- en: 'Features in the dataset include:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的特征包括：
- en: '**Image data**: Color images of various objects, each represented as a 3-dimensional
    array containing pixel intensities for red, green, and blue channels. These images
    serve as input data for training the CNN model.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像数据**：各种对象的彩色图像，每个图像表示为一个包含红、绿、蓝通道像素强度的三维数组。这些图像作为训练CNN模型的输入数据。'
- en: '**Label**: The class label assigned to each image, representing the category
    of the depicted object. The labels range from 0 to 9, corresponding to classes
    such as airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签**：分配给每张图像的类别标签，代表所描绘对象的类别。标签范围从0到9，对应于如飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车等类别。'
- en: By analyzing the CIFAR-10 dataset and its associated labels, our goal is to
    train a CNN model capable of accurately identifying objects depicted in images.
    This predictive model can then be deployed in real-world applications to automate
    object recognition tasks, improve decision-making processes, and enhance overall
    efficiency in diverse industries.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析CIFAR-10数据集及其相关标签，我们的目标是训练一个能够准确识别图像中描绘对象的CNN模型。然后，此预测模型可以部署到实际应用中，以自动化对象识别任务，改进决策过程，并提高各行业的整体效率。
- en: '![](img/B21232_15_01.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21232_15_01.png)'
- en: 'Figure 15.1: CIFAR-10 dataset'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.1：CIFAR-10数据集
- en: Breaking the problem down into features
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将问题分解为特征
- en: 'Given the CIFAR-10 dataset and the application of CNNs for image recognition,
    we outline the following features to guide users through building and optimizing
    CNN models:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于CIFAR-10数据集和CNN在图像识别中的应用，我们概述以下功能，以指导用户构建和优化CNN模型：
- en: '**Building the baseline CNN model with a single convolutional layer**: Users
    will start by constructing a simple CNN model with a single convolutional layer
    for image classification. This feature focuses on defining the basic architecture,
    including convolutional filters, activation functions, and pooling layers, to
    establish a foundational understanding of CNNs.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**构建具有单个卷积层的基线CNN模型**：用户将首先构建一个简单的CNN模型，其中包含单个卷积层用于图像分类。此功能侧重于定义基本架构，包括卷积滤波器、激活函数和池化层，以建立对CNN的基础理解。'
- en: '**Experimenting with the addition of convolutional layers**: Users will explore
    the impact of adding additional convolutional layers to the baseline model architecture.
    By incrementally increasing the depth of the network, users can observe how the
    model’s capacity to capture hierarchical features evolves and its ability to learn
    complex patterns improves.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验添加卷积层**：用户将探索向基线模型架构添加额外卷积层的影响。通过逐步增加网络的深度，用户可以观察到模型捕捉层次特征的能力如何演变，以及其学习复杂模式的能力如何提高。'
- en: '**Incorporating dropout regularization**: Users will learn how to integrate
    dropout regularization into the CNN model to mitigate overfitting and improve
    generalization performance. By randomly dropping units during training, dropout
    helps prevent the network from relying too heavily on specific features and encourages
    robust feature learning.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**整合dropout正则化**：用户将学习如何将dropout正则化集成到CNN模型中，以减轻过拟合并提高泛化性能。通过在训练过程中随机丢弃单元，dropout有助于防止网络过度依赖特定特征，并鼓励鲁棒的特征学习。'
- en: '**Implementing batch normalization**: Users will explore the benefits of batch
    normalization in stabilizing training dynamics and accelerating convergence. This
    feature focuses on incorporating batch normalization layers into the CNN architecture
    to normalize activations and reduce internal covariate shift, leading to faster
    and more stable training.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实现批量归一化**：用户将探索批量归一化在稳定训练动态和加速收敛方面的好处。此功能侧重于将批量归一化层集成到CNN架构中，以归一化激活并减少内部协变量偏移，从而实现更快、更稳定的训练。'
- en: '**Optimizing with different optimizers**: This feature explores the effects
    of using various optimization algorithms, including SGD, Adam, and RMSprop, to
    train the CNN model. Users will compare the training dynamics, convergence speed,
    and final model performance achieved with different optimizers, allowing them
    to select the most suitable optimization strategy for their specific task.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用不同的优化器进行优化**：本功能探讨了使用各种优化算法（包括 SGD、Adam 和 RMSprop）来训练 CNN 模型的效果。用户将比较使用不同优化器获得的训练动态、收敛速度和最终模型性能，从而能够为他们的特定任务选择最合适的优化策略。'
- en: '**Performing data augmentation**: Users will experiment with data augmentation
    techniques such as rotation, flipping, zooming, and shifting to increase the diversity
    and size of the training dataset. By generating augmented samples on the fly during
    training, users can improve the model’s ability to generalize to unseen data and
    enhance robustness against variations in input images.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行数据增强**：用户将尝试旋转、翻转、缩放和移位等数据增强技术，以增加训练数据集的多样性和规模。通过在训练过程中动态生成增强样本，用户可以提高模型泛化到未见数据的能力，并增强对输入图像变化的鲁棒性。'
- en: By following these features, users will gain practical insights into building,
    fine-tuning, and optimizing CNN models for image classification tasks using the
    CIFAR-10 dataset. They will learn how to systematically experiment with different
    architectural components, regularization techniques, and optimization strategies
    to achieve superior performance and accuracy in object recognition.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这些功能，用户将获得关于使用 CIFAR-10 数据集构建、微调和优化 CNN 模型以进行图像分类任务的实用见解。他们将学习如何系统地实验不同的架构组件、正则化技术和优化策略，以实现卓越的性能和准确性，在物体识别中达到更高的精度。
- en: Prompting strategy
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示策略
- en: To leverage ChatGPT for machine learning, we need to have a clear understanding
    of how to implement prompting strategies specifically for code generation for
    machine learning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用 ChatGPT 进行机器学习，我们需要清楚地了解如何实现针对代码生成的特定于机器学习的提示策略。
- en: Let’s brainstorm what we would like to achieve in this task to get a better
    understanding of what needs to go into the prompts.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们头脑风暴一下我们希望在这次任务中实现的目标，以便更好地理解需要包含在提示中的内容。
- en: 'Strategy 1: Task-Actions-Guidelines (TAG) prompt strategy'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 策略 1：任务-行动-指南（TAG）提示策略
- en: '**1.1 - Task**: The specific task or goal is to build and optimize a CNN model
    for the CIFAR-10 dataset.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.1 - 任务**：具体任务是构建和优化 CIFAR-10 数据集的 CNN 模型。'
- en: '**1.2 - Actions**: The key steps involved in building and optimizing a CNN
    model for the CIFAR-10 dataset include:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.2 - 行动**：构建和优化 CIFAR-10 数据集的 CNN 模型的关键步骤包括：'
- en: '**Preprocessing the image data**: Normalize the pixel values and resize the
    images to a standardized size.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预处理图像数据**：归一化像素值并将图像调整到标准尺寸。'
- en: '**Model construction**: Define the baseline CNN model architecture with a single
    convolutional layer.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型构建**：定义具有单个卷积层的基线 CNN 模型架构。'
- en: '**1.3 - Guidelines**: We will provide the following guidelines to ChatGPT in
    our prompt:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.3 - 指南**：在我们的提示中，我们将向 ChatGPT 提供以下指南：'
- en: The code should be compatible with Jupyter Notebook.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码应与 Jupyter Notebook 兼容。
- en: Ensure that there are detailed comments for each line of code.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保每行代码都有详细的注释。
- en: You have to explain each line of code in detail, covering each method used in
    the code.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您必须详细解释每一行代码，涵盖代码中使用的每个方法。
- en: 'Strategy 2: Persona-Instructions-Context (PIC) prompt strategy'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 策略 2：角色-指令-上下文（PIC）提示策略
- en: '**2.1 - Persona**: Adopt the persona of a beginner who needs step-by-step guidance
    on building and optimizing CNN models for image classification tasks.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.1 - 角色扮演**：扮演一个需要逐步指导构建和优化用于图像分类任务的 CNN 模型的初学者角色。'
- en: '**2.2 - Instructions**: Request ChatGPT to generate code for each feature one
    step at a time and wait for user feedback before proceeding to the next step.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.2 - 指令**：请求 ChatGPT 逐个生成每个功能的代码，并在进行下一步之前等待用户反馈。'
- en: '**2.3 - Context**: Given that the focus is on building CNN models for image
    classification tasks using the CIFAR-10 dataset, ChatGPT is already aware of the
    dataset and its characteristics, so additional context may not be necessary.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.3 - 上下文**：鉴于重点是使用 CIFAR-10 数据集构建用于图像分类任务的 CNN 模型，ChatGPT 已经了解该数据集及其特征，因此可能不需要额外的上下文。'
- en: 'Strategy 3: Learn-Improvise-Feedback-Evaluate (LIFE) prompt strategy'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 策略 3：学习-即兴创作-反馈-评估（LIFE）提示策略
- en: '**3.1 - Learn**:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.1 - 学习**：'
- en: Emphasize the importance of learning about CNN models and their components,
    including convolutional layers, pooling layers, dropout regularization, batch
    normalization, data augmentation, and optimization algorithms.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强调了解 CNN 模型和其组件的重要性，包括卷积层、池化层、dropout 正则化、批量归一化、数据增强和优化算法。
- en: '**3.2 - Improvise**:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.2 - 改进**：'
- en: We will improvise later by adding more layers, dropout layers, pooling, data
    augmentation, and so on.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将在后面通过添加更多层、dropout 层、池化、数据增强等来改进。
- en: '**3.3 - Feedback**:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.3 - 反馈**：'
- en: Share code and model outputs for feedback to ensure effective learning and understanding.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分享代码和模型输出以供反馈，以确保有效的学习和理解。
- en: Incorporate suggestions and critiques to refine the model and the approach**.**
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将建议和批评纳入，以完善模型和方法**。
- en: Provide errors to troubleshoot and resolve the issues.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供错误以排除故障和解决问题。
- en: '**3.4- Evaluate**:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.4- 评估**：'
- en: Execute the code provided by ChatGPT to ensure accuracy and validity. This is
    used throughout the chapter.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 执行 ChatGPT 提供的代码，以确保准确性和有效性。这一点在本章中会反复使用。
- en: Building a CNN model to accurately classify the CIFAR-10 images using the free
    version of ChatGPT
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 ChatGPT 的免费版本构建 CNN 模型，以准确分类 CIFAR-10 图像
- en: The premium version of ChatGPT has a code interpreter, but it doesn’t support
    deep learning libraries such as Keras and TensorFlow, which are required to build
    ML code. Hence, for this chapter, we will stick to the free version of ChatGPT.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 的付费版本具有代码解释器，但它不支持构建 ML 代码所需的深度学习库，如 Keras 和 TensorFlow。因此，在本章中，我们将坚持使用
    ChatGPT 的免费版本。
- en: 'Feature 1: Building the baseline CNN model with a single convolutional layer'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征 1：使用单个卷积层构建基线 CNN 模型
- en: Let’s craft our initial prompt for the baseline model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为基线模型制定初始提示。
- en: '[P**rompt]**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[**提示**]'
- en: 'I want to create a simple classification model for CIFAR-10 dataset (TAG 1.1)
    that consists of a single-layer CNN model (PIC 2.2). It should consist of following
    steps (TAG 1.2) and provide one step at a time, waiting for user feedback (PIC
    2.2):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我想为 CIFAR-10 数据集创建一个简单的分类模型（TAG 1.1），该模型由单个层 CNN 模型（PIC 2.2）组成。它应包括以下步骤（TAG
    1.2），并一次提供一个步骤，等待用户反馈（PIC 2.2）：
- en: 'Preprocessing the image data: Normalize the pixel values and resize the images
    to a standardized size.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理图像数据：归一化像素值并将图像调整到标准尺寸。
- en: 'Model construction: Define the baseline CNN model architecture with a single
    convolutional layer.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型构建：定义具有单个卷积层的基线 CNN 模型架构。
- en: 'I am a beginner user (PIC 2.1), so please provide step-by-step code and strictly
    follow the below instructions (TAG 1.3):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我是一个初学者用户（PIC 2.1），因此请提供逐步的代码，并严格遵循以下说明（TAG 1.3）：
- en: The code should be compatible with Jupyter Notebook.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码应与 Jupyter Notebook 兼容。
- en: Ensure that there are detailed comments for each line of code.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保每行代码都有详细的注释。
- en: You have to explain each line of code in detail, covering each method used in
    the code.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须详细解释每一行代码，涵盖代码中使用的每个方法。
- en: '[E**nd of prompt]**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[**提示结束**]'
- en: You should receive a response similar to the following, where ChatGPT has provided
    us with the code for the data preprocessing step along with detailed comments
    and explanations.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该收到以下类似的响应，其中 ChatGPT 为我们提供了数据预处理步骤的代码，并附有详细的注释和解释。
- en: '[P**rompt response]**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[**快速响应**]'
- en: 'Sure, let’s start with the first step: preprocessing the image data. In this
    step, we will normalize the pixel values and resize the images to a standardized
    size.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，让我们从第一步开始：预处理图像数据。在这一步中，我们将归一化像素值并将图像调整到标准尺寸。
- en: '[PRE0]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, let’s break down each line of code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐行分析代码：
- en: 'We import the necessary libraries:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入必要的库：
- en: '`numpy` for numerical operations.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `numpy` 进行数值运算。
- en: '`tensorflow` for building and training the model.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `tensorflow` 构建 和训练模型。
- en: cifar10 dataset from `tensorflow.keras.datasets` for loading CIFAR-10 data.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用来自 `tensorflow.keras.datasets` 的 `cifar10` 数据集加载 CIFAR-10 数据。
- en: '`to_categorical` function from `tensorflow.keras.utils` for one-hot encoding
    labels.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用来自 `tensorflow.keras.utils` 的 `to_categorical` 函数进行标签的一热编码。
- en: resize function from `skimage.transform` for resizing images.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用来自 `skimage.transform` 的 `resize` 函数调整图像大小。
- en: We load the CIFAR-10 dataset using `cifar10.load_data()` function, which returns
    training and testing data splits.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用 `cifar10.load_data()` 函数加载 CIFAR-10 数据集，该函数返回训练和测试数据分割。
- en: We normalize pixel values of images to the range `[0, 1]` by dividing by `255.0`.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过除以 `255.0` 将图像的像素值归一化到 `[0, 1]` 范围内。
- en: We define the standardized size for resizing images (e.g., 32x32 pixels).
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义图像调整大小的标准化大小（例如，32x32像素）。
- en: We resize all images in the training and testing sets to the standardized size
    using list comprehension and the resize function.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用列表推导和resize函数将训练集和测试集中的所有图像调整到标准化大小。
- en: Finally, we print the shapes of the training and testing datasets after preprocessing
    to verify the changes.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们在预处理后打印训练集和测试集的形状，以验证变化。
- en: Let me know if you have any questions or if you’d like to proceed to the next
    step!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有任何问题或想要进行下一步，请告诉我！
- en: '**[End of response]**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束]**'
- en: We will now apply the evaluate prompting strategy (LIFE 3.4) and validate the
    code by executing the code in Google Colab for every step. The code loads the
    model from Keras and normalizes the images. The code runs perfectly fine without
    requiring any modifications or returning any errors.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将应用评估提示策略（LIFE 3.4），并通过在Google Colab的每一步执行代码来验证代码。该代码从Keras加载模型并规范化图像。代码运行良好，无需任何修改或返回任何错误。
- en: Please refer to the Building a CNN Model for CIFAR-10 with `ChatGPT.ipynb` notebook
    for the executable code snippets or copy the code from the prompt response.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考`Building a CNN Model for CIFAR-10 with `ChatGPT.ipynb`笔记本中的可执行代码片段，或从提示响应中复制代码。
- en: '![](img/B21232_15_02.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21232_15_02.png)'
- en: 'Figure 15.2: Code execution – data preprocessing'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.2：代码执行 – 数据预处理
- en: We will now instruct ChatGPT to proceed to the next step.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将指示ChatGPT进行下一步。
- en: '[P**rompt]**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**rompt**]'
- en: Let’s proceed to the next step.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行下一步。
- en: '[E**nd of prompt]**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[E**nd of prompt**]'
- en: We should receive a response like the following, where ChatGPT should provide
    the code for creating a baseline model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下响应，其中ChatGPT应提供创建基线模型的代码。
- en: '[P**rompt response]**'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**rompt response**]'
- en: Great! The next step is to construct the baseline CNN model architecture with
    a single convolutional layer.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！下一步是构建具有单个卷积层的基线CNN模型架构。
- en: '[PRE1]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let’s explain each line of code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们解释每一行代码：
- en: 'We import the necessary libraries:'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们导入必要的库：
- en: Sequential from `tensorflow.keras.models` to create a sequential model.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`tensorflow.keras.models`中的`Sequential`创建一个序列模型。
- en: '`Conv2D`, `MaxPooling2D`, `Flatten`, and `Dense` layers from `tensorflow.keras.layers`
    to define the different types of layers in the CNN model.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.layers`中获取`Conv2D`、`MaxPooling2D`、`Flatten`和`Dense`层，以定义CNN模型中的不同类型层。
- en: We define the baseline CNN model architecture using the Sequential API, which
    allows us to create a linear stack of layers.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用序列API定义基线CNN模型架构，这允许我们创建线性堆叠的层。
- en: 'Within the Sequential model:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在序列模型中：
- en: We add a convolutional layer (`Conv2D`) with 32 filters, a kernel size of `(3,
    3)`, and `ReLU` activation function. The `input_shape` parameter defines the shape
    of input images.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们添加一个卷积层（`Conv2D`），包含32个过滤器，核大小为`(3, 3)`，以及`ReLU`激活函数。`input_shape`参数定义了输入图像的形状。
- en: We add a max pooling layer (`MaxPooling2D`) with a pool size of `(2, 2)` to
    downsample the feature maps.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们添加一个最大池化层（`MaxPooling2D`），池化大小为`(2, 2)`，以对特征图进行下采样。
- en: We flatten the output of the convolutional layer using the `Flatten` layer to
    prepare it for the fully connected layers.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`Flatten`层将卷积层的输出展平，以便为全连接层做准备。
- en: We add a fully connected layer (`Dense`) with 64 neurons and a `ReLU` activation
    function.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们添加一个全连接层（`Dense`），包含64个神经元和一个`ReLU`激活函数。
- en: Finally, we add the output layer with 10 neurons (one for each class in CIFAR-10)
    and the `softmax` activation function.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们添加一个输出层，包含10个神经元（每个CIFAR-10类别一个）和`softmax`激活函数。
- en: 'We compile the model using `model.compile()` with the following:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`model.compile()`编译模型，以下为配置：
- en: '`optimizer=''adam''` to use the `Adam` optimizer.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`optimizer='adam'`来使用`Adam`优化器。
- en: '`loss=''sparse_categorical_crossentropy''` as the loss function, suitable for
    classification tasks with integer labels.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`loss='sparse_categorical_crossentropy'`作为损失函数，适用于具有整数标签的分类任务。
- en: '`metrics=[''accuracy'']` to monitor the accuracy during training.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`metrics=['accuracy']`来监控训练过程中的准确率。
- en: We display the summary of the model architecture using `model.summary()`.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`model.summary()`显示模型架构的摘要。
- en: Let me know if you have any questions or if you’d like to make any adjustments!
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有任何问题或想要进行调整，请告诉我！
- en: '**[End of response]**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束]**'
- en: We execute the code in the notebook and it runs perfectly. A model summary is
    printed, which includes the `Conv2d` layer with 32 filters and 896 params, followed
    by a `MaxPooling2D` layer, a flatten layer, which doesn’t have any parameters,
    then a dense layer with 64 neurons and the ReLU activation function, and finally
    the dense layer with 10 neurons and the softmax activation function.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在笔记本中执行代码，它运行得非常完美。打印了一个模型摘要，其中包括32个滤波器和896个参数的`Conv2d`层，接着是一个`MaxPooling2D`层，一个没有参数的扁平层，然后是一个有64个神经元的密集层和ReLU激活函数，最后是一个有10个神经元和softmax激活函数的密集层。
- en: '![](img/B21232_15_03.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21232_15_03.png)'
- en: 'Figure 15.3: Code execution – baseline model summary'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.3：代码执行 – 基线模型摘要
- en: We will now instruct ChatGPT to proceed to the next step.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将指示ChatGPT继续下一步。
- en: '[P**rompt]**'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**rompt**]'
- en: Let’s proceed to the next step.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续下一步。
- en: '[E**nd of prompt]**'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[E**nd of prompt**]'
- en: We should receive a response like the following where ChatGPT should provide
    the code for training the model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下类似的响应，其中ChatGPT应提供训练模型的代码。
- en: '[P**rompt response]**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**rompt response**]'
- en: Sure! The next step is to train the model on the preprocessed CIFAR-10 dataset.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当然！下一步是在预处理过的CIFAR-10数据集上训练模型。
- en: '[PRE2]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here’s an explanation of the code:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码的解释：
- en: We train the model using the fit method on the preprocessed training data `(x_train_resized)`
    and corresponding labels `(y_train)`.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`fit`方法在预处理过的训练数据`(x_train_resized)`和相应的标签`(y_train)`上训练模型。
- en: We specify the number of training epochs (`epochs=10`) to train the model for
    10 iterations over the entire dataset.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们指定训练轮数（`epochs=10`）以在整个数据集上迭代10次来训练模型。
- en: We set the batch size (`batch_size=32`) to specify the number of samples per
    gradient update. It is a hyperparameter that determines how many samples are processed
    before updating the model’s parameters.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将批大小（`batch_size=32`）设置为指定每次梯度更新时的样本数量。这是一个超参数，它决定了在更新模型参数之前处理多少个样本。
- en: We provide the validation data (`validation_data=(x_test_resized, y_test)`)
    to evaluate the model’s performance on the testing data after each epoch.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们提供验证数据（`validation_data=(x_test_resized, y_test)`）以在每个epoch后评估模型在测试数据上的性能。
- en: The `fit` method returns a history object containing training metrics (e.g.,
    loss and accuracy) for each epoch, which can be used for analysis and visualization.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fit`方法返回一个包含每个epoch的训练指标（例如，损失和准确率）的历史对象，这些指标可用于分析和可视化。'
- en: Let me know if you have any questions or if you’d like to proceed with evaluating
    the model or making any adjustments!
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有任何问题或想要继续评估模型或进行任何调整，请告诉我！
- en: '**[End of response]**'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**[End of response**]'
- en: We execute the code and it runs without any errors. The model is trained for
    10 epochs, after which we receive a validation accuracy of 62.6%, which is not
    bad for a basic model.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行代码，它运行无误。模型训练了10个epoch，之后我们收到62.6%的验证准确率，对于一个基本模型来说还不错。
- en: '![](img/B21232_15_04.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21232_15_04.png)'
- en: 'Figure 15.4: Code execution – model training'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.4：代码执行 – 模型训练
- en: We will now instruct ChatGPT to proceed to the next step to evaluate the model
    performance.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将指示ChatGPT继续下一步以评估模型性能。
- en: '[P**rompt]**'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**rompt**]'
- en: Let’s proceed to the next step.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续下一步。
- en: '[E**nd of prompt]**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[E**nd of prompt**]'
- en: We should receive a response like the following where ChatGPT should provide
    the code for model evaluation along with comments.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下类似的响应，其中ChatGPT应提供模型评估的代码以及注释。
- en: '[P**rompt response]**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**rompt response**]'
- en: Sure! The next step is to evaluate the trained model on the testing dataset
    and visualize its performance.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 当然！下一步是对测试数据集上的训练模型进行评估并可视化其性能。
- en: '[PRE3]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here’s what this code does:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的作用如下：
- en: We import `matplotlib.pyplot` to visualize the training history.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们导入`matplotlib.pyplot`来可视化训练历史。
- en: We evaluate the trained model on the testing dataset using the evaluate method,
    which returns the test loss and accuracy.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`evaluate`方法在测试数据集上评估训练模型，该方法返回测试损失和准确率。
- en: We print the test loss and test accuracy to assess the model’s performance on
    unseen data.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们打印测试损失和测试准确率以评估模型在未见数据上的性能。
- en: We plot the training and validation accuracy over epochs using `matplotlib.pyplot`.
    The history object returned by the `fit` method contains accuracy values for both
    training and validation datasets across epochs.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`matplotlib.pyplot`绘制训练和验证准确率随epoch的变化。`fit`方法返回的历史对象包含训练和验证数据集在各个epoch的准确率值。
- en: The `history.history['accuracy']` contains training accuracy values.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`history.history[''accuracy'']`包含训练准确率值。'
- en: The `history.history['val_accuracy']` contains validation accuracy values.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`history.history[''val_accuracy'']`包含验证准确率值。'
- en: The plot helps us visualize how well the model is learning over time and whether
    it is overfitting or underfitting.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该图表帮助我们可视化模型随时间学习的效果，以及它是否过拟合或欠拟合。
- en: Let me know if you have any questions or if you’d like to analyze the results
    further!
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有任何问题或想要进一步分析结果，请告诉我！
- en: '**[End of response]**'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束]**'
- en: We execute the code and it runs without any errors. It evaluates the test loss
    and test accuracy (62.5%) and also plots the graph of training accuracy vs. validation
    accuracy, showing that model is not performing well on the validation set.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行代码，它运行没有任何错误。它评估了测试损失和测试准确率（62.5%），并绘制了训练准确率与验证准确率的图表，显示模型在验证集上的表现不佳。
- en: '![](img/B21232_15_05.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21232_15_05.png)'
- en: 'Figure 15.5: Code execution – model evaluation'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.5：代码执行 – 模型评估
- en: This completes feature 1, where we achieved an accuracy of 0.6259 (62.59%) with
    our baseline CNN model. (Please note that you may receive different accuracy scores
    even after running the exact same code.) Next, we will move to the second feature
    of adding more layers to the model and learn how ChatGPT can assist us in that.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了功能1，我们使用基线CNN模型实现了0.6259（62.59%）的准确率。（请注意，即使运行了完全相同的代码，您也可能收到不同的准确率分数。）接下来，我们将转向第二个功能，即在模型中添加更多层，并了解ChatGPT如何帮助我们。
- en: 'Feature 2: Experimenting with the addition of convolutional layers'
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 功能2：实验添加卷积层
- en: Now that we have a baseline model architecture, let us try adding layers to
    it. We will apply the prompting strategy to improvise the model (LIFE 3.4) and
    ask ChatGPT to provide us the code for it, also note the importance of providing
    specific instructions by using the phrase (on top of our baseline model) (PIC
    2.2) and keyword incrementally (PIC 2.2); without these, the response wouldn’t
    be fully consistent with our expectations.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了基线模型架构，让我们尝试向其中添加层。我们将应用提示策略来改进模型（LIFE 3.4），并要求ChatGPT提供相应的代码，同时注意使用短语（在基线模型之上）（PIC
    2.2）和关键词增量（PIC 2.2）的重要性；没有这些，响应将不会完全符合我们的期望。
- en: '[P**rompt]**'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示]'
- en: We received an accuracy of 62.59 with the baseline model, so now I would like
    to experiment with the addition of two consecutive layers of 64 filters first
    and then two consecutive layers of 128 filters on top of our baseline model. Then,
    let’s compare the result of these two incremental changes with our baseline model.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在基线模型上获得了62.59的准确率，因此现在我想先尝试在基线模型上添加两层连续的64个滤波器，然后在其之上再添加两层连续的128个滤波器。然后，让我们比较这两个增量变化与基线模型的成果。
- en: '[E**nd of prompt]**'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示结束]'
- en: We should receive a response like the following where ChatGPT understands the
    request and provides us with the code for a modified model with consecutive layers
    of 64 filters and another one with consecutive layers of 128 filters.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下响应，其中ChatGPT理解请求并为我们提供具有连续64个滤波器层的修改模型代码，以及另一个具有连续128个滤波器层的模型代码。
- en: '[P**rompt response]**'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[响应提示]'
- en: Sure! Let’s first add two consecutive layers of 64 filters to the baseline model
    and train it again. After that, we’ll add two consecutive layers of 128 filters
    and train the model once more. Finally, we’ll compare the results of these two
    changes with the baseline model.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 当然！让我们首先在基线模型上添加两层连续的64个滤波器，并重新训练它。然后，我们将添加两层连续的128个滤波器并再次训练模型。最后，我们将比较这两个变化与基线模型的成果。
- en: 'Here’s how we can modify the baseline model to include additional layers:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们如何修改基线模型以包含额外层的方法：
- en: '[PRE4]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, let’s explain the modifications:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们解释一下这些修改：
- en: We define the modified model (`modified_model_64`) by adding two consecutive
    convolutional layers with 64 filters each after the baseline model’s architecture.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过在基线模型架构之后添加两个连续的64个滤波器卷积层来定义修改后的模型（`modified_model_64`）。
- en: We compile the modified model with the same settings as the baseline model.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用与基线模型相同的设置编译了修改后的模型。
- en: We train the modified model (`modified_model_64`) on the preprocessed training
    data (`x_train_resized`).
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在预处理后的训练数据（`x_train_resized`）上训练了修改后的模型（`modified_model_64`）。
- en: We evaluate the performance of the modified model on the testing dataset (`x_test_resized`)
    and print the test loss and accuracy.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在测试数据集（`x_test_resized`）上评估修改后模型的性能，并打印测试损失和准确率。
- en: 'Next, we’ll repeat the process for adding two consecutive layers of 128 filters:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将重复添加两层连续128个滤波器的过程：
- en: '[PRE5]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This code follows the same structure as the previous modification but adds two
    consecutive convolutional layers with 128 filters each. We train and evaluate
    the model accordingly.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码遵循与之前修改相同的结构，但添加了两个连续的具有128个滤波器的卷积层。我们相应地训练和评估模型。
- en: Let me know if you have any questions or if you’d like to proceed with the modifications!
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何问题或想要继续修改，请告诉我！
- en: '**[End of response]**'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束]**'
- en: We first execute the code that defines the two additional layers with 64 filters.
    It runs perfectly fine, training the model and achieving an improved accuracy
    of 71%.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先执行定义两个具有64个滤波器的额外层的代码。它运行得很好，训练了模型并实现了71%的改进准确率。
- en: '![](img/B21232_15_06.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21232_15_06.png)'
- en: 'Figure 15.6: Adding two consecutive layers with 64 filters to the model'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.6：向模型添加两个具有64个滤波器的连续层
- en: Next, we execute the code to add further depth to the model by adding two more
    layers with 128 filters. In this case, the code results in an error, so we will
    use a prompting strategy and provide the error back to ChatGPT.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们执行代码，通过添加两个具有128个滤波器的额外层来增加模型的深度。在这种情况下，代码导致错误，因此我们将使用提示策略，并将错误反馈给ChatGPT。
- en: You should see a `ValueError` from running the code.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在运行代码时看到一个`ValueError`。
- en: '[P**rompt]**'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示]**'
- en: 'We received the below error. Also, ensure that maxpooling doesn’t reduce the
    dimension too much for 128 filters. Error is below:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收到了以下错误。同时，确保最大池化不会过多地减少128个滤波器的维度。错误如下：
- en: '[PRE6]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[E**nd of prompt]**'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示结束]**'
- en: We should receive a response like the following where ChatGPT understands the
    request and provides us with the modified code to resolve the issue.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下响应，其中ChatGPT理解请求并为我们提供解决该问题的修改后的代码。
- en: '[P**rompt response]**'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示响应]**'
- en: It seems we’re encountering an issue where the dimensions after the last max
    pooling layer are too small for the subsequent convolutional layer with 128 filters.
    To address this, we’ll adjust the architecture to ensure compatibility between
    layers.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们遇到了一个问题，即最后一个最大池化层之后的维度对于具有128个滤波器的后续卷积层来说太小。为了解决这个问题，我们将调整架构以确保层之间的兼容性。
- en: 'Here’s the corrected code:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是修正后的代码：
- en: '[PRE7]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In this modification:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次修改中：
- en: We’ve removed the max pooling layer after the last convolutional layer with
    64 filters to ensure that the feature map dimensions are not reduced too much
    before applying the subsequent convolutional layers with 128 filters.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在最后一个具有64个滤波器的卷积层之后移除了最大池化层，以确保在应用具有128个滤波器的后续卷积层之前，特征图维度不会减少太多。
- en: We’ve added `same` padding to the convolutional layers with 128 filters to ensure
    compatibility with the input dimensions.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在具有128个滤波器的卷积层中添加了`same`填充，以确保与输入维度兼容。
- en: The rest of the architecture remains the same.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剩余的架构保持不变。
- en: This adjustment should resolve the issue, and the model should compile and train
    properly. Let me know if you have any questions or if you encounter any further
    issues!
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这个调整应该会解决这个问题，模型应该能够正确编译和训练。如果你有任何问题或遇到任何进一步的问题，请告诉我！
- en: '**[End of response]**'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束]**'
- en: Let’s execute the code, which removes some max pooling layers and also has `padding
    = 'same'` added to ensure the dimensions are compatible. It runs successfully,
    training the model but reducing the accuracy to 69%.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行代码，该代码删除了一些最大池化层，并且添加了`padding = 'same'`以确保维度兼容。它运行成功，训练了模型但将准确率降低到69%。
- en: '![A screenshot of a computer  Description automatically generated](img/B21232_15_07.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，描述自动生成](img/B21232_15_07.png)'
- en: 'Figure 15.7: Added layers with 128 filters'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.7：添加了具有128个滤波器的层
- en: Based on these results, we can observe that the addition of more layers achieved
    a slightly higher accuracy compared to the baseline model. However, the differences
    in accuracy are relatively small, indicating that the addition of layers did not
    significantly improve the model’s performance and the model is also still not
    regularized. Let’s move on to the next feature and experiment with dropout regularization.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些结果，我们可以观察到，与基线模型相比，增加更多层实现了略微更高的准确率。然而，准确率的差异相对较小，表明增加层并没有显著提高模型性能，并且模型仍未进行正则化。让我们继续到下一个特征，并尝试dropout正则化。
- en: 'Feature 3: Incorporating dropout regularization'
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征3：引入dropout正则化
- en: Now that we have learned how to add more layers, we will now experiment with
    a dropout layer. We will apply the prompting strategy to improvise the model (LIFE
    3.4) and ask ChatGPT to provide us the code for it.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何添加更多层，我们将现在尝试使用dropout层。我们将应用提示策略来改进模型（LIFE 3.4），并要求ChatGPT提供相应的代码。
- en: Also note that we have applied the prompting strategy of using specific instructions
    (PIC 2.2) by asking it to add the dropout over the previously provided code.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 还请注意，我们已经通过要求在之前提供的代码上添加dropout来应用了使用特定指令（PIC 2.2）的提示策略。
- en: '[P**rompt]**'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[**提示**]'
- en: The model accuracy of the baseline model was 62.5%, with additional layers of
    64 filters it was 71%, and the further addition of layers with 128 filters reduced
    it to 69%. Can we please apply dropout regularization to the model code given
    by you in your previous message?
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 基线模型的模型准确率为62.5%，增加64个滤波器的额外层后为71%，进一步添加具有128个滤波器的层将其降低到69%。请在我们之前消息中给出的模型代码上应用dropout正则化吗？
- en: '[E**nd of prompt]**'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[**提示结束**]'
- en: We should receive a response like the following where ChatGPT understands the
    request and provides us with the code for the addition of a dropout layer.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下类似的响应，其中ChatGPT理解请求并提供添加dropout层的代码。
- en: '[P**rompt response]**'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[**快速响应**]'
- en: 'Sure, let’s add dropout regularization to the modified model with two consecutive
    layers of 128 filters. Dropout regularization helps prevent overfitting by randomly
    dropping a fraction of the units (neurons) during training. Here’s how we can
    modify the model to include dropout layers:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，让我们向修改后的模型添加两个连续的128个滤波器的dropout正则化。dropout正则化通过在训练过程中随机丢弃一部分单元（神经元）来帮助防止过拟合。以下是我们可以如何修改模型以包含dropout层：
- en: '[PRE8]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In this modification:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次修改中：
- en: We add dropout layers after the convolutional layers with 128 filters. We set
    the dropout rates to 25% and 50% for the first and last dropout layers, respectively.
    These values can be adjusted based on experimentation and the level of regularization
    needed.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在具有128个滤波器的卷积层之后添加dropout层。我们将第一个和最后一个dropout层的dropout率分别设置为25%和50%。这些值可以根据实验和所需的正则化水平进行调整。
- en: We compile and train the modified model with dropout regularization using the
    same settings as before.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用与之前相同的设置编译和训练带有dropout正则化的修改后的模型。
- en: We evaluate the performance of the modified model with dropout regularization
    on the testing dataset and print the test loss and accuracy.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在测试数据集上评估带有dropout正则化的修改后模型的性能，并打印测试损失和准确率。
- en: Adding dropout regularization may help improve the generalization performance
    of the model and reduce overfitting. Let me know if you have any questions or
    if you’d like to explore further!
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 添加dropout正则化可能有助于提高模型的泛化性能并减少过拟合。如果您有任何问题或想要进一步探索，请告诉我！
- en: '**[End of response]**'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束**]'
- en: We execute the code, which defines a model with a dropout layer. It also trains
    and evaluates the performance of the model and prints the model summary covering
    loss and accuracy. Note that the dropout layer does not add any parameters to
    the model.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行代码，该代码定义了一个包含dropout层的模型。它还训练并评估了模型的性能，并打印了包含损失和准确率的模型摘要。请注意，dropout层不会向模型添加任何参数。
- en: '![](img/B21232_15_08.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21232_15_08.png)'
- en: 'Figure 15.8: Code execution – dropout layer'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.8：代码执行 – dropout层
- en: We can see that there is not much difference between the accuracies, so we will
    apply the Learn prompting strategy (LIFE 3.1) and ask ChatGPT to provide the plot
    of the loss and accuracy to see the impact of regularization.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到准确率之间没有太大差异，因此我们将应用Learn提示策略（LIFE 3.1），并要求ChatGPT提供损失和准确率的图表，以查看正则化的影响。
- en: '[P**rompt]**'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '[**提示**]'
- en: '[PRE9]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Can you please provide the plots for loss and accuracy to see if there has been
    any regularization and also explain it?
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 请您提供损失和准确性的图表，以便查看是否进行了正则化，并解释一下。
- en: '**[End of prompt]**'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示结束**]'
- en: We should receive a response like the following where ChatGPT provides the code
    and explains the significance of the plots.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下类似的响应，其中ChatGPT提供代码并解释图表的重要性。
- en: '[P**rompt response]**'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[**快速响应**]'
- en: Certainly! Let’s plot the training and validation loss and accuracy curves for
    the modified model with dropout regularization. This will help us visualize how
    dropout regularization affects the training process and the model’s performance.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 当然！让我们绘制修改后的模型使用dropout正则化的训练和验证损失及准确率曲线。这将帮助我们可视化dropout正则化对训练过程和模型性能的影响。
- en: '[PRE10]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Explanation:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 解释：
- en: '**Training Loss vs. Validation Loss**: This plot shows the trend of training
    and validation loss over epochs. If there is a large gap between training and
    validation loss, it indicates overfitting. Dropout regularization aims to reduce
    overfitting by preventing the model from becoming overly reliant on specific features,
    thereby reducing the gap between training and validation loss.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练损失与验证损失对比**：此图显示了训练和验证损失随epoch的变化趋势。如果训练和验证损失之间存在较大差距，则表明过拟合。dropout正则化的目的是通过防止模型过度依赖特定特征来减少训练和验证损失之间的差距，从而减少过拟合。'
- en: '**Training Accuracy vs. Validation Accuracy**: This plot shows the trend of
    training and validation accuracy over epochs. Dropout regularization can also
    help improve generalization performance, leading to better validation accuracy,
    especially if overfitting was present in the model.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练准确率与验证准确率对比**：此图显示了训练和验证准确率随epoch的变化趋势。dropout正则化也可以帮助提高泛化性能，从而提高验证准确率，尤其是在模型中存在过拟合的情况下。'
- en: By observing these plots, we can assess whether dropout regularization effectively
    mitigated overfitting and improved the model’s generalization performance. Let
    me know if you have any questions or if you need further explanation!
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察这些图表，我们可以评估dropout正则化是否有效地减轻了过拟合并提高了模型泛化性能。如果您有任何问题或需要进一步解释，请告诉我！
- en: '**[End of response]**'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '**[回复结束]**'
- en: We will execute the code and plot the graphs to understand the impact of dropout.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将执行代码并绘制图表，以了解dropout的影响。
- en: '![A graph of a training and vallation accuracy  Description automatically generated](img/B21232_15_09.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![训练和验证准确率的图表  描述自动生成](img/B21232_15_09.png)'
- en: 'Figure 15.9: Effect of the dropout layer'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.9：dropout层的影响
- en: The output graphs show the training and validation loss and accuracy for a model
    trained on the CIFAR-10 dataset with a dropout layer. Both losses decrease over
    epochs while the accuracy improves, indicating effective learning. The small gap
    between training and validation metrics suggests minimal overfitting, likely aided
    by the dropout layer. Overall, the model generalizes well to new data, demonstrating
    good performance.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的图表显示了在CIFAR-10数据集上训练并带有dropout层的模型训练和验证损失及准确率。随着准确率的提高，损失在各个epoch中下降，这表明学习是有效的。训练和验证指标之间的小差距表明过拟合最小，这可能是由于dropout层的作用。总体而言，模型对新数据具有良好的泛化能力，表现出良好的性能。
- en: 'Feature 4: Implementing batch normalization'
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 功能4：实现批量归一化
- en: We will apply the prompting strategy to improvise the model (LIFE 3.4) and ask
    ChatGPT to provide us the code for adding batch normalization to the previously
    provided code.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将应用提示策略来改进模型（LIFE 3.4），并要求ChatGPT为我们提供将批量归一化添加到之前提供的代码中的代码。
- en: '[P**rompt]**'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示]**'
- en: I want to apply the batch normalization on the previously provided code.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我想将批量归一化应用于之前提供的代码。
- en: '[E**nd of prompt]**'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示结束]**'
- en: We should receive a response like the following where ChatGPT understands the
    request and provides us with the code for batch normalization on our existing
    model.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下类似的回复，其中ChatGPT理解请求并为我们提供在现有模型上添加批量归一化的代码。
- en: '[P**rompt response]**'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**[提示回复]**'
- en: 'Sure! We can apply batch normalization to the convolutional layers of the model
    to improve training stability and convergence speed. Here’s how we can modify
    the model to include batch normalization layers:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 当然！我们可以将批量归一化应用于模型的卷积层，以提高训练稳定性和收敛速度。以下是修改模型以包含批量归一化层的步骤：
- en: '[PRE11]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In this modification:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次修改中：
- en: We add `BatchNormalization` layers after each convolutional layer. Batch normalization
    normalizes the activations of the previous layer at each batch, making training
    more stable and accelerating convergence.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在每个卷积层之后添加`BatchNormalization`层。批量归一化在每个批次中对前一层的激活进行归一化，使训练更加稳定并加速收敛。
- en: We compile and train the modified model with batch normalization using the same
    settings as before.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用与之前相同的设置编译和训练带有批量归一化的修改后模型。
- en: We evaluate the performance of the modified model with batch normalization on
    the testing dataset and print the test loss and accuracy.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用测试数据集评估带有批量归一化的修改后模型的性能，并打印测试损失和准确率。
- en: Adding batch normalization can improve the performance and stability of the
    model during training. Let me know if you have any questions or if you’d like
    further explanation!
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 添加批量归一化可以在训练过程中提高模型性能和稳定性。如果您有任何问题或需要进一步解释，请告诉我！
- en: '**[End of response]**'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '**[回复结束]**'
- en: We will execute the code, evaluate the model’s performance, and print the results.
    Note that batch normalization adds a small number of parameters, unlike dropout
    or maxpooling.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将执行代码，评估模型性能，并打印结果。注意，批量归一化添加了少量参数，与dropout或maxpooling不同。
- en: '![](img/B21232_15_10.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21232_15_10.png)'
- en: 'Figure 15.10: Batch normalization'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.10：批量归一化
- en: We can see that there are some non-trainable parameters. Let us make use of
    the Learn prompting strategy (LIFE 3.1) to understand the calculations of non-trainable
    parameters.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到有一些非训练参数。让我们利用Learn提示策略（LIFE 3.1）来理解非训练参数的计算。
- en: '[P**rompt]**'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示]**'
- en: Can you please explain the calculation of 832 in the model summary?
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 请解释模型摘要中832的计算方法？
- en: '[PRE12]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[E**nd of prompt]**'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示结束]**'
- en: We should receive a response like the following where ChatGPT understands the
    request and provides us with an explanation of the calculation of non-trainable
    parameters.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到如下响应，其中ChatGPT理解了请求，并提供了非训练参数计算的解释。
- en: '[P**rompt response]**'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示响应]**'
- en: 'In the model you’ve described, the non-trainable parameters are 832, which
    specifically come from the batch normalization layers. Here’s how this number
    is calculated:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在您描述的模型中，非训练参数是832，这具体来自批量归一化层。以下是这个数字的计算方法：
- en: Components of Batch Normalization
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 批量归一化的组成部分
- en: 'Each batch normalization layer introduces parameters that are used to normalize
    the outputs of the previous layer. Specifically, these parameters are:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 每个批量归一化层引入了用于归一化前一层输出的参数。具体来说，这些参数是：
- en: '**Gamma (scale factor)**'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Gamma（缩放因子）**'
- en: '**Beta (shift factor)**'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Beta（平移因子）**'
- en: '**Moving average of means**'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均值移动平均值**'
- en: '**Moving average of variances**'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方差移动平均值**'
- en: The gamma and beta parameters are trainable, while the moving means and variances
    are non-trainable. Each of these groups (gamma/beta and moving mean/variance)
    has as many elements as there are channels in the input to the batch normalization
    layer.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: gamma和beta参数是可训练的，而移动均值和方差是不可训练的。这些组（gamma/beta和移动均值/方差）的元素数量与批量归一化层的输入通道数相同。
- en: Calculation
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 计算
- en: 'Based on your model configuration:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的模型配置：
- en: '**Batch Normalization after first Conv2D layer (32 channels):**'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '**在第一个Conv2D层（32通道）之后的批量归一化：**'
- en: 'Moving means: 32'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动均值：32
- en: 'Moving variances: 32'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动方差：32
- en: '**Batch Normalization after second Conv2D layer (64 channels):**'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '**在第二个Conv2D层（64通道）之后的批量归一化：**'
- en: 'Moving means: 64'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动均值：64
- en: 'Moving variances: 64'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动方差：64
- en: '**Batch Normalization after third Conv2D layer (128 channels):**'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '**在第三个Conv2D层（128通道）之后的批量归一化：**'
- en: 'Moving means: 128'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动均值：128
- en: 'Moving variances: 128'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动方差：128
- en: '**Batch Normalization after fourth Conv2D layer (128 channels):**'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '**在第四个Conv2D层（128通道）之后的批量归一化：**'
- en: 'Moving means: 128'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动均值：128
- en: 'Moving variances: 128'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动方差：128
- en: '**Batch Normalization after Dense layer (64 units):**'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '**在Dense层（64个单元）之后的批量归一化：**'
- en: 'Moving means: 64'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动均值：64
- en: 'Moving variances: 64'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移动方差：64
- en: Total Non-Trainable Parameters
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 总非训练参数
- en: 'Summing these values gives the total number of non-trainable parameters: `[
    (32 + 32) + (64 + 64) + (128 + 128) + (128 + 128) + (64 + 64) = 832 ]`'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 求和这些值得到非训练参数的总数：`[ (32 + 32) + (64 + 64) + (128 + 128) + (128 + 128) + (64 +
    64) = 832 ]`
- en: Each batch normalization layer contributes twice the number of its input’s channels
    to the non-trainable parameter count (once for moving means and once for moving
    variances). This results in a total of 832 non-trainable parameters for your model.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 每个批量归一化层将其输入通道数的两倍贡献给非训练参数计数（一次用于移动均值，一次用于移动方差）。这导致您的模型总共有832个非训练参数。
- en: '**[End of response]**'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束]**'
- en: Now that we have learned how to add batch normalization and also the calculation
    of non-trainable parameters, let us move to the next feature and try different
    optimizers.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何添加批量归一化以及非训练参数的计算，让我们转向下一个特性并尝试不同的优化器。
- en: 'Feature 5: Optimizing with different optimizers'
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征5：使用不同的优化器进行优化
- en: We will apply the prompting strategy to improvise the model (LIFE 3.4) and ask
    ChatGPT to provide us the code for experimenting with different optimizers such
    as SGD, Adam, and RMSProp.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将应用提示策略来改进模型（LIFE 3.4），并要求ChatGPT为我们提供用于实验不同优化器（如SGD、Adam和RMSProp）的代码。
- en: '[P**rompt]**'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示]**'
- en: Can you please provide me with code for the SGD, Adam, and RMSprop optimizers,
    and compare the previously provided code for the model and its performance for
    various optimizer combinations?
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 请您提供SGD、Adam和RMSprop优化器的代码，并比较之前提供的模型及其在不同优化器组合下的性能。
- en: '[E**nd of prompt]**'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示结束]**'
- en: We should receive a response like the following where ChatGPT understands the
    request and provides us with the code for different optimizers along with comparison
    results.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下类似的响应，其中ChatGPT理解了请求，并为我们提供了不同优化器的代码以及比较结果。
- en: '[P**rompt response]**'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示响应]**'
- en: 'Certainly! We can compare the performance of the model with different optimizers
    such as SGD, Adam, and RMSprop. Here’s how we can modify the model and train it
    with different optimizers:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 当然！我们可以比较使用SGD、Adam和RMSprop等不同优化器的模型性能。以下是修改模型并使用不同优化器训练的方法：
- en: '[PRE13]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In this code:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中：
- en: We import the `SGD`, `Adam`, and `RMSprop` optimizers from `tensorflow.keras.optimizers`.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们从`tensorflow.keras.optimizers`中导入`SGD`、`Adam`和`RMSprop`优化器。
- en: We define a list of optimizers to iterate over.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了一个优化器列表以进行迭代。
- en: For each optimizer, we define the model with batch normalization and the current
    optimizer.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个优化器，我们定义具有批量归一化和当前优化器的模型。
- en: We compile and train the model with the current optimizer.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用当前优化器编译和训练模型。
- en: We evaluate the model’s performance on the testing dataset with the current
    optimizer.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用当前优化器在测试数据集上评估模型的性能。
- en: We print the test accuracy for each optimizer and store the test accuracies
    in a list.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们打印每个优化器的测试准确率并将测试准确率存储在列表中。
- en: Finally, we plot the test accuracies for each optimizer to compare their performance.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们绘制每个优化器的测试准确率以比较它们的性能。
- en: This code allows us to compare the performance of the model trained with different
    optimizers. Let me know if you have any questions or if you’d like further explanation!
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码使我们能够比较使用不同优化器训练的模型的性能。如果您有任何问题或需要进一步解释，请告诉我！
- en: '**[End of response]**'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束]**'
- en: We execute the code, which defines the models with different optimizers. It
    also trains the models, evaluates their performance, and prints the results of
    the comparison of their performance.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行代码，该代码定义了具有不同优化器的模型。它还训练模型，评估其性能，并打印出它们性能比较的结果。
- en: '![](img/B21232_15_11.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21232_15_11.png)'
- en: 'Figure 15.11: Code execution – different optimizers'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.11：代码执行 – 不同优化器
- en: Based on these results, we can observe that the RMSprop optimizer achieved the
    highest accuracy, followed by Adam and SGD. This indicates that RMSprop performed
    better in optimizing the model’s parameters and improving its performance on the
    testing data.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些结果，我们可以观察到RMSprop优化器实现了最高的准确率，其次是Adam和SGD。这表明RMSprop在优化模型参数和改进测试数据上的性能方面表现更好。
- en: Let us move on to our last feature and apply the DavidNet architecture.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续到最后一个特性，并应用DavidNet架构。
- en: 'Feature 6: Applying the DavidNet architecture'
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特性6：应用DavidNet架构
- en: We will apply the prompting strategy to improvise the model (LIFE 3.4) and ask
    ChatGPT to provide us the code for DavidNet and also learn about it using the
    Learn prompting strategy (LIFE 3.1).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将应用提示策略来改进模型（LIFE 3.4），并要求ChatGPT提供DavidNet的代码，并使用学习提示策略（LIFE 3.1）了解它。
- en: '[P**rompt]**'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示]**'
- en: Tell me what is so special about DavidNet architecture?
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 请告诉我DavidNet架构有什么特别之处？
- en: '[E**nd of prompt]**'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示结束]**'
- en: We should receive a response like the following where ChatGPT will provide us
    with an explanation of DavidNet.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下类似的响应，其中ChatGPT将提供DavidNet的解释。
- en: '[P**rompt response]**'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示响应]**'
- en: 'DavidNet architecture is notable for its simplicity and effectiveness in achieving
    high accuracy on image classification tasks, particularly on the CIFAR-10 dataset.
    Here are some key aspects that make DavidNet special:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: DavidNet架构因其简单性和在图像分类任务上实现高准确率而著称，尤其是在CIFAR-10数据集上。以下是使DavidNet特殊的一些关键方面：
- en: '**Residual Blocks**: DavidNet utilizes residual blocks, which allow for easier
    training of very deep neural networks. Residual connections enable the network
    to learn residual mappings, making it easier to train deeper networks without
    vanishing or exploding gradients.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**残差块**：DavidNet利用残差块，这使得训练非常深的神经网络变得更加容易。残差连接使网络能够学习残差映射，这使得在没有梯度消失或梯度爆炸的情况下训练更深的网络变得更容易。'
- en: '**Batch Normalization**: Batch normalization is applied after each convolutional
    layer, which helps stabilize and speed up the training process by normalizing
    the activations of each layer. This improves the convergence of the model during
    training and helps prevent overfitting.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量归一化**: 在每个卷积层之后应用批量归一化，这有助于通过归一化每一层的激活来稳定和加速训练过程。这提高了模型在训练过程中的收敛性，并有助于防止过拟合。'
- en: '**Skip Connections**: Skip connections (also known as identity shortcuts) are
    used within residual blocks. These connections allow the gradient to flow directly
    through the network, mitigating the vanishing gradient problem and facilitating
    the training of very deep networks.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跳过连接**: 跳过连接（也称为恒等快捷方式）在残差块中使用。这些连接允许梯度直接通过网络流动，减轻梯度消失问题并促进非常深网络的训练。'
- en: '**Max Pooling**: Max pooling layers are used to reduce the spatial dimensions
    of the feature maps, aiding in the extraction of important features while reducing
    computational complexity.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大池化**: 最大池化层用于减少特征图的空間维度，有助于提取重要特征同时降低计算复杂度。'
- en: '**Dense Layers**: Fully connected (dense) layers are employed at the end of
    the network to perform classification based on the learned features from the convolutional
    layers.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**密集层**: 在网络的末端使用全连接（密集）层来根据卷积层学习到的特征进行分类。'
- en: '**Learning Rate Schedule**: DavidNet uses a learning rate schedule with warmup
    epochs and a decay factor to gradually adjust the learning rate during training.
    This helps to stabilize training and improve convergence.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习率调度**: DavidNet使用带有预热周期和衰减因子的学习率调度，在训练过程中逐步调整学习率。这有助于稳定训练并提高收敛性。'
- en: '**Regularization**: Although not explicitly mentioned in the architecture,
    regularization techniques such as weight decay can be applied to prevent overfitting
    and improve generalization performance.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正则化**: 虽然在架构中没有明确提及，但可以应用如权重衰减等正则化技术来防止过拟合并提高泛化性能。'
- en: Overall, DavidNet strikes a balance between model complexity and effectiveness,
    demonstrating that even relatively simple architectures can achieve impressive
    results with appropriate design choices and training strategies.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，DavidNet在模型复杂性和有效性之间取得了平衡，证明了即使相对简单的架构，通过适当的设计选择和训练策略也能取得令人印象深刻的成果。
- en: '**[End of response]**'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束]**'
- en: We will try to learn about the residual blocks and ask a follow-up question
    to ChatGPT.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试了解残差块并向ChatGPT提出后续问题。
- en: '[P**rompt]**'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**提示**]'
- en: What are residual blocks?
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 残差块是什么？
- en: '[E**nd of prompt]**'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[E**nd of prompt**]'
- en: We should receive a response like the following where ChatGPT provides us with
    an explanation about residual blocks.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到如下响应，其中ChatGPT为我们提供关于残差块的解释。
- en: '[P**rompt response]**'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**提示响应**]'
- en: Residual blocks are a fundamental component of deep neural networks, particularly
    in architectures like ResNet and its variants. They are designed to address the
    vanishing gradient problem that occurs during the training of very deep networks.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 残差块是深度神经网络的基本组成部分，尤其是在ResNet及其变体等架构中。它们旨在解决在非常深网络的训练过程中出现的梯度消失问题。
- en: 'Residual blocks are composed of two main paths: the identity path and the shortcut
    path. The identity path is the main path through the block, while the shortcut
    path provides a direct connection for the input to skip one or more layers.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 残差块由两个主要路径组成：恒等路径和快捷路径。恒等路径是块中的主要路径，而快捷路径为输入提供了一个直接连接，以便跳过一层或多层。
- en: 'Here’s a basic overview of how residual blocks work:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是残差块工作原理的基本概述：
- en: '**Identity Path**: The input to the residual block is passed through a series
    of convolutional layers, batch normalization, and activation functions. This sequence
    of operations allows the network to learn a representation of the input data.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**恒等路径**: 输入通过一系列卷积层、批量归一化和激活函数传递到残差块。这一系列操作允许网络学习输入数据的表示。'
- en: '**Shortcut Path**: The original input to the residual block (identity) is passed
    through a separate path, bypassing some of the convolutional layers. This path
    is known as the “shortcut” or “skip” connection.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快捷路径**: 残差块（恒等）的原始输入通过一个单独的路径传递，绕过了一些卷积层。这条路径被称为“快捷”或“跳过”连接。'
- en: '**Merge Operation**: The outputs from the identity path and the shortcut path
    are combined using element-wise addition. This merge operation adds the original
    input to the output of the convolutional layers.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合并操作**：恒等路径和快捷路径的输出通过逐元素加法进行合并。这种合并操作将原始输入添加到卷积层的输出中。'
- en: '**Activation Function**: Finally, the combined output undergoes an activation
    function, typically a **ReLU** (**Rectified Linear Unit**) activation, to introduce
    non-linearity.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活函数**：最后，合并后的输出经过一个激活函数，通常是**ReLU（修正线性单元**）激活，以引入非线性。'
- en: The key idea behind residual blocks is that the shortcut connection allows the
    gradient to flow more easily through the network during backpropagation. If the
    identity path (convolutional layers) learns to approximate the identity function,
    the residual block can learn to adjust the output by a small residual mapping,
    hence the name “residual block.”
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 基于残差块的关键思想是，快捷连接允许在反向传播过程中梯度更容易地通过网络流动。如果恒等路径（卷积层）学会近似恒等函数，残差块就可以通过一个小残差映射来调整输出，因此得名“残差块”。
- en: By enabling the direct propagation of the input signal through the shortcut
    connection, residual blocks mitigate the vanishing gradient problem and facilitate
    the training of very deep neural networks. This architecture has been highly successful
    in various tasks, leading to the development of deeper and more accurate models.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 通过启用通过快捷连接直接传播输入信号，残差块减轻了梯度消失问题，并促进了非常深层的神经网络训练。这种架构在各种任务中取得了高度成功，导致了更深、更精确的模型的发展。
- en: '**[End of response]**'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '**[End of response**]'
- en: We will now ask ChatGPT to provide us the code for DavidNet and here we will
    give some information to ChatGPT that we obtained from an internet search to achieve
    better accuracy using CIFAR-10.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将要求ChatGPT提供DavidNet的代码，并且我们将向ChatGPT提供从互联网搜索中获得的信息，以使用CIFAR-10实现更好的准确度。
- en: '[P**rompt]**'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**rompt**]'
- en: 'Can you give me the code for DavidNet which offers better accuracy? The hyperparameters
    used in DavidNet include:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 你能给我DavidNet的代码吗？它提供了更好的准确度？DavidNet使用的超参数包括：
- en: 'Batch size: 512'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量大小：512
- en: 'Momentum: 0.9'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动量：0.9
- en: 'Weight decay: 0.000125'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重衰减：0.000125
- en: 'Learning rate: 0.4'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习率：0.4
- en: 'Number of epochs: 24'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练轮数：24
- en: 'Warmup epochs: 5'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预热轮数：5
- en: '[E**nd of prompt]**'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '[E**nd of prompt**]'
- en: We should receive a response like the following where ChatGPT understands the
    request and provides us with the code for DavidNet.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到一个ChatGPT理解请求并提供DavidNet代码的响应。
- en: '[P**rompt response]**'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**rompt response**]'
- en: 'Certainly! Here’s an implementation of DavidNet with the specified hyperparameters:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 当然！以下是根据指定超参数实现的DavidNet：
- en: '[PRE14]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In this code:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中：
- en: We define the DavidNet architecture, which consists of convolutional layers,
    residual blocks, max pooling, and dense layers.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了DavidNet架构，它由卷积层、残差块、最大池化和密集层组成。
- en: We define a learning rate scheduler function to adjust the learning rate during
    training, implementing both warmup and exponential decay as specified.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了一个学习率调度函数来调整训练过程中的学习率，实现了既定的预热和指数衰减。
- en: 'We compile the model with the **Stochastic Gradient Descent** (**SGD**) optimizer
    with the specified hyperparameters: `momentum=0.9` and `decay=0.000125`.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用指定超参数的**随机梯度下降（SGD**）优化器编译模型：`momentum=0.9`和`decay=0.000125`。
- en: We train the model using the CIFAR-10 dataset, with the specified batch size,
    number of epochs, and learning rate scheduler.
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用CIFAR-10数据集训练模型，指定了批量大小、训练轮数和学习率调度器。
- en: This implementation follows the described architecture and hyperparameters of
    DavidNet. Let me know if you have any questions or if you need further assistance!
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 这个实现遵循了DavidNet描述的架构和超参数。如果你有任何问题或需要进一步的帮助，请告诉我！
- en: '**[End of response]**'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '**[End of response**]'
- en: We execute the code provided by ChatGPT and it encounters an error, since ChatGPT
    is trained on older versions of machine learning code and hence provided us with
    a deprecated method for decay.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行了ChatGPT提供的代码，但遇到了错误，因为ChatGPT是在较老的机器学习代码版本上训练的，因此提供了过时的衰减方法。
- en: You should see a `ValueError` from running the code.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在运行代码时看到一个`ValueError`。
- en: We will provide the error to ChatGPT and see if the modified code provided by
    ChatGPT works.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将提供错误信息给ChatGPT，看看ChatGPT提供的修改后的代码是否可行。
- en: '[P**rompt]**'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '[P**rompt**]'
- en: '[PRE15]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[E**nd of prompt]**'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '[E**nd of prompt**]'
- en: We should receive a response like the following where ChatGPT understands the
    request and provides us with the modified code with the decay issue addressed.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该收到以下类似的响应，其中ChatGPT理解了请求，并提供了修改后的代码，解决了衰减问题。
- en: '[P**rompt response]**'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示响应]'
- en: 'Thank you for the update. It seems the decay parameter is deprecated in the
    new Keras optimizer. We can use a different method to implement weight decay,
    such as using a custom callback. Let’s modify the code accordingly:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您的更新。看起来新的Keras优化器中已经弃用了衰减参数。我们可以使用不同的方法来实现权重衰减，例如使用自定义回调。让我们相应地修改代码：
- en: '[PRE16]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In this modified code:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个修改后的代码中：
- en: We define a custom callback `SGDLearningRateDecay` to implement the learning
    rate decay strategy. This callback adjusts the learning rate based on the current
    epoch and the specified warmup epochs and decay factor.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了一个自定义回调`SGDLearningRateDecay`来实现学习率衰减策略。此回调根据当前epoch和指定的预热epoch以及衰减因子调整学习率。
- en: We remove the decay parameter from the optimizer initialization and set it to
    the default value of 0.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们从优化器初始化中移除了衰减参数，并将其设置为默认值0。
- en: We use the custom learning rate decay callback during model training.
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在模型训练期间使用自定义的学习率衰减回调。
- en: This approach allows us to implement the weight decay strategy without using
    the decay parameter in the optimizer. Let me know if you have any questions or
    if you need further assistance!
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法允许我们实现权重衰减策略，而无需在优化器中使用衰减参数。如果您有任何问题或需要进一步的帮助，请告诉我！
- en: '**[End of response]**'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '**[响应结束]**'
- en: We execute the code provided by ChatGPT and it runs perfectly fine. It provides
    a model summary and the accuracy score has improved to 77%.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行了ChatGPT提供的代码，它运行得非常完美。它提供了一个模型摘要，准确率已提高到77%。
- en: '[PRE17]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/B21232_15_12.png)'
  id: totrans-392
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B21232_15_12.png)'
- en: 'Figure 15.12: DavidNet – improved accuracy'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.12：DavidNet – 提高准确性
- en: Assignment
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作业
- en: Increase the number of epochs for feature 3 when the dropout layer is added.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加dropout层时，增加特征3的epoch数量。
- en: Challenge
  id: totrans-396
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 挑战
- en: Try to improve the model performance to greater than 80%. Feel free to use any
    architecture.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试提高模型性能，使其超过80%。请随意使用任何架构。
- en: Summary
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored how to effectively use AI assistants like ChatGPT
    to learn and experiment with **convolutional neural network** (**CNN**) models.
    The strategies provided a clear step-by-step approach to experimenting with different
    techniques for building and training CNN models using the CIFAR-10 dataset.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了如何有效地使用像ChatGPT这样的AI助手来学习和实验**卷积神经网络**（**CNN**）模型。提供的策略提供了一个清晰的逐步方法，用于使用CIFAR-10数据集实验不同的CNN模型构建和训练技术。
- en: Each step was accompanied by detailed instructions, code generation, and user
    validation, ensuring a structured learning experience. We started by building
    a baseline CNN model, where we learned the essential preprocessing steps, including
    normalizing pixel values and resizing images. It guided you through generating
    beginner-friendly code that is compatible with Jupyter notebooks, ensuring that
    even those new to the field could easily grasp the fundamentals of CNN construction.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 每一步都伴随着详细的说明、代码生成和用户验证，确保了结构化的学习体验。我们首先构建了一个基线CNN模型，学习了必要的预处理步骤，包括归一化像素值和调整图像大小。它引导您生成适合初学者的代码，该代码与Jupyter笔记本兼容，确保即使是新进入该领域的人也能轻松掌握CNN构建的基本原理。
- en: As we progressed, our AI assistant became an integral part of the learning process,
    helping us delve into more complex areas such as adding layers, implementing dropout
    and batch normalization, and experimenting with different optimization algorithms.
    Each of these steps was accompanied by incremental code updates, and we paused
    regularly to review the feedback, making sure the learning was paced appropriately
    and responsive to your needs. Our journey culminated with the implementation of
    the DavidNet architecture, applying all the strategies and techniques we had learned.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们不断进步，我们的AI助手成为了学习过程中的一个重要部分，帮助我们深入探索更复杂的内容，例如添加层、实现dropout和批量归一化，以及尝试不同的优化算法。每一步都伴随着代码的逐步更新，我们定期暂停以审查反馈，确保学习节奏适当且能够满足您的需求。我们的旅程以实现DavidNet架构告终，应用了我们所学到的所有策略和技术。
- en: In the next chapter, we will learn how to use ChatGPT to generate the code for
    clustering and PCA.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何使用ChatGPT生成聚类和PCA的代码。
- en: Join our community on Discord
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的社区Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/aicode](https://packt.link/aicode)'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/aicode](https://packt.link/aicode)'
- en: '![](img/QR_Code510410532445718281.png)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code510410532445718281.png)'
