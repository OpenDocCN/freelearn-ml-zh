<html><head></head><body>
		<div id="_idContainer117">
			<h1 id="_idParaDest-177"><em class="italic"><a id="_idTextAnchor184"/>Chapter 9</em>: Drift and Drift Detection</h1>
			<p>Throughout the previous chapters, you have discovered plenty of ways to build <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) models that work in an online manner. They are able to update their learned decision rules from one single observation rather than having to retrain completely as is common in most ML models.</p>
			<p>One reason that this is great is streaming, as these models will allow you to work and learn continuously. However, we could argue that a traditional ML model can also predict on a single observation. Even batch learning and offline models can predict a single new observation at a time. To get more insight into the added value of online ML, this chapter will go in depth into drift and drift detection.</p>
			<p>To get to an improved understanding of those concepts, the chapter will start with an in-depth description of what drift is. You will then see different types of drift, including concept drift, data drift, and retraining strategy issues. </p>
			<p>After that, you will be exposed to a number of methods to detect both data drift and concept drift. You will also see a number of methods to counteract drift and will be introduced to model explicability and retraining strategies.</p>
			<p>For now, let's get started with the basics by having a deeper look at a definition of drift.</p>
			<p>This chapter will cover the following topics:</p>
			<ul>
				<li>Defining drift</li>
				<li>Introducing model explicability</li>
				<li>Measuring drift</li>
				<li>Measuring drift in Python</li>
				<li>Counteracting drift</li>
			</ul>
			<h1 id="_idParaDest-178"><a id="_idTextAnchor185"/>Technical requirements</h1>
			<p>You can find all the code for this book on GitHub at the following link: <a href="https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python">https://github.com/PacktPublishing/Machine-Learning-for-Streaming-Data-with-Python</a>. If you are not yet familiar with Git and GitHub, the easiest way to download the notebooks and code samples is by doing the following:</p>
			<ol>
				<li>Go to the link of the repository.</li>
				<li>Go to the green <strong class="bold">Code</strong> button.</li>
				<li>Select <strong class="bold">Download zip</strong>.</li>
			</ol>
			<p>When you download the ZIP file, you unzip it in your local environment, and you will be able to access the code through your preferred Python editor.</p>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor186"/>Python environment</h2>
			<p>To follow along with this book, you can download the code in the repository and execute it using your preferred Python editor.</p>
			<p>If you are not yet familiar with Python environments, I would advise you to check out Anaconda (<a href="https://www.anaconda.com/products/individual">https://www.anaconda.com/products/individual</a>), which comes with Jupyter Notebook and JupyterLab, which are both great for executing notebooks. It also comes with Spyder and <strong class="bold">Visual Studio Code</strong> (<strong class="bold">VS Code</strong>) for editing scripts and programs.</p>
			<p>If you have difficulty installing Python or the associated programs on your machine, you can check out <strong class="bold">Google Colabatory</strong> (<strong class="bold">Google Colab</strong>) (<a href="https://colab.research.google.com/">https://colab.research.google.com/</a>) or Kaggle Notebooks (<a href="https://www.kaggle.com/code">https://www.kaggle.com/code</a>), which both allow you to run Python code in online notebooks for free, without any setup required.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The code in the book will generally use Colab and Kaggle Notebooks with Python version 3.7.13, and you can set up your own environment to mimic this. </p>
			<h1 id="_idParaDest-180"><a id="_idTextAnchor187"/>Defining drift</h1>
			<p>It is a well-known and commonly observed problem that models tend to start performing worse <a id="_idIndexMarker502"/>with time. Whether your metric is accuracy, R2 score, F1 score, or anything else, you will see a slow but steady decrease in performance over time if you put models into production and do not update them.</p>
			<p>Depending on your use case, this decrease may become problematic quickly or slowly. Some use cases need to have continuous, near-perfect predictions. In some use cases— for example, for specialized ML in which the models have a direct impact on life—you would be strongly shocked if you observed a 1 percent decrease. In other use cases, ML is used more as automation than as prediction, and the business partners may not even notice a 5 percent decrease.</p>
			<p>Whether it is going to impact you is not the question here. What is sure, is that in general, you will see your models decreasing. The goal for this chapter is to make sure to find out why model performance is decreasing, how you can measure it, and what can be done about it if you decide that it is too problematic for your use case.</p>
			<p>In the next section, we will start by presenting three different types of drift that you may encounter in streaming use cases.</p>
			<h2 id="_idParaDest-181"><a id="_idTextAnchor188"/>Three types of drift</h2>
			<p>There are two reasons for drift that are generally considered with streaming data: concept drift and <a id="_idIndexMarker503"/>data drift. In this part, you will first discover concept and data drift, but you will also see how retraining strategies can have an impact on your model drifting away from the data rather than the opposite.</p>
			<h3>Concept drift</h3>
			<p>In concept drift, we try to explain worsening model performance by a change in the concept that we <a id="_idIndexMarker504"/>are modeling. This means that the statistical properties of the <a id="_idIndexMarker505"/>target variable are changing, and therefore the model is no longer adequate for our use case.</p>
			<p>A simplified example of concept change is a model that tries to forecast hot chocolate sales of a certain bar. Maybe the model was perfect for a certain while, but at some point, a competing bar got installed in the area. The underlying demand process has changed, and this was logically not included in the model, as the competition was not relevant when the model was built.</p>
			<p>When the <a id="_idIndexMarker506"/>concept changes, the model needs to be updated to take into account <a id="_idIndexMarker507"/>the most recent processes, as the model is no longer adequate for the use case. The following schematic diagram shows what goes wrong in the case of concept drift:</p>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B18335_09_1.jpg" alt="Figure 9.1 – Concept drift&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – Concept drift</p>
			<p>Now that you have seen the theory behind concept drift, the next section will present data drift—a second important type of drift.</p>
			<h3>Data drift</h3>
			<p>When we talk about data drift, we talk about a change in the statistical properties of independent <a id="_idIndexMarker508"/>variables. This is mainly relevant when we have worked with a sample of data (maybe just based on what we had available), but then we start to realize that the sample is no longer representative of the data that we are receiving at the current moment.</p>
			<p>Examples include changes in measurement machines, where a new measurement device may give slightly different measurements than the old material. Imagine we change the thermometer and our new thermometer measures about 0.5 degrees higher than the old one. You can understand that the model is not able to take this type of information into account and will make wrong predictions as the model takes the temperature <a id="_idIndexMarker509"/>higher than it should.</p>
			<p>The following schematic diagram shows what goes wrong in the case of data drift:</p>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B18335_09_2.jpg" alt="Figure 9.2 – Data drift&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.2 – Data drift</p>
			<p>Having covered two important causes of drift, the next section will present model decay and misspecification—a third drift-related problem.</p>
			<h3>Model decay and misspecification</h3>
			<p>Although not generally considered a problem of drift in the literature, I find it important to also mention <a id="_idIndexMarker510"/>problems with the model as one of the problems behind <a id="_idIndexMarker511"/>drifting and decaying performance. In real-life situations, humans are imperfect and make mistakes. Theoretically, we should expect models to be well specified and therefore not be the reasons for any problems.</p>
			<p>In practice, however, retraining of models may be wrongly automated, thereby introducing small problems that slowly, with time, add up to large problems, and this may be an important reason for model decay and lowering performance.</p>
			<p>The following schematic diagram shows what goes wrong in the case of model problems, due to any reason such as misspecification or retraining problems:</p>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/B18335_09_3.jpg" alt="Figure 9.3 – Model-induced problems&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – Model-induced problems</p>
			<p>Having seen three <a id="_idIndexMarker512"/>potential reasons for drift in streaming models, the next section <a id="_idIndexMarker513"/>will explain how model explicability can be used as a solution against drift.</p>
			<h1 id="_idParaDest-182"><a id="_idTextAnchor189"/>Introducing model explicability</h1>
			<p>When models are learning in an online fashion, they are repeatedly relearning. This relearning process <a id="_idIndexMarker514"/>is happening automatically, and it is often impossible for a human user to keep an eye on the models continuously. In addition, this would go against the main goal of doing ML as the goal is to let machines—or models—take over, rather than having continuous human intervention.</p>
			<p>When models learn or relearn, data scientists are generally faced with programmatic model-building interfaces. Imagine a random forest, in which hundreds of decision trees are acting at the same time to predict a target variable for a new observation. Even the task of printing out and looking at all those decisions would be a huge task.</p>
			<p>Model explicability is a big topic in recent advances in ML. By throwing black-box models at data-science use cases, big mistakes are occurring. An example is that when self-driving cars were trained on a biased sample containing too many white people, the cars were measured to have more accidents with black people, just because of a data-science error. Understanding what happens in your model can have a life-saving impact.</p>
			<p>When considering drift in models, it is also important to understand what happens in your model. The first model that you deploy is likely to be quite close to your expectation. After that, the model will relearn from every data point it encounters. If there are biases in the data, or if biases are occurring from over- or underfitting (and this happens when the model is running in autonomy), then at some point, you are likely to miss out on those trends.</p>
			<p>You need to make sure to set up an initial method for model explicability as well as continue to <a id="_idIndexMarker515"/>investigate the topic. In the current chapter, we'll be focusing on data drift and concept drift, but keep in mind that model misspecification can also be a huge contributor to decreasing accuracy. This will be covered in more depth in <a href="B18335_11_ePub.xhtml#_idTextAnchor215"><em class="italic">Chapter 11</em></a>.</p>
			<p>For now, let's move on to some methods for measuring drift.</p>
			<h1 id="_idParaDest-183"><a id="_idTextAnchor190"/>Measuring drift</h1>
			<p>There are two important things to consider for drift. We should first be able to measure drift, as we cannot <a id="_idIndexMarker516"/>counteract something that we are not aware of. Secondly, once we become aware of drift, we should define the right strategies for counteracting it. Let's discuss measurements for drift first.</p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor191"/>Measuring data drift</h2>
			<p>As described earlier, data drift means that the measurements are slowly changing over time, whereas <a id="_idIndexMarker517"/>the underlying concepts stay the same. To measure this, descriptive statistics can be very useful. As you have seen a lot of descriptive statistics in earlier chapters, we will not repeat the theory behind this.</p>
			<p>To apply descriptive statistics to measure data drift, we could simply set up a number of descriptive statistics and track them over time. For each variable, you could set up the following:</p>
			<ul>
				<li>Measurements of centrality (mean, median, mode)</li>
				<li>Measurements <a id="_idIndexMarker518"/>of variation (standard deviation, variance, <a id="_idIndexMarker519"/><strong class="bold">interquartile range</strong>, or <strong class="bold">IQR</strong>)</li>
				<li>Event correlation between the variables</li>
			</ul>
			<p>Besides this, it would be necessary to track drift on specific time scales. If you expect drift on very long periods, you could compute these descriptive statistics on a monthly or even yearly basis, but for quicker detection, it could be weekly, daily, or even hourly or more frequent. </p>
			<p>The comparison <a id="_idIndexMarker520"/>of these metrics over time would allow you to detect a change in the data, which would be a common cause for drift in your model.</p>
			<h2 id="_idParaDest-185"><a id="_idTextAnchor192"/>Measuring concept drift</h2>
			<p>When measuring concept drift, the best thing to do is to set up a thorough tracking of model <a id="_idIndexMarker521"/>performance over time. The performance metric that you use will depend on your use case and on the type of model you use but may include an R2 score for regression, accuracy, an F1 score for validation, or even more.</p>
			<p>When measuring model performance over time, you are likely to see a decrease if no model updating is done. With online models that relearn on every data point, this should theoretically be less of an issue. When you do see your performance decrease, this indicates that something is off somewhere in your system.</p>
			<p>If you are already measuring data drift, this would be a good first thing to look at, as data drift is likely to cause decreasing model performance. If data drift is not occurring, you are likely to have a concept drift in your system.</p>
			<p>It is important to keep in mind that measuring model drift and data drift are closely linked together in practice: it is hard to attribute decreasing performance to one specific root cause. The goal should be to keep your model performance high and find solutions for this if things are off. Measuring both performance and individual statistics and even more metrics together is what will make your strategy powerful against drift.</p>
			<p>Let's now see some Python examples of how to detect drift in modeling.</p>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor193"/>Measuring drift in Python</h1>
			<p>When measuring drift, the first thing to do is to make sure that your model is writing out logs or results <a id="_idIndexMarker522"/>in some way. For the following example, you'll use <a id="_idIndexMarker523"/>a dataset in which each prediction was logged so that we have for each prediction the input variables, the prediction, the ground truth, and the absolute differences between prediction and ground truth as an indicator of error.</p>
			<p>Logging your <a id="_idIndexMarker524"/>model's behavior is an absolute prerequisite if you <a id="_idIndexMarker525"/>want to work on drift detection. Let's start with some basic measurements that could help you to detect drift using Python.</p>
			<h2 id="_idParaDest-187"><a id="_idTextAnchor194"/>A basic intuitive approach to measuring drift</h2>
			<p>In this section, you <a id="_idIndexMarker526"/>will discover an intuitive approach to measuring drift. Here are the steps we'll follow:</p>
			<ol>
				<li value="1">To get started measuring drift on our logged results data, we start by importing the data as a <strong class="source-inline">pandas</strong> DataFrame. This is done in the following code block:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Code block 9-1</p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">data = pd.read_excel('chapter9datafile.xlsx')</p>
			<p class="source-code">data</p>
			<p>You will obtain a table that looks like the one shown here:</p>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/B18335_09_4.jpg" alt="Figure 9.4 – The data&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.4 – The data</p>
			<ol>
				<li value="2">Now that you have the drift-detection data, let's have a look at the development <a id="_idIndexMarker527"/>of the error over time by doing a <strong class="source-inline">groupby</strong> operation on the day and looking at the average error, as follows:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Code Block 9-2</p>
			<p class="source-code">data.groupby('Day')['Error'].mean()</p>
			<p>You will obtain the following result:</p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B18335_09_5.jpg" alt="Figure 9.5 – The result&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.5 – The result</p>
			<p>You can clearly see that the error is strongly increasing over time, so we can be quite certain that we have a problem with model drift here. Now, of course, it is not yet defined whether this problem is caused by a problem in the data or a problem in the concept. </p>
			<ol>
				<li value="3">Let's do an analysis with the target variable to see whether the target has experienced <a id="_idIndexMarker528"/>large changes over time. The following code does an average of the ground-truth value per day, to see whether there was a clear drift in the target variable:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Code block 9-3</p>
			<p class="source-code">data.groupby('Day')['Ground Truth'].mean()</p>
			<p>The result looks like this:</p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/B18335_09_6.jpg" alt="Figure 9.6 – The result (continued)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.6 – The result (continued)</p>
			<p>We do see a quite important change on average over this period. </p>
			<ol>
				<li value="4">Let's take our inspection further and also do this analysis for each of the independent variables. The following code does an average of the three independent variables per day to see if there is any obvious shift in there:</li>
			</ol>
			<p class="SC---Heading" lang="en-US" xml:lang="en-US">Code block 9-4</p>
			<p class="source-code">data.groupby('Day')[['X1', 'X2', 'X3']].mean()</p>
			<p>You will <a id="_idIndexMarker529"/>obtain the following result:</p>
			<div>
				<div id="_idContainer114" class="IMG---Figure">
					<img src="image/B18335_09_7.jpg" alt="Figure 9.7 – The groupby result&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.7 – The groupby result</p>
			<p>We see a very clear change happening in the third explanatory variable, <strong class="source-inline">X3</strong>. It is highly probable that this is the cause of our model shift.</p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor195"/>Measuring drift with robust tools</h2>
			<p>If you are working on small use cases and you do not want to integrate with large external <a id="_idIndexMarker530"/>platforms, the previous examples are really good. However, if you <a id="_idIndexMarker531"/>are working at a company where you are limited in resources, it may not be possible or not worth it to develop code for common use cases from scratch. </p>
			<p>Drift detection is a use case that is getting quite some popularity at the moment, so more and more robust solutions are being presented to the public—be it paid programs, cloud programs, or open source solutions.</p>
			<p>Next, I will present a number of useful solutions that you could look at if you are interested in <a id="_idIndexMarker532"/>taking on external platforms for doing your model <a id="_idIndexMarker533"/>performance follow-ups and your drift-detection use cases. As those platforms are owned by companies and are sometimes paid, I do not want to go into much depth here, but it is good to give you some pointers in case this is of interest to you.</p>
			<h3>Soda SQL</h3>
			<p>One solution that is interesting to look at is Soda SQL. This is a tool that is specific for data quality, so it is <a id="_idIndexMarker534"/>not necessarily tuned for ML use cases. However, data quality issues will almost necessarily result in problematic models, so I find it valuable to discuss this solution. </p>
			<p>You can find full information here: <a href="https://docs.soda.io/">https://docs.soda.io/</a>. Soda SQL is a tool that is really oriented toward <a id="_idIndexMarker535"/>data engineering, so I won't go too much into detail here, but I do recommend keeping it in mind for your use cases.</p>
			<h3>MLflow with whylogs</h3>
			<p>A tool that is much <a id="_idIndexMarker536"/>more oriented toward ML models <a id="_idIndexMarker537"/>in production is the <strong class="source-inline">whylogs</strong> open source Python library, which integrates with the WhyLabs app (<a href="http://whylabsapp.com">whylabsapp.com</a>). If you sign up for an account with WhyLabs, you can use their <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>) and send your <a id="_idIndexMarker538"/>model logging directly to their databases, where it will be analyzed and made accessible to you.</p>
			<h3>Neptune</h3>
			<p>A comparable tool is being delivered by Neptune (<a href="http://neptune.ai">neptune.ai</a>). The goal of Neptune is also to present an <strong class="bold">ML operations</strong> (<strong class="bold">MLOps</strong>) platform to which you can send your logging data from <a id="_idIndexMarker539"/>basically any Python (or other) model environment. After that, you <a id="_idIndexMarker540"/>can access the performance on their web <a id="_idIndexMarker541"/>platform, and all the heavy lifting for drift detection is taken off your shoulders.</p>
			<p>You have now seen some theoretical methods for measuring and detecting drift, and some start-up platforms that are proposing to do this type of work for you if you do not have the capacity <a id="_idIndexMarker542"/>to deliver it. Still, we have not talked about something equally important, which is counteracting drift.</p>
			<h1 id="_idParaDest-189"><a id="_idTextAnchor196"/>Counteracting drift</h1>
			<p>As discussed in the <a id="_idIndexMarker543"/>introduction, model drift is bound to happen. Maybe it happens very slowly or maybe it occurs quickly, but it is something that cannot really be avoided if we don't try to actively counteract it.</p>
			<p>What you will realize in the coming section is that online learning, which has been covered extensively in this book, is actually a very performant method against drift. Although we had not yet clearly defined drift, you will now come to understand that online learning has a strong added value here.</p>
			<p>We will now recapitulate two approaches for counteracting drift, depending on the type of work you <a id="_idIndexMarker544"/>are doing, as follows:</p>
			<ul>
				<li>Retraining for offline learning</li>
				<li>Online learning</li>
			</ul>
			<p>Let's start with the most traditional case, which is offline learning with retraining strategies implemented against model decay.</p>
			<h2 id="_idParaDest-190"><a id="_idTextAnchor197"/>Offline learning with retraining strategies against drift</h2>
			<p>Offline learning is still the most commonly used method for ML. In offline learning, the model is trained <a id="_idIndexMarker545"/>once and then used only for prediction. The following schematic diagram depicts the offline learning process: </p>
			<div>
				<div id="_idContainer115" class="IMG---Figure">
					<img src="image/B18335_09_8.jpg" alt="Figure 9.8 – Schematic diagram of offline learning&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.8 – Schematic diagram of offline learning</p>
			<p>To update the model, it is generally necessary to retrain the full model and deploy a new version to your production environment. This is shown in <em class="italic">Figure 9.9</em>.</p>
			<p>The advantages of this approach are that the model builder has complete control over their model. There is <a id="_idIndexMarker546"/>no risk of the model learning new—wrong—processes. This comes at the cost of not updating when data or concept drift occurs. In this way, its advantages and disadvantages are the opposite of online learning. </p>
			<h2 id="_idParaDest-191"><a id="_idTextAnchor198"/>Online learning against drift</h2>
			<p>As you have seen throughout this book, online learning is an alternative to offline learning and <a id="_idIndexMarker547"/>allows the model to update whenever a new data point arrives. The following diagram illustrates how a retraining strategy works:</p>
			<div>
				<div id="_idContainer116" class="IMG---Figure">
					<img src="image/B18335_09_9.jpg" alt="Figure 9.9 – Schematic diagram of online learning&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.9 – Schematic diagram of online learning</p>
			<p>Using online learning, the model has some autonomy in updating and will theoretically stay closer to the <a id="_idIndexMarker548"/>data: less drift should occur. However, this comes at a cost of the model builder not having full control over the theory model. Learning may go in the wrong direction, and unwanted decision rules are learned by the model.</p>
			<p>The advantages are the opposite of offline learning, and it will really depend on the business case whether to choose online or offline learning.</p>
			<h1 id="_idParaDest-192"><a id="_idTextAnchor199"/>Summary</h1>
			<p>In this chapter, you have first been introduced to the underlying foundations of model drift. You have seen that model drift and a decrease in model performance over time are to be expected in ML models in a real-life environment.</p>
			<p>Decreasing performance can generally be attributed to drifting data, drifting concepts, or model-induced problems. Drifting data occurs when data measurements change over time, but the underlying theoretical concept behind the model stays the same. Concept drift captures problems of those theoretical underlying foundations of the learned processes.</p>
			<p>Model- and model retraining-related problems are generally not considered standard reasons for drift, but they should still be monitored and taken seriously. Depending on your business case, relearning—especially if monitoring is lacking—can introduce large problems with ML systems.</p>
			<p>Data drift can generally be measured well by using descriptive statistics. Concept drift is often harder to measure, but its presence can be deduced from an otherwise inexplicable decrease in model performance. In general, the importance here is not in attributing the decreasing performance to a specific cause, but rather in solving the problem using one of the provided solutions.</p>
			<p>Retraining strategies can often be used for offline models. They are a way to update models, without giving up control of learned decision rules. Online models, as thoroughly presented throughout the earlier chapters of this book, are a great alternative to retraining offline models. The great advantage of using online models is that online models are made specifically for retraining. These models allow for a larger degree of autonomy and will prove useful in many business cases, as long as monitoring of both data and models is implemented correctly.</p>
			<p>In the next chapter, you will see how to adapt <strong class="bold">feature transformation</strong> (<strong class="bold">FT</strong>) and scaling to the online modeling case. FT and scaling are standard practice in many ML use cases, but due to drift in data—and bias in windowing—it poses some theoretical difficulties that need to be taken into account.</p>
			<h1 id="_idParaDest-193"><a id="_idTextAnchor200"/>Further reading</h1>
			<ul>
				<li>Model drift: <a href="https://www.ibm.com/cloud/watson-studio/drift">https://www.ibm.com/cloud/watson-studio/drift</a></li>
				<li>Data drift: <a href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-monitor-datasets?tabs=python">https://docs.microsoft.com/en-us/azure/machine-learning/how-to-monitor-datasets?tabs=python</a></li>
				<li>Concept drift: <a href="https://www.iguazio.com/blog/concept-drift-deep-dive-how-to-build-a-drift-aware-ml-system/">https://www.iguazio.com/blog/concept-drift-deep-dive-how-to-build-a-drift-aware-ml-system/</a></li>
				<li>Dealing with concept drift: <a href="https://neptune.ai/blog/concept-drift-best-practices">https://neptune.ai/blog/concept-drift-best-practices</a></li>
				<li>Retraining strategies: <a href="https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html">https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html</a></li>
			</ul>
		</div>
	</body></html>